arxiv-1609-08389 | A Hackathon for Classical Tibetan | http://arxiv.org/abs/1609.08389 | id:1609.08389 author:Orna Almogi, Lena Dankin, Nachum Dershowitz, Lior Wolf category:cs.CL cs.CY  published:2016-09-27 summary:We describe the course of a hackathon dedicated to the development of linguistic tools for Tibetan Buddhist studies. Over a period of five days, a group of seventeen scholars, scientists, and students developed and compared algorithms for intertextual alignment and text classification, along with some basic language tools, including a stemmer and word segmenter. version:1
arxiv-1609-08387 | Tensor Based Second Order Variational Model for Image Reconstruction | http://arxiv.org/abs/1609.08387 | id:1609.08387 author:Jinming Duan, Wil OC Ward, Luke Sibbett, Zhenkuan Pan, Li Bai category:cs.CV  published:2016-09-27 summary:Second order total variation (SOTV) models have advantages for image reconstruction over their first order counterparts including their ability to remove the staircase artefact in the reconstructed image, but they tend to blur the reconstructed image. To overcome this drawback, we introduce a new Tensor Weighted Second Order (TWSO) model for image reconstruction. Specifically, we develop a novel regulariser for the SOTV model that uses the Frobenius norm of the product of the SOTV Hessian matrix and the anisotropic tensor. We then adapt the alternating direction method of multipliers (ADMM) to solve the proposed model by breaking down the original problem into several subproblems. All the subproblems have closed-forms and can thus be solved efficiently. The proposed method is compared with a range of state-of-the-art approaches such as tensor-based anisotropic diffusion, total generalised variation, Euler's elastica, etc. Numerical experimental results of the method on both synthetic and real images from the Berkeley database BSDS500 demonstrate that the proposed method eliminates both the staircase and blurring effects and outperforms the existing approaches for image inpainting and denoising applications. version:1
arxiv-1609-08364 | Automated Breast Lesion Segmentation in Ultrasound Images | http://arxiv.org/abs/1609.08364 | id:1609.08364 author:Ibrahim Sadek, Mohamed Elawady, Viktor Stefanovski category:cs.CV  published:2016-09-27 summary:The main objective of this project is to segment different breast ultrasound images to find out lesion area by discarding the low contrast regions as well as the inherent speckle noise. The proposed method consists of three stages (removing noise, segmentation, classification) in order to extract the correct lesion. We used normalized cuts approach to segment ultrasound images into regions of interest where we can possibly finds the lesion, and then K-means classifier is applied to decide finally the location of the lesion. For every original image, an annotated ground-truth image is given to perform comparison with the obtained experimental results, providing accurate evaluation measures. version:1
arxiv-1609-08359 | emoji2vec: Learning Emoji Representations from their Description | http://arxiv.org/abs/1609.08359 | id:1609.08359 author:Ben Eisner, Tim Rocktäschel, Isabelle Augenstein, Matko Bošnjak, Sebastian Riedel category:cs.CL 68T50 I.2.7  published:2016-09-27 summary:Many current natural language processing applications for social media rely on representation learning and utilize pre-trained word embeddings. There currently exist several publicly-available, pre-trained sets of word embeddings, but they contain few or no emoji representations even as emoji usage in social media has increased. In this paper we release emoji2vec, pre-trained embeddings for all Unicode emoji which are learned from their description in the Unicode emoji standard. The resulting emoji embeddings can be readily used in downstream social natural language processing applications alongside word2vec. We demonstrate, for the downstream task of sentiment analysis, that emoji embeddings learned from short descriptions outperforms a skip-gram model trained on a large collection of tweets, while avoiding the need for contexts in which emoji need to appear frequently in order to estimate a representation. version:1
arxiv-1609-08337 | Multi-task Recurrent Model for True Multilingual Speech Recognition | http://arxiv.org/abs/1609.08337 | id:1609.08337 author:Zhiyuan Tang, Lantian Li, Dong Wang category:cs.CL cs.LG cs.NE  published:2016-09-27 summary:Research on multilingual speech recognition remains attractive yet challenging. Recent studies focus on learning shared structures under the multi-task paradigm, in particular a feature sharing structure. This approach has been found effective to improve performance on each individual language. However, this approach is only useful when the deployed system supports just one language. In a true multilingual scenario where multiple languages are allowed, performance will be significantly reduced due to the competition among languages in the decoding space. This paper presents a multi-task recurrent model that involves a multilingual speech recognition (ASR) component and a language recognition (LR) component, and the ASR component is informed of the language information by the LR component, leading to a language-aware recognition. We tested the approach on an English-Chinese bilingual recognition task. The results show that the proposed multi-task recurrent model can improve performance of multilingual recognition systems. version:1
arxiv-1609-08326 | Asynchronous Stochastic Gradient Descent with Delay Compensation for Distributed Deep Learning | http://arxiv.org/abs/1609.08326 | id:1609.08326 author:Shuxin Zheng, Qi Meng, Taifeng Wang, Wei Chen, Nenghai Yu, Zhi-Ming Ma, Tie-Yan Liu category:cs.LG cs.DC  published:2016-09-27 summary:With the fast development of deep learning, people have started to train very big neural networks using massive data. Asynchronous Stochastic Gradient Descent (ASGD) is widely used to fulfill this task, which, however, is known to suffer from the problem of delayed gradient. That is, when a local worker adds the gradient it calculates to the global model, the global model may have been updated by other workers and this gradient becomes "delayed". We propose a novel technology to compensate this delay, so as to make the optimization behavior of ASGD closer to that of sequential SGD. This is done by leveraging Taylor expansion of the gradient function and efficient approximators to the Hessian matrix of the loss function. We call the corresponding new algorithm Delay Compensated ASGD (DC-ASGD). We evaluated the proposed algorithm on CIFAR-10 and ImageNet datasets, and experimental results demonstrate that DC-ASGD can outperform both synchronous SGD and ASGD, and nearly approaches the performance of sequential SGD. version:1
arxiv-1609-08312 | Duality between Feature Selection and Data Clustering | http://arxiv.org/abs/1609.08312 | id:1609.08312 author:Chung Chan, Ali Al-Bashabsheh, Qiaoqiao Zhou, Tie Liu category:cs.IT cs.LG math.IT  published:2016-09-27 summary:The feature-selection problem is formulated from an information-theoretic perspective. We show that the problem can be efficiently solved by a recently proposed info-clustering paradigm. This reveals the fundamental duality between feature selection and data clustering,which is a consequence of the more general duality between the principal partition and the principal lattice of partitions in combinatorial optimization. version:1
arxiv-1609-09116 | Analysis of Massive Heterogeneous Temporal-Spatial Data with 3D Self-Organizing Map and Time Vector | http://arxiv.org/abs/1609.09116 | id:1609.09116 author:Yu Ding category:cs.LG cs.NE  published:2016-09-27 summary:Self-organizing map(SOM) have been widely applied in clustering, this paper focused on centroids of clusters and what they reveal. When the input vectors consists of time, latitude and longitude, the map can be strongly linked to physical world, providing valuable information. Beyond basic clustering, a novel approach to address the temporal element is developed, enabling 3D SOM to track behaviors in multiple periods concurrently. Combined with adaptations targeting to process heterogeneous data relating to distribution in time and space, the paper offers a fresh scope for business and services based on temporal-spatial pattern. version:1
arxiv-1609-08293 | The Effects of Data Size and Frequency Range on Distributional Semantic Models | http://arxiv.org/abs/1609.08293 | id:1609.08293 author:Magnus Sahlgren, Alessandro Lenci category:cs.CL  published:2016-09-27 summary:This paper investigates the effects of data size and frequency range on distributional semantic models. We compare the performance of a number of representative models for several test settings over data of varying sizes, and over test items of various frequency. Our results show that neural network-based models underperform when the data is small, and that the most reliable model over data of varying sizes and frequency ranges is the inverted factorized model. version:1
arxiv-1609-08291 | Image Retrieval with Fisher Vectors of Binary Features | http://arxiv.org/abs/1609.08291 | id:1609.08291 author:Yusuke Uchida, Shigeyuki Sakazawa, Shin'ichi Satoh category:cs.CV  published:2016-09-27 summary:Recently, the Fisher vector representation of local features has attracted much attention because of its effectiveness in both image classification and image retrieval. Another trend in the area of image retrieval is the use of binary features such as ORB, FREAK, and BRISK. Considering the significant performance improvement for accuracy in both image classification and retrieval by the Fisher vector of continuous feature descriptors, if the Fisher vector were also to be applied to binary features, we would receive similar benefits in binary feature based image retrieval and classification. In this paper, we derive the closed-form approximation of the Fisher vector of binary features modeled by the Bernoulli mixture model. We also propose accelerating the Fisher vector by using the approximate value of posterior probability. Experiments show that the Fisher vector representation significantly improves the accuracy of image retrieval compared with a bag of binary words approach. version:1
arxiv-1609-08286 | Online Unsupervised Multi-view Feature Selection | http://arxiv.org/abs/1609.08286 | id:1609.08286 author:Weixiang Shao, Lifang He, Chun-Ta Lu, Xiaokai Wei, Philip S. Yu category:cs.LG  published:2016-09-27 summary:In the era of big data, it is becoming common to have data with multiple modalities or coming from multiple sources, known as "multi-view data". Multi-view data are usually unlabeled and come from high-dimensional spaces (such as language vocabularies), unsupervised multi-view feature selection is crucial to many applications. However, it is nontrivial due to the following challenges. First, there are too many instances or the feature dimensionality is too large. Thus, the data may not fit in memory. How to select useful features with limited memory space? Second, how to select features from streaming data and handles the concept drift? Third, how to leverage the consistent and complementary information from different views to improve the feature selection in the situation when the data are too big or come in as streams? To the best of our knowledge, none of the previous works can solve all the challenges simultaneously. In this paper, we propose an Online unsupervised Multi-View Feature Selection, OMVFS, which deals with large-scale/streaming multi-view data in an online fashion. OMVFS embeds unsupervised feature selection into a clustering algorithm via NMF with sparse learning. It further incorporates the graph regularization to preserve the local structure information and help select discriminative features. Instead of storing all the historical data, OMVFS processes the multi-view data chunk by chunk and aggregates all the necessary information into several small matrices. By using the buffering technique, the proposed OMVFS can reduce the computational and storage cost while taking advantage of the structure information. Furthermore, OMVFS can capture the concept drifts in the data streams. Extensive experiments on four real-world datasets show the effectiveness and efficiency of the proposed OMVFS method. More importantly, OMVFS is about 100 times faster than the off-line methods. version:1
arxiv-1609-08281 | Robust Projection Matrix Design and Its Application in Compression | http://arxiv.org/abs/1609.08281 | id:1609.08281 author:Tao Hong, Zhihui Zhu category:cs.LG  published:2016-09-27 summary:The aim of this brief is to design a robust projection matrix for the Compressive Sensing (CS) system when the signal is not exactly sparse. The optimal projection matrix design is obtained by minimizing the Frobenius norm of the difference between the identity matrix and the Gram matrix of the equivalent dictionary $\Phi\Psi$. A novel penalty $\ \Phi\ _F$ is added to make the projection matrix robust when the sparse representation error (SRE) exists. Additionally, designing the projection matrix with a high dimensional dictionary improves the signal reconstruct accuracy when the compression rate is the same as in a low dimensional dictionary scenario. Simulation results demonstrate the effectiveness of the proposed approach comparing with the state-of-the-art methods. version:1
arxiv-1609-08267 | De-noising, Stabilizing and Completing 3D Reconstructions On-the-go using Plane Priors | http://arxiv.org/abs/1609.08267 | id:1609.08267 author:Maksym Dzitsiuk, Jürgen Sturm, Robert Maier, Lingni Ma, Daniel Cremers category:cs.CV  published:2016-09-27 summary:Creating 3D maps on robots and other mobile devices has become a reality in recent years. Online 3D reconstruction enables many exciting applications in robotics and AR/VR gaming. However, the reconstructions are noisy and generally incomplete. Moreover, during onine reconstruction, the surface changes with every newly integrated depth image which poses a significant challenge for physics engines and path planning algorithms. This paper presents a novel, fast and robust method for obtaining and using information about planar surfaces, such as walls, floors, and ceilings as a stage in 3D reconstruction based on Signed Distance Fields. Our algorithm recovers clean and accurate surfaces, reduces the movement of individual mesh vertices caused by noise during online reconstruction and fills in the occluded and unobserved regions. We implemented and evaluated two different strategies to generate plane candidates and two strategies for merging them. Our implementation is optimized to run in real-time on mobile devices such as the Tango tablet. In an extensive set of experiments, we validated that our approach works well in a large number of natural environments despite the presence of significant amount of occlusion, clutter and noise, which occur frequently. We further show that plane fitting enables in many cases a meaningful semantic segmentation of real-world scenes. version:1
arxiv-1609-09106 | HyperNetworks | http://arxiv.org/abs/1609.09106 | id:1609.09106 author:David Ha, Andrew Dai, Quoc V. Le category:cs.LG  published:2016-09-27 summary:This work explores hypernetworks: an approach of using a small network, also known as a hypernetwork, to generate the weights for a larger network. Hypernetworks provide an abstraction that is similar to what is found in nature: the relationship between a genotype - the hypernetwork - and a phenotype - the main network. Though they are also reminiscent of HyperNEAT in evolution, our hypernetworks are trained end-to-end with backpropagation and thus are usually faster. The focus of this work is to make hypernetworks useful for deep convolutional networks and long recurrent networks, where hypernetworks can be viewed as relaxed form of weight-sharing across layers. Our main result is that hypernetworks can generate non-shared weights for LSTM and achieve state-of-art results on a variety of language modeling tasks with Character-Level Penn Treebank and Hutter Prize Wikipedia datasets, challenging the weight-sharing paradigm for recurrent networks. Our results also show that hypernetworks applied to convolutional networks still achieve respectable results for image recognition tasks compared to state-of-the-art baseline models while requiring fewer learnable parameters. version:1
arxiv-1609-07859 | Visual Fashion-Product Search at SK Planet | http://arxiv.org/abs/1609.07859 | id:1609.07859 author:Taewan Kim, Seyeong Kim, Sangil Na, Hayoon Kim, Moonki Kim, Beyeongki Jeon category:cs.CV  published:2016-09-26 summary:We build a large-scale visual search system which finds similar product images given a fashion item. Defining similarity among arbitrary fashion-products is still remains a challenging problem, even there is no exact ground-truth. To resolve this problem, we define more than 90 fashion-related attributes, and combination of these attributes can represent thousands of unique fashion-styles. The fashion- attributes are one of the ingredients to define semantic similarity among fashion- product images. To build our system at scale, these fashion-attributes are again used to build an inverted indexing scheme. In addition to these fashion-attributes for semantic similarity, we extract colour and appearance features in a region-of- interest (ROI) of a fashion item for visual similarity. By sharing our approach, we expect active discussion on that how to apply current computer vision research into the e-commerce industry. version:2
arxiv-1609-06417 | Matrix Variate RBM Model with Gaussian Distributions | http://arxiv.org/abs/1609.06417 | id:1609.06417 author:Simeng Liu, Yanfeng Sun, Yongli Hu, Junbin Gao, Baocai Yin category:cs.CV  published:2016-09-21 summary:Restricted Boltzmann Machine (RBM) is a particular type of random neural network models modeling vector data based on the assumption of Bernoulli distribution. For multi-dimensional and non-binary data, it is necessary to vectorize and discretize the information in order to apply the conventional RBM. It is well-known that vectorization would destroy internal structure of data, and the binary units will limit the applying performance due to fickle real data. To address the issue, this paper proposes a Matrix variate Gaussian Restricted Boltzmann Machine (MVGRBM) model for matrix data whose entries follow Gaussian distributions. Compared with some other RBM algorithm, MVGRBM can model real value data better and it has good performance in image classification. version:2
arxiv-1609-08237 | Aligning Coordinated Text Streams through Burst Information Network Construction and Decipherment | http://arxiv.org/abs/1609.08237 | id:1609.08237 author:Tao Ge, Qing Dou, Xiaoman Pan, Heng Ji, Lei Cui, Baobao Chang, Zhifang Sui, Ming Zhou category:cs.CL H.2.8; I.2.7  published:2016-09-27 summary:Aligning coordinated text streams from multiple sources and multiple languages has opened many new research venues on cross-lingual knowledge discovery. In this paper we aim to advance state-of-the-art by: (1). extending coarse-grained topic-level knowledge mining to fine-grained information units such as entities and events; (2). following a novel Data-to-Network-to-Knowledge (D2N2K) paradigm to construct and utilize network structures to capture and propagate reliable evidence. We introduce a novel Burst Information Network (BINet) representation that can display the most important information and illustrate the connections among bursty entities, events and keywords in the corpus. We propose an effective approach to construct and decipher BINets, incorporating novel criteria based on multi-dimensional clues from pronunciation, translation, burst, neighbor and graph topological structure. The experimental results on Chinese and English coordinated text streams show that our approach can accurately decipher the nodes with high confidence in the BINets and that the algorithm can be efficiently run in parallel, which makes it possible to apply it to huge amounts of streaming data for never-ending language and information decipherment. version:1
arxiv-1609-08235 | Online Categorical Subspace Learning for Sketching Big Data with Misses | http://arxiv.org/abs/1609.08235 | id:1609.08235 author:Yanning Shen, Morteza Mardani, Georgios B. Giannakis category:stat.ML  published:2016-09-27 summary:With the scale of data growing every day, reducing the dimensionality (a.k.a. sketching) of high-dimensional data has emerged as a task of paramount importance. Relevant issues to address in this context include the sheer volume of data that may consist of categorical samples, the typically streaming format of acquisition, and the possibly missing entries. To cope with these challenges, the present paper develops a novel categorical subspace learning approach to unravel the latent structure for three prominent categorical (bilinear) models, namely, Probit, Tobit, and Logit. The deterministic Probit and Tobit models treat data as quantized values of an analog-valued process lying in a low-dimensional subspace, while the probabilistic Logit model relies on low dimensionality of the data log-likelihood ratios. Leveraging the low intrinsic dimensionality of the sought models, a rank regularized maximum-likelihood estimator is devised, which is then solved recursively via alternating majorization-minimization to sketch high-dimensional categorical data `on the fly.' The resultant procedure alternates between sketching the new incomplete datum and refining the latent subspace, leading to lightweight first-order algorithms with highly parallelizable tasks per iteration. As an extra degree of freedom, the quantization thresholds are also learned jointly along with the subspace to enhance the predictive power of the sought models. Performance of the subspace iterates is analyzed for both infinite and finite data streams, where for the former asymptotic convergence to the stationary point set of the batch estimator is established, while for the latter sublinear regret bounds are derived for the empirical cost. Simulated tests with both synthetic and real-world datasets corroborate the merits of the novel schemes for real-time movie recommendation and chess-game classification. version:1
arxiv-1609-08004 | BioLeaf: a professional mobile application to measure foliar damage caused by insect herbivory | http://arxiv.org/abs/1609.08004 | id:1609.08004 author:Bruno Machado, Jonatan Orue, Mauro Arruda, Cleidimar Santos, Diogo Sarath, Wesley Goncalves, Gercina Silva, Hemerson Pistori, Antonia Roel, Jose Rodrigues-Jr category:cs.CV  published:2016-09-26 summary:Soybean is one of the ten greatest crops in the world, answering for billion-dollar businesses every year. This crop suffers from insect herbivory that costs millions from producers. Hence, constant monitoring of the crop foliar damage is necessary to guide the application of insecticides. However, current methods to measure foliar damage are expensive and dependent on laboratory facilities, in some cases, depending on complex devices. To cope with these shortcomings, we introduce an image processing methodology to measure the foliar damage in soybean leaves. We developed a non-destructive imaging method based on two techniques, Otsu segmentation and Bezier curves, to estimate the foliar loss in leaves with or without border damage. We instantiate our methodology in a mobile application named BioLeaf, which is freely distributed for smartphone users. We experimented with real-world leaves collected from a soybean crop in Brazil. Our results demonstrated that BioLeaf achieves foliar damage quantification with precision comparable to that of human specialists. With these results, our proposal might assist soybean producers, reducing the time to measure foliar damage, reducing analytical costs, and defining a commodity application that is applicable not only to soy, but also to different crops such as cotton, bean, potato, coffee, and vegetables. version:2
arxiv-1609-08221 | Simultaneous Low-rank Component and Graph Estimation for High-dimensional Graph Signals: Application to Brain Imaging | http://arxiv.org/abs/1609.08221 | id:1609.08221 author:Rui Liu, Hossein Nejati, Ngai-Man Cheung category:cs.CV cs.LG  published:2016-09-26 summary:We propose an algorithm to uncover the intrinsic low-rank component of a high-dimensional, graph-smooth and grossly-corrupted dataset, under the situations that the underlying graph is unknown. Based on a model with a low-rank component plus a sparse perturbation, and an initial graph estimation, our proposed algorithm simultaneously learns the low-rank component and refines the graph. Our evaluations using synthetic and real brain imaging data in unsupervised and supervised classification tasks demonstrate encouraging performance. version:1
arxiv-1609-08210 | Learning to Translate for Multilingual Question Answering | http://arxiv.org/abs/1609.08210 | id:1609.08210 author:Ferhan Ture, Elizabeth Boschee category:cs.CL cs.AI  published:2016-09-26 summary:In multilingual question answering, either the question needs to be translated into the document language, or vice versa. In addition to direction, there are multiple methods to perform the translation, four of which we explore in this paper: word-based, 10-best, context-based, and grammar-based. We build a feature for each combination of translation direction and method, and train a model that learns optimal feature weights. On a large forum dataset consisting of posts in English, Arabic, and Chinese, our novel learn-to-translate approach was more effective than a strong baseline (p<0.05): translating all text into English, then training a classifier based only on English (original or translated) text. version:1
arxiv-1609-08209 | Automatic Construction of a Recurrent Neural Network based Classifier for Vehicle Passage Detection | http://arxiv.org/abs/1609.08209 | id:1609.08209 author:Evgeny Burnaev, Ivan Koptelov, German Novikov, Timur Khanipov category:cs.CV cs.LG stat.ML  published:2016-09-26 summary:Recurrent Neural Networks (RNNs) are extensively used for time-series modeling and prediction. We propose an approach for automatic construction of a binary classifier based on Long Short-Term Memory RNNs (LSTM-RNNs) for detection of a vehicle passage through a checkpoint. As an input to the classifier we use multidimensional signals of various sensors that are installed on the checkpoint. Obtained results demonstrate that the previous approach to handcrafting a classifier, consisting of a set of deterministic rules, can be successfully replaced by an automatic RNN training on an appropriately labelled data. version:1
arxiv-1609-08203 | Variational Inference with Hamiltonian Monte Carlo | http://arxiv.org/abs/1609.08203 | id:1609.08203 author:Christopher Wolf, Maximilian Karl, Patrick van der Smagt category:stat.ML  published:2016-09-26 summary:Variational inference lies at the core of many state-of-the-art algorithms. To improve the approximation of the posterior beyond parametric families, it was proposed to include MCMC steps into the variational lower bound. In this work we explore this idea using steps of the Hamiltonian Monte Carlo (HMC) algorithm, an efficient MCMC method. In particular, we incorporate the acceptance step of the HMC algorithm, guaranteeing asymptotic convergence to the true posterior. Additionally, we introduce some extensions to the HMC algorithm geared towards faster convergence. The theoretical advantages of these modifications are reflected by performance improvements in our experimental results. version:1
arxiv-1609-08201 | Robust Time-Series Retrieval Using Probabilistic Adaptive Segmental Alignment | http://arxiv.org/abs/1609.08201 | id:1609.08201 author:Shahriar Shariat, Vladimir Pavlovic category:cs.DB cs.IR stat.ML  published:2016-09-26 summary:Traditional pairwise sequence alignment is based on matching individual samples from two sequences, under time monotonicity constraints. However, in many application settings matching subsequences (segments) instead of individual samples may bring in additional robustness to noise or local non-causal perturbations. This paper presents an approach to segmental sequence alignment that jointly segments and aligns two sequences, generalizing the traditional per-sample alignment. To accomplish this task, we introduce a distance metric between segments based on average pairwise distances and then present a modified pair-HMM (PHMM) that incorporates the proposed distance metric to solve the joint segmentation and alignment task. We also propose a relaxation to our model that improves the computational efficiency of the generic segmental PHMM. Our results demonstrate that this new measure of sequence similarity can lead to improved classification performance, while being resilient to noise, on a variety of sequence retrieval problems, from EEG to motion sequence classification. version:1
arxiv-1609-08194 | Online Segment to Segment Neural Transduction | http://arxiv.org/abs/1609.08194 | id:1609.08194 author:Lei Yu, Jan Buys, Phil Blunsom category:cs.CL cs.AI cs.NE  published:2016-09-26 summary:We introduce an online neural sequence to sequence model that learns to alternate between encoding and decoding segments of the input as it is read. By independently tracking the encoding and decoding representations our algorithm permits exact polynomial marginalization of the latent segmentation during training, and during decoding beam search is employed to find the best alignment path together with the predicted output sequence. Our model tackles the bottleneck of vanilla encoder-decoders that have to read and memorize the entire input sequence in their fixed-length hidden states before producing any output. It is different from previous attentive models in that, instead of treating the attention weights as output of a deterministic function, our model assigns attention weights to a sequential latent variable which can be marginalized out and permits online generation. Experiments on abstractive sentence summarization and morphological inflection show significant performance gains over the baseline encoder-decoders. version:1
arxiv-1609-08144 | Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation | http://arxiv.org/abs/1609.08144 | id:1609.08144 author:Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Łukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes, Jeffrey Dean category:cs.CL cs.AI cs.LG  published:2016-09-26 summary:Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT's use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units ("wordpieces") for both input and output. This method provides a good balance between the flexibility of "character"-delimited models and the efficiency of "word"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google's phrase-based production system. version:1
arxiv-1609-08139 | An Unsupervised Probability Model for Speech-to-Translation Alignment of Low-Resource Languages | http://arxiv.org/abs/1609.08139 | id:1609.08139 author:Antonios Anastasopoulos, David Chiang, Long Duong category:cs.CL  published:2016-09-26 summary:For many low-resource languages, spoken language resources are more likely to be annotated with translations than with transcriptions. Translated speech data is potentially valuable for documenting endangered languages or for training speech translation systems. A first step towards making use of such data would be to automatically align spoken words with their translations. We present a model that combines Dyer et al.'s reparameterization of IBM Model 2 (fast-align) and k-means clustering using Dynamic Time Warping as a distance metric. The two components are trained jointly using expectation-maximization. In an extremely low-resource scenario, our model performs significantly better than both a neural model and a strong baseline. version:1
arxiv-1609-08124 | Learning Language-Visual Embedding for Movie Understanding with Natural-Language | http://arxiv.org/abs/1609.08124 | id:1609.08124 author:Atousa Torabi, Niket Tandon, Leonid Sigal category:cs.CV  published:2016-09-26 summary:Learning a joint language-visual embedding has a number of very appealing properties and can result in variety of practical application, including natural language image/video annotation and search. In this work, we study three different joint language-visual neural network model architectures. We evaluate our models on large scale LSMDC16 movie dataset for two tasks: 1) Standard Ranking for video annotation and retrieval 2) Our proposed movie multiple-choice test. This test facilitate automatic evaluation of visual-language models for natural language video annotation based on human activities. In addition to original Audio Description (AD) captions, provided as part of LSMDC16, we collected and will make available a) manually generated re-phrasings of those captions obtained using Amazon MTurk b) automatically generated human activity elements in "Predicate + Object" (PO) phrases based on "Knowlywood", an activity knowledge mining model. Our best model archives Recall@10 of 19.2% on annotation and 18.9% on video retrieval tasks for subset of 1000 samples. For multiple-choice test, our best model achieve accuracy 58.11% over whole LSMDC16 public test-set. version:1
arxiv-1609-07082 | Large Margin Nearest Neighbor Classification using Curved Mahalanobis Distances | http://arxiv.org/abs/1609.07082 | id:1609.07082 author:Frank Nielsen, Boris Muzellec, Richard Nock category:cs.LG cs.CG cs.CV  published:2016-09-22 summary:We consider the supervised classification problem of machine learning in Cayley-Klein projective geometries: We show how to learn a curved Mahalanobis metric distance corresponding to either the hyperbolic geometry or the elliptic geometry using the Large Margin Nearest Neighbor (LMNN) framework. We report on our experimental results, and further consider the case of learning a mixed curved Mahalanobis distance. Besides, we show that the Cayley-Klein Voronoi diagrams are affine, and can be built from an equivalent (clipped) power diagrams, and that Cayley-Klein balls have Mahalanobis shapes with displaced centers. version:2
arxiv-1609-07042 | Temporal Selective Max Pooling Towards Practical Face Recognition | http://arxiv.org/abs/1609.07042 | id:1609.07042 author:Xiang Xiang category:cs.CV  published:2016-09-22 summary:In this report, we deal with two challenges when building a real-world face recognition system - the pose variation in uncontrolled environment and the computational expense of processing a video stream. First, we argue that the frame-wise feature mean is unable to characterize the variation among frames. We propose to preserve the overall pose diversity if we want the video feature to represent the subject identity. Then identity will be the only source of variation across videos since pose varies even within a single video. Following such an untangling variation idea, we present a pose-robust face verification algorithm with each video represented as a bag of frame-wise CNN features. Second, instead of simply using all the frames, we highlight the algorithm at the key frame selection. It is achieved by pose quantization using pose distances to K-means centroids, which reduces the number of feature vectors from hundreds to K while still preserving the overall diversity. The recognition is implemented with a rank-list of one-to-one similarities (i.e., verification) using the proposed video representation. On the official 5000 video-pairs of the YouTube Face dataset, our algorithm achieves a comparable performance with state-of-the-art that averages over deep features of all frames. Particularly, the proposed generic algorithm is verified on a public dataset and yet applicable in real-world systems. version:2
arxiv-1609-08097 | Creating Causal Embeddings for Question Answering with Minimal Supervision | http://arxiv.org/abs/1609.08097 | id:1609.08097 author:Rebecca Sharp, Mihai Surdeanu, Peter Jansen, Peter Clark, Michael Hammond category:cs.CL  published:2016-09-26 summary:A common model for question answering (QA) is that a good answer is one that is closely related to the question, where relatedness is often determined using general-purpose lexical models such as word embeddings. We argue that a better approach is to look for answers that are related to the question in a relevant way, according to the information need of the question, which may be determined through task-specific embeddings. With causality as a use case, we implement this insight in three steps. First, we generate causal embeddings cost-effectively by bootstrapping cause-effect pairs extracted from free text using a small set of seed patterns. Second, we train dedicated embeddings over this data, by using task-specific contexts, i.e., the context of a cause is its effect. Finally, we extend a state-of-the-art reranking approach for QA to incorporate these causal embeddings. We evaluate the causal embedding models both directly with a casual implication task, and indirectly, in a downstream causal QA task using data from Yahoo! Answers. We show that explicitly modeling causality improves performance in both tasks. In the QA task our best model achieves 37.3% P@1, significantly outperforming a strong baseline by 7.7% (relative). version:1
arxiv-1609-08084 | Toward Socially-Infused Information Extraction: Embedding Authors, Mentions, and Entities | http://arxiv.org/abs/1609.08084 | id:1609.08084 author:Yi Yang, Ming-Wei Chang, Jacob Eisenstein category:cs.CL  published:2016-09-26 summary:Entity linking is the task of identifying mentions of entities in text, and linking them to entries in a knowledge base. This task is especially difficult in microblogs, as there is little additional text to provide disambiguating context; rather, authors rely on an implicit common ground of shared knowledge with their readers. In this paper, we attempt to capture some of this implicit context by exploiting the social network structure in microblogs. We build on the theory of homophily, which implies that socially linked individuals share interests, and are therefore likely to mention the same sorts of entities. We implement this idea by encoding authors, mentions, and entities in a continuous vector space, which is constructed so that socially-connected authors have similar vector representations. These vectors are incorporated into a neural structured prediction model, which captures structural constraints that are inherent in the entity linking task. Together, these design decisions yield F1 improvements of 1%-5% on benchmark datasets, as compared to the previous state-of-the-art. version:1
arxiv-1609-08082 | An Ontology of Preference-Based Multiobjective Evolutionary Algorithms | http://arxiv.org/abs/1609.08082 | id:1609.08082 author:Longmei Li, Iryna Yevseyeva, Vitor Basto-Fernandes, Heike Trautmann, Ning Jing, Michael Emmerich category:cs.NE cs.AI  published:2016-09-26 summary:User preference integration is of great importance in multiobjective optimization, in particular in many objective optimization. Preferences have long been considered in traditional multicriteria decision making (MCDM) which is based on mathematical programming and recently it is integrated in evolutionary multiobjective optimization (EMO), resulting in focus on preferred parts of the Pareto front instead of the whole Pareto front. The number of publications and results on preference-based multiobjective evolutionary algorithms (PMOEAs) has increased rapidly over the past decade. There already exists a large variety of preference handling methods and EMO methods, which have been combined in various ways. This article proposes to use the Web Ontology Language (OWL) to model and systematize the results developed in this field. An extensive review of the existing work is provided, based on which an ontology is built and instantiated with state of the art results. The OWL ontology is made public and open to future extension. Moreover, the usage of the ontology is exemplified for different use-cases, including training new researchers into this knowledge domain, querying for methods that match an application problem in engineering optimization, checking existence of combinations of preference models and EMO techniques, and discovering opportunities for new research and open research questions. version:1
arxiv-1609-08080 | Swipe Mosaics from Video | http://arxiv.org/abs/1609.08080 | id:1609.08080 author:Malcolm Reynolds, Tom S. F. Haines, Gabriel J. Brostow category:cs.CV  published:2016-09-26 summary:A panoramic image mosaic is an attractive visualization for viewing many overlapping photos, but its images must be both captured and processed correctly to produce an acceptable composite. We propose Swipe Mosaics, an interactive visualization that places the individual video frames on a 2D planar map that represents the layout of the physical scene. Compared to traditional panoramic mosaics, our capture is easier because the user can both translate the camera center and film moving subjects. Processing and display degrade gracefully if the footage lacks distinct, overlapping, non-repeating texture. Our proposed visual odometry algorithm produces a distribution over (x,y) translations for image pairs. Inferring a distribution of possible camera motions allows us to better cope with parallax, lack of texture, dynamic scenes, and other phenomena that hurt deterministic reconstruction techniques. Robustness is obtained by training on synthetic scenes with known camera motions. We show that Swipe Mosaics are easy to generate, support a wide range of difficult scenes, and are useful for documenting a scene for closer inspection. version:1
arxiv-1609-08078 | Robust Matrix Decomposition for Image Segmentation under Heavy Noises and Uneven Background Intensities | http://arxiv.org/abs/1609.08078 | id:1609.08078 author:Garret Vo, Chiwoo Park category:cs.CV  published:2016-09-26 summary:This paper presents a robust matrix decomposition approach that automatically segments a binary image to foreground regions and background regions under high observation noise levels and uneven background intensities. The work is motivated by the need of identifying foreground objects in a noisy electron microscopic image, but the method can be applied for a general binary classification problem. The proposed method models an input image as a matrix of image pixel values, and the matrix is represented by a mixture of three component matrices of the same size, background, foreground and noise matrices. We propose a robust matrix decomposition approach to separate the input matrix into the three components through robust singular value decomposition. The proposed approach is more robust to high image noises and uneven background than the existing matrix-based approaches, which is numerically shown using simulated images and five electron microscope images with manually achieved ground truth data. version:1
arxiv-1609-08075 | S-MART: Novel Tree-based Structured Learning Algorithms Applied to Tweet Entity Linking | http://arxiv.org/abs/1609.08075 | id:1609.08075 author:Yi Yang, Ming-Wei Chang category:cs.CL  published:2016-09-26 summary:Non-linear models recently receive a lot of attention as people are starting to discover the power of statistical and embedding features. However, tree-based models are seldom studied in the context of structured learning despite their recent success on various classification and ranking tasks. In this paper, we propose S-MART, a tree-based structured learning framework based on multiple additive regression trees. S-MART is especially suitable for handling tasks with dense features, and can be used to learn many different structures under various loss functions. We apply S-MART to the task of tweet entity linking --- a core component of tweet information extraction, which aims to identify and link name mentions to entities in a knowledge base. A novel inference algorithm is proposed to handle the special structure of the task. The experimental results show that S-MART significantly outperforms state-of-the-art tweet entity linking systems. version:1
arxiv-1609-08039 | One-Class SVM with Privileged Information and its Application to Malware Detection | http://arxiv.org/abs/1609.08039 | id:1609.08039 author:Evgeny Burnaev, Dmitry Smolyakov category:stat.ML cs.CR stat.AP  published:2016-09-26 summary:A number of important applied problems in engineering, finance and medicine can be formulated as a problem of anomaly detection. A classical approach to the problem is to describe a normal state using a one-class support vector machine. Then to detect anomalies we quantify a distance from a new observation to the constructed description of the normal class. In this paper we present a new approach to the one-class classification. We formulate a new problem statement and a corresponding algorithm that allow taking into account a privileged information during the training phase. We evaluate performance of the proposed approach using a synthetic dataset, as well as the publicly available Microsoft Malware Classification Challenge dataset. version:1
arxiv-1609-08017 | Dropout with Expectation-linear Regularization | http://arxiv.org/abs/1609.08017 | id:1609.08017 author:Xuezhe Ma, Yingkai Gao, Zhiting Hu, Yaoliang Yu, Yuntian Deng, Eduard Hovy category:cs.LG stat.ML  published:2016-09-26 summary:Dropout, a simple and effective way to train deep neural networks, has led to a number of impressive empirical successes and spawned many recent theoretical investigations. However, the gap between dropout's training and inference phases, introduced due to tractability considerations, has largely remained under-appreciated. In this work, we first formulate dropout as a tractable approximation of some latent variable model, leading to a clean view of parameter sharing and enabling further theoretical analysis. Then, we introduce (approximate) expectation-linear dropout neural networks, whose inference gap we are able to formally characterize. Algorithmically, we show that our proposed measure of the inference gap can be used to regularize the standard dropout training objective, resulting in an \emph{explicit} control of the gap. Our method is as simple and efficient as standard dropout. We further prove the upper bounds on the loss in accuracy due to expectation-linearization, describe classes of input distributions that expectation-linearize easily. Experiments on three image classification benchmark datasets demonstrate that reducing the inference gap can indeed improve the performance consistently. version:1
arxiv-1609-08009 | Grounding object perception in a naive agent's sensorimotor experience | http://arxiv.org/abs/1609.08009 | id:1609.08009 author:Alban Laflaquière, Nikolas Hemion category:cs.RO cs.LG  published:2016-09-26 summary:Artificial object perception usually relies on a priori defined models and feature extraction algorithms. We study how the concept of object can be grounded in the sensorimotor experience of a naive agent. Without any knowledge about itself or the world it is immersed in, the agent explores its sensorimotor space and identifies objects as consistent networks of sensorimotor transitions, independent from their context. A fundamental drive for prediction is assumed to explain the emergence of such networks from a developmental standpoint. An algorithm is proposed and tested to illustrate the approach. version:1
arxiv-1609-07986 | Super-resolving multiresolution images with band-independant geometry of multispectral pixels | http://arxiv.org/abs/1609.07986 | id:1609.07986 author:Nicolas Brodu category:cs.CV  published:2016-09-26 summary:A new resolution enhancement method is presented for multispectral and multi-resolution images, such as these provided by the Sentinel-2 satellites. Starting from the highest resolution bands, band-dependent information (reflectance) is separated from information that is common to all bands (geometry of scene elements). This model is then applied to unmix low-resolution bands, preserving their reflectance, while propagating band-independent information to preserve the sub-pixel details. A reference implementation is provided, with an application example for super-resolving Sentinel-2 data. version:1
arxiv-1609-07982 | Optimistic and Pessimistic Neural Networks for Scene and Object Recognition | http://arxiv.org/abs/1609.07982 | id:1609.07982 author:Rene Grzeszick, Sebastian Sudholt, Gernot A. Fink category:cs.CV  published:2016-09-26 summary:In this paper the application of uncertainty modeling to convolutional neural networks is evaluated. A novel method for adjusting the network's predictions based on uncertainty information is introduced. This allows the network to be either optimistic or pessimistic in its prediction scores. The proposed method builds on the idea of applying dropout at test time and sampling a predictive mean and variance from the network's output. Besides the methodological aspects, implementation details allowing for a fast evaluation are presented. Furthermore, a multilabel network architecture is introduced that strongly benefits from the presented approach. In the evaluation it will be shown that modeling uncertainty allows for improving the performance of a given model purely at test time without any further training steps. The evaluation considers several applications in the field of computer vision, including object classification and detection as well as scene attribute recognition. version:1
arxiv-1609-07959 | Multiplicative LSTM for sequence modelling | http://arxiv.org/abs/1609.07959 | id:1609.07959 author:Ben Krause, Liang Lu, Iain Murray, Steve Renals category:cs.NE stat.ML  published:2016-09-26 summary:This paper introduces multiplicative LSTM, a novel hybrid recurrent neural network architecture for sequence modelling that combines the long short-term memory (LSTM) and multiplicative recurrent neural network architectures. Multiplicative LSTM is motivated by its flexibility to have very different recurrent transition functions for each possible input, which we argue helps make it more expressive in autoregressive density estimation. We show empirically that multiplicative LSTM outperforms standard LSTM and deep variants for a range of character level modelling tasks. We also found that this improvement increases as the complexity of the task scales up. This model achieves a validation error of 1.20 bits/character on the Hutter prize dataset when combined with dynamic evaluation. version:1
arxiv-1609-07916 | Deep Structured Features for Semantic Segmentation | http://arxiv.org/abs/1609.07916 | id:1609.07916 author:Michael Tschannen, Lukas Cavigelli, Fabian Mentzer, Thomas Wiatowski, Luca Benini category:cs.CV cs.LG  published:2016-09-26 summary:We propose a highly structured neural network architecture for semantic segmentation of images that combines i) a Haar wavelet-based tree-like convolutional neural network (CNN), ii) a random layer realizing a radial basis function kernel approximation, and iii) a linear classifier. While stages i) and ii) are completely pre-specified, only the linear classifier is learned from data. Thanks to its high degree of structure, our architecture has a very small memory footprint and thus fits onto low-power embedded and mobile platforms. We apply the proposed architecture to outdoor scene and aerial image semantic segmentation and show that the accuracy of our architecture is competitive with conventional pixel classification CNNs. Furthermore, we demonstrate that the proposed architecture is data efficient in the sense of matching the accuracy of pixel classification CNNs when trained on a much smaller data set. version:1
arxiv-1609-07912 | Construction Safety Risk Modeling and Simulation | http://arxiv.org/abs/1609.07912 | id:1609.07912 author:Antoine J. -P. Tixier, Matthew R. Hallowell, Balaji Rajagopalan category:stat.AP math.PR stat.ML  published:2016-09-26 summary:By building on a recently introduced genetic-inspired attribute-based conceptual framework for safety risk analysis, we propose a novel methodology to compute construction univariate and bivariate construction safety risk at a situational level. Our fully data-driven approach provides construction practitioners and academicians with an easy and automated way of extracting valuable empirical insights from databases of unstructured textual injury reports. By applying our methodology on an attribute and outcome dataset directly obtained from 814 injury reports, we show that the frequency-magnitude distribution of construction safety risk is very similar to that of natural phenomena such as precipitation or earthquakes. Motivated by this observation, and drawing on state-of-the-art techniques in hydroclimatology and insurance, we introduce univariate and bivariate nonparametric stochastic safety risk generators, based on Kernel Density Estimators and Copulas. These generators enable the user to produce large numbers of synthetic safety risk values faithfully to the original data, allowing safetyrelated decision-making under uncertainty to be grounded on extensive empirical evidence. Just like the accurate modeling and simulation of natural phenomena such as wind or streamflow is indispensable to successful structure dimensioning or water reservoir management, we posit that improving construction safety calls for the accurate modeling, simulation, and assessment of safety risk. The underlying assumption is that like natural phenomena, construction safety may benefit from being studied in an empirical and quantitative way rather than qualitatively which is the current industry standard. Finally, a side but interesting finding is that attributes related to high energy levels and to human error emerge as strong risk shapers on the dataset we used to illustrate our methodology. version:1
arxiv-1609-07878 | Linear Support Tensor Machine: Pedestrian Detection in Thermal Infrared Images | http://arxiv.org/abs/1609.07878 | id:1609.07878 author:Sujoy Kumar Biswas, Peyman Milanfar category:cs.CV  published:2016-09-26 summary:Pedestrian detection in thermal infrared images poses unique challenges because of the low resolution and noisy nature of the image. Here we propose a mid-level attribute in the form of multidimensional template, or tensor, using Local Steering Kernel (LSK) as low-level descriptors for detecting pedestrians in far infrared images. LSK is specifically designed to deal with intrinsic image noise and pixel level uncertainty by capturing local image geometry succinctly instead of collecting local orientation statistics (e.g., histograms in HOG). Our second contribution is the introduction of a new image similarity kernel in the popular maximum margin framework of support vector machines that results in a relatively short and simple training phase for building a rigid pedestrian detector. Our third contribution is to replace the sluggish but de facto sliding window based detection methodology with multichannel discrete Fourier transform, facilitating very fast and efficient pedestrian localization. The experimental studies on publicly available thermal infrared images justify our proposals and model assumptions. In addition, the proposed work also involves the release of our in-house annotations of pedestrians in more than 17000 frames of OSU Color Thermal database for the purpose of sharing with the research community. version:1
arxiv-1609-07876 | Lexicon-Free Fingerspelling Recognition from Video: Data, Models, and Signer Adaptation | http://arxiv.org/abs/1609.07876 | id:1609.07876 author:Taehwan Kim, Jonathan Keane, Weiran Wang, Hao Tang, Jason Riggle, Gregory Shakhnarovich, Diane Brentari, Karen Livescu category:cs.CL cs.CV  published:2016-09-26 summary:We study the problem of recognizing video sequences of fingerspelled letters in American Sign Language (ASL). Fingerspelling comprises a significant but relatively understudied part of ASL. Recognizing fingerspelling is challenging for a number of reasons: It involves quick, small motions that are often highly coarticulated; it exhibits significant variation between signers; and there has been a dearth of continuous fingerspelling data collected. In this work we collect and annotate a new data set of continuous fingerspelling videos, compare several types of recognizers, and explore the problem of signer variation. Our best-performing models are segmental (semi-Markov) conditional random fields using deep neural network-based features. In the signer-dependent setting, our recognizers achieve up to about 92% letter accuracy. The multi-signer setting is much more challenging, but with neural network adaptation we achieve up to 83% letter accuracies in this setting. version:1
arxiv-1609-07843 | Pointer Sentinel Mixture Models | http://arxiv.org/abs/1609.07843 | id:1609.07843 author:Stephen Merity, Caiming Xiong, James Bradbury, Richard Socher category:cs.CL cs.AI  published:2016-09-26 summary:Recent neural network sequence models with softmax classifiers have achieved their best language modeling performance only with very large hidden states and large vocabularies. Even then they struggle to predict rare or unseen words even if the context makes the prediction unambiguous. We introduce the pointer sentinel mixture architecture for neural sequence models which has the ability to either reproduce a word from the recent context or produce a word from a standard softmax classifier. Our pointer sentinel-LSTM model achieves state of the art language modeling performance on the Penn Treebank (70.9 perplexity) while using far fewer parameters than a standard softmax LSTM. In order to evaluate how well language models can exploit longer contexts and deal with more realistic vocabularies and larger corpora we also introduce the freely available WikiText corpus. version:1
arxiv-1609-07835 | Autonomous Exploration with a Low-Cost Quadrocopter using Semi-Dense Monocular SLAM | http://arxiv.org/abs/1609.07835 | id:1609.07835 author:Lukas von Stumberg, Vladyslav Usenko, Jakob Engel, Jörg Stückler, Daniel Cremers category:cs.RO cs.CV 68T40 I.2.9  published:2016-09-26 summary:Micro aerial vehicles (MAVs) are strongly limited in their payload and power capacity. In order to implement autonomous navigation, algorithms are therefore desirable that use sensory equipment that is as small, low-weight, and low- power consuming as possible. In this paper, we propose a method for autonomous MAV navigation and exploration using a low-cost consumer-grade quadrocopter equipped with a monocular camera. Our vision-based navigation system builds on LSD-SLAM which estimates the MAV trajectory and a semi-dense reconstruction of the environment in real-time. Since LSD-SLAM only determines depth at high gradient pixels, texture-less areas are not directly observed. We propose an obstacle mapping and exploration approach that takes this property into account. In experiments, we demonstrate our vision-based autonomous navigation and exploration system with a commercially available Parrot Bebop MAV. version:1
arxiv-1609-07826 | Multiview RGB-D Dataset for Object Instance Detection | http://arxiv.org/abs/1609.07826 | id:1609.07826 author:Georgios Georgakis, Md Alimoor Reza, Arsalan Mousavian, Phi-Hung Le, Jana Kosecka category:cs.CV cs.RO  published:2016-09-26 summary:This paper presents a new multi-view RGB-D dataset of nine kitchen scenes, each containing several objects in realistic cluttered environments including a subset of objects from the BigBird dataset. The viewpoints of the scenes are densely sampled and objects in the scenes are annotated with bounding boxes and in the 3D point cloud. Also, an approach for detection and recognition is presented, which is comprised of two parts: i) a new multi-view 3D proposal generation method and ii) the development of several recognition baselines using AlexNet to score our proposals, which is trained either on crops of the dataset or on synthetically composited training images. Finally, we compare the performance of the object proposals and a detection baseline to the Washington RGB-D Scenes (WRGB-D) dataset and demonstrate that our Kitchen scenes dataset is more challenging for object detection and recognition. The dataset is available at: http://cs.gmu.edu/~robot/gmu-kitchens.html. version:1
arxiv-1609-06616 | Gov2Vec: Learning Distributed Representations of Institutions and Their Legal Text | http://arxiv.org/abs/1609.06616 | id:1609.06616 author:John J. Nay category:cs.CL cs.IR cs.NE cs.SI  published:2016-09-21 summary:We compare policy differences across institutions by embedding representations of the entire legal corpus of each institution and the vocabulary shared across all corpora into a continuous vector space. We apply our method, Gov2Vec, to Supreme Court opinions, Presidential actions, and official summaries of Congressional bills. The model discerns meaningful differences between government branches. We also learn representations for more fine-grained word sources: individual Presidents and (2-year) Congresses. The similarities between learned representations of Congresses over time and sitting Presidents are negatively correlated with the bill veto rate, and the temporal ordering of Presidents and Congresses was implicitly learned from only text. With the resulting vectors we answer questions such as: how does Obama and the 113th House differ in addressing climate change and how does this vary from environmental or economic perspectives? Our work illustrates vector-arithmetic-based investigations of complex relationships between word sources based on their texts. We are extending this to create a more comprehensive legal semantic map. version:2
arxiv-1609-08395 | Appraisal of data-driven and mechanistic emulators of nonlinear hydrodynamic urban drainage simulators | http://arxiv.org/abs/1609.08395 | id:1609.08395 author:Juan Pablo Carbajal, João Paulo Leitão, Carlo Albert, Jörg Rieckermann category:stat.ME cs.CE cs.LG  published:2016-09-25 summary:Many model based scientific and engineering methodologies, such as system identification, sensitivity analysis, optimization and control, require a large number of model evaluations. In particular, model based real-time control of urban water infrastructures and online flood alarm systems require fast prediction of the network response at different actuation and/or parameter values. General purpose urban drainage simulators are too slow for this application. Fast surrogate models, so-called emulators, provide a solution to this efficiency demand. Emulators are attractive, because they sacrifice unneeded accuracy in favor of speed. However, they have to be fine-tuned to predict the system behavior satisfactorily. Also, some emulators fail to extrapolate the system behavior beyond the training set. Although, there are many strategies for developing emulators, up until now the selection of the emulation strategy remains subjective. In this paper, we therefore compare the performance of two families of emulators for open channel flows in the context of urban drainage simulators. We compare emulators that explicitly use knowledge of the simulator's equations, i.e. mechanistic emulators based on Gaussian Processes, with purely data-driven emulators using matrix factorization. Our results suggest that in many urban applications, naive data-driven emulation outperforms mechanistic emulation. Nevertheless, we discuss scenarios in which we think that mechanistic emulation might be favorable for i) extrapolation in time and ii) dealing with sparse and unevenly sampled data. We also provide many references to advances in the field of Machine Learning that have not yet permeated into the Bayesian environmental science community. version:1
arxiv-1609-07770 | Random Forest for Malware Classification | http://arxiv.org/abs/1609.07770 | id:1609.07770 author:Felan Carlo C. Garcia, Felix P. Muga II category:cs.CR cs.LG  published:2016-09-25 summary:The challenge in engaging malware activities involves the correct identification and classification of different malware variants. Various malwares incorporate code obfuscation methods that alters their code signatures effectively countering antimalware detection techniques utilizing static methods and signature database. In this study, we utilized an approach of converting a malware binary into an image and use Random Forest to classify various malware families. The resulting accuracy of 0.9562 exhibits the effectivess of the method in detecting malware version:1
arxiv-1609-07769 | Joint Rain Detection and Removal via Iterative Region Dependent Multi-Task Learning | http://arxiv.org/abs/1609.07769 | id:1609.07769 author:Wenhan Yang, Robby T. Tan, Jiashi Feng, Jiaying Liu, Zongming Guo, Shuicheng Yan category:cs.CV  published:2016-09-25 summary:In this paper, we address a rain removal problem from a single image, even in the presence of heavy rain and rain accumulation. Our core ideas lie in our new rain image models and a novel deep learning architecture. We first modify the commonly used model, which is a linear combination of a rain streak layer and a background layer, by adding a binary map that locates rain streak regions. Second, we create a model consisting of a component representing rain accumulation (where individual streaks cannot be seen, and thus visually similar to mist or fog), and another component representing various shapes and directions of overlapping rain streaks, which normally happen in heavy rain. Based on the first model, we develop a multi-task deep learning architecture that learns the binary rain streak map, the appearance of rain streaks, and the clean background, which is our ultimate output. The additional binary map is critically beneficial, since its loss function can provide additional strong information to the network. In many cases though, rain streaks can be dense and large in their size, thus to obtain the clean background, we need spatial contextual information. For this, we utilize the dilated convolution. To handle rain accumulation (again, a phenomenon visually similar to mist or fog) and various shapes and directions of overlapping rain streaks, we propose an iterative information feedback (IIF) network that removes rain streaks and clears up the rain accumulation iteratively and progressively. Overall, this multi-task learning and iterative information feedback benefits each other and constitutes a network that is end-to-end trainable. Our extensive evaluation on real images, particularly on heavy rain, shows the effectiveness of our novel models and architecture, outperforming the state-of-the-art methods significantly. version:1
arxiv-1609-08408 | Deep learning for detection of bird vocalisations | http://arxiv.org/abs/1609.08408 | id:1609.08408 author:Ilyas Potamitis category:cs.SD cs.LG  published:2016-09-25 summary:This work focuses on reliable detection of bird sound emissions as recorded in the open field. Acoustic detection of avian sounds can be used for the automatized monitoring of multiple bird taxa and querying in long-term recordings for species of interest for researchers, conservation practitioners, and decision makers. Recordings in the wild can be very noisy due to the exposure of the microphones to a large number of audio sources originating from all distances and directions, the number and identity of which cannot be known a-priori. The co-existence of the target vocalizations with abiotic interferences in an unconstrained environment is inefficiently treated by current approaches of audio signal enhancement. A technique that would spot only bird vocalization while ignoring other audio sources is of prime importance. These difficulties are tackled in this work, presenting a deep autoencoder that maps the audio spectrogram of bird vocalizations to its corresponding binary mask that encircles the spectral blobs of vocalizations while suppressing other audio sources. The procedure requires minimum human attendance, it is very fast during execution, thus suitable to scan massive volumes of data, in order to analyze them, evaluate insights and hypotheses, identify patterns of bird activity that, hopefully, finally lead to design policies on biodiversity issues. version:1
arxiv-1609-07756 | A Factorized Model for Transitive Verbs in Compositional Distributional Semantics | http://arxiv.org/abs/1609.07756 | id:1609.07756 author:Lilach Edelstein, Roi Reichart category:cs.CL I.2.7  published:2016-09-25 summary:We present a factorized compositional distributional semantics model for the representation of transitive verb constructions. Our model first produces (subject, verb) and (verb, object) vector representations based on the similarity of the nouns in the construction to each of the nouns in the vocabulary and the tendency of these nouns to take the subject and object roles of the verb. These vectors are then combined into a final (subject,verb,object) representation through simple vector operations. On two established tasks for the transitive verb construction our model outperforms recent previous work. version:1
arxiv-1609-07750 | Accurate and Efficient Hyperbolic Tangent Activation Function on FPGA using the DCT Interpolation Filter | http://arxiv.org/abs/1609.07750 | id:1609.07750 author:Ahmed M. Abdelsalam, J. M. Pierre Langlois, F. Cheriet category:cs.NE cs.LG  published:2016-09-25 summary:Implementing an accurate and fast activation function with low cost is a crucial aspect to the implementation of Deep Neural Networks (DNNs) on FPGAs. We propose a high-accuracy approximation approach for the hyperbolic tangent activation function of artificial neurons in DNNs. It is based on the Discrete Cosine Transform Interpolation Filter (DCTIF). The proposed architecture combines simple arithmetic operations on stored samples of the hyperbolic tangent function and on input data. The proposed DCTIF implementation achieves two orders of magnitude greater precision than previous work while using the same or fewer computational resources. Various combinations of DCTIF parameters can be chosen to tradeoff the accuracy and complexity of the hyperbolic tangent function. In one case, the proposed architecture approximates the hyperbolic tangent activation function with 10E-5 maximum error while requiring only 1.52 Kbits memory and 57 LUTs of a Virtex-7 FPGA. We also discuss how the activation function accuracy affects the performance of DNNs in terms of their training and testing accuracies. We show that a high accuracy approximation can be necessary in order to maintain the same DNN training and testing performances realized by the exact function. version:1
arxiv-1609-05473 | SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient | http://arxiv.org/abs/1609.05473 | id:1609.05473 author:Lantao Yu, Weinan Zhang, Jun Wang, Yong Yu category:cs.LG cs.AI  published:2016-09-18 summary:As a new way of training generative models, Generative Adversarial Nets (GAN) that uses a discriminative model to guide the training of the generative model has enjoyed considerable success in generating real-valued data. However, it has limitations when the goal is for generating sequences of discrete tokens. A major reason lies in that the discrete outputs from the generative model make it difficult to pass the gradient update from the discriminative model to the generative model. Also, the discriminative model can only assess a complete sequence, while for a partially generated sequence, it is non-trivial to balance its current score and the future one once the entire sequence has been generated. In this paper, we propose a sequence generation framework, called SeqGAN, to solve the problems. Modeling the data generator as a stochastic policy in reinforcement learning (RL), SeqGAN bypasses the generator differentiation problem by directly performing gradient policy update. The RL reward signal comes from the GAN discriminator judged on a complete sequence, and is passed back to the intermediate state-action steps using Monte Carlo search. Extensive experiments on synthetic data and real-world tasks demonstrate significant improvements over strong baselines. version:3
arxiv-1609-06369 | Generalized Kalman Smoothing: Modeling and Algorithms | http://arxiv.org/abs/1609.06369 | id:1609.06369 author:A. Y. Aravkin, J. V. Burke, L. Ljung, A. Lozano, G. Pillonetto category:math.OC stat.ML 62F35  65K10  49M15  published:2016-09-20 summary:State-space smoothing has found many applications in science and engineering. Under linear and Gaussian assumptions, smoothed estimates can be obtained using efficient recursions, for example Rauch-Tung-Striebel and Mayne-Fraser algorithms. Such schemes are equivalent to linear algebraic techniques that minimize a convex quadratic objective function with structure induced by the dynamic model. These classical formulations fall short in many important circumstances. For instance, smoothers obtained using quadratic penalties can fail when outliers are present in the data, and cannot track impulsive inputs and abrupt state changes. Motivated by these shortcomings, generalized Kalman smoothing formulations have been proposed in the last few years, replacing quadratic models with more suitable, often nonsmooth, convex functions. In contrast to classical models, these general estimators require use of iterated algorithms, and these have received increased attention from control, signal processing, machine learning, and optimization communities. In this survey we show that the optimization viewpoint provides the control and signal processing community great freedom in the development of novel modeling and inference frameworks for dynamical systems. We discuss general statistical models for dynamic systems, making full use of nonsmooth convex penalties and constraints, and providing links to important models in signal processing and machine learning. We also survey optimization techniques for these formulations, paying close attention to dynamic problem structure. Modeling concepts and algorithms are illustrated with numerical examples. version:2
arxiv-1609-07730 | Lattice-Based Recurrent Neural Network Encoders for Neural Machine Translation | http://arxiv.org/abs/1609.07730 | id:1609.07730 author:Jinsong Su, Zhixing Tan, Deyi Xiong, Yang Liu category:cs.CL  published:2016-09-25 summary:Neural machine translation (NMT) heavily relies on word level modelling to learn semantic representations of input sentences. However, for languages without natural word delimiters (e.g., Chinese) where input sentences have to be tokenized first, conventional NMT is confronted with two issues: 1) it is difficult to find an optimal tokenization granularity for source sentence modelling, and 2) errors in 1-best tokenizations may propagate to the encoder of NMT. To handle these issues, we propose word-lattice based Recurrent Neural Network (RNN) encoders for NMT, which generalize the standard RNN to word lattice topology. The proposed encoders take as input a word lattice that compactly encodes multiple tokenizations, and learn to generate new hidden states from arbitrarily many inputs and hidden states in preceding time steps. As such, the word-lattice based encoders not only alleviate the negative impact of tokenization errors but also are more expressive and flexible to embed input sentences. Experiment results on Chinese-English translation demonstrate the superiorities of the proposed encoders over the conventional encoder. version:1
arxiv-1609-07727 | Deep learning based fence segmentation and removal from an image using a video sequence | http://arxiv.org/abs/1609.07727 | id:1609.07727 author:Sankaraganesh Jonna, Krishna K. Nakka, Rajiv R. Sahay category:cs.CV  published:2016-09-25 summary:Conventional approaches to image de-fencing use multiple adjacent frames for segmentation of fences in the reference image and are limited to restoring images of static scenes only. In this paper, we propose a de-fencing algorithm for images of dynamic scenes using an occlusion-aware optical flow method. We divide the problem of image de-fencing into the tasks of automated fence segmentation from a single image, motion estimation under known occlusions and fusion of data from multiple frames of a captured video of the scene. Specifically, we use a pre-trained convolutional neural network to segment fence pixels from a single image. The knowledge of spatial locations of fences is used to subsequently estimate optical flow in the occluded frames of the video for the final data fusion step. We cast the fence removal problem in an optimization framework by modeling the formation of the degraded observations. The inverse problem is solved using fast iterative shrinkage thresholding algorithm (FISTA). Experimental results show the effectiveness of proposed algorithm. version:1
arxiv-1609-07724 | The RNN-ELM Classifier | http://arxiv.org/abs/1609.07724 | id:1609.07724 author:Athanasios Vlontzos category:cs.NE cs.LG  published:2016-09-25 summary:In this paper we examine learning methods combining the Random Neural Network, a biologically inspired neural network and the Extreme Learning Machine that achieve state of the art classification performance while requiring much shorter training time. The Random Neural Network is a integrate and fire computational model of a neural network whose mathematical structure permits the efficient analysis of large ensembles of neurons. An activation function is derived from the RNN and used in an Extreme Learning Machine. We compare the performance of this combination against the ELM with various activation functions, we reduce the input dimensionality via PCA and compare its performance vs. autoencoder based versions of the RNN-ELM. version:1
arxiv-1609-07722 | Sooner than Expected: Hitting the Wall of Complexity in Evolution | http://arxiv.org/abs/1609.07722 | id:1609.07722 author:Thomas Schmickl, Payam Zahadat, Heiko Hamann category:cs.NE  published:2016-09-25 summary:In evolutionary robotics an encoding of the control software, which maps sensor data (input) to motor control values (output), is shaped by stochastic optimization methods to complete a predefined task. This approach is assumed to be beneficial compared to standard methods of controller design in those cases where no a-priori model is available that could help to optimize performance. Also for robots that have to operate in unpredictable environments, an evolutionary robotics approach is favorable. We demonstrate here that such a model-free approach is not a free lunch, as already simple tasks can represent unsolvable barriers for fully open-ended uninformed evolutionary computation techniques. We propose here the 'Wankelmut' task as an objective for an evolutionary approach that starts from scratch without pre-shaped controller software or any other informed approach that would force the behavior to be evolved in a desired way. Our focal claim is that 'Wankelmut' represents the simplest set of problems that makes plain-vanilla evolutionary computation fail. We demonstrate this by a series of simple standard evolutionary approaches using different fitness functions and standard artificial neural networks as well as continuous-time recurrent neural networks. All our tested approaches failed. We claim that any other evolutionary approach will also fail that does per-se not favor or enforce modularity and does not freeze or protect already evolved functionalities. Thus we propose a hard-to-pass benchmark and make a strong statement for self-complexifying and generative approaches in evolutionary computation. We anticipate that defining such a 'simplest task to fail' is a valuable benchmark for promoting future development in the field of artificial intelligence, evolutionary robotics and artificial life. version:1
arxiv-1609-07706 | Learning by Stimulation Avoidance: A Principle to Control Spiking Neural Networks Dynamics | http://arxiv.org/abs/1609.07706 | id:1609.07706 author:Lana Sinapayen, Atsushi Masumori, Takashi Ikegami category:cs.NE cs.AI cs.LG  published:2016-09-25 summary:Learning based on networks of real neurons, and by extension biologically inspired models of neural networks, has yet to find general learning rules leading to widespread applications. In this paper, we argue for the existence of a principle allowing to steer the dynamics of a biologically inspired neural network. Using carefully timed external stimulation, the network can be driven towards a desired dynamical state. We term this principle "Learning by Stimulation Avoidance" (LSA). We demonstrate through simulation that the minimal sufficient conditions leading to LSA in artificial networks are also sufficient to reproduce learning results similar to those obtained in biological neurons by Shahaf and Marom [1]. We examine the mechanism's basic dynamics in a reduced network, and demonstrate how it scales up to a network of 100 neurons. We show that LSA has a higher explanatory power than existing hypotheses about the response of biological neural networks to external simulation, and can be used as a learning rule for an embodied application: learning of wall avoidance by a simulated robot. The surge in popularity of artificial neural networks is mostly directed to disembodied models of neurons with biologically irrelevant dynamics: to the authors' knowledge, this is the first work demonstrating sensory-motor learning with random spiking networks through pure Hebbian learning. version:1
arxiv-1609-07701 | Large-Scale Machine Translation between Arabic and Hebrew: Available Corpora and Initial Results | http://arxiv.org/abs/1609.07701 | id:1609.07701 author:Yonatan Belinkov, James Glass category:cs.CL I.2.7  published:2016-09-25 summary:Machine translation between Arabic and Hebrew has so far been limited by a lack of parallel corpora, despite the political and cultural importance of this language pair. Previous work relied on manually-crafted grammars or pivoting via English, both of which are unsatisfactory for building a scalable and accurate MT system. In this work, we compare standard phrase-based and neural systems on Arabic-Hebrew translation. We experiment with tokenization by external tools and sub-word modeling by character-level neural models, and show that both methods lead to improved translation performance, with a small advantage to the neural models. version:1
arxiv-1609-07681 | The distribution of information content in English sentences | http://arxiv.org/abs/1609.07681 | id:1609.07681 author:Shuiyuan Yu, Jin Cong, Junying Liang, Haitao Liu category:cs.CL  published:2016-09-24 summary:Sentence is a basic linguistic unit, however, little is known about how information content is distributed across different positions of a sentence. Based on authentic language data of English, the present study calculated the entropy and other entropy-related statistics for different sentence positions. The statistics indicate a three-step staircase-shaped distribution pattern, with entropy in the initial position lower than the medial positions (positions other than the initial and final), the medial positions lower than the final position and the medial positions showing no significant difference. The results suggest that: (1) the hypotheses of Constant Entropy Rate and Uniform Information Density do not hold for the sentence-medial positions; (2) the context of a word in a sentence should not be simply defined as all the words preceding it in the same sentence; and (3) the contextual information content in a sentence does not accumulate incrementally but follows a pattern of "the whole is greater than the sum of parts". version:1
arxiv-1609-07680 | Existence of Hierarchies and Human's Pursuit of Top Hierarchy Lead to Power Law | http://arxiv.org/abs/1609.07680 | id:1609.07680 author:Shuiyuan Yu, Junying Liang, Haitao Liu category:cs.CL physics.soc-ph  published:2016-09-24 summary:The power law is ubiquitous in natural and social phenomena, and is considered as a universal relationship between the frequency and its rank for diverse social systems. However, a general model is still lacking to interpret why these seemingly unrelated systems share great similarity. Through a detailed analysis of natural language texts and simulation experiments based on the proposed 'Hierarchical Selection Model', we found that the existence of hierarchies and human's pursuit of top hierarchy lead to the power law. Further, the power law is a statistical and emergent performance of hierarchies, and it is the universality of hierarchies that contributes to the ubiquity of the power law. version:1
arxiv-1609-07672 | Information-Theoretic Methods for Planning and Learning in Partially Observable Markov Decision Processes | http://arxiv.org/abs/1609.07672 | id:1609.07672 author:Roy Fox category:cs.LG  published:2016-09-24 summary:Bounded agents are limited by intrinsic constraints on their ability to process information that is available in their sensors and memory and choose actions and memory updates. In this dissertation, we model these constraints as information-rate constraints on communication channels connecting these various internal components of the agent. We make four major contributions detailed below and many smaller contributions detailed in each section. First, we formulate the problem of optimizing the agent under both extrinsic and intrinsic constraints and develop the main tools for solving it. Second, we identify another reason for the challenging convergence properties of the optimization algorithm, which is the bifurcation structure of the update operator near phase transitions. Third, we study the special case of linear-Gaussian dynamics and quadratic cost (LQG), where the optimal solution has a particularly simple and solvable form. Fourth, we explore the learning task, where the model of the world dynamics is unknown and sample-based updates are used instead. version:1
arxiv-1609-07664 | Max-Norm Optimization for Robust Matrix Recovery | http://arxiv.org/abs/1609.07664 | id:1609.07664 author:Ethan X. Fang, Han Liu, Kim-Chuan Toh, Wen-Xin Zhou category:stat.ML math.OC  published:2016-09-24 summary:This paper studies the matrix completion problem under arbitrary sampling schemes. We propose a new estimator incorporating both max-norm and nuclear-norm regularization, based on which we can conduct efficient low-rank matrix recovery using a random subset of entries observed with additive noise under general non-uniform and unknown sampling distributions. This method significantly relaxes the uniform sampling assumption imposed for the widely used nuclear-norm penalized approach, and makes low-rank matrix recovery feasible in more practical settings. Theoretically, we prove that the proposed estimator achieves fast rates of convergence under different settings. Computationally, we propose an alternating direction method of multipliers algorithm to efficiently compute the estimator, which bridges a gap between theory and practice of machine learning methods with max-norm regularization. Further, we provide thorough numerical studies to evaluate the proposed method using both simulated and real datasets. version:1
arxiv-1609-07630 | Low-complexity Image and Video Coding Based on an Approximate Discrete Tchebichef Transform | http://arxiv.org/abs/1609.07630 | id:1609.07630 author:P. A. M. Oliveira, R. J. Cintra, F. M. Bayer, S. Kulasekera, A. Madanayake category:cs.MM cs.CV cs.DS stat.CO stat.ME  published:2016-09-24 summary:The usage of linear transformations has great relevance for data decorrelation applications, like image and video compression. In that sense, the discrete Tchebichef transform (DTT) possesses useful coding and decorrelation properties. The DTT transform kernel does not depend on the input data and fast algorithms can be developed to real time applications. However, the DTT fast algorithm presented in literature possess high computational complexity. In this work, we introduce a new low-complexity approximation for the DTT. The fast algorithm of the proposed transform is multiplication-free and requires a reduced number of additions and bit-shifting operations. Image and video compression simulations in popular standards shows good performance of the proposed transform. Regarding hardware resource consumption for FPGA shows 43.1% reduction of configurable logic blocks and ASIC place and route realization shows 57.7% reduction in the area-time figure when compared with the 2-D version of the exact DTT. version:1
arxiv-1609-07615 | Perceptual uniform descriptor and Ranking on manifold: A bridge between image representation and ranking for image retrieval | http://arxiv.org/abs/1609.07615 | id:1609.07615 author:Shenglan Liu, Jun Wu, Lin Feng, Yang Liu, Hong Qiao, Wenbo Luo Muxin Sun, Wei Wang category:cs.CV  published:2016-09-24 summary:Incompatibility of image descriptor and ranking is always neglected in image retrieval. In this paper, manifold learning and Gestalt psychology theory are involved to solve the incompatibility problem. A new holistic descriptor called Perceptual Uniform Descriptor (PUD) based on Gestalt psychology is proposed, which combines color and gradient direction to imitate the human visual uniformity. PUD features in the same class images distributes on one manifold in most cases because PUD improves the visual uniformity of the traditional descriptors. Thus, we use manifold ranking and PUD to realize image retrieval. Experiments were carried out on five benchmark data sets, and the proposed method can greatly improve the accuracy of image retrieval. Our experimental results in the Ukbench and Corel-1K datasets demonstrated that N-S score reached to 3.58 (HSV 3.4) and mAP to 81.77% (ODBTC 77.9%) respectively by utilizing PUD which has only 280 dimension. The results are higher than other holistic image descriptors (even some local ones) and state-of-the-arts retrieval methods. version:1
arxiv-1609-07599 | Three Tiers Neighborhood Graph and Multi-graph Fusion Ranking for Multi-feature Image Retrieval: A Manifold Aspect | http://arxiv.org/abs/1609.07599 | id:1609.07599 author:Shenglan Liu, Muxin Sun, Lin Feng, Yang Liu, Jun Wu category:cs.CV  published:2016-09-24 summary:Single feature is inefficient to describe content of an image, which is a shortcoming in traditional image retrieval task. We know that one image can be described by different features. Multi-feature fusion ranking can be utilized to improve the ranking list of query. In this paper, we first analyze graph structure and multi-feature fusion re-ranking from manifold aspect. Then, Three Tiers Neighborhood Graph (TTNG) is constructed to re-rank the original ranking list by single feature and to enhance precision of single feature. Furthermore, we propose Multi-graph Fusion Ranking (MFR) for multi-feature ranking, which considers the correlation of all images in multiple neighborhood graphs. Evaluations are conducted on UK-bench, Corel-1K, Corel-10K and Cifar-10 benchmark datasets. The experimental results show that our TTNG and MFR outperform than other state-of-the-art methods. For example, we achieve competitive results N-S score 3.91 and precision 65.00% on UK-bench and Corel-10K datasets respectively. version:1
arxiv-1609-07597 | DimensionApp : android app to estimate object dimensions | http://arxiv.org/abs/1609.07597 | id:1609.07597 author:Suriya Singh, Vijay Kumar category:cs.CV  published:2016-09-24 summary:In this project, we develop an android app that uses on computer vision techniques to estimate an object dimension present in field of view. The app while having compact size, is accurate upto +/- 5 mm and robust towards touch inputs. We use single-view metrology to compute accurate measurement. Unlike previous approaches, our technique does not rely on line detection and can be generalize to any object shape easily. version:1
arxiv-1609-07585 | An Investigation of Recurrent Neural Architectures for Drug Name Recognition | http://arxiv.org/abs/1609.07585 | id:1609.07585 author:Raghavendra Chalapathy, Ehsan Zare Borzeshi, Massimo Piccardi category:cs.CL  published:2016-09-24 summary:Drug name recognition (DNR) is an essential step in the Pharmacovigilance (PV) pipeline. DNR aims to find drug name mentions in unstructured biomedical texts and classify them into predefined categories. State-of-the-art DNR approaches heavily rely on hand crafted features and domain specific resources which are difficult to collect and tune. For this reason, this paper investigates the effectiveness of contemporary recurrent neural architectures - the Elman and Jordan networks and the bidirectional LSTM with CRF decoding - at performing DNR straight from the text. The experimental results achieved on the authoritative SemEval-2013 Task 9.1 benchmarks show that the bidirectional LSTM-CRF ranks closely to highly-dedicated, hand-crafted systems. version:1
arxiv-1609-07574 | Dynamic Pricing in High-dimensions | http://arxiv.org/abs/1609.07574 | id:1609.07574 author:Adel Javanmard, Hamid Nazerzadeh category:stat.ML cs.LG  published:2016-09-24 summary:We study the pricing problem faced by a firm that sells a large number of products, described via a wide range of features, to customers that arrive over time. This is motivated in part by the prevalence of online marketplaces that allow for real-time pricing. We propose a dynamic policy, called Regularized Maximum Likelihood Pricing (RMLP), that obtains asymptotically optimal revenue. Our policy leverages the structure (sparsity) of a high-dimensional demand space in order to obtain a logarithmic regret compared to the clairvoyant policy that knows the parameters of the demand in advance. More specifically, the regret of our algorithm is of $O(s_0 \log T (\log d + \log T))$, where $d$ and $s_0$ correspond to the dimension of the demand space and its sparsity. Furthermore, we show that no policy can obtain regret better than $O(s_0 (\log d + \log T))$. version:1
arxiv-1609-07568 | A Character-level Convolutional Neural Network for Distinguishing Similar Languages and Dialects | http://arxiv.org/abs/1609.07568 | id:1609.07568 author:Yonatan Belinkov, James Glass category:cs.CL I.2.7  published:2016-09-24 summary:Discriminating between closely-related language varieties is considered a challenging and important task. This paper describes our submission to the DSL 2016 shared-task, which included two sub-tasks: one on discriminating similar languages and one on identifying Arabic dialects. We developed a character-level neural network for this task. Given a sequence of characters, our model embeds each character in vector space, runs the sequence through multiple convolutions with different filter widths, and pools the convolutional representations to obtain a hidden vector representation of the text that is used for predicting the language or dialect. We primarily focused on the Arabic dialect identification task and obtained an F1 score of 0.4834, ranking 6th out of 18 participants. We also analyze errors made by our system on the Arabic data in some detail, and point to challenges such an approach is faced with. version:1
arxiv-1609-07561 | Distilling an Ensemble of Greedy Dependency Parsers into One MST Parser | http://arxiv.org/abs/1609.07561 | id:1609.07561 author:Adhiguna Kuncoro, Miguel Ballesteros, Lingpeng Kong, Chris Dyer, Noah A. Smith category:cs.CL  published:2016-09-24 summary:We introduce two first-order graph-based dependency parsers achieving a new state of the art. The first is a consensus parser built from an ensemble of independently trained greedy LSTM transition-based parsers with different random initializations. We cast this approach as minimum Bayes risk decoding (under the Hamming cost) and argue that weaker consensus within the ensemble is a useful signal of difficulty or ambiguity. The second parser is a "distillation" of the ensemble into a single model. We train the distillation parser using a structured hinge loss objective with a novel cost that incorporates ensemble uncertainty estimates for each possible attachment, thereby avoiding the intractable cross-entropy computations required by applying standard distillation objectives to problems with structured outputs. The first-order distillation parser matches or surpasses the state of the art on English, Chinese, and German. version:1
arxiv-1609-07560 | Informative Planning and Online Learning with Sparse Gaussian Processes | http://arxiv.org/abs/1609.07560 | id:1609.07560 author:Kai-Chieh Ma, Lantao Liu, Gaurav S. Sukhatme category:cs.RO cs.LG stat.ML  published:2016-09-24 summary:A big challenge in environmental monitoring is the spatiotemporal variation of the phenomena to be observed. To enable persistent sensing and estimation in such a setting, it is beneficial to have a time-varying underlying environmental model. Here we present a planning and learning method that enables an autonomous marine vehicle to perform persistent ocean monitoring tasks by learning and refining an environmental model. To alleviate the computational bottleneck caused by large-scale data accumulated, we propose a framework that iterates between a planning component aimed at collecting the most information-rich data, and a sparse Gaussian Process learning component where the environmental model and hyperparameters are learned online by taking advantage of only a subset of data that provides the greatest contribution. Our simulations with ground-truth ocean data shows that the proposed method is both accurate and efficient. version:1
arxiv-1609-05672 | Multi-Residual Networks | http://arxiv.org/abs/1609.05672 | id:1609.05672 author:Masoud Abdi, Saeid Nahavandi category:cs.CV  published:2016-09-19 summary:In this article, we take one step toward understanding the learning behavior of deep residual networks, and supporting the hypothesis that deep residual networks are exponential ensembles by construction. We examine the effective range of ensembles by introducing multi-residual networks that significantly improve classification accuracy of residual networks. The multi-residual networks increase the number of residual functions in the residual blocks. This is shown to improve the accuracy of the residual network when the network is deeper than a threshold. Based on a series of empirical studies on CIFAR-10 and CIFAR-100 datasets, the proposed multi-residual network yield $6\%$ and $10\%$ improvement with respect to the residual networks with identity mappings. Comparing with other state-of-the-art models, the proposed multi-residual network obtains a test error rate of $3.92\%$ on CIFAR-10. version:2
arxiv-1609-07540 | Derivative Delay Embedding: Online Modeling of Streaming Time Series | http://arxiv.org/abs/1609.07540 | id:1609.07540 author:Zhifei Zhang, Yang Song, Wei Wang, Hairong Qi category:cs.LG  published:2016-09-24 summary:The staggering amount of streaming time series coming from the real world calls for more efficient and effective online modeling solution. For time series modeling, most existing works make some unrealistic assumptions such as the input data is of fixed length or well aligned, which requires extra effort on segmentation or normalization of the raw streaming data. Although some literature claim their approaches to be invariant to data length and misalignment, they are too time-consuming to model a streaming time series in an online manner. We propose a novel and more practical online modeling and classification scheme, DDE-MGM, which does not make any assumptions on the time series while maintaining high efficiency and state-of-the-art performance. The derivative delay embedding (DDE) is developed to incrementally transform time series to the embedding space, where the intrinsic characteristics of data is preserved as recursive patterns regardless of the stream length and misalignment. Then, a non-parametric Markov geographic model (MGM) is proposed to both model and classify the pattern in an online manner. Experimental results demonstrate the effectiveness and superior classification accuracy of the proposed DDE-MGM in an online setting as compared to the state-of-the-art. version:1
arxiv-1609-07537 | A Tutorial on Distributed (Non-Bayesian) Learning: Problem, Algorithms and Results | http://arxiv.org/abs/1609.07537 | id:1609.07537 author:Angelia Nedić, Alex Olshevsky, César A. Uribe category:math.OC cs.LG cs.MA cs.SI stat.ML  published:2016-09-23 summary:We overview some results on distributed learning with focus on a family of recently proposed algorithms known as non-Bayesian social learning. We consider different approaches to the distributed learning problem and its algorithmic solutions for the case of finitely many hypotheses. The original centralized problem is discussed at first, and then followed by a generalization to the distributed setting. The results on convergence and convergence rate are presented for both asymptotic and finite time regimes. Various extensions are discussed such as those dealing with directed time-varying networks, Nesterov's acceleration technique and a continuum sets of hypothesis. version:1
arxiv-1609-07521 | Fast Learning of Clusters and Topics via Sparse Posteriors | http://arxiv.org/abs/1609.07521 | id:1609.07521 author:Michael C. Hughes, Erik B. Sudderth category:stat.ML  published:2016-09-23 summary:Mixture models and topic models generate each observation from a single cluster, but standard variational posteriors for each observation assign positive probability to all possible clusters. This requires dense storage and runtime costs that scale with the total number of clusters, even though typically only a few clusters have significant posterior mass for any data point. We propose a constrained family of sparse variational distributions that allow at most $L$ non-zero entries, where the tunable threshold $L$ trades off speed for accuracy. Previous sparse approximations have used hard assignments ($L=1$), but we find that moderate values of $L>1$ provide superior performance. Our approach easily integrates with stochastic or incremental optimization algorithms to scale to millions of examples. Experiments training mixture models of image patches and topic models for news articles show that our approach produces better-quality models in far less time than baseline methods. version:1
arxiv-1609-07498 | Speaker Recognition for Children's Speech | http://arxiv.org/abs/1609.07498 | id:1609.07498 author:Saeid Safavi, Maryam Najafian, Abualsoud Hanani, Martin J Russell, Peter Jancovic, Michael J Carey category:cs.SD cs.CL  published:2016-09-23 summary:This paper presents results on Speaker Recognition (SR) for children's speech, using the OGI Kids corpus and GMM-UBM and GMM-SVM SR systems. Regions of the spectrum containing important speaker information for children are identified by conducting SR experiments over 21 frequency bands. As for adults, the spectrum can be split into four regions, with the first (containing primary vocal tract resonance information) and third (corresponding to high frequency speech sounds) being most useful for SR. However, the frequencies at which these regions occur are from 11% to 38% higher for children. It is also noted that subband SR rates are lower for younger children. Finally results are presented of SR experiments to identify a child in a class (30 children, similar age) and school (288 children, varying ages). Class performance depends on age, with accuracy varying from 90% for young children to 99% for older children. The identification rate achieved for a child in a school is 81%. version:1
arxiv-1609-07495 | A Rotation Invariant Latent Factor Model for Moveme Discovery from Static Poses | http://arxiv.org/abs/1609.07495 | id:1609.07495 author:Matteo Ruggero Ronchi, Joon Sik Kim, Yisong Yue category:cs.CV cs.LG  published:2016-09-23 summary:We tackle the problem of learning a rotation invariant latent factor model when the training data is comprised of lower-dimensional projections of the original feature space. The main goal is the discovery of a set of 3-D bases poses that can characterize the manifold of primitive human motions, or movemes, from a training set of 2-D projected poses obtained from still images taken at various camera angles. The proposed technique for basis discovery is data-driven rather than hand-designed. The learned representation is rotation invariant, and can reconstruct any training instance from multiple viewing angles. We apply our method to modeling human poses in sports (via the Leeds Sports Dataset), and demonstrate the effectiveness of the learned bases in a range of applications such as activity classification, inference of dynamics from a single frame, and synthetic representation of movements. version:1
arxiv-1609-07479 | Incorporating Relation Paths in Neural Relation Extraction | http://arxiv.org/abs/1609.07479 | id:1609.07479 author:Wenyuan Zeng, Yankai Lin, Zhiyuan Liu, Maosong Sun category:cs.CL  published:2016-09-23 summary:Distantly supervised relation extraction has been widely used to find novel relational facts from plain text. To predict the relation between a pair of two target entities, existing methods solely rely on those direct sentences containing both entities. In fact, there are also many sentences containing only one of the target entities, which provide rich and useful information for relation extraction. To address this issue, we build inference chains between two target entities via intermediate entities, and propose a path-based neural relation extraction model to encode the relational semantics from both direct sentences and inference chains. Experimental results on real-world datasets show that, our model can make full use of those sentences containing only one target entity, and achieves significant and consistent improvements on relation extraction as compared with baselines. version:1
arxiv-1609-07478 | Screening Rules for Convex Problems | http://arxiv.org/abs/1609.07478 | id:1609.07478 author:Anant Raj, Jakob Olbrich, Bernd Gärtner, Bernhard Schölkopf, Martin Jaggi category:math.OC cs.LG stat.ML  published:2016-09-23 summary:We propose a new framework for deriving screening rules for convex optimization problems. Our approach covers a large class of constrained and penalized optimization formulations, and works in two steps. First, given any approximate point, the structure of the objective function and the duality gap is used to gather information on the optimal solution. In the second step, this information is used to produce screening rules, i.e. safely identifying unimportant weight variables of the optimal solution. Our general framework leads to a large variety of useful existing as well as new screening rules for many applications. For example, we provide new screening rules for general simplex and $L_1$-constrained problems, Elastic Net, squared-loss Support Vector Machines, minimum enclosing ball, as well as structured norm regularized problems, such as group lasso. version:1
arxiv-1609-07451 | AMR-to-text generation as a Traveling Salesman Problem | http://arxiv.org/abs/1609.07451 | id:1609.07451 author:Linfeng Song, Yue Zhang, Xiaochang Peng, Zhiguo Wang, Daniel Gildea category:cs.CL  published:2016-09-23 summary:The task of AMR-to-text generation is to generate grammatical text that sustains the semantic meaning for a given AMR graph. We at- tack the task by first partitioning the AMR graph into smaller fragments, and then generating the translation for each fragment, before finally deciding the order by solving an asymmetric generalized traveling salesman problem (AGTSP). A Maximum Entropy classifier is trained to estimate the traveling costs, and a TSP solver is used to find the optimized solution. The final model reports a BLEU score of 22.44 on the SemEval-2016 Task8 dataset. version:1
arxiv-1609-05158 | Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network | http://arxiv.org/abs/1609.05158 | id:1609.05158 author:Wenzhe Shi, Jose Caballero, Ferenc Huszár, Johannes Totz, Andrew P. Aitken, Rob Bishop, Daniel Rueckert, Zehan Wang category:cs.CV stat.ML  published:2016-09-16 summary:Recently, several models based on deep neural networks have achieved great success in terms of both reconstruction accuracy and computational performance for single image super-resolution. In these methods, the low resolution (LR) input image is upscaled to the high resolution (HR) space using a single filter, commonly bicubic interpolation, before reconstruction. This means that the super-resolution (SR) operation is performed in HR space. We demonstrate that this is sub-optimal and adds computational complexity. In this paper, we present the first convolutional neural network (CNN) capable of real-time SR of 1080p videos on a single K2 GPU. To achieve this, we propose a novel CNN architecture where the feature maps are extracted in the LR space. In addition, we introduce an efficient sub-pixel convolution layer which learns an array of upscaling filters to upscale the final LR feature maps into the HR output. By doing so, we effectively replace the handcrafted bicubic filter in the SR pipeline with more complex upscaling filters specifically trained for each feature map, whilst also reducing the computational complexity of the overall SR operation. We evaluate the proposed approach using images and videos from publicly available datasets and show that it performs significantly better (+0.15dB on Images and +0.39dB on Videos) and is an order of magnitude faster than previous CNN-based methods. version:2
arxiv-1609-07434 | Regulating Reward Training by Means of Certainty Prediction in a Neural Network-Implemented Pong Game | http://arxiv.org/abs/1609.07434 | id:1609.07434 author:Matt Oberdorfer, Matt Abuzalaf category:cs.AI cs.NE  published:2016-09-23 summary:We present the first reinforcement-learning model to self-improve its reward-modulated training implemented through a continuously improving "intuition" neural network. An agent was trained how to play the arcade video game Pong with two reward-based alternatives, one where the paddle was placed randomly during training, and a second where the paddle was simultaneously trained on three additional neural networks such that it could develop a sense of "certainty" as to how probable its own predicted paddle position will be to return the ball. If the agent was less than 95% certain to return the ball, the policy used an intuition neural network to place the paddle. We trained both architectures for an equivalent number of epochs and tested learning performance by letting the trained programs play against a near-perfect opponent. Through this, we found that the reinforcement learning model that uses an intuition neural network for placing the paddle during reward training quickly overtakes the simple architecture in its ability to outplay the near-perfect opponent, additionally outscoring that opponent by an increasingly wide margin after additional epochs of training. version:1
arxiv-1609-07420 | Real-time Human Pose Estimation from Video with Convolutional Neural Networks | http://arxiv.org/abs/1609.07420 | id:1609.07420 author:Marko Linna, Juho Kannala, Esa Rahtu category:cs.CV  published:2016-09-23 summary:In this paper, we present a method for real-time multi-person human pose estimation from video by utilizing convolutional neural networks. Our method is aimed for use case specific applications, where good accuracy is essential and variation of the background and poses is limited. This enables us to use a generic network architecture, which is both accurate and fast. We divide the problem into two phases: (1) pre-training and (2) finetuning. In pre-training, the network is learned with highly diverse input data from publicly available datasets, while in finetuning we train with application specific data, which we record with Kinect. Our method differs from most of the state-of-the-art methods in that we consider the whole system, including person detector, pose estimator and an automatic way to record application specific training material for finetuning. Our method is considerably faster than many of the state-of-the-art methods. Our method can be thought of as a replacement for Kinect, and it can be used for higher level tasks, such as gesture control, games, person tracking, action recognition and action tracking. We achieved accuracy of 96.8\% (PCK@0.2) with application specific data. version:1
arxiv-1609-07410 | One-vs-Each Approximation to Softmax for Scalable Estimation of Probabilities | http://arxiv.org/abs/1609.07410 | id:1609.07410 author:Michalis K. Titsias category:stat.ML  published:2016-09-23 summary:The softmax representation of probabilities for categorical variables plays a prominent role in modern machine learning with numerous applications is areas such as large scale classification, neural language modeling and recommendation systems. However, softmax estimation is very expensive for large scale inference because of the high cost associated with computing the normalizing constant. Here, we introduce an efficient approximation to softmax probabilities which takes the form of a rigorous lower bound on the exact probability. This bound is expressed as a product over pairwise probabilities and it leads to scalable estimation based on stochastic optimization. It allows us to perform doubly stochastic estimation by subsampling both training instances and class labels. We show that the new bound has interesting theoretical properties and we demonstrate its use in classification problems. version:1
arxiv-1609-07386 | A penalized likelihood method for classification with matrix-valued predictors | http://arxiv.org/abs/1609.07386 | id:1609.07386 author:Aaron J. Molstad, Adam J. Rothman category:stat.ML stat.CO  published:2016-09-23 summary:We propose a penalized likelihood method to fit the linear discriminant analysis model when the predictor is matrix valued. We simultaneously estimate the means and the precision matrix, which we assume has a Kronecker product decomposition. Our penalties encourage pairs of response category mean matrices to have equal entries and also encourage zeros in the precision matrix. To compute our estimators, we use a blockwise coordinate descent algorithm. To update the optimization variables corresponding to response category mean matrices, we use an alternating minimization algorithm that takes advantage of the Kronecker structure of the precision matrix. We show that our method can outperform relevant competitors in classification, even when our modeling assumptions are violated. We analyze an EEG dataset to demonstrate our method's interpretability and classification accuracy. version:1
arxiv-1609-07384 | Discovering Sound Concepts and Acoustic Relations In Text | http://arxiv.org/abs/1609.07384 | id:1609.07384 author:Anurag Kumar, Bhiksha Raj, Ndapandula Nakashole category:cs.SD cs.AI cs.LG  published:2016-09-23 summary:In this paper we describe approaches for discovering acoustic concepts and relations in text. The first major goal is to be able to identify text phrases which contain a notion of audibility and can be termed as a sound or an acoustic concept. We also propose a method to define an acoustic scene through a set of sound concepts. We use pattern matching and parts of speech tags to generate sound concepts from large scale text corpora. We use dependency parsing and LSTM recurrent neural network to predict a set of sound concepts for a given acoustic scene. These methods are not only helpful in creating an acoustic knowledge base but also directly help in acoustic event and scene detection research in a variety of ways. version:1
arxiv-1609-07378 | Multi-Output Artificial Neural Network for Storm Surge Prediction in North Carolina | http://arxiv.org/abs/1609.07378 | id:1609.07378 author:Anton Bezuglov, Brian Blanton, Reinaldo Santiago category:cs.NE physics.ao-ph stat.AP  published:2016-09-23 summary:During hurricane seasons, emergency managers and other decision makers need accurate and `on-time' information on potential storm surge impacts. Fully dynamical computer models, such as the ADCIRC tide, storm surge, and wind-wave model take several hours to complete a forecast when configured at high spatial resolution. Additionally, statically meaningful ensembles of high-resolution models (needed for uncertainty estimation) cannot easily be computed in near real-time. This paper discusses an artificial neural network model for storm surge prediction in North Carolina. The network model provides fast, real-time storm surge estimates at coastal locations in North Carolina. The paper studies the performance of the neural network model vs. other models on synthetic and real hurricane data. version:1
arxiv-1609-06026 | An Approach for Self-Training Audio Event Detectors Using Web Data | http://arxiv.org/abs/1609.06026 | id:1609.06026 author:Ankit Shah, Rohan Badlani, Anurag Kumar, Benjamin Elizalde, Bhiksha Raj category:cs.SD cs.LG cs.MM  published:2016-09-20 summary:Audio event detection in the era of Big Data has the constraint of lacking annotations to train robust models that match the scale of class diversity. This is mainly due to the expensive and time-consuming process of manually annotating sound events in isolation or as segments within audio recordings. In this paper, we propose an approach for semi-supervised self-training of audio event detectors using unlabeled web data. We started with a small annotated dataset and trained sound events detectors. Then, we crawl and collect thousands of web videos and extract their soundtrack. The segmented soundtracks are run by the detectors and different selection techniques were used to determine whether a segment should be used for self-training the detectors. The original detectors were compared to the self-trained detectors and the results showed a performance improvement by the latter when evaluated on the annotated test set. version:2
arxiv-1609-07371 | The face-space duality hypothesis: a computational model | http://arxiv.org/abs/1609.07371 | id:1609.07371 author:Jonathan Vitale, Mary-Anne Williams, Benjamin Johnston category:cs.CV  published:2016-09-23 summary:Valentine's face-space suggests that faces are represented in a psychological multidimensional space according to their perceived properties. However, the proposed framework was initially designed as an account of invariant facial features only, and explanations for dynamic features representation were neglected. In this paper we propose, develop and evaluate a computational model for a twofold structure of the face-space, able to unify both identity and expression representations in a single implemented model. To capture both invariant and dynamic facial features we introduce the face-space duality hypothesis and subsequently validate it through a mathematical presentation using a general approach to dimensionality reduction. Two experiments with real facial images show that the proposed face-space: (1) supports both identity and expression recognition, and (2) has a twofold structure anticipated by our formal argument. version:1
arxiv-1609-07370 | Example-Based Image Synthesis via Randomized Patch-Matching | http://arxiv.org/abs/1609.07370 | id:1609.07370 author:Yi Ren, Yaniv Romano, Michael Elad category:cs.CV  published:2016-09-23 summary:Image and texture synthesis is a challenging task that has long been drawing attention in the fields of image processing, graphics, and machine learning. This problem consists of modelling the desired type of images, either through training examples or via a parametric modeling, and then generating images that belong to the same statistical origin. This work addresses the image synthesis task, focusing on two specific families of images -- handwritten digits and face images. This paper offers two main contributions. First, we suggest a simple and intuitive algorithm capable of generating such images in a unified way. The proposed approach taken is pyramidal, consisting of upscaling and refining the estimated image several times. For each upscaling stage, the algorithm randomly draws small patches from a patch database, and merges these to form a coherent and novel image with high visual quality. The second contribution is a general framework for the evaluation of the generation performance, which combines three aspects: the likelihood, the originality and the spread of the synthesized images. We assess the proposed synthesis scheme and show that the results are similar in nature, and yet different from the ones found in the training set, suggesting that true synthesis effect has been obtained. version:1
arxiv-1609-07363 | Changepoint Detection in the Presence of Outliers | http://arxiv.org/abs/1609.07363 | id:1609.07363 author:Paul Fearnhead, Guillem Rigaill category:stat.ME stat.AP stat.CO stat.ML  published:2016-09-23 summary:Many traditional methods for identifying changepoints can struggle in the presence of outliers, or when the noise is heavy-tailed. Often they will infer additional changepoints in order to fit the outliers. To overcome this problem, data often needs to be pre-processed to remove outliers, though this is not feasible in applications where the data needs to be analysed online. We present an approach to changepoint detection that is robust to the presence of outliers. The idea is to adapt existing penalised cost approaches for detecting changes so that they use cost functions that are less sensitive to outliers. We argue that cost functions that are bounded, such as the classical biweight cost, are particularly suitable -- as we show that only bounded cost functions are robust to arbitrarily extreme outliers. We present a novel and efficient dynamic programming algorithm that can then find the optimal segmentation under our penalised cost criteria. Importantly, this algorithm can be used in settings where the data needs to be analysed online. We present theoretical bounds on the worst-case complexity of this algorithm, and show empirically that its average computational cost is linear in the amount of the data. We show the usefulness of our approach for applications such as analysing well-log data, detecting copy number variation, and detecting tampering of wireless devices. version:1
arxiv-1609-06371 | Robust Estimation of Multiple Inlier Structures | http://arxiv.org/abs/1609.06371 | id:1609.06371 author:Xiang Yang, Peter Meer category:cs.CV  published:2016-09-20 summary:In this paper we present a method to robustly estimate multiple inlier structures with different scales in the presence of noise.The estimation is done iteratively with the objective function transformed into a higher dimensional linear space by carrier vectors. An initial set consisting of a small number of points that has the minimum sum of Mahalanobis distances is detected from the trials based on elemental subsets. The region of interest is defined by applying an expansion criteria to an increasing sequence of sets of points which begins with the initial set and increases until the set cannot expand. The largest expansion in this region gives the scale estimate. The original mean shift is applied to all remaining input points to re-estimate the structure. After all data are processed, the segmented structures are sorted by strengths with the strongest inlier structures at the front. Several synthetic and real examples are presented to illustrate every aspect of the algorithm. This method is easy to implement and its limitations of robustness are clearly stated. version:2
arxiv-1609-07333 | Estimating Probability Distributions using "Dirac" Kernels (via Rademacher-Walsh Polynomial Basis Functions) | http://arxiv.org/abs/1609.07333 | id:1609.07333 author:Hamse Y. Mussa, Avid M. Afzal category:stat.ML  published:2016-09-23 summary:In many applications (in particular information systems, such as pattern recognition, machine learning, cheminformatics, bioinformatics to name but a few) the assessment of uncertainty is essential - i.e., the estimation of the underlying probability distribution function. More often than not, the form of this function is unknown and it becomes necessary to non-parametrically construct/estimate it from a given sample. One of the methods of choice to non-parametrically estimate the unknown probability distribution function for a given random variable (defined on binary space) has been the expansion of the estimation function in Rademacher-Walsh Polynomial basis functions. In this paper we demonstrate that the expansion of the probability distribution function estimation in Rademacher-Walsh Polynomial basis functions is equivalent to the expansion of the function estimation in a set of "Dirac kernel" functions. The latter approach can ameliorate the computational bottleneck and notational awkwardness often associated with the Rademacher-Walsh Polynomial basis functions approach, in particular when the binary input space is large. version:1
arxiv-1609-07317 | Language as a Latent Variable: Discrete Generative Models for Sentence Compression | http://arxiv.org/abs/1609.07317 | id:1609.07317 author:Yishu Miao, Phil Blunsom category:cs.CL cs.AI  published:2016-09-23 summary:In this work we explore deep generative models of text in which the latent representation of a document is itself drawn from a discrete language model distribution. We formulate a variational auto-encoder for inference in this model and apply it to the task of compressing sentences. In this application the generative model first draws a latent summary sentence from a background language model, and then subsequently draws the observed sentence conditioned on this latent summary. In our empirical evaluation we show that generative formulations of both abstractive and extractive compression yield state-of-the-art results when trained on a large amount of supervised data. Further, we explore semi-supervised compression scenarios where we show that it is possible to achieve performance competitive with previously proposed supervised models while training on a fraction of the supervised data. version:1
arxiv-1609-07306 | EgoCap: Egocentric Marker-less Motion Capture with Two Fisheye Cameras | http://arxiv.org/abs/1609.07306 | id:1609.07306 author:Helge Rhodin, Christian Richardt, Dan Casas, Eldar Insafutdinov, Mohammad Shafiei, Hans-Peter Seidel, Bernt Schiele, Christian Theobalt category:cs.CV  published:2016-09-23 summary:Marker-based and marker-less optical skeletal motion-capture methods use an outside-in arrangement of cameras placed around a scene, with viewpoints converging on the center. They often create discomfort by possibly needed marker suits, and their recording volume is severely restricted and often constrained to indoor scenes with controlled backgrounds. Alternative suit-based systems use several inertial measurement units or an exoskeleton to capture motion. This makes capturing independent of a confined volume, but requires substantial, often constraining, and hard to set up body instrumentation. We therefore propose a new method for real-time, marker-less and egocentric motion capture which estimates the full-body skeleton pose from a lightweight stereo pair of fisheye cameras that are attached to a helmet or virtual reality headset. It combines the strength of a new generative pose estimation framework for fisheye views with a ConvNet-based body-part detector trained on a large new dataset. Our inside-in method captures full-body motion in general indoor and outdoor scenes, and also crowded scenes with many people in close vicinity. The captured user can freely move around, which enables reconstruction of larger-scale activities and is particularly useful in virtual reality to freely roam and interact, while seeing the fully motion-captured virtual body. version:1
arxiv-1609-07304 | Funnel-Structured Cascade for Multi-View Face Detection with Alignment-Awareness | http://arxiv.org/abs/1609.07304 | id:1609.07304 author:Shuzhe Wu, Meina Kan, Zhenliang He, Shiguang Shan, Xilin Chen category:cs.CV  published:2016-09-23 summary:Multi-view face detection in open environment is a challenging task due to diverse variations of face appearances and shapes. Most multi-view face detectors depend on multiple models and organize them in parallel, pyramid or tree structure, which compromise between the accuracy and time-cost. Aiming at a more favorable multi-view face detector, we propose a novel funnel-structured cascade (FuSt) detection framework. In a coarse-to-fine flavor, our FuSt consists of, from top to bottom, 1) multiple view-specific fast LAB cascade for extremely quick face proposal, 2) multiple coarse MLP cascade for further candidate window verification, and 3) a unified fine MLP cascade with shape-indexed features for accurate face detection. Compared with other structures, on the one hand, the proposed one uses multiple computationally efficient distributed classifiers to propose a small number of candidate windows but with a high recall of multi-view faces. On the other hand, by using a unified MLP cascade to examine proposals of all views in a centralized style, it provides a favorable solution for multi-view face detection with high accuracy and low time-cost. Besides, the FuSt detector is alignment-aware and performs a coarse facial part prediction which is beneficial for subsequent face alignment. Extensive experiments on two challenging datasets, FDDB and AFW, demonstrate the effectiveness of our FuSt detector in both accuracy and speed. version:1
arxiv-1609-07272 | Constraint-Based Clustering Selection | http://arxiv.org/abs/1609.07272 | id:1609.07272 author:Toon Van Craenendonck, Hendrik Blockeel category:stat.ML cs.LG  published:2016-09-23 summary:Semi-supervised clustering methods incorporate a limited amount of supervision into the clustering process. Typically, this supervision is provided by the user in the form of pairwise constraints. Existing methods use such constraints in one of the following ways: they adapt their clustering procedure, their similarity metric, or both. All of these approaches operate within the scope of individual clustering algorithms. In contrast, we propose to use constraints to choose between clusterings generated by very different unsupervised clustering algorithms, run with different parameter settings. We empirically show that this simple approach often outperforms existing semi-supervised clustering methods. version:1
arxiv-1609-07257 | Using Neural Network Formalism to Solve Multiple-Instance Problems | http://arxiv.org/abs/1609.07257 | id:1609.07257 author:Tomas Pevny, Petr Somol category:cs.LG stat.ML  published:2016-09-23 summary:Many objects in the real world are difficult to describe by a single numerical vector of a fixed length, whereas describing them by a set of vectors is more natural. Therefore, Multiple instance learning (MIL) techniques have been constantly gaining on importance throughout last years. MIL formalism represents each object (sample) by a set (bag) of feature vectors (instances) of fixed length where knowledge about objects (e.g., class label) is available on bag level but not necessarily on instance level. Many standard tools including supervised classifiers have been already adapted to MIL setting since the problem got formalized in late nineties. In this work we propose a neural network (NN) based formalism that intuitively bridges the gap between MIL problem definition and the vast existing knowledge-base of standard models and classifiers. We show that the proposed NN formalism is effectively optimizable by a modified back-propagation algorithm and can reveal unknown patterns inside bags. Comparison to eight types of classifiers from the prior art on a set of 14 publicly available benchmark datasets confirms the advantages and accuracy of the proposed solution. version:1
arxiv-1609-07245 | Novel stochastic properties of the short-time spectrum for unvoiced pronunciation modeling and synthesis | http://arxiv.org/abs/1609.07245 | id:1609.07245 author:Xiaodong Zhuang, Nikos E. Mastorakis category:cs.SD cs.CL  published:2016-09-23 summary:Stochastic property of speech signal is a fundamental research topic in speech analysis and processing. In this paper, multiple levels of randomness in speech signal are discussed, and the stochastic properties of unvoiced pronunciation are studied in detail, which has not received sufficient research attention before. The study is based on the signals of sustained unvoiced pronunciation captured in the experiments, for which the amplitude and phase values in the short-time spectrum are studied as random variables. The statistics of amplitude for each frequency component is studied individually, based on which a new property of "consistent standard deviation coefficient" is revealed for the amplitude spectrum of unvoiced pronunciation. The relationship between the amplitude probability distributions of different frequency components is further studied, which indicates that all the frequency components have a common prototype of amplitude probability distribution. As an adaptive and flexible probability distribution, the Weibull distribution is adopted to fit the expectation-normalized amplitude spectrum data. The phase distribution for the short-time spectrum is also studied, and the results show a uniform distribution. A synthesis method for unvoiced pronunciation is proposed based on the Weibull distribution of amplitude and uniform distribution of phase, which is implemented by STFT with artificially generated short-time spectrum with random amplitude and phase. The synthesis results have identical quality of auditory perception as the original pronunciation, and have similar autocorrelation as that of the original signal, which proves the effectiveness of the proposed stochastic model of short-time spectrum for unvoiced pronunciation. version:1
arxiv-1609-07236 | On the (im)possibility of fairness | http://arxiv.org/abs/1609.07236 | id:1609.07236 author:Sorelle A. Friedler, Carlos Scheidegger, Suresh Venkatasubramanian category:cs.CY stat.ML  published:2016-09-23 summary:What does it mean for an algorithm to be fair? Different papers use different notions of algorithmic fairness, and although these appear internally consistent, they also seem mutually incompatible. We present a mathematical setting in which the distinctions in previous papers can be made formal. In addition to characterizing the spaces of inputs (the "observed" space) and outputs (the "decision" space), we introduce the notion of a construct space: a space that captures unobservable, but meaningful variables for the prediction. We show that in order to prove desirable properties of the entire decision-making process, different mechanisms for fairness require different assumptions about the nature of the mapping from construct space to decision space. The results in this paper imply that future treatments of algorithmic fairness should more explicitly state assumptions about the relationship between constructs and observations. version:1
arxiv-1609-07228 | EFANNA : An Extremely Fast Approximate Nearest Neighbor Search Algorithm Based on kNN Graph | http://arxiv.org/abs/1609.07228 | id:1609.07228 author:Cong Fu, Deng Cai category:cs.CV  published:2016-09-23 summary:Approximate nearest neighbor (ANN) search is a fundamental problem in many areas of data mining, machine learning and computer vision. The performance of traditional hierarchical structure (tree) based methods decreases as the dimensionality of data grows, while hashing based methods usually lack efficiency in practice. Recently, the graph based methods have drawn considerable attention. The main idea is that \emph{a neighbor of a neighbor is also likely to be a neighbor}, which we refer as \emph{NN-expansion}. These methods construct a $k$-nearest neighbor ($k$NN) graph offline. And at online search stage, these methods find candidate neighbors of a query point in some way (\eg, random selection), and then check the neighbors of these candidate neighbors for closer ones iteratively. Despite some promising results, there are mainly two problems with these approaches: 1) These approaches tend to converge to local optima. 2) Constructing a $k$NN graph is time consuming. We find that these two problems can be nicely solved when we provide a good initialization for NN-expansion. In this paper, we propose EFANNA, an extremely fast approximate nearest neighbor search algorithm based on $k$NN Graph. Efanna nicely combines the advantages of hierarchical structure based methods and nearest-neighbor-graph based methods. Extensive experiments have shown that EFANNA outperforms the state-of-art algorithms both on approximate nearest neighbor search and approximate nearest neighbor graph construction. To the best of our knowledge, EFANNA is the fastest algorithm so far both on approximate nearest neighbor graph construction and approximate nearest neighbor search. A library EFANNA based on this research is released on Github. version:1
arxiv-1609-07222 | Deep Multi-Task Learning with Shared Memory | http://arxiv.org/abs/1609.07222 | id:1609.07222 author:Pengfei Liu, Xipeng Qiu, Xuanjing Huang category:cs.CL  published:2016-09-23 summary:Neural network based models have achieved impressive results on various specific tasks. However, in previous works, most models are learned separately based on single-task supervised objectives, which often suffer from insufficient training data. In this paper, we propose two deep architectures which can be trained jointly on multiple related tasks. More specifically, we augment neural model with an external memory, which is shared by several tasks. Experiments on two groups of text classification tasks show that our proposed architectures can improve the performance of a task with the help of other related tasks. version:1
arxiv-1609-07215 | A Novel Progressive Multi-label Classifier for Classincremental Data | http://arxiv.org/abs/1609.07215 | id:1609.07215 author:Mihika Dave, Sahil Tapiawala, Meng Joo Er, Rajasekar Venkatesan category:cs.LG cs.NE  published:2016-09-23 summary:In this paper, a progressive learning algorithm for multi-label classification to learn new labels while retaining the knowledge of previous labels is designed. New output neurons corresponding to new labels are added and the neural network connections and parameters are automatically restructured as if the label has been introduced from the beginning. This work is the first of the kind in multi-label classifier for class-incremental learning. It is useful for real-world applications such as robotics where streaming data are available and the number of labels is often unknown. Based on the Extreme Learning Machine framework, a novel universal classifier with plug and play capabilities for progressive multi-label classification is developed. Experimental results on various benchmark synthetic and real datasets validate the efficiency and effectiveness of our proposed algorithm. version:1
arxiv-1609-07200 | Multilayer Spectral Graph Clustering via Convex Layer Aggregation | http://arxiv.org/abs/1609.07200 | id:1609.07200 author:Pin-Yu Chen, Alfred O. Hero III category:cs.LG cs.SI stat.ML  published:2016-09-23 summary:Multilayer graphs are commonly used for representing different relations between entities and handling heterogeneous data processing tasks. New challenges arise in multilayer graph clustering for assigning clusters to a common multilayer node set and for combining information from each layer. This paper presents a theoretical framework for multilayer spectral graph clustering of the nodes via convex layer aggregation. Under a novel multilayer signal plus noise model, we provide a phase transition analysis that establishes the existence of a critical value on the noise level that permits reliable cluster separation. The analysis also specifies analytical upper and lower bounds on the critical value, where the bounds become exact when the clusters have identical sizes. Numerical experiments on synthetic multilayer graphs are conducted to validate the phase transition analysis and study the effect of layer weights and noise levels on clustering reliability. version:1
arxiv-1609-07197 | Annotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems | http://arxiv.org/abs/1609.07197 | id:1609.07197 author:Shyam Upadhyay, Ming-Wei Chang category:cs.CL  published:2016-09-23 summary:We propose a new evaluation for automatic solvers for algebra word problems, which can identify reasoning mistakes that existing evaluations overlook. Our proposal is to use derivations for evaluations, which reflect the reasoning process of the solver by explaining how the equation system was constructed. We accomplish this by developing an algorithm for checking the equivalence between two derivations, and showing how derivation annotations can be semi-automatically added to existing datasets. To make our experiments more comprehensive, we also annotated DRAW-1K , a new dataset of 1000 general algebra word problems. In total, our experiments span over 2300 algebra word problems. We found that the annotated derivation enable a superior evaluation of automatic solvers than previously used metrics. version:1
arxiv-1609-07195 | Efficient Feature Selection With Large and High-dimensional Data | http://arxiv.org/abs/1609.07195 | id:1609.07195 author:Néhémy Lim, Johannes Lederer category:stat.ME stat.CO stat.ML  published:2016-09-23 summary:Driven by the advances in technology, large and high-dimensional data have become the rule rather than the exception. Approaches that allow for feature selection with such data are thus highly sought after, in particular, since standard methods, like cross-validated Lasso, can be computationally intractable and, in any case, lack theoretical guarantees. In this paper, we propose a novel approach to feature selection in regression. Consisting of simple optimization steps and tests, it is computationally more efficient than existing methods and, therefore, suited even for very large data sets. Moreover, in contrast to standard methods, it is equipped with sharp statistical guarantees. We thus expect that our algorithm can help to leverage the increasing volume of data in Biology, Public Health, Astronomy, Economics, and other fields. version:1
arxiv-1609-07170 | Deep Quality: A Deep No-reference Quality Assessment System | http://arxiv.org/abs/1609.07170 | id:1609.07170 author:Prajna Paramita Dash, Akshaya Mishra, Alexander Wong category:cs.MM cs.CV  published:2016-09-22 summary:Image quality assessment (IQA) continues to garner great interest in the research community, particularly given the tremendous rise in consumer video capture and streaming. Despite significant research effort in IQA in the past few decades, the area of no-reference image quality assessment remains a great challenge and is largely unsolved. In this paper, we propose a novel no-reference image quality assessment system called Deep Quality, which leverages the power of deep learning to model the complex relationship between visual content and the perceived quality. Deep Quality consists of a novel multi-scale deep convolutional neural network, trained to learn to assess image quality based on training samples consisting of different distortions and degradations such as blur, Gaussian noise, and compression artifacts. Preliminary results using the CSIQ benchmark image quality dataset showed that Deep Quality was able to achieve strong quality prediction performance (89% patch-level and 98% image-level prediction accuracy), being able to achieve similar performance as full-reference IQA methods. version:1
arxiv-1609-07152 | Input Convex Neural Networks | http://arxiv.org/abs/1609.07152 | id:1609.07152 author:Brandon Amos, Lei Xu, J. Zico Kolter category:cs.LG math.OC  published:2016-09-22 summary:This paper presents the input convex neural network architecture. These are scalar-valued (potentially deep) neural networks with constraints on the network parameters such that the output of the network is a convex function of (some of) the inputs. The networks allow for efficient inference via optimization over some inputs to the network given others, and can be applied to settings including structured prediction, data imputation, reinforcement learning, and others. In this paper we lay the basic groundwork for these models, proposing methods for inference, optimization and learning, and analyze their representational power. We show that many existing neural network architectures can be made input-convex with only minor modification, and develop specialized optimization algorithms tailored to this setting. Finally, we highlight the performance of the methods on multi-label prediction, image completion, and reinforcement learning problems, where we show improvement over the existing state of the art in many cases. version:1
arxiv-1609-07132 | A Fully Convolutional Neural Network for Speech Enhancement | http://arxiv.org/abs/1609.07132 | id:1609.07132 author:Se Rim Park, Jinwon Lee category:cs.LG  published:2016-09-22 summary:In hearing aids, the presence of babble noise degrades hearing intelligibility of human speech greatly. However, removing the babble without creating artifacts in human speech is a challenging task in a low SNR environment. Here, we sought to solve the problem by finding a `mapping' between noisy speech spectra and clean speech spectra via supervised learning. Specifically, we propose using fully Convolutional Neural Networks, which consist of lesser number of parameters than fully connected networks. The proposed network, Redundant Convolutional Encoder Decoder (R-CED), demonstrates that a convolutional network can be 12 times smaller than a recurrent network and yet achieves better performance, which shows its applicability for an embedded system: the hearing aids. version:1
arxiv-1609-07093 | Neural Photo Editing with Introspective Adversarial Networks | http://arxiv.org/abs/1609.07093 | id:1609.07093 author:Andrew Brock, Theodore Lim, J. M. Ritchie, Nick Weston category:cs.LG cs.CV cs.NE stat.ML  published:2016-09-22 summary:We present the Neural Photo Editor, an interface for exploring the latent space of generative image models and making large, semantically coherent changes to existing images. Our interface is powered by the Introspective Adversarial Network, a hybridization of the Generative Adversarial Network and the Variational Autoencoder designed for use in the editor. Our model makes use of a novel computational block based on dilated convolutions, and Orthogonal Regularization, a novel weight regularization method. We validate our model on CelebA, SVHN, and ImageNet, and produce samples and reconstructions with high visual fidelity. version:1
arxiv-1609-07088 | Learning Modular Neural Network Policies for Multi-Task and Multi-Robot Transfer | http://arxiv.org/abs/1609.07088 | id:1609.07088 author:Coline Devin, Abhishek Gupta, Trevor Darrell, Pieter Abbeel, Sergey Levine category:cs.LG cs.RO  published:2016-09-22 summary:Reinforcement learning (RL) can automate a wide variety of robotic skills, but learning each new skill requires considerable real-world data collection and manual representation engineering to design policy classes or features. Using deep reinforcement learning to train general purpose neural network policies alleviates some of the burden of manual representation engineering by using expressive policy classes, but exacerbates the challenge of data collection, since such methods tend to be less efficient than RL with low-dimensional, hand-designed representations. Transfer learning can mitigate this problem by enabling us to transfer information from one skill to another and even from one robot to another. We show that neural network policies can be decomposed into "task-specific" and "robot-specific" modules, where the task-specific modules are shared across robots, and the robot-specific modules are shared across all tasks on that robot. This allows for sharing task information, such as perception, between robots and sharing robot information, such as dynamics and kinematics, between tasks. We exploit this decomposition to train mix-and-match modules that can solve new robot-task combinations that were not seen during training. Using a novel neural network architecture, we demonstrate the effectiveness of our transfer method for enabling zero-shot generalization with a variety of robots and tasks in simulation for both visual and non-visual tasks. version:1
arxiv-1609-07087 | (Bandit) Convex Optimization with Biased Noisy Gradient Oracles | http://arxiv.org/abs/1609.07087 | id:1609.07087 author:Xiaowei Hu, Prashanth L. A., András György, Csaba Szepesvári category:cs.LG stat.ML  published:2016-09-22 summary:Algorithms for bandit convex optimization and online learning often rely on constructing noisy gradient estimates, which are then used in appropriately adjusted first-order algorithms, replacing actual gradients. Depending on the properties of the function to be optimized and the nature of "noise" in the bandit feedback, the bias and variance of gradient estimates exhibit various tradeoffs. In this paper we propose a novel framework that replaces the specific gradient estimation methods with an abstract oracle. With the help of the new framework we unify previous works, reproducing their results in a clean and concise fashion, while, perhaps more importantly, the framework also allows us to formally show that to achieve the optimal root-$n$ rate either the algorithms that use existing gradient estimators, or the proof techniques used to analyze them have to go beyond what exists today. version:1
arxiv-1609-07075 | Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs | http://arxiv.org/abs/1609.07075 | id:1609.07075 author:Jiawei Wu, Ruobing Xie, Zhiyuan Liu, Maosong Sun category:cs.CL  published:2016-09-22 summary:Textual information is considered as significant supplement to knowledge representation learning (KRL). There are two main challenges for constructing knowledge representations from plain texts: (1) How to take full advantages of sequential contexts of entities in plain texts for KRL. (2) How to dynamically select those informative sentences of the corresponding entities for KRL. In this paper, we propose the Sequential Text-embodied Knowledge Representation Learning to build knowledge representations from multiple sentences. Given each reference sentence of an entity, we first utilize recurrent neural network with pooling or long short-term memory network to encode the semantic information of the sentence with respect to the entity. Then we further design an attention model to measure the informativeness of each sentence, and build text-based representations of entities. We evaluate our method on two tasks, including triple classification and link prediction. Experimental results demonstrate that our method outperforms other baselines on both tasks, which indicates that our method is capable of selecting informative sentences and encoding the textual information well into knowledge representations. version:1
arxiv-1609-07072 | The Many-Body Expansion Combined with Neural Networks | http://arxiv.org/abs/1609.07072 | id:1609.07072 author:Kun Yao, John E. Herr, John Parkhill category:physics.chem-ph physics.comp-ph stat.ML  published:2016-09-22 summary:Fragmentation methods such as the many-body expansion (MBE) are a common strategy to model large systems by partitioning energies into a hierarchy of decreasingly significant contributions. The number of fragments required for chemical accuracy is still prohibitively expensive for ab-initio MBE to compete with force field approximations for applications beyond single-point energies. Alongside the MBE, empirical models of ab-initio potential energy surfaces have improved, especially non-linear models based on neural networks (NN) which can reproduce ab-initio potential energy surfaces rapidly and accurately. Although they are fast, NNs suffer from their own curse of dimensionality; they must be trained on a representative sample of chemical space. In this paper we examine the synergy of the MBE and NN's, and explore their complementarity. The MBE offers a systematic way to treat systems of arbitrary size and intelligently sample chemical space. NN's reduce, by a factor in excess of $10^6$ the computational overhead of the MBE and reproduce the accuracy of ab-initio calculations without specialized force fields. We show they are remarkably general, providing comparable accuracy with drastically different chemical embeddings. To assess this we test a new chemical embedding which can be inverted to predict molecules with desired properties. version:1
arxiv-1609-07061 | Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations | http://arxiv.org/abs/1609.07061 | id:1609.07061 author:Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, Yoshua Bengio category:cs.NE cs.LG  published:2016-09-22 summary:We introduce a method to train Quantized Neural Networks (QNNs) --- neural networks with extremely low precision (e.g., 1-bit) weights and activations, at run-time. At train-time the quantized weights and activations are used for computing the parameter gradients. During the forward pass, QNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations. As a result, power consumption is expected to be drastically reduced. We trained QNNs over the MNIST, CIFAR-10, SVHN and ImageNet datasets. The resulting QNNs achieve prediction accuracy comparable to their 32-bit counterparts. For example, our quantized version of AlexNet with 1-bit weights and 2-bit activations achieves $51\%$ top-1 accuracy. Moreover, we quantize the parameter gradients to 6-bits as well which enables gradients computation using only bit-wise operation. Quantized recurrent neural networks were tested over the Penn Treebank dataset, and achieved comparable accuracy as their 32-bit counterparts using only 4-bits. Last but not least, we programmed a binary matrix multiplication GPU kernel with which it is possible to run our MNIST QNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The QNN code is available online. version:1
arxiv-1609-07060 | An equivalence between high dimensional Bayes optimal inference and M-estimation | http://arxiv.org/abs/1609.07060 | id:1609.07060 author:Madhu Advani, Surya Ganguli category:stat.ML cond-mat.dis-nn math.ST q-bio.NC stat.TH  published:2016-09-22 summary:When recovering an unknown signal from noisy measurements, the computational difficulty of performing optimal Bayesian MMSE (minimum mean squared error) inference often necessitates the use of maximum a posteriori (MAP) inference, a special case of regularized M-estimation, as a surrogate. However, MAP is suboptimal in high dimensions, when the number of unknown signal components is similar to the number of measurements. In this work we demonstrate, when the signal distribution and the likelihood function associated with the noise are both log-concave, that optimal MMSE performance is asymptotically achievable via another M-estimation procedure. This procedure involves minimizing convex loss and regularizer functions that are nonlinearly smoothed versions of the widely applied MAP optimization problem. Our findings provide a new heuristic derivation and interpretation for recent optimal M-estimators found in the setting of linear measurements and additive noise, and further extend these results to nonlinear measurements with non-additive noise. We numerically demonstrate superior performance of our optimal M-estimators relative to MAP. Overall, at the heart of our work is the revelation of a remarkable equivalence between two seemingly very different computational problems: namely that of high dimensional Bayesian integration underlying MMSE inference, and high dimensional convex optimization underlying M-estimation. In essence we show that the former difficult integral may be computed by solving the latter, simpler optimization problem. version:1
arxiv-1609-07053 | Semantic Tagging with Deep Residual Networks | http://arxiv.org/abs/1609.07053 | id:1609.07053 author:Johannes Bjerva, Barbara Plank, Johan Bos category:cs.CL  published:2016-09-22 summary:We propose a novel semantic tagging task, semtagging, tailored for the purpose of multilingual semantic parsing, and present the first tagger using deep residual networks (ResNets). Our tagger uses both word and character representations and includes a novel residual bypass architecture. We evaluate the tagset both intrinsically on the new task of semantic tagging, as well as on Part-of-Speech (POS) tagging. Our system, consisting of a ResNet and an auxiliary loss function predicting our semantic tags, significantly outperforms prior results on English Universal Dependencies POS tagging (95.71% accuracy on UD v1.2 and 95.67% accuracy on UD v1.3). version:1
arxiv-1609-07049 | Customized Facial Constant Positive Air Pressure (CPAP) Masks | http://arxiv.org/abs/1609.07049 | id:1609.07049 author:Matan Sela, Nadav Toledo, Yaron Honen, Ron Kimmel category:cs.GR cs.CV  published:2016-09-22 summary:Sleep apnea is a syndrome that is characterized by sudden breathing halts while sleeping. One of the common treatments involves wearing a mask that delivers continuous air flow into the nostrils so as to maintain a steady air pressure. These masks are designed for an average facial model and are often difficult to adjust due to poor fit to the actual patient. The incompatibility is characterized by gaps between the mask and the face, which deteriorates the impermeability of the mask and leads to air leakage. We suggest a fully automatic approach for designing a personalized nasal mask interface using a facial depth scan. The interfaces generated by the proposed method accurately fit the geometry of the scanned face, and are easy to manufacture. The proposed method utilizes cheap commodity depth sensors and 3D printing technologies to efficiently design and manufacture customized masks for patients suffering from sleep apnea. version:1
arxiv-1609-07035 | Abstractive Meeting Summarization UsingDependency Graph Fusion | http://arxiv.org/abs/1609.07035 | id:1609.07035 author:Siddhartha Banerjee, Prasenjit Mitra, Kazunari Sugiyama category:cs.CL  published:2016-09-22 summary:Automatic summarization techniques on meeting conversations developed so far have been primarily extractive, resulting in poor summaries. To improve this, we propose an approach to generate abstractive summaries by fusing important content from several utterances. Any meeting is generally comprised of several discussion topic segments. For each topic segment within a meeting conversation, we aim to generate a one sentence summary from the most important utterances using an integer linear programming-based sentence fusion approach. Experimental results show that our method can generate more informative summaries than the baselines. version:1
arxiv-1609-07034 | Multi-document abstractive summarization using ILP based multi-sentence compression | http://arxiv.org/abs/1609.07034 | id:1609.07034 author:Siddhartha Banerjee, Prasenjit Mitra, Kazunari Sugiyama category:cs.CL  published:2016-09-22 summary:Abstractive summarization is an ideal form of summarization since it can synthesize information from multiple documents to create concise informative summaries. In this work, we aim at developing an abstractive summarizer. First, our proposed approach identifies the most important document in the multi-document set. The sentences in the most important document are aligned to sentences in other documents to generate clusters of similar sentences. Second, we generate K-shortest paths from the sentences in each cluster using a word-graph structure. Finally, we select sentences from the set of shortest paths generated from all the clusters employing a novel integer linear programming (ILP) model with the objective of maximizing information content and readability of the final summary. Our ILP model represents the shortest paths as binary variables and considers the length of the path, information score and linguistic quality score in the objective function. Experimental results on the DUC 2004 and 2005 multi-document summarization datasets show that our proposed approach outperforms all the baselines and state-of-the-art extractive summarizers as measured by the ROUGE scores. Our method also outperforms a recent abstractive summarization technique. In manual evaluation, our approach also achieves promising results on informativeness and readability. version:1
arxiv-1609-07033 | Generating Abstractive Summaries from Meeting Transcripts | http://arxiv.org/abs/1609.07033 | id:1609.07033 author:Siddhartha Banerjee, Prasenjit Mitra, Kazunari Sugiyama category:cs.CL  published:2016-09-22 summary:Summaries of meetings are very important as they convey the essential content of discussions in a concise form. Generally, it is time consuming to read and understand the whole documents. Therefore, summaries play an important role as the readers are interested in only the important context of discussions. In this work, we address the task of meeting document summarization. Automatic summarization systems on meeting conversations developed so far have been primarily extractive, resulting in unacceptable summaries that are hard to read. The extracted utterances contain disfluencies that affect the quality of the extractive summaries. To make summaries much more readable, we propose an approach to generating abstractive summaries by fusing important content from several utterances. We first separate meeting transcripts into various topic segments, and then identify the important utterances in each segment using a supervised learning approach. The important utterances are then combined together to generate a one-sentence summary. In the text generation step, the dependency parses of the utterances in each segment are combined together to create a directed graph. The most informative and well-formed sub-graph obtained by integer linear programming (ILP) is selected to generate a one-sentence summary for each topic segment. The ILP formulation reduces disfluencies by leveraging grammatical relations that are more prominent in non-conversational style of text, and therefore generates summaries that is comparable to human-written abstractive summaries. Experimental results show that our method can generate more informative summaries than the baselines. In addition, readability assessments by human judges as well as log-likelihood estimates obtained from the dependency parser show that our generated summaries are significantly readable and well-formed. version:1
arxiv-1609-07028 | Image-embodied Knowledge Representation Learning | http://arxiv.org/abs/1609.07028 | id:1609.07028 author:Ruobing Xie, Zhiyuan Liu, Tat-seng Chua, Huanbo Luan, Maosong Sun category:cs.CV cs.CL  published:2016-09-22 summary:Entity images provide significant visual information that helps the construction of knowledge representations. Most conventional methods learn knowledge representations solely from structured triples, ignoring rich visual information extracted from entity images. In this paper, we propose a novel Image-embodied Knowledge Representation Learning model, where knowledge representations are learned with both triples and images. More specifically, for each image of an entity, we construct image-based representations via a neural image encoder, and these representations with respect to multiple image instances are then integrated via an attention-based method. We evaluate our models on knowledge graph completion and triple classification. Experimental results demonstrate that our models outperform all baselines on both tasks, which indicates the significance of visual information for knowledge representations and the capability of our models in learning knowledge representations with images. version:1
arxiv-1609-07009 | Is the deconvolution layer the same as a convolutional layer? | http://arxiv.org/abs/1609.07009 | id:1609.07009 author:Wenzhe Shi, Jose Caballero, Lucas Theis, Ferenc Huszar, Andrew Aitken, Christian Ledig, Zehan Wang category:cs.CV  published:2016-09-22 summary:In this note, we want to focus on aspects related to two questions most people asked us at CVPR about the network we presented. Firstly, What is the relationship between our proposed layer and the deconvolution layer? And secondly, why are convolutions in low-resolution (LR) space a better choice? These are key questions we tried to answer in the paper, but we were not able to go into as much depth and clarity as we would have liked in the space allowance. To better answer these questions in this note, we first discuss the relationships between the deconvolution layer in the forms of the transposed convolution layer, the sub-pixel convolutional layer and our efficient sub-pixel convolutional layer. We will refer to our efficient sub-pixel convolutional layer as a convolutional layer in LR space to distinguish it from the common sub-pixel convolutional layer. We will then show that for a fixed computational budget and complexity, a network with convolutions exclusively in LR space has more representation power at the same speed than a network that first upsamples the input in high resolution space. version:1
arxiv-1609-06988 | Symmetric Non-Rigid Structure from Motion for Category-Specific Object Structure Estimation | http://arxiv.org/abs/1609.06988 | id:1609.06988 author:Yuan Gao, Alan Yuille category:cs.CV cs.CG  published:2016-09-22 summary:Many objects, especially these made by humans, are symmetric, e.g. cars and aeroplanes. This paper addresses the estimation of 3D structures of symmetric objects from multiple images of the same object category, e.g. different cars, seen from various viewpoints. We assume that the deformation between different instances from the same object category is non-rigid and symmetric. In this paper, we extend two leading non-rigid structure from motion (SfM) algorithms to exploit symmetry constraints. We model the both methods as energy minimization, in which we also recover the missing observations caused by occlusions. In particularly, we show that by rotating the coordinate system, the energy can be decoupled into two independent terms, which still exploit symmetry, to apply matrix factorization separately on each of them for initialization. The results on the Pascal3D+ dataset show that our methods significantly improve performance over baseline methods. version:1
arxiv-1609-06942 | Randomized Independent Component Analysis | http://arxiv.org/abs/1609.06942 | id:1609.06942 author:Matan Sela, Ron Kimmel category:stat.ML cs.LG cs.SY math.PR math.ST stat.TH  published:2016-09-22 summary:Independent component analysis (ICA) is a method for recovering statistically independent signals from observations of unknown linear combinations of the sources. Some of the most accurate ICA decomposition methods require searching for the inverse transformation which minimizes different approximations of the Mutual Information, a measure of statistical independence of random vectors. Two such approximations are the Kernel Generalized Variance or the Kernel Canonical Correlation which has been shown to reach the highest performance of ICA methods. However, the computational effort necessary just for computing these measures is cubic in the sample size. Hence, optimizing them becomes even more computationally demanding, in terms of both space and time. Here, we propose a couple of alternative novel measures based on randomized features of the samples - the Randomized Generalized Variance and the Randomized Canonical Correlation. The computational complexity of calculating the proposed alternatives is linear in the sample size and provide a controllable approximation of their Kernel-based non-random versions. We also show that optimization of the proposed statistical properties yields a comparable separation error at an order of magnitude faster compared to Kernel-based measures. version:1
arxiv-1609-06936 | Walker-Independent Features for Gait Recognition from Motion Capture Data | http://arxiv.org/abs/1609.06936 | id:1609.06936 author:Michal Balazia, Petr Sojka category:cs.CV 68T05  68T10 I.5  published:2016-09-22 summary:MoCap-based human identification, as a pattern recognition discipline, can be optimized using a machine learning approach. Yet in some applications such as video surveillance new identities can appear on the fly and labeled data for all encountered people may not always be available. This work introduces the concept of learning walker-independent gait features directly from raw joint coordinates by a modification of the Fisher Linear Discriminant Analysis with Maximum Margin Criterion. Our new approach shows not only that these features can discriminate different people than who they are learned on, but also that the number of learning identities can be much smaller than the number of walkers encountered in the real operation. version:1
arxiv-1609-06935 | Quantum Neural Machine Learning - Backpropagation and Dynamics | http://arxiv.org/abs/1609.06935 | id:1609.06935 author:Carlos Pedro Gonçalves category:cs.NE cond-mat.dis-nn nlin.AO quant-ph  published:2016-09-22 summary:The current work addresses quantum machine learning in the context of Quantum Artificial Neural Networks such that the networks' processing is divided in two stages: the learning stage, where the network converges to a specific quantum circuit, and the backpropagation stage where the network effectively works as a self-programing quantum computing system that selects the quantum circuits to solve computing problems. The results are extended to general architectures including recurrent networks that interact with an environment, coupling with it in the neural links' activation order, and self-organizing in a dynamical regime that intermixes patterns of dynamical stochasticity and persistent quasiperiodic dynamics, making emerge a form of noise resilient dynamical record. version:1
arxiv-1609-06927 | A quantitative analysis of tilt in the Café Wall illusion: a bioplausible model for foveal and peripheral vision | http://arxiv.org/abs/1609.06927 | id:1609.06927 author:Nasim Nematzadeh, David M. W. Powers category:cs.CV  published:2016-09-22 summary:The biological characteristics of human visual processing can be investigated through the study of optical illusions and their perception, giving rise to intuitions that may improve computer vision to match human performance. Geometric illusions are a specific subfamily in which orientations and angles are misperceived. This paper reports quantifiable predictions of the degree of tilt for a typical geometric illusion called Caf\'e Wall, in which the mortar between the tiles seems to tilt or bow. Our study employs a common bioplausible model of retinal processing and we further develop an analytic processing pipeline to quantify and thus predict the specific angle of tilt. We further study the effect of resolution and feature size in order to predict the different perceived tilts in different areas of the fovea and periphery, where resolution varies as the eye saccades to different parts of the image. In the experiments, several different minimal portions of the pattern, modeling monocular and binocular foveal views, are investigated across multiple scales, in order to quantify tilts with confidence intervals and explore the difference between local and global tilt. version:1
arxiv-1609-06896 | Realtime Hierarchical Clustering based on Boundary and Surface Statistics | http://arxiv.org/abs/1609.06896 | id:1609.06896 author:Dominik Alexander Klein, Dirk Schulz, Armin Bernd Cremers category:cs.CV  published:2016-09-22 summary:Visual grouping is a key mechanism in human scene perception. There, it belongs to the subconscious, early processing and is key prerequisite for other high level tasks such as recognition. In this paper, we introduce an efficient, realtime capable algorithm which likewise agglomerates a valuable hierarchical clustering of a scene, while using purely local appearance statistics. To speed up the processing, first we subdivide the image into meaningful, atomic segments using a fast Watershed transform. Starting from there, our rapid, agglomerative clustering algorithm prunes and maintains the connectivity graph between clusters to contain only such pairs, which directly touch in the image domain and are reciprocal nearest neighbors (RNN) wrt. a distance metric. The core of this approach is our novel cluster distance: it combines boundary and surface statistics both in terms of appearance as well as spatial linkage. This yields state-of-the-art performance, as we demonstrate in conclusive experiments conducted on BSDS500 and Pascal-Context datasets. version:1
arxiv-1609-06864 | A probabilistic network for the diagnosis of acute cardiopulmonary diseases | http://arxiv.org/abs/1609.06864 | id:1609.06864 author:Alessandro Magrini, Davide Luciani, Federico Mattia Stefanini category:stat.ML stat.AP 62F15  62P10  published:2016-09-22 summary:We describe our experience in the development of a probabilistic network for the diagnosis of acute cardiopulmonary diseases. A panel of expert physicians collaborated to specify the qualitative part, that is a directed acyclic graph defining a factorization of the joint probability distribution of domain variables. The quantitative part, that is the set of all conditional probability distributions defined by each factor, was estimated in the Bayesian paradigm: we applied a special formal representation, characterized by a low number of parameters and a parameterization intelligible for physicians, elicited the joint prior distribution of parameters from medical experts, and updated it by conditioning on a dataset of hospital patient records using Markov Chain Monte Carlo simulation. Refinement was cyclically performed until the probabilistic network provided satisfactory Concordance Index values for a selection of acute diseases and reasonable inference on six fictitious patient cases. The probabilistic network can be employed to perform medical diagnosis on a total of 63 diseases (38 acute and 25 chronic) on the basis of up to 167 patient findings. version:1
arxiv-1609-06861 | How Useful is Region-based Classification of Remote Sensing Images in a Deep Learning Framework? | http://arxiv.org/abs/1609.06861 | id:1609.06861 author:Nicolas Audebert, Bertrand Le Saux, Sébastien Lefèvre category:cs.CV  published:2016-09-22 summary:In this paper, we investigate the impact of segmentation algorithms as a preprocessing step for classification of remote sensing images in a deep learning framework. Especially, we address the issue of segmenting the image into regions to be classified using pre-trained deep neural networks as feature extractors for an SVM-based classifier. An efficient segmentation as a preprocessing step helps learning by adding a spatially-coherent structure to the data. Therefore, we compare algorithms producing superpixels with more traditional remote sensing segmentation algorithms and measure the variation in terms of classification accuracy. We establish that superpixel algorithms allow for a better classification accuracy as a homogenous and compact segmentation favors better generalization of the training samples. version:1
arxiv-1609-06846 | Semantic Segmentation of Earth Observation Data Using Multimodal and Multi-scale Deep Networks | http://arxiv.org/abs/1609.06846 | id:1609.06846 author:Nicolas Audebert, Bertrand Le Saux, Sébastien Lefèvre category:cs.CV cs.NE  published:2016-09-22 summary:This work investigates the use of deep fully convolutional neural networks (DFCNN) for pixel-wise scene labeling of Earth Observation images. Especially, we train a variant of the SegNet architecture on remote sensing data over an urban area and study different strategies for performing accurate semantic segmentation. Our contributions are the following: 1) we transfer efficiently a DFCNN from generic everyday images to remote sensing images; 2) we introduce a multi-kernel convolutional layer for fast aggregation of predictions at multiple scales; 3) we perform data fusion from heterogeneous sensors (optical and laser) using residual correction. Our framework improves state-of-the-art accuracy on the ISPRS Vaihingen 2D Semantic Labeling dataset. version:1
arxiv-1609-06845 | On the usability of deep networks for object-based image analysis | http://arxiv.org/abs/1609.06845 | id:1609.06845 author:Nicolas Audebert, Bertrand Le Saux, Sébastien Lefèvre category:cs.NE cs.CV  published:2016-09-22 summary:As computer vision before, remote sensing has been radically changed by the introduction of Convolution Neural Networks. Land cover use, object detection and scene understanding in aerial images rely more and more on deep learning to achieve new state-of-the-art results. Recent architectures such as Fully Convolutional Networks (Long et al., 2015) can even produce pixel level annotations for semantic mapping. In this work, we show how to use such deep networks to detect, segment and classify different varieties of wheeled vehicles in aerial images from the ISPRS Potsdam dataset. This allows us to tackle object detection and classification on a complex dataset made up of visually similar classes, and to demonstrate the relevance of such a subclass modeling approach. Especially, we want to show that deep learning is also suitable for object-oriented analysis of Earth Observation data. First, we train a FCN variant on the ISPRS Potsdam dataset and show how the learnt semantic maps can be used to extract precise segmentation of vehicles, which allow us studying the repartition of vehicles in the city. Second, we train a CNN to perform vehicle classification on the VEDAI (Razakarivony and Jurie, 2016) dataset, and transfer its knowledge to classify candidate segmented vehicles on the Potsdam dataset. version:1
arxiv-1609-06426 | From Facial Expression Recognition to Interpersonal Relation Prediction | http://arxiv.org/abs/1609.06426 | id:1609.06426 author:Zhanpeng Zhang, Ping Luo, Chen Change Loy, Xiaoou Tang category:cs.CV  published:2016-09-21 summary:Interpersonal relation defines the association, e.g., warm, friendliness, and dominance, between two or more people. Motivated by psychological studies, we investigate if such fine-grained and high-level relation traits can be characterized and quantified from face images in the wild. We address this challenging problem by first studying a deep network architecture for robust recognition of facial expressions. Unlike existing models that typically learn from facial expression labels alone, we devise an effective multitask network that is capable of learning from rich auxiliary attributes such as gender, age, and head pose, beyond just facial expression data. While conventional supervised training requires datasets with complete labels (e.g., all samples must be labeled with gender, age, and expression), we show that this requirement can be relaxed via a novel attribute propagation method. The approach further allows us to leverage the inherent correspondences between heterogeneous attribute sources despite the disparate distributions of different datasets. With the network we demonstrate state-of-the-art results on existing facial expression recognition benchmarks. To predict inter-personal relation, we use the expression recognition network as branches for a Siamese model. Extensive experiments show that our model is capable of mining mutual context of faces for accurate fine-grained interpersonal prediction. version:2
arxiv-1609-06840 | Exact Sampling from Determinantal Point Processes | http://arxiv.org/abs/1609.06840 | id:1609.06840 author:Philipp Hennig, Roman Garnett category:cs.LG math.PR stat.ML  published:2016-09-22 summary:Determinantal point processes (DPPs) are an important concept in random matrix theory and combinatorics. They have also recently attracted interest in the study of numerical methods for machine learning, as they offer an elegant "missing link" between independent Monte Carlo sampling and deterministic evaluation on regular grids, applicable to a general set of spaces. This is helpful whenever an algorithm *explores* to reduce uncertainty, such as in active learning, Bayesian optimization, reinforcement learning, and marginalization in graphical models. To draw samples from a DPP in practice, existing literature focuses on approximate schemes of low cost, or comparably inefficient exact algorithms like rejection sampling. We point out that, for many settings of relevance to machine learning, it is also possible to draw *exact* samples from DPPs on continuous domains. We start from an intuitive example on the real line, which is then generalized to multivariate real vector spaces. We also compare to previously studied approximations, showing that exact sampling, despite higher cost, can be preferable where precision is needed. version:1
arxiv-1609-06838 | Deep-Learned Collision Avoidance Policy for Distributed Multi-Agent Navigation | http://arxiv.org/abs/1609.06838 | id:1609.06838 author:Pinxin Long, Wenxi Liu, Jia Pan category:cs.AI cs.CV cs.RO  published:2016-09-22 summary:High-speed, low-latency obstacle avoidance that is insensitive to sensor noise is essential for enabling multiple decentralized robots to function reliably in cluttered and dynamic environments. While other distributed multi-agent collision avoidance systems exist, these systems require online geometric optimization where tedious parameter tuning and perfect sensing are necessary. We present a novel end-to-end framework to generate reactive collision avoidance policy for efficient distributed multi-agent navigation. Our method formulates an agent's navigation strategy as a deep neural network mapping from the observed noisy sensor measurements to the agent's steering commands in terms of movement velocity. We train the network on a large number of frames of collision avoidance data collected by repeatedly running a multi-agent simulator with different parameter settings. We validate the learned deep neural network policy in a set of simulated scenarios with noisy measurements and demonstrate that our method is able to generate a robust navigation strategy that is insensitive to imperfect sensing and works reliably in all situations. We also show that our method can be well generalized to scenarios that do not appear in our training data, including scenes with static obstacles and agents with different shapes. A video is available at https://youtu.be/uMcdMmcR67A. version:1
arxiv-1609-06831 | Hawkes Processes with Stochastic Excitations | http://arxiv.org/abs/1609.06831 | id:1609.06831 author:Young Lee, Kar Wai Lim, Cheng Soon Ong category:cs.LG stat.ML  published:2016-09-22 summary:We propose an extension to Hawkes processes by treating the levels of self-excitation as a stochastic differential equation. Our new point process allows better approximation in application domains where events and intensities accelerate each other with correlated levels of contagion. We generalize a recent algorithm for simulating draws from Hawkes processes whose levels of excitation are stochastic processes, and propose a hybrid Markov chain Monte Carlo approach for model fitting. Our sampling procedure scales linearly with the number of required events and does not require stationarity of the point process. A modular inference procedure consisting of a combination between Gibbs and Metropolis Hastings steps is put forward. We recover expectation maximization as a special case. Our general approach is illustrated for contagion following geometric Brownian motion and exponential Langevin dynamics. version:1
arxiv-1609-06826 | Bibliographic Analysis with the Citation Network Topic Model | http://arxiv.org/abs/1609.06826 | id:1609.06826 author:Kar Wai Lim, Wray Buntine category:cs.DL cs.LG stat.ML  published:2016-09-22 summary:Bibliographic analysis considers author's research areas, the citation network and paper content among other things. In this paper, we combine these three in a topic model that produces a bibliographic model of authors, topics and documents using a non-parametric extension of a combination of the Poisson mixed-topic link model and the author-topic model. We propose a novel and efficient inference algorithm for the model to explore subsets of research publications from CiteSeerX. Our model demonstrates improved performance in both model fitting and a clustering task compared to several baselines. version:1
arxiv-1609-06791 | Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling | http://arxiv.org/abs/1609.06791 | id:1609.06791 author:Kar Wai Lim, Changyou Chen, Wray Buntine category:cs.CL cs.IR cs.SI  published:2016-09-22 summary:Twitter data is extremely noisy -- each tweet is short, unstructured and with informal language, a challenge for current topic modeling. On the other hand, tweets are accompanied by extra information such as authorship, hashtags and the user-follower network. Exploiting this additional information, we propose the Twitter-Network (TN) topic model to jointly model the text and the social network in a full Bayesian nonparametric way. The TN topic model employs the hierarchical Poisson-Dirichlet processes (PDP) for text modeling and a Gaussian process random function model for social network modeling. We show that the TN topic model significantly outperforms several existing nonparametric models due to its flexibility. Moreover, the TN topic model enables additional informative inference such as authors' interests, hashtag analysis, as well as leading to further applications such as author recommendation, automatic topic labeling and hashtag suggestion. Note our general inference framework can readily be applied to other topic models with embedded PDP nodes. version:1
arxiv-1609-06591 | FaceNet2ExpNet: Regularizing a Deep Face Recognition Net for Expression Recognition | http://arxiv.org/abs/1609.06591 | id:1609.06591 author:Hui Ding, Shaohua Kevin Zhou, Rama Chellappa category:cs.CV  published:2016-09-21 summary:Relatively small data sets available for expression recognition research make the training of deep networks for expression recognition very challenging. Although fine-tuning can partially alleviate the issue, the performance is still below acceptable levels as the deep features probably contain redun- dant information from the pre-trained domain. In this paper, we present FaceNet2ExpNet, a novel idea to train an expression recognition network based on static images. We first propose a new distribution function to model the high-level neurons of the expression network. Based on this, a two-stage training algorithm is carefully designed. In the pre-training stage, we train the convolutional layers of the expression net, regularized by the face net; In the refining stage, we append fully- connected layers to the pre-trained convolutional layers and train the whole network jointly. Visualization shows that the model trained with our method captures improved high-level expression semantics. Evaluations on four public expression databases, CK+, Oulu-CASIA, TFD, and SFEW demonstrate that our method achieves better results than state-of-the-art. version:2
arxiv-1609-06693 | SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks | http://arxiv.org/abs/1609.06693 | id:1609.06693 author:Armen Aghajanyan category:cs.LG  published:2016-09-21 summary:Deep neural networks are learning models with a very high capacity and therefore prone to over-fitting. Many regularization techniques such as Dropout, DropConnect, and weight decay all attempt to solve the problem of over-fitting by reducing the capacity of their respective models (Srivastava et al., 2014), (Wan et al., 2013), (Krogh & Hertz, 1992). In this paper we introduce a new form of regularization that guides the learning problem in a way that reduces over-fitting without sacrificing the capacity of the model. The mistakes that models make in early stages of training carry information about the learning problem. By adjusting the labels of the current epoch of training through a weighted average of the real labels, and an exponential average of the past soft-targets we achieved a regularization scheme as powerful as Dropout without necessarily reducing the capacity of the model, and simplified the complexity of the learning problem. SoftTarget regularization proved to be an effective tool in various neural network architectures. version:2
arxiv-1609-06783 | Nonparametric Bayesian Topic Modelling with the Hierarchical Pitman-Yor Processes | http://arxiv.org/abs/1609.06783 | id:1609.06783 author:Kar Wai Lim, Wray Buntine, Changyou Chen, Lan Du category:stat.ML cs.CL cs.LG  published:2016-09-22 summary:The Dirichlet process and its extension, the Pitman-Yor process, are stochastic processes that take probability distributions as a parameter. These processes can be stacked up to form a hierarchical nonparametric Bayesian model. In this article, we present efficient methods for the use of these processes in this hierarchical context, and apply them to latent variable models for text analytics. In particular, we propose a general framework for designing these Bayesian models, which are called topic models in the computer science community. We then propose a specific nonparametric Bayesian topic model for modelling text from social media. We focus on tweets (posts on Twitter) in this article due to their ease of access. We find that our nonparametric model performs better than existing parametric models in both goodness of fit and real world applications. version:1
arxiv-1609-06782 | Deep Learning for Video Classification and Captioning | http://arxiv.org/abs/1609.06782 | id:1609.06782 author:Zuxuan Wu, Ting Yao, Yanwei Fu, Yu-Gang Jiang category:cs.CV cs.MM  published:2016-09-22 summary:Accelerated by the tremendous increase in Internet bandwidth and storage space, video data has been generated, published and spread explosively, becoming an indispensable part of today's big data. In this paper, we focus on reviewing two lines of research aiming to stimulate the comprehension of videos with deep learning: video classification and video captioning. While video classification concentrates on automatically labeling video clips based on their semantic contents like human actions or complex events, video captioning attempts to generate a complete and natural sentence, enriching the single label as in video classification, to capture the most informative dynamics in videos. In addition, we also provide a review of popular benchmarks and competitions, which are critical for evaluating the technical progress of this vibrant field. version:1
arxiv-1609-06773 | Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning | http://arxiv.org/abs/1609.06773 | id:1609.06773 author:Suyoun Kim, Takaaki Hori, Shinji Watanabe category:cs.CL  published:2016-09-21 summary:Recently, there has been an increasing interest in end-to-end speech recognition that directly transcribes speech to text without any predefined alignments. One approach is the attention-based encoder-decoder framework that learns a mapping between variable-length input and output sequences in one step using a purely data-driven method. The attention model has often been shown to improve the performance over another end-to-end approach, the Connectionist Temporal Classification (CTC), mainly because it explicitly uses the history of the target character without any conditional independence assumptions. However, we observed that the attention model has shown poor results especially in noisy condition and is hard to be trained in the initial training stage with long input sequences, as compared with CTC. This is because the attention model is too flexible to predict proper alignments in such cases due to the lack of left-to-right constraints as used in CTC. This paper presents a novel method for end-to-end speech recognition to improve robustness and achieve fast convergence by using a joint CTC-attention model within the multi-task learning framework, thereby mitigating the alignment issue. An experiment on the WSJ and CHiME-4 tasks demonstrates its advantages over both the CTC and attention-based encoder-decoder baselines, showing 6.6-10.3% relative improvements in Character Error Rate (CER). version:1
arxiv-1609-06772 | Spatio-Temporal Sentiment Hotspot Detection Using Geotagged Photos | http://arxiv.org/abs/1609.06772 | id:1609.06772 author:Yi Zhu, Shawn Newsam category:cs.CV cs.CY cs.MM  published:2016-09-21 summary:We perform spatio-temporal analysis of public sentiment using geotagged photo collections. We develop a deep learning-based classifier that predicts the emotion conveyed by an image. This allows us to associate sentiment with place. We perform spatial hotspot detection and show that different emotions have distinct spatial distributions that match expectations. We also perform temporal analysis using the capture time of the photos. Our spatio-temporal hotspot detection correctly identifies emerging concentrations of specific emotions and year-by-year analyses of select locations show there are strong temporal correlations between the predicted emotions and known events. version:1
arxiv-1609-06753 | How should we evaluate supervised hashing? | http://arxiv.org/abs/1609.06753 | id:1609.06753 author:Alexandre Sablayrolles, Matthijs Douze, Hervé Jégou, Nicolas Usunier category:cs.CV  published:2016-09-21 summary:Hashing is the problem of producing compact representations such that one can efficiently solve a task, such as image classification or retrieval, based on these short codes. When hashing is supervised, the codes are trained on a labelled dataset. This paper first shows that the evaluation protocols used in the literature are not satisfactory. In particular, we show that a trivial solution that encodes the output of a classifier significantly outperforms existing supervised or semi-supervised methods, while using much shorter codes. We then propose two alternative protocols for supervised hashing: one based on retrieval on a disjoint set of classes, and another based on transfer learning to new classes. We provide two baseline methods for image-related tasks to assess the performance of (semi-)supervised hashing: without coding and with unsupervised codes. These baselines give a lower- and upper-bound on the performance of a supervised hashing scheme. version:1
arxiv-1609-06741 | Using CMA-ES for tuning coupled PID controllers within models of combustion engines | http://arxiv.org/abs/1609.06741 | id:1609.06741 author:Katerina Marova category:cs.SY cs.NE math.OC  published:2016-09-21 summary:Proportional integral derivative (PID) controllers are important and widely used tools of system control. In this paper, we deal with the problem of tuning multiple coupled PID controllers within the practical context of combustion engine simulations, where no information about the controlled system is provided. We formulate the problem as a black-box optimization problem and, based on its properties and practical limitations, we find and tune the appropriate optimization algorithm: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with bi-population restart strategy, elitist parent selection and active covariance matrix adaptation. Details of the algorithm's experiment-based calibration are explained as well as derivation of a suitable objective function. Finally, the method's usability is verified on six models of real engines. version:1
arxiv-1609-06694 | PixelNet: Towards a General Pixel-level Architecture | http://arxiv.org/abs/1609.06694 | id:1609.06694 author:Aayush Bansal, Xinlei Chen, Bryan Russell, Abhinav Gupta, Deva Ramanan category:cs.CV cs.LG  published:2016-09-21 summary:We explore architectures for general pixel-level prediction problems, from low-level edge detection to mid-level surface normal estimation to high-level semantic segmentation. Convolutional predictors, such as the fully-convolutional network (FCN), have achieved remarkable success by exploiting the spatial redundancy of neighboring pixels through convolutional processing. Though computationally efficient, we point out that such approaches are not statistically efficient during learning precisely because spatial redundancy limits the information learned from neighboring pixels. We demonstrate that (1) stratified sampling allows us to add diversity during batch updates and (2) sampled multi-scale features allow us to explore more nonlinear predictors (multiple fully-connected layers followed by ReLU) that improve overall accuracy. Finally, our objective is to show how a architecture can get performance better than (or comparable to) the architectures designed for a particular task. Interestingly, our single architecture produces state-of-the-art results for semantic segmentation on PASCAL-Context, surface normal estimation on NYUDv2 dataset, and edge detection on BSDS without contextual post-processing. version:1
arxiv-1609-06686 | Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution | http://arxiv.org/abs/1609.06686 | id:1609.06686 author:Sebastian Ruder, Parsa Ghaffari, John G. Breslin category:cs.CL cs.LG  published:2016-09-21 summary:Convolutional neural networks (CNNs) have demonstrated superior capability for extracting information from raw signals in computer vision. Recently, character-level and multi-channel CNNs have exhibited excellent performance for sentence classification tasks. We apply CNNs to large-scale authorship attribution, which aims to determine an unknown text's author among many candidate authors, motivated by their ability to process character-level signals and to differentiate between a large number of classes, while making fast predictions in comparison to state-of-the-art approaches. We extensively evaluate CNN-based approaches that leverage word and character channels and compare them against state-of-the-art methods for a large range of author numbers, shedding new light on traditional approaches. We show that character-level CNNs outperform the state-of-the-art on four out of five datasets in different domains. Additionally, we present the first application of authorship attribution to reddit. version:1
arxiv-1609-06669 | Fast and reliable stereopsis measurement at multiple distances with iPad | http://arxiv.org/abs/1609.06669 | id:1609.06669 author:Manuel Rodriguez-Vallejo, Clara Llorens-Quintana, Diego Montagud, Walter D. Furlan, Juan A. Monsoriu category:cs.CV  published:2016-09-21 summary:Purpose: To present a new fast and reliable application for iPad (ST) for screening stereopsis at multiple distances. Methods: A new iPad application (app) based on a random dot stereogram was designed for screening stereopsis at multiple distances. Sixty-five subjects with no ocular diseases and wearing their habitual correction were tested at two different distances: 3 m and at 0.4 m. Results were compared with other commercial tests: TNO (at near) and Howard Dolman (at distance) Subjects were cited one week later in order to repeat the same procedures for assessing reproducibility of the tests. Results: Stereopsis at near was better with ST (40 arcsec) than with TNO (60 arcsec), but not significantly (p = 0.36). The agreement was good (k = 0.604) and the reproducibility was better with ST (k = 0.801) than with TNO (k = 0.715), in fact median difference between days was significant only with TNO (p = 0.02). On the other hand, poor agreement was obtained between HD and ST at far distance (k=0.04), obtaining significant differences in medians (p = 0.001) and poorer reliability with HD (k = 0.374) than with ST (k = 0.502). Conclusions: Screening stereopsis at near with a new iPad app demonstrated to be a fast and realiable. Results were in a good agreement with conventional tests as TNO, but it could not be compared at far vision with HD due to the limited resolution of the iPad. version:1
arxiv-1609-06668 | Characterization of Lung Nodule Malignancy using Hybrid Shape and Appearance Features | http://arxiv.org/abs/1609.06668 | id:1609.06668 author:Mario Buty, Ziyue Xu, Mingchen Gao, Ulas Bagci, Aaron Wu, Daniel J. Mollura category:cs.CV  published:2016-09-21 summary:Computed tomography imaging is a standard modality for detecting and assessing lung cancer. In order to evaluate the malignancy of lung nodules, clinical practice often involves expert qualitative ratings on several criteria describing a nodule's appearance and shape. Translating these features for computer-aided diagnostics is challenging due to their subjective nature and the difficulties in gaining a complete description. In this paper, we propose a computerized approach to quantitatively evaluate both appearance distinctions and 3D surface variations. Nodule shape was modeled and parameterized using spherical harmonics, and appearance features were extracted using deep convolutional neural networks. Both sets of features were combined to estimate the nodule malignancy using a random forest classifier. The proposed algorithm was tested on the publicly available Lung Image Database Consortium dataset, achieving high accuracy. By providing lung nodule characterization, this method can provide a robust alternative reference opinion for lung cancer diagnosis. version:1
arxiv-1609-06666 | Vote3Deep: Fast Object Detection in 3D Point Clouds Using Efficient Convolutional Neural Networks | http://arxiv.org/abs/1609.06666 | id:1609.06666 author:Martin Engelcke, Dushyant Rao, Dominic Zeng Wang, Chi Hay Tong, Ingmar Posner category:cs.RO cs.AI cs.CV cs.LG cs.NE  published:2016-09-21 summary:This paper proposes a computationally efficient approach to detecting objects natively in 3D point clouds using convolutional neural networks (CNNs). In particular, this is achieved by leveraging a feature-centric voting scheme to implement novel convolutional layers which explicitly exploit the sparsity encountered in the input. To this end we examine the trade-off between accuracy and speed for different architectures and additionally propose to use an L1 penalty on the filter activations to further encourage sparsity in the intermediate representations. To the best of our knowledge, this is the first work to propose sparse convolutional layers and L1 regularisation for efficient large-scale processing of 3D data. We demonstrate the efficacy of our approach on the KITTI object detection benchmark and show that Vote3Deep models with as few as three layers outperform the previous state of the art in both laser and laser-vision based approaches across the board by margins of up to 40% while remaining highly competitive in terms of processing time. version:1
arxiv-1609-06657 | The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA) | http://arxiv.org/abs/1609.06657 | id:1609.06657 author:Andrew Shin, Yoshitaka Ushiku, Tatsuya Harada category:cs.CV cs.CL  published:2016-09-21 summary:Visual Question Answering (VQA) task has showcased a new stage of interaction between language and vision, two of the most pivotal components of artificial intelligence. However, it has mostly focused on generating short and repetitive answers, mostly single words, which fall short of rich linguistic capabilities of humans. We introduce Full-Sentence Visual Question Answering (FSVQA) dataset, consisting of nearly 1 million pairs of questions and full-sentence answers for images, built by applying a number of rule-based natural language processing techniques to original VQA dataset and captions in the MS COCO dataset. This poses many additional complexities to conventional VQA task, and we provide a baseline for approaching and evaluating the task, on top of which we invite the research community to build further improvements. version:1
arxiv-1609-06653 | Land Use Classification using Convolutional Neural Networks Applied to Ground-Level Images | http://arxiv.org/abs/1609.06653 | id:1609.06653 author:Yi Zhu, Shawn Newsam category:cs.CV cs.CY cs.MM  published:2016-09-21 summary:Land use mapping is a fundamental yet challenging task in geographic science. In contrast to land cover mapping, it is generally not possible using overhead imagery. The recent, explosive growth of online geo-referenced photo collections suggests an alternate approach to geographic knowledge discovery. In this work, we present a general framework that uses ground-level images from Flickr for land use mapping. Our approach benefits from several novel aspects. First, we address the nosiness of the online photo collections, such as imprecise geolocation and uneven spatial distribution, by performing location and indoor/outdoor filtering, and semi- supervised dataset augmentation. Our indoor/outdoor classifier achieves state-of-the-art performance on several bench- mark datasets and approaches human-level accuracy. Second, we utilize high-level semantic image features extracted using deep learning, specifically convolutional neural net- works, which allow us to achieve upwards of 76% accuracy on a challenging eight class land use mapping problem. version:1
arxiv-1609-06649 | Minimally Supervised Written-to-Spoken Text Normalization | http://arxiv.org/abs/1609.06649 | id:1609.06649 author:Ke Wu, Kyle Gorman, Richard Sproat category:cs.CL  published:2016-09-21 summary:In speech-applications such as text-to-speech (TTS) or automatic speech recognition (ASR), \emph{text normalization} refers to the task of converting from a \emph{written} representation into a representation of how the text is to be \emph{spoken}. In all real-world speech applications, the text normalization engine is developed---in large part---by hand. For example, a hand-built grammar may be used to enumerate the possible ways of saying a given token in a given language, and a statistical model used to select the most appropriate pronunciation in context. In this study we examine the tradeoffs associated with using more or less language-specific domain knowledge in a text normalization engine. In the most data-rich scenario, we have access to a carefully constructed hand-built normalization grammar that for any given token will produce a set of all possible verbalizations for that token. We also assume a corpus of aligned written-spoken utterances, from which we can train a ranking model that selects the appropriate verbalization for the given context. As a substitute for the carefully constructed grammar, we also consider a scenario with a language-universal normalization \emph{covering grammar}, where the developer merely needs to provide a set of lexical items particular to the language. As a substitute for the aligned corpus, we also consider a scenario where one only has the spoken side, and the corresponding written side is "hallucinated" by composing the spoken side with the inverted normalization grammar. We investigate the accuracy of a text normalization engine under each of these scenarios. We report the results of experiments on English and Russian. version:1
arxiv-1609-06647 | Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge | http://arxiv.org/abs/1609.06647 | id:1609.06647 author:Oriol Vinyals, Alexander Toshev, Samy Bengio, Dumitru Erhan category:cs.CV  published:2016-09-21 summary:Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. Finally, given the recent surge of interest in this task, a competition was organized in 2015 using the newly released COCO dataset. We describe and analyze the various improvements we applied to our own baseline and show the resulting performance in the competition, which we won ex-aequo with a team from Microsoft Research, and provide an open source implementation in TensorFlow. version:1
arxiv-1609-06604 | Improving analytical tomographic reconstructions through consistency conditions | http://arxiv.org/abs/1609.06604 | id:1609.06604 author:Filippo Arcadu, Jakob Vogel, Marco Stampanoni, Federica Marone category:physics.med-ph cs.CV  published:2016-09-21 summary:This work introduces and characterizes a fast parameterless filter based on the Helgason-Ludwig consistency conditions, used to improve the accuracy of analytical reconstructions of tomographic undersampled datasets. The filter, acting in the Radon domain, extrapolates intermediate projections between those existing. The resulting sinogram, doubled in views, is then reconstructed by a standard analytical method. Experiments with simulated data prove that the peak-signal-to-noise ratio of the results computed by filtered backprojection is improved up to 5-6 dB, if the filter is used prior to reconstruction. version:1
arxiv-1609-06585 | Image Denoising via Multi-scale Nonlinear Diffusion Models | http://arxiv.org/abs/1609.06585 | id:1609.06585 author:Wensen Feng, Peng Qiao, Xuanyang Xi, Yunjin Chen category:cs.CV  published:2016-09-21 summary:Image denoising is a fundamental operation in image processing and holds considerable practical importance for various real-world applications. Arguably several thousands of papers are dedicated to image denoising. In the past decade, sate-of-the-art denoising algorithm have been clearly dominated by non-local patch-based methods, which explicitly exploit patch self-similarity within image. However, in recent two years, discriminatively trained local approaches have started to outperform previous non-local models and have been attracting increasing attentions due to the additional advantage of computational efficiency. Successful approaches include cascade of shrinkage fields (CSF) and trainable nonlinear reaction diffusion (TNRD). These two methods are built on filter response of linear filters of small size using feed forward architectures. Due to the locality inherent in local approaches, the CSF and TNRD model become less effective when noise level is high and consequently introduces some noise artifacts. In order to overcome this problem, in this paper we introduce a multi-scale strategy. To be specific, we build on our newly-developed TNRD model, adopting the multi-scale pyramid image representation to devise a multi-scale nonlinear diffusion process. As expected, all the parameters in the proposed multi-scale diffusion model, including the filters and the influence functions across scales, are learned from training data through a loss based approach. Numerical results on Gaussian and Poisson denoising substantiate that the exploited multi-scale strategy can successfully boost the performance of the original TNRD model with single scale. As a consequence, the resulting multi-scale diffusion models can significantly suppress the typical incorrect features for those noisy images with heavy noise. version:1
arxiv-1609-06583 | Revealing Structure in Large Graphs: Szemerédi's Regularity Lemma and its Use in Pattern Recognition | http://arxiv.org/abs/1609.06583 | id:1609.06583 author:Marcello Pelillo, Ismail Elezi, Marco Fiorucci category:cs.CV cs.DM  published:2016-09-21 summary:Introduced in the mid-1970's as an intermediate step in proving a long-standing conjecture on arithmetic progressions, Szemer\'edi's regularity lemma has emerged over time as a fundamental tool in different branches of graph theory, combinatorics and theoretical computer science. Roughly, it states that every graph can be approximated by the union of a small number of random-like bipartite graphs called regular pairs. In other words, the result provides us a way to obtain a good description of a large graph using a small amount of data, and can be regarded as a manifestation of the all-pervading dichotomy between structure and randomness. In this paper we will provide an overview of the regularity lemma and its algorithmic aspects, and will discuss its relevance in the context of pattern recognition research. version:1
arxiv-1609-06582 | Privacy-Friendly Mobility Analytics using Aggregate Location Data | http://arxiv.org/abs/1609.06582 | id:1609.06582 author:Apostolos Pyrgelis, Emiliano De Cristofaro, Gordon Ross category:cs.CR cs.CY cs.LG  published:2016-09-21 summary:Location data can be extremely useful to study commuting patterns and disruptions, as well as to predict real-time traffic volumes. At the same time, however, the fine-grained collection of user locations raises serious privacy concerns, as this can reveal sensitive information about the users, such as, life style, political and religious inclinations, or even identities. In this paper, we study the feasibility of crowd-sourced mobility analytics over aggregate location information: users periodically report their location, through using a privacy-preserving aggregation protocol, so that the server can only recover aggregates -- i.e., how many, but not which, users are in a region at a given time. We experiment with real-world mobility datasets obtained from the Transport For London authority and the San Francisco Cabs network, and present a novel methodology based on time series modeling that is geared to forecast traffic volumes in regions of interest and to detect mobility anomalies in them. In the presence of anomalies, we also make enhanced traffic volume predictions by feeding our model with additional information from correlated regions. Finally, we present and evaluate a mobile app prototype, called Mobility Data Donors (MDD), in terms of computation, communication, and energy overhead, demonstrating the real-world deployability of our techniques. version:1
arxiv-1609-06578 | Twitter Opinion Topic Model: Extracting Product Opinions from Tweets by Leveraging Hashtags and Sentiment Lexicon | http://arxiv.org/abs/1609.06578 | id:1609.06578 author:Kar Wai Lim, Wray Buntine category:cs.CL cs.IR cs.LG  published:2016-09-21 summary:Aspect-based opinion mining is widely applied to review data to aggregate or summarize opinions of a product, and the current state-of-the-art is achieved with Latent Dirichlet Allocation (LDA)-based model. Although social media data like tweets are laden with opinions, their "dirty" nature (as natural language) has discouraged researchers from applying LDA-based opinion model for product review mining. Tweets are often informal, unstructured and lacking labeled data such as categories and ratings, making it challenging for product opinion mining. In this paper, we propose an LDA-based opinion model named Twitter Opinion Topic Model (TOTM) for opinion mining and sentiment analysis. TOTM leverages hashtags, mentions, emoticons and strong sentiment words that are present in tweets in its discovery process. It improves opinion prediction by modeling the target-opinion interaction directly, thus discovering target specific opinion words, neglected in existing approaches. Moreover, we propose a new formulation of incorporating sentiment prior information into a topic model, by utilizing an existing public sentiment lexicon. This is novel in that it learns and updates with the data. We conduct experiments on 9 million tweets on electronic products, and demonstrate the improved performance of TOTM in both quantitative evaluations and qualitative analysis. We show that aspect-based opinion analysis on massive volume of tweets provides useful opinions on products. version:1
arxiv-1609-06577 | Semi-supervised knowledge extraction for detection of drugs and their effects | http://arxiv.org/abs/1609.06577 | id:1609.06577 author:Fabio Del Vigna, Marinella Petrocchi, Alessandro Tommasi, Cesare Zavattari, Maurizio Tesconi category:cs.CL  published:2016-09-21 summary:New Psychoactive Substances (NPS) are drugs that lay in a grey area of legislation, since they are not internationally and officially banned, possibly leading to their not prosecutable trade. The exacerbation of the phenomenon is that NPS can be easily sold and bought online. Here, we consider large corpora of textual posts, published on online forums specialized on drug discussions, plus a small set of known substances and associated effects, which we call seeds. We propose a semi-supervised approach to knowledge extraction, applied to the detection of drugs (comprising NPS) and effects from the corpora under investigation. Based on the very small set of initial seeds, the work highlights how a contrastive approach and context deduction are effective in detecting substances and effects from the corpora. Our promising results, which feature a F1 score close to 0.9, pave the way for shortening the detection time of new psychoactive substances, once these are discussed and advertised on the Internet. version:1
arxiv-1609-06575 | Theoretical Evaluation of Feature Selection Methods based on Mutual Information | http://arxiv.org/abs/1609.06575 | id:1609.06575 author:Cláudia Pascoal, M. Rosário Oliveira, António Pacheco, Rui Valadas category:stat.ML cs.LG  published:2016-09-21 summary:Feature selection methods are usually evaluated by wrapping specific classifiers and datasets in the evaluation process, resulting very often in unfair comparisons between methods. In this work, we develop a theoretical framework that allows obtaining the true feature ordering of two-dimensional sequential forward feature selection methods based on mutual information, which is independent of entropy or mutual information estimation methods, classifiers, or datasets, and leads to an undoubtful comparison of the methods. Moreover, the theoretical framework unveils problems intrinsic to some methods that are otherwise difficult to detect, namely inconsistencies in the construction of the objective function used to select the candidate features, due to various types of indeterminations and to the possibility of the entropy of continuous random variables taking null and negative values. version:1
arxiv-1609-06570 | Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning | http://arxiv.org/abs/1609.06570 | id:1609.06570 author:Guillaume Lemaitre, Fernando Nogueira, Christos K. Aridas category:cs.LG  published:2016-09-21 summary:Imbalanced-learn is an open-source python toolbox aiming at providing a wide range of methods to cope with the problem of imbalanced dataset frequently encountered in machine learning and pattern recognition. The implemented state-of-the-art methods can be categorized into 4 groups: (i) under-sampling, (ii) over-sampling, (iii) combination of over- and under-sampling, and (iv) ensemble learning methods. The proposed toolbox only depends on numpy, scipy, and scikit-learn and is distributed under MIT license. Furthermore, it is fully compatible with scikit-learn and is part of the scikit-learn-contrib supported project. Documentation, unit tests as well as integration tests are provided to ease usage and contribution. The toolbox is publicly available in GitHub: https://github.com/scikit-learn-contrib/imbalanced-learn. version:1
arxiv-1609-06536 | Facial Performance Capture with Deep Neural Networks | http://arxiv.org/abs/1609.06536 | id:1609.06536 author:Samuli Laine, Tero Karras, Timo Aila, Antti Herva, Jaakko Lehtinen category:cs.CV cs.GR  published:2016-09-21 summary:We present a deep learning technique for facial performance capture, i.e., the transfer of video footage into a motion sequence of a 3D mesh representing an actor's face. Specifically, we build on a conventional capture pipeline based on computer vision and multi-view video, and use its results to train a deep neural network to produce similar output from a monocular video sequence. Once trained, our network produces high-quality results for unseen inputs with greatly reduced effort compared to the conventional system. In practice, we have found that approximately 10 minutes worth of high-quality data is sufficient for training a network that can then automatically process as much footage from video to 3D as needed. This yields major savings in the development of modern narrative-driven video games involving digital doubles of actors and potentially hours of animated dialogue per character. version:1
arxiv-1609-06533 | On Data-Independent Properties for Density-Based Dissimilarity Measures in Hybrid Clustering | http://arxiv.org/abs/1609.06533 | id:1609.06533 author:Kajsa Møllersen, Subhra S. Dhar, Fred Godtliebsen category:stat.ML cs.LG  published:2016-09-21 summary:Hybrid clustering combines partitional and hierarchical clustering for computational effectiveness and versatility in cluster shape. In such clustering, a dissimilarity measure plays a crucial role in the hierarchical merging. The dissimilarity measure has great impact on the final clustering, and data-independent properties are needed to choose the right dissimilarity measure for the problem at hand. Properties for distance-based dissimilarity measures have been studied for decades, but properties for density-based dissimilarity measures have so far received little attention. Here, we propose six data-independent properties to evaluate density-based dissimilarity measures associated with hybrid clustering, regarding equality, orthogonality, symmetry, outlier and noise observations, and light-tailed models for heavy-tailed clusters. The significance of the properties is investigated, and we study some well-known dissimilarity measures based on Shannon entropy, misclassification rate, Bhattacharyya distance and Kullback-Leibler divergence with respect to the proposed properties. As none of them satisfy all the proposed properties, we introduce a new dissimilarity measure based on the Kullback-Leibler information and show that it satisfies all proposed properties. The effect of the proposed properties is also illustrated on several real and simulated data sets. version:1
arxiv-1609-06532 | Bibliographic Analysis on Research Publications using Authors, Categorical Labels and the Citation Network | http://arxiv.org/abs/1609.06532 | id:1609.06532 author:Kar Wai Lim, Wray Buntine category:cs.DL cs.LG stat.ML  published:2016-09-21 summary:Bibliographic analysis considers the author's research areas, the citation network and the paper content among other things. In this paper, we combine these three in a topic model that produces a bibliographic model of authors, topics and documents, using a nonparametric extension of a combination of the Poisson mixed-topic link model and the author-topic model. This gives rise to the Citation Network Topic Model (CNTM). We propose a novel and efficient inference algorithm for the CNTM to explore subsets of research publications from CiteSeerX. The publication datasets are organised into three corpora, totalling to about 168k publications with about 62k authors. The queried datasets are made available online. In three publicly available corpora in addition to the queried datasets, our proposed model demonstrates an improved performance in both model fitting and document clustering, compared to several baselines. Moreover, our model allows extraction of additional useful knowledge from the corpora, such as the visualisation of the author-topics network. Additionally, we propose a simple method to incorporate supervision into topic modelling to achieve further improvement on the clustering task. version:1
arxiv-1609-06530 | Weakly supervised spoken term discovery using cross-lingual side information | http://arxiv.org/abs/1609.06530 | id:1609.06530 author:Sameer Bansal, Herman Kamper, Sharon Goldwater, Adam Lopez category:cs.CL  published:2016-09-21 summary:Recent work on unsupervised term discovery (UTD) aims to identify and cluster repeated word-like units from audio alone. These systems are promising for some very low-resource languages where transcribed audio is unavailable, or where no written form of the language exists. However, in some cases it may still be feasible (e.g., through crowdsourcing) to obtain (possibly noisy) text translations of the audio. If so, this information could be used as a source of side information to improve UTD. Here, we present a simple method for rescoring the output of a UTD system using text translations, and test it on a corpus of Spanish audio with English translations. We show that it greatly improves the average precision of the results over a wide range of system configurations and data preprocessing methods. version:1
arxiv-1609-06500 | Wavelet-Based Segmentation on the Sphere | http://arxiv.org/abs/1609.06500 | id:1609.06500 author:Xiaohao Cai, Christopher G. R. Wallis, Jennifer Y. H. Chan, Jason D. McEwen category:cs.CV cs.IT math.IT  published:2016-09-21 summary:Segmentation is the process of identifying object outlines within images. There are a number of efficient algorithms for segmentation in Euclidean space that depend on the variational approach and partial differential equation modelling. Wavelets have been used successfully in various problems in image processing, including segmentation, inpainting, noise removal, super-resolution image restoration, and many others. Wavelets on the sphere have been developed to solve such problems for data defined on the sphere, which arise in numerous fields such as cosmology and geophysics. In this work, we propose a wavelet-based method to segment images on the sphere, accounting for the underlying geometry of spherical data. Our method is a direct extension of the tight-frame based segmentation method used to automatically identify tube-like structures such as blood vessels in medical imaging. It is compatible with any arbitrary type of wavelet frame defined on the sphere, such as axisymmetric wavelets, directional wavelets, curvelets, and hybrid wavelet constructions. Such an approach allows the desirable properties of wavelets to be naturally inherited in the segmentation process. In particular, directional wavelets and curvelets, which were designed to efficiently capture directional signal content, provide additional advantages in segmenting images containing prominent directional and curvilinear features. We present several numerical experiments, applying our wavelet-based segmentation method, as well as the common K-means method, on real-world spherical images. These experiments demonstrate the superiority of our method and show that it is capable of segmenting different kinds of spherical images, including those with prominent directional features. Moreover, our algorithm is efficient with convergence usually within a few iterations. version:1
arxiv-1609-06492 | Document Image Coding and Clustering for Script Discrimination | http://arxiv.org/abs/1609.06492 | id:1609.06492 author:Darko Brodic, Alessia Amelio, Zoran N. Milivojevic, Milena Jevtic category:cs.CV cs.AI cs.CL cs.LG cs.NE  published:2016-09-21 summary:The paper introduces a new method for discrimination of documents given in different scripts. The document is mapped into a uniformly coded text of numerical values. It is derived from the position of the letters in the text line, based on their typographical characteristics. Each code is considered as a gray level. Accordingly, the coded text determines a 1-D image, on which texture analysis by run-length statistics and local binary pattern is performed. It defines feature vectors representing the script content of the document. A modified clustering approach employed on document feature vector groups documents written in the same script. Experimentation performed on two custom oriented databases of historical documents in old Cyrillic, angular and round Glagolitic as well as Antiqua and Fraktur scripts demonstrates the superiority of the proposed method with respect to well-known methods in the state-of-the-art. version:1
arxiv-1609-06490 | One Sentence One Model for Neural Machine Translation | http://arxiv.org/abs/1609.06490 | id:1609.06490 author:Xiaoqing Li, Jiajun Zhang, Chengqing Zong category:cs.CL  published:2016-09-21 summary:Neural machine translation (NMT) becomes a new state-of-the-art and achieves promising translation results using a simple encoder-decoder neural network. This neural network is trained once on the parallel corpus and the fixed network is used to translate all the test sentences. We argue that the general fixed network cannot best fit the specific test sentences. In this paper, we propose the dynamic NMT which learns a general network as usual, and then fine-tunes the network for each test sentence. The fine-tune work is done on a small set of the bilingual training data that is obtained through similarity search according to the test sentence. Extensive experiments demonstrate that this method can significantly improve the translation performance, especially when highly similar sentences are available. version:1
arxiv-1609-06480 | Network-regularized Sparse Logistic Regression Models for Clinical Risk Prediction and Biomarker Discovery | http://arxiv.org/abs/1609.06480 | id:1609.06480 author:Wenwen Min, Juan Liu, Shihua Zhang category:q-bio.GN cs.LG stat.ML  published:2016-09-21 summary:Molecular profiling data (e.g., gene expression) has been used for clinical risk prediction and biomarker discovery. However, it is necessary to integrate other prior knowledge like biological pathways or gene interaction networks to improve the predictive ability and biological interpretability of biomarkers. Here, we first introduce a general regularized Logistic Regression (LR) framework with regularized term $\lambda \ \bm{w}\ _1 + \eta\bm{w}^T\bm{M}\bm{w}$, which can reduce to different penalties, including Lasso, elastic net, and network-regularized terms with different $\bm{M}$. This framework can be easily solved in a unified manner by a cyclic coordinate descent algorithm which can avoid inverse matrix operation and accelerate the computing speed. However, if those estimated $\bm{w}_i$ and $\bm{w}_j$ have opposite signs, then the traditional network-regularized penalty may not perform well. To address it, we introduce a novel network-regularized sparse LR model with a new penalty $\lambda \ \bm{w}\ _1 + \eta \bm{w} ^T\bm{M} \bm{w} $ to consider the difference between the absolute values of the coefficients. And we develop two efficient algorithms to solve it. Finally, we test our methods and compare them with the related ones using simulated and real data to show their efficiency. version:1
arxiv-1609-06957 | Early Warning System for Seismic Events in Coal Mines Using Machine Learning | http://arxiv.org/abs/1609.06957 | id:1609.06957 author:Robert Bogucki, Jan Lasek, Jan Kanty Milczek, Michal Tadeusiak category:cs.LG stat.ML  published:2016-09-21 summary:This document describes an approach to the problem of predicting dangerous seismic events in active coal mines up to 8 hours in advance. It was developed as a part of the AAIA'16 Data Mining Challenge: Predicting Dangerous Seismic Events in Active Coal Mines. The solutions presented consist of ensembles of various predictive models trained on different sets of features. The best one achieved a winning score of 0.939 AUC. version:1
arxiv-1609-06954 | Semiring Programming: A Framework for Search, Inference and Learning | http://arxiv.org/abs/1609.06954 | id:1609.06954 author:Vaishak Belle, Luc De Raedt category:cs.AI cs.LG cs.LO  published:2016-09-21 summary:To solve hard problems, AI relies on a variety of disciplines such as logic, probabilistic reasoning, machine learning and mathematical programming. Although it is widely accepted that solving real-world problems requires an integration amongst these, contemporary representation methodologies offer little support for this. In an attempt to alleviate this situation, we introduce a new declarative programming framework that provides abstractions of well-known problems such as SAT, Bayesian inference, generative models, and convex optimization. The semantics of programs is defined in terms of first-order structures with semiring labels, which allows us to freely combine and integrate problems from different AI disciplines. version:1
arxiv-1609-06457 | AMOS: An Automated Model Order Selection Algorithm for Spectral Graph Clustering | http://arxiv.org/abs/1609.06457 | id:1609.06457 author:Pin-Yu Chen, Thibaut Gensollen, Alfred O. Hero III category:cs.SI cs.LG stat.ML  published:2016-09-21 summary:One of the longstanding problems in spectral graph clustering (SGC) is the so-called model order selection problem: automated selection of the correct number of clusters. This is equivalent to the problem of finding the number of connected components or communities in an undirected graph. In this paper, we propose AMOS, an automated model order selection algorithm for SGC. Based on a recent analysis of clustering reliability for SGC under the random interconnection model, AMOS works by incrementally increasing the number of clusters, estimating the quality of identified clusters, and providing a series of clustering reliability tests. Consequently, AMOS outputs clusters of minimal model order with statistical clustering reliability guarantees. Comparing to three other automated graph clustering methods on real-world datasets, AMOS shows superior performance in terms of multiple external and internal clustering metrics. version:1
arxiv-1609-06456 | Multi-View Constraint Propagation with Consensus Prior Knowledge | http://arxiv.org/abs/1609.06456 | id:1609.06456 author:Yaoyi Li, Hongtao Lu category:cs.CV  published:2016-09-21 summary:In many applications, the pairwise constraint is a kind of weaker supervisory information which can be collected easily. The constraint propagation has been proved to be a success of exploiting such side-information. In recent years, some methods of multi-view constraint propagation have been proposed. However, the problem of reasonably fusing different views remains unaddressed. In this paper, we present a method dubbed Consensus Prior Constraint Propagation (CPCP), which can provide the prior knowledge of the robustness of each data instance and its neighborhood. With the robustness generated from the consensus information of each view, we build a unified affinity matrix as a result of the propagation. Specifically, we fuse the affinity of different views at a data instance level instead of a view level. This paper also introduces an approach to deal with the imbalance between the positive and negative constraints. The proposed method has been tested in clustering tasks on two publicly available multi-view data sets to show the superior performance. version:1
arxiv-1609-06441 | Detecting facial landmarks in the video based on a hybrid framework | http://arxiv.org/abs/1609.06441 | id:1609.06441 author:Nian Cai, Zhineng Lin, Fu Zhang, Guandong Cen, Han Wang category:cs.CV  published:2016-09-21 summary:To dynamically detect the facial landmarks in the video, we propose a novel hybrid framework termed as detection-tracking-detection (DTD). First, the face bounding box is achieved from the first frame of the video sequence based on a traditional face detection method. Then, a landmark detector detects the facial landmarks, which is based on a cascaded deep convolution neural network (DCNN). Next, the face bounding box in the current frame is estimated and validated after the facial landmarks in the previous frame are tracked based on the median flow. Finally, the facial landmarks in the current frame are exactly detected from the validated face bounding box via the landmark detector. Experimental results indicate that the proposed framework can detect the facial landmarks in the video sequence more effectively and with lower consuming time compared to the frame-by-frame method via the DCNN. version:1
arxiv-1609-06438 | Large-Scale Strategic Games and Adversarial Machine Learning | http://arxiv.org/abs/1609.06438 | id:1609.06438 author:Tansu Alpcan, Benjamin I. P. Rubinstein, Christopher Leckie category:cs.GT cs.LG  published:2016-09-21 summary:Decision making in modern large-scale and complex systems such as communication networks, smart electricity grids, and cyber-physical systems motivate novel game-theoretic approaches. This paper investigates big strategic (non-cooperative) games where a finite number of individual players each have a large number of continuous decision variables and input data points. Such high-dimensional decision spaces and big data sets lead to computational challenges, relating to efforts in non-linear optimization scaling up to large systems of variables. In addition to these computational challenges, real-world players often have limited information about their preference parameters due to the prohibitive cost of identifying them or due to operating in dynamic online settings. The challenge of limited information is exacerbated in high dimensions and big data sets. Motivated by both computational and information limitations that constrain the direct solution of big strategic games, our investigation centers around reductions using linear transformations such as random projection methods and their effect on Nash equilibrium solutions. Specific analytical results are presented for quadratic games and approximations. In addition, an adversarial learning game is presented where random projection and sampling schemes are investigated. version:1
arxiv-1609-06434 | Partial Least Squares Regression on Riemannian Manifolds and Its Application in Classifications | http://arxiv.org/abs/1609.06434 | id:1609.06434 author:Haoran Chen, Yanfeng Sun, Junbin Gao, Yongli Hu, Baocai Yin category:cs.CV  published:2016-09-21 summary:Partial least squares regression (PLSR) has been a popular technique to explore the linear relationship between two datasets. However, most of algorithm implementations of PLSR may only achieve a suboptimal solution through an optimization on the Euclidean space. In this paper, we propose several novel PLSR models on Riemannian manifolds and develop optimization algorithms based on Riemannian geometry of manifolds. This algorithm can calculate all the factors of PLSR globally to avoid suboptimal solutions. In a number of experiments, we have demonstrated the benefits of applying the proposed model and algorithm to a variety of learning tasks in pattern recognition and object classification. version:1
arxiv-1609-06404 | KU-ISPL Language Recognition System for NIST 2015 i-Vector Machine Learning Challenge | http://arxiv.org/abs/1609.06404 | id:1609.06404 author:Suwon Shon, Seongkyu Mun, John H. L. Hansen, Hanseok Ko category:cs.SD cs.CL  published:2016-09-21 summary:In language recognition, the task of rejecting/differentiating closely spaced versus acoustically far spaced languages remains a major challenge. For confusable closely spaced languages, the system needs longer input test duration material to obtain sufficient information to distinguish between languages. Alternatively, if languages are distinct and not acoustically/linguistically similar to others, duration is not a sufficient remedy. The solution proposed here is to explore duration distribution analysis for near/far languages based on the Language Recognition i-Vector Machine Learning Challenge 2015 (LRiMLC15) database. Using this knowledge, we propose a likelihood ratio based fusion approach that leveraged both score and duration information. The experimental results show that the use of duration and score fusion improves language recognition performance by 5% relative in LRiMLC15 cost. version:1
arxiv-1609-06390 | Learning HMMs with Nonparametric Emissions via Spectral Decompositions of Continuous Matrices | http://arxiv.org/abs/1609.06390 | id:1609.06390 author:Kirthevasan Kandasamy, Maruan Al-Shedivat, Eric P. Xing category:stat.ML cs.LG  published:2016-09-21 summary:Recently, there has been a surge of interest in using spectral methods for estimating latent variable models. However, it is usually assumed that the distribution of the observations conditioned on the latent variables is either discrete or belongs to a parametric family. In this paper, we study the estimation of an $m$-state hidden Markov model (HMM) with only smoothness assumptions, such as H\"olderian conditions, on the emission densities. By leveraging some recent advances in continuous linear algebra and numerical analysis, we develop a computationally efficient spectral algorithm for learning nonparametric HMMs. Our technique is based on computing an SVD on nonparametric estimates of density functions by viewing them as \emph{continuous matrices}. We derive sample complexity bounds via concentration results for nonparametric density estimation and novel perturbation theory results for continuous matrices. We implement our method using Chebyshev polynomial approximations. Our method is competitive with other baselines on synthetic and real problems and is also very computationally efficient. version:1
arxiv-1609-06385 | Multiclass Classification Calibration Functions | http://arxiv.org/abs/1609.06385 | id:1609.06385 author:Bernardo Ávila Pires, Csaba Szepesvári category:stat.ML cs.LG  published:2016-09-20 summary:In this paper we refine the process of computing calibration functions for a number of multiclass classification surrogate losses. Calibration functions are a powerful tool for easily converting bounds for the surrogate risk (which can be computed through well-known methods) into bounds for the true risk, the probability of making a mistake. They are particularly suitable in non-parametric settings, where the approximation error can be controlled, and provide tighter bounds than the common technique of upper-bounding the 0-1 loss by the surrogate loss. The abstract nature of the more sophisticated existing calibration function results requires calibration functions to be explicitly derived on a case-by-case basis, requiring repeated efforts whenever bounds for a new surrogate loss are required. We devise a streamlined analysis that simplifies the process of deriving calibration functions for a large number of surrogate losses that have been proposed in the literature. The effort of deriving calibration functions is then surmised in verifying, for a chosen surrogate loss, a small number of conditions that we introduce. As case studies, we recover existing calibration functions for the well-known loss of Lee et al. (2004), and also provide novel calibration functions for well-known losses, including the one-versus-all loss and the logistic regression loss, plus a number of other losses that have been shown to be classification-calibrated in the past, but for which no calibration function had been derived. version:1
arxiv-1609-06380 | Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention | http://arxiv.org/abs/1609.06380 | id:1609.06380 author:Yang Liu, Sujian Li category:cs.CL cs.AI  published:2016-09-20 summary:Recognizing implicit discourse relations is a challenging but important task in the field of Natural Language Processing. For such a complex text processing task, different from previous studies, we argue that it is necessary to repeatedly read the arguments and dynamically exploit the efficient features useful for recognizing discourse relations. To mimic the repeated reading strategy, we propose the neural networks with multi-level attention (NNMA), combining the attention mechanism and external memories to gradually fix the attention on some specific words helpful to judging the discourse relations. Experiments on the PDTB dataset show that our proposed method achieves the state-of-art results. The visualization of the attention weights also illustrates the progress that our model observes the arguments on each level and progressively locates the important words. version:1
arxiv-1609-06377 | Geometry-Based Next Frame Prediction from Monocular Video | http://arxiv.org/abs/1609.06377 | id:1609.06377 author:Reza Mahjourian, Martin Wicke, Anelia Angelova category:cs.LG cs.CV 68Txx I.2.10; I.4.8  published:2016-09-20 summary:We propose a method for next frame prediction from video input. A convolutional recurrent neural network is trained to predict depth from monocular video input, which, along with the current video image and the camera trajectory, can then be used to compute the next frame. Unlike prior next-frame prediction approaches, we take advantage of the scene geometry and use the predicted depth for generating next frame prediction. A useful side effect of our technique is that it produces depth from video, which can be used in other applications. We evaluate the proposed approach on the KITTI raw dataset, which is collected from a vehicle moving through urban environments. The results are compared with the state-of-the-art models for next frame prediction. We show that our method produces visually and numerically superior results to existing methods that directly predict the next frame. version:1
arxiv-1609-06354 | Recognizing Detailed Human Context In-the-Wild from Smartphones and Smartwatches | http://arxiv.org/abs/1609.06354 | id:1609.06354 author:Yonatan Vaizman, Katherine Ellie, Gert Lanckriet category:cs.AI cs.CY cs.HC cs.LG  published:2016-09-20 summary:We demonstrate that a person's behavioral and environmental context can be automatically recognized by harnessing the sensors built into smartphones and smartwatches. We propose a generic system that can simultaneously recognize many contextual attributes from diverse behavioral domains. By fusing complementary information from different types of sensors our system successfully recognizes fine details of work and leisure activities, body movement, transportation, and more. Health monitoring, clinical intervention, aging care, personal assistance and many more applications will benefit from automatic, frequent and detailed context recognition. version:1
arxiv-1609-06341 | Markov Random Field Model-Based Salt and Pepper Noise Removal | http://arxiv.org/abs/1609.06341 | id:1609.06341 author:Ahmadreza Baghaie category:cs.CV  published:2016-09-20 summary:Problem of impulse noise reduction is a very well studied problem in image processing community and many different approaches have been proposed to tackle this problem. In the current work, the problem of fixed value impulse noise (salt and pepper) removal from images is investigated by use of a Markov Random Field (MRF) models with smoothness priors. After the formulation of the problem as an inpainting problem, graph cuts with $\alpha$-expansion moves are considered for minimization of the energy functional. As for comparisons, several other minimization techniques that are widely used for MRF models' optimization are considered and the results are compared using Peak-Signal-to-Noise-Ratio (PSNR) and Structural Similarity Index (SSIM) as metrics. The investigations show the superiority of graph cuts with $\alpha$-expansion moves over the other techniques both in terms of PSNR and also computational times. version:1
arxiv-1609-06335 | Unsupervised learning of transcriptional regulatory networks via latent tree graphical models | http://arxiv.org/abs/1609.06335 | id:1609.06335 author:Anthony Gitter, Furong Huang, Ragupathyraj Valluvan, Ernest Fraenkel, Animashree Anandkumar category:q-bio.MN cs.LG  published:2016-09-20 summary:Gene expression is a readily-observed quantification of transcriptional activity and cellular state that enables the recovery of the relationships between regulators and their target genes. Reconstructing transcriptional regulatory networks from gene expression data is a problem that has attracted much attention, but previous work often makes the simplifying (but unrealistic) assumption that regulator activity is represented by mRNA levels. We use a latent tree graphical model to analyze gene expression without relying on transcription factor expression as a proxy for regulator activity. The latent tree model is a type of Markov random field that includes both observed gene variables and latent (hidden) variables, which factorize on a Markov tree. Through efficient unsupervised learning approaches, we determine which groups of genes are co-regulated by hidden regulators and the activity levels of those regulators. Post-processing annotates many of these discovered latent variables as specific transcription factors or groups of transcription factors. Other latent variables do not necessarily represent physical regulators but instead reveal hidden structure in the gene expression such as shared biological function. We apply the latent tree graphical model to a yeast stress response dataset. In addition to novel predictions, such as condition-specific binding of the transcription factor Msn4, our model recovers many known aspects of the yeast regulatory network. These include groups of co-regulated genes, condition-specific regulator activity, and combinatorial regulation among transcription factors. The latent tree graphical model is a general approach for analyzing gene expression data that requires no prior knowledge of which possible regulators exist, regulator activity, or where transcription factors physically bind. version:1
arxiv-1609-06268 | Semantic Similarity Strategies for Job Title Classification | http://arxiv.org/abs/1609.06268 | id:1609.06268 author:Yun Zhu, Faizan Javed, Ozgur Ozturk category:cs.AI cs.CL  published:2016-09-20 summary:Automatic and accurate classification of items enables numerous downstream applications in many domains. These applications can range from faceted browsing of items to product recommendations and big data analytics. In the online recruitment domain, we refer to classifying job ads to pre-defined or custom occupation categories as job title classification. A large-scale job title classification system can power various downstream applications such as semantic search, job recommendations and labor market analytics. In this paper, we discuss experiments conducted to improve our in-house job title classification system. The classification component of the system is composed of a two-stage coarse and fine level classifier cascade that classifies input text such as job title and/or job ads to one of the thousands of job titles in our taxonomy. To improve classification accuracy and effectiveness, we experiment with various semantic representation strategies such as average W2V vectors and document similarity measures such as Word Movers Distance (WMD). Our initial results show an overall improvement in accuracy of Carotene[1]. version:1
arxiv-1609-06260 | GAdaBoost: Accelerating Adaboost Feature Selection with Genetic Algorithms | http://arxiv.org/abs/1609.06260 | id:1609.06260 author:Mai Tolba, Mohamed Moustafa category:cs.CV  published:2016-09-20 summary:Boosted cascade of simple features, by Viola and Jones, is one of the most famous object detection frameworks. However, it suffers from a lengthy training process. This is due to the vast features space and the exhaustive search nature of Adaboost. In this paper we propose GAdaboost: a Genetic Algorithm to accelerate the training procedure through natural feature selection. Specifically, we propose to limit Adaboost search within a subset of the huge feature space, while evolving this subset following a Genetic Algorithm. Experiments demonstrate that our proposed GAdaboost is up to 3.7 times faster than Adaboost. We also demonstrate that the price of this speedup is a mere decrease (3%, 4%) in detection accuracy when tested on FDDB benchmark face detection set, and Caltech Web Faces respectively. version:1
arxiv-1609-06239 | Generating Politically-Relevant Event Data | http://arxiv.org/abs/1609.06239 | id:1609.06239 author:John Beieler category:cs.CL  published:2016-09-20 summary:Automatically generated political event data is an important part of the social science data ecosystem. The approaches for generating this data, though, have remained largely the same for two decades. During this time, the field of computational linguistics has progressed tremendously. This paper presents an overview of political event data, including methods and ontologies, and a set of experiments to determine the applicability of deep neural networks to the extraction of political events from news text. version:1
arxiv-1609-06204 | Italy goes to Stanford: a collection of CoreNLP modules for Italian | http://arxiv.org/abs/1609.06204 | id:1609.06204 author:Alessio Palmero Aprosio, Giovanni Moretti category:cs.CL  published:2016-09-20 summary:In this we paper present Tint, an easy-to-use set of fast, accurate and extendable Natural Language Processing modules for Italian. It is based on Stanford CoreNLP and is freely available as a standalone software or a library that can be integrated in an existing project. version:1
arxiv-1609-06192 | Hands-Free Segmentation of Medical Volumes via Binary Inputs | http://arxiv.org/abs/1609.06192 | id:1609.06192 author:Florian Dubost, Loic Peter, Christian Rupprecht, Benjamin Gutierrez-Becker, Nassir Navab category:cs.CV  published:2016-09-20 summary:We propose a novel hands-free method to interactively segment 3D medical volumes. In our scenario, a human user progressively segments an organ by answering a series of questions of the form "Is this voxel inside the object to segment?". At each iteration, the chosen question is defined as the one halving a set of candidate segmentations given the answered questions. For a quick and efficient exploration, these segmentations are sampled according to the Metropolis-Hastings algorithm. Our sampling technique relies on a combination of relaxed shape prior, learnt probability map and consistency with previous answers. We demonstrate the potential of our strategy on a prostate segmentation MRI dataset. Through the study of failure cases with synthetic examples, we demonstrate the adaptation potential of our method. We also show that our method outperforms two intuitive baselines: one based on random questions, the other one being the thresholded probability map. version:1
arxiv-1609-06188 | Transfer Learning for Material Classification using Convolutional Networks | http://arxiv.org/abs/1609.06188 | id:1609.06188 author:Patrick Wieschollek, Hendrik P. A. Lensch category:cs.CV  published:2016-09-20 summary:Material classification in natural settings is a challenge due to complex interplay of geometry, reflectance properties, and illumination. Previous work on material classification relies strongly on hand-engineered features of visual samples. In this work we use a Convolutional Neural Network (convnet) that learns descriptive features for the specific task of material recognition. Specifically, transfer learning from the task of object recognition is exploited to more effectively train good features for material classification. The approach of transfer learning using convnets yields significantly higher recognition rates when compared to previous state-of-the-art approaches. We then analyze the relative contribution of reflectance and shading information by a decomposition of the image into its intrinsic components. The use of convnets for material classification was hindered by the strong demand for sufficient and diverse training data, even with transfer learning approaches. Therefore, we present a new data set containing approximately 10k images divided into 10 material categories. version:1
arxiv-1609-05834 | On Support Relations and Semantic Scene Graphs | http://arxiv.org/abs/1609.05834 | id:1609.05834 author:Wentong Liao, Michael Ying Yang, Hanno Ackermann, Bodo Rosenhahn category:cs.CV cs.RO  published:2016-09-19 summary:Rapid development of robots and autonomous vehicles requires semantic information about the surrounding scene to decide upon the correct action or to be able to complete particular tasks. Scene understanding provides the necessary semantic interpretation by semantic scene graphs. For this task, so-called support relationships which describe the contextual relations between parts of the scene such as floor, wall, table, etc, need be known. This paper presents a novel approach to infer such relations and then to construct the scene graph. Support relations are estimated by considering important, previously ignored information: the physical stability and the prior support knowledge between object classes. In contrast to previous methods for extracting support relations, the proposed approach generates more accurate results, and does not require a pixel-wise semantic labeling of the scene. The semantic scene graph which describes all the contextual relations within the scene is constructed using this information. To evaluate the accuracy of these graphs, multiple different measures are formulated. The proposed algorithms are evaluated using the NYUv2 database. The results demonstrate that the inferred support relations are more precise than state-of-the-art. The scene graphs are compared against ground truth graphs. version:2
arxiv-1609-06141 | Discriminative Scale Space Tracking | http://arxiv.org/abs/1609.06141 | id:1609.06141 author:Martin Danelljan, Gustav Häger, Fahad Shahbaz Khan, Michael Felsberg category:cs.CV  published:2016-09-20 summary:Accurate scale estimation of a target is a challenging research problem in visual object tracking. Most state-of-the-art methods employ an exhaustive scale search to estimate the target size. The exhaustive search strategy is computationally expensive and struggles when encountered with large scale variations. This paper investigates the problem of accurate and robust scale estimation in a tracking-by-detection framework. We propose a novel scale adaptive tracking approach by learning separate discriminative correlation filters for translation and scale estimation. The explicit scale filter is learned online using the target appearance sampled at a set of different scales. Contrary to standard approaches, our method directly learns the appearance change induced by variations in the target scale. Additionally, we investigate strategies to reduce the computational cost of our approach. Extensive experiments are performed on the OTB and the VOT2014 datasets. Compared to the standard exhaustive scale search, our approach achieves a gain of 2.5% in average overlap precision on the OTB dataset. Additionally, our method is computationally efficient, operating at a 50% higher frame rate compared to the exhaustive scale search. Our method obtains the top rank in performance by outperforming 19 state-of-the-art trackers on OTB and 37 state-of-the-art trackers on VOT2014. version:1
arxiv-1609-06127 | A framework for mining process models from emails logs | http://arxiv.org/abs/1609.06127 | id:1609.06127 author:Diana Jlailaty, Daniela Grigori, Khalid Belhajjame category:cs.CL cs.LG  published:2016-09-20 summary:Due to its wide use in personal, but most importantly, professional contexts, email represents a valuable source of information that can be harvested for understanding, reengineering and repurposing undocumented business processes of companies and institutions. Towards this aim, a few researchers investigated the problem of extracting process oriented information from email logs in order to take benefit of the many available process mining techniques and tools. In this paper we go further in this direction, by proposing a new method for mining process models from email logs that leverage unsupervised machine learning techniques with little human involvement. Moreover, our method allows to semi-automatically label emails with activity names, that can be used for activity recognition in new incoming emails. A use case demonstrates the usefulness of the proposed solution using a modest in size, yet real-world, dataset containing emails that belong to two different process models. version:1
arxiv-1609-07480 | Predictive modelling of football injuries | http://arxiv.org/abs/1609.07480 | id:1609.07480 author:Stylianos Kampakis category:stat.AP cs.AI stat.ML  published:2016-09-20 summary:The goal of this thesis is to investigate the potential of predictive modelling for football injuries. This work was conducted in close collaboration with Tottenham Hotspurs FC (THFC), the PGA European tour and the participation of Wolverhampton Wanderers (WW). Three investigations were conducted: 1. Predicting the recovery time of football injuries using the UEFA injury recordings: The UEFA recordings is a common standard for recording injuries in professional football. For this investigation, three datasets of UEFA injury recordings were available. Different machine learning algorithms were used in order to build a predictive model. The performance of the machine learning models is then improved by using feature selection conducted through correlation-based subset feature selection and random forests. 2. Predicting injuries in professional football using exposure records: The relationship between exposure (in training hours and match hours) in professional football athletes and injury incidence was studied. A common problem in football is understanding how the training schedule of an athlete can affect the chance of him getting injured. The task was to predict the number of days a player can train before he gets injured. 3. Predicting intrinsic injury incidence using in-training GPS measurements: A significant percentage of football injuries can be attributed to overtraining and fatigue. GPS data collected during training sessions might provide indicators of fatigue, or might be used to detect very intense training sessions which can lead to overtraining. This research used GPS data gathered during training sessions of the first team of THFC, in order to predict whether an injury would take place during a week. version:1
arxiv-1609-05294 | Sparse Boltzmann Machines with Structure Learning as Applied to Text Analysis | http://arxiv.org/abs/1609.05294 | id:1609.05294 author:Zhourong Chen, Nevin L. Zhang, Dit-Yan Yeung, Peixian Chen category:cs.LG  published:2016-09-17 summary:We are interested in exploring the possibility and benefits of structure learning for deep models. As the first step, this paper investigates the matter for Restricted Boltzmann Machines (RBMs). We conduct the study with Replicated Softmax, a variant of RBMs for unsupervised text analysis. We present a method for learning what we call Sparse Boltzmann Machines, where each hidden unit is connected to a subset of the visible units instead of all of them. Empirical results show that the method yields models with significantly improved model fit and interpretability as compared with RBMs where each hidden unit is connected to all visible units. version:2
arxiv-1609-06119 | FastBDT: A speed-optimized and cache-friendly implementation of stochastic gradient-boosted decision trees for multivariate classification | http://arxiv.org/abs/1609.06119 | id:1609.06119 author:Thomas Keck category:cs.LG  published:2016-09-20 summary:Stochastic gradient-boosted decision trees are widely employed for multivariate classification and regression tasks. This paper presents a speed-optimized and cache-friendly implementation for multivariate classification called FastBDT. FastBDT is one order of magnitude faster during the fitting-phase and application-phase, in comparison with popular implementations in software frameworks like TMVA, scikit-learn and XGBoost. The concepts used to optimize the execution time and performance studies are discussed in detail in this paper. The key ideas include: An equal-frequency binning on the input data, which allows replacing expensive floating-point with integer operations, while at the same time increasing the quality of the classification; a cache-friendly linear access pattern to the input data, in contrast to usual implementations, which exhibit a random access pattern. FastBDT provides interfaces to C/C++, Python and TMVA. It is extensively used in the field of high energy physics by the Belle II experiment. version:1
arxiv-1609-06118 | Adaptive Decontamination of the Training Set: A Unified Formulation for Discriminative Visual Tracking | http://arxiv.org/abs/1609.06118 | id:1609.06118 author:Martin Danelljan, Gustav Häger, Fahad Shahbaz Khan, Michael Felsberg category:cs.CV  published:2016-09-20 summary:Tracking-by-detection methods have demonstrated competitive performance in recent years. In these approaches, the tracking model heavily relies on the quality of the training set. Due to the limited amount of labeled training data, additional samples need to be extracted and labeled by the tracker itself. This often leads to the inclusion of corrupted training samples, due to occlusions, misalignments and other perturbations. Existing tracking-by-detection methods either ignore this problem, or employ a separate component for managing the training set. We propose a novel generic approach for alleviating the problem of corrupted training samples in tracking-by-detection frameworks. Our approach dynamically manages the training set by estimating the quality of the samples. Contrary to existing approaches, we propose a unified formulation by minimizing a single loss over both the target appearance model and the sample quality weights. The joint formulation enables corrupted samples to be down-weighted while increasing the impact of correct ones. Experiments are performed on three benchmarks: OTB-2015 with 100 videos, VOT-2015 with 60 videos, and Temple-Color with 128 videos. On the OTB-2015, our unified formulation significantly improves the baseline, with a gain of 3.8% in mean overlap precision. Finally, our method achieves state-of-the-art results on all three datasets. Code and supplementary material are available at http://www.cvl.isy.liu.se/research/objrec/visualtracking/decontrack/index.html . version:1
arxiv-1609-06100 | Distributed Adaptive Learning of Graph Signals | http://arxiv.org/abs/1609.06100 | id:1609.06100 author:P. Di Lorenzo, P. Banelli, S. Barbarossa, S. Sardellitti category:cs.LG stat.ML  published:2016-09-20 summary:The aim of this paper is to propose distributed strategies for adaptive learning of signals defined over graphs. Assuming the graph signal to be band-limited, the method enables distributed reconstruction, with guaranteed performance in terms of mean-square error, and tracking from a limited number of sampled observations taken from a subset of vertices. A detailed mean square analysis is carried out and illustrates the role played by the sampling strategy on the performance of the proposed method. Finally, some useful strategies for distributed selection of the sampling set are provided. Several numerical results validate our theoretical findings, and illustrate the performance of the proposed method for distributed adaptive learning of signals defined over graphs. version:1
arxiv-1609-06086 | Modelling Stock-market Investors as Reinforcement Learning Agents [Correction] | http://arxiv.org/abs/1609.06086 | id:1609.06086 author:Alvin Pastore, Umberto Esposito, Eleni Vasilaki category:cs.CE cs.LG  published:2016-09-20 summary:Decision making in uncertain and risky environments is a prominent area of research. Standard economic theories fail to fully explain human behaviour, while a potentially promising alternative may lie in the direction of Reinforcement Learning (RL) theory. We analyse data for 46 players extracted from a financial market online game and test whether Reinforcement Learning (Q-Learning) could capture these players behaviour using a risk measure based on financial modeling. Moreover we test an earlier hypothesis that players are "na\"ive" (short-sighted). Our results indicate that a simple Reinforcement Learning model which considers only the selling component of the task captures the decision-making process for a subset of players but this is not sufficient to draw any conclusion on the population. We also find that there is not a significant improvement of fitting of the players when using a full RL model against a myopic version, where only immediate reward is valued by the players. This indicates that players, if using a Reinforcement Learning approach, do so na\"ively version:1
arxiv-1609-06082 | Learning Robust Representations of Text | http://arxiv.org/abs/1609.06082 | id:1609.06082 author:Yitong Li, Trevor Cohn, Timothy Baldwin category:cs.CL  published:2016-09-20 summary:Deep neural networks have achieved remarkable results across many language processing tasks, however these methods are highly sensitive to noise and adversarial attacks. We present a regularization based method for limiting network sensitivity to its inputs, inspired by ideas from computer vision, thus learning models that are more robust. Empirical evaluation over a range of sentiment datasets with a convolutional neural network shows that, compared to a baseline model and the dropout method, our method achieves superior performance over noisy inputs and out-of-domain data. version:1
arxiv-1609-06076 | Robust Fusion of Multi-Band Images with Different Spatial and Spectral Resolutions for Change Detection | http://arxiv.org/abs/1609.06076 | id:1609.06076 author:Vinicius Ferraris, Nicolas Dobigeon, Qi Wei, Marie Chabert category:cs.CV physics.data-an stat.ME  published:2016-09-20 summary:Archetypal scenarios for change detection generally consider two images acquired through sensors of the same modality. However, in some specific cases such as emergency situations, the only images available may be those acquired through different kinds of sensors. More precisely, this paper addresses the problem of detecting changes between two multi-band optical images characterized by different spatial and spectral resolutions. This sensor dissimilarity introduces additional issues in the context of operational change detection. To alleviate these issues, classical change detection methods are applied after independent preprocessing steps (e.g., resampling) used to get the same spatial and spectral resolutions for the pair of observed images. Nevertheless, these preprocessing steps tend to throw away relevant information. Conversely, in this paper, we propose a method that more effectively uses the available information by modeling the two observed images as spatial and spectral versions of two (unobserved) latent images characterized by the same high spatial and high spectral resolutions. As they cover the same scene, these latent images are expected to be globally similar except for possible changes in sparse spatial locations. Thus, the change detection task is envisioned through a robust multi-band image fusion method which enforces the differences between the estimated latent images to be spatially sparse. This robust fusion problem is formulated as an inverse problem which is iteratively solved using an efficient block-coordinate descent algorithm. The proposed method is applied to real panchormatic/multispectral and hyperspectral images with simulated realistic changes. A comparison with state-of-the-art change detection methods evidences the accuracy of the proposed strategy. version:1
arxiv-1609-06074 | Detecting Changes Between Optical Images of Different Spatial and Spectral Resolutions: a Fusion-Based Approach | http://arxiv.org/abs/1609.06074 | id:1609.06074 author:Vinicius Ferraris, Nicolas Dobigeon, Qi Wei, Marie Chabert category:cs.CV physics.data-an  published:2016-09-20 summary:Change detection is one of the most challenging issues when analyzing remotely sensed images. Comparing several multi-date images acquired through the same kind of sensor is the most common scenario. Conversely, designing robust, flexible and scalable algorithms for change detection becomes even more challenging when the images have been acquired by two different kinds of sensors. This situation arises in case of emergency under critical constraints. This paper presents, to the best of authors' knowledge, the first strategy to deal with optical images characterized by dissimilar spatial and spectral resolutions. Typical considered scenarios include change detection between panchromatic or multispectral and hyperspectral images. The proposed strategy consists of a 3-step procedure: i) inferring a high spatial and spectral resolution image by fusion of the two observed images characterized one by a low spatial resolution and the other by a low spectral resolution, ii) predicting two images with respectively the same spatial and spectral resolutions as the observed images by degradation of the fused one and iii) implementing a decision rule to each pair of observed and predicted images characterized by the same spatial and spectral resolutions to identify changes. The performance of the proposed framework is evaluated on real images with simulated realistic changes. version:1
arxiv-1609-06070 | Boosting Factor-Specific Functional Historical Models for the Detection of Synchronisation in Bioelectrical Signals | http://arxiv.org/abs/1609.06070 | id:1609.06070 author:David Rügamer, Sarah Brockhaus, Kornelia Gentsch, Klaus Scherer, Sonja Greven category:stat.AP stat.ME stat.ML  published:2016-09-20 summary:The link between different psychophysiological measures during emotion episodes is not well understood. To analyse the functional relationship between electroencephalography (EEG) and facial electromyography (EMG), we apply historical function-on-function regression models to EEG and EMG data that were simultaneously recorded from 24 participants while they were playing a computerised gambling task. Given the complexity of the data structure for this application, we extend simple functional historical models to models including random historical effects, factor-specific historical effects, and factor-specific random historical effects. Estimation is conducted by a component-wise gradient boosting algorithm, which scales well to large data sets and complex models. version:1
arxiv-1609-06049 | Automatic Quality Assessment for Speech Translation Using Joint ASR and MT Features | http://arxiv.org/abs/1609.06049 | id:1609.06049 author:Ngoc-Tien Le, Benjamin Lecouteux, Laurent Besacier category:cs.CL  published:2016-09-20 summary:This paper addresses automatic quality assessment of spoken language translation (SLT). This relatively new task is defined and formalized as a sequence labeling problem where each word in the SLT hypothesis is tagged as good or bad according to a large feature set. We propose several word confidence estimators (WCE) based on our automatic evaluation of transcription (ASR) quality, translation (MT) quality, or both (combined ASR+MT). This research work is possible because we built a specific corpus which contains 6.7k utterances for which a quintuplet containing: ASR output, verbatim transcript, text translation, speech translation and post-edition of translation is built. The conclusion of our multiple experiments using joint ASR and MT features for WCE is that MT features remain the most influent while ASR feature can bring interesting complementary information. Our robust quality estimators for SLT can be used for re-scoring speech translation graphs or for providing feedback to the user in interactive speech translation or computer-assisted speech-to-text scenarios. version:1
arxiv-1609-06041 | A very fast iterative algorithm for TV-regularized image reconstruction with applications to low-dose and few-view CT | http://arxiv.org/abs/1609.06041 | id:1609.06041 author:Hiroyuki Kudo, Fukashi Yamazaki, Takuya Nemoto, Keita Takaki category:physics.med-ph cs.CV math.NA  published:2016-09-20 summary:This paper concerns iterative reconstruction for low-dose and few-view CT by minimizing a data-fidelity term regularized with the Total Variation (TV) penalty. We propose a very fast iterative algorithm to solve this problem. The algorithm derivation is outlined as follows. First, the original minimization problem is reformulated into the saddle point (primal-dual) problem by using the Lagrangian duality, to which we apply the first-order primal-dual iterative methods. Second, we precondition the iteration formula using the ramp flter of Filtered Backprojection (FBP) reconstruction algorithm in such a way that the problem solution is not altered. The resulting algorithm resembles the structure of so-called iterative FBP algorithm, and it converges to the exact minimizer of cost function very fast. version:1
arxiv-1609-06038 | Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference | http://arxiv.org/abs/1609.06038 | id:1609.06038 author:Qian Chen, Xiaodan Zhu, Zhenhua Ling, Si Wei, Hui Jiang category:cs.CL  published:2016-09-20 summary:Reasoning and inference are central to human and artificial intelligence. Modeling inference in human language is notoriously challenging but is fundamental to natural language understanding and many applications. With the availability of large annotated data, neural network models have recently advanced the field significantly. In this paper, we present a new state-of-the-art result, achieving the accuracy of 88.3% on the standard benchmark, the Stanford Natural Language Inference dataset. This result is achieved first through our enhanced sequential encoding model, which outperforms the previous best model that employs more complicated network architectures, suggesting that the potential of sequential LSTM-based models have not been fully explored yet in previous work. We further show that by explicitly considering recursive architectures, we achieve additional improvement. Particularly, incorporating syntactic parse information contributes to our best result; it improves the performance even when the parse information is added to an already very strong system. version:1
arxiv-1609-03057 | Style-Transfer via Texture-Synthesis | http://arxiv.org/abs/1609.03057 | id:1609.03057 author:Michael Elad, Peyman Milanfar category:cs.CV  published:2016-09-10 summary:Style-transfer is a process of migrating a style from a given image to the content of another, synthesizing a new image which is an artistic mixture of the two. Recent work on this problem adopting Convolutional Neural-networks (CNN) ignited a renewed interest in this field, due to the very impressive results obtained. There exists an alternative path towards handling the style-transfer task, via generalization of texture-synthesis algorithms. This approach has been proposed over the years, but its results are typically less impressive compared to the CNN ones. In this work we propose a novel style-transfer algorithm that extends the texture-synthesis work of Kwatra et. al. (2005), while aiming to get stylized images that get closer in quality to the CNN ones. We modify Kwatra's algorithm in several key ways in order to achieve the desired transfer, with emphasis on a consistent way for keeping the content intact in selected regions, while producing hallucinated and rich style in others. The results obtained are visually pleasing and diverse, shown to be competitive with the recent CNN style-transfer algorithms. The proposed algorithm is fast and flexible, being able to process any pair of content + style images. version:3
arxiv-1609-06024 | Contextual Relationship-based Activity Segmentation on an Event Stream in the IoT Environment with Multi-user Activities | http://arxiv.org/abs/1609.06024 | id:1609.06024 author:Minkyoung Cho, Younggi Kim, Younghee Lee category:cs.CV  published:2016-09-20 summary:The human activity recognition in the IoT environment plays the central role in the ambient assisted living, where the human activities can be represented as a concatenated event stream generated from various smart objects. From the concatenated event stream, each activity should be distinguished separately for the human activity recognition to provide services that users may need. In this regard, accurately segmenting the entire stream at the precise boundary of each activity is indispensable high priority task to realize the activity recognition. Multiple human activities in an IoT environment generate varying event stream patterns, and the unpredictability of these patterns makes them include redundant or missing events. In dealing with this complex segmentation problem, we figured out that the dynamic and confusing patterns cause major problems due to: inclusive event stream, redundant events, and shared events. To address these problems, we exploited the contextual relationships associated with the activity status about either ongoing or terminated/started. To discover the intrinsic relationships between the events in a stream, we utilized the LSTM model by rendering it for the activity segmentation. Then, the inferred boundaries were revised by our validation algorithm for a bit shifted boundaries. Our experiments show the surprising result of high accuracy above 95%, on our own testbed with various smart objects. This is superior to the prior works that even do not assume the environment with multi-user activities, where their accuracies are slightly above 80% in their test environment. It proves that our work is feasible enough to be applied in the IoT environment. version:1
arxiv-1609-06020 | Proposal of fault-tolerant tomographic image reconstruction | http://arxiv.org/abs/1609.06020 | id:1609.06020 author:Hiroyuki Kudo, Keita Takaki, Fukashi Yamazaki, Takuya Nemoto category:physics.med-ph cs.CV math.NA  published:2016-09-20 summary:This paper deals with tomographic image reconstruction under the situation where some of projection data bins are contaminated with abnormal data. Such situations occur in various instances of tomography. We propose a new reconstruction algorithm called the Fault-Tolerant reconstruction outlined as follows. The least-squares (L2-norm) error function Ax-b _2^2 used in ordinary iterative reconstructions is sensitive to the existence of abnormal data. The proposed algorithm utilizes the L1-norm error function Ax-b _1^1 instead of the L2-norm, and we develop a row-action-type iterative algorithm using the proximal splitting framework in convex optimization fields. We also propose an improved version of the L1-norm reconstruction called the L1-TV reconstruction, in which a weak Total Variation (TV) penalty is added to the cost function. Simulation results demonstrate that reconstructed images with the L2-norm were severely damaged by the effect of abnormal bins, whereas images with the L1-norm and L1-TV reconstructions were robust to the existence of abnormal bins. version:1
arxiv-1609-06018 | Deep CTR Prediction in Display Advertising | http://arxiv.org/abs/1609.06018 | id:1609.06018 author:Junxuan Chen, Baigui Sun, Hao Li, Hongtao Lu, Xian-Sheng Hua category:cs.CV cs.MM  published:2016-09-20 summary:Click through rate (CTR) prediction of image ads is the core task of online display advertising systems, and logistic regression (LR) has been frequently applied as the prediction model. However, LR model lacks the ability of extracting complex and intrinsic nonlinear features from handcrafted high-dimensional image features, which limits its effectiveness. To solve this issue, in this paper, we introduce a novel deep neural network (DNN) based model that directly predicts the CTR of an image ad based on raw image pixels and other basic features in one step. The DNN model employs convolution layers to automatically extract representative visual features from images, and nonlinear CTR features are then learned from visual features and other contextual features by using fully-connected layers. Empirical evaluations on a real world dataset with over 50 million records demonstrate the effectiveness and efficiency of this method. version:1
arxiv-1609-05993 | Reducing Drift in Visual Odometry by Inferring Sun Direction using a Bayesian Convolutional Neural Network | http://arxiv.org/abs/1609.05993 | id:1609.05993 author:Valentin Peretroukhin, Lee Clement, Jonathan Kelly category:cs.RO cs.CV  published:2016-09-20 summary:We present a method to incorporate global orientation information from the sun into a visual odometry pipeline using the existing image stream only. We leverage recent advances in Bayesian Convolutional Neural Networks to train and implement a sun detection model that infers a three-dimensional sun direction vector from a single RGB image (where the sun is typically not visible). Crucially, our method also computes a principled uncertainty associated with each prediction, using a Monte-Carlo dropout scheme. We incorporate this uncertainty into a sliding window stereo visual odometry pipeline where accurate uncertainty estimates are critical for optimal data fusion. Our Bayesian sun detection model achieves median errors of less than 10 degrees on the KITTI odometry benchmark training set, and yields improvements of up to 37% in translational ARMSE and 32% in rotational ARMSE compared to standard VO. An implementation of our Bayesian CNN sun estimator (Sun-BCNN) is available as open-source code at https://github.com/utiasSTARS/sun-bcnn-vo. version:1
arxiv-1609-05959 | Conformalized Kernel Ridge Regression | http://arxiv.org/abs/1609.05959 | id:1609.05959 author:Evgeny Burnaev, Ivan Nazarov category:stat.ML cs.LG stat.AP  published:2016-09-19 summary:General predictive models do not provide a measure of confidence in predictions without Bayesian assumptions. A way to circumvent potential restrictions is to use conformal methods for constructing non-parametric confidence regions, that offer guarantees regarding validity. In this paper we provide a detailed description of a computationally efficient conformal procedure for Kernel Ridge Regression (KRR), and conduct a comparative numerical study to see how well conformal regions perform against the Bayesian confidence sets. The results suggest that conformalized KRR can yield predictive confidence regions with specified coverage rate, which is essential in constructing anomaly detection systems based on predictive models. version:1
arxiv-1609-06560 | The Optional Prisoner's Dilemma in a Spatial Environment: Coevolving Game Strategy and Link Weights | http://arxiv.org/abs/1609.06560 | id:1609.06560 author:Marcos Cardinot, Colm O'Riordan, Josephine Griffith category:cs.NE cs.MA math.DS  published:2016-09-19 summary:In this paper, the Optional Prisoner's Dilemma game in a spatial environment, with coevolutionary rules for both the strategy and network links between agents, is studied. Using a Monte Carlo simulation approach, a number of experiments are performed to identify favourable configurations of the environment for the emergence of cooperation in adverse scenarios. Results show that abstainers play a key role in the protection of cooperators against exploitation from defectors. Scenarios of cyclic competition and of full dominance of cooperation are also observed. This work provides insights towards gaining an in-depth understanding of the emergence of cooperative behaviour in real-world systems. version:1
arxiv-1609-02997 | Iteratively Reweighted Least Squares Algorithms for L1-Norm Principal Component Analysis | http://arxiv.org/abs/1609.02997 | id:1609.02997 author:Young Woong Park, Diego Klabjan category:stat.ML cs.LG  published:2016-09-10 summary:Principal component analysis (PCA) is often used to reduce the dimension of data by selecting a few orthonormal vectors that explain most of the variance structure of the data. L1 PCA uses the L1 norm to measure error, whereas the conventional PCA uses the L2 norm. For the L1 PCA problem minimizing the fitting error of the reconstructed data, we propose an exact reweighted and an approximate algorithm based on iteratively reweighted least squares. We provide convergence analyses, and compare their performance against benchmark algorithms in the literature. The computational experiment shows that the proposed algorithms consistently perform best. version:2
arxiv-1609-05935 | Advances in All-Neural Speech Recognition | http://arxiv.org/abs/1609.05935 | id:1609.05935 author:G. Zweig, C. Yu, J. Droppo, A. Stolcke category:cs.CL  published:2016-09-19 summary:This paper advances the design of CTC-based all-neural (or end-to-end) speech recognizers. We propose a novel symbol inventory, and a novel iterated-CTC method in which a second system is used to transform a noisy initial output into a cleaner version. We present a number of stabilization and initialization methods we have found useful in training these networks. We evaluate our system on the commonly used NIST 2000 conversational telephony test set, and significantly exceed the previously published performance of similar systems, both with and without the use of an external language model and decoding technology. version:1
arxiv-1609-05884 | A Quantum Implementation Model for Artificial Neural Networks | http://arxiv.org/abs/1609.05884 | id:1609.05884 author:Ammar Daskin category:quant-ph cs.LG cs.NE  published:2016-09-19 summary:The learning process for multi layered neural networks with many nodes makes heavy demands on computational resources. In some neural network models, the learning formulas, such as the Widrow-Hoff formula, do not change the eigenvectors of the weight matrix while flatting the eigenvalues. In infinity, this iterative formulas result in terms formed by the principal components of the weight matrix: i.e., the eigenvectors corresponding to the non-zero eigenvalues. In quantum computing, the phase estimation algorithm is known to provide speed-ups over the conventional algorithms when it is used for the eigenvalue related problems. Therefore, it is appealing to ask whether we can model such learning formulas in quantum computing and gain a computational speed-up. Combining the quantum amplitude amplification with the phase estimation algorithm, a quantum implementation model for artificial neural networks using the Widrow-Hoff learning rule is presented. In addition, the complexity of the model is found to be linear in the size of the weight matrix. This provides a quadratic improvement over the classical algorithms. version:1
arxiv-1609-05881 | Online and Distributed learning of Gaussian mixture models by Bayesian Moment Matching | http://arxiv.org/abs/1609.05881 | id:1609.05881 author:Priyank Jaini, Pascal Poupart category:cs.AI cs.LG stat.ML  published:2016-09-19 summary:The Gaussian mixture model is a classic technique for clustering and data modeling that is used in numerous applications. With the rise of big data, there is a need for parameter estimation techniques that can handle streaming data and distribute the computation over several processors. While online variants of the Expectation Maximization (EM) algorithm exist, their data efficiency is reduced by a stochastic approximation of the E-step and it is not clear how to distribute the computation over multiple processors. We propose a Bayesian learning technique that lends itself naturally to online and distributed computation. Since the Bayesian posterior is not tractable, we project it onto a family of tractable distributions after each observation by matching a set of sufficient moments. This Bayesian moment matching technique compares favorably to online EM in terms of time and accuracy on a set of data modeling benchmarks. version:1
arxiv-1609-04849 | Predicting Shot Making in Basketball using Convolutional Neural Networks Learnt from Adversarial Multiagent Trajectories | http://arxiv.org/abs/1609.04849 | id:1609.04849 author:Mark Harmon, Patrick Lucey, Diego Klabjan category:stat.ML cs.LG  published:2016-09-15 summary:In this paper, we predict the likelihood of a player making a shot in basketball from multiagent trajectories. Previous approaches to similar problems center on hand-crafting features to capture domain specific knowledge. Although intuitive, recent work in deep learning has shown this approach is prone to missing important predictive features. To circumvent this issue, we present a convolutional neural network (CNN) approach where we initially represent the multiagent behavior as an image. To encode the adversarial nature of basketball, we use a multi-channel image which we then feed into a CNN. Additionally, to capture the temporal aspect of the trajectories we use "fading." By using gradient ascent, we were able to discover what the CNN filters look for during training. Last, we find that a combined FNN+CNN is the best performing network with an error rate of 26%. version:2
arxiv-1609-05877 | Geometrically Convergent Distributed Optimization with Uncoordinated Step-Sizes | http://arxiv.org/abs/1609.05877 | id:1609.05877 author:Angelia Nedić, Alex Olshevsky, Wei Shi, César A. Uribe category:math.OC cs.SY stat.ML  published:2016-09-19 summary:A recent algorithmic family for distributed optimization, DIGing's, have been shown to have geometric convergence over time-varying undirected/directed graphs. Nevertheless, an identical step-size for all agents is needed. In this paper, we study the convergence rates of the Adapt-Then-Combine (ATC) variation of the DIGing algorithm under uncoordinated step-sizes. We show that the ATC variation of DIGing algorithm converges geometrically fast even if the step-sizes are different among the agents. In addition, our analysis implies that the ATC structure can accelerate convergence compared to the distributed gradient descent (DGD) structure which has been used in the original DIGing algorithm. version:1
arxiv-1609-05871 | Deep Neural Ensemble for Retinal Vessel Segmentation in Fundus Images towards Achieving Label-free Angiography | http://arxiv.org/abs/1609.05871 | id:1609.05871 author:Avisek Lahiri, Abhijit Guha Roy, Debdoot Sheet, Prabir Kumar Biswas category:cs.CV  published:2016-09-19 summary:Automated segmentation of retinal blood vessels in label-free fundus images entails a pivotal role in computed aided diagnosis of ophthalmic pathologies, viz., diabetic retinopathy, hypertensive disorders and cardiovascular diseases. The challenge remains active in medical image analysis research due to varied distribution of blood vessels, which manifest variations in their dimensions of physical appearance against a noisy background. In this paper we formulate the segmentation challenge as a classification task. Specifically, we employ unsupervised hierarchical feature learning using ensemble of two level of sparsely trained denoised stacked autoencoder. First level training with bootstrap samples ensures decoupling and second level ensemble formed by different network architectures ensures architectural revision. We show that ensemble training of auto-encoders fosters diversity in learning dictionary of visual kernels for vessel segmentation. SoftMax classifier is used for fine tuning each member auto-encoder and multiple strategies are explored for 2-level fusion of ensemble members. On DRIVE dataset, we achieve maximum average accuracy of 95.33\% with an impressively low standard deviation of 0.003 and Kappa agreement coefficient of 0.708 . Comparison with other major algorithms substantiates the high efficacy of our model. version:1
arxiv-1609-05866 | A Cheap Linear Attention Mechanism with Fast Lookups and Fixed-Size Representations | http://arxiv.org/abs/1609.05866 | id:1609.05866 author:Alexandre de Brébisson, Pascal Vincent category:cs.LG cs.IR cs.NE stat.ML  published:2016-09-19 summary:The softmax content-based attention mechanism has proven to be very beneficial in many applications of recurrent neural networks. Nevertheless it suffers from two major computational limitations. First, its computations for an attention lookup scale linearly in the size of the attended sequence. Second, it does not encode the sequence into a fixed-size representation but instead requires to memorize all the hidden states. These two limitations restrict the use of the softmax attention mechanism to relatively small-scale applications with short sequences and few lookups per sequence. In this work we introduce a family of linear attention mechanisms designed to overcome the two limitations listed above. We show that removing the softmax non-linearity from the traditional attention formulation yields constant-time attention lookups and fixed-size representations of the attended sequences. These properties make these linear attention mechanisms particularly suitable for large-scale applications with extreme query loads, real-time requirements and memory constraints. Early experiments on a question answering task show that these linear mechanisms yield significantly better accuracy results than no attention, but obviously worse than their softmax alternative. version:1
arxiv-1609-03499 | WaveNet: A Generative Model for Raw Audio | http://arxiv.org/abs/1609.03499 | id:1609.03499 author:Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, Koray Kavukcuoglu category:cs.SD cs.LG  published:2016-09-12 summary:This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition. version:2
arxiv-1609-01775 | Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking | http://arxiv.org/abs/1609.01775 | id:1609.01775 author:Ergys Ristani, Francesco Solera, Roger S. Zou, Rita Cucchiara, Carlo Tomasi category:cs.CV  published:2016-09-06 summary:To help accelerate progress in multi-target, multi-camera tracking systems, we present (i) a new pair of precision-recall measures of performance that treats errors of all types uniformly and emphasizes correct identification over sources of error; (ii) the largest fully-annotated and calibrated data set to date with more than 2 million frames of 1080p, 60fps video taken by 8 cameras observing more than 2,700 identities over 85 minutes; and (iii) a reference software system as a comparison baseline. We show that (i) our measures properly account for bottom-line identity match performance in the multi-camera setting; (ii) our data set poses realistic challenges to current trackers; and (iii) the performance of our system is comparable to the state of the art. version:2
arxiv-1609-04802 | Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network | http://arxiv.org/abs/1609.04802 | id:1609.04802 author:Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi category:cs.CV stat.ML  published:2016-09-15 summary:Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? During image downsampling information is lost, making super-resolution a highly ill-posed inverse problem with a large set of possible solutions. The behavior of optimization-based super-resolution methods is therefore principally driven by the choice of objective function. Recent work has largely focussed on minimizing the mean squared reconstruction error (MSE). The resulting estimates have high peak signal-to-noise-ratio (PSNR), but they are often overly smoothed, lack high-frequency detail, making them perceptually unsatisfying. In this paper, we present super-resolution generative adversarial network (SRGAN). To our knowledge, it is the first framework capable of recovering photo-realistic natural images from 4 times downsampling. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss function motivated by perceptual similarity instead of similarity in pixel space. Trained on 350K images using the perceptual loss function, our deep residual network was able to recover photo-realistic textures from heavily downsampled images on public benchmarks. version:2
arxiv-1609-03461 | MUG: A Parameterless No-Reference JPEG Quality Evaluator Robust to Block Size and Misalignment | http://arxiv.org/abs/1609.03461 | id:1609.03461 author:Hossein Ziaei Nafchi, Atena Shahkolaei, Rachid Hedjam, Mohamed Cheriet category:cs.CV  published:2016-09-12 summary:In this letter, a very simple no-reference image quality assessment (NR-IQA) model for JPEG compressed images is proposed. The proposed metric called median of unique gradients (MUG) is based on the very simple facts of unique gradient magnitudes of JPEG compressed images. MUG is a parameterless metric and does not need training. Unlike other NR-IQAs, MUG is independent to block size and cropping. A more stable index called MUG+ is also introduced. The experimental results on six benchmark datasets of natural images and a benchmark dataset of synthetic images show that MUG is comparable to the state-of-the-art indices in literature. In addition, its performance remains unchanged for the case of the cropped images in which block boundaries are not known. The MATLAB source code of the proposed metrics is available at https://dl.dropboxusercontent.com/u/74505502/MUG.m and https://dl.dropboxusercontent.com/u/74505502/MUGplus.m. version:2
arxiv-1609-05820 | The Projected Power Method: An Efficient Algorithm for Joint Alignment from Pairwise Differences | http://arxiv.org/abs/1609.05820 | id:1609.05820 author:Yuxin Chen, Emmanuel Candes category:cs.IT cs.CV cs.LG math.IT math.OC stat.ML  published:2016-09-19 summary:Various applications involve assigning discrete label values to a collection of objects based on some noisy data. Due to the discrete---and hence nonconvex---structure of the problem, computing the maximum likelihood estimates (MLE) becomes intractable at first sight. This paper makes progress towards efficient computation of the MLE by focusing on a concrete joint alignment problem---that is, the problem of recovering $n$ discrete variables $x_i \in \{1,\cdots, m\}$, $1\leq i\leq n$ given noisy observations of their modulo differences $\{x_i - x_j~\mathsf{mod}~m\}$. We propose a novel low-complexity procedure, which operates in a lifted space by representing distinct label values in orthogonal directions, and which attempts to optimize quadratic functions over hyper cubes. Starting with a first guess computed via a special method, the algorithm successively refines the iterates via projected power iterations. We prove that the proposed projected power method makes no error---and hence converges to the MLE---in a suitable regime. Numerical experiments have been carried out on both synthetic and real data to demonstrate the practicality of our algorithm. We expect this algorithmic framework to be effective for a broad range of discrete assignment problems. version:1
arxiv-1609-05807 | Inherent Trade-Offs in the Fair Determination of Risk Scores | http://arxiv.org/abs/1609.05807 | id:1609.05807 author:Jon Kleinberg, Sendhil Mullainathan, Manish Raghavan category:cs.LG cs.CY stat.ML  published:2016-09-19 summary:Recent discussion in the public sphere about algorithmic classification has involved tension between competing notions of what it means for a probabilistic classification to be fair to different groups. We formalize three fairness conditions that lie at the heart of these debates, and we prove that except in highly constrained special cases, there is no method that can satisfy these three conditions simultaneously. Moreover, even satisfying all three conditions approximately requires that the data lie in an approximate version of one of the constrained special cases identified by our theorem. These results suggest some of the ways in which key notions of fairness are incompatible with each other, and hence provide a framework for thinking about the trade-offs between them. version:1
arxiv-1609-05797 | Random Forests versus Neural Networks - What's Best for Camera Relocalization? | http://arxiv.org/abs/1609.05797 | id:1609.05797 author:Daniela Massiceti, Alexander Krull, Eric Brachmann, Carsten Rother, Philip H. S. Torr category:cs.CV cs.RO  published:2016-09-19 summary:This work addresses the task of camera localization in a known 3D scene, given a single input RGB image. State-of-the-art approaches accomplish this with two steps. Firstly, regressing for every pixel in the image its so-called 3D scene coordinate and, subsequently, using those coordinates to estimate the final 6D camera pose via RANSAC. To solve the first step, Random Forests (RFs) are typically used. On the other hand, Neural Networks (NNs) currently reign in many dense regression problems, but are not test-time efficient. We ask the question: Which of the two is the best choice for camera localization? To address this, we make two method contributions: (1) a test-time efficient NN architecture which we term a ForestNet that is derived and initialized from a RF, and (2) a new fully-differentiable robust averaging technique for regression ensembles which can be trained end-to-end with a NN architecture. Our experimental findings show that traditional NN architectures are superior to test-time efficient RFs and ForestNets in terms of scene coordinate regression, however, this does not translate to final 6D camera pose accuracy where ForestNets and RFs perform slightly better. To summarize, our best method, a ForestNet with a robust average, improves over the state-of-the-art for camera localization on the 7-Scenes dataset. While this work focuses on scene coordinate regression for camera localization, our innovations may also be applied to other continuous regression tasks. version:1
arxiv-1609-05796 | Enabling Dark Energy Science with Deep Generative Models of Galaxy Images | http://arxiv.org/abs/1609.05796 | id:1609.05796 author:Siamak Ravanbakhsh, Francois Lanusse, Rachel Mandelbaum, Jeff Schneider, Barnabas Poczos category:astro-ph.IM astro-ph.CO cs.AI stat.ML  published:2016-09-19 summary:Understanding the nature of dark energy, the mysterious force driving the accelerated expansion of the Universe, is a major challenge of modern cosmology. The next generation of cosmological surveys, specifically designed to address this issue, rely on accurate measurements of the apparent shapes of distant galaxies. However, shape measurement methods suffer from various unavoidable biases and therefore will rely on a precise calibration to meet the accuracy requirements of the science analysis. This calibration process remains an open challenge as it requires large sets of high quality galaxy images. To this end, we study the application of deep conditional generative models in generating realistic galaxy images. In particular we consider variations on conditional variational autoencoder and introduce a new adversarial objective for training of conditional generative networks. Our results suggest a reliable alternative to the acquisition of expensive high quality observations for generating the calibration data needed by the next generation of cosmological surveys. version:1
arxiv-1609-05772 | Stochastic Matrix Factorization | http://arxiv.org/abs/1609.05772 | id:1609.05772 author:Christopher Adams category:stat.ML cs.LG  published:2016-09-19 summary:This paper considers a restriction to non-negative matrix factorization in which at least one matrix factor is stochastic. That is, the elements of the matrix factors are non-negative and the columns of one matrix factor sum to 1. This restriction includes topic models, a popular method for analyzing unstructured data. It also includes a method for storing and finding pictures. The paper presents necessary and sufficient conditions on the observed data such that the factorization is unique. In addition, the paper characterizes natural bounds on the parameters for any observed data and presents a consistent least squares estimator. The results are illustrated using a topic model analysis of PhD abstracts in economics and the problem of storing and retrieving a set of pictures of faces. version:1
arxiv-1609-05722 | Poisson Noise Reduction with Higher-order Natural Image Prior Model | http://arxiv.org/abs/1609.05722 | id:1609.05722 author:Wensen Feng, Hong Qiao, Yunjin Chen category:cs.CV  published:2016-09-19 summary:Poisson denoising is an essential issue for various imaging applications, such as night vision, medical imaging and microscopy. State-of-the-art approaches are clearly dominated by patch-based non-local methods in recent years. In this paper, we aim to propose a local Poisson denoising model with both structure simplicity and good performance. To this end, we consider a variational modeling to integrate the so-called Fields of Experts (FoE) image prior, that has proven an effective higher-order Markov Random Fields (MRF) model for many classic image restoration problems. We exploit several feasible variational variants for this task. We start with a direct modeling in the original image domain by taking into account the Poisson noise statistics, which performs generally well for the cases of high SNR. However, this strategy encounters problem in cases of low SNR. Then we turn to an alternative modeling strategy by using the Anscombe transform and Gaussian statistics derived data term. We retrain the FoE prior model directly in the transform domain. With the newly trained FoE model, we end up with a local variational model providing strongly competitive results against state-of-the-art non-local approaches, meanwhile bearing the property of simple structure. Furthermore, our proposed model comes along with an additional advantage, that the inference is very efficient as it is well-suited for parallel computation on GPUs. For images of size $512 \times 512$, our GPU implementation takes less than 1 second to produce state-of-the-art Poisson denoising performance. version:1
arxiv-1609-05695 | A scalable convolutional neural network for task-specified scenarios via knowledge distillation | http://arxiv.org/abs/1609.05695 | id:1609.05695 author:Mengnan Shi, Fei Qin, Qixiang Ye, Zhenjun Han, Jianbin Jiao category:cs.CV  published:2016-09-19 summary:In this paper, we explore the redundancy in convolutional neural network, which scales with the complexity of vision tasks. Considering that many front-end visual systems are interested in only a limited range of visual targets, the removing of task-specified network redundancy can promote a wide range of potential applications. We propose a task-specified knowledge distillation algorithm to derive a simplified model with pre-set computation cost and minimized accuracy loss, which suits the resource constraint front-end systems well. Experiments on the MNIST and CIFAR10 datasets demonstrate the feasibility of the proposed approach as well as the existence of task-specified redundancy. version:1
arxiv-1609-05650 | Multi-view Dimensionality Reduction for Dialect Identification of Arabic Broadcast Speech | http://arxiv.org/abs/1609.05650 | id:1609.05650 author:Sameer Khurana, Ahmed Ali, Steve Renals category:cs.CL  published:2016-09-19 summary:In this work, we present a new Vector Space Model (VSM) of speech utterances for the task of spoken dialect identification. Generally, DID systems are built using two sets of features that are extracted from speech utterances; acoustic and phonetic. The acoustic and phonetic features are used to form vector representations of speech utterances in an attempt to encode information about the spoken dialects. The Phonotactic and Acoustic VSMs, thus formed, are used for the task of DID. The aim of this paper is to construct a single VSM that encodes information about spoken dialects from both the Phonotactic and Acoustic VSMs. Given the two views of the data, we make use of a well known multi-view dimensionality reduction technique known as Canonical Correlation Analysis (CCA), to form a single vector representation for each speech utterance that encodes dialect specific discriminative information from both the phonetic and acoustic representations. We refer to this approach as feature space combination approach and show that our CCA based feature vector representation performs better on the Arabic DID task than the phonetic and acoustic feature representations used alone. We also present the feature space combination approach as a viable alternative to the model based combination approach, where two DID systems are built using the two VSMs (Phonotactic and Acoustic) and the final prediction score is the output score combination from the two systems. version:1
arxiv-1609-05625 | The MGB-2 Challenge: Arabic Multi-Dialect Broadcast Media Recognition | http://arxiv.org/abs/1609.05625 | id:1609.05625 author:Ahmed Ali, Peter Bell, James Glass, Yacine Messaoui, Hamdy Mubarak, Steve Renals, Yifan Zhang category:cs.CL  published:2016-09-19 summary:This paper describes the Arabic Multi-Genre Broadcast (MGB-2) Challenge for SLT-2016. Unlike last year's English MGB Challenge, which focused on recognition of diverse TV genres, this year, the challenge has an emphasis on handling the diversity in dialect in Arabic speech. Audio data comes from 19 distinct programmes from the Aljazeera Arabic TV channel between March 2005 and December 2015. Programmes are split into three groups: conversations, interviews, and reports. A total of 1,200 hours have been released with lightly supervised transcriptions for the acoustic modelling. For language modelling, we made available over 110M words crawled from Aljazeera Arabic website Aljazeera.net for a 10 year duration 2000-2011. Two lexicons have been provided, one phoneme based and one grapheme based. Finally, two tasks were proposed for this year's challenge: standard speech transcription, and word alignment. This paper describes the task data and evaluation process used in the MGB challenge, and summarises the results obtained. version:1
arxiv-1609-05619 | Coarse-to-fine Surgical Instrument Detection for Cataract Surgery Monitoring | http://arxiv.org/abs/1609.05619 | id:1609.05619 author:Hassan Al Hajj, Gwenolé Quellec, Mathieu Lamard, Guy Cazuguel, Béatrice Cochener category:cs.CV  published:2016-09-19 summary:The amount of surgical data, recorded during video-monitored surgeries, has extremely increased. This paper aims at improving existing solutions for the automated analysis of cataract surgeries in real time. Through the analysis of a video recording the operating table, it is possible to know which instruments exit or enter the operating table, and therefore which ones are likely being used by the surgeon. Combining these observations with observations from the microscope video should enhance the overall performance of the systems. To this end, the proposed solution is divided into two main parts: one to detect the instruments at the beginning of the surgery and one to update the list of instruments every time a change is detected in the scene. In the first part, the goal is to separate the instruments from the background and from irrelevant objects. For the second, we are interested in detecting the instruments that appear and disappear whenever the surgeon interacts with the table. Experiments on a dataset of 36 cataract surgeries validate the good performance of the proposed solution. version:1
arxiv-1609-05610 | Enhancing LambdaMART Using Oblivious Trees | http://arxiv.org/abs/1609.05610 | id:1609.05610 author:Michal Ferov, Marek Modrý category:cs.IR cs.LG  published:2016-09-19 summary:Learning to rank is a machine learning technique broadly used in many areas such as document retrieval, collaborative filtering or question answering. We present experimental results which suggest that the performance of the current state-of-the-art learning to rank algorithm LambdaMART, when used for document retrieval for search engines, can be improved if standard regression trees are replaced by oblivious trees. This paper provides a comparison of both variants and our results demonstrate that the use of oblivious trees can improve the performance by more than $2.2\%$. Additional experimental analysis of the influence of a number of features and of a size of the training set is also provided and confirms the desirability of properties of oblivious decision trees. version:1
arxiv-1609-05600 | Graph-Structured Representations for Visual Question Answering | http://arxiv.org/abs/1609.05600 | id:1609.05600 author:Damien Teney, Lingqiao Liu, Anton van den Hengel category:cs.CV cs.AI cs.CL  published:2016-09-19 summary:This paper proposes to improve visual question answering (VQA) with structured representations of both scene contents and questions. A key challenge in VQA is to require joint reasoning over the visual and text domains. The predominant CNN/LSTM-based approach to VQA is limited by monolithic vector representations that largely ignore structure in the scene and in the form of the question. CNN feature vectors cannot effectively capture situations as simple as multiple object instances, and LSTMs process questions as series of words, which does not reflect the true complexity of language structure. We instead propose to build graphs over the scene objects and over the question words, and we describe a deep neural network that exploits the structure in these representations. This shows significant benefit over the sequential processing of LSTMs. The overall efficacy of our approach is demonstrated by significant improvements over the state-of-the-art, from 71.2% to 74.4% in accuracy on the "abstract scenes" multiple-choice benchmark, and from 34.7% to 39.1% in accuracy over pairs of "balanced" scenes, i.e. images with fine-grained differences and opposite yes/no answers to a same question. version:1
arxiv-1609-05590 | Fast Single Shot Detection and Pose Estimation | http://arxiv.org/abs/1609.05590 | id:1609.05590 author:Patrick Poirson, Phil Ammirato, Cheng-Yang Fu, Wei Liu, Jana Kosecka, Alexander C. Berg category:cs.CV  published:2016-09-19 summary:For applications in navigation and robotics, estimating the 3D pose of objects is as important as detection. Many approaches to pose estimation rely on detecting or tracking parts or keypoints [11, 21]. In this paper we build on a recent state-of-the-art convolutional network for slidingwindow detection [10] to provide detection and rough pose estimation in a single shot, without intermediate stages of detecting parts or initial bounding boxes. While not the first system to treat pose estimation as a categorization problem, this is the first attempt to combine detection and pose estimation at the same level using a deep learning approach. The key to the architecture is a deep convolutional network where scores for the presence of an object category, the offset for its location, and the approximate pose are all estimated on a regular grid of locations in the image. The resulting system is as accurate as recent work on pose estimation (42.4% 8 View mAVP on Pascal 3D+ [21] ) and significantly faster (46 frames per second (FPS) on a TITAN X GPU). This approach to detection and rough pose estimation is fast and accurate enough to be widely applied as a pre-processing step for tasks including high-accuracy pose estimation, object tracking and localization, and vSLAM. version:1
arxiv-1609-05587 | Tensor Completion by Alternating Minimization under the Tensor Train (TT) Model | http://arxiv.org/abs/1609.05587 | id:1609.05587 author:Wenqi Wang, Vaneet Aggarwal, Shuchin Aeron category:cs.NA cs.IT cs.LG math.IT  published:2016-09-19 summary:Using the matrix product state (MPS) representation of tensor train decompositions, in this paper we propose a tensor completion algorithm which alternates over the matrices (tensors) in the MPS representation. This development is motivated in part by the success of matrix completion algorithms which alternate over the (low-rank) factors. We comment on the computational complexity of the proposed algorithm and numerically compare it with existing methods employing low rank tensor train approximation for data completion as well as several other recently proposed methods. We show that our method is superior to existing ones for a variety of real settings. version:1
arxiv-1609-05583 | Color: A Crucial Factor for Aesthetic Quality Assessment in a Subjective Dataset of Paintings | http://arxiv.org/abs/1609.05583 | id:1609.05583 author:Seyed Ali Amirshahi, Gregor Uwe Hayn-Leichsenring, Joachim Denzler, Christoph Redies category:cs.CV  published:2016-09-19 summary:Computational aesthetics is an emerging field of research which has attracted different research groups in the last few years. In this field, one of the main approaches to evaluate the aesthetic quality of paintings and photographs is a feature-based approach. Among the different features proposed to reach this goal, color plays an import role. In this paper, we introduce a novel dataset that consists of paintings of Western provenance from 36 well-known painters from the 15th to the 20th century. As a first step and to assess this dataset, using a classifier, we investigate the correlation between the subjective scores and two widely used features that are related to color perception and in different aesthetic quality assessment approaches. Results show a classification rate of up to 73% between the color features and the subjective scores. version:1
arxiv-1609-04909 | An Iterative Transfer Learning Based Ensemble Technique for Automatic Short Answer Grading | http://arxiv.org/abs/1609.04909 | id:1609.04909 author:Shourya Roy, Himanshu S. Bhatt, Y. Narahari category:cs.CL  published:2016-09-16 summary:Automatic short answer grading (ASAG) techniques are designed to automatically assess short answers to questions in natural language, having a length of a few words to a few sentences. Supervised ASAG techniques have been demonstrated to be effective but suffer from a couple of key practical limitations. They are greatly reliant on instructor provided model answers and need labeled training data in the form of graded student answers for every assessment task. To overcome these, in this paper, we introduce an ASAG technique with two novel features. We propose an iterative technique on an ensemble of (a) a text classifier of student answers and (b) a classifier using numeric features derived from various similarity measures with respect to model answers. Second, we employ canonical correlation analysis based transfer learning on a common feature representation to build the classifier ensemble for questions having no labelled data. The proposed technique handsomely beats all winning supervised entries on the SCIENTSBANK dataset from the Student Response Analysis task of SemEval 2013. Additionally, we demonstrate generalizability and benefits of the proposed technique through evaluation on multiple ASAG datasets from different subject topics and standards. version:2
arxiv-1609-05573 | Optimality and Sub-optimality of PCA for Spiked Random Matrices and Synchronization | http://arxiv.org/abs/1609.05573 | id:1609.05573 author:Amelia Perry, Alexander S. Wein, Afonso S. Bandeira, Ankur Moitra category:math.ST cs.DS cs.IT math.IT math.PR stat.ML stat.TH 62H15  62B15  published:2016-09-19 summary:A central problem of random matrix theory is to understand the eigenvalues of spiked random matrix models, in which a prominent eigenvector is planted into a random matrix. These distributions form natural statistical models for principal component analysis (PCA) problems throughout the sciences. Baik, Ben Arous and P\'ech\'e showed that the spiked Wishart ensemble exhibits a sharp phase transition asymptotically: when the signal strength is above a critical threshold, it is possible to detect the presence of a spike based on the top eigenvalue, and below the threshold the top eigenvalue provides no information. Such results form the basis of our understanding of when PCA can detect a low-rank signal in the presence of noise. However, not all the information about the spike is necessarily contained in the spectrum. We study the fundamental limitations of statistical methods, including non-spectral ones. Our results include: i) For the Gaussian Wigner ensemble, we show that PCA achieves the optimal detection threshold for a variety of benign priors for the spike. We extend previous work on the spherically symmetric and i.i.d. Rademacher priors through an elementary, unified analysis. ii) For any non-Gaussian Wigner ensemble, we show that PCA is always suboptimal for detection. However, a variant of PCA achieves the optimal threshold (for benign priors) by pre-transforming the matrix entries according to a carefully designed function. This approach has been stated before, and we give a rigorous and general analysis. iii) For both the Gaussian Wishart ensemble and various synchronization problems over groups, we show that inefficient procedures can work below the threshold where PCA succeeds, whereas no known efficient algorithm achieves this. This conjectural gap between what is statistically possible and what can be done efficiently remains open. version:1
arxiv-1609-05561 | From Multiview Image Curves to 3D Drawings | http://arxiv.org/abs/1609.05561 | id:1609.05561 author:Anil Usumezbas, Ricardo Fabbri, Benjamin B. Kimia category:cs.CV cs.CG cs.GR cs.RO  published:2016-09-18 summary:Reconstructing 3D scenes from multiple views has made impressive strides in recent years, chiefly by correlating isolated feature points, intensity patterns, or curvilinear structures. In the general setting - without controlled acquisition, abundant texture, curves and surfaces following specific models or limiting scene complexity - most methods produce unorganized point clouds, meshes, or voxel representations, with some exceptions producing unorganized clouds of 3D curve fragments. Ideally, many applications require structured representations of curves, surfaces and their spatial relationships. This paper presents a step in this direction by formulating an approach that combines 2D image curves into a collection of 3D curves, with topological connectivity between them represented as a 3D graph. This results in a 3D drawing, which is complementary to surface representations in the same sense as a 3D scaffold complements a tent taut over it. We evaluate our results against truth on synthetic and real datasets. version:1
arxiv-1609-05559 | Opponent Modeling in Deep Reinforcement Learning | http://arxiv.org/abs/1609.05559 | id:1609.05559 author:He He, Jordan Boyd-Graber, Kevin Kwok, Hal Daumé III category:cs.LG  published:2016-09-18 summary:Opponent modeling is necessary in multi-agent settings where secondary agents with competing goals also adapt their strategies, yet it remains challenging because strategies interact with each other and change. Most previous work focuses on developing probabilistic models or parameterized strategies for specific applications. Inspired by the recent success of deep reinforcement learning, we present neural-based models that jointly learn a policy and the behavior of opponents. Instead of explicitly predicting the opponent's action, we encode observation of the opponents into a deep Q-Network (DQN); however, we retain explicit modeling (if desired) using multitasking. By using a Mixture-of-Experts architecture, our model automatically discovers different strategy patterns of opponents without extra supervision. We evaluate our models on a simulated soccer game and a popular trivia game, showing superior performance over DQN and its variants. version:1
arxiv-1609-05539 | On Randomized Distributed Coordinate Descent with Quantized Updates | http://arxiv.org/abs/1609.05539 | id:1609.05539 author:Mostafa El Gamal, Lifeng Lai category:stat.ML cs.LG  published:2016-09-18 summary:In this paper, we study the randomized distributed coordinate descent algorithm with quantized updates. In the literature, the iteration complexity of the randomized distributed coordinate descent algorithm has been characterized under the assumption that machines can exchange updates with an infinite precision. We consider a practical scenario in which the messages exchange occurs over channels with finite capacity, and hence the updates have to be quantized. We derive sufficient conditions on the quantization error such that the algorithm with quantized update still converge. We further compare the convergence rates of the randomized distributed coordinate descent algorithm with and without quantization errors through numerical results. version:1
arxiv-1609-05536 | Learning Personalized Optimal Control for Repeatedly Operated Systems | http://arxiv.org/abs/1609.05536 | id:1609.05536 author:Theja Tulabandhula category:cs.LG stat.ML  published:2016-09-18 summary:We consider the problem of online learning of optimal control for repeatedly operated systems in the presence of parametric uncertainty. During each round of operation, environment selects system parameters according to a fixed but unknown probability distribution. These parameters govern the dynamics of a plant. An agent chooses a control input to the plant and is then revealed the cost of the choice. In this setting, we design an agent that personalizes the control input to this plant taking into account the stochasticity involved. We demonstrate the effectiveness of our approach on a simulated system. version:1
arxiv-1609-05528 | Sequential Ensemble Learning for Outlier Detection: A Bias-Variance Perspective | http://arxiv.org/abs/1609.05528 | id:1609.05528 author:Shebuti Rayana, Wen Zhong, Leman Akoglu category:cs.LG stat.ML  published:2016-09-18 summary:Ensemble methods for classification and clustering have been effectively used for decades, while ensemble learning for outlier detection has only been studied recently. In this work, we design a new ensemble approach for outlier detection in multi-dimensional point data, which provides improved accuracy by reducing error through both bias and variance. Although classification and outlier detection appear as different problems, their theoretical underpinnings are quite similar in terms of the bias-variance trade-off [1], where outlier detection is considered as a binary classification task with unobserved labels but a similar bias-variance decomposition of error. In this paper, we propose a sequential ensemble approach called CARE that employs a two-phase aggregation of the intermediate results in each iteration to reach the final outcome. Unlike existing outlier ensembles which solely incorporate a parallel framework by aggregating the outcomes of independent base detectors to reduce variance, our ensemble incorporates both the parallel and sequential building blocks to reduce bias as well as variance by ($i$) successively eliminating outliers from the original dataset to build a better data model on which outlierness is estimated (sequentially), and ($ii$) combining the results from individual base detectors and across iterations (parallelly). Through extensive experiments on sixteen real-world datasets mainly from the UCI machine learning repository [2], we show that CARE performs significantly better than or at least similar to the individual baselines. We also compare CARE with the state-of-the-art outlier ensembles where it also provides significant improvement when it is the winner and remains close otherwise. version:1
arxiv-1609-04117 | Network learning via multi-agent inverse transportation problems | http://arxiv.org/abs/1609.04117 | id:1609.04117 author:Jia Xu, Mehdi Nourinejad, Joseph Y. J. Chow category:cs.MA cs.CE cs.LG math.ST stat.TH  published:2016-09-14 summary:Despite the ubiquity of transportation data, statistical inference methods alone are not able to explain mechanistic relations within a network. Inverse optimization methods fulfill this gap, but they are designed to take observations of the same model to learn the parameters of that model. New inverse optimization models and supporting algorithms are proposed to learn the parameters of heterogeneous travelers' route optimization such that the value of shared network resources (e.g. link capacity dual prices) can be inferred. The inferred values are internally consistent with each agent's optimization program. We prove that the method can obtain unique dual prices for a network shared by these agents, in polynomial time. Three experiments are conducted. The first one, conducted on a 4-node network, verifies the methodology to obtain heterogeneous link cost parameters even when a mixed logit model cannot provide meaningful results. The second is a parameter recovery test on the Nguyen-Dupuis network that shows that unique latent link capacity dual prices can be inferred using the proposed method. The last test on the same network demonstrates how a monitoring system in an online learning environment can be designed using this method. version:2
arxiv-1609-05524 | Principled Option Learning in Markov Decision Processes | http://arxiv.org/abs/1609.05524 | id:1609.05524 author:Roy Fox, Michal Moshkovitz, Naftali Tishby category:cs.LG stat.ML  published:2016-09-18 summary:It is well known that options can make planning more efficient, among their many benefits. Thus far, algorithms for autonomously discovering a set of useful options were heuristic. Naturally, a principled way of finding a set of useful options may be more promising and insightful. In this paper we suggest a mathematical characterization of good sets of options using tools from information theory. This characterization enables us to find conditions for a set of options to be optimal and an algorithm that outputs a useful set of options and illustrate the proposed algorithm in simulation. version:1
arxiv-1609-05522 | Learning camera viewpoint using CNN to improve 3D body pose estimation | http://arxiv.org/abs/1609.05522 | id:1609.05522 author:Mona Fathollahi Ghezelghieh, Rangachar Kasturi, Sudeep Sarkar category:cs.CV  published:2016-09-18 summary:The objective of this work is to estimate 3D human pose from a single RGB image. Extracting image representations which incorporate both spatial relation of body parts and their relative depth plays an essential role in accurate3D pose reconstruction. In this paper, for the first time, we show that camera viewpoint in combination to 2D joint lo-cations significantly improves 3D pose accuracy without the explicit use of perspective geometry mathematical models.To this end, we train a deep Convolutional Neural Net-work (CNN) to learn categorical camera viewpoint. To make the network robust against clothing and body shape of the subject in the image, we utilized 3D computer rendering to synthesize additional training images. We test our framework on the largest 3D pose estimation bench-mark, Human3.6m, and achieve up to 20% error reduction compared to the state-of-the-art approaches that do not use body part segmentation. version:1
arxiv-1609-05511 | Multilinear Grammar: Ranks and Interpretations | http://arxiv.org/abs/1609.05511 | id:1609.05511 author:Dafydd Gibbon, Sascha Griffiths category:cs.CL  published:2016-09-18 summary:Multilinear Grammar (MLG) is an approach to integrating the many different syntagmatic structures of language into a coherent architecture, the Rank-Interpretation Architecture. The architecture defines ranks from discourse structure through utterances, phrasal structures, word structures to speech sounds. Each rank has its own specific kind of prosodic-phonetic interpretation and semantic-pragmatic interpretation. Common to models of all these subdomains are models based on regular languages, and processors with finite working memory. version:1
arxiv-1609-03426 | Multi-Label Learning with Provable Guarantee | http://arxiv.org/abs/1609.03426 | id:1609.03426 author:Sayantan Dasgupta category:cs.LG  published:2016-09-12 summary:Here we study the problem of learning labels for large text corpora where each text can be assigned a variable number of labels. The problem might seem trivial when the label dimensionality is small, and can be easily solved using a series of one-vs-all classifiers. However, as the label dimensionality increases to several thousand, the parameter space becomes extremely large, and it is no longer possible to use the one-vs-all technique. Here we propose a model based on the factorization of higher order moments of the words in the corpora, as well as the cross moment between the labels and the words for multi-label prediction. Our model provides guaranteed convergence bounds on the estimated parameters. Further, our model takes only three passes through the training dataset to extract the parameters, resulting in a highly scalable algorithm that can train on GB's of data consisting of millions of documents with hundreds of thousands of labels using a nominal resource of a single processor with 16GB RAM. Our model achieves 10x-15x order of speed-up on large-scale datasets while producing competitive performance in comparison with existing benchmark algorithms. version:3
arxiv-1609-05486 | Probabilistic Feature Selection and Classification Vector Machine | http://arxiv.org/abs/1609.05486 | id:1609.05486 author:Chang Li, Huanhuan Chen, Xin Yao category:cs.LG stat.ML  published:2016-09-18 summary:Sparse Bayesian classifiers are among the state-of-the-art classification algorithms, which are able to make stable and reliable probabilistic predictions. However, some of these algorithms, e.g. probabilistic classification vector machine (PCVM) and relevant vector machine (RVM), are not capable of eliminating irrelevant and redundant features which result in performance degradation. To tackle this problem, in this paper, a Bayesian approach is adopted to simultaneously select the relevant samples and features for clas- sification. We call it a probabilistic feature selection and classification vector machine (PFCVM), which adopts truncated Gaussian priors as both sample and feature priors. In order to derive the analytical solution to Bayesian inference, we use Laplace approximation to obtain approximate posteriors and marginal likelihoods. Then we obtain the optimized parameters and hyperparameters by the type-II maximum likelihood method. The experi- ments on benchmark data sets and high dimensional data sets validate the performance of PFCVM under two criteria: accuracy of classification and effectiveness of selected features. Finally, we analyse the generalization performance of PFCVM and derive a generalization error bound for PFCVM. Then by tightening the bound, we demonstrate the significance of the sparseness for the model. version:1
arxiv-1609-05483 | Set-Point Regulation of Linear Continuous-Time Systems using Neuromorphic Vision Sensors | http://arxiv.org/abs/1609.05483 | id:1609.05483 author:Prince Singh, Sze Zheng Yong, Emilio Frazzoli category:cs.SY cs.CV cs.RO  published:2016-09-18 summary:Recently developed neuromorphic vision sensors have become promising candidates for agile and autonomous robotic applications primarily due to, in particular, their high temporal resolution and low latency. Each pixel of this sensor independently fires an asynchronous stream of "retinal events" once a change in the light field is detected. Existing computer vision algorithms can only process periodic frames and so a new class of algorithms needs to be developed that can efficiently process these events for control tasks. In this paper, we investigate the problem of regulating a continuous-time linear time invariant (LTI) system to a desired point using measurements from a neuromorphic sensor. We present an $H_\infty$ controller that regulates the LTI system to a desired set-point and provide the set of neuromorphic sensor based cameras for the given system that fulfill the regulation task. The effectiveness of our approach is illustrated on an unstable system. version:1
arxiv-1609-05434 | Consistent Discretization and Minimization of the L1 Norm on Manifolds | http://arxiv.org/abs/1609.05434 | id:1609.05434 author:Alex Bronstein, Yoni Choukroun, Ron Kimmel, Matan Sela category:cs.NA cs.CV  published:2016-09-18 summary:The L1 norm has been tremendously popular in signal and image processing in the past two decades due to its sparsity-promoting properties. More recently, its generalization to non-Euclidean domains has been found useful in shape analysis applications. For example, in conjunction with the minimization of the Dirichlet energy, it was shown to produce a compactly supported quasi-harmonic orthonormal basis, dubbed as compressed manifold modes. The continuous L1 norm on the manifold is often replaced by the vector l1 norm applied to sampled functions. We show that such an approach is incorrect in the sense that it does not consistently discretize the continuous norm and warn against its sensitivity to the specific sampling. We propose two alternative discretizations resulting in an iteratively-reweighed l2 norm. We demonstrate the proposed strategy on the compressed modes problem, which reduces to a sequence of simple eigendecomposition problems not requiring non-convex optimization on Stiefel manifolds and producing more stable and accurate results. version:1
arxiv-1609-05420 | Pose from Action: Unsupervised Learning of Pose Features based on Motion | http://arxiv.org/abs/1609.05420 | id:1609.05420 author:Senthil Purushwalkam, Abhinav Gupta category:cs.CV  published:2016-09-18 summary:Human actions are comprised of a sequence of poses. This makes videos of humans a rich and dense source of human poses. We propose an unsupervised method to learn pose features from videos that exploits a signal which is complementary to appearance and can be used as supervision: motion. The key idea is that humans go through poses in a predictable manner while performing actions. Hence, given two poses, it should be possible to model the motion that caused the change between them. We represent each of the poses as a feature in a CNN (Appearance ConvNet) and generate a motion encoding from optical flow maps using a separate CNN (Motion ConvNet). The data for this task is automatically generated allowing us to train without human supervision. We demonstrate the strength of the learned representation by finetuning the trained model for Pose Estimation on the FLIC dataset, for static image action recognition on PASCAL and for action recognition in videos on UCF101 and HMDB51. version:1
arxiv-1609-06146 | mlr Tutorial | http://arxiv.org/abs/1609.06146 | id:1609.06146 author:Julia Schiffner, Bernd Bischl, Michel Lang, Jakob Richter, Zachary M. Jones, Philipp Probst, Florian Pfisterer, Mason Gallo, Dominik Kirchhoff, Tobias Kühn, Janek Thomas, Lars Kotthoff category:cs.LG  published:2016-09-18 summary:This document provides and in-depth introduction to the mlr framework for machine learning experiments in R. version:1
arxiv-1609-05396 | A Deep Metric for Multimodal Registration | http://arxiv.org/abs/1609.05396 | id:1609.05396 author:Martin Simonovsky, Benjamín Gutiérrez-Becker, Diana Mateus, Nassir Navab, Nikos Komodakis category:cs.CV cs.LG cs.NE  published:2016-09-17 summary:Multimodal registration is a challenging problem in medical imaging due the high variability of tissue appearance under different imaging modalities. The crucial component here is the choice of the right similarity measure. We make a step towards a general learning-based solution that can be adapted to specific situations and present a metric based on a convolutional neural network. Our network can be trained from scratch even from a few aligned image pairs. The metric is validated on intersubject deformable registration on a dataset different from the one used for training, demonstrating good generalization. In this task, we outperform mutual information by a significant margin. version:1
arxiv-1609-05394 | Predicting Future Shanghai Stock Market Price using ANN in the Period 21-Sep-2016 to 11-Oct-2016 | http://arxiv.org/abs/1609.05394 | id:1609.05394 author:Barack Wamkaya Wanjawa category:cs.LG q-fin.ST  published:2016-09-17 summary:Predicting the prices of stocks at any stock market remains a quest for many investors and researchers. Those who trade at the stock market tend to use technical, fundamental or time series analysis in their predictions. These methods usually guide on trends and not the exact likely prices. It is for this reason that Artificial Intelligence systems, such as Artificial Neural Network, that is feedforward multi-layer perceptron with error backpropagation, can be used for such predictions. A difficulty in neural network application is the determination of suitable network parameters. A previous research by the author already determined the network parameters as 5:21:21:1 with 80% training data or 4-year of training data as a good enough model for stock prediction. This model has been put to the test in predicting selected Shanghai Stock Exchange stocks in the future period of 21-Sep-2016 to 11-Oct-2016, about one week after the publication of these predictions. The research aims at confirming that simple neural network systems can be quite powerful in typical stock market predictions. version:1
arxiv-1609-05388 | ADAGIO: Fast Data-aware Near-Isometric Linear Embeddings | http://arxiv.org/abs/1609.05388 | id:1609.05388 author:Jarosław Błasiok, Charalampos E. Tsourakakis category:stat.ML cs.LG  published:2016-09-17 summary:Many important applications, including signal reconstruction, parameter estimation, and signal processing in a compressed domain, rely on a low-dimensional representation of the dataset that preserves {\em all} pairwise distances between the data points and leverages the inherent geometric structure that is typically present. Recently Hedge, Sankaranarayanan, Yin and Baraniuk \cite{hedge2015} proposed the first data-aware near-isometric linear embedding which achieves the best of both worlds. However, their method NuMax does not scale to large-scale datasets. Our main contribution is a simple, data-aware, near-isometric linear dimensionality reduction method which significantly outperforms a state-of-the-art method \cite{hedge2015} with respect to scalability while achieving high quality near-isometries. Furthermore, our method comes with strong worst-case theoretical guarantees that allow us to guarantee the quality of the obtained near-isometry. We verify experimentally the efficiency of our method on numerous real-world datasets, where we find that our method ($<$10 secs) is more than 3\,000$\times$ faster than the state-of-the-art method \cite{hedge2015} ($>$9 hours) on medium scale datasets with 60\,000 data points in 784 dimensions. Finally, we use our method as a preprocessing step to increase the computational efficiency of a classification application and for speeding up approximate nearest neighbor queries. version:1
arxiv-1609-05374 | Extended Formulation for Online Learning of Combinatorial Objects | http://arxiv.org/abs/1609.05374 | id:1609.05374 author:Holakou Rahmanian, S. V. N. Vishwanathan, David P. Helmbold category:cs.LG  published:2016-09-17 summary:The convex hull of $n$-symbol Huffman trees is known to have exponentially many facets/constraints. This makes the standard on-line learning techniques for learning Huffman trees impractical, since they use multiplicative updates followed by projections to satisfy all of the constraints. However, there are general extended formulation techniques that encode the convex hull of Huffman trees as a polytope in a higher dimensional space with only polynomially many facets. This extended formulation methodology can also be used to encode the $n$-element permutahedron in $O(n \log n)$ dimensions with only a polynomial number of facets. We develop a general technique for converting these extended formulations into efficient on-line algorithms with good relative loss bounds. The resulting algorithms have nearly the same regret bounds as state of the art algorithms for permutations, and are the first efficient algorithms for the on-line learning of Huffman trees. version:1
arxiv-1609-05353 | Leveraging Environmental Correlations: The Thermodynamics of Requisite Variety | http://arxiv.org/abs/1609.05353 | id:1609.05353 author:Alexander B. Boyd, Dibyendu Mandal, James P. Crutchfield category:cond-mat.stat-mech cs.IT cs.LG math.DS math.IT nlin.AO  published:2016-09-17 summary:Key to biological success, the requisite variety that confronts an adaptive organism is the set of detectable, accessible, and controllable states in its environment. We analyze its role in the thermodynamic functioning of information ratchets---a form of autonomous Maxwellian Demon capable of exploiting fluctuations in an external information reservoir to harvest useful work from a thermal bath. This establishes a quantitative paradigm for understanding how adaptive agents leverage structured thermal environments for their own thermodynamic benefit. General ratchets behave as memoryful communication channels, interacting with their environment sequentially and storing results to an output. The bulk of thermal ratchets analyzed to date, however, assume memoryless environments that generate input signals without temporal correlations. Employing computational mechanics and a new information-processing Second Law of Thermodynamics (IPSL) we remove these restrictions, analyzing general finite-state ratchets interacting with structured environments that generate correlated input signals. On the one hand, we demonstrate that a ratchet need not have memory to exploit an uncorrelated environment. On the other, and more appropriate to biological adaptation, we show that a ratchet must have memory to most effectively leverage structure and correlation in its environment. The lesson is that to optimally harvest work a ratchet's memory must reflect the input generator's memory. Finally, we investigate achieving the IPSL bounds on the amount of work a ratchet can extract from its environment, discovering that finite-state, optimal ratchets are unable to reach these bounds. In contrast, we show that infinite-state ratchets can go well beyond these bounds by utilizing their own infinite "negentropy". We conclude with an outline of the collective thermodynamics of information-ratchet swarms. version:1
arxiv-1609-05342 | Fast and Effective Algorithms for Symmetric Nonnegative Matrix Factorization | http://arxiv.org/abs/1609.05342 | id:1609.05342 author:Reza Borhani, Jeremy Watt, Aggelos Katsaggelos category:cs.CV cs.LG stat.ML  published:2016-09-17 summary:Symmetric Nonnegative Matrix Factorization (SNMF) models arise naturally as simple reformulations of many standard clustering algorithms including the popular spectral clustering method. Recent work has demonstrated that an elementary instance of SNMF provides superior clustering quality compared to many classic clustering algorithms on a variety of synthetic and real world data sets. In this work, we present novel reformulations of this instance of SNMF based on the notion of variable splitting and produce two fast and effective algorithms for its optimization using i) the provably convergent Accelerated Proximal Gradient (APG) procedure and ii) a heuristic version of the Alternating Direction Method of Multipliers (ADMM) framework. Our two algorithms present an interesting tradeoff between computational speed and mathematical convergence guarantee: while the former method is provably convergent it is considerably slower than the latter approach, for which we also provide significant but less stringent mathematical proof regarding its convergence. Through extensive experiments we show not only that the efficacy of these approaches is equal to that of the state of the art SNMF algorithm, but also that the latter of our algorithms is extremely fast being one to two orders of magnitude faster in terms of total computation time than the state of the art approach, outperforming even spectral clustering in terms of computation time on large data sets. version:1
arxiv-1609-05317 | Deep Kinematic Pose Regression | http://arxiv.org/abs/1609.05317 | id:1609.05317 author:Xingyi Zhou, Xiao Sun, Wei Zhang, Shuang Liang, Yichen Wei category:cs.CV  published:2016-09-17 summary:Learning articulated object pose is inherently difficult because the pose is high dimensional but has many structural constraints. Most existing work do not model such constraints and does not guarantee the geometric validity of their pose estimation, therefore requiring a post-processing to recover the correct geometry if desired, which is cumbersome and sub-optimal. In this work, we propose to directly embed a kinematic object model into the deep neutral network learning for general articulated object pose estimation. The kinematic function is defined on the appropriately parameterized object motion variables. It is differentiable and can be used in the gradient descent based optimization in network training. The prior knowledge on the object geometric model is fully exploited and the structure is guaranteed to be valid. We show convincing experiment results on a toy example and the 3D human pose estimation problem. For the latter we achieve state-of-the-art result on Human3.6M dataset. version:1
arxiv-1609-05296 | Development of a Fuzzy Expert System based Liveliness Detection Scheme for Biometric Authentication | http://arxiv.org/abs/1609.05296 | id:1609.05296 author:Avinash Kumar Singh, Piyush Joshi, G C Nandi category:cs.CV  published:2016-09-17 summary:Liveliness detection acts as a safe guard against spoofing attacks. Most of the researchers used vision based techniques to detect liveliness of the user, but they are highly sensitive to illumination effects. Therefore it is very hard to design a system, which will work robustly under all circumstances. Literature shows that most of the research utilize eye blink or mouth movement to detect the liveliness, while the other group used face texture to distinguish between real and imposter. The classification results of all these approaches decreases drastically in variable light conditions. Hence in this paper we are introducing fuzzy expert system which is sufficient enough to handle most of the cases comes in real time. We have used two testing parameters, (a) under bad illumination and (b) less movement in eyes and mouth in case of real user to evaluate the performance of the system. The system is behaving well in all, while in first case its False Rejection Rate (FRR) is 0.28, and in second case its FRR is 0.4. version:1
arxiv-1609-05284 | ReasoNet: Learning to Stop Reading in Machine Comprehension | http://arxiv.org/abs/1609.05284 | id:1609.05284 author:Yelong Shen, Po-Sen Huang, Jianfeng Gao, Weizhu Chen category:cs.LG cs.NE  published:2016-09-17 summary:Teaching a computer to read a document and answer general questions pertaining to the document is a challenging yet unsolved problem. In this paper, we describe a novel neural network architecture called Reasoning Network ({ReasoNet}) for machine comprehension tasks. ReasoNet makes use of multiple turns to effectively exploit and then reason over the relation among queries, documents, and answers. Different from previous approaches using a fixed number of turns during inference, ReasoNet introduces a termination state to relax this constraint on the reasoning depth. With the use of reinforcement learning, ReasoNet can dynamically determine whether to continue the comprehension process after digesting intermediate results, or to terminate reading when it concludes that existing information is adequate to produce an answer. ReasoNet has achieved state-of-the-art performance in machine comprehension datasets, including unstructured CNN and Daily Mail datasets, and a structured Graph Reachability dataset. version:1
arxiv-1609-03348 | A Threshold-based Scheme for Reinforcement Learning in Neural Networks | http://arxiv.org/abs/1609.03348 | id:1609.03348 author:Thomas H. Ward category:cs.LG cs.NE  published:2016-09-12 summary:A generic and scalable Reinforcement Learning scheme for Artificial Neural Networks is presented, providing a general purpose learning machine. By reference to a node threshold three features are described 1) A mechanism for Primary Reinforcement, capable of solving linearly inseparable problems 2) The learning scheme is extended to include a mechanism for Conditioned Reinforcement, capable of forming long term strategy 3) The learning scheme is modified to use a threshold-based deep learning algorithm, providing a robust and biologically inspired alternative to backpropagation. The model may be used for supervised as well as unsupervised training regimes. version:2
arxiv-1609-05281 | GeThR-Net: A Generalized Temporally Hybrid Recurrent Neural Network for Multimodal Information Fusion | http://arxiv.org/abs/1609.05281 | id:1609.05281 author:Ankit Gandhi, Arjun Sharma, Arijit Biswas, Om Deshmukh category:cs.CV  published:2016-09-17 summary:Data generated from real world events are usually temporal and contain multimodal information such as audio, visual, depth, sensor etc. which are required to be intelligently combined for classification tasks. In this paper, we propose a novel generalized deep neural network architecture where temporal streams from multiple modalities are combined. There are total M+1 (M is the number of modalities) components in the proposed network. The first component is a novel temporally hybrid Recurrent Neural Network (RNN) that exploits the complimentary nature of the multimodal temporal information by allowing the network to learn both modality specific temporal dynamics as well as the dynamics in a multimodal feature space. M additional components are added to the network which extract discriminative but non-temporal cues from each modality. Finally, the predictions from all of these components are linearly combined using a set of automatically learned weights. We perform exhaustive experiments on three different datasets spanning four modalities. The proposed network is relatively 3.5%, 5.7% and 2% better than the best performing temporal multimodal baseline for UCF-101, CCV and Multimodal Gesture datasets respectively. version:1
arxiv-1609-05258 | The ACRV Picking Benchmark (APB): A Robotic Shelf Picking Benchmark to Foster Reproducible Research | http://arxiv.org/abs/1609.05258 | id:1609.05258 author:Jürgen Leitner, Adam W. Tow, Jake E. Dean, Niko Suenderhauf, Joseph W. Durham, Matthew Cooper, Markus Eich, Christopher Lehnert, Ruben Mangels, Christopher McCool, Peter Kujala, Lachlan Nicholson, Trung Pham, James Sergeant, Fangyi Zhang, Ben Upcroft, Peter Corke category:cs.RO cs.AI cs.CV cs.SY  published:2016-09-17 summary:Robotic challenges like the Amazon Picking Challenge (APC) or the DARPA Challenges are an established and important way to drive scientific progress as they make research comparable on a well-defined benchmark with equal test conditions for all participants. However, such challenge events occur only occasionally, are limited to a small number of contestants, and the test conditions are very difficult to replicate after the main event. We present a new physical benchmark challenge for robotic picking. The ACRV Picking Benchmark is designed to be reproducible by using a set of 42 common objects, a widely available shelf, and exact guidelines for object arrangement using stencils. A well-defined evaluation protocol enables the comparability of complete robotic systems -- including perception and manipulation -- instead of sub-systems only. Our paper describes this new benchmark challenge and presents results acquired by a baseline system based on a Baxter robot. version:1
arxiv-1609-05257 | A convolutional approach to reflection symmetry | http://arxiv.org/abs/1609.05257 | id:1609.05257 author:Marcelo Cicconet, Vighnesh Birodkar, Mads Lund, Michael Werman, Davi Geiger category:cs.CV  published:2016-09-17 summary:We present a convolutional approach to reflection symmetry detection in 2D. Our model, built on the products of complex-valued wavelet convolutions, simplifies previous edge-based pairwise methods. Being parameter-centered, as opposed to feature-centered, it has certain computational advantages when the object sizes are known a priori, as demonstrated in an ellipse detection application. The method outperforms the best-performing algorithm on the CVPR 2013 Symmetry Detection Competition Database in the single-symmetry case. Code and a new database for 2D symmetry detection is available. version:1
arxiv-1609-00680 | Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model | http://arxiv.org/abs/1609.00680 | id:1609.00680 author:Sheng Wang, Siqi Sun, Zhen Li, Renyu Zhang, Jinbo Xu category:q-bio.BM cs.LG q-bio.QM stat.ML  published:2016-09-02 summary:Recently exciting progress has been made on protein contact prediction, but the predicted contacts for proteins without many sequence homologs is still of low quality and not very useful for de novo structure prediction. This paper presents a new deep learning method that predicts contacts by integrating both evolutionary coupling (EC) and sequence conservation information through an ultra-deep neural network formed by two deep residual networks. This deep neural network allows us to model very complex sequence-contact relationship as well as long-range inter-contact correlation. Our method greatly outperforms existing contact prediction methods and leads to much more accurate contact-assisted protein folding. Tested on three datasets of 579 proteins, the average top L long-range prediction accuracy obtained our method, the representative EC method CCMpred and the CASP11 winner MetaPSICOV is 0.47, 0.21 and 0.30, respectively; the average top L/10 long-range accuracy of our method, CCMpred and MetaPSICOV is 0.77, 0.47 and 0.59, respectively. Ab initio folding using our predicted contacts as restraints can yield correct folds (i.e., TMscore>0.6) for 203 test proteins, while that using MetaPSICOV- and CCMpred-predicted contacts can do so for only 79 and 62 proteins, respectively. Further, our contact-assisted models have much better quality than template-based models. Using our predicted contacts as restraints, we can (ab initio) fold 208 of the 398 membrane proteins with TMscore>0.5. By contrast, when the training proteins of our method are used as templates, homology modeling can only do so for 10 of them. One interesting finding is that even if we do not train our prediction models with any membrane proteins, our method works very well on membrane protein prediction. Finally, in recent CAMEO benchmark our method successfully folded a mainly-beta protein of 182 residues with a novel fold. version:4
arxiv-1609-05244 | Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis | http://arxiv.org/abs/1609.05244 | id:1609.05244 author:Haohan Wang, Aaksha Meghawat, Louis-Philippe Morency, Eric P. Xing category:cs.CL cs.IR  published:2016-09-16 summary:Multimodal sentiment analysis is drawing an increasing amount of attention these days. It enables mining of opinions in video reviews and surveys which are now available aplenty on online platforms like YouTube. However, the limited number of high-quality multimodal sentiment data samples may introduce the problem of the sentiment being dependent on the individual specific features in the dataset. This results in a lack of generalizability of the trained models for classification on larger online platforms. In this paper, we first examine the data and verify the existence of this dependence problem. Then we propose a Select-Additive Learning (SAL) procedure that improves the generalizability of trained discriminative neural networks. SAL is a two-phase learning method. In Selection phase, it selects the confounding learned representation. In Addition phase, it forces the classifier to discard confounded representations by adding Gaussian noise. In our experiments, we show how SAL improves the generalizability of state-of-the-art models. We increase prediction accuracy significantly in all three modalities (text, audio, video), as well as in their fusion. We show how SAL, even when trained on one dataset, achieves good accuracy across test datasets. version:1
arxiv-1609-05234 | Interactive Spoken Content Retrieval by Deep Reinforcement Learning | http://arxiv.org/abs/1609.05234 | id:1609.05234 author:Yen-Chen Wu, Tzu-Hsiang Lin, Yang-De Chen, Hung-Yi Lee, Lin-Shan Lee category:cs.CL cs.IR  published:2016-09-16 summary:User-machine interaction is important for spoken content retrieval. For text content retrieval, the user can easily scan through and select on a list of retrieved item. This is impossible for spoken content retrieval, because the retrieved items are difficult to show on screen. Besides, due to the high degree of uncertainty for speech recognition, the retrieval results can be very noisy. One way to counter such difficulties is through user-machine interaction. The machine can take different actions to interact with the user to obtain better retrieval results before showing to the user. The suitable actions depend on the retrieval status, for example requesting for extra information from the user, returning a list of topics for user to select, etc. In our previous work, some hand-crafted states estimated from the present retrieval results are used to determine the proper actions. In this paper, we propose to use Deep-Q-Learning techniques instead to determine the machine actions for interactive spoken content retrieval. Deep-Q-Learning bypasses the need for estimation of the hand-crafted states, and directly determine the best action base on the present retrieval status even without any human knowledge. It is shown to achieve significantly better performance compared with the previous hand-crafted states. version:1
arxiv-1609-05191 | Gradient Descent Learns Linear Dynamical Systems | http://arxiv.org/abs/1609.05191 | id:1609.05191 author:Moritz Hardt, Tengyu Ma, Benjamin Recht category:cs.LG cs.DS math.OC stat.ML  published:2016-09-16 summary:We prove that gradient descent efficiently converges to the global optimizer of the maximum likelihood objective of an unknown linear time-invariant dynamical system from a sequence of noisy observations generated by the system. Even though the objective function is non-convex, we provide polynomial running time and sample complexity bounds under strong but natural assumptions. Linear systems identification has been studied for many decades, yet, to the best of our knowledge, these are the first polynomial guarantees for the problem we consider. version:1
arxiv-1609-05181 | Information Theoretic Limits of Data Shuffling for Distributed Learning | http://arxiv.org/abs/1609.05181 | id:1609.05181 author:Mohamed Attia, Ravi Tandon category:cs.IT cs.DC cs.LG math.IT  published:2016-09-16 summary:Data shuffling is one of the fundamental building blocks for distributed learning algorithms, that increases the statistical gain for each step of the learning process. In each iteration, different shuffled data points are assigned by a central node to a distributed set of workers to perform local computations, which leads to communication bottlenecks. The focus of this paper is on formalizing and understanding the fundamental information-theoretic trade-off between storage (per worker) and the worst-case communication overhead for the data shuffling problem. We completely characterize the information theoretic trade-off for $K=2$, and $K=3$ workers, for any value of storage capacity, and show that increasing the storage across workers can reduce the communication overhead by leveraging coding. We propose a novel and systematic data delivery and storage update strategy for each data shuffle iteration, which preserves the structural properties of the storage across the workers, and aids in minimizing the communication overhead in subsequent data shuffling iterations. version:1
arxiv-1609-05180 | Grammatical Templates: Improving Text Difficulty Evaluation for Language Learners | http://arxiv.org/abs/1609.05180 | id:1609.05180 author:Shuhan Wang, Erik Andersen category:cs.CL cs.AI  published:2016-09-16 summary:Language students are most engaged while reading texts at an appropriate difficulty level. However, existing methods of evaluating text difficulty focus mainly on vocabulary and do not prioritize grammatical features, hence they do not work well for language learners with limited knowledge of grammar. In this paper, we introduce grammatical templates, the expert-identified units of grammar that students learn from class, as an important feature of text difficulty evaluation. Experimental classification results show that grammatical template features significantly improve text difficulty prediction accuracy over baseline readability features by 7.4%. Moreover, we build a simple and human-understandable text difficulty evaluation approach with 87.7% accuracy, using only 5 grammatical template features. version:1
arxiv-1609-05162 | No-Regret Replanning under Uncertainty | http://arxiv.org/abs/1609.05162 | id:1609.05162 author:Wen Sun, Niteesh Sood, Debadeepta Dey, Gireeja Ranade, Siddharth Prakash, Ashish Kapoor category:cs.RO cs.LG  published:2016-09-16 summary:This paper explores the problem of path planning under uncertainty. Specifically, we consider online receding horizon based planners that need to operate in a latent environment where the latent information can be modeled via Gaussian Processes. Online path planning in latent environments is challenging since the robot needs to explore the environment to get a more accurate model of latent information for better planning later and also achieves the task as quick as possible. We propose UCB style algorithms that are popular in the bandit settings and show how those analyses can be adapted to the online robotic path planning problems. The proposed algorithm trades-off exploration and exploitation in near-optimal manner and has appealing no-regret properties. We demonstrate the efficacy of the framework on the application of aircraft flight path planning when the winds are partially observed. version:1
arxiv-1609-05148 | Discovering Relationships Across Disparate Data Modalities | http://arxiv.org/abs/1609.05148 | id:1609.05148 author:Cencheng Shen, Carey E. Priebe, Mauro Maggioni, Joshua T. Vogelstein category:stat.ML  published:2016-09-16 summary:Discovering whether certain properties are associated with other properties is fundamental to all science. As the amount of data increases, it is becoming increasingly difficult and important to determine whether one property of the data (e.g., cloud density) is related to another (e.g., grass wetness). Only If they are related does it make sense to further investigate the nature of the relationship. Unfortunately, reliably identifying relationships can be challenging, especially when the properties themselves are complex and the relationship is nonlinear and high-dimensional. Here, we describe a procedure, Multiscale Generalized Correlation (MGC), that addresses these challenges. Our key insight is that if two properties are related, comparisons between measurements of similar pairs of the first property (e.g., two clouds of similar density) should be correlated with the comparisons between corresponding measurements of the second property (grass wetness under those clouds). We demonstrate the statistical and computational efficiency of MGC in both simulations and theory. We then apply it to detect the presence and nature of the relationships between brain activity and personality, brain shape and disorder, and brain connectivity and creativity. Finally, we demonstrate that MGC does not suffer from the false positives that have plagued parametric methods. Our open source implementation of MGC is applicable to fundamental questions confronting science, government, finance, and many other disciplines. version:1
arxiv-1609-05143 | Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning | http://arxiv.org/abs/1609.05143 | id:1609.05143 author:Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph J. Lim, Abhinav Gupta, Li Fei-Fei, Ali Farhadi category:cs.CV  published:2016-09-16 summary:Two less addressed issues of deep reinforcement learning are (1) lack of generalization capability to new target goals, and (2) data inefficiency i.e., the model requires several (and often costly) episodes of trial and error to converge, which makes it impractical to be applied to real-world scenarios. In this paper, we address these two issues and apply our model to the task of target-driven visual navigation. To address the first issue, we propose an actor-critic model whose policy is a function of the goal as well as the current state, which allows to better generalize. To address the second issue, we propose AI2-THOR framework, which provides an environment with high-quality 3D scenes and physics engine. Our framework enables agents to take actions and interact with objects. Hence, we can collect a huge number of training samples efficiently. We show that our proposed method (1) converges faster than the state-of-the-art deep reinforcement learning methods, (2) generalizes across targets and across scenes, (3) generalizes to a real robot scenario with a small amount of fine-tuning (although the model is trained in simulation), (4) is end-to-end trainable and does not need feature engineering, feature matching between frames or 3D reconstruction of the environment. The supplementary video can be accessed at the following link: https://youtu.be/SmBxMDiOrvs. version:1
arxiv-1609-05123 | Learning Opposites Using Neural Networks | http://arxiv.org/abs/1609.05123 | id:1609.05123 author:Shivam Kalra, Aditya Sriram, Shahryar Rahnamayan, H. R. Tizhoosh category:cs.LG cs.NE  published:2016-09-16 summary:Many research works have successfully extended algorithms such as evolutionary algorithms, reinforcement agents and neural networks using "opposition-based learning" (OBL). Two types of the "opposites" have been defined in the literature, namely \textit{type-I} and \textit{type-II}. The former are linear in nature and applicable to the variable space, hence easy to calculate. On the other hand, type-II opposites capture the "oppositeness" in the output space. In fact, type-I opposites are considered a special case of type-II opposites where inputs and outputs have a linear relationship. However, in many real-world problems, inputs and outputs do in fact exhibit a nonlinear relationship. Therefore, type-II opposites are expected to be better in capturing the sense of "opposition" in terms of the input-output relation. In the absence of any knowledge about the problem at hand, there seems to be no intuitive way to calculate the type-II opposites. In this paper, we introduce an approach to learn type-II opposites from the given inputs and their outputs using the artificial neural networks (ANNs). We first perform \emph{opposition mining} on the sample data, and then use the mined data to learn the relationship between input $x$ and its opposite $\breve{x}$. We have validated our algorithm using various benchmark functions to compare it against an evolving fuzzy inference approach that has been recently introduced. The results show the better performance of a neural approach to learn the opposites. This will create new possibilities for integrating oppositional schemes within existing algorithms promising a potential increase in convergence speed and/or accuracy. version:1
arxiv-1609-05119 | Deep Impression: Audiovisual Deep Residual Networks for Multimodal Apparent Personality Trait Recognition | http://arxiv.org/abs/1609.05119 | id:1609.05119 author:Yağmur Güçlütürk, Umut Güçlü, Marcel A. J. van Gerven, Rob van Lier category:cs.CV  published:2016-09-16 summary:Here, we develop an audiovisual deep residual network for multimodal apparent personality trait recognition. The network is trained end-to-end for predicting the Big Five personality traits of people from their videos. That is, the network does not require any feature engineering or visual analysis such as face detection, face landmark alignment or facial expression recognition. Recently, the network won the third place in the ChaLearn First Impressions Challenge with a test accuracy of 0.9109. version:1
arxiv-1609-05118 | Radon-Gabor Barcodes for Medical Image Retrieval | http://arxiv.org/abs/1609.05118 | id:1609.05118 author:Mina Nouredanesh, H. R. Tizhoosh, Ershad Banijamali, James Tung category:cs.CV  published:2016-09-16 summary:In recent years, with the explosion of digital images on the Web, content-based retrieval has emerged as a significant research area. Shapes, textures, edges and segments may play a key role in describing the content of an image. Radon and Gabor transforms are both powerful techniques that have been widely studied to extract shape-texture-based information. The combined Radon-Gabor features may be more robust against scale/rotation variations, presence of noise, and illumination changes. The objective of this paper is to harness the potentials of both Gabor and Radon transforms in order to introduce expressive binary features, called barcodes, for image annotation/tagging tasks. We propose two different techniques: Gabor-of-Radon-Image Barcodes (GRIBCs), and Guided-Radon-of-Gabor Barcodes (GRGBCs). For validation, we employ the IRMA x-ray dataset with 193 classes, containing 12,677 training images and 1,733 test images. A total error score as low as 322 and 330 were achieved for GRGBCs and GRIBCs, respectively. This corresponds to $\approx 81\%$ retrieval accuracy for the first hit. version:1
arxiv-1609-05115 | Dense Wide-Baseline Scene Flow From Two Handheld Video Cameras | http://arxiv.org/abs/1609.05115 | id:1609.05115 author:Christian Richardt, Hyeongwoo Kim, Levi Valgaerts, Christian Theobalt category:cs.CV  published:2016-09-16 summary:We propose a new technique for computing dense scene flow from two handheld videos with wide camera baselines and different photometric properties due to different sensors or camera settings like exposure and white balance. Our technique innovates in two ways over existing methods: (1) it supports independently moving cameras, and (2) it computes dense scene flow for wide-baseline scenarios.We achieve this by combining state-of-the-art wide-baseline correspondence finding with a variational scene flow formulation. First, we compute dense, wide-baseline correspondences using DAISY descriptors for matching between cameras and over time. We then detect and replace occluded pixels in the correspondence fields using a novel edge-preserving Laplacian correspondence completion technique. We finally refine the computed correspondence fields in a variational scene flow formulation. We show dense scene flow results computed from challenging datasets with independently moving, handheld cameras of varying camera settings. version:1
arxiv-1609-05112 | Barcodes for Medical Image Retrieval Using Autoencoded Radon Transform | http://arxiv.org/abs/1609.05112 | id:1609.05112 author:Hamid R. Tizhoosh, Christopher Mitcheltree, Shujin Zhu, Shamak Dutta category:cs.CV  published:2016-09-16 summary:Using content-based binary codes to tag digital images has emerged as a promising retrieval technology. Recently, Radon barcodes (RBCs) have been introduced as a new binary descriptor for image search. RBCs are generated by binarization of Radon projections and by assembling them into a vector, namely the barcode. A simple local thresholding has been suggested for binarization. In this paper, we put forward the idea of "autoencoded Radon barcodes". Using images in a training dataset, we autoencode Radon projections to perform binarization on outputs of hidden layers. We employed the mini-batch stochastic gradient descent approach for the training. Each hidden layer of the autoencoder can produce a barcode using a threshold determined based on the range of the logistic function used. The compressing capability of autoencoders apparently reduces the redundancies inherent in Radon projections leading to more accurate retrieval results. The IRMA dataset with 14,410 x-ray images is used to validate the performance of the proposed method. The experimental results, containing comparison with RBCs, SURF and BRISK, show that autoencoded Radon barcode (ARBC) has the capacity to capture important information and to learn richer representations resulting in lower retrieval errors for image retrieval measured with the accuracy of the first hit only. version:1
arxiv-1609-05104 | Intrinsic-cum-extrinsic normalization of formant data of vowels | http://arxiv.org/abs/1609.05104 | id:1609.05104 author:T. V. Ananthapadmanabha, A. G. Ramakrishnan category:cs.SD cs.CL  published:2016-09-16 summary:Using a known speaker-intrinsic normalization procedure, formant data are scaled by the reciprocal of the geometric mean of the first three formant frequencies. This reduces the influence of the talker but results in a distorted vowel space. The proposed speaker-extrinsic procedure re-scales the normalized values by the mean formant values of vowels. When tested on the formant data of vowels published by Peterson and Barney, the combined approach leads to well separated clusters by reducing the spread due to talkers. The proposed procedure performs better than two top-ranked normalization procedures based on the accuracy of vowel classification as the objective measure. version:1
arxiv-1609-05058 | A Formal Solution to the Grain of Truth Problem | http://arxiv.org/abs/1609.05058 | id:1609.05058 author:Jan Leike, Jessica Taylor, Benya Fallenstein category:cs.AI cs.GT cs.LG  published:2016-09-16 summary:A Bayesian agent acting in a multi-agent environment learns to predict the other agents' policies if its prior assigns positive probability to them (in other words, its prior contains a \emph{grain of truth}). Finding a reasonably large class of policies that contains the Bayes-optimal policies with respect to this class is known as the \emph{grain of truth problem}. Only small classes are known to have a grain of truth and the literature contains several related impossibility results. In this paper we present a formal and general solution to the full grain of truth problem: we construct a class of policies that contains all computable policies as well as Bayes-optimal policies for every lower semicomputable prior over the class. When the environment is unknown, Bayes-optimal agents may fail to act optimally even asymptotically. However, agents based on Thompson sampling converge to play {\epsilon}-Nash equilibria in arbitrary unknown computable multi-agent environments. While these results are purely theoretical, we show that they can be computationally approximated arbitrarily closely. version:1
arxiv-1609-05057 | Unbiased Sparse Subspace Clustering By Selective Pursuit | http://arxiv.org/abs/1609.05057 | id:1609.05057 author:Hanno Ackermann, Michael Yang, Bodo Rosenhahn category:stat.ML  published:2016-09-16 summary:Sparse subspace clustering (SSC) is an elegant approach for unsupervised segmentation if the data points of each cluster are located in linear subspaces. This model applies, for instance, in motion segmentation if some restrictions on the camera model hold. SSC requires that problems based on the $l_1$-norm are solved to infer which points belong to the same subspace. If these unknown subspaces are well-separated this algorithm is guaranteed to succeed. The algorithm rests upon the assumption that points on the same subspace are well spread. The question what happens if this condition is violated has not yet been investigated. In this work, the effect of particular distributions on the same subspace will be analyzed. It will be shown that SSC fails to infer correct labels if points on the same subspace fall into more than one cluster. version:1
arxiv-1603-03833 | Learning real manipulation tasks from virtual demonstrations using LSTM | http://arxiv.org/abs/1603.03833 | id:1603.03833 author:Rouhollah Rahmatizadeh, Pooya Abolghasemi, Aman Behal, Ladislau Bölöni category:cs.RO cs.AI cs.LG  published:2016-03-12 summary:Robots assisting disabled or elderly people in activities of daily living must perform complex manipulation tasks. These tasks are dependent on the user's environment and preferences. Thus, learning from demonstration (LfD) is a promising choice that would allow the non-expert user to teach the robot different tasks. Unfortunately, learning general solutions from raw demonstrations requires a significant amount of data. Performing this number of physical demonstrations is unfeasible for a disabled user. In this paper we propose an approach where the user demonstrates the manipulation task in a virtual environment. The collected demonstrations are used to train an LSTM recurrent neural network that can act as the controller for the robot. We show that the controller learned from virtual demonstrations can be used to successfully perform the manipulation tasks on a physical robot. version:2
arxiv-1610-00574 | Cosine Similarity Search with Multi Index Hashing | http://arxiv.org/abs/1610.00574 | id:1610.00574 author:Sepehr Eghbali, Ladan Tahvildari category:cs.DB cs.DS cs.IR cs.LG  published:2016-09-14 summary:Due to rapid development of the Internet, recent years have witnessed an explosion in the rate of data generation. Dealing with data at current scales brings up unprecedented challenges. From the algorithmic view point, executing existing linear algorithms in information retrieval and machine learning on such tremendous amounts of data incur intolerable computational and storage costs. To address this issue, there is a growing interest to map data points in large-scale datasets to binary codes. This can significantly reduce the storage complexity of large-scale datasets. However, one of the most compelling reasons for using binary codes or any discrete representation is that they can be used as direct indices into a hash table. Incorporating hash table offers fast query execution; one can look up the nearby buckets in a hash table populated with binary codes to retrieve similar items. Nonetheless, if binary codes are compared in terms of the cosine similarity rather than the Hamming distance, there is no fast exact sequential procedure to find the $K$ closest items to the query other than the exhaustive search. Given a large dataset of binary codes and a binary query, the problem that we address is to efficiently find $K$ closest codes in the dataset that yield the largest cosine similarities to the query. To handle this issue, we first elaborate on the relation between the Hamming distance and the cosine similarity. This allows finding the sequence of buckets to check in the hash table. Having this sequence, we propose a multi-index hashing approach that can increase the search speed up to orders of magnitude in comparison to the exhaustive search and even approximation methods such as LSH. We empirically evaluate the performance of the proposed algorithm on real world datasets. version:1
arxiv-1609-07472 | Gated Neural Networks for Option Pricing: Rationality by Design | http://arxiv.org/abs/1609.07472 | id:1609.07472 author:Yongxin Yang, Yu Zheng, Timothy M. Hospedales category:q-fin.CP cs.LG q-fin.PR  published:2016-09-14 summary:We propose a neural network approach to price EU call options that significantly outperforms some existing pricing models and comes with guarantees that its predictions are economically reasonable. To achieve this, we introduce a class of gated neural networks that automatically learn to divide-and-conquer the problem space for robust and accurate pricing. We then derive instantiations of these networks that are 'rational by design' in terms of naturally encoding a valid call option surface that enforces no arbitrage principles. This integration of human insight within data-driven learning provides significantly better generalisation in pricing performance due to the encoded inductive bias in the learning, guarantees sanity in the model's predictions, and provides econometrically useful byproduct such as risk neutral density. version:1
arxiv-1610-00029 | Microscopic Pedestrian Flow Characteristics: Development of an Image Processing Data Collection and Simulation Model | http://arxiv.org/abs/1610.00029 | id:1610.00029 author:Kardi Teknomo category:cs.CV  published:2016-09-06 summary:Microscopic pedestrian studies consider detailed interaction of pedestrians to control their movement in pedestrian traffic flow. The tools to collect the microscopic data and to analyze microscopic pedestrian flow are still very much in its infancy. The microscopic pedestrian flow characteristics need to be understood. Manual, semi manual and automatic image processing data collection systems were developed. It was found that the microscopic speed resemble a normal distribution with a mean of 1.38 m/second and standard deviation of 0.37 m/second. The acceleration distribution also bear a resemblance to the normal distribution with an average of 0.68 m/ square second. A physical based microscopic pedestrian simulation model was also developed. Both Microscopic Video Data Collection and Microscopic Pedestrian Simulation Model generate a database called NTXY database. The formulations of the flow performance or microscopic pedestrian characteristics are explained. Sensitivity of the simulation and relationship between the flow performances are described. Validation of the simulation using real world data is then explained through the comparison between average instantaneous speed distributions of the real world data with the result of the simulations. The simulation model is then applied for some experiments on a hypothetical situation to gain more understanding of pedestrian behavior in one way and two way situations, to know the behavior of the system if the number of elderly pedestrian increases and to evaluate a policy of lane-like segregation toward pedestrian crossing and inspects the performance of the crossing. It was revealed that the microscopic pedestrian studies have been successfully applied to give more understanding to the behavior of microscopic pedestrians flow, predict the theoretical and practical situation and evaluate some design policies before its implementation. version:1
