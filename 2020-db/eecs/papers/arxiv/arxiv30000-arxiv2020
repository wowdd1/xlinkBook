arxiv-1703-06130 | Communication Primitives in Cognitive Radio Networks | http://arxiv.org/abs/1703.06130 | id:1703.06130 author:Seth Gilbert, Fabian Kuhn, Chaodong Zheng category:cs.DC  published:2017-03-17 summary:Cognitive radio networks are a new type of multi-channel wireless network in which different nodes can have access to different sets of channels. By providing multiple channels, they improve the efficiency and reliability of wireless communication. However, the heterogeneous nature of cognitive radio networks also brings new challenges to the design and analysis of distributed algorithms. In this paper, we focus on two fundamental problems in cognitive radio networks: neighbor discovery, and global broadcast. We consider a network containing $n$ nodes, each of which has access to $c$ channels. We assume the network has diameter $D$, and each pair of neighbors have at least $k\geq 1$, and at most $k_{max}\leq c$, shared channels. We also assume each node has at most $\Delta$ neighbors. For the neighbor discovery problem, we design a randomized algorithm CSeek which has time complexity $\tilde{O}((c^2/k)+(k_{max}/k)\cdot\Delta)$. CSeek is flexible and robust, which allows us to use it as a generic "filter" to find "well-connected" neighbors with an even shorter running time. We then move on to the global broadcast problem, and propose CGCast, a randomized algorithm which takes $\tilde{O}((c^2/k)+(k_{max}/k)\cdot\Delta+D\cdot\Delta)$ time. CGCast uses CSeek to achieve communication among neighbors, and uses edge coloring to establish an efficient schedule for fast message dissemination. Towards the end of the paper, we give lower bounds for solving the two problems. These lower bounds demonstrate that in many situations, CSeek and CGCast are near optimal. version:1
arxiv-1502-00089 | Efficiently Testing T-Interval Connectivity in Dynamic Graphs | http://arxiv.org/abs/1502.00089 | id:1502.00089 author:Arnaud Casteigts, Ralf Klasing, Yessin M. Neggaz, Joseph G. Peters category:cs.DS cs.DC  published:2015-01-31 summary:Many types of dynamic networks are made up of durable entities whose links evolve over time. When considered from a {\em global} and {\em discrete} standpoint, these networks are often modelled as evolving graphs, i.e. a sequence of graphs ${\cal G}=(G_1,G_2,...,G_{\delta})$ such that $G_i=(V,E_i)$ represents the network topology at time step $i$. Such a sequence is said to be $T$-interval connected if for any $t\in [1, \delta-T+1]$ all graphs in $\{G_t,G_{t+1},...,G_{t+T-1}\}$ share a common connected spanning subgraph. In this paper, we consider the problem of deciding whether a given sequence ${\cal G}$ is $T$-interval connected for a given $T$. We also consider the related problem of finding the largest $T$ for which a given ${\cal G}$ is $T$-interval connected. We assume that the changes between two consecutive graphs are arbitrary, and that two operations, {\em binary intersection} and {\em connectivity testing}, are available to solve the problems. We show that $\Omega(\delta)$ such operations are required to solve both problems, and we present optimal $O(\delta)$ online algorithms for both problems. We extend our online algorithms to a dynamic setting in which connectivity is based on the recent evolution of the network. version:3
arxiv-1608-08472 | ALLSAT compressed with wildcards. Part 1: Converting CNF's to orthogonal DNF's | http://arxiv.org/abs/1608.08472 | id:1608.08472 author:Marcel Wild category:cs.AI cs.LO  published:2016-08-30 summary:For most branching algorithms in Boolean logic "branching" means "variable-wise branching". We present the apparently novel technique of clause-wise branching, which is used to solve the ALLSAT problem for arbitrary Boolean functions in CNF format. Specifically, it converts a CNF into an orthogonal DNF, i.e. into an exclusive sum of products. Our method is enhanced by two ingredients: The use of a good SAT-solver and wildcards beyond the common don't-care symbol. version:2
arxiv-1703-06058 | Computation Peer Offloading for Energy-Constrained Mobile Edge Computing in Small-Cell Networks | http://arxiv.org/abs/1703.06058 | id:1703.06058 author:Lixing Chen, Sheng Zhou, Jie Xu category:cs.GT cs.DC  published:2017-03-17 summary:The (ultra-)dense deployment of small-cell base stations (SBSs) endowed with cloud-like computing functionalities paves the way for pervasive mobile edge computing (MEC), enabling ultra-low latency and location-awareness for a variety of emerging mobile applications and the Internet of Things. To handle spatially uneven computation workloads in the network, cooperation among SBSs via workload peer offloading is essential to avoid large computation latency at overloaded SBSs and provide high quality of service to end users. However, performing effective peer offloading faces many unique challenges in small cell networks due to limited energy resources committed by self-interested SBS owners, uncertainties in the system dynamics and co-provisioning of radio access and computing services. This paper develops a novel online SBS peer offloading framework, called OPEN, by leveraging the Lyapunov technique, in order to maximize the long-term system performance while keeping the energy consumption of SBSs below individual long-term constraints. OPEN works online without requiring information about future system dynamics, yet provides provably near-optimal performance compared to the oracle solution that has the complete future information. In addition, this paper formulates a novel peer offloading game among SBSs, analyzes its equilibrium and efficiency loss in terms of the price of anarchy in order to thoroughly understand SBSs' strategic behaviors, thereby enabling decentralized and autonomous peer offloading decision making. Extensive simulations are carried out and show that peer offloading among SBSs dramatically improves the edge computing performance. version:1
arxiv-1703-06737 | An improved lion strategy for the lion and man problem | http://arxiv.org/abs/1703.06737 | id:1703.06737 author:Marco Casini, Andrea Garulli category:math.OC cs.RO  published:2017-03-17 summary:In this paper, a novel lion strategy for David Gale's lion and man problem is proposed. The devised approach enhances a popular strategy proposed by Sgall, which relies on the computation of a suitable "center". The key idea of the new strategy is to update the center at each move, instead of computing it once and for all at the beginning of the game. Convergence of the proposed lion strategy is proven and an upper bound on the game length is derived, which dominates the existing bounds. version:1
arxiv-1701-08661 | Credal Networks under Epistemic Irrelevance | http://arxiv.org/abs/1701.08661 | id:1701.08661 author:Jasper De Bock category:cs.AI math.PR  published:2017-01-27 summary:A credal network under epistemic irrelevance is a generalised type of Bayesian network that relaxes its two main building blocks. On the one hand, the local probabilities are allowed to be partially specified. On the other hand, the assessments of independence do not have to hold exactly. Conceptually, these two features turn credal networks under epistemic irrelevance into a powerful alternative to Bayesian networks, offering a more flexible approach to graph-based multivariate uncertainty modelling. However, in practice, they have long been perceived as very hard to work with, both theoretically and computationally. The aim of this paper is to demonstrate that this perception is no longer justified. We provide a general introduction to credal networks under epistemic irrelevance, give an overview of the state of the art, and present several new theoretical results. Most importantly, we explain how these results can be combined to allow for the design of recursive inference methods. We provide numerous concrete examples of how this can be achieved, and use these to demonstrate that computing with credal networks under epistemic irrelevance is most definitely feasible, and in some cases even highly efficient. We also discuss several philosophical aspects, including the lack of symmetry, how to deal with probability zero, the interpretation of lower expectations, the axiomatic status of graphoid properties, and the difference between updating and conditioning. version:2
arxiv-1703-04741 | Towards Moral Autonomous Systems | http://arxiv.org/abs/1703.04741 | id:1703.04741 author:Vicky Charisi, Louise Dennis, Michael Fisher, Robert Lieck, Andreas Matthias, Marija Slavkovik, Janina Sombetzki, Alan F. T. Winfield, Roman Yampolskiy category:cs.AI  published:2017-03-14 summary:Both the ethics of autonomous systems and the problems of their technical implementation have by now been studied in some detail. Less attention has been given to the areas in which these two separate concerns meet. This paper, written by both philosophers and engineers of autonomous systems, addresses a number of issues in machine ethics that are located at precisely the intersection between ethics and engineering. We first discuss different approaches towards the conceptual design of autonomous systems and their implications on the ethics implementation in such systems. Then we examine problematic areas regarding the specification and verification of ethical behavior in autonomous systems, particularly with a view towards the requirements of future legislation. We discuss transparency and accountability issues that will be crucial for any future wide deployment of autonomous systems in society. Finally we consider the, often overlooked, possibility of intentional misuse of AI systems and the possible dangers arising out of deliberately unethical design, implementation, and use of autonomous robots. version:2
arxiv-1703-04912 | Syntax-Preserving Belief Change Operators for Logic Programs | http://arxiv.org/abs/1703.04912 | id:1703.04912 author:Sebastian Binnewies, Zhiqiang Zhuang, Kewen Wang, Bela Stantic category:cs.AI I.2.3; I.2.4; F.4.1  published:2017-03-15 summary:Recent methods have adapted the well-established AGM and belief base frameworks for belief change to cover belief revision in logic programs. In this study here, we present two new sets of belief change operators for logic programs. They focus on preserving the explicit relationships expressed in the rules of a program, a feature that is missing in purely semantic approaches that consider programs only in their entirety. In particular, operators of the latter class fail to satisfy preservation and support, two important properties for belief change in logic programs required to ensure intuitive results. We address this shortcoming of existing approaches by introducing partial meet and ensconcement constructions for logic program belief change, which allow us to define syntax-preserving operators that satisfy preservation and support. Our work is novel in that our constructions not only preserve more information from a logic program during a change operation than existing ones, but they also facilitate natural definitions of contraction operators, the first in the field to the best of our knowledge. In order to evaluate the rationality of our operators, we translate the revision and contraction postulates from the AGM and belief base frameworks to the logic programming setting. We show that our operators fully comply with the belief base framework and formally state the interdefinability between our operators. We further propose an algorithm that is based on modularising a logic program to reduce partial meet and ensconcement revisions or contractions to performing the operation only on the relevant modules of that program. Finally, we compare our approach to two state-of-the-art logic program revision methods and demonstrate that our operators address the shortcomings of one and generalise the other method. version:2
arxiv-1703-05769 | A 594 Gbps LDPC Decoder Based on Finite-Alphabet Message Passing | http://arxiv.org/abs/1703.05769 | id:1703.05769 author:Reza Ghanaatian, Alexios Balatsoukas-Stimming, Christoph Muller, Michael Meidlinger, Gerald Matz, Adam Teman, Andreas Burg category:cs.AR cs.IT math.IT  published:2017-03-16 summary:An ultra-high throughput low-density parity check (LDPC) decoder with an unrolled full-parallel architecture is proposed, which achieves the highest decoding throughput compared to previously reported LDPC decoders in literature. The decoder benefits from a serial message-transfer approach between the decoding stages to alleviate the well-known routing congestion problem in parallel LDPC decoders. Furthermore, a finite-alphabet message passing algorithm is employed to replace the variable node update rule of standard min-sum decoders with optimized look-up tables, designed in a way that maximize the mutual information between decoding messages. The proposed algorithm results in an architecture with reduced bit-width messages, leading to a significantly higher decoding throughput and to a lower area as compared to a min-sum decoder when serial message-transfer is used. The architecture is placed and routed for the standard min-sum reference decoder and for the proposed finite-alphabet decoder using a custom pseudo-hierarchical backend design strategy to further alleviate routing congestions and to handle the large design. Post-layout results show that the finite-alphabet decoder with the serial message-transfer architecture achieves a throughput as large as 594 Gbps with an area of 16.2 mm$^2$ and dissipates an average power of 22.7 pJ per decoded bit in a 28 nm FD-SOI library. Compared to the reference min-sum decoder, this corresponds to 3.3 times smaller area and 2 times better energy efficiency. version:1
arxiv-1703-05713 | The challenge of decentralized marketplaces | http://arxiv.org/abs/1703.05713 | id:1703.05713 author:Bas van IJzendoorn category:cs.DC cs.CR cs.CY  published:2017-03-16 summary:Online trust systems are playing an important role in to-days world and face various challenges in building them. Billions of dollars of products and services are traded through electronic commerce, files are shared among large peer-to-peer networks and smart contracts can potentially replace paper contracts with digital contracts. These systems rely on trust mechanisms in peer-to-peer networks like reputation systems or a trustless public ledger. In most cases, reputation systems are build to determine the trustworthiness of users and to provide incentives for users to make a fair contribution to the peer-to-peer network. The main challenges are how to set up a good trust system, how to deal with security issues and how to deal with strategic users trying to cheat on the system. The Sybil attack, the most important attack on reputation systems is discussed. At last match making in two sided markets and the strategy proofness of these markets are discussed. version:1
arxiv-1702-02628 | Optimal Detection of Faulty Traffic Sensors Used in Route Planning | http://arxiv.org/abs/1702.02628 | id:1702.02628 author:Amin Ghafouri, Aron Laszka, Abhishek Dubey, Xenofon Koutsoukos category:cs.AI cs.SY  published:2017-02-08 summary:In a smart city, real-time traffic sensors may be deployed for various applications, such as route planning. Unfortunately, sensors are prone to failures, which result in erroneous traffic data. Erroneous data can adversely affect applications such as route planning, and can cause increased travel time. To minimize the impact of sensor failures, we must detect them promptly and accurately. However, typical detection algorithms may lead to a large number of false positives (i.e., false alarms) and false negatives (i.e., missed detections), which can result in suboptimal route planning. In this paper, we devise an effective detector for identifying faulty traffic sensors using a prediction model based on Gaussian Processes. Further, we present an approach for computing the optimal parameters of the detector which minimize losses due to false-positive and false-negative errors. We also characterize critical sensors, whose failure can have high impact on the route planning application. Finally, we implement our method and evaluate it numerically using a real-world dataset and the route planning platform OpenTripPlanner. version:2
arxiv-1703-04216 | Cognitive Inference of Demographic Data by User Ratings | http://arxiv.org/abs/1703.04216 | id:1703.04216 author:Jinliang Xu, Shangguang Wang, Fangchun Yang, Rong N. Chang category:cs.IR cs.DC  published:2017-03-13 summary:Cognitive inference of user demographics, such as gender and age, plays an important role in creating user profiles for adjusting marketing strategies and generating personalized recommendations because user demographic data is usually not available due to data privacy concerns. At present, users can readily express feedback regarding products or services that they have purchased. During this process, user demographics are concealed, but the data has never yet been successfully utilized to contribute to the cognitive inference of user demographics. In this paper, we investigate the inference power of user ratings data, and propose a simple yet general cognitive inference model, called rating to profile (R2P), to infer user demographics from user provided ratings. In particular, the proposed R2P model can achieve the following: 1. Correctly integrate user ratings into model training. 2.Infer multiple demographic attributes of users simultaneously, capturing the underlying relevance between different demographic attributes. 3. Train its two components, i.e. feature extractor and classifier, in an integrated manner under a supervised learning paradigm, which effectively helps to discover useful hidden patterns from highly sparse ratings data. We introduce how to incorporate user ratings data into the research field of cognitive inference of user demographic data, and detail the model development and optimization process for the proposed R2P. Extensive experiments are conducted on two real-world ratings datasets against various compared state-of-the-art methods, and the results from multiple aspects demonstrate that our proposed R2P model can significantly improve on the cognitive inference performance of user demographic data. version:2
arxiv-1703-04215 | Multiple User Context Inference by Fusing Data Sources | http://arxiv.org/abs/1703.04215 | id:1703.04215 author:Jinliang Xu, Shangguang Wang, Fangchun Yang, Jie Tang category:cs.IR cs.DC  published:2017-03-13 summary:Inference of user context information, including user's gender, age, marital status, location and so on, has been proven to be valuable for building context aware recommender system. However, prevalent existing studies on user context inference have two shortcommings: 1. focusing on only a single data source (e.g. Internet browsing logs, or mobile call records), and 2. ignoring the interdependence of multiple user contexts (e.g. interdependence between age and marital status), which have led to poor inference performance. To solve this problem, in this paper, we first exploit tensor outer product to fuse multiple data sources in the feature space to obtain an extensional user feature representation. Following this, by taking this extensional user feature representation as input, we propose a multiple attribute probabilistic model called MulAProM to infer user contexts that can take advantage of the interdependence between them. Our study is based on large telecommunication datasets from the local mobile operator of Shanghai, China, and consists of two data sources, 4.6 million call detail records and 7.5 million data traffic records of 8,000 mobile users, collected in the course of six months. The experimental results show that our model can outperform other models in terms of \emph{recall}, \emph{precision}, and the \emph{F1-measure}. version:2
arxiv-1703-05647 | Replicable Parallel Branch and Bound Search | http://arxiv.org/abs/1703.05647 | id:1703.05647 author:Blair Archibald, Ciaran McCreesh, Patrick Maier, Rob Stewart, Phil Trinder category:cs.DC G.2.1; F.1.2; H.3.4  published:2017-03-16 summary:Branch and bound searches are a common technique for solving global optimisation and decision problems, yet their irregularity, search order dependence, and the need to share bound information globally makes it challenging to implement them in parallel, and to reason about their parallel performance. We identify three key parallel search properties for replicable branch and bound implementations: Sequential Lower Bound, Non-increasing Runtimes, and Repeatability. We define a formal model for parallel branch and bound search problems and show its generality by using it to define three benchmarks: finding a Maximum Clique in a graph, 0/1 Knapsack and Travelling Salesperson (TSP). We present a Generic Branch and Bound search API that conforms to the model. For reusability we encapsulate the search behaviours as a pair of algorithmic based skeletons in a distributed-memory parallel Haskell. Crucially the Ordered skeleton is designed to guarantee the parallel search properties, potentially at a performance cost compared with the Unordered skeleton. We compare the sequential performance of the skeletons with a class leading C++ search implementation. We then use relative speedups to evaluate the skeletons for 40 benchmark instances on a cluster using 200 workers. The Ordered skeleton preserves the Sequential Lower Bound for all benchmark instances while the Unordered skeleton violates the property for 5 TSP instances. The Ordered skeleton preserves Non-increasing Runtimes for all benchmark instances while the Unordered skeleton violates the property for many instances of all three benchmarks. The Ordered skeleton delivers far more repeatable performance than the Unordered skeleton (Repeatability property) with a median relative standard deviation (RSD) of 1.78% vs 5.56%, 1.83% vs 87.56% and 1.96% vs 8.61% for all Maximum Clique, Knapsack and TSP instances respectively. version:1
arxiv-1612-03849 | Distributed and Proximity-Constrained C-Means for Discrete Coverage Control | http://arxiv.org/abs/1612.03849 | id:1612.03849 author:Gabriele Oliva, Andrea Gasparri, Adriano Fagiolini, Christoforos N. Hadjicostis category:cs.RO  published:2016-12-12 summary:In this paper we present a novel distributed coverage control framework for a network of mobile agents, in charge of covering a finite set of points of interest (PoI), such as people in danger, geographically dispersed equipment or environmental landmarks. The proposed algorithm is inspired by the C-Means, an unsupervised learning algorithm originally proposed for non-exclusive clustering and for identification of cluster centroids from a set of observations. To cope with the agents' limited sensing range and avoid infeasible coverage solutions, traditional C-Means needs to be enhanced with proximity constraints, ensuring that each agent takes into account only neighboring PoIs. The proposed coverage control framework provides useful information concerning the ranking or importance of the different PoIs to the agents, which can be exploited in further application-dependent data fusion processes, patrolling, or disaster relief applications. version:2
arxiv-1703-05626 | Scalable Accelerated Decentralized Multi-Robot Policy Search in Continuous Observation Spaces | http://arxiv.org/abs/1703.05626 | id:1703.05626 author:Shayegan Omidshafiei, Christopher Amato, Miao Liu, Michael Everett, Jonathan P. How, John Vian category:cs.MA cs.RO  published:2017-03-16 summary:This paper presents the first ever approach for solving \emph{continuous-observation} Decentralized Partially Observable Markov Decision Processes (Dec-POMDPs) and their semi-Markovian counterparts, Dec-POSMDPs. This contribution is especially important in robotics, where a vast number of sensors provide continuous observation data. A continuous-observation policy representation is introduced using Stochastic Kernel-based Finite State Automata (SK-FSAs). An SK-FSA search algorithm titled Entropy-based Policy Search using Continuous Kernel Observations (EPSCKO) is introduced and applied to the first ever continuous-observation Dec-POMDP/Dec-POSMDP domain, where it significantly outperforms state-of-the-art discrete approaches. This methodology is equally applicable to Dec-POMDPs and Dec-POSMDPs, though the empirical analysis presented focuses on Dec-POSMDPs due to their higher scalability. To improve convergence, an entropy injection policy search acceleration approach for both continuous and discrete observation cases is also developed and shown to improve convergence rates without degrading policy quality. version:1
arxiv-1703-05623 | Semantic-level Decentralized Multi-Robot Decision-Making using Probabilistic Macro-Observations | http://arxiv.org/abs/1703.05623 | id:1703.05623 author:Shayegan Omidshafiei, Shih-Yuan Liu, Michael Everett, Brett T. Lopez, Christopher Amato, Miao Liu, Jonathan P. How, John Vian category:cs.MA cs.RO  published:2017-03-16 summary:Robust environment perception is essential for decision-making on robots operating in complex domains. Intelligent task execution requires principled treatment of uncertainty sources in a robot's observation model. This is important not only for low-level observations (e.g., accelerometer data), but also for high-level observations such as semantic object labels. This paper formalizes the concept of macro-observations in Decentralized Partially Observable Semi-Markov Decision Processes (Dec-POSMDPs), allowing scalable semantic-level multi-robot decision making. A hierarchical Bayesian approach is used to model noise statistics of low-level classifier outputs, while simultaneously allowing sharing of domain noise characteristics between classes. Classification accuracy of the proposed macro-observation scheme, called Hierarchical Bayesian Noise Inference (HBNI), is shown to exceed existing methods. The macro-observation scheme is then integrated into a Dec-POSMDP planner, with hardware experiments running onboard a team of dynamic quadrotors in a challenging domain where noise-agnostic filtering fails. To the best of our knowledge, this is the first demonstration of a real-time, convolutional neural net-based classification framework running fully onboard a team of quadrotors in a multi-robot decision-making domain. version:1
arxiv-1703-06109 | Generalised Reichenbachian Common Cause Systems | http://arxiv.org/abs/1703.06109 | id:1703.06109 author:Claudio Mazzola category:stat.OT cs.AI  published:2017-03-16 summary:The principle of the common cause claims that if an improbable coincidence has occurred, there must exist a common cause. This is generally taken to mean that positive correlations between non-causally related events should disappear when conditioning on the action of some underlying common cause. The extended interpretation of the principle, by contrast, urges that common causes should be called for in order to explain positive deviations between the estimated correlation of two events and the expected value of their correlation. The aim of this paper is to provide the extended reading of the principle with a general probabilistic model, capturing the simultaneous action of a system of multiple common causes. To this end, two distinct models are elaborated, and the necessary and sufficient conditions for their existence are determined. version:1
arxiv-1703-06042 | A Visual Web Tool to Perform What-If Analysis of Optimization Approaches | http://arxiv.org/abs/1703.06042 | id:1703.06042 author:Sascha Van Cauwelaert, Michele Lombardi, Pierre Schaus category:cs.AI cs.PF  published:2017-03-16 summary:In Operation Research, practical evaluation is essential to validate the efficacy of optimization approaches. This paper promotes the usage of performance profiles as a standard practice to visualize and analyze experimental results. It introduces a Web tool to construct and export performance profiles as SVG or HTML files. In addition, the application relies on a methodology to estimate the benefit of hypothetical solver improvements. Therefore, the tool allows one to employ what-if analysis to screen possible research directions, and identify those having the best potential. The approach is showcased on two Operation Research technologies: Constraint Programming and Mixed Integer Linear Programming. version:1
arxiv-1505-05441 | Decentralized Simultaneous Multi-target Exploration using a Connected Network of Multiple Robots | http://arxiv.org/abs/1505.05441 | id:1505.05441 author:Thomas Nestmeyer, Paolo Robuffo Giordano, Heinrich H. Bülthoff, Antonio Franchi category:cs.RO  published:2015-05-20 summary:This paper presents a novel decentralized control strategy for a multi-robot system that enables parallel multi-target exploration while ensuring a time-varying connected topology in cluttered 3D environments. Flexible continuous connectivity is guaranteed by building upon a recent connectivity maintenance method, in which limited range, line-of-sight visibility, and collision avoidance are taken into account at the same time. Completeness of the decentralized multi-target exploration algorithm is guaranteed by dynamically assigning the robots with different motion behaviors during the exploration task. One major group is subject to a suitable downscaling of the main traveling force based on the traveling efficiency of the current leader and the direction alignment between traveling and connectivity force. This supports the leader in always reaching its current target and, on a larger time horizon, that the whole team realizes the overall task in finite time. Extensive Monte~Carlo simulations with a group of several quadrotor UAVs show the scalability and effectiveness of the proposed method and experiments validate its practicability. version:3
arxiv-1703-05509 | VieM v1.00 -- Vienna Mapping and Sparse Quadratic Assignment User Guide | http://arxiv.org/abs/1703.05509 | id:1703.05509 author:Christian Schulz, Jesper Larsson Träff category:cs.DC cs.DS math.CO  published:2017-03-16 summary:This paper severs as a user guide to the mapping framework VieM (Vienna Mapping and Sparse Quadratic Assignment). We give a rough overview of the techniques used within the framework and describe the user interface as well as the file formats used. version:1
arxiv-1703-05435 | Proof of Luck: an Efficient Blockchain Consensus Protocol | http://arxiv.org/abs/1703.05435 | id:1703.05435 author:Mitar Milutinovic, Warren He, Howard Wu, Maxinder Kanwal category:cs.CR cs.DC  published:2017-03-16 summary:In the paper, we present designs for multiple blockchain consensus primitives and a novel blockchain system, all based on the use of trusted execution environments (TEEs), such as Intel SGX-enabled CPUs. First, we show how using TEEs for existing proof of work schemes can make mining equitably distributed by preventing the use of ASICs. Next, we extend the design with proof of time and proof of ownership consensus primitives to make mining energy- and time-efficient. Further improving on these designs, we present a blockchain using a proof of luck consensus protocol. Our proof of luck blockchain uses a TEE platform's random number generation to choose a consensus leader, which offers low-latency transaction validation, deterministic confirmation time, negligible energy consumption, and equitably distributed mining. Lastly, we discuss a potential protection against up to a constant number of compromised TEEs. version:1
arxiv-1703-05424 | Lower Bounds and Algorithm for Partially Replicated Causally Consistent Shared Memory | http://arxiv.org/abs/1703.05424 | id:1703.05424 author:Zhuolun Xiang, Nitin H. Vaidya category:cs.DC  published:2017-03-15 summary:Distributed shared memory systems maintain multiple replicas of the shared memory locations. Maintaining causal consistency in such systems has received significant attention in the past. However, much of the previous literature focuses on full replication wherein each replica stores a copy of all the locations in the shared memory. In this paper, we investigate causal consistency in partially replicated systems, wherein each replica may store only a subset of the shared data. To achieve causal consistency, it is necessary to ensure that, before an update is performed at any given replica, all causally preceding updates must also be performed. Achieving this goal requires some mechanism to track causal dependencies. In the context of full replication, this goal is often achieved using vector timestamps, with the number of vector elements being equal to the number of replicas. Building on the past work, this paper makes three key contributions: 1. We develop lower bounds on the size of the timestamps that must be maintained in order to achieve causal consistency in partially replicated systems. The size of the timestamps is a function of the manner in which the replicas share data, and the set of replicas accessed by each client. 2. We present an algorithm to achieve causal consistency in partially replicated systems using simple vector timestamps. 3. We present some optimizations to improve the overhead of the timestamps required with partial replication. version:1
arxiv-1703-05569 | Future of Flexible Robotic Endoscopy Systems | http://arxiv.org/abs/1703.05569 | id:1703.05569 author:Tian En Timothy Seah, Thanh Nho Do, Nobuyoshi Takeshita, Khek Yu Ho, Soo Jay Phee category:physics.med-ph cs.RO  published:2017-03-15 summary:Robotics enables a variety of unconventional actuation strategies to be used for endoscopes, resulting in reduced trauma to the GI tract. For transmission of force to distally mounted endoscopic instruments, robotically actuated tendon sheath mechanisms are the current state of the art. Robotics in surgical endoscopy enables an ergonomic mapping of the surgeon movements to remotely controlled slave arms, facilitating tissue manipulation. The learning curve for difficult procedures such as endoscopic submucosal dissection and full-thickness resection can be significantly reduced. Improved surgical outcomes are also observed from clinical and pre-clinical trials. The technology behind master-slave surgical robotics will continue to mature, with the addition of position and force sensors enabling better control and tactile feedback. More robotic assisted GI luminal and NOTES surgeries are expected to be conducted in future, and gastroenterologists will have a key collaborative role to play. version:1
arxiv-1607-06966 | A Generalized Label Correcting Method for Optimal Kinodynamic Motion Planning | http://arxiv.org/abs/1607.06966 | id:1607.06966 author:Brian Paden, Emilio Frazzoli category:cs.RO  published:2016-07-23 summary:A resolution complete optimal kinodynamic motion planning algorithm is presented and described as a generalized label correcting (GLC) method. In contrast to related algorithms, the GLC method does not require a local planning subroutine and benefits from a simple implementation. The key contributions of this paper are the construction and analysis of the GLC conditions which are the basis of the proposed algorithm. Numerical experiments demonstrate the running time of the GLC method to be less than the related SST algorithm. version:4
arxiv-1604-02943 | Taming mismatches in inter-agent distances for the formation-motion control of second-order agents | http://arxiv.org/abs/1604.02943 | id:1604.02943 author:Hector Garcia de Marina, Bayu Jayawardhana, Ming Cao category:math.OC cs.RO cs.SY  published:2016-04-11 summary:This paper presents the analysis on the influence of distance mismatches on the standard gradient-based rigid formation control for second-order agents. It is shown that, similar to the first-order case as recently discussed in the literature, these mismatches introduce two undesired group behaviors: a distorted final shape and a steady-state motion of the group formation. We show that such undesired behaviors can be eliminated by combining the standard formation control law with distributed estimators. Finally, we show how the mismatches can be effectively employed as design parameters in order to control a combined translational and rotational motion of the formation. version:2
arxiv-1703-01274 | Actor-Critic Reinforcement Learning with Simultaneous Human Control and Feedback | http://arxiv.org/abs/1703.01274 | id:1703.01274 author:Kory W. Mathewson, Patrick M. Pilarski category:cs.AI cs.HC cs.RO  published:2017-03-03 summary:This paper contributes a first study into how different human users deliver simultaneous control and feedback signals during human-robot interaction. As part of this work, we formalize and present a general interactive learning framework for online cooperation between humans and reinforcement learning agents. In many human-machine interaction settings, there is a growing gap between the degrees-of-freedom of complex semi-autonomous systems and the number of human control channels. Simple human control and feedback mechanisms are required to close this gap and allow for better collaboration between humans and machines on complex tasks. To better inform the design of concurrent control and feedback interfaces, we present experimental results from a human-robot collaborative domain wherein the human must simultaneously deliver both control and feedback signals to interactively train an actor-critic reinforcement learning robot. We compare three experimental conditions: 1) human delivered control signals, 2) reward-shaping feedback signals, and 3) simultaneous control and feedback. Our results suggest that subjects provide less feedback when simultaneously delivering feedback and control signals and that control signal quality is not significantly diminished. Our data suggest that subjects may also modify when and how they provide feedback. Through algorithmic development and tuning informed by this study, we expect semi-autonomous actions of robotic agents can be better shaped by human feedback, allowing for seamless collaboration and improved performance in difficult interactive domains. version:2
arxiv-1703-05201 | Fuzzy Rankings: Properties and Applications | http://arxiv.org/abs/1703.05201 | id:1703.05201 author:Jiří Mazurek category:cs.AI  published:2017-03-15 summary:In practice, a ranking of objects with respect to given set of criteria is of considerable importance. However, due to lack of knowledge, information of time pressure, decision makers might not be able to provide a (crisp) ranking of objects from the top to the bottom. Instead, some objects might be ranked equally, or better than other objects only to some degree. In such cases, a generalization of crisp rankings to fuzzy rankings can be more useful. The aim of the article is to introduce the notion of a fuzzy ranking and to discuss its several properties, namely orderings, similarity and indecisiveness. The proposed approach can be used both for group decision making or multiple criteria decision making when uncertainty is involved. version:1
arxiv-1702-08065 | Using Battery Storage for Peak Shaving and Frequency Regulation: Joint Optimization for Superlinear Gains | http://arxiv.org/abs/1702.08065 | id:1702.08065 author:Yuanyuan Shi, Bolun Xu, Di Wang, Baosen Zhang category:cs.SY cs.DC math.OC  published:2017-02-26 summary:We consider using a battery storage system simultaneously for peak shaving and frequency regulation through a joint optimization framework which captures battery degradation, operational constraints and uncertainties in customer load and regulation signals. Under this framework, using real data we show the electricity bill of users can be reduced by up to 15\%. Furthermore, we demonstrate that the saving from joint optimization is often larger than the sum of the optimal savings when the battery is used for the two individual applications. A simple threshold real-time algorithm is proposed and achieves this super-linear gain. Compared to prior works that focused on using battery storage systems for single applications, our results suggest that batteries can achieve much larger economic benefits than previously thought if they jointly provide multiple services. version:2
arxiv-1703-05126 | Bandwidth-efficient Storage Services for Mitigating Side Channel Attack | http://arxiv.org/abs/1703.05126 | id:1703.05126 author:Pengfei Zuo, Yu Hua, Cong Wang, Wen Xia, Shunde Cao, Yukun Zhou, Yuanyuan Sun category:cs.CR cs.DC  published:2017-03-15 summary:Data deduplication is able to effectively identify and eliminate redundant data and only maintain a single copy of files and chunks. Hence, it is widely used in cloud storage systems to save storage space and network bandwidth. However, the occurrence of deduplication can be easily identified by monitoring and analyzing network traffic, which leads to the risk of user privacy leakage. The attacker can carry out a very dangerous side channel attack, i.e., learn-the-remaining-information (LRI) attack, to reveal users' privacy information by exploiting the side channel of network traffic in deduplication. Existing work addresses the LRI attack at the cost of the high bandwidth efficiency of deduplication. In order to address this problem, we propose a simple yet effective scheme, called randomized redundant chunk scheme (RRCS), to significantly mitigate the risk of the LRI attack while maintaining the high bandwidth efficiency of deduplication. The basic idea behind RRCS is to add randomized redundant chunks to mix up the real deduplication states of files used for the LRI attack, which effectively obfuscates the view of the attacker, who attempts to exploit the side channel of network traffic for the LRI attack. Our security analysis shows that RRCS could significantly mitigate the risk of the LRI attack. We implement the RRCS prototype and evaluate it by using three large-scale real-world datasets. Experimental results demonstrate the efficiency and efficacy of RRCS. version:1
arxiv-1703-05106 | How to Stop Consensus Algorithms, locally? | http://arxiv.org/abs/1703.05106 | id:1703.05106 author:Pei Xie, Keyou You, Cheng Wu category:cs.DC  published:2017-03-15 summary:This paper studies problems on locally stopping distributed consensus algorithms over networks where each node updates its state by interacting with its neighbors and decides by itself whether certain level of agreement has been achieved among nodes. Since an individual node is unable to access the states of those beyond its neighbors, this problem becomes challenging. In this work, we first define the stopping problem for generic distributed algorithms. Then, a distributed algorithm is explicitly provided for each node to stop consensus updating by exploring the relationship between the so-called local and global consensus. Finally, we show both in theory and simulation that its effectiveness depends both on the network size and the structure. version:1
arxiv-1602-07919 | Experimental Performance Evaluation of Cloud-Based Analytics-as-a-Service | http://arxiv.org/abs/1602.07919 | id:1602.07919 author:Francesco Pace, Marco Milanesio, Daniele Venzano, Damiano Carra, Pietro Michiardi category:cs.DC  published:2016-02-25 summary:An increasing number of Analytics-as-a-Service solutions has recently seen the light, in the landscape of cloud-based services. These services allow flexible composition of compute and storage components, that create powerful data ingestion and processing pipelines. This work is a first attempt at an experimental evaluation of analytic application performance executed using a wide range of storage service configurations. We present an intuitive notion of data locality, that we use as a proxy to rank different service compositions in terms of expected performance. Through an empirical analysis, we dissect the performance achieved by analytic workloads and unveil problems due to the impedance mismatch that arise in some configurations. Our work paves the way to a better understanding of modern cloud-based analytic services and their performance, both for its end-users and their providers. version:3
arxiv-1703-05045 | Friend or Foe? Population Protocols can perform Community Detection | http://arxiv.org/abs/1703.05045 | id:1703.05045 author:Luca Becchetti, Andrea Clementi, Emanuele Natale, Francesco Pasquale, Prasad Raghavendra, Luca Trevisan category:cs.DM cs.DC cs.SI  published:2017-03-15 summary:We present a simple distributed algorithm that, given a regular graph consisting of two communities (or clusters), each inducing a good expander and such that the cut between them has sparsity $1/\mbox{polylog}(n)$, recovers the two communities. More precisely, upon running the protocol, every node assigns itself a binary label of $m = \Theta(\log n)$ bits, so that with high probability, for all but a small number of outliers, nodes within the same community are assigned labels with Hamming distance $o(m)$, while nodes belonging to different communities receive labels with Hamming distance at least $m/2 - o(m)$. We refer to such an outcome as a "community sensitive labeling" of the graph. Our algorithm uses $\Theta(\log^2 n)$ local memory and computes the community sensitive labeling after each node performs $\Theta(\log^2 n)$ steps of local work. Our algorithm and its analysis work in the "(random) population protocol" model, in which anonymous nodes do not share any global clock (the model is asynchronous) and communication occurs over one single (random) edge per round. We believe, this is the first provably-effective protocol for community detection that works in this model. version:1
arxiv-1703-05019 | Finding a Feasible Initial Solution for Flatness-Based Multi-Link Manipulator Motion Planning under State and Control Constraints | http://arxiv.org/abs/1703.05019 | id:1703.05019 author:Keisuke Uto, Makoto Obayashi, Gaku Takano category:cs.SY cs.RO math.OC  published:2017-03-15 summary:In this paper, we present a method to initialize at a feasible point and unfailingly solve a non-convex optimization problem in which a set-point motion is planned for a multi-link manipulator under state and control constraints. We construct an initial feasible solution by analyzing the final time effect for feasibility problems of flatness based motion planning problems. More specifically, we first find a feasible time-optimal trajectory under state constraints without a control constraint by solving a linear programming problem. Then, we find a feasible trajectory under control constraints by scaling the trajectory. To evaluate the practical applicability of the proposed method, we did numerical experiments to solve a multi-link manipulator motion planning problem by combining the method with recursive inverse dynamics algorithms. version:1
arxiv-1703-04159 | Any-Angle Pathfinding for Multiple Agents Based on SIPP Algorithm | http://arxiv.org/abs/1703.04159 | id:1703.04159 author:Konstantin Yakovlev, Anton Andreychuk category:cs.AI  published:2017-03-12 summary:The problem of finding conflict-free trajectories for multiple agents of identical circular shape, operating in shared 2D workspace, is addressed in the paper and decoupled, e.g., prioritized, approach is used to solve this problem. Agents' workspace is tessellated into the square grid on which any-angle moves are allowed, e.g. each agent can move into an arbitrary direction as long as this move follows the straight line segment whose endpoints are tied to the distinct grid elements. A novel any-angle planner based on Safe Interval Path Planning (SIPP) algorithm is proposed to find trajectories for an agent moving amidst dynamic obstacles (other agents) on a grid. This algorithm is then used as part of a prioritized multi-agent planner AA-SIPP(m). On the theoretical, side we show that AA-SIPP(m) is complete under well-defined conditions. On the experimental side, in simulation tests with up to 200 agents involved, we show that our planner finds much better solutions in terms of cost (up to 20%) compared to the planners relying on cardinal moves only. version:2
arxiv-1605-00335 | Gaussian Process Autonomous Mapping and Exploration for Range Sensing Mobile Robots | http://arxiv.org/abs/1605.00335 | id:1605.00335 author:Maani Ghaffari Jadidi, Jaime Valls Miro, Gamini Dissanayake category:cs.RO  published:2016-05-02 summary:Most of the existing robotic exploration schemes use occupancy grid representations and geometric targets known as frontiers. The occupancy grid representation relies on the assumption of independence between grid cells and ignores structural correlations present in the environment. We develop an incremental Gaussian Processes (GPs) occupancy mapping technique that is computationally tractable for online map building and provides a continuous model of uncertainty over the map spatial coordinates. The standard way to represent geometric frontiers extracted from occupancy maps is to assign binary values to each grid cell. We extend this notion to novel probabilistic frontier maps computed efficiently using the gradient of the GP occupancy map. We also propose a mutual information-based greedy exploration technique built on that representation that takes into account all possible future observations. A major advantage of high-dimensional map inference is the fact that such techniques require fewer observations, leading to a faster map entropy reduction during exploration for map building scenarios. Evaluations using the publicly available datasets show the effectiveness of the proposed framework for robotic mapping and exploration tasks. version:3
arxiv-1701-01654 | Application of Fuzzy Logic in Design of Smart Washing Machine | http://arxiv.org/abs/1701.01654 | id:1701.01654 author:Rao Farhat Masood category:cs.SY cs.AI  published:2017-01-04 summary:Washing machine is of great domestic necessity as it frees us from the burden of washing our clothes and saves ample of our time. This paper will cover the aspect of designing and developing of Fuzzy Logic based, Smart Washing Machine. The regular washing machine (timer based) makes use of multi-turned timer based start-stop mechanism which is mechanical as is prone to breakage. In addition to its starting and stopping issues, the mechanical timers are not efficient with respect of maintenance and electricity usage. Recent developments have shown that merger of digital electronics in optimal functionality of this machine is possible and nowadays in practice. A number of international renowned companies have developed the machine with the introduction of smart artificial intelligence. Such a machine makes use of sensors and smartly calculates the amount of run-time (washing time) for the main machine motor. Realtime calculations and processes are also catered in optimizing the run-time of the machine. The obvious result is smart time management, better economy of electricity and efficiency of work. This paper deals with the indigenization of FLC (Fuzzy Logic Controller) based Washing Machine, which is capable of automating the inputs and getting the desired output (wash-time). version:2
arxiv-1703-04906 | Vision-based Robotic Arm Imitation by Human Gesture | http://arxiv.org/abs/1703.04906 | id:1703.04906 author:Zhiqiang Tang, Jinxin Xu category:cs.RO  published:2017-03-15 summary:One of the most efficient ways for a learning-based robotic arm to learn to process complex tasks as human, is to directly learn from observing how human complete those tasks, and then imitate. Our idea is based on success of Deep Q-Learning (DQN) algorithm according to reinforcement learning, and then extend to Deep Deterministic Policy Gradient (DDPG) algorithm. We developed a learning-based method, combining modified DDPG and visual imitation network. Our approach acquires frames only from a monocular camera, and no need to either construct a 3D environment or generate actual points. The result we expected during training, was that robot would be able to move as almost the same as how human hands did. version:1
arxiv-1703-04881 | Multi-Objective Cooperative Search of Spatially Diverse Routes in Uncertain Environments | http://arxiv.org/abs/1703.04881 | id:1703.04881 author:Johnathan Votion, Yongcan Cao category:cs.SY cs.RO  published:2017-03-15 summary:This paper focuses on developing new navigation and reconnaissance capabilities for cooperative unmanned systems in uncertain environments. The goal is to design a cooperative multi-vehicle system that can survey an unknown environment and find the most valuable route for personnel to travel. To accomplish the goal, the multi-vehicle system first explores spatially diverse routes and then selects the safest route. In particular, the proposed cooperative path planner sequentially generates a set of spatially diverse routes according to a number of factors, including travel distance, ease of travel, and uncertainty associated with the ease of travel. The planner's dependence on each of these factors is altered by a weighted score, doing so changes the criteria for determining an optimum route. To penalize the selection of same paths by different vehicles, a control gain is used to increase the cost of paths that lie near the route(s) assigned to other vehicles. By varying the control gain, the spatial diversity among routes can be accomplished. By repeatedly searching for different paths cooperatively, an optimal path can be selected that yields the most valuable route. version:1
arxiv-1703-04862 | Exploring the Combination Rules of D Numbers From a Perspective of Conflict Redistribution | http://arxiv.org/abs/1703.04862 | id:1703.04862 author:Xinyang Deng, Wen Jiang category:cs.AI  published:2017-03-15 summary:Dempster-Shafer theory of evidence is widely applied to uncertainty modelling and knowledge reasoning because of its advantages in dealing with uncertain information. But some conditions or requirements, such as exclusiveness hypothesis and completeness constraint, limit the development and application of that theory to a large extend. To overcome the shortcomings and enhance its capability of representing the uncertainty, a novel model, called D numbers, has been proposed recently. However, many key issues, for example how to implement the combination of D numbers, remain unsolved. In the paper, we have explored the combination of D Numbers from a perspective of conflict redistribution, and proposed two combination rules being suitable for different situations for the fusion of two D numbers. The proposed combination rules can reduce to the classical Dempster's rule in Dempster-Shafer theory under a certain conditions. Numerical examples and discussion about the proposed rules are also given in the paper. version:1
arxiv-1609-06405 | A Logic of Knowing Why | http://arxiv.org/abs/1609.06405 | id:1609.06405 author:Chao Xu, Yanjing Wang, Thomas Studer category:cs.AI cs.LO math.LO  published:2016-09-21 summary:When we say "I know why he was late", we know not only the fact that he was late, but also an explanation of this fact. We propose a logical framework of "knowing why" inspired by the existing formal studies on why-questions, scientific explanation, and justification logic. We introduce the Ky_i operator into the language of epistemic logic to express "agent i knows why phi" and propose a Kripke-style semantics of such expressions in terms of knowing an explanation of phi. We obtain two sound and complete axiomatizations w.r.t. two different model classes depending on different assumptions about introspection. version:2
arxiv-1703-04797 | A Macroscopic Model for Differential Privacy in Dynamic Robotic Networks | http://arxiv.org/abs/1703.04797 | id:1703.04797 author:Amanda Prorok, Vijay Kumar category:cs.RO cs.CR  published:2017-03-14 summary:The increasing availability of online and mobile information platforms is facilitating the development of peer-to-peer collaboration strategies in large-scale networks. These technologies are being leveraged by networked robotic systems to provide applications of automated transport, resource redistribution (collaborative consumption), and location services. Yet, external observations of the system dynamics may expose sensitive information about the participants that compose these networks (robots, resources, and humans). In particular, we are concerned with settings where an adversary gains access to a snapshot of the dynamic state of the system. We propose a method that quantifies how easy it is for the adversary to identify the specific type of any agent (which can be a robot, resource, or human) in the network, based on this observation. We draw from the theory of differential privacy to propose a closed-form expression for the leakage of the system when the snapshot is taken at steady-state, as well as a numerical approach to compute the leakage when the snapshot is taken at any given time. The novelty of our approach is that our privacy model builds on a macroscopic description of the system's state, which allows us to take account of protected entities (network participants) that are interdependent. Our results show how the leakage varies, as a function of the composition and dynamic behavior of the network; they also indicate design rules for increasing privacy levels. version:1
arxiv-1703-04771 | Visual end-effector tracking using a 3D model-aided particle filter for humanoid robot platforms | http://arxiv.org/abs/1703.04771 | id:1703.04771 author:Claudio Fantacci, Ugo Pattacini, Vadim Tikhanoff, Lorenzo Natale category:cs.RO  published:2017-03-14 summary:This paper addresses recursive markerless estimation of a robot's end-effector using visual observations from its cameras. The problem is formulated into the Bayesian framework and addressed using Sequential Monte Carlo (SMC) filtering. We use a 3D rendering engine and Computer Aided Design (CAD) schematics of the robot to virtually create images from the robot's camera viewpoints. These images are then used to extract information and estimate the pose of the end-effector. To this aim, we developed a particle filter for estimating the position and orientation of the robot's end-effector using the Histogram of Oriented Gradient (HOG) descriptors to capture robust characteristic features of shapes in both cameras and rendered images. We implemented the algorithm on the iCub humanoid robot and employed it in a closed-loop reaching scenario. We demonstrate that the tracking is robust to clutter, allows compensating for errors in the robot kinematics and servoing the arm in closed loop using vision. version:1
arxiv-1703-04738 | Privacy-Preserving Vehicle Assignment for Mobility-on-Demand Systems | http://arxiv.org/abs/1703.04738 | id:1703.04738 author:Amanda Prorok, Vijay Kumar category:cs.CR cs.RO  published:2017-03-14 summary:Urban transportation is being transformed by mobility-on-demand (MoD) systems. One of the goals of MoD systems is to provide personalized transportation services to passengers. This process is facilitated by a centralized operator that coordinates the assignment of vehicles to individual passengers, based on location data. However, current approaches assume that accurate positioning information for passengers and vehicles is readily available. This assumption raises privacy concerns. In this work, we address this issue by proposing a method that protects passengers' drop-off locations (i.e., their travel destinations). Formally, we solve a batch assignment problem that routes vehicles at obfuscated origin locations to passenger locations (since origin locations correspond to previous drop-off locations), such that the mean waiting time is minimized. Our main contributions are two-fold. First, we formalize the notion of privacy for continuous vehicle-to-passenger assignment in MoD systems, and integrate a privacy mechanism that provides formal guarantees. Second, we present a scalable algorithm that takes advantage of superfluous (idle) vehicles in the system, combining multiple iterations of the Hungarian algorithm to allocate a redundant number of vehicles to a single passenger. As a result, we are able to reduce the performance deterioration induced by the privacy mechanism. We evaluate our methods on a real, large-scale data set consisting of over 11 million taxi rides (specifying vehicle availability and passenger requests), recorded over a month's duration, in the area of Manhattan, New York. Our work demonstrates that privacy can be integrated into MoD systems without incurring a significant loss of performance, and moreover, that this loss can be further minimized at the cost of deploying additional (redundant) vehicles into the fleet. version:1
arxiv-1603-07644 | Local Histogram Matching for Efficient Optical Flow Computation Applied to Velocity Estimation on Pocket Drones | http://arxiv.org/abs/1603.07644 | id:1603.07644 author:Kimberly McGuire, Guido de Croon, Christophe de Wagter, Bart Remes, Karl Tuyls, Hilbert Kappen category:cs.RO  published:2016-03-24 summary:Autonomous flight of pocket drones is challenging due to the severe limitations on on-board energy, sensing, and processing power. However, tiny drones have great potential as their small size allows maneuvering through narrow spaces while their small weight provides significant safety advantages. This paper presents a computationally efficient algorithm for determining optical flow, which can be run on an STM32F4 microprocessor (168 MHz) of a 4 gram stereo-camera. The optical flow algorithm is based on edge histograms. We propose a matching scheme to determine local optical flow. Moreover, the method allows for sub-pixel flow determination based on time horizon adaptation. We demonstrate velocity measurements in flight and use it within a velocity control-loop on a pocket drone. version:3
arxiv-1612-06702 | Efficient Optical flow and Stereo Vision for Velocity Estimation and Obstacle Avoidance on an Autonomous Pocket Drone | http://arxiv.org/abs/1612.06702 | id:1612.06702 author:Kimberly McGuire, Guido de Croon, Christophe De Wagter, Karl Tuyls, Hilbert Kappen category:cs.RO  published:2016-12-20 summary:Miniature Micro Aerial Vehicles (MAV) are very suitable for flying in indoor environments, but autonomous navigation is challenging due to their strict hardware limitations. This paper presents a highly efficient computer vision algorithm called Edge-FS for the determination of velocity and depth. It runs at 20 Hz on a 4 g stereo camera with an embedded STM32F4 microprocessor (168 MHz, 192 kB) and uses feature histograms to calculate optical flow and stereo disparity. The stereo-based distance estimates are used to scale the optical flow in order to retrieve the drone's velocity. The velocity and depth measurements are used for fully autonomous flight of a 40 g pocket drone only relying on on-board sensors. The method allows the MAV to control its velocity and avoid obstacles. version:2
arxiv-1703-04603 | Locality and Singularity for Store-Atomic Memory Models | http://arxiv.org/abs/1703.04603 | id:1703.04603 author:Egor Derevenetc, Roland Meyer, Sebastian Schweizer category:cs.DC  published:2017-03-14 summary:Robustness is a correctness notion for concurrent programs running under relaxed consistency models. The task is to check that the relaxed behavior coincides (up to traces) with sequential consistency (SC). Although computationally simple on paper (robustness has been shown to be PSPACE-complete for TSO, PGAS, and Power), building a practical robustness checker remains a challenge. The problem is that the various relaxations lead to a dramatic number of computations, only few of which violate robustness. In the present paper, we set out to reduce the search space for robustness checkers. We focus on store-atomic consistency models and establish two completeness results. The first result, called locality, states that a non-robust program always contains a violating computation where only one thread delays commands. The second result, called singularity, is even stronger but restricted to programs without lightweight fences. It states that there is a violating computation where a single store is delayed. As an application of the results, we derive a linear-size source-to-source translation of robustness to SC-reachability. It applies to general programs, regardless of the data domain and potentially with an unbounded number of threads and with unbounded buffers. We have implemented the translation and verified, for the first time, PGAS algorithms in a fully automated fashion. For TSO, our analysis outperforms existing tools. version:1
arxiv-1703-04594 | Optimization of Lattice Boltzmann Simulations on Heterogeneous Computers | http://arxiv.org/abs/1703.04594 | id:1703.04594 author:E. Calore, A. Gabbana, S. F. Schifano, R. Tripiccione category:cs.DC  published:2017-03-14 summary:High-performance computing systems are more and more often based on accelerators. Computing applications targeting those systems often follow a host-driven approach in which hosts offload almost all compute-intensive sections of the code onto accelerators; this approach only marginally exploits the computational resources available on the host CPUs, limiting performance and energy efficiency. The obvious step forward is to run compute-intensive kernels in a concurrent and balanced way on both hosts and accelerators. In this paper we consider exactly this problem for a class of applications based on Lattice Boltzmann Methods, widely used in computational fluid-dynamics. Our goal is to develop just one program, portable and able to run efficiently on several different combinations of hosts and accelerators. To reach this goal, we define common data layouts enabling the code to exploit efficiently the different parallel and vector options of the various accelerators, and matching the possibly different requirements of the compute-bound and memory-bound kernels of the application. We also define models and metrics that predict the best partitioning of workloads among host and accelerator, and the optimally achievable overall performance level. We test the performance of our codes and their scaling properties using as testbeds HPC clusters incorporating different accelerators: Intel Xeon-Phi many-core processors, NVIDIA GPUs and AMD GPUs. version:1
arxiv-1703-04587 | Minimizing Maximum Regret in Commitment Constrained Sequential Decision Making | http://arxiv.org/abs/1703.04587 | id:1703.04587 author:Qi Zhang, Satinder Singh, Edmund Durfee category:cs.AI  published:2017-03-14 summary:In cooperative multiagent planning, it can often be beneficial for an agent to make commitments about aspects of its behavior to others, allowing them in turn to plan their own behaviors without taking the agent's detailed behavior into account. Extending previous work in the Bayesian setting, we consider instead a worst-case setting in which the agent has a set of possible environments (MDPs) it could be in, and develop a commitment semantics that allows for probabilistic guarantees on the agent's behavior in any of the environments it could end up facing. Crucially, an agent receives observations (of reward and state transitions) that allow it to potentially eliminate possible environments and thus obtain higher utility by adapting its policy to the history of observations. We develop algorithms and provide theory and some preliminary empirical results showing that they ensure an agent meets its commitments with history-dependent policies while minimizing maximum regret over the possible environments. version:1
arxiv-1703-03821 | A 3-DOF Neuro-Adaptive Pose Correction System For Frameless and Maskless Cancer Radiotherapy | http://arxiv.org/abs/1703.03821 | id:1703.03821 author:Lekan Ogunmolu, Adwait Kulkarni, Yonas Tadesse, Xuejun Gu, Steve Jiang, Nicholas Gans category:cs.RO  published:2017-03-10 summary:Precise patient positioning during treatment of cancers of the head and neck region is fundamental to a successful clinical removal of malignant tumors. We propose a 3-DOF soft-robot position correcting system to correct head deviations along 3 axes. The robot consists of inflatable air bladders to move the head while ensuring patient safety and comfort. The robot is controlled with an based off an adaptive neuro-controller consisting of a state feedback regulator, a command reference tracking component, and a function approximator that compensated for parametric and non-parametric system errors in real-time. Feedback is provided by a precise 3D stereo camera for surface imaging of the head. We implement the controller on a 3D printed head-and-neck simulator and demonstrate that our control exhibits real-time learning to correct positioning deviations. version:2
arxiv-1703-04552 | Distributed Optimal Vehicle Grid Integration Strategy with User Behavior Prediction | http://arxiv.org/abs/1703.04552 | id:1703.04552 author:Yingqi Xiong, Bin Wang, Chi-cheng Chu, Rajit Gadh category:math.OC cs.DC  published:2017-03-13 summary:With the increasing of electric vehicle (EV) adoption in recent years, the impact of EV charging activities to the power grid becomes more and more significant. In this article, an optimal scheduling algorithm which combines smart EV charging and V2G gird service is developed to integrate EVs into power grid as distributed energy resources, with improved system cost performance. Specifically, an optimization problem is formulated and solved at each EV charging station according to control signal from aggregated control center and user charging behavior prediction by mean estimation and linear regression. The control center collects distributed optimization results and updates the control signal, periodically. The iteration continues until it converges to optimal scheduling. Experimental result shows this algorithm helps fill the valley and shave the peak in electric load profiles within a microgrid, while the energy demand of individual driver can be satisfied. version:1
arxiv-1612-02684 | Fixpoint Approximation of Strategic Abilities under Imperfect Information | http://arxiv.org/abs/1612.02684 | id:1612.02684 author:Wojciech Jamroga, Michał Knapik, Damian Kurpiewski category:cs.MA cs.AI cs.LO  published:2016-12-08 summary:Model checking of strategic ability under imperfect information is known to be hard. The complexity results range from NP-completeness to undecidability, depending on the precise setup of the problem. No less importantly, fixpoint equivalences do not generally hold for imperfect information strategies, which seriously hampers incremental synthesis of winning strategies. In this paper, we propose translations of ATLir formulae that provide lower and upper bounds for their truth values, and are cheaper to verify than the original specifications. That is, if the expression is verified as true then the corresponding formula of ATLir should also hold in the given model. We begin by showing where the straightforward approach does not work. Then, we propose how it can be modified to obtain guaranteed lower bounds. To this end, we alter the next-step operator in such a way that traversing one's indistinguishability relation is seen as atomic activity. Most interestingly, the lower approximation is provided by a fixpoint expression that uses a nonstandard variant of the next-step ability operator. We show the correctness of the translations, establish their computational complexity, and validate the approach by experiments with a scalable scenario of Bridge play. version:3
arxiv-1610-06819 | Multiscale Abstraction, Planning and Control using Diffusion Wavelets for Stochastic Optimal Control Problems | http://arxiv.org/abs/1610.06819 | id:1610.06819 author:Jung-Su Ha, Han-Lim Choi category:cs.RO math.OC  published:2016-10-21 summary:This work presents a multiscale framework to solve a class of stochastic optimal control problems in the context of robot motion planning and control in a complex environment. In order to handle complications resulting from a large decision space and complex environmental geometry, two key concepts are adopted: (a) a diffusion wavelet representation of the Markov chain for hierarchical abstraction of the state space; and (b) a desirability function-based representation of the Markov decision process (MDP) to efficiently calculate the optimal policy. In the proposed framework, a global plan that compressively takes into account the long time/length-scale state transition is first obtained by approximately solving an MDP whose desirability function is represented by coarse scale bases in the hierarchical abstraction. Then, a detailed local plan is computed by solving an MDP that considers wavelet bases associated with a focused region of the state space, guided by the global plan. The resulting multiscale plan is utilized to finally compute a continuous-time optimal control policy within a receding horizon implementation. Two numerical examples are presented to demonstrate the applicability and validity of the proposed approach. version:2
arxiv-1703-04382 | Cost-Based Intuitionist Probabilities on Spaces of Graphs, Hypergraphs and Theorems | http://arxiv.org/abs/1703.04382 | id:1703.04382 author:Ben Goertzel category:cs.AI  published:2017-03-13 summary:A novel partial order is defined on the space of digraphs or hypergraphs, based on assessing the cost of producing a graph via a sequence of elementary transformations. Leveraging work by Knuth and Skilling on the foundations of inference, and the structure of Heyting algebras on graph space, this partial order is used to construct an intuitionistic probability measure that applies to either digraphs or hypergraphs. As logical inference steps can be represented as transformations on hypergraphs representing logical statements, this also yields an intuitionistic probability measure on spaces of theorems. The central result is also extended to yield intuitionistic probabilities based on more general weighted rule systems defined over bicartesian closed categories. version:1
arxiv-1703-04381 | On the Transformation Capability of Feasible Mechanisms for Programmable Matter | http://arxiv.org/abs/1703.04381 | id:1703.04381 author:Othon Michail, George Skretas, Paul G. Spirakis category:cs.DS cs.DC cs.RO  published:2017-03-13 summary:In this work, we study theoretical models of \emph{programmable matter} systems. The systems under consideration consist of spherical modules, kept together by magnetic forces and able to perform two minimal mechanical operations (or movements): \emph{rotate} around a neighbor and \emph{slide} over a line. In terms of modeling, there are $n$ nodes arranged in a 2-dimensional grid and forming some initial \emph{shape}. The goal is for the initial shape $A$ to \emph{transform} to some target shape $B$ by a sequence of movements. Most of the paper focuses on \emph{transformability} questions, meaning whether it is in principle feasible to transform a given shape to another. We first consider the case in which only rotation is available to the nodes. Our main result is that deciding whether two given shapes $A$ and $B$ can be transformed to each other, is in $\mathbf{P}$. We then insist on rotation only and impose the restriction that the nodes must maintain global connectivity throughout the transformation. We prove that the corresponding transformability question is in $\mathbf{PSPACE}$ and study the problem of determining the minimum \emph{seeds} that can make feasible, otherwise infeasible transformations. Next we allow both rotations and slidings and prove universality: any two connected shapes $A,B$ of the same order, can be transformed to each other without breaking connectivity. The worst-case number of movements of the generic strategy is $\Omega(n^2)$. We improve this to $O(n)$ parallel time, by a pipelining strategy, and prove optimality of both by matching lower bounds. In the last part of the paper, we turn our attention to distributed transformations. The nodes are now distributed processes able to perform communicate-compute-move rounds. We provide distributed algorithms for a general type of transformations. version:1
arxiv-1703-04368 | Symbol Grounding via Chaining of Morphisms | http://arxiv.org/abs/1703.04368 | id:1703.04368 author:Ruiting Lian, Ben Goertzel, Linas Vepstas, David Hanson, Changle Zhou category:cs.AI  published:2017-03-13 summary:A new model of symbol grounding is presented, in which the structures of natural language, logical semantics, perception and action are represented categorically, and symbol grounding is modeled via the composition of morphisms between the relevant categories. This model gives conceptual insight into the fundamentally systematic nature of symbol grounding, and also connects naturally to practical real-world AI systems in current research and commercial use. Specifically, it is argued that the structure of linguistic syntax can be modeled as a certain asymmetric monoidal category, as e.g. implicit in the link grammar formalism; the structure of spatiotemporal relationships and action plans can be modeled similarly using "image grammars" and "action grammars"; and common-sense logical semantic structure can be modeled using dependently-typed lambda calculus with uncertain truth values. Given these formalisms, the grounding of linguistic descriptions in spatiotemporal perceptions and coordinated actions consists of following morphisms from language to logic through to spacetime and body (for comprehension), and vice versa (for generation). The mapping is indicated between the spatial relationships in the Region Connection Calculus and Allen Interval Algebra and corresponding entries in the link grammar syntax parsing dictionary. Further, the abstractions introduced here are shown to naturally model the structures and systems currently being deployed in the context of using the OpenCog cognitive architecture to control Hanson Robotics humanoid robots. version:1
arxiv-1703-04367 | Towards Efficient Verification of Population Protocols | http://arxiv.org/abs/1703.04367 | id:1703.04367 author:Michael Blondin, Stefan Jaax, Javier Esparza, Philipp J. Meyer category:cs.LO cs.DC  published:2017-03-13 summary:Population protocols are a well established model of computation by anonymous, identical finite state agents. A protocol is well-specified if from every initial configuration, all fair executions reach a common consensus. The central verification question for population protocols is the well-specification problem: deciding if a given protocol is well-specified. Esparza et al. have recently shown that this problem is decidable, but with very high complexity: it is at least as hard as the Petri net reachability problem, which is EXPSPACE-hard, and for which only algorithms of non-primitive recursive complexity are currently known. In this paper we introduce the class WS3 of well-specified strongly-silent protocols and we prove that it is suitable for automatic verification. More precisely, we show that WS3 has the same computational power as general well-specified protocols, and captures standard protocols from the literature. Moreover, we show that the membership problem for WS3 reduces to solving boolean combinations of linear constraints over N. This allowed us to develop the first software able to automatically prove well-specification for all of the infinitely many possible inputs. version:1
arxiv-1703-04361 | Toward a Formal Model of Cognitive Synergy | http://arxiv.org/abs/1703.04361 | id:1703.04361 author:Ben Goertzel category:cs.AI  published:2017-03-13 summary:"Cognitive synergy" refers to a dynamic in which multiple cognitive processes, cooperating to control the same cognitive system, assist each other in overcoming bottlenecks encountered during their internal processing. Cognitive synergy has been posited as a key feature of real-world general intelligence, and has been used explicitly in the design of the OpenCog cognitive architecture. Here category theory and related concepts are used to give a formalization of the cognitive synergy concept. A series of formal models of intelligent agents is proposed, with increasing specificity and complexity: simple reinforcement learning agents; "cognit" agents with an abstract memory and processing model; hypergraph-based agents (in which "cognit" operations are carried out via hypergraphs); hypergraph agents with a rich language of nodes and hyperlinks (such as the OpenCog framework provides); "PGMC" agents whose rich hypergraphs are endowed with cognitive processes guided via Probabilistic Growth and Mining of Combinations; and finally variations of the PrimeAGI design, which is currently being built on top of OpenCog. A notion of cognitive synergy is developed for cognitive processes acting within PGMC agents, based on developing a formal notion of "stuckness," and defining synergy as a relationship between cognitive processes in which they can help each other out when they get stuck. It is proposed that cognitive processes relating to each other synergetically, associate in a certain way with functors that map into each other via natural transformations. Cognitive synergy is proposed to correspond to a certain inequality regarding the relative costs of different paths through certain commutation diagrams. Applications of this notion of cognitive synergy to particular cognitive phenomena, and specific cognitive processes in the PrimeAGI design, are discussed. version:1
arxiv-1703-04316 | Fast Simulation of Vehicles with Non-deformable Tracks | http://arxiv.org/abs/1703.04316 | id:1703.04316 author:Martin Pecka, Karel Zimmermann, Tomáš Svoboda category:cs.RO I.6.3  published:2017-03-13 summary:This paper presents a novel technique that allows for both computationally fast and sufficiently plausible simulation of vehicles with non-deformable tracks. The method is based on an effect we have called Contact Surface Motion. A comparison with several other methods for simulation of tracked vehicle dynamics is presented with the aim to evaluate methods that are available off-the-shelf or with minimum effort in general-purpose robotics simulators. The proposed method is implemented as a plugin for the open-source physics-based simulator Gazebo using the Open Dynamics Engine. version:1
arxiv-1703-04232 | Numerical Integration and Dynamic Discretization in Heuristic Search Planning over Hybrid Domains | http://arxiv.org/abs/1703.04232 | id:1703.04232 author:Miquel Ramirez, Enrico Scala, Patrik Haslum, Sylvie Thiebaux category:cs.AI  published:2017-03-13 summary:In this paper we look into the problem of planning over hybrid domains, where change can be both discrete and instantaneous, or continuous over time. In addition, it is required that each state on the trajectory induced by the execution of plans complies with a given set of global constraints. We approach the computation of plans for such domains as the problem of searching over a deterministic state model. In this model, some of the successor states are obtained by solving numerically the so-called initial value problem over a set of ordinary differential equations (ODE) given by the current plan prefix. These equations hold over time intervals whose duration is determined dynamically, according to whether zero crossing events take place for a set of invariant conditions. The resulting planner, FS+, incorporates these features together with effective heuristic guidance. FS+ does not impose any of the syntactic restrictions on process effects often found on the existing literature on Hybrid Planning. A key concept of our approach is that a clear separation is struck between planning and simulation time steps. The former is the time allowed to observe the evolution of a given dynamical system before committing to a future course of action, whilst the later is part of the model of the environment. FS+ is shown to be a robust planner over a diverse set of hybrid domains, taken from the existing literature on hybrid planning and systems. version:1
arxiv-1703-04221 | A Hierarchical Framework of Cloud Resource Allocation and Power Management Using Deep Reinforcement Learning | http://arxiv.org/abs/1703.04221 | id:1703.04221 author:Ning Liu, Zhe Li, Zhiyuan Xu, Jielong Xu, Sheng Lin, Qinru Qiu, Jian Tang, Yanzhi Wang category:cs.DC cs.AI  published:2017-03-13 summary:Automatic decision-making approaches, such as reinforcement learning (RL), have been applied to (partially) solve the resource allocation problem adaptively in the cloud computing system. However, a complete cloud resource allocation framework exhibits high dimensions in state and action spaces, which prohibit the usefulness of traditional RL techniques. In addition, high power consumption has become one of the critical concerns in design and control of cloud computing systems, which degrades system reliability and increases cooling cost. An effective dynamic power management (DPM) policy should minimize power consumption while maintaining performance degradation within an acceptable level. Thus, a joint virtual machine (VM) resource allocation and power management framework is critical to the overall cloud computing system. Moreover, novel solution framework is necessary to address the even higher dimensions in state and action spaces. In this paper, we propose a novel hierarchical framework for solving the overall resource allocation and power management problem in cloud computing systems. The proposed hierarchical framework comprises a global tier for VM resource allocation to the servers and a local tier for distributed power management of local servers. The emerging deep reinforcement learning (DRL) technique, which can deal with complicated control problems with large state space, is adopted to solve the global tier problem. Furthermore, an autoencoder and a novel weight sharing structure are adopted to handle the high-dimensional state space and accelerate the convergence speed. On the other hand, the local tier of distributed server power managements comprises an LSTM based workload predictor and a model-free RL based power manager, operating in a distributed manner. version:1
arxiv-1703-04211 | Sequential Bayesian Optimisation as a POMDP for Environment Monitoring with UAVs | http://arxiv.org/abs/1703.04211 | id:1703.04211 author:Philippe Morere, Roman Marchant, Fabio Ramos category:cs.RO  published:2017-03-13 summary:Bayesian Optimisation has gained much popularity lately, as a global optimisation technique for functions that are expensive to evaluate or unknown a priori. While classical BO focuses on where to gather an observation next, it does not take into account practical constraints for a robotic system such as where it is physically possible to gather samples from, nor the sequential nature of the problem while executing a trajectory. In field robotics and other real-life situations, physical and trajectory constraints are inherent problems. This paper addresses these issues by formulating Bayesian Optimisation for continuous trajectories within a Partially Observable Markov Decision Process (POMDP) framework. The resulting POMDP is solved using Monte-Carlo Tree Search (MCTS), which we adapt to using a reward function balancing exploration and exploitation. Experiments on monitoring a spatial phenomenon with a UAV illustrate how our BO-POMDP algorithm outperforms competing techniques. version:1
arxiv-1703-04171 | Big Data in HEP: A comprehensive use case study | http://arxiv.org/abs/1703.04171 | id:1703.04171 author:Oliver Gutsche, Matteo Cremonesi, Peter Elmer, Bo Jayatilaka, Jim Kowalkowski, Jim Pivarski, Saba Sehrish, Cristina Mantilla Surez, Alexey Svyatkovskiy, Nhan Tran category:cs.DC  published:2017-03-12 summary:Experimental Particle Physics has been at the forefront of analyzing the worlds largest datasets for decades. The HEP community was the first to develop suitable software and computing tools for this task. In recent times, new toolkits and systems collectively called Big Data technologies have emerged to support the analysis of Petabyte and Exabyte datasets in industry. While the principles of data analysis in HEP have not changed (filtering and transforming experiment-specific data formats), these new technologies use different approaches and promise a fresh look at analysis of very large datasets and could potentially reduce the time-to-physics with increased interactivity. In this talk, we present an active LHC Run 2 analysis, searching for dark matter with the CMS detector, as a testbed for Big Data technologies. We directly compare the traditional NTuple-based analysis with an equivalent analysis using Apache Spark on the Hadoop ecosystem and beyond. In both cases, we start the analysis with the official experiment data formats and produce publication physics plots. We will discuss advantages and disadvantages of each approach and give an outlook on further studies needed. version:1
arxiv-1703-03254 | Abductive, Causal, and Counterfactual Conditionals Under Incomplete Probabilistic Knowledge | http://arxiv.org/abs/1703.03254 | id:1703.03254 author:Niki Pfeifer, Leena Tulkki category:cs.AI math.PR  published:2017-03-09 summary:We study abductive, causal, and non-causal conditionals in indicative and counterfactual formulations using probabilistic truth table tasks under incomplete probabilistic knowledge (N = 80). We frame the task as a probability-logical inference problem. The most frequently observed response type across all conditions was a class of conditional event interpretations of conditionals; it was followed by conjunction interpretations. An interesting minority of participants neglected some of the relevant imprecision involved in the premises when inferring lower or upper probability bounds on the target conditional/counterfactual ("halfway responses"). We discuss the results in the light of coherence-based probability logic and the new paradigm psychology of reasoning. version:2
arxiv-1703-00391 | A Hypercat-enabled Semantic Internet of Things Data Hub: Technical Report | http://arxiv.org/abs/1703.00391 | id:1703.00391 author:Ilias Tachmazidis, Sotiris Batsakis, John Davies, Alistair Duke, Mauro Vallati, Grigoris Antoniou, Sandra Stincic Clarke category:cs.AI cs.DB  published:2017-03-01 summary:An increasing amount of information is generated from the rapidly increasing number of sensor networks and smart devices. A wide variety of sources generate and publish information in different formats, thus highlighting interoperability as one of the key prerequisites for the success of Internet of Things (IoT). The BT Hypercat Data Hub provides a focal point for the sharing and consumption of available datasets from a wide range of sources. In this work, we propose a semantic enrichment of the BT Hypercat Data Hub, using well-accepted Semantic Web standards and tools. We propose an ontology that captures the semantics of the imported data and present the BT SPARQL Endpoint by means of a mapping between SPARQL and SQL queries. Furthermore, federated SPARQL queries allow queries over multiple hub-based and external data sources. Finally, we provide two use cases in order to illustrate the advantages afforded by our semantic approach. version:2
arxiv-1703-04115 | BetaRun 2017 Team Description Paper: Variety, Complexity, and Learning | http://arxiv.org/abs/1703.04115 | id:1703.04115 author:Olivia Michael, Oliver Obst category:cs.AI  published:2017-03-12 summary:RoboCup offers a set of benchmark problems for Artificial Intelligence in form of official world championships since 1997. The most tactical advanced and richest in terms of behavioural complexity of these is the 2D Soccer Simulation League, a simulated robotic soccer competition. BetaRun is a new attempt combining both machine learning and manual programming approaches, with the ultimate goal to arrive at a team that is trained entirely from observing and playing games, and a successor of the World Champion team Gliders 2016. version:1
arxiv-1412-8461 | From Clarity to Efficiency for Distributed Algorithms | http://arxiv.org/abs/1412.8461 | id:1412.8461 author:Yanhong A. Liu, Scott D. Stoller, Bo Lin category:cs.PL cs.DC  published:2014-12-29 summary:This article describes a very high-level language for clear description of distributed algorithms and optimizations necessary for generating efficient implementations. The language supports high-level control flows where complex synchronization conditions can be expressed using high-level queries, especially logic quantifications, over message history sequences. Unfortunately, the programs would be extremely inefficient, including consuming unbounded memory, if executed straightforwardly. We present new optimizations that automatically transform complex synchronization conditions into incremental updates of necessary auxiliary values as messages are sent and received. The core of the optimizations is the first general method for efficient implementation of logic quantifications. We have developed an operational semantics of the language, implemented a prototype of the compiler and the optimizations, and successfully used the language and implementation on a variety of important distributed algorithms. version:4
arxiv-1703-04057 | BLOCKBENCH: A Framework for Analyzing Private Blockchains | http://arxiv.org/abs/1703.04057 | id:1703.04057 author:Tien Tuan Anh Dinh, Ji Wang, Gang Chen, Rui Liu, Beng Chin Ooi, Kian-Lee Tan category:cs.DB cs.CR cs.DC  published:2017-03-12 summary:Blockchain technologies are taking the world by storm. Public blockchains, such as Bitcoin and Ethereum, enable secure peer-to-peer applications like crypto-currency or smart contracts. Their security and performance are well studied. This paper concerns recent private blockchain systems designed with stronger security (trust) assumption and performance requirement. These systems target and aim to disrupt applications which have so far been implemented on top of database systems, for example banking, finance applications. Multiple platforms for private blockchains are being actively developed and fine tuned. However, there is a clear lack of a systematic framework with which different systems can be analyzed and compared against each other. Such a framework can be used to assess blockchains' viability as another distributed data processing platform, while helping developers to identify bottlenecks and accordingly improve their platforms. In this paper, we first describe BlockBench, the first evaluation framework for analyzing private blockchains. It serves as a fair means of comparison for different platforms and enables deeper understanding of different system design choices. Any private blockchain can be integrated to BlockBench via simple APIs and benchmarked against workloads that are based on real and synthetic smart contracts. BlockBench measures overall and component-wise performance in terms of throughput, latency, scalability and fault-tolerance. Next, we use BlockBench to conduct comprehensive evaluation of three major private blockchains: Ethereum, Parity and Hyperledger Fabric. The results demonstrate that these systems are still far from displacing current database systems in traditional data processing workloads. Furthermore, there are gaps in performance among the three systems which are attributed to the design choices at different layers of the software stack. version:1
arxiv-1703-04565 | Fuzzy Model Tree For Early Effort Estimation | http://arxiv.org/abs/1703.04565 | id:1703.04565 author:Mohammad Azzeh, Ali Bou Nassif category:cs.SE cs.AI  published:2017-03-11 summary:Use Case Points (UCP) is a well-known method to estimate the project size, based on Use Case diagram, at early phases of software development. Although the Use Case diagram is widely accepted as a de-facto model for analyzing object oriented software requirements over the world, UCP method did not take sufficient amount of attention because, as yet, there is no consensus on how to produce software effort from UCP. This paper aims to study the potential of using Fuzzy Model Tree to derive effort estimates based on UCP size measure using a dataset collected for that purpose. The proposed approach has been validated against Treeboost model, Multiple Linear Regression and classical effort estimation based on the UCP model. The obtained results are promising and show better performance than those obtained by classical UCP, Multiple Linear Regression and slightly better than those obtained by Tree boost model. version:1
arxiv-1703-04567 | Learning best K analogies from data distribution for case-based software effort estimation | http://arxiv.org/abs/1703.04567 | id:1703.04567 author:Mohammad Azzeh, Yousef Elsheikh category:cs.SE cs.AI  published:2017-03-11 summary:Case-Based Reasoning (CBR) has been widely used to generate good software effort estimates. The predictive performance of CBR is a dataset dependent and subject to extremely large space of configuration possibilities. Regardless of the type of adaptation technique, deciding on the optimal number of similar cases to be used before applying CBR is a key challenge. In this paper we propose a new technique based on Bisecting k-medoids clustering algorithm to better understanding the structure of a dataset and discovering the the optimal cases for each individual project by excluding irrelevant cases. Results obtained showed that understanding of the data characteristic prior prediction stage can help in automatically finding the best number of cases for each test project. Performance figures of the proposed estimation method are better than those of other regular K-based CBR methods. version:1
arxiv-1703-03941 | A Vision-based Scheme for Kinematic Model Construction of Re-configurable Modular Robots | http://arxiv.org/abs/1703.03941 | id:1703.03941 author:Kewei Lin, Juan Rojas, Yisheng Guan category:cs.RO  published:2017-03-11 summary:Re-configurable modular robotic (RMR) systems are advantageous for their reconfigurability and versatility. A new modular robot can be built for a specific task by using modules as building blocks. However, constructing a kinematic model for a newly conceived robot requires significant work. Due to the finite size of module-types, models of all module-types can be built individually and stored in a database beforehand. With this priori knowledge, the model construction process can be automated by detecting the modules and their corresponding interconnections. Previous literature proposed theoretical frameworks for constructing kinematic models of modular robots, assuming that such information was known a priori. While well-devised mechanisms and built-in sensors can be employed to detect these parameters automatically, they significantly complicate the module design and thus are expensive. In this paper, we propose a vision-based method to identify kinematic chains and automatically construct robot models for modular robots. Each module is affixed with augmented reality (AR) tags that are encoded with unique IDs. An image of a modular robot is taken and the detected modules are recognized by querying a database that maintains all module information. The poses of detected modules are used to compute: (i) the connection between modules and (ii) joint angles of joint-modules. Finally, the robot serial-link chain is identified and the kinematic model constructed and visualized. Our experimental results validate the effectiveness of our approach. While implementation with only our RMR is shown, our method can be applied to other RMRs where self-identification is not possible. version:1
arxiv-1703-03933 | Micro-Objective Learning : Accelerating Deep Reinforcement Learning through the Discovery of Continuous Subgoals | http://arxiv.org/abs/1703.03933 | id:1703.03933 author:Sungtae Lee, Sang-Woo Lee, Jinyoung Choi, Dong-Hyun Kwak, Byoung-Tak Zhang category:cs.AI  published:2017-03-11 summary:Recently, reinforcement learning has been successfully applied to the logical game of Go, various Atari games, and even a 3D game, Labyrinth, though it continues to have problems in sparse reward settings. It is difficult to explore, but also difficult to exploit, a small number of successes when learning policy. To solve this issue, the subgoal and option framework have been proposed. However, discovering subgoals online is too expensive to be used to learn options in large state spaces. We propose Micro-objective learning (MOL) to solve this problem. The main idea is to estimate how important a state is while training and to give an additional reward proportional to its importance. We evaluated our algorithm in two Atari games: Montezuma's Revenge and Seaquest. With three experiments to each game, MOL significantly improved the baseline scores. Especially in Montezuma's Revenge, MOL achieved two times better results than the previous state-of-the-art model. version:1
arxiv-1703-03912 | The Curse of Correlation in Security Games and Principle of Max-Entropy | http://arxiv.org/abs/1703.03912 | id:1703.03912 author:Haifeng Xu, Milind Tambe, Shaddin Dughmi, Venil Loyd Noronha category:cs.GT cs.AI cs.CR  published:2017-03-11 summary:In this paper, we identify and study a fundamental, yet underexplored, phenomenon in security games, which we term the Curse of Correlation (CoC). Specifically, we observe that there is inevitable correlation among the protection status of different targets. Such correlation is a crucial concern, especially in spatio-temporal domains like conservation area patrolling, where attackers can monitor patrollers at certain areas and then infer their patrolling routes using such correlation. To mitigate this issue, we introduce the principle of max-entropy to security games, and focus on designing entropy-maximizing defending strategies for the spatio-temporal security game -- a major victim of CoC. We prove that the problem is #P-hard in general, but propose efficient algorithms in well-motivated special settings. Our experiments show significant advantages of the max-entropy algorithms against previous algorithms. version:1
arxiv-1703-03904 | DotGrid: a .NET-based cross-platform software for desktop grids | http://arxiv.org/abs/1703.03904 | id:1703.03904 author:Alireza Poshtkohi, Ali Haj Abutalebi, Shaahin Hessabi category:cs.DC  published:2017-03-11 summary:Grid infrastructures that have provided wide integrated use of resources are becoming the de-facto computing platform for solving large-scale problems in science, engineering and commerce. In this evolution, desktop grid technologies allow the grid communities to exploit the idle cycles of pervasive desktop PC systems to increase the available computing power. In this paper we present DotGrid, a cross-platform grid software. DotGrid is the first comprehensive desktop grid software utilising Microsoft's .NET Framework in Windows-based environments and MONO .NET in Unix-class operating systems to operate. Using DotGrid services and APIs, grid desktop middleware and applications can be implemented conveniently. We evaluated our DotGrid's performance by implementing a set of grid-based applications. version:1
arxiv-1703-07706 | Ozone: Efficient Execution with Zero Timing Leakage for Modern Microarchitectures | http://arxiv.org/abs/1703.07706 | id:1703.07706 author:Zelalem Birhanu Aweke, Todd Austin category:cs.CR cs.AR  published:2017-03-10 summary:Time variation during program execution can leak sensitive information. Time variations due to program control flow and hardware resource contention have been used to steal encryption keys in cipher implementations such as AES and RSA. A number of approaches to mitigate timing-based side-channel attacks have been proposed including cache partitioning, control-flow obfuscation and injecting timing noise into the outputs of code. While these techniques make timing-based side-channel attacks more difficult, they do not eliminate the risks. Prior techniques are either too specific or too expensive, and all leave remnants of the original timing side channel for later attackers to attempt to exploit. In this work, we show that the state-of-the-art techniques in timing side-channel protection, which limit timing leakage but do not eliminate it, still have significant vulnerabilities to timing-based side-channel attacks. To provide a means for total protection from timing-based side-channel attacks, we develop Ozone, the first zero timing leakage execution resource for a modern microarchitecture. Code in Ozone execute under a special hardware thread that gains exclusive access to a single core's resources for a fixed (and limited) number of cycles during which it cannot be interrupted. Memory access under Ozone thread execution is limited to a fixed size uncached scratchpad memory, and all Ozone threads begin execution with a known fixed microarchitectural state. We evaluate Ozone using a number of security sensitive kernels that have previously been targets of timing side-channel attacks, and show that Ozone eliminates timing leakage with minimal performance overhead. version:1
arxiv-1702-00361 | Agreement Functions for Distributed Computing Models | http://arxiv.org/abs/1702.00361 | id:1702.00361 author:Petr Kuznetsov, Thibault Rieutord category:cs.DC  published:2017-02-01 summary:The paper proposes a surprisingly simple characterization of a large class of models of distributed computing, via an agreement function: for each set of processes, the function determines the best level of set consensus these processes can reach. We show that the task computability of a large class of fair adversaries that includes, in particular superset-closed and symmetric one, is precisely captured by agreement functions. version:3
arxiv-1609-03897 | Design of a Ternary Edge-Triggered D Flip-Flap-Flop for Multiple-Valued Sequential Logic | http://arxiv.org/abs/1609.03897 | id:1609.03897 author:Reza Faghih Mirzaee, Niloofar Farahani category:cs.AR B.3; B.6.1; B.7.1  published:2016-09-13 summary:Development of large computerized systems requires both combinational and sequential circuits. Registers and counters are two important examples of sequential circuits, which are widely used in practical applications like CPUs. The basic element of sequential logic is Flip-Flop, which stores an input value and returns two outputs (Q and Q_bar). This paper presents an innovative ternary D Flip-Flap-Flop, which offers circuit designers to customize their design by eliminating one of the outputs if it is not required. This unique feature of the new design leads to considerable power reduction in comparison with the previously presented structures. The proposed design is simulated and tested by HSPICE and 45 nm CMOS technology. version:3
arxiv-1702-00019 | Optimal Synthesis of Overconstrained 6R Linkages by Curve Evolution | http://arxiv.org/abs/1702.00019 | id:1702.00019 author:Tudor-Dan Rad, Hans-Peter Schröcker category:cs.RO 70B10  published:2017-01-31 summary:The paper presents an optimal synthesis of overconstrained linkages, based on the factorization of rational curves (representing one parametric motions) contained in Study's quadric. The group of Euclidean displacements is embedded in a affine space where a metric between motions based on the homogeneous mass distribution of the end effector is used to evolve the curves such that they are fitted to a set of target poses. The metric will measure the distance (in Euclidean sense) between the two resulting vectors of the feature points displaced by the two motions. The evolution is driven by the normal velocity of the curve projected in the direction of the target points. In the end we present an example for the optimal synthesis of an overconstrained $6R$ linkage by choosing a set of target poses and explaining in steps how this approach is implemented. version:2
arxiv-1703-03649 | Localization of Internet-based Mobile Robot | http://arxiv.org/abs/1703.03649 | id:1703.03649 author:Manh Duong Phung, Thi Thanh Van Nguyen, Thuan Hoang Tran, Quang Vinh Tran category:cs.RO  published:2017-03-10 summary:This paper presents a new optimal filter namely past observation-based extended Kalman filter for the problem of localization of Internet-based mobile robot in which the control input and the feedback measurement suffer from communication delay. The filter operates through two phases: the time update and the data correction. The time update predicts the robot position by reformulating the kinematics model to be non-memoryless. The correction step corrects the prediction by extrapolating the delayed measurement to the present and then incorporating it to the being estimate as there is no delay. The optimality of the incorporation is ensured by the derivation of a multiplier that reflects the relevance of past observations to the present. Simulations in MATLAB and experiments in a real networked robot system confirm the validity of the proposed approach. version:1
arxiv-1703-03607 | The Efficiency Challenges of Resource Discovery in Grid Environments | http://arxiv.org/abs/1703.03607 | id:1703.03607 author:Mahdi MollaMotalebi, Raheleh Maghami, Abdul Samad Ismail, Alireza Poshtkohi category:cs.DC H.3.4; K.6  published:2017-03-10 summary:Resource discovery is one of the most important services that significantly affects the efficiency of grid computing systems. The inherent dynamic and large-scale characteristics of grid environments make their resource discovery a challenging task. In recent years, different approaches have been proposed for resource discovery, attempting to tackle the challenges of grid environments and improve the efficiency. Being aware of these challenges and approaches is worthwhile in order to choose an appropriate approach according to the application in different organizations. This study reviews the most important factors that should be considered and challenges to be tackled in order to develop an efficient grid resource discovery system. version:1
arxiv-1703-03594 | The xDotGrid Native, Cross-Platform, High-Performance xDFS File Transfer Framework | http://arxiv.org/abs/1703.03594 | id:1703.03594 author:Alireza Poshtkohi, M. B. Ghaznavi-Ghoushchi category:cs.DC  published:2017-03-10 summary:In this paper we introduce and describe the highly concurrent xDFS file transfer protocol and examine its cross-platform and cross-language implementation in native code for both Linux and Windows in 32 or 64-bit multi-core processor architectures. The implemented xDFS protocol based on xDotGrid.NET framework is fully compared with the Globus GridFTP protocol. We finally propose the xDFS protocol as a new paradigm of distributed systems for Internet services, and data-intensive Grid and Cloud applications. Also, we incrementally consider different developmental methods of the optimum file transfer systems, and their advantages and disadvantages. The vision of this paper tries as possible to minimize the overhead concerned with the file transfer protocol itself and to examine optimal software design patterns of that protocol. In all disk-to-disk tests for transferring a 2GB file with or without parallelism, the xDFS throughput at minimum 30% and at most 53% was superior to the GridFTP. version:1
arxiv-1703-03453 | Using Options for Long-Horizon Off-Policy Evaluation | http://arxiv.org/abs/1703.03453 | id:1703.03453 author:Zhaohan Daniel Guo, Philip S. Thomas, Emma Brunskill category:cs.AI  published:2017-03-09 summary:Evaluating a policy by deploying it in the real world can be risky and costly. Off-policy evaluation (OPE) algorithms use historical data collected from running a previous policy to evaluate a new policy, which provides a means for evaluating a policy without requiring it to ever be deployed. Importance sampling is a popular OPE method because it is robust to partial observability and works with continuous states and actions. However, we show that the amount of historical data required by importance sampling can scale exponentially with the horizon of the problem: the number of sequential decisions that are made. We propose using policies over temporally extended actions, called options, to address this long-horizon problem. We show theoretically and experimentally that combining importance sampling with options-based policies can significantly improve performance for long-horizon problems. version:1
arxiv-1701-08623 | Dynamic System Identification, and Control for a cost effective open-source VTOL MAV | http://arxiv.org/abs/1701.08623 | id:1701.08623 author:Inkyu Sa, Mina Kamel, Raghav Khanna, Marija Popovic, Juan Nieto, Roland Siegwart category:cs.RO  published:2017-01-30 summary:This paper describes dynamic system identification, and full control of a cost-effective vertical take-off and landing (VTOL) multi-rotor micro-aerial vehicle (MAV) --- DJI Matrice 100. The dynamics of the vehicle and autopilot controllers are identified using only a built-in IMU and utilized to design a subsequent model predictive controller (MPC). Experimental results for the control performance are evaluated using a motion capture system while performing hover, step responses, and trajectory following tasks in the present of external wind disturbances. We achieve root-mean-square (RMS) errors between the reference and actual trajectory of x=0.021m, y=0.016m, z=0.029m, roll=0.392deg, pitch=0.618deg, and yaw=1.087deg while performing hover. This paper also conveys the insights we have gained about the platform and returned to the community through open-source code, and documentation. version:2
arxiv-1703-03315 | Self-Stabilizing Disconnected Components Detection and Rooted Shortest-Path Tree Maintenance in Polynomial Steps | http://arxiv.org/abs/1703.03315 | id:1703.03315 author:Stéphane Devismes, David Ilcinkas, Colette Johnen category:cs.DC  published:2017-03-09 summary:We deal with the problem of maintaining a shortest-path tree rooted at some process r in a network that may be disconnected after topological changes. The goal is then to maintain a shortest-path tree rooted at r in its connected component, Vr, and make all processes of other components detecting that r is not part of their connected component. We propose, in the composite atomicity model, a silent self-stabilizing algorithm for this problem working in semi-anonymous networks, where edges have strictly positive weights. This algorithm does not require any a priori knowledge about global parameters of the network. We prove its correctness assuming the distributed unfair daemon, the most general daemon. Its stabilization time in rounds is at most 3nmaxCC + D, where nmaxCC is the maximum number of non-root processes in a connected component and D is the hop-diameter of Vr. Furthermore, if we additionally assume that edge weights are positive integers, then it stabilizes in a polynomial number of steps: namely, we exhibit a bound in O(WmaxnmaxCC 3 n), where Wmax is the maximum weight of an edge and n is the number of processes. version:1
arxiv-1703-02582 | Efficient motion planning for problems lacking optimal substructure | http://arxiv.org/abs/1703.02582 | id:1703.02582 author:Oren Salzman, Brian Hou, Siddhartha Srinivasa category:cs.RO  published:2017-03-07 summary:We consider the motion-planning problem of planning a collision-free path of a robot in the presence of risk zones. The robot is allowed to travel in these zones but is penalized in a super-linear fashion for consecutive accumulative time spent there. We suggest a natural cost function that balances path length and risk-exposure time. Specifically, we consider the discrete setting where we are given a graph, or a roadmap, and we wish to compute the minimal-cost path under this cost function. Interestingly, paths defined using our cost function do not have an optimal substructure. Namely, subpaths of an optimal path are not necessarily optimal. Thus, the Bellman condition is not satisfied and standard graph-search algorithms such as Dijkstra cannot be used. We present a path-finding algorithm, which can be seen as a natural generalization of Dijkstra's algorithm. Our algorithm runs in $O\left((n_B\cdot n) \log( n_B\cdot n) + n_B\cdot m\right)$ time, where~$n$ and $m$ are the number of vertices and edges of the graph, respectively, and $n_B$ is the number of intersections between edges and the boundary of the risk zone. We present simulations on robotic platforms demonstrating both the natural paths produced by our cost function and the computational efficiency of our algorithm. version:2
arxiv-1703-03255 | Counterfactuals, indicative conditionals, and negation under uncertainty: Are there cross-cultural differences? | http://arxiv.org/abs/1703.03255 | id:1703.03255 author:Niki Pfeifer, Hiroshi Yama category:cs.AI math.LO math.PR  published:2017-03-09 summary:In this paper we study selected argument forms involving counterfactuals and indicative conditionals under uncertainty. We selected argument forms to explore whether people with an Eastern cultural background reason differently about conditionals compared to Westerners, because of the differences in the location of negations. In a 2x2 between-participants design, 63 Japanese university students were allocated to four groups, crossing indicative conditionals and counterfactuals, and each presented in two random task orders. The data show close agreement between the responses of Easterners and Westerners. The modal responses provide strong support for the hypothesis that conditional probability is the best predictor for counterfactuals and indicative conditionals. Finally, the grand majority of the responses are probabilistically coherent, which endorses the psychological plausibility of choosing coherence-based probability logic as a rationality framework for psychological reasoning research. version:1
arxiv-1702-01795 | ASHACL: Alternative Shapes Constraint Language | http://arxiv.org/abs/1702.01795 | id:1702.01795 author:Peter F. Patel-Schneider category:cs.AI  published:2017-02-06 summary:ASHACL, a variant of the W3C Shapes Constraint Language, is designed to determine whether an RDF graph meets some conditions. These conditions are grouped into shapes, which validate whether particular RDF terms each meet the constraints of the shape. Shapes are themselves expressed as RDF triples in an RDF graph, called a shapes graph. version:2
arxiv-1703-03233 | Modeling the Ellsberg Paradox by Argument Strength | http://arxiv.org/abs/1703.03233 | id:1703.03233 author:Niki Pfeifer, Hanna Pankka category:cs.AI math.LO math.PR  published:2017-03-09 summary:We present a formal measure of argument strength, which combines the ideas that conclusions of strong arguments are (i) highly probable and (ii) their uncertainty is relatively precise. Likewise, arguments are weak when their conclusion probability is low or when it is highly imprecise. We show how the proposed measure provides a new model of the Ellsberg paradox. Moreover, we further substantiate the psychological plausibility of our approach by an experiment (N = 60). The data show that the proposed measure predicts human inferences in the original Ellsberg task and in corresponding argument strength tasks. Finally, we report qualitative data taken from structured interviews on folk psychological conceptions on what argument strength means. version:1
arxiv-1703-03225 | Anomaly Detection and Redundancy Elimination of Big Sensor Data in Internet of Things | http://arxiv.org/abs/1703.03225 | id:1703.03225 author:Sai Xie, Zhe Chen category:cs.DC cs.NI  published:2017-03-09 summary:In the era of big data and Internet of things, massive sensor data are gathered with Internet of things. Quantity of data captured by sensor networks are considered to contain highly useful and valuable information. However, for a variety of reasons, received sensor data often appear abnormal. Therefore, effective anomaly detection methods are required to guarantee the quality of data collected by those sensor nodes. Since sensor data are usually correlated in time and space, not all the gathered data are valuable for further data processing and analysis. Preprocessing is necessary for eliminating the redundancy in gathered massive sensor data. In this paper, the proposed work defines a sensor data preprocessing framework. It is mainly composed of two parts, i.e., sensor data anomaly detection and sensor data redundancy elimination. In the first part, methods based on principal statistic analysis and Bayesian network is proposed for sensor data anomaly detection. Then, approaches based on static Bayesian network (SBN) and dynamic Bayesian networks (DBNs) are proposed for sensor data redundancy elimination. Static sensor data redundancy detection algorithm (SSDRDA) for eliminating redundant data in static datasets and real-time sensor data redundancy detection algorithm (RSDRDA) for eliminating redundant sensor data in real-time are proposed. The efficiency and effectiveness of the proposed methods are validated using real-world gathered sensor datasets. version:1
arxiv-1703-02335 | Effects of Faults, Experience, and Personality on Trust in a Robot Co-Worker | http://arxiv.org/abs/1703.02335 | id:1703.02335 author:Satragni Sarkar, Dejanira Araiza-Illan, Kerstin Eder category:cs.RO cs.HC  published:2017-03-07 summary:To design trustworthy robots, we need to understand the impact factors of trust: people's attitudes, experience, and characteristics; the robot's physical design, reliability, and performance; a task's specification and the circumstances under which it is to be performed, e.g. at leisure or under time pressure. As robots are used for a wide variety of tasks and applications, robot designers ought to be provided with evidence and guidance, to inform their decisions to achieve safe, trustworthy and efficient human-robot interactions. In this work, the impact factors of trust in a collaborative manufacturing scenario are studied by conducting an experiment with a real robot and participants where a physical object was assembled and then disassembled. Objective and subjective measures were employed to evaluate the development of trust, under faulty and non-faulty robot conditions, and the effect of previous experience with robots, and personality traits. Our findings highlight differences when compared to other, more social, scenarios with robotic assistants (such as a home care assistant), in that the condition (faulty or not) does not have a significant impact on the human's perception of the robot in terms of human-likeliness, likeability, trustworthiness, and even competence. However, personality and previous experience do have an effect on how the robot is perceived by participants, even though that is relatively small. version:2
arxiv-1703-03193 | Embedding Tarskian Semantics in Vector Spaces | http://arxiv.org/abs/1703.03193 | id:1703.03193 author:Taisuke Sato category:cs.AI cs.LO  published:2017-03-09 summary:We propose a new linear algebraic approach to the computation of Tarskian semantics in logic. We embed a finite model M in first-order logic with N entities in N-dimensional Euclidean space R^N by mapping entities of M to N dimensional one-hot vectors and k-ary relations to order-k adjacency tensors (multi-way arrays). Second given a logical formula F in prenex normal form, we compile F into a set Sigma_F of algebraic formulas in multi-linear algebra with a nonlinear operation. In this compilation, existential quantifiers are compiled into a specific type of tensors, e.g., identity matrices in the case of quantifying two occurrences of a variable. It is shown that a systematic evaluation of Sigma_F in R^N gives the truth value, 1(true) or 0(false), of F in M. Based on this framework, we also propose an unprecedented way of computing the least models defined by Datalog programs in linear spaces via matrix equations and empirically show its effectiveness compared to state-of-the-art approaches. version:1
arxiv-1703-03190 | Robustness in Highly Dynamic Networks | http://arxiv.org/abs/1703.03190 | id:1703.03190 author:Arnaud Casteigts, Swan Dubois, Franck Petit, John Michael Robson category:cs.DC cs.DM  published:2017-03-09 summary:We investigate a special case of hereditary property that we refer to as {\em robustness}. A property is {\em robust} in a given graph if it is inherited by all connected spanning subgraphs of this graph. We motivate this definition in different contexts, showing that it plays a central role in highly dynamic networks, although the problem is defined in terms of classical (static) graph theory. In this paper, we focus on the robustness of {\em maximal independent sets} (MIS). Following the above definition, a MIS is said to be {\em robust} (RMIS) if it remains a valid MIS in all connected spanning subgraphs of the original graph. We characterize the class of graphs in which {\em all} possible MISs are robust. We show that, in these particular graphs, the problem of finding a robust MIS is {\em local}; that is, we present an RMIS algorithm using only a sublogarithmic number of rounds (in the number of nodes $n$) in the ${\cal LOCAL}$ model. On the negative side, we show that, in general graphs, the problem is not local. Precisely, we prove a $\Omega(n)$ lower bound on the number of rounds required for the nodes to decide consistently in some graphs. This result implies a separation between the RMIS problem and the MIS problem in general graphs. It also implies that any strategy in this case is asymptotically (in order) as bad as collecting all the network information at one node and solving the problem in a centralized manner. Motivated by this observation, we present a centralized algorithm that computes a robust MIS in a given graph, if one exists, and rejects otherwise. Significantly, this algorithm requires only a polynomial amount of local computation time, despite the fact that exponentially many MISs and exponentially many connected spanning subgraphs may exist. version:1
arxiv-1703-03161 | Behavior-based Navigation of Mobile Robot in Unknown Environments Using Fuzzy Logic and Multi-Objective Optimization | http://arxiv.org/abs/1703.03161 | id:1703.03161 author:Thi Thanh Van Nguyen, Manh Duong Phung, Quang Vinh Tran category:cs.RO cs.AI cs.SY  published:2017-03-09 summary:This study proposes behavior-based navigation architecture, named BBFM, to deal with the problem of navigating the mobile robot in unknown environments in the presence of obstacles and local minimum regions. In the architecture, the complex navigation task is split into principal sub-tasks or behaviors. Each behavior is implemented by a fuzzy controller and executed independently to deal with a specific problem of navigation. The fuzzy controller is modified to contain only the fuzzification and inference procedures so that its output is a membership function representing the behavior's objective. The membership functions of all controllers are then used as the objective functions for a multi-objective optimization process to coordinate all behaviors. The result of this process is an overall control signal, which is Pareto-optimal, used to control the robot. A number of simulations, comparisons, and experiments were conducted. The results show that the proposed architecture outperforms some popular behavior-based architectures in term of accuracy, smoothness, traveled distance, and time response. version:1
arxiv-1703-03146 | An Approach to Autonomous Science by Modeling Geological Knowledge in a Bayesian Framework | http://arxiv.org/abs/1703.03146 | id:1703.03146 author:Akash Arora, Robert Fitch, Salah Sukkarieh category:cs.RO  published:2017-03-09 summary:Autonomous Science is a field of study which aims to extend the autonomy of exploration robots from low level functionality, such as on-board perception and obstacle avoidance, to science autonomy, which allows scientists to specify missions at task level. This will enable more remote and extreme environments such as deep ocean and other planets to be studied, leading to significant science discoveries. This paper presents an approach to extend the high level autonomy of robots by encoding scientific knowledge in the form of Bayesian networks. Reasoning about this network to plan informative sensing actions is, however, a challenging optimization problem due to large state and observation spaces. To tackle this, we employ an anytime sampling-based non-myopic planner. The Bayesian network and planner are applied in a mission in which the robot is required to plan the placement of multiple sensors to study a scientific latent variable of interest. Extensive simulation results show that our approach has significant performance benefits over alternative methods. We also demonstrate the practicality of our approach in an analog Martian environment where our experimental rover, Continuum, plans and executes a science mission autonomously. version:1
arxiv-1703-03693 | On Quantum Decision Trees | http://arxiv.org/abs/1703.03693 | id:1703.03693 author:Subhash Kak category:cs.AI  published:2017-03-08 summary:Quantum decision systems are being increasingly considered for use in artificial intelligence applications. Classical and quantum nodes can be distinguished based on certain correlations in their states. This paper investigates some properties of the states obtained in a decision tree structure. How these correlations may be mapped to the decision tree is considered. Classical tree representations and approximations to quantum states are provided. version:1
arxiv-1510-00552 | Exposing the Probabilistic Causal Structure of Discrimination | http://arxiv.org/abs/1510.00552 | id:1510.00552 author:Francesco Bonchi, Sara Hajian, Bud Mishra, Daniele Ramazzotti category:cs.DB cs.AI  published:2015-10-02 summary:Discrimination discovery from data is an important task aiming at identifying patterns of illegal and unethical discriminatory activities against protected-by-law groups, e.g., ethnic minorities. While any legally-valid proof of discrimination requires evidence of causality, the state-of-the-art methods are essentially correlation-based, albeit, as it is well known, correlation does not imply causation. In this paper we take a principled causal approach to the data mining problem of discrimination detection in databases. Following Suppes' probabilistic causation theory, we define a method to extract, from a dataset of historical decision records, the causal structures existing among the attributes in the data. The result is a type of constrained Bayesian network, which we dub Suppes-Bayes Causal Network (SBCN). Next, we develop a toolkit of methods based on random walks on top of the SBCN, addressing different anti-discrimination legal concepts, such as direct and indirect discrimination, group and individual discrimination, genuine requirement, and favoritism. Our experiments on real-world datasets confirm the inferential power of our approach in all these different tasks. version:3
arxiv-1703-02949 | Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning | http://arxiv.org/abs/1703.02949 | id:1703.02949 author:Abhishek Gupta, Coline Devin, YuXuan Liu, Pieter Abbeel, Sergey Levine category:cs.AI cs.RO  published:2017-03-08 summary:People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where two agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of "analogy making", or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven. version:1
arxiv-1703-02854 | Multiresolution Mapping and Informative Path Planning for UAV-based Terrain Monitoring | http://arxiv.org/abs/1703.02854 | id:1703.02854 author:Marija Popovic, Teresa Vidal-Calleja, Gregory Hitz, Inkyu Sa, Roland Siegwart, Juan Nieto category:cs.RO  published:2017-03-08 summary:Unmanned aerial vehicles (UAVs) can offer timely and cost-effective delivery of high-quality sensing data. How- ever, deciding when and where to take measurements in complex environments remains an open challenge. To address this issue, we introduce a new multiresolution mapping approach for informative path planning in terrain monitoring using UAVs. Our strategy exploits the spatial correlation encoded in a Gaussian Process model as a prior for Bayesian data fusion with probabilistic sensors. This allows us to incorporate altitude-dependent sensor models for aerial imaging and perform constant-time measurement updates. The resulting maps are used to plan information-rich trajectories in continuous 3-D space through a combination of grid search and evolutionary optimization. We evaluate our framework on the application of agricultural biomass monitoring. Extensive simulations show that our planner performs better than existing methods, with mean error reductions of up to 45% compared to traditional "lawnmower" coverage. We demonstrate proof of concept using a multirotor to map color in different environments. version:1
arxiv-1510-08473 | A Certain Tendency Of The Database Community | http://arxiv.org/abs/1510.08473 | id:1510.08473 author:Christopher S. Meiklejohn category:cs.DC  published:2015-10-28 summary:We posit that striving for distributed systems that provide "single system image" semantics is fundamentally flawed and at odds with how systems operate in the physical world. We realize the database as an optimization of this system: a required, essential optimization in practice that facilitates central data placement and ease of access to participants in a system. We motivate a new model of computation that is designed to address the problems of computation over "eventually consistent" information in a large-scale distributed system. version:3
arxiv-1703-02788 | Evaluation of DVFS techniques on modern HPC processors and accelerators for energy-aware applications | http://arxiv.org/abs/1703.02788 | id:1703.02788 author:Enrico Calore, Alessandro Gabbana, Sebastiano Fabio Schifano, Raffaele Tripiccione category:cs.DC cs.PF  published:2017-03-08 summary:Energy efficiency is becoming increasingly important for computing systems, in particular for large scale HPC facilities. In this work we evaluate, from an user perspective, the use of Dynamic Voltage and Frequency Scaling (DVFS) techniques, assisted by the power and energy monitoring capabilities of modern processors in order to tune applications for energy efficiency. We run selected kernels and a full HPC application on two high-end processors widely used in the HPC context, namely an NVIDIA K80 GPU and an Intel Haswell CPU. We evaluate the available trade-offs between energy-to-solution and time-to-solution, attempting a function-by-function frequency tuning. We finally estimate the benefits obtainable running the full code on a HPC multi-GPU node, with respect to default clock frequency governors. We instrument our code to accurately monitor power consumption and execution time without the need of any additional hardware, and we enable it to change CPUs and GPUs clock frequencies while running. We analyze our results on the different architectures using a simple energy-performance model, and derive a number of energy saving strategies which can be easily adopted on recent high-end HPC systems for generic applications. version:1
arxiv-1605-01903 | Deterministic Leader Election Takes $Θ(D + \log n)$ Bit Rounds | http://arxiv.org/abs/1605.01903 | id:1605.01903 author:Arnaud Casteigts, Yves Métivier, John Michael Robson, Akka Zemmari category:cs.DC  published:2016-05-06 summary:Leader election is, together with consensus, one of the most central problems in distributed computing. This paper presents a distributed algorithm, called \STT, for electing deterministically a leader in an arbitrary network, assuming processors have unique identifiers of size $O(\log n)$, where $n$ is the number of processors. It elects a leader in $O(D +\log n)$ rounds, where $D$ is the diameter of the network, with messages of size $O(1)$. Thus it has a bit round complexity of $O(D +\log n)$. This substantially improves upon the best known algorithm whose bit round complexity is $O(D\log n)$. In fact, using the lower bound by Kutten et al. (2015) and result of Dinitz and Solomon (2007), we show that the bit round complexity of \STT is optimal (up to a constant factor), which is a significant step forward in understanding the interplay between time and message optimality for the election problem. Our algorithm requires no knowledge on the graph such as $n$ or $D$, and the pipelining technique we introduce to break the $O(D\log n)$ barrier is general. version:3
arxiv-1703-02755 | A Scalable Data Streaming Infrastructure for Smart Cities | http://arxiv.org/abs/1703.02755 | id:1703.02755 author:Jesus Arias Fisteus, Luis Sanchez Fernandez, Victor Corcoba Magaña, Mario Muñoz Organero, Jorge Yago Fernandez, Juan Antonio Alvarez Garcia category:cs.DC  published:2017-03-08 summary:Many of the services a smart city can provide to its citizens rely on the ability of its infrastructure to collect and process in real time vast amounts of continuous data that sensors deployed through the city produce. In this paper we present the server infrastructure we have designed in the context of the HERMES project to collect the data from sensors and aggregate it in streams for their use in services of the smart city. version:1
arxiv-1607-02951 | Design Patterns in Beeping Algorithms: Examples, Emulation, and Analysis | http://arxiv.org/abs/1607.02951 | id:1607.02951 author:Arnaud Casteigts, Yves Métivier, John Michael Robson, Akka Zemmari category:cs.DC cs.DS  published:2016-07-11 summary:We consider networks of processes which interact with beeps. In the basic model defined by Cornejo and Kuhn (2010), processes can choose in each round either to beep or to listen. Those who beep are unable to detect simultaneous beeps. Those who listen can only distinguish between silence and the presence of at least one beep. We refer to this model as $BL$ (beep or listen). Stronger models exist where the nodes can detect collision while they are beeping ($B_{cd}L$), listening ($BL_{cd}$), or both ($B_{cd}L_{cd}$). Beeping models are weak in essence and even simple tasks are difficult or unfeasible within. We present a set of generic building blocks (design patterns) which seem to occur frequently in the design of beeping algorithms. They include multi-slot phases: the fact of dividing the main loop into a number of specialised slots; exclusive beeps: having a single node beep at a time in a neighbourhood (within one or two hops); adaptive probability: increasing or decreasing the probability of beeping to produce more exclusive beeps; internal (resp. peripheral) collision detection: for detecting collision while beeping (resp. listening). Based on these patterns, we provide algorithms for a number of basic problems, including colouring, 2-hop colouring, degree computation, 2-hop MIS, and collision detection (in $BL$). The patterns make it possible to formulate these algorithms in a rather concise and elegant way. Their analyses are more technical; one of them improves significantly upon that of the best known MIS algorithm by Jeavons et al. (2016). Finally, inspired by a technique from Afek et al. (2013), our last contribution is to show that any Las Vegas algorithm relying on collision detection can be transposed into a Monte Carlo algorithm without collision detection at the cost of a logarithmic slowdown, which we prove is optimal. version:2
arxiv-1609-08811 | On-board Communication-based Relative Localization for Collision Avoidance in Micro Air Vehicle teams | http://arxiv.org/abs/1609.08811 | id:1609.08811 author:Mario Coppola, Kimberly McGuire, Kirk Y. W. Scheper, Guido C. H. E. de Croon category:cs.RO  published:2016-09-28 summary:Micro Air Vehicles (MAVs) will unlock their true potential once they can operate in groups. To this end, it is essential for them to estimate on-board the relative location of their neighbors. The challenge lies in limiting the mass and processing burden needed to enable this. We developed a relative localization method that only requires the MAVs to communicate via their wireless transceiver. Communication allows the exchange of on-board states (velocity, height, and orientation), while the signal-strength provides range data. These quantities are fused to provide a full relative location estimate. We used our method to tackle the problem of collision avoidance in tight areas. The system was tested with a team of AR.Drones flying in a 4mx4m area and with miniature drones of ~50g in a 2mx2m area. The MAVs were able to track their relative positions and fly several minutes without collisions. Our implementation used Bluetooth to communicate between the drones. This featured significant noise and disturbances in signal-strength, which worsened as more drones were added. Simulation analysis suggests that results can improve with a more suitable transceiver module. version:2
arxiv-1703-02743 | MSF and Connectivity in Limited Variants of the Congested Clique | http://arxiv.org/abs/1703.02743 | id:1703.02743 author:Tomasz Jurdzinski, Krzysztof Nowicki category:cs.DC cs.DS  published:2017-03-08 summary:The congested clique is a synchronous, message-passing model of distributed computing in which each computational unit (node) in each round can send message of O(log n) bits to each other node of the network, where n is the number of nodes. This model has been considered under two extreme scanarios: unicast or broadcast. In the unicast model, a node can send (possibly) different message to each other node of the network. In contrast, in the broadcast model each node sends a single (the same) message to all other nodes. We study the congested clique model parametrized by the range r, the maximum number of different messages a node can send in one round. Following recent progress in design of algorihms for graph connectivity and minimum span- ning forest (MSF) in the unicast congested clique, we study these problems in limited variants of the congested clique. We present the first sub-logarithmic algorithm for connected components in the broadcast congested clique. Then, we show that efficient unicast deterministic algorithm for MSF and randomized algorithm for connected components can be efficiently imple- mented in the rcast model with range r = 2, the weakest model of the congested clique above the broadcast variant (r = 1) in the hierarchy with respect to range. More importantly, our al- gorithms give the first solutions with optimal capacity of communication edges, while preserving small round complexity. version:1
arxiv-1609-03250 | DESPOT: Online POMDP Planning with Regularization | http://arxiv.org/abs/1609.03250 | id:1609.03250 author:Nan Ye, Adhiraj Somani, David Hsu, Wee Sun Lee category:cs.AI  published:2016-09-12 summary:The partially observable Markov decision process (POMDP) provides a principled general framework for planning under uncertainty, but solving POMDPs optimally is computationally intractable, due to the "curse of dimensionality" and the "curse of history". To overcome these challenges, we introduce the Determinized Sparse Partially Observable Tree (DESPOT), a sparse approximation of the standard belief tree, for online planning under uncertainty. A DESPOT focuses online planning on a set of randomly sampled scenarios and compactly captures the "execution" of all policies under these scenarios. We show that the best policy obtained from a DESPOT is near-optimal, with a regret bound that depends on the representation size of the optimal policy. Leveraging this result, we give an anytime online planning algorithm, which searches a DESPOT for a policy that optimizes a regularized objective function. Regularization balances the estimated value of a policy under the sampled scenarios and the policy size, thus avoiding overfitting. The algorithm demonstrates strong experimental results, compared with some of the best online POMDP algorithms available. It has also been incorporated into an autonomous driving system for real-time vehicle control. The source code for the algorithm is available online. version:2
arxiv-1703-02658 | What Would You Do? Acting by Learning to Predict | http://arxiv.org/abs/1703.02658 | id:1703.02658 author:Adam Tow, Niko Sünderhauf, Sareh Shirazi, Michael Milford, Jürgen Leitner category:cs.RO  published:2017-03-08 summary:We propose to learn tasks directly from visual demonstrations by learning to predict the outcome of human and robot actions on an environment. We enable a robot to physically perform a human demonstrated task without knowledge of the thought processes or actions of the human, only their visually observable state transitions. We evaluate our approach on two table-top, object manipulation tasks and demonstrate generalisation to previously unseen states. Our approach reduces the priors required to implement a robot task learning system compared with the existing approaches of Learning from Demonstration, Reinforcement Learning and Inverse Reinforcement Learning. version:1
arxiv-1703-02640 | Realizing the Aerial Robotic Worker for Inspection Operations | http://arxiv.org/abs/1703.02640 | id:1703.02640 author:Kostas Alexis category:cs.RO  published:2017-03-08 summary:This report overviews a set of recent contributions in the field of path planning that were developed to enable the realization of the autonomous aerial robotic worker for inspection operations. The specific algorithmic contributions address several fundamental challenges of robotic inspection and exploration, and specifically those of optimal coverage planning given an a priori known model of the structure to be inspected, full coverage, optimized and fast inspection path planning, as well as efficient exploration of completely unknown environments and structures. All of the developed path planners support both holonomic and nonholonomic systems, and respect the on-board sensor model and constraints. An overview of the achieved results, followed by an integrating architecture in order to enable fully autonomous and highly-efficient infrastructure inspection in both known and unknown environments. version:1
arxiv-1508-00036 | Scaling laws for consensus protocols subject to noise | http://arxiv.org/abs/1508.00036 | id:1508.00036 author:Ali Jadbabaie, Alex Olshevsky category:math.OC cs.DC cs.SY math.PR  published:2015-07-31 summary:We study the performance of discrete-time consensus protocols in the presence of additive noise. When the consensus dynamic corresponds to a reversible Markov chain, we give an exact expression for a weighted version of steady-state disagreement in terms of the stationary distribution and hitting times in an underlying graph. We then show how this result can be used to characterize the noise robustness of a class of protocols for formation control in terms of the Kemeny constant of an underlying graph. version:3
arxiv-1703-02610 | Multi-Robot Active Information Gathering with Periodic Communication | http://arxiv.org/abs/1703.02610 | id:1703.02610 author:Mikko Lauri, Eero Heinänen, Simone Frintrop category:cs.RO cs.AI  published:2017-03-07 summary:A team of robots sharing a common goal can benefit from coordination of the activities of team members, helping the team to reach the goal more reliably or quickly. We address the problem of coordinating the actions of a team of robots with periodic communication capability executing an information gathering task. We cast the problem as a multi-agent optimal decision-making problem with an information theoretic objective function. We show that appropriate techniques for solving decentralized partially observable Markov decision processes (Dec-POMDPs) are applicable in such information gathering problems. We quantify the usefulness of coordinated information gathering through simulation studies, and demonstrate the feasibility of the method in a real-world target tracking domain. version:1
arxiv-1703-02484 | GPU parallel simulation algorithm of Brownian particles with excluded volume using Delaunay triangulations | http://arxiv.org/abs/1703.02484 | id:1703.02484 author:Francisco Carter, Nancy Hitschfeld, Cristóbal Navarro, Rodrigo Soto category:cs.DC  published:2017-03-07 summary:A novel parallel simulation algorithm on the GPU, implemented in CUDA and C++, is presented for the simulation of Brownian particles that display excluded volume repulsion and interact with long and short range forces. When an explicit Euler-Maruyama integration step is performed to take into account the pairwise forces and Brownian motion, particle overlaps can appear. The excluded volume property brings up the need for correcting these overlaps as they happen, since predicting them is not feasible due to the random displacement of Brownian particles. The proposed solution handles, at each time step, a Delaunay triangulation of the particle positions because it allows us to efficiently solve overlaps between particles by checking just their neighborhood. The algorithm starts by generating a Delaunay triangulation of the particle initial positions on CPU, but after that the triangulation is always kept on GPU memory. We used a parallel edge-flip implementation to keep the triangulation updated during each time step, checking previously that the triangulation was not rendered invalid due to the particle displacements. The algorithm is validated with two models of active colloidal particles. Upon testing the parallel implementation of a long range forces simulation, the results show a performance improvement of up to two orders of magnitude when compared to the previously existing sequential solution. version:1
arxiv-1703-02438 | Parallel Implementation of Lossy Data Compression for Temporal Data Sets | http://arxiv.org/abs/1703.02438 | id:1703.02438 author:Zheng Yuan, William Hendrix, Seung Woo Son, Christoph Federrath, Ankit Agrawal, Wei-keng Liao, Alok Choudhary category:cs.DC  published:2017-03-07 summary:Many scientific data sets contain temporal dimensions. These are the data storing information at the same spatial location but different time stamps. Some of the biggest temporal datasets are produced by parallel computing applications such as simulations of climate change and fluid dynamics. Temporal datasets can be very large and cost a huge amount of time to transfer among storage locations. Using data compression techniques, files can be transferred faster and save storage space. NUMARCK is a lossy data compression algorithm for temporal data sets that can learn emerging distributions of element-wise change ratios along the temporal dimension and encodes them into an index table to be concisely represented. This paper presents a parallel implementation of NUMARCK. Evaluated with six data sets obtained from climate and astrophysics simulations, parallel NUMARCK achieved scalable speedups of up to 8788 when running 12800 MPI processes on a parallel computer. We also compare the compression ratios against two lossy data compression algorithms, ISABELA and ZFP. The results show that NUMARCK achieved higher compression ratio than ISABELA and ZFP. version:1
arxiv-1703-02340 | Design and Development of an automated Robotic Pick & Stow System for an e-Commerce Warehouse | http://arxiv.org/abs/1703.02340 | id:1703.02340 author:Swagat Kumar, Anima Majumder, Samrat Dutta, Rekha Raja, Sharath Jotawar, Ashish Kumar, Manish Soni, Venkat Raju, Olyvia Kundu, Ehtesham Hassan Laxmidhar Behera, K. S. Venkatesh, Rajesh Sinha category:cs.RO  published:2017-03-07 summary:In this paper, we provide details of a robotic system that can automate the task of picking and stowing objects from and to a rack in an e-commerce fulfillment warehouse. The system primarily comprises of four main modules: (1) Perception module responsible for recognizing query objects and localizing them in the 3-dimensional robot workspace; (2) Planning module generates necessary paths that the robot end- effector has to take for reaching the objects in the rack or in the tote; (3) Calibration module that defines the physical workspace for the robot visible through the on-board vision system; and (4) Gripping and suction system for picking and stowing different kinds of objects. The perception module uses a faster region-based Convolutional Neural Network (R-CNN) to recognize objects. We designed a novel two finger gripper that incorporates pneumatic valve based suction effect to enhance its ability to pick different kinds of objects. The system was developed by IITK-TCS team for participation in the Amazon Picking Challenge 2016 event. The team secured a fifth place in the stowing task in the event. The purpose of this article is to share our experiences with students and practicing engineers and enable them to build similar systems. The overall efficacy of the system is demonstrated through several simulation as well as real-world experiments with actual robots. version:1
arxiv-1703-02326 | Robust Whole-Body Motion Control of Legged Robots | http://arxiv.org/abs/1703.02326 | id:1703.02326 author:Farbod Farshidian, Edo Jelavić, Alexander W. Winkler, Jonas Buchli category:cs.RO  published:2017-03-07 summary:We introduce a robust control architecture for the whole-body motion control of torque controlled robots with arms and legs. The method is based on the robust control of contact forces in order to track a planned Center of Mass trajectory. Its appeal lies in the ability to guarantee robust stability and performance despite rigid body model mismatch, actuator dynamics, delays, contact surface stiffness, and unobserved ground profiles. Furthermore, we introduce a task space decomposition approach which removes the coupling effects between contact force controller and the other non-contact controllers. Finally, we verify our control performance on a quadruped robot and compare its performance to a standard inverse dynamics approach on hardware. version:1
arxiv-1702-06335 | Edge-Fog Cloud: A Distributed Cloud for Internet of Things Computations | http://arxiv.org/abs/1702.06335 | id:1702.06335 author:Nitinder Mohan, Jussi Kangasharju category:cs.DC  published:2017-02-21 summary:Internet of Things typically involves a significant number of smart sensors sensing information from the environment and sharing it to a cloud service for processing. Various architectural abstractions, such as Fog and Edge computing, have been proposed to localize some of the processing near the sensors and away from the central cloud servers. In this paper, we propose Edge-Fog Cloud which distributes task processing on the participating cloud resources in the network. We develop the Least Processing Cost First (LPCF) method for assigning the processing tasks to nodes which provide the optimal processing time and near optimal networking costs. We evaluate LPCF in a variety of scenarios and demonstrate its effectiveness in finding the processing task assignments. version:2
arxiv-1703-02279 | On Model Predictive Path Following and Trajectory Tracking for Industrial Robots | http://arxiv.org/abs/1703.02279 | id:1703.02279 author:Mathias Hauan Arbo, Esten Ingar Grøtli, Jan Tommy Gravdahl category:cs.RO  published:2017-03-07 summary:In this article we show how the model predictive path following controller allows robotic manipulators to stop at obstructions in a way that model predictive trajectory tracking controllers cannot. We present both controllers as applied to robotic manipulators, simulations for a two-link manipulator using an interior point solver, consider discretization of the optimal control problem using collocation or Runge-Kutta, and discuss the real-time viability of our implementation of the model predictive path following controller. version:1
arxiv-1703-02247 | Fault Tolerant Leader Election in Distributed Systems | http://arxiv.org/abs/1703.02247 | id:1703.02247 author:Marius Rafailescu category:cs.DC  published:2017-03-07 summary:There are many distributed systems which use a leader in their logic. When such systems need to be fault tolerant and the current leader suffers a technical problem, it is necesary to apply a special algorithm in order to choose a new leader. In this paper I present a new fault tolerant algorithm which elects a new leader based on a random roulette wheel selection. version:1
arxiv-1611-09452 | An Efficient Partial Sums Generator for Constituent Code based Successive Cancellation Decoding of Polar Codes | http://arxiv.org/abs/1611.09452 | id:1611.09452 author:Tiben Che, Gwan Choi category:cs.AR  published:2016-11-29 summary:This paper proposes the architecture of partial sum generator for constituent codes based polar code decoder. Constituent codes based polar code decoder has the advantage of low latency. However, no purposefully designed partial sum generator design exists that can yield desired timing for the decoder. We first derive the mathematical presentation with the partial sums set $\bm{\beta^c}$ which is corresponding to each constituent codes. From this, we concoct a shift-register based partial sum generator. Next, the overall architecture and design details are described, and the overhead compared with conventional partial sum generator is evaluated. Finally, the implementation results with both ASIC and FPGA technology and relevant discussions are presented. version:2
arxiv-1702-05437 | Quantifying Program Bias | http://arxiv.org/abs/1702.05437 | id:1702.05437 author:Aws Albarghouthi, Loris D'Antoni, Samuel Drews, Aditya Nori category:cs.PL cs.AI  published:2017-02-17 summary:With the range and sensitivity of algorithmic decisions expanding at a break-neck speed, it is imperative that we aggressively investigate whether programs are biased. We propose a novel probabilistic program analysis technique and apply it to quantifying bias in decision-making programs. Specifically, we (i) present a sound and complete automated verification technique for proving quantitative properties of probabilistic programs; (ii) show that certain notions of bias, recently proposed in the fairness literature, can be phrased as quantitative correctness properties; and (iii) present FairSquare, the first verification tool for quantifying program bias, and evaluate it on a range of decision-making programs. version:2
arxiv-1703-02196 | Cooperative Epistemic Multi-Agent Planning for Implicit Coordination | http://arxiv.org/abs/1703.02196 | id:1703.02196 author:Thorsten Engesser, Thomas Bolander, Robert Mattmüller, Bernhard Nebel category:cs.AI cs.LO cs.MA  published:2017-03-07 summary:Epistemic planning can be used for decision making in multi-agent situations with distributed knowledge and capabilities. Recently, Dynamic Epistemic Logic (DEL) has been shown to provide a very natural and expressive framework for epistemic planning. We extend the DEL-based epistemic planning framework to include perspective shifts, allowing us to define new notions of sequential and conditional planning with implicit coordination. With these, it is possible to solve planning tasks with joint goals in a decentralized manner without the agents having to negotiate about and commit to a joint policy at plan time. First we define the central planning notions and sketch the implementation of a planning system built on those notions. Afterwards we provide some case studies in order to evaluate the planner empirically and to show that the concept is useful for multi-agent systems in practice. version:1
arxiv-1703-02192 | A Gentle Introduction to Epistemic Planning: The DEL Approach | http://arxiv.org/abs/1703.02192 | id:1703.02192 author:Thomas Bolander category:cs.AI cs.LO cs.MA  published:2017-03-07 summary:Epistemic planning can be used for decision making in multi-agent situations with distributed knowledge and capabilities. Dynamic Epistemic Logic (DEL) has been shown to provide a very natural and expressive framework for epistemic planning. In this paper, we aim to give an accessible introduction to DEL-based epistemic planning. The paper starts with the most classical framework for planning, STRIPS, and then moves towards epistemic planning in a number of smaller steps, where each step is motivated by the need to be able to model more complex planning scenarios. version:1
arxiv-1703-02145 | Dynamic Arrival Rate Estimation for Campus Mobility on Demand Network Graphs | http://arxiv.org/abs/1703.02145 | id:1703.02145 author:Justin Miller, Andres Hasfura, Shih-Yuan Liu, Jonathan P. How category:cs.RO  published:2017-03-06 summary:Mobility On Demand (MOD) systems are revolutionizing transportation in urban settings by improving vehicle utilization and reducing parking congestion. A key factor in the success of an MOD system is the ability to measure and respond to real-time customer arrival data. Real time traffic arrival rate data is traditionally difficult to obtain due to the need to install fixed sensors throughout the MOD network. This paper presents a framework for measuring pedestrian traffic arrival rates using sensors onboard the vehicles that make up the MOD fleet. A novel distributed fusion algorithm is presented which combines onboard LIDAR and camera sensor measurements to detect trajectories of pedestrians with a 90% detection hit rate with 1.5 false positives per minute. A novel moving observer method is introduced to estimate pedestrian arrival rates from pedestrian trajectories collected from mobile sensors. The moving observer method is evaluated in both simulation and hardware and is shown to achieve arrival rate estimates comparable to those that would be obtained with multiple stationary sensors. version:1
arxiv-1703-01161 | FeUdal Networks for Hierarchical Reinforcement Learning | http://arxiv.org/abs/1703.01161 | id:1703.01161 author:Alexander Sasha Vezhnevets, Simon Osindero, Tom Schaul, Nicolas Heess, Max Jaderberg, David Silver, Koray Kavukcuoglu category:cs.AI  published:2017-03-03 summary:We introduce FeUdal Networks (FuNs): a novel architecture for hierarchical reinforcement learning. Our approach is inspired by the feudal reinforcement learning proposal of Dayan and Hinton, and gains power and efficacy by decoupling end-to-end learning across multiple levels -- allowing it to utilise different resolutions of time. Our framework employs a Manager module and a Worker module. The Manager operates at a lower temporal resolution and sets abstract goals which are conveyed to and enacted by the Worker. The Worker generates primitive actions at every tick of the environment. The decoupled structure of FuN conveys several benefits -- in addition to facilitating very long timescale credit assignment it also encourages the emergence of sub-policies associated with different goals set by the Manager. These properties allow FuN to dramatically outperform a strong baseline agent on tasks that involve long-term credit assignment or memorisation. We demonstrate the performance of our proposed system on a range of tasks from the ATARI suite and also from a 3D DeepMind Lab environment. version:2
arxiv-1611-08554 | Asynchronous Distributed Automata: A Characterization of the Modal Mu-Fragment | http://arxiv.org/abs/1611.08554 | id:1611.08554 author:Fabian Reiter category:cs.FL cs.DC cs.LO  published:2016-11-25 summary:We establish the equivalence between a class of asynchronous distributed automata and a small fragment of least fixpoint logic, when restricted to finite directed graphs. More specifically, the logic we consider is (a variant of) the fragment of the modal $\mu$-calculus that allows least fixpoints but forbids greatest fixpoints. The corresponding automaton model uses a network of identical finite-state machines that communicate in an asynchronous manner and whose state diagram must be acyclic except for self-loops. Exploiting the connection with logic, we also prove that the expressive power of those machines is independent of whether or not messages can be lost. version:2
arxiv-1703-01975 | The Fog Makes Sense: Enabling Social Sensing Services With Limited Internet Connectivity | http://arxiv.org/abs/1703.01975 | id:1703.01975 author:Ruben Mayer, Harshit Gupta, Enrique Saurez, Umakishore Ramachandran category:cs.DC  published:2017-03-06 summary:Social sensing services use humans as sensor carriers, sensor operators and sensors themselves in order to provide situation-awareness to applications. This promises to provide a multitude of benefits to the users, for example in the management of natural disasters or in community empowerment. However, current social sensing services depend on Internet connectivity since the services are deployed on central Cloud platforms. In many circumstances, Internet connectivity is constrained, for instance when a natural disaster causes Internet outages or when people do not have Internet access due to economical reasons. In this paper, we propose the emerging Fog Computing infrastructure to become a key-enabler of social sensing services in situations of constrained Internet connectivity. To this end, we develop a generic architecture and API of Fog-enabled social sensing services. We exemplify the usage of the proposed social sensing architecture on a number of concrete use cases from two different scenarios. version:1
arxiv-1703-01971 | Evidential supplier selection based on interval data fusion | http://arxiv.org/abs/1703.01971 | id:1703.01971 author:Zichang He, Wen Jiang category:cs.AI  published:2017-03-06 summary:Supplier selection is a typical multi-criteria decision making (MCDM) problem and lots of uncertain information exist inevitably. To address this issue, a new method was proposed based on interval data fusion. Our method follows the original way to generate classical basic probability assignment(BPA) determined by the distance among the evidences. However, the weights of criteria are kept as interval numbers to generate interval BPAs and do the fusion of interval BPAs. Finally, the order is ranked and the decision is made according to the obtained interval BPAs. In this paper, a numerical example of supplier selection is applied to verify the feasibility and validity of our method. The new method is presented aiming at solving multiple-criteria decision-making problems in which the weights of criteria or experts are described in fuzzy data like linguistic terms or interval data. version:1
arxiv-1703-02894 | A quantum dynamic belief model to explain the interference effects of categorization on decision making | http://arxiv.org/abs/1703.02894 | id:1703.02894 author:Zichang He, Wen Jiang category:cs.AI quant-ph  published:2017-03-06 summary:Categorization is necessary for many decision making tasks. However, the categorization process may interfere the decision making result and the law of total probability can be violated in some situations. To predict the interference effect of categorization, some model based on quantum probability has been proposed. In this paper, a new quantum dynamic belief (QDB) model is proposed. Considering the precise decision may not be made during the process, the concept of uncertainty is introduced in our model to simulate real human thinking process. Then the interference effect categorization can be predicted by handling the uncertain information. The proposed model is applied to a categorization decision-making experiment to explain the interference effect of categorization. Compared with other models, our model is relatively more succinct and the result shows the correctness and effectiveness of our model. version:1
arxiv-1703-01963 | A new belief Markov chain model and its application in inventory prediction | http://arxiv.org/abs/1703.01963 | id:1703.01963 author:Zichang He, Wen Jiang category:cs.AI cs.CE  published:2017-03-06 summary:Markov chain model is widely applied in many fields, especially the field of prediction. The classical Discrete-time Markov chain(DTMC) is a widely used method for prediction. However, the classical DTMC model has some limitation when the system is complex with uncertain information or state space is not discrete. To address it, a new belief Markov chain model is proposed by combining Dempster-Shafer evidence theory with Markov chain. In our model, the uncertain data is allowed to be handle in the form of interval number and the basic probability assignment(BPA) is generated based on the distance between interval numbers. The new belief Markov chain model overcomes the shortcomings of classical Markov chain and has an efficient ability in dealing with uncertain information. Moreover, an example of inventory prediction and the comparison between our model and classical DTMC model can show the effectiveness and rationality of our proposed model. version:1
arxiv-1703-01924 | Exchangeable choice functions | http://arxiv.org/abs/1703.01924 | id:1703.01924 author:Arthur Van Camp, Gert de Cooman category:cs.AI  published:2017-03-06 summary:We investigate how to model exchangeability with choice functions. Exchangeability is a structural assessment on a sequence of uncertain variables. We show how such assessments are a special indifference assessment, and how that leads to a counterpart of de Finetti's Representation Theorem, both in a finite and a countable context. version:1
arxiv-1703-02386 | A quantum dynamic belief decision making model | http://arxiv.org/abs/1703.02386 | id:1703.02386 author:Zichang He, Wen Jiang category:cs.AI q-bio.NC quant-ph  published:2017-03-06 summary:The sure thing principle and the law of total probability are basic laws in classic probability theory. A disjunction fallacy leads to the violation of these two classical probability laws. In this paper, a new quantum dynamic belief decision making model based on quantum dynamic modelling and Dempster-Shafer (D-S) evidence theory is proposed to address this issue and model the real human decision-making process. Some mathematical techniques are borrowed from quantum mathematics. Generally, belief and action are two parts in a decision making process. The uncertainty in belief part is represented by a superposition of certain states. The uncertainty in actions is represented as an extra uncertainty state. The interference effect is produced due to the entanglement between beliefs and actions. Basic probability assignment (BPA) of decisions is generated by quantum dynamic modelling. Then BPA of the extra uncertain state and an entanglement degree defined by an entropy function named Deng entropy are used to measure the interference effect. Compared the existing model, the number of free parameters is less in our model. Finally, a classical categorization decision-making experiment is illustrated to show the effectiveness of our model. version:1
arxiv-1702-05087 | SLAM auto-complete using an emergency map | http://arxiv.org/abs/1702.05087 | id:1702.05087 author:Malcolm Mielle, Martin Magnusson, Henrik Andreasson, Achim J. Lilienthal category:cs.RO  published:2017-02-16 summary:Often, robots have to work in situations where classic sensors do not perform well. Dust, fire or smoke can corrupt laser scanners and camera measurements. In those situation, it is important to be able to reason on non-visible and unknown part of the environment. One way to achieve this is to integrate prior information in the SLAM. While previous research mainly focused on using accurate maps or aerial images as prior in the SLAM it is not always possible to get those, especially indoor. We developed a formulation of graph-based SLAM, incorporating information from a rough prior. We focus on emergency-maps. Emergency-maps are easy to get and a support extensively used, e.g., by firemen in rescue missions. However, those maps can be outdated, information might be missing, and the scales of all rooms are typically not consistent. We create a graph associating information from both types of maps. The graph is optimized, using a combination of robust kernels, fusing information from the emergency and the SLAM-map into one map even when faced with scale inaccuracies and inexact start poses. We typically have more than 50% of wrong correspondences in the settings studied in this paper, and the method we propose correctly handles them. Experiments on an office environment show that, we can handle up to 69% of wrong correspondences and still get the expected result. By incorporating the emergency-map's information in the SLAM-map, the robot can navigate and explore while taking into account places it has not yet seen. We also show that the emergency-map is enhanced by adding information not represented such as closed doors or new walls. version:2
arxiv-1703-01893 | Approximate Muscle Guided Beam Search for Three-Index Assignment Problem | http://arxiv.org/abs/1703.01893 | id:1703.01893 author:He Jiang, Shuwei Zhang, Zhilei Ren, Xiaochen Lai, Yong Piao category:cs.AI  published:2017-03-06 summary:As a well-known NP-hard problem, the Three-Index Assignment Problem (AP3) has attracted lots of research efforts for developing heuristics. However, existing heuristics either obtain less competitive solutions or consume too much time. In this paper, a new heuristic named Approximate Muscle guided Beam Search (AMBS) is developed to achieve a good trade-off between solution quality and running time. By combining the approximate muscle with beam search, the solution space size can be significantly decreased, thus the time for searching the solution can be sharply reduced. Extensive experimental results on the benchmark indicate that the new algorithm is able to obtain solutions with competitive quality and it can be employed on instances with largescale. Work of this paper not only proposes a new efficient heuristic, but also provides a promising method to improve the efficiency of beam search. version:1
arxiv-1703-01882 | Momentum Control of Humanoid Robots with Series Elastic Actuators | http://arxiv.org/abs/1703.01882 | id:1703.01882 author:Gabriele Nava, Daniele Pucci, Francesco Nori category:math.OC cs.RO  published:2017-03-06 summary:Humanoid robots may require a degree of compliance at the joint level for improving efficiency, shock tolerance, and safe interaction with humans. The presence of joint elasticity, however, complexifies the design of balancing and walking controllers. This paper proposes a control framework for extending momentum based controllers developed for stiff actuators to the case of series elastic actuators. The key point is to consider the motor velocities as an intermediate control input, and then apply high-gain control to stabilise the desired motor velocities achieving momentum control. Simulations carried out on a model of the robot iCub verify the soundness of the proposed approach. version:1
arxiv-1506-00853 | Deterministic Communication in Radio Networks | http://arxiv.org/abs/1506.00853 | id:1506.00853 author:Artur Czumaj, Peter Davies category:cs.DC  published:2015-06-02 summary:In this paper we improve the deterministic complexity of two fundamental communication primitives in the classical model of ad-hoc radio networks with unknown topology: broadcasting and wake-up. We consider an unknown radio network, in which all nodes have no prior knowledge about network topology, and know only the size of the network $n$, the maximum in-degree of any node $\Delta$, and the eccentricity of the network $D$. For such networks, we first give an algorithm for wake-up, in both directed and undirected networks, based on the existence of small universal synchronizers. This algorithm runs in $O(\frac{\min\{n, D \Delta\} \log n \log \Delta}{\log\log \Delta})$ time, improving over the previous best $O(n \log^2n)$-time result across all ranges of parameters, but particularly when maximum in-degree is small. Next, we introduce a new combinatorial framework of block synchronizers and prove the existence of such objects of low size. Using this framework, we design a new deterministic algorithm for the fundamental problem of \emph{broadcasting}, running in $O(n \log D \log\log\frac{D \Delta}{n})$ time. This is the fastest known algorithm for the problem, improving upon the $O(n \log n \log \log n)$-time algorithm of De Marco (2010) and the $O(n \log^2 D)$-time algorithm due to Czumaj and Rytter (2003), the previous fastest results for directed networks. It is also the first to come within a log-logarithmic factor of the $\Omega(n \log D)$ lower bound due to Clementi et al. (2003). Our results also have direct implications on the fastest deterministic leader election and clock synchronization algorithms in both directed and undirected radio networks, tasks which are commonly used as building blocks for more complex procedures. version:6
arxiv-1703-01859 | Exploiting Spontaneous Transmissions for Broadcasting and Leader Election in Radio Networks | http://arxiv.org/abs/1703.01859 | id:1703.01859 author:Artur Czumaj, Peter Davies category:cs.DC  published:2017-03-06 summary:We study two fundamental communication primitives: broadcasting and leader election in the classical model of multi-hop radio networks with unknown topology and without collision detection mechanisms. It has been known for almost 20 years that in undirected networks with n nodes and diameter D, randomized broadcasting requires Omega(D log n/D + log^2 n) rounds in expectation, assuming that uninformed nodes are not allowed to communicate (until they are informed). Only very recently, Haeupler and Wajc (PODC'2016) showed that this bound can be slightly improved for the model with spontaneous transmissions, providing an O(D log n loglog n / log D + log^O(1) n)-time broadcasting algorithm. In this paper, we give a new and faster algorithm that completes broadcasting in O(D log n/log D + log^O(1) n) time, with high probability. This yields the first optimal O(D)-time broadcasting algorithm whenever D is polynomial in n. Furthermore, our approach can be applied to design a new leader election algorithm that matches the performance of our broadcasting algorithm. Previously, all fast randomized leader election algorithms have been using broadcasting as their subroutine and their complexity have been asymptotically strictly bigger than the complexity of broadcasting. In particular, the fastest previously known randomized leader election algorithm of Ghaffari and Haeupler (SODA'2013) requires O(D log n/D min{loglog n, log n/D} + log^O(1) n)-time with high probability. Our new algorithm requires O(D log n / log D + log^O(1) n) time with high probability, and it achieves the optimal O(D) time whenever D is polynomial in n. version:1
arxiv-1703-04519 | Decentralized, Robust and Efficient Services for an Autonomous and Real-time Urban Crisis Management | http://arxiv.org/abs/1703.04519 | id:1703.04519 author:Frédéric Le Mouël, Carlos Barrios Hernández, Oscar Carrillo, Gabriel Pedraza category:cs.CY cs.DC cs.SI  published:2017-03-06 summary:The globalization of trade and the organization of work are currently causing a large migratory flow towards the cities. This growth of cities requires new urban planning where digital tools take a preponderant place to capture data and understand and decide in face of changes. These tools however hardly resist to natural disasters, terrorism, accidents, etc. Based on the expertise of the CITI laboratory of INSA Lyon and SC3 of the Industrial University of Santander, we propose to create the ALERT project - Autonomous Liable Emergency service in Real Time - with decentralized, reliable and efficient services, physically close to the citizens, taking decisions locally, in a relevant manner without risk of disconnection with a central authority. These information gathering and decision-making will involve the population with participatory and social approaches. version:1
arxiv-1703-00754 | RGBDTAM: A Cost-Effective and Accurate RGB-D Tracking and Mapping System | http://arxiv.org/abs/1703.00754 | id:1703.00754 author:Alejo Concha, Javier Civera category:cs.RO  published:2017-03-02 summary:Simultaneous Localization and Mapping using RGB-D cameras has been a fertile research topic in the latest decade, due to the suitability of such sensors for indoor robotics. In this paper we propose a RGB-D SLAM algorithm aiming at state-of-the-art performance at a much lower cost. Our experiments in the RGB-D TUM dataset [25] effectively show a better accuracy and robustness in CPU real time than RGB-D SLAM systems that make intensive use of the GPU. The key ingredients of our approach are mainly two. Firstly, the combination of a semi-dense photometric and dense geo- metric error for the pose tracking (see Figure 1 in the paper), which we demonstrate to be the most accurate option. And secondly, a model of the multi-view constraints and their errors in the mapping and pose tracking threads, which adds extra information over other approaches. We release the open-source implementation of our approach (1) . The reader is referred to a video with our results (2) for an illustration of our system. version:3
arxiv-1502-03945 | Efficiency and complexity of price competition among single-product vendors | http://arxiv.org/abs/1502.03945 | id:1502.03945 author:Ioannis Caragiannis, Xenophon Chatzigeorgiou, Panagiotis Kanellopoulos, George A. Krimpas, Nikos Protopapas, Alexandros A. Voudouris category:cs.GT cs.AI cs.CC  published:2015-02-13 summary:Motivated by recent progress on pricing in the AI literature, we study marketplaces that contain multiple vendors offering identical or similar products and unit-demand buyers with different valuations on these vendors. The objective of each vendor is to set the price of its product to a fixed value so that its profit is maximized. The profit depends on the vendor's price itself and the total volume of buyers that find the particular price more attractive than the price of the vendor's competitors. We model the behaviour of buyers and vendors as a two-stage full-information game and study a series of questions related to the existence, efficiency (price of anarchy) and computational complexity of equilibria in this game. To overcome situations where equilibria do not exist or exist but are highly inefficient, we consider the scenario where some of the vendors are subsidized in order to keep prices low and buyers highly satisfied. version:2
arxiv-1703-01704 | Ad-hoc Affectance-selective Families for Layer Dissemination | http://arxiv.org/abs/1703.01704 | id:1703.01704 author:Dariusz R. Kowalski, Harshita Kudaravalli, Miguel A. Mosteiro category:cs.DC  published:2017-03-06 summary:Information dissemination protocols for ad-hoc wireless networks frequently use a minimal subset of the available communication links, defining a rooted "broadcast" tree. In this work, we focus on the core challenge of disseminating from one layer to the next one of such tree. We call this problem Layer Dissemination. We study Layer Dissemination under a generalized model of interference, called affectance. The affectance model subsumes previous models, such as Radio Network and Signal to Inteference-plus-Noise Ratio. We present randomized and deterministic protocols for Layer Dissemination. These protocols are based on a combinatorial object that we call Affectance-selective Families. Our approach combines an engineering solution with theoretical guarantees. That is, we provide a method to characterize the network with a global measure of affectance based on measurements of interference in the specific deployment area. Then, our protocols distributedly produce an ad-hoc transmissions schedule for dissemination. In the randomized protocol only the network characterization is needed, whereas the deterministic protocol requires full knowledge of affectance. Our theoretical analysis provides guarantees on schedule length. We also present simulations of a real network-deployment area contrasting the performance of our randomized protocol, which takes into account affectance, against previous work for interference models that ignore some physical constraints. The striking improvement in performance shown by our simulations show the importance of utilizing a more physically-accurate model of interference that takes into account other effects beyond distance to transmitters. version:1
arxiv-1703-01673 | Learn-and-Adapt Stochastic Dual Gradients for Network Resource Allocation | http://arxiv.org/abs/1703.01673 | id:1703.01673 author:Tianyi Chen, Qing Ling, Georgios B. Giannakis category:cs.SY cs.DC  published:2017-03-05 summary:Network resource allocation shows revived popularity in the era of data deluge and information explosion. Existing stochastic optimization approaches fall short in attaining a desirable cost-delay tradeoff. Recognizing the central role of Lagrange multipliers in network resource allocation, a novel learn-and-adapt stochastic dual gradient (LA-SDG) method is developed in this paper to learn the empirical optimal Lagrange multiplier from historical data, and adapt to the upcoming resource allocation strategy. Remarkably, it only requires one more sample (gradient) evaluation than the celebrated stochastic dual gradient (SDG) method. LA-SDG can be interpreted as a foresighted learning approach with an eye on the future, or, a modified heavy-ball approach from an optimization viewpoint. It is established - both theoretically and empirically - that LA-SDG markedly improves the cost-delay tradeoff over state-of-the-art allocation schemes. version:1
arxiv-1703-01653 | Pneumatic Modelling for Adroit Manipulation Platform | http://arxiv.org/abs/1703.01653 | id:1703.01653 author:Vikash Kumar, Visak CV category:cs.RO  published:2017-03-05 summary:ADROIT Manipulation platform is a pneumatically actuated, tendon driven 28 degree of freedom platform being developed for investigating complex hand manipulation behaviors. ADROIT derives its unique capabilities, necessary to support dynamic and dexterous manipulation, from a custom designed high-performance pneumatic actuation system for tendon-driven hands. The custom pneumatic actuation system is fast, strong, low friction-stiction, compliant and is capable of actuating a shadow hand skeleton faster that human capabilities -- at a unique combination of speed, force, and compliance that has never been achieved before. In this paper, we develop models for the pneumatic muscles of ADROIT and perform a thorough investigation of the various parameters that affect pressure dynamics in a pneumatic system such as, different cylinder types, leakage from valves and cylinders, valve deadzone, input pressure fluctuations etc to improve the model's accuracy. version:1
arxiv-1611-00111 | Densification Strategies for Anytime Motion Planning over Large Dense Roadmaps | http://arxiv.org/abs/1611.00111 | id:1611.00111 author:Shushman Choudhury, Oren Salzman, Sanjiban Choudhury, Siddhartha S. Srinivasa category:cs.RO  published:2016-11-01 summary:We consider the problem of computing shortest paths in a dense motion-planning roadmap $\mathcal{G}$. We assume that~$n$, the number of vertices of $\mathcal{G}$, is very large. Thus, using any path-planning algorithm that directly searches $\mathcal{G}$, running in $O(V\textrm{log}V + E) \approx O(n^2)$ time, becomes unacceptably expensive. We are therefore interested in anytime search to obtain successively shorter feasible paths and converge to the shortest path in $\mathcal{G}$. Our key insight is to provide existing path-planning algorithms with a sequence of increasingly dense subgraphs of $\mathcal{G}$. We study the space of all ($r$-disk) subgraphs of $\mathcal{G}$. We then formulate and present two densification strategies for traversing this space which exhibit complementary properties with respect to problem difficulty. This inspires a third, hybrid strategy which has favourable properties regardless of problem difficulty. This general approach is then demonstrated and analyzed using the specific case where a low-dispersion deterministic sequence is used to generate the samples used for $\mathcal{G}$. Finally we empirically evaluate the performance of our strategies for random scenarios in $\mathbb{R}^{2}$ and $\mathbb{R}^{4}$ and on manipulation planning problems for a 7 DOF robot arm, and validate our analysis. version:2
arxiv-1609-09861 | An Efficient Optimal Planning and Control Framework For Quadrupedal Locomotion | http://arxiv.org/abs/1609.09861 | id:1609.09861 author:Farbod Farshidian, Michael Neunert, Alexander W. Winkler, Gonzalo Rey, Jonas Buchli category:cs.SY cs.RO  published:2016-09-30 summary:In this paper, we present an efficient Dynamic Programing framework for optimal planning and control of legged robots. First we formulate this problem as an optimal control problem for switched systems. Then we propose a multi--level optimization approach to find the optimal switching times and the optimal continuous control inputs. Through this scheme, the decomposed optimization can potentially be done more efficiently than the combined approach. Finally, we present a continuous-time constrained LQR algorithm which simultaneously optimizes the feedforward and feedback controller with $O(n)$ time-complexity. In order to validate our approach, we show the performance of our framework on a quadrupedal robot. We choose the Center of Mass dynamics and the full kinematic formulation as the switched system model where the switching times as well as the contact forces and the joint velocities are optimized for different locomotion tasks such as gap crossing, walking and trotting. version:2
arxiv-1702-08495 | Don't Fear the Reaper: Refuting Bostrom's Superintelligence Argument | http://arxiv.org/abs/1702.08495 | id:1702.08495 author:Sebastian Benthall category:cs.AI  published:2017-02-27 summary:In recent years prominent intellectuals have raised ethical concerns about the consequences of artificial intelligence. One concern is that an autonomous agent might modify itself to become "superintelligent" and, in supremely effective pursuit of poorly specified goals, destroy all of humanity. This paper considers and rejects the possibility of this outcome. We argue that this scenario depends on an agent's ability to rapidly improve its ability to predict its environment through self-modification. Using a Bayesian model of a reasoning agent, we show that there are important limitations to how an agent may improve its predictive ability through self-modification alone. We conclude that concern about this artificial intelligence outcome is misplaced and better directed at policy questions around data access and storage. version:2
arxiv-1701-02272 | Morphognosis: the shape of knowledge in space and time | http://arxiv.org/abs/1701.02272 | id:1701.02272 author:Thomas E. Portegys category:q-bio.NC cs.AI  published:2017-01-05 summary:Artificial intelligence research to a great degree focuses on the brain and behaviors that the brain generates. But the brain, an extremely complex structure resulting from millions of years of evolution, can be viewed as a solution to problems posed by an environment existing in space and time. The environment generates signals that produce sensory events within an organism. Building an internal spatial and temporal model of the environment allows an organism to navigate and manipulate the environment. Higher intelligence might be the ability to process information coming from a larger extent of space-time. In keeping with nature's penchant for extending rather than replacing, the purpose of the mammalian neocortex might then be to record events from distant reaches of space and time and render them, as though yet near and present, to the older, deeper brain whose instinctual roles have changed little over eons. Here this notion is embodied in a model called morphognosis (morpho = shape and gnosis = knowledge). Its basic structure is a pyramid of event recordings called a morphognostic. At the apex of the pyramid are the most recent and nearby events. Receding from the apex are less recent and possibly more distant events. A morphognostic can thus be viewed as a structure of progressively larger chunks of space-time knowledge. A set of morphognostics forms long-term memories that are learned by exposure to the environment. A cellular automaton is used as the platform to investigate the morphognosis model, using a simulated organism that learns to forage in its world for food, build a nest, and play the game of Pong. version:2
arxiv-1703-01423 | Soft Pneumatic Gelatin Actuator for Edible Robotics | http://arxiv.org/abs/1703.01423 | id:1703.01423 author:Jun Shintake, Harshal Sonar, Egor Piskarev, Jamie Paik, Dario Floreano category:cs.RO  published:2017-03-04 summary:We present a fully edible pneumatic actuator based on gelatin-glycerol composite. The actuator is monolithic, fabricated via a molding process, and measures 90 mm in length, 20 mm in width, and 17 mm in thickness. Thanks to the composite mechanical characteristics similar to those of silicone elastomers, the actuator exhibits a bending angle of 170.3 {\deg} and a blocked force of 0.34 N at the applied pressure of 25 kPa. These values are comparable to elastomer based pneumatic actuators. As a validation example, two actuators are integrated to form a gripper capable of handling various objects, highlighting the high performance and applicability of the edible actuator. These edible actuators, combined with other recent edible materials and electronics, could lay the foundation for a new type of edible robots. version:1
arxiv-1703-01358 | Generalised Discount Functions applied to a Monte-Carlo AImu Implementation | http://arxiv.org/abs/1703.01358 | id:1703.01358 author:Sean Lamont, John Aslanides, Jan Leike, Marcus Hutter category:cs.AI  published:2017-03-03 summary:In recent years, work has been done to develop the theory of General Reinforcement Learning (GRL). However, there are few examples demonstrating these results in a concrete way. In particular, there are no examples demonstrating the known results regarding gener- alised discounting. We have added to the GRL simulation platform AIXIjs the functionality to assign an agent arbitrary discount functions, and an environment which can be used to determine the effect of discounting on an agent's policy. Using this, we investigate how geometric, hyperbolic and power discounting affect an informed agent in a simple MDP. We experimentally reproduce a number of theoretical results, and discuss some related subtleties. It was found that the agent's behaviour followed what is expected theoretically, assuming appropriate parameters were chosen for the Monte-Carlo Tree Search (MCTS) planning algorithm. version:1
arxiv-1610-03557 | Learning Feedback Terms for Reactive Planning and Control | http://arxiv.org/abs/1610.03557 | id:1610.03557 author:Akshara Rai, Giovanni Sutanto, Stefan Schaal, Franziska Meier category:cs.RO  published:2016-10-11 summary:With the advancement of robotics, machine learning, and machine perception, increasingly more robots will enter human environments to assist with daily tasks. However, dynamically-changing human environments requires reactive motion plans. Reactivity can be accomplished through replanning, e.g. model-predictive control, or through a reactive feedback policy that modifies on-going behavior in response to sensory events. In this paper, we investigate how to use machine learning to add reactivity to a previously learned nominal skilled behavior. We approach this by learning a reactive modification term for movement plans represented by nonlinear differential equations. In particular, we use dynamic movement primitives (DMPs) to represent a skill and a neural network to learn a reactive policy from human demonstrations. We use the well explored domain of obstacle avoidance for robot manipulation as a test bed. Our approach demonstrates how a neural network can be combined with physical insights to ensure robust behavior across different obstacle settings and movement durations. Evaluations on an anthropomorphic robotic system demonstrate the effectiveness of our work. version:2
arxiv-1701-01724 | DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker | http://arxiv.org/abs/1701.01724 | id:1701.01724 author:Matej Moravčík, Martin Schmid, Neil Burch, Viliam Lisý, Dustin Morrill, Nolan Bard, Trevor Davis, Kevin Waugh, Michael Johanson, Michael Bowling category:cs.AI  published:2017-01-06 summary:Artificial intelligence has seen several breakthroughs in recent years, with games often serving as milestones. A common feature of these games is that players have perfect information. Poker is the quintessential game of imperfect information, and a longstanding challenge problem in artificial intelligence. We introduce DeepStack, an algorithm for imperfect information settings. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition that is automatically learned from self-play using deep learning. In a study involving 44,000 hands of poker, DeepStack defeated with statistical significance professional poker players in heads-up no-limit Texas hold'em. The approach is theoretically sound and is shown to produce more difficult to exploit strategies than prior approaches. version:3
arxiv-1703-01270 | Baxter's Homunculus: Virtual Reality Spaces for Teleoperation in Manufacturing | http://arxiv.org/abs/1703.01270 | id:1703.01270 author:Jeffrey I Lipton, Aidan J Fay, Daniela Rus category:cs.RO  published:2017-03-03 summary:Expensive specialized systems have hampered development of telerobotic systems for manufacturing systems. In this paper we demonstrate a telerobotic system which can reduce the cost of such system by leveraging commercial virtual reality(VR) technology and integrating it with existing robotics control software. The system runs on a commercial gaming engine using off the shelf VR hardware. This system can be deployed on multiple network architectures from a wired local network to a wireless network connection over the Internet. The system is based on the homunculus model of mind wherein we embed the user in a virtual reality control room. The control room allows for multiple sensor display, dynamic mapping between the user and robot, does not require the production of duals for the robot, or its environment. The control room is mapped to a space inside the robot to provide a sense of co-location within the robot. We compared our system with state of the art automation algorithms for assembly tasks, showing a 100% success rate for our system compared with a 66% success rate for automated systems. We demonstrate that our system can be used for pick and place, assembly, and manufacturing tasks. version:1
arxiv-1701-03500 | A Savage-Like Axiomatization for Nonstandard Expected Utility | http://arxiv.org/abs/1701.03500 | id:1701.03500 author:Grant Molnar category:cs.AI  published:2017-01-12 summary:Since Leonard Savage's epoch-making "Foundations of Statistics," Subjective Expected Utility Theory has been the presumptive model for decision-making. Savage provided an act-based axiomatization of standard expected utility theory. In this article, we provide a Savage-like axiomatization of nonstandard expected utility theory. It corresponds to a weakening of Savage's $6^{th}$ axiom. version:4
arxiv-1703-01200 | Everware toolkit. Supporting reproducible science and challenge-driven education | http://arxiv.org/abs/1703.01200 | id:1703.01200 author:Andrey Ustyuzhanin, Timothy Daniel Head, Igor Babuschkin, Alexander Tiunov category:cs.CY cs.DC  published:2017-03-03 summary:Modern science clearly demands for a higher level of reproducibility and collaboration. To make research fully reproducible one has to take care of several aspects: research protocol description, data access, environment preservation, workflow pipeline, and analysis script preservation. Version control systems like git help with the workflow and analysis scripts part. Virtualization techniques like Docker or Vagrant can help deal with environments. Jupyter notebooks are a powerful platform for conducting research in a collaborative manner. We present project Everware that seamlessly integrates git repository management systems such as Github or Gitlab, Docker and Jupyter helping with a) sharing results of real research and b) boosts education activities. With the help of Everware one can not only share the final artifacts of research but all the depth of the research process. This been shown to be extremely helpful during organization of several data analysis hackathons and machine learning schools. Using Everware participants could start from an existing solution instead of starting from scratch. They could start contributing immediately. Everware allows its users to make use of their own computational resources to run the workflows they are interested in, which leads to higher scalability of the toolkit. version:1
arxiv-1609-04888 | Resource-Performance Trade-off Analysis for Mobile Robot Design | http://arxiv.org/abs/1609.04888 | id:1609.04888 author:Maria Svorenova, Morteza Lahijanian, Akshay A. Morye, Dushyant Rao, Ingmar Posner, Paul Newman, Hadas Kress-Gazit, Marta Kwiatkowska category:cs.RO  published:2016-09-16 summary:The design of mobile autonomous robots is challenging due to the limited on-board resources such as processing power and energy. A promising approach is to generate intelligent schedules that trade off reduced resource consumption for a slightly lower but still acceptable level of performance. In this paper, we provide a framework to aid designers in exploring such resource-performance trade-offs and finding schedules for mobile robots, guided by questions such as "what is the minimum resource budget required to achieve a given level of performance?" The framework is based on a quantitative multi-objective verification technique which, for a collection of possibly conflicting objectives, produces the Pareto front that contains all the optimal trade-offs that are achievable. The designer then selects a specific Pareto point based on the resource constraints and desired performance level, and a correct-by-construction schedule that meets those constraints is automatically generated. We demonstrate the efficacy of this framework on several robotic scenarios with encouraging results. version:2
arxiv-1703-01164 | Nonlinear Model Predictive Control for Multi-Micro Aerial Vehicle Robust Collision Avoidance | http://arxiv.org/abs/1703.01164 | id:1703.01164 author:Mina Kamel, Javier Alonso-Mora, Roland Siegwart, Juan Nieto category:cs.RO  published:2017-03-03 summary:Multiple multirotor Micro Aerial Vehicles sharing the same airspace require a reliable and robust collision avoidance technique. In this paper we address the problem of multi-MAV reactive collision avoidance. A model-based controller is employed to achieve simultaneously reference trajectory tracking and collision avoidance. Moreover, we also account for the uncertainty of the state estimator and the other agents position and velocity uncertainties to achieve a higher degree of robustness. The proposed approach is decentralized, does not require collision-free reference trajectory and accounts for the full MAV dynamics. We validated our approach in simulation and experimentally. version:1
arxiv-1603-07567 | Dynamics, Control, and Estimation for Aerial Robots Tethered by Cables or Bars | http://arxiv.org/abs/1603.07567 | id:1603.07567 author:Marco Tognon, Antonio Franchi category:cs.RO cs.SY  published:2016-03-24 summary:We consider the problem of controlling an aerial robot connected to the ground by a passive cable or a passive rigid link. We provide a thorough characterization of this nonlinear dynamical robotic system in terms of fundamental properties such as differential flatness, controllability, and observability. We prove that the robotic system is differentially flat with respect to two output pairs: elevation of the link and attitude of the vehicle; elevation of the link and longitudinal link force (e.g., cable tension, or bar compression). We show the design of an almost globally convergent nonlinear observer of the full state that resorts only to an onboard accelerometer and a gyroscope. We also design two almost globally convergent nonlinear controllers to track any sufficiently smooth time-varying trajectory of the two output pairs. Finally we numerically test the robustness of the proposed method in several far-from-nominal conditions: nonlinear cross-coupling effects, parameter deviations, measurements noise and non ideal actuators. version:2
arxiv-1703-01083 | Sequential Plan Recognition | http://arxiv.org/abs/1703.01083 | id:1703.01083 author:Reuth Mirsky, Roni Stern, Ya'akov, Gal, Meir Kalech category:cs.AI  published:2017-03-03 summary:Plan recognition algorithms infer agents' plans from their observed actions. Due to imperfect knowledge about the agent's behavior and the environment, it is often the case that there are multiple hypotheses about an agent's plans that are consistent with the observations, though only one of these hypotheses is correct. This paper addresses the problem of how to disambiguate between hypotheses, by querying the acting agent about whether a candidate plan in one of the hypotheses matches its intentions. This process is performed sequentially and used to update the set of possible hypotheses during the recognition process. The paper defines the sequential plan recognition process (SPRP), which seeks to reduce the number of hypotheses using a minimal number of queries. We propose a number of policies for the SPRP which use maximum likelihood and information gain to choose which plan to query. We show this approach works well in practice on two domains from the literature, significantly reducing the number of hypotheses using fewer queries than a baseline approach. Our results can inform the design of future plan recognition systems that interleave the recognition process with intelligent interventions of their users. version:1
arxiv-1509-03118 | Execution-Cache-Memory Performance Model: Introduction and Validation | http://arxiv.org/abs/1509.03118 | id:1509.03118 author:Johannes Hofmann, Jan Eitzinger, Dietmar Fey category:cs.DC cs.PF  published:2015-09-10 summary:This report serves two purposes: To introduce and validate the Execution-Cache-Memory (ECM) performance model and to provide a thorough analysis of current Intel processor architectures with a special emphasis on Intel Xeon Haswell-EP. The ECM model is a simple analytical performance model which focuses on basic architectural resources. The architectural analysis and model predictions are showcased and validated using a set of elementary microbenchmarks. version:3
arxiv-1703-01054 | When Hashes Met Wedges: A Distributed Algorithm for Finding High Similarity Vectors | http://arxiv.org/abs/1703.01054 | id:1703.01054 author:Aneesh Sharma, C. Seshadhri, Ashish Goel category:cs.SI cs.DC cs.DS  published:2017-03-03 summary:Finding similar user pairs is a fundamental task in social networks, with numerous applications in ranking and personalization tasks such as link prediction and tie strength detection. A common manifestation of user similarity is based upon network structure: each user is represented by a vector that represents the user's network connections, where pairwise cosine similarity among these vectors defines user similarity. The predominant task for user similarity applications is to discover all similar pairs that have a pairwise cosine similarity value larger than a given threshold $\tau$. In contrast to previous work where $\tau$ is assumed to be quite close to 1, we focus on recommendation applications where $\tau$ is small, but still meaningful. The all pairs cosine similarity problem is computationally challenging on networks with billions of edges, and especially so for settings with small $\tau$. To the best of our knowledge, there is no practical solution for computing all user pairs with, say $\tau = 0.2$ on large social networks, even using the power of distributed algorithms. Our work directly addresses this challenge by introducing a new algorithm --- WHIMP --- that solves this problem efficiently in the MapReduce model. The key insight in WHIMP is to combine the "wedge-sampling" approach of Cohen-Lewis for approximate matrix multiplication with the SimHash random projection techniques of Charikar. We provide a theoretical analysis of WHIMP, proving that it has near optimal communication costs while maintaining computation cost comparable with the state of the art. We also empirically demonstrate WHIMP's scalability by computing all highly similar pairs on four massive data sets, and show that it accurately finds high similarity pairs. In particular, we note that WHIMP successfully processes the entire Twitter network, which has tens of billions of edges. version:1
arxiv-1607-07558 | SLAM-Safe Planner: Preventing Monocular SLAM Failure using Reinforcement Learning | http://arxiv.org/abs/1607.07558 | id:1607.07558 author:Vignesh Prasad, Saurabh Singh, Nahas Pareekutty, Balaraman Ravindran, Madhava Krishna category:cs.RO  published:2016-07-26 summary:Effective SLAM using a single monocular camera is highly preferred due to its simplicity. However, when compared to trajectory planning methods using depth-based SLAM, Monocular SLAM in loop does need additional considerations. One main reason being that for the optimization, in the form of Bundle Adjustment (BA), to be robust, the SLAM system needs to scan the area for a reasonable duration. Most monocular SLAM systems do not tolerate large camera rotations between successive views and tend to breakdown. Other reasons for Monocular SLAM failure include ambiguities in decomposition of the Essential Matrix, feature-sparse scenes and more layers of non linear optimization apart from BA. This paper presents a novel formulation based on Reinforcement Learning (RL) that generates fail safe trajectories wherein the SLAM generated outputs (scene structure and camera motion) do not deviate largely from their true values. Quintessentially, the RL framework successfully learns the otherwise complex relation between motor actions and perceptual inputs that result in trajectories that do not cause failure of SLAM, which are almost intractable to capture in an obvious mathematical formulation. We show systematically in simulations how the quality of the SLAM map and trajectory dramatically improves when trajectories are computed by using RL. version:4
arxiv-1612-00150 | Decentralized Consensus Optimization with Asynchrony and Delays | http://arxiv.org/abs/1612.00150 | id:1612.00150 author:Tianyu Wu, Kun Yuan, Qing Ling, Wotao Yin, Ali H. Sayed category:math.OC cs.DC cs.MA  published:2016-12-01 summary:We propose an asynchronous, decentralized algorithm for consensus optimization. The algorithm runs over a network in which the agents communicate with their neighbors and perform local computation. In the proposed algorithm, each agent can compute and communicate independently at different times, for different durations, with the information it has even if the latest information from its neighbors is not yet available. Such an asynchronous algorithm reduces the time that agents would otherwise waste idle because of communication delays or because their neighbors are slower. It also eliminates the need for a global clock for synchronization. Mathematically, the algorithm involves both primal and dual variables, uses fixed step-size parameters, and provably converges to the exact solution under a bounded delay assumption and a random agent assumption. When running synchronously, the algorithm performs just as well as existing competitive synchronous algorithms such as PG-EXTRA, which diverges without synchronization. Numerical experiments confirm the theoretical findings and illustrate the performance of the proposed algorithm. version:2
arxiv-1703-00924 | Workload Analysis of Blue Waters | http://arxiv.org/abs/1703.00924 | id:1703.00924 author:Matthew D. Jones, Joseph P. White, Martins Innus, Robert L. DeLeon, Nikolay Simakov, Jeffrey T. Palmer, Steven M. Gallo, Thomas R. Furlani, Michael Showerman, Robert Brunner, Andry Kot, Gregory Bauer, Brett Bode, Jeremy Enos, William Kramer category:cs.DC 68M14  68M20  68U20  published:2017-03-02 summary:Blue Waters is a Petascale-level supercomputer whose mission is to enable the national scientific and research community to solve "grand challenge" problems that are orders of magnitude more complex than can be carried out on other high performance computing systems. Given the important and unique role that Blue Waters plays in the U.S. research portfolio, it is important to have a detailed understanding of its workload in order to guide performance optimization both at the software and system configuration level as well as inform architectural balance tradeoffs. Furthermore, understanding the computing requirements of the Blue Water's workload (memory access, IO, communication, etc.), which is comprised of some of the most computationally demanding scientific problems, will help drive changes in future computing architectures, especially at the leading edge. With this objective in mind, the project team carried out a detailed workload analysis of Blue Waters. version:1
arxiv-1702-07081 | DyAdHyTM: A Low Overhead Dynamically Adaptive Hybrid Transactional Memory on Big Data Graphs | http://arxiv.org/abs/1702.07081 | id:1702.07081 author:Mohammad Qayum, Abdel-Hameed Badawy, Jeanine Cook category:cs.DC  published:2017-02-23 summary:Big data is a buzzword used to describe massive volumes of data that provides opportunities of exploring new insights through data analytics. However, big data is mostly structured but can be semi-structured or unstructured. It is normally so large that it is not only difficult but also slow to process using traditional computing systems. One of the solutions is to format the data as graph data structures and process them on shared memory architecture to use fast and novel policies such as transactional memory. In most graph applications in big data type problems such as bioinformatics, social networks, and cyber security, graphs are sparse in nature. Due to this sparsity, we have the opportunity to use Transactional Memory (TM) as the synchronization policy for critical sections to speedup applications. At low conflict probability TM performs better than most synchronization policies due to its inherent non-blocking characteristics. TM can be implemented in Software, Hardware or a combination of both. However, hardware TM implementations are fast but limited by scarce hardware resources while software implementations have high overheads which can degrade performance. In this paper, we develop a low overhead, yet simple, dynamically adaptive (i.e. at runtime) hybrid (i.e. combines hardware and software) TM (DyAdHyTM) scheme that combines the best features of both Hardware TM (HTM) and Software TM (STM) while adapting to application requirements. It performs better than coarse grain lock by up to 8.12x, a low overhead STM by up to 2.68x, a couple of implementations of HTMs (by up to 2.59x), and other HyTMs (by up to 1.55x) for SSCA2 graph benchmark running on a multicore machine with a large shared memory. version:2
arxiv-1703-00897 | Adapting the DMTCP Plugin Model for Checkpointing of Hardware Emulation | http://arxiv.org/abs/1703.00897 | id:1703.00897 author:Rohan Garg, Kapil Arya, Jiajun Cao, Gene Cooperman, Jeff Evans, Ankit Garg, Neil A. Rosenberg, K. Suresh category:cs.OS cs.AR B.6.3  published:2017-03-02 summary:Checkpoint-restart is now a mature technology. It allows a user to save and later restore the state of a running process. The new plugin model for the upcoming version 3.0 of DMTCP (Distributed MultiThreaded Checkpointing) is described here. This plugin model allows a target application to disconnect from the hardware emulator at checkpoint time and then re-connect to a possibly different hardware emulator at the time of restart. The DMTCP plugin model is important in allowing three distinct parties to seamlessly inter-operate. The three parties are: the EDA designer, who is concerned with formal verification of a circuit design; the DMTCP developers, who are concerned with providing transparent checkpointing during the circuit emulation; and the hardware emulator vendor, who provides a plugin library that responds to checkpoint, restart, and other events. The new plugin model is an example of process-level virtualization: virtualization of external abstractions from within a process. This capability is motivated by scenarios for testing circuit models with the help of a hardware emulator. The plugin model enables a three-way collaboration: allowing a circuit designer and emulator vendor to each contribute separate proprietary plugins while sharing an open source software framework from the DMTCP developers. This provides a more flexible platform, where different fault injection models based on plugins can be designed within the DMTCP checkpointing framework. After initialization, one restarts from a checkpointed state under the control of the desired plugin. This restart saves the time spent in simulating the initialization phase, while enabling fault injection exactly at the region of interest. Upon restart, one can inject faults or otherwise modify the remainder of the simulation. The work concludes with a brief survey of checkpointing and process-level virtualization. version:1
arxiv-1512-06425 | Content-based Dynaic Routing in Structured Overlays Networks | http://arxiv.org/abs/1512.06425 | id:1512.06425 author:Muhammad Shafique category:cs.DC  published:2015-12-20 summary:Acyclic overlays used for broker-based publish/subscribe systems provide unique paths for content-based routing from a publisher to interested subscribers. Cyclic overlays may provide multiple paths, however, the subscription broadcast process generates one content-based routing path per subscription. This poses serious challenges in offering dynamic routing of notifications when congestion is detected because instantaneous updates in routing tables are required to generate alternative routing paths. This paper introduces the first subscription-based publish/subscribe system, OctopiS, which offers inter-cluster dynamic routing when congestion in the output queues is detected. OctopiS is based on a formally defined Structured Cyclic Overlay Topology (SCOT). SCOT is divided into homogeneous clusters where each cluster has equal number of brokers and connects to other clusters through multiple inter-cluster overlay links. These links are used to provide parallel routing paths between publishers and subscribers connected to brokers in different clusters. While aiming at deployment at data center networks, OctopiS generates subscription-trees of shortest lengths used by Static Notification Routing (SNR) algorithm. Dynamic Notification Routing (DNR) algorithm uses a bit-vector mechanism to exploit the structuredness of a clustered SCOT to offer inter-cluster dynamic routing without making updates in routing tables and minimizing load on overwhelmed brokers and congested links. Experiments on a cluster testbed with real world data show that OctopiS is scalable and reduces the number of inter-broker messages in subscription delivery by 89%, subscription delay by 77%, end-to-end notification delay in static and dynamic routing by 47% and 58% respectively, and the lengths of output queues of brokers in dynamic routing paths by 59%. version:2
arxiv-1609-08546 | Shape Completion Enabled Robotic Grasping | http://arxiv.org/abs/1609.08546 | id:1609.08546 author:Jacob Varley, Chad DeChant, Adam Richardson, Joaquín Ruales, Peter Allen category:cs.RO  published:2016-09-27 summary:This work provides an architecture to enable robotic grasp planning via shape completion. Shape completion is accomplished through the use of a 3D convolutional neural network (CNN). The network is trained on our own new open source dataset of over 440,000 3D exemplars captured from varying viewpoints. At runtime, a 2.5D pointcloud captured from a single point of view is fed into the CNN, which fills in the occluded regions of the scene, allowing grasps to be planned and executed on the completed object. Runtime shape completion is very rapid because most of the computational costs of shape completion are borne during offline training. We explore how the quality of completions vary based on several factors. These include whether or not the object being completed existed in the training data and how many object models were used to train the network. We also look at the ability of the network to generalize to novel objects allowing the system to complete previously unseen objects at runtime. Finally, experimentation is done both in simulation and on actual robotic hardware to explore the relationship between completion quality and the utility of the completed mesh model for grasping. version:2
arxiv-1703-00838 | SLIM: Semi-Lazy Inference Mechanism for Plan Recognition | http://arxiv.org/abs/1703.00838 | id:1703.00838 author:Retuh Mirsky, Ya'akov, Gal category:cs.AI  published:2017-03-02 summary:Plan Recognition algorithms require to recognize a complete hierarchy explaining the agent's actions and goals. While the output of such algorithms is informative to the recognizer, the cost of its calculation is high in run-time, space, and completeness. Moreover, performing plan recognition online requires the observing agent to reason about future actions that have not yet been seen and maintain a set of hypotheses to support all possible options. This paper presents a new and efficient algorithm for online plan recognition called SLIM (Semi-Lazy Inference Mechanism). It combines both a bottom-up and top-down parsing processes, which allow it to commit only to the minimum necessary actions in real-time, but still provide complete hypotheses post factum. We show both theoretically and empirically that although the computational cost of this process is still exponential, there is a significant improvement in run-time when compared to a state of the art of plan recognition algorithm. version:1
arxiv-1612-03471 | Reinforcement Learning With Temporal Logic Rewards | http://arxiv.org/abs/1612.03471 | id:1612.03471 author:Xiao Li, Cristian-Ioan Vasile, Calin Belta category:cs.AI cs.RO  published:2016-12-11 summary:Reinforcement learning (RL) depends critically on the choice of reward functions used to capture the de- sired behavior and constraints of a robot. Usually, these are handcrafted by a expert designer and represent heuristics for relatively simple tasks. Real world applications typically involve more complex tasks with rich temporal and logical structure. In this paper we take advantage of the expressive power of temporal logic (TL) to specify complex rules the robot should follow, and incorporate domain knowledge into learning. We propose Truncated Linear Temporal Logic (TLTL) as specifications language, that is arguably well suited for the robotics applications, together with quantitative semantics, i.e., robustness degree. We propose a RL approach to learn tasks expressed as TLTL formulae that uses their associated robustness degree as reward functions, instead of the manually crafted heuristics trying to capture the same specifications. We show in simulated trials that learning is faster and policies obtained using the proposed approach outperform the ones learned using heuristic rewards in terms of the robustness degree, i.e., how well the tasks are satisfied. Furthermore, we demonstrate the proposed RL approach in a toast-placing task learned by a Baxter robot. version:2
arxiv-1702-04396 | Hybrid control trajectory optimization under uncertainty | http://arxiv.org/abs/1702.04396 | id:1702.04396 author:Joni Pajarinen, Ville Kyrki, Michael Koval, Siddhartha Srinivasa, Jan Peters, Gerhard Neumann category:cs.RO  published:2017-02-14 summary:Trajectory optimization is a fundamental problem in robotics. While optimization of continuous control trajectories is well developed, many applications require both discrete and continuous, i.e., hybrid, controls. Finding an optimal sequence of hybrid controls is challenging due to the exponential explosion of discrete control combinations. Our method, based on Differential Dynamic Programming (DDP), circumvents this problem by incorporating discrete actions inside DDP: we first optimize continuous mixtures of discrete actions, and, subsequently force the mixtures into fully discrete actions. Moreover, we show how our approach can be extended to partially observable Markov decision processes (POMDPs) for trajectory planning under uncertainty. We validate the approach in a car driving problem where the robot has to switch discrete gears and in a box pushing application where the robot can switch the side of the box to push. The pose and the friction parameters of the pushed box are initially unknown and only indirectly observable. version:2
arxiv-1702-04441 | A Concurrency-Optimal Binary Search Tree | http://arxiv.org/abs/1702.04441 | id:1702.04441 author:Vitaly Aksenov, Vincent Gramoli, Petr Kuznetsov, Anna Malova, Srivatsan Ravi category:cs.DC  published:2017-02-15 summary:The paper presents the first \emph{concurrency-optimal} implementation of a binary search tree (BST). The implementation, based on a standard sequential implementation of an internal tree, ensures that every \emph{schedule} is accepted, i.e., interleaving of steps of the sequential code, unless linearizability is violated. To ensure this property, we use a novel read-write locking scheme that protects tree \emph{edges} in addition to nodes. Our implementation outperforms the state-of-the art BSTs on most basic workloads, which suggests that optimizing the set of accepted schedules of the sequential code can be an adequate design principle for efficient concurrent data structures. version:3
arxiv-1703-00760 | Sampling Variations of Lead Sheets | http://arxiv.org/abs/1703.00760 | id:1703.00760 author:Pierre Roy, Alexandre Papadopoulos, François Pachet category:cs.AI  published:2017-03-02 summary:Machine-learning techniques have been recently used with spectacular results to generate artefacts such as music or text. However, these techniques are still unable to capture and generate artefacts that are convincingly structured. In this paper we present an approach to generate structured musical sequences. We introduce a mechanism for sampling efficiently variations of musical sequences. Given a input sequence and a statistical model, this mechanism samples a set of sequences whose distance to the input sequence is approximately within specified bounds. This mechanism is implemented as an extension of belief propagation, and uses local fields to bias the generation. We show experimentally that sampled sequences are indeed closely correlated to the standard musical similarity measure defined by Mongeau and Sankoff. We then show how this mechanism can used to implement composition strategies that enforce arbitrary structure on a musical lead sheet generation problem. version:1
arxiv-1703-00727 | Deep Predictive Policy Training using Reinforcement Learning | http://arxiv.org/abs/1703.00727 | id:1703.00727 author:Ali Ghadirzadeh, Atsuto Maki, Danica Kragic, Mårten Björkman category:cs.RO  published:2017-03-02 summary:Skilled robot task learning is best implemented by predictive action policies due to the inherent latency of sensorimotor processes. However, training such predictive policies is challenging as it involves finding a trajectory of motor activations for the full duration of the action. We propose a data-efficient deep predictive policy training (DPPT) framework with a deep neural network policy architecture which maps an image observation to a sequence of motor activations. The architecture consists of three sub-networks referred to as the perception, policy and behavior super-layers. The perception and behavior super-layers force an abstraction of visual and motor data trained with synthetic and simulated training samples, respectively. The policy super-layer is a small sub-network with fewer parameters that maps data in-between the abstracted manifolds. It is trained for each task using methods for policy search reinforcement learning. We demonstrate the suitability of the proposed architecture and learning framework by training predictive policies for skilled object grasping and ball throwing on a PR2 robot. The effectiveness of the method is illustrated by the fact that these tasks are trained using only about 180 real robot attempts with qualitative terminal rewards. version:1
arxiv-1703-00690 | Even better correction of genome sequencing data | http://arxiv.org/abs/1703.00690 | id:1703.00690 author:Maciej Dlugosz, Sebastian Deorowicz, Marek Kokot category:q-bio.GN cs.DC  published:2017-03-02 summary:We introduce an improved version of RECKONER, an error corrector for Illumina whole genome sequencing data. By modifying its workflow we reduce the computation time even 10 times. We also propose a new method of determination of $k$-mer length, the key parameter of $k$-spectrum-based family of correctors. The correction algorithms are examined on huge data sets, i.e., human and maize genomes for both Illumina HiSeq and MiSeq instruments. version:1
arxiv-1703-00687 | Even faster sorting of (not only) integers | http://arxiv.org/abs/1703.00687 | id:1703.00687 author:Marek Kokot, Sebastian Deorowicz, Maciej Dlugosz category:cs.DS cs.DC  published:2017-03-02 summary:In this paper we introduce RADULS2, the fastest parallel sorter based on radix algorithm. It is optimized to process huge amounts of data making use of modern multicore CPUs. The main novelties include: extremely optimized algorithm for handling tiny arrays (up to about a hundred of records) that could appear even billions times as subproblems to handle and improved processing of larger subarrays with better use of non-temporal memory stores. version:1
arxiv-1703-00626 | The RowHammer Problem and Other Issues We May Face as Memory Becomes Denser | http://arxiv.org/abs/1703.00626 | id:1703.00626 author:Onur Mutlu category:cs.DC  published:2017-03-02 summary:As memory scales down to smaller technology nodes, new failure mechanisms emerge that threaten its correct operation. If such failure mechanisms are not anticipated and corrected, they can not only degrade system reliability and availability but also, perhaps even more importantly, open up security vulnerabilities: a malicious attacker can exploit the exposed failure mechanism to take over the entire system. As such, new failure mechanisms in memory can become practical and significant threats to system security. In this work, we discuss the RowHammer problem in DRAM, which is a prime (and perhaps the first) example of how a circuit-level failure mechanism in DRAM can cause a practical and widespread system security vulnerability. RowHammer, as it is popularly referred to, is the phenomenon that repeatedly accessing a row in a modern DRAM chip causes bit flips in physically-adjacent rows at consistently predictable bit locations. It is caused by a hardware failure mechanism called DRAM disturbance errors, which is a manifestation of circuit-level cell-to-cell interference in a scaled memory technology. We analyze the root causes of the RowHammer problem and examine various solutions. We also discuss what other vulnerabilities may be lurking in DRAM and other types of memories, e.g., NAND flash memory or Phase Change Memory, that can potentially threaten the foundations of secure systems, as the memory technologies scale to higher densities. We conclude by describing and advocating a principled approach to memory reliability and security research that can enable us to better anticipate and prevent such vulnerabilities. version:1
arxiv-1603-02208 | An Online Mechanism for Ridesharing in Autonomous Mobility-on-Demand Systems | http://arxiv.org/abs/1603.02208 | id:1603.02208 author:Wen Shen, Cristina V. Lopes, Jacob W. Crandall category:cs.AI cs.GT  published:2016-03-07 summary:With proper management, Autonomous Mobility-on-Demand (AMoD) systems have great potential to satisfy the transport demands of urban populations by providing safe, convenient, and affordable ridesharing services. Meanwhile, such systems can substantially decrease private car ownership and use, and thus significantly reduce traffic congestion, energy consumption, and carbon emissions. To achieve this objective, an AMoD system requires private information about the demand from passengers. However, due to self-interestedness, passengers are unlikely to cooperate with the service providers in this regard. Therefore, an online mechanism is desirable if it incentivizes passengers to truthfully report their actual demand. For the purpose of promoting ridesharing, we hereby introduce a posted-price, integrated online ridesharing mechanism (IORS) that satisfies desirable properties such as ex-post incentive compatibility, individual rationality, and budget-balance. Numerical results indicate the competitiveness of IORS compared with two benchmarks, namely the optimal assignment and an offline, auction-based mechanism. version:3
arxiv-1703-00477 | Walking Stabilization Using Step Timing and Location Adjustment on the Humanoid Robot, Atlas | http://arxiv.org/abs/1703.00477 | id:1703.00477 author:Robert J. Griffin, Georg Wiedebach, Sylvain Bertrand, Alexander Leonessa, Jerry Pratt category:cs.RO  published:2017-03-01 summary:While humans are highly capable of recovering from external disturbances and uncertainties that result in large tracking errors, humanoid robots have yet to reliably mimic this level of robustness. Essential to this is the ability to combine traditional "ankle strategy" balancing with step timing and location adjustment techniques. In doing so, the robot is able to step quickly to the necessary location to continue walking. In this work, we present both a new swing speed up algorithm to adjust the step timing, allowing the robot to set the foot down more quickly to recover from errors in the direction of the current capture point dynamics, and a new algorithm to adjust the desired footstep, expanding the base of support to utilize the center of pressure (CoP)-based ankle strategy for balance. We then utilize the desired centroidal moment pivot (CMP) to calculate the momentum rate of change for our inverse-dynamics based whole-body controller. We present simulation and experimental results using this work, and discuss performance limitations and potential improvements. version:1
arxiv-1703-00426 | HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving | http://arxiv.org/abs/1703.00426 | id:1703.00426 author:Cezary Kaliszyk, François Chollet, Christian Szegedy category:cs.AI  published:2017-03-01 summary:Large computer-understandable proofs consist of millions of intermediate logical steps. The vast majority of such steps originate from manually selected and manually guided heuristics applied to intermediate goals. So far, machine learning has generally not been used to filter or generate these steps. In this paper, we introduce a new dataset based on Higher-Order Logic (HOL) proofs, for the purpose of developing new machine learning-based theorem-proving strategies. We make this dataset publicly available under the BSD license. We propose various machine learning tasks that can be performed on this dataset, and discuss their significance for theorem proving. We also benchmark a set of simple baseline machine learning models suited for the tasks (including logistic regression, convolutional neural networks and recurrent neural networks). The results of our baseline models show the promise of applying machine learning to HOL theorem proving. version:1
arxiv-1702-08410 | Clustering in Discrete Path Planning for Approximating Minimum Length Paths | http://arxiv.org/abs/1702.08410 | id:1702.08410 author:Frank Imeson, Stephen L. Smith category:cs.RO  published:2017-02-27 summary:In this paper we consider discrete robot path planning problems on metric graphs. We propose a clustering method, Gamma-Clustering for the planning graph that significantly reduces the number of feasible solutions, yet retains a solution within a constant factor of the optimal. By increasing the input parameter Gamma, the constant factor can be decreased, but with less reduction in the search space. We provide a simple polynomial- time algorithm for finding optimal Gamma-Clusters, and show that for a given Gamma, this optimal is unique. We demonstrate the effectiveness of the clustering method on traveling salesman instances, showing that for many instances we obtain significant reductions in computation time with little to no reduction in solution quality. version:2
arxiv-1602-06667 | A Motion Planning Strategy for the Active Vision-Based Mapping of Ground-Level Structures | http://arxiv.org/abs/1602.06667 | id:1602.06667 author:S. R. Manikandasriram, André Phu-Van Nguyen, Jerome Le Ny category:cs.RO cs.AI cs.SY  published:2016-02-22 summary:This paper presents a strategy to guide a mobile ground robot equipped with a camera or depth sensor, in order to autonomously map the visible part of a bounded three-dimensional structure. We describe motion planning algorithms that determine appropriate successive viewpoints and attempt to fill holes automatically in a point cloud produced by the sensing and perception layer. The emphasis is on accurately reconstructing a 3D model of a structure of moderate size rather than mapping large open environments, with applications for example in architecture, construction and inspection. The proposed algorithms do not require any initialization in the form of a mesh model or a bounding box, and the paths generated are well adapted to situations where the vision sensor is used simultaneously for mapping and for localizing the robot, in the absence of additional absolute positioning system. We analyze the coverage properties of our policy, and compare its performance to the classic frontier based exploration algorithm. We illustrate its efficacy for different structure sizes, levels of localization accuracy and range of the depth sensor, and validate our design on a real-world experiment. version:2
arxiv-1703-00812 | Improper Filter Reduction | http://arxiv.org/abs/1703.00812 | id:1703.00812 author:Fatemeh Zahra Saberifar, Ali Mohades, Mohammadreza Razzazi, Jason M. O'Kane category:cs.RO cs.FL  published:2017-03-01 summary:Combinatorial filters have been the subject of increasing interest from the robotics community in recent years. This paper considers automatic reduction of combinatorial filters to a given size, even if that reduction necessitates changes to the filter's behavior. We introduce an algorithmic problem called improper filter reduction, in which the input is a combinatorial filter F along with an integer k representing the target size. The output is another combinatorial filter F' with at most k states, such that the difference in behavior between F and F' is minimal. We present two metrics for measuring the distance between pairs of filters, describe dynamic programming algorithms for computing these distances, and show that improper filter reduction is NP-hard under these metrics. We then describe two heuristic algorithms for improper filter reduction, one greedy sequential approach, and one randomized global approach based on prior work on weighted improper graph coloring. We have implemented these algorithms and analyze the results of three sets of experiments. version:1
arxiv-1703-00390 | Multimodal Gaze Stabilization of a Humanoid Robot based on Reafferences | http://arxiv.org/abs/1703.00390 | id:1703.00390 author:Timothee Habra, Markus Grotz, David Sippel, Tamim Asfour, Renaud Ronsse category:cs.RO  published:2017-03-01 summary:Gaze stabilization is fundamental for humanoid robots. By stabilizing vision, it enhances perception of the environment and keeps points of interest in the field of view. In this contribution, a multimodal gaze stabilization combining classic inverse kinematic control with vestibulo-ocular and optokinetic reflexes is introduced. Inspired by neuroscience, it implements a forward model that can modulate the reflexes based on the reafference principle. This principle filters self-generated movements out of the reflexive feedback loop. The versatility and effectiveness of this method are experimentally validated on the Armar-III humanoid robot. It is first demonstrated that each stabilization mechanism (inverse kinematics and reflexes) performs better than the others as a function of the type of perturbation to be stabilized. Furthermore, combining these three modalities by reafference provides a universal gaze stabilizer which can handle any kind of perturbation. version:1
arxiv-1702-07281 | A Probabilistic Framework for Location Inference from Social Media | http://arxiv.org/abs/1702.07281 | id:1702.07281 author:Yujie Qian, Jie Tang, Zhilin Yang, Binxuan Huang, Wei Wei, Kathleen M. Carley category:cs.AI cs.SI  published:2017-02-23 summary:We study the extent to which we can infer users' geographical locations from social media. Location inference from social media can benefit many applications, such as disaster management, targeted advertising, and news content tailoring. In recent years, a number of algorithms have been proposed for identifying user locations on social media platforms such as Twitter and Facebook from message contents, friend networks, and interactions between users. In this paper, we propose a novel probabilistic model based on factor graphs for location inference that offers several unique advantages for this task. First, the model generalizes previous methods by incorporating content, network, and deep features learned from social context. The model is also flexible enough to support both supervised learning and semi-supervised learning. Second, we explore several learning algorithms for the proposed model, and present a Two-chain Metropolis-Hastings (MH+) algorithm, which improves the inference accuracy. Third, we validate the proposed model on three different genres of data - Twitter, Weibo, and Facebook - and demonstrate that the proposed model can substantially improve the inference accuracy (+3.3-18.5% by F1-score) over that of several state-of-the-art methods. version:2
arxiv-1512-04114 | Building and Measuring Privacy-Preserving Predictive Blacklists | http://arxiv.org/abs/1512.04114 | id:1512.04114 author:Luca Melis, Apostolos Pyrgelis, Emiliano De Cristofaro category:cs.CR cs.AI  published:2015-12-13 summary:Collaborative security initiatives are increasingly often advocated to improve timeliness and effectiveness of threat mitigation. Among these, collaborative predictive blacklisting (CPB) aims to forecast attack sources based on alerts contributed by multiple organizations that might be targeted in similar ways. Alas, CPB proposals thus far have only focused on improving hit counts, but overlooked the impact of collaboration on false positives and false negatives. Moreover, sharing threat intelligence often prompts important privacy, confidentiality, and liability issues. In this paper, we first provide a comprehensive measurement analysis of two state-of-the-art CPB systems: one that uses a trusted central party to collect alerts [Soldo et al., Infocom'10] and a peer-to-peer one relying on controlled data sharing [Freudiger et al., DIMVA'15], studying the impact of collaboration on both correct and incorrect predictions. Then, we present a novel privacy-friendly approach that significantly improves over previous work, achieving a better balance of true and false positive rates, while minimizing information disclosure. Finally, we present an extension that allows our system to scale to very large numbers of organizations. version:4
arxiv-1701-05226 | Reasoning in Non-Probabilistic Uncertainty: Logic Programming and Neural-Symbolic Computing as Examples | http://arxiv.org/abs/1701.05226 | id:1701.05226 author:Tarek R. Besold, Artur d'Avila Garcez, Keith Stenning, Leendert van der Torre, Michiel van Lambalgen category:cs.AI  published:2017-01-18 summary:This article aims to achieve two goals: to show that probability is not the only way of dealing with uncertainty (and even more, that there are kinds of uncertainty which are for principled reasons not addressable with probabilistic means); and to provide evidence that logic-based methods can well support reasoning with uncertainty. For the latter claim, two paradigmatic examples are presented: Logic Programming with Kleene semantics for modelling reasoning from information in a discourse, to an interpretation of the state of affairs of the intended model, and a neural-symbolic implementation of Input/Output logic for dealing with uncertainty in dynamic normative contexts. version:2
arxiv-1703-00320 | Investigating the Characteristics of One-Sided Matching Mechanisms Under Various Preferences and Risk Attitudes | http://arxiv.org/abs/1703.00320 | id:1703.00320 author:Hadi Hosseini, Kate Larson, Robin Cohen category:cs.GT cs.AI cs.MA I.2.11; J.4  published:2017-03-01 summary:One-sided matching mechanisms are fundamental for assigning a set of indivisible objects to a set of self-interested agents when monetary transfers are not allowed. Two widely-studied randomized mechanisms in multiagent settings are the Random Serial Dictatorship (RSD) and the Probabilistic Serial Rule (PS). Both mechanisms require only that agents specify ordinal preferences and have a number of desirable economic and computational properties. However, the induced outcomes of the mechanisms are often incomparable and thus there are challenges when it comes to deciding which mechanism to adopt in practice. In this paper, we first consider the space of general ordinal preferences and provide empirical results on the (in)comparability of RSD and PS. We analyze their respective economic properties under general and lexicographic preferences. We then instantiate utility functions with the goal of gaining insights on the manipulability, efficiency, and envyfreeness of the mechanisms under different risk-attitude models. Our results hold under various preference distribution models, which further confirm the broad use of RSD in most practical applications. version:1
arxiv-1311-1714 | KaHIP v2.0 -- Karlsruhe High Quality Partitioning -- User Guide | http://arxiv.org/abs/1311.1714 | id:1311.1714 author:Peter Sanders, Christian Schulz category:cs.DC cs.DS  published:2013-11-07 summary:This paper serves as a user guide to the graph partitioning framework KaHIP (Karlsruhe High Quality Partitioning). We give a rough overview of the techniques used within the framework and describe the user interface as well as the file formats used. Moreover, we provide a short description of the current library functions provided within the framework. version:6
arxiv-1702-07920 | An Invariant-EKF VINS Algorithm for Improving Consistency | http://arxiv.org/abs/1702.07920 | id:1702.07920 author:Teng Zhang, Kanzhi Wu, Daobilige Su, Shoudong Huang, Gamini Dissanayake category:cs.RO  published:2017-02-25 summary:The main contribution of this paper is an invariant extended Kalman filter (EKF) for visual inertial navigation systems (VINS). It is demonstrated that the conventional EKF based VINS is not invariant under the stochastic unobservable transformation, associated with translations and a rotation about the gravitational direction. This can lead to inconsistent state estimates as the estimator does not obey a fundamental property of the physical system. To address this issue, we use a novel uncertainty representation to derive a Right Invariant error extended Kalman filter (RIEKF-VINS) that preserves this invariance property. RIEKF-VINS is then adapted to the multistate constraint Kalman filter framework to obtain a consistent state estimator. Both Monte Carlo simulations and real-world experiments are used to validate the proposed method. version:2
arxiv-1703-00227 | Occupancy Map Building through Bayesian Exploration | http://arxiv.org/abs/1703.00227 | id:1703.00227 author:Gilad Francis, Lionel Ott, Roman Marchant, Fabio Ramos category:cs.RO  published:2017-03-01 summary:We propose a novel holistic approach for safe autonomous exploration and map building based on constrained Bayesian optimisation. This method finds optimal continuous paths instead of discrete sensing locations that inherently satisfy motion and safety constraints. Evaluating both the objective and constraints functions requires forward simulation of expected observations. As such evaluations are costly, the Bayesian optimiser proposes only paths which are likely to yield optimal results and satisfy the constraints with high confidence. By balancing the reward and risk associated with each path, the optimiser minimises the number of expensive function evaluations. We demonstrate the effectiveness of our approach in a series of experiments both in simulation and with a real ground robot and provide comparisons to other exploration techniques. Evidently, each method has its specific favourable conditions, where it outperforms all other techniques. Yet, by reasoning on the usefulness of the entire path instead of its end point, our method provides a robust and consistent performance through all tests and performs better than or as good as the other leading methods. version:1
arxiv-1703-00194 | Stochastic Functional Gradient for Motion Planning in Continuous Occupancy Maps | http://arxiv.org/abs/1703.00194 | id:1703.00194 author:Gilad Francis, Lionel Ott, Fabio Ramos category:cs.RO  published:2017-03-01 summary:Safe path planning is a crucial component in autonomous robotics. The many approaches to find a collision free path can be categorically divided into trajectory optimisers and sampling-based methods. When planning using occupancy maps, the sampling-based approach is the prevalent method. The main drawback of such techniques is that the reasoning about the expected cost of a plan is limited to the search heuristic used by each method. We introduce a novel planning method based on trajectory optimisation to plan safe and efficient paths in continuous occupancy maps. We extend the expressiveness of the state-of-the-art functional gradient optimisation methods by devising a stochastic gradient update rule to optimise a path represented as a Gaussian process. This approach avoids the need to commit to a specific resolution of the path representation, whether spatial or parametric. We utilise a continuous occupancy map representation in order to define our optimisation objective, which enables fast computation of occupancy gradients. We show that this approach is essential in order to ensure convergence to the optimal path, and present results and comparisons to other planning methods in both simulation and with real laser data. The experiments demonstrate the benefits of using this technique when planning for safe and efficient paths in continuous occupancy maps. version:1
arxiv-1504-04804 | Multi-GPU Graph Analytics | http://arxiv.org/abs/1504.04804 | id:1504.04804 author:Yuechao Pan, Yangzihao Wang, Yuduo Wu, Carl Yang, John D. Owens category:cs.DC  published:2015-04-19 summary:We present a single-node, multi-GPU programmable graph processing library that allows programmers to easily extend single-GPU graph algorithms to achieve scalable performance on large graphs with billions of edges. Directly using the single-GPU implementations, our design only requires programmers to specify a few algorithm-dependent concerns, hiding most multi-GPU related implementation details. We analyze the theoretical and practical limits to scalability in the context of varying graph primitives and datasets. We describe several optimizations, such as direction optimizing traversal, and a just-enough memory allocation scheme, for better performance and smaller memory consumption. Compared to previous work, we achieve best-of-class performance across operations and datasets, including excellent strong and weak scalability on most primitives as we increase the number of GPUs in the system. version:4
arxiv-1703-00186 | Performance and Portability of Accelerated Lattice Boltzmann Applications with OpenACC | http://arxiv.org/abs/1703.00186 | id:1703.00186 author:E. Calore, A. Gabbana, J. Kraus, S. F. Schifano, R. Tripiccione category:cs.DC  published:2017-03-01 summary:An increasingly large number of HPC systems rely on heterogeneous architectures combining traditional multi-core CPUs with power efficient accelerators. Designing efficient applications for these systems has been troublesome in the past as accelerators could usually be programmed using specific programming languages threatening maintainability, portability and correctness. Several new programming environments try to tackle this problem. Among them, OpenACC offers a high-level approach based on compiler directive clauses to mark regions of existing C, C++ or Fortran codes to run on accelerators. This approach directly addresses code portability, leaving to compilers the support of each different accelerator, but one has to carefully assess the relative costs of portable approaches versus computing efficiency. In this paper we address precisely this issue, using as a test-bench a massively parallel Lattice Boltzmann algorithm. We first describe our multi-node implementation and optimization of the algorithm, using OpenACC and MPI. We then benchmark the code on a variety of processors, including traditional CPUs and GPUs, and make accurate performance comparisons with other GPU implementations of the same algorithm using CUDA and OpenCL. We also asses the performance impact associated to portable programming, and the actual portability and performance-portability of OpenACC-based applications across several state-of-the- art architectures. version:1
arxiv-1703-00185 | Massively parallel lattice-Boltzmann codes on large GPU clusters | http://arxiv.org/abs/1703.00185 | id:1703.00185 author:E. Calore, A. Gabbana, J. Kraus, E. Pellegrini, S. F. Schifano, R. Tripiccione category:cs.DC  published:2017-03-01 summary:This paper describes a massively parallel code for a state-of-the art thermal lattice- Boltzmann method. Our code has been carefully optimized for performance on one GPU and to have a good scaling behavior extending to a large number of GPUs. Versions of this code have been already used for large-scale studies of convective turbulence. GPUs are becoming increasingly popular in HPC applications, as they are able to deliver higher performance than traditional processors. Writing efficient programs for large clusters is not an easy task as codes must adapt to increasingly parallel architectures, and the overheads of node-to-node communications must be properly handled. We describe the structure of our code, discussing several key design choices that were guided by theoretical models of performance and experimental benchmarks. We present an extensive set of performance measurements and identify the corresponding main bot- tlenecks; finally we compare the results of our GPU code with those measured on other currently available high performance processors. Our results are a production-grade code able to deliver a sustained performance of several tens of Tflops as well as a design and op- timization methodology that can be used for the development of other high performance applications for computational physics. version:1
arxiv-1703-00042 | Reproducible experiments on dynamic resource allocation in cloud data centers | http://arxiv.org/abs/1703.00042 | id:1703.00042 author:Andreas Wolke, Martin Bichler, Fernando Chirigati, Victoria Steeves category:cs.DC  published:2017-02-28 summary:In Wolke et al. [1] we compare the efficiency of different resource allocation strategies experimentally. We focused on dynamic environments where virtual machines need to be allocated and deallocated to servers over time. In this companion paper, we describe the simulation framework and how to run simulations to replicate experiments or run new experiments within the framework. version:1
arxiv-1702-08862 | Proportional Representation in Vote Streams | http://arxiv.org/abs/1702.08862 | id:1702.08862 author:Palash Dey, Nimrod Talmon, Otniel van Handel category:cs.GT cs.AI cs.CC cs.DS cs.MA  published:2017-02-28 summary:We consider elections where the voters come one at a time, in a streaming fashion, and devise space-efficient algorithms which identify an approximate winning committee with respect to common multiwinner proportional representation voting rules; specifically, we consider the Approval-based and the Borda-based variants of both the Chamberlin-- ourant rule and the Monroe rule. We complement our algorithms with lower bounds. Somewhat surprisingly, our results imply that, using space which does not depend on the number of voters it is possible to efficiently identify an approximate representative committee of fixed size over vote streams with huge number of voters. version:1
arxiv-1504-08248 | Frugal Bribery in Voting | http://arxiv.org/abs/1504.08248 | id:1504.08248 author:Palash Dey, Neeldhara Misra, Y. Narahari category:cs.AI cs.MA  published:2015-04-30 summary:Bribery in elections is an important problem in computational social choice theory. However, bribery with money is often illegal in elections. Motivated by this, we introduce the notion of frugal bribery and formulate two new pertinent computational problems which we call Frugal-bribery and Frugal- $bribery to capture bribery without money in elections. In the proposed model, the briber is frugal in nature and this is captured by her inability to bribe votes of a certain kind, namely, non-vulnerable votes. In the Frugal-bribery problem, the goal is to make a certain candidate win the election by changing only vulnerable votes. In the Frugal-{dollar}bribery problem, the vulnerable votes have prices and the goal is to make a certain candidate win the election by changing only vulnerable votes, subject to a budget constraint of the briber. We further formulate two natural variants of the Frugal-{dollar}bribery problem namely Uniform-frugal-{dollar}bribery and Nonuniform-frugal-{dollar}bribery where the prices of the vulnerable votes are, respectively, all the same or different. We study the computational complexity of the above problems for unweighted and weighted elections for several commonly used voting rules. We observe that, even if we have only a small number of candidates, the problems are intractable for all voting rules studied here for weighted elections, with the sole exception of the Frugal-bribery problem for the plurality voting rule. In contrast, we have polynomial time algorithms for the Frugal-bribery problem for plurality, veto, k-approval, k-veto, and plurality with runoff voting rules for unweighted elections. However, the Frugal-{dollar}bribery problem is intractable for all the voting rules studied here barring the plurality and the veto voting rules for unweighted elections. version:3
arxiv-1702-08817 | Privacy-enhancing Aggregation of Internet of Things Data via Sensors Grouping | http://arxiv.org/abs/1702.08817 | id:1702.08817 author:Stefano Bennati, Evangelos Pournaras category:cs.DC  published:2017-02-28 summary:Big data collection practices using Internet of Things (IoT) pervasive technologies are often privacy-intrusive and result in surveillance, profiling, and discriminatory actions over citizens. On the other hand, real-time data analytics and aggregate information open up tremendous opportunities for managing and regulating infrastructures of smart grids and smart cities in a more efficient and sustainable way. The privacy-enhancing aggregation of distributed sensor data is the research focus and challenge tackled in this paper. A baseline scenario is considered in which IoT sensor data are sent directly to an untrustworthy central aggregator. Users are enabled to choose their privacy level by reducing the quality of the shared data. There is a trade-off between the quality of data and the accuracy level of data analytics. A grouping mechanism is introduced that improves privacy over the baseline scenario by sharing aggregated group data with the aggregator. The group-level aggregation step obfuscates the individual sensor data, in a similar fashion as differential privacy techniques and homomorphic encryption schemes, thus inference of privacy-sensitive information from single sensors becomes computationally harder compared to the baseline scenario. The mechanism improves individual privacy over the baseline, without an impact on accuracy. Furthermore, if groups are large enough, the mechanism improves the privacy independently of individual choices. Inter-group effects such as the influence of individual choices on the privacy of other group members are investigated. Finally, several grouping strategies are evaluated and compared, and the implications for the design of an incentive mechanism are discussed. version:1
arxiv-1703-00352 | Do Reichenbachian Common Cause Systems of Arbitrary Finite Size Exist? | http://arxiv.org/abs/1703.00352 | id:1703.00352 author:Claudio Mazzola, Peter Evans category:stat.OT cs.AI physics.hist-ph  published:2017-02-28 summary:The principle of common cause asserts that positive correlations between causally unrelated events ought to be explained through the action of some shared causal factors. Reichenbachian common cause systems are probabilistic structures aimed at accounting for cases where correlations of the aforesaid sort cannot be explained through the action of a single common cause. The existence of Reichenbachian common cause systems of arbitrary finite size for each pair of non-causally correlated events was allegedly demonstrated by Hofer-Szab\'o and R\'edei in 2006. This paper shows that their proof is logically deficient, and we propose an improved proof. version:1
arxiv-1702-08745 | Optimal Categorical Attribute Transformation for Granularity Change in Relational Databases for Binary Decision Problems in Educational Data Mining | http://arxiv.org/abs/1702.08745 | id:1702.08745 author:Paulo J. L. Adeodato, Fábio C. Pereira, Rosalvo F. Oliveira Neto category:cs.AI cs.DB I.2; H.2.8; J.1  published:2017-02-28 summary:This paper presents an approach for transforming data granularity in hierarchical databases for binary decision problems by applying regression to categorical attributes at the lower grain levels. Attributes from a lower hierarchy entity in the relational database have their information content optimized through regression on the categories histogram trained on a small exclusive labelled sample, instead of the usual mode category of the distribution. The paper validates the approach on a binary decision task for assessing the quality of secondary schools focusing on how logistic regression transforms the students and teachers attributes into school attributes. Experiments were carried out on Brazilian schools public datasets via 10-fold cross-validation comparison of the ranking score produced also by logistic regression. The proposed approach achieved higher performance than the usual distribution mode transformation and equal to the expert weighing approach measured by the maximum Kolmogorov-Smirnov distance and the area under the ROC curve at 0.01 significance level. version:1
arxiv-1702-08742 | Robust Bipedal Locomotion Control Based on Model Predictive Control and Divergent Component of Motion | http://arxiv.org/abs/1702.08742 | id:1702.08742 author:Milad Shafiee-Ashtiani, Aghil Yousefi-Koma, Masoud Shariat-Panahi category:cs.RO  published:2017-02-28 summary:In this paper, previous works on the Model Predictive Control (MPC) and the Divergent Component of Motion (DCM) for bipedal walking control are extended. To this end, we employ a single MPC which uses a combination of Center of Pressure (CoP) manipulation, step adjustment, and Centroidal Moment Pivot (CMP) modulation to design a robust walking controller. Furthermore, we exploit the concept of time-varying DCM to generalize our walking controller for walking in uneven surfaces. Using our scheme, a general and robust walking controller is designed which can be implemented on robots with different control authorities, for walking on various environments, e.g. uneven terrains or surfaces with a very limited feasible area for stepping. The effectiveness of the proposed approach is verified through simulations on different scenarios and comparison to the state of the art. version:1
arxiv-1702-08726 | Stacked Thompson Bandits | http://arxiv.org/abs/1702.08726 | id:1702.08726 author:Lenz Belzner, Thomas Gabor category:cs.SE cs.AI cs.SY  published:2017-02-28 summary:We introduce Stacked Thompson Bandits (STB) for efficiently generating plans that are likely to satisfy a given bounded temporal logic requirement. STB uses a simulation for evaluation of plans, and takes a Bayesian approach to using the resulting information to guide its search. In particular, we show that stacking multiarmed bandits and using Thompson sampling to guide the action selection process for each bandit enables STB to generate plans that satisfy requirements with a high probability while only searching a fraction of the search space. version:1
arxiv-1702-08725 | Bayesian Verification under Model Uncertainty | http://arxiv.org/abs/1702.08725 | id:1702.08725 author:Lenz Belzner, Thomas Gabor category:cs.SE cs.AI  published:2017-02-28 summary:Machine learning enables systems to build and update domain models based on runtime observations. In this paper, we study statistical model checking and runtime verification for systems with this ability. Two challenges arise: (1) Models built from limited runtime data yield uncertainty to be dealt with. (2) There is no definition of satisfaction w.r.t. uncertain hypotheses. We propose such a definition of subjective satisfaction based on recently introduced satisfaction functions. We also propose the BV algorithm as a Bayesian solution to runtime verification of subjective satisfaction under model uncertainty. BV provides user-definable stochastic bounds for type I and II errors. We discuss empirical results from an example application to illustrate our ideas. version:1
arxiv-1702-08656 | Design and Approach of Team IHMC in the 2016 Cybathlon | http://arxiv.org/abs/1702.08656 | id:1702.08656 author:Robert Griffin, Tyson Cobb, Travis Craig, Mark Daniel, Nick van Dijk, Jeremy Gines, Koen Kramer, Shriya Shah, Olger Siebinga, Jesper Smith, Peter Neuhaus category:cs.RO  published:2017-02-28 summary:Exoskeletons are a promising technology for enabling individuals with mobility limitations to walk again. As the 2016 Cybathlon illustrated, however, we have a considerable way to go before exoskeletons have the necessary capabilities to be incorporated into daily life. Most exoskeletons, power only the hip and knee flexion, whereas we present a new exoskeleton, Mina v2, that includes a powered dorsi/plantar flexion. As our entry to the 2016 Cybathlon Powered Exoskeleton Competition, Mina v2's powered ankle allowed us to explore its effectiveness on powered exoskeletons for pilots with paraplegia. We designed our gaits around the incorporation of powered ankle plantar flexion to help improve mobility. Using this approach, our pilot was able to navigate the tasks quickly, especially those that required ascending, and reliably achieve average, conservative walking speeds of 0.29 m/s. This enabled our team to place 2nd overall in the Powered Exoskeleton Competition in the 2016 Cybathlon. version:1
arxiv-1612-02088 | Effect of Reward Function Choices in MDPs with Value-at-Risk | http://arxiv.org/abs/1612.02088 | id:1612.02088 author:Shuai Ma, Jia Yuan Yu category:cs.AI  published:2016-12-07 summary:This paper studies Value-at-Risk (VaR) problems in short- and long-horizon Markov decision processes (MDPs) with finite state space and two different reward functions. Firstly we examine the effects of two reward functions under two criteria in a short-horizon MDP. We show that under the VaR criterion, when the original reward function is on both current and next states, the reward simplification will change the VaR. Secondly, for long-horizon MDPs, we estimate the Pareto front of the total reward distribution set with the aid of spectral theory and the central limit theorem. Since the estimation is for a Markov process with the simplified reward function only, we present a transformation algorithm for the Markov process with the original reward function, in order to estimate the Pareto front with an intact total reward distribution. version:3
arxiv-1702-05513 | Rethinking High Performance Computing Platforms: Challenges, Opportunities and Recommendations | http://arxiv.org/abs/1702.05513 | id:1702.05513 author:Ole Weidner, Malcolm Atkinson, Adam Barker, Rosa Filgueira category:cs.DC  published:2017-02-17 summary:A new class of Second generation high-performance computing applications with heterogeneous, dynamic and data-intensive properties have an extended set of requirements, which cover application deployment, resource allocation, -control, and I/O scheduling. These requirements are not met by the current production HPC platform models and policies. This results in a loss of opportunity, productivity and innovation for new computational methods and tools. It also decreases effective system utilization for platform providers due to unsupervised workarounds and rogue resource management strategies implemented in application space. In this paper we critically discuss the dominant HPC platform model and describe the challenges it creates for second generation applications because of its asymmetric resource view, interfaces and software deployment policies. We present an extended, more symmetric and application-centric platform model that adds decentralized deployment, introspection, bidirectional control and information flow and more comprehensive resource scheduling. We describe cHPC: an early prototype of a non-disruptive implementation based on Linux Containers (LXC). It can operate alongside existing batch queuing systems and exposes a symmetric platform API without interfering with existing applications and usage modes. We see our approach as a viable, incremental next step in HPC platform evolution that benefits applications and platform providers alike. To demonstrate this further, we layout out a roadmap for future research and experimental evaluation. version:2
arxiv-1702-08377 | Optimized Secure Position Sharing with Non-trusted Servers | http://arxiv.org/abs/1702.08377 | id:1702.08377 author:Pavel Skvortsov, Björn Schembera, Frank Dürr, Kurt Rothermel category:cs.DC 68M14 C.2.4; H.3.5  published:2017-02-27 summary:Today, location-based applications and services such as friend finders and geo-social networks are very popular. However, storing private position information on third-party location servers leads to privacy problems. In our previous work, we proposed a position sharing approach for secure management of positions on non-trusted servers, which distributes position shares of limited precision among servers of several providers. In this paper, we propose two novel contributions to improve the original approach. First, we optimize the placement of shares among servers by taking their trustworthiness into account. Second, we optimize the location update protocols to minimize the number of messages between mobile device and location servers. version:1
arxiv-1702-08376 | Admittance Control Parameter Adaptation for Physical Human-Robot Interaction | http://arxiv.org/abs/1702.08376 | id:1702.08376 author:Chiara Talignani Landi, Federica Ferraguti, Lorenzo Sabattini, Cristian Secchi, Cesare Fantuzzi category:cs.RO  published:2017-02-27 summary:In physical human-robot interaction, the coexistence of robots and humans in the same workspace requires the guarantee of a stable interaction, trying to minimize the effort for the operator. To this aim, the admittance control is widely used and the appropriate selection of the its parameters is crucial, since they affect both the stability and the ability of the robot to interact with the user. In this paper, we present a strategy for detecting deviations from the nominal behavior of an admittance-controlled robot and for adapting the parameters of the controller while guaranteeing the passivity. The proposed methodology is validated on a KUKA LWR 4+. version:1
arxiv-1609-05243 | Fast Second-order Cone Programming for Safe Mission Planning | http://arxiv.org/abs/1609.05243 | id:1609.05243 author:Kai Zhong, Prateek Jain, Ashish Kapoor category:cs.RO  published:2016-09-16 summary:This paper considers the problem of safe mission planning of dynamic systems operating under uncertain environments. Much of the prior work on achieving robust and safe control requires solving second-order cone programs (SOCP). Unfortunately, existing general purpose SOCP methods are often infeasible for real-time robotic tasks due to high memory and computational requirements imposed by existing general optimization methods. The key contribution of this paper is a fast and memory-efficient algorithm for SOCP that would enable robust and safe mission planning on-board robots in real-time. Our algorithm does not have any external dependency, can efficiently utilize warm start provided in safe planning settings, and in fact leads to significant speed up over standard optimization packages (like SDPT3) for even standard SOCP problems. For example, for a standard quadrotor problem, our method leads to speedup of 1000x over SDPT3 without any deterioration in the solution quality. Our method is based on two insights: a) SOCPs can be interpreted as optimizing a function over a polytope with infinite sides, b) a linear function can be efficiently optimized over this polytope. We combine the above observations with a novel utilization of Wolfe's algorithm to obtain an efficient optimization method that can be easily implemented on small embedded devices. In addition to the above mentioned algorithm, we also design a two-level sensing method based on Gaussian Process for complex obstacles with non-linear boundaries such as a cylinder. version:2
arxiv-1702-08286 | Balancing Lexicographic Fairness and a Utilitarian Objective with Application to Kidney Exchange | http://arxiv.org/abs/1702.08286 | id:1702.08286 author:Duncan C. McElfresh, John P. Dickerson category:cs.GT cs.AI I.2.11; J.4  published:2017-02-27 summary:Balancing fairness and efficiency in resource allocation is a classical economic and computational problem. The price of fairness measures the worst-case loss of economic efficiency when using an inefficient but fair allocation rule; for indivisible goods in many settings, this price is unacceptably high. In this work, we propose a hybrid fairness rule that balances a strict lexicographic preference ordering over classes of agents and a utilitarian objective that maximizes economic efficiency. We develop a utility function that favors disadvantaged groups lexicographically; but if cost to overall efficiency becomes too high, it smoothly switches to a utilitarian objective. This rule has only one parameter which is proportional to a bound on the price of fairness, and can be adjusted by policymakers. We apply this rule to kidney exchange, where needy patients swap willing but incompatible donors, and demonstrate on real data from a large exchange that our hybrid rule produces more reliable outcomes than other fairness rules. version:1
arxiv-1702-08222 | Synergistic Team Composition | http://arxiv.org/abs/1702.08222 | id:1702.08222 author:Ewa Andrejczuk, Juan A. Rodriguez-Aguilar, Carme Roig, Carles Sierra category:cs.AI  published:2017-02-27 summary:Effective teams are crucial for organisations, especially in environments that require teams to be constantly created and dismantled, such as software development, scientific experiments, crowd-sourcing, or the classroom. Key factors influencing team performance are competences and personality of team members. Hence, we present a computational model to compose proficient and congenial teams based on individuals' personalities and their competences to perform tasks of different nature. With this purpose, we extend Wilde's post-Jungian method for team composition, which solely employs individuals' personalities. The aim of this study is to create a model to partition agents into teams that are balanced in competences, personality and gender. Finally, we present some preliminary empirical results that we obtained when analysing student performance. Results show the benefits of a more informed team composition that exploits individuals' competences besides information about their personalities. version:1
arxiv-1702-08176 | Another Look at the Implementation of Read/write Registers in Crash-prone Asynchronous Message-Passing Systems (Extended Version) | http://arxiv.org/abs/1702.08176 | id:1702.08176 author:Damien Imbs, Achour Mostefaoui, Matthieu Perrin, Michel Raynal category:cs.DC  published:2017-02-27 summary:" Yet another paper on " the implementation of read/write registers in crash-prone asynchronous message-passing systems! Yes..., but, differently from its predecessors, this paper looks for a communication abstraction which captures the essence of such an implementation in the same sense that total order broadcast can be associated with consensus, or message causal delivery can be associated with causal read/write registers. To this end, the paper introduces a new communication abstraction, named SCD-broadcast (SCD standing for " Set Constrained Delivery "), which, instead of a single message, delivers to processes sets of messages (whose size can be arbitrary), such that the sequences of message sets delivered to any two processes satisfies some constraints. The paper then shows that: (a) SCD-broadcast allows for a very simple implementation of a snapshot object (and consequently also of atomic read/write registers) in crash-prone asynchronous message-passing systems, (b) SCD-broadcast can be built from snapshot objects (hence SCD-broadcast and snapshot objects --or read/write registers-- are " computationally equivalent "), (c) SCD-broadcast can be built in message-passing systems where any minority of processes may crash (which is the weakest assumption on the number of possible process crashes needed to implement a read/write register). version:1
arxiv-1702-08172 | Tars: Timeliness-aware Adaptive Replica Selection for Key-Value Stores | http://arxiv.org/abs/1702.08172 | id:1702.08172 author:Wanchun Jiang, Liyuan Fang, Haiming Xie, Xiangqian Zhou, Jianxin Wang category:cs.DC  published:2017-02-27 summary:In current large-scale distributed key-value stores, a single end-user request may lead to key-value access across tens or hundreds of servers. The tail latency of these key-value accesses is crucial to the user experience and greatly impacts the revenue. To cut the tail latency, it is crucial for clients to choose the fastest replica server as much as possible for the service of each key-value access. Aware of the challenges on the time varying performance across servers and the herd behaviors, an adaptive replica selection scheme C3 is proposed recently. In C3, feedback from individual servers is brought into replica ranking to reflect the time-varying performance of servers, and the distributed rate control and backpressure mechanism is invented. Despite of C3's good performance, we reveal the timeliness issue of C3, which has large impacts on both the replica ranking and the rate control, and propose the Tars (timeliness-aware adaptive replica selection) scheme. Following the same framework as C3, Tars improves the replica ranking by taking the timeliness of the feedback information into consideration, as well as revises the rate control of C3. Simulation results confirm that Tars outperforms C3. version:1
arxiv-1702-07335 | Approximately Optimal Continuous-Time Motion Planning and Control via Probabilistic Inference | http://arxiv.org/abs/1702.07335 | id:1702.07335 author:Mustafa Mukadam, Ching-An Cheng, Xinyan Yan, Byron Boots category:cs.RO cs.SY  published:2017-02-23 summary:The problem of optimal motion planing and control is fundamental in robotics. However, this problem is intractable for continuous-time stochastic systems in general and the solution is difficult to approximate if non-instantaneous nonlinear performance indices are present. In this work, we provide an efficient algorithm, PIPC (Probabilistic Inference for Planning and Control), that yields approximately optimal policies with arbitrary higher-order nonlinear performance indices. Using probabilistic inference and a Gaussian process representation of trajectories, PIPC exploits the underlying sparsity of the problem such that its complexity scales linearly in the number of nonlinear factors. We demonstrate the capabilities of our algorithm in a receding horizon setting with multiple systems in simulation. version:2
arxiv-1501-06238 | Sky: Opinion Dynamics Based Consensus for P2P Network with Trust Relationships | http://arxiv.org/abs/1501.06238 | id:1501.06238 author:Houwu Chen, Jiwu Shu category:cs.DC  published:2015-01-26 summary:Traditional Byzantine consensus does not work in P2P network due to Sybil attack while the most prevalent Sybil-proof consensus at present still can't resist adversary with dominant compute power. This paper proposed opinion dynamics based consensus for P2P network with trust relationships, consisting of the sky framework and the sky model. With the sky framework, opinion dynamics can be applied in P2P network for consensus which is Sybil-proof through trust relationships and emerges from local interactions of each node with its direct contacts without topology, global information or even sample of the network involved. The sky model has better performance of convergence than existing models including MR, voter and Sznajd, and its lower bound of fault tolerance performance is also analyzed and proved. Simulations show that our approach can tolerant failures by at least 13% random nodes or 2% top influential nodes while over 96% correct nodes still make correct decision within 70 seconds on the SNAP Wikipedia who-votes-on-whom network for initial configuration of convergence>0.5 with reasonable latencies. Comparing to compute power based consensus, our approach can resist any faulty or malicious nodes by unfollowing them. To the best of our knowledge, it's the first work to bring opinion dynamics to P2P network for consensus. version:9
arxiv-1507-03927 | SkyHash: a Hash Opinion Dynamics Model | http://arxiv.org/abs/1507.03927 | id:1507.03927 author:Houwu Chen, Jiwu Shu category:cs.DC  published:2015-07-14 summary:This paper proposes the first hash opinion dynamics model, named SkyHash, that can help a P2P network quickly reach consensus on hash opinion. The model consists of a bit layer and a hash layer, each time when a node shapes its new opinion, the bit layer is to determine each bit of a pseudo hash, and the hash layer is to choose a hash opinion with minimum Hamming distance to the pseudo hash. With simulations, we conducted a comprehensive study on the convergence speed of the model by taking into account impacts of various configurations such as network size, node degree, hash size, and initial hash density. Evaluation demonstrates that using our model, consensus can be quickly reached even in large networks. We also developed a denial-of-service (DoS) proof extension for our model. Experiments on the SNAP dataset of the Wikipedia who-votes-on-whom network demonstrate that besides the ability to refuse known ill-behaved nodes, the DoS-proof extended model also outperforms Bitcoin by producing consensus in 45 seconds, and tolerating DoS attack committed by up to 0.9% top influential nodes. version:6
arxiv-1702-08107 | Guidance of an Autonomous Underwater Vehicle in Special Situations | http://arxiv.org/abs/1702.08107 | id:1702.08107 author:Mike Eichhorn category:cs.RO  published:2017-02-26 summary:This article describes a guidance system of the autonomous underwater vehicle "DeepC" [1] in Special situations. A special situation occurs when one or more objects interfere with the planned route of a mission. The possible reactions are evasion or identification of the objects. The paper presents these two tasks in overview. The special demands challenges of the underwater environment, computer parameters, sensors and the maneuverability of the vehicle are considered in the selection and development of the required strategies. Such challenges include the sea current, maneuver in the 3-D space and the limited perceptive faculty of the sonar. version:1
arxiv-1702-08106 | A New Concept for an Obstacle Avoidance System for the AUV "SLOCUM Glider" Operation under Ice | http://arxiv.org/abs/1702.08106 | id:1702.08106 author:Mike Eichhorn category:cs.RO  published:2017-02-26 summary:This paper presents a concept for a control System for an autonomous underwater vehicle under ice using a "SLOCUM" underwater glider. The project concept, the separate working tasks for the next one-and-a-half years and the first results will be presented. In this context the structure of the obstacle avoidance system and a simulator structure with a sensor and environment simulation as well as the interfaces to the glider hardware will be discussed. As a first result of the main research, a graph-based algorithm for the path planning in a time-varying environment (variable ocean field, moving obstacles) will be described. version:1
arxiv-1702-08104 | A Mission Planning System for the AUV "SLOCUM Glider" for the Newfoundland and Labrador Shelf | http://arxiv.org/abs/1702.08104 | id:1702.08104 author:Mike Eichhorn, Christopher D. Williams, Ralf Bachmayer, Brad de Young category:cs.RO  published:2017-02-26 summary:This paper presents a system for mission planning for an autonomous underwater vehicle in time-varying ocean currents. The mission planning system is designed for the AUV "SLOCUM Glider" to collect oceanographic data along the Newfoundland and Labrador Shelf. The data will be used in conjunction with a numerical ocean model currently under development by the Department of Fisheries and Oceans Canada. This allows for the validation and the modification of existing ocean current and climate models as well as the design of new models with the aim of improving the accuracy of forecasts. The use of the ocean current forecast data in netCDF format in an ocean current model, the algorithms which consider glider-specific behaviour, details of the program's technical implementation in C++, and, preliminary results will be described. version:1
arxiv-1702-08101 | Solutions for Practice-oriented Requirements for Optimal Path Planning for the AUV "SLOCUM Glider" | http://arxiv.org/abs/1702.08101 | id:1702.08101 author:Mike Eichhorn category:cs.RO  published:2017-02-26 summary:This paper presents a few important practiceoriented requirements for optimal path planning for the AUV "SLOCUM Glider" as well as solutions using fast graph basedalgorithms. These algorithms build upon the TVE (time-varying environment) search algorithm. The experience with this algorithm, requirements of real missions along the Newfoundland and Labrador Shelf and the idea to find the optimal departure time are the motivation to address the field of research, which is described in this paper. The main focus of this paper is a discussion of possible methods to accelerate the path planning algorithm, without deterioration of the results. version:1
arxiv-1702-08098 | Opportunities to Parallelize Path Planning Algorithms for Autonomous Underwater Vehicles | http://arxiv.org/abs/1702.08098 | id:1702.08098 author:Mike Eichhorn, Ulrich Kremer category:cs.RO  published:2017-02-26 summary:This paper discusses opportunities to parallelize graph based path planning algorithms in a time varying environment. Parallel architectures have become commonplace, requiring algorithm to be parallelized for efficient execution. An additional focal point of this paper is the inclusion of inaccuracies in path planning as a result of forecast error variance, accuracy of calculation in the cost functions and a different observed vehicle speed in the real mission than planned. In this context, robust path planning algorithms will be described. These algorithms are equally applicable to land based, aerial, or underwater mobile autonomous systems. The results presented here provide the basis for a future Research project in which the parallelized algorithms will be evaluated on multi and many core systems such as the dual core ARM Panda board and the 48 core Single-chip Cloud Computer (SCC). Modern multi and many core processors support a wide range of performance vs. energy tradeoffs that can be exploited in energyconstrained environments such as battery operated autonomous underwater vehicles. For this evaluation, the boards will be deployed within the Slocum glider, a commercially available, buoyancy driven autonomous underwater vehicle (AUV). version:1
arxiv-1702-08094 | Modular AUV System for Sea Water Quality Monitoring and Management | http://arxiv.org/abs/1702.08094 | id:1702.08094 author:Mike Eichhorn, Ralf Taubert, Christoph Ament, Marco Jacobi, Torsten Pfuetzenreuter category:cs.RO  published:2017-02-26 summary:The sustained and cost-effective monitoring of the water quality within European coastal areas is of growing importance in view of the upcoming European marine and maritime directives, i.e. the increased industrial use of the marine environment. Such monitoring needs mechanisms/systems to detect the water quality in a large sea area at different depths in real time. This paper presents a system for the automated detection and analysis of water quality parameters using an autonomous underwater vehicle. The analysis of discharge of nitrate into Norwegian fjords near aqua farms is one of the main application fields of this AUV system. As carrier platform the AUV "CWolf" from the Fraunhofer IOSB-AST will be used, which is perfectly suited through its modular payload concept. The mission Task and the integration of the payload unit which includes the sensor module, the scientific and measurement computer in the AUV carrier platform will be described. Few practice oriented information about the software and interface concept, the function of the several software modules and the test platform with the several test levels to test every module will be discussed. version:1
arxiv-1702-08092 | Parallelization of Path Planning Algorithms for AUVs Concepts, Opportunities, and Program-Technical Implementation | http://arxiv.org/abs/1702.08092 | id:1702.08092 author:Mike Eichhorn, Hans Christian Woithe, Ulrich Kremer category:cs.RO  published:2017-02-26 summary:Modern autonomous underwater vehicles (AUVs) have advanced sensing capabilities including sonar, cameras, acoustic communication, and diverse bio-sensors. Instead of just sensing its environment and storing the data for post-Mission inspection, an AUV could use the collected information to gain an understanding of its environment, and based on this understanding autonomously adapt its behavior to enhance the overall effectiveness of its mission. Many such tasks are highly computation intensive. This paper presents the results of a case study that illustrates the effectiveness of an energy-aware, many-core computing architecture to perform on-board path planning within a batteryoperated AUV. A previously published path planning algorithm was ported onto the SCC, an experimental 48 core single-chip system developed by Intel. The performance, power, and energy consumption of the application were measured for different numbers of cores and other system parameters. This case study shows that computation intensive tasks can be executed within an AUV that relies mainly on battery power. Future plans include the deployment and testing of an SCC system within a Teledyne Webb Research Slocum glider. version:1
arxiv-1702-08090 | Comparison of Guidance Modes for the AUV "Slocum Glider" in Time-Varying Ocean Flows | http://arxiv.org/abs/1702.08090 | id:1702.08090 author:Mike Eichhorn, Hans Christian Woithe, Ulrich Kremer category:cs.RO  published:2017-02-26 summary:This paper presents possibilities for the reliable guidance of an AUV "Slocum Glider" in time-varying ocean flows. The presented guidance modes consider the restricted information during a real mission about the actual position and ocean current conditions as well as the available control modes of a glider. A faster-than-real-time, full software stack simulator for the Slocum glider will be described in order to test the developed guidance modes under real mission conditions. version:1
arxiv-1604-01504 | Integrating NOE and RDC using sum-of-squares relaxation for protein structure determination | http://arxiv.org/abs/1604.01504 | id:1604.01504 author:Yuehaw Khoo, Amit Singer, David Cowburn category:cs.CE cs.RO math.OC I.4.9; G.1.6  published:2016-04-06 summary:We revisit the problem of protein structure determination from geometrical restraints from NMR, using convex optimization. It is well-known that the NP-hard distance geometry problem of determining atomic positions from pairwise distance restraints can be relaxed into a convex semidefinite program. Often the NOE distance restraints are too imprecise and sparse for accurate structure determination. Residual dipolar coupling (RDC) measurements provide additional geometric information on the angles between atom-pair directions and axes of the principal-axis-frame. The optimization problem involving RDC is highly non-convex and requires a good initialization even within the simulated annealing framework. In this paper, we model the protein backbone as an articulated structure composed of rigid units. Determining the rotation of each rigid unit gives the full protein structure. We propose solving the non-convex optimization problems using the sum-of-squares (SOS) hierarchy. The two algorithms - RDC-SOS and RDC-NOE-SOS, have polynomial time complexity in the number of amino-acid residues and run efficiently on a standard desktop. In many instances, the proposed methods exactly recover the solution to the original non-convex optimization problem. We introduce a statistical tool, the Cramer-Rao bound (CRB), to provide an information theoretic bound on the highest resolution one can hope to achieve when determining protein structure from noisy measurements using any methodology. Our simulation results show that when the RDC measurements are corrupted by Gaussian noise of realistic variance, both SOS based algorithms attain the CRB. We successfully apply our method in a divide-and-conquer fashion to determine the structure of ubiquitin from experimental NOE and RDC measurements, achieving more accurate and faster reconstructions compared to the current state of the art. version:5
arxiv-1611-06951 | Enforcing Relational Matching Dependencies with Datalog for Entity Resolution | http://arxiv.org/abs/1611.06951 | id:1611.06951 author:Zeinab Bahmani, Leopoldo Bertossi category:cs.DB cs.AI  published:2016-11-21 summary:Entity resolution (ER) is about identifying and merging records in a database that represent the same real-world entity. Matching dependencies (MDs) have been introduced and investigated as declarative rules that specify ER policies. An ER process induced by MDs over a dirty instance leads to multiple clean instances, in general. General "answer sets programs" have been proposed to specify the MD-based cleaning task and its results. In this work, we extend MDs to "relational MDs", which capture more application semantics, and identify classes of relational MDs for which the general ASP can be automatically rewritten into a stratified Datalog program, with the single clean instance as its standard model. version:2
arxiv-1702-07889 | Contractibility for Open Global Constraints | http://arxiv.org/abs/1702.07889 | id:1702.07889 author:Michael J. Maher category:cs.LO cs.AI  published:2017-02-25 summary:Open forms of global constraints allow the addition of new variables to an argument during the execution of a constraint program. Such forms are needed for difficult constraint programming problems where problem construction and problem solving are interleaved, and fit naturally within constraint logic programming. However, in general, filtering that is sound for a global constraint can be unsound when the constraint is open. This paper provides a simple characterization, called contractibility, of the constraints where filtering remains sound when the constraint is open. With this characterization we can easily determine whether a constraint has this property or not. In the latter case, we can use it to derive a contractible approximation to the constraint. We demonstrate this work on both hard and soft constraints. In the process, we formulate two general classes of soft constraints. version:1
arxiv-1702-08441 | Monte Carlo Action Programming | http://arxiv.org/abs/1702.08441 | id:1702.08441 author:Lenz Belzner category:cs.AI cs.PL  published:2017-02-25 summary:This paper proposes Monte Carlo Action Programming, a programming language framework for autonomous systems that act in large probabilistic state spaces with high branching factors. It comprises formal syntax and semantics of a nondeterministic action programming language. The language is interpreted stochastically via Monte Carlo Tree Search. Effectiveness of the approach is shown empirically. version:1
arxiv-1702-07784 | Measuring #GamerGate: A Tale of Hate, Sexism, and Bullying | http://arxiv.org/abs/1702.07784 | id:1702.07784 author:Despoina Chatzakou, Nicolas Kourtellis, Jeremy Blackburn, Emiliano De Cristofaro, Gianluca Stringhini, Athena Vakali category:cs.SI cs.AI cs.CY  published:2017-02-24 summary:Over the past few years, online aggression and abusive behaviors have occurred in many different forms and on a variety of platforms. In extreme cases, these incidents have evolved into hate, discrimination, and bullying, and even materialized into real-world threats and attacks against individuals or groups. In this paper, we study the Gamergate controversy. Started in August 2014 in the online gaming world, it quickly spread across various social networking platforms, ultimately leading to many incidents of cyberbullying and cyberaggression. We focus on Twitter, presenting a measurement study of a dataset of 340k unique users and 1.6M tweets to study the properties of these users, the content they post, and how they differ from random Twitter users. We find that users involved in this "Twitter war" tend to have more friends and followers, are generally more engaged and post tweets with negative sentiment, less joy, and more hate than random users. We also perform preliminary measurements on how the Twitter suspension mechanism deals with such abusive behaviors. While we focus on Gamergate, our methodology to collect and analyze tweets related to aggressive and bullying activities is of independent interest. version:1
arxiv-1702-07647 | Path Planning for Multiple Heterogeneous Unmanned Vehicles with Uncertain Service Times | http://arxiv.org/abs/1702.07647 | id:1702.07647 author:Kaarthik Sundar, Saravanan Venkatachalam, Satyanarayana G. Manyam category:cs.RO math.OC  published:2017-02-24 summary:This article presents a framework and develops a formulation to solve a path planning problem for multiple heterogeneous Unmanned Vehicles (UVs) with uncertain service times for each vehicle--target pair. The vehicles incur a penalty proportional to the duration of their total service time in excess of a preset constant. The vehicles differ in their motion constraints and are located at distinct depots at the start of the mission. The vehicles may also be equipped with disparate sensors. The objective is to find a tour for each vehicle that starts and ends at its respective depot such that every target is visited and serviced by some vehicle while minimizing the sum of the total travel distance and the expected penalty incurred by all the vehicles. We formulate the problem as a two-stage stochastic program with recourse, present the theoretical properties of the formulation and advantages of using such a formulation, as opposed to a deterministic expected value formulation, to solve the problem. Extensive numerical simulations also corroborate the effectiveness of the proposed approach. version:1
arxiv-1702-07617 | DALiuGE: A Graph Execution Framework for Harnessing the Astronomical Data Deluge | http://arxiv.org/abs/1702.07617 | id:1702.07617 author:Chen Wu, Rodrigo Tobar, Kevin Vinsen, Andreas Wicenec, Dave Pallot, Baoqiang Lao, Ruonan Wang, Tao An, Mark Boulton, Ian Cooper, Richard Dodson, Markus Dolensky, Ying Mei, Feng Wang category:cs.DC physics.ins-det  published:2017-02-24 summary:The Data Activated Liu Graph Engine - DALiuGE - is an execution framework for processing large astronomical datasets at a scale required by the Square Kilometre Array Phase 1 (SKA1). It includes an interface for expressing complex data reduction pipelines consisting of both data sets and algorithmic components and an implementation run-time to execute such pipelines on distributed resources. By mapping the logical view of a pipeline to its physical realisation, DALiuGE separates the concerns of multiple stakeholders, allowing them to collectively optimise large-scale data processing solutions in a coherent manner. The execution in DALiuGE is data-activated, where each individual data item autonomously triggers the processing on itself. Such decentralisation also makes the execution framework very scalable and flexible, supporting pipeline sizes ranging from less than ten tasks running on a laptop to tens of millions of concurrent tasks on the second fastest supercomputer in the world. DALiuGE has been used in production for reducing interferometry data sets from the Karl E. Jansky Very Large Array and the Mingantu Ultrawide Spectral Radioheliograph; and is being developed as the execution framework prototype for the Science Data Processor (SDP) consortium of the Square Kilometre Array (SKA) telescope. This paper presents a technical overview of DALiuGE and discusses case studies from the CHILES and MUSER projects that use DALiuGE to execute production pipelines. In a companion paper, we provide in-depth analysis of DALiuGE's scalability to very large numbers of tasks on two supercomputing facilities. version:1
arxiv-1702-07605 | Compact Self-Stabilizing Leader Election for Arbitrary Networks | http://arxiv.org/abs/1702.07605 | id:1702.07605 author:Lélia Blin, Sébastien Tixeuil category:cs.DC  published:2017-02-24 summary:We present a self-stabilizing leader election algorithm for arbitrary networks, with space-complexity $O(\max\{\log \Delta, \log \log n\})$ bits per node in $n$-node networks with maximum degree~$\Delta$. This space complexity is sub-logarithmic in $n$ as long as $\Delta = n^{o(1)}$. The best space-complexity known so far for arbitrary networks was $O(\log n)$ bits per node, and algorithms with sub-logarithmic space-complexities were known for the ring only. To our knowledge, our algorithm is the first algorithm for self-stabilizing leader election to break the $\Omega(\log n)$ bound for silent algorithms in arbitrary networks. Breaking this bound was obtained via the design of a (non-silent) self-stabilizing algorithm using sophisticated tools such as solving the distance-2 coloring problem in a silent self-stabilizing manner, with space-complexity $O(\max\{\log \Delta, \log \log n\})$ bits per node. Solving this latter coloring problem allows us to implement a sub-logarithmic encoding of spanning trees --- storing the IDs of the neighbors requires $\Omega(\log n)$ bits per node, while we encode spanning trees using $O(\max\{\log \Delta, \log \log n\})$ bits per node. Moreover, we show how to construct such compactly encoded spanning trees without relying on variables encoding distances or number of nodes, as these two types of variables would also require $\Omega(\log n)$ bits per node. version:1
arxiv-1703-00374 | Resource Management in Cloud Computing: Classification and Taxonomy | http://arxiv.org/abs/1703.00374 | id:1703.00374 author:Swapnil M Parikh, Narendra M Patel, Harshadkumar B Prajapati category:cs.DC  published:2017-02-24 summary:Cloud Computing is a new era of remote computing / Internet based computing where one can access their personal resources easily from any computer through Internet. Cloud delivers computing as a utility as it is available to the cloud consumers on demand. It is a simple pay-per-use consumer-provider service model. It contains large number of shared resources. So Resource Management is always a major issue in cloud computing like any other computing paradigm. Due to the availability of finite resources it is very challenging for cloud providers to provide all the requested resources. From the cloud providers perspective cloud resources must be allocated in a fair and efficient manner. Research Survey is not available from the perspective of resource management as a process in cloud computing. So this research paper provides a detailed sequential view / steps on resource management in cloud computing. Firstly this research paper classifies various resources in cloud computing. It also gives taxonomy on resource management in cloud computing through which one can do further research. Lastly comparisons on various resource management algorithms has been presented. version:1
arxiv-1702-07514 | Medical Image Retrieval Based On the Parallelization of the Cluster Sampling Algorithm | http://arxiv.org/abs/1702.07514 | id:1702.07514 author:Hesham Arafat Ali, Salah Attiya, Ibrahim El-henawy category:cs.DC  published:2017-02-24 summary:In this paper we develop parallel cluster sampling algorithms and show that a multi-chain version is embarrassingly parallel and can be used efficiently for medical image retrieval among other applications. version:1
arxiv-1608-00139 | A Linear Algebraic Approach to Datalog Evaluation | http://arxiv.org/abs/1608.00139 | id:1608.00139 author:Taisuke Sato category:cs.AI  published:2016-07-30 summary:In this paper, we propose a fundamentally new approach to Datalog evaluation. Given a linear Datalog program DB written using N constants and binary predicates, we first translate if-and-only-if completions of clauses in DB into a set Eq(DB) of matrix equations with a non-linear operation where relations in M_DB, the least Herbrand model of DB, are encoded as adjacency matrices. We then translate Eq(DB) into another, but purely linear matrix equations tilde_Eq(DB). It is proved that the least solution of tilde_Eq(DB) in the sense of matrix ordering is converted to the least solution of Eq(DB) and the latter gives M_DB as a set of adjacency matrices. Hence computing the least solution of tilde_Eq(DB) is equivalent to computing M_DB specified by DB. For a class of tail recursive programs and for some other types of programs, our approach achieves O(N^3) time complexity irrespective of the number of variables in a clause since only matrix operations costing O(N^3) or less are used. We conducted two experiments that compute the least Herbrand models of linear Datalog programs. The first experiment computes transitive closure of artificial data and real network data taken from the Koblenz Network Collection. The second one compared the proposed approach with the state-of-the-art symbolic systems including two Prolog systems and two ASP systems, in terms of computation time for a transitive closure program and the same generation program. In the experiment, it is observed that our linear algebraic approach runs 10^1 ~ 10^4 times faster than the symbolic systems when data is not sparse. To appear in Theory and Practice of Logic Programming (TPLP). version:2
arxiv-1609-03103 | Uncertainty in Monotone Co-Design Problems | http://arxiv.org/abs/1609.03103 | id:1609.03103 author:Andrea Censi category:cs.RO  published:2016-09-11 summary:This work contributes to a compositional theory of "co-design" that allows to optimally design a robotic platform. In this framework, the user describes each subsystem as a monotone relation between "functionality" provided and "resources" required. These models can be easily composed to express the co-design constraints among different subsystems. The user then queries the model, to obtain the design with minimal resources usage, subject to a lower bound on the provided functionality. This paper concerns the introduction of uncertainty in the framework. Uncertainty has two roles: first, it allows to deal with limited knowledge of the models; second, it also can be used to generate consistent relaxations of a problem, as the computation requirements can be lowered, should the user accept some uncertainty in the answer. version:2
arxiv-1702-07431 | A Debt-Aware Learning Approach for Resource Adaptations in Cloud Elasticity Management | http://arxiv.org/abs/1702.07431 | id:1702.07431 author:Carlos Mera-Gómez, Francisco Ramírez, Rami Bahsoon, Rajkumar Buyya category:cs.SE cs.DC  published:2017-02-24 summary:Elasticity is a cloud property that enables applications and its execution systems to dynamically acquire and release shared computational resources on demand. Moreover, it unfolds the advantage of economies of scale in the cloud through a drop in the average costs of these shared resources. However, it is still an open challenge to achieve a perfect match between resource demand and provision in autonomous elasticity management. Resource adaptation decisions essentially involve a trade-off between economics and performance, which produces a gap between the ideal and actual resource provisioning. This gap, if not properly managed, can negatively impact the aggregate utility of a cloud customer in the long run. To address this limitation, we propose a technical debt-aware learning approach for autonomous elasticity management based on a reinforcement learning of elasticity debts in resource provisioning; the adaptation pursues strategic decisions that trades off economics against performance. We extend CloudSim and Burlap to evaluate our approach. The evaluation shows that a reinforcement learning of technical debts in elasticity obtains a higher utility for a cloud customer, while conforming expected levels of performance. version:1
arxiv-1702-07425 | Streaming supercomputing needs workflow-enabled programming-in-the-large | http://arxiv.org/abs/1702.07425 | id:1702.07425 author:Justin M Wozniak, Jonathan Ozik, Daniel S. Katz, Michael Wilde category:cs.DC  published:2017-02-24 summary:This is a position paper, submitted to the Future Online Analysis Platform Workshop (https://press3.mcs.anl.gov/futureplatform/), which argues that simple data analysis applications are common today, but future online supercomputing workloads will need to couple multiple advanced technologies (streams, caches, analysis, and simulations) to rapidly deliver scientific results. Each of these technologies are active research areas when integrated with high-performance computing. These components will interact in complex ways, therefore coupling them needs to be programmed. Programming in the large, on top of existing applications, enables us to build much more capable applications and to productively manage this complexity. version:1
arxiv-1607-06886 | Real-Time Stochastic Kinodynamic Motion Planning via Multiobjective Search on GPUs | http://arxiv.org/abs/1607.06886 | id:1607.06886 author:Brian Ichter, Edward Schmerling, Ali-akbar Agha-mohammadi, Marco Pavone category:cs.RO  published:2016-07-23 summary:In this paper we present the PUMP (Parallel Uncertainty-aware Multiobjective Planning) algorithm for addressing the stochastic kinodynamic motion planning problem, whereby one seeks a low-cost, dynamically-feasible motion plan subject to a constraint on collision probability (CP). To ensure exhaustive evaluation of candidate motion plans (as needed to tradeoff the competing objectives of performance and safety), PUMP incrementally builds the Pareto front of the problem, accounting for the optimization objective and an approximation of CP. This is performed by a massively parallel multiobjective search, here implemented with a focus on GPUs. Upon termination of the exploration phase, PUMP searches the Pareto set of motion plans to identify the lowest cost solution that is certified to satisfy the CP constraint (according to an asymptotically exact estimator). We introduce a novel particle-based CP approximation scheme, designed for efficient GPU implementation, which accounts for dependencies over the history of a trajectory execution. We present numerical experiments for quadrotor planning wherein PUMP identifies solutions in ~100 ms, evaluating over one hundred thousand partial plans through the course of its exploration phase. The results show that this multiobjective search achieves a lower motion plan cost, for the same CP constraint, compared to a safety buffer-based search heuristic and repeated RRT trials. version:3
arxiv-1702-07403 | Making Asynchronous Distributed Computations Robust to Noise | http://arxiv.org/abs/1702.07403 | id:1702.07403 author:Keren Censor-Hillel, Ran Gelles, Bernhard Haeupler category:cs.DS cs.DC  published:2017-02-23 summary:We consider the problem of making distributed computations robust to noise, in particular to worst-case (adversarial) corruptions of messages. We give a general distributed interactive coding scheme which simulates any asynchronous distributed protocol while tolerating an optimal corruption of a $\Theta(1/n)$ fraction of all messages while incurring a moderate blowup of $O(n\log^2 n)$ in the communication complexity. Our result is the first fully distributed interactive coding scheme in which the topology of the communication network is not known in advance. Prior work required either a coordinating node to be connected to all other nodes in the network or assumed a synchronous network in which all nodes already know the complete topology of the network. version:1
arxiv-1702-07393 | Controlling Parent Systems Through Swarms Using Abstraction | http://arxiv.org/abs/1702.07393 | id:1702.07393 author:Kyle L Crandall, Adam M Wickenheiser category:cs.RO  published:2017-02-23 summary:This study considers the control of parent-child systems where a parent system is acted on by a set of child systems with their own inputs. Examples of such systems include a swarm of robots pushing an object over a surface, a swarm of aerial vehicles carrying a large load, or a set of end effectors manipulating an object. In this paper, a general framework for decoupling the swarm from the parent system through a low-dimensional abstract state space is presented. The requirements of this framework are presented along with how constraints on both systems propagate through the abstract state and impact the requirements of the controllers for both systems. Several controllers with hard state constraints are designed to track a desired angle of the tilting plane with a swarm of robots driving on top. Both homogeneous and heterogeneous swarms of varying sizes and properties are considered. The controllers are shown to be locally asymptotically stable and are demonstrated in simulation. version:1
arxiv-1702-07311 | ERA: A Framework for Economic Resource Allocation for the Cloud | http://arxiv.org/abs/1702.07311 | id:1702.07311 author:Moshe Babaioff, Yishay Mansour, Noam Nisan, Gali Noti, Carlo Curino, Nar Ganapathy, Ishai Menache, Omer Reingold, Moshe Tennenholtz, Erez Timnat category:cs.GT cs.DC  published:2017-02-23 summary:Cloud computing has reached significant maturity from a systems perspective, but currently deployed solutions rely on rather basic economics mechanisms that yield suboptimal allocation of the costly hardware resources. In this paper we present Economic Resource Allocation (ERA), a complete framework for scheduling and pricing cloud resources, aimed at increasing the efficiency of cloud resources usage by allocating resources according to economic principles. The ERA architecture carefully abstracts the underlying cloud infrastructure, enabling the development of scheduling and pricing algorithms independently of the concrete lower-level cloud infrastructure and independently of its concerns. Specifically, ERA is designed as a flexible layer that can sit on top of any cloud system and interfaces with both the cloud resource manager and with the users who reserve resources to run their jobs. The jobs are scheduled based on prices that are dynamically calculated according to the predicted demand. Additionally, ERA provides a key internal API to pluggable algorithmic modules that include scheduling, pricing and demand prediction. We provide a proof-of-concept software and demonstrate the effectiveness of the architecture by testing ERA over both public and private cloud systems -- Azure Batch of Microsoft and Hadoop/YARN. A broader intent of our work is to foster collaborations between economics and system communities. To that end, we have developed a simulation platform via which economics and system experts can test their algorithmic implementations. version:1
arxiv-1701-03836 | Formal Analysis of SEU Mitigation for Early Dependability and Performability Analysis of FPGA-based Space Applications | http://arxiv.org/abs/1701.03836 | id:1701.03836 author:Khaza Anuarul Hoque, Otmane Ait Mohamed, Yvon Savaria category:cs.PF cs.AR cs.LO  published:2017-01-12 summary:SRAM-based FPGAs are increasingly popular in the aerospace industry due to their field programmability and low cost. However, they suffer from cosmic radiation induced Single Event Upsets (SEUs). In safety-critical applications, the dependability of the design is a prime concern since failures may have catastrophic consequences. An early analysis of the relationship between dependability metrics, performability-area trade-off, and different mitigation techniques for such applications can reduce the design effort while increasing the design confidence. This paper introduces a novel methodology based on probabilistic model checking, for the analysis of the reliability, availability, safety and performance-area tradeoffs of safety-critical systems for early design decisions. Starting from the high-level description of a system, a Markov reward model is constructed from the Control Data Flow Graph (CDFG) and a component characterization library targeting FPGAs. The proposed model and exhaustive analysis capture all the failure states (based on the fault detection coverage) and repairs possible in the system. We present quantitative results based on an FIR filter circuit to illustrate the applicability of the proposed approach and to demonstrate that a wide range of useful dependability and performability properties can be analyzed using the proposed methodology. The modeling results show the relationship between different mitigation techniques and fault detection coverage, exposing their direct impact on the design for early decisions. version:2
arxiv-1702-07297 | How to Optimally Allocate Resources for Coded Distributed Computing? | http://arxiv.org/abs/1702.07297 | id:1702.07297 author:Qian Yu, Songze Li, Mohammad Ali Maddah-Ali, A. Salman Avestimehr category:cs.IT cs.DC math.IT  published:2017-02-23 summary:Today's data centers have an abundance of computing resources, hosting server clusters consisting of as many as tens or hundreds of thousands of machines. To execute a complex computing task over a data center, it is natural to distribute computations across many nodes to take advantage of parallel processing. However, as we allocate more and more computing resources to a computation task and further distribute the computations, large amounts of (partially) computed data must be moved between consecutive stages of computation tasks among the nodes, hence the communication load can become the bottleneck. In this paper, we study the optimal allocation of computing resources in distributed computing, in order to minimize the total execution time in distributed computing accounting for both the duration of computation and communication phases. In particular, we consider a general MapReduce-type distributed computing framework, in which the computation is decomposed into three stages: \emph{Map}, \emph{Shuffle}, and \emph{Reduce}. We focus on a recently proposed \emph{Coded Distributed Computing} approach for MapReduce and study the optimal allocation of computing resources in this framework. For all values of problem parameters, we characterize the optimal number of servers that should be used for distributed processing, provide the optimal placements of the Map and Reduce tasks, and propose an optimal coded data shuffling scheme, in order to minimize the total execution time. To prove the optimality of the proposed scheme, we first derive a matching information-theoretic converse on the execution time, then we prove that among all possible resource allocation schemes that achieve the minimum execution time, our proposed scheme uses the exactly minimum possible number of servers. version:1
arxiv-1612-00291 | Aggressive Quadrotor Flight through Narrow Gaps with Onboard Sensing and Computing using Active Vision | http://arxiv.org/abs/1612.00291 | id:1612.00291 author:Davide Falanga, Elias Mueggler, Matthias Faessler, Davide Scaramuzza category:cs.RO  published:2016-12-01 summary:We address one of the main challenges towards autonomous quadrotor flight in complex environments, which is flight through narrow gaps. While previous works relied on off-board localization systems or on accurate prior knowledge of the gap position and orientation, we rely solely on onboard sensing and computing and estimate the full state by fusing gap detection from a single onboard camera with an IMU. This problem is challenging for two reasons: (i) the quadrotor pose uncertainty with respect to the gap increases quadratically with the distance from the gap; (ii) the quadrotor has to actively control its orientation towards the gap to enable state estimation (i.e., active vision). We solve this problem by generating a trajectory that considers geometric, dynamic, and perception constraints: during the approach maneuver, the quadrotor always faces the gap to allow state estimation, while respecting the vehicle dynamics; during the traverse through the gap, the distance of the quadrotor to the edges of the gap is maximized. Furthermore, we replan the trajectory during its execution to cope with the varying uncertainty of the state estimate. We successfully evaluate and demonstrate the proposed approach in many real experiments. To the best of our knowledge, this is the first work that addresses and achieves autonomous, aggressive flight through narrow gaps using only onboard sensing and computing and without prior knowledge of the pose of the gap. version:4
arxiv-1511-00457 | Structure theory of flip graphs with applications to Weak Symmetry Breaking | http://arxiv.org/abs/1511.00457 | id:1511.00457 author:Dmitry N. Kozlov category:cs.DC math.CO 68Q85  05C70  published:2015-11-02 summary:This paper is devoted to advancing the theoretical understanding of the iterated immediate snapshot (IIS) complexity of the Weak Symmetry Breaking task (WSB). Our rather unexpected main theorem states that there exist infinitely many values of n, such that WSB for n~processes is solvable by a certain explicitly constructed 3-round IIS protocol. In particular, the minimal number of rounds, which an IIS protocol needs in order to solve the WSB task, does not go to infinity, when the number of processes goes to infinity. Our methods can also be used to generate such values of n. We phrase our proofs in combinatorial language, while avoiding using topology. To this end, we study a~certain class of graphs, which we call flip graphs. These graphs encode adjacency structure in certain subcomplexes of iterated standard chromatic subdivisions of a simplex. While keeping the geometric background in mind for an additional intuition, we develop the structure theory of matchings in flip graphs in a purely combinatorial way. Our bound for the IIS complexity is then a corollary of this general theory. As an afterthought of our result, we suggest to change the overall paradigm. Specifically, we think, that the bounds on the IIS complexity of solving WSB for n processes should be formulated in terms of the size of the solutions of the associated Diophantine equation, rather than in terms of the value n itself. version:5
arxiv-1702-07195 | First Experiences Optimizing Smith-Waterman on Intel's Knights Landing Processor | http://arxiv.org/abs/1702.07195 | id:1702.07195 author:Enzo Rucci, Carlos Garcia, Guillermo Botella, Armando De Giusti, Marcelo Naiouf, Manuel Prieto-Matias category:cs.DC cs.PF  published:2017-02-23 summary:The well-known Smith-Waterman (SW) algorithm is the most commonly used method for local sequence alignments. However, SW is very computationally demanding for large protein databases. There exist several implementations that take advantage of computing parallelization on many-cores, FPGAs or GPUs, in order to increase the alignment throughtput. In this paper, we have explored SW acceleration on Intel KNL processor. The novelty of this architecture requires the revision of previous programming and optimization techniques on many-core architectures. To the best of authors knowledge, this is the first KNL architecture assessment for SW algorithm. Our evaluation, using the renowned Environmental NR database as benchmark, has shown that multi-threading and SIMD exploitation reports competitive performance (351 GCUPS) in comparison with other implementations. version:1
arxiv-1702-07193 | Ontologies in System Engineering: a Field Report | http://arxiv.org/abs/1702.07193 | id:1702.07193 author:Marco Menapace, Armando Tacchella category:cs.AI cs.SE I.2.4  published:2017-02-23 summary:In recent years ontologies enjoyed a growing popularity outside specialized AI communities. System engineering is no exception to this trend, with ontologies being proposed as a basis for several tasks in complex industrial implements, including system design, monitoring and diagnosis. In this paper, we consider four different contributions to system engineering wherein ontologies are instrumental to provide enhancements over traditional ad-hoc techniques. For each application, we briefly report the methodologies, the tools and the results obtained with the goal to provide an assessment of merits and limits of ontologies in such domains. version:1
arxiv-1702-07168 | A DIKW Paradigm to Cognitive Engineering | http://arxiv.org/abs/1702.07168 | id:1702.07168 author:Amit Kumar Mishra category:cs.AI  published:2017-02-23 summary:Though the word cognitive has a wide range of meanings we define cognitive engineering as learning from brain to bolster engineering solutions. However, giving an achievable framework to the process towards this has been a difficult task. In this work we take the classic data information knowledge wisdom (DIKW) framework to set some achievable goals and sub-goals towards cognitive engineering. A layered framework like DIKW aligns nicely with the layered structure of pre-frontal cortex. And breaking the task into sub-tasks based on the layers also makes it easier to start developmental endeavours towards achieving the final goal of a brain-inspired system. version:1
arxiv-1702-06915 | Solving DCOPs with Distributed Large Neighborhood Search | http://arxiv.org/abs/1702.06915 | id:1702.06915 author:Ferdinando Fioretto, Agostino Dovier, Enrico Pontelli, William Yeoh, Roie Zivan category:cs.AI  published:2017-02-22 summary:The field of Distributed Constraint Optimization has gained momentum in recent years, thanks to its ability to address various applications related to multi-agent cooperation. Nevertheless, solving Distributed Constraint Optimization Problems (DCOPs) optimally is NP-hard. Therefore, in large-scale, complex applications, incomplete DCOP algorithms are necessary. Current incomplete DCOP algorithms suffer of one or more of the following limitations: they (a) find local minima without providing quality guarantees; (b) provide loose quality assessment; or (c) are unable to benefit from the structure of the problem, such as domain-dependent knowledge and hard constraints. Therefore, capitalizing on strategies from the centralized constraint solving community, we propose a Distributed Large Neighborhood Search (D-LNS) framework to solve DCOPs. The proposed framework (with its novel repair phase) provides guarantees on solution quality, refining upper and lower bounds during the iterative process, and can exploit domain-dependent structures. Our experimental results show that D-LNS outperforms other incomplete DCOP algorithms on both structured and unstructured problem instances. version:2
arxiv-1702-07031 | Proactive Resource Management in LTE-U Systems: A Deep Learning Perspective | http://arxiv.org/abs/1702.07031 | id:1702.07031 author:Ursula Challita, Li Dong, Walid Saad category:cs.IT cs.AI cs.GT math.IT  published:2017-02-22 summary:LTE in unlicensed spectrum (LTE-U) is a promising approach to overcome the wireless spectrum scarcity. However, to reap the benefits of LTE-U, a fair coexistence mechanism with other incumbent WiFi deployments is required. In this paper, a novel deep learning approach is proposed for modeling the resource allocation problem of LTE-U small base stations (SBSs). The proposed approach enables multiple SBSs to proactively perform dynamic channel selection, carrier aggregation, and fractional spectrum access while guaranteeing fairness with existing WiFi networks and other LTE-U operators. Adopting a proactive coexistence mechanism enables future delay-intolerant LTE-U data demands to be served within a given prediction window ahead of their actual arrival time thus avoiding the underutilization of the unlicensed spectrum during off-peak hours while maximizing the total served LTE-U traffic load. To this end, a noncooperative game model is formulated in which SBSs are modeled as Homo Egualis agents that aim at predicting a sequence of future actions and thus achieving long-term equal weighted fairness with WLAN and other LTE-U operators over a given time horizon. The proposed deep learning algorithm is then shown to reach a mixed-strategy Nash equilibrium (NE), when it converges. Simulation results using real data traces show that the proposed scheme can yield up to 28% and 11% gains over a conventional reactive approach and a proportional fair coexistence mechanism, respectively. The results also show that the proposed framework prevents WiFi performance degradation for a densely deployed LTE-U network. version:1
arxiv-1702-07001 | Theoretical and Experimental Analysis of the Canadian Traveler Problem | http://arxiv.org/abs/1702.07001 | id:1702.07001 author:Doron Zarchy category:cs.AI  published:2017-02-22 summary:Devising an optimal strategy for navigation in a partially observable environment is one of the key objectives in AI. One of the problem in this context is the Canadian Traveler Problem (CTP). CTP is a navigation problem where an agent is tasked to travel from source to target in a partially observable weighted graph, whose edge might be blocked with a certain probability and observing such blockage occurs only when reaching upon one of the edges end points. The goal is to find a strategy that minimizes the expected travel cost. The problem is known to be P$\#$ hard. In this work we study the CTP theoretically and empirically. First, we study the Dep-CTP, a CTP variant we introduce which assumes dependencies between the edges status. We show that Dep-CTP is intractable, and further we analyze two of its subclasses on disjoint paths graph. Second, we develop a general algorithm Gen-PAO that optimally solve the CTP. Gen-PAO is capable of solving two other types of CTP called Sensing-CTP and Expensive-Edges CTP. Since the CTP is intractable, Gen-PAO use some pruning methods to reduce the space search for the optimal solution. We also define some variants of Gen-PAO, compare their performance and show some benefits of Gen-PAO over existing work. version:1
arxiv-1604-04315 | Moving Beyond the Turing Test with the Allen AI Science Challenge | http://arxiv.org/abs/1604.04315 | id:1604.04315 author:Carissa Schoenick, Peter Clark, Oyvind Tafjord, Peter Turney, Oren Etzioni category:cs.AI  published:2016-04-14 summary:Given recent successes in AI (e.g., AlphaGo's victory against Lee Sedol in the game of GO), it's become increasingly important to assess: how close are AI systems to human-level intelligence? This paper describes the Allen AI Science Challenge---an approach towards that goal which led to a unique Kaggle Competition, its results, the lessons learned, and our next steps. version:3
arxiv-1702-06970 | A Realistic Dataset for the Smart Home Device Scheduling Problem for DCOPs | http://arxiv.org/abs/1702.06970 | id:1702.06970 author:William Kluegel, Muhammad Aamir Iqbal, Ferdinando Fioretto, William Yeoh, Enrico Pontelli category:cs.AI cs.DC  published:2017-02-22 summary:The field of Distributed Constraint Optimization has gained momentum in recent years thanks to its ability to address various applications related to multi-agent cooperation. While techniques to solve Distributed Constraint Optimization Problems (DCOPs) are abundant and have matured substantially since the field inception, the number of DCOP realistic applications and benchmark used to asses the performance of DCOP algorithms is lagging behind. To contrast this background we (i) introduce the Smart Home Device Scheduling (SHDS) problem, which describe the problem of coordinating smart devices schedules across multiple homes as a multi-agent system, (ii) detail the physical models adopted to simulate smart sensors, smart actuators, and homes environments, and (iii) introduce a DCOP realistic benchmark for SHDS problems. version:1
arxiv-1702-06934 | Realization of Ontology Web Search Engine | http://arxiv.org/abs/1702.06934 | id:1702.06934 author:Olegs Verhodubs category:cs.AI cs.IR  published:2017-02-22 summary:This paper describes the realization of the Ontology Web Search Engine. The Ontology Web Search Engine is realizable as independent project and as a part of other projects. The main purpose of this paper is to present the Ontology Web Search Engine realization details as the part of the Semantic Web Expert System and to present the results of the Ontology Web Search Engine functioning. It is expected that the Semantic Web Expert System will be able to process ontologies from the Web, generate rules from these ontologies and develop its knowledge base. version:1
arxiv-1702-06900 | Periodic I/O scheduling for super-computers | http://arxiv.org/abs/1702.06900 | id:1702.06900 author:Guillaume Aupy, Ana Gainaru, Valentin Le Fèvre category:cs.DC  published:2017-02-22 summary:With the ever-growing need of data in HPC applications, the congestion at the I/O level becomes critical in super-computers. Architectural enhancement such as burst-buffers and pre-fetching are added to machines, but are not sufficient to prevent congestion. Recent online I/O scheduling strategies have been put in place, but they add an additional congestion point and overheads in the computation of applications. In this work, we show how to take advantage of the periodic nature of HPC applications in order to develop efficient periodic scheduling strategies for their I/O transfers. Our strategy computes once during the job scheduling phase a pattern where it defines the I/O behavior for each application, after which the applications run independently, transferring their I/O at the specified times. Our strategy limits the amount of I/O congestion at the I/O node level and can be easily integrated into current job schedulers. We validate this model through extensive simulations and experiments by comparing it to state-of-the-art online solutions, showing that not only our scheduler has the advantage of being de-centralized and thus overcoming the overhead of online schedulers, but also that it performs better than these solutions, improving the application dilation up to 13% and the maximum system efficiency up to 18%. version:1
arxiv-1702-06898 | Enhancing speed and scalability of the ParFlow simulation code | http://arxiv.org/abs/1702.06898 | id:1702.06898 author:Carsten Burstedde, Jose A. Fonseca, Stefan Kollet category:cs.MS cs.DC physics.flu-dyn  published:2017-02-22 summary:Regional hydrology studies are often supported by high resolution simulations of subsurface flow that require expensive and extensive computations. Efficient usage of the latest high performance parallel computing systems becomes a necessity. The simulation software ParFlow has been demonstrated to meet this requirement and shown to have excellent solver scalability for up to 16,384 processes. In the present work we show that the code requires further enhancements in order to fully take advantage of current petascale machines. We identify ParFlow's way of parallelization of the computational mesh as a central bottleneck. We propose to reorganize this subsystem using fast mesh partition algorithms provided by the parallel adaptive mesh refinement library p4est. We realize this in a minimally invasive manner by modifying selected parts of the code to reinterpret the existing mesh data structures. We evaluate the scaling performance of the modified version of ParFlow, demonstrating good weak and strong scaling up to 458k cores of the Juqueen supercomputer, and test an example application at large scale. version:1
arxiv-1602-04667 | Rapid Asynchronous Plurality Consensus | http://arxiv.org/abs/1602.04667 | id:1602.04667 author:Robert Elsässer, Tom Friedetzky, Dominik Kaaser, Frederik Mallmann-Trenn, Horst Trinker category:cs.DC cs.DS  published:2016-02-15 summary:We consider distributed plurality consensus in a complete graph of size $n$ with $k$ initial opinions. We design an efficient and simple protocol in the asynchronous communication model that ensures that all nodes eventually agree on the initially most frequent opinion. In this model, each node is equipped with a random Poisson clock with parameter $\lambda=1$. Whenever a node's clock ticks, it samples some neighbors, uniformly at random and with replacement, and adjusts its opinion according to the sample. A prominent example is the so-called two-choices algorithm in the synchronous model, where in each round, every node chooses two neighbors uniformly at random, and if the two sampled opinions coincide, then that opinion is adopted. This protocol is very efficient and well-studied when $k=2$. If $k=O(n^\varepsilon)$ for some small $\varepsilon$, we show that it converges to the initial plurality opinion within $O(k \cdot \log{n})$ rounds, w.h.p., as long as the initial difference between the largest and second largest opinion is $\Omega(\sqrt{n \log n})$. On the other side, we show that there are cases in which $\Omega(k)$ rounds are needed, w.h.p. One can beat this lower bound in the synchronous model by combining the two-choices protocol with randomized broadcasting. Our main contribution is a non-trivial adaptation of this approach to the asynchronous model. If the support of the most frequent opinion is at least $(1+\varepsilon)$ times that of the second-most frequent one and $k=O(\exp(\log{n}/\log \log{n}))$, then our protocol achieves the best possible run time of $O(\log n)$, w.h.p. We relax full synchronicity by allowing $o(n)$ nodes to be poorly synchronized, and the well synchronized nodes are only required to be within a certain time difference from one another. We enforce this synchronicity by introducing a novel gadget into the protocol. version:5
arxiv-1702-06865 | Platform independent profiling of a QCD code | http://arxiv.org/abs/1702.06865 | id:1702.06865 author:Marina Krstic Marinkovic, Luka Stanisic category:hep-lat cs.DC physics.comp-ph  published:2017-02-22 summary:The supercomputing platforms available for high performance computing based research evolve at a great rate. However, this rapid development of novel technologies requires constant adaptations and optimizations of the existing codes for each new machine architecture. In such context, minimizing time of efficiently porting the code on a new platform is of crucial importance. A possible solution for this common challenge is to use simulations of the application that can assist in detecting performance bottlenecks. Due to prohibitive costs of classical cycle-accurate simulators, coarse-grain simulations are more suitable for large parallel and distributed systems. We present a procedure of implementing the profiling for openQCD code [1] through simulation, which will enable the global reduction of the cost of profiling and optimizing this code commonly used in the lattice QCD community. Our approach is based on well-known SimGrid simulator [2], which allows for fast and accurate performance predictions of HPC codes. Additionally, accurate estimations of the program behavior on some future machines, not yet accessible to us, are anticipated. version:1
arxiv-1606-01588 | HopsFS: Scaling Hierarchical File System Metadata Using NewSQL Databases | http://arxiv.org/abs/1606.01588 | id:1606.01588 author:Salman Niazi, Mahmoud Ismail, Steffen Grohsschmiedt, Mikael Ronström, Seif Haridi, Jim Dowling category:cs.DC  published:2016-06-06 summary:Recent improvements in both the performance and scalability of shared-nothing, transactional, in-memory NewSQL databases have reopened the research question of whether distributed metadata for hierarchical file systems can be managed using commodity databases. In this paper, we introduce HopsFS, a next generation distribution of the Hadoop Distributed File System (HDFS) that replaces HDFS' single node in-memory metadata service, with a distributed metadata service built on a NewSQL database. By removing the metadata bottleneck, HopsFS enables an order of magnitude larger and higher throughput clusters compared to HDFS. Metadata capacity has been increased to at least 37 times HDFS' capacity, and in experiments based on a workload trace from Spotify, we show that HopsFS supports 16 to 37 times the throughput of Apache HDFS. HopsFS also has lower latency for many concurrent clients, and no downtime during failover. Finally, as metadata is now stored in a commodity database, it can be safely extended and easily exported to external systems for online analysis and free-text search. version:2
arxiv-1702-03400 | Gathering Anonymous, Oblivious Robots on a Grid | http://arxiv.org/abs/1702.03400 | id:1702.03400 author:Matthias Fischer, Daniel Jung, Friedhelm Meyer auf der Heide category:cs.DC cs.MA cs.RO  published:2017-02-11 summary:We consider a swarm of $n$ autonomous mobile robots, distributed on a 2-dimensional grid. A basic task for such a swarm is the gathering process: all robots have to gather at one (not predefined) place. The work in this paper is motivated by the following insight: On one side, for swarms of robots distributed in the 2-dimensional Euclidean space, several gathering algorithms are known for extremely simple robots that are oblivious, have bounded viewing radius, no compass, and no "flags" to communicate a status to others. On the other side, in case of the 2-dimensional grid, the only known gathering algorithms for robots with bounded viewing radius without compass, need to memorize a constant number of rounds and need flags. In this paper we contribute the, to the best of our knowledge, first gathering algorithm on the grid, which works for anonymous, oblivious robots with bounded viewing range, without any further means of communication and without any memory. We prove its correctness and an $O(n^2)$ time bound. This time bound matches those of the best known algorithms for the Euclidean plane mentioned above. version:2
arxiv-1702-06756 | Risk-based Triggering of Bio-inspired Self-Preservation to Protect Robots from Threats | http://arxiv.org/abs/1702.06756 | id:1702.06756 author:Sing-Kai Chiu, Dejanira Araiza-Illan, Kerstin Eder category:cs.RO  published:2017-02-22 summary:Safety in autonomous systems has been mostly studied from a human-centered perspective. Besides the loads they may carry, autonomous systems are also valuable property, and self-preservation mechanisms are needed to protect them in the presence of external threats, including malicious robots and antagonistic humans. We present a biologically inspired risk-based triggering mechanism to initiate self-preservation strategies. This mechanism considers environmental and internal system factors to measure the overall risk at any moment in time, to decide whether behaviours such as fleeing or hiding are necessary, or whether the system should continue on its task. We integrated our risk-based triggering mechanism into a delivery rover that is being attacked by a drone and evaluated its effectiveness through systematic testing in a simulated environment in Robot Operating System (ROS) and Gazebo, with a variety of different randomly generated conditions. We compared the use of the triggering mechanism and different configurations of self-preservation behaviours to not having any of these. Our results show that triggering self-preservation increases the distance between the drone and the rover for many of these configurations, and, in some instances, the drone does not catch up with the rover. Our study demonstrates the benefits of embedding risk awareness and self-preservation into autonomous systems to increase their robustness, and the value of using bio-inspired engineering to find solutions in this area. version:1
arxiv-1702-07748 | A Methodology for Oracle Selection of Monitors and Knobs for Configuring an HPC System running a Flood Management Application | http://arxiv.org/abs/1702.07748 | id:1702.07748 author:Panagiota Nikolaou, Yiannakis Sazeides, Antoni Portero, Radim Vavrik, Vit Vondrak category:cs.DC  published:2017-02-22 summary:This paper defines a methodology for the oracle selection of the monitors and knobs to use to configure an HPC system running a scientific application while satisfying the application's requirements and not violating any system constraints. This methodology relies on a heuristic correlation analysis between requirements, monitors and knobs to determine the minimum subset of monitors to observe and knobs to explore, to determine the optimal system configuration for the HPC application. At the end of this analysis, we reduce an 11-dimensional space to a 3-dimensional space for monitors and a 6-dimensional space to a 3-dimensional space for knobs. This reduction shows the potential and highlights the need for a realistic methodology to help identify such minimum set of monitors and knobs. version:1
arxiv-1702-03068 | (Leader/Randomization/Signature)-free Byzantine Consensus for Consortium Blockchains | http://arxiv.org/abs/1702.03068 | id:1702.03068 author:Tyler Crain, Vincent Gramoli, Mikel Larrea, Michel Raynal category:cs.DC cs.CR  published:2017-02-10 summary:This paper presents a new resilience optimal Byzantine consensus algorithm targeting consortium blockchains. To this end, it first revisits the consensus validity property by requiring that the decided value satisfies a predefined predicate, which does not systematically exclude a value proposed only by Byzantine processes, thereby generalizing the validity properties found in the literature. Then the paper presents a simple and modular Byzantine consensus algorithm that relies neither on a leader, nor on signatures, nor on randomization. It consists of a reduction of multivalued Byzantine consensus to binary Byzantine consensus satisfying this validity property. This reduction terminates after a constant-sized sequence of binary Byzantine consensus instances. The idea is to spawn concurrent instances of binary consensus but to decide only after a sequence of two of these instances. The binary consensus instances result in a bitmask that the reduction applies to a vector of multivalued proposals to filter out a valid proposed value that is decided. The paper then presents an underlying binary Byzantine consensus algorithm that assumes eventual synchrony to terminate. version:2
arxiv-1702-06680 | Convergence and Consistency Analysis for A 3D Invariant-EKF SLAM | http://arxiv.org/abs/1702.06680 | id:1702.06680 author:Teng Zhang, Kanzhi Wu, Jingwei Song, Shoudong Huang, Gamini Dissanayake category:cs.RO  published:2017-02-22 summary:In this paper, we investigate the convergence and consistency properties of an Invariant-Extended Kalman Filter (RI-EKF) based Simultaneous Localization and Mapping (SLAM) algorithm. Basic convergence properties of this algorithm are proven. These proofs do not require the restrictive assumption that the Jacobians of the motion and observation models need to be evaluated at the ground truth. It is also shown that the output of RI-EKF is invariant under any stochastic rigid body transformation in contrast to $\mathbb{SO}(3)$ based EKF SLAM algorithm ($\mathbb{SO}(3)$-EKF) that is only invariant under deterministic rigid body transformation. Implications of these invariance properties on the consistency of the estimator are also discussed. Monte Carlo simulation results demonstrate that RI-EKF outperforms $\mathbb{SO}(3)$-EKF, Robocentric-EKF and the "First Estimates Jacobian" EKF, for 3D point feature based SLAM. version:1
arxiv-1702-06662 | An Integer Programming Model for Binary Knapsack Problem with Value-Related Dependencies among Elements | http://arxiv.org/abs/1702.06662 | id:1702.06662 author:Davoud Mougouei, David M. W. Powers, Asghar Moeini category:cs.AI  published:2017-02-22 summary:Binary Knapsack Problem (BKP) is to select a subset of an element (item) set with the highest value while keeping the total weight within the capacity of the knapsack. This paper presents an integer programming model for a variation of BKP where the value of each element may depend on selecting or ignoring other elements. Strengths of such Value-Related Dependencies are assumed to be imprecise and hard to specify. To capture this imprecision, we have proposed modeling value-related dependencies using fuzzy graphs and their algebraic structure. version:1
arxiv-1612-07433 | Comparative Analysis of SpatialHadoop and GeoSpark for Geospatial Big Data Analytics | http://arxiv.org/abs/1612.07433 | id:1612.07433 author:Rakesh K. Lenka, Rabindra K. Barik, Noopur Gupta, Syed Mohd Ali, Amiya Rath, Harishchandra Dubey category:cs.DC cs.CY  published:2016-12-22 summary:In this digitalised world where every information is stored, the data a are growing exponentially. It is estimated that data are doubles itself every two years. Geospatial data are one of the prime contributors to the big data scenario. There are numerous tools of the big data analytics. But not all the big data analytics tools are capabilities to handle geospatial big data. In the present paper, it has been discussed about the recent two popular open source geospatial big data analytical tools i.e. Spatial- Hadoop and GeoSpark which can be used for analysis and process the geospatial big data in efficient manner. It has compared the architectural view of SpatialHadoop and GeoSpark. Through the architectural comparison, it has also summarised the merits and demerits of these tools according the execution times and volume of the data which has been used. version:2
arxiv-1611-00404 | Per-Server Dominant-Share Fairness (PS-DSF): A Multi-Resource Fair Allocation Mechanism for Heterogeneous Servers | http://arxiv.org/abs/1611.00404 | id:1611.00404 author:Jalal Khamse-Ashari, Ioannis Lambadaris, George Kesidis, Bhuvan Urgaonkar, Yiqiang Zhao category:cs.DC  published:2016-11-01 summary:Users of cloud computing platforms pose different types of demands for multiple resources on servers (physical or virtual machines). Besides differences in their resource capacities, servers may be additionally heterogeneous in their ability to service users - certain users' tasks may only be serviced by a subset of the servers. We identify important shortcomings in existing multi-resource fair allocation mechanisms - Dominant Resource Fairness (DRF) and its follow up work - when used in such environments. We develop a new fair allocation mechanism called Per-Server Dominant-Share Fairness (PS-DSF) which we show offers all desirable sharing properties that DRF is able to offer in the case of a single "resource pool" (i.e., if the resources of all servers were pooled together into one hypothetical server). We evaluate the performance of PS-DSF through simulations. Our evaluation shows the enhanced efficiency of PS-DSF compared to the existing allocation mechanisms. We argue how our proposed allocation mechanism is applicable in cloud computing networks and especially large scale data-centers. version:2
arxiv-1702-06404 | Delving Deeper into MOOC Student Dropout Prediction | http://arxiv.org/abs/1702.06404 | id:1702.06404 author:Jacob Whitehill, Kiran Mohan, Daniel Seaton, Yigal Rosen, Dustin Tingley category:cs.AI cs.CY  published:2017-02-21 summary:In order to obtain reliable accuracy estimates for automatic MOOC dropout predictors, it is important to train and test them in a manner consistent with how they will be used in practice. Yet most prior research on MOOC dropout prediction has measured test accuracy on the same course used for training the classifier, which can lead to overly optimistic accuracy estimates. In order to understand better how accuracy is affected by the training+testing regime, we compared the accuracy of a standard dropout prediction architecture (clickstream features + logistic regression) across 4 different training paradigms. Results suggest that (1) training and testing on the same course ("post-hoc") can overestimate accuracy by several percentage points; (2) dropout classifiers trained on proxy labels based on students' persistence are surprisingly competitive with post-hoc training (87.33% versus 90.20% AUC averaged over 8 weeks of 40 HarvardX MOOCs); and (3) classifier performance does not vary significantly with the academic discipline. Finally, we also research new dropout prediction architectures based on deep, fully-connected, feed-forward neural networks and find that (4) networks with as many as 5 hidden layers can statistically significantly increase test accuracy over that of logistic regression. version:1
arxiv-1701-07553 | Guidance, Navigation and Control of Multirobot Systems in Cooperative Cliff Climbing | http://arxiv.org/abs/1701.07553 | id:1701.07553 author:Himangshu Kalita, Ravi Teja Nallapu, Andrew Warren, Jekan Thangavelautham category:cs.RO astro-ph.IM  published:2017-01-26 summary:The application of GNC devices on small robots is a game-changer that enables these robots to be mobile on low-gravity planetary surfaces and small bodies. Use of reaction wheels enables these robots to roll, hop, summersault and rest on precarious/sloped surfaces that would otherwise not be possible with conven-tional wheeled robots. We are extending this technology to enable robots to climb off-world canyons, cliffs and caves. A single robot may slip and fall, however, a multirobot system can work cooperatively by being interlinked using spring-tethers and work much like a team of mountaineers to systematically climb a slope. A multirobot system as we will show in this paper can climb sur-faces not possible with a single robot alone. We consider a team of four robots that are interlinked with tethers in an 'x' configuration. Each robot secures itself to a slope using spiny gripping actuators, and one by one each robot moves up-wards by crawling, rolling or hopping up the slope. If any one of the robots loses grip, slips or falls, the remaining robots will be holding it up as they are anchored. This distributed controls approach to cliff climbing enables the system to reconfigure itself where possible and avoid getting stuck at one hard to reach location. Instead, the risk is distributed and through close cooperation, the robots can identify multiple trajectories to climb a cliff or rugged surface. The benefits can also be realized on milligravity surfaces such as asteroids. Too fast a jump can result in the robot flying off the surface into space. Having multiple robots anchored to the surface keeps the entire system secure. Our work combines dynamics and control simulation to evaluate the feasibility of our approach. The simulation results show a promising pathway towards advanced development of this technology on a team of real robots. version:3
arxiv-1702-06331 | Demystifying Fog Computing: Characterizing Architectures, Applications and Abstractions | http://arxiv.org/abs/1702.06331 | id:1702.06331 author:Prateeksha Varshney, Yogesh Simmhan category:cs.DC  published:2017-02-21 summary:Internet of Things (IoT) has accelerated the deployment of millions of sensors at the edge of the network, through Smart City infrastructure and lifestyle devices. Cloud computing platforms are often tasked with handling these large volumes and fast streams of data from the edge. Recently, Fog computing has emerged as a concept for low-latency and resource-rich processing of these observation streams, to complement Edge and Cloud computing. In this paper, we review various dimensions of system architecture, application characteristics and platform abstractions that are manifest in this Edge, Fog and Cloud eco-system. We highlight novel capabilities of the Edge and Fog layers, such as physical and application mobility, privacy sensitivity, and a nascent runtime environment. IoT application case studies based on first-hand experiences across diverse domains drive this categorization. We also highlight the gap between the potential and the reality of Fog computing, and identify challenges that need to be overcome for the solution to be sustainable. Together, our article can help platform and application developers bridge the gap that remains in making Fog computing viable. version:1
arxiv-1702-06298 | Computing Influence of a Product through Uncertain Reverse Skyline | http://arxiv.org/abs/1702.06298 | id:1702.06298 author:Md. Saiful Islam, Wenny Rahayu, Chengfei Liu, Tarique Anwar, Bela Stantic category:cs.DB cs.DC cs.DS  published:2017-02-21 summary:Understanding the influence of a product is crucially important for making informed business decisions. This paper introduces a new type of skyline queries, called uncertain reverse skyline, for measuring the influence of a probabilistic product in uncertain data settings. More specifically, given a dataset of probabilistic products P and a set of customers C, an uncertain reverse skyline of a probabilistic product q retrieves all customers c in C which include q as one of their preferred products. We present efficient pruning ideas and techniques for processing the uncertain reverse skyline query of a probabilistic product using R-Tree data index. We also present an efficient parallel approach to compute the uncertain reverse skyline and influence score of a probabilistic product. Our approach significantly outperforms the baseline approach derived from the existing literature. The efficiency of our approach is demonstrated by conducting extensive experiments with both real and synthetic datasets. version:1
arxiv-1702-06284 | Review of Apriori Based Algorithms on MapReduce Framework | http://arxiv.org/abs/1702.06284 | id:1702.06284 author:Sudhakar Singh, Rakhi Garg, P. K. Mishra category:cs.DB cs.DC  published:2017-02-21 summary:The Apriori algorithm that mines frequent itemsets is one of the most popular and widely used data mining algorithms. Now days many algorithms have been proposed on parallel and distributed platforms to enhance the performance of Apriori algorithm. They differ from each other on the basis of load balancing technique, memory system, data decomposition technique and data layout used to implement them. The problems with most of the distributed framework are overheads of managing distributed system and lack of high level parallel programming language. Also with grid computing there is always potential chances of node failures which cause multiple re-executions of tasks. These problems can be overcome by the MapReduce framework introduced by Google. MapReduce is an efficient, scalable and simplified programming model for large scale distributed data processing on a large cluster of commodity computers and also used in cloud computing. In this paper, we present the overview of parallel Apriori algorithm implemented on MapReduce framework. They are categorized on the basis of Map and Reduce functions used to implement them e.g. 1-phase vs. k-phase, I/O of Mapper, Combiner and Reducer, using functionality of Combiner inside Mapper etc. This survey discusses and analyzes the various implementations of Apriori on MapReduce framework on the basis of their distinguishing characteristics. Moreover, it also includes the advantages and limitations of MapReduce framework. version:1
arxiv-1604-03670 | Interactive Perception: Leveraging Action in Perception and Perception in Action | http://arxiv.org/abs/1604.03670 | id:1604.03670 author:Jeannette Bohg, Karol Hausman, Bharath Sankaran, Oliver Brock, Danica Kragic, Stefan Schaal, Gaurav Sukhatme category:cs.RO  published:2016-04-13 summary:Recent approaches in robotics follow the insight that perception is facilitated by interaction with the environment. These approaches are subsumed under the term of Interactive Perception (IP). It provides the following benefits: (i) interaction with the environment creates a rich sensory signal that would otherwise not be present and (ii) knowledge of the regularity in the combined space of sensory data and action parameters facilitate the prediction and interpretation of the signal. In this survey we postulate this as a principle and collect evidence in support by analyzing and categorizing existing work in this area. We also provide an overview of the most important applications of Interactive Perception. We close this survey by discussing remaining open questions. Thereby, we hope to define a field and inspire future work. version:2
arxiv-1702-06199 | The Dialog State Tracking Challenge with Bayesian Approach | http://arxiv.org/abs/1702.06199 | id:1702.06199 author:Quan Nguyen category:cs.AI  published:2017-02-20 summary:Generative model has been one of the most common approaches for solving the Dialog State Tracking Problem with the capabilities to model the dialog hypotheses in an explicit manner. The most important task in such Bayesian networks models is constructing the most reliable user models by learning and reflecting the training data into the probability distribution of user actions conditional on networks states. This paper provides an overall picture of the learning process in a Bayesian framework with an emphasize on the state-of-the-art theoretical analyses of the Expectation Maximization learning algorithm. version:1
arxiv-1702-06167 | A Rollback in the History of Communication-Induced Checkpointing | http://arxiv.org/abs/1702.06167 | id:1702.06167 author:Islene C. Garcia, Gustavo M. D. Vieira, Luiz E. Buzato category:cs.DC  published:2017-02-20 summary:The literature on communication-induced checkpointing presents a family of protocols that use logical clocks to control whether forced checkpoints must be taken. For many years, HMNR, also called Fully Informed (FI), was the most complex and efficient protocol of this family. The Lazy-FI protocol applies a lazy strategy that defers the increase of logical clocks, resulting in a protocol with better perfomance for distributed systems where processes can take basic checkpoints at different, asymmetric, rates. Recently, the Fully Informed aNd Efficient (FINE) protocol was proposed using the same control structures as FI, but with a stronger and, presumably better, checkpoint-inducing condition. FINE and its lazy version, called Lazy-FINE, would now be the most efficient checkpointing protocols based on logical clocks. This paper reviews this family of protocols, proves a theorem on a condition that must be enforced by all stronger versions of FI, and proves that both FINE and Lazy-FINE do not guarantee the absence of useless checkpoints. As a consequence, FI and Lazy-FI can be rolled back to the position of most efficient protocols of this family of index-based checkpointing protocols. version:1
arxiv-1702-06082 | Coding for Distributed Fog Computing | http://arxiv.org/abs/1702.06082 | id:1702.06082 author:Songze Li, Mohammad Ali Maddah-Ali, A. Salman Avestimehr category:cs.IT cs.DC math.IT  published:2017-02-20 summary:Redundancy is abundant in Fog networks (i.e., many computing and storage points) and grows linearly with network size. We demonstrate the transformational role of coding in Fog computing for leveraging such redundancy to substantially reduce the bandwidth consumption and latency of computing. In particular, we discuss two recently proposed coding concepts, namely Minimum Bandwidth Codes and Minimum Latency Codes, and illustrate their impacts in Fog computing. We also review a unified coding framework that includes the above two coding techniques as special cases, and enables a tradeoff between computation latency and communication load to optimize system performance. At the end, we will discuss several open problems and future research directions. version:1
arxiv-1604-02113 | Parallel Delta-Stepping Algorithm for Shared Memory Architectures | http://arxiv.org/abs/1604.02113 | id:1604.02113 author:M. Kranjčević, D. Palossi, S. Pintarelli category:cs.DC  published:2016-04-07 summary:We present a shared memory implementation of a parallel algorithm, called delta-stepping, for solving the single source shortest path problem for directed and undirected graphs. In order to reduce synchronization costs we make some deviations from the algorithm and discuss the consequences. We study the behaviour of our implementation on small-world and scale-free graphs, and graphs arising from game maps. We collect performance data on multi-core CPUs and Intel Xeon Phi. When run in sequential mode, our implementation outperforms the implementation of Dijkstra's algorithm from Boost Graph Library on graphs with a small diameter. Both on the CPU and the co-processor we achieve an overall performance of at least 50% parallel efficiency. version:2
arxiv-1609-03130 | Gaussian Processes Online Observation Classification for RSSI-based Low-cost Indoor Positioning Systems | http://arxiv.org/abs/1609.03130 | id:1609.03130 author:Maani Ghaffari Jadidi, Mitesh Patel, Jaime Valls Miro category:cs.NI cs.RO  published:2016-09-11 summary:In this paper, we propose a real-time classification scheme to cope with noisy Radio Signal Strength Indicator (RSSI) measurements utilized in indoor positioning systems. RSSI values are often converted to distances for position estimation. However due to multipathing and shadowing effects, finding a unique sensor model using both parametric and non-parametric methods is highly challenging. We learn decision regions using the Gaussian Processes classification to accept measurements that are consistent with the operating sensor model. The proposed approach can perform online, does not rely on a particular sensor model or parameters, and is robust to sensor failures. The experimental results achieved using hardware show that available positioning algorithms can benefit from incorporating the classifier into their measurement model as a meta-sensor modeling technique. version:2
arxiv-1609-05307 | On the Structure of the Time-Optimal Path Parameterization Problem with Third-Order Constraints | http://arxiv.org/abs/1609.05307 | id:1609.05307 author:Pham Tien Hung, Quang-Cuong Pham category:cs.RO I.2.9; I.2.8  published:2016-09-17 summary:Finding the Time-Optimal Parameterization of a Path (TOPP) subject to second-order constraints (e.g. acceleration, torque, contact stability, etc.) is an important and well-studied problem in robotics. In comparison, TOPP subject to third-order constraints (e.g. jerk, torque rate, etc.) has received far less attention and remains largely open. In this paper, we investigate the structure of the TOPP problem with third-order constraints. In particular, we identify two major difficulties: (i) how to smoothly connect optimal profiles, and (ii) how to address singularities, which stop profile integration prematurely. We propose a new algorithm, TOPP3, which addresses these two difficulties and thereby constitutes an important milestone towards an efficient computational solution to TOPP with third-order constraints. version:2
arxiv-1702-06831 | Using Redescription Mining to Relate Clinical and Biological Characteristics of Cognitively Impaired and Alzheimer's Disease Patients | http://arxiv.org/abs/1702.06831 | id:1702.06831 author:Matej Mihelčić, Goran Šimić, Mirjana Babić Leko, Nada Lavrač, Sašo Džeroski, Tomislav Šmuc category:q-bio.QM cs.AI q-bio.NC  published:2017-02-20 summary:Based on a set of subjects and a collection of descriptors obtained from the Alzheimer's Disease Neuroimaging Initiative database, we use redescription mining to find rules revealing associations between these determinants which provides insights about the Alzheimer's disease (AD). We applied a four-step redescription mining algorithm (CLUS-RM), which has been extended to engender constraint-based redescription mining (CBRM) and enables several modes of targeted exploration of specific, user-defined associations. To a large extent we confirmed known findings, previously reported in the literature. However, several redescriptions contained biological descriptors that differentiated well between the groups and for which connection to AD is still not completely explained. Examples include testosterone, ciliary neurotrophic factor, brain natriuretic peptide, insulin etc. The imaging descriptor Spatial Pattern of Abnormalities for Recognition of Early AD and levels of leptin and angiopoietin-2 in plasma were also found to be remarkably good descriptors, that may provide better understanding of AD pathogenesis. Finally, the most intriguing and novel finding was the high association of the Pregnancy-Associated Protein-A (PAPP-A) with cognitive impairment in AD. The high importance of this finding lies in the fact that PAPP-A is a metalloproteinase, known to cleave insulin-like growth factor binding proteins. Since it also shares similar substrates with A Disintegrin and Metalloproteinase family of enzymes that act as {\alpha}-secretase to physiologically cleave amyloid precursor protein (APP) in the non-amyloidogenic pathway, it could be directly involved in metabolism of APP very early during the disease course. Therefore, further studies should investigate the role of PAPP-A in the development of AD more thoroughly. version:1
arxiv-1702-05778 | The Absent-Minded Driver Problem Redux | http://arxiv.org/abs/1702.05778 | id:1702.05778 author:Subhash Kak category:cs.AI cs.GT  published:2017-02-19 summary:This paper reconsiders the problem of the absent-minded driver who must choose between alternatives with different payoff with imperfect recall and varying degrees of knowledge of the system. The classical absent-minded driver problem represents the case with limited information and it has bearing on the general area of communication and learning, social choice, mechanism design, auctions, theories of knowledge, belief, and rational agency. Within the framework of extensive games, this problem has applications to many artificial intelligence scenarios. It is obvious that the performance of the agent improves as information available increases. It is shown that a non-uniform assignment strategy for successive choices does better than a fixed probability strategy. We consider both classical and quantum approaches to the problem. We argue that the superior performance of quantum decisions with access to entanglement cannot be fairly compared to a classical algorithm. If the cognitive systems of agents are taken to have access to quantum resources, or have a quantum mechanical basis, then that can be leveraged into superior performance. version:1
arxiv-1702-05770 | Achieving the Desired Dynamic Behavior in Multi-Robot Systems Interacting with the Environment | http://arxiv.org/abs/1702.05770 | id:1702.05770 author:Lorenzo Sabattini, Cristian Secchi, Cesare Fantuzzi category:cs.RO  published:2017-02-19 summary:In this paper we consider the problem of controlling the dynamic behavior of a multi-robot system while interacting with the environment. In particular, we propose a general methodology that, by means of locally scaling inter-robot coupling relationships, leads to achieving a desired interactive behavior. The proposed method is shown to guarantee passivity preservation, which ensures a safe interaction. The performance of the proposed methodology is evaluated in simulation, over large-scale multi-robot systems. version:1
arxiv-1702-05710 | Polynomial Time Efficient Construction Heuristics for Vertex Separation Minimization Problem | http://arxiv.org/abs/1702.05710 | id:1702.05710 author:Pallavi Jain, Gur Saran, Kamal Srivastava category:cs.DS cs.AI  published:2017-02-19 summary:Vertex Separation Minimization Problem (VSMP) consists of finding a layout of a graph G = (V,E) which minimizes the maximum vertex cut or separation of a layout. It is an NP-complete problem in general for which metaheuristic techniques can be applied to find near optimal solution. VSMP has applications in VLSI design, graph drawing and computer language compiler design. VSMP is polynomially solvable for grids, trees, permutation graphs and cographs. Construction heuristics play a very important role in the metaheuristic techniques as they are responsible for generating initial solutions which lead to fast convergence. In this paper, we have proposed three construction heuristics H1, H2 and H3 and performed experiments on Grids, Small graphs, Trees and Harwell Boeing graphs, totaling 248 instances of graphs. Experiments reveal that H1, H2 and H3 are able to achieve best results for 88.71%, 43.5% and 37.1% of the total instances respectively while the best construction heuristic in the literature achieves the best solution for 39.9% of the total instances. We have also compared the results with the state-of-the-art metaheuristic GVNS and observed that the proposed construction heuristics improves the results for some of the input instances. It was found that GVNS obtained best results for 82.9% instances of all input instances and the heuristic H1 obtained best results for 82.3% of all input instances. version:1
arxiv-1609-03433 | Feedback Motion Planning for Liquid Transfer using Supervised Learning | http://arxiv.org/abs/1609.03433 | id:1609.03433 author:Zherong Pan, Dinesh Manocha category:cs.RO  published:2016-09-12 summary:We present a novel motion planning algorithm for transferring a liquid body from a source to a target container. Our approach uses a receding-horizon optimization strategy that takes into account fluid constraints and avoids collisions. In order to efficiently handle the high-dimensional configuration space of a liquid body, we use system identification to learn its dynamics characteristics using a neural network. We generate the training dataset using stochastic optimization in a transfer-problem-specific search space. The runtime feedback motion planner is used for real-time planning and we observe high success rate in our simulated 2D and 3D fluid transfer benchmarks. version:2
arxiv-1511-05958 | Comparative Design, Scaling, and Control of Appendages for Inertial Reorientation | http://arxiv.org/abs/1511.05958 | id:1511.05958 author:Thomas Libby, Aaron M. Johnson, Evan Chang-Siu, Robert J. Full, D. E. Koditschek category:cs.RO  published:2015-11-18 summary:This paper develops a comparative framework for the design of actuated inertial appendages for planar, aerial reorientation. We define the Inertial Reorientation template, the simplest model of this behavior, and leverage its linear dynamics to reveal the design constraints linking a task with the body designs capable of completing it. As practicable inertial appendage designs lead to morphology that is generally more complex, we advance a notion of "anchoring" whereby a judicious choice of physical design in concert with an appropriate control policy yields a system whose closed loop dynamics are sufficiently captured by the template as to permit all further design to take place in its far simpler parameter space. This approach is effective and accurate over the diverse design spaces afforded by existing platforms, enabling performance comparison through the shared task space. We analyze examples from the literature and find advantages to each body type, but conclude that tails provide the highest potential performance for reasonable designs. Thus motivated, we build a physical example by retrofitting a tail to a RHex robot and present empirical evidence of its efficacy. version:2
arxiv-1702-05515 | Overview: Generalizations of Multi-Agent Path Finding to Real-World Scenarios | http://arxiv.org/abs/1702.05515 | id:1702.05515 author:Hang Ma, Sven Koenig, Nora Ayanian, Liron Cohen, Wolfgang Hoenig, T. K. Satish Kumar, Tansel Uras, Hong Xu, Craig Tovey, Guni Sharon category:cs.AI cs.MA cs.RO  published:2017-02-17 summary:Multi-agent path finding (MAPF) is well-studied in artificial intelligence, robotics, theoretical computer science and operations research. We discuss issues that arise when generalizing MAPF methods to real-world scenarios and four research directions that address them. We emphasize the importance of addressing these issues as opposed to developing faster methods for the standard formulation of the MAPF problem. version:1
arxiv-1702-05511 | A Concurrent Perspective on Smart Contracts | http://arxiv.org/abs/1702.05511 | id:1702.05511 author:Ilya Sergey, Aquinas Hobor category:cs.DC  published:2017-02-17 summary:In this paper, we explore remarkable similarities between multi-transactional behaviors of smart contracts in cryptocurrencies such as Ethereum and classical problems of shared-memory concurrency. We examine two real-world examples from the Ethereum blockchain and analyzing how they are vulnerable to bugs that are closely reminiscent to those that often occur in traditional concurrent programs. We then elaborate on the relation between observable contract behaviors and well-studied concurrency topics, such as atomicity, interference, synchronization, and resource ownership. The described contracts-as-concurrent-objects analogy provides deeper understanding of potential threats for smart contracts, indicate better engineering practices, and enable applications of existing state-of-the-art formal verification techniques. version:1
arxiv-1702-05510 | Java Code Analysis and Transformation into AWS Lambda Functions | http://arxiv.org/abs/1702.05510 | id:1702.05510 author:Josef Spillner, Serhii Dorodko category:cs.DC cs.SE D.2.1; I.2.2; C.2.4  published:2017-02-17 summary:Software developers are faced with the issue of either adapting their programming model to the execution model (e.g. cloud platforms) or finding appropriate tools to adapt the model and code automatically. A recent execution model which would benefit from automated enablement is Function-as-a-Service. Automating this process requires a pipeline which includes steps for code analysis, transformation and deployment. In this paper, we outline the design and runtime characteristics of Podilizer, a tool which implements the pipeline specifically for Java source code as input and AWS Lambda as output. We contribute technical and economic metrics about this concrete 'FaaSification' process by observing the behaviour of Podilizer with two representative Java software projects. version:1
arxiv-1702-05459 | Communication Reducing Algorithms for Distributed Hierarchical N-Body Problems with Boundary Distributions | http://arxiv.org/abs/1702.05459 | id:1702.05459 author:Mustafa Abduljabbar, George Markomanolis, Huda Ibeid, Rio Yokota, David Keyes category:cs.DC  published:2017-02-17 summary:Reduction of communication and efficient partitioning are key issues for achieving scalability in hierarchical $N$-Body algorithms like FMM. In the present work, we propose four independent strategies to improve partitioning and reduce communication. First of all, we show that the conventional wisdom of using space-filling curve partitioning may not work well for boundary integral problems, which constitute about 50% of FMM's application user base. We propose an alternative method which modifies orthogonal recursive bisection to solve the cell-partition misalignment that has kept it from scaling previously. Secondly, we optimize the granularity of communication to find the optimal balance between a bulk-synchronous collective communication of the local essential tree and an RDMA per task per cell. Finally, we take the dynamic sparse data exchange proposed by Hoefler et al. and extend it to a hierarchical sparse data exchange, which is demonstrated at scale to be faster than the MPI library's MPI_Alltoallv that is commonly used. version:1
arxiv-1702-05314 | Control of an Unmanned Surface Vehicle with Uncertain Displacement and Drag | http://arxiv.org/abs/1702.05314 | id:1702.05314 author:Wilhelm B. Klinger, Ivan R. Bertaska, Karl D. von Ellenrieder, Manhar R. Dhanak category:cs.SY cs.RO  published:2017-02-17 summary:Experimental testing of an unmanned surface vehicle (USV) has been performed to evaluate the performance of two low-level controllers when displacement and drag properties are time-varying and uncertain. The USV is a 4.3 meter long, 150 kilogram wave adaptive modular vessel (WAM-V) with an inflatable twin hull configuration and waterjet propulsion. Open loop maneuvering tests were conducted to characterize the dynamics of the vehicle. The hydrodynamic coefficients of the vehicle were determined through system identification of the maneuvering data and were used for simulations during control system development. The resulting controllers were experimentally field tested on-water. Variable mass and drag tests show that the vehicle is best controlled by a model reference adaptive backstepping speed and heading controller. The backstepping controller developed by Liao et. al (2010) is modified to account for an overprediction of necessary control action and motor saturation. It is shown that when an adaptive algorithm is implemented for the surge control subsystem of the modified backstepping controller, the effects of variable mass and drag are mitigated. version:1
arxiv-1604-00997 | Progressive Temporal Window Widening | http://arxiv.org/abs/1604.00997 | id:1604.00997 author:David Tolpin category:cs.DC  published:2016-04-04 summary:This paper introduces a scheme for data stream processing which is robust to batch duration. Streaming frameworks process streams in batches retrieved at fixed time intervals. In a common setting a pattern recognition algorithm is applied independently to each batch. Choosing the right time interval is tough --- a pattern may not fit in an interval which is too short, but detection will be delayed and memory may be exhausted if the interval is too long. We propose here Progressive Window Widening, an algorithm for increasing the interval gradually so that patterns are caught at any pace without unnecessary delays or memory overflow. This algorithm is relevant to computer security, system monitoring, user behavior tracking, and other applications where patterns of unknown or varying duration must be recognized online in data streams. Modern data stream processing frameworks are ubiquitously used to process high volumes of data, and adaptive memory and CPU allocation, facilitated by Progressive Window Widening, is crucial for their performance. version:3
arxiv-1702-05116 | Collective Motion under Beacon-referenced Cyclic Pursuit | http://arxiv.org/abs/1702.05116 | id:1702.05116 author:Kevin S. Galloway, Biswadip Dey category:cs.SY cs.RO  published:2017-02-16 summary:Cyclic pursuit frameworks, which are built upon pursuit interactions between neighboring agents in a cycle graph, provide an efficient way to create useful global behaviors in a collective of autonomous robots. Previous work has considered cyclic pursuit with a constant bearing (CB) pursuit law and has demonstrated the existence of circling equilibria for the corresponding dynamics. In this work we propose a beacon-referenced version of the CB pursuit law, wherein a stationary beacon provides an additional reference for the individual agents in the collective. When implemented in a cyclic framework, we show that the resulting dynamics admit relative equilibria corresponding to a circling orbit around the beacon, with the circling radius and the distribution of agents along the orbit determined by parameters of the proposed feedback law. We also derive necessary conditions for stability of the circling equilibria, which provides a guide for parameter selection. Finally, by introducing a change of variables, we demonstrate the existence of a family of invariant manifolds related to spiraling motions around the beacon which preserve the "pure shape" of the collective, and we carry out an analysis of the reduced dynamics on a representative manifold. version:1
arxiv-1702-05112 | OntoMath Digital Ecosystem: Ontologies, Mathematical Knowledge Analytics and Management | http://arxiv.org/abs/1702.05112 | id:1702.05112 author:Alexander Elizarov, Alexander Kirillovich, Evgeny Lipachev, Olga Nevzorova category:cs.DL cs.AI 68T30 H.3.7  published:2017-02-16 summary:In this article we consider the basic ideas, approaches and results of developing of mathematical knowledge management technologies based on ontologies. These solutions form the basis of a specialized digital ecosystem OntoMath which consists of the ontology of the logical structure of mathematical documents Mocassin and ontology of mathematical knowledge OntoMathPRO, tools of text analysis, recommender system and other applications to manage mathematical knowledge. The studies are in according to the ideas of creating a distributed system of interconnected repositories of digitized versions of mathematical documents and project to create a World Digital Mathematical Library. version:1
arxiv-1702-04970 | A Framework for Interactive Teaching of Virtual Borders to Mobile Robots | http://arxiv.org/abs/1702.04970 | id:1702.04970 author:Dennis Sprute, Robin Rasch, Klaus Tönnies, Matthias König category:cs.RO  published:2017-02-16 summary:The increasing number of robots in home environments leads to an emerging coexistence between humans and robots. Robots undertake common tasks and support the residents in their everyday life. People appreciate the presence of robots in their environment as long as they keep the control over them. One important aspect is the control of a robot's workspace. Therefore, we introduce virtual borders to precisely and flexibly define the workspace of mobile robots. First, we propose a novel framework that allows a person to interactively restrict a mobile robot's workspace. To show the validity of this framework, a concrete implementation based on visual markers is implemented. Afterwards, the mobile robot is capable of performing its tasks while respecting the new virtual borders. The approach is accurate, flexible and less time consuming than explicit robot programming. Hence, even non-experts are able to teach virtual borders to their robots which is especially interesting in domains like vacuuming or service robots in home environments. version:1
arxiv-1702-04941 | Station-keeping control of an unmanned surface vehicle exposed to current and wind disturbances | http://arxiv.org/abs/1702.04941 | id:1702.04941 author:Edoardo I. Sarda, Huajin Qu, Ivan R. Bertaska, Karl D. von Ellenrieder category:cs.SY cs.RO  published:2017-02-16 summary:Field trials of a 4 meter long, 180 kilogram, unmanned surface vehicle (USV) have been conducted to evaluate the performance of station-keeping heading and position controllers in an outdoor marine environment disturbed by wind and current. The USV has a twin hull configuration and a custom-designed propulsion system, which consists of two azimuthing thrusters, one for each hull. Nonlinear proportional derivative, backstepping and sliding mode feedback controllers were tested in winds of about 4-5 knots, with and without wind feedforward control. The controllers were tested when the longitudinal axis of the USV was aligned with the mean wind direction and when the longitudinal axis was perpendicular to the mean wind direction. It was found that the sliding mode controller performed best overall and that the addition of wind feedforward control did not significantly improve its effectiveness. However, wind feedforward control did substantially improve the performance of the proportional derivative and backstepping controllers when the mean wind direction was perpendicular to the longitudinal axis of the USV. An analysis of the length scales present in the power spectrum of the turbulent speed fluctuations in the wind suggests that a single anemometer is sufficient to characterize the speed and direction of the wind acting on the USV. version:1
arxiv-1702-04940 | Supervisory Switching Control of an Unmanned Surface Vehicle | http://arxiv.org/abs/1702.04940 | id:1702.04940 author:Ivan R. Bertaska, Karl D. von Ellenrieder category:cs.SY cs.RO  published:2017-02-16 summary:A novel method to determine the switching of controllers to increase the performance of a system is presented. Three controllers are utilized to capture three behaviors representative of unmanned surface vehicles (USVs). An underactuated nonlinear controller is derived to transit the vehicle between locations; a fully-actuated nonlinear controller is given to station-keep the vehicle at a setpoint; and a linear anti-windup controller is presented for the reversing mode of operation. Given a trajectory to follow, a performance-based supervisory switching control system (PBSSC) dictates the switching between controllers to improve system performance. Experimental results are shown that indicate that the PBSSC system is able to mitigate errors in pose better than any of the individual controllers. version:1
arxiv-1702-04921 | Ignore or Comply? On Breaking Symmetry in Consensus | http://arxiv.org/abs/1702.04921 | id:1702.04921 author:Petra Berenbrink, Andrea Clementi, Robert Elsässer, Peter Kling, Frederik Mallmann-Trenn, Emanuele Natale category:cs.DC  published:2017-02-16 summary:We study consensus processes on the complete graph of $n$ nodes. Initially, each node supports one from up to n opinions. Nodes randomly and in parallel sample the opinions of constant many nodes. Based on these samples, they use an update rule to change their own opinion. The goal is to reach consensus, a configuration where all nodes support the same opinion. We compare two well-known update rules: 2-Choices and 3-Majority. In the former, each node samples two nodes and adopts their opinion if they agree. In the latter, each node samples three nodes: If an opinion is supported by at least two samples the node adopts it, otherwise it randomly adopts one of the sampled opinions. Known results for these update rules focus on initial configurations with a limited number of colors (say $n^{1/3}$ ), or typically assume a bias, where one opinion has a much larger support than any other. For such biased configurations, the time to reach consensus is roughly the same for 2-Choices and 3-Majority. Interestingly, we prove that this is no longer true for configurations with a large number of initial colors. In particular, we show that 3-Majority reaches consensus with high probability in $O(n^{3/4}\log^{7/8}n)$ rounds, while 2-Choices can need $\Omega(n/\log n)$ rounds. We thus get the first unconditional sublinear bound for 3-Majority and the first result separating the consensus time of these processes. Along the way, we develop a framework that allows a fine-grained comparison between consensus processes from a specific class. We believe that this framework might help to classify the performance of more consensus processes. version:1
arxiv-1701-04395 | Linear Matrix Inequalities for Rigid-Body Inertia Parameter Identification: A Statistical Perspective | http://arxiv.org/abs/1701.04395 | id:1701.04395 author:Patrick M. Wensing, Sangbae Kim, Jean-Jacques Slotine category:cs.RO  published:2017-01-16 summary:With the increased application of model-based whole-body control methods in legged robots, there has been an resurgence of interest in system identification strategies and adaptive control. An important class of methods relates to the identification of inertia parameters for rigid-body systems. For each link, these consist of the mass, first mass moment (related to center of mass location), and 3D rotational inertia tensor. The main contribution of this paper is to formulate physical-consistency constraints on these parameters as Linear Matrix Inequalities (LMIs). Matrix inequalities are found not in terms of moments of inertia, but in terms of statistical moments, suggesting a statistical perspective on the mass distribution of a rigid body. Through this viewpoint, a rich set of new constraints can be formulated as LMIs that enforce properties on the underlying mass distribution of each link. Overall, new constraints have a simpler form, are more efficient to enforce in optimization, and are tighter than those used in the current literature. The methods are verified in system identification for a leg of the MIT Cheetah 3 robot. Detailed properties of transmission components are identified alongside link inertias, with parameter optimization carried out to guaranteed global optimality through semidefinite programming. version:2
arxiv-1702-04850 | Coded TeraSort | http://arxiv.org/abs/1702.04850 | id:1702.04850 author:Songze Li, Sucha Supittayapornpong, Mohammad Ali Maddah-Ali, A. Salman Avestimehr category:cs.DC cs.IT math.IT  published:2017-02-16 summary:We focus on sorting, which is the building block of many machine learning algorithms, and propose a novel distributed sorting algorithm, named Coded TeraSort, which substantially improves the execution time of the TeraSort benchmark in Hadoop MapReduce. The key idea of Coded TeraSort is to impose structured redundancy in data, in order to enable in-network coding opportunities that overcome the data shuffling bottleneck of TeraSort. We empirically evaluate the performance of CodedTeraSort algorithm on Amazon EC2 clusters, and demonstrate that it achieves 1.97x - 3.39x speedup, compared with TeraSort, for typical settings of interest. version:1
arxiv-1702-04739 | An Efficient Parallel Data Clustering Algorithm Using Isoperimetric Number of Trees | http://arxiv.org/abs/1702.04739 | id:1702.04739 author:Ramin Javadi, Saleh Ashkboos category:cs.DC  published:2017-02-15 summary:We propose a parallel graph-based data clustering algorithm using CUDA GPU, based on exact clustering of the minimum spanning tree in terms of a minimum isoperimetric criteria. We also provide a comparative performance analysis of our algorithm with other related ones which demonstrates the general superiority of this parallel algorithm over other competing algorithms in terms of accuracy and speed. version:1
arxiv-1702-04700 | Target assignment for robots constrained by limited communication range | http://arxiv.org/abs/1702.04700 | id:1702.04700 author:Xiaoshan Bai, Weisheng Yan, Ming Cao, Jie Huang category:math.OC cs.MA cs.RO math.PR  published:2017-02-15 summary:This paper investigates the task assignment problem for multiple dispersed robots constrained by limited communication range. The robots are initially randomly distributed and need to visit several target locations while minimizing the total travel time. A centralized rendezvous-based algorithm is proposed, under which all the robots first move towards a rendezvous position until communication paths are established between every pair of robots either directly or through intermediate peers, and then one robot is chosen as the leader to make a centralized task assignment for the other robots. Furthermore, we propose a decentralized algorithm based on a single-traveling-salesman tour, which does not require all the robots to be connected through communication. We investigate the variation of the quality of the assignment solutions as the level of information sharing increases and as the communication range grows, respectively. The proposed algorithms are compared with a centralized algorithm with shared global information and a decentralized greedy algorithm respectively. Monte Carlo simulation results show the satisfying performance of the proposed algorithms. version:1
