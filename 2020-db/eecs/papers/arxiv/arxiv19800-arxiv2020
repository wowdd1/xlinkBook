arxiv-1607-08188 | Online Trajectory Segmentation and Summary With Applications to Visualization and Retrieval | http://arxiv.org/abs/1607.08188 | id:1607.08188 author:Yehezkel S. Resheff category:cs.CV cs.DB stat.ML  published:2016-07-24 summary:Trajectory segmentation is the process of subdividing a trajectory into parts either by grouping points similar with respect to some measure of interest, or by minimizing a global objective function. Here we present a novel online algorithm for segmentation and summary, based on point density along the trajectory, and based on the nature of the naturally occurring structure of intermittent bouts of locomotive and local activity. We show an application to visualization of trajectory datasets, and discuss the use of the summary as an index allowing efficient queries which are otherwise impossible or computationally expensive, over very large datasets. version:1
arxiv-1607-07043 | Spatio-Temporal LSTM with Trust Gates for 3D Human Action Recognition | http://arxiv.org/abs/1607.07043 | id:1607.07043 author:Jun Liu, Amir Shahroudy, Dong Xu, Gang Wang category:cs.CV cs.AI cs.LG cs.NE  published:2016-07-24 summary:3D action recognition - analysis of human actions based on 3D skeleton data - becomes popular recently due to its succinctness, robustness, and view-invariant representation. Recent attempts on this problem suggested to develop RNN-based learning methods to model the contextual dependency in the temporal domain. In this paper, we extend this idea to spatio-temporal domains to analyze the hidden sources of action-related information within the input data over both domains concurrently. Inspired by the graphical structure of the human skeleton, we further propose a more powerful tree-structure based traversal method. To handle the noise and occlusion in 3D skeleton data, we introduce new gating mechanism within LSTM to learn the reliability of the sequential input data and accordingly adjust its effect on updating the long-term context information stored in the memory cell. Our method achieves state-of-the-art performance on 4 challenging benchmark datasets for 3D human action analysis. version:1
arxiv-1607-07034 | Impact of Physical Activity on Sleep:A Deep Learning Based Exploration | http://arxiv.org/abs/1607.07034 | id:1607.07034 author:Aarti Sathyanarayana, Shafiq Joty, Luis Fernandez-Luque, Ferda Ofli, Jaideep Srivastava, Ahmed Elmagarmid, Shahrad Taheri, Teresa Arora category:cs.LG  published:2016-07-24 summary:The importance of sleep is paramount for maintaining physical, emotional and mental wellbeing. Though the relationship between sleep and physical activity is known to be important, it is not yet fully understood. The explosion in popularity of actigraphy and wearable devices, provides a unique opportunity to understand this relationship. Leveraging this information source requires new tools to be developed to facilitate data-driven research for sleep and activity patient-recommendations. In this paper we explore the use of deep learning to build sleep quality prediction models based on actigraphy data. We first use deep learning as a pure model building device by performing human activity recognition (HAR) on raw sensor data, and using deep learning to build sleep prediction models. We compare the deep learning models with those build using classical approaches, i.e. logistic regression, support vector machines, random forest and adaboost. Secondly, we employ the advantage of deep learning with its ability to handle high dimensional datasets. We explore several deep learning models on the raw wearable sensor output without performing HAR or any other feature extraction. Our results show that using a convolutional neural network on the raw wearables output improves the predictive value of sleep quality from physical activity, by an additional 8% compared to state-of-the-art non-deep learning approaches, which itself shows a 15% improvement over current practice. Moreover, utilizing deep learning on raw data eliminates the need for data pre-processing and simplifies the overall workflow to analyze actigraphy data for sleep and physical activity research. version:1
arxiv-1607-03070 | Forward Table-Based Presynaptic Event-Triggered Spike-Timing-Dependent Plasticity | http://arxiv.org/abs/1607.03070 | id:1607.03070 author:Bruno U. Pedroni, Sadique Sheik, Siddharth Joshi, Georgios Detorakis, Somnath Paul, Charles Augustine, Emre Neftci, Gert Cauwenberghs category:cs.NE  published:2016-07-11 summary:Spike-timing-dependent plasticity (STDP) incurs both causal and acausal synaptic weight updates, for negative and positive time differences between pre-synaptic and post-synaptic spike events. For realizing such updates in neuromorphic hardware, current implementations either require forward and reverse lookup access to the synaptic connectivity table, or rely on memory-intensive architectures such as crossbar arrays. We present a novel method for realizing both causal and acausal weight updates using only forward lookup access of the synaptic connectivity table, permitting memory-efficient implementation. A simplified implementation in FPGA, using a single timer variable for each neuron, closely approximates exact STDP cumulative weight updates for neuron refractory periods greater than 10 ms, and reduces to exact STDP for refractory periods greater than the STDP time window. Compared to conventional crossbar implementation, the forward table-based implementation leads to substantial memory savings for sparsely connected networks supporting scalable neuromorphic systems with fully reconfigurable synaptic connectivity and plasticity. version:2
arxiv-1607-07006 | Autonomous Ingress of a UAV through a window using Monocular Vision | http://arxiv.org/abs/1607.07006 | id:1607.07006 author:Abhinav Pachauri, Vikrant More, Pradeep Gaidhani, Nitin Gupta category:cs.CV cs.RO  published:2016-07-24 summary:The use of autonomous UAVs for surveillance purposes and other reconnaissance tasks is increasingly becoming popular and convenient.These tasks requires the ability to successfully ingress through the rectangular openings or windows of the target structure.In this paper, a method to robustly detect the window in the surrounding using basic image processing techniques and efficient distance measure, is proposed.Furthermore, a navigation scheme which incorporates this detection method for performing navigation task has also been proposed.The whole navigation task is performed and tested in the simulation environment GAZEBO. version:1
arxiv-1607-06999 | Recurrent Regression for Face Recognition | http://arxiv.org/abs/1607.06999 | id:1607.06999 author:Yang Li, Wenming Zheng, Zhen Cui category:cs.CV  published:2016-07-24 summary:To address the sequential changes of images including poses, in this paper we propose a recurrent regression neural network(RRNN) framework to unify two classic tasks of cross-pose face recognition on still images and video-based face recognition. To imitate the changes of images, we explicitly construct the potential dependencies of sequential images so as to regularize the final learning model. By performing progressive transforms for sequentially adjacent images, RRNN can adaptively memorize and forget the information that benefits for the final classification. For face recognition of still images, given any one image with any one pose, we recurrently predict the images with its sequential poses to expect to capture some useful information of others poses. For video-based face recognition, the recurrent regression takes one entire sequence rather than one image as its input. We verify RRNN in static face dataset MultiPIE and face video dataset YouTube Celebrities(YTC). The comprehensive experimental results demonstrate the effectiveness of the proposed RRNN method. version:1
arxiv-1607-06997 | Peak-Piloted Deep Network for Facial Expression Recognition | http://arxiv.org/abs/1607.06997 | id:1607.06997 author:Xiangyun Zhao, Xiaodan Liang, Luoqi Liu, Teng Li, Nuno Vasconcelos, Shuicheng Yan category:cs.CV  published:2016-07-24 summary:Objective functions for training of deep networks for face-related recognition tasks, such as facial expression recognition (FER), usually consider each sample independently. In this work, we present a novel peak-piloted deep network (PPDN) that uses a sample with peak expression (easy sample) to supervise the intermediate feature responses for a sample of non-peak expression (hard sample) of the same type and from the same subject. The expression evolving process from non-peak expression to peak expression can thus be implicitly embedded in the network to achieve the invariance to expression intensities. A special purpose back-propagation procedure, peak gradient suppression (PGS), is proposed for network training. It drives the intermediate-layer feature responses of non-peak expression samples towards those of the corresponding peak expression samples, while avoiding the inverse. This avoids degrading the recognition capability for samples of peak expression due to interference from their non-peak expression counterparts. Extensive comparisons on two popular FER datasets, Oulu-CASIA and CK+, demonstrate the superiority of the PPDN over state-ofthe-art FER methods, as well as the advantages of both the network structure and the optimization strategy. Moreover, it is shown that PPDN is a general architecture, extensible to other tasks by proper definition of peak and non-peak samples. This is validated by experiments that show state-of-the-art performance on pose-invariant face recognition, using the Multi-PIE dataset. version:1
arxiv-1607-06996 | Scaling Up Sparse Support Vector Machine by Simultaneous Feature and Sample Reduction | http://arxiv.org/abs/1607.06996 | id:1607.06996 author:Weizhong Zhang, Bin Hong, Jieping Ye, Deng Cai, Xiaofei He, Jie Wang category:stat.ML cs.LG  published:2016-07-24 summary:Sparse support vector machine (SVM) is a popular classification technique that can simultaneously learn a small set of the most interpretable features. It has achieved great success in many real-world applications. However, for large-scale problems involving a huge number of samples and extremely high-dimensional features, solving sparse SVM remains challenging. By noting that sparse SVM induces sparsities in both feature and sample spaces, we propose a novel approach---that is based on accurate estimations of the primal and dual optimums of sparse SVM---to simultaneously identify the features and samples that are guaranteed to be irrelevant to the outputs. Thus, we can remove the identified samples and features from the training phase, which may lead to substantial savings in both memory usage and computational cost without sacrificing accuracy. To the best of our knowledge, the proposed method is the \emph{first} \emph{static} feature and sample reduction method for sparse SVM. Experiments on both synthetic and real data sets (e.g., the kddb data set with about 20 million of samples and 30 million of features) demonstrate that our approach significantly outperforms existing state-of-the-art methods and the speedup gained by our approach can be orders of magnitude. version:1
arxiv-1607-06993 | Community Detection in Degree-Corrected Block Models | http://arxiv.org/abs/1607.06993 | id:1607.06993 author:Chao Gao, Zongming Ma, Anderson Y. Zhang, Harrison H. Zhou category:math.ST cs.SI stat.ML stat.TH  published:2016-07-24 summary:Community detection is a central problem of network data analysis. Given a network, the goal of community detection is to partition the network nodes into a small number of clusters, which could often help reveal interesting structures. The present paper studies community detection in Degree-Corrected Block Models (DCBMs). We first derive asymptotic minimax risks of the problem for a misclassification proportion loss under appropriate conditions. The minimax risks are shown to depend on degree-correction parameters, community sizes, and average within and between community connectivities in an intuitive and interpretable way. In addition, we propose a polynomial time algorithm to adaptively perform consistent and even asymptotically optimal community detection in DCBMs. version:1
arxiv-1607-06988 | Interactive Learning from Multiple Noisy Labels | http://arxiv.org/abs/1607.06988 | id:1607.06988 author:Shankar Vembu, Sandra Zilles category:cs.LG stat.ML  published:2016-07-24 summary:Interactive learning is a process in which a machine learning algorithm is provided with meaningful, well-chosen examples as opposed to randomly chosen examples typical in standard supervised learning. In this paper, we propose a new method for interactive learning from multiple noisy labels where we exploit the disagreement among annotators to quantify the easiness (or meaningfulness) of an example. We demonstrate the usefulness of this method in estimating the parameters of a latent variable classification model, and conduct experimental analyses on a range of synthetic and benchmark datasets. Furthermore, we theoretically analyze the performance of perceptron in this interactive learning framework. version:1
arxiv-1607-06986 | Ego2Top: Matching Viewers in Egocentric and Top-view Videos | http://arxiv.org/abs/1607.06986 | id:1607.06986 author:Shervin Ardeshir, Ali Borji category:cs.CV  published:2016-07-24 summary:Egocentric cameras are becoming increasingly popular and provide us with large amounts of videos, captured from the first person perspective. At the same time, surveillance cameras and drones offer an abundance of visual information, often captured from top-view. Although these two sources of information have been separately studied in the past, they have not been collectively studied and related. Having a set of egocentric cameras and a top-view camera capturing the same area, we propose a framework to identify the egocentric viewers in the top-view video. We utilize two types of features for our assignment procedure. Unary features encode what a viewer (seen from top-view or recording an egocentric video) visually experiences over time. Pairwise features encode the relationship between the visual content of a pair of viewers. Modeling each view (egocentric or top) by a graph, the assignment process is formulated as spectral graph matching. Evaluating our method over a dataset of 50 top-view and 188 egocentric videos taken in different scenarios demonstrates the efficiency of the proposed approach in assigning egocentric viewers to identities present in top-view camera. We also study the effect of different parameters such as the number of egocentric viewers and visual features. version:1
arxiv-1607-06973 | Combined Classifiers for Invariant Face Recognition | http://arxiv.org/abs/1607.06973 | id:1607.06973 author:Ahmad H. A. Eid category:cs.CV  published:2016-07-23 summary:No single classifier can alone solve the complex problem of face recognition. Researchers found that combining some base classifiers usually enhances their recognition rate. The weaknesses of the base classifiers are reflected on the resulting combined system. In this work, a system for combining unstable, low performance classifiers is proposed. The system is applied to face images of 392 persons. The system shows remarkable stability and high recognition rate using a reduced number of parameters. The system illustrates the possibility of designing a combined system that benefits from the strengths of its base classifiers while avoiding many of their weaknesses. version:1
arxiv-1607-06972 | Kinematic-aware random forest for static and dynamic action recognition from depth sequences | http://arxiv.org/abs/1607.06972 | id:1607.06972 author:Seungryul Beak, Zhiyuan Shi, Masato Kawade, Tae-Kyun Kim category:cs.CV  published:2016-07-23 summary:Existing work for action recognition from depth sequences focus on modeling the dynamics of various actions. In this paper, we tackle the problem of 24 hours-monitoring patient actions in a ward, where temporal movements can be significant or subtle, and their relative positions to scene layout and body postures become important cues, such as "lying on the bed", "stretching an arm out of the bed", "falling out of the bed". To address this problem, we propose a kinematic-aware random forest method to maximize the discriminative power of depth image representation, which takes into account both spatio-temporal appearance by a pre-trained CNN and additional kinematic prior (e.g. layout, skeleton) information. We integrate the additional information in the split functions to guide the learning process, i.e. the spatio-temporal appearance feature selection, by directly measuring the uncertainty of kinematic information and closing the gap between posterior class distributions given the kinematic prior and the appearance features. This additional information is not required for test data, thus called "privileged information prior". The learned relationship from the kinematic space to the appearance space helps maximize class separation of both static and dynamic actions. The inferred class label distribution is further refined by enforcing the consistency across frames. Experimental evaluations on our new dataset and Cornell Activity Dataset demonstrate that our method significantly outperforms various state-of-the-arts. version:1
arxiv-1607-06961 | Authorship attribution via network motifs identification | http://arxiv.org/abs/1607.06961 | id:1607.06961 author:Vanessa Queiroz Marinho, Graeme Hirst, Diego Raphael Amancio category:cs.CL  published:2016-07-23 summary:Concepts and methods of complex networks can be used to analyse texts at their different complexity levels. Examples of natural language processing (NLP) tasks studied via topological analysis of networks are keyword identification, automatic extractive summarization and authorship attribution. Even though a myriad of network measurements have been applied to study the authorship attribution problem, the use of motifs for text analysis has been restricted to a few works. The goal of this paper is to apply the concept of motifs, recurrent interconnection patterns, in the authorship attribution task. The absolute frequencies of all thirteen directed motifs with three nodes were extracted from the co-occurrence networks and used as classification features. The effectiveness of these features was verified with four machine learning methods. The results show that motifs are able to distinguish the writing style of different authors. In our best scenario, 57.5% of the books were correctly classified. The chance baseline for this problem is 12.5%. In addition, we have found that function words play an important role in these recurrent patterns. Taken together, our findings suggest that motifs should be further explored in other related linguistic tasks. version:1
arxiv-1607-06952 | Neural Sentence Ordering | http://arxiv.org/abs/1607.06952 | id:1607.06952 author:Xinchi Chen, Xipeng Qiu, Xuanjing Huang category:cs.CL  published:2016-07-23 summary:Sentence ordering is a general and critical task for natural language generation applications. Previous works have focused on improving its performance in an external, downstream task, such as multi-document summarization. Given its importance, we propose to study it as an isolated task. We collect a large corpus of academic texts, and derive a data driven approach to learn pairwise ordering of sentences, and validate the efficacy with extensive experiments. Source codes and dataset of this paper will be made publicly available. version:1
arxiv-1607-06902 | Rank Correlation Measure: A Representational Transformation for Biometric Template Protection | http://arxiv.org/abs/1607.06902 | id:1607.06902 author:Zhe Jin, Yen-Lung Lai, Andrew Beng Jin Teoh category:cs.CV cs.CR  published:2016-07-23 summary:Despite a variety of theoretical-sound techniques have been proposed for biometric template protection, there is rarely practical solution that guarantees non-invertibility, cancellability, non-linkability and performance simultaneously. In this paper, a ranking-based representational transformation is proposed for fingerprint templates. The proposed method transforms a real-valued feature vector into index code such that the pairwise-order measure in the resultant codes are closely correlated with rank similarity measure. Such a ranking based technique offers two major merits: 1) Resilient to noises/perturbations in numeric values; and 2) Highly nonlinear embedding based on partial order statistics. The former takes care of the accuracy performance mitigating numeric noises/perturbations while the latter offers strong non-invertible transformation via nonlinear feature embedding from Euclidean to Rank space that leads to toughness in inversion. The experimental results demonstrate reasonable accuracy performance on benchmark FVC2002 and FVC2004 fingerprint databases, thus confirm the proposition of the rank correlation. Moreover, the security and privacy analysis justify the strong capability against the existing major privacy attacks. version:1
arxiv-1607-06875 | Processing Natural Language About Ongoing Actions | http://arxiv.org/abs/1607.06875 | id:1607.06875 author:Steve Doubleday, Sean Trott, Jerome Feldman category:cs.AI cs.CL cs.HC cs.RO  published:2016-07-23 summary:Actions may not proceed as planned; they may be interrupted, resumed or overridden. This is a challenge to handle in a natural language understanding system. We describe extensions to an existing implementation for the control of autonomous systems by natural language, to enable such systems to handle incoming language requests regarding actions. Language Communication with Autonomous Systems (LCAS) has been extended with support for X-nets, parameterized executable schemas representing actions. X-nets enable the system to control actions at a desired level of granularity, while providing a mechanism for language requests to be processed asynchronously. Standard semantics supported include requests to stop, continue, or override the existing action. The specific domain demonstrated is the control of motion of a simulated robot, but the approach is general, and could be applied to other domains. version:1
arxiv-1607-06854 | Unsupervised Learning from Continuous Video in a Scalable Predictive Recurrent Network | http://arxiv.org/abs/1607.06854 | id:1607.06854 author:Filip Piekniewski, Patryk Laurent, Csaba Petre, Micah Richert, Dimitry Fisher, Todd Hylton category:cs.CV  published:2016-07-22 summary:Understanding visual reality involves acquiring common-sense knowledge about countless regularities in the visual world, e.g., how illumination alters the appearance of objects in a scene, and how motion changes their apparent spatial relationship. These regularities are hard to label for training supervised machine learning algorithms; consequently, algorithms need to learn these regularities from the real world in an unsupervised way. We present a novel network meta-architecture that can learn world dynamics from raw, continuous video. The components of this network can be implemented using any algorithm that possesses certain key characteristics. The highly-parallelized architecture is scalable, with localized connectivity, processing, and learning. We demonstrate an implementation of this architecture where the components are built from multi-layer perceptrons. We use this implementation to create a system capable of stable and robust visual tracking of objects as seen by a moving camera. Results show performance on par with or exceeding state-of-the-art tracking algorithms. The tracker can be trained in either fully supervised or unsupervised-then-briefly-supervised regimes. Success of the briefly-supervised regime suggests that the unsupervised portion of the model extracts useful information about visual reality. The results suggest a new class of AI algorithms that can learn from and act within the real world. version:1
arxiv-1607-06852 | CFGs-2-NLU: Sequence-to-Sequence Learning for Mapping Utterances to Semantics and Pragmatics | http://arxiv.org/abs/1607.06852 | id:1607.06852 author:Adam James Summerville, James Ryan, Michael Mateas, Noah Wardrip-Fruin category:cs.CL  published:2016-07-22 summary:In this paper, we present a novel approach to natural language understanding that utilizes context-free grammars (CFGs) in conjunction with sequence-to-sequence (seq2seq) deep learning. Specifically, we take a CFG authored to generate dialogue for our target application for NLU, a videogame, and train a long short-term memory (LSTM) recurrent neural network (RNN) to map the surface utterances that it produces to traces of the grammatical expansions that yielded them. Critically, this CFG was authored using a tool we have developed that supports arbitrary annotation of the nonterminal symbols in the grammar. Because we already annotated the symbols in this grammar for the semantic and pragmatic considerations that our game's dialogue manager operates over, we can use the grammatical trace associated with any surface utterance to infer such information. During gameplay, we translate player utterances into grammatical traces (using our RNN), collect the mark-up attributed to the symbols included in that trace, and pass this information to the dialogue manager, which updates the conversation state accordingly. From an offline evaluation task, we demonstrate that our trained RNN translates surface utterances to grammatical traces with great accuracy. To our knowledge, this is the first usage of seq2seq learning for conversational agents (our game's characters) who explicitly reason over semantic and pragmatic considerations. version:1
arxiv-1607-06801 | High-dimensional regression adjustments in randomized experiments | http://arxiv.org/abs/1607.06801 | id:1607.06801 author:Stefan Wager, Wenfei Du, Jonathan Taylor, Robert Tibshirani category:stat.ME stat.ML  published:2016-07-22 summary:We study the problem of treatment effect estimation in randomized experiments with high-dimensional regression adjustments. We present an inferential approach that takes any risk-consistent regression adjustment and yields efficient estimates of the average treatment effect. This considerably extends the range of settings where high-dimensional regression adjustments are guaranteed to provide valid inference about the population average treatment effect. We also propose cross-estimation, a simple method for obtaining finite-sample-unbiased treatment effect estimates that leverages high-dimensional regression adjustments. Our method can be used when the regression model is estimated using the lasso, the elastic net, subset selection, or many other methods; we also extend our analysis to allow for adaptive specification search via cross-validation, and flexible non-parametric regression adjustments with, e.g., random forests or neural networks. version:1
arxiv-1607-06797 | A probabilistic patch based image representation using Conditional Random Field model for image classification | http://arxiv.org/abs/1607.06797 | id:1607.06797 author:Fariborz Taherkhani category:cs.CV  published:2016-07-22 summary:In this paper we proposed an ordered patch based method using Conditional Random Field (CRF) in order to encode local properties and their spatial relationship in images to address texture classification, face recognition, and scene classification problems. Typical image classification approaches work without considering spatial causality among distinctive properties of an image for image representation in feature space. In this method first, each image is encoded as a sequence of ordered patches, including local properties. Second, the sequence of these ordered patches is modeled as a probabilistic feature vector by CRF to model spatial relationship of these local properties. And finally, image classification is performed on such probabilistic image representation. Experimental results on several standard image datasets indicate that proposed method outperforms some of existing image classification methods. version:1
arxiv-1607-06794 | An ensemble learning method for scene classification based on Hidden Markov Model image representation | http://arxiv.org/abs/1607.06794 | id:1607.06794 author:Fariborz Taherkhani, Reza Hedayati category:cs.CV  published:2016-07-22 summary:Low level images representation in feature space performs poorly for classification with high accuracy since this level of representation is not able to project images into the discriminative feature space. In this work, we propose an efficient image representation model for classification. First we apply Hidden Markov Model (HMM) on ordered grids represented by different type of image descriptors in order to include causality of local properties existing in image for feature extraction and then we train up a separate classifier for each of these features sets. Finally we ensemble these classifiers efficiently in a way that they can cancel out each other errors for obtaining higher accuracy. This method is evaluated on 15 natural scene dataset. Experimental results show the superiority of the proposed method in comparison to some current existing methods version:1
arxiv-1607-06787 | Prior-based Coregistration and Cosegmentation | http://arxiv.org/abs/1607.06787 | id:1607.06787 author:Mahsa Shakeri, Enzo Ferrante, Stavros Tsogkas, Sarah Lippe, Samuel Kadoury, Iasonas Kokkinos, Nikos Paragios category:cs.CV  published:2016-07-22 summary:We propose a modular and scalable framework for dense coregistration and cosegmentation with two key characteristics: first, we substitute ground truth data with the semantic map output of a classifier; second, we combine this output with population deformable registration to improve both alignment and segmentation. Our approach deforms all volumes towards consensus, taking into account image similarities and label consistency. Our pipeline can incorporate any classifier and similarity metric. Results on two datasets, containing annotations of challenging brain structures, demonstrate the potential of our method. version:1
arxiv-1607-06783 | Can DMD obtain a Scene Background in Color? | http://arxiv.org/abs/1607.06783 | id:1607.06783 author:Santosh Tirunagari, Norman Poh, Miroslaw Bober, David Windridge category:cs.CV  published:2016-07-22 summary:A background model describes a scene without any foreground objects and has a number of applications, ranging from video surveillance to computational photography. Recent studies have introduced the method of Dynamic Mode Decomposition (DMD) for robustly separating video frames into a background model and foreground components. While the method introduced operates by converting color images to grayscale, we in this study propose a technique to obtain the background model in the color domain. The effectiveness of our technique is demonstrated using a publicly available Scene Background Initialisation (SBI) dataset. Our results both qualitatively and quantitatively show that DMD can successfully obtain a colored background model. version:1
arxiv-1607-06781 | On Covariate Shift Adaptation via Sparse Filtering | http://arxiv.org/abs/1607.06781 | id:1607.06781 author:Fabio Massimo Zennaro, Ke Chen category:cs.LG stat.ML  published:2016-07-22 summary:A major challenge in machine learning is covariate shift, i.e., the problem of training data and test data coming from different distributions. This paper studies the feasibility of tackling this problem by means of sparse filtering. We show that the sparse filtering algorithm intrinsically addresses this problem, but it has limited capacity for covariate shift adaptation. To overcome this limit, we propose a novel semi-supervised sparse filtering algorithm, named periodic sparse filtering. Our proposed algorithm is formally analyzed and empirically evaluated with an elaborated synthetic data set and real speech emotion data sets. As a result, we argue that, as an alternative methodology, feature distribution learning has enormous potential in carrying out covariate shift adaptation. version:1
arxiv-1607-06641 | Optimal resampling for the noisy OneMax problem | http://arxiv.org/abs/1607.06641 | id:1607.06641 author:Jialin Liu, Michael Fairbank, Diego Pérez-Liébana, Simon M. Lucas category:cs.NE cs.AI I.2.8  published:2016-07-22 summary:The OneMax problem is a standard benchmark optimisation problem for a binary search space. Recent work on applying a Bandit-Based Random Mutation Hill-Climbing algorithm to the noisy OneMax Problem showed that it is important to choose a good value for the resampling number to make a careful trade off between taking more samples in order to reduce noise, and taking fewer samples to reduce the total computational cost. This paper extends that observation, by deriving an analytical expression for the running time of the RMHC algorithm with resampling applied to the noisy OneMax problem, and showing both theoretically and empirically that the optimal resampling number increases with the number of dimensions in the search space. version:1
arxiv-1607-06617 | Latent Variable Discovery Using Dependency Patterns | http://arxiv.org/abs/1607.06617 | id:1607.06617 author:Xuhui Zhang, Kevin B. Korb, Ann E. Nicholson, Steven Mascaro category:cs.AI stat.ML  published:2016-07-22 summary:The causal discovery of Bayesian networks is an active and important research area, and it is based upon searching the space of causal models for those which can best explain a pattern of probabilistic dependencies shown in the data. However, some of those dependencies are generated by causal structures involving variables which have not been measured, i.e., latent variables. Some such patterns of dependency "reveal" themselves, in that no model based solely upon the observed variables can explain them as well as a model using a latent variable. That is what latent variable discovery is based upon. Here we did a search for finding them systematically, so that they may be applied in latent variable discovery in a more rigorous fashion. version:1
arxiv-1607-06583 | Classification of Alzheimer's Disease Structural MRI Data by Deep Learning Convolutional Neural Networks | http://arxiv.org/abs/1607.06583 | id:1607.06583 author:Saman Sarraf, Ghassem Tofighi category:cs.CV cs.AI  published:2016-07-22 summary:Recently, machine learning techniques especially predictive modeling and pattern recognition in biomedical sciences from drug delivery system to medical imaging has become one of the important methods which are assisting researchers to have deeper understanding of entire issue and to solve complex medical problems. Deep learning is a powerful machine learning algorithm in classification while extracting low to high-level features. In this paper, we used convolutional neural network to classify Alzheimer's brain from normal healthy brain. The importance of classifying this kind of medical data is to potentially develop a predict model or system in order to recognize the type disease from normal subjects or to estimate the stage of the disease. Classification of clinical data such as Alzheimer's disease has been always challenging and most problematic part has been always selecting the most discriminative features. Using Convolutional Neural Network (CNN) and the famous architecture LeNet-5, we successfully classified structural MRI data of Alzheimer's subjects from normal controls where the accuracy of test data on trained data reached 98.84%. This experiment suggests us the shift and scale invariant features extracted by CNN followed by deep learning classification is most powerful method to distinguish clinical data from healthy data in fMRI. This approach also enables us to expand our methodology to predict more complicated systems. version:1
arxiv-1607-06560 | Automated Prediction of Temporal Relations | http://arxiv.org/abs/1607.06560 | id:1607.06560 author:Amol S Patwardhan, Jacob Badeaux, Siavash, Gerald M Knapp category:cs.CL cs.AI  published:2016-07-22 summary:Background: There has been growing research interest in automated answering of questions or generation of summary of free form text such as news article. In order to implement this task, the computer should be able to identify the sequence of events, duration of events, time at which event occurred and the relationship type between event pairs, time pairs or event-time pairs. Specific Problem: It is important to accurately identify the relationship type between combinations of event and time before the temporal ordering of events can be defined. The machine learning approach taken in Mani et. al (2006) provides an accuracy of only 62.5 on the baseline data from TimeBank. The researchers used maximum entropy classifier in their methodology. TimeML uses the TLINK annotation to tag a relationship type between events and time. The time complexity is quadratic when it comes to tagging documents with TLINK using human annotation. This research proposes using decision tree and parsing to improve the relationship type tagging. This research attempts to solve the gaps in human annotation by automating the task of relationship type tagging in an attempt to improve the accuracy of event and time relationship in annotated documents. Scope information: The documents from the domain of news will be used. The tagging will be performed within the same document and not across documents. The relationship types will be identified only for a pair of event and time and not a chain of events. The research focuses on documents tagged using the TimeML specification which contains tags such as EVENT, TLINK, and TIMEX. Each tag has attributes such as identifier, relation, POS, time etc. version:1
arxiv-1607-06556 | Syntax-based Attention Model for Natural Language Inference | http://arxiv.org/abs/1607.06556 | id:1607.06556 author:PengFei Liu, Xipeng Qiu, Xuanjing Huang category:cs.CL  published:2016-07-22 summary:Introducing attentional mechanism in neural network is a powerful concept, and has achieved impressive results in many natural language processing tasks. However, most of the existing models impose attentional distribution on a flat topology, namely the entire input representation sequence. Clearly, any well-formed sentence has its accompanying syntactic tree structure, which is a much rich topology. Applying attention to such topology not only exploits the underlying syntax, but also makes attention more interpretable. In this paper, we explore this direction in the context of natural language inference. The results demonstrate its efficacy. We also perform extensive qualitative analysis, deriving insights and intuitions of why and how our model works. version:1
arxiv-1607-06532 | Novel Word Embedding and Translation-based Language Modeling for Extractive Speech Summarization | http://arxiv.org/abs/1607.06532 | id:1607.06532 author:Kuan-Yu Chen, Shih-Hung Liu, Berlin Chen, Hsin-Min Wang, Hsin-Hsi Chen category:cs.CL cs.AI cs.IR cs.MM  published:2016-07-22 summary:Word embedding methods revolve around learning continuous distributed vector representations of words with neural networks, which can capture semantic and/or syntactic cues, and in turn be used to induce similarity measures among words, sentences and documents in context. Celebrated methods can be categorized as prediction-based and count-based methods according to the training objectives and model architectures. Their pros and cons have been extensively analyzed and evaluated in recent studies, but there is relatively less work continuing the line of research to develop an enhanced learning method that brings together the advantages of the two model families. In addition, the interpretation of the learned word representations still remains somewhat opaque. Motivated by the observations and considering the pressing need, this paper presents a novel method for learning the word representations, which not only inherits the advantages of classic word embedding methods but also offers a clearer and more rigorous interpretation of the learned word representations. Built upon the proposed word embedding method, we further formulate a translation-based language modeling framework for the extractive speech summarization task. A series of empirical evaluations demonstrate the effectiveness of the proposed word representation learning and language modeling techniques in extractive speech summarization. version:1
arxiv-1607-06525 | CGMOS: Certainty Guided Minority OverSampling | http://arxiv.org/abs/1607.06525 | id:1607.06525 author:Xi Zhang, Di Ma, Lin Gan, Shanshan Jiang, Gady Agam category:cs.LG  published:2016-07-21 summary:Handling imbalanced datasets is a challenging problem that if not treated correctly results in reduced classification performance. Imbalanced datasets are commonly handled using minority oversampling, whereas the SMOTE algorithm is a successful oversampling algorithm with numerous extensions. SMOTE extensions do not have a theoretical guarantee during training to work better than SMOTE and in many instances their performance is data dependent. In this paper we propose a novel extension to the SMOTE algorithm with a theoretical guarantee for improved classification performance. The proposed approach considers the classification performance of both the majority and minority classes. In the proposed approach CGMOS (Certainty Guided Minority OverSampling) new data points are added by considering certainty changes in the dataset. The paper provides a proof that the proposed algorithm is guaranteed to work better than SMOTE for training data. Further experimental results on 30 real-world datasets show that CGMOS works better than existing algorithms when using 6 different classifiers. version:1
arxiv-1607-06520 | Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings | http://arxiv.org/abs/1607.06520 | id:1607.06520 author:Tolga Bolukbasi, Kai-Wei Chang, James Zou, Venkatesh Saligrama, Adam Kalai category:cs.CL cs.AI cs.LG stat.ML  published:2016-07-21 summary:The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between between the words receptionist and female, while maintaining desired associations such as between the words queen and female. We define metrics to quantify both direct and indirect gender biases in embeddings, and develop algorithms to "debias" the embedding. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias. version:1
arxiv-1607-06514 | Geometric Neural Phrase Pooling: Modeling the Spatial Co-occurrence of Neurons | http://arxiv.org/abs/1607.06514 | id:1607.06514 author:Lingxi Xie, Qi Tian, John Flynn, Jingdong Wang, Alan Yuille category:cs.CV  published:2016-07-21 summary:Deep Convolutional Neural Networks (CNNs) are playing important roles in state-of-the-art visual recognition. This paper focuses on modeling the spatial co-occurrence of neuron responses, which is less studied in the previous work. For this, we consider the neurons in the hidden layer as neural words, and construct a set of geometric neural phrases on top of them. The idea that grouping neural words into neural phrases is borrowed from the Bag-of-Visual-Words (BoVW) model. Next, the Geometric Neural Phrase Pooling (GNPP) algorithm is proposed to efficiently encode these neural phrases. GNPP acts as a new type of hidden layer, which punishes the isolated neuron responses after convolution, and can be inserted into a CNN model with little extra computational overhead. Experimental results show that GNPP produces significant and consistent accuracy gain in image classification. version:1
arxiv-1607-06450 | Layer Normalization | http://arxiv.org/abs/1607.06450 | id:1607.06450 author:Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton category:stat.ML cs.LG  published:2016-07-21 summary:Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques. version:1
arxiv-1607-06416 | Hierarchical Attention Network for Action Recognition in Videos | http://arxiv.org/abs/1607.06416 | id:1607.06416 author:Yilin Wang, Suhang Wang, Jiliang Tang, Neil O'Hare, Yi Chang, Baoxin Li category:cs.CV  published:2016-07-21 summary:Understanding human actions in wild videos is an important task with a broad range of applications. In this paper we propose a novel approach named Hierarchical Attention Network (HAN), which enables to incorporate static spatial information, short-term motion information and long-term video temporal structures for complex human action understanding. Compared to recent convolutional neural network based approaches, HAN has following advantages (1) HAN can efficiently capture video temporal structures in a longer range; (2) HAN is able to reveal temporal transitions between frame chunks with different time steps, i.e. it explicitly models the temporal transitions between frames as well as video segments and (3) with a multiple step spatial temporal attention mechanism, HAN automatically learns important regions in video frames and temporal segments in the video. The proposed model is trained and evaluated on the standard video action benchmarks, i.e., UCF-101 and HMDB-51, and it significantly outperforms the state-of-the arts version:1
arxiv-1607-06408 | Multi-Camera Action Dataset (MCAD): A Dataset for Studying Non-overlapped Cross-Camera Action Recognition | http://arxiv.org/abs/1607.06408 | id:1607.06408 author:Wenhui Li, Yongkang Wong, An-An Liu, Yang Li, Yu-Ting Su, Mohan Kankanhalli category:cs.CV  published:2016-07-21 summary:Action recognition has received increasing attentions from the computer vision and machine learning communities in the last decades. To enable the study of this problem, there exist a vast number of action datasets, which are recorded under the controlled laboratory environment, the real-world surveillance environment, or crawled from the Internet. Most of these datasets are recorded using one camera, or simultaneously recorded with the same action with multiple overlapped cameras. This results in that the training and test data are often resemble similar environment conditions. In this paper, we introduce a new dataset, namely Multi-Camera Action Dataset (MCAD), which is designed to evaluate the open view classification problem under the surveillance environment. Specifically, it enable researchers to study the robustness of exiting algorithm for actions that are recorded from multiple cameras with similar Field-of-View (FOV) and environment conditions. This dataset contains 14,298 action samples from 18 action categories, including 9 classes of single person actions and 9 classes of person-object actions, which are performed by 20 subjects and recorded with 5 cameras. Inspired by the well received evaluation approach on the LFW dataset, we design a standard evaluation protocol to enable comparisonagainst existing works. version:1
arxiv-1607-06407 | Small-Variance Nonparametric Clustering on the Hypersphere | http://arxiv.org/abs/1607.06407 | id:1607.06407 author:Julian Straub, Trevor Campbell, Jonathan P. How, John W. Fisher III category:cs.CV math.ST stat.AP stat.TH  published:2016-07-21 summary:Structural regularities in man-made environments reflect in the distribution of their surface normals. Describing these surface normal distributions is important in many computer vision applications, such as scene understanding, plane segmentation, and regularization of 3D reconstructions. Based on the small-variance limit of Bayesian nonparametric von-Mises-Fisher (vMF) mixture distributions, we propose two new flexible and efficient k-means-like clustering algorithms for directional data such as surface normals. The first, DP-vMF-means, is a batch clustering algorithm derived from the Dirichlet process (DP) vMF mixture. Recognizing the sequential nature of data collection in many applications, we extend this algorithm to DDP-vMF-means, which infers temporally evolving cluster structure from streaming data. Both algorithms naturally respect the geometry of directional data, which lies on the unit sphere. We demonstrate their performance on synthetic directional data and real 3D surface normals from RGB-D sensors. While our experiments focus on 3D data, both algorithms generalize to high dimensional directional data such as protein backbone configurations and semantic word vectors. version:1
arxiv-1607-06364 | Distributed Supervised Learning using Neural Networks | http://arxiv.org/abs/1607.06364 | id:1607.06364 author:Simone Scardapane category:stat.ML cs.LG  published:2016-07-21 summary:Distributed learning is the problem of inferring a function in the case where training data is distributed among multiple geographically separated sources. Particularly, the focus is on designing learning strategies with low computational requirements, in which communication is restricted only to neighboring agents, with no reliance on a centralized authority. In this thesis, we analyze multiple distributed protocols for a large number of neural network architectures. The first part of the thesis is devoted to a definition of the problem, followed by an extensive overview of the state-of-the-art. Next, we introduce different strategies for a relatively simple class of single layer neural networks, where a linear output layer is preceded by a nonlinear layer, whose weights are stochastically assigned in the beginning of the learning process. We consider both batch and sequential learning, with horizontally and vertically partitioned data. In the third part, we consider instead the more complex problem of semi-supervised distributed learning, where each agent is provided with an additional set of unlabeled training samples. We propose two different algorithms based on diffusion processes for linear support vector machines and kernel ridge regression. Subsequently, the fourth part extends the discussion to learning with time-varying data (e.g. time-series) using recurrent neural networks. We consider two different families of networks, namely echo state networks (extending the algorithms introduced in the second part), and spline adaptive filters. Overall, the algorithms presented throughout the thesis cover a wide range of possible practical applications, and lead the way to numerous future extensions, which are briefly summarized in the conclusive chapter. version:1
arxiv-1607-06356 | Reasoning about Body-Parts Relations for Sign Language Recognition | http://arxiv.org/abs/1607.06356 | id:1607.06356 author:Marc Martínez-Camarena, Jose Oramas, Mario Montagud-Climent, Tinne Tuytelaars category:cs.CV  published:2016-07-21 summary:Over the years, hand gesture recognition has been mostly addressed considering hand trajectories in isolation. However, in most sign languages, hand gestures are defined on a particular context (body region). We propose a pipeline to perform sign language recognition which models hand movements in the context of other parts of the body captured in the 3D space using the MS Kinect sensor. In addition, we perform sign recognition based on the different hand postures that occur during a sign. Our experiments show that considering different body parts brings improved performance when compared to other methods which only consider global hand trajectories. Finally, we demonstrate that the combination of hand postures features with hand gestures features helps to improve the prediction of a given sign. version:1
arxiv-1607-06349 | Fast Robust Monocular Depth Estimation for Obstacle Detection with Fully Convolutional Networks | http://arxiv.org/abs/1607.06349 | id:1607.06349 author:Michele Mancini, Gabriele Costante, Paolo Valigi, Thomas A. Ciarfuglia category:cs.RO cs.CV  published:2016-07-21 summary:Obstacle Detection is a central problem for any robotic system, and critical for autonomous systems that travel at high speeds in unpredictable environment. This is often achieved through scene depth estimation, by various means. When fast motion is considered, the detection range must be longer enough to allow for safe avoidance and path planning. Current solutions often make assumption on the motion of the vehicle that limit their applicability, or work at very limited ranges due to intrinsic constraints. We propose a novel appearance-based Object Detection system that is able to detect obstacles at very long range and at a very high speed (~300Hz), without making assumptions on the type of motion. We achieve these results using a Deep Neural Network approach trained on real and synthetic images and trading some depth accuracy for fast, robust and consistent operation. We show how photo-realistic synthetic images are able to solve the problem of training set dimension and variety typical of machine learning approaches, and how our system is robust to massive blurring of test images. version:1
arxiv-1607-06339 | Excisive Hierarchical Clustering Methods for Network Data | http://arxiv.org/abs/1607.06339 | id:1607.06339 author:Gunnar Carlsson, Facundo Mémoli, Alejandro Ribeiro, Santiago Segarra category:cs.LG  published:2016-07-21 summary:We introduce two practical properties of hierarchical clustering methods for (possibly asymmetric) network data: excisiveness and linear scale preservation. The latter enforces imperviousness to change in units of measure whereas the former ensures local consistency of the clustering outcome. Algorithmically, excisiveness implies that we can reduce computational complexity by only clustering a data subset of interest while theoretically guaranteeing that the same hierarchical outcome would be observed when clustering the whole dataset. Moreover, we introduce the concept of representability, i.e. a generative model for describing clustering methods through the specification of their action on a collection of networks. We further show that, within a rich set of admissible methods, requiring representability is equivalent to requiring both excisiveness and linear scale preservation. Leveraging this equivalence, we show that all excisive and linear scale preserving methods can be factored into two steps: a transformation of the weights in the input network followed by the application of a canonical clustering method. Furthermore, their factorization can be used to show stability of excisive and linear scale preserving methods in the sense that a bounded perturbation in the input network entails a bounded perturbation in the clustering output. version:1
arxiv-1607-06335 | Admissible Hierarchical Clustering Methods and Algorithms for Asymmetric Networks | http://arxiv.org/abs/1607.06335 | id:1607.06335 author:Gunnar Carlsson, Facundo Mémoli, Alejandro Ribeiro, Santiago Segarra category:cs.LG stat.ML  published:2016-07-21 summary:This paper characterizes hierarchical clustering methods that abide by two previously introduced axioms -- thus, denominated admissible methods -- and proposes tractable algorithms for their implementation. We leverage the fact that, for asymmetric networks, every admissible method must be contained between reciprocal and nonreciprocal clustering, and describe three families of intermediate methods. Grafting methods exchange branches between dendrograms generated by different admissible methods. The convex combination family combines admissible methods through a convex operation in the space of dendrograms, and thirdly, the semi-reciprocal family clusters nodes that are related by strong cyclic influences in the network. Algorithms for the computation of hierarchical clusters generated by reciprocal and nonreciprocal clustering as well as the grafting, convex combination, and semi-reciprocal families are derived using matrix operations in a dioid algebra. Finally, the introduced clustering methods and algorithms are exemplified through their application to a network describing the interrelation between sectors of the United States (U.S.) economy. version:1
arxiv-1607-06333 | Uncovering Causality from Multivariate Hawkes Integrated Cumulants | http://arxiv.org/abs/1607.06333 | id:1607.06333 author:Massil Achab, Emmanuel Bacry, Stéphane Gaïffas, Iacopo Mastromatteo, Jean-Francois Muzy category:stat.ML cs.LG  published:2016-07-21 summary:We design a new nonparametric method that allows one to estimate the matrix of integrated kernels of a multivariate Hawkes process. This matrix not only encodes the mutual influences of each nodes of the process, but also disentangles the causality relationships between them. Our approach is the first that leads to an estimation of this matrix without any parametric modeling and estimation of the kernels themselves. A consequence is that it can give an estimation of causality relationships between nodes (or users), based on their activity timestamps (on a social network for instance), without knowing or estimating the shape of the activities lifetime. For that purpose, we introduce a moment matching method that fits the third-order integrated cumulants of the process. We show on numerical experiments that our approach is indeed very robust to the shape of the kernels, and gives appealing results on the MemeTracker database. version:1
arxiv-1607-06317 | A Multi-cut Formulation for Joint Segmentation and Tracking of Multiple Objects | http://arxiv.org/abs/1607.06317 | id:1607.06317 author:Margret Keuper, Siyu Tang, Yu Zhongjie, Bjoern Andres, Thomas Brox, Bernt Schiele category:cs.CV  published:2016-07-21 summary:Recently, Minimum Cost Multicut Formulations have been proposed and proven to be successful in both motion trajectory segmentation and multi-target tracking scenarios. Both tasks benefit from decomposing a graphical model into an optimal number of connected components based on attractive and repulsive pairwise terms. The two tasks are formulated on different levels of granularity and, accordingly, leverage mostly local information for motion segmentation and mostly high-level information for multi-target tracking. In this paper we argue that point trajectories and their local relationships can contribute to the high-level task of multi-target tracking and also argue that high-level cues from object detection and tracking are helpful to solve motion segmentation. We propose a joint graphical model for point trajectories and object detections whose Multicuts are solutions to motion segmentation {\it and} multi-target tracking problems at once. Results on the FBMS59 motion segmentation benchmark as well as on pedestrian tracking sequences from the 2D MOT 2015 benchmark demonstrate the promise of this joint approach. version:1
arxiv-1607-06299 | Opinion Mining in Online Reviews About Distance Education Programs | http://arxiv.org/abs/1607.06299 | id:1607.06299 author:Janik Jaskolski, Fabian Siegberg, Thomas Tibroni, Philipp Cimiano, Roman Klinger category:cs.CL 68T50 K.3.1; I.2.7; H.2.8  published:2016-07-21 summary:The popularity of distance education programs is increasing at a fast pace. En par with this development, online communication in fora, social media and reviewing platforms between students is increasing as well. Exploiting this information to support fellow students or institutions requires to extract the relevant opinions in order to automatically generate reports providing an overview of pros and cons of different distance education programs. We report on an experiment involving distance education experts with the goal to develop a dataset of reviews annotated with relevant categories and aspects in each category discussed in the specific review together with an indication of the sentiment. Based on this experiment, we present an approach to extract general categories and specific aspects under discussion in a review together with their sentiment. We frame this task as a multi-label hierarchical text classification problem and empirically investigate the performance of different classification architectures to couple the prediction of a category with the prediction of particular aspects in this category. We evaluate different architectures and show that a hierarchical approach leads to superior results in comparison to a flat model which makes decisions independently. version:1
arxiv-1607-06294 | Hierarchical Clustering of Asymmetric Networks | http://arxiv.org/abs/1607.06294 | id:1607.06294 author:Gunnar Carlsson, Facundo Mémoli, Alejandro Ribeiro, Santiago Segarra category:cs.LG stat.ML  published:2016-07-21 summary:This paper considers networks where relationships between nodes are represented by directed dissimilarities. The goal is to study methods that, based on the dissimilarity structure, output hierarchical clusters, i.e., a family of nested partitions indexed by a connectivity parameter. Our construction of hierarchical clustering methods is built around the concept of admissible methods, which are those that abide by the axioms of value - nodes in a network with two nodes are clustered together at the maximum of the two dissimilarities between them - and transformation - when dissimilarities are reduced, the network may become more clustered but not less. Two particular methods, termed reciprocal and nonreciprocal clustering, are shown to provide upper and lower bounds in the space of admissible methods. Furthermore, alternative clustering methodologies and axioms are considered. In particular, modifying the axiom of value such that clustering in two-node networks occurs at the minimum of the two dissimilarities entails the existence of a unique admissible clustering method. version:1
arxiv-1607-06290 | Confidence-Weighted Local Expression Predictions for Occlusion Handling in Expression Recognition and Action Unit detection | http://arxiv.org/abs/1607.06290 | id:1607.06290 author:Arnaud Dapogny, Kévin Bailly, Séverine Dubuisson category:cs.CV  published:2016-07-21 summary:Fully-Automatic Facial Expression Recognition (FER) from still images is a challenging task as it involves handling large interpersonal morphological differences, and as partial occlusions can occasionally happen. Furthermore, labelling expressions is a time-consuming process that is prone to subjectivity, thus the variability may not be fully covered by the training data. In this work, we propose to train Random Forests upon spatially defined local subspaces of the face. The output local predictions form a categorical expression-driven high-level representation that we call Local Expression Predictions (LEPs). LEPs can be combined to describe categorical facial expressions as well as Action Units (AUs). Furthermore, LEPs can be weighted by confidence scores provided by an autoencoder network. Such network is trained to locally capture the manifold of the non-occluded training data in a hierarchical way. Extensive experiments show that the proposed LEP representation yields high descriptive power for categorical expressions and AU occurrence prediction, and leads to interesting perspectives towards the design of occlusion-robust and confidence-aware FER systems. version:1
arxiv-1607-06283 | Real-Time Intensity-Image Reconstruction for Event Cameras Using Manifold Regularisation | http://arxiv.org/abs/1607.06283 | id:1607.06283 author:Christian Reinbacher, Gottfried Graber, Thomas Pock category:cs.CV  published:2016-07-21 summary:Event cameras or neuromorphic cameras mimic the human perception system as they measure the per-pixel intensity change rather than the actual intensity level. In contrast to traditional cameras, such cameras capture new information about the scene at MHz frequency in the form of sparse events. The high temporal resolution comes at the cost of losing the familiar per-pixel intensity information. In this work we propose a variational model that accurately models the behaviour of event cameras, enabling reconstruction of intensity images with arbitrary frame rate in real-time. Our method is formulated on a per-event-basis, where we explicitly incorporate information about the asynchronous nature of events via an event manifold induced by the relative timestamps of events. In our experiments we verify that solving the variational model on the manifold produces high-quality images without explicitly estimating optical flow. version:1
arxiv-1607-06275 | Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering | http://arxiv.org/abs/1607.06275 | id:1607.06275 author:Peng Li, Wei Li, Zhengyan He, Xuguang Wang, Ying Cao, Jie Zhou, Wei Xu category:cs.CL cs.AI cs.NE  published:2016-07-21 summary:While question answering (QA) with neural network, i.e. neural QA, has achieved promising results in recent years, lacking of large scale real-word QA dataset is still a challenge for developing and evaluating neural QA system. To alleviate this problem, we propose a large scale human annotated real-world QA dataset WebQA with more than 42k questions and 556k evidences. As existing neural QA methods resolve QA either as sequence generation or classification/ranking problem, they face challenges of expensive softmax computation, unseen answers handling or separate candidate answer generation component. In this work, we cast neural QA as a sequence labeling problem and propose an end-to-end sequence labeling model, which overcomes all the above challenges. Experimental results on WebQA show that our model outperforms the baselines significantly with an F1 score of 74.69% with word-based input, and the performance drops only 3.72 F1 points with more challenging character-based input. version:1
arxiv-1607-06264 | Left/Right Hand Segmentation in Egocentric Videos | http://arxiv.org/abs/1607.06264 | id:1607.06264 author:Alejandro Betancourt, Pietro Morerio, Emilia Barakova, Lucio Marcenaro, Matthias Rauterberg, Carlo Regazzoni category:cs.HC cs.AI cs.CV  published:2016-07-21 summary:Wearable cameras allow people to record their daily activities from a user-centered (First Person Vision) perspective. Due to their favorable location, wearable cameras frequently capture the hands of the user, and may thus represent a promising user-machine interaction tool for different applications. Existent First Person Vision methods handle hand segmentation as a background-foreground problem, ignoring two important facts: i) hands are not a single "skin-like" moving element, but a pair of interacting cooperative entities, ii) close hand interactions may lead to hand-to-hand occlusions and, as a consequence, create a single hand-like segment. These facts complicate a proper understanding of hand movements and interactions. Our approach extends traditional background-foreground strategies, by including a hand-identification step (left-right) based on a Maxwell distribution of angle and position. Hand-to-hand occlusions are addressed by exploiting temporal superpixels. The experimental results show that, in addition to a reliable left/right hand-segmentation, our approach considerably improves the traditional background-foreground hand-segmentation. version:1
arxiv-1607-06250 | Dynamic Pose-Robust Facial Expression Recognition by Multi-View Pairwise Conditional Random Forests | http://arxiv.org/abs/1607.06250 | id:1607.06250 author:Arnaud Dapogny, Kévin Bailly, Séverine Dubuisson category:cs.CV  published:2016-07-21 summary:Automatic facial expression classification (FER) from videos is a critical problem for the development of intelligent human-computer interaction systems. Still, it is a challenging problem that involves capturing high-dimensional spatio-temporal patterns describing the variation of one's appearance over time. Such representation undergoes great variability of the facial morphology and environmental factors as well as head pose variations. In this paper, we use Conditional Random Forests to capture low-level expression transition patterns. More specifically, heterogeneous derivative features (e.g. feature point movements or texture variations) are evaluated upon pairs of images. When testing on a video frame, pairs are created between this current frame and previous ones and predictions for each previous frame are used to draw trees from Pairwise Conditional Random Forests (PCRF) whose pairwise outputs are averaged over time to produce robust estimates. Moreover, PCRF collections can also be conditioned on head pose estimation for multi-view dynamic FER. As such, our approach appears as a natural extension of Random Forests for learning spatio-temporal patterns, potentially from multiple viewpoints. Experiments on popular datasets show that our method leads to significant improvements over standard Random Forests as well as state-of-the-art approaches on several scenarios, including a novel multi-view video corpus generated from a publicly available database. version:1
arxiv-1607-06235 | Haze Visibility Enhancement: A Survey and Quantitative Benchmarking | http://arxiv.org/abs/1607.06235 | id:1607.06235 author:Yu Li, Shaodi You, Michael S. Brown, Robby T. Tan category:cs.CV  published:2016-07-21 summary:This paper provides a comprehensive survey of methods dealing with visibility enhancement of images taken in hazy or foggy scenes. The survey begins with discussing the optical models of atmospheric scattering media and image formation. This is followed by a survey of existing methods, which are grouped to multiple image methods, polarizing filters based methods, methods with known depth, and single-image methods. We also provide a benchmark of a number of well known single-image methods, based on a recent dataset provided by Fattal and our newly generated scattering media dataset that contains ground truth images for quantitative evaluation. To our knowledge, this is the first benchmark using numerical metrics to evaluate dehazing techniques. This benchmark allows us to objectively compare the results of existing methods and to better identify the strengths and limitations of each method. version:1
arxiv-1607-06676 | Detection of surface defects on ceramic tiles based on morphological techniques | http://arxiv.org/abs/1607.06676 | id:1607.06676 author:Grasha Jacob, R. Shenbagavalli, S. Karthika category:cs.CV  published:2016-07-21 summary:Ceramic tiles have become very popular and are used in the flooring of offices and shopping malls. As testing the quality of tiles manually in a highly polluted environment in the manufacturing industry is a labor-intensive and time consuming process, analysis is carried out on the tile images. This paper discusses an automated system to detect the defects on the surface of ceramic tiles based on dilation, erosion, SMEE and boundary detection techniques. version:1
arxiv-1607-06215 | A Comprehensive Survey on Cross-modal Retrieval | http://arxiv.org/abs/1607.06215 | id:1607.06215 author:Kaiye Wang, Qiyue Yin, Wei Wang, Shu Wu, Liang Wang category:cs.MM cs.CL cs.IR  published:2016-07-21 summary:In recent years, cross-modal retrieval has drawn much attention due to the rapid growth of multimodal data. It takes one type of data as the query to retrieve relevant data of another type. For example, a user can use a text to retrieve relevant pictures or videos. Since the query and its retrieved results can be of different modalities, how to measure the content similarity between different modalities of data remains a challenge. Various methods have been proposed to deal with such a problem. In this paper, we first review a number of representative methods for cross-modal retrieval and classify them into two main groups: 1) real-valued representation learning, and 2) binary representation learning. Real-valued representation learning methods aim to learn real-valued common representations for different modalities of data. To speed up the cross-modal retrieval, a number of binary representation learning methods are proposed to map different modalities of data into a common Hamming space. Then, we introduce several multimodal datasets in the community, and show the experimental results on two commonly used multimodal datasets. The comparison reveals the characteristic of different kinds of cross-modal retrieval methods, which is expected to benefit both practical applications and future research. Finally, we discuss open problems and future research directions. version:1
arxiv-1607-06208 | Exploring phrase-compositionality in skip-gram models | http://arxiv.org/abs/1607.06208 | id:1607.06208 author:Xiaochang Peng, Daniel Gildea category:cs.CL  published:2016-07-21 summary:In this paper, we introduce a variation of the skip-gram model which jointly learns distributed word vector representations and their way of composing to form phrase embeddings. In particular, we propose a learning procedure that incorporates a phrase-compositionality function which can capture how we want to compose phrases vectors from their component word vectors. Our experiments show improvement in word and phrase similarity tasks as well as syntactic tasks like dependency parsing using the proposed joint models. version:1
arxiv-1607-06203 | Greedy bi-criteria approximations for $k$-medians and $k$-means | http://arxiv.org/abs/1607.06203 | id:1607.06203 author:Daniel Hsu, Matus Telgarsky category:cs.DS cs.LG  published:2016-07-21 summary:This paper investigates the following natural greedy procedure for clustering in the bi-criterion setting: iteratively grow a set of centers, in each round adding the center from a candidate set that maximally decreases clustering cost. In the case of $k$-medians and $k$-means, the key results are as follows. $\bullet$ When the method considers all data points as candidate centers, then selecting $\mathcal{O}(k\log(1/\varepsilon))$ centers achieves cost at most $2+\varepsilon$ times the optimal cost with $k$ centers. $\bullet$ Alternatively, the same guarantees hold if each round samples $\mathcal{O}(k/\varepsilon^5)$ candidate centers proportionally to their cluster cost (as with $\texttt{kmeans++}$, but holding centers fixed). $\bullet$ In the case of $k$-means, considering an augmented set of $n^{\lceil1/\varepsilon\rceil}$ candidate centers gives $1+\varepsilon$ approximation with $\mathcal{O}(k\log(1/\varepsilon))$ centers, the entire algorithm taking $\mathcal{O}(dk\log(1/\varepsilon)n^{1+\lceil1/\varepsilon\rceil})$ time, where $n$ is the number of data points in $\mathbb{R}^d$. $\bullet$ In the case of Euclidean $k$-medians, generating a candidate set via $n^{\mathcal{O}(1/\varepsilon^2)}$ executions of stochastic gradient descent with adaptively determined constraint sets will once again give approximation $1+\varepsilon$ with $\mathcal{O}(k\log(1/\varepsilon))$ centers in $dk\log(1/\varepsilon)n^{\mathcal{O}(1/\varepsilon^2)}$ time. Ancillary results include: guarantees for cluster costs based on powers of metrics; a brief, favorable empirical evaluation against $\texttt{kmeans++}$; data-dependent bounds allowing $1+\varepsilon$ in the first two bullets above, for example with $k$-medians over finite metric spaces. version:1
arxiv-1607-06190 | An ensemble of machine learning and anti-learning methods for predicting tumour patient survival rates | http://arxiv.org/abs/1607.06190 | id:1607.06190 author:Christopher Roadknight, Durga Suryanarayanan, Uwe Aickelin, John Scholefield, Lindy Durrant category:cs.LG  published:2016-07-21 summary:This paper primarily addresses a dataset relating to cellular, chemical and physical conditions of patients gathered at the time they are operated upon to remove colorectal tumours. This data provides a unique insight into the biochemical and immunological status of patients at the point of tumour removal along with information about tumour classification and post-operative survival. The relationship between severity of tumour, based on TNM staging, and survival is still unclear for patients with TNM stage 2 and 3 tumours. We ask whether it is possible to predict survival rate more accurately using a selection of machine learning techniques applied to subsets of data to gain a deeper understanding of the relationships between a patient's biochemical markers and survival. We use a range of feature selection and single classification techniques to predict the 5 year survival rate of TNM stage 2 and 3 patients which initially produces less than ideal results. The performance of each model individually is then compared with subsets of the data where agreement is reached for multiple models. This novel method of selective ensembling demonstrates that significant improvements in model accuracy on an unseen test set can be achieved for patients where agreement between models is achieved. Finally we point at a possible method to identify whether a patients prognosis can be accurately predicted or not. version:1
arxiv-1607-06182 | Streaming Recommender Systems | http://arxiv.org/abs/1607.06182 | id:1607.06182 author:Shiyu Chang, Yang Zhang, Jiliang Tang, Dawei Yin, Yi Chang, Mark A. Hasegawa-Johnson, Thomas S. Huang category:cs.SI cs.IR cs.LG  published:2016-07-21 summary:The increasing popularity of real-world recommender systems produces data continuously and rapidly, and it becomes more realistic to study recommender systems under streaming scenarios. Data streams present distinct properties such as temporally ordered, continuous and high-velocity, which poses tremendous challenges to traditional recommender systems. In this paper, we investigate the problem of recommendation with stream inputs. In particular, we provide a principled framework termed sRec, which provides explicit continuous-time random process models of the creation of users and topics, and of the evolution of their interests. A variational Bayesian approach called recursive meanfield approximation is proposed, which permits computationally efficient instantaneous on-line inference. Experimental results on several real-world datasets demonstrate the advantages of our sRec over other state-of-the-arts. version:1
arxiv-1607-05447 | On Differentiating Parameterized Argmin and Argmax Problems with Application to Bi-level Optimization | http://arxiv.org/abs/1607.05447 | id:1607.05447 author:Stephen Gould, Basura Fernando, Anoop Cherian, Peter Anderson, Rodrigo Santa Cruz, Edison Guo category:cs.CV math.OC  published:2016-07-19 summary:Some recent works in machine learning and computer vision involve the solution of a bi-level optimization problem. Here the solution of a parameterized lower-level problem binds variables that appear in the objective of an upper-level problem. The lower-level problem typically appears as an argmin or argmax optimization problem. Many techniques have been proposed to solve bi-level optimization problems, including gradient descent, which is popular with current end-to-end learning approaches. In this technical report we collect some results on differentiating argmin and argmax optimization problems with and without constraints and provide some insightful motivating examples. version:2
arxiv-1607-06178 | Feature Descriptors for Tracking by Detection: a Benchmark | http://arxiv.org/abs/1607.06178 | id:1607.06178 author:Alessandro Pieropan, Mårten Björkman, Niklas Bergström, Danica Kragic category:cs.CV  published:2016-07-21 summary:In this paper, we provide an extensive evaluation of the performance of local descriptors for tracking applications. Many different descriptors have been proposed in the literature for a wide range of application in computer vision such as object recognition and 3D reconstruction. More recently, due to fast key-point detectors, local image features can be used in online tracking frameworks. However, while much effort has been spent on evaluating their performance in terms of distinctiveness and robustness to image transformations, very little has been done in the contest of tracking. Our evaluation is performed in terms of distinctiveness, tracking precision and tracking speed. Our results show that binary descriptors like ORB or BRISK have comparable results to SIFT or AKAZE due to a higher number of key-points. version:1
arxiv-1607-06657 | e-Distance Weighted Support Vector Regression | http://arxiv.org/abs/1607.06657 | id:1607.06657 author:Yan Wang, Ge Ou category:cs.LG  published:2016-07-21 summary:We propose a novel support vector regression approach called e-Distance Weighted Support Vector Regression (e-DWSVR).e-DWSVR specifically addresses two challenging issues in support vector regression: first, the process of noisy data; second, how to deal with the situation when the distribution of boundary data is different from that of the overall data. The proposed e-DWSVR optimizes the minimum margin and the mean of functional margin simultaneously to tackle these two issues. In addition, we use both dual coordinate descent (CD) and averaged stochastic gradient descent (ASGD) strategies to make e-DWSVR scalable to large scale problems. We report promising results obtained by e-DWSVR in comparison with existing methods on several benchmark datasets. version:1
arxiv-1607-05695 | FusionNet: 3D Object Classification Using Multiple Data Representations | http://arxiv.org/abs/1607.05695 | id:1607.05695 author:Vishakh Hegde, Reza Zadeh category:cs.CV  published:2016-07-19 summary:High-quality 3D object recognition is an important component of many vision and robotics systems. We tackle the object recognition problem using two data representations, to achieve leading results on the Princeton ModelNet challenge. The two representations: 1. Volumetric representation: the 3D object is discretized spatially as binary voxels - $1$ if the voxel is occupied and $0$ otherwise. 2. Pixel representation: the 3D object is represented as a set of projected 2D pixel images. Current leading submissions to the ModelNet Challenge use Convolutional Neural Networks (CNNs) on pixel representations. However, we diverge from this trend and additionally, use Volumetric CNNs to bridge the gap between the efficiency of the above two representations. We combine both representations and exploit them to learn new features, which yield a significantly better classifier than using either of the representations in isolation. To do this, we introduce new Volumetric CNN (V-CNN) architectures. version:2
arxiv-1607-06166 | Local Multiple Directional Pattern of Palmprint Image | http://arxiv.org/abs/1607.06166 | id:1607.06166 author:Lunke Fei, Jie Wen, Zheng Zhang, Ke Yan, Zuofeng Zhong category:cs.CV  published:2016-07-21 summary:Lines are the most essential and discriminative features of palmprint images, which motivate researches to propose various line direction based methods for palmprint recognition. Conventional methods usually capture the only one of the most dominant direction of palmprint images. However, a number of points in palmprint images have double or even more than two dominant directions because of a plenty of crossing lines of palmprint images. In this paper, we propose a local multiple directional pattern (LMDP) to effectively characterize the multiple direction features of palmprint images. LMDP can not only exactly denote the number and positions of dominant directions but also effectively reflect the confidence of each dominant direction. Then, a simple and effective coding scheme is designed to represent the LMDP and a block-wise LMDP descriptor is used as the feature space of palmprint images in palmprint recognition. Extensive experimental results demonstrate the superiority of the LMDP over the conventional powerful descriptors and the state-of-the-art direction based methods in palmprint recognition. version:1
arxiv-1607-06153 | Compositional Sequence Labeling Models for Error Detection in Learner Writing | http://arxiv.org/abs/1607.06153 | id:1607.06153 author:Marek Rei, Helen Yannakoudakis category:cs.CL cs.NE I.5.1; I.2.6; I.2.7  published:2016-07-20 summary:In this paper, we present the first experiments using neural network models for the task of error detection in learner writing. We perform a systematic comparison of alternative compositional architectures and propose a framework for error detection based on bidirectional LSTMs. Experiments on the CoNLL-14 shared task dataset show the model is able to outperform other participants on detecting errors in learner writing. Finally, the model is integrated with a publicly deployed self-assessment system, leading to performance comparable to human annotators. version:1
arxiv-1607-06146 | Supervised quantum gate "teaching" for quantum hardware design | http://arxiv.org/abs/1607.06146 | id:1607.06146 author:Leonardo Banchi, Nicola Pancotti, Sougato Bose category:cs.LG quant-ph stat.ML  published:2016-07-20 summary:We show how to train a quantum network of pairwise interacting qubits such that its evolution implements a target quantum algorithm into a given network subset. Our strategy is inspired by supervised learning and is designed to help the physical construction of a quantum computer which operates with minimal external classical control. version:1
arxiv-1607-06144 | Learning the Roots of Visual Domain Shift | http://arxiv.org/abs/1607.06144 | id:1607.06144 author:Tatiana Tommasi, Martina Lanzi, Paolo Russo, Barbara Caputo category:cs.CV  published:2016-07-20 summary:In this paper we focus on the spatial nature of visual domain shift, attempting to learn where domain adaptation originates in each given image of the source and target set. We borrow concepts and techniques from the CNN visualization literature, and learn domainnes maps able to localize the degree of domain specificity in images. We derive from these maps features related to different domainnes levels, and we show that by considering them as a preprocessing step for a domain adaptation algorithm, the final classification performance is strongly improved. Combined with the whole image representation, these features provide state of the art results on the Office dataset. version:1
arxiv-1607-06140 | A Haar Wavelet-Based Perceptual Similarity Index for Image Quality Assessment | http://arxiv.org/abs/1607.06140 | id:1607.06140 author:Rafael Reisenhofer, Sebastian Bosse, Gitta Kutyniok, Thomas Wiegand category:cs.CV  published:2016-07-20 summary:In most practical situations, images and videos can neither be compressed nor transmitted without introducing distortions that will eventually be perceived by a human observer. Vice versa, most applications of image and video restoration techniques, such as inpainting or denoising, aim to enhance the quality of experience of human viewers. Correctly predicting the similarity of an image with an undistorted reference image, as subjectively experienced by a human viewer, can thus lead to significant improvements in any transmission, compression, or restoration system. This paper introduces the Haar wavelet-based perceptual similarity index (HaarPSI), a novel and easy-to-compute similarity measure for full reference image quality assessment. HaarPSI utilizes the coefficients obtained from a Haar wavelet decomposition to assess local similarities between two images, as well as the relative importance of image areas. The consistency of HaarPSI with human quality of experience was validated on four large benchmark databases containing several thousands of differently distorted images. On these databases, HaarPSI achieves higher correlations with human opinion scores than state-of-the-art full reference similarity measures like the structural similarity index (SSIM), the feature similarity index (FSIM), and the visual saliency-based index (VSI). Along with the simple computational structure and the short execution time, these promising experimental results suggest a high applicability of HaarPSI in real world tasks. version:1
arxiv-1607-06125 | Sequence to sequence learning for unconstrained scene text recognition | http://arxiv.org/abs/1607.06125 | id:1607.06125 author:Ahmed Mamdouh A. Hassanien category:cs.CV cs.LG cs.NE  published:2016-07-20 summary:In this work we present a state-of-the-art approach for unconstrained natural scene text recognition. We propose a cascade approach that incorporates a convolutional neural network (CNN) architecture followed by a long short term memory model (LSTM). The CNN learns visual features for the characters and uses them with a softmax layer to detect sequence of characters. While the CNN gives very good recognition results, it does not model relation between characters, hence gives rise to false positive and false negative cases (confusing characters due to visual similarities like "g" and "9", or confusing background patches with characters; either removing existing characters or adding non-existing ones) To alleviate these problems we leverage recent developments in LSTM architectures to encode contextual information. We show that the LSTM can dramatically reduce such errors and achieve state-of-the-art accuracy in the task of unconstrained natural scene text recognition. Moreover we manually remove all occurrences of the words that exist in the test set from our training set to test whether our approach will generalize to unseen data. We use the ICDAR 13 test set for evaluation and compare the results with the state of the art approaches [11, 18]. We finally present an application of the work in the domain of for traffic monitoring. version:1
arxiv-1607-06123 | Predicting Branch Visits and Upselling using Temporal Banking Data | http://arxiv.org/abs/1607.06123 | id:1607.06123 author:Sandra Mitrović, Gaurav Singh category:cs.LG  published:2016-07-20 summary:There is an abundance of temporal and non-temporal data in banking (and other industries), but such temporal activity data can not be used directly with classical machine learning models. In this work, we perform extensive feature extraction from the temporal user activity data in an attempt to predict user visits to different branches and credit card upselling as part of \emph{ECML/PKDD Discovery Challenge 2016}. Our solution ranked \nth{4} for \emph{Task 1} and achieved an AUC of \textbf{$0.7056$} for \emph{Task 2} on public leaderboard. version:1
arxiv-1607-05418 | Runtime Configurable Deep Neural Networks for Energy-Accuracy Trade-off | http://arxiv.org/abs/1607.05418 | id:1607.05418 author:Hokchhay Tann, Soheil Hashemi, R. Iris Bahar, Sherief Reda category:cs.NE cs.CV  published:2016-07-19 summary:We present a novel dynamic configuration technique for deep neural networks that permits step-wise energy-accuracy trade-offs during runtime. Our configuration technique adjusts the number of channels in the network dynamically depending on response time, power, and accuracy targets. To enable this dynamic configuration technique, we co-design a new training algorithm, where the network is incrementally trained such that the weights in channels trained in earlier steps are fixed. Our technique provides the flexibility of multiple networks while storing and utilizing one set of weights. We evaluate our techniques using both an ASIC-based hardware accelerator as well as a low-power embedded GPGPU and show that our approach leads to only a small or negligible loss in the final network accuracy. We analyze the performance of our proposed methodology using three well-known networks for MNIST, CIFAR-10, and SVHN datasets, and we show that we are able to achieve up to 95% energy reduction with less than 1% accuracy loss across the three benchmarks. In addition, compared to prior work on dynamic network reconfiguration, we show that our approach leads to approximately 50% savings in storage requirements, while achieving similar accuracy. version:2
arxiv-1607-07427 | Mesh Denoising based on Normal Voting Tensor and Binary Optimization | http://arxiv.org/abs/1607.07427 | id:1607.07427 author:S. K. Yadav, U. Reitebuch, K. Polthier category:cs.CV cs.GR math.DG  published:2016-07-20 summary:This paper presents a tensor multiplication based smoothing algorithm that follows a two step denoising method. Unlike other traditional averaging approaches, our approach uses an element based normal voting tensor to compute smooth surfaces. By introducing a binary optimization on the proposed tensor together with a local binary neighborhood concept, our algorithm better retains sharp features and produces smoother umbilical regions than previous approaches. On top of that, we provide a stochastic analysis on the different kinds of noise based on the average edge length. The quantitative and visual results demonstrate the performance our method is better compared to state of the art smoothing approaches. version:1
arxiv-1607-06062 | Hashmod: A Hashing Method for Scalable 3D Object Detection | http://arxiv.org/abs/1607.06062 | id:1607.06062 author:Wadim Kehl, Federico Tombari, Nassir Navab, Slobodan Ilic, Vincent Lepetit category:cs.CV  published:2016-07-20 summary:We present a scalable method for detecting objects and estimating their 3D poses in RGB-D data. To this end, we rely on an efficient representation of object views and employ hashing techniques to match these views against the input frame in a scalable way. While a similar approach already exists for 2D detection, we show how to extend it to estimate the 3D pose of the detected objects. In particular, we explore different hashing strategies and identify the one which is more suitable to our problem. We show empirically that the complexity of our method is sublinear with the number of objects and we enable detection and pose estimation of many 3D objects with high accuracy while outperforming the state-of-the-art in terms of runtime. version:1
arxiv-1607-06038 | Deep Learning of Local RGB-D Patches for 3D Object Detection and 6D Pose Estimation | http://arxiv.org/abs/1607.06038 | id:1607.06038 author:Wadim Kehl, Fausto Milletari, Federico Tombari, Slobodan Ilic, Nassir Navab category:cs.CV  published:2016-07-20 summary:We present a 3D object detection method that uses regressed descriptors of locally-sampled RGB-D patches for 6D vote casting. For regression, we employ a convolutional auto-encoder that has been trained on a large collection of random local patches. During testing, scene patch descriptors are matched against a database of synthetic model view patches and cast 6D object votes which are subsequently filtered to refined hypotheses. We evaluate on three datasets to show that our method generalizes well to previously unseen input data, delivers robust detection results that compete with and surpass the state-of-the-art while being scalable in the number of objects. version:1
arxiv-1607-06029 | Automatic Detection of Solar Photovoltaic Arrays in High Resolution Aerial Imagery | http://arxiv.org/abs/1607.06029 | id:1607.06029 author:Jordan M. Malof, Kyle Bradbury, Leslie M. Collins, Richard G. Newell category:cs.CV  published:2016-07-20 summary:The quantity of small scale solar photovoltaic (PV) arrays in the United States has grown rapidly in recent years. As a result, there is substantial interest in high quality information about the quantity, power capacity, and energy generated by such arrays, including at a high spatial resolution (e.g., counties, cities, or even smaller regions). Unfortunately, existing methods for obtaining this information, such as surveys and utility interconnection filings, are limited in their completeness and spatial resolution. This work presents a computer algorithm that automatically detects PV panels using very high resolution color satellite imagery. The approach potentially offers a fast, scalable method for obtaining accurate information on PV array location and size, and at much higher spatial resolutions than are currently available. The method is validated using a very large (135 km^2) collection of publicly available [1] aerial imagery, with over 2,700 human annotated PV array locations. The results demonstrate the algorithm is highly effective on a per-pixel basis. It is likewise effective at object-level PV array detection, but with significant potential for improvement in estimating the precise shape/size of the PV arrays. These results are the first of their kind for the detection of solar PV in aerial imagery, demonstrating the feasibility of the approach and establishing a baseline performance for future investigations. version:1
arxiv-1607-06025 | Constructing a Natural Language Inference Dataset using Generative Neural Networks | http://arxiv.org/abs/1607.06025 | id:1607.06025 author:Janez Starc, Dunja Mladenić category:cs.AI cs.CL cs.NE  published:2016-07-20 summary:Natural Language Inference is an important task for Natural Language Understanding. It is concerned with classifying the logical relation between two sentences. In this paper, we propose several text generative neural networks for constructing Natural Language Inference datasets suitable for training classifiers. To evaluate the models, we propose a new metric - the accuracy of the classifier trained on the generated dataset. The accuracy obtained with our best generative model is only 2.7% lower than the accuracy of the classifier trained on the original, manually constructed dataset. The model learns a mapping embedding for each training example. By comparing various metrics we show that datasets that obtain higher ROUGE or METEOR scores do not necessarily yield higher classification accuracies. We also provide analysis of what are the characteristics of a good dataset including the distinguishability of the generated datasets from the original one. version:1
arxiv-1607-06017 | Doubly Accelerated Methods for Faster CCA and Generalized Eigendecomposition | http://arxiv.org/abs/1607.06017 | id:1607.06017 author:Zeyuan Allen-Zhu, Yuanzhi Li category:math.OC cs.DS cs.LG stat.ML  published:2016-07-20 summary:We study $k$-GenEV, the problem of finding the top $k$ generalized eigenvectors, and $k$-CCA, the problem of finding the top $k$ vectors in canonical-correlation analysis. We propose algorithms $\mathtt{LazyEV}$ and $\mathtt{LazyCCA}$ to solve the two problems with running times linearly dependent on the input size and on $k$. Furthermore, our algorithms are DOUBLY-ACCELERATED: our running times depend only on the square root of the matrix condition number, and on the square root of the eigengap. This is the first such result for both $k$-GenEV or $k$-CCA. We also provide the first gap-free results, which provide running times that depend on $1/\sqrt{\varepsilon}$ rather than the eigengap. version:1
arxiv-1607-06011 | On the Modeling of Error Functions as High Dimensional Landscapes for Weight Initialization in Learning Networks | http://arxiv.org/abs/1607.06011 | id:1607.06011 author:Julius, Gopinath Mahale, Sumana T., C. S. Adityakrishna category:cs.LG cs.CV physics.data-an stat.ML  published:2016-07-20 summary:Next generation deep neural networks for classification hosted on embedded platforms will rely on fast, efficient, and accurate learning algorithms. Initialization of weights in learning networks has a great impact on the classification accuracy. In this paper we focus on deriving good initial weights by modeling the error function of a deep neural network as a high-dimensional landscape. We observe that due to the inherent complexity in its algebraic structure, such an error function may conform to general results of the statistics of large systems. To this end we apply some results from Random Matrix Theory to analyse these functions. We model the error function in terms of a Hamiltonian in N-dimensions and derive some theoretical results about its general behavior. These results are further used to make better initial guesses of weights for the learning algorithm. version:1
arxiv-1607-05975 | Person Re-identification for Real-world Surveillance Systems | http://arxiv.org/abs/1607.05975 | id:1607.05975 author:Furqan M. Khan, Francois Bremond category:cs.CV I.2.10  published:2016-07-20 summary:Appearance based person re-identification in a real-world video surveillance system with non-overlapping camera views is a challenging problem for many reasons. Current state-of-the-art methods often address the problem by relying on supervised learning of similarity metrics or ranking functions to implicitly model appearance transformation between cameras for each camera pair, or group, in the system. This requires considerable human effort to annotate data. Furthermore, the learned models are camera specific and not transferable from one set of cameras to another. Therefore, the annotation process is required after every network expansion or camera replacement, which strongly limits their applicability. Alternatively, we propose a novel modeling approach to harness complementary appearance information without supervised learning that significantly outperforms current state-of-the-art unsupervised methods on multiple benchmark datasets. version:1
arxiv-1607-05974 | Anomaly Detection and Localisation using Mixed Graphical Models | http://arxiv.org/abs/1607.05974 | id:1607.05974 author:Romain Laby, François Roueff, Alexandre Gramfort category:stat.ML  published:2016-07-20 summary:We propose a method that performs anomaly detection and localisation within heterogeneous data using a pairwise undirected mixed graphical model. The data are a mixture of categorical and quantitative variables, and the model is learned over a dataset that is supposed not to contain any anomaly. We then use the model over temporal data, potentially a data stream, using a version of the two-sided CUSUM algorithm. The proposed decision statistic is based on a conditional likelihood ratio computed for each variable given the others. Our results show that this function allows to detect anomalies variable by variable, and thus to localise the variables involved in the anomalies more precisely than univariate methods based on simple marginals. version:1
arxiv-1607-05970 | On the Identification and Mitigation of Weaknesses in the Knowledge Gradient Policy for Multi-Armed Bandits | http://arxiv.org/abs/1607.05970 | id:1607.05970 author:James Edwards, Paul Fearnhead, Kevin Glazebrook category:stat.ML cs.LG  published:2016-07-20 summary:The Knowledge Gradient (KG) policy was originally proposed for online ranking and selection problems but has recently been adapted for use in online decision making in general and multi-armed bandit problems (MABs) in particular. We study its use in a class of exponential family MABs and identify weaknesses, including a propensity to take actions which are dominated with respect to both exploitation and exploration. We propose variants of KG which avoid such errors. These new policies include an index heuristic which deploys a KG approach to develop an approximation to the Gittins index. A numerical study shows this policy to perform well over a range of MABs including those for which index policies are not optimal. While KG does not make dominated actions when bandits are Gaussian, it fails to be index consistent and appears not to enjoy a performance advantage over competitor policies when arms are correlated to compensate for its greater computational demands. version:1
arxiv-1607-05969 | 4D Cardiac Ultrasound Standard Plane Location by Spatial-Temporal Correlation | http://arxiv.org/abs/1607.05969 | id:1607.05969 author:Yun Gu, Guang-Zhong Yang, Jie Yang, Kun Sun category:cs.CV  published:2016-07-20 summary:Echocardiography plays an important part in diagnostic aid in cardiac diseases. A critical step in echocardiography-aided diagnosis is to extract the standard planes since they tend to provide promising views to present different structures that are benefit to diagnosis. To this end, this paper proposes a spatial-temporal embedding framework to extract the standard view planes from 4D STIC (spatial-temporal image corre- lation) volumes. The proposed method is comprised of three stages, the frame smoothing, spatial-temporal embedding and final classification. In first stage, an L 0 smoothing filter is used to preprocess the frames that removes the noise and preserves the boundary. Then a compact repre- sentation is learned via embedding spatial and temporal features into a latent space in the supervised scheme considering both standard plane information and diagnosis result. In last stage, the learned features are fed into support vector machine to identify the standard plane. We eval- uate the proposed method on a 4D STIC volume dataset with 92 normal cases and 93 abnormal cases in three standard planes. It demonstrates that our method outperforms the baselines in both classification accuracy and computational efficiency. version:1
arxiv-1607-05968 | Robust Natural Language Processing - Combining Reasoning, Cognitive Semantics and Construction Grammar for Spatial Language | http://arxiv.org/abs/1607.05968 | id:1607.05968 author:Michael Spranger, Jakob Suchan, Mehul Bhatt category:cs.AI cs.CL  published:2016-07-20 summary:We present a system for generating and understanding of dynamic and static spatial relations in robotic interaction setups. Robots describe an environment of moving blocks using English phrases that include spatial relations such as "across" and "in front of". We evaluate the system in robot-robot interactions and show that the system can robustly deal with visual perception errors, language omissions and ungrammatical utterances. version:1
arxiv-1607-05967 | Interactive Illumination Invariance | http://arxiv.org/abs/1607.05967 | id:1607.05967 author:Han Gong, Graham Finlayson category:cs.CV  published:2016-07-20 summary:Illumination effects cause problems for many computer vision algorithms. We present a user-friendly interactive system for robust illumination-invariant image generation. Compared with the previous automated illumination-invariant image derivation approaches, our system enables users to specify a particular kind of illumination variation for removal. The derivation of illumination-invariant image is guided by the user input. The input is a stroke that defines an area covering a set of pixels whose intensities are influenced predominately by the illumination variation. This additional flexibility enhances the robustness for processing non-linearly rendered images and the images of the scenes where their illumination variations are difficult to estimate automatically. Finally, we present some evaluation results of our method. version:1
arxiv-1607-05966 | Onsager-corrected deep learning for sparse linear inverse problems | http://arxiv.org/abs/1607.05966 | id:1607.05966 author:Mark Borgerding, Philip Schniter category:cs.IT cs.LG math.IT stat.ML  published:2016-07-20 summary:Deep learning has gained great popularity due to its widespread success on many inference problems. We consider the application of deep learning to the sparse linear inverse problem encountered in compressive sensing, where one seeks to recover a sparse signal from a small number of noisy linear measurements. In this paper, we propose a novel neural-network architecture that decouples prediction errors across layers in the same way that the approximate message passing (AMP) algorithm decouples them across iterations: through Onsager correction. Numerical experiments suggest that our "learned AMP" network significantly improves upon Gregor and LeCun's "learned ISTA" network in both accuracy and complexity. version:1
arxiv-1607-04315 | Neural Semantic Encoders | http://arxiv.org/abs/1607.04315 | id:1607.04315 author:Tsendsuren Munkhdalai, Hong Yu category:cs.LG cs.CL stat.ML  published:2016-07-14 summary:We present a memory augmented neural network for natural language understanding: Neural Semantic Encoders (NSE). NSE has a variable sized encoding memory that evolves over time and maintains the understanding of input sequences through read, compose and write operations. NSE can access multiple and shared memories depending on the complexity of a task. We demonstrated the effectiveness and the flexibility of NSE on five different natural language tasks, natural language inference, question answering, sentence classification, document sentiment analysis and machine translation where NSE achieved state-of-the-art performance when evaluated on publically available benchmarks. For example, our shared-memory model showed an encouraging result on neural machine translation, improving an attention-based baseline by approximately 1.0 BLEU. version:2
arxiv-1607-05962 | Indoor occupancy estimation from carbon dioxide concentration | http://arxiv.org/abs/1607.05962 | id:1607.05962 author:Chaoyang Jiang, Mustafa K. Masood, Yeng Chai Soh, Hua Li category:cs.SY cs.LG  published:2016-07-20 summary:This paper presents an indoor occupancy estimator with which we can estimate the number of real-time indoor occupants based on the carbon dioxide (CO2) measurement. The estimator is actually a dynamic model of the occupancy level. To identify the dynamic model, we propose the Feature Scaled Extreme Learning Machine (FS-ELM) algorithm, which is a variation of the standard Extreme Learning Machine (ELM) but is shown to perform better for the occupancy estimation problem. The measured CO2 concentration suffers from serious spikes. We find that pre-smoothing the CO2 data can greatly improve the estimation accuracy. In real applications, however, we cannot obtain the real-time globally smoothed CO2 data. We provide a way to use the locally smoothed CO2 data instead, which is real-time available. We introduce a new criterion, i.e. $x$-tolerance accuracy, to assess the occupancy estimator. The proposed occupancy estimator was tested in an office room with 24 cubicles and 11 open seats. The accuracy is up to 94 percent with a tolerance of four occupants. version:1
arxiv-1607-05944 | The encoding of proprioceptive inputs in the brain: knowns and unknowns from a robotic perspective | http://arxiv.org/abs/1607.05944 | id:1607.05944 author:Matej Hoffmann, Nada Bednarova category:cs.NE cs.RO 68T40  published:2016-07-20 summary:Somatosensory inputs can be grossly divided into tactile (or cutaneous) and proprioceptive -- the former conveying information about skin stimulation, the latter about limb position and movement. The principal proprioceptors are constituted by muscle spindles, which deliver information about muscle length and speed. In primates, this information is relayed to the primary somatosensory cortex and eventually the posterior parietal cortex, where integrated information about body posture (postural schema) is presumably available. However, coming from robotics and seeking a biologically motivated model that could be used in a humanoid robot, we faced a number of difficulties. First, it is not clear what neurons in the ascending pathway and primary somatosensory cortex code. To an engineer, joint angles would seem the most useful variables. However, the lengths of individual muscles have nonlinear relationships with the angles at joints. Kim et al. (Neuron, 2015) found different types of proprioceptive neurons in the primary somatosensory cortex -- sensitive to movement of single or multiple joints or to static postures. Second, there are indications that the somatotopic arrangement ("the homunculus") of these brain areas is to a significant extent learned. However, the mechanisms behind this developmental process are unclear. We will report first results from modeling of this process using data obtained from body babbling in the iCub humanoid robot and feeding them into a Self-Organizing Map (SOM). Our results reveal that the SOM algorithm is only suited to develop receptive fields of the posture-selective type. Furthermore, the SOM algorithm has intrinsic difficulties when combined with population code on its input and in particular with nonlinear tuning curves (sigmoids or Gaussians). version:1
arxiv-1607-05910 | Visual Question Answering: A Survey of Methods and Datasets | http://arxiv.org/abs/1607.05910 | id:1607.05910 author:Qi Wu, Damien Teney, Peng Wang, Chunhua Shen, Anthony Dick, Anton van den Hengel category:cs.CV  published:2016-07-20 summary:Visual Question Answering (VQA) is a challenging task that has received increasing attention from both the computer vision and the natural language processing communities. Given an image and a question in natural language, it requires reasoning over visual elements of the image and general knowledge to infer the correct answer. In the first part of this survey, we examine the state of the art by comparing modern approaches to the problem. We classify methods by their mechanism to connect the visual and textual modalities. In particular, we examine the common approach of combining convolutional and recurrent neural networks to map images and questions to a common feature space. We also discuss memory-augmented and modular architectures that interface with structured knowledge bases. In the second part of this survey, we review the datasets available for training and evaluating VQA systems. The various datatsets contain questions at different levels of complexity, which require different capabilities and types of reasoning. We examine in depth the question/answer pairs from the Visual Genome project, and evaluate the relevance of the structured annotations of images with scene graphs for VQA. Finally, we discuss promising future directions for the field, in particular the connection to structured knowledge bases and the use of natural language processing models. version:1
arxiv-1607-05851 | Learning to Recognize Objects by Retaining other Factors of Variation | http://arxiv.org/abs/1607.05851 | id:1607.05851 author:Jiaping Zhao, Chin-kai Chang, Laurent Itti category:cs.CV  published:2016-07-20 summary:Natural images are generated under many factors, including shape, pose, illumination etc. Most existing ConvNets formulate object recognition from natural images as a single task classification problem, and attempt to learn features useful for object categories, but invariant to other factors of variation as much as possible. These architectures do not explicitly learn other factors, like pose and lighting, instead, they usually discard them by pooling and normalization. In this work, we take the opposite approach: we train ConvNets for object recognition by retaining other factors (pose in our case) and learn them jointly with object category. We design a new multi-task leaning (MTL) ConvNet, named disentangling CNN (disCNN), which explicitly enforces the disentangled representations of object identity and pose, and is trained to predict object categories and pose transformations. We show that disCNN achieves significantly better object recognition accuracies than AlexNet trained solely to predict object categories on the iLab-20M dataset, which is a large scale turntable dataset with detailed object pose and lighting information. We further show that the pretrained disCNN/AlexNet features on iLab- 20M generalize to object recognition on both Washington RGB-D and ImageNet datasets, and the pretrained disCNN features are significantly better than the pretrained AlexNet features for fine-tuning object recognition on the ImageNet dataset. version:1
arxiv-1607-05839 | Superpixel-based Two-view Deterministic Fitting for Multiple-structure Data | http://arxiv.org/abs/1607.05839 | id:1607.05839 author:Guobao Xiao, Hanzi Wang, Yan Yan, David Suter category:cs.CV  published:2016-07-20 summary:This paper proposes a two-view deterministic geometric model fitting method, termed Superpixel-based Deterministic Fitting (SDF), for multiple-structure data. SDF starts from superpixel segmentation, which effectively captures prior information of feature appearances. The feature appearances are beneficial to reduce the computational complexity for deterministic fitting methods. SDF also includes two original elements, i.e., a deterministic sampling algorithm and a novel model selection algorithm. The two algorithms are tightly coupled to boost the performance of SDF in both speed and accuracy. Specifically, the proposed sampling algorithm leverages the grouping cues of superpixels to generate reliable and consistent hypotheses. The proposed model selection algorithm further makes use of desirable properties of the generated hypotheses, to improve the conventional fit-and-remove framework for more efficient and effective performance. The key characteristic of SDF is that it can efficiently and deterministically estimate the parameters of model instances in multi-structure data. Experimental results demonstrate that the proposed SDF shows superiority over several state-of-the-art fitting methods for real images with single-structure and multiple-structure data. version:1
arxiv-1607-05836 | Improved Deep Learning of Object Category using Pose Information | http://arxiv.org/abs/1607.05836 | id:1607.05836 author:Jiaping Zhao, Laurent Itti category:cs.CV  published:2016-07-20 summary:Despite significant recent progress, the best available computer vision algorithms still lag far behind human capabilities, even for recognizing individual discrete objects under various poses, illuminations, and backgrounds. Here we present a new approach to using object pose information to improve deep network learning. While existing large-scale datasets, e.g. ImageNet, do not have pose information, we leverage the newly published turntable dataset, iLab-20M, which has ~22M images of 704 object instances shot under different lightings, camera viewpoints and turntable rotations, to do more controlled object recognition experiments. We introduce a new convolutional neural network architecture, what/where CNN (2W-CNN), built on a linear-chain feedforward CNN (e.g., AlexNet), augmented by hierarchical layers regularized by object poses. Pose information is only used as feedback signal during training, in addition to category information; during test, the feedforward network only predicts category. To validate the approach, we train both 2W-CNN and AlexNet using a fraction of the dataset, and 2W-CNN achieves 6% performance improvement in category prediction. We show mathematically that 2W-CNN has inherent advantages over AlexNet under the stochastic gradient descent (SGD) optimization procedure. Further more, we fine-tune object recognition on ImageNet by using the pretrained 2W-CNN and AlexNet features on iLab-20M, results show that significant improvements have been achieved, compared with training AlexNet from scratch. Moreover, fine-tuning 2W-CNN features performs even better than fine-tuning the pretrained AlexNet features. These results show pretrained features on iLab- 20M generalizes well to natural image datasets, and 2WCNN learns even better features for object recognition than AlexNet. version:1
arxiv-1607-05832 | Personalization Effect on Emotion Recognition from Physiological Data: An Investigation of Performance on Different Setups and Classifiers | http://arxiv.org/abs/1607.05832 | id:1607.05832 author:Varvara Kollia category:stat.ML cs.HC  published:2016-07-20 summary:This paper addresses the problem of emotion recognition from physiological signals. Features are extracted and ranked based on their effect on classification accuracy. Different classifiers are compared. The inter-subject variability and the personalization effect are thoroughly investigated, through trial-based and subject-based cross-validation. Finally, a personalized model is introduced, that would allow for enhanced emotional state prediction, based on the physiological data of subjects that exhibit a certain degree of similarity, without the requirement of further feedback. version:1
arxiv-1607-05822 | Incremental Learning for Fully Unsupervised Word Segmentation Using Penalized Likelihood and Model Selection | http://arxiv.org/abs/1607.05822 | id:1607.05822 author:Ruey-Cheng Chen category:cs.CL  published:2016-07-20 summary:We present a novel incremental learning approach for unsupervised word segmentation that combines features from probabilistic modeling and model selection. This includes super-additive penalties for addressing the cognitive burden imposed by long word formation, and new model selection criteria based on higher-order generative assumptions. Our approach is fully unsupervised; it relies on a small number of parameters that permits flexible modeling and a mechanism that automatically learns parameters from the data. Through experimentation, we show that this intricate design has led to top-tier performance in both phonemic and orthographic word segmentation. version:1
arxiv-1607-05818 | An Adaptation of Topic Modeling to Sentences | http://arxiv.org/abs/1607.05818 | id:1607.05818 author:Ruey-Cheng Chen, Reid Swanson, Andrew S. Gordon category:cs.CL  published:2016-07-20 summary:Advances in topic modeling have yielded effective methods for characterizing the latent semantics of textual data. However, applying standard topic modeling approaches to sentence-level tasks introduces a number of challenges. In this paper, we adapt the approach of latent-Dirichlet allocation to include an additional layer for incorporating information about the sentence boundaries in documents. We show that the addition of this minimal information of document structure improves the perplexity results of a trained model. version:1
arxiv-1607-05809 | Neural Contextual Conversation Learning with Labeled Question-Answering Pairs | http://arxiv.org/abs/1607.05809 | id:1607.05809 author:Kun Xiong, Anqi Cui, Zefeng Zhang, Ming Li category:cs.CL cs.AI  published:2016-07-20 summary:Neural conversational models tend to produce generic or safe responses in different contexts, e.g., reply \textit{"Of course"} to narrative statements or \textit{"I don't know"} to questions. In this paper, we propose an end-to-end approach to avoid such problem in neural generative models. Additional memory mechanisms have been introduced to standard sequence-to-sequence (seq2seq) models, so that context can be considered while generating sentences. Three seq2seq models, which memorize a fix-sized contextual vector from hidden input, hidden input/output and a gated contextual attention structure respectively, have been trained and tested on a dataset of labeled question-answering pairs in Chinese. The model with contextual attention outperforms others including the state-of-the-art seq2seq models on perplexity test. The novel contextual model generates diverse and robust responses, and is able to carry out conversations on a wide range of topics appropriately. version:1
arxiv-1607-06318 | Hierarchical Manifold Clustering on Diffusion Maps for Connectomics (MIT 18.S096 final project) | http://arxiv.org/abs/1607.06318 | id:1607.06318 author:Gergely Odor category:cs.CV  published:2016-07-20 summary:In this paper, we introduce a novel algorithm for segmentation of imperfect boundary probability maps (BPM) in connectomics. Our algorithm can be a considered as an extension of spectral clustering. Instead of clustering the diffusion maps with traditional clustering algorithms, we learn the manifold and compute an estimate of the minimum normalized cut. We proceed by divide and conquer. We also introduce a novel criterion for determining if further splits are necessary in a component based on it's topological properties. Our algorithm complements the currently popular agglomeration approaches in connectomics, which overlook the geometrical aspects of this segmentation problem. version:1
arxiv-1607-05781 | Spatially Supervised Recurrent Convolutional Neural Networks for Visual Object Tracking | http://arxiv.org/abs/1607.05781 | id:1607.05781 author:Guanghan Ning, Zhi Zhang, Chen Huang, Zhihai He, Xiaobo Ren, Haohong Wang category:cs.CV  published:2016-07-19 summary:In this paper, we develop a new approach of spatially supervised recurrent convolutional neural networks for visual object tracking. Our recurrent convolutional network exploits the history of locations as well as the distinctive visual features learned by the deep neural networks. Inspired by recent bounding box regression methods for object detection, we study the regression capability of Long Short-Term Memory (LSTM) in the temporal domain, and propose to concatenate high-level visual features produced by convolutional networks with region information. In contrast to existing deep learning based trackers that use binary classification for region candidates, we use regression for direct prediction of the tracking locations both at the convolutional layer and at the recurrent unit. Our extensive experimental results and performance comparison with state-of-the-art tracking methods on challenging benchmark video tracking datasets shows that our tracker is more accurate and robust while maintaining low computational cost. For most test video sequences, our method achieves the best tracking performance, often outperforms the second best by a large margin. version:1
arxiv-1607-05749 | PRIIME: A Generic Framework for Interactive Personalized Interesting Pattern Discovery | http://arxiv.org/abs/1607.05749 | id:1607.05749 author:Mansurul Bhuiyan, Mohammad Al Hasan category:cs.LG  published:2016-07-19 summary:The traditional frequent pattern mining algorithms generate an exponentially large number of patterns of which a substantial proportion are not much significant for many data analysis endeavors. Discovery of a small number of personalized interesting patterns from the large output set according to a particular user's interest is an important as well as challenging task. Existing works on pattern summarization do not solve this problem from the personalization viewpoint. In this work, we propose an interactive pattern discovery framework named PRIIME which identifies a set of interesting patterns for a specific user without requiring any prior input on the interestingness measure of patterns from the user. The proposed framework is generic to support discovery of the interesting set, sequence and graph type patterns. We develop a softmax classification based iterative learning algorithm that uses a limited number of interactive feedback from the user to learn her interestingness profile, and use this profile for pattern recommendation. To handle sequence and graph type patterns PRIIME adopts a neural net (NN) based unsupervised feature construction approach. We also develop a strategy that combines exploration and exploitation to select patterns for feedback. We show experimental results on several real-life datasets to validate the performance of the proposed method. We also compare with the existing methods of interactive pattern discovery to show that our method is substantially superior in performance. To portray the applicability of the framework, we present a case study from the real-estate domain. version:1
arxiv-1607-03738 | Do semantic parts emerge in Convolutional Neural Networks? | http://arxiv.org/abs/1607.03738 | id:1607.03738 author:Abel Gonzalez-Garcia, Davide Modolo, Vittorio Ferrari category:cs.CV  published:2016-07-13 summary:Semantic object parts can be useful for several visual recognition tasks. Lately, these tasks have been addressed using Convolutional Neural Networks (CNN), achieving outstanding results. In this work we study whether CNNs learn semantic parts in their internal representation. We investigate the responses of convolutional filters and try to associate their stimuli with semantic parts. While previous efforts [1,2,3,4] studied this matter by visual inspection, we perform an extensive quantitative analysis based on ground-truth part bounding-boxes, exploring different layers, network depths, and supervision levels. Even after assisting the filters with several mechanisms to favor this association, we find that only about 25 percent of the semantic parts in PASCAL Part dataset [5] emerge in the popular AlexNet [6] network finetuned for object detection [7]. Interestingly, both the supervision level and the network depth do not seem to significantly affect the emergence of parts. Finally, we investigate if filters are responding to recurrent discriminative patches as opposed to semantic parts. We discover that the discriminative power of the network can be attributed to a few discriminative filters specialized to each object class. Moreover, about 60 percent of them can be associated with semantic parts. The overlap between discriminative and semantic filters might be the reason why previous studies suggested a stronger emergence of semantic parts, based on visual inspection only. version:3
arxiv-1607-05709 | Multi-category Angle-based Classifier Refit | http://arxiv.org/abs/1607.05709 | id:1607.05709 author:Guo Xian Yau, Chong Zhang category:math.ST stat.ML stat.TH  published:2016-07-19 summary:Classification is an important statistical learning tool. In real application, besides high prediction accuracy, it is often desirable to estimate class conditional probabilities for new observations. For traditional problems where the number of observations is large, there exist many well developed approaches. Recently, high dimensional low sample size problems are becoming increasingly popular. Margin-based classifiers, such as logistic regression, are well established methods in the literature. On the other hand, in terms of probability estimation, it is known that for binary classifiers, the commonly used methods tend to under-estimate the norm of the classification function. This can lead to biased probability estimation. Remedy approaches have been proposed in the literature. However, for the simultaneous multicategory classification framework, much less work has been done. We fill the gap in this paper. In particular, we give theoretical insights on why heavy regularization terms are often needed in high dimensional applications, and how this can lead to bias in probability estimation. To overcome this difficulty, we propose a new refit strategy for multicategory angle-based classifiers. Our new method only adds a small computation cost to the problem, and is able to attain prediction accuracy that is as good as the regular margin-based classifiers. On the other hand, the improvement of probability estimation can be very significant. Numerical results suggest that the new refit approach is highly competitive. version:1
arxiv-1607-05691 | Information-theoretical label embeddings for large-scale image classification | http://arxiv.org/abs/1607.05691 | id:1607.05691 author:François Chollet category:cs.CV cs.LG stat.ML  published:2016-07-19 summary:We present a method for training multi-label, massively multi-class image classification models, that is faster and more accurate than supervision via a sigmoid cross-entropy loss (logistic regression). Our method consists in embedding high-dimensional sparse labels onto a lower-dimensional dense sphere of unit-normed vectors, and treating the classification problem as a cosine proximity regression problem on this sphere. We test our method on a dataset of 300 million high-resolution images with 17,000 labels, where it yields considerably faster convergence, as well as a 7% higher mean average precision compared to logistic regression. version:1
arxiv-1607-05690 | Stochastic Backpropagation through Mixture Density Distributions | http://arxiv.org/abs/1607.05690 | id:1607.05690 author:Alex Graves category:cs.NE  published:2016-07-19 summary:The ability to backpropagate stochastic gradients through continuous latent distributions has been crucial to the emergence of variational autoencoders and stochastic gradient variational Bayes. The key ingredient is an unbiased and low-variance way of estimating gradients with respect to distribution parameters from gradients evaluated at distribution samples. The "reparameterization trick" provides a class of transforms yielding such estimators for many continuous distributions, including the Gaussian and other members of the location-scale family. However the trick does not readily extend to mixture density models, due to the difficulty of reparameterizing the discrete distribution over mixture weights. This report describes an alternative transform, applicable to any continuous multivariate distribution with a differentiable density function from which samples can be drawn, and uses it to derive an unbiased estimator for mixture density weight derivatives. Combined with the reparameterization trick applied to the individual mixture components, this estimator makes it straightforward to train variational autoencoders with mixture-distributed latent variables, or to perform stochastic variational inference with a mixture density variational posterior. version:1
arxiv-1607-05666 | Trainable Frontend For Robust and Far-Field Keyword Spotting | http://arxiv.org/abs/1607.05666 | id:1607.05666 author:Yuxuan Wang, Pascal Getreuer, Thad Hughes, Richard F. Lyon, Rif A. Saurous category:cs.CL cs.NE  published:2016-07-19 summary:Robust and far-field speech recognition is critical to enable true hands-free communication. In far-field conditions, signals are attenuated due to distance. To improve robustness to loudness variation, we introduce a novel frontend called per-channel energy normalization (PCEN). The key ingredient of PCEN is the use of an automatic gain control based dynamic compression to replace the widely used static (such as log or root) compression. We evaluate PCEN on the keyword spotting task. On our large rerecorded noisy and far-field eval sets, we show that PCEN significantly improves recognition performance. Furthermore, we model PCEN as neural network layers and optimize high-dimensional PCEN parameters jointly with the keyword spotting acoustic model. The trained PCEN frontend demonstrates significant further improvements without increasing model complexity or inference-time cost. version:1
arxiv-1607-04889 | Gland Instance Segmentation by Deep Multichannel Neural Networks | http://arxiv.org/abs/1607.04889 | id:1607.04889 author:Yan Xu, Yang Li, Mingyuan Liu, Yipei Wang, Yubo Fan, Maode Lai, Eric I-Chao Chang category:cs.CV  published:2016-07-17 summary:In this paper, we propose a new image instance segmentation method that segments individual glands (instances) in colon histology images. This is a task called instance segmentation that has recently become increasingly important. The problem is challenging since not only do the glands need to be segmented from the complex background, they are also required to be individually identified. Here we leverage the idea of image-to-image prediction in recent deep learning by building a framework that automatically exploits and fuses complex multichannel information, regional, location and boundary patterns in gland histology images. Our proposed system, deep multichannel framework, alleviates heavy feature design due to the use of convolutional neural networks and is able to meet multifarious requirement by altering channels. Compared to methods reported in the 2015 MICCAI Gland Segmentation Challenge and other currently prevalent methods of instance segmentation, we observe state-of-the-art results based on a number of evaluation metrics. version:2
arxiv-1607-05954 | On the estimation of stellar parameters with uncertainty prediction from Generative Artificial Neural Networks: application to Gaia RVS simulated spectra | http://arxiv.org/abs/1607.05954 | id:1607.05954 author:C. Dafonte, D. Fustes, M. Manteiga, D. Garabato, M. A. Alvarez, A. Ulla, C. Allende Prieto category:astro-ph.IM astro-ph.SR cs.AI cs.NE  published:2016-07-19 summary:Aims. We present an innovative artificial neural network (ANN) architecture, called Generative ANN (GANN), that computes the forward model, that is it learns the function that relates the unknown outputs (stellar atmospheric parameters, in this case) to the given inputs (spectra). Such a model can be integrated in a Bayesian framework to estimate the posterior distribution of the outputs. Methods. The architecture of the GANN follows the same scheme as a normal ANN, but with the inputs and outputs inverted. We train the network with the set of atmospheric parameters (Teff, logg, [Fe/H] and [alpha/Fe]), obtaining the stellar spectra for such inputs. The residuals between the spectra in the grid and the estimated spectra are minimized using a validation dataset to keep solutions as general as possible. Results. The performance of both conventional ANNs and GANNs to estimate the stellar parameters as a function of the star brightness is presented and compared for different Galactic populations. GANNs provide significantly improved parameterizations for early and intermediate spectral types with rich and intermediate metallicities. The behaviour of both algorithms is very similar for our sample of late-type stars, obtaining residuals in the derivation of [Fe/H] and [alpha/Fe] below 0.1dex for stars with Gaia magnitude Grvs<12, which accounts for a number in the order of four million stars to be observed by the Radial Velocity Spectrograph of the Gaia satellite. Conclusions. Uncertainty estimation of computed astrophysical parameters is crucial for the validation of the parameterization itself and for the subsequent exploitation by the astronomical community. GANNs produce not only the parameters for a given spectrum, but a goodness-of-fit between the observed spectrum and the predicted one for a given set of parameters. Moreover, they allow us to obtain the full posterior distribution... version:1
arxiv-1607-05620 | A Local-Global Approach to Semantic Segmentation in Aerial Images | http://arxiv.org/abs/1607.05620 | id:1607.05620 author:Alina Elena Marcu category:cs.CV  published:2016-07-19 summary:Aerial images are often taken under poor lighting conditions and contain low resolution objects, many times occluded by other objects. In this domain, visual context could be of great help, but there are still very few papers that consider context in aerial image understanding and still remains an open problem in computer vision. We propose a dual-stream deep neural network that processes information along two independent pathways. Our model learns to combine local and global appearance in a complementary way, such that together form a powerful classifier. We test our dual-stream network on the task of buildings segmentation in aerial images and obtain state-of-the-art results on the Massachusetts Buildings Dataset. We study the relative importance of local appearance versus the larger scene, as well as their performance in combination on three new buildings datasets. We clearly demonstrate the effectiveness of visual context in conjunction with deep neural networks for aerial image understanding. version:1
arxiv-1607-05573 | Combing Random Walks and Nonparametric Bayesian Topic Model for Community Detection | http://arxiv.org/abs/1607.05573 | id:1607.05573 author:Ruimin Zhu, Wenxin Jiang category:stat.AP stat.ML  published:2016-07-19 summary:Community detection has been an active research area for decades. Among all probabilistic models, Stochastic Block Model has been the most popular one. This paper introduces a novel probabilistic model: RW-HDP, based on random walks and Hierarchical Dirichlet Process, for community extraction. In RW-HDP, random walks conducted in a social network are treated as documents; nodes are treated as words. By using Hierarchical Dirichlet Process, a nonparametric Bayesian model, we are not only able to cluster nodes into different communities, but also determine the number of communities automatically. We use Stochastic Variational Inference for our model inference, which makes our method time efficient and can be easily extended to an online learning algorithm. version:1
arxiv-1607-05529 | Dual Purpose Hashing | http://arxiv.org/abs/1607.05529 | id:1607.05529 author:Haomiao Liu, Ruiping Wang, Shiguang Shan, Xilin Chen category:cs.CV  published:2016-07-19 summary:Recent years have seen more and more demand for a unified framework to address multiple realistic image retrieval tasks concerning both category and attributes. Considering the scale of modern datasets, hashing is favorable for its low complexity. However, most existing hashing methods are designed to preserve one single kind of similarity, thus improper for dealing with the different tasks simultaneously. To overcome this limitation, we propose a new hashing method, named Dual Purpose Hashing (DPH), which jointly preserves the category and attribute similarities by exploiting the Convolutional Neural Network (CNN) models to hierarchically capture the correlations between category and attributes. Since images with both category and attribute labels are scarce, our method is designed to take the abundant partially labelled images on the Internet as training inputs. With such a framework, the binary codes of new-coming images can be readily obtained by quantizing the network outputs of a binary-like layer, and the attributes can be recovered from the codes easily. Experiments on two large-scale datasets show that our dual purpose hash codes can achieve comparable or even better performance than those state-of-the-art methods specifically designed for each individual retrieval task, while being more compact than the compared methods. version:1
arxiv-1607-05523 | Dendritic Spine Shape Analysis: A Clustering Perspective | http://arxiv.org/abs/1607.05523 | id:1607.05523 author:Muhammad Usman Ghani, Ertunc Erdil, Sumeyra Demir Kanik, Ali Ozgur Argunsah, Anna Felicity Hobbiss, Inbal Israely, Devrim Unay, Tolga Tasdizen, Mujdat Cetin category:cs.CV  published:2016-07-19 summary:Functional properties of neurons are strongly coupled with their morphology. Changes in neuronal activity alter morphological characteristics of dendritic spines. First step towards understanding the structure-function relationship is to group spines into main spine classes reported in the literature. Shape analysis of dendritic spines can help neuroscientists understand the underlying relationships. Due to unavailability of reliable automated tools, this analysis is currently performed manually which is a time-intensive and subjective task. Several studies on spine shape classification have been reported in the literature, however, there is an on-going debate on whether distinct spine shape classes exist or whether spines should be modeled through a continuum of shape variations. Another challenge is the subjectivity and bias that is introduced due to the supervised nature of classification approaches. In this paper, we aim to address these issues by presenting a clustering perspective. In this context, clustering may serve both confirmation of known patterns and discovery of new ones. We perform cluster analysis on two-photon microscopic images of spines using morphological, shape, and appearance based features and gain insights into the spine shape analysis problem. We use histogram of oriented gradients (HOG), disjunctive normal shape models (DNSM), morphological features, and intensity profile based features for cluster analysis. We use x-means to perform cluster analysis that selects the number of clusters automatically using the Bayesian information criterion (BIC). For all features, this analysis produces 4 clusters and we observe the formation of at least one cluster consisting of spines which are difficult to be assigned to a known class. This observation supports the argument of intermediate shape types. version:1
arxiv-1607-05506 | Distribution-dependent concentration inequalities for tighter generalization bounds | http://arxiv.org/abs/1607.05506 | id:1607.05506 author:Xinxing Wu, Junping Zhang category:stat.ML  published:2016-07-19 summary:We prove several distribution-dependent extensions of Hoeffding and McDiarmid's inequalities with (difference-) unbounded and hierarchically (difference-) bounded functions. For this purpose, several assumptions about the probabilistic boundedness and bounded differences are introduced. Our approaches improve the previous concentration inequalities' bounds, and achieve tight bounds in some exceptional cases where the original inequalities cannot hold. Furthermore, we discuss the potential applications of our extensions in VC dimension and Rademacher complexity. Then we obtain generalization bounds for (difference-) unbounded loss functions and tighten the existing generalization bounds. version:1
arxiv-1607-05477 | Supervised Transformer Network for Efficient Face Detection | http://arxiv.org/abs/1607.05477 | id:1607.05477 author:Dong Chen, Gang Hua, Fang Wen, Jian Sun category:cs.CV  published:2016-07-19 summary:Large pose variations remain to be a challenge that confronts real-word face detection. We propose a new cascaded Convolutional Neural Network, dubbed the name Supervised Transformer Network, to address this challenge. The first stage is a multi-task Region Proposal Network (RPN), which simultaneously predicts candidate face regions along with associated facial landmarks. The candidate regions are then warped by mapping the detected facial landmarks to their canonical positions to better normalize the face patterns. The second stage, which is a RCNN, then verifies if the warped candidate regions are valid faces or not. We conduct end-to-end learning of the cascaded network, including optimizing the canonical positions of the facial landmarks. This supervised learning of the transformations automatically selects the best scale to differentiate face/non-face patterns. By combining feature maps from both stages of the network, we achieve state-of-the-art detection accuracies on several public benchmarks. For real-time performance, we run the cascaded network only on regions of interests produced from a boosting cascade face detector. Our detector runs at 30 FPS on a single CPU core for a VGA-resolution image. version:1
arxiv-1607-05440 | Collaborative Layer-wise Discriminative Learning in Deep Neural Networks | http://arxiv.org/abs/1607.05440 | id:1607.05440 author:Xiaojie Jin, Yunpeng Chen, Jian Dong, Jiashi Feng, Shuicheng Yan category:cs.CV  published:2016-07-19 summary:Intermediate features at different layers of a deep neural network are known to be discriminative for visual patterns of different complexities. However, most existing works ignore such cross-layer heterogeneities when classifying samples of different complexities. For example, if a training sample has already been correctly classified at a specific layer with high confidence, we argue that it is unnecessary to enforce rest layers to classify this sample correctly and a better strategy is to encourage those layers to focus on other samples. In this paper, we propose a layer-wise discriminative learning method to enhance the discriminative capability of a deep network by allowing its layers to work collaboratively for classification. Towards this target, we introduce multiple classifiers on top of multiple layers. Each classifier not only tries to correctly classify the features from its input layer, but also coordinates with other classifiers to jointly maximize the final classification performance. Guided by the other companion classifiers, each classifier learns to concentrate on certain training examples and boosts the overall performance. Allowing for end-to-end training, our method can be conveniently embedded into state-of-the-art deep networks. Experiments with multiple popular deep networks, including Network in Network, GoogLeNet and VGGNet, on scale-various object classification benchmarks, including CIFAR100, MNIST and ImageNet, and scene classification benchmarks, including MIT67, SUN397 and Places205, demonstrate the effectiveness of our method. In addition, we also analyze the relationship between the proposed method and classical conditional random fields models. version:1
arxiv-1607-05432 | Nested Kriging estimations for datasets with large number of observations | http://arxiv.org/abs/1607.05432 | id:1607.05432 author:Didier Rullière, Nicolas Durrande, François Bachoc, Clément Chevalier category:stat.ML  published:2016-07-19 summary:This work falls within the context of predicting the value of a real function f at some input locations given a limited number of observations of this function. Kriging interpolation technique (or Gaussian process regression) is often considered to tackle such problem but the method suffers from its computational burden when the number of observation points n is large. We introduce in this article nested Kriging estimators which are constructed by aggregating sub-models based on subsets of observation points. This approach is proven to have better theoretical properties than other aggregation methods that can be found in the literature. In particular, contrary to some other methods which are shown inconsistent, we prove the consistency of our proposed aggregation method. Finally, the practical interest of the proposed method is illustrated on simulated datasets and on an industrial test case with 10 4 observations in a 6-dimensional space. version:1
arxiv-1607-05427 | Trunk-Branch Ensemble Convolutional Neural Networks for Video-based Face Recognition | http://arxiv.org/abs/1607.05427 | id:1607.05427 author:Changxing Ding, Dacheng Tao category:cs.CV  published:2016-07-19 summary:Human faces in surveillance videos often suffer from severe image blur, dramatic pose variations, and occlusion. In this paper, we propose a comprehensive framework based on Convolutional Neural Networks (CNN) to overcome challenges in video-based face recognition (VFR). First, to learn blur-robust face representations, we artificially blur training data composed of clear still images to account for a shortfall in real-world video training data. Using training data composed of both still images and artificially blurred data, CNN is encouraged to learn blur-insensitive features automatically. Second, to enhance robustness of CNN features to pose variations and occlusion, we propose a Trunk-Branch Ensemble CNN model (TBE-CNN), which extracts complementary information from holistic face images and patches cropped around facial components. TBE-CNN is an end-to-end model that extracts features efficiently by sharing the low- and middle-level convolutional layers between the trunk and branch networks. Third, to further promote the discriminative power of the representations learnt by TBE-CNN, we propose an improved triplet loss function. Systematic experiments justify the effectiveness of the proposed techniques. Most impressively, TBE-CNN achieves state-of-the-art performance on three popular video face databases: PaSC, COX Face, and YouTube Faces. version:1
arxiv-1607-04867 | Robust Automated Human Activity Recognition and its Application to Sleep Research | http://arxiv.org/abs/1607.04867 | id:1607.04867 author:Aarti Sathyanarayana, Ferda Ofli, Luis Fernandes-Luque, Jaideep Srivastava, Ahmed Elmagarmid, Teresa Arora, Shahrad Taheri category:cs.LG  published:2016-07-17 summary:Human Activity Recognition (HAR) is a powerful tool for understanding human behaviour. Applying HAR to wearable sensors can provide new insights by enriching the feature set in health studies, and enhance the personalisation and effectiveness of health, wellness, and fitness applications. Wearable devices provide an unobtrusive platform for user monitoring, and due to their increasing market penetration, feel intrinsic to the wearer. The integration of these devices in daily life provide a unique opportunity for understanding human health and wellbeing. This is referred to as the "quantified self" movement. The analyses of complex health behaviours such as sleep, traditionally require a time-consuming manual interpretation by experts. This manual work is necessary due to the erratic periodicity and persistent noisiness of human behaviour. In this paper, we present a robust automated human activity recognition algorithm, which we call RAHAR. We test our algorithm in the application area of sleep research by providing a novel framework for evaluating sleep quality and examining the correlation between the aforementioned and an individual's physical activity. Our results improve the state-of-the-art procedure in sleep research by 15 percent for area under ROC and by 30 percent for F1 score on average. However, application of RAHAR is not limited to sleep analysis and can be used for understanding other health problems such as obesity, diabetes, and cardiac diseases. version:2
arxiv-1607-05423 | Training Skinny Deep Neural Networks with Iterative Hard Thresholding Methods | http://arxiv.org/abs/1607.05423 | id:1607.05423 author:Xiaojie Jin, Xiaotong Yuan, Jiashi Feng, Shuicheng Yan category:cs.CV  published:2016-07-19 summary:Deep neural networks have achieved remarkable success in a wide range of practical problems. However, due to the inherent large parameter space, deep models are notoriously prone to overfitting and difficult to be deployed in portable devices with limited memory. In this paper, we propose an iterative hard thresholding (IHT) approach to train Skinny Deep Neural Networks (SDNNs). An SDNN has much fewer parameters yet can achieve competitive or even better performance than its full CNN counterpart. More concretely, the IHT approach trains an SDNN through following two alternative phases: (I) perform hard thresholding to drop connections with small activations and fine-tune the other significant filters; (II)~re-activate the frozen connections and train the entire network to improve its overall discriminative capability. We verify the superiority of SDNNs in terms of efficiency and classification performance on four benchmark object recognition datasets, including CIFAR-10, CIFAR-100, MNIST and ImageNet. Experimental results clearly demonstrate that IHT can be applied for training SDNN based on various CNN architectures such as NIN and AlexNet. version:1
arxiv-1607-05422 | A Novel Information Theoretic Framework for Finding Semantic Similarity in WordNet | http://arxiv.org/abs/1607.05422 | id:1607.05422 author:Abhijit Adhikari, Shivang Singh, Deepjyoti Mondal, Biswanath Dutta, Animesh Dutta category:cs.IR cs.CL  published:2016-07-19 summary:Information content (IC) based measures for finding semantic similarity is gaining preferences day by day. Semantics of concepts can be highly characterized by information theory. The conventional way for calculating IC is based on the probability of appearance of concepts in corpora. Due to data sparseness and corpora dependency issues of those conventional approaches, a new corpora independent intrinsic IC calculation measure has evolved. In this paper, we mainly focus on such intrinsic IC model and several topological aspects of the underlying ontology. Accuracy of intrinsic IC calculation and semantic similarity measure rely on these aspects deeply. Based on these analysis we propose an information theoretic framework which comprises an intrinsic IC calculator and a semantic similarity model. Our approach is compared with state of the art semantic similarity measures based on corpora dependent IC calculation as well as intrinsic IC based methods using several benchmark data set. We also compare our model with the related Edge based, Feature based and Distributional approaches. Experimental results show that our intrinsic IC model gives high correlation value when applied to different semantic similarity models. Our proposed semantic similarity model also achieves significant results when embedded with some state of the art IC models including ours. version:1
arxiv-1607-05408 | Discriminating between similar languages in Twitter using label propagation | http://arxiv.org/abs/1607.05408 | id:1607.05408 author:Will Radford, Matthias Galle category:cs.CL I.2.7  published:2016-07-19 summary:Identifying the language of social media messages is an important first step in linguistic processing. Existing models for Twitter focus on content analysis, which is successful for dissimilar language pairs. We propose a label propagation approach that takes the social graph of tweet authors into account as well as content to better tease apart similar languages. This results in state-of-the-art shared task performance of $76.63\%$, $1.4\%$ higher than the top system. version:1
arxiv-1607-05397 | Multidimensional Dynamic Pricing for Welfare Maximization | http://arxiv.org/abs/1607.05397 | id:1607.05397 author:Aaron Roth, Aleksandrs Slivkins, Jonathan Ullman, Zhiwei Steven Wu category:cs.DS cs.GT cs.LG  published:2016-07-19 summary:We study the problem of a seller dynamically pricing $d$ distinct types of goods, when faced with the online arrival of buyers drawn independently from an unknown distribution. The seller observes only the bundle of goods purchased at each day, but nothing else about the buyer's valuation function. When buyers have strongly concave, Holder continuous valuation functions, we give a pricing scheme that finds a pricing that optimizes welfare (including the seller's cost of production) in time and number of rounds that are polynomial in $d$ and the accuracy parameter. We are able to do this despite the fact that (i) welfare is a non-concave function of the prices, and (ii) the welfare is not observable to the seller. We also extend our results to a limited-supply setting. version:1
arxiv-1607-05396 | Binary Hashing with Semidefinite Relaxation and Augmented Lagrangian | http://arxiv.org/abs/1607.05396 | id:1607.05396 author:Thanh-Toan Do, Anh-Dzung Doan, Duc-Thanh Nguyen, Ngai-Man Cheung category:cs.CV  published:2016-07-19 summary:This paper proposes two approaches for inferencing binary codes in two-step (supervised, unsupervised) hashing. We first introduce an unified formulation for both supervised and unsupervised hashing. Then, we cast the learning of one bit as a Binary Quadratic Problem (BQP). We propose two approaches to solve BQP. In the first approach, we relax BQP as a semidefinite programming problem which its global optimum can be achieved. We theoretically prove that the objective value of the binary solution achieved by this approach is well bounded. In the second approach, we propose an augmented Lagrangian based approach to solve BQP directly without relaxing the binary constraint. Experimental results on three benchmark datasets show that our proposed methods compare favorably with the state of the art. version:1
arxiv-1607-05390 | Genetic Transfer or Population Diversification? Deciphering the Secret Ingredients of Evolutionary Multitask Optimization | http://arxiv.org/abs/1607.05390 | id:1607.05390 author:Abhishek Gupta, Yew-Soon Ong category:cs.NE  published:2016-07-19 summary:Evolutionary multitasking has recently emerged as a novel paradigm that enables the similarities and/or latent complementarities (if present) between distinct optimization tasks to be exploited in an autonomous manner simply by solving them together with a unified solution representation scheme. An important matter underpinning future algorithmic advancements is to develop a better understanding of the driving force behind successful multitask problem-solving. In this regard, two (seemingly disparate) ideas have been put forward, namely, (a) implicit genetic transfer as the key ingredient facilitating the exchange of high-quality genetic material across tasks, and (b) population diversification resulting in effective global search of the unified search space encompassing all tasks. In this paper, we present some empirical results that provide a clearer picture of the relationship between the two aforementioned propositions. For the numerical experiments we make use of Sudoku puzzles as case studies, mainly because of their feature that outwardly unlike puzzle statements can often have nearly identical final solutions. The experiments reveal that while on many occasions genetic transfer and population diversity may be viewed as two sides of the same coin, the wider implication of genetic transfer, as shall be shown herein, captures the true essence of evolutionary multitasking to the fullest. version:1
arxiv-1607-05387 | Generating Images Part by Part with Composite Generative Adversarial Networks | http://arxiv.org/abs/1607.05387 | id:1607.05387 author:Hanock Kwak, Byoung-Tak Zhang category:cs.AI cs.CV cs.LG  published:2016-07-19 summary:Image generation remains a fundamental problem in artificial intelligence in general and deep learning in specific. The generative adversarial network (GAN) was successful in generating high quality samples of natural images. We propose a model called composite generative adversarial network, that reveals the complex structure of images with multiple generators in which each generator generates some part of the image. Those parts are combined by alpha blending process to create a new single image. It can generate, for example, background and face sequentially with two generators, after training on face dataset. Training was done in an unsupervised way without any labels about what each generator should generate. We found possibilities of learning the structure by using this generative model empirically. version:1
arxiv-1607-04648 | Context Matters: Refining Object Detection in Video with Recurrent Neural Networks | http://arxiv.org/abs/1607.04648 | id:1607.04648 author:Subarna Tripathi, Zachary C. Lipton, Serge Belongie, Truong Nguyen category:cs.CV  published:2016-07-15 summary:Given the vast amounts of video available online, and recent breakthroughs in object detection with static images, object detection in video offers a promising new frontier. However, motion blur and compression artifacts cause substantial frame-level variability, even in videos that appear smooth to the eye. Additionally, video datasets tend to have sparsely annotated frames. We present a new framework for improving object detection in videos that captures temporal context and encourages consistency of predictions. First, we train a pseudo-labeler, that is, a domain-adapted convolutional neural network for object detection. The pseudo-labeler is first trained individually on the subset of labeled frames, and then subsequently applied to all frames. Then we train a recurrent neural network that takes as input sequences of pseudo-labeled frames and optimizes an objective that encourages both accuracy on the target frame and consistency across consecutive frames. The approach incorporates strong supervision of target frames, weak-supervision on context frames, and regularization via a smoothness penalty. Our approach achieves mean Average Precision (mAP) of 68.73, an improvement of 7.1 over the strongest image-based baselines for the Youtube-Video Objects dataset. Our experiments demonstrate that neighboring frames can provide valuable information, even absent labels. version:2
arxiv-1607-05369 | A Multi-task Deep Network for Person Re-identification | http://arxiv.org/abs/1607.05369 | id:1607.05369 author:Weihua Chen, Xiaotang Chen, Jianguo Zhang, Kaiqi Huang category:cs.CV  published:2016-07-19 summary:Person re-identification (RID) focuses on identifying people across different scenes in video surveillance, which is usually formulated as either a binary classification task or a ranking task in current person RID approaches. To the best of our knowledge, none of existing work treats the two tasks simultaneously. In this paper, we take both tasks into account and propose a multi-task deep network (MTDnet) to jointly optimize the two tasks simultaneously for person RID. We show that our proposed architecture significantly boosts the performance. Furthermore, a good performance of any deep architectures requires a sufficient training set which is usually not met in person RID. To cope with this situation, we further extend the MTDnet and propose a cross-domain architecture that is capable of using an auxiliary set to assist training on small target sets. In the experiments, our approach significantly outperforms previous state-of-the-art methods on almost all the datasets, which clearly demonstrates the effectiveness of the proposed approach. version:1
arxiv-1607-05368 | An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation | http://arxiv.org/abs/1607.05368 | id:1607.05368 author:Jey Han Lau, Timothy Baldwin category:cs.CL  published:2016-07-19 summary:Recently, Le and Mikolov (2014) proposed doc2vec as an extension to word2vec (Mikolov et al., 2013a) to learn document-level embeddings. Despite promising results in the original paper, others have struggled to reproduce those results. This paper presents a rigorous empirical evaluation of doc2vec over two tasks. We compare doc2vec to two baselines and two state-of-the-art document embedding methodologies. We found that doc2vec performs robustly when using models trained on large external corpora, and can be further improved by using pre-trained word embeddings. We also provide recommendations on hyper-parameter settings for general purpose applications, and release source code to induce document embeddings using our trained doc2vec models. version:1
arxiv-1607-05338 | Geometry-Informed Material Recognition | http://arxiv.org/abs/1607.05338 | id:1607.05338 author:Joseph DeGol, Mani Golparvar-Fard, Derek Hoiem category:cs.CV  published:2016-07-18 summary:Our goal is to recognize material categories using images and geometry information. In many applications, such as construction management, coarse geometry information is available. We investigate how 3D geometry (surface normals, camera intrinsic and extrinsic parameters) can be used with 2D features (texture and color) to improve material classification. We introduce a new dataset, GeoMat, which is the first to provide both image and geometry data in the form of: (i) training and testing patches that were extracted at different scales and perspectives from real world examples of each material category, and (ii) a large scale construction site scene that includes 160 images and over 800,000 hand labeled 3D points. Our results show that using 2D and 3D features both jointly and independently to model materials improves classification accuracy across multiple scales and viewing directions for both material patches and images of a large scale construction site scene. version:1
arxiv-1607-05258 | Deep learning trends for focal brain pathology segmentation in MRI | http://arxiv.org/abs/1607.05258 | id:1607.05258 author:Mohammad Havaei, Nicolas Guizard, Hugo Larochelle, Pierre-Marc Jodoin category:cs.CV  published:2016-07-18 summary:Segmentation of focal (localized) brain pathologies such as brain tumors and brain lesions caused by multiple sclerosis and ischemic strokes are necessary for medical diagnosis, surgical planning and disease development as well as other applications such as tractography. Over the years, attempts have been made to automate this process for both clinical and research reasons. In this regard, machine learning methods have long been a focus of attention. Over the past two years, the medical imaging field has seen a rise in the use of a particular branch of machine learning commonly known as deep learning. In the non-medical computer vision world, deep learning based methods have obtained state-of-the-art results on many datasets. Recent studies in computer aided diagnostics have shown deep learning methods (and especially convolutional neural networks - CNN) to yield promising results. In this chapter, we provide a survey of CNN methods applied to medical imaging with a focus on brain pathology segmentation. In particular, we discuss their characteristic peculiarities and their specific configuration and adjustments that are best suited to segment medical images. We also underline the intrinsic differences deep learning methods have with other machine learning methods. version:1
arxiv-1607-05241 | Imitation Learning with Recurrent Neural Networks | http://arxiv.org/abs/1607.05241 | id:1607.05241 author:Khanh Nguyen category:cs.CL cs.LG stat.ML  published:2016-07-18 summary:We present a novel view that unifies two frameworks that aim to solve sequential prediction problems: learning to search (L2S) and recurrent neural networks (RNN). We point out equivalences between elements of the two frameworks. By complementing what is missing from one framework comparing to the other, we introduce a more advanced imitation learning framework that, on one hand, augments L2S s notion of search space and, on the other hand, enhances RNNs training procedure to be more robust to compounding errors arising from training on highly correlated examples. version:1
arxiv-1607-05213 | mpEAd: Multi-Population EA Diagrams | http://arxiv.org/abs/1607.05213 | id:1607.05213 author:Sebastian Lenartowicz, Mark Wineberg category:cs.NE  published:2016-07-18 summary:Multi-population evolutionary algorithms are, by nature, highly complex and difficult to describe. Even two populations working in concert (or opposition) present a myriad of potential configurations that are often difficult to relate using text alone. Little effort has been made, however, to depict these kinds of systems, relying solely on the simple structural connections (related using ad hoc diagrams) between populations and often leaving out crucial details. In this paper, we propose a notation and accompanying formalism for consistently and powerfully depicting these structures and the relationships within them in an intuitive and consistent way. Using our notation, we examine simple co-evolutionary systems and discover new configurations by the simple process of "drawing on a whiteboard". Finally, we demonstrate that even complex, highly-interconnected systems with large numbers of populations can be understood with ease using the advanced features of our formalism version:1
arxiv-1607-05208 | Bag of Attributes for Video Event Retrieval | http://arxiv.org/abs/1607.05208 | id:1607.05208 author:Leonardo A. Duarte, Otávio A. B. Penatti, Jurandy Almeida category:cs.IR cs.CV  published:2016-07-18 summary:In this paper, we present the Bag-of-Attributes (BoA) model for video representation aiming at video event retrieval. The BoA model is based on a semantic feature space for representing videos, resulting in high-level video feature vectors. For creating a semantic space, i.e., the attribute space, we can train a classifier using a labeled image dataset, obtaining a classification model that can be understood as a high-level codebook. This model is used to map low-level frame vectors into high-level vectors (e.g., classifier probability scores). Then, we apply pooling operations on the frame vectors to create the final bag of attributes for the video. In the BoA representation, each dimension corresponds to one category (or attribute) of the semantic space. Other interesting properties are: compactness, flexibility regarding the classifier, and ability to encode multiple semantic concepts in a single video representation. Our experiments considered the semantic space created by a deep convolutional neural network (OverFeat) pre-trained on 1000 object categories of ImageNet. OverFeat was then used to classify each video frame and max pooling combined the frame vectors in the BoA representation for the video. Results using BoA outperformed the baselines with statistical significance in the task of video event retrieval using the EVVE dataset. version:1
arxiv-1607-03343 | DeepBinaryMask: Learning a Binary Mask for Video Compressive Sensing | http://arxiv.org/abs/1607.03343 | id:1607.03343 author:Michael Iliadis, Leonidas Spinoulas, Aggelos K. Katsaggelos category:cs.CV cs.LG  published:2016-07-12 summary:In this paper, we propose a novel encoder-decoder neural network model referred to as DeepBinaryMask for video compressive sensing. In video compressive sensing one frame is acquired using a set of coded masks (sensing matrix) from which a number of video frames is reconstructed, equal to the number of coded masks. The proposed framework is an end-to-end model where the sensing matrix is trained along with the video reconstruction. The encoder learns the binary elements of the sensing matrix and the decoder is trained to recover the unknown video sequence. The reconstruction performance is found to improve when using the trained sensing mask from the network as compared to other mask designs such as random, across a wide variety of compressive sensing reconstruction algorithms. Finally, our analysis and discussion offers insights into understanding the characteristics of the trained mask designs that lead to the improved reconstruction quality. version:2
arxiv-1607-05194 | HeMIS: Hetero-Modal Image Segmentation | http://arxiv.org/abs/1607.05194 | id:1607.05194 author:Mohammad Havaei, Nicolas Guizard, Nicolas Chapados, Yoshua Bengio category:cs.CV  published:2016-07-18 summary:We introduce a deep learning image segmentation framework that is extremely robust to missing imaging modalities. Instead of attempting to impute or synthesize missing data, the proposed approach learns, for each modality, an embedding of the input image into a single latent vector space for which arithmetic operations (such as taking the mean) are well defined. Points in that space, which are averaged over modalities available at inference time, can then be further processed to yield the desired segmentation. As such, any combinatorial subset of available modalities can be provided as input, without having to learn a combinatorial number of imputation models. Evaluated on two neurological MRI datasets (brain tumors and MS lesions), the approach yields state-of-the-art segmentation results when provided with all modalities; moreover, its performance degrades remarkably gracefully when modalities are removed, significantly more so than alternative mean-filling or other synthesis approaches. version:1
arxiv-1607-05177 | Query-Focused Extractive Video Summarization | http://arxiv.org/abs/1607.05177 | id:1607.05177 author:Aidean Sharghi, Boqing Gong, Mubarak Shah category:cs.CV  published:2016-07-18 summary:Video data is explosively growing. As a result of the "big video data", intelligent algorithms for automatic video summarization have re-emerged as a pressing need. We develop a probabilistic model, Sequential and Hierarchical Determinantal Point Process (SH-DPP), for query-focused extractive video summarization. Given a user query and a long video sequence, our algorithm returns a summary by selecting key shots from the video. The decision to include a shot in the summary depends on the shot's relevance to the user query and importance in the context of the video, jointly. We verify our approach on two densely annotated video datasets. The query-focused video summarization is particularly useful for search engines, e.g., to display snippets of videos. version:1
arxiv-1607-05174 | Is spoken language all-or-nothing? Implications for future speech-based human-machine interaction | http://arxiv.org/abs/1607.05174 | id:1607.05174 author:Roger K. Moore category:cs.HC cs.AI cs.CL cs.RO  published:2016-07-18 summary:Recent years have seen significant market penetration for voice-based personal assistants such as Apple's Siri. However, despite this success, user take-up is frustratingly low. This position paper argues that there is a habitability gap caused by the inevitable mismatch between the capabilities and expectations of human users and the features and benefits provided by contemporary technology. Suggestions are made as to how such problems might be mitigated, but a more worrisome question emerges: "is spoken language all-or-nothing"? The answer, based on contemporary views on the special nature of (spoken) language, is that there may indeed be a fundamental limit to the interaction that can take place between mismatched interlocutors (such as humans and machines). However, it is concluded that interactions between native and non-native speakers, or between adults and children, or even between humans and dogs, might provide critical inspiration for the design of future speech-based human-machine interaction. version:1
arxiv-1607-05154 | On the Application of Support Vector Machines to the Prediction of Propagation Losses at 169 MHz for Smart Metering Applications | http://arxiv.org/abs/1607.05154 | id:1607.05154 author:Martino Uccellari, Francesca Facchini, Matteo Sola, Emilio Sirignano, Giorgio M. Vitetta, Andrea Barbieri, Stefano Tondelli category:stat.ML stat.AP  published:2016-07-18 summary:Recently, the need of deploying new wireless networks for smart gas metering has raised the problem of radio planning in the169 MHz band. Unluckily, software tools commonly adopted for radio planning in cellular communication systems cannot be employed to solve this problem because of the substantially lower transmission frequencies characterizing this application. In this manuscript a novel data-centric solution, based on the use of support vector machine techniques for classification and regression, is proposed. Our method requires the availability of a limited set of received signal strength measurements and the knowledge of a three-dimensional map of the propagation environment of interest, and generates both an estimate of the coverage area and a prediction of the field strength within it. Numerical results referring to different Italian villages and cities evidence that our method is able to achieve good accuracy at the price of an acceptable computational cost and of a limited effort for the acquisition of measurements in the considered environments. version:1
arxiv-1607-05142 | Joint Event Detection and Entity Resolution: a Virtuous Cycle | http://arxiv.org/abs/1607.05142 | id:1607.05142 author:Matthias Galle, Jean-Michel Renders, Guillaume Jacquet category:cs.CL  published:2016-07-18 summary:Clustering web documents has numerous applications, such as aggregating news articles into meaningful events, detecting trends and hot topics on the Web, preserving diversity in search results, etc. At the same time, the importance of named entities and, in particular, the ability to recognize them and to solve the associated co-reference resolution problem are widely recognized as key enabling factors when mining, aggregating and comparing content on the Web. Instead of considering these two problems separately, we propose in this paper a method that tackles jointly the problem of clustering news articles into events and cross-document co-reference resolution of named entities. The co-occurrence of named entities in the same clusters is used as an additional signal to decide whether two referents should be merged into one entity. These refined entities can in turn be used as enhanced features to re-cluster the documents and then be refined again, entering into a virtuous cycle that improves simultaneously the performances of both tasks. We implemented a prototype system and report results using the TDT5 collection of news articles, demonstrating the potential of our approach. version:1
arxiv-1607-05140 | Learning to Hash with Binary Deep Neural Network | http://arxiv.org/abs/1607.05140 | id:1607.05140 author:Thanh-Toan Do, Anh-Dzung Doan, Ngai-Man Cheung category:cs.CV  published:2016-07-18 summary:This work proposes deep network models and learning algorithms for unsupervised and supervised binary hashing. Our novel network design constrains one hidden layer to directly output the binary codes. This addresses a challenging issue in some previous works: optimizing non-smooth objective functions due to binarization. Moreover, we incorporate independence and balance properties in the direct and strict forms in the learning. Furthermore, we include similarity preserving property in our objective function. Our resulting optimization with these binary, independence, and balance constraints is difficult to solve. We propose to attack it with alternating optimization and careful relaxation. Experimental results on three benchmark datasets show that our proposed methods compare favorably with the state of the art. version:1
arxiv-1607-05271 | A Semiparametric Model for Bayesian Reader Identification | http://arxiv.org/abs/1607.05271 | id:1607.05271 author:Ahmed Abdelwahab, Reinhold Kliegl, Niels Landwehr category:cs.LG  published:2016-07-18 summary:We study the problem of identifying individuals based on their characteristic gaze patterns during reading of arbitrary text. The motivation for this problem is an unobtrusive biometric setting in which a user is observed during access to a document, but no specific challenge protocol requiring the user's time and attention is carried out. Existing models of individual differences in gaze control during reading are either based on simple aggregate features of eye movements, or rely on parametric density models to describe, for instance, saccade amplitudes or word fixation durations. We develop flexible semiparametric models of eye movements during reading in which densities are inferred under a Gaussian process prior centered at a parametric distribution family that is expected to approximate the true distribution well. An empirical study on reading data from 251 individuals shows significant improvements over the state of the art. version:1
arxiv-1607-05108 | Neural Machine Translation with Recurrent Attention Modeling | http://arxiv.org/abs/1607.05108 | id:1607.05108 author:Zichao Yang, Zhiting Hu, Yuntian Deng, Chris Dyer, Alex Smola category:cs.NE cs.CL  published:2016-07-18 summary:Knowing which words have been attended to in previous time steps while generating a translation is a rich source of information for predicting what words will be attended to in the future. We improve upon the attention model of Bahdanau et al. (2014) by explicitly modeling the relationship between previous and subsequent attention levels for each word using one recurrent network per input word. This architecture easily captures informative features, such as fertility and regularities in relative distortion. In experiments, we show our parameterization of attention improves translation quality. version:1
arxiv-1607-05074 | Deep Active Contours | http://arxiv.org/abs/1607.05074 | id:1607.05074 author:Christian Rupprecht, Elizabeth Huaroc, Maximilian Baust, Nassir Navab category:cs.CV  published:2016-07-18 summary:We propose a method for interactive boundary extraction which combines a deep, patch-based representation with an active contour framework. We train a class-specific convolutional neural network which predicts a vector pointing from the respective point on the evolving contour towards the closest point on the boundary of the object of interest. These predictions form a vector field which is then used for evolving the contour by the Sobolev active contour framework proposed by Sundaramoorthi et al. The resulting interactive segmentation method is very efficient in terms of required computational resources and can even be trained on comparatively small graphics cards. We evaluate the potential of the proposed method on both medical and non-medical challenge data sets, such as the STACOM data set and the PASCAL VOC 2012 data set. version:1
arxiv-1607-05066 | Recycle deep features for better object detection | http://arxiv.org/abs/1607.05066 | id:1607.05066 author:Wei Li, Matthias Breier, Dorit Merhof category:cs.CV I.4; I.5  published:2016-07-18 summary:Aiming at improving the performance of existing detection algorithms developed for different applications, we propose a region regression-based multi-stage class-agnostic detection pipeline, whereby the existing algorithms are employed for providing the initial detection proposals. Better detection is obtained by exploiting the power of deep learning in the region regress scheme while avoiding the requirement on a huge amount of reference data for training deep neural networks. Additionally, a novel network architecture with recycled deep features is proposed, which provides superior regression results compared to the commonly used architectures. As demonstrated on a data set with ~1200 samples of different classes, it is feasible to successfully train a deep neural network in our proposed architecture and use it to obtain the desired detection performance. Since only slight modifications are required to common network architectures and since the deep neural network is trained using the standard hyperparameters, the proposed detection is well accessible and can be easily adopted to a broad variety of detection tasks. version:1
arxiv-1607-05047 | A Batch, Off-Policy, Actor-Critic Algorithm for Optimizing the Average Reward | http://arxiv.org/abs/1607.05047 | id:1607.05047 author:S. A. Murphy, Y. Deng, E. B. Laber, H. R. Maei, R. S. Sutton, K. Witkiewitz category:stat.ML cs.LG  published:2016-07-18 summary:We develop an off-policy actor-critic algorithm for learning an optimal policy from a training set composed of data from multiple individuals. This algorithm is developed with a view towards its use in mobile health. version:1
arxiv-1607-05046 | Deep Cascaded Bi-Network for Face Hallucination | http://arxiv.org/abs/1607.05046 | id:1607.05046 author:Shizhan Zhu, Sifei Liu, Chen Change Loy, Xiaoou Tang category:cs.CV  published:2016-07-18 summary:We present a novel framework for hallucinating faces of unconstrained poses and with very low resolution (face size as small as 5pxIOD). In contrast to existing studies that mostly ignore or assume pre-aligned face spatial configuration (e.g. facial landmarks localization or dense correspondence field), we alternatingly optimize two complementary tasks, namely face hallucination and dense correspondence field estimation, in a unified framework. In addition, we propose a new gated deep bi-network that contains two functionality-specialized branches to recover different levels of texture details. Extensive experiments demonstrate that such formulation allows exceptional hallucination quality on in-the-wild low-res faces with significant pose and illumination variations. version:1
arxiv-1607-05014 | Language classification from bilingual word embedding graphs | http://arxiv.org/abs/1607.05014 | id:1607.05014 author:Steffen Eger, Armin Hoenen category:cs.CL  published:2016-07-18 summary:We study the role of the second language in bilingual word embeddings in monolingual semantic evaluation tasks. We find strongly and weakly positive correlations between down-stream task performance and second language similarity to the target language. Additionally, we show how bilingual word embeddings can be employed for the task of semantic language classification and that joint semantic spaces vary in meaningful ways across second languages. Our results support the hypothesis that semantic language similarity is influenced by both structural similarity as well as geography/contact. version:1
arxiv-1607-04564 | DAVE: A Unified Framework for Fast Vehicle Detection and Annotation | http://arxiv.org/abs/1607.04564 | id:1607.04564 author:Yi Zhou, Li Liu, Ling Shao, Matt Mellor category:cs.CV  published:2016-07-15 summary:Vehicle detection and annotation for streaming video data with complex scenes is an interesting but challenging task for urban traffic surveillance. In this paper, we present a fast framework of Detection and Annotation for Vehicles (DAVE), which effectively combines vehicle detection and attributes annotation. DAVE consists of two convolutional neural networks (CNNs): a fast vehicle proposal network (FVPN) for vehicle-like objects extraction and an attributes learning network (ALN) aiming to verify each proposal and infer each vehicle's pose, color and type simultaneously. These two nets are jointly optimized so that abundant latent knowledge learned from the ALN can be exploited to guide FVPN training. Once the system is trained, it can achieve efficient vehicle detection and annotation for real-world traffic surveillance data. We evaluate DAVE on a new self-collected UTS dataset and the public PASCAL VOC2007 car and LISA 2010 datasets, with consistent improvements over existing algorithms. version:2
arxiv-1607-05006 | End-to-end optimization of nonlinear transform codes for perceptual quality | http://arxiv.org/abs/1607.05006 | id:1607.05006 author:Johannes Ballé, Valero Laparra, Eero P. Simoncelli category:cs.IT cs.CV math.IT  published:2016-07-18 summary:We introduce a general framework for end-to-end optimization of the rate-distortion performance of nonlinear transform codes assuming scalar quantization. The proposed framework can be used to optimize any differentiable pair of analysis and synthesis transforms in combination with any differentiable perceptual metric. As an example, we optimize a code built from a linear transform followed by a form of multi-dimensional gain control. Distortion is measured with a state-of-the-art perceptual metric. The code, optimized over a large database of images, offers substantial improvements in bitrate and perceptual appearance over fixed (DCT) codes, as well as over linear transform codes optimized for mean squared error. version:1
arxiv-1607-05002 | Geometric Mean Metric Learning | http://arxiv.org/abs/1607.05002 | id:1607.05002 author:Pourya Habib Zadeh, Reshad Hosseini, Suvrit Sra category:stat.ML cs.LG  published:2016-07-18 summary:We revisit the task of learning a Euclidean metric from data. We approach this problem from first principles and formulate it as a surprisingly simple optimization problem. Indeed, our formulation even admits a closed form solution. This solution possesses several very attractive properties: (i) an innate geometric appeal through the Riemannian geometry of positive definite matrices; (ii) ease of interpretability; and (iii) computational speed several orders of magnitude faster than the widely used LMNN and ITML methods. Furthermore, on standard benchmark datasets, our closed-form solution consistently attains higher classification accuracy. version:1
arxiv-1607-04423 | Attention-over-Attention Neural Networks for Reading Comprehension | http://arxiv.org/abs/1607.04423 | id:1607.04423 author:Yiming Cui, Zhipeng Chen, Si Wei, Shijin Wang, Ting Liu, Guoping Hu category:cs.CL cs.NE  published:2016-07-15 summary:Cloze-style queries are representative problems in reading comprehension. Over the past few months, we have seen much progress that utilizing neural network approach to solve Cloze-style questions. In this paper, we present a novel model called attention-over-attention reader for the Cloze-style reading comprehension task. Our model aims to place another attention mechanism over the document-level attention, and induces "attended attention" for final predictions. Unlike the previous works, our neural network model requires less pre-defined hyper-parameters and uses an elegant architecture for modeling. Experimental results show that the proposed attention-over-attention model significantly outperforms various state-of-the-art systems by a large margin in public datasets, such as CNN and Children's Book Test datasets. version:2
arxiv-1607-04427 | A Theoretical Analysis of the BDeu Scores in Bayesian Network Structure Learning | http://arxiv.org/abs/1607.04427 | id:1607.04427 author:Joe Suzuki category:cs.LG cs.IT math.IT  published:2016-07-15 summary:In Bayesian network structure learning (BNSL), we need the prior probability over structures and parameters. If the former is the uniform distribution, the latter determines the correctness of BNSL. In this paper, we compare BDeu (Bayesian Dirichlet equivalent uniform) and Jeffreys' prior w.r.t. their consistency. When we seek a parent set $U$ of a variable $X$, we require regularity that if $H(X U)\leq H(X U')$ and $U\subsetneq U'$, then $U$ should be chosen rather than $U'$. We prove that the BDeu scores violate the property and cause fatal situations in BNSL. This is because for the BDeu scores, for any sample size $n$,there exists a probability in the form $P(X,Y,Z)={P(XZ)P(YZ)}/{P(Z)}$ such that the probability of deciding that $X$ and $Y$ are not conditionally independent given $Z$ is more than a half. For Jeffreys' prior, the false-positive probability uniformly converges to zero without depending on any parameter values, and no such an inconvenience occurs. version:2
arxiv-1607-04984 | Distributed Graph Clustering by Load Balancing | http://arxiv.org/abs/1607.04984 | id:1607.04984 author:He Sun, Luca Zanetti category:cs.DS cs.DC cs.LG F.2.0  published:2016-07-18 summary:Graph clustering is a fundamental problem with a number of applications in algorithm design, machine learning, data mining, and analysis of social networks. Over the past decades, researchers have proposed a number of algorithmic design methods for graph clustering. However, most of these methods are based on complicated spectral techniques or convex optimization, and cannot be applied directly for clustering most real-world networks, whose information is often collected on different sites. Designing a simple clustering algorithm that works in the distributed setting is of important interest, and has wide applications for processing big datasets. In this paper we present a simple and distributed algorithm for graph clustering: for a wide class of graphs with n nodes that can be characterized by a well-defined cluster-structure, our algorithm finishes in a poly-logarithmic number of rounds, and recovers a partition of the graph with at most o(n) misclassified nodes. The main component of our algorithm is an application of the random matching model of load balancing, which is a fundamental protocol in distributed computing and has been extensively studied in the past 20 years. Hence, our result highlights an intrinsic and interesting connection between graph clustering and load balancing. version:1
arxiv-1607-04982 | Dependency Language Models for Transition-based Dependency Parsing | http://arxiv.org/abs/1607.04982 | id:1607.04982 author:Juntao Yu, Bernd Bohnet category:cs.CL  published:2016-07-18 summary:In this paper, we present an approach to improve the accuracy of a dependency parser by exploiting dependency language models that are extracted from a large parsed corpus. We integrated a small number of features based on the dependency language models into the parser. To demonstrate the effectiveness of the proposed approach, we evaluate our parser on standard English and Chinese data where the base parser could achieve competitive accuracy scores. Our parser achieved state-of-the-art accuracy on Chinese data and competitive results on English data. We gained a large absolute improvement of one point (UAS) on Chinese and 0.5 points for English. version:1
arxiv-1607-04965 | Distributed Coding of Multiview Sparse Sources with Joint Recovery | http://arxiv.org/abs/1607.04965 | id:1607.04965 author:Huynh Van Luong, Nikos Deligiannis, Søren Forchhammer, André Kaup category:cs.CV cs.IT cs.MM math.IT  published:2016-07-18 summary:In support of applications involving multiview sources in distributed object recognition using lightweight cameras, we propose a new method for the distributed coding of sparse sources as visual descriptor histograms extracted from multiview images. The problem is challenging due to the computational and energy constraints at each camera as well as the limitations regarding inter-camera communication. Our approach addresses these challenges by exploiting the sparsity of the visual descriptor histograms as well as their intra- and inter-camera correlations. Our method couples distributed source coding of the sparse sources with a new joint recovery algorithm that incorporates multiple side information signals, where prior knowledge (low quality) of all the sparse sources is initially sent to exploit their correlations. Experimental evaluation using the histograms of shift-invariant feature transform (SIFT) descriptors extracted from multiview images shows that our method leads to bit-rate saving of up to 43% compared to the state-of-the-art distributed compressed sensing method with independent encoding of the sources. version:1
arxiv-1607-04942 | Sparse Representation-Based Classification: Orthogonal Least Squares or Orthogonal Matching Pursuit? | http://arxiv.org/abs/1607.04942 | id:1607.04942 author:Minshan Cui, Saurabh Prasad category:cs.CV  published:2016-07-18 summary:Spare representation of signals has received significant attention in recent years. Based on these developments, a sparse representation-based classification (SRC) has been proposed for a variety of classification and related tasks, including face recognition. Recently, a class dependent variant of SRC was proposed to overcome the limitations of SRC for remote sensing image classification. Traditionally, greedy pursuit based method such as orthogonal matching pursuit (OMP) are used for sparse coefficient recovery due to their simplicity as well as low time-complexity. However, orthogonal least square (OLS) has not yet been widely used in classifiers that exploit the sparse representation properties of data. Since OLS produces lower signal reconstruction error than OMP under similar conditions, we hypothesize that more accurate signal estimation will further improve the classification performance of classifiers that exploiting the sparsity of data. In this paper, we present a classification method based on OLS, which implements OLS in a classwise manner to perform the classification. We also develop and present its kernelized variant to handle nonlinearly separable data. Based on two real-world benchmarking hyperspectral datasets, we demonstrate that class dependent OLS based methods outperform several baseline methods including traditional SRC and the support vector machine classifier. version:1
arxiv-1607-04939 | Composite Kernel Local Angular Discriminant Analysis for Multi-Sensor Geospatial Image Analysis | http://arxiv.org/abs/1607.04939 | id:1607.04939 author:Saurabh Prasad, Minshan Cui, Lifeng Yan category:cs.CV  published:2016-07-18 summary:With the emergence of passive and active optical sensors available for geospatial imaging, information fusion across sensors is becoming ever more important. An important aspect of single (or multiple) sensor geospatial image analysis is feature extraction - the process of finding "optimal" lower dimensional subspaces that adequately characterize class-specific information for subsequent analysis tasks, such as classification, change and anomaly detection etc. In recent work, we proposed and developed an angle-based discriminant analysis approach that projected data onto subspaces with maximal "angular" separability in the input (raw) feature space and Reproducible Kernel Hilbert Space (RKHS). We also developed an angular locality preserving variant of this algorithm. In this letter, we advance this work and make it suitable for information fusion - we propose and validate a composite kernel local angular discriminant analysis projection, that can operate on an ensemble of feature sources (e.g. from different sources), and project the data onto a unified space through composite kernels where the data are maximally separated in an angular sense. We validate this method with the multi-sensor University of Houston hyperspectral and LiDAR dataset, and demonstrate that the proposed method significantly outperforms other composite kernel approaches to sensor (information) fusion. version:1
arxiv-1607-04917 | Piecewise convexity of artificial neural networks | http://arxiv.org/abs/1607.04917 | id:1607.04917 author:Blaine Rister category:cs.LG cs.AI cs.CV  published:2016-07-17 summary:Although artificial neural networks have shown great promise in applications ranging from computer vision to speech recognition, there remains considerable practical and theoretical difficulty in optimizing their parameters. The seemingly unreasonable success of gradient descent methods in minimizing these non-convex functions remains poorly understood. In this work we offer some theoretical guarantees concerning networks with continuous piecewise affine activation functions, which have in recent years become the norm. We prove three main results. Firstly, that the network is piecewise convex as a function of the input data. Secondly, that the network, considered as a function of the parameters in a single layer, all others held constant, is again piecewise convex. Finally, that the network as a function of all its parameters is piecewise multi-convex, a generalization of biconvexity. Accordingly, we show that any point to which gradient descent converges is a local minimum of some piece. Thus gradient descent converges to non-minima only at the boundaries of pieces. These results might offer some insights into the effectiveness of gradient descent methods in optimizing this class of networks. version:1
arxiv-1607-04903 | Learning Unitary Operators with Help From u(n) | http://arxiv.org/abs/1607.04903 | id:1607.04903 author:Stephanie L. Hyland, Gunnar Rätsch category:stat.ML cs.LG  published:2016-07-17 summary:A major challenge in the training of recurrent neural networks is the so-called vanishing or exploding gradient problem. The use of a norm-preserving transition operator can address this issue, but parametrization is challenging. In this work we focus on unitary operators and describe a parametrization using the Lie algebra u(n) associated with the Lie group U(n) of n x n unitary matrices. The exponential map provides a correspondence between these spaces, and allows us to define a unitary matrix using n^2 real coefficients relative to a basis of the Lie algebra. The parametrization is closed under additive updates of these coefficients, and thus provides a simple space in which to do gradient descent. We demonstrate the effectiveness of this parametrization on the problem of learning arbitrary unitary operators, comparing to several baselines and outperforming a recently-proposed lower-dimensional parametrization. version:1
arxiv-1607-04853 | An Empirical Evaluation of various Deep Learning Architectures for Bi-Sequence Classification Tasks | http://arxiv.org/abs/1607.04853 | id:1607.04853 author:Anirban Laha, Vikas Raykar category:cs.CL  published:2016-07-17 summary:Several tasks in argumentation mining and debating, question-answering, and natural language inference involve categorizing a sentence in the context of another sentence (referred as bi-sequence classification). For several single sequence classification tasks, the current state-of-the-art approaches are based on recurrent and convolutional neural networks. On the other hand, for bi-sequence classification problems, there is not much understanding as to the best deep learning architecture. In this paper, we attempt to get an understanding of this category of problems by extensive empirical evaluation of 19 different deep learning architectures (specifically on different ways of handling context) for various problems originating in natural language processing like debating, textual entailment and question-answering. Following the empirical evaluation, we offer our insights and conclusions regarding the architectures we have considered. We also establish the first deep learning baselines for three argumentation mining tasks. version:1
arxiv-1607-04805 | Inferring solutions of differential equations using noisy multi-fidelity data | http://arxiv.org/abs/1607.04805 | id:1607.04805 author:Maziar Raissi, Paris Perdikaris, George Em. Karniadakis category:cs.LG  published:2016-07-16 summary:For more than two centuries, solutions of differential equations have been obtained either analytically or numerically based on typically well-behaved forcing and boundary conditions for well-posed problems. We are changing this paradigm in a fundamental way by establishing an interface between probabilistic machine learning and differential equations. We develop data-driven algorithms for general linear equations using Gaussian process priors tailored to the corresponding integro-differential operators. The only observables are scarce noisy multi-fidelity data for the forcing and solution that are not required to reside on the domain boundary. The resulting predictive posterior distributions quantify uncertainty and naturally lead to adaptive solution refinement via active learning. This general framework circumvents the tyranny of numerical discretization as well as the consistency and stability issues of time-integration, and is scalable to high-dimensions. version:1
arxiv-1607-04793 | Learning to Decode Linear Codes Using Deep Learning | http://arxiv.org/abs/1607.04793 | id:1607.04793 author:Eliya Nachmani, Yair Beery, David Burshtein category:cs.IT cs.LG cs.NE math.IT  published:2016-07-16 summary:A novel deep learning method for improving the belief propagation algorithm is proposed. The method generalizes the standard belief propagation algorithm by assigning weights to the edges of the Tanner graph. These edges are then trained using deep learning techniques. A well-known property of the belief propagation algorithm is the independence of the performance on the transmitted codeword. A crucial property of our new method is that our decoder preserved this property. Furthermore, this property allows us to learn only a single codeword instead of exponential number of code-words. Improvements over the belief propagation algorithm are demonstrated for various high density parity check codes. version:1
arxiv-1607-04780 | Exploiting Multi-modal Curriculum in Noisy Web Data for Large-scale Concept Learning | http://arxiv.org/abs/1607.04780 | id:1607.04780 author:Junwei Liang, Lu Jiang, Deyu Meng, Alexander Hauptmann category:cs.CV cs.LG  published:2016-07-16 summary:Learning video concept detectors automatically from the big but noisy web data with no additional manual annotations is a novel but challenging area in the multimedia and the machine learning community. A considerable amount of videos on the web are associated with rich but noisy contextual information, such as the title, which provides weak annotations or labels about the video content. To leverage the big noisy web labels, this paper proposes a novel method called WEbly-Labeled Learning (WELL), which is established on the state-of-the-art machine learning algorithm inspired by the learning process of human. WELL introduces a number of novel multi-modal approaches to incorporate meaningful prior knowledge called curriculum from the noisy web videos. To investigate this problem, we empirically study the curriculum constructed from the multi-modal features of the videos collected from YouTube and Flickr. The efficacy and the scalability of WELL have been extensively demonstrated on two public benchmarks, including the largest multimedia dataset and the largest manually-labeled video set. The comprehensive experimental results demonstrate that WELL outperforms state-of-the-art studies by a statically significant margin on learning concepts from noisy web video data. In addition, the results also verify that WELL is robust to the level of noisiness in the video data. Notably, WELL trained on sufficient noisy web labels is able to achieve a comparable accuracy to supervised learning methods trained on the clean manually-labeled data. version:1
arxiv-1607-04773 | Construction of extended 3D field of views of the internal bladder wall surface: a proof of concept | http://arxiv.org/abs/1607.04773 | id:1607.04773 author:Achraf Ben-Hamadou, Christian Daul, Charles Soussen category:cs.CV  published:2016-07-16 summary:3D extended field of views (FOVs) of the internal bladder wall facilitate lesion diagnosis, patient follow-up and treatment traceability. In this paper, we propose a 3D image mosaicing algorithm guided by 2D cystoscopic video-image registration for obtaining textured FOV mosaics. In this feasibility study, the registration makes use of data from a 3D cystoscope prototype providing, in addition to each small FOV image, some 3D points located on the surface. This proof of concept shows that textured surfaces can be constructed with minimally modified cystoscopes. The potential of the method is demonstrated on numerical and real phantoms reproducing various surface shapes. Pig and human bladder textures are superimposed on phantoms with known shape and dimensions. These data allow for quantitative assessment of the 3D mosaicing algorithm based on the registration of images simulating bladder textures. version:1
arxiv-1607-04770 | Shesop Healthcare: Stress and influenza classification using support vector machine kernel | http://arxiv.org/abs/1607.04770 | id:1607.04770 author:Andrien Ivander Wijaya, Ary Setijadi Prihatmanto, Rifki Wijaya category:cs.CY cs.LG G.1.2; J.3; I.2.1  published:2016-07-16 summary:Shesop is an integrated system to make human lives more easily and to help people in terms of healthcare. Stress and influenza classification is a part of Shesop's application for a healthcare devices such as smartwatch, polar and fitbit. The main objective of this paper is to classify a new data and inform whether you are stress, depressed, caught by influenza or not. We will use the heart rate data taken for months in Bandung, analyze the data and find the Heart rate variance that constantly related with the stress and flu level. After we found the variable, we will use the variable as an input to the support vector machine learning. We will use the lagrangian and kernel technique to transform 2D data into 3D data so we can use the linear classification in 3D space. In the end, we could use the machine learning's result to classify new data and get the final result immediately: stress or not, influenza or not. version:1
arxiv-1607-04760 | Design and implementation of image processing system for Lumen social robot-humanoid as an exhibition guide for Electrical Engineering Days 2015 | http://arxiv.org/abs/1607.04760 | id:1607.04760 author:Setyaki Sholata Sya, Ary Setijadi Prihatmanto category:cs.CV cs.HC cs.RO I.2.10; H.5.2  published:2016-07-16 summary:Lumen Social Robot is a humanoid robot development with the purpose that it could be a good friend to all people. In this year, the Lumen Social Robot is being developed into a guide in the exhibition and in the seminar of the Final Exam of undergraduate and graduate students in Electrical Engineering ITB, named Electrical Engineering Days 2015. In order to be the guide in that occasion, Lumen is supported by several things. They are Nao robot components, servers, and multiple processor systems. The image processing system is a processing application system that allows Lumen to recognize and determine an object from the image taken from the camera eye. The image processing system is provided with four modules. They are face detection module to detect a person's face, face recognition module to recognize a person's face, face tracking module to follow a person's face, and human detection module to detect humans based on the upper parts of person's body. Face detection module and human detection module are implemented by using the library harcascade.xml on EMGU CV. Face recognition module is implemented by adding the database for the face that has been detected and store it in that database. Face tracking module is implemented by using the Smooth Gaussian filter to the image. ----- Lumen Sosial Robot merupakan sebuah pengembangan robot humanoid agar dapat menjadi teman bagi banyak orang. Sistem pengolahan citra merupakan sistem aplikasi pengolah yang bertujuan Lumen dapat mengenali dan mengetahui suatu objek pada citra yang diambil dari camera mata Lumen. System pengolahan citra dilengkapi dengan empat buah modul, yaitu modul face detection untuk mendeteksi wajah seseorang, modul face recognition untuk mengenali wajah orang tersebut, modul face tracking untuk mengikuti wajah seseorang, dan modul human detection untuk mendeteksi manusia berdasarkan bagian tubuh atas orang version:1
arxiv-1607-04759 | New version of Gram-Schmidt Process with inverse for Signal and Image Processing | http://arxiv.org/abs/1607.04759 | id:1607.04759 author:Mario Mastriani category:cs.CV  published:2016-07-16 summary:The Gram-Schmidt Process (GSP) is used to convert a non-orthogonal basis (a set of linearly independent vectors, matrices, etc) into an orthonormal basis (a set of orthogonal, unit-length vectors, bi or tri dimensional matrices). The process consists of taking each array and then subtracting the projections in common with the previous arrays. This paper introduces an enhanced version of the Gram-Schmidt Process (EGSP) with inverse, which is useful for Digital Signal and Image Processing, among others applications. version:1
arxiv-1607-04747 | Learning Social Circles in Ego Networks based on Multi-View Social Graphs | http://arxiv.org/abs/1607.04747 | id:1607.04747 author:Chao Lan, Yuhao Yang, Xiaoli Li, Bo Luo, Jun Huan category:cs.SI cs.LG 68T01  published:2016-07-16 summary:Automatic social circle detection in ego-networks is becoming a fundamentally important task for social network analysis, which can be used for privacy protection or interest group recommendation. So far, most studies focused on how to detect overlapping circles or how to perform detection using both network structure and its node profiles. This paper asks an orthogonal research question: how to detect social circles by leveraging the multiple views of the network structure? As a first step, we crawl ego networks from Twitter to construct multi-view social graphs with six views, including two relationship views, three interaction views and one content view. Then, we apply both standard and our modified multi-view spectral clustering methods on the graph to detect circles. Based on extensive automatic and manual evaluations, we deliver two major findings: first, multi-view clustering methods detect better circles than single-view clustering methods; second, by presuming the sparse social graphs are incomplete, our modified method detects better circles than the standard method that ignores such potential incompleteness. In particular, we believe a direct application of the standard method on a possibly incomplete graph may yield a biased result. By integrating theories from spectral clustering and matrix perturbation, we prove an information-theoretic upper bound for such bias and discuss how it may be affected by the characteristics of the social network. version:1
arxiv-1607-04731 | Weakly supervised object detection using pseudo-strong labels | http://arxiv.org/abs/1607.04731 | id:1607.04731 author:Ke Yang, Dongsheng Li, Yong Dou, Shaohe Lv, Qiang Wang category:cs.CV  published:2016-07-16 summary:Object detection is an import task of computer vision.A variety of methods have been proposed,but methods using the weak labels still do not have a satisfactory result.In this paper,we propose a new framework that using the weakly supervised method's output as the pseudo-strong labels to train a strongly supervised model.One weakly supervised method is treated as black-box to generate class-specific bounding boxes on train dataset.A de-noise method is then applied to the noisy bounding boxes.Then the de-noised pseudo-strong labels are used to train a strongly object detection network.The whole framework is still weakly supervised because the entire process only uses the image-level labels.The experiment results on PASCAL VOC 2007 prove the validity of our framework, and we get result 43.4% on mean average precision compared to 39.5% of the previous best result and 34.5% of the initial method,respectively.And this frame work is simple and distinct,and is promising to be applied to other method easily. version:1
arxiv-1607-04730 | Two-Stream Convolutional Networks for Dynamic Saliency Prediction | http://arxiv.org/abs/1607.04730 | id:1607.04730 author:Çağdaş Bak, Aykut Erdem, Erkut Erdem category:cs.CV  published:2016-07-16 summary:In recent years, visual saliency estimation in images has attracted much attention in the computer vision community. However, predicting saliency in videos has received rela- tively little attention. Inspired by the recent success of deep convolutional neural networks based static saliency mod- els, in this work, we study two different two-stream convo- lutional networks for dynamic saliency prediction. To im- prove the generalization capability of our models, we also introduce a novel, empirically grounded data augmenta- tion technique for this task. We test our models on DIEM dataset and report superior results against the existing mod- els. Moreover, we perform transfer learning experiments on SALICON, a recently proposed static saliency dataset, by finetuning our models on the optical flows estimated from static images. Our experiments show that taking motion into account in this way can be helpful for static saliency estimation. version:1
arxiv-1607-04683 | On the efficient representation and execution of deep acoustic models | http://arxiv.org/abs/1607.04683 | id:1607.04683 author:Raziel Alvarez, Rohit Prabhavalkar, Anton Bakhtin category:cs.LG cs.CL  published:2016-07-15 summary:In this paper we present a simple and computationally efficient quantization scheme that enables us to reduce the resolution of the parameters of a neural network from 32-bit floating point values to 8-bit integer values. The proposed quantization scheme leads to significant memory savings and enables the use of optimized hardware instructions for integer arithmetic, thus significantly reducing the cost of inference. Finally, we propose a "quantization aware" training process that applies the proposed scheme during network training and find that it allows us to recover most of the loss in accuracy introduced by quantization. We validate the proposed techniques by applying them to a long short-term memory-based acoustic model on an open-ended large vocabulary speech recognition task. version:1
arxiv-1607-04673 | Registration based Tracking with Structural Similarity : A Unifying Formulation | http://arxiv.org/abs/1607.04673 | id:1607.04673 author:Abhineet Singh, Martin Jagersand category:cs.CV  published:2016-07-15 summary:This paper adapts a popular image quality measure called Structural Similarity for high precision registration based tracking while also introducing a simpler and faster variant of the same. Further, to evaluate these comprehensively against existing measures, it presents a unified way to study registration based trackers by decomposing them into three constituent sub modules: appearance model, state space model and search method. This approach has relevance beyond the present work as it is often the case that when a new tracker is introduced in this domain, it only contributes to one or two of these sub modules while using existing methods for the rest. Since these are often selected arbitrarily by the authors, they may not be optimal for the new method. In such cases, this breakdown can help to experimentally find the best combination of methods for these sub modules while also providing a framework within which the contributions of the new tracker can be clearly demarcated and thus studied better. %We show how existing trackers can be broken down using the suggested methodology and compare the performance of the default configuration chosen by the authors against other possible combinations to demonstrate the new insights that can be gained by such an approach. All experiments are performed using an open source tracking framework on three publicly available datasets so the results are easily reproducible. In addition, this framework, by following this decomposition closely through extensive use of generic programming, provides a convenient interface to plug in a new method for any sub module and combine it with existing methods for the others. It can also serve as a fast and flexible solution for practical tracking requirements owing to its highly efficient C++ implementation. version:1
arxiv-1607-04614 | Guided Policy Search as Approximate Mirror Descent | http://arxiv.org/abs/1607.04614 | id:1607.04614 author:William Montgomery, Sergey Levine category:cs.LG cs.RO  published:2016-07-15 summary:Guided policy search algorithms can be used to optimize complex nonlinear policies, such as deep neural networks, without directly computing policy gradients in the high-dimensional parameter space. Instead, these methods use supervised learning to train the policy to mimic a "teacher" algorithm, such as a trajectory optimizer or a trajectory-centric reinforcement learning method. Guided policy search methods provide asymptotic local convergence guarantees by construction, but it is not clear how much the policy improves within a small, finite number of iterations. We show that guided policy search algorithms can be interpreted as an approximate variant of mirror descent, where the projection onto the constraint manifold is not exact. We derive a new guided policy search algorithm that is simpler and provides appealing improvement and convergence guarantees in simplified convex and linear settings, and show that in the more general nonlinear setting, the error in the projection step can be bounded. We provide empirical results on several simulated robotic navigation and manipulation tasks that show that our method is stable and achieves similar or better performance when compared to prior guided policy search methods, with a simpler formulation and fewer hyperparameters. version:1
arxiv-1607-04609 | Person Re-identification with Hyperspectral Multi-Camera Systems --- A Pilot Study | http://arxiv.org/abs/1607.04609 | id:1607.04609 author:Saurabh Prasad, Tanu Priya, Minshan Cui, Shishir Shah category:cs.CV  published:2016-07-15 summary:Person re-identification in a multi-camera environment is an important part of modern surveillance systems. Person re-identification from color images has been the focus of much active research, due to the numerous challenges posed with such analysis tasks, such as variations in illumination, pose and viewpoints. In this paper, we suggest that hyperspectral imagery has the potential to provide unique information that is expected to be beneficial for the re-identification task. Specifically, we assert that by accurately characterizing the unique spectral signature for each person's skin, hyperspectral imagery can provide very useful descriptors (e.g. spectral signatures from skin pixels) for re-identification. Towards this end, we acquired proof-of-concept hyperspectral re-identification data under challenging (practical) conditions from 15 people. Our results indicate that hyperspectral data result in a substantially enhanced re-identification performance compared to color (RGB) images, when using spectral signatures over skin as the feature descriptor. version:1
arxiv-1607-04606 | Enriching Word Vectors with Subword Information | http://arxiv.org/abs/1607.04606 | id:1607.04606 author:Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov category:cs.CL cs.LG  published:2016-07-15 summary:Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Many popular models to learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for morphologically rich languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skip-gram model, where each word is represented as a bag of character n-grams. A vector representation is associated to each character n-gram, words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpus quickly. We evaluate the obtained word representations on five different languages, on word similarity and analogy tasks. version:1
arxiv-1607-04593 | Spatial Context based Angular Information Preserving Projection for Hyperspectral Image Classification | http://arxiv.org/abs/1607.04593 | id:1607.04593 author:Minshan Cui, Saurabh Prasad category:cs.CV  published:2016-07-15 summary:Dimensionality reduction is a crucial preprocessing for hyperspectral data analysis - finding an appropriate subspace is often required for subsequent image classification. In recent work, we proposed supervised angular information based dimensionality reduction methods to find effective subspaces. Since unlabeled data are often more readily available compared to labeled data, we propose an unsupervised projection that finds a lower dimensional subspace where local angular information is preserved. To exploit spatial information from the hyperspectral images, we further extend our unsupervised projection to incorporate spatial contextual information around each pixel in the image. Additionally, we also propose a sparse representation based classifier which is optimized to exploit spatial information during classification - we hence assert that our proposed projection is particularly suitable for classifiers where local similarity and spatial context are both important. Experimental results with two real-world hyperspectral datasets demonstrate that our proposed methods provide a robust classification performance. version:1
arxiv-1607-04589 | Automatic Environmental Sound Recognition: Performance versus Computational Cost | http://arxiv.org/abs/1607.04589 | id:1607.04589 author:Siddharth Sigtia, Adam M. Stark, Sacha Krstulovic, Mark D. Plumbley category:cs.SD cs.LG cs.NE  published:2016-07-15 summary:In the context of the Internet of Things (IoT), sound sensing applications are required to run on embedded platforms where notions of product pricing and form factor impose hard constraints on the available computing power. Whereas Automatic Environmental Sound Recognition (AESR) algorithms are most often developed with limited consideration for computational cost, this article seeks which AESR algorithm can make the most of a limited amount of computing power by comparing the sound classification performance em as a function of its computational cost. Results suggest that Deep Neural Networks yield the best ratio of sound classification accuracy across a range of computational costs, while Gaussian Mixture Models offer a reasonable accuracy at a consistently small cost, and Support Vector Machines stand between both in terms of compromise between accuracy and computational cost. version:1
arxiv-1607-04579 | Learning from Conditional Distributions via Dual Kernel Embeddings | http://arxiv.org/abs/1607.04579 | id:1607.04579 author:Bo Dai, Niao He, Yunpeng Pan, Byron Boots, Le Song category:cs.LG math.OC stat.ML  published:2016-07-15 summary:In many machine learning problems, such as policy evaluation in reinforcement learning and learning with invariance, each data point $x$ itself is a conditional distribution $p(z x)$, and we want to learn a function $f$ which links these conditional distributions to target values $y$. The learning problem becomes very challenging when we only have limited samples or in the extreme case only one sample from each conditional distribution $p(z x)$. Commonly used approaches either assume that $z$ is independent of $x$, or require an overwhelmingly large sample size from each conditional distribution. To address these challenges, we propose a novel approach which reformulates the original problem into a min-max optimization problem. In the new view, we only need to deal with the kernel embedding of the joint distribution $p(z,x)$ which is easy to estimate. Furthermore, we design an efficient learning algorithm based on mirror descent stochastic approximation, and establish the sample complexity for learning from conditional distributions. Finally, numerical experiments in both synthetic and real data show that our method can significantly improve over the previous state-of-the-arts. version:1
arxiv-1607-04576 | Neural Discourse Modeling of Conversations | http://arxiv.org/abs/1607.04576 | id:1607.04576 author:John M. Pierre, Mark Butler, Jacob Portnoff, Luis Aguilar category:cs.CL cs.NE  published:2016-07-15 summary:Deep neural networks have shown recent promise in many language-related tasks such as the modeling of conversations. We extend RNN-based sequence to sequence models to capture the long range discourse across many turns of conversation. We perform a sensitivity analysis on how much additional context affects performance, and provide quantitative and qualitative evidence that these models are able to capture discourse relationships across multiple utterances. Our results quantifies how adding an additional RNN layer for modeling discourse improves the quality of output utterances and providing more of the previous conversation as input also improves performance. By searching the generated outputs for specific discourse markers we show how neural discourse models can exhibit increased coherence and cohesion in conversations. version:1
arxiv-1607-04573 | Analyzing features learned for Offline Signature Verification using Deep CNNs | http://arxiv.org/abs/1607.04573 | id:1607.04573 author:Luiz G. Hafemann, Robert Sabourin, Luiz S. Oliveira category:cs.CV stat.ML  published:2016-07-15 summary:Research on Offline Handwritten Signature Verification explored a large variety of handcrafted feature extractors, ranging from graphology, texture descriptors to interest points. In spite of advancements in the last decades, performance of such systems is still far from optimal when we test the systems against skilled forgeries - signature forgeries that target a particular individual. In previous research, we proposed a formulation of the problem to learn features from data (signature images) in a Writer-Independent format, using Deep Convolutional Neural Networks (CNNs), seeking to improve performance on the task. In this research, we push further the performance of such method, exploring a range of architectures, and obtaining a large improvement in state-of-the-art performance on the GPDS dataset, the largest publicly available dataset on the task. In the GPDS-160 dataset, we obtained an Equal Error Rate of 2.74%, compared to 6.97% in the best result published in literature (that used a combination of multiple classifiers). We also present a visual analysis of the feature space learned by the model, and an analysis of the errors made by the classifier. Our analysis shows that the model is very effective in separating signatures that have a different global appearance, while being particularly vulnerable to forgeries that very closely resemble genuine signatures, even if their line quality is bad, which is the case of slowly-traced forgeries. version:1
arxiv-1607-04566 | Spectral Echolocation via the Wave Embedding | http://arxiv.org/abs/1607.04566 | id:1607.04566 author:Alexander Cloninger, Stefan Steinerberger category:stat.ML  published:2016-07-15 summary:Spectral embedding uses eigenfunctions of the discrete Laplacian on a weighted graph to obtain coordinates for an embedding of an abstract data set into Euclidean space. We propose a new pre-processing step of first using the eigenfunctions to simulate a low-frequency wave moving over the data and using both position as well as change in time of the wave to obtain a refined metric to which classical methods of dimensionality reduction can then applied. This is motivated by the behavior of waves, symmetries of the wave equation and the hunting technique of bats. It is shown to be effective in practice and also works for other partial differential equations -- the method yields improved results even for the classical heat equation. version:1
arxiv-1607-04515 | Multi-body Non-rigid Structure-from-Motion | http://arxiv.org/abs/1607.04515 | id:1607.04515 author:Suryansh Kumar, Yuchao Dai, Hongdong Li category:cs.CV  published:2016-07-15 summary:Conventional structure-from-motion (SFM) research is primarily concerned with the 3D reconstruction of a single, rigidly moving object seen by a static camera, or a static and rigid scene observed by a moving camera --in both cases there are only one relative rigid motion involved. Recent progress have extended SFM to the areas of {multi-body SFM} (where there are {multiple rigid} relative motions in the scene), as well as {non-rigid SFM} (where there is a single non-rigid, deformable object or scene). Along this line of thinking, there is apparently a missing gap of "multi-body non-rigid SFM", in which the task would be to jointly reconstruct and segment multiple 3D structures of the multiple, non-rigid objects or deformable scenes from images. Such a multi-body non-rigid scenario is common in reality (e.g. two persons shaking hands, multi-person social event), and how to solve it represents a natural {next-step} in SFM research. By leveraging recent results of subspace clustering, this paper proposes, for the first time, an effective framework for multi-body NRSFM, which simultaneously reconstructs and segments each 3D trajectory into their respective low-dimensional subspace. Under our formulation, 3D trajectories for each non-rigid structure can be well approximated with a sparse affine combination of other 3D trajectories from the same structure (self-expressiveness). We solve the resultant optimization with the alternating direction method of multipliers (ADMM). We demonstrate the efficacy of the proposed framework through extensive experiments on both synthetic and real data sequences. Our method clearly outperforms other alternative methods, such as first clustering the 2D feature tracks to groups and then doing non-rigid reconstruction in each group or first conducting 3D reconstruction by using single subspace assumption and then clustering the 3D trajectories into groups. version:1
arxiv-1607-04492 | Neural Tree Indexers for Text Understanding | http://arxiv.org/abs/1607.04492 | id:1607.04492 author:Tsendsuren Munkhdalai, Hong Yu category:cs.CL cs.LG stat.ML  published:2016-07-15 summary:Neural networks with recurrent or recursive architecture have shown promising results on various natural language processing (NLP) tasks. The recurrent and recursive architectures have their own strength and limitations. The recurrent networks process input text sequentially and model the conditional transition between word tokens. In contrast, the recursive networks explicitly model the compositionality and the recursive structure of natural language. Current recursive architecture is based on syntactic tree, thus limiting its practical applicability in different NLP applications. In this paper, we introduce a class of tree structured model, Neural Tree Indexers (NTI) that provides a middle ground between the sequential RNNs and the syntactic tree-based recursive models. NTI constructs a full n-ary tree by processing the input text with its node function in a bottom-up fashion. Attention mechanism can then be applied to both structure and different forms of node function. We demonstrated the effectiveness and the flexibility of a binary-tree model of NTI, showing the model achieved the state-of-the-art performance on three different NLP tasks: natural language inference, answer sentence selection, and sentence classification. version:1
arxiv-1607-04450 | Channel Selection Algorithm for Cognitive Radio Networks with Heavy-Tailed Idle Times | http://arxiv.org/abs/1607.04450 | id:1607.04450 author:S. Senthilmurugan, Junaid Ansari, Petri Mähönen, T. G. Venkatesh, Marina Petrova category:cs.NI cs.LG  published:2016-07-15 summary:We consider a multichannel Cognitive Radio Network (CRN), where secondary users sequentially sense channels for opportunistic spectrum access. In this scenario, the Channel Selection Algorithm (CSA) allows secondary users to find a vacant channel with the minimal number of channel switches. Most of the existing CSA literature assumes exponential ON-OFF time distribution for primary users (PU) channel occupancy pattern. This exponential assumption might be helpful to get performance bounds; but not useful to evaluate the performance of CSA under realistic conditions. An in-depth analysis of independent spectrum measurement traces reveals that wireless channels have typically heavy-tailed PU OFF times. In this paper, we propose an extension to the Predictive CSA framework and its generalization for heavy tailed PU OFF time distribution, which represents realistic scenarios. In particular, we calculate the probability of channel being idle for hyper-exponential OFF times to use in CSA. We implement our proposed CSA framework in a wireless test-bed and comprehensively evaluate its performance by recreating the realistic PU channel occupancy patterns. The proposed CSA shows significant reduction in channel switches and energy consumption as compared to Predictive CSA which always assumes exponential PU ON-OFF times.Through our work, we show the impact of the PU channel occupancy pattern on the performance of CSA in multichannel CRN. version:1
arxiv-1607-04441 | A Real-Time Pedestrian Detector using Deep Learning for Human-Aware Navigation | http://arxiv.org/abs/1607.04441 | id:1607.04441 author:David Ribeiro, Andre Mateus, Jacinto C. Nascimento, Pedro Miraldo category:cs.RO cs.CV  published:2016-07-15 summary:This paper addresses the problem of Human-Aware Navigation (HAN), using multi camera sensors to implement a vision-based person tracking system. The main contributions of this paper are a novel and real-time Deep Learning person detection and a standardization of personal space, that can be used with any path planer. In the first stage of the approach, we propose to cascade the Aggregate Channel Features (ACF) detector with a deep Convolutional Neural Network (CNN) to achieve fast and accurate Pedestrian Detection (PD). For the personal space definition (that can be defined as constraints associated with the robot's motion), we used a mixture of asymmetric Gaussian functions, to define the cost functions associated to each constraint. Both methods were evaluated individually. The final solution (including both the proposed pedestrian detection and the personal space constraints) was tested in a typical domestic indoor scenario, in four distinct experiments. The results show that the robot is able to cope with human-aware constraints, defined after common proxemics rules. version:1
arxiv-1607-04436 | A Real-Time Deep Learning Pedestrian Detector for Robot Navigation | http://arxiv.org/abs/1607.04436 | id:1607.04436 author:David Ribeiro, Andre Mateus, Jacinto C. Nascimento, Pedro Miraldo category:cs.RO cs.CV  published:2016-07-15 summary:A real-time Deep Learning based method for Pedestrian Detection (PD) is applied to the Human-Aware robot navigation problem. The pedestrian detector combines the Aggregate Channel Features (ACF) detector with a deep Convolutional Neural Network (CNN) in order to obtain fast and accurate performance. Our solution is firstly evaluated using a set of real images taken from onboard and offboard cameras and, then, it is validated in a typical domestic indoor scenario, in two distinct experiments. The results show that the robot is able to cope with human-aware constraints, defined after common proxemics rules. version:1
arxiv-1607-04433 | End-to-End Learning for Image Burst Deblurring | http://arxiv.org/abs/1607.04433 | id:1607.04433 author:Patrick Wieschollek, Michael Hirsch, Hendrik P. A. Lensch, Bernhard Schölkopf category:cs.CV  published:2016-07-15 summary:We present a neural network model approach for multi-frame blind deconvolution. The discriminative approach adopts and combines two recent techniques for image deblurring into a single neural network architecture. Our proposed hybrid-architecture combines the explicit prediction of a deconvolution filter and non-trivial averaging of Fourier coefficients in the frequency domain. In order to make full use of the information contained in all images in one burst, the proposed network embeds smaller networks, which explicitly allow the model to transfer information between images in early layers. Our system is trained end-to-end using standard backpropagation on a set of artificially generated training examples, enabling competitive performance in multi-frame blind deconvolution, both with respect to quality and runtime. version:1
arxiv-1607-05073 | Higher-Order Block Term Decomposition for Spatially Folded fMRI Data | http://arxiv.org/abs/1607.05073 | id:1607.05073 author:Christos Chatzichristos, Eleftherios Kofidis, Giannis Kopsinis, Sergios Theodoridis category:cs.NA stat.ML  published:2016-07-15 summary:The growing use of neuroimaging technologies generates a massive amount of biomedical data that exhibit high dimensionality. Tensor-based analysis of brain imaging data has been proved quite effective in exploiting their multiway nature. The advantages of tensorial methods over matrix-based approaches have also been demonstrated in the characterization of functional magnetic resonance imaging (fMRI) data, where the spatial (voxel) dimensions are commonly grouped (unfolded) as a single way/mode of the 3-rd order array, the other two ways corresponding to time and subjects. However, such methods are known to be ineffective in more demanding scenarios, such as the ones with strong noise and/or significant overlapping of activated regions. This paper aims at investigating the possible gains from a better exploitation of the spatial dimension, through a higher- (4 or 5) order tensor modeling of the fMRI signal. In this context, and in order to increase the degrees of freedom of the modeling process, a higher-order Block Term Decomposition (BTD) is applied, for the first time in fMRI analysis. Its effectiveness is demonstrated via extensive simulation results. version:1
arxiv-1607-04411 | Model-Driven Feed-Forward Prediction for Manipulation of Deformable Objects | http://arxiv.org/abs/1607.04411 | id:1607.04411 author:Yinxiao Li, Yan Wang, Yonghao Yue, Danfei Xu, Michael Case, Shih-Fu Chang, Eitan Grinspun, Peter Allen category:cs.CV cs.GR cs.RO  published:2016-07-15 summary:Robotic manipulation of deformable objects is a difficult problem especially because of the complexity of the many different ways an object can deform. Searching such a high dimensional state space makes it difficult to recognize, track, and manipulate deformable objects. In this paper, we introduce a predictive, model-driven approach to address this challenge, using a pre-computed, simulated database of deformable object models. Mesh models of common deformable garments are simulated with the garments picked up in multiple different poses under gravity, and stored in a database for fast and efficient retrieval. To validate this approach, we developed a comprehensive pipeline for manipulating clothing as in a typical laundry task. First, the database is used for category and pose estimation for a garment in an arbitrary position. A fully featured 3D model of the garment is constructed in real-time and volumetric features are then used to obtain the most similar model in the database to predict the object category and pose. Second, the database can significantly benefit the manipulation of deformable objects via non-rigid registration, providing accurate correspondences between the reconstructed object model and the database models. Third, the accurate model simulation can also be used to optimize the trajectories for manipulation of deformable objects, such as the folding of garments. Extensive experimental results are shown for the tasks above using a variety of different clothing. version:1
arxiv-1607-04063 | Update Strength in EDAs and ACO: How to Avoid Genetic Drift | http://arxiv.org/abs/1607.04063 | id:1607.04063 author:Dirk Sudholt, Carsten Witt category:cs.NE  published:2016-07-14 summary:We provide a rigorous runtime analysis concerning the update strength, a vital parameter in probabilistic model-building GAs such as the step size $1/K$ in the compact Genetic Algorithm (cGA) and the evaporation factor $\rho$ in ACO. While a large update strength is desirable for exploitation, there is a general trade-off: too strong updates can lead to genetic drift and poor performance. We demonstrate this trade-off for the cGA and a simple MMAS ACO algorithm on the OneMax function. More precisely, we obtain lower bounds on the expected runtime of $\Omega(K\sqrt{n} + n \log n)$ and $\Omega(\sqrt{n}/\rho + n \log n)$, respectively, showing that the update strength should be limited to $1/K, \rho = O(1/(\sqrt{n} \log n))$. In fact, choosing $1/K, \rho \sim 1/(\sqrt{n}\log n)$ both algorithms efficiently optimize OneMax in expected time $O(n \log n)$. Our analyses provide new insights into the stochastic behavior of probabilistic model-building GAs and propose new guidelines for setting the update strength in global optimization. version:2
arxiv-1607-07697 | Low-complexity feedback-channel-free distributed video coding using Local Rank Transform | http://arxiv.org/abs/1607.07697 | id:1607.07697 author:P Raj Bhagath, Kallol Mallick, Jayanta Mukherjee, Sudipta Mukopadhayay category:cs.MM cs.CV cs.IT math.IT  published:2016-07-15 summary:In this paper, we propose a new feedback-channel-free Distributed Video Coding (DVC) algorithm using Local Rank Transform (LRT). The encoder computes LRT by considering selected neighborhood pixels of Wyner-Ziv frame. The ranks from the modified LRT are merged, and their positions are entropy coded and sent to the decoder. In addition, means of each block of Wyner-Ziv frame are also transmitted to assist motion estimation. Using these measurements, the decoder generates side information (SI) by implementing motion estimation and compensation in LRT domain. An iterative algorithm is executed on SI using LRT to reconstruct the Wyner-Ziv frame. Experimental results show that the coding efficiency of our codec is close to the efficiency of pixel domain distributed video coders based on Low-Density Parity Check and Accumulate (LDPCA) or turbo codes, with less encoder complexity. version:1
arxiv-1607-04381 | DSD: Regularizing Deep Neural Networks with Dense-Sparse-Dense Training Flow | http://arxiv.org/abs/1607.04381 | id:1607.04381 author:Song Han, Jeff Pool, Sharan Narang, Huizi Mao, Shijian Tang, Erich Elsen, Bryan Catanzaro, John Tran, William J. Dally category:cs.CV  published:2016-07-15 summary:Modern deep neural networks have a large number of parameters, making them very powerful machine learning systems. A critical issue for training such large networks on large-scale data-sets is to prevent overfitting while at the same time providing enough model capacity. We propose DSD, a dense-sparse-dense training flow, for regularizing deep neural networks. In the first D step, we train a dense network to learn which connections are important. In the S step, we regularize the network by pruning the unimportant connections and retrain the network given the sparsity constraint. In the final D step, we increase the model capacity by freeing the sparsity constraint, re-initializing the pruned parameters, and retraining the whole dense network. Experiments show that DSD training can improve the performance of a wide range of CNN, RNN and LSTMs on the tasks of image classification, caption generation and speech recognition. On the Imagenet dataset, DSD improved the absolute accuracy of AlexNet, GoogleNet, VGG-16, ResNet-50, ResNet-152 and SqueezeNet by a geo-mean of 2.1 points(Top-1) and 1.4 points(Top-5). On the WSJ'92 and WSJ'93 dataset, DSD improved DeepSpeech-2 WER by 0.53 and 1.08 points. On the Flickr-8K dataset, DSD improved the NeuralTalk BLEU score by 2.0 points. DSD training flow produces the same model architecture and doesn't incur any inference overhead. version:1
arxiv-1607-04379 | DeepQA: Improving the estimation of single protein model quality with deep belief networks | http://arxiv.org/abs/1607.04379 | id:1607.04379 author:Renzhi Cao, Debswapna Bhattacharya, Jie Hou, Jianlin Cheng category:cs.AI cs.LG q-bio.QM  published:2016-07-15 summary:Protein quality assessment (QA) by ranking and selecting protein models has long been viewed as one of the major challenges for protein tertiary structure prediction. Especially, estimating the quality of a single protein model, which is important for selecting a few good models out of a large model pool consisting of mostly low-quality models, is still a largely unsolved problem. We introduce a novel single-model quality assessment method DeepQA based on deep belief network that utilizes a number of selected features describing the quality of a model from different perspectives, such as energy, physio-chemical characteristics, and structural information. The deep belief network is trained on several large datasets consisting of models from the Critical Assessment of Protein Structure Prediction (CASP) experiments, several publicly available datasets, and models generated by our in-house ab initio method. Our experiment demonstrate that deep belief network has better performance compared to Support Vector Machines and Neural Networks on the protein model quality assessment problem, and our method DeepQA achieves the state-of-the-art performance on CASP11 dataset. It also outperformed two well-established methods in selecting good outlier models from a large set of models of mostly low quality generated by ab initio modeling methods. DeepQA is a useful tool for protein single model quality assessment and protein structure prediction. The source code, executable, document and training/test datasets of DeepQA for Linux is freely available to non-commercial users at http://cactus.rnet.missouri.edu/DeepQA/. version:1
arxiv-1607-04331 | Random projections of random manifolds | http://arxiv.org/abs/1607.04331 | id:1607.04331 author:Subhaneil Lahiri, Peiran Gao, Surya Ganguli category:stat.ML cs.LG q-bio.NC  published:2016-07-14 summary:A ubiquitous phenomenon is that interesting signals or data concentrate on low dimensional smooth manifolds inside a high dimensional ambient Euclidean space. Random projections are a simple and powerful tool for dimensionality reduction of such signals and data. Previous, seminal works have studied bounds on how the number of projections needed to preserve the geometry of these manifolds, at a given accuracy, scales with the intrinsic dimensionality, volume and curvature of the manifold. However, such works employ definitions of volume and curvature that are inherently difficult to compute. Therefore such theory cannot be easily tested against numerical simulations to quantitatively understand the tightness of the proven bounds. We instead study the typical distortions arising in random projections of an ensemble of smooth Gaussian random manifolds. In doing so, we find explicitly computable, approximate theoretical bounds on the number of projections required to preserve the geometric structure of these manifolds to a prescribed level of accuracy. Our bounds, while approximate, can only be violated with a probability that is exponentially small in the ambient dimension, and therefore they hold with high probability in most cases of practical interest. Moreover, unlike previous work, we test our theoretical bounds against numerical experiments on the actual geometric distortions that typically occur for random projections of random smooth manifolds. Through this comparison, we find our bounds are tighter than previous results by several orders of magnitude. version:1
arxiv-1607-04311 | Defensive Distillation is Not Robust to Adversarial Examples | http://arxiv.org/abs/1607.04311 | id:1607.04311 author:Nicholas Carlini, David Wagner category:cs.CR cs.CV  published:2016-07-14 summary:We show that defensive distillation is not secure: it is no more resistant to targeted misclassification attacks than unprotected neural networks. version:1
arxiv-1607-04243 | A real-time analysis of rock fragmentation using UAV technology | http://arxiv.org/abs/1607.04243 | id:1607.04243 author:Thomas Bamford, Kamran Esmaeili, Angela P. Schoellig category:cs.RO cs.CV  published:2016-07-14 summary:Accurate measurement of blast-induced rock fragmentation is of great importance for many mining operations. The post-blast rock size distribution can significantly influence the efficiency of all the downstream mining and comminution processes. Image analysis methods are one of the most common methods used to measure rock fragment size distribution in mines regardless of criticism for lack of accuracy to measure fine particles and other perceived deficiencies. The current practice of collecting rock fragmentation data for image analysis is highly manual and provides data with low temporal and spatial resolution. Using UAVs for collecting images of rock fragments can not only improve the quality of the image data but also automate the data collection process. Ultimately, real-time acquisition of high temporal- and spatial-resolution data based on UAV technology will provide a broad range of opportunities for both improving blast design without interrupting the production process and reducing the cost of the human operator. This paper presents the results of a series of laboratory-scale rock fragment measurements using a quadrotor UAV equipped with a camera. The goal of this work is to highlight the benefits of aerial fragmentation analysis in terms of both prediction accuracy and time effort. A pile of rock fragments with different fragment sizes was placed in a lab that is equipped with a motion capture camera system for precise UAV localization and control. Such an environment presents optimal conditions for UAV flight and thus, is well-suited for conducting proof-of-concept experiments before testing them in large-scale field experiments. The pile was photographed by a camera attached to the UAV, and the particle size distribution curves were generated in almost real-time. The pile was also manually photographed and the results of the manual method were compared to the UAV method. version:1
arxiv-1607-04228 | Fifty Shades of Ratings: How to Benefit from a Negative Feedback in Top-N Recommendations Tasks | http://arxiv.org/abs/1607.04228 | id:1607.04228 author:Evgeny Frolov, Ivan Oseledets category:cs.LG cs.IR stat.ML H.3.3  published:2016-07-14 summary:Conventional collaborative filtering techniques treat a top-n recommendations problem as a task of generating a list of the most relevant items. This formulation, however, disregards an opposite - avoiding recommendations with completely irrelevant items. Due to that bias, standard algorithms, as well as commonly used evaluation metrics, become insensitive to negative feedback. In order to resolve this problem we propose to treat user feedback as a categorical variable and model it with users and items in a ternary way. We employ a third-order tensor factorization technique and implement a higher order folding-in method to support online recommendations. The method is equally sensitive to entire spectrum of user ratings and is able to accurately predict relevant items even from a negative only feedback. Our method may partially eliminate the need for complicated rating elicitation process as it provides means for personalized recommendations from the very beginning of an interaction with a recommender system. We also propose a modification of standard metrics which helps to reveal unwanted biases and account for sensitivity to a negative feedback. Our model achieves state-of-the-art quality in standard recommendation tasks while significantly outperforming other methods in the cold-start "no-positive-feedback" scenarios. version:1
arxiv-1607-04209 | Dynamic Question Ordering in Online Surveys | http://arxiv.org/abs/1607.04209 | id:1607.04209 author:Kirstin Early, Jennifer Mankoff, Stephen E. Fienberg category:stat.OT stat.ME stat.ML  published:2016-07-14 summary:Online surveys have the potential to support adaptive questions, where later questions depend on earlier responses. Past work has taken a rule-based approach, uniformly across all respondents. We envision a richer interpretation of adaptive questions, which we call dynamic question ordering (DQO), where question order is personalized. Such an approach could increase engagement, and therefore response rate, as well as imputation quality. We present a DQO framework to improve survey completion and imputation. In the general survey-taking setting, we want to maximize survey completion, and so we focus on ordering questions to engage the respondent and collect hopefully all information, or at least the information that most characterizes the respondent, for accurate imputations. In another scenario, our goal is to provide a personalized prediction. Since it is possible to give reasonable predictions with only a subset of questions, we are not concerned with motivating users to answer all questions. Instead, we want to order questions to get information that reduces prediction uncertainty, while not being too burdensome. We illustrate this framework with an example of providing energy estimates to prospective tenants. We also discuss DQO for national surveys and consider connections between our statistics-based question-ordering approach and cognitive survey methodology. version:1
arxiv-1607-04174 | Adaptable Precomputation for Random Walker Image Segmentation and Registration | http://arxiv.org/abs/1607.04174 | id:1607.04174 author:Shawn Andrews, Ghassan Hamarneh category:cs.CV  published:2016-07-14 summary:The random walker (RW) algorithm is used for both image segmentation and registration, and possesses several useful properties that make it popular in medical imaging, such as being globally optimizable, allowing user interaction, and providing uncertainty information. The RW algorithm defines a weighted graph over an image and uses the graph's Laplacian matrix to regularize its solutions. This regularization reduces to solving a large system of equations, which may be excessively time consuming in some applications, such as when interacting with a human user. Techniques have been developed that precompute eigenvectors of a Laplacian offline, after image acquisition but before any analysis, in order speed up the RW algorithm online, when segmentation or registration is being performed. However, precomputation requires certain algorithm parameters be fixed offline, limiting their flexibility. In this paper, we develop techniques to update the precomputed data online when RW parameters are altered. Specifically, we dynamically determine the number of eigenvectors needed for a desired accuracy based on user input, and derive update equations for the eigenvectors when the edge weights or topology of the image graph are changed. We present results demonstrating that our techniques make RW with precomputation much more robust to offline settings while only sacrificing minimal accuracy. version:1
arxiv-1607-04147 | Multi-modal dictionary learning for image separation with application in art investigation | http://arxiv.org/abs/1607.04147 | id:1607.04147 author:Nikos Deligiannis, Joao F. C. Mota, Bruno Cornelis, Miguel R. D. Rodrigues, Ingrid Daubechies category:cs.CV  published:2016-07-14 summary:In support of art investigation, we propose a new source separation method that unmixes a single X-ray scan acquired from double-sided paintings. In this problem, the X-ray signals to be separated have similar morphological characteristics, which brings previous source separation methods to their limits. Our solution is to use photographs taken from the front and back-side of the panel to drive the separation process. The crux of our approach relies on the coupling of the two imaging modalities (photographs and X-rays) using a novel coupled dictionary learning framework able to capture both common and disparate features across the modalities using parsimonious representations; the common component models features shared by the multi-modal images, whereas the innovation component captures modality-specific information. As such, our model enables the formulation of appropriately regularized convex optimization procedures that lead to the accurate separation of the X-rays. Our dictionary learning framework can be tailored both to a single- and a multi-scale framework, with the latter leading to a significant performance improvement. Moreover, to improve further on the visual quality of the separated images, we propose to train coupled dictionaries that ignore certain parts of the painting corresponding to craquelure. Experimentation on synthetic and real data - taken from digital acquisition of the Ghent Altarpiece (1432) - confirms the superiority of our method against the state-of-the-art morphological component analysis technique that uses either fixed or trained dictionaries to perform image separation. version:1
arxiv-1607-03597 | Accelerating Eulerian Fluid Simulation With Convolutional Networks | http://arxiv.org/abs/1607.03597 | id:1607.03597 author:Jonathan Tompson, Kristofer Schlachter, Pablo Sprechmann, Ken Perlin category:cs.CV  published:2016-07-13 summary:Real-time simulation of fluid and smoke is a long standing problem in computer graphics, where state-of-the-art approaches require large compute resources, making real-time applications often impractical. In this work, we propose a data-driven approach that leverages the approximation power of deep-learning methods with the precision of standard fluid solvers to obtain both fast and highly realistic simulations. The proposed method solves the incompressible Euler equations following the standard operator splitting method in which a large, often ill-condition linear system must be solved. We propose replacement of this system by learning a Convolutional Network (ConvNet) from a training set of simulations using a semi-supervised learning method to minimize long-term velocity divergence. ConvNets are amenable to efficient GPU implementations and, unlike exact iterative solvers, have fixed computational complexity and latency. The proposed hybrid approach restricts the learning task to a linear projection without modeling the well understood advection and body forces. We present real-time 2D and 3D simulations of fluids and smoke; the obtained results are realistic and show good generalization properties to unseen geometry. version:2
arxiv-1607-04110 | Using Recurrent Neural Network for Learning Expressive Ontologies | http://arxiv.org/abs/1607.04110 | id:1607.04110 author:Giulio Petrucci, Chiara Ghidini, Marco Rospocher category:cs.CL cs.AI  published:2016-07-14 summary:Recently, Neural Networks have been proven extremely effective in many natural language processing tasks such as sentiment analysis, question answering, or machine translation. Aiming to exploit such advantages in the Ontology Learning process, in this technical report we present a detailed description of a Recurrent Neural Network based system to be used to pursue such goal. version:1
arxiv-1607-04032 | Adaptive Gray World-Based Color Normalization of Thin Blood Film Images | http://arxiv.org/abs/1607.04032 | id:1607.04032 author:F. Boray Tek, Andrew G. Dempster, İzzet Kale category:cs.CV 68U10  published:2016-07-14 summary:This paper presents an effective color normalization method for thin blood film images of peripheral blood specimens. Thin blood film images can easily be separated to foreground (cell) and background (plasma) parts. The color of the plasma region is used to estimate and reduce the differences arising from different illumination conditions. A second stage normalization based on the database-gray world algorithm transforms the color of the foreground objects to match a reference color character. The quantitative experiments demonstrate the effectiveness of the method and its advantages against two other general purpose color correction methods: simple gray world and Retinex. version:1
arxiv-1607-03991 | Vision-based Traffic Flow Prediction using Dynamic Texture Model and Gaussian Process | http://arxiv.org/abs/1607.03991 | id:1607.03991 author:Bin Liu, Hao Ji, Yi Dai category:cs.CV  published:2016-07-14 summary:In this paper, we describe work in progress towards a real-time vision-based traffic flow prediction (TFP) system. The proposed method consists of three elemental operators, that are dynamic texture model based motion segmentation, feature extraction and Gaussian process (GP) regression. The objective of motion segmentation is to recognize the target regions covering the moving vehicles in the sequence of visual processes. The feature extraction operator aims to extract useful features from the target regions. The extracted features are then mapped to the number of vehicles through the operator of GP regression. A training stage using historical visual data is required for determining the parameter values of the GP. Using a low-resolution visual data set, we performed preliminary evaluations on the performance of the proposed method. The results show that our method beats a benchmark solution based on Gaussian mixture model, and has the potential to be developed into qualified and practical solutions to real-time TFP. version:1
arxiv-1607-03990 | Fast Algorithms for Segmented Regression | http://arxiv.org/abs/1607.03990 | id:1607.03990 author:Jayadev Acharya, Ilias Diakonikolas, Jerry Li, Ludwig Schmidt category:cs.LG cs.DS math.ST stat.TH  published:2016-07-14 summary:We study the fixed design segmented regression problem: Given noisy samples from a piecewise linear function $f$, we want to recover $f$ up to a desired accuracy in mean-squared error. Previous rigorous approaches for this problem rely on dynamic programming (DP) and, while sample efficient, have running time quadratic in the sample size. As our main contribution, we provide new sample near-linear time algorithms for the problem that -- while not being minimax optimal -- achieve a significantly better sample-time tradeoff on large datasets compared to the DP approach. Our experimental evaluation shows that, compared with the DP approach, our algorithms provide a convergence rate that is only off by a factor of $2$ to $4$, while achieving speedups of three orders of magnitude. version:1
arxiv-1607-02834 | Tight Lower Bounds for Multiplicative Weights Algorithmic Families | http://arxiv.org/abs/1607.02834 | id:1607.02834 author:Nick Gravin, Yuval Peres, Balasubramanian Sivan category:cs.LG  published:2016-07-11 summary:We study the fundamental problem of prediction with expert advice and develop regret lower bounds for a large family of algorithms for this problem. We develop simple adversarial primitives, that lend themselves to various combinations leading to sharp lower bounds for many algorithmic families. We use these primitives to show that the classic Multiplicative Weights Algorithm (MWA) has a regret of $\sqrt{\frac{T \ln k}{2}}$, there by completely closing the gap between upper and lower bounds. We further show a regret lower bound of $\frac{2}{3}\sqrt{\frac{T\ln k}{2}}$ for a much more general family of algorithms than MWA, where the learning rate can be arbitrarily varied over time, or even picked from arbitrary distributions over time. We also use our primitives to construct adversaries in the geometric horizon setting for MWA to precisely characterize the regret at $\frac{0.391}{\sqrt{\delta}}$ for the case of $2$ experts and a lower bound of $\frac{1}{2}\sqrt{\frac{\ln k}{2\delta}}$ for the case of arbitrary number of experts $k$. version:2
arxiv-1607-03222 | Gland Instance Segmentation by Deep Multichannel Side Supervision | http://arxiv.org/abs/1607.03222 | id:1607.03222 author:Yan Xu, Yang Li, Mingyuan Liu, Yipei Wang, Maode Lai, Eric I-Chao Chang category:cs.CV  published:2016-07-12 summary:In this paper, we propose a new image instance segmentation method that segments individual glands (instances) in colon histology images. This is a task called instance segmentation that has recently become increasingly important. The problem is challenging since not only do the glands need to be segmented from the complex background, they are also required to be individually identified. Here we leverage the idea of image-to-image prediction in recent deep learning by building a framework that automatically exploits and fuses complex multichannel information, regional and boundary patterns, with side supervision (deep supervision on side responses) in gland histology images. Our proposed system, deep multichannel side supervision (DMCS), alleviates heavy feature design due to the use of convolutional neural networks guided by side supervision. Compared to methods reported in the 2015 MICCAI Gland Segmentation Challenge, we observe state-of-the-art results based on a number of evaluation metrics. version:2
arxiv-1607-03975 | Estimating and Controlling the False Discovery Rate for the PC Algorithm Using Edge-Specific P-Values | http://arxiv.org/abs/1607.03975 | id:1607.03975 author:Eric V. Strobl, Peter L. Spirtes, Shyam Visweswaran category:stat.ML stat.ME  published:2016-07-14 summary:The PC algorithm allows investigators to estimate a complete partially directed acyclic graph (CPDAG) from a finite dataset, but few groups have investigated strategies for estimating and controlling the false discovery rate (FDR) of the edges in the CPDAG. In this paper, we introduce PC with p-values (PC-p), a fast algorithm which robustly computes edge-specific p-values and then estimates and controls the FDR across the edges. PC-p specifically uses the p-values returned by many conditional independence tests to upper bound the p-values of more complex edge-specific hypothesis tests. The algorithm then estimates and controls the FDR using the bounded p-values and the Benjamini-Yekutieli FDR procedure. Modifications to the original PC algorithm also help PC-p accurately compute the upper bounds despite non-zero Type II error rates. Experiments show that PC-p yields more accurate FDR estimation and control across the edges in a variety of CPDAGs compared to alternative methods. version:1
arxiv-1607-03967 | Concatenated image completion via tensor augmentation and completion | http://arxiv.org/abs/1607.03967 | id:1607.03967 author:Johann A. Bengua, Hoang D. Tuan, Ho N. Phien, Minh N. Do category:cs.LG cs.CV cs.DS  published:2016-07-14 summary:This paper proposes a novel framework called concatenated image completion via tensor augmentation and completion (ICTAC), which recovers missing entries of color images with high accuracy. Typical images are second- or third-order tensors (2D/3D) depending if they are grayscale or color, hence tensor completion algorithms are ideal for their recovery. The proposed framework performs image completion by concatenating copies of a single image that has missing entries into a third-order tensor, applying a dimensionality augmentation technique to the tensor, utilizing a tensor completion algorithm for recovering its missing entries, and finally extracting the recovered image from the tensor. The solution relies on two key components that have been recently proposed to take advantage of the tensor train (TT) rank: A tensor augmentation tool called ket augmentation (KA) that represents a low-order tensor by a higher-order tensor, and the algorithm tensor completion by parallel matrix factorization via tensor train (TMac-TT), which has been demonstrated to outperform state-of-the-art tensor completion algorithms. Simulation results for color image recovery show the clear advantage of our framework against current state-of-the-art tensor completion algorithms. version:1
arxiv-1607-03961 | Testing Pattern-Freeness | http://arxiv.org/abs/1607.03961 | id:1607.03961 author:Simon Korman, Daniel Reichman category:cs.DS cs.CV  published:2016-07-13 summary:We consider the problem of testing pattern-freeness (PF): given a string $I$ and a fixed pattern $J$ of length $k$ over a finite alphabet $\Sigma$, decide whether $I$ is $J$-free (has no occurrence of $J$) or alternatively, one has to modify $I$ in at least an $\epsilon$-fraction of its locations to obtain a string that is $J$-free. The 2D analog where one is given a 2D-image and a fixed pattern of dimension $k$ is studied as well. We show that other than a small number of specific patterns, for both 1D and 2D cases, there are simple one-sided testers for this problem whose query complexity is $O(1/\epsilon)$. The testers work for any finite alphabet, with complexity that does not depend on the template dimension $k$, which might depend on $n$. For the 1D case, testing PF is a specific case of the problem of testing regular languages. Our algorithm improves upon the query complexity of the known tester of Alon et. al., removing a polynomial dependency on $k$ as well as a polylogarithmic factor in $1/\epsilon$. For the 2D case, it is the first testing algorithm we are aware of. The PF property belongs to the more general class of matrix properties, studied by Fisher and Newman. They provide a 2-sided tester, doubly exponential in $1/\epsilon$, for matrix properties that can be characterized by a finite set of forbidden induced submatrices and pose the problem of testing such properties for tight submatrices (with consecutive rows and columns) as an open problem. Our algorithm provides a strong tester for this class of properties, in which the forbidden set is of size 1. The dependence of our testers on $\epsilon$ is tight up to constant factors since any tester erring with probability at most $1/3$ must make $\Omega(1/\epsilon)$ queries to $I$. The analysis of our testers builds upon novel combinatorial properties of strings and images, which may be of independent interest. version:1
arxiv-1607-03954 | Ensemble preconditioning for Markov chain Monte Carlo simulation | http://arxiv.org/abs/1607.03954 | id:1607.03954 author:Charles Matthews, Jonathan Weare, Benedict Leimkuhler category:stat.ME math.NA stat.CO stat.ML  published:2016-07-13 summary:We describe parallel Markov chain Monte Carlo methods that propagate a collective ensemble of paths, with local covariance information calculated from neighboring replicas. The use of collective dynamics eliminates multiplicative noise and stabilizes the dynamics thus providing a practical approach to difficult anisotropic sampling problems in high dimensions. Numerical experiments with model problems demonstrate that dramatic potential speedups, compared to various alternative schemes, are attainable. version:1
arxiv-1607-03949 | Large Scale SfM with the Distributed Camera Model | http://arxiv.org/abs/1607.03949 | id:1607.03949 author:Chris Sweeney, Victor Fragoso, Tobias Hollerer, Matthew Turk category:cs.CV  published:2016-07-13 summary:We introduce the distributed camera model, a novel model for Structure-from-Motion (SfM). This model describes image observations in terms of light rays with ray origins and directions rather than pixels. As such, the proposed model is capable of describing a single camera or multiple cameras simultaneously as the collection of all light rays observed. We show how the distributed camera model is a generalization of the standard camera model and describe a general formulation and solution to the absolute camera pose problem that works for standard or distributed cameras. The proposed method computes a solution that is up to 8 times more efficient and robust to rotation singularities in comparison with gDLS. Finally, this method is used in an novel large-scale incremental SfM pipeline where distributed cameras are accurately and robustly merged together. This pipeline is a direct generalization of traditional incremental SfM; however, instead of incrementally adding one camera at a time to grow the reconstruction the reconstruction is grown by adding a distributed camera. Our pipeline produces highly accurate reconstructions efficiently by avoiding the need for many bundle adjustment iterations and is capable of computing a 3D model of Rome from over 15,000 images in just 22 minutes. version:1
arxiv-1607-03895 | Tie-breaker: Using language models to quantify gender bias in sports journalism | http://arxiv.org/abs/1607.03895 | id:1607.03895 author:Liye Fu, Cristian Danescu-Niculescu-Mizil, Lillian Lee category:cs.CL physics.soc-ph  published:2016-07-13 summary:Gender bias is an increasingly important issue in sports journalism. In this work, we propose a language-model-based approach to quantify differences in questions posed to female vs. male athletes, and apply it to tennis post-match interviews. We find that journalists ask male players questions that are generally more focused on the game when compared with the questions they ask their female counterparts. We also provide a fine-grained analysis of the extent to which the salience of this bias depends on various factors, such as question type, game outcome or player rank. version:1
arxiv-1607-03856 | Deep Structured-Output Regression Learning for Computational Color Constancy | http://arxiv.org/abs/1607.03856 | id:1607.03856 author:Yanlin Qian, Ke Chen, Joni-Kristian Kamarainen, Jarno Nikkanen, Jiri Matas category:cs.CV  published:2016-07-13 summary:Computational color constancy that requires esti- mation of illuminant colors of images is a fundamental yet active problem in computer vision, which can be formulated into a regression problem. To learn a robust regressor for color constancy, obtaining meaningful imagery features and capturing latent correlations across output variables play a vital role. In this work, we introduce a novel deep structured-output regression learning framework to achieve both goals simultaneously. By borrowing the power of deep convolutional neural networks (CNN) originally designed for visual recognition, the proposed framework can automatically discover strong features for white balancing over different illumination conditions and learn a multi-output regressor beyond underlying relationships between features and targets to find the complex interdependence of dif- ferent dimensions of target variables. Experiments on two public benchmarks demonstrate that our method achieves competitive performance in comparison with the state-of-the-art approaches. version:1
arxiv-1607-03849 | Fitting a Simplicial Complex using a Variation of $k$-means | http://arxiv.org/abs/1607.03849 | id:1607.03849 author:Piotr Beben category:cs.LG cs.CG stat.ML  published:2016-07-13 summary:In this paper we give a simple two stage algorithm for approximating a point cloud $\mathcal{S}\subset\mathbb{R}^m$ by a simplicial complex $K$. The first stage is an iterative fitting procedure that generalizes $k$-means clustering, while the second stage involves deleting redundant simplices. A form of dimension reduction of $\mathcal{S}$ is obtained as a consequence. version:1
arxiv-1607-03842 | Safe Policy Improvement by Minimizing Robust Baseline Regret | http://arxiv.org/abs/1607.03842 | id:1607.03842 author:Marek Petrik, Yinlam Chow, Mohammad Ghavamzadeh category:stat.ML  published:2016-07-13 summary:An important problem in sequential decision-making under uncertainty is to use limited data to compute a safe policy, i.e., a policy that is guaranteed to perform at least as well as a given baseline strategy. In this paper, we develop and analyze a new model-based approach to compute a safe policy when we have access to an inaccurate dynamics model of the system with known accuracy guarantees. Our proposed robust method uses this (inaccurate) model to directly minimize the (negative) regret w.r.t. the baseline policy. Contrary to the existing approaches, minimizing the regret allows one to improve the baseline policy in states with accurate dynamics and seamlessly fall back to the baseline policy, otherwise. We show that our formulation is NP-hard and propose an approximate algorithm. Our empirical results on several domains show that even this relatively simple approximate algorithm can significantly outperform standard approaches. version:1
arxiv-1607-03827 | The KIT Motion-Language Dataset | http://arxiv.org/abs/1607.03827 | id:1607.03827 author:Matthias Plappert, Christian Mandery, Tamim Asfour category:cs.RO cs.CL cs.CV cs.LG  published:2016-07-13 summary:Linking human motion and natural language is of great interest for the generation of semantic representations of human activities as well as for the generation of robot activities based on natural language input. However, while there have been years of research in this area, no standardized and openly available dataset exists to support the development and evaluation of such systems. We therefore propose the KIT Motion-Language Dataset, which is large, open, and extensible. We aggregate data from multiple motion capture databases and include them in our dataset using a unified representation that is independent of the capture system or marker set, making it easy to work with the data regardless of its origin. To obtain motion annotations in natural language, we apply a crowd-sourcing approach and a web-based tool that was specifically build for this purpose, the Motion Annotation Tool. We thoroughly document the annotation process itself and discuss gamification methods that we used to keep annotators motivated. We further propose a novel method, perplexity-based selection, which systematically selects motions for further annotation that are either under-represented in our dataset or that have erroneous annotations. We show that our method mitigates the two aforementioned problems and ensures a systematic annotation process. We provide an in-depth analysis of the structure and contents of our resulting dataset, which, as of June 14, 2016, contains 3917 motions with a total duration of 11.26 hours and 5486 annotations in natural language that contain 45779 words. We believe that this makes our dataset an excellent choice that enables more transparent and comparable research in this important area. version:1
arxiv-1607-03822 | Feature Extraction and Automated Classification of Heartbeats by Machine Learning | http://arxiv.org/abs/1607.03822 | id:1607.03822 author:Choudur Lakshminarayan, Tony Basil category:stat.ML cs.LG  published:2016-07-13 summary:We present algorithms for the detection of a class of heart arrhythmias with the goal of eventual adoption by practicing cardiologists. In clinical practice, detection is based on a small number of meaningful features extracted from the heartbeat cycle. However, techniques proposed in the literature use high dimensional vectors consisting of morphological, and time based features for detection. Using electrocardiogram (ECG) signals, we found smaller subsets of features sufficient to detect arrhythmias with high accuracy. The features were found by an iterative step-wise feature selection method. We depart from common literature in the following aspects: 1. As opposed to a high dimensional feature vectors, we use a small set of features with meaningful clinical interpretation, 2. we eliminate the necessity of short-duration patient-specific ECG data to append to the global training data for classification 3. We apply semi-parametric classification procedures (in an ensemble framework) for arrhythmia detection, and 4. our approach is based on a reduced sampling rate of ~ 115 Hz as opposed to 360 Hz in standard literature. version:1
arxiv-1607-03085 | Recurrent Memory Array Structures | http://arxiv.org/abs/1607.03085 | id:1607.03085 author:Kamil Rocki category:cs.LG cs.NE  published:2016-07-11 summary:The following report introduces ideas augmenting standard Long Short Term Memory (LSTM) architecture with multiple memory cells per hidden unit in order to improve its generalization capabilities. It considers both deterministic and stochastic variants of memory operation. It is shown that the nondeterministic Array-LSTM approach improves state-of-the-art performance on character level text prediction achieving 1.402 BPC on enwik8 dataset. Furthermore, this report estabilishes baseline neural-based results of 1.12 BPC and 1.19 BPC for enwik9 and enwik10 datasets respectively. version:2
arxiv-1607-03815 | Homotopy Smoothing for Non-Smooth Problems with Lower Complexity than $O(1/ε)$ | http://arxiv.org/abs/1607.03815 | id:1607.03815 author:Yi Xu, Yan Yan, Qihang Lin, Tianbao Yang category:math.OC stat.ML  published:2016-07-13 summary:In this paper, we develop a novel {\bf ho}moto{\bf p}y {\bf s}moothing (HOPS) algorithm for solving a family of non-smooth problems that is composed of a non-smooth term with an explicit max-structure and a smooth term or a simple non-smooth term whose proximal mapping is easy to compute. Such kind of non-smooth optimization problems arise in many applications, e.g., machine learning, image processing, statistics, cone programming, etc. The best known iteration complexity for solving such non-smooth optimization problems is $O(1/\epsilon)$ without any assumption on the strong convexity. In this work, we will show that the proposed HOPS achieves a lower iteration complexity of $\tilde O(1/\epsilon^{1-\theta})$ with $\theta\in(0,1]$ capturing the local sharpness of the objective function around the optimal solutions. To the best of our knowledge, this is the lowest iteration complexity achieved so far for the considered non-smooth optimization problems without strong convexity assumption. The HOPS algorithm uses Nesterov's smoothing trick and Nesterov's accelerated gradient method and runs in stages, which gradually decreases the smoothing parameter until it yields a sufficiently good approximation of the original function. Experimental results verify the effectiveness of HOPS in comparison with Nesterov's smoothing algorithm and the primal-dual style of first-order methods. version:1
arxiv-1607-03792 | Kernel Density Estimation for Dynamical Systems | http://arxiv.org/abs/1607.03792 | id:1607.03792 author:Hanyuan Hang, Ingo Steinwart, Yunlong Feng, Johan A. K. Suykens category:stat.ML  published:2016-07-13 summary:We study the density estimation problem with observations generated by certain dynamical systems that admit a unique underlying invariant Lebesgue density. Observations drawn from dynamical systems are not independent and moreover, usual mixing concepts may not be appropriate for measuring the dependence among these observations. By employing the $\mathcal{C}$-mixing concept to measure the dependence, we conduct statistical analysis on the consistency and convergence of the kernel density estimator. Our main results are as follows: First, we show that with properly chosen bandwidth, the kernel density estimator is universally consistent under $L_1$-norm; Second, we establish convergence rates for the estimator with respect to several classes of dynamical systems under $L_1$-norm. In the analysis, the density function $f$ is only assumed to be H\"{o}lder continuous which is a weak assumption in the literature of nonparametric density estimation and also more realistic in the dynamical system context. Last but not least, we prove that the same convergence rates of the estimator under $L_\infty$-norm and $L_1$-norm can be achieved when the density function is H\"{o}lder continuous, compactly supported and bounded. The bandwidth selection problem of the kernel density estimator for dynamical system is also discussed in our study via numerical simulations. version:1
arxiv-1607-03785 | Application of Convolutional Neural Network for Image Classification on Pascal VOC Challenge 2012 dataset | http://arxiv.org/abs/1607.03785 | id:1607.03785 author:Suyash Shetty category:cs.CV  published:2016-07-13 summary:In this project we work on creating a model to classify images for the Pascal VOC Challenge 2012. We use convolutional neural networks trained on a single GPU instance provided by Amazon via their cloud service Amazon Web Services (AWS) to classify images in the Pascal VOC 2012 data set. We train multiple convolutional neural network models and finally settle on the best model which produced a validation accuracy of 85.6% and a testing accuracy of 85.24%. version:1
arxiv-1607-03780 | A Vector Space for Distributional Semantics for Entailment | http://arxiv.org/abs/1607.03780 | id:1607.03780 author:James Henderson, Diana Nicoleta Popa category:cs.CL cs.LG  published:2016-07-13 summary:Distributional semantics creates vector-space representations that capture many forms of semantic similarity, but their relation to semantic entailment has been less clear. We propose a vector-space model which provides a formal foundation for a distributional semantics of entailment. Using a mean-field approximation, we develop approximate inference procedures and entailment operators over vectors of probabilities of features being known (versus unknown). We use this framework to reinterpret an existing distributional-semantic model (Word2Vec) as approximating an entailment-based model of the distributions of words in contexts, thereby predicting lexical entailment relations. In both unsupervised and semi-supervised experiments on hyponymy detection, we get substantial improvements over previous results. version:1
arxiv-1607-03766 | AudioSentibank: Large-scale Semantic Ontology of Acoustic Concepts for Audio Content Analysis | http://arxiv.org/abs/1607.03766 | id:1607.03766 author:Sebastian Sager, Damian Borth, Benjamin Elizalde, Christian Schulze, Bhiksha Raj, Ian Lane, Andreas Dengel category:cs.SD cs.CL  published:2016-07-13 summary:Audio carries substantial information about the content of our surroundings. The content has been explored at the semantic level using acoustic concepts, but rarely on concept pairs such as happy crowd and angry crowd. Concept pairs convey unique information and complement other audio and multimedia applications. Hence, in this work we explored for the first time the classification's performance of acoustic concepts pairs. For this study, we introduce the AudioSentiBank corpus, which is a large-scale folksology containing over 1,123 adjective and verb noun pairs. Our contribution consists on providing the research corpus, the benchmark for classification of acoustic concept pairs, and an analysis on the pairs. version:1
arxiv-1607-03730 | Learning Shallow Detection Cascades for Wearable Sensor-Based Mobile Health Applications | http://arxiv.org/abs/1607.03730 | id:1607.03730 author:Hamid Dadkhahi, Nazir Saleheen, Santosh Kumar, Benjamin Marlin category:stat.ML cs.LG  published:2016-07-13 summary:The field of mobile health aims to leverage recent advances in wearable on-body sensing technology and smart phone computing capabilities to develop systems that can monitor health states and deliver just-in-time adaptive interventions. However, existing work has largely focused on analyzing collected data in the off-line setting. In this paper, we propose a novel approach to learning shallow detection cascades developed explicitly for use in a real-time wearable-phone or wearable-phone-cloud systems. We apply our approach to the problem of cigarette smoking detection from a combination of wrist-worn actigraphy data and respiration chest band data using two and three stage cascades. version:1
arxiv-1607-03707 | Re-presenting a Story by Emotional Factors using Sentimental Analysis Method | http://arxiv.org/abs/1607.03707 | id:1607.03707 author:Hwiyeol Jo, Yohan Moon, Jong In Kim, Jeong Ryu category:cs.CL cs.LG  published:2016-07-13 summary:Remembering an event is affected by personal emotional status. We examined the psychological status and personal factors; depression (Center for Epidemiological Studies - Depression, Radloff, 1977), present affective (Positive Affective and Negative Affective Schedule, Watson et al., 1988), life orient (Life Orient Test, Scheier & Carver, 1985), self-awareness (Core Self Evaluation Scale, Judge et al., 2003), and social factor (Social Support, Sarason et al., 1983) of undergraduate students (N=64) and got summaries of a story, Chronicle of a Death Foretold (Gabriel Garcia Marquez, 1981) from them. We implement a sentimental analysis model based on convolutional neural network (LeCun & Bengio, 1995) to evaluate each summary. From the same vein used for transfer learning (Pan & Yang, 2010), we collected 38,265 movie review data to train the model and then use them to score summaries of each student. The results of CES-D and PANAS show the relationship between emotion and memory retrieval as follows: depressed people have shown a tendency of representing a story more negatively, and they seemed less expressive. People with full of emotion - high in PANAS - have retrieved their memory more expressively than others, using more negative words then others. The contributions of this study can be summarized as follows: First, lightening the relationship between emotion and its effect during times of storing or retrieving a memory. Second, suggesting objective methods to evaluate the intensity of emotion in natural language format, using a sentimental analysis model. version:1
arxiv-1607-03705 | Possibilistic Networks: Parameters Learning from Imprecise Data and Evaluation strategy | http://arxiv.org/abs/1607.03705 | id:1607.03705 author:Maroua Haddad, Philippe Leray, Nahla Ben Amor category:cs.AI cs.LG  published:2016-07-13 summary:There has been an ever-increasing interest in multidisciplinary research on representing and reasoning with imperfect data. Possibilistic networks present one of the powerful frameworks of interest for representing uncertain and imprecise information. This paper covers the problem of their parameters learning from imprecise datasets, i.e., containing multi-valued data. We propose in the rst part of this paper a possibilistic networks sampling process. In the second part, we propose a likelihood function which explores the link between random sets theory and possibility theory. This function is then deployed to parametrize possibilistic networks. version:1
arxiv-1607-03691 | Sequential Cost-Sensitive Feature Acquisition | http://arxiv.org/abs/1607.03691 | id:1607.03691 author:Gabriella Contardo, Ludovic Denoyer, Thierry Artières category:cs.LG  published:2016-07-13 summary:We propose a reinforcement learning based approach to tackle the cost-sensitive learning problem where each input feature has a specific cost. The acquisition process is handled through a stochastic policy which allows features to be acquired in an adaptive way. The general architecture of our approach relies on representation learning to enable performing prediction on any partially observed sample, whatever the set of its observed features are. The resulting model is an original mix of representation learning and of reinforcement learning ideas. It is learned with policy gradient techniques to minimize a budgeted inference cost. We demonstrate the effectiveness of our proposed method with several experiments on a variety of datasets for the sparse prediction problem where all features have the same cost, but also for some cost-sensitive settings. version:1
arxiv-1607-03316 | Separating Answers from Queries for Neural Reading Comprehension | http://arxiv.org/abs/1607.03316 | id:1607.03316 author:Dirk Weissenborn category:cs.CL cs.NE  published:2016-07-12 summary:We present a novel neural architecture for answering queries, designed to optimally leverage explicit support in the form of query-answer memories. Our model is able to refine and update a given query while separately accumulating evidence for predicting the answer. Its architecture reflects this separation with dedicated embedding matrices and loosely connected information pathways (modules) for updating the query and accumulating evidence. This separation of responsibilities effectively decouples the search for query related support and the prediction of the answer. On recent benchmark datasets for reading comprehension, our model achieves state-of-the-art results. A qualitative analysis demonstrates that the model effectively accumulates weighted evidence from the query and over multiple support retrieval cycles which results in a robust answer prediction. version:2
arxiv-1607-03682 | Hierachical learning for DNN-based acoustic scene classification | http://arxiv.org/abs/1607.03682 | id:1607.03682 author:Yong Xu, Qiang Huang, Wenwu Wang, Mark D. Plumbley category:cs.SD cs.CV cs.LG  published:2016-07-13 summary:In this paper, we present a deep neural network (DNN)-based acoustic scene classification framework. Two hierarchical learning methods are proposed to improve the DNN baseline performance by incorporating the hierarchical taxonomy information of environmental sounds. Firstly, the parameters of the DNN are initialized by the proposed hierarchical pre-training. Multi-level objective function is then adopted to add more constraint on the cross-entropy based loss function. A series of experiments were conducted on the Task1 of the Detection and Classification of Acoustic Scenes and Events (DCASE) 2016 challenge. The final DNN-based system achieved a 22.9% relative improvement on average scene classification error as compared with the Gaussian Mixture Model (GMM)-based benchmark system across four standard folds. version:1
arxiv-1607-03681 | Fully Deep Neural Networks Incorporating Unsupervised Feature Learning for Audio Tagging | http://arxiv.org/abs/1607.03681 | id:1607.03681 author:Yong Xu, Qiang Huang, Wenwu Wang, Peter Foster, Siddharth Sigtia, Philip J. B. Jackson, Mark D. Plumbley category:cs.SD cs.CV cs.LG  published:2016-07-13 summary:In this paper we make contributions to audio tagging in two parts, respectively, acoustic modeling and feature learning. We propose to use a fully deep neural network (DNN) framework incorporating unsupervised feature learning to handle the multi-label classification task in a regression way. Considering that only chunk-level rather than frame-level labels are available, the whole or almost whole frames of the chunk are fed into the DNN to perform a multi-label regression for the expected tags. The fully DNN, which is regarded as an encoding function, can map the audio features sequence to a multi-tag vector. For the unsupervised feature learning, we propose to use a deep auto-encoder (AE) to generate new features with non-negative representation from the basic features. The new feature can further improve the performance of audio tagging. A deep pyramid structure was also designed to extract more robust high-level features related to the target tags. Further improved methods were adopted, such as the dropout and background noise aware training, to enhance the generalization capability of DNNs for new audio recordings in mismatched environments. Compared with the conventional Gaussian Mixture Model (GMM) and support vector machine (SVM) methods, the proposed fully DNN-based method is able to utilize the long-term temporal information with the whole chunk as the input. The results show that our approach obtains a 19.1% relative improvement compared with the official GMM-based baseline method of DCASE 2016 audio tagging task. version:1
arxiv-1607-03626 | San Francisco Crime Classification | http://arxiv.org/abs/1607.03626 | id:1607.03626 author:Yehya Abouelnaga category:cs.LG  published:2016-07-13 summary:San Francisco Crime Classification is an online competition administered by Kaggle Inc. The competition aims at predicting the future crimes based on a given set of geographical and time-based features. In this paper, I achieved a an accuracy that ranks at top %18, as of May 19th, 2016. I will explore the data, and explain in details the tools I used to achieve that result. version:1
arxiv-1607-03615 | Multiple-Instance Logistic Regression with LASSO Penalty | http://arxiv.org/abs/1607.03615 | id:1607.03615 author:Ray-Bing Chen, Kuang-Hung Cheng, Sheng-Mao Chang, Shuen-Lin Jeng, Ping-Yang Chen, Chun-Hao Yang, Chi-Chun Hsia category:stat.ML stat.AP  published:2016-07-13 summary:In this work, we consider a manufactory process which can be described by a multiple-instance logistic regression model. In order to compute the maximum likelihood estimation of the unknown coefficient, an expectation-maximization algorithm is proposed, and the proposed modeling approach can be extended to identify the important covariates by adding the coefficient penalty term into the likelihood function. In addition to essential technical details, we demonstrate the usefulness of the proposed method by simulations and real examples. version:1
arxiv-1607-03611 | Characterizing Driving Styles with Deep Learning | http://arxiv.org/abs/1607.03611 | id:1607.03611 author:Weishan Dong, Jian Li, Renjie Yao, Changsheng Li, Ting Yuan, Lanjun Wang category:cs.AI cs.LG  published:2016-07-13 summary:Characterizing driving styles of human drivers using vehicle sensor data, e.g., GPS, is an interesting research problem and an important real-world requirement from automotive industries. A good representation of driving features can be highly valuable for autonomous driving, auto insurance, and many other application scenarios. However, traditional methods mainly rely on handcrafted features, which limit machine learning algorithms to achieve a better performance. In this paper, we propose a novel deep learning solution to this problem, which could be the first attempt of studying deep learning for driving behavior analysis. The proposed approach can effectively extract high level and interpretable features describing complex driving patterns from GPS data. It also requires significantly less human experience and work. The power of the learned driving style representations are validated through the driver identification problem using a large real dataset. version:1
arxiv-1607-05650 | A Supervised Authorship Attribution Framework for Bengali Language | http://arxiv.org/abs/1607.05650 | id:1607.05650 author:Shanta Phani, Shibamouli Lahiri, Arindam Biswas category:cs.CL cs.DL  published:2016-07-13 summary:Authorship Attribution is a long-standing problem in Natural Language Processing. Several statistical and computational methods have been used to find a solution to this problem. In this paper, we have proposed methods to deal with the authorship attribution problem in Bengali. More specifically, we proposed a supervised framework consisting of lexical and shallow features, and investigated the possibility of using topic-modeling-inspired features, to classify documents according to their authors. We have created a corpus from nearly all the literary works of three eminent Bengali authors, consisting of 3000 disjoint samples. Our models showed better performance than the state-of-the-art, with more than 98% test accuracy for the shallow features, and 100% test accuracy for the topic-based features. version:1
arxiv-1607-03594 | Reliable Confidence Estimation via Online Learning | http://arxiv.org/abs/1607.03594 | id:1607.03594 author:Volodymyr Kuleshov, Stefano Ermon category:cs.LG  published:2016-07-13 summary:Assessing uncertainty within machine learning systems is an important step towards ensuring their safety and reliability. Existing uncertainty estimation techniques may fail when their modeling assumptions are not met, e.g. when the data distribution differs from the one seen at training time. Here, we propose techniques that assess a classification algorithm's uncertainty via calibrated probabilities (i.e. probabilities that match empirical outcome frequencies in the long run) and which are guaranteed to be reliable (i.e. accurate and calibrated) on out-of-distribution input, including input generated by an adversary. Our methods admit formal bounds that can serve as confidence intervals, and process data in an online manner, which obviates the need for a separate calibration dataset. We establish theoretical guarantees on our methods' accuracies and convergence rates, and we validate them on two real-world problems: question answering and medical diagnosis from genomic data. version:1
arxiv-1607-03574 | Effects of Additional Data on Bayesian Clustering | http://arxiv.org/abs/1607.03574 | id:1607.03574 author:Keisuke Yamazaki category:stat.ML  published:2016-07-13 summary:Hierarchical probabilistic models, such as mixture models, are used for cluster analysis. These models have two types of variables: observable and latent. In cluster analysis, the latent variable is estimated, and it is expected that additional information will improve the accuracy of the estimation of the latent variable. Many proposed learning methods are able to use additional data; these include semi-supervised learning and transfer learning. However, from a statistical point of view, a complex probabilistic model that encompasses both the initial and additional data might be less accurate due to having a higher-dimensional parameter. The present paper presents a theoretical analysis of the accuracy of such a model and clarifies which factor has the greatest effect on its accuracy, the advantages of obtaining additional data, and the disadvantages of increasing the complexity. version:1
arxiv-1607-03559 | Fast Sampling for Strongly Rayleigh Measures with Application to Determinantal Point Processes | http://arxiv.org/abs/1607.03559 | id:1607.03559 author:Chengtao Li, Stefanie Jegelka, Suvrit Sra category:cs.LG cs.DS math.PR stat.ML  published:2016-07-13 summary:In this note we consider sampling from (non-homogeneous) strongly Rayleigh probability measures. As an important corollary, we obtain a fast mixing Markov Chain sampler for Determinantal Point Processes. version:1
arxiv-1607-03547 | Improved Multi-Class Cost-Sensitive Boosting via Estimation of the Minimum-Risk Class | http://arxiv.org/abs/1607.03547 | id:1607.03547 author:Ron Appel, Xavier Burgos-Artizzu, Pietro Perona category:cs.CV cs.LG  published:2016-07-12 summary:We present a simple unified framework for multi-class cost-sensitive boosting. The minimum-risk class is estimated directly, rather than via an approximation of the posterior distribution. Our method jointly optimizes binary weak learners and their corresponding output vectors, requiring classes to share features at each iteration. By training in a cost-sensitive manner, weak learners are invested in separating classes whose discrimination is important, at the expense of less relevant classification boundaries. Additional contributions are a family of loss functions along with proof that our algorithm is Boostable in the theoretical sense, as well as an efficient procedure for growing decision trees for use as weak learners. We evaluate our method on a variety of datasets: a collection of synthetic planar data, common UCI datasets, MNIST digits, SUN scenes, and CUB-200 birds. Results show state-of-the-art performance across all datasets against several strong baselines, including non-boosting multi-class approaches. version:1
arxiv-1607-03542 | Open-Vocabulary Semantic Parsing with both Distributional Statistics and Formal Knowledge | http://arxiv.org/abs/1607.03542 | id:1607.03542 author:Matt Gardner, Jayant Krishnamurthy category:cs.CL  published:2016-07-12 summary:Semantic parsers map language onto executable statements in a fixed schema. This mapping allows them to effectively leverage the information contained in large, formal knowledge bases (e.g., Freebase) to answer questions, but it is also fundamentally limiting---semantic parsers can only represent language that falls within their manually produced schema. Recently proposed methods for open vocabulary semantic parsing overcome this limitation by learning execution models for arbitrary language. However, all prior approaches to open vocabulary semantic parsing are purely distributional, making no use of any underlying knowledge base. We show how to combine the benefits of both of these approaches by incorporating knowledge base information into open vocabulary semantic parsing models, improving mean average precision on an open-domain natural language query task by more than 120%. version:1
arxiv-1607-03516 | Deep Reconstruction-Classification Networks for Unsupervised Domain Adaptation | http://arxiv.org/abs/1607.03516 | id:1607.03516 author:Muhammad Ghifary, W. Bastiaan Kleijn, Mengjie Zhang, David Balduzzi, Wen Li category:cs.CV  published:2016-07-12 summary:In this paper, we propose a novel unsupervised domain adaptation algorithm based on deep learning for visual object recognition. Specifically, we design a new model called Deep Reconstruction-Classification Network (DRCN), which jointly learns a shared encoding representation for two tasks: i) supervised classification of labeled source data, and ii) unsupervised reconstruction of unlabeled target data.In this way, the learnt representation not only preserves discriminability, but also encodes useful information from the target domain. Our new DRCN model can be optimized by using backpropagation similarly as the standard neural networks. version:1
arxiv-1607-03502 | Natural brain-information interfaces: Recommending information by relevance inferred from human brain signals | http://arxiv.org/abs/1607.03502 | id:1607.03502 author:Manuel J. A. Eugster, Tuukka Ruotsalo, Michiel M. Spapé, Oswald Barral, Niklas Ravaja, Giulio Jacucci, Samuel Kaski category:cs.IR cs.HC q-bio.NC stat.ML  published:2016-07-12 summary:Finding relevant information from large document collections such as the World Wide Web is a common task in our daily lives. Estimation of a user's interest or search intention is necessary to recommend and retrieve relevant information from these collections. We introduce a brain-information interface used for recommending information by relevance inferred directly from brain signals. In experiments, participants were asked to read Wikipedia documents about a selection of topics while their EEG was recorded. Based on the prediction of word relevance, the individual's search intent was modeled and successfully used for retrieving new, relevant documents from the whole English Wikipedia corpus. The results show that the users' interests towards digital content can be modeled from the brain signals evoked by reading. The introduced brain-relevance paradigm enables the recommendation of information without any explicit user interaction, and may be applied across diverse information-intensive applications. version:1
arxiv-1607-03476 | End-to-end training of object class detectors for mean average precision | http://arxiv.org/abs/1607.03476 | id:1607.03476 author:Paul Henderson, Vittorio Ferrari category:cs.CV  published:2016-07-12 summary:We present a method for training CNN-based object class detectors directly using mean average precision (mAP) as the training loss, in a truly end-to-end fashion that includes non-maximum suppresion (NMS) at training time. This contrasts with the traditional approach of training a CNN for a window classification loss, then applying NMS only at test time, when mAP is used as the evaluation metric in place of classification accuracy. However, mAP following NMS forms a piecewise-constant structured loss over thousands of windows, with gradients that do not convey useful information for gradient descent. Hence, we define new, general gradient-like quantities for piecewise constant functions, which have wide applicability. We describe how to calculate these efficiently for mAP following NMS, enabling to train a detector based on Fast R-CNN directly for mAP. This model achieves equivalent performance to the standard Fast R-CNN on the PASCAL VOC 2007 and 2012 datasets, while being conceptually more appealing as the very same model and loss are used at both training and test time. version:1
arxiv-1607-03475 | Nystrom Method for Approximating the GMM Kernel | http://arxiv.org/abs/1607.03475 | id:1607.03475 author:Ping Li category:stat.ML cs.LG  published:2016-07-12 summary:The GMM (generalized min-max) kernel was recently proposed (Li, 2016) as a measure of data similarity and was demonstrated effective in machine learning tasks. In order to use the GMM kernel for large-scale datasets, the prior work resorted to the (generalized) consistent weighted sampling (GCWS) to convert the GMM kernel to linear kernel. We call this approach as ``GMM-GCWS''. In the machine learning literature, there is a popular algorithm which we call ``RBF-RFF''. That is, one can use the ``random Fourier features'' (RFF) to convert the ``radial basis function'' (RBF) kernel to linear kernel. It was empirically shown in (Li, 2016) that RBF-RFF typically requires substantially more samples than GMM-GCWS in order to achieve comparable accuracies. The Nystrom method is a general tool for computing nonlinear kernels, which again converts nonlinear kernels into linear kernels. We apply the Nystrom method for approximating the GMM kernel, a strategy which we name as ``GMM-NYS''. In this study, our extensive experiments on a set of fairly large datasets confirm that GMM-NYS is also a strong competitor of RBF-RFF. version:1
arxiv-1607-03474 | Recurrent Highway Networks | http://arxiv.org/abs/1607.03474 | id:1607.03474 author:Julian Georg Zilly, Rupesh Kumar Srivastava, Jan Koutník, Jürgen Schmidhuber category:cs.LG cs.CL cs.NE  published:2016-07-12 summary:Many sequential processing tasks require complex nonlinear transition functions from one step to the next. However, recurrent neural networks with such 'deep' transition functions remain difficult to train, even when using Long Short-Term Memory networks. We introduce a novel theoretical analysis of recurrent networks based on Ger\v{s}gorin's circle theorem that illuminates several modeling and optimization issues and improves our understanding of the LSTM cell. Based on this analysis we propose Recurrent Highway Networks (RHN), which are long not only in time but also in space, generalizing LSTMs to larger step-to-step depths. Experiments indicate that the proposed architecture results in complex but efficient models, beating previous models for character prediction on the Hutter Prize dataset with less than half of the parameters. version:1
arxiv-1607-03468 | Event-based, 6-DOF Camera Tracking for High-Speed Applications | http://arxiv.org/abs/1607.03468 | id:1607.03468 author:Guillermo Gallego, Jon E. A. Lund, Elias Mueggler, Henri Rebecq, Tobi Delbruck, Davide Scaramuzza category:cs.CV cs.RO  published:2016-07-12 summary:In contrast to standard cameras, which produce frames at a fixed rate, event cameras respond asynchronously to pixel-level brightness changes, thus enabling the design of new algorithms for high-speed applications with latencies of microseconds. However, this advantage comes at a cost: because the output is composed by a sequence of events, traditional computer-vision algorithms are not applicable, so that a new paradigm shift is needed. We present an event-based approach for ego-motion estimation, which provides pose updates upon the arrival of each event, thus virtually eliminating latency. Our method is the first work addressing and demonstrating event-based pose tracking in six degrees-of-freedom (DOF) motions in realistic and natural scenes, and it is able to track high-speed motions. The method is successfully evaluated in both indoor and outdoor scenes. version:1
arxiv-1607-03464 | A Representation Theory Perspective on Simultaneous Alignment and Classification | http://arxiv.org/abs/1607.03464 | id:1607.03464 author:Roy R. Lederman, Amit Singer category:cs.CV math.OC  published:2016-07-12 summary:One of the difficulties in 3D reconstruction of molecules from images in single particle Cryo-Electron Microscopy (Cryo-EM), in addition to high levels of noise and unknown image orientations, is heterogeneity in samples: in many cases, the samples contain a mixture of molecules, or multiple conformations of one molecule. Many algorithms for the reconstruction of molecules from images in heterogeneous Cryo-EM experiments are based on iterative approximations of the molecules in a non-convex optimization that is prone to reaching suboptimal local minima. Other algorithms require an alignment in order to perform classification, or vice versa. The recently introduced Non-Unique Games framework provides a representation theoretic approach to studying problems of alignment over compact groups, and offers convex relaxations for alignment problems which are formulated as semidefinite programs (SDPs) with certificates of global optimality under certain circumstances. In this manuscript, we propose to extend Non-Unique Games to the problem of simultaneous alignment and classification with the goal of simultaneously classifying Cryo-EM images and aligning them within their respective classes. Our proposed approach can also be extended to the case of continuous heterogeneity. version:1
arxiv-1607-03463 | Even Faster SVD Decomposition Yet Without Agonizing Pain | http://arxiv.org/abs/1607.03463 | id:1607.03463 author:Zeyuan Allen-Zhu, Yuanzhi Li category:cs.NA cs.DS cs.LG math.OC stat.ML  published:2016-07-12 summary:We study k-SVD that is to obtain the first k singular vectors of a matrix $A$ approximately. Recently, a few breakthroughs have been discovered on k-SVD: Musco and Musco [1] provided the first gap-free theorem for the block Krylov method, Shamir [2] discovered the first variance-reduction stochastic method, and Bhojanapalli et al. [3] provided the fastest $O(\mathsf{nnz}(A) + \mathsf{poly}(1/\varepsilon))$-type of algorithm using alternating minimization. In this paper, put forward a new framework for SVD and improve the above breakthroughs. We obtain faster gap-free convergence rate outperforming [1], we obtain the first accelerated AND stochastic method outperforming [2]. In the $O(\mathsf{nnz}(A) + \mathsf{poly}(1/\varepsilon))$ running-time regime, we outperform [3] in certain parameter regimes without even using alternating minimization. version:1
arxiv-1607-03456 | Incomplete Pivoted QR-based Dimensionality Reduction | http://arxiv.org/abs/1607.03456 | id:1607.03456 author:Amit Bermanis, Aviv Rotbart, Moshe Salhov, Amir Averbuch category:cs.LG stat.ML  published:2016-07-12 summary:High-dimensional big data appears in many research fields such as image recognition, biology and collaborative filtering. Often, the exploration of such data by classic algorithms is encountered with difficulties due to `curse of dimensionality' phenomenon. Therefore, dimensionality reduction methods are applied to the data prior to its analysis. Many of these methods are based on principal components analysis, which is statistically driven, namely they map the data into a low-dimension subspace that preserves significant statistical properties of the high-dimensional data. As a consequence, such methods do not directly address the geometry of the data, reflected by the mutual distances between multidimensional data point. Thus, operations such as classification, anomaly detection or other machine learning tasks may be affected. This work provides a dictionary-based framework for geometrically driven data analysis that includes dimensionality reduction, out-of-sample extension and anomaly detection. It embeds high-dimensional data in a low-dimensional subspace. This embedding preserves the original high-dimensional geometry of the data up to a user-defined distortion rate. In addition, it identifies a subset of landmark data points that constitute a dictionary for the analyzed dataset. The dictionary enables to have a natural extension of the low-dimensional embedding to out-of-sample data points, which gives rise to a distortion-based criterion for anomaly detection. The suggested method is demonstrated on synthetic and real-world datasets and achieves good results for classification, anomaly detection and out-of-sample tasks. version:1
arxiv-1607-07695 | A Hierarchical Multi-resolution Mesh Network for Brain Decoding | http://arxiv.org/abs/1607.07695 | id:1607.07695 author:Itir Onal, Mete Ozay, Fatos Tunay Yarman Vural category:cs.NE cs.CV cs.LG  published:2016-07-12 summary:We propose a new framework, called Hierarchical Multi-resolution Mesh Network (HMMN), which establishes a dynamic brain network for each time resolution of the fMRI signal to represent the underlying cognitive process. The edge weights of the multi-resolution network are then used to train an ensemble learning architecture, called, fuzzy stacked generalization (FSG) for brain decoding. The suggested framework, first, decomposes the fMRI signal into various time resolutions using Wavelet transforms. Then, for each time resolution, a local mesh is formed around each brain region. The locality is defined with respect to a neighborhood system based on functional connectivity. The edge weights of each mesh are estimated by Ridge regression. The local meshes are ensembled to form a dynamic network at each time resolution. In the final step, the edge weights of the networks are used for brain decoding. This task is achieved by fusing the multi-resolution edge weights as the input to the Fuzzy Stacked Generalization (FSG) architecture. Our results on Human Connectome Project task-fMRI dataset reflect that the suggested model, HMMN, can successfully discriminate tasks by extracting complementary information obtained from mesh edge weights of multiple subbands. version:1
arxiv-1607-03434 | DNA Image Pro -- A Tool for Generating Pixel Patterns using DNA Tile Assembly | http://arxiv.org/abs/1607.03434 | id:1607.03434 author:Dixita Limbachiya, Dhaval Trivedi, Manish K Gupta category:cs.ET cs.CV  published:2016-07-12 summary:Self-assembly is a process found everywhere in the Nature. In particular, it is known that DNA self-assembly is Turing universal. Thus one can do arbitrary computations or build nano-structures using DNA self-assembly. In order to understand the DNA self-assembly process, many mathematical models have been proposed in the literature. In particular, abstract Tile Assembly Model (aTAM) received much attention. In this work, we investigate pixel pattern generation using aTAM. For a given image, a tile assembly system is given which can generate the image by self-assembly process. We also consider image blocks with specific cyclic pixel patterns (uniform shift and non uniform shift) self assembly. A software, DNA Image Pro, for generating pixel patterns using DNA tile assembly is also given. version:1
arxiv-1607-03428 | Learning in Quantum Control: High-Dimensional Global Optimization for Noisy Quantum Dynamics | http://arxiv.org/abs/1607.03428 | id:1607.03428 author:Pantita Palittapongarnpim, Peter Wittek, Ehsan Zahedinejad, Barry C. Sanders category:cs.LG cs.SY quant-ph stat.ML  published:2016-07-12 summary:Quantum control is valuable for various quantum technologies such as high-fidelity gates for universal quantum computing, adaptive quantum-enhanced metrology, and ultra-cold atom manipulation. Although supervised machine learning and reinforcement learning are widely used for optimizing control parameters in classical systems, quantum control for parameter optimization is mainly pursued via gradient-based greedy algorithms. Although the quantum fitness landscape is often compatible for greedy algorithms, sometimes greedy algorithms yield poor results, especially for large-dimensional quantum systems. We employ differential evolution algorithms to circumvent the stagnation problem of non-convex optimization, and we average over the objective function to improve quantum control fidelity for noisy systems. To reduce computational cost, we introduce heuristics for early termination of runs and for adaptive selection of search subspaces. Our implementation is massively parallel and vectorized to reduce run time even further. We demonstrate our methods with two examples, namely quantum phase estimation and quantum gate design, for which we achieve superior fidelity and scalability than obtained using greedy algorithms. version:1
arxiv-1607-03425 | Bayesian Inference of Bijective Non-Rigid Shape Correspondence | http://arxiv.org/abs/1607.03425 | id:1607.03425 author:Matthias Vestner, Roee Litman, Alex Bronstein, Emanuele Rodolà, Daniel Cremers category:cs.CV  published:2016-07-12 summary:Many algorithms for the computation of correspondences between deformable shapes rely on some variant of nearest neighbor matching in a descriptor space. Such are, for example, various point-wise correspondence recovery algorithms used as a postprocessing stage in the functional correspondence framework. In this paper, we show that such frequently used techniques in practice suffer from lack of accuracy and result in poor surjectivity. We propose an alternative recovery technique guaranteeing a bijective correspondence and producing significantly higher accuracy. We derive the proposed method from a statistical framework of Bayesian inference and demonstrate its performance on several challenging deformable 3D shape matching datasets. version:1
arxiv-1607-03406 | Multi-modal image retrieval with random walk on multi-layer graphs | http://arxiv.org/abs/1607.03406 | id:1607.03406 author:Renata Khasanova, Xiaowen Dong, Pascal Frossard category:cs.IR cs.CV cs.MM  published:2016-07-12 summary:The analysis of large collections of image data is still a challenging problem due to the difficulty of capturing the true concepts in visual data. The similarity between images could be computed using different and possibly multimodal features such as color or edge information or even text labels. This motivates the design of image analysis solutions that are able to effectively integrate the multi-view information provided by different feature sets. We therefore propose a new image retrieval solution that is able to sort images through a random walk on a multi-layer graph, where each layer corresponds to a different type of information about the image data. We study in depth the design of the image graph and propose in particular an effective method to select the edge weights for the multi-layer graph, such that the image ranking scores are optimised. We then provide extensive experiments in different real-world photo collections, which confirm the high performance of our new image retrieval algorithm that generally surpasses state-of-the-art solutions due to a more meaningful image similarity computation. version:1
arxiv-1607-03401 | Parsimonious Mixed-Effects HodgeRank for Crowdsourced Preference Aggregation | http://arxiv.org/abs/1607.03401 | id:1607.03401 author:Qianqian Xu, Jiechao Xiong, Xiaochun Cao, Yuan Yao category:cs.HC cs.LG cs.MM  published:2016-07-12 summary:In crowdsourced preference aggregation, it is often assumed that all the annotators are subject to a common preference or utility function which generates their comparison behaviors in experiments. However, in reality annotators are subject to variations due to multi-criteria, abnormal, or a mixture of such behaviors. In this paper, we propose a parsimonious mixed-effects model based on HodgeRank, which takes into account both the fixed effect that the majority of annotators follows a common linear utility model, and the random effect that a small subset of annotators might deviate from the common significantly and exhibits strongly personalized preferences. HodgeRank has been successfully applied to subjective quality evaluation of multimedia and resolves pairwise crowdsourced ranking data into a global consensus ranking and cyclic conflicts of interests. As an extension, our proposed methodology further explores the conflicts of interests through the random effect in annotator specific variations. The key algorithm in this paper establishes a dynamic path from the common utility to individual variations, with different levels of parsimony or sparsity on personalization, based on newly developed Linearized Bregman Algorithms with Inverse Scale Space method. Finally the validity of the methodology are supported by experiments with both simulated examples and three real-world crowdsourcing datasets, which shows that our proposed method exhibits better performance (i.e. smaller test error) compared with HodgeRank due to its parsimonious property. version:1
arxiv-1607-03392 | Statistical power and measurement bias in multisite resting-state fMRI connectivity | http://arxiv.org/abs/1607.03392 | id:1607.03392 author:Christian Dansereau, Yassine Benhajali, Celine Risterucci, Emilio Merlo Pich, Pierre Orban, Douglas Arnold, Pierre Bellec category:q-bio.QM cs.CE stat.ML  published:2016-07-12 summary:Connectivity studies using resting-state functional magnetic resonance imaging are increasingly pooling data acquired at multiple sites. While this may allow investigators to speed up recruitment or increase sample size, multisite studies also potentially introduce systematic biases in connectivity measures across sites. In this work, we measure the inter-site bias in connectivity and its impact on our ability to detect individual and group differences. Our study was based on real multisite fMRI datasets collected in N=345 young, healthy subjects across 8 scanning sites with 3T scanners and heterogeneous scanning protocols. We first empirically show that typical functional networks were reliably found at the group level in all sites, and that the amplitude of the inter-site bias was small to moderate, with a Cohen's effect size below 0.5 on average across brain connections. We then implemented a series of Monte-Carlo simulations, based on real data, to evaluate the impact of the multisite bias on detection power in statistical tests comparing two groups (with and without the effect) using a general linear model, as well as on the prediction of group labels with a support-vector machine. As a reference, we also implemented the same simulations with fMRI data collected at a single site using an identical sample size. Simulations revealed that using data from heterogeneous sites only slightly decreased our ability to detect changes compared to a monosite study with the GLM, and had a more serious impact on prediction accuracy. However, the deleterious effect of multisite data pooling tended to decrease as the total sample size increased, to a point where differences between monosite and multisite simulations were small with N=120 subjects. Taken together, our results support the feasibility of multisite studies in rs-fMRI provided sample size is large enough. version:1
arxiv-1607-03360 | Approximate maximum entropy principles via Goemans-Williamson with applications to provable variational methods | http://arxiv.org/abs/1607.03360 | id:1607.03360 author:Yuanzhi Li, Andrej Risteski category:cs.LG cs.DS stat.ML  published:2016-07-12 summary:The well known maximum-entropy principle due to Jaynes, which states that given mean parameters, the maximum entropy distribution matching them is in an exponential family, has been very popular in machine learning due to its "Occam's razor" interpretation. Unfortunately, calculating the potentials in the maximum-entropy distribution is intractable \cite{bresler2014hardness}. We provide computationally efficient versions of this principle when the mean parameters are pairwise moments: we design distributions that approximately match given pairwise moments, while having entropy which is comparable to the maximum entropy distribution matching those moments. We additionally provide surprising applications of the approximate maximum entropy principle to designing provable variational methods for partition function calculations for Ising models without any assumptions on the potentials of the model. More precisely, we show that in every temperature, we can get approximation guarantees for the log-partition function comparable to those in the low-temperature limit, which is the setting of optimization of quadratic forms over the hypercube. \cite{alon2006approximating} version:1
arxiv-1607-03333 | RGBD Salient Object Detection via Deep Fusion | http://arxiv.org/abs/1607.03333 | id:1607.03333 author:Liangqiong Qu, Shengfeng He, Jiawei Zhang, Jiandong Tian, Yandong Tang, Qingxiong Yang category:cs.CV  published:2016-07-12 summary:Numerous efforts have been made to design different low level saliency cues for the RGBD saliency detection, such as color or depth contrast features, background and color compactness priors. However, how these saliency cues interact with each other and how to incorporate these low level saliency cues effectively to generate a master saliency map remain a challenging problem. In this paper, we design a new convolutional neural network (CNN) to fuse different low level saliency cues into hierarchical features for automatically detecting salient objects in RGBD images. In contrast to the existing works that directly feed raw image pixels to the CNN, the proposed method takes advantage of the knowledge in traditional saliency detection by adopting various meaningful and well-designed saliency feature vectors as input. This can guide the training of CNN towards detecting salient object more effectively due to the reduced learning ambiguity. We then integrate a Laplacian propagation framework with the learned CNN to extract a spatially consistent saliency map by exploiting the intrinsic structure of the input image. Extensive quantitative and qualitative experimental evaluations on three datasets demonstrate that the proposed method consistently outperforms state-of-the-art methods. version:1
arxiv-1607-03317 | Populations can be essential in tracking dynamic optima | http://arxiv.org/abs/1607.03317 | id:1607.03317 author:Duc-Cuong Dang, Thomas Jansen, Per Kristian Lehre category:cs.NE cs.AI q-bio.PE  published:2016-07-12 summary:Real-world optimisation problems are often dynamic. Previously good solutions must be updated or replaced due to changes in objectives and constraints. It is often claimed that evolutionary algorithms are particularly suitable for dynamic optimisation because a large population can contain different solutions that may be useful in the future. However, rigorous theoretical demonstrations for how populations in dynamic optimisation can be essential are sparse and restricted to special cases. This paper provides theoretical explanations of how populations can be essential in evolutionary dynamic optimisation in a general and natural setting. We describe a natural class of dynamic optimisation problems where a sufficiently large population is necessary to keep track of moving optima reliably. We establish a relationship between the population-size and the probability that the algorithm loses track of the optimum. version:1
arxiv-1607-03313 | Predicting the evolution of stationary graph signals | http://arxiv.org/abs/1607.03313 | id:1607.03313 author:Andreas Loukas, Nathanael Perraudin category:stat.ML cs.LG  published:2016-07-12 summary:An emerging way of tackling the dimensionality issues arising in the modeling of a multivariate process is to assume that the inherent data structure can be captured by a graph. Nevertheless, though state-of-the-art graph-based methods have been successful for many learning tasks, they do not consider time-evolving signals and thus are not suitable for prediction. Based on the recently introduced joint stationarity framework for time-vertex processes, this letter considers multivariate models that exploit the graph topology so as to facilitate the prediction. The resulting method yields similar accuracy to the joint (time-graph) mean-squared error estimator but at lower complexity, and outperforms purely time-based methods. version:1
arxiv-1607-03305 | Camera Elevation Estimation from a Single Mountain Landscape Photograph | http://arxiv.org/abs/1607.03305 | id:1607.03305 author:Martin Cadik, Jan Vasicek, Michal Hradis, Filip Radenovic, Ondrej Chum category:cs.CV  published:2016-07-12 summary:This work addresses the problem of camera elevation estimation from a single photograph in an outdoor environment. We introduce a new benchmark dataset of one-hundred thousand images with annotated camera elevation called Alps100K. We propose and experimentally evaluate two automatic data-driven approaches to camera elevation estimation: one based on convolutional neural networks, the other on local features. To compare the proposed methods to human performance, an experiment with 100 subjects is conducted. The experimental results show that both proposed approaches outperform humans and that the best result is achieved by their combination. version:1
arxiv-1607-03300 | From Dependence to Causation | http://arxiv.org/abs/1607.03300 | id:1607.03300 author:David Lopez-Paz category:stat.ML  published:2016-07-12 summary:Machine learning is the science of discovering statistical dependencies in data, and the use of those dependencies to perform predictions. During the last decade, machine learning has made spectacular progress, surpassing human performance in complex tasks such as object recognition, car driving, and computer gaming. However, the central role of prediction in machine learning avoids progress towards general-purpose artificial intelligence. As one way forward, we argue that causal inference is a fundamental component of human intelligence, yet ignored by learning algorithms. Causal inference is the problem of uncovering the cause-effect relationships between the variables of a data generating system. Causal structures provide understanding about how these systems behave under changing, unseen environments. In turn, knowledge about these causal dynamics allows to answer "what if" questions, describing the potential responses of the system under hypothetical manipulations and interventions. Thus, understanding cause and effect is one step from machine learning towards machine reasoning and machine intelligence. But, currently available causal inference algorithms operate in specific regimes, and rely on assumptions that are difficult to verify in practice. This thesis advances the art of causal inference in three different ways. First, we develop a framework for the study of statistical dependence based on copulas and random features. Second, we build on this framework to interpret the problem of causal inference as the task of distribution classification, yielding a family of novel causal inference algorithms. Third, we discover causal structures in convolutional neural network features using our algorithms. The algorithms presented in this thesis are scalable, exhibit strong theoretical guarantees, and achieve state-of-the-art performance in a variety of real-world benchmarks. version:1
arxiv-1607-03289 | Boundary conditions for Shape from Shading | http://arxiv.org/abs/1607.03289 | id:1607.03289 author:Lyes Abada, Saliha Aouat, Omar el farouk Bourahla category:cs.CV  published:2016-07-12 summary:The Shape From Shading is one of a computer vision field. It studies the 3D reconstruction of an object from a single grayscale image. The difficulty of this field can be expressed in the local ambiguity (convex / concave). J.Shi and Q.Zhu have proposed a method (Global View) to solve the local ambiguity. This method based on the graph theory and the relationship between the singular points. In this work we will show that the use of singular points is not sufficient and requires further information on the object to resolve this ambiguity. version:1
arxiv-1607-03284 | A Machine learning approach for Shape From Shading | http://arxiv.org/abs/1607.03284 | id:1607.03284 author:Lyes Abada, Saliha Aouat category:cs.CV  published:2016-07-12 summary:The aim of Shape From Shading (SFS) problem is to reconstruct the relief of an object from a single gray level image. In this paper we present a new method to solve the problem of SFS using Machine learning method. Our approach belongs to Local resolution category. The orientation of each part of the object is represented by the perpendicular vector to the surface (Normal Vector), this vector is defined by two angles SLANT and TILT, such as the TILT is the angle between the normal vector and Z-axis, and the SLANT is the angle between the the X-axis and the projection of the normal to the plane. The TILT can be determined from the gray level, the unknown is the SLANT. To calculate the normal of each part of the surface (pixel) a supervised Machine learning method has been proposed. This method divided into three steps: the first step is the preparation of the training data from 3D mathematical functions and synthetic objects. The second step is the creation of database of examples from 3D objects (off-line process). The third step is the application of test images (on-line process). The idea is to find for each pixel of the test image the most similar element in the examples database using a similarity value. version:1
arxiv-1607-03257 | City-Identification of Flickr Videos Using Semantic Acoustic Features | http://arxiv.org/abs/1607.03257 | id:1607.03257 author:Benjamin Elizalde, Guan-Lin Chao, Ming Zeng, Ian Lane category:cs.MM cs.CV cs.SD  published:2016-07-12 summary:City-identification of videos aims to determine the likelihood of a video belonging to a set of cities. In this paper, we present an approach using only audio, thus we do not use any additional modality such as images, user-tags or geo-tags. In this manner, we show to what extent the city-location of videos correlates to their acoustic information. Success in this task suggests improvements can be made to complement the other modalities. In particular, we present a method to compute and use semantic acoustic features to perform city-identification and the features show semantic evidence of the identification. The semantic evidence is given by a taxonomy of urban sounds and expresses the potential presence of these sounds in the city- soundtracks. We used the MediaEval Placing Task set, which contains Flickr videos labeled by city. In addition, we used the UrbanSound8K set containing audio clips labeled by sound- type. Our method improved the state-of-the-art performance and provides a novel semantic approach to this task version:1
arxiv-1607-03255 | A Variational Model for Joint Motion Estimation and Image Reconstruction | http://arxiv.org/abs/1607.03255 | id:1607.03255 author:Martin Burger, Hendrik Dirks, Carola-Bibiane Schönlieb category:math.NA cs.CV math.OC 68U10  65K10  65M06  published:2016-07-12 summary:The aim of this paper is to derive and analyze a variational model for the joint estimation of motion and reconstruction of image sequences, which is based on a time-continuous Eulerian motion model. The model can be set up in terms of the continuity equation or the brightness constancy equation. The analysis in this paper focuses on the latter for robust motion estimation on sequences of two-dimensional images. We rigorously prove the existence of a minimizer in a suitable function space setting. Moreover, we discuss the numerical solution of the model based on primal-dual algorithms and investigate several examples. Finally, the benefits of our model compared to existing techniques, such as sequential image reconstruction and motion estimation, are shown. version:1
arxiv-1607-03250 | Network Trimming: A Data-Driven Neuron Pruning Approach towards Efficient Deep Architectures | http://arxiv.org/abs/1607.03250 | id:1607.03250 author:Hengyuan Hu, Rui Peng, Yu-Wing Tai, Chi-Keung Tang category:cs.NE cs.CV cs.LG  published:2016-07-12 summary:State-of-the-art neural networks are getting deeper and wider. While their performance increases with the increasing number of layers and neurons, it is crucial to design an efficient deep architecture in order to reduce computational and memory costs. Designing an efficient neural network, however, is labor intensive requiring many experiments, and fine-tunings. In this paper, we introduce network trimming which iteratively optimizes the network by pruning unimportant neurons based on analysis of their outputs on a large dataset. Our algorithm is inspired by an observation that the outputs of a significant portion of neurons in a large network are mostly zero, regardless of what inputs the network received. These zero activation neurons are redundant, and can be removed without affecting the overall accuracy of the network. After pruning the zero activation neurons, we retrain the network using the weights before pruning as initialization. We alternate the pruning and retraining to further reduce zero activations in a network. Our experiments on the LeNet and VGG-16 show that we can achieve high compression ratio of parameters without losing or even achieving higher accuracy than the original network. version:1
arxiv-1607-03240 | Weakly Supervised Learning of Heterogeneous Concepts in Videos | http://arxiv.org/abs/1607.03240 | id:1607.03240 author:Sohil Shah, Kuldeep Kulkarni, Arijit Biswas, Ankit Gandhi, Om Deshmukh, Larry Davis category:cs.CV  published:2016-07-12 summary:Typical textual descriptions that accompany online videos are 'weak': i.e., they mention the main concepts in the video but not their corresponding spatio-temporal locations. The concepts in the description are typically heterogeneous (e.g., objects, persons, actions). Certain location constraints on these concepts can also be inferred from the description. The goal of this paper is to present a generalization of the Indian Buffet Process (IBP) that can (a) systematically incorporate heterogeneous concepts in an integrated framework, and (b) enforce location constraints, for efficient classification and localization of the concepts in the videos. Finally, we develop posterior inference for the proposed formulation using mean-field variational approximation. Comparative evaluations on the Casablanca and the A2D datasets show that the proposed approach significantly outperforms other state-of-the-art techniques: 24% relative improvement for pairwise concept classification in the Casablanca dataset and 9% relative improvement for localization in the A2D dataset as compared to the most competitive baseline. version:1
arxiv-1607-03226 | Local feature hierarchy for face recognition across pose and illumination | http://arxiv.org/abs/1607.03226 | id:1607.03226 author:Xiaoyue Jiang, Dong Zhang, Xiaoyi Feng category:cs.CV  published:2016-07-12 summary:Even though face recognition in frontal view and normal lighting condition works very well, the performance degenerates sharply in extreme conditions. Recently there are many work dealing with pose and illumination problems, respectively. However both the lighting and pose variation will always be encountered at the same time. Accordingly we propose an end-to-end face recognition method to deal with pose and illumination simultaneously based on convolutional networks where the discriminative nonlinear features that are invariant to pose and illumination are extracted. Normally the global structure for images taken in different views is quite diverse. Therefore we propose to use the 1*1 convolutional kernel to extract the local features. Furthermore the parallel multi-stream multi-layer 1*1 convolution network is developed to extract multi-hierarchy features. In the experiments we obtained the average face recognition rate of 96.9% on multiPIE dataset,which improves the state-of-the-art of face recognition across poses and illumination by 7.5%. Especially for profile-wise positions, the average recognition rate of our proposed network is 97.8%, which increases the state-of-the-art recognition rate by 19%. version:1
arxiv-1607-03204 | Information Projection and Approximate Inference for Structured Sparse Variables | http://arxiv.org/abs/1607.03204 | id:1607.03204 author:Rajiv Khanna, Joydeep Ghosh, Russell Poldrack, Oluwasanmi Koyejo category:stat.ML cs.LG  published:2016-07-12 summary:Approximate inference via information projection has been recently introduced as a general-purpose approach for efficient probabilistic inference given sparse variables. This manuscript goes beyond classical sparsity by proposing efficient algorithms for approximate inference via information projection that are applicable to any structure on the set of variables that admits enumeration using a \emph{matroid}. We show that the resulting information projection can be reduced to combinatorial submodular optimization subject to matroid constraints. Further, leveraging recent advances in submodular optimization, we provide an efficient greedy algorithm with strong optimization-theoretic guarantees. The class of probabilistic models that can be expressed in this way is quite broad and, as we show, includes group sparse regression, group sparse principal components analysis and sparse canonical correlation analysis, among others. Moreover, empirical results on simulated data and high dimensional neuroimaging data highlight the superior performance of the information projection approach as compared to established baselines for a range of probabilistic models. version:1
arxiv-1607-03202 | Rapid Prediction of Player Retention in Free-to-Play Mobile Games | http://arxiv.org/abs/1607.03202 | id:1607.03202 author:Anders Drachen, Eric Thurston Lundquist, Yungjen Kung, Pranav Simha Rao, Diego Klabjan, Rafet Sifa, Julian Runge category:stat.ML cs.SI stat.AP  published:2016-07-12 summary:Predicting and improving player retention is crucial to the success of mobile Free-to-Play games. This paper explores the problem of rapid retention prediction in this context. Heuristic modeling approaches are introduced as a way of building simple rules for predicting short-term retention. Compared to common classification algorithms, our heuristic-based approach achieves reasonable and comparable performance using information from the first session, day, and week of player activity. version:1
arxiv-1607-03200 | Qualitative Judgement of Research Impact: Domain Taxonomy as a Fundamental Framework for Judgement of the Quality of Research | http://arxiv.org/abs/1607.03200 | id:1607.03200 author:Fionn Murtagh, Michael Orlov, Boris Mirkin category:cs.DL stat.ML 68P01 H.0; I.5.3; G.3  published:2016-07-11 summary:The appeal of metric evaluation of research impact has attracted considerable interest in recent times. Although the public at large and administrative bodies are much interested in the idea, scientists and other researchers are much more cautious, insisting that metrics are but an auxiliary instrument to the qualitative peer-based judgement. The goal of this article is to propose availing of such a well positioned construct as domain taxonomy as a tool for directly assessing the scope and quality of research. We first show how taxonomies can be used to analyse the scope and perspectives of a set of research projects or papers. Then we proceed to define a research team or researcher's rank by those nodes in the hierarchy that have been created or significantly transformed by the results of the researcher. An experimental test of the approach in the data analysis domain is described. Although the concept of taxonomy seems rather simplistic to describe all the richness of a research domain, its changes and use can be made transparent and subject to open discussions. version:1
arxiv-1607-03195 | Multi-Step Bayesian Optimization for One-Dimensional Feasibility Determination | http://arxiv.org/abs/1607.03195 | id:1607.03195 author:J. Massey Cashore, Lemuel Kumarga, Peter I. Frazier category:math.OC cs.LG stat.CO  published:2016-07-11 summary:Bayesian optimization methods allocate limited sampling budgets to maximize expensive-to-evaluate functions. One-step-lookahead policies are often used, but computing optimal multi-step-lookahead policies remains a challenge. We consider a specialized Bayesian optimization problem: finding the superlevel set of an expensive one-dimensional function, with a Markov process prior. We compute the Bayes-optimal sampling policy efficiently, and characterize the suboptimality of one-step lookahead. Our numerical experiments demonstrate that the one-step lookahead policy is close to optimal in this problem, performing within 98% of optimal in the experimental settings considered. version:1
arxiv-1607-03191 | On Deterministic Conditions for Subspace Clustering under Missing Data | http://arxiv.org/abs/1607.03191 | id:1607.03191 author:Wenqi Wang, Shuchin Aeron, Vaneet Aggarwal category:cs.IT cs.LG math.IT stat.ML  published:2016-07-11 summary:In this paper we present deterministic conditions for success of sparse subspace clustering (SSC) under missing data, when data is assumed to come from a Union of Subspaces (UoS) model. We consider two algorithms, which are variants of SSC with entry-wise zero-filling that differ in terms of the optimization problems used to find affinity matrix for spectral clustering. For both the algorithms, we provide deterministic conditions for any pattern of missing data such that perfect clustering can be achieved. We provide extensive sets of simulation results for clustering as well as completion of data at missing entries, under the UoS model. Our experimental results indicate that in contrast to the full data case, accurate clustering does not imply accurate subspace identification and completion, indicating the natural order of relative hardness of these problems. version:1
arxiv-1607-03183 | How to calculate partition functions using convex programming hierarchies: provable bounds for variational methods | http://arxiv.org/abs/1607.03183 | id:1607.03183 author:Andrej Risteski category:cs.LG cs.DS stat.ML  published:2016-07-11 summary:We consider the problem of approximating partition functions for Ising models. We make use of recent tools in combinatorial optimization: the Sherali-Adams and Lasserre convex programming hierarchies, in combination with variational methods to get algorithms for calculating partition functions in these families. These techniques give new, non-trivial approximation guarantees for the partition function beyond the regime of correlation decay. They also generalize some classical results from statistical physics about the Curie-Weiss ferromagnetic Ising model, as well as provide a partition function counterpart of classical results about max-cut on dense graphs \cite{arora1995polynomial}. With this, we connect techniques from two apparently disparate research areas -- optimization and counting/partition function approximations. (i.e. \#-P type of problems). Furthermore, we design to the best of our knowledge the first provable, convex variational methods. Though in the literature there are a host of convex versions of variational methods \cite{wainwright2003tree, wainwright2005new, heskes2006convexity, meshi2009convexifying}, they come with no guarantees (apart from some extremely special cases, like e.g. the graph has a single cycle \cite{weiss2000correctness}). We consider dense and low threshold rank graphs, and interestingly, the reason our approach works on these types of graphs is because local correlations propagate to global correlations -- completely the opposite of algorithms based on correlation decay. In the process we design novel entropy approximations based on the low-order moments of a distribution. Our proof techniques are very simple and generic, and likely to be applicable to many other settings other than Ising models. version:1
arxiv-1607-03182 | Stream-based Online Active Learning in a Contextual Multi-Armed Bandit Framework | http://arxiv.org/abs/1607.03182 | id:1607.03182 author:Linqi Song category:cs.LG  published:2016-07-11 summary:We study the stream-based online active learning in a contextual multi-armed bandit framework. In this framework, the reward depends on both the arm and the context. In a stream-based active learning setting, obtaining the ground truth of the reward is costly, and the conventional contextual multi-armed bandit algorithm fails to achieve a sublinear regret due to this cost. Hence, the algorithm needs to determine whether or not to request the ground truth of the reward at current time slot. In our framework, we consider a stream-based active learning setting in which a query request for the ground truth is sent to the annotator, together with some prior information of the ground truth. Depending on the accuracy of the prior information, the query cost varies. Our algorithm mainly carries out two operations: the refinement of the context and arm spaces and the selection of actions. In our algorithm, the partitions of the context space and the arm space are maintained for a certain time slots, and then become finer as more information about the rewards accumulates. We use a strategic way to select the arms and to request the ground truth of the reward, aiming to maximize the total reward. We analytically show that the regret is sublinear and in the same order with that of the conventional contextual multi-armed bandit algorithms, where no query cost version:1
arxiv-1607-03164 | Fast Cosine Transform to increase speed-up and efficiency of Karhunen-Loeve Transform for lossy image compression | http://arxiv.org/abs/1607.03164 | id:1607.03164 author:Mario Mastriani, Juliana Gambini category:cs.CV  published:2016-07-11 summary:In this work, we present a comparison between two techniques of image compression. In the first case, the image is divided in blocks which are collected according to zig-zag scan. In the second one, we apply the Fast Cosine Transform to the image, and then the transformed image is divided in blocks which are collected according to zig-zag scan too. Later, in both cases, the Karhunen-Loeve transform is applied to mentioned blocks. On the other hand, we present three new metrics based on eigenvalues for a better comparative evaluation of the techniques. Simulations show that the combined version is the best, with minor Mean Absolute Error (MAE) and Mean Squared Error (MSE), higher Peak Signal to Noise Ratio (PSNR) and better image quality. Finally, new technique was far superior to JPEG and JPEG2000. version:1
arxiv-1607-03084 | Kernel-based methods for bandit convex optimization | http://arxiv.org/abs/1607.03084 | id:1607.03084 author:Sébastien Bubeck, Ronen Eldan, Yin Tat Lee category:cs.LG cs.DS math.OC stat.ML  published:2016-07-11 summary:We consider the adversarial convex bandit problem and we build the first $\mathrm{poly}(T)$-time algorithm with $\mathrm{poly}(n) \sqrt{T}$-regret for this problem. To do so we introduce three new ideas in the derivative-free optimization literature: (i) kernel methods, (ii) a generalization of Bernoulli convolutions, and (iii) a new annealing schedule for exponential weights (with increasing learning rate). The basic version of our algorithm achieves $\tilde{O}(n^{9.5} \sqrt{T})$-regret, and we show that a simple variant of this algorithm can be run in $\mathrm{poly}(n \log(T))$-time per step at the cost of an additional $\mathrm{poly}(n) T^{o(1)}$ factor in the regret. These results improve upon the $\tilde{O}(n^{11} \sqrt{T})$-regret and $\exp(\mathrm{poly}(T))$-time result of the first two authors, and the $\log(T)^{\mathrm{poly}(n)} \sqrt{T}$-regret and $\log(T)^{\mathrm{poly}(n)}$-time result of Hazan and Li. Furthermore we conjecture that another variant of the algorithm could achieve $\tilde{O}(n^{1.5} \sqrt{T})$-regret, and moreover that this regret is unimprovable (the current best lower bound being $\Omega(n \sqrt{T})$ and it is achieved with linear functions). For the simpler situation of zeroth order stochastic convex optimization this corresponds to the conjecture that the optimal query complexity is of order $n^3 / \epsilon^2$. version:1
arxiv-1607-03081 | Proximal Quasi-Newton Methods for Convex Optimization | http://arxiv.org/abs/1607.03081 | id:1607.03081 author:Hiva Ghanbari, Katya Scheinberg category:cs.NA cs.LG math.OC stat.ML  published:2016-07-11 summary:In [19], a general, inexact, efficient proximal quasi-Newton algorithm for composite optimization problems has been proposed and a sublinear global convergence rate has been established. In this paper, we analyze the convergence properties of this method, both in the exact and inexact setting, in the case when the objective function is strongly convex. We also investigate a practical variant of this method by establishing a simple stopping criterion for the subproblem optimization. Furthermore, we consider an accelerated variant, based on FISTA [1], to the proximal quasi-Newton algorithm. A similar accelerated method has been considered in [7], where the convergence rate analysis relies on very strong impractical assumptions. We present a modified analysis while relaxing these assumptions and perform a practical comparison of the accelerated proximal quasi- Newton algorithm and the regular one. Our analysis and computational results show that acceleration may not bring any benefit in the quasi-Newton setting. version:1
arxiv-1607-03055 | Exploring the Political Agenda of the European Parliament Using a Dynamic Topic Modeling Approach | http://arxiv.org/abs/1607.03055 | id:1607.03055 author:Derek Greene, James P. Cross category:cs.CL cs.CY  published:2016-07-11 summary:This study analyzes the political agenda of the European Parliament (EP) plenary, how it has evolved over time, and the manner in which Members of the European Parliament (MEPs) have reacted to external and internal stimuli when making plenary speeches. To unveil the plenary agenda and detect latent themes in legislative speeches over time, MEP speech content is analyzed using a new dynamic topic modeling method based on two layers of Non-negative Matrix Factorization (NMF). This method is applied to a new corpus of all English language legislative speeches in the EP plenary from the period 1999-2014. Our findings suggest that two-layer NMF is a valuable alternative to existing dynamic topic modeling approaches found in the literature, and can unveil niche topics and associated vocabularies not captured by existing methods. Substantively, our findings suggest that the political agenda of the EP evolves significantly over time and reacts to exogenous events such as EU Treaty referenda and the emergence of the Euro-crisis. MEP contributions to the plenary agenda are also found to be impacted upon by voting behaviour and the committee structure of the Parliament. version:1
arxiv-1607-03050 | Learning a metric for class-conditional KNN | http://arxiv.org/abs/1607.03050 | id:1607.03050 author:Daniel Jiwoong Im, Graham W. Taylor category:cs.LG stat.ML  published:2016-07-11 summary:Naive Bayes Nearest Neighbour (NBNN) is a simple and effective framework which addresses many of the pitfalls of K-Nearest Neighbour (KNN) classification. It has yielded competitive results on several computer vision benchmarks. Its central tenet is that during NN search, a query is not compared to every example in a database, ignoring class information. Instead, NN searches are performed within each class, generating a score per class. A key problem with NN techniques, including NBNN, is that they fail when the data representation does not capture perceptual (e.g.~class-based) similarity. NBNN circumvents this by using independent engineered descriptors (e.g.~SIFT). To extend its applicability outside of image-based domains, we propose to learn a metric which captures perceptual similarity. Similar to how Neighbourhood Components Analysis optimizes a differentiable form of KNN classification, we propose "Class Conditional" metric learning (CCML), which optimizes a soft form of the NBNN selection rule. Typical metric learning algorithms learn either a global or local metric. However, our proposed method can be adjusted to a particular level of locality by tuning a single parameter. An empirical evaluation on classification and retrieval tasks demonstrates that our proposed method clearly outperforms existing learned distance metrics across a variety of image and non-image datasets. version:1
arxiv-1607-03026 | Retrospective Causal Inference with Machine Learning Ensembles: An Application to Anti-Recidivism Policies in Colombia | http://arxiv.org/abs/1607.03026 | id:1607.03026 author:Cyrus Samii, Laura Paler, Sarah Zukerman Daly category:stat.ML  published:2016-07-11 summary:We present new methods to estimate causal effects retrospectively from micro data with the assistance of a machine learning ensemble. This approach overcomes two important limitations in conventional methods like regression modeling or matching: (i) ambiguity about the pertinent retrospective counterfactuals and (ii) potential misspecification, overfitting, and otherwise bias-prone or inefficient use of a large identifying covariate set in the estimation of causal effects. Our method targets the analysis toward a well defined ``retrospective intervention effect'' (RIE) based on hypothetical population interventions and applies a machine learning ensemble that allows data to guide us, in a controlled fashion, on how to use a large identifying covariate set. We illustrate with an analysis of policy options for reducing ex-combatant recidivism in Colombia. version:1
arxiv-1607-03021 | Salient Region Detection and Segmentation in Images using Dynamic Mode Decomposition | http://arxiv.org/abs/1607.03021 | id:1607.03021 author:Sikha O K, Sachin Kumar S, K P Soman category:cs.CV  published:2016-07-11 summary:Visual Saliency is the capability of vision system to select distinctive parts of scene and reduce the amount of visual data that need to be processed. The presentpaper introduces (1) a novel approach to detect salient regions by considering color and luminance based saliency scores using Dynamic Mode Decomposition (DMD), (2) a new interpretation to use DMD approach in static image processing. This approach integrates two data analysis methods: (1) Fourier Transform, (2) Principle Component Analysis.The key idea of our work is to create a color based saliency map. This is based on the observation thatsalient part of an image usually have distinct colors compared to the remaining portion of the image. We have exploited the power of different color spaces to model the complex and nonlinear behavior of human visual system to generate a color based saliency map. To further improve the effect of final saliency map, weutilized luminance information exploiting the fact that human eye is more sensitive towards brightness than color.The experimental results shows that our method based on DMD theory is effective in comparison with previous state-of-art saliency estimation approaches. The approach presented in this paperis evaluated using ROC curve, F-measure rate, Precision-Recall rate, AUC score etc. version:1
arxiv-1607-04267 | Enhanced Boolean Correlation Matrix Memory | http://arxiv.org/abs/1607.04267 | id:1607.04267 author:Mario Mastriani category:cs.NE  published:2016-07-11 summary:This paper introduces an Enhanced Boolean version of the Correlation Matrix Memory (CMM), which is useful to work with binary memories. A novel Boolean Orthonormalization Process (BOP) is presented to convert a non-orthonormal Boolean basis, i.e., a set of non-orthonormal binary vectors (in a Boolean sense) to an orthonormal Boolean basis, i.e., a set of orthonormal binary vectors (in a Boolean sense). This work shows that it is possible to improve the performance of Boolean CMM thanks BOP algorithm. Besides, the BOP algorithm has a lot of additional fields of applications, e.g.: Steganography, Hopfield Networks, Bi-level image processing, etc. Finally, it is important to mention that the BOP is an extremely stable and fast algorithm. version:1
arxiv-1607-03105 | Systholic Boolean Orthonormalizer Network in Wavelet Domain for SAR Image Despeckling | http://arxiv.org/abs/1607.03105 | id:1607.03105 author:Mario Mastriani category:cs.CV  published:2016-07-11 summary:We describe a novel method for removing speckle (in wavelet domain) of unknown variance from SAR images. The me-thod is based on the following procedure: We apply 1) Bidimentional Discrete Wavelet Transform (DWT-2D) to the speckled image, 2) scaling and rounding to the coefficients of the highest subbands (to obtain integer and positive coefficients), 3) bit-slicing to the new highest subbands (to obtain bit-planes), 4) then we apply the Systholic Boolean Orthonormalizer Network (SBON) to the input bit-plane set and we obtain two orthonormal output bit-plane sets (in a Boolean sense), we project a set on the other one, by means of an AND operation, and then, 5) we apply re-assembling, and, 6) re-sca-ling. Finally, 7) we apply Inverse DWT-2D and reconstruct a SAR image from the modified wavelet coefficients. Despeckling results compare favorably to the most of methods in use at the moment. version:1
arxiv-1607-02959 | From Behavior to Sparse Graphical Games: Efficient Recovery of Equilibria | http://arxiv.org/abs/1607.02959 | id:1607.02959 author:Asish Ghoshal, Jean Honorio category:cs.GT cs.LG stat.ML  published:2016-07-11 summary:In this paper we study the problem of exact recovery of the pure-strategy Nash equilibria (PSNE) set of a graphical game from noisy observations of joint actions of the players alone. We consider sparse linear influence games --- a parametric class of graphical games with linear payoffs, and represented by directed graphs of n nodes (players) and in-degree of at most k. We present an $\ell_1$-regularized logistic regression based algorithm for recovering the PSNE set exactly, that is both computationally efficient --- i.e. runs in polynomial time --- and statistically efficient --- i.e. has logarithmic sample complexity. Specifically, we show that the sufficient number of samples required for exact PSNE recovery scales as $\mathcal{O}(\mathrm{poly}(k) \log n)$. We also validate our theoretical results using synthetic experiments. version:1
arxiv-1607-02196 | Persistent Homology on Grassmann Manifolds for Analysis of Hyperspectral Movies | http://arxiv.org/abs/1607.02196 | id:1607.02196 author:Sofya Chepushtanova, Michael Kirby, Chris Peterson, Lori Ziegelmeier category:cs.CV cs.CG math.AT  published:2016-07-07 summary:The existence of characteristic structure, or shape, in complex data sets has been recognized as increasingly important for mathematical data analysis. This realization has motivated the development of new tools such as persistent homology for exploring topological invariants, or features, in large data sets. In this paper we apply persistent homology to the characterization of gas plumes in time dependent sequences of hyperspectral cubes, i.e. the analysis of 4-way arrays. We investigate hyperspectral movies of Long-Wavelength Infrared data monitoring an experimental release of chemical simulant into the air. Our approach models regions of interest within the hyperspectral data cubes as points on the real Grassmann manifold $G(k, n)$ (whose points parameterize the $k$-dimensional subspaces of $\mathbb{R}^n$), contrasting our approach with the more standard framework in Euclidean space. An advantage of this approach is that it allows a sequence of time slices in a hyperspectral movie to be collapsed to a sequence of points in such a way that some of the key structure within and between the slices is encoded by the points on the Grassmann manifold. This motivates the search for topological features, associated with the evolution of the frames of a hyperspectral movie, within the corresponding points on the Grassmann manifold. The proposed mathematical model affords the processing of large data sets while retaining valuable discriminatory information. In this paper, we discuss how embedding our data in the Grassmann manifold, together with topological data analysis, captures dynamical events that occur as the chemical plume is released and evolves. version:2
arxiv-1607-02937 | A Benchmark for License Plate Character Segmentation | http://arxiv.org/abs/1607.02937 | id:1607.02937 author:Gabriel Resende Gonçalves, Sirlene Pio Gomes da Silva, David Menotti, William Robson Schwartz category:cs.CV  published:2016-07-11 summary:Automatic License Plate Recognition (ALPR) has been the focus of many researches in the past years. In general, ALPR is divided into the following problems: detection of on-track vehicles, license plates detection, segmention of license plate characters and optical character recognition (OCR). Even though commercial solutions are available for controlled acquisition conditions, e.g., the entrance of a parking lot, ALPR is still an open problem when dealing with data acquired from uncontrolled environments, such as roads and highways when relying only on imaging sensors. Due to the multiple orientations and scales of the license plates captured by the camera, a very challenging task of the ALPR is the License Plate Character Segmentation (LPCS) step, which effectiveness is required to be (near) optimal to achieve a high recognition rate by the OCR. To tackle the LPCS problem, this work proposes a novel benchmark composed of a dataset designed to focus specifically on the character segmentation step of the ALPR within an evaluation protocol. Furthermore, we propose the Jaccard-Centroid coefficient, a new evaluation measure more suitable than the Jaccard coefficient regarding the location of the bounding box within the ground-truth annotation. The dataset is composed of 2,000 Brazilian license plates consisting of 14,000 alphanumeric symbols and their corresponding bounding box annotations. We also present a new straightforward approach to perform LPCS efficiently. Finally, we provide an experimental evaluation for the dataset based on four LPCS approaches and demonstrate the importance of character segmentation for achieving an accurate OCR. version:1
arxiv-1607-02936 | Inference of Haemoglobin Concentration From Stereo RGB | http://arxiv.org/abs/1607.02936 | id:1607.02936 author:Geoffrey Jones, Neil T. Clancy, Simon Arridge, Daniel S. Elson, Danail Stoyanov category:cs.CV  published:2016-07-11 summary:Multispectral imaging (MSI) can provide information about tissue oxygenation, perfusion and potentially function during surgery. In this paper we present a novel, near real-time technique for intrinsic measurements of total haemoglobin (THb) and blood oxygenation (SO2) in tissue using only RGB images from a stereo laparoscope. The high degree of spectral overlap between channels makes inference of haemoglobin concentration challenging, non-linear and under constrained. We decompose the problem into two constrained linear sub-problems and show that with Tikhonov regularisation the estimation significantly improves, giving robust estimation of the Thb. We demonstrate by using the co-registered stereo image data from two cameras it is possible to get robust SO2 estimation as well. Our method is closed from, providing computational efficiency even with multiple cameras. The method we present requires only spectral response calibration of each camera, without modification of existing laparoscopic imaging hardware. We validate our technique on synthetic data from Monte Carlo simulation % of light transport through soft tissue containing submerged blood vessels and further, in vivo, on a multispectral porcine data set. version:1
arxiv-1607-02914 | Minimum Description Length Principle in Supervised Learning with Application to Lasso | http://arxiv.org/abs/1607.02914 | id:1607.02914 author:Masanori Kawakita, Jun'ichi Takeuchi category:cs.IT math.IT stat.ML  published:2016-07-11 summary:The minimum description length (MDL) principle in supervised learning is studied. One of the most important theories for the MDL principle is Barron and Cover's theory (BC theory), which gives a mathematical justification of the MDL principle. The original BC theory, however, can be applied to supervised learning only approximately and limitedly. Though Barron et al. recently succeeded in removing a similar approximation in case of unsupervised learning, their idea cannot be essentially applied to supervised learning in general. To overcome this issue, an extension of BC theory to supervised learning is proposed. The derived risk bound has several advantages inherited from the original BC theory. First, the risk bound holds for finite sample size. Second, it requires remarkably few assumptions. Third, the risk bound has a form of redundancy of the two-stage code for the MDL procedure. Hence, the proposed extension gives a mathematical justification of the MDL principle to supervised learning like the original BC theory. As an important example of application, new risk and (probabilistic) regret bounds of lasso with random design are derived. The derived risk bound holds for any finite sample size $n$ and feature number $p$ even if $n\ll p$ without boundedness of features in contrast to the past work. Behavior of the regret bound is investigated by numerical simulations. We believe that this is the first extension of BC theory to general supervised learning with random design without approximation. version:1
arxiv-1607-00148 | LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection | http://arxiv.org/abs/1607.00148 | id:1607.00148 author:Pankaj Malhotra, Anusha Ramakrishnan, Gaurangi Anand, Lovekesh Vig, Puneet Agarwal, Gautam Shroff category:cs.AI cs.LG stat.ML  published:2016-07-01 summary:Mechanical devices such as engines, vehicles, aircrafts, etc., are typically instrumented with numerous sensors to capture the behavior and health of the machine. However, there are often external factors or variables which are not captured by sensors leading to time-series which are inherently unpredictable. For instance, manual controls and/or unmonitored environmental conditions or load may lead to inherently unpredictable time-series. Detecting anomalies in such scenarios becomes challenging using standard approaches based on mathematical models that rely on stationarity, or prediction models that utilize prediction errors to detect anomalies. We propose a Long Short Term Memory Networks based Encoder-Decoder scheme for Anomaly Detection (EncDec-AD) that learns to reconstruct 'normal' time-series behavior, and thereafter uses reconstruction error to detect anomalies. We experiment with three publicly available quasi predictable time-series datasets: power demand, space shuttle, and ECG, and two real-world engine datasets with both predictive and unpredictable behavior. We show that EncDec-AD is robust and can detect anomalies from predictable, unpredictable, periodic, aperiodic, and quasi-periodic time-series. Further, we show that EncDec-AD is able to detect anomalies from short time-series (length as small as 30) as well as long time-series (length as large as 500). version:2
arxiv-1607-01231 | Stochastic Quasi-Newton Methods for Nonconvex Stochastic Optimization | http://arxiv.org/abs/1607.01231 | id:1607.01231 author:Xiao Wang, Shiqian Ma, Donald Goldfarb, Wei Liu category:math.OC cs.LG cs.NA stat.ML  published:2016-07-05 summary:In this paper we study stochastic quasi-Newton methods for nonconvex stochastic optimization, where we assume that noisy information about the gradients of the objective function is available via a stochastic first-order oracle (SFO). We propose a general framework for such methods, and prove the almost sure convergence of them to stationary points and analyze their worst-case iteration complexity. When a randomly chosen iterate is returned as the output of such an algorithm, we prove that in the worst-case, the SFO-calls complexity is $O(\epsilon^{-2})$ to ensure that the expectation of the squared norm of the gradient is smaller than the given accuracy tolerance $\epsilon$. We also propose a specific algorithm, namely a stochastic damped L-BFGS method, that falls under the proposed framework. Numerical results on a nonconvex classification problem are reported for both synthetic and real data, that demonstrate the promising potential of the proposed method. version:2
arxiv-1607-02858 | Incremental Factorization Machines for Persistently Cold-starting Online Item Recommendation | http://arxiv.org/abs/1607.02858 | id:1607.02858 author:Takuya Kitazawa category:cs.LG cs.IR  published:2016-07-11 summary:Real-world item recommenders commonly suffer from a persistent cold-start problem which is caused by dynamically changing users and items. In order to overcome the problem, several context-aware recommendation techniques have been recently proposed. In terms of both feasibility and performance, factorization machine (FM) is one of the most promising methods as generalization of the conventional matrix factorization techniques. However, since online algorithms are suitable for dynamic data, the static FMs are still inadequate. Thus, this paper proposes incremental FMs (iFMs), a general online factorization framework, and specially extends iFMs into an online item recommender. The proposed framework can be a promising baseline for further development of the production recommender systems. Evaluation is done empirically both on synthetic and real-world unstable datasets. version:1
arxiv-1607-02857 | Classifying Variable-Length Audio Files with All-Convolutional Networks and Masked Global Pooling | http://arxiv.org/abs/1607.02857 | id:1607.02857 author:Lars Hertel, Huy Phan, Alfred Mertins category:cs.NE cs.LG cs.MM cs.SD  published:2016-07-11 summary:We trained a deep all-convolutional neural network with masked global pooling to perform single-label classification for acoustic scene classification and multi-label classification for domestic audio tagging in the DCASE-2016 contest. Our network achieved an average accuracy of 84.5% on the four-fold cross-validation for acoustic scene recognition, compared to the provided baseline of 72.5%, and an average equal error rate of 0.17 for domestic audio tagging, compared to the baseline of 0.21. The network therefore improves the baselines by a relative amount of 17% and 19%, respectively. The network only consists of convolutional layers to extract features from the short-time Fourier transform and one global pooling layer to combine those features. It particularly possesses neither fully-connected layers, besides the fully-connected output layer, nor dropout layers. version:1
arxiv-1607-01981 | Nesterov's Accelerated Gradient and Momentum as approximations to Regularised Update Descent | http://arxiv.org/abs/1607.01981 | id:1607.01981 author:Aleksandar Botev, Guy Lever, David Barber category:stat.ML cs.LG  published:2016-07-07 summary:We present a unifying framework for adapting the update direction in gradient-based iterative optimization methods. As natural special cases we re-derive classical momentum and Nesterov's accelerated gradient method, lending a new intuitive interpretation to the latter algorithm. We show that a new algorithm, which we term Regularised Gradient Descent, can converge more quickly than either Nesterov's algorithm or the classical momentum algorithm. version:2
arxiv-1607-02829 | Hypergraph Modelling for Geometric Model Fitting | http://arxiv.org/abs/1607.02829 | id:1607.02829 author:Guobao Xiao, Hanzi Wang, Taotao Lai, David Suter category:cs.CV  published:2016-07-11 summary:In this paper, we propose a novel hypergraph based method (called HF) to fit and segment multi-structural data. The proposed HF formulates the geometric model fitting problem as a hypergraph partition problem based on a novel hypergraph model. In the hypergraph model, vertices represent data points and hyperedges denote model hypotheses. The hypergraph, with large and "data-determined" degrees of hyperedges, can express the complex relationships between model hypotheses and data points. In addition, we develop a robust hypergraph partition algorithm to detect sub-hypergraphs for model fitting. HF can effectively and efficiently estimate the number of, and the parameters of, model instances in multi-structural data heavily corrupted with outliers simultaneously. Experimental results show the advantages of the proposed method over previous methods on both synthetic data and real images. version:1
arxiv-1607-02815 | Efficient Activity Detection in Untrimmed Video with Max-Subgraph Search | http://arxiv.org/abs/1607.02815 | id:1607.02815 author:Chao-Yeh Chen, Kristen Grauman category:cs.CV  published:2016-07-11 summary:We propose an efficient approach for activity detection in video that unifies activity categorization with space-time localization. The main idea is to pose activity detection as a maximum-weight connected subgraph problem. Offline, we learn a binary classifier for an activity category using positive video exemplars that are "trimmed" in time to the activity of interest. Then, given a novel \emph{untrimmed} video sequence, we decompose it into a 3D array of space-time nodes, which are weighted based on the extent to which their component features support the learned activity model. To perform detection, we then directly localize instances of the activity by solving for the maximum-weight connected subgraph in the test video's space-time graph. We show that this detection strategy permits an efficient branch-and-cut solution for the best-scoring---and possibly non-cubically shaped---portion of the video for a given activity classifier. The upshot is a fast method that can search a broader space of space-time region candidates than was previously practical, which we find often leads to more accurate detection. We demonstrate the proposed algorithm on four datasets, and we show its speed and accuracy advantages over multiple existing search strategies. version:1
arxiv-1607-05755 | A New Bengali Readability Score | http://arxiv.org/abs/1607.05755 | id:1607.05755 author:Shanta Phani, Shibamouli Lahiri, Arindam Biswas category:cs.CL  published:2016-07-10 summary:In this paper we propose a set of novel regression models for readability scoring in Bengali language, making use of several lexical, surface-level, syntactic and semantic features. We perform 5-fold and leave-one-out cross-validation on a human-annotated gold standard dataset of 30 passages, written by four eminent Bengali litterateurs. On this dataset, our best model achieves a mean squared error (MSE) of 57%, which is better than state-of-the-art results (73% MSE). We further perform feature analysis to identify potentially useful features in learning a regression model for Bengali readability. Ablation studies indicate the importance of compound characters (Juktakkhor ) in readability assessment. version:1
arxiv-1607-02763 | How to Allocate Resources For Features Acquisition? | http://arxiv.org/abs/1607.02763 | id:1607.02763 author:Oran Richman, Shie Mannor category:cs.AI cs.LG stat.ML  published:2016-07-10 summary:We study classification problems where features are corrupted by noise and where the magnitude of the noise in each feature is influenced by the resources allocated to its acquisition. This is the case, for example, when multiple sensors share a common resource (power, bandwidth, attention, etc.). We develop a method for computing the optimal resource allocation for a variety of scenarios and derive theoretical bounds concerning the benefit that may arise by non-uniform allocation. We further demonstrate the effectiveness of the developed method in simulations. version:1
arxiv-1607-07751 | Machine Learning in Falls Prediction; A cognition-based predictor of falls for the acute neurological in-patient population | http://arxiv.org/abs/1607.07751 | id:1607.07751 author:Bilal A. Mateen, Matthias Bussas, Catherine Doogan, Denise Waller, Alessia Saverino, Franz J Király, E Diane Playford category:cs.CY cs.LG  published:2016-07-05 summary:Background Information: Falls are associated with high direct and indirect costs, and significant morbidity and mortality for patients. Pathological falls are usually a result of a compromised motor system, and/or cognition. Very little research has been conducted on predicting falls based on this premise. Aims: To demonstrate that cognitive and motor tests can be used to create a robust predictive tool for falls. Methods: Three tests of attention and executive function (Stroop, Trail Making, and Semantic Fluency), a measure of physical function (Walk-12), a series of questions (concerning recent falls, surgery and physical function) and demographic information were collected from a cohort of 323 patients at a tertiary neurological center. The principal outcome was a fall during the in-patient stay (n = 54). Data-driven, predictive modelling was employed to identify the statistical modelling strategies which are most accurate in predicting falls, and which yield the most parsimonious models of clinical relevance. Results: The Trail test was identified as the best predictor of falls. Moreover, addition of any others variables, to the results of the Trail test did not improve the prediction (Wilcoxon signed-rank p < .001). The best statistical strategy for predicting falls was the random forest (Wilcoxon signed-rank p < .001), based solely on results of the Trail test. Tuning of the model results in the following optimized values: 68% (+- 7.7) sensitivity, 90% (+- 2.3) specificity, with a positive predictive value of 60%, when the relevant data is available. Conclusion: Predictive modelling has identified a simple yet powerful machine learning prediction strategy based on a single clinical test, the Trail test. Predictive evaluation shows this strategy to be robust, suggesting predictive modelling and machine learning as the standard for future predictive tools. version:1
arxiv-1607-07804 | Error-Resilient Machine Learning in Near Threshold Voltage via Classifier Ensemble | http://arxiv.org/abs/1607.07804 | id:1607.07804 author:Sai Zhang, Naresh Shanbhag category:cs.LG  published:2016-07-03 summary:In this paper, we present the design of error-resilient machine learning architectures by employing a distributed machine learning framework referred to as classifier ensemble (CE). CE combines several simple classifiers to obtain a strong one. In contrast, centralized machine learning employs a single complex block. We compare the random forest (RF) and the support vector machine (SVM), which are representative techniques from the CE and centralized frameworks, respectively. Employing the dataset from UCI machine learning repository and architectural-level error models in a commercial 45 nm CMOS process, it is demonstrated that RF-based architectures are significantly more robust than SVM architectures in presence of timing errors due to process variations in near-threshold voltage (NTV) regions (0.3 V - 0.7 V). In particular, the RF architecture exhibits a detection accuracy (P_{det}) that varies by 3.2% while maintaining a median P_{det} > 0.9 at a gate level delay variation of 28.9% . In comparison, SVM exhibits a P_{det} that varies by 16.8%. Additionally, we propose an error weighted voting technique that incorporates the timing error statistics of the NTV circuit fabric to further enhance robustness. Simulation results confirm that the error weighted voting achieves a P_{det} that varies by only 1.4%, which is 12X lower compared to SVM. version:1
arxiv-1607-06032 | A Topological Lowpass Filter for Quasiperiodic Signals | http://arxiv.org/abs/1607.06032 | id:1607.06032 author:Michael Robinson category:cs.CV math.DS math.NA math.OC 37C05  94A12  60G35  published:2016-06-28 summary:This article presents a two-stage topological algorithm for recovering an estimate of a quasiperiodic function from a set of noisy measurements. The first stage of the algorithm is a topological phase estimator, which detects the quasiperiodic structure of the function without placing additional restrictions on the function. By respecting this phase estimate, the algorithm avoids creating distortion even when it uses a large number of samples for the estimate of the function. version:1
