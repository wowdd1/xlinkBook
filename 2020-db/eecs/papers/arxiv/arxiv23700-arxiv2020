arxiv-1612-02490 | Bridging Medical Data Inference to Achilles Tendon Rupture Rehabilitation | http://arxiv.org/abs/1612.02490 | id:1612.02490 author:An Qu, Cheng Zhang, Paul Ackermann, Hedvig Kjellström category:cs.LG stat.AP  published:2016-12-07 summary:Imputing incomplete medical tests and predicting patient outcomes are crucial for guiding the decision making for therapy, such as after an Achilles Tendon Rupture (ATR). We formulate the problem of data imputation and prediction for ATR relevant medical measurements into a recommender system framework. By applying MatchBox, which is a collaborative filtering approach, on a real dataset collected from 374 ATR patients, we aim at offering personalized medical data imputation and prediction. In this work, we show the feasibility of this approach and discuss potential research directions by conducting initial qualitative evaluations. version:1
arxiv-1612-02487 | Interactive Elicitation of Knowledge on Feature Relevance Improves Predictions in Small Data Sets | http://arxiv.org/abs/1612.02487 | id:1612.02487 author:Luana Micallef, Iiris Sundin, Pekka Marttinen, Muhammad Ammad-ud-din, Tomi Peltola, Marta Soare, Giulio Jacucci, Samuel Kaski category:cs.AI cs.LG stat.ML  published:2016-12-07 summary:Providing accurate predictions is challenging for machine learning algorithms when the number of features is larger than the number of samples in the data. Prior knowledge can improve machine learning models by indicating relevant variables and parameter values. Yet, this prior knowledge is often tacit and only available from domain experts. We present a novel approach that uses interactive visualization to elicit the tacit prior knowledge and uses it to improve the accuracy of prediction models. The main component of our approach is a user model that models the domain expert's knowledge of the relevance of different features for a prediction task. In particular, based on the expert's earlier input, the user model guides the selection of the features on which to elicit user's knowledge next. The results of a controlled user study show that the user model significantly improves prior knowledge elicitation and prediction accuracy, when predicting the relative citation counts of scientific documents in a specific domain. version:1
arxiv-1612-02482 | Improving the Performance of Neural Machine Translation Involving Morphologically Rich Languages | http://arxiv.org/abs/1612.02482 | id:1612.02482 author:Krupakar Hans, R S Milton category:cs.CL cs.LG cs.NE  published:2016-12-07 summary:The advent of the attention mechanism in neural machine translation models has improved the performance of machine translation systems by enabling selective lookup into the source sentence. In this paper, the efficiencies of translation using bidirectional encoder attention decoder models were studied with respect to translation involving morphologically rich languages. The English - Tamil language pair was selected for this analysis. First, the use of Word2Vec embedding for both the English and Tamil words improved the translation results by 0.73 BLEU points over the baseline RNNSearch model with 4.84 BLEU score. The use of morphological segmentation before word vectorization to split the morphologically rich Tamil words into their respective morphemes before the translation, caused a reduction in the target vocabulary size by a factor of 8. Also, this model (RNNMorph) improved the performance of neural machine translation by 7.05 BLEU points over the RNNSearch model used over the same corpus. Since the BLEU evaluation of the RNNMorph model might be unreliable due to an increase in the number of matching tokens per sentence, the performances of the translations were also compared by means of human evaluation metrics of adequacy, fluency and relative ranking. Further, the use of morphological segmentation also improved the efficacy of the attention mechanism. version:1
arxiv-1612-02460 | Demographical Priors for Health Conditions Diagnosis Using Medicare Data | http://arxiv.org/abs/1612.02460 | id:1612.02460 author:Fahad Alhasoun, May Alhazzani, Marta C. González category:stat.AP stat.ML  published:2016-12-07 summary:This paper presents an example of how demographical characteristics of patients influence their susceptibility to certain medical conditions. In this paper, we investigate the association of health conditions to age of patients in a heterogeneous population. We show that besides the symptoms a patients is having, the age has the potential of aiding the diagnostic process in hospitals. Working with Electronic Health Records (EHR), we show that medical conditions group into clusters that share distinctive population age densities. We use Electronic Health Records from Brazil for a period of 15 months from March of 2013 to July of 2014. The number of patients in the data is 1.7 million patients and the number of records is 47 million records. The findings has the potential of helping in a setting where an automated system undergoes the task of predicting the condition of a patient given their symptoms and demographical information. version:1
arxiv-1612-01922 | Tag Prediction at Flickr: a View from the Darkroom | http://arxiv.org/abs/1612.01922 | id:1612.01922 author:Pierre Garrigues, Sachin Farfade, Hamid Izadinia, Kofi Boakye, Yannis Kalantidis category:cs.CV  published:2016-12-06 summary:Automated photo tagging has established itself as one of the most compelling applications of deep learning. While deep convolutional neural networks have repeatedly demonstrated top performance on standard datasets for classification, there are a number of often overlooked but important considerations when deploying this technology in a real-world scenario. In this paper, we present our efforts in developing a large-scale photo-tagging system for Flickr photo search. We discuss topics including how to select the tags that matter most to our users, develop lightweight, high-performance models for tag prediction, and leverage the power of large amounts of noisy data for training. Our results demonstrate that, for real-world datasets, training exclusively with noisy data yields performance nearly on par with the standard paradigm of first pre-training on clean data and then fine-tuning. We advocate for the approach of harnessing user-generated data in large-scale systems. version:2
arxiv-1612-02401 | DeMoN: Depth and Motion Network for Learning Monocular Stereo | http://arxiv.org/abs/1612.02401 | id:1612.02401 author:Benjamin Ummenhofer, Huizhong Zhou, Jonas Uhrig, Nikolaus Mayer, Eddy Ilg, Alexey Dosovitskiy, Thomas Brox category:cs.CV  published:2016-12-07 summary:In this paper we formulate structure from motion as a learning problem. We train a convolutional network end-to-end to compute depth and camera motion from successive, unconstrained image pairs. The architecture is composed of multiple stacked encoder-decoder networks, the core part being an iterative network that is able to improve its own predictions. The network estimates not only depth and motion, but additionally surface normals, optical flow between the images and confidence of the matching. A crucial component of the approach is a training loss based on spatial relative differences. Compared to traditional two-frame structure from motion methods, results are more accurate and more robust. In contrast to the popular depth-from-single-image networks, DeMoN learns the concept of matching and, thus, better generalizes to structures not seen during training. version:1
arxiv-1612-02374 | Automatic Detection of ADHD and ASD from Expressive Behaviour in RGBD Data | http://arxiv.org/abs/1612.02374 | id:1612.02374 author:Shashank Jaiswal, Michel Valstar, Alinda Gillott, David Daley category:cs.CV  published:2016-12-07 summary:Attention Deficit Hyperactivity Disorder (ADHD) and Autism Spectrum Disorder (ASD) are neurodevelopmental conditions which impact on a significant number of children and adults. Currently, the diagnosis of such disorders is done by experts who employ standard questionnaires and look for certain behavioural markers through manual observation. Such methods for their diagnosis are not only subjective, difficult to repeat, and costly but also extremely time consuming. In this work, we present a novel methodology to aid diagnostic predictions about the presence/absence of ADHD and ASD by automatic visual analysis of a person's behaviour. To do so, we conduct the questionnaires in a computer-mediated way while recording participants with modern RGBD (Colour+Depth) sensors. In contrast to previous automatic approaches which have focussed only detecting certain behavioural markers, our approach provides a fully automatic end-to-end system for directly predicting ADHD and ASD in adults. Using state of the art facial expression analysis based on Dynamic Deep Learning and 3D analysis of behaviour, we attain classification rates of 96% for Controls vs Condition (ADHD/ASD) group and 94% for Comorbid (ADHD+ASD) vs ASD only group. We show that our system is a potentially useful time saving contribution to the diagnostic field of ADHD and ASD. version:1
arxiv-1612-02372 | Differential Angular Imaging for Material Recognition | http://arxiv.org/abs/1612.02372 | id:1612.02372 author:Jia Xue, Hang Zhang, Kristin Dana, Ko Nishino category:cs.CV  published:2016-12-07 summary:Material recognition for real-world outdoor surfaces has become increasingly important for computer vision to support its operation "in the wild." Computational surface modeling that underlies material recognition has transitioned from reflectance modeling using in-lab controlled radiometric measurements to image-based representations based on internet-mined images of materials captured in the scene. We propose to take a middle-ground approach for material recognition that takes advantage of both rich radiometric cues and flexible image capture. We realize this by developing a framework for differential angular imaging, where small angular variations in image capture provide an enhanced appearance representation and significant recognition improvement. We build a large-scale material database, Ground Terrain in Outdoor Scenes (GTOS) database, geared towards real use for autonomous agents. The database consists of over 30,000 images covering 40 classes of outdoor ground terrain under varying weather and lighting conditions. We develop a novel approach for material recognition called a Differential Angular Imaging Network (DAIN) to fully leverage this large dataset. With this novel network architecture, we extract characteristics of materials encoded in the angular and spatial gradients of their appearance. Our results show that DAIN achieves recognition performance that surpasses single view or coarsely quantized multiview images. These results demonstrate the effectiveness of differential angular imaging as a means for flexible, in-place material recognition. version:1
arxiv-1612-02350 | An Information-theoretic Approach to Machine-oriented Music Summarization | http://arxiv.org/abs/1612.02350 | id:1612.02350 author:Francisco Raposo, David Martins de Matos, Ricardo Ribeiro category:cs.IR cs.LG cs.SD H.5.5  published:2016-12-07 summary:Applying generic media-agnostic summarization to music allows for higher efficiency in automatic processing, storage, and communication of datasets while also alleviating copyright issues. This process has already been proven useful in the context of music genre classification. In this paper, we generalize conclusions from previous work by evaluating generic the impact of summarization in music from a probabilistic perspective and agnostic relative to certain tasks. We estimate Gaussian distributions for original and summarized songs and compute their relative entropy to measure how much information is lost in the summarization process. Based on this observation, we further propose a simple yet expressive summarization method that objectively outperforms previous methods and is better suited to avoid copyright issues. We present results suggesting that relative entropy is a good predictor of summarization performance in the context of tasks relying on a bag-of-features assumption. version:1
arxiv-1612-02336 | Neural Turing Machines: Convergence of Copy Tasks | http://arxiv.org/abs/1612.02336 | id:1612.02336 author:Janez Aleš category:cs.NE  published:2016-12-07 summary:The architecture of neural Turing machines is differentiable end to end and is trainable with gradient descent methods. Due to their large unfolded depth Neural Turing Machines are hard to train and because of their linear access of complete memory they do not scale. Other architectures have been studied to overcome these difficulties. In this report we focus on improving the quality of prediction of the original linear memory architecture on copy and repeat copy tasks. Copy task predictions on sequences of length six times larger than those the neural Turing machine was trained on prove to be highly accurate and so do predictions of repeat copy tasks for sequences with twice the repetition number and twice the sequence length neural Turing machine was trained on. version:1
arxiv-1612-02335 | Pano2Vid: Automatic Cinematography for Watching 360$^{\circ}$ Videos | http://arxiv.org/abs/1612.02335 | id:1612.02335 author:Yu-Chuan Su, Dinesh Jayaraman, Kristen Grauman category:cs.CV  published:2016-12-07 summary:We introduce the novel task of Pano2Vid $-$ automatic cinematography in panoramic 360$^{\circ}$ videos. Given a 360$^{\circ}$ video, the goal is to direct an imaginary camera to virtually capture natural-looking normal field-of-view (NFOV) video. By selecting "where to look" within the panorama at each time step, Pano2Vid aims to free both the videographer and the end viewer from the task of determining what to watch. Towards this goal, we first compile a dataset of 360$^{\circ}$ videos downloaded from the web, together with human-edited NFOV camera trajectories to facilitate evaluation. Next, we propose AutoCam, a data-driven approach to solve the Pano2Vid task. AutoCam leverages NFOV web video to discriminatively identify space-time "glimpses" of interest at each time instant, and then uses dynamic programming to select optimal human-like camera trajectories. Through experimental evaluation on multiple newly defined Pano2Vid performance measures against several baselines, we show that our method successfully produces informative videos that could conceivably have been captured by human videographers. version:1
arxiv-1612-02310 | Extend natural neighbor: a novel classification method with self-adaptive neighborhood parameters in different stages | http://arxiv.org/abs/1612.02310 | id:1612.02310 author:Ji Feng, Qingsheng Zhu, Jinlong Huang, Lijun Yang category:cs.AI cs.LG  published:2016-12-07 summary:Various kinds of k-nearest neighbor (KNN) based classification methods are the bases of many well-established and high-performance pattern-recognition techniques, but both of them are vulnerable to their parameter choice. Essentially, the challenge is to detect the neighborhood of various data sets, while utterly ignorant of the data characteristic. This article introduces a new supervised classification method: the extend natural neighbor (ENaN) method, and shows that it provides a better classification result without choosing the neighborhood parameter artificially. Unlike the original KNN based method which needs a prior k, the ENaNE method predicts different k in different stages. Therefore, the ENaNE method is able to learn more from flexible neighbor information both in training stage and testing stage, and provide a better classification result. version:1
arxiv-1612-02297 | Spatially Adaptive Computation Time for Residual Networks | http://arxiv.org/abs/1612.02297 | id:1612.02297 author:Michael Figurnov, Maxwell D. Collins, Yukun Zhu, Li Zhang, Jonathan Huang, Dmitry Vetrov, Ruslan Salakhutdinov category:cs.CV cs.LG  published:2016-12-07 summary:This paper proposes a deep learning architecture based on Residual Network that dynamically adjusts the number of executed layers for the regions of the image. This architecture is end-to-end trainable, deterministic and problem-agnostic. It is therefore applicable without any modifications to a wide range of computer vision problems such as image classification, object detection and image segmentation. We present experimental results showing that this model improves the computational efficiency of Residual Networks on the challenging ImageNet classification and COCO object detection datasets. Additionally, we evaluate the computation time maps on the visual saliency dataset cat2000 and find that they correlate surprisingly well with human eye fixation positions. version:1
arxiv-1612-02295 | Large-Margin Softmax Loss for Convolutional Neural Networks | http://arxiv.org/abs/1612.02295 | id:1612.02295 author:Weiyang Liu, Yandong Wen, Zhiding Yu, Meng Yang category:stat.ML cs.LG  published:2016-12-07 summary:Cross-entropy loss together with softmax is arguably one of the most common used supervision components in convolutional neural networks (CNNs). Despite its simplicity, popularity and excellent performance, the component does not explicitly encourage discriminative learning of features. In this paper, we propose a generalized large-margin softmax (L-Softmax) loss which explicitly encourages intra-class compactness and inter-class separability between learned features. Moreover, L-Softmax not only can adjust the desired margin but also can avoid overfitting. We also show that the L-Softmax loss can be optimized by typical stochastic gradient descent. Extensive experiments on four benchmark datasets demonstrate that the deeply-learned features with L-softmax loss become more discriminative, hence significantly boosting the performance on a variety of visual classification and verification tasks. version:1
arxiv-1612-00125 | A Novel Artificial Fish Swarm Algorithm for Pattern Recognition with Convex Optimization | http://arxiv.org/abs/1612.00125 | id:1612.00125 author:Lei Shi, Rui Guo, Yuchen Ma category:cs.CV  published:2016-12-01 summary:Image pattern recognition is an important area in digital image processing. An efficient pattern recognition algorithm should be able to provide correct recognition at a reduced computational time. Off late amongst the machine learning pattern recognition algorithms, Artificial fish swarm algorithm is one of the swarm intelligence optimization algorithms that works based on population and stochastic search. In order to achieve acceptable result, there are many parameters needs to be adjusted in AFSA. Among these parameters, visual and step are very significant in view of the fact that artificial fish basically move based on these parameters. In standard AFSA, these two parameters remain constant until the algorithm termination. Large values of these parameters increase the capability of algorithm in global search, while small values improve the local search ability of the algorithm. In this paper, we empirically study the performance of the AFSA and different approaches to balance between local and global exploration have been tested based on the adaptive modification of visual and step during algorithm execution. The proposed approaches have been evaluated based on the four well-known benchmark functions. Experimental results show considerable positive impact on the performance of AFSA. A Convex optimization has been integrated into the proposed work to have an ideal segmentation of the input image which is a MR brain image. version:2
arxiv-1612-02251 | Multitask learning for semantic sequence prediction under varying data conditions | http://arxiv.org/abs/1612.02251 | id:1612.02251 author:Héctor Martínez Alonso, Barbara Plank category:cs.CL  published:2016-12-07 summary:Multitask learning has been applied successfully to a range of tasks, mostly morphosyntactic. However, little is known on when MTL works and whether there are data characteristics that help to determine the success of MTL. In this paper we evaluate a range of semantic sequence labeling tasks in a MTL setup. We examine different auxiliary task configurations, amongst which a novel setup, and correlate their impact to data-dependent conditions. Our results show that MTL is not always effective, because significant improvements are obtained only for 1 out of 5 tasks. When successful, auxiliary tasks with compact and more uniform label distributions are preferable. version:1
arxiv-1612-02233 | A simple and efficient SNN and its performance & robustness evaluation method to enable hardware implementation | http://arxiv.org/abs/1612.02233 | id:1612.02233 author:Anmol Biswas, Sidharth Prasad, Sandip Lashkare, Udayan Ganguly category:cs.NE  published:2016-12-07 summary:Spiking Neural Networks (SNN) are more closely related to brain-like computation and inspire hardware implementation. This is enabled by small networks that give high performance on standard classification problems. In literature, typical SNNs are deep and complex in terms of network structure, weight update rules and learning algorithms. This makes it difficult to translate them into hardware. In this paper, we first develop a simple 2-layered network in software which compares with the state of the art on four different standard data-sets within SNNs and has improved efficiency. For example, it uses lower number of neurons (3 x), synapses (3.5 x) and epochs for training (30 x) for the Fisher Iris classification problem. The efficient network is based on effective population coding and synapse-neuron co-design. Second, we develop a computationally efficient (15000 x) and accurate (correlation of 0.98) method to evaluate the performance of the network without standard recognition tests. Third, we show that the method produces a robustness metric that can be used to evaluate noise tolerance. version:1
arxiv-1612-02223 | Exploring the potential of combining time of flight and thermal infrared cameras for person detection | http://arxiv.org/abs/1612.02223 | id:1612.02223 author:Wim Abbeloos, Toon Goedemé category:cs.CV  published:2016-12-07 summary:Combining new, low-cost thermal infrared and time-of-flight range sensors provides new opportunities. In this position paper we explore the possibilities of combining these sensors and using their fused data for person detection. The proposed calibration approach for this sensor combination differs from the traditional stereo camera calibration in two fundamental ways. A first distinction is that the spectral sensitivity of the two sensors differs significantly. In fact, there is no sensitivity range overlap at all. A second distinction is that their resolution is typically very low, which requires special attention. We assume a situation in which the sensors' relative position is known, but their orientation is unknown. In addition, some of the typical measurement errors are discussed, and methods to compensate for them are proposed. We discuss how the fused data could allow increased accuracy and robustness without the need for complex algorithms requiring large amounts of computational power and training data. version:1
arxiv-1612-02222 | A Communication-Efficient Parallel Method for Group-Lasso | http://arxiv.org/abs/1612.02222 | id:1612.02222 author:Binghong Chen, Jun Zhu category:cs.LG stat.ML  published:2016-12-07 summary:Group-Lasso (gLasso) identifies important explanatory factors in predicting the response variable by considering the grouping structure over input variables. However, most existing algorithms for gLasso are not scalable to deal with large-scale datasets, which are becoming a norm in many applications. In this paper, we present a divide-and-conquer based parallel algorithm (DC-gLasso) to scale up gLasso in the tasks of regression with grouping structures. DC-gLasso only needs two iterations to collect and aggregate the local estimates on subsets of the data, and is provably correct to recover the true model under certain conditions. We further extend it to deal with overlappings between groups. Empirical results on a wide range of synthetic and real-world datasets show that DC-gLasso can significantly improve the time efficiency without sacrificing regression accuracy. version:1
arxiv-1612-02219 | Process Monitoring of Extrusion Based 3D Printing via Laser Scanning | http://arxiv.org/abs/1612.02219 | id:1612.02219 author:Matthias Faes, Wim Abbeloos, Frederik Vogeler, Hans Valkenaers, Kurt Coppens, Toon Goedemé, Eleonora Ferraris category:cs.CV  published:2016-12-07 summary:Extrusion based 3D Printing (E3DP) is an Additive Manufacturing (AM) technique that extrudes thermoplastic polymer in order to build up components using a layerwise approach. Hereby, AM typically requires long production times in comparison to mass production processes such as Injection Molding. Failures during the AM process are often only noticed after build completion and frequently lead to part rejection because of dimensional inaccuracy or lack of mechanical performance, resulting in an important loss of time and material. A solution to improve the accuracy and robustness of a manufacturing technology is the integration of sensors to monitor and control process state-variables online. In this way, errors can be rapidly detected and possibly compensated at an early stage. To achieve this, we integrated a modular 2D laser triangulation scanner into an E3DP machine and analyzed feedback signals. A 2D laser triangulation scanner was selected here owing to the very compact size, achievable accuracy and the possibility of capturing geometrical 3D data. Thus, our implemented system is able to provide both quantitative and qualitative information. Also, in this work, first steps towards the development of a quality control loop for E3DP processes are presented and opportunities are discussed. version:1
arxiv-1612-02218 | Embedded Line Scan Image Sensors: The Low Cost Alternative for High Speed Imaging | http://arxiv.org/abs/1612.02218 | id:1612.02218 author:Stef Van Wolputte, Wim Abbeloos, Stijn Helsen, Abdellatif Bey-Temsamani, Toon Goedemé category:cs.CV  published:2016-12-07 summary:In this paper we propose a low-cost high-speed imaging line scan system. We replace an expensive industrial line scan camera and illumination with a custom-built set-up of cheap off-the-shelf components, yielding a measurement system with comparative quality while costing about 20 times less. We use a low-cost linear (1D) image sensor, cheap optics including a LED-based or LASER-based lighting and an embedded platform to process the images. A step-by-step method to design such a custom high speed imaging system and select proper components is proposed. Simulations allowing to predict the final image quality to be obtained by the set-up has been developed. Finally, we applied our method in a lab, closely representing the real-life cases. Our results shows that our simulations are very accurate and that our low-cost line scan set-up acquired image quality compared to the high-end commercial vision system, for a fraction of the price. version:1
arxiv-1612-01756 | Video Ladder Networks | http://arxiv.org/abs/1612.01756 | id:1612.01756 author:Francesco Cricri, Xingyang Ni, Mikko Honkala, Emre Aksu, Moncef Gabbouj category:cs.LG cs.CV stat.ML  published:2016-12-06 summary:We present the Video Ladder Network (VLN) for video prediction. VLN is a neural encoder-decoder model augmented by both recurrent and feedforward lateral connections at all layers. The model achieves competitive results on the Moving MNIST dataset while having very simple structure and providing fast inference. version:2
arxiv-1612-02203 | A Functional Regression approach to Facial Landmark Tracking | http://arxiv.org/abs/1612.02203 | id:1612.02203 author:Enrique Sánchez-Lozano, Georgios Tzimiropoulos, Brais Martinez, Fernando De la Torre, Michel Valstar category:cs.CV  published:2016-12-07 summary:Linear regression is a fundamental building block in many face detection and tracking algorithms, typically used to predict shape displacements from image features through a linear mapping. This paper presents a Functional Regression solution to the least squares problem, which we coin Continuous Regression, resulting in the first real-time incremental face tracker. Contrary to prior work in Functional Regression, in which B-splines or Fourier series were used, we propose to approximate the input space by its first-order Taylor expansion, yielding a closed-form solution for the continuous domain of displacements. We then extend the continuous least squares problem to correlated variables, and demonstrate the generalisation of our approach. We incorporate Continuous Regression into the cascaded regression framework, and show its computational benefits for both training and testing. We then present a fast approach for incremental learning within Cascaded Continuous Regression, coined iCCR, and show that its complexity allows real-time face tracking, being 20 times faster than the state of the art. To the best of our knowledge, this is the first incremental face tracker that is shown to operate in real-time. We show that iCCR achieves state-of-the-art performance in the 300-VW dataset, the most recent, large-scale benchmark for face tracking. version:1
arxiv-1612-02192 | Fast Adaptation in Generative Models with Generative Matching Networks | http://arxiv.org/abs/1612.02192 | id:1612.02192 author:Sergey Bartunov, Dmitry P. Vetrov category:stat.ML cs.LG I.2.6; I.5  published:2016-12-07 summary:Despite recent advances, the remaining bottlenecks in deep generative models are necessity of extensive training and difficulties with generalization from small number of training examples. Both problems may be addressed by conditional generative models that are trained to adapt the generative distribution to additional input data. So far this idea was explored only under certain limitations such as restricting the input data to be a single object or multiple objects representing the same concept. In this work we develop a new class of deep generative model called generative matching networks which is inspired by the recently proposed matching networks for one-shot learning in discriminative tasks and the ideas from meta-learning. By conditioning on the additional input dataset, generative matching networks may instantly learn new concepts that were not available during the training but conform to a similar generative process, without explicit limitations on the number of additional input objects or the number of concepts they represent. Our experiments on the Omniglot dataset demonstrate that generative matching networks can significantly improve predictive performance on the fly as more additional data is available to the model and also adapt the latent space which is beneficial in the context of feature extraction. version:1
arxiv-1612-02190 | Template Matching with Deformable Diversity Similarity | http://arxiv.org/abs/1612.02190 | id:1612.02190 author:Itamar Talmi, Roey Mechrez, Lihi Zelnik-Manor category:cs.CV  published:2016-12-07 summary:We propose a novel measure for template matching named Deformable Diversity Similarity -- based on the diversity of feature matches between a target image window and the template. We rely on both local appearance and geometric information that jointly lead to a powerful approach for matching. Our key contribution is a similarity measure, that is robust to complex deformations, significant background clutter, and occlusions. Empirical evaluation on the most up-to-date benchmark shows that our method outperforms the current state-of-the-art in its detection accuracy while improving computational complexity. version:1
arxiv-1612-02189 | Tensor-Based Fusion of EEG and FMRI to Understand Neurological Changes in Schizophrenia | http://arxiv.org/abs/1612.02189 | id:1612.02189 author:Evrim Acar, Yuri Levin-Schwartz, Vince D. Calhoun, Tülay Adalı category:stat.AP q-bio.NC stat.ML  published:2016-12-07 summary:Neuroimaging modalities such as functional magnetic resonance imaging (fMRI) and electroencephalography (EEG) provide information about neurological functions in complementary spatiotemporal resolutions; therefore, fusion of these modalities is expected to provide better understanding of brain activity. In this paper, we jointly analyze fMRI and multi-channel EEG signals collected during an auditory oddball task with the goal of capturing brain activity patterns that differ between patients with schizophrenia and healthy controls. Rather than selecting a single electrode or matricizing the third-order tensor that can be naturally used to represent multi-channel EEG signals, we preserve the multi-way structure of EEG data and use a coupled matrix and tensor factorization (CMTF) model to jointly analyze fMRI and EEG signals. Our analysis reveals that (i) joint analysis of EEG and fMRI using a CMTF model can capture meaningful temporal and spatial signatures of patterns that behave differently in patients and controls, and (ii) these differences and the interpretability of the associated components increase by including multiple electrodes from frontal, motor and parietal areas, but not necessarily by including all electrodes in the analysis. version:1
arxiv-1612-02184 | Saliency Driven Image Manipulation | http://arxiv.org/abs/1612.02184 | id:1612.02184 author:Roey Mechrez, Eli Shechtman, Lihi Zelnik-Manor category:cs.CV  published:2016-12-07 summary:Have you ever taken a picture only to find out that an unimportant background object ended up being overly salient? Or one of those team sports photos where your favorite player blends with the rest? Wouldn't it be nice if you could tweak these pictures just a little bit so that the distractor would be attenuated and your favorite player will stand-out among her peers? Manipulating images in order to control the saliency of objects is the goal of this paper. We propose an approach that considers the internal color and saliency properties of the image. It changes the saliency map via an optimization framework that relies on patch-based manipulation using only patches from within the same image to achieve realistic looking results. Applications include object enhancement, distractors attenuation and background decluttering. Comparing our method to previous ones shows significant improvement, both in the achieved saliency manipulation and in the realistic appearance of the resulting images. version:1
arxiv-1612-02183 | Fusion of Range and Thermal Images for Person Detection | http://arxiv.org/abs/1612.02183 | id:1612.02183 author:Wim Abbeloos, Toon Goedemé category:cs.CV  published:2016-12-07 summary:Detecting people in images is a challenging problem. Differences in pose, clothing and lighting, along with other factors, cause a lot of variation in their appearance. To overcome these issues, we propose a system based on fused range and thermal infrared images. These measurements show considerably less variation and provide more meaningful information. We provide a brief introduction to the sensor technology used and propose a calibration method. Several data fusion algorithms are compared and their performance is assessed on a simulated data set. The results of initial experiments on real data are analyzed and the measurement errors and the challenges they present are discussed. The resulting fused data are used to efficiently detect people in a fixed camera set-up. The system is extended to include person tracking. version:1
arxiv-1612-02179 | Model-based Adversarial Imitation Learning | http://arxiv.org/abs/1612.02179 | id:1612.02179 author:Nir Baram, Oron Anschel, Shie Mannor category:stat.ML cs.LG  published:2016-12-07 summary:Generative adversarial learning is a popular new approach to training generative models which has been proven successful for other related problems as well. The general idea is to maintain an oracle $D$ that discriminates between the expert's data distribution and that of the generative model $G$. The generative model is trained to capture the expert's distribution by maximizing the probability of $D$ misclassifying the data it generates. Overall, the system is \emph{differentiable} end-to-end and is trained using basic backpropagation. This type of learning was successfully applied to the problem of policy imitation in a model-free setup. However, a model-free approach does not allow the system to be differentiable, which requires the use of high-variance gradient estimations. In this paper we introduce the Model based Adversarial Imitation Learning (MAIL) algorithm. A model-based approach for the problem of adversarial imitation learning. We show how to use a forward model to make the system fully differentiable, which enables us to train policies using the (stochastic) gradient of $D$. Moreover, our approach requires relatively few environment interactions, and fewer hyper-parameters to tune. We test our method on the MuJoCo physics simulator and report initial results that surpass the current state-of-the-art. version:1
arxiv-1612-02177 | Deep Multi-scale Convolutional Neural Network for Dynamic Scene Deblurring | http://arxiv.org/abs/1612.02177 | id:1612.02177 author:Seungjun Nah, Tae Hyun Kim, Kyoung Mu Lee category:cs.CV  published:2016-12-07 summary:Non-uniform blind deblurring for general dynamic scenes is a challenging computer vision problem since blurs are caused by camera shake, scene depth as well as multiple object motions. To remove these complicated motion blurs, conventional energy optimization based methods rely on simple assumptions such that blur kernel is partially uniform or locally linear. Moreover, recent machine learning based methods also depend on synthetic blur datasets generated under these assumptions. This makes conventional deblurring methods fail to remove blurs where blur kernel is difficult to approximate or parameterize (e.g. object motion boundaries). In this work, we propose a multi-scale convolutional neural network that restores blurred images caused by various sources in an end-to-end manner. Furthermore, we present multi-scale loss function that mimics conventional coarse-to-fine approaches. Moreover, we propose a new large scale dataset that provides pairs of realistic blurry image and the corresponding ground truth sharp image that are obtained by a high-speed camera. With the proposed model trained on this dataset, we demonstrate empirically that our method achieves the state-of-the-art performance in dynamic scene deblurring not only qualitatively, but also quantitatively. version:1
arxiv-1612-02166 | Semi-Supervised Learning And Graph Cuts For Consensus Based Medical Image Segmentation | http://arxiv.org/abs/1612.02166 | id:1612.02166 author:Dwarikanath Mahapatra category:cs.CV  published:2016-12-07 summary:Medical image segmentation requires consensus ground truth segmentations to be derived from multiple expert annotations. A novel approach is proposed that obtains consensus segmentations from experts using graph cuts (GC) and semi supervised learning (SSL). Popular approaches use iterative Expectation Maximization (EM) to estimate the final annotation and quantify annotator's performance. Such techniques pose the risk of getting trapped in local minima. We propose a self consistency (SC) score to quantify annotator consistency using low level image features. SSL is used to predict missing annotations by considering global features and local image consistency. The SC score also serves as the penalty cost in a second order Markov random field (MRF) cost function optimized using graph cuts to derive the final consensus label. Graph cut obtains a global maximum without an iterative procedure. Experimental results on synthetic images, real data of Crohn's disease patients and retinal images show our final segmentation to be accurate and more consistent than competing methods. version:1
arxiv-1612-02161 | Measuring the non-asymptotic convergence of sequential Monte Carlo samplers using probabilistic programming | http://arxiv.org/abs/1612.02161 | id:1612.02161 author:Marco F. Cusumano-Towner, Vikash K. Mansinghka category:cs.AI cs.LG stat.ML  published:2016-12-07 summary:A key limitation of sampling algorithms for approximate inference is that it is difficult to quantify their approximation error. Widely used sampling schemes, such as sequential importance sampling with resampling and Metropolis-Hastings, produce output samples drawn from a distribution that may be far from the target posterior distribution. This paper shows how to upper-bound the symmetric KL divergence between the output distribution of a broad class of sequential Monte Carlo (SMC) samplers and their target posterior distributions, subject to assumptions about the accuracy of a separate gold-standard sampler. The proposed method applies to samplers that combine multiple particles, multinomial resampling, and rejuvenation kernels. The experiments show the technique being used to estimate bounds on the divergence of SMC samplers for posterior inference in a Bayesian linear regression model and a Dirichlet process mixture model. version:1
arxiv-1612-02155 | Re-identification of Humans in Crowds using Personal, Social and Environmental Constraints | http://arxiv.org/abs/1612.02155 | id:1612.02155 author:Shayan Modiri Assari, Haroon Idrees, Mubarak Shah category:cs.CV  published:2016-12-07 summary:This paper addresses the problem of human re-identification across non-overlapping cameras in crowds.Re-identification in crowded scenes is a challenging problem due to large number of people and frequent occlusions, coupled with changes in their appearance due to different properties and exposure of cameras. To solve this problem, we model multiple Personal, Social and Environmental (PSE) constraints on human motion across cameras. The personal constraints include appearance and preferred speed of each individual assumed to be similar across the non-overlapping cameras. The social influences (constraints) are quadratic in nature, i.e. occur between pairs of individuals, and modeled through grouping and collision avoidance. Finally, the environmental constraints capture the transition probabilities between gates (entrances / exits) in different cameras, defined as multi-modal distributions of transition time and destination between all pairs of gates. We incorporate these constraints into an energy minimization framework for solving human re-identification. Assigning $1-1$ correspondence while modeling PSE constraints is NP-hard. We present a stochastic local search algorithm to restrict the search space of hypotheses, and obtain $1-1$ solution in the presence of linear and quadratic PSE constraints. Moreover, we present an alternate optimization using Frank-Wolfe algorithm that solves the convex approximation of the objective function with linear relaxation on binary variables, and yields an order of magnitude speed up over stochastic local search with minor drop in performance. We evaluate our approach using Cumulative Matching Curves as well $1-1$ assignment on several thousand frames of Grand Central, PRID and DukeMTMC datasets, and obtain significantly better results compared to existing re-identification methods. version:1
arxiv-1612-01834 | Revisiting Winner Take All (WTA) Hashing for Sparse Datasets | http://arxiv.org/abs/1612.01834 | id:1612.01834 author:Beidi Chen, Anshumali Shrivastava category:cs.CV cs.IR  published:2016-12-06 summary:WTA (Winner Take All) hashing has been successfully applied in many large scale vision applications. This hashing scheme was tailored to take advantage of the comparative reasoning (or order based information), which showed significant accuracy improvements. In this paper, we identify a subtle issue with WTA, which grows with the sparsity of the datasets. This issue limits the discriminative power of WTA. We then propose a solution for this problem based on the idea of Densification which provably fixes the issue. Our experiments show that Densified WTA Hashing outperforms Vanilla WTA both in image classification and retrieval tasks consistently and significantly. version:2
arxiv-1612-02141 | A Deep 3D Convolutional Neural Network Based Design for Manufacturability Framework | http://arxiv.org/abs/1612.02141 | id:1612.02141 author:Aditya Balu, Kin Gwn Lore, Gavin Young, Adarsh Krishnamurthy, Soumik Sarkar category:cs.CV  published:2016-12-07 summary:Deep 3D Convolutional Neural Networks (3D-CNN) are traditionally used for object recognition, video data analytics and human gesture recognition. In this paper, we present a novel application of 3D-CNNs in understanding difficult-to-manufacture features from computer-aided design (CAD) models to develop a decision support tool for cyber-enabled manufacturing. Traditionally, design for manufacturability (DFM) rules are hand-crafted and used to accelerate the engineering product design cycle by integrating manufacturability analysis during the design stage. Such a practice relies on the experience and training of the designer to create a complex component that is manufacturable. However, even after careful design, the inclusion of certain features might cause the part to be non-manufacturable. In this paper, we develop a framework using Deep 3D-CNNs to learn salient features from a CAD model of a mechanical part and determine if the part can be manufactured or not. CAD models of different manufacturable and non-manufacturable parts are generated using a solid modeling kernel and then converted into 3D voxel data using a fast GPU-accelerated voxelization algorithm. The voxel data is used to train a 3D-CNN model for manufacturability classification. Feature space and filter visualization is also performed to understand the learning capability in the context of manufacturability features. We demonstrate that the proposed 3D-CNN based DFM framework is able to learn the DFM rules for non-manufacturable features without a human prior. The framework can be extended to identify a large variety of difficult-to-manufacture features at multiple spatial scales leading to a real-time decision support system for DFM. version:1
arxiv-1612-02136 | Mode Regularized Generative Adversarial Networks | http://arxiv.org/abs/1612.02136 | id:1612.02136 author:Tong Che, Yanran Li, Athul Paul Jacob, Yoshua Bengio, Wenjie Li category:cs.LG cs.NE  published:2016-12-07 summary:Although Generative Adversarial Networks achieve state-of-the-art results on a variety of generative tasks, they are regarded as highly unstable and prone to miss modes. We argue that these bad behaviors of GANs are due to the very particular functional shape of the trained discriminators in high dimensional spaces, which can easily make training stuck or push probability mass in the wrong direction, towards that of higher concentration than that of the data generating distribution. We introduce several ways of regularizing the objective, which can dramatically stabilize the training of GAN models. We also show that our regularizers can help the fair distribution of probability mass across the modes of the data generating distribution, during the early phases of training and thus providing a unified solution to the missing modes problem. version:1
arxiv-1612-02130 | Predictive Business Process Monitoring with LSTM Neural Networks | http://arxiv.org/abs/1612.02130 | id:1612.02130 author:Niek Tax, Ilya Verenich, Marcello La Rosa, Marlon Dumas category:stat.AP cs.DB cs.LG stat.ML  published:2016-12-07 summary:Predictive business process monitoring methods exploit logs of completed cases of a process in order to make predictions about running cases thereof. Existing methods in this space are tailor-made for specific prediction tasks. Moreover, their relative accuracy is highly sensitive to the dataset at hand, thus requiring users to engage in trial-and-error and tuning when applying them in a specific setting. This paper investigates Long Short-Term Memory (LSTM) neural networks as an approach to build consistently accurate models for a wide range of predictive process monitoring tasks. First, we show that LSTMs outperform existing techniques to predict the next event of a running case and its timestamp. Next, we show how to use models for predicting the next task in order to predict the full continuation of a running case. Finally, we apply the same approach to predict the remaining time, and show that this approach outperforms existing tailor-made methods. version:1
arxiv-1612-01600 | Distributed Gaussian Learning over Time-varying Directed Graphs | http://arxiv.org/abs/1612.01600 | id:1612.01600 author:Angelia Nedić, Alex Olshevsky, César A. Uribe category:math.OC cs.LG cs.MA cs.SY stat.ML  published:2016-12-06 summary:We present a distributed (non-Bayesian) learning algorithm for the problem of parameter estimation with Gaussian noise. The algorithm is expressed as explicit updates on the parameters of the Gaussian beliefs (i.e. means and precision). We show a convergence rate of $O(1/k)$ with the constant term depending on the number of agents and the topology of the network. Moreover, we show almost sure convergence to the optimal solution of the estimation problem for the general case of time-varying directed graphs. version:2
arxiv-1612-02103 | Richer Convolutional Features for Edge Detection | http://arxiv.org/abs/1612.02103 | id:1612.02103 author:Yun Liu, Ming-Ming Cheng, Xiaowei Hu, Kai Wang, Xiang Bai category:cs.CV  published:2016-12-07 summary:In this paper, we propose an accurate edge detector using richer convolutional features (RCF). Since objects in nature images have various scales and aspect ratios, the automatically learned rich hierarchical representations by CNNs are very critical and effective to detect edges and object boundaries. And the convolutional features gradually become coarser with receptive fields increasing. Based on these observations, our proposed network architecture makes full use of multiscale and multi-level information to perform the image-to-image edge prediction by combining all of the useful convolutional features into a holistic framework. It is the first attempt to adopt such rich convolutional features in computer vision tasks. Using VGG16 network, we achieve \sArt results on several available datasets. When evaluating on the well-known BSDS500 benchmark, we achieve ODS F-measure of \textbf{.811} while retaining a fast speed (\textbf{8} FPS). Besides, our fast version of RCF achieves ODS F-measure of \textbf{.806} with \textbf{30} FPS. version:1
arxiv-1612-02101 | Mining Pixels: Weakly Supervised Semantic Segmentation Using Image Labels | http://arxiv.org/abs/1612.02101 | id:1612.02101 author:Qinbin Hou, Puneet Kumar Dokania, Daniela Massiceti, Yunchao Wei, Ming-Ming Cheng, Philip Torr category:cs.CV  published:2016-12-07 summary:We consider the task of learning a classifier for semantic segmentation using weak supervision, in this case, image labels specifying the objects within the image. Our method uses deep convolutional neural networks (CNNs) and adopts an Expectation-Maximization (EM) based approach maintaining the uncertainty on pixel labels. We focus on the following three crucial aspects of the EM based approach: (i) initialization; (ii) latent posterior estimation (E step) and (iii) the parameter update (M step). We show that {\em saliency} and {\em attention} maps provide good cues to learn an initialization model and allows us to skip the bad local minimum to which EM methods are otherwise traditionally prone. In order to update the parameters, we propose minimizing the combination of the standard \textit{softmax} loss and the KL divergence between the true latent posterior and the likelihood given by the CNN. We argue that this combination is more robust to wrong predictions made by the expectation step of the EM method. We support this argument with empirical and visual results. We additionally incorporate an approximate intersection-over-union (IoU) term into the loss function for better parameter estimation. Extensive experiments and discussions show that: (i) our method is very simple and intuitive; (ii) requires only image-level labels; and (iii) consistently outperforms other weakly supervised state-of-the-art methods with a very high margin on the PASCAL VOC 2012 dataset. version:1
arxiv-1612-02099 | Statistical and Computational Guarantees of Lloyd's Algorithm and its Variants | http://arxiv.org/abs/1612.02099 | id:1612.02099 author:Yu Lu, Harrison H. Zhou category:math.ST cs.LG stat.ML stat.TH  published:2016-12-07 summary:Clustering is a fundamental problem in statistics and machine learning. Lloyd's algorithm, proposed in 1957, is still possibly the most widely used clustering algorithm in practice due to its simplicity and empirical performance. However, there has been little theoretical investigation on the statistical and computational guarantees of Lloyd's algorithm. This paper is an attempt to bridge this gap between practice and theory. We investigate the performance of Lloyd's algorithm on clustering sub-Gaussian mixtures. Under an appropriate initialization for labels or centers, we show that Lloyd's algorithm converges to an exponentially small clustering error after an order of $\log n$ iterations, where $n$ is the sample size. The error rate is shown to be minimax optimal. For the two-mixture case, we only require the initializer to be slightly better than random guess. In addition, we extend the Lloyd's algorithm and its analysis to community detection and crowdsourcing, two problems that have received a lot of attention recently in statistics and machine learning. Two variants of Lloyd's algorithm are proposed respectively for community detection and crowdsourcing. On the theoretical side, we provide statistical and computational guarantees of the two algorithms, and the results improve upon some previous signal-to-noise ratio conditions in literature for both problems. Experimental results on simulated and real data sets demonstrate competitive performance of our algorithms to the state-of-the-art methods. version:1
arxiv-1612-02095 | Semi-Supervised Detection of Extreme Weather Events in Large Climate Datasets | http://arxiv.org/abs/1612.02095 | id:1612.02095 author:Evan Racah, Christopher Beckham, Tegan Maharaj, Prabhat, Christopher Pal category:cs.CV stat.ML  published:2016-12-07 summary:The detection and identification of extreme weather events in large scale climate simulations is an important problem for risk management, informing governmental policy decisions and advancing our basic understanding of the climate system. Recent work has shown that fully supervised convolutional neural networks (CNNs) can yield acceptable accuracy for classifying well-known types of extreme weather events when large amounts of labeled data are available. However, there are many different types of spatially localized climate patterns of interest (including hurricanes, extra-tropical cyclones, weather fronts, blocking events, etc.) found in simulation data for which labeled data is not available at large scale for all simulations of interest. We present a multichannel spatiotemporal encoder-decoder CNN architecture for semi-supervised bounding box prediction and exploratory data analysis. This architecture is designed to fully model multi-channel simulation data, temporal dynamics and unlabelled data within a reconstruction and prediction framework so as to improve the detection of a wide range of extreme weather events. Our architecture can be viewed as a 3D convolutional autoencoder with an additional modified one-pass bounding box regression loss. We demonstrate that our approach is able to leverage temporal information and unlabelled data to improve localization of extreme weather events. Further, we explore the representations learned by our model in order to better understand this important data, and facilitate further work in understanding and mitigating the effects of climate change. version:1
arxiv-1612-00603 | A Point Set Generation Network for 3D Object Reconstruction from a Single Image | http://arxiv.org/abs/1612.00603 | id:1612.00603 author:Haoqiang Fan, Hao Su, Leonidas Guibas category:cs.CV  published:2016-12-02 summary:Generation of 3D data by deep neural network has been attracting increasing attention in the research community. The majority of extant works resort to regular representations such as volumetric grids or collection of images; however, these representations obscure the natural invariance of 3D shapes under geometric transformations and also suffer from a number of other issues. In this paper we address the problem of 3D reconstruction from a single image, generating a straight-forward form of output -- point cloud coordinates. Along with this problem arises a unique and interesting issue, that the groundtruth shape for an input image may be ambiguous. Driven by this unorthodox output form and the inherent ambiguity in groundtruth, we design architecture, loss function and learning paradigm that are novel and effective. Our final solution is a conditional shape sampler, capable of predicting multiple plausible 3D point clouds from an input image. In experiments not only can our system outperform state-of-the-art methods on single image based 3d reconstruction benchmarks; but it also shows a strong performance for 3d shape completion and promising ability in making multiple plausible predictions. version:2
arxiv-1612-01991 | Diverse Sampling for Self-Supervised Learning of Semantic Segmentation | http://arxiv.org/abs/1612.01991 | id:1612.01991 author:Mohammadreza Mostajabi, Nicholas Kolkin, Gregory Shakhnarovich category:cs.CV  published:2016-12-06 summary:We propose an approach for learning category-level semantic segmentation purely from image-level classification tags indicating presence of categories. It exploits localization cues that emerge from training classification-tasked convolutional networks, to drive a "self-supervision" process that automatically labels a sparse, diverse training set of points likely to belong to classes of interest. Our approach has almost no hyperparameters, is modular, and allows for very fast training of segmentation in less than 3 minutes. It obtains competitive results on the VOC 2012 segmentation benchmark. More, significantly the modularity and fast training of our framework allows new classes to efficiently added for inference. version:1
arxiv-1612-01988 | Local Group Invariant Representations via Orbit Embeddings | http://arxiv.org/abs/1612.01988 | id:1612.01988 author:Anant Raj, Abhishek Kumar, Youssef Mroueh, P. Thomas Fletcher, Bernhard Sch\"olkopf category:cs.LG stat.ML  published:2016-12-06 summary:Invariance to nuisance transformations is one of the desirable properties of effective representations. We consider transformations that form a \emph{group} and propose an approach based on kernel methods to derive local group invariant representations. Locality is achieved by defining a suitable probability distribution over the group which in turn induces distributions in the input feature space. We learn a decision function over these distributions by appealing to the powerful framework of kernel methods and generate local invariant random feature maps via kernel approximations. We show uniform convergence bounds for kernel approximation and provide excess risk bounds for learning with these features. We evaluate our method on three real datasets, including Rotated MNIST and CIFAR-10, and observe that it outperforms competing kernel based approaches. The proposed method also outperforms deep CNN on Rotated-MNIST and performs comparably to the recently proposed group-equivariant CNN. version:1
arxiv-1612-01981 | Core Sampling Framework for Pixel Classification | http://arxiv.org/abs/1612.01981 | id:1612.01981 author:Manohar Karki, Robert DiBiano, Saikat Basu, Supratik Mukhopadhyay category:cs.CV cs.LG  published:2016-12-06 summary:The intermediate map responses of a Convolutional Neural Network (CNN) contain information about an image that can be used to extract contextual knowledge about it. In this paper, we present a core sampling framework that is able to use these activation maps from several layers as features to another neural network using transfer learning to provide an understanding of an input image. Our framework creates a representation that combines features from the test data and the contextual knowledge gained from the responses of a pretrained network, processes it and feeds it to a separate Deep Belief Network. We use this representation to extract more information from an image at the pixel level, hence gaining understanding of the whole image. We experimentally demonstrate the usefulness of our framework using a pretrained VGG-16 model to perform segmentation on the BAERI dataset of Synthetic Aperture Radar(SAR) imagery and the CAMVID dataset. version:1
arxiv-1612-01958 | Learning Diverse Image Colorization | http://arxiv.org/abs/1612.01958 | id:1612.01958 author:Aditya Deshpande, Jiajun Lu, Mao-Chuang Yeh, David Forsyth category:cs.CV  published:2016-12-06 summary:Colorization is an ambiguous problem, with multiple viable colorizations for a single grey-level image. However, previous methods only produce the single most probable colorization. Our goal is to model the diversity intrinsic to the problem of colorization and produce multiple colorizations that display long-scale spatial co-ordination. We learn a low dimensional embedding of color fields using a variational autoencoder (VAE). We construct loss terms for the VAE decoder that avoid blurry outputs and take into account the uneven distribution of pixel colors. Finally, we develop a conditional model for the multi-modal distribution between grey-level image and the color field embeddings. Samples from this conditional model result in diverse colorization. We demonstrate that our method obtains better diverse colorizations than a standard conditional variational autoencoder model. version:1
arxiv-1612-01943 | Segmental Convolutional Neural Networks for Detection of Cardiac Abnormality With Noisy Heart Sound Recordings | http://arxiv.org/abs/1612.01943 | id:1612.01943 author:Yuhao Zhang, Sandeep Ayyar, Long-Huei Chen, Ethan J. Li category:cs.SD cs.LG stat.ML  published:2016-12-06 summary:Heart diseases constitute a global health burden, and the problem is exacerbated by the error-prone nature of listening to and interpreting heart sounds. This motivates the development of automated classification to screen for abnormal heart sounds. Existing machine learning-based systems achieve accurate classification of heart sound recordings but rely on expert features that have not been thoroughly evaluated on noisy recordings. Here we propose a segmental convolutional neural network architecture that achieves automatic feature learning from noisy heart sound recordings. Our experiments show that our best model, trained on noisy recording segments acquired with an existing hidden semi-markov model-based approach, attains a classification accuracy of 87.5% on the 2016 PhysioNet/CinC Challenge dataset, compared to the 84.6% accuracy of the state-of-the-art statistical classifier trained and evaluated on the same dataset. Our results indicate the potential of using neural network-based methods to increase the accuracy of automated classification of heart sound recordings for improved screening of heart diseases. version:1
arxiv-1612-01942 | Semi-Supervised Learning with the Deep Rendering Mixture Model | http://arxiv.org/abs/1612.01942 | id:1612.01942 author:Tan Nguyen, Wanjia Liu, Ethan Perez, Richard G. Baraniuk, Ankit B. Patel category:stat.ML cs.LG cs.NE  published:2016-12-06 summary:Semi-supervised learning algorithms reduce the high cost of acquiring labeled training data by using both labeled and unlabeled data during learning. Deep Convolutional Networks (DCNs) have achieved great success in supervised tasks and as such have been widely employed in the semi-supervised learning. In this paper we leverage the recently developed Deep Rendering Mixture Model (DRMM), a probabilistic generative model that models latent nuisance variation, and whose inference algorithm yields DCNs. We develop an EM algorithm for the DRMM to learn from both labeled and unlabeled data. Guided by the theory of the DRMM, we introduce a novel non-negativity constraint and a variational inference term. We report state-of-the-art performance on MNIST and SVHN and competitive results on CIFAR10. We also probe deeper into how a DRMM trained in a semi-supervised setting represents latent nuisance variation using synthetically rendered images. Taken together, our work provides a unified framework for supervised, unsupervised, and semi-supervised learning. version:1
arxiv-1612-01939 | Correlation Alignment for Unsupervised Domain Adaptation | http://arxiv.org/abs/1612.01939 | id:1612.01939 author:Baochen Sun, Jiashi Feng, Kate Saenko category:cs.CV cs.AI cs.NE  published:2016-12-06 summary:In this chapter, we present CORrelation ALignment (CORAL), a simple yet effective method for unsupervised domain adaptation. CORAL minimizes domain shift by aligning the second-order statistics of source and target distributions, without requiring any target labels. In contrast to subspace manifold methods, it aligns the original feature distributions of the source and target domains, rather than the bases of lower-dimensional subspaces. It is also much simpler than other distribution matching methods. CORAL performs remarkably well in extensive evaluations on standard benchmark datasets. We first describe a solution that applies a linear transformation to source features to align them with target features before classifier training. For linear classifiers, we propose to equivalently apply CORAL to the classifier weights, leading to added efficiency when the number of classifiers is small but the number and dimensionality of target examples are very high. The resulting CORAL Linear Discriminant Analysis (CORAL-LDA) outperforms LDA by a large margin on standard domain adaptation benchmarks. Finally, we extend CORAL to learn a nonlinear transformation that aligns correlations of layer activations in deep neural networks (DNNs). The resulting Deep CORAL approach works seamlessly with DNNs and achieves state-of-the-art performance on standard benchmark datasets. Our code is available at:~\url{https://github.com/VisionLearningGroup/CORAL} version:1
arxiv-1612-01936 | A Probabilistic Framework for Deep Learning | http://arxiv.org/abs/1612.01936 | id:1612.01936 author:Ankit B. Patel, Tan Nguyen, Richard G. Baraniuk category:stat.ML cs.LG cs.NE  published:2016-12-06 summary:We develop a probabilistic framework for deep learning based on the Deep Rendering Mixture Model (DRMM), a new generative probabilistic model that explicitly capture variations in data due to latent task nuisance variables. We demonstrate that max-sum inference in the DRMM yields an algorithm that exactly reproduces the operations in deep convolutional neural networks (DCNs), providing a first principles derivation. Our framework provides new insights into the successes and shortcomings of DCNs as well as a principled route to their improvement. DRMM training via the Expectation-Maximization (EM) algorithm is a powerful alternative to DCN back-propagation, and initial training results are promising. Classification based on the DRMM and other variants outperforms DCNs in supervised digit classification, training 2-3x faster while achieving similar accuracy. Moreover, the DRMM is applicable to semi-supervised and unsupervised learning tasks, achieving results that are state-of-the-art in several categories on the MNIST benchmark and comparable to state of the art on the CIFAR10 benchmark. version:1
arxiv-1612-01930 | Nonparametric Bayesian label prediction on a graph | http://arxiv.org/abs/1612.01930 | id:1612.01930 author:Jarno Hartog, Harry van Zanten category:stat.CO stat.ML  published:2016-12-06 summary:This article describes an implementation of a nonparametric Bayesian approach to solving binary classification problems on graphs. We consider a hierarchical Bayesian approach with a randomly scaled Gaussian prior. We have two simulated data examples and two examples using real data to illustrate our proposed methods. version:1
arxiv-1612-01925 | FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks | http://arxiv.org/abs/1612.01925 | id:1612.01925 author:Eddy Ilg, Nikolaus Mayer, Tonmoy Saikia, Margret Keuper, Alexey Dosovitskiy, Thomas Brox category:cs.CV  published:2016-12-06 summary:The FlowNet demonstrated that optical flow estimation can be cast as a learning problem. However, the state of the art with regard to the quality of the flow has still been defined by traditional methods. Particularly on small displacements and real-world data, FlowNet cannot compete with variational methods. In this paper, we advance the concept of end-to-end learning of optical flow and make it work really well. The large improvements in quality and speed are caused by three major contributions: first, we focus on the training data and show that the schedule of presenting data during training is very important. Second, we develop a stacked architecture that includes warping of the second image with intermediate optical flow. Third, we elaborate on small displacements by introducing a sub-network specializing on small motions. FlowNet 2.0 is only marginally slower than the original FlowNet but decreases the estimation error by more than 50%. It performs on par with state-of-the-art methods, while running at interactive frame rates. Moreover, we present faster variants that allow optical flow computation at up to 140fps with accuracy matching the original FlowNet. version:1
arxiv-1612-01892 | Cross-Lingual Predicate Mapping Between Linked Data Ontologies | http://arxiv.org/abs/1612.01892 | id:1612.01892 author:Gautam Singh, Saemi Jang, Mun Y. Yi category:cs.AI cs.CL  published:2016-12-06 summary:Ontologies in different natural languages often differ in quality in terms of richness of schema or richness of internal links. This difference is markedly visible when comparing a rich English language ontology with a non-English language counterpart. Discovering alignment between them is a useful endeavor as it serves as a starting point in bridging the disparity. In particular, our work is motivated by the absence of inter-language links for predicates in the localised versions of DBpedia. In this paper, we propose and demonstrate an ad-hoc system to find possible owl:equivalentProperty links between predicates in ontologies of different natural languages. We seek to achieve this mapping by using pre-existing inter-language links of the resources connected by the given predicate. Thus, our methodology stresses on semantic similarity rather than lexical. Moreover, through an evaluation, we show that our system is capable of outperforming a baseline system that is similar to the one used in recent OAEI campaigns. version:1
arxiv-1612-01887 | Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning | http://arxiv.org/abs/1612.01887 | id:1612.01887 author:Jiasen Lu, Caiming Xiong, Devi Parikh, Richard Socher category:cs.CV cs.AI  published:2016-12-06 summary:Attention-based neural encoder-decoder frameworks have been widely adopted for image captioning. Most methods force visual attention to be active for every generated word. However, the decoder likely requires little to no visual information from the image to predict non-visual words such as "the" and "of". Other words that may seem visual can often be predicted reliably just from the language model e.g., "sign" after "behind a red stop" or "phone" following "talking on a cell". In this paper, we propose a novel adaptive attention model with a visual sentinel. At each time step, our model decides whether to attend to the image (and if so, to which regions) or to the visual sentinel. The model decides whether to attend to the image and where, in order to extract meaningful information for sequential word generation. We test our method on the COCO image captioning 2015 challenge dataset and Flickr30K. Our approach sets the new state-of-the-art by a significant margin. version:1
arxiv-1612-01871 | Recommender Engine for Continuous Time Quantum Monte Carlo Methods | http://arxiv.org/abs/1612.01871 | id:1612.01871 author:Li Huang, Yi-feng Yang, Lei Wang category:cond-mat.str-el physics.comp-ph stat.ML  published:2016-12-06 summary:Recommender systems play an essential role in the modern business world. They recommend favorable items like books, movies, and search queries to users based on their past preferences. Applying similar ideas and techniques to Monte Carlo simulations of physical systems boosts their efficiency without sacrificing accuracy. Exploiting the quantum to classical mapping inherent in the continuous-time quantum Monte Carlo methods, we construct a classical molecular gas model to reproduce the quantum distributions. We then utilize powerful molecular simulation techniques to propose efficient quantum Monte Carlo updates. The recommender engine approach provides a general way to speed up the quantum impurity solvers. version:1
arxiv-1612-01859 | Combinatorial semi-bandit with known covariance | http://arxiv.org/abs/1612.01859 | id:1612.01859 author:Rémy Degenne, Vianney Perchet category:cs.LG  published:2016-12-06 summary:The combinatorial stochastic semi-bandit problem is an extension of the classical multi-armed bandit problem in which an algorithm pulls more than one arm at each stage and the rewards of all pulled arms are revealed. One difference with the single arm variant is that the dependency structure of the arms is crucial. Previous works on this setting either used a worst-case approach or imposed independence of the arms. We introduce a way to quantify the dependency structure of the problem and design an algorithm that adapts to it. The algorithm is based on linear regression and the analysis develops techniques from the linear bandit literature. By comparing its performance to a new lower bound, we prove that it is optimal, up to a poly-logarithmic factor in the number of pulled arms. version:1
arxiv-1612-01848 | Condensed Memory Networks for Clinical Diagnostic Inferencing | http://arxiv.org/abs/1612.01848 | id:1612.01848 author:Aaditya Prakash, Siyuan Zhao, Sadid A. Hasan, Vivek Datla, Kathy Lee, Ashequl Qadir, Joey Liu, Oladimeji Farri category:cs.CL  published:2016-12-06 summary:Diagnosis of a clinical condition is a challenging task, which often requires significant medical investigation. Previous work related to diagnostic inferencing problems mostly consider multivariate observational data (e.g. physiological signals, lab tests etc.). In contrast, we explore the problem using free-text medical notes recorded in an electronic health record (EHR). Complex tasks like these can benefit from structured knowledge bases, but those are not scalable. We instead exploit raw text from Wikipedia as a knowledge source. Memory networks have been demonstrated to be effective in tasks which require comprehension of free-form text. They use the final iteration of the learned representation to predict probable classes. We introduce condensed memory neural networks (C-MemNNs), a novel model with iterative condensation of memory representations that preserves the hierarchy of features in the memory. Experiments on the MIMIC-III dataset show that the proposed model outperforms other variants of memory networks to predict the most probable diagnoses given a complex clinical scenario. version:1
arxiv-1612-01810 | FLIC: Fast Linear Iterative Clustering with Active Search | http://arxiv.org/abs/1612.01810 | id:1612.01810 author:Jia-Xin Zhao, Ren Bo, Qibin Hou, Ming-Ming Cheng category:cs.CV  published:2016-12-06 summary:Benefiting from its high efficiency and simplicity, Simple Linear Iterative Clustering (SLIC) remains one of the most popular over-segmentation tools. However, due to explicit enforcement of spatial similarity for region continuity, the boundary adaptation of SLIC is sub-optimal. It also has drawbacks on convergence rate as a result of both the fixed search region and separately doing the assignment step and the update step. In this paper, we propose an alternative approach to fix the inherent limitations of SLIC. In our approach, each pixel actively searches its corresponding segment under the help of its neighboring pixels, which naturally enables region coherence without being harmful to boundary adaptation. We also jointly perform the assignment and update steps, allowing high convergence rate. Extensive evaluations on Berkeley segmentation benchmark verify that our method outperforms competitive methods under various evaluation metrics. It also has the lowest time cost among existing methods (approximately 30fps for a 481x321 image on a single CPU core). version:1
arxiv-1612-01501 | BrainFrame: A heterogeneous accelerator platform for neuron simulations | http://arxiv.org/abs/1612.01501 | id:1612.01501 author:Georgios Smaragdos, Georgios Chatzikonstantis, Rahul Kukreja, Harrys Sidiropoulos, Dimitrios Rodopoulos, Ioannis Sourdis, Zaid Al-Ars, Christoforos Kachris, Dimitrios Soudris, Chris I. De Zeeuw, Christos Strydis category:cs.NE cs.DC  published:2016-12-05 summary:Objective: The advent of High-Performance Computing (HPC) in recent years has led to its increasing use in brain study through computational models. The scale and complexity of such models are constantly increasing, leading to challenging computational requirements. Even though modern HPC platforms can often deal with such challenges, the vast diversity of the modeling field does not permit for a single acceleration (or homogeneous) platform to effectively address the complete array of modeling requirements. Approach: In this paper we propose and build BrainFrame, a heterogeneous acceleration platform, incorporating three distinct acceleration technologies, a Dataflow Engine, a Xeon Phi and a GP-GPU. The PyNN framework is also integrated into the platform. As a challenging proof of concept, we analyze the performance of BrainFrame on different instances of a state-of-the-art neuron model, modeling the Inferior- Olivary Nucleus using a biophysically-meaningful, extended Hodgkin-Huxley representation. The model instances take into account not only the neuronal- network dimensions but also different network-connectivity circumstances that can drastically change application workload characteristics. Main results: The synthetic approach of three HPC technologies demonstrated that BrainFrame is better able to cope with the modeling diversity encountered. Our performance analysis shows clearly that the model directly affect performance and all three technologies are required to cope with all the model use cases. version:2
arxiv-1612-01452 | ImageNet pre-trained models with batch normalization | http://arxiv.org/abs/1612.01452 | id:1612.01452 author:Marcel Simon, Erik Rodner, Joachim Denzler category:cs.CV  published:2016-12-05 summary:Convolutional neural networks (CNN) pre-trained on ImageNet are the backbone of most state-of-the-art approaches. In this paper, we present a new set of pre-trained models with popular state-of-the-art architectures for the Caffe framework. The first release includes Residual Networks (ResNets) with generation script as well as the batch-normalization-variants of AlexNet and VGG19. All models outperform previous models with the same architecture. The models and training code are available at http://www.inf-cv.uni-jena.de/Research/CNN+Models.html and https://github.com/cvjena/cnn-models version:2
arxiv-1612-00188 | Efficient Orthogonal Parametrisation of Recurrent Neural Networks Using Householder Reflections | http://arxiv.org/abs/1612.00188 | id:1612.00188 author:Zakaria Mhammedi, Andrew Hellicar, Ashfaqur Rahman, James Bailey category:cs.LG  published:2016-12-01 summary:Recurrent Neural Networks (RNNs) have been successfully used in many applications. However, the problem of learning long-term dependencies in sequences using these networks is still a major challenge. Recent methods have been suggested to solve this problem by constraining the transition matrix to be unitary during training, which ensures that its norm is exactly equal to one. These methods either have limited expressiveness or scale poorly with the size of the network when compared with the simple RNN case, especially in an online learning setting. Our contributions are as follows. We first show that constraining the transition matrix to be unitary is a special case of an orthogonal constraint. Therefore, it may not be necessary to work with complex valued matrices. Then we present a new parametrisation of the transition matrix which allows efficient training of an RNN while ensuring that the matrix is always orthogonal. Using our approach, one online gradient step can, in the worst case, be performed in time complexity $\mathcal{O}(T n^2)$, where $T$ and $n$ are the length of the input sequence and the size of the hidden layer respectively. This time complexity is the same as that of the simple RNN. Finally, we test our new parametrisation on problems with long-term dependencies. Our results suggest that the orthogonal constraint on the transition matrix has similar benefits to the unitary constraint. version:2
arxiv-1612-01746 | Factored Contextual Policy Search with Bayesian Optimization | http://arxiv.org/abs/1612.01746 | id:1612.01746 author:Peter Karkus, Andras Kupcsik, David Hsu, Wee Sun Lee category:cs.LG cs.AI cs.RO stat.ML  published:2016-12-06 summary:Scarce data is a major challenge to scaling robot learning to truly complex tasks, as we need to generalize locally learned policies over different "contexts". Bayesian optimization approaches to contextual policy search (CPS) offer data-efficient policy learning that generalize over a context space. We propose to improve data- efficiency by factoring typically considered contexts into two components: target- type contexts that correspond to a desired outcome of the learned behavior, e.g. target position for throwing a ball; and environment type contexts that correspond to some state of the environment, e.g. initial ball position or wind speed. Our key observation is that experience can be directly generalized over target-type contexts. Based on that we introduce Factored Contextual Policy Search with Bayesian Optimization for both passive and active learning settings. Preliminary results show faster policy generalization on a simulated toy problem. version:1
arxiv-1612-01744 | Listen and Translate: A Proof of Concept for End-to-End Speech-to-Text Translation | http://arxiv.org/abs/1612.01744 | id:1612.01744 author:Alexandre Berard, Olivier Pietquin, Christophe Servan, Laurent Besacier category:cs.CL  published:2016-12-06 summary:This paper proposes a first attempt to build an end-to-end speech-to-text translation system, which does not use source language transcription during learning or decoding. We propose a model for direct speech-to-text translation, which gives promising results on a small French-English synthetic corpus. Relaxing the need for source language transcription would drastically change the data collection methodology in speech translation, especially in under-resourced scenarios. For instance, in the former project DARPA TRANSTAC (speech translation from spoken Arabic dialects), a large effort was devoted to the collection of speech transcripts (and a prerequisite to obtain transcripts was often a detailed transcription guide for languages with little standardized spelling). Now, if end-to-end approaches for speech-to-text translation are successful, one might consider collecting data by asking bilingual speakers to directly utter speech in the source language from target language text utterances. Such an approach has the advantage to be applicable to any unwritten (source) language. version:1
arxiv-1612-01725 | Deep Stereo Matching with Dense CRF Priors | http://arxiv.org/abs/1612.01725 | id:1612.01725 author:Ron Slossberg, Aaron Wetzler, Ron Kimmel category:cs.CV  published:2016-12-06 summary:Stereo reconstruction from rectified images has recently been revisited within the context of deep learning. Using a deep Convolutional Neural Network to obtain patch-wise matching cost volumes has resulted in state of the art stereo reconstruction on classic datasets like Middlebury and Kitti. By introducing this cost into a classical stereo pipeline, the final results are improved dramatically over non-learning based cost models. However these pipelines typically include hand engineered post processing steps to effectively regularize and clean the result. Here, we show that it is possible to take a more holistic approach by training a fully end-to-end network which directly includes regularization in the form of a densely connected Conditional Random Field (CRF) that acts as a prior on inter-pixel interactions. We demonstrate that our approach on both synthetic and real world datasets outperforms an alternative end-to-end network and compares favorably to more hand engineered approaches. version:1
arxiv-1612-01717 | Statistical mechanics of unsupervised feature learning in a restricted Boltzmann machine with binary synapses | http://arxiv.org/abs/1612.01717 | id:1612.01717 author:Haiping Huang category:cs.LG cond-mat.dis-nn cond-mat.stat-mech cs.NE q-bio.NC  published:2016-12-06 summary:Revealing hidden features in unlabeled data is called unsupervised feature learning, which plays an important role in pretraining a deep neural network. Here we provide a statistical mechanics analysis of the unsupervised learning in a restricted Boltzmann machine with binary synapses. A message passing equation to infer the hidden feature is derived, and furthermore, variants of this equation are analyzed. A statistical analysis by replica theory describes the thermodynamic properties of the model. Our analysis confirms an entropy crisis preceding the non-convergence of the message passing equation, suggesting a discontinuous phase transition as a key characteristic of the restricted Boltzmann machine. Continuous phase transition is also confirmed depending on the embedded feature strength in the data. The mean-field result under the replica symmetric assumption agrees with that obtained by running message passing algorithms on single instances of finite sizes. Interestingly, in an approximate Hopfield model, the entropy crisis is absent, and a continuous phase transition is observed instead. We also develop an iterative equation to infer the hyper-parameter (temperature) hidden in the data, which in physics corresponds to iteratively imposing Nishimori condition. Our study provides insights towards understanding the thermodynamic properties of the restricted Boltzmann machine learning, and moreover important theoretical basis to build simplified deep networks. version:1
arxiv-1612-01697 | Deep Neural Networks for No-Reference and Full-Reference Image Quality Assessment | http://arxiv.org/abs/1612.01697 | id:1612.01697 author:Sebastian Bosse, Dominique Maniry, Klaus-Robert Müller, Thomas Wiegand, Wojciech Samek category:cs.CV  published:2016-12-06 summary:This paper presents a deep neural network-based approach to image quality assessment (IQA). The network can be trained end-to-end and comprises 10 convolutional layers and 5 pooling layers for feature extraction, and 2 fully connected layers for regression, which makes it significantly deeper than related IQA methods. An unique feature of the proposed architecture is that it can be used (with slight adaptations) in a no-reference (NR) as well as in a full-reference (FR) IQA setting. Our approach is purely data-driven and does not rely on hand-crafted features or other types of prior domain knowledge about the human visual system or image statistics. The network estimates perceived quality patchwise; the overall image quality is calculated as the average of these patchwise scores. In order to consider the locally non-uniform distribution of perceived quality in images, we introduce a spatial attention mechanism which performs a weighted aggregation of the patchwise scores. We evaluate the proposed approach on the LIVE, CISQ and TID2013 databases and show superior performance to state-of-the-art NR and FR IQA methods. Finally, cross-database evaluation shows a high ability to generalize between different datasets, indicating a high robustness of the learned features. version:1
arxiv-1612-01689 | Cluster-Wise Ratio Tests for Fast Camera Localization | http://arxiv.org/abs/1612.01689 | id:1612.01689 author:Raúl Díaz, Charless C. Fowlkes category:cs.CV  published:2016-12-06 summary:Feature point matching for camera localization suffers from scalability problems. Even when feature descriptors associated with 3D scene points are locally unique, as coverage grows, similar or repeated features become increasingly common. As a result, the standard distance ratio-test used to identify reliable image feature points is overly restrictive and rejects many good candidate matches. We propose a simple coarse-to-fine strategy that uses conservative approximations to robust local ratio-tests that can be computed efficiently using global approximate k-nearest neighbor search. We treat these forward matches as votes in camera pose space and use them to prioritize back-matching within candidate camera pose clusters, exploiting feature co-visibility captured by clustering the 3D model camera pose graph. This approach achieves state-of-the-art camera localization results on a variety of popular benchmarks, outperforming several methods that use more complicated data structures and that make more restrictive assumptions on camera pose. We also carry out diagnostic analyses on a difficult test dataset containing globally repetitive structure that suggest our approach successfully adapts to the challenges of large-scale image localization. version:1
arxiv-1612-01057 | Learning to Segment Object Proposals via Recursive Neural Networks | http://arxiv.org/abs/1612.01057 | id:1612.01057 author:Tianshui Chen, Liang Lin, Xian Wu, Xiaonan Luo category:cs.CV  published:2016-12-04 summary:To avoid the exhaustive search over locations and scales, current state-of-the-art object detection systems usually involve a crucial component generating a batch of candidate object proposals from images. In this paper, we present a simple yet effective approach for segmenting object proposals via a deep architecture of recursive neural networks (RNNs), which hierarchically groups regions for detecting object candidates over scales. Unlike traditional methods that mainly adopt fixed similarity measures for merging regions or finding object proposals, our approach adaptively learns the region merging similarity and the objectness measure during the process of hierarchical region grouping. Specifically, guided by a structured loss, the RNN model jointly optimizes the cross-region similarity metric with the region merging process as well as the objectness prediction. During inference of the object proposal generation, we introduce randomness into the greedy search to cope with the ambiguity of grouping regions. Extensive experiments on standard benchmarks, e.g., PASCAL VOC and ImageNet, suggest that our approach is capable of producing object proposals with high recall while well preserving the object boundaries and outperforms other existing methods in both accuracy and efficiency. version:2
arxiv-1612-01678 | Supervised topic models for clinical interpretability | http://arxiv.org/abs/1612.01678 | id:1612.01678 author:Michael C. Hughes, Huseyin Melih Elibol, Thomas McCoy, Roy Perlis, Finale Doshi-Velez category:stat.ML  published:2016-12-06 summary:Supervised topic models can help clinical researchers find interpretable cooccurence patterns in count data that are relevant for diagnostics. However, standard formulations of supervised Latent Dirichlet Allocation have two problems. First, when documents have many more words than labels, the influence of the labels will be negligible. Second, due to conditional independence assumptions in the graphical model the impact of supervised labels on the learned topic-word probabilities is often minimal, leading to poor predictions on heldout data. We investigate penalized optimization methods for training sLDA that produce interpretable topic-word parameters and useful heldout predictions, using recognition networks to speed-up inference. We report preliminary results on synthetic data and on predicting successful anti-depressant medication given a patient's diagnostic history. version:1
arxiv-1612-01669 | MarioQA: Answering Questions by Watching Gameplay Videos | http://arxiv.org/abs/1612.01669 | id:1612.01669 author:Jonghwan Mun, Paul Hongsuck Seo, Ilchae Jung, Bohyung Han category:cs.CV  published:2016-12-06 summary:We present a new benchmark dataset for video question answering (VideoQA) designed to evaluate algorithms' capability of spatio-temporal event understanding. Existing datasets either require very high-level reasoning from multi-modal information to find answers, or is mostly composed of the questions that can be answered by watching a single frame. Therefore, they are not suitable to evaluate models' real capacity and flexibility for VideoQA. To overcome such critical limitations, we focus on event-centric questions that require understanding temporal relation between multiple events in videos. An interesting idea in dataset construction process is that question-answer pairs are automatically generated from Super Mario video gameplays given a set of question templates. We also tackle VideoQA problem in the new dataset, referred to as MarioQA, by proposing spatio-temporal attention models based on deep neural networks. Our experiments show that the proposed deep neural network models with attention have meaningful performance improvement over several baselines. version:1
arxiv-1612-01663 | Efficient Non-oblivious Randomized Reduction for Risk Minimization with Improved Excess Risk Guarantee | http://arxiv.org/abs/1612.01663 | id:1612.01663 author:Yi Xu, Haiqin Yang, Lijun Zhang, Tianbao Yang category:cs.LG  published:2016-12-06 summary:In this paper, we address learning problems for high dimensional data. Previously, oblivious random projection based approaches that project high dimensional features onto a random subspace have been used in practice for tackling high-dimensionality challenge in machine learning. Recently, various non-oblivious randomized reduction methods have been developed and deployed for solving many numerical problems such as matrix product approximation, low-rank matrix approximation, etc. However, they are less explored for the machine learning tasks, e.g., classification. More seriously, the theoretical analysis of excess risk bounds for risk minimization, an important measure of generalization performance, has not been established for non-oblivious randomized reduction methods. It therefore remains an open problem what is the benefit of using them over previous oblivious random projection based approaches. To tackle these challenges, we propose an algorithmic framework for employing non-oblivious randomized reduction method for general empirical risk minimizing in machine learning tasks, where the original high-dimensional features are projected onto a random subspace that is derived from the data with a small matrix approximation error. We then derive the first excess risk bound for the proposed non-oblivious randomized reduction approach without requiring strong assumptions on the training data. The established excess risk bound exhibits that the proposed approach provides much better generalization performance and it also sheds more insights about different randomized reduction approaches. Finally, we conduct extensive experiments on both synthetic and real-world benchmark datasets, whose dimension scales to $O(10^7)$, to demonstrate the efficacy of our proposed approach. version:1
arxiv-1612-01657 | Binary Subspace Coding for Query-by-Image Video Retrieval | http://arxiv.org/abs/1612.01657 | id:1612.01657 author:Ruicong Xu, Yang Yang, Yadan Luo, Fumin Shen, Zi Huang, Heng Tao Shen category:cs.MM cs.CV  published:2016-12-06 summary:The query-by-image video retrieval (QBIVR) task has been attracting considerable research attention recently. However, most existing methods represent a video by either aggregating or projecting all its frames into a single datum point, which may easily cause severe information loss. In this paper, we propose an efficient QBIVR framework to enable an effective and efficient video search with image query. We first define a similarity-preserving distance metric between an image and its orthogonal projection in the subspace of the video, which can be equivalently transformed to a Maximum Inner Product Search (MIPS) problem. Besides, to boost the efficiency of solving the MIPS problem, we propose two asymmetric hashing schemes, which bridge the domain gap of images and videos. The first approach, termed Inner-product Binary Coding (IBC), preserves the inner relationships of images and videos in a common Hamming space. To further improve the retrieval efficiency, we devise a Bilinear Binary Coding (BBC) approach, which employs compact bilinear projections instead of a single large projection matrix. Extensive experiments have been conducted on four real-world video datasets to verify the effectiveness of our proposed approaches as compared to the state-of-the-arts. version:1
arxiv-1612-01655 | Fine-grained Recurrent Neural Networks for Automatic Prostate Segmentation in Ultrasound Images | http://arxiv.org/abs/1612.01655 | id:1612.01655 author:Xin Yang, Lequan Yu, Lingyun Wu, Yi Wang, Dong Ni, Jing Qin, Pheng-Ann Heng category:cs.CV  published:2016-12-06 summary:Boundary incompleteness raises great challenges to automatic prostate segmentation in ultrasound images. Shape prior can provide strong guidance in estimating the missing boundary, but traditional shape models often suffer from hand-crafted descriptors and local information loss in the fitting procedure. In this paper, we attempt to address those issues with a novel framework. The proposed framework can seamlessly integrate feature extraction and shape prior exploring, and estimate the complete boundary with a sequential manner. Our framework is composed of three key modules. Firstly, we serialize the static 2D prostate ultrasound images into dynamic sequences and then predict prostate shapes by sequentially exploring shape priors. Intuitively, we propose to learn the shape prior with the biologically plausible Recurrent Neural Networks (RNNs). This module is corroborated to be effective in dealing with the boundary incompleteness. Secondly, to alleviate the bias caused by different serialization manners, we propose a multi-view fusion strategy to merge shape predictions obtained from different perspectives. Thirdly, we further implant the RNN core into a multiscale Auto-Context scheme to successively refine the details of the shape prediction map. With extensive validation on challenging prostate ultrasound images, our framework bridges severe boundary incompleteness and achieves the best performance in prostate boundary delineation when compared with several advanced methods. Additionally, our approach is general and can be extended to other medical image segmentation tasks, where boundary incompleteness is one of the main challenges. version:1
arxiv-1612-01635 | Automatic Image Defect Diagnosis | http://arxiv.org/abs/1612.01635 | id:1612.01635 author:Ning Yu, Xiaohui Shen, Zhe Lin, Radomir Mech, Connelly Barnes category:cs.CV  published:2016-12-06 summary:Although problems relating to specific image correction have been explored intensively, the problem of simultaneous diagnosis for multiple photographic defects remains relatively untouched. Solutions to this problem attempt to predict the existence, severity, and locations of common defects. This paper proposes a first attempt at a solution to the general defect diagnosis problem based on our novel dataset. We formulate the defect diagnosis problem as a multi-task prediction problem and utilize multi-column deep neural networks (DNN) to approach the problem. We propose DNN models with holistic and multi-patch inputs and combine their predicted scores to integrate multi-scale information. During experiments, we validate the complementarity of both kinds of inputs. We also validate that our combined predictions have a more consistent ranking correlation with our ground truth than the average of individual users' judgments. Furthermore, we apply the fully convolutional version of our trained model to visualize defect severity heat maps, which can effectively identify defective regions of input images. We propose that our work will provide casual photographers with better experiences when using image editing software to improve image quality. Another promising avenue for future application involves the equipping of photo summarization systems with defect cues to focus more on defect-free photos. version:1
arxiv-1612-01277 | Cryptocurrency Portfolio Management with Deep Reinforcement Learning | http://arxiv.org/abs/1612.01277 | id:1612.01277 author:Zhengyao Jiang, Jinjun Liang category:cs.LG  published:2016-12-05 summary:We present a convolutional neural network with historic prices of a set of financial assets as its input, outputting portfolio weights of the set. The network is trained to achieve maximum accumulative return. A back-test trading experiment is conducted in a cryptocurrency market, achieving 10-fold returns in 1.8 month's periods, outperforming many traditional portfolio management algorithms and benchmarks. version:2
arxiv-1612-01627 | Sequential Match Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots | http://arxiv.org/abs/1612.01627 | id:1612.01627 author:Yu Wu, Wei Wu, Ming Zhou, Zhoujun Li category:cs.CL  published:2016-12-06 summary:We study response selection for multi-turn conversation in retrieval based chatbots. Existing works either ignores relationships among utterances, or misses important information in context when matching a response with a highly abstract context vector finally. We propose a new session based matching model to address both problems. The model first matches a response with each utterance on multiple granularities, and distills important matching information from each pair as a vector with convolution and pooling operations. The vectors are then accumulated in a chronological order through a recurrent neural network (RNN) which models the relationships among the utterances. The final matching score is calculated with the hidden states of the RNN. Empirical study on two public data sets shows that our model can significantly outperform the state-of-the-art methods for response selection in multi-turn conversation. version:1
arxiv-1612-01611 | Automatic Event Detection for Signal-based Surveillance | http://arxiv.org/abs/1612.01611 | id:1612.01611 author:Jingxin Xu, Clinton Fookes, Sridha Sridharan category:cs.CV  published:2016-12-06 summary:Signal-based Surveillance systems such as Closed Circuits Televisions (CCTV) have been widely installed in public places. Those systems are normally used to find the events with security interest, and play a significant role in public safety. Though such systems are still heavily reliant on human labour to monitor the captured information, there have been a number of automatic techniques proposed to analysing the data. This article provides an overview of automatic surveillance event detection techniques . Despite it's popularity in research, it is still too challenging a problem to be realised in a real world deployment. The challenges come from not only the detection techniques such as signal processing and machine learning, but also the experimental design with factors such as data collection, evaluation protocols, and ground-truth annotation. Finally, this article propose that multi-disciplinary research is the path towards a solution to this problem. version:1
arxiv-1612-01601 | Superpixels: An Evaluation of the State-of-the-Art | http://arxiv.org/abs/1612.01601 | id:1612.01601 author:David Stutz, Alexander Hermans, Bastian Leibe category:cs.CV  published:2016-12-06 summary:Superpixels group perceptually similar pixels to create visually meaningful entities while heavily reducing the number of primitives. As of these properties, superpixel algorithms have received much attention since their naming in 2003. By today, publicly available and well-understood superpixel algorithms have turned into standard tools in low-level vision. As such, and due to their quick adoption in a wide range of applications, appropriate benchmarks are crucial for algorithm selection and comparison. Until now, the rapidly growing number of algorithms as well as varying experimental setups hindered the development of a unifying benchmark. We present a comprehensive evaluation of 28 state-of-the-art superpixel algorithms utilizing a benchmark focussing on fair comparison and designed to provide new and relevant insights. To this end, we explicitly discuss parameter optimization and the importance of strictly enforcing connectivity. Furthermore, by extending well-known metrics, we are able to summarize algorithm performance independent of the number of generated superpixels, thereby overcoming a major limitation of available benchmarks. Furthermore, we discuss runtime, robustness against noise, blur and affine transformations, implementation details as well as aspects of visual quality. Finally, we present an overall ranking of superpixel algorithms which redefines the state-of-the-art and enables researchers to easily select appropriate algorithms and the corresponding implementations which themselves are made publicly available as part of our benchmark at davidstutz.de/projects/superpixel-benchmark/. version:1
arxiv-1612-01597 | Deterministic and Probabilistic Conditions for Finite Completability of Low Rank Tensor | http://arxiv.org/abs/1612.01597 | id:1612.01597 author:Morteza Ashraphijuo, Vaneet Aggarwal, Xiaodong Wang category:cs.NA cs.IT cs.LG math.IT  published:2016-12-06 summary:We investigate the fundamental conditions on the sampling pattern, i.e., locations of the sampled entries, for finite completability of a low-rank tensor given some components of its Tucker rank. In order to find the deterministic necessary and sufficient conditions, we propose an algebraic geometric analysis on the Tucker manifold, which allows us to incorporate multiple rank components in the proposed analysis in contrast with the conventional geometric approaches on the Grassmannian manifold. This analysis characterizes the algebraic independence of a set of polynomials defined based on the sampling pattern, which is closely related to finite completion. Probabilistic conditions are then studied and a lower bound on the sampling probability is given, which guarantees that the proposed deterministic conditions on the sampling patterns for finite completability hold with high probability. Furthermore, using the proposed geometric approach for finite completability, we propose a sufficient condition on the sampling pattern that ensures there exists exactly one completion for the sampled tensor. version:1
arxiv-1612-01594 | Object Classification with Joint Projection and Low-rank Dictionary Learning | http://arxiv.org/abs/1612.01594 | id:1612.01594 author:Homa Foroughi, Nilanjan Ray, Hong Zhang category:cs.CV  published:2016-12-05 summary:For an object classification system, the most critical obstacles towards real-world applications are often caused by large intra-class variability, arising from different lightings, occlusion and corruption, in limited sample sets. Most methods in the literature would fail when the training samples are heavily occluded, corrupted or have significant illumination or viewpoint variations. Besides, most of the existing methods and especially deep learning-based methods, need large training sets to achieve a satisfactory recognition performance. Although using the pre-trained network on a generic large-scale dataset and fine-tune it to the small-sized target dataset is a widely used technique, this would not help when the content of base and target datasets are very different. To address these issues, we propose a joint projection and low-rank dictionary learning method using dual graph constraints (JP-LRDL). The proposed joint learning method would enable us to learn the features on top of which dictionaries can be better learned, from the data with large intra-class variability. Specifically, a structured class-specific dictionary is learned and the discrimination is further improved by imposing a graph constraint on the coding coefficients, that maximizes the intra-class compactness and inter-class separability. We also enforce low-rank and structural incoherence constraints on sub-dictionaries to make them more compact and robust to variations and outliers and reduce the redundancy among them, respectively. To preserve the intrinsic structure of data and penalize unfavourable relationship among training samples simultaneously, we introduce a projection graph into the framework, which significantly enhances the discriminative ability of the projection matrix and makes the method robust to small-sized and high-dimensional datasets. version:1
arxiv-1612-01589 | Improving the Performance of Neural Networks in Regression Tasks Using Drawering | http://arxiv.org/abs/1612.01589 | id:1612.01589 author:Konrad Zolna category:cs.LG cs.AI cs.NE stat.ML  published:2016-12-05 summary:The method presented extends a given regression neural network to make its performance improve. The modification affects the learning procedure only, hence the extension may be easily omitted during evaluation without any change in prediction. It means that the modified model may be evaluated as quickly as the original one but tends to perform better. This improvement is possible because the modification gives better expressive power, provides better behaved gradients and works as a regularization. The knowledge gained by the temporarily extended neural network is contained in the parameters shared with the original neural network. The only cost is an increase in learning time. version:1
arxiv-1612-01556 | The Evolution of Sentiment Analysis - A Review of Research Topics, Venues, and Top Cited Papers | http://arxiv.org/abs/1612.01556 | id:1612.01556 author:Mika Viking Mäntylä, Daniel Graziotin, Miikka Kuutila category:cs.CL cs.DL cs.SI  published:2016-12-05 summary:Research in sentiment analysis is increasing at a fast pace making it challenging to keep track of all the activities in the area. We present a computer-assisted literature review and analyze 5,163 papers from Scopus. We find that the roots of sentiment analysis are in studies on public opinion analysis at the start of 20th century, but the outbreak of computer-based sentiment analysis only occurred with the availability of subjective texts in the Web. Consequently, 99% of the papers have been published after 2005. Sentiment analysis papers are scattered to multiple publication venues and the combined number of papers in the top-15 venues only represent 29% of the papers in total. In recent years, sentiment analysis has shifted from analyzing online product reviews to social media texts from Twitter and Facebook. We created a taxonomy of research topics with text mining and qualitative coding. A meaningful future for sentiment analysis could be in ensuring the authenticity of public opinions, and detecting fake news. version:1
arxiv-1612-01551 | Deep learning in color: towards automated quark/gluon jet discrimination | http://arxiv.org/abs/1612.01551 | id:1612.01551 author:Patrick T. Komiske, Eric M. Metodiev, Matthew D. Schwartz category:hep-ph stat.ML  published:2016-12-05 summary:Artificial intelligence offers the potential to automate challenging data-processing tasks in collider physics. To establish its prospects, we explore to what extent deep learning with convolutional neural networks can discriminate quark and gluon jets better than observables designed by physicists. Our approach builds upon the paradigm that a jet can be treated as an image, with intensity given by the local calorimeter deposits. We supplement this construction by adding color to the images, with red, green and blue intensities given by the transverse momentum in charged particles, transverse momentum in neutral particles, and pixel-level charged particle counts. Overall, the deep networks match or outperform traditional jet variables. We also find that, while various simulations produce different quark and gluon jets, the neural networks are surprisingly insensitive to these differences, similar to traditional observables. This suggests that the networks can extract robust physical information from imperfect simulations. version:1
arxiv-1612-01543 | Towards the Limit of Network Quantization | http://arxiv.org/abs/1612.01543 | id:1612.01543 author:Yoojin Choi, Mostafa El-Khamy, Jungwon Lee category:cs.CV cs.LG cs.NE  published:2016-12-05 summary:Network quantization is one of network compression techniques employed to reduce the redundancy of deep neural networks. It compresses the size of the storage for a large number of network parameters in a neural network by quantizing them and encoding the quantized values into binary codewords of smaller sizes. In this paper, we aim to design network quantization schemes that minimize the expected loss due to quantization while maximizing the compression ratio. To this end, we analyze the quantitative relation of quantization errors to the loss function of a neural network and identify that the Hessian-weighted distortion measure is locally the right objective function that we need to optimize for minimizing the loss due to quantization. As a result, Hessian-weighted k-means clustering is proposed for clustering network parameters to quantize when fixed-length binary encoding follows. When optimal variable-length binary codes, e.g., Huffman codes, are employed for further compression of quantized values after clustering, we derive that the network quantization problem can be related to the entropy-constrained scalar quantization (ECSQ) problem in information theory and consequently propose two solutions of ECSQ for network quantization, i.e., uniform quantization and an iterative algorithm similar to Lloyd's algorithm for k-means clustering. Finally, using the simple uniform quantization followed by Huffman coding, our experiment results show that the compression ratios of 51.25, 22.17 and 40.65 are achievable (i.e., the sizes of the compressed models are 1.95%, 4.51% and 2.46% of the original model sizes) for LeNet, ResNet and AlexNet, respectively, at no or marginal performance loss. version:1
arxiv-1612-01820 | Explaining Radiological Emphysema Subtypes with Unsupervised Texture Prototypes: MESA COPD Study | http://arxiv.org/abs/1612.01820 | id:1612.01820 author:Jie Yang, Elsa D. Angelini, Benjamin M. Smith, John H. M. Austin, Eric A. Hoffman, David A. Bluemke, R. Graham Barr, Andrew F. Laine category:cs.CV  published:2016-12-05 summary:Pulmonary emphysema is traditionally subcategorized into three subtypes, which have distinct radiological appearances on computed tomography (CT) and can help with the diagnosis of chronic obstructive pulmonary disease (COPD). Automated texture-based quantification of emphysema subtypes has been successfully implemented via supervised learning of these three emphysema subtypes. In this work, we demonstrate that unsupervised learning on a large heterogeneous database of CT scans can generate texture prototypes that are visually homogeneous and distinct, reproducible across subjects, and capable of predicting accurately the three standard radiological subtypes. These texture prototypes enable automated labeling of lung volumes, and open the way to new interpretations of lung CT scans with finer subtyping of emphysema. version:1
arxiv-1612-01504 | Dynamic change-point detection using similarity networks | http://arxiv.org/abs/1612.01504 | id:1612.01504 author:Shanshan Cao, Yao Xie category:math.ST stat.ML stat.TH  published:2016-12-05 summary:From a sequence of similarity networks, with edges representing certain similarity measures between nodes, we are interested in detecting a change-point which changes the statistical property of the networks. After the change, a subset of anomalous nodes which compares dissimilarly with the normal nodes. We study a simple sequential change detection procedure based on node-wise average similarity measures, and study its theoretical property. Simulation and real-data examples demonstrate such a simply stopping procedure has reasonably good performance. We further discuss the faulty sensor isolation (estimating anomalous nodes) using community detection. version:1
arxiv-1612-02666 | Evaluating the Performance of ANN Prediction System at Shanghai Stock Market in the Period 21-Sep-2016 to 11-Oct-2016 | http://arxiv.org/abs/1612.02666 | id:1612.02666 author:Barack Wamkaya Wanjawa category:q-fin.ST cs.LG stat.ML  published:2016-12-05 summary:This research evaluates the performance of an Artificial Neural Network based prediction system that was employed on the Shanghai Stock Exchange for the period 21-Sep-2016 to 11-Oct-2016. It is a follow-up to a previous paper in which the prices were predicted and published before September 21. Stock market price prediction remains an important quest for investors and researchers. This research used an Artificial Intelligence system, being an Artificial Neural Network that is feedforward multi-layer perceptron with error backpropagation for prediction, unlike other methods such as technical, fundamental or time series analysis. While these alternative methods tend to guide on trends and not the exact likely prices, neural networks on the other hand have the ability to predict the real value prices, as was done on this research. Nonetheless, determination of suitable network parameters remains a challenge in neural network design, with this research settling on a configuration of 5:21:21:1 with 80% training data or 4-year of training data as a good enough model for stock prediction, as already determined in a previous research by the author. The comparative results indicate that neural network can predict typical stock market prices with mean absolute percentage errors that are as low as 1.95% over the ten prediction instances that was studied in this research. version:1
arxiv-1612-00835 | Scribbler: Controlling Deep Image Synthesis with Sketch and Color | http://arxiv.org/abs/1612.00835 | id:1612.00835 author:Patsorn Sangkloy, Jingwan Lu, Chen Fang, Fisher Yu, James Hays category:cs.CV cs.LG  published:2016-12-02 summary:Recently, there have been several promising methods to generate realistic imagery from deep convolutional networks. These methods sidestep the traditional computer graphics rendering pipeline and instead generate imagery at the pixel level by learning from large collections of photos (e.g. faces or bedrooms). However, these methods are of limited utility because it is difficult for a user to control what the network produces. In this paper, we propose a deep adversarial image synthesis architecture that is conditioned on sketched boundaries and sparse color strokes to generate realistic cars, bedrooms, or faces. We demonstrate a sketch based image synthesis system which allows users to 'scribble' over the sketch to indicate preferred color for objects. Our network can then generate convincing images that satisfy both the color and the sketch constraints of user. The network is feed-forward which allows users to see the effect of their edits in real time. We compare to recent work on sketch to image synthesis and show that our approach can generate more realistic, more diverse, and more controllable outputs. The architecture is also effective at user-guided colorization of grayscale images. version:2
arxiv-1612-01495 | ROAM: a Rich Object Appearance Model with Application to Rotoscoping | http://arxiv.org/abs/1612.01495 | id:1612.01495 author:Ondrej Miksik, Juan-Manuel Pérez-Rúa, Philip H. S. Torr, Patrick Pérez category:cs.CV  published:2016-12-05 summary:Rotoscoping, the detailed delineation of scene elements through a video shot, is a painstaking task of tremendous importance in professional post-production pipelines. While pixel-wise segmentation techniques can help for this task, professional rotoscoping tools rely on parametric curves that offer the artists a much better interactive control on the definition, editing and manipulation of the segments of interest. Sticking to this prevalent rotoscoping paradigm, we propose a novel framework to capture and track the visual aspect of an arbitrary object in a scene, given a first closed outline of this object. This model combines a collection of local foreground/background appearance models spread along the outline, a global appearance model of the enclosed object and a set of distinctive foreground landmarks. The structure of this rich appearance model allows simple initialization, efficient iterative optimization with exact minimization at each step, and on-line adaptation in videos. We demonstrate qualitatively and quantitatively the merit of this framework through comparisons with tools based on either dynamic segmentation with a closed curve or pixel-wise binary labelling. version:1
arxiv-1612-01491 | Enabling Bio-Plausible Multi-level STDP using CMOS Neurons with Dendrites and Bistable RRAMs | http://arxiv.org/abs/1612.01491 | id:1612.01491 author:Xinyu Wu, Vishal Saxena category:cs.ET cs.NE  published:2016-12-05 summary:Large-scale integration of emerging nanoscale non-volatile memory devices, e.g. resistive random-access memory (RRAM), can enable a new generation of neuromorphic computers that can solve a wide range of machine learning problems. Such hybrid CMOS-RRAM neuromorphic architectures will result in several orders of magnitude reduction in energy consumption at a very small form factor, and herald autonomous learning machines capable of self-adapting to their environment. However, the progress in this area has been impeded from the realization that the actual memory devices fall well short of their expected behavior. In this work, we discuss the challenges associated with these memory devices and their use in neuromorphic computing circuits, and propose pathways to overcome these limitations by introducing 'dendritic learning'. version:1
arxiv-1612-01490 | Whiteout: Gaussian Adaptive Regularization Noise in Deep Neural Networks | http://arxiv.org/abs/1612.01490 | id:1612.01490 author:Yinan Li, Ruoyi Xu, Fang Liu category:stat.ML 62  published:2016-12-05 summary:Noise injection is an off-the-shelf method to mitigate over-fitting in neural networks (NNs). The recent developments in Bernoulli noise injection as implemented in the dropout and shakeout procedures demonstrates the efficiency and feasibility of noise injection in regularizing deep NNs. We propose whiteout, a new regularization technique via injection of adaptive Gaussian noises into a deep NN. Whiteout offers three tuning parameters, offering flexibility during training of NNs. We show that whiteout is associated with a deterministic optimization objective function in the context of generalized linear models with a closed-form penalty term and includes lasso, ridge regression, adaptive lasso, and elastic net as special cases. We also demonstrate that whiteout can be viewed as robust learning of NN model in the presence of small and insignificant perturbations in input and hidden nodes. Compared to dropout, whiteout has better performance when training data of relatively small sizes with the sparsity introduced through the $l_1$ regularization. Compared to shakeout, the penalized objective function in whiteout has better convergence behaviors and is more stable given the continuity of injected noises. We establish theoretically that the noise-perturbed empirical loss function with whiteout converges almost surely to the ideal loss function, and the estimates of NN parameters obtained from minimizing the former loss function are consistent with those obtained from minimizing the ideal loss function. Computationally, whiteout can be incorporated in the back-propagation algorithm and is computationally efficient. The superiority of whiteout over dropout and shakeout in training NNs in classification is demonstrated using the MNIST data. version:1
arxiv-1612-01489 | MCMC Louvain for Online Community Detection | http://arxiv.org/abs/1612.01489 | id:1612.01489 author:Yves Darmaillac, Sébastien Loustau category:cs.SI physics.soc-ph stat.ML  published:2016-12-05 summary:We introduce a novel algorithm of community detection that maintains dynamically a community structure of a large network that evolves with time. The algorithm maximizes the modularity index thanks to the construction of a randomized hierarchical clustering based on a Monte Carlo Markov Chain (MCMC) method. Interestingly, it could be seen as a dynamization of Louvain algorithm (see Blondel et Al, 2008) where the aggregation step is replaced by the hierarchical instrumental probability. version:1
arxiv-1612-01481 | A Nonparametric Latent Factor Model For Location-Aware Video Recommendations | http://arxiv.org/abs/1612.01481 | id:1612.01481 author:Ehtsham Elahi category:stat.ML cs.LG  published:2016-12-05 summary:We are interested in learning customers' video preferences from their historic viewing patterns and geographical location. We consider a Bayesian latent factor modeling approach for this task. In order to tune the complexity of the model to best represent the data, we make use of Bayesian nonparameteric techniques. We describe an inference technique that can scale to large real-world data sets. Finally we show results obtained by applying the model to a large internal Netflix data set, that illustrates that the model was able to capture interesting relationships between viewing patterns and geographical location. version:1
arxiv-1612-01480 | Incomplete data representation for SVM classification | http://arxiv.org/abs/1612.01480 | id:1612.01480 author:Łukasz Struski, Marek Śmieja, Jacek Tabor category:cs.LG stat.ML  published:2016-12-05 summary:In this paper we propose two ways of incomplete data representation. The first one is a generalization of a flag representation, where a vector with missing attributes is filled with some values and joined with flag vectors indicating missing components. Our generalization uses pointed affine subspaces, which in addition to flag representation allows to perform various affine transformations of data, as whitening or dimensionality reduction. We show how to embed such affine subspaces into a vector space and how to define a proper scalar product. In the second approach, we represent missing data points by degenerated Gaussian densities, which additionally model the uncertainty connected with missing features. This representation allows to construct an analogue of RBF kernel on incomplete data space. version:1
arxiv-1612-01479 | Authoring image decompositions with generative models | http://arxiv.org/abs/1612.01479 | id:1612.01479 author:Jason Rock, Theerasit Issaranon, Aditya Deshpande, David Forsyth category:cs.CV  published:2016-12-05 summary:We show how to extend traditional intrinsic image decompositions to incorporate further layers above albedo and shading. It is hard to obtain data to learn a multi-layer decomposition. Instead, we can learn to decompose an image into layers that are "like this" by authoring generative models for each layer using proxy examples that capture the Platonic ideal (Mondrian images for albedo; rendered 3D primitives for shading; material swatches for shading detail). Our method then generates image layers, one from each model, that explain the image. Our approach rests on innovation in generative models for images. We introduce a Convolutional Variational Auto Encoder (conv-VAE), a novel VAE architecture that can reconstruct high fidelity images. The approach is general, and does not require that layers admit a physical interpretation. version:1
arxiv-1612-01474 | Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles | http://arxiv.org/abs/1612.01474 | id:1612.01474 author:Balaji Lakshminarayanan, Alexander Pritzel, Charles Blundell category:stat.ML cs.LG  published:2016-12-05 summary:Deep neural networks are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in neural networks is a challenging and yet unsolved problem. Bayesian neural networks, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty; however these require significant modifications to the training procedure and are computationally expensive compared to standard (non-Bayesian) neural neural networks. We propose an alternative to Bayesian neural networks, that is simple to implement, readily parallelisable and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian neural networks. Finally, we evaluate the predictive uncertainty on test examples from known and unknown classes, and show that our method is able to express higher degree of uncertainty on unknown classes, unlike existing methods which make overconfident predictions even on unknown classes. version:1
arxiv-1612-01465 | Articulated Multi-person Tracking in the Wild | http://arxiv.org/abs/1612.01465 | id:1612.01465 author:Eldar Insafutdinov, Mykhaylo Andriluka, Leonid Pishchulin, Siyu Tang, Bjoern Andres, Bernt Schiele category:cs.CV  published:2016-12-05 summary:In this paper we propose an approach for articulated tracking of multiple people in unconstrained videos. Our starting point is a model that resembles existing architectures for single-frame pose estimation but is several orders of magnitude faster. We achieve this in two ways: (1) by simplifying and sparsifying the body-part relationship graph and leveraging recent methods for faster inference, and (2) by offloading a substantial share of computation onto a feed-forward convolutional architecture that is able to detect and associate body joints of the same person even in clutter. We use this model to generate proposals for body joint locations and formulate articulated tracking as spatio-temporal grouping of such proposals. This allows to jointly solve the association problem for all people in the scene by propagating evidence from strong detections through time and enforcing constraints that each proposal can be assigned to one person only. We report results on a public MPII Human Pose benchmark and on a new dataset of videos with multiple people. We demonstrate that our model achieves state-of-the-art results while using only a fraction of time and is able to leverage temporal information to improve state-of-the-art for crowded scenes. version:1
arxiv-1612-01458 | Support vector regression model for BigData systems | http://arxiv.org/abs/1612.01458 | id:1612.01458 author:Alessandro Maria Rizzi category:cs.DC cs.LG cs.PF  published:2016-12-05 summary:Nowadays Big Data are becoming more and more important. Many sectors of our economy are now guided by data-driven decision processes. Big Data and business intelligence applications are facilitated by the MapReduce programming model while, at infrastructural layer, cloud computing provides flexible and cost effective solutions for allocating on demand large clusters. In such systems, capacity allocation, which is the ability to optimally size minimal resources for achieve a certain level of performance, is a key challenge to enhance performance for MapReduce jobs and minimize cloud resource costs. In order to do so, one of the biggest challenge is to build an accurate performance model to estimate job execution time of MapReduce systems. Previous works applied simulation based models for modeling such systems. Although this approach can accurately describe the behavior of Big Data clusters, it is too computationally expensive and does not scale to large system. We try to overcome these issues by applying machine learning techniques. More precisely we focus on Support Vector Regression (SVR) which is intrinsically more robust w.r.t other techniques, like, e.g., neural networks, and less sensitive to outliers in the training set. To better investigate these benefits, we compare SVR to linear regression. version:1
arxiv-1612-01437 | High-Performance Distributed Machine Learning using Apache SPARK | http://arxiv.org/abs/1612.01437 | id:1612.01437 author:Celestine Dünner, Thomas Parnell, Kubilay Atasu, Manolis Sifalakis, Haralampos Pozidis category:cs.DC cs.LG  published:2016-12-05 summary:In this paper we compare the performance of distributed learning using Apache SPARK and MPI by implementing a distributed linear learning algorithm from scratch on the two programming frameworks. We then explore the performance gap and show how SPARK learning can be accelerated, by reducing computational cost as well as communication-related overheads, to reduce the relative loss in performance versus MPI from 20x to 2x. With these different implementations at hand, we will illustrate how the optimal parameters of the algorithm depend strongly on the characteristics of the framework on which it is executed. We will show that carefully tuning a distributed algorithm to trade-off communication and computation can improve performance by orders of magnitude. Hence, understanding system aspects of the framework and their implications, and then correctly adapting the algorithm proves to be the key to performance. version:1
arxiv-1612-00334 | A Theoretical Framework for Robustness of (Deep) Classifiers Under Adversarial Noise | http://arxiv.org/abs/1612.00334 | id:1612.00334 author:Beilun Wang, Ji Gao, Yanjun Qi category:cs.LG  published:2016-12-01 summary:Recent literature has pointed out that machine learning classifiers, including deep neural networks (DNN), are vulnerable to adversarial samples that are maliciously created inputs that force a machine learning classifier to produce wrong output labels. Multiple studies have tried to analyze and thus harden machine classifiers under such adversarial noise (AN). However, they are mostly empirical and provide little understanding of the underlying principles that enable evaluation of the robustness of a classier against AN. This paper proposes a unified framework using two metric spaces to evaluate classifiers' robustness against AN and provides general guidance for hardening such classifiers. The central idea of our work is that for a certain classification task, the robustness of a classifier $f_1$ against AN is decided by both $f_1$ and its oracle $f_2$ (like human annotator of that specific task). In particular: (1) By adding oracle $f_2$ into the framework, we provide a general definition of the adversarial sample problem. (2) We theoretically formulate a definition that decides whether a classifier is always robust against AN (strong-robustness); (3) Using two metric spaces ($X_1,d_1$) and ($X_2,d_2$) defined by $f_1$ and $f_2$ respectively, we prove that the topological equivalence between ($X_1,d_1$) and ($X_2,d_2$) is sufficient in deciding whether $f_1$ is strong-robust at test time, or not; (5) By training a DNN classifier using the Siamese architecture, we propose a new defense strategy "Siamese training" to intuitively approach topological equivalence between ($X_1,d_1$) and ($X_2,d_2$). Experimental results show that Siamese training helps multiple DNN models achieve better accuracy compared to previous defense strategies in an adversarial setting. DNN models after Siamese training exhibit better robustness than the state-of-the-art baselines. version:2
arxiv-1612-01428 | Extracting Implicit Social Relation for Social Recommendation Techniques in User Rating Prediction | http://arxiv.org/abs/1612.01428 | id:1612.01428 author:Seyed Mohammad Taheri, Hamidreza Mahyar, Mohammad Firouzi, Ali Movaghar category:cs.SI cs.LG  published:2016-12-05 summary:Recommendation plays an increasingly important role in our daily lives. Recommender systems automatically suggest items to users that might be interesting for them. Recent studies illustrate that incorporating social trust in Matrix Factorization methods demonstrably improves accuracy of rating prediction. Such approaches mainly use the trust scores explicitly expressed by users. However, it is often challenging to have users provide explicit trust scores of each other. There exist quite a few works, which propose Trust Metrics to compute and predict trust scores between users based on their interactions. In this paper, first we present how social relation can be extracted from users' ratings to items by describing Hellinger distance between users in recommender systems. Then, we propose to incorporate the predicted trust scores into social matrix factorization models. By analyzing social relation extraction from three well-known real-world datasets, which both: trust and recommendation data available, we conclude that using the implicit social relation in social recommendation techniques has almost the same performance compared to the actual trust scores explicitly expressed by users. Hence, we build our method, called Hell-TrustSVD, on top of the state-of-the-art social recommendation technique to incorporate both the extracted implicit social relations and ratings given by users on the prediction of items for an active user. To the best of our knowledge, this is the first work to extend TrustSVD with extracted social trust information. The experimental results support the idea of employing implicit trust into matrix factorization whenever explicit trust is not available, can perform much better than the state-of-the-art approaches in user rating prediction. version:1
arxiv-1612-01425 | Zeroth-order Asynchronous Doubly Stochastic Algorithm with Variance Reduction | http://arxiv.org/abs/1612.01425 | id:1612.01425 author:Bin Gu, Zhouyuan Huo, Heng Huang category:cs.LG  published:2016-12-05 summary:Zeroth-order (derivative-free) optimization attracts a lot of attention in machine learning, because explicit gradient calculations may be computationally expensive or infeasible. To handle large scale problems both in volume and dimension, recently asynchronous doubly stochastic zeroth-order algorithms were proposed. The convergence rate of existing asynchronous doubly stochastic zeroth order algorithms is $O(\frac{1}{\sqrt{T}})$ (also for the sequential stochastic zeroth-order optimization algorithms). In this paper, we focus on the finite sums of smooth but not necessarily convex functions, and propose an asynchronous doubly stochastic zeroth-order optimization algorithm using the accelerated technology of variance reduction (AsyDSZOVR). Rigorous theoretical analysis show that the convergence rate can be improved from $O(\frac{1}{\sqrt{T}})$ the best result of existing algorithms to $O(\frac{1}{T})$. Also our theoretical results is an improvement to the ones of the sequential stochastic zeroth-order optimization algorithms. version:1
arxiv-1612-01414 | Sparse Label Propagation | http://arxiv.org/abs/1612.01414 | id:1612.01414 author:Alexander Jung category:cs.LG stat.ML  published:2016-12-05 summary:We consider massive heterogeneous datasets with intrinsic network structure, i.e., big data over networks. These datasets can be modelled by graph signals, which are defined over large-scale irregular graphs representing complex networks. We show that (semi-supervised) learning of the entire underlying graph signal based on incomplete information provided by few initial labels can be reduced to a compressed sensing recovery problem within the cosparse analysis model. This reduction provides two things: First, it allows to apply highly developed compressed sensing methods to the learning problem. In particular, by implementing a recent primal-dual method for convex optimization, we obtain a sparse label propagation algorithm. Moreover, by casting the learning problem within compressed sensing, we are able to derive sufficient conditions on the graph structure and available label information, such that sparse label propagation is accurate. version:1
arxiv-1612-01404 | Mapping the Dialog Act Annotations of the LEGO Corpus into the Communicative Functions of ISO 24617-2 | http://arxiv.org/abs/1612.01404 | id:1612.01404 author:Eugénio Ribeiro, Ricardo Ribeiro, David Martins de Matos category:cs.CL H.1.2; H.3.1  published:2016-12-05 summary:In this paper we present strategies for mapping the dialog act annotations of the LEGO corpus into the communicative functions of the ISO 24617-2 standard. Using these strategies, we obtained an additional 347 dialogs annotated according to the standard. This is particularly important given the reduced amount of existing data in those conditions due to the recency of the standard. Furthermore, these are dialogs from a widely explored corpus for dialog related tasks. However, its dialog annotations have been neglected due to their high domain-dependency, which renders them unuseful outside the context of the corpus. Thus, through our mapping process, we both obtain more data annotated according to a recent standard and provide useful dialog act annotations for a widely explored corpus in the context of dialog research. version:1
arxiv-1612-01401 | Learning Adversary-Resistant Deep Neural Networks | http://arxiv.org/abs/1612.01401 | id:1612.01401 author:Qinglong Wang, Wenbo Guo, Kaixuan Zhang, Alexander G. Ororbia II, Xinyu Xing, C. Lee Giles, Xue Liu category:cs.LG  published:2016-12-05 summary:Deep neural networks (DNNs) have proven to be quite effective in a vast array of machine learning tasks, with recent examples in cyber security and autonomous vehicles. Despite the superior performance of DNNs in these applications, it has been recently shown that these models are susceptible to a particular type of attack that exploits a fundamental flaw in their design. This attack consists of generating particular synthetic examples referred to as adversarial samples. These samples are constructed by slightly manipulating real data-points in order to "fool" the original DNN model, forcing it to mis-classify previously correctly classified samples with high confidence. Addressing this flaw in the model is essential if DNNs are to be used in critical applications such as those in cyber security. Previous work has provided various defense mechanisms by either augmenting the training set or enhancing model complexity. However, after a thorough analysis, we discover that DNNs protected by these defense mechanisms are still susceptible to adversarial samples, indicating that there are no theoretical guarantees of resistance provided by these mechanisms. To the best of our knowledge, we are the first to investigate this issue shared across previous research work and to propose a unifying framework for protecting DNN models by integrating a data transformation module with the DNN. More importantly, we provide a theoretical guarantee for protection under our proposed framework. We evaluate our method and several other existing solutions on both MNIST, CIFAR-10, and a malware dataset, to demonstrate the generality of our proposed method and its potential for handling cyber security applications. The results show that our framework provides better resistance compared to state-of-art solutions while experiencing negligible degradation in accuracy. version:1
arxiv-1612-01397 | Implicit Modeling -- A Generalization of Discriminative and Generative Approaches | http://arxiv.org/abs/1612.01397 | id:1612.01397 author:Dmitrij Schlesinger, Carsten Rother category:cs.LG  published:2016-12-05 summary:We propose a new modeling approach that is a generalization of generative and discriminative models. The core idea is to use an implicit parameterization of a joint probability distribution by specifying only the conditional distributions. The proposed scheme combines the advantages of both worlds -- it can use powerful complex discriminative models as its parts, having at the same time better generalization capabilities. We thoroughly evaluate the proposed method for a simple classification task with artificial data and illustrate its advantages for real-word scenarios on a semantic image segmentation problem. version:1
arxiv-1612-01380 | From One-Trick Ponies to All-Rounders: On-Demand Learning for Image Restoration | http://arxiv.org/abs/1612.01380 | id:1612.01380 author:Ruohan Gao, Kristen Grauman category:cs.CV  published:2016-12-05 summary:While machine learning approaches to image restoration offer great promise, current methods risk training "one-trick ponies" that perform well only for image corruption of a particular level of difficulty---such as a certain level of noise or blur. First, we expose the weakness of today's one-trick pony and demonstrate that training general models equipped to handle arbitrary levels of corruption is indeed non-trivial. Then, we propose an on-demand learning algorithm for training image restoration models with deep convolutional neural networks. The main idea is to exploit a feedback mechanism to self-generate training instances where they are needed most, thereby learning models that can generalize across difficulty levels. On four restoration tasks---image inpainting, pixel interpolation, image deblurring, and image denoising---and three diverse datasets, our approach consistently outperforms both the status quo training procedure and curriculum learning alternatives. version:1
arxiv-1612-01367 | A Nearly Optimal Contextual Bandit Algorithm | http://arxiv.org/abs/1612.01367 | id:1612.01367 author:Mohammadreza Mohaghegh Neyshabouri, Kaan Gokcesu, Selami Ciftci, Suleyman S. Kozat category:cs.LG  published:2016-12-05 summary:We investigate the contextual multi-armed bandit problem in an adversarial setting and introduce an online algorithm that asymptotically achieves the performance of the best contextual bandit arm selection strategy under certain conditions. We show that our algorithm is highly efficient and provides significantly improved performance with a guaranteed performance upper bound in a strong mathematical sense. We have no statistical assumptions on the context vectors and the loss of the bandit arms, hence our results are guaranteed to hold even in adversarial environments. We use a tree notion in order to partition the space of context vectors in a nested structure. Using this tree, we construct a large class of context dependent bandit arm selection strategies and adaptively combine them to achieve the performance of the best strategy. We use the hierarchical nature of introduced tree to implement this combination with a significantly low computational complexity, thus our algorithm can be efficiently used in applications involving big data. Through extensive set of experiments involving synthetic and real data, we demonstrate significant performance gains achieved by the proposed algorithm with respect to the state-of-the-art adversarial bandit algorithms. version:1
arxiv-1612-01356 | Diagnostic Prediction Using Discomfort Drawings | http://arxiv.org/abs/1612.01356 | id:1612.01356 author:Cheng Zhang, Hedvig Kjellstrom, Bo C. Bertilson category:cs.LG  published:2016-12-05 summary:In this paper, we explore the possibility to apply machine learning to make diagnostic predictions using discomfort drawings. A discomfort drawing is an intuitive way for patients to express discomfort and pain related symptoms. These drawings have proven to be an effective method to collect patient data and make diagnostic decisions in real-life practice. A dataset from real-world patient cases is collected for which medical experts provide diagnostic labels. Next, we extend a factorized multimodal topic model, Inter-Battery Topic Model (IBTM), to train a system that can make diagnostic predictions given an unseen discomfort drawing. Experimental results show reasonable predictions of diagnostic labels given an unseen discomfort drawing. The positive result indicates a significant potential of machine learning to be used for parts of the pain diagnostic process and to be a decision support system for physicians and other health care personnel. version:1
arxiv-1612-01345 | Human-In-The-Loop Person Re-Identification | http://arxiv.org/abs/1612.01345 | id:1612.01345 author:Hanxiao Wang, Shaogang Gong, Xiatian Zhu, Tao Xiang category:cs.CV  published:2016-12-05 summary:Current person re-identification (re-id) methods assume that (1) pre-labelled training data are available for every camera pair, (2) the gallery size for re-identification is moderate. Both assumptions scale poorly to real-world applications when camera network size increases and gallery size becomes large. Human verification of automatic model ranked re-id results becomes inevitable. In this work, a novel human-in-the-loop re-id model based on Human Verification Incremental Learning (HVIL) is formulated which does not require any pre-labelled training data to learn a model, therefore readily scalable to new camera pairs. This HVIL model learns cumulatively from human feedback to provide instant improvement to re-id ranking of each probe on-the-fly enabling the model scalable to large gallery sizes. We further formulate a Regularised Metric Ensemble Learning (RMEL) model to combine a series of incrementally learned HVIL models into a single ensemble model to be used when human feedback becomes unavailable. version:1
arxiv-1612-01341 | Highly Efficient Regression for Scalable Person Re-Identification | http://arxiv.org/abs/1612.01341 | id:1612.01341 author:Hanxiao Wang, Shaogang Gong, Tao Xiang category:cs.CV  published:2016-12-05 summary:Existing person re-identification models are poor for scaling up to large data required in real-world applications due to: (1) Complexity: They employ complex models for optimal performance resulting in high computational cost for training at a large scale; (2) Inadaptability: Once trained, they are unsuitable for incremental update to incorporate any new data available. This work proposes a truly scalable solution to re-id by addressing both problems. Specifically, a Highly Efficient Regression (HER) model is formulated by embedding the Fisher's criterion to a ridge regression model for very fast re-id model learning with scalable memory/storage usage. Importantly, this new HER model supports faster than real-time incremental model updates therefore making real-time active learning feasible in re-id with human-in-the-loop. Extensive experiments show that such a simple and fast model not only outperforms notably the state-of-the-art re-id methods, but also is more scalable to large data with additional benefits to active learning for reducing human labelling effort in re-id deployment. version:1
arxiv-1612-01340 | We used Neural Networks to Detect Clickbaits: You won't believe what happened Next! | http://arxiv.org/abs/1612.01340 | id:1612.01340 author:Ankesh Anand, Tanmoy Chakraborty, Noseong Park category:cs.CL cs.IR  published:2016-12-05 summary:Online content publishers often use catchy headlines for their articles in order to attract users to their websites. These headlines, popularly known as clickbaits, exploit a user's curiosity gap and lure them to click on links that often disappoint them. Existing methods for automatically detecting clickbaits rely on heavy feature engineering and domain knowledge. Here, we introduce a neural network architecture based on Recurrent Neural Networks for detecting clickbaits. Our model relies on distributed word representations learned from a large unannotated corpora, and character embeddings learned via Convolutional Neural Networks. Experimental results on a dataset of news headlines show that our model outperforms existing techniques for clickbait detection with an accuracy of 0.98 with F1-score of 0.98 and ROC-AUC of 0.99. version:1
arxiv-1612-01337 | Classification With an Edge: Improving Semantic Image Segmentation with Boundary Detection | http://arxiv.org/abs/1612.01337 | id:1612.01337 author:Dimitrios Marmanis, Konrad Schindler, Jan Dirk Wegner, Silvano Galliani, Mihai Datcu, Uwe Stilla category:cs.CV  published:2016-12-05 summary:We present an end-to-end trainable deep convolutional neural network (DCNN) for semantic segmentation with built-in awareness of semantically meaningful boundaries. Semantic segmentation is a fundamental remote sensing task, and most state-of-the-art methods rely on DCNNs as their workhorse. A major reason for their success is that deep networks learn to accumulate contextual information over very large windows (receptive fields). However, this success comes at a cost, since the associated loss of effecive spatial resolution washes out high-frequency details and leads to blurry object boundaries. Here, we propose to counter this effect by combining semantic segmentation with semantically informed edge detection, thus making class-boundaries explicit in the model, First, we construct a comparatively simple, memory-efficient model by adding boundary detection to the Segnet encoder-decoder architecture. Second, we also include boundary detection in FCN-type models and set up a high-end classifier ensemble. We show that boundary detection significantly improves semantic segmentation with CNNs. Our high-end ensemble achieves > 90% overall accuracy on the ISPRS Vaihingen benchmark. version:1
arxiv-1612-01323 | Stereo image de-fencing using smartphones | http://arxiv.org/abs/1612.01323 | id:1612.01323 author:Sankaraganesh Jonna, Sukla Satapathy, Rajiv R. Sahay category:cs.CV  published:2016-12-05 summary:Conventional approaches to image de-fencing have limited themselves to using only image data in adjacent frames of the captured video of an approximately static scene. In this work, we present a method to harness disparity using a stereo pair of fenced images in order to detect fence pixels. Tourists and amateur photographers commonly carry smartphones/phablets which can be used to capture a short video sequence of the fenced scene. We model the formation of the occluded frames in the captured video. Furthermore, we propose an optimization framework to estimate the de-fenced image using the total variation prior to regularize the ill-posed problem. version:1
arxiv-1612-01316 | Ranking Biomarkers Through Mutual Information | http://arxiv.org/abs/1612.01316 | id:1612.01316 author:Konstantinos Sechidis, Emily Turner, Paul D. Metcalfe, James Weatherall, Gavin Brown category:stat.ML cs.LG stat.AP  published:2016-12-05 summary:We study information theoretic methods for ranking biomarkers. In clinical trials there are two, closely related, types of biomarkers: predictive and prognostic, and disentangling them is a key challenge. Our first step is to phrase biomarker ranking in terms of optimizing an information theoretic quantity. This formalization of the problem will enable us to derive rankings of predictive/prognostic biomarkers, by estimating different, high dimensional, conditional mutual information terms. To estimate these terms, we suggest efficient low dimensional approximations, and we derive an empirical Bayes estimator, which is suitable for small or sparse datasets. Finally, we introduce a new visualisation tool that captures the prognostic and the predictive strength of a set of biomarkers. We believe this representation will prove to be a powerful tool in biomarker discovery. version:1
arxiv-1612-01294 | Message Passing Multi-Agent GANs | http://arxiv.org/abs/1612.01294 | id:1612.01294 author:Arnab Ghosh, Viveka Kulharia, Vinay Namboodiri category:cs.CV cs.AI cs.LG cs.NE  published:2016-12-05 summary:Communicating and sharing intelligence among agents is an important facet of achieving Artificial General Intelligence. As a first step towards this challenge, we introduce a novel framework for image generation: Message Passing Multi-Agent Generative Adversarial Networks (MPM GANs). While GANs have recently been shown to be very effective for image generation and other tasks, these networks have been limited to mostly single generator-discriminator networks. We show that we can obtain multi-agent GANs that communicate through message passing to achieve better image generation. The objectives of the individual agents in this framework are two fold: a co-operation objective and a competing objective. The co-operation objective ensures that the message sharing mechanism guides the other generator to generate better than itself while the competing objective encourages each generator to generate better than its counterpart. We analyze and visualize the messages that these GANs share among themselves in various scenarios. We quantitatively show that the message sharing formulation serves as a regularizer for the adversarial training. Qualitatively, we show that the different generators capture different traits of the underlying data distribution. version:1
arxiv-1612-01288 | Point Pair Feature based Object Detection for Random Bin Picking | http://arxiv.org/abs/1612.01288 | id:1612.01288 author:Wim Abbeloos, Toon Goedemé category:cs.CV  published:2016-12-05 summary:Point pair features are a popular representation for free form 3D object detection and pose estimation. In this paper, their performance in an industrial random bin picking context is investigated. A new method to generate representative synthetic datasets is proposed. This allows to investigate the influence of a high degree of clutter and the presence of self similar features, which are typical to our application. We provide an overview of solutions proposed in literature and discuss their strengths and weaknesses. A simple heuristic method to drastically reduce the computational complexity is introduced, which results in improved robustness, speed and accuracy compared to the naive approach. version:1
arxiv-1612-01256 | Panoramic Structure from Motion via Geometric Relationship Detection | http://arxiv.org/abs/1612.01256 | id:1612.01256 author:Satoshi Ikehata, Ivaylo Boyadzhiev, Qi Shan, Yasutaka Furukawa category:cs.CV  published:2016-12-05 summary:This paper addresses the problem of Structure from Motion (SfM) for indoor panoramic image streams, extremely challenging even for the state-of-the-art due to the lack of textures and minimal parallax. The key idea is the fusion of single-view and multi-view reconstruction techniques via geometric relationship detection (e.g., detecting 2D lines as coplanar in 3D). Rough geometry suffices to perform such detection, and our approach utilizes rough surface normal estimates from an image-to-normal deep network to discover geometric relationships among lines. The detected relationships provide exact geometric constraints in our line-based linear SfM formulation. A constrained linear least squares is used to reconstruct a 3D model and camera motions, followed by the bundle adjustment. We have validated our algorithm on challenging datasets, outperforming various state-of-the-art reconstruction techniques. version:1
arxiv-1612-01254 | Deep Symbolic Representation Learning for Heterogeneous Time-series Classification | http://arxiv.org/abs/1612.01254 | id:1612.01254 author:Shengdong Zhang, Soheil Bahrampour, Naveen Ramakrishnan, Mohak Shah category:cs.LG stat.ML  published:2016-12-05 summary:In this paper, we consider the problem of event classification with multi-variate time series data consisting of heterogeneous (continuous and categorical) variables. The complex temporal dependencies between the variables combined with sparsity of the data makes the event classification problem particularly challenging. Most state-of-art approaches address this either by designing hand-engineered features or breaking up the problem over homogeneous variates. In this work, we propose and compare three representation learning algorithms over symbolized sequences which enables classification of heterogeneous time-series data using a deep architecture. The proposed representations are trained jointly along with the rest of the network architecture in an end-to-end fashion that makes the learned features discriminative for the given task. Experiments on three real-world datasets demonstrate the effectiveness of the proposed approaches. version:1
arxiv-1612-01253 | Deep Image Category Discovery using a Transferred Similarity Function | http://arxiv.org/abs/1612.01253 | id:1612.01253 author:Yen-Chang Hsu, Zhaoyang Lv, Zsolt Kira category:cs.CV cs.LG  published:2016-12-05 summary:Automatically discovering image categories in unlabeled natural images is one of the important goals of unsupervised learning. However, the task is challenging and even human beings define visual categories based on a large amount of prior knowledge. In this paper, we similarly utilize prior knowledge to facilitate the discovery of image categories. We present a novel end-to-end network to map unlabeled images to categories as a clustering network. We propose that this network can be learned with contrastive loss which is only based on weak binary pair-wise constraints. Such binary constraints can be learned from datasets in other domains as transferred similarity functions, which mimic a simple knowledge transfer. We first evaluate our experiments on the MNIST dataset as a proof of concept, based on predicted similarities trained on Omniglot, showing a 99\% accuracy which significantly outperforms clustering based approaches. Then we evaluate the discovery performance on Cifar-10, STL-10, and ImageNet, which achieves both state-of-the-art accuracy and shows it can be scalable to various large natural images. version:1
arxiv-1612-01251 | Known Unknowns: Uncertainty Quality in Bayesian Neural Networks | http://arxiv.org/abs/1612.01251 | id:1612.01251 author:Ramon Oliveira, Pedro Tabacof, Eduardo Valle category:stat.ML cs.LG cs.NE  published:2016-12-05 summary:We evaluate the uncertainty quality in neural networks using anomaly detection. We extract uncertainty measures (e.g. entropy) from the predictions of candidate models, use those measures as features for an anomaly detector, and gauge how well the detector differentiates known from unknown classes. We assign higher uncertainty quality to candidate models that lead to better detectors. We also propose a novel method for sampling a variational approximation of a Bayesian neural network, called One-Sample Bayesian Approximation (OSBA). We experiment on two datasets, MNIST and CIFAR10. We compare the following candidate neural network models: Maximum Likelihood, Bayesian Dropout, OSBA, and --- for MNIST --- the standard variational approximation. We show that Bayesian Dropout and OSBA provide better uncertainty information than Maximum Likelihood, and are essentially equivalent to the standard variational approximation, but much faster. version:1
arxiv-1612-00525 | A Noise-Filtering Approach for Cancer Drug Sensitivity Prediction | http://arxiv.org/abs/1612.00525 | id:1612.00525 author:Turki Turki, Zhi Wei category:cs.LG q-bio.GN stat.ML  published:2016-12-02 summary:Accurately predicting drug responses to cancer is an important problem hindering oncologists' efforts to find the most effective drugs to treat cancer, which is a core goal in precision medicine. The scientific community has focused on improving this prediction based on genomic, epigenomic, and proteomic datasets measured in human cancer cell lines. Real-world cancer cell lines contain noise, which degrades the performance of machine learning algorithms. This problem is rarely addressed in the existing approaches. In this paper, we present a noise-filtering approach that integrates techniques from numerical linear algebra and information retrieval targeted at filtering out noisy cancer cell lines. By filtering out noisy cancer cell lines, we can train machine learning algorithms on better quality cancer cell lines. We evaluate the performance of our approach and compare it with an existing approach using the Area Under the ROC Curve (AUC) on clinical trial data. The experimental results show that our proposed approach is stable and also yields the highest AUC at a statistically significant level. version:2
arxiv-1612-01237 | Cancerous Nuclei Detection and Scoring in Breast Cancer Histopathological Images | http://arxiv.org/abs/1612.01237 | id:1612.01237 author:Pegah Faridi, Habibollah Danyali, Mohammad Sadegh Helfroush, Mojgan Akbarzadeh Jahromi category:cs.CV  published:2016-12-05 summary:Early detection and prognosis of breast cancer are feasible by utilizing histopathological grading of biopsy specimens. This research is focused on detection and grading of nuclear pleomorphism in histopathological images of breast cancer. The proposed method consists of three internal steps. First, unmixing colors of H&E is used in the preprocessing step. Second, nuclei boundaries are extracted incorporating the center of cancerous nuclei which are detected by applying morphological operations and Difference of Gaussian filter on the preprocessed image. Finally, segmented nuclei are scored to accomplish one parameter of the Nottingham grading system for breast cancer. In this approach, the nuclei area, chromatin density, contour regularity, and nucleoli presence, are features for nuclear pleomorphism scoring. Experimental results showed that the proposed algorithm, with an accuracy of 86.6%, made significant advancement in detecting cancerous nuclei compared to existing methods in the related literature. version:1
arxiv-1612-01235 | Turning an Urban Scene Video into a Cinemagraph | http://arxiv.org/abs/1612.01235 | id:1612.01235 author:Hang Yan, Yebin Liu, Yasutaka Furukawa category:cs.CV  published:2016-12-05 summary:This paper proposes an algorithm that turns a regular video capturing urban scenes into a high-quality endless animation, known as a Cinemagraph. The creation of a Cinemagraph usually requires a static camera in a carefully configured scene. The task becomes challenging for a regular video with a moving camera and objects. Our approach first warps an input video into the viewpoint of a reference camera. Based on the warped video, we propose effective temporal analysis algorithms to detect regions with static geometry and dynamic appearance, where geometric modeling is reliable and visually attractive animations can be created. Lastly, the algorithm applies a sequence of video processing techniques to produce a Cinemagraph movie. We have tested the proposed approach on numerous challenging real scenes. To our knowledge, this work is the first to automatically generate Cinemagraph animations from regular movies in the wild. version:1
arxiv-1612-01234 | Multi-way Particle Swarm Fusion | http://arxiv.org/abs/1612.01234 | id:1612.01234 author:Chen Liu, Hang Yan, Pushmeet Kohli, Yasutaka Furukawa category:cs.CV  published:2016-12-05 summary:This paper proposes a novel MAP inference framework for Markov Random Field (MRF) in parallel computing environments. The inference framework, dubbed Swarm Fusion, is a natural generalization of the Fusion Move method. Every thread (in a case of multi-threading environments) maintains and updates a solution. At each iteration, a thread can generate arbitrary number of solution proposals and take arbitrary number of concurrent solutions from the other threads to perform multi-way fusion in updating its solution. The framework is general, making popular existing inference techniques such as alpha-expansion, fusion move, parallel alpha-expansion, and hierarchical fusion, its special cases. We have evaluated the effectiveness of our approach against competing methods on three problems of varying difficulties, in particular, the stereo, the optical flow, and the layered depthmap estimation problems. version:1
arxiv-1612-01230 | Deep Pyramidal Residual Networks with Separated Stochastic Depth | http://arxiv.org/abs/1612.01230 | id:1612.01230 author:Yoshihiro Yamada, Masakazu Iwamura, Koichi Kise category:cs.CV  published:2016-12-05 summary:On general object recognition, Deep Convolutional Neural Networks (DCNNs) achieve high accuracy. In particular, ResNet and its improvements have broken the lowest error rate records. In this paper, we propose a method to successfully combine two ResNet improvements, ResDrop and PyramidNet. We confirmed that the proposed network outperformed the conventional methods; on CIFAR-100, the proposed network achieved an error rate of 16.18% in contrast to PiramidNet achieving that of 18.29% and ResNeXt 17.31%. version:1
arxiv-1612-01227 | Local Blur Mapping: Exploiting High-Level Semantics by Deep Neural Networks | http://arxiv.org/abs/1612.01227 | id:1612.01227 author:Kede Ma, Huan Fu, Tongliang Liu, Zhou Wang, Dacheng Tao category:cs.CV  published:2016-12-05 summary:The human visual system excels at detecting local blur of visual images, but the underlying mechanism is mysterious. Traditional views of blur such as reduction in local or global high-frequency energy and loss of local phase coherence have fundamental limitations. For example, they cannot well discriminate flat regions from blurred ones. Here we argue that high-level semantic information is critical in successfully detecting local blur. Therefore, we resort to deep neural networks that are proficient in learning high-level features and propose the first end-to-end local blur mapping algorithm based on a fully convolutional network (FCN). We empirically show that high-level features of deeper layers indeed play a more important role than low-level features of shallower layers in resolving challenging ambiguities for this task. We test the proposed method on a standard blur detection benchmark and demonstrate that it significantly advances the state-of-the-art (ODS F-score of 0.853). In addition, we explore the use of the generated blur map in three applications, including blur region segmentation, blur degree estimation, and blur magnification. version:1
arxiv-1612-01225 | Deep Multi-Modal Image Correspondence Learning | http://arxiv.org/abs/1612.01225 | id:1612.01225 author:Chen Liu, Jiajun Wu, Pushmeet Kohli, Yasutaka Furukawa category:cs.CV  published:2016-12-05 summary:Inference of correspondences between images from different modalities is an extremely important perceptual ability that enables humans to understand and recognize cross-modal concepts. In this paper, we consider an instance of this problem that involves matching photographs of building interiors with their corresponding floorplan. This is a particularly challenging problem because a floorplan, as a stylized architectural drawing, is very different in appearance from a color photograph. Furthermore, individual photographs by themselves depict only a part of a floorplan (e.g., kitchen, bathroom, and living room). We propose the use of a number of different neural network architectures for this task, which are trained and evaluated on a novel large-scale dataset of 5 million floorplan images and 80 million associated photographs. Experimental evaluation reveals that our neural network architectures are able to identify visual cues that result in reliable matches across these two quite different modalities. In fact, the trained networks are able to even outperform human subjects in several challenging image matching problems. Our result implies that neural networks are effective at perceptual tasks that require long periods of reasoning even for humans to solve. version:1
arxiv-1612-01216 | Decentralized Projection-free Optimization for Convex and Non-convex Problems | http://arxiv.org/abs/1612.01216 | id:1612.01216 author:Hoi-To Wai, Jean Lafond, Anna Scaglione, Eric Moulines category:math.OC cs.SY stat.ML  published:2016-12-05 summary:Decentralized optimization algorithms have received much attention as fueled by the recent advances in network information processing and the tremendous amount of data that is generated by human activities. However, conventional decentralized algorithms based on projected gradient descent are incapable of handling high dimensional constrained problems, as the projection step becomes computationally prohibitive to compute. To address this problem, we adopt a projection-free optimization approach, a.k.a. the Frank-Wolfe (FW) or conditional gradient algorithm. We first develop a decentralized FW (DeFW) algorithm from the classical FW algorithm. The convergence of the proposed algorithm is studied by viewing the decentralized algorithm as an \emph{inexact} FW algorithm. Using a diminishing step size rule and letting $t$ be the iteration number, we show that the DeFW algorithm's convergence rate is ${\cal O}(1/t)$ for convex objectives; is ${\cal O}(1/t^2)$ for strongly convex objectives with the optimal solution in the interior of the constraint set; and is ${\cal O}(1/\sqrt{t})$ towards a stationary point for smooth but non-convex objectives. We then show that a gossip-based implementation meets the above guarantees with two communication rounds per iteration. Furthermore, we demonstrate the advantages of the proposed DeFW algorithm on two applications including low-complexity robust matrix completion and communication efficient sparse learning. Numerical results on synthetic and realistic data are presented to support our findings. version:1
arxiv-1612-01213 | Learnable Structured Clustering Framework for Deep Metric Learning | http://arxiv.org/abs/1612.01213 | id:1612.01213 author:Hyun Oh Song, Stefanie Jegelka, Vivek Rathod, Kevin Murphy category:cs.CV cs.LG  published:2016-12-05 summary:Learning the representation and the similarity metric in an end-to-end fashion with deep networks have demonstrated outstanding results for clustering and retrieval. However, these recent approaches still suffer from the performance degradation stemming from the local metric training procedure which is unaware of the global structure of the embedding space. We propose a global metric learning scheme for optimizing the deep metric embedding with the learnable clustering function and the clustering metric (NMI) in a novel structured prediction framework. Our experiments on CUB200-2011, Cars196, and Stanford online products datasets show state of the art performance both on the clustering and retrieval tasks measured in the NMI and Recall@K evaluation metrics. version:1
arxiv-1612-01205 | Optimal and Adaptive Off-policy Evaluation in Contextual Bandits | http://arxiv.org/abs/1612.01205 | id:1612.01205 author:Yu-Xiang Wang, Alekh Agarwal, Miroslav Dudik category:stat.ML cs.LG  published:2016-12-04 summary:We consider the problem of off-policy evaluation---estimating the value of a target policy using data collected by another policy---under the contextual bandit model. We establish a minimax lower bound on the mean squared error (MSE), and show that it is matched up to constant factors by the inverse propensity scoring (IPS) estimator. Since in the multi-armed bandit problem the IPS is suboptimal (Li et. al, 2015), our result highlights the difficulty of the contextual setting with non-degenerate context distributions. We further consider improvements on this minimax MSE bound, given access to a reward model. We show that the existing doubly robust approach, which utilizes such a reward model, may continue to suffer from high variance even when the reward model is perfect. We propose a new estimator called SWITCH which more effectively uses the reward model and achieves a superior bias-variance tradeoff compared with prior work. We prove an upper bound on its MSE and demonstrate its benefits empirically on a diverse collection of datasets, often seeing orders of magnitude improvements over a number of baselines. version:1
arxiv-1612-01202 | DenseReg: Fully Convolutional Dense Shape Regression In-the-Wild | http://arxiv.org/abs/1612.01202 | id:1612.01202 author:Rıza Alp Güler, George Trigeorgis, Epameinondas Antonakos, Patrick Snape, Stefanos Zafeiriou, Iasonas Kokkinos category:cs.CV  published:2016-12-04 summary:In this paper we propose to learn a mapping from image pixels into a dense template grid through a fully convolutional network. We formulate this task as a regression problem and train our network by leveraging upon manually annotated facial landmarks "in-the-wild". We use such landmarks to establish a dense correspondence field between a three-dimensional object template and the input image, which then serves as the ground-truth for training our regression system. We show that we can combine ideas from semantic segmentation with regression networks, yielding a highly-accurate "quantized regression" architecture. Our system, called DenseReg, allows us to estimate dense image-to-template correspondences in a fully convolutional manner. As such our network can provide useful correspondence information as a stand-alone system, while when used as an initialization for Statistical Deformable Models we obtain landmark localization results that largely outperform the current state-of-the-art on the challenging 300W benchmark. We thoroughly evaluate our method on a host of facial analysis tasks, and also demonstrate its use for other correspondence estimation tasks, such as modelling of the human ear. DenseReg code is made available at http://alpguler.com/DenseReg.html along with supplementary materials. version:1
arxiv-1612-01200 | Intra-day Activity Better Predicts Chronic Conditions | http://arxiv.org/abs/1612.01200 | id:1612.01200 author:Tom Quisel, David C. Kale, Luca Foschini category:stat.ML cs.LG  published:2016-12-04 summary:In this work we investigate intra-day patterns of activity on a population of 7,261 users of mobile health wearable devices and apps. We show that: (1) using intra-day step and sleep data recorded from passive trackers significantly improves classification performance on self-reported chronic conditions related to mental health and nervous system disorders, (2) Convolutional Neural Networks achieve top classification performance vs. baseline models when trained directly on multivariate time series of activity data, and (3) jointly predicting all condition classes via multi-task learning can be leveraged to extract features that generalize across data sets and achieve the highest classification performance. version:1
arxiv-1612-01197 | Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision (Short Version) | http://arxiv.org/abs/1612.01197 | id:1612.01197 author:Chen Liang, Jonathan Berant, Quoc Le, Kenneth D. Forbus, Ni Lao category:cs.CL cs.AI cs.LG  published:2016-12-04 summary:Extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory. Recent neural program induction approaches have attempted to address this problem, but are typically limited to differentiable memory, and consequently cannot scale beyond small synthetic tasks. In this work, we propose the Manager-Programmer-Computer framework, which integrates neural networks with non-differentiable memory to support abstract, scalable and precise operations through a friendly neural computer interface. Specifically, we introduce a Neural Symbolic Machine, which contains a sequence-to-sequence neural "programmer", and a non-differentiable "computer" that is a Lisp interpreter with code assist. To successfully apply REINFORCE for training, we augment it with approximate gold programs found by an iterative maximum likelihood training process. NSM is able to learn a semantic parser from weak supervision over a large knowledge base. It achieves new state-of-the-art performance on WebQuestionsSP, a challenging semantic parsing dataset, with weak supervision. Compared to previous approaches, NSM is end-to-end, therefore does not rely on feature engineering or domain specific knowledge. version:1
arxiv-1612-01194 | Online Localization and Prediction of Actions and Interactions | http://arxiv.org/abs/1612.01194 | id:1612.01194 author:Khurram Soomro, Haroon Idrees, Mubarak Shah category:cs.CV  published:2016-12-04 summary:This paper proposes a person-centric and online approach to the challenging problem of localization and prediction of actions and interactions in videos. Typically, localization or recognition is performed in an offline manner where all the frames in the video are processed together. This prevents timely localization and prediction of actions and interactions - an important consideration for many tasks including surveillance and human-machine interaction. In our approach, we estimate human poses at each frame and train discriminative appearance models using the superpixels inside the pose bounding boxes. Since the pose estimation per frame is inherently noisy, the conditional probability of pose hypotheses at current time-step (frame) is computed using pose estimations in the current frame and their consistency with poses in the previous frames. Next, both the superpixel and pose-based foreground likelihoods are used to infer the location of actors at each time through a Conditional Random. The issue of visual drift is handled by updating the appearance models, and refining poses using motion smoothness on joint locations, in an online manner. For online prediction of action (interaction) confidences, we propose an approach based on Structural SVM that operates on short video segments, and is trained with the objective that confidence of an action or interaction increases as time progresses. Lastly, we quantify the performance of both detection and prediction together, and analyze how the prediction accuracy varies as a time function of observed action (interaction) at different levels of detection performance. Our experiments on several datasets suggest that despite using only a few frames to localize actions (interactions) at each time instant, we are able to obtain competitive results to state-of-the-art offline methods. version:1
arxiv-1612-01175 | Who is Mistaken? | http://arxiv.org/abs/1612.01175 | id:1612.01175 author:Benjamin Eysenbach, Carl Vondrick, Antonio Torralba category:cs.CV  published:2016-12-04 summary:Recognizing when people have false beliefs is crucial for understanding their actions. We introduce the novel problem of identifying when people in abstract scenes have incorrect beliefs. We present a dataset of scenes, each visually depicting an 8-frame story in which a character has a mistaken belief. We then create a representation of characters' beliefs for two tasks in human action understanding: predicting who is mistaken, and when they are mistaken. Experiments suggest that our method for identifying mistaken characters performs better on these tasks than simple baselines. Diagnostics on our model suggest it learns important cues for recognizing mistaken beliefs, such as gaze. We believe models of people's beliefs will have many applications in action understanding, robotics, and healthcare. version:1
arxiv-1612-01158 | On the propriety of restricted Boltzmann machines | http://arxiv.org/abs/1612.01158 | id:1612.01158 author:Andee Kaplan, Daniel Nordman, Stephen Vardeman category:stat.ML cs.LG  published:2016-12-04 summary:A restricted Boltzmann machine (RBM) is an undirected graphical model constructed for discrete or continuous random variables, with two layers, one hidden and one visible, and no conditional dependency within a layer. In recent years, RBMs have risen to prominence due to their connection to deep learning. By treating a hidden layer of one RBM as the visible layer in a second RBM, a deep architecture can be created. RBMs are thought to thereby have the ability to encode very complex and rich structures in data, making them attractive for supervised learning. However, the generative behavior of RBMs is largely unexplored. In this paper, we discuss the relationship between RBM parameter specification in the binary case and the tendency to undesirable model properties such as degeneracy, instability and uninterpretability. We also describe the difficulties that arise in likelihood-based and Bayes fitting of such (highly flexible) models, especially as Gibbs sampling (quasi-Bayes) methods are often advocated for the RBM model structure. version:1
arxiv-1612-01131 | A method for the segmentation of images based on thresholding and applied to vesicular textures | http://arxiv.org/abs/1612.01131 | id:1612.01131 author:Amelia Carolina Sparavigna category:cs.CV  published:2016-12-04 summary:In image processing, a segmentation is a process of partitioning an image into multiple sets of pixels, that are defined as super-pixels. Each super-pixel is characterized by a label or parameter. Here, we are proposing a method for determining the super-pixels based on the thresholding of the image. This approach is quite useful for studying the images showing vesicular textures. version:1
arxiv-1612-01105 | Pyramid Scene Parsing Network | http://arxiv.org/abs/1612.01105 | id:1612.01105 author:Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, Jiaya Jia category:cs.CV  published:2016-12-04 summary:Scene parsing is challenging for unrestricted open vocabulary and diverse scenes. In this paper, we exploit the capability of global context information by different-region-based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network (PSPNet). Our global prior representation is effective to produce good quality results on the scene parsing task, while PSPNet provides a superior framework for pixel-level prediction tasks. The proposed approach achieves state-of-the-art performance on various datasets. It came first in ImageNet scene parsing challenge 2016, PASCAL VOC 2012 benchmark and Cityscapes benchmark. A single PSPNet yields new record of mIoU score as 85.4% on PASCAL VOC 2012 and 80.2% on Cityscapes. version:1
arxiv-1612-01103 | Robust nonparametric nearest neighbor random process clustering | http://arxiv.org/abs/1612.01103 | id:1612.01103 author:Michael Tschannen, Helmut Bölcskei category:cs.LG cs.IT math.IT stat.ML  published:2016-12-04 summary:We consider the problem of clustering noisy finite-length observations of stationary ergodic random processes according to their generative models without prior knowledge of the model statistics and the number of generative models. Two algorithms, both using the L1-distance between estimated power spectral densities (PSDs) as a measure of dissimilarity, are analyzed. The first one, termed nearest neighbor process clustering (NNPC) is new and relies on partitioning the nearest neighbor graph of the observations via spectral clustering. The second algorithm, simply referred to as k-means (KM), consists of a single k-means iteration with farthest point initialization and was considered before in the literature, albeit with a different dissimilarity measure and with asymptotic performance results only. We prove that both algorithms succeed with high probability in the presence of noise and missing entries, and even when the generative process PSDs overlap significantly, all provided that the observation length is sufficiently large. Our results quantify the tradeoff between the overlap of the generative process PSDs, the observation length, the fraction of missing entries, and the noise variance. Furthermore, we prove that treating the finite-length observations of stationary ergodic random processes as vectors in Euclidean space and clustering them using the thresholding-based subspace clustering (TSC) algorithm, the subspace clustering cousin of NNPC, results in performance strictly inferior to that of NNPC. We argue that the underlying cause is to be found in TSC employing spherical distance as dissimilarity measure, thereby ignoring the stationary process structure of the observations. Finally, we provide extensive numerical results for synthetic and real data and find that NNPC outperforms state-of-the-art algorithms in human motion sequence clustering. version:1
arxiv-1612-01095 | Representing Independence Models with Elementary Triplets | http://arxiv.org/abs/1612.01095 | id:1612.01095 author:Jose M. Peña category:stat.ML cs.AI  published:2016-12-04 summary:In an independence model, the triplets that represent conditional independences between singletons are called elementary. It is known that the elementary triplets represent the independence model unambiguously under some conditions. In this paper, we show how this representation helps performing some operations with independence models, such as finding the dominant triplets or a minimal independence map of an independence model, or computing the union or intersection of a pair of independence models, or performing causal reasoning. For the latter, we rephrase in terms of conditional independences some of Pearl's results for computing causal effects. version:1
arxiv-1612-01094 | Learning to superoptimize programs - Workshop Version | http://arxiv.org/abs/1612.01094 | id:1612.01094 author:Rudy Bunel, Alban Desmaison, M. Pawan Kumar, Philip H. S. Torr, Pushmeet Kohli category:cs.LG  published:2016-12-04 summary:Superoptimization requires the estimation of the best program for a given computational task. In order to deal with large programs, superoptimization techniques perform a stochastic search. This involves proposing a modification of the current program, which is accepted or rejected based on the improvement achieved. The state of the art method uses uniform proposal distributions, which fails to exploit the problem structure to the fullest. To alleviate this deficiency, we learn a proposal distribution over possible modifications using Reinforcement Learning. We provide convincing results on the superoptimization of "Hacker's Delight" programs. version:1
arxiv-1612-01086 | Deep Learning of Robotic Tasks using Strong and Weak Human Supervision | http://arxiv.org/abs/1612.01086 | id:1612.01086 author:Bar Hilleli, Ran El-Yaniv category:cs.AI cs.LG cs.RO  published:2016-12-04 summary:We propose a scheme for training a computerized agent to perform complex human tasks such as highway steering. The scheme resembles natural teaching-learning processes used by humans to teach themselves and each other complex tasks, and consists of the following four stages. In the first stage the agent learns by itself an informative low-dimensional representations of raw input signals in an unsupervised learning manner. In the second stage the agent learns to mimic the human instructor using supervised learning so as to reach a basic performance level; the third stage is devoted to learning an instantaneous reward model. Here, the (human) instructor observes (possibly in real time) the agent performing the task and provides reward feedback. During this stage the agent monitors both itself and the instructor feedback and learns a reward model using supervised learning. This stage terminates when the reward model is sufficiently accurate. In the last stage a reinforcement learning algorithm is deployed to optimize the agent policy. The guidance reward signal in the reinforcement learning algorithm relies on the previously learned reward model. As a proof of concept for the proposed scheme, we designed a system consisting of deep convolutional neural networks, and applied it to successfully learn a computerized agent capable of autonomous highway steering over the well-known racing game Assetto Corsa. version:1
arxiv-1612-01082 | Multi-Label Image Classification with Regional Latent Semantic Dependencies | http://arxiv.org/abs/1612.01082 | id:1612.01082 author:Junjie Zhang, Qi Wu, Chunhua Shen, Jian Zhang, Jianfeng Lu category:cs.CV  published:2016-12-04 summary:Recent state-of-the-art approaches of multi-label image classification exploit the label dependencies at the global level, largely improving the labeling ability. However, accurately predicting small objects and visual concepts is still challenging due to the limited discrimination of the global visual features. In this paper, we propose a Regional Latent Semantic Dependencies model (RLSD) to address this problem. The utilized model includes a fully convolutional localization architecture to localize the regions that may contain multiple highly-dependent labels. The localized regions are further sent to the recurrent neural networks (RNN) to characterize the latent semantic dependencies at the regional level. Experimental results on several benchmark datasets show that our proposed model achieves the best performance compared to the state-of-the-art models, especially for predicting small objects occurred in the images. In addition, we set up an upper bound model (RLSD+ft-RPN) using bounding box coordinates during training, the experimental results also show that our RLSD can approach the upper bound without using the bounding-box annotations, which is more realistic in the real world. version:1
arxiv-1612-01079 | End-to-end Learning of Driving Models from Large-scale Video Datasets | http://arxiv.org/abs/1612.01079 | id:1612.01079 author:Huazhe Xu, Yang Gao, Fisher Yu, Trevor Darrell category:cs.CV  published:2016-12-04 summary:Robust perception-action models should be learned from training data with diverse visual appearances and realistic behaviors, yet current approaches to deep visuomotor policy learning have been generally limited to in-situ models learned from a single vehicle or a simulation environment. We advocate learning a generic vehicle motion model from large scale crowd-sourced video data, and develop an end-to-end trainable architecture for learning to predict a distribution over future vehicle egomotion from instantaneous monocular camera observations and previous vehicle state. Our model incorporates a novel FCN-LSTM architecture, which can be learned from large-scale crowd-sourced vehicle action data, and leverages available scene segmentation side tasks to improve performance under a privileged learning paradigm. version:1
arxiv-1612-01078 | Enhancing Use Case Points Estimation Method Using Soft Computing Techniques | http://arxiv.org/abs/1612.01078 | id:1612.01078 author:Ali Bou Nassif, Luiz Fernando Capretz, Danny Ho category:cs.SE cs.AI cs.LG  published:2016-12-04 summary:Software estimation is a crucial task in software engineering. Software estimation encompasses cost, effort, schedule, and size. The importance of software estimation becomes critical in the early stages of the software life cycle when the details of software have not been revealed yet. Several commercial and non-commercial tools exist to estimate software in the early stages. Most software effort estimation methods require software size as one of the important metric inputs and consequently, software size estimation in the early stages becomes essential. One of the approaches that has been used for about two decades in the early size and effort estimation is called use case points. Use case points method relies on the use case diagram to estimate the size and effort of software projects. Although the use case points method has been widely used, it has some limitations that might adversely affect the accuracy of estimation. This paper presents some techniques using fuzzy logic and neural networks to improve the accuracy of the use case points method. Results showed that an improvement up to 22% can be obtained using the proposed approach. version:1
arxiv-1612-01075 | Joint Visual Denoising and Classification using Deep Learning | http://arxiv.org/abs/1612.01075 | id:1612.01075 author:Gang Chen, Yawei Li, Sargur N. Srihari category:cs.CV  published:2016-12-04 summary:Visual restoration and recognition are traditionally addressed in pipeline fashion, i.e. denoising followed by classification. Instead, observing correlations between the two tasks, for example clearer image will lead to better categorization and vice visa, we propose a joint framework for visual restoration and recognition for handwritten images, inspired by advances in deep autoencoder and multi-modality learning. Our model is a 3-pathway deep architecture with a hidden-layer representation which is shared by multi-inputs and outputs, and each branch can be composed of a multi-layer deep model. Thus, visual restoration and classification can be unified using shared representation via non-linear mapping, and model parameters can be learnt via backpropagation. Using MNIST and USPS data corrupted with structured noise, the proposed framework performs at least 20\% better in classification than separate pipelines, as well as clearer recovered images. The noise model and the reproducible source code is available at {\url{https://github.com/ganggit/jointmodel}}. version:1
arxiv-1612-01074 | Skin Cancer Detection and Tracking using Data Synthesis and Deep Learning | http://arxiv.org/abs/1612.01074 | id:1612.01074 author:Yunzhu Li, Andre Esteva, Brett Kuprel, Rob Novoa, Justin Ko, Sebastian Thrun category:cs.CV  published:2016-12-04 summary:Dense object detection and temporal tracking are needed across applications domains ranging from people-tracking to analysis of satellite imagery over time. The detection and tracking of malignant skin cancers and benign moles poses a particularly challenging problem due to the general uniformity of large skin patches, the fact that skin lesions vary little in their appearance, and the relatively small amount of data available. Here we introduce a novel data synthesis technique that merges images of individual skin lesions with full-body images and heavily augments them to generate significant amounts of data. We build a convolutional neural network (CNN) based system, trained on this synthetic data, and demonstrate superior performance to traditional detection and tracking techniques. Additionally, we compare our system to humans trained with simple criteria. Our system is intended for potential clinical use to augment the capabilities of healthcare providers. While domain-specific, we believe the methods invoked in this work will be useful in applying CNNs across domains that suffer from limited data availability. version:1
arxiv-1612-01072 | Word Recognition with Deep Conditional Random Fields | http://arxiv.org/abs/1612.01072 | id:1612.01072 author:Gang Chen, Yawei Li, Sargur N. Srihari category:cs.CV  published:2016-12-04 summary:Recognition of handwritten words continues to be an important problem in document analysis and recognition. Existing approaches extract hand-engineered features from word images--which can perform poorly with new data sets. Recently, deep learning has attracted great attention because of the ability to learn features from raw data. Moreover they have yielded state-of-the-art results in classification tasks including character recognition and scene recognition. On the other hand, word recognition is a sequential problem where we need to model the correlation between characters. In this paper, we propose using deep Conditional Random Fields (deep CRFs) for word recognition. Basically, we combine CRFs with deep learning, in which deep features are learned and sequences are labeled in a unified framework. We pre-train the deep structure with stacked restricted Boltzmann machines (RBMs) for feature learning and optimize the entire network with an online learning algorithm. The proposed model was evaluated on two datasets, and seen to perform significantly better than competitive baseline models. The source code is available at https://github.com/ganggit/deepCRFs. version:1
arxiv-1612-01064 | Trained Ternary Quantization | http://arxiv.org/abs/1612.01064 | id:1612.01064 author:Chenzhuo Zhu, Song Han, Huizi Mao, William J. Dally category:cs.LG  published:2016-12-04 summary:Deep neural networks are widely used in machine learning applications. However, the deployment of large neural networks models can be difficult to deploy on mobile devices with limited power budgets. To solve this problem, we propose Trained Ternary Quantization (TTQ), a method that can reduce the precision of weights in neural networks to ternary values. This method has very little accuracy degradation and can even improve the accuracy of some models (32, 44, 56-layer ResNet) on CIFAR-10 and AlexNet on ImageNet. And our AlexNet model is trained from scratch, which means it's as easy as to train normal full precision model. We highlight our trained quantization method that can learn both ternary values and ternary assignment. During inference, only ternary values (2-bit weights) and scaling factors are needed, therefore our models are nearly 16x smaller than full-precision models. Our ternary models can also be viewed as sparse binary weight networks, which can potentially be accelerated with custom circuit. Experiments on CIFAR-10 show that the ternary models obtained by trained quantization method outperform full-precision models of ResNet-32,44,56 by 0.04%, 0.16%, 0.36%, respectively. On ImageNet, our model outperforms full-precision AlexNet model by 0.3% of Top-1 accuracy and outperforms previous ternary models by 3%. version:1
arxiv-1612-01058 | Algorithmic Songwriting with ALYSIA | http://arxiv.org/abs/1612.01058 | id:1612.01058 author:Margareta Ackerman, David Loker category:cs.AI cs.LG cs.MM cs.SD  published:2016-12-04 summary:This paper introduces ALYSIA: Automated LYrical SongwrIting Application. ALYSIA is based on a machine learning model using Random Forests, and we discuss its success at pitch and rhythm prediction. Next, we show how ALYSIA was used to create original pop songs that were subsequently recorded and produced. Finally, we discuss our vision for the future of Automated Songwriting for both co-creative and autonomous systems. version:1
arxiv-1612-01055 | Modeling trajectories of mental health: challenges and opportunities | http://arxiv.org/abs/1612.01055 | id:1612.01055 author:Lauren Erdman, Ekansh Sharma, Eva Unternahrer, Shantala Hari Dass, Kieran ODonnell, Sara Mostafavi, Rachel Edgar, Michael Kobor, Helene Gaudreau, Michael Meaney, Anna Goldenberg category:stat.ML cs.LG stat.AP  published:2016-12-04 summary:More than two thirds of mental health problems have their onset during childhood or adolescence. Identifying children at risk for mental illness later in life and predicting the type of illness is not easy. We set out to develop a platform to define subtypes of childhood social-emotional development using longitudinal, multifactorial trait-based measures. Subtypes discovered through this study could ultimately advance psychiatric knowledge of the early behavioural signs of mental illness. To this extent we have examined two types of models: latent class mixture models and GP-based models. Our findings indicate that while GP models come close in accuracy of predicting future trajectories, LCMMs predict the trajectories as well in a fraction of the time. Unfortunately, neither of the models are currently accurate enough to lead to immediate clinical impact. The available data related to the development of childhood mental health is often sparse with only a few time points measured and require novel methods with improved efficiency and accuracy. version:1
arxiv-1612-01051 | SqueezeDet: Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving | http://arxiv.org/abs/1612.01051 | id:1612.01051 author:Bichen Wu, Forrest Iandola, Peter H. Jin, Kurt Keutzer category:cs.CV  published:2016-12-04 summary:Object detection is a crucial task for autonomous driving. In addition to requiring high accuracy to ensure safety, object detection for autonomous driving also requires real-time inference speed to guarantee prompt vehicle control, as well as small model size and energy efficiency to enable embedded system deployment. In this work, we propose SqueezeDet, a fully convolutional neural network for object detection that aims to simultaneously satisfy all of the above constraints. In our network we use convolutional layers not only to extract feature maps, but also as the output layer to compute bounding boxes and class probabilities. The detection pipeline of our model only contains a single forward pass of a neural network, thus it is extremely fast. Our model is fully-convolutional, which leads to small model size and better energy efficiency. Finally, our experiments show that our model is very accurate, achieving state-of-the-art accuracy on the KITTI benchmark. version:1
arxiv-1612-01039 | CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews | http://arxiv.org/abs/1612.01039 | id:1612.01039 author:Hu Xu, Sihong Xie, Lei Shu, Philip S. Yu category:cs.CL  published:2016-12-04 summary:Product reviews contain a lot of useful information about product features and customer opinions. One important product feature is the complementary entity (products) that may potentially work together with the reviewed product. Knowing complementary entities of the reviewed product is very important because customers want to buy compatible products and avoid incompatible ones. In this paper, we address the problem of Complementary Entity Recognition (CER). Since no existing method can solve this problem, we first propose a novel unsupervised method to utilize syntactic dependency paths to recognize complementary entities. Then we expand category-level domain knowledge about complementary entities using only a few general seed verbs on a large amount of unlabeled reviews. The domain knowledge helps the unsupervised method to adapt to different products and greatly improves the precision of the CER task. The advantage of the proposed method is that it does not require any labeled data for training. We conducted experiments on 7 popular products with about 1200 reviews in total to demonstrate that the proposed approach is effective. version:1
arxiv-1612-01035 | Semi-Automated Annotation of Discrete States in Large Video Datasets | http://arxiv.org/abs/1612.01035 | id:1612.01035 author:Lex Fridman, Bryan Reimer category:cs.CV  published:2016-12-03 summary:We propose a framework for semi-automated annotation of video frames where the video is of an object that at any point in time can be labeled as being in one of a finite number of discrete states. A Hidden Markov Model (HMM) is used to model (1) the behavior of the underlying object and (2) the noisy observation of its state through an image processing algorithm. The key insight of this approach is that the annotation of frame-by-frame video can be reduced from a problem of labeling every single image to a problem of detecting a transition between states of the underlying objected being recording on video. The performance of the framework is evaluated on a driver gaze classification dataset composed of 16,000,000 images that were fully annotated over 6,000 hours of direct manual annotation labor. On this dataset, we achieve a 13x reduction in manual annotation for an average accuracy of 99.1% and a 84x reduction for an average accuracy of 91.2%. version:1
arxiv-1612-01033 | Areas of Attention for Image Captioning | http://arxiv.org/abs/1612.01033 | id:1612.01033 author:Marco Pedersoli, Thomas Lucas, Cordelia Schmid, Jakob Verbeek category:cs.CV  published:2016-12-03 summary:We propose "Areas of Attention", a novel attention-based model for automatic image caption generation. Our approach models the interplay between the state of the RNN, image region descriptors and word embedding vectors by three pairwise interactions. It allows association of caption words with local visual appearances rather than with descriptors of the entire scene. This enables better generalization to complex scenes not seen during training. Our model is agnostic to the type of attention areas, and we instantiate it using regions based on CNN activation grids, object proposals, and spatial transformer networks. Our results show that all components of our model contribute to obtain state-of-the-art performance on the MSCOCO dataset. In addition, our results indicate that attention areas are correctly associated to meaningful latent semantic structure in the generated captions. version:1
arxiv-1612-01030 | Large scale modeling of antimicrobial resistance with interpretable classifiers | http://arxiv.org/abs/1612.01030 | id:1612.01030 author:Alexandre Drouin, Frédéric Raymond, Gaël Letarte St-Pierre, Mario Marchand, Jacques Corbeil, François Laviolette category:q-bio.GN cs.LG stat.ML  published:2016-12-03 summary:Antimicrobial resistance is an important public health concern that has implications in the practice of medicine worldwide. Accurately predicting resistance phenotypes from genome sequences shows great promise in promoting better use of antimicrobial agents, by determining which antibiotics are likely to be effective in specific clinical cases. In healthcare, this would allow for the design of treatment plans tailored for specific individuals, likely resulting in better clinical outcomes for patients with bacterial infections. In this work, we present the recent work of Drouin et al. (2016) on using Set Covering Machines to learn highly interpretable models of antibiotic resistance and complement it by providing a large scale application of their method to the entire PATRIC database. We report prediction results for 36 new datasets and present the Kover AMR platform, a new web-based tool allowing the visualization and interpretation of the generated models. version:1
arxiv-1612-01022 | Short-term traffic flow forecasting with spatial-temporal correlation in a hybrid deep learning framework | http://arxiv.org/abs/1612.01022 | id:1612.01022 author:Yuankai Wu, Huachun Tan category:cs.CV  published:2016-12-03 summary:Deep learning approaches have reached a celebrity status in artificial intelligence field, its success have mostly relied on Convolutional Networks (CNN) and Recurrent Networks. By exploiting fundamental spatial properties of images and videos, the CNN always achieves dominant performance on visual tasks. And the Recurrent Networks (RNN) especially long short-term memory methods (LSTM) can successfully characterize the temporal correlation, thus exhibits superior capability for time series tasks. Traffic flow data have plentiful characteristics on both time and space domain. However, applications of CNN and LSTM approaches on traffic flow are limited. In this paper, we propose a novel deep architecture combined CNN and LSTM to forecast future traffic flow (CLTFP). An 1-dimension CNN is exploited to capture spatial features of traffic flow, and two LSTMs are utilized to mine the short-term variability and periodicities of traffic flow. Given those meaningful features, the feature-level fusion is performed to achieve short-term forecasting. The proposed CLTFP is compared with other popular forecasting methods on an open datasets. Experimental results indicate that the CLTFP has considerable advantages in traffic flow forecasting. in additional, the proposed CLTFP is analyzed from the view of Granger Causality, and several interesting properties of CLTFP are discovered and discussed . version:1
arxiv-1612-01020 | Transformation Function Based Methods for Model Shift | http://arxiv.org/abs/1612.01020 | id:1612.01020 author:Simon Shaolei Du, Jayanth Koushik, Aarti Singh, Barnabas Poczos category:stat.ML cs.LG  published:2016-12-03 summary:Transfer learning techniques are often used when one tries to adapt a model learned from a source domain with abundant labeled samples to the target domain with limited labeled samples. In this paper, we consider the regression problem under model shift condition, i.e., regression functions are different but related in the source and target domains. We approach this problem through the use of transformation functions which characterize the relation between the source and the target domain. These transformation functions are able to transform the original problem of learning the complicated regression function of target domain into a problem of learning a simple auxiliary function. This transformation function based technique includes some previous works as special cases, but the class we propose is significantly more general. In this work we consider two widely used non-parametric estimators, Kernel Smoothing (KS) and Kernel Ridge Regression (KRR) for this setting and show improved statistical rates for excess risk than non-transfer learning. Through an $\epsilon$-cover technique, we show that we can find the best transformation function a function class. Lastly, experiments on synthesized, robotics and neural imaging data demonstrate the effectiveness of our framework. version:1
arxiv-1612-01006 | A Non-Local Means Approach for Gaussian Noise Removal from Images using a Modified Weighting Kernel | http://arxiv.org/abs/1612.01006 | id:1612.01006 author:Mojtaba Kazemi, Ehsan Mohammadi. P, Parichehr shahidi sadeghi, Mohamad B. Menhaj category:cs.CV  published:2016-12-03 summary:Gaussian noise removal is an interesting area in digital image processing not only to improve the visual quality, but for its impact on other post-processing algorithms like image registration or segmentation. Many presented state-of-the-art denoising methods are based on the self-similarity or patch-based image processing. Specifically, Non-Local Means (NLM) as a patch-based filter has gained increasing attention in recent years. Essentially, this filter tends to obtain the noise-less signal value by computing the Gaussian-weighted Euclidean distance between the patch under-processing and other patches inside the image. However, the NLM filter is sensitive to the outliers (pixels that their intensity values are far away from other pixels) inside the patch, meaning that the pixels with the symmetric locations in the patch are assigned the same weight. This can lead to sub-optimal denoising performance when the destructive nature of noise generates some outliers inside patches. In this paper, we propose a new weighting approach to modify the Gaussian kernel of the NLM filter. Our approach employs the geometric distance between image intensities to come up with new weights for each pixel of a patch, lowering the impact of outliers on the denoising performance. Experiments on a set of standard images and different noise levels show that our proposed method outperforms the other compared denoising filters. version:1
arxiv-1612-00992 | Mining Spatio-temporal Data on Industrialization from Historical Registries | http://arxiv.org/abs/1612.00992 | id:1612.00992 author:David Berenbaum, Dwyer Deighan, Thomas Marlow, Ashley Lee, Scott Frickel, Mark Howison category:cs.CV cs.IR  published:2016-12-03 summary:Despite the growing availability of big data in many fields, historical data on socioevironmental phenomena are often not available due to a lack of automated and scalable approaches for collecting, digitizing, and assembling them. We have developed a data-mining method for extracting tabulated, geocoded data from printed directories. While scanning and optical character recognition (OCR) can digitize printed text, these methods alone do not capture the structure of the underlying data. Our pipeline integrates both page layout analysis and OCR to extract tabular, geocoded data from structured text. We demonstrate the utility of this method by applying it to scanned manufacturing registries from Rhode Island that record 41 years of industrial land use. The resulting spatio-temporal data can be used for socioenvironmental analyses of industrialization at a resolution that was not previously possible. In particular, we find strong evidence for the dispersion of manufacturing from the urban core of Providence, the state's capital, along the Interstate 95 corridor to the north and south. version:1
arxiv-1612-00991 | Ensembles of Generative Adversarial Networks | http://arxiv.org/abs/1612.00991 | id:1612.00991 author:Yaxing Wang, Lichao Zhang, Joost van de Weijer category:cs.CV  published:2016-12-03 summary:Ensembles are a popular way to improve results of discriminative CNNs. The combination of several networks trained starting from different initializations improves results significantly. In this paper we investigate the usage of ensembles of GANs. The specific nature of GANs opens up several new ways to construct ensembles. The first one is based on the fact that in the minimax game which is played to optimize the GAN objective the generator network keeps on changing even after the network can be considered optimal. As such ensembles of GANs can be constructed based on the same network initialization but just taking models which have different amount of iterations. These so-called self ensembles are much faster to train than traditional ensembles. The second method, called cascade GANs, redirects part of the training data which is badly modeled by the first GAN to another GAN. In experiments on the CIFAR10 dataset we show that ensembles of GANs obtain model probability distributions which better model the data distribution. In addition, we show that these improved results can be obtained at little additional computational cost. version:1
arxiv-1612-00986 | Deep Learning with Energy-efficient Binary Gradient Cameras | http://arxiv.org/abs/1612.00986 | id:1612.00986 author:Suren Jayasuriya, Orazio Gallo, Jinwei Gu, Jan Kautz category:cs.CV  published:2016-12-03 summary:Power consumption is a critical factor for the deployment of embedded computer vision systems. We explore the use of computational cameras that directly output binary gradient images to reduce the portion of the power consumption allocated to image sensing. We survey the accuracy of binary gradient cameras on a number of computer vision tasks using deep learning. These include object recognition, head pose regression, face detection, and gesture recognition. We show that, for certain applications, accuracy can be on par or even better than what can be achieved on traditional images. We are also the first to recover intensity information from binary spatial gradient images--useful for applications with a human observer in the loop, such as surveillance. Our results, which we validate with a prototype binary gradient camera, point to the potential of gradient-based computer vision systems. version:1
arxiv-1612-00984 | Estimating latent feature-feature interactions in large feature-rich graphs | http://arxiv.org/abs/1612.00984 | id:1612.00984 author:Corrado Monti, Paolo Boldi category:cs.SI cs.LG stat.ML  published:2016-12-03 summary:Real-world complex networks describe connections between objects; in reality, those objects are often endowed with some kind of features. How does the presence or absence of such features interplay with the network link structure? Although the situation here described is truly ubiquitous, there is a limited body of research dealing with large graphs of this kind. Many previous works considered homophily as the only possible transmission mechanism translating node features into links. Other authors, instead, developed more sophisticated models, that are able to handle complex feature interactions, but are unfit to scale to very large networks. We expand on the MGJ model, where interactions between pairs of features can foster or discourage link formation. In this work, we will investigate how to estimate the latent feature-feature interactions in this model. We shall propose two solutions: the first one assumes feature independence and it is essentially based on Naive Bayes; the second one, which relaxes the independence assumption assumption, is based on perceptrons. In fact, we show it is possible to cast the model equation in order to see it as the prediction rule of a perceptron. We analyze how classical results for the perceptrons can be interpreted in this context; then, we define a fast and simple perceptron-like algorithm for this task, which can process $10^8$ links in minutes. We then compare these two techniques, first with synthetic datasets that follows our model, gaining evidence that the Naive independence assumptions are detrimental in practice. Secondly, we consider a real, large-scale citation network where each node (i.e., paper) can be described by different types of characteristics; there, our algorithm can assess how well each set of features can explain the links, and thus finding meaningful latent feature-feature interactions. version:1
arxiv-1612-00983 | Food Image Recognition by Using Convolutional Neural Networks (CNNs) | http://arxiv.org/abs/1612.00983 | id:1612.00983 author:Yuzhen Lu category:cs.CV  published:2016-12-03 summary:Food image recognition is one of the promising applications of visual object recognition in computer vision. In this study, a small-scale dataset consisting of 5822 images of ten categories and a five-layer CNN was constructed to recognize these images. The bag-of-features (BoF) model coupled with support vector machine was first tested as comparison, resulting in an overall accuracy of 56%, while the CNN performed much better with an overall accuracy of 74%. Data expansion techniques were applied to increase the size of training images, which achieved a significantly improved accuracy of more than 90% and prevent the overfitting issue that occurred to the CNN without using data expansion. Further improvement is within reach by collecting more images and optimizing the network architecture and relevant hyper-parameters. version:1
arxiv-1612-00979 | Semi-supervised learning of deep metrics for stereo reconstruction | http://arxiv.org/abs/1612.00979 | id:1612.00979 author:Stepan Tulyakov, Anton Ivanov, Francois Fleuret category:cs.CV cs.NE  published:2016-12-03 summary:Deep-learning metrics have recently demonstrated extremely good performance to match image patches for stereo reconstruction. However, training such metrics requires large amount of labeled stereo images, which can be difficult or costly to collect for certain applications. The main contribution of our work is a new semi-supervised method for learning deep metrics from unlabeled stereo images, given coarse information about the scenes and the optical system. Our method alternatively optimizes the metric with a standard stochastic gradient descent, and applies stereo constraints to regularize its prediction. Experiments on reference data-sets show that, for a given network architecture, training with this new method without ground-truth produces a metric with performance as good as state-of-the-art baselines trained with the said ground-truth. This work has three practical implications. Firstly, it helps to overcome limitations of training sets, in particular noisy ground truth. Secondly it allows to use much more training data during learning. Thirdly, it allows to tune deep metric for a particular stereo system, even if ground truth is not available. version:1
arxiv-1612-00969 | Unit Dependency Graph and its Application to Arithmetic Word Problem Solving | http://arxiv.org/abs/1612.00969 | id:1612.00969 author:Subhro Roy, Dan Roth category:cs.CL  published:2016-12-03 summary:Math word problems provide a natural abstraction to a range of natural language understanding problems that involve reasoning about quantities, such as interpreting election results, news about casualties, and the financial section of a newspaper. Units associated with the quantities often provide information that is essential to support this reasoning. This paper proposes a principled way to capture and reason about units and shows how it can benefit an arithmetic word problem solver. This paper presents the concept of Unit Dependency Graphs (UDGs), which provides a compact representation of the dependencies between units of numbers mentioned in a given problem. Inducing the UDG alleviates the brittleness of the unit extraction system and allows for a natural way to leverage domain knowledge about unit compatibility, for word problem solving. We introduce a decomposed model for inducing UDGs with minimal additional annotations, and use it to augment the expressions used in the arithmetic word problem solver of (Roy and Roth 2015) via a constrained inference framework. We show that introduction of UDGs reduces the error of the solver by over 10 %, surpassing all existing systems for solving arithmetic word problems. In addition, it also makes the system more robust to adaptation to new vocabulary and equation forms . version:1
arxiv-1612-00962 | Positive blood culture detection in time series data using a BiLSTM network | http://arxiv.org/abs/1612.00962 | id:1612.00962 author:Leen De Baets, Joeri Ruyssinck, Thomas Peiffer, Johan Decruyenaere, Filip De Turck, Femke Ongenae, Tom Dhaene category:cs.LG cs.NE q-bio.QM stat.ML  published:2016-12-03 summary:The presence of bacteria or fungi in the bloodstream of patients is abnormal and can lead to life-threatening conditions. A computational model based on a bidirectional long short-term memory artificial neural network, is explored to assist doctors in the intensive care unit to predict whether examination of blood cultures of patients will return positive. As input it uses nine monitored clinical parameters, presented as time series data, collected from 2177 ICU admissions at the Ghent University Hospital. Our main goal is to determine if general machine learning methods and more specific, temporal models, can be used to create an early detection system. This preliminary research obtains an area of 71.95% under the precision recall curve, proving the potential of temporal neural networks in this context. version:1
arxiv-1612-00951 | On the Pitfalls of Nested Monte Carlo | http://arxiv.org/abs/1612.00951 | id:1612.00951 author:Tom Rainforth, Robert Cornish, Hongseok Yang, Frank Wood category:stat.CO stat.ME stat.ML  published:2016-12-03 summary:There is an increasing interest in estimating expectations outside of the classical inference framework, such as for models expressed as probabilistic programs. Many of these contexts call for some form of nested inference to be applied. In this paper, we analyse the behaviour of nested Monte Carlo (NMC) schemes, for which classical convergence proofs are insufficient. We give conditions under which NMC will converge, establish a rate of convergence, and provide empirical data that suggests that this rate is observable in practice. Finally, we prove that general-purpose nested inference schemes are inherently biased. Our results serve to warn of the dangers associated with naive composition of inference and models. version:1
arxiv-1612-00086 | Semi-supervised Kernel Metric Learning Using Relative Comparisons | http://arxiv.org/abs/1612.00086 | id:1612.00086 author:Ehsan Amid, Aristides Gionis, Antti Ukkonen category:cs.LG stat.ML  published:2016-12-01 summary:We consider the problem of metric learning subject to a set of constraints on relative-distance comparisons between the data items. Such constraints are meant to reflect side-information that is not expressed directly in the feature vectors of the data items. The relative-distance constraints used in this work are particularly effective in expressing structures at finer level of detail than must-link (ML) and cannot-link (CL) constraints, which are most commonly used for semi-supervised clustering. Relative-distance constraints are thus useful in settings where providing an ML or a CL constraint is difficult because the granularity of the true clustering is unknown. Our main contribution is an efficient algorithm for learning a kernel matrix using the log determinant divergence --- a variant of the Bregman divergence --- subject to a set of relative-distance constraints. The learned kernel matrix can then be employed by many different kernel methods in a wide range of applications. In our experimental evaluations, we consider a semi-supervised clustering setting and show empirically that kernels found by our algorithm yield clusterings of higher quality than existing approaches that either use ML/CL constraints or a different means to implement the supervision using relative comparisons. version:2
arxiv-1612-00944 | Using Discourse Signals for Robust Instructor Intervention Prediction | http://arxiv.org/abs/1612.00944 | id:1612.00944 author:Muthu Kumar Chandrasekaran, Carrie Demmans Epp, Min-Yen Kan, Diane Litman category:cs.AI cs.CL cs.CY I.2.7; K.3.1  published:2016-12-03 summary:We tackle the prediction of instructor intervention in student posts from discussion forums in Massive Open Online Courses (MOOCs). Our key finding is that using automatically obtained discourse relations improves the prediction of when instructors intervene in student discussions, when compared with a state-of-the-art, feature-rich baseline. Our supervised classifier makes use of an automatic discourse parser which outputs Penn Discourse Treebank (PDTB) tags that represent in-post discourse features. We show PDTB relation-based features increase the robustness of the classifier and complement baseline features in recalling more diverse instructor intervention patterns. In comprehensive experiments over 14 MOOC offerings from several disciplines, the PDTB discourse features improve performance on average. The resultant models are less dependent on domain-specific vocabulary, allowing them to better generalize to new courses. version:1
arxiv-1612-00940 | End-to-end learning of brain tissue segmentation from imperfect labeling | http://arxiv.org/abs/1612.00940 | id:1612.00940 author:Alex Fedorov, Jeremy Johnson, Eswar Damaraju, Alexei Ozerin, Vince Calhoun, Sergey Plis category:cs.CV  published:2016-12-03 summary:Segmenting a structural magnetic resonance imaging (MRI) scan is an important pre-processing step for analytic procedures and subsequent inferences about longitudinal tissue changes. Manual segmentation defines the current gold standard in quality but is prohibitively expensive. Automatic approaches are computationally intensive, incredibly slow at scale, and error prone due to usually involving many potentially faulty intermediate steps. In order to streamline the segmentation, we introduce a deep learning model that is based on volumetric dilated convolutions, subsequently reducing both processing time and errors. Compared to its competitors, the model has a reduced set of parameters and thus is easier to train and much faster to execute. The contrast in performance between the dilated network and its competitors becomes obvious when both are tested on a large dataset of unprocessed human brain volumes. The dilated network consistently outperforms not only another state-of-the-art deep learning approach, the up convolutional network, but also the ground truth on which it was trained. Not only can the incredible speed of our model make large scale analyses much easier but we also believe it has great potential in a clinical setting where, with little to no substantial delay, a patient and provider can go over test results. version:1
arxiv-1612-00913 | End-to-End Joint Learning of Natural Language Understanding and Dialogue Manager | http://arxiv.org/abs/1612.00913 | id:1612.00913 author:Xuesong Yang, Yun-Nung Chen, Dilek Hakkani-Tur, Paul Crook, Xiujun Li, Jianfeng Gao, Li Deng category:cs.CL cs.LG  published:2016-12-03 summary:Natural language understanding and dialogue policy learning are both essential in conversational systems that predict the next system actions in response to a current user utterance. Conventional approaches aggregate separate models of natural language understanding (NLU) and system action prediction (SAP) as a pipeline that is sensitive to noisy outputs of error-prone NLU. To address the issues, we propose an end-to-end deep recurrent neural network with limited contextual dialogue memory by jointly training NLU and SAP on DSTC4 multi-domain human-human dialogues. Experiments show that our proposed model significantly outperforms the state-of-the-art pipeline models for both NLU and SAP, which indicates that our joint model is capable of mitigating the affects of noisy NLU outputs, and NLU model can be refined by error flows backpropagating from the extra supervised signals of system actions. version:1
arxiv-1612-00901 | Commonly Uncommon: Semantic Sparsity in Situation Recognition | http://arxiv.org/abs/1612.00901 | id:1612.00901 author:Mark Yatskar, Vicente Ordonez, Luke Zettlemoyer, Ali Farhadi category:cs.CV cs.AI  published:2016-12-03 summary:Semantic sparsity is a common challenge in structured visual classification problems; when the output space is complex, the vast majority of the possible predictions are rarely, if ever, seen in the training set. This paper studies semantic sparsity in situation recognition, the task of producing structured summaries of what is happening in images, including activities, objects and the roles objects play within the activity. For this problem, we find empirically that most object-role combinations are rare, and current state-of-the-art models significantly underperform in this sparse data regime. We avoid many such errors by (1) introducing a novel tensor composition function that learns to share examples across role-noun combinations and (2) semantically augmenting our training data with automatically gathered examples of rarely observed outputs using web data. When integrated within a complete CRF-based structured prediction model, the tensor-based approach outperforms existing state of the art by a relative improvement of 2.11% and 4.40% on top-5 verb and noun-role accuracy, respectively. Adding 5 million images with our semantic augmentation techniques gives further relative improvements of 6.23% and 9.57% on top-5 verb and noun-role accuracy. version:1
arxiv-1612-00891 | Parameter Compression of Recurrent Neural Networks and Degredation of Short-term Memory | http://arxiv.org/abs/1612.00891 | id:1612.00891 author:Jonathan A. Cox category:cs.CV cs.LG cs.NE  published:2016-12-02 summary:The significant computational costs of deploying neural networks in large-scale or resource constrained environments, such as data centers and mobile devices, has spurred interest in model compression, which can achieve a reduction in both arithmetic operations and storage memory. Several techniques have been proposed for reducing or compressing the parameters for feed-forward and convolutional neural networks, but less is understood about the effect of parameter compression on recurrent neural networks (RNN). In particular, the extent to which the recurrent parameters can be compressed and the impact on short-term memory performance, is not well understood. In this paper, we study the effect of complexity reduction, through singular value decomposition rank reduction, on RNN and minimal gated recurrent unit (MGRU) networks for several tasks. We show that considerable rank reduction is possible when compressing recurrent weights, even without fine tuning. Furthermore, we propose a perturbation model for the effect of general perturbations, such as a compression, on the recurrent parameters of RNNs. The model is tested against a noiseless memorization experiment that elucidates the short-term memory performance. In this way, we demonstrate that the effect of compression of recurrent parameters is dependent on the degree of temporal coherence present in the data and task. This work can guide on-the-fly RNN compression for novel environments or tasks, and provides insight for applying RNN compression in low-power devices, such as hearing aids. version:1
arxiv-1612-00882 | Success Probability of Exploration: a Concrete Analysis of Learning Efficiency | http://arxiv.org/abs/1612.00882 | id:1612.00882 author:Liangpeng Zhang, Ke Tang, Xin Yao category:cs.LG  published:2016-12-02 summary:Exploration has been a crucial part of reinforcement learning, yet several important questions concerning exploration efficiency are still not answered satisfactorily by existing analytical frameworks. These questions include exploration parameter setting, situation analysis, and hardness of MDPs, all of which are unavoidable for practitioners. To bridge the gap between the theory and practice, we propose a new analytical framework called the success probability of exploration. We show that those important questions of exploration above can all be answered under our framework, and the answers provided by our framework meet the needs of practitioners better than the existing ones. More importantly, we introduce a concrete and practical approach to evaluating the success probabilities in certain MDPs without the need of actually running the learning algorithm. We then provide empirical results to verify our approach, and demonstrate how the success probability of exploration can be used to analyse and predict the behaviours and possible outcomes of exploration, which are the keys to the answer of the important questions of exploration. version:1
arxiv-1612-00881 | Procedural Generation of Videos to Train Deep Action Recognition Networks | http://arxiv.org/abs/1612.00881 | id:1612.00881 author:César Roberto de Souza, Adrien Gaidon, Yohann Cabon, Antonio Manuel López Peña category:cs.CV  published:2016-12-02 summary:Deep learning for human action recognition in videos is making significant progress, but is slowed down by its dependency on expensive manual labeling of large video collections. In this work, we investigate the generation of synthetic training data for action recognition, as it has recently shown promising results for a variety of other computer vision tasks. We propose an interpretable parametric generative model of human action videos that relies on procedural generation and other computer graphics techniques of modern game engines.We generate a diverse, realistic, and physically plausible dataset of human action videos, called PHAV for "Procedural Human Action Videos". It contains a total of 37,536 videos, more than 1,000 examples for each action of 35 categories. Our approach is not limited to existing motion capture sequences, and we procedurally define 14 synthetic actions. We introduce a deep multi-task representation learning architecture to mix synthetic and real videos, even if the action categories differ. Our experiments on the UCF101 and HMDB51 benchmarks suggest that combining our large set of synthetic videos with small real-world datasets can boost recognition performance, significantly outperforming fine-tuning state-of-the-art unsupervised generative models of videos. version:1
arxiv-1612-00866 | Creating a Real-Time, Reproducible Event Dataset | http://arxiv.org/abs/1612.00866 | id:1612.00866 author:John Beieler category:cs.CL  published:2016-12-02 summary:The generation of political event data has remained much the same since the mid-1990s, both in terms of data acquisition and the process of coding text into data. Since the 1990s, however, there have been significant improvements in open-source natural language processing software and in the availability of digitized news content. This paper presents a new, next-generation event dataset, named Phoenix, that builds from these and other advances. This dataset includes improvements in the underlying news collection process and event coding software, along with the creation of a general processing pipeline necessary to produce daily-updated data. This paper provides a face validity checks by briefly examining the data for the conflict in Syria, and a comparison between Phoenix and the Integrated Crisis Early Warning System data. version:1
arxiv-1612-00837 | Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering | http://arxiv.org/abs/1612.00837 | id:1612.00837 author:Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, Devi Parikh category:cs.CV cs.AI cs.CL cs.LG  published:2016-12-02 summary:Problems at the intersection of vision and language are of significant importance both as challenging research questions and for the rich set of applications they enable. However, inherent structure in our world and bias in our language tend to be a simpler signal for learning than visual modalities, resulting in models that ignore visual information, leading to an inflated sense of their capability. We propose to counter these language priors for the task of Visual Question Answering (VQA) and make vision (the V in VQA) matter! Specifically, we balance the popular VQA dataset (Antol et al., ICCV 2015) by collecting complementary images such that every question in our balanced dataset is associated with not just a single image, but rather a pair of similar images that result in two different answers to the question. Our dataset is by construction more balanced than the original VQA dataset and has approximately twice the number of image-question pairs. Our complete balanced dataset will be publicly released as part of the 2nd iteration of the Visual Question Answering Challenge (VQA v2.0). We further benchmark a number of state-of-art VQA models on our balanced dataset. All models perform significantly worse on our balanced dataset, suggesting that these models have indeed learned to exploit language priors. This finding provides the first concrete empirical evidence for what seems to be a qualitative sense among practitioners. Finally, our data collection protocol for identifying complementary images enables us to develop a novel interpretable model, which in addition to providing an answer to the given (image, question) pair also provides a counter-example based explanation - specifically, it identifies an image that is similar to the original image, but it believes has a different answer to the same question. This can help in building trust for machines among their users. version:1
arxiv-1612-00827 | Learning Operations on a Stack with Neural Turing Machines | http://arxiv.org/abs/1612.00827 | id:1612.00827 author:Tristan Deleu, Joseph Dureau category:cs.LG  published:2016-12-02 summary:Multiple extensions of Recurrent Neural Networks (RNNs) have been proposed recently to address the difficulty of storing information over long time periods. In this paper, we experiment with the capacity of Neural Turing Machines (NTMs) to deal with these long-term dependencies on well-balanced strings of parentheses. We show that not only does the NTM emulate a stack with its heads and learn an algorithm to recognize such words, but it is also capable of strongly generalizing to much longer sequences. version:1
arxiv-1612-00824 | Learning with Hierarchical Gaussian Kernels | http://arxiv.org/abs/1612.00824 | id:1612.00824 author:Ingo Steinwart, Philipp Thomann, Nico Schmid category:stat.ML cs.LG  published:2016-12-02 summary:We investigate iterated compositions of weighted sums of Gaussian kernels and provide an interpretation of the construction that shows some similarities with the architectures of deep neural networks. On the theoretical side, we show that these kernels are universal and that SVMs using these kernels are universally consistent. We further describe a parameter optimization method for the kernel parameters and empirically compare this method to SVMs, random forests, a multiple kernel learning approach, and to some deep neural networks. version:1
arxiv-1612-00817 | Summary - TerpreT: A Probabilistic Programming Language for Program Induction | http://arxiv.org/abs/1612.00817 | id:1612.00817 author:Alexander L. Gaunt, Marc Brockschmidt, Rishabh Singh, Nate Kushman, Pushmeet Kohli, Jonathan Taylor, Daniel Tarlow category:cs.LG cs.AI cs.NE  published:2016-12-02 summary:We study machine learning formulations of inductive program synthesis; that is, given input-output examples, synthesize source code that maps inputs to corresponding outputs. Our key contribution is TerpreT, a domain-specific language for expressing program synthesis problems. A TerpreT model is composed of a specification of a program representation and an interpreter that describes how programs map inputs to outputs. The inference task is to observe a set of input-output examples and infer the underlying program. From a TerpreT model we automatically perform inference using four different back-ends: gradient descent (thus each TerpreT model can be seen as defining a differentiable interpreter), linear program (LP) relaxations for graphical models, discrete satisfiability solving, and the Sketch program synthesis system. TerpreT has two main benefits. First, it enables rapid exploration of a range of domains, program representations, and interpreter models. Second, it separates the model specification from the inference algorithm, allowing proper comparisons between different approaches to inference. We illustrate the value of TerpreT by developing several interpreter models and performing an extensive empirical comparison between alternative inference algorithms on a variety of program models. To our knowledge, this is the first work to compare gradient-based search over program space to traditional search-based alternatives. Our key empirical finding is that constraint solvers dominate the gradient descent and LP-based formulations. This is a workshop summary of a longer report at arXiv:1608.04428 version:1
arxiv-1612-00804 | Restricted Strong Convexity Implies Weak Submodularity | http://arxiv.org/abs/1612.00804 | id:1612.00804 author:Ethan R. Elenberg, Rajiv Khanna, Alexandros G. Dimakis, Sahand Negahban category:stat.ML cs.IT cs.LG math.IT  published:2016-12-02 summary:We connect high-dimensional subset selection and submodular maximization. Our results extend the work of Das and Kempe (2011) from the setting of linear regression to arbitrary objective functions. For greedy feature selection, this connection allows us to obtain strong multiplicative performance bounds on several methods without statistical modeling assumptions. We also derive recovery guarantees of this form under standard assumptions. Our work shows that greedy algorithms perform within a constant factor from the best possible subset-selection solution for a broad class of general objective functions. Our methods allow a direct control over the number of obtained features as opposed to regularization parameters that only implicitly control sparsity. Our proof technique uses the concept of weak submodularity initially defined by Das and Kempe. We draw a connection between convex analysis and submodular set function theory which may be of independent interest for other statistical learning applications that have combinatorial structure. version:1
arxiv-1612-00799 | A Benchmark for Endoluminal Scene Segmentation of Colonoscopy Images | http://arxiv.org/abs/1612.00799 | id:1612.00799 author:David Vázquez, Jorge Bernal, F. Javier Sánchez, Gloria Fernández-Esparrach, Antonio M. López, Adriana Romero, Michal Drozdzal, Aaron Courville category:cs.CV  published:2016-12-02 summary:Colorectal cancer (CRC) is the third cause of cancer death worldwide. Currently, the standard approach to reduce CRC-related mortality is to perform regular screening in search for polyps and colonoscopy is the screening tool of choice. The main limitations of this screening procedure are polyp miss-rate and inability to perform visual assessment of polyp malignancy. These drawbacks can be reduced by designing Decision Support Systems (DSS) aiming to help clinicians in the different stages of the procedure by providing endoluminal scene segmentation. Thus, in this paper, we introduce an extended benchmark of colonoscopy image, with the hope of establishing a new strong benchmark for colonoscopy image analysis research. We provide new baselines on this dataset by training standard fully convolutional networks (FCN) for semantic segmentation and significantly outperforming, without any further post-processing, prior results in endoluminal scene segmentation. version:1
arxiv-1612-00796 | Overcoming catastrophic forgetting in neural networks | http://arxiv.org/abs/1612.00796 | id:1612.00796 author:James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, Raia Hadsell category:cs.LG cs.AI stat.ML  published:2016-12-02 summary:The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari 2600 games sequentially. version:1
arxiv-1612-00108 | When to Reset Your Keys: Optimal Timing of Security Updates via Learning | http://arxiv.org/abs/1612.00108 | id:1612.00108 author:Zizhan Zheng, Ness B. Shroff, Prasant Mohapatra category:cs.LG cs.AI cs.CR  published:2016-12-01 summary:Cybersecurity is increasingly threatened by advanced and persistent attacks. As these attacks are often designed to disable a system (or a critical resource, e.g., a user account) repeatedly, it is crucial for the defender to keep updating its security measures to strike a balance between the risk of being compromised and the cost of security updates. Moreover, these decisions often need to be made with limited and delayed feedback due to the stealthy nature of advanced attacks. In addition to targeted attacks, such an optimal timing policy under incomplete information has broad applications in cybersecurity. Examples include key rotation, password change, application of patches, and virtual machine refreshing. However, rigorous studies of optimal timing are rare. Further, existing solutions typically rely on a pre-defined attack model that is known to the defender, which is often not the case in practice. In this work, we make an initial effort towards achieving optimal timing of security updates in the face of unknown stealthy attacks. We consider a variant of the influential FlipIt game model with asymmetric feedback and unknown attack time distribution, which provides a general model to consecutive security updates. The defender's problem is then modeled as a time associative bandit problem with dependent arms. We derive upper confidence bound based learning policies that achieve low regret compared with optimal periodic defense strategies that can only be derived when attack time distributions are known. version:2
arxiv-1612-00775 | A simple squared-error reformulation for ordinal classification | http://arxiv.org/abs/1612.00775 | id:1612.00775 author:Christopher Beckham, Christopher Pal category:stat.ML cs.LG  published:2016-12-02 summary:In this paper, we explore ordinal classification (in the context of deep neural networks) through a simple modification of the squared error loss which not only allows it to not only be sensitive to class ordering, but also allows the possibility of having a discrete probability distribution over the classes. Our formulation is based on the use of a softmax hidden layer, which has received relatively little attention in the literature. We empirically evaluate its performance on the Kaggle diabetic retinopathy dataset, an ordinal and high-resolution dataset and show that it outperforms all of the baselines employed. version:1
arxiv-1612-00745 | Cognitive Deep Machine Can Train Itself | http://arxiv.org/abs/1612.00745 | id:1612.00745 author:András Lőrincz, Máté Csákvári, Áron Fóthi, Zoltán Ádám Milacski, András Sárkány, Zoltán Tősér category:cs.LG cs.AI cs.NE  published:2016-12-02 summary:Machine learning is making substantial progress in diverse applications. The success is mostly due to advances in deep learning. However, deep learning can make mistakes and its generalization abilities to new tasks are questionable. We ask when and how one can combine network outputs, when (i) details of the observations are evaluated by learned deep components and (ii) facts and confirmation rules are available in knowledge based systems. We show that in limited contexts the required number of training samples can be low and self-improvement of pre-trained networks in more general context is possible. We argue that the combination of sparse outlier detection with deep components that can support each other diminish the fragility of deep methods, an important requirement for engineering applications. We argue that supervised learning of labels may be fully eliminated under certain conditions: a component based architecture together with a knowledge based system can train itself and provide high quality answers. We demonstrate these concepts on the State Farm Distracted Driver Detection benchmark. We argue that the view of the Study Panel (2016) may overestimate the requirements on `years of focused research' and `careful, unique construction' for `AI systems'. version:1
arxiv-1612-00738 | Action Recognition with Dynamic Image Networks | http://arxiv.org/abs/1612.00738 | id:1612.00738 author:Hakan Bilen, Basura Fernando, Efstratios Gavves, Andrea Vedaldi category:cs.CV  published:2016-12-02 summary:We introduce the concept of "dynamic image", a novel compact representation of videos useful for video analysis especially when convolutional neural networks (CNNs) are used. The dynamic image is based on the rank pooling concept and is obtained through the parameters of a ranking machine that encodes the temporal evolution of the frames of the video. Dynamic images are obtained by directly applying rank pooling on the raw image pixels of a video producing a single RGB image per video. This idea is simple but powerful as it enables the use of existing CNN models directly on video data with fine-tuning. We present an efficient and effective approximate rank pooling operator, speeding it up orders of magnitude compared to rank pooling. Our new approximate rank pooling CNN layer allows us to generalize dynamic images to dynamic feature maps and we demonstrate the power of our new representations on standard benchmarks in action recognition achieving state-of-the-art performance. version:1
arxiv-1612-00729 | Automated assessment of non-native learner essays: Investigating the role of linguistic features | http://arxiv.org/abs/1612.00729 | id:1612.00729 author:Sowmya Vajjala category:cs.CL  published:2016-12-02 summary:Automatic essay scoring (AES) refers to the process of scoring free text responses to given prompts, considering human grader scores as the gold standard. Writing such essays is an essential component of many language and aptitude exams. Hence, AES became an active and established area of research, and there are many proprietary systems used in real life applications today. However, not much is known about which specific linguistic features are useful for prediction and how much of this is consistent across datasets. This article addresses that by exploring the role of various linguistic features in automatic essay scoring using two publicly available datasets of non-native English essays written in test taking scenarios. The linguistic properties are modeled by encoding lexical, syntactic, discourse and error types of learner language in the feature set. Predictive models are then developed using these features on both datasets and the most predictive features are compared. While the results show that the feature set used results in good predictive models with both datasets, the question "what are the most predictive features?" has a different answer for each dataset. version:1
arxiv-1612-00712 | Probabilistic Neural Programs | http://arxiv.org/abs/1612.00712 | id:1612.00712 author:Kenton W. Murray, Jayant Krishnamurthy category:cs.NE cs.AI cs.LG  published:2016-12-02 summary:We present probabilistic neural programs, a framework for program induction that permits flexible specification of both a computational model and inference algorithm while simultaneously enabling the use of deep neural networks. Probabilistic neural programs combine a computation graph for specifying a neural network with an operator for weighted nondeterministic choice. Thus, a program describes both a collection of decisions as well as the neural network architecture used to make each one. We evaluate our approach on a challenging diagram question answering task where probabilistic neural programs correctly execute nearly twice as many programs as a baseline model. version:1
arxiv-1612-00686 | Identifying and Categorizing Anomalies in Retinal Imaging Data | http://arxiv.org/abs/1612.00686 | id:1612.00686 author:Philipp Seeböck, Sebastian Waldstein, Sophie Klimscha, Bianca S. Gerendas, René Donner, Thomas Schlegl, Ursula Schmidt-Erfurth, Georg Langs category:cs.LG cs.CV  published:2016-12-02 summary:The identification and quantification of markers in medical images is critical for diagnosis, prognosis and management of patients in clinical practice. Supervised- or weakly supervised training enables the detection of findings that are known a priori. It does not scale well, and a priori definition limits the vocabulary of markers to known entities reducing the accuracy of diagnosis and prognosis. Here, we propose the identification of anomalies in large-scale medical imaging data using healthy examples as a reference. We detect and categorize candidates for anomaly findings untypical for the observed data. A deep convolutional autoencoder is trained on healthy retinal images. The learned model generates a new feature representation, and the distribution of healthy retinal patches is estimated by a one-class support vector machine. Results demonstrate that we can identify pathologic regions in images without using expert annotations. A subsequent clustering categorizes findings into clinically meaningful classes. In addition the learned features outperform standard embedding approaches in a classification task. version:1
arxiv-1612-00667 | Voxelwise nonlinear regression toolbox for neuroimage analysis: Application to aging and neurodegenerative disease modeling | http://arxiv.org/abs/1612.00667 | id:1612.00667 author:Santi Puch, Asier Aduriz, Adrià Casamitjana, Veronica Vilaplana, Paula Petrone, Grégory Operto, Raffaele Cacciaglia, Stavros Skouras, Carles Falcon, José Luis Molinuevo, Juan Domingo Gispert category:stat.ML cs.CV cs.LG q-bio.NC stat.AP  published:2016-12-02 summary:This paper describes a new neuroimaging analysis toolbox that allows for the modeling of nonlinear effects at the voxel level, overcoming limitations of methods based on linear models like the GLM. We illustrate its features using a relevant example in which distinct nonlinear trajectories of Alzheimer's disease related brain atrophy patterns were found across the full biological spectrum of the disease. version:1
arxiv-1612-00662 | Predicting Patient State-of-Health using Sliding Window and Recurrent Classifiers | http://arxiv.org/abs/1612.00662 | id:1612.00662 author:Adam McCarthy, Christopher K. I. Williams category:stat.ML cs.LG  published:2016-12-02 summary:Bedside monitors in Intensive Care Units (ICUs) frequently sound incorrectly, slowing response times and desensitising nurses to alarms (Chambrin, 2001), causing true alarms to be missed (Hug et al., 2011). We compare sliding window predictors with recurrent predictors to classify patient state-of-health from ICU multivariate time series; we report slightly improved performance for the RNN for three out of four targets. version:1
arxiv-1612-00653 | Inverse Modeling of Complex Interactive Behavior with ABC | http://arxiv.org/abs/1612.00653 | id:1612.00653 author:Antti Kangasrääsiö, Kumaripaba Athukorala, Andrew Howes, Jukka Corander, Samuel Kaski, Antti Oulasvirta category:cs.HC cs.AI cs.LG stat.ML  published:2016-12-02 summary:Can one make deep inferences about a user based only on observations of how she interacts? This paper contributes a methodology for inverse modeling in HCI, where the goal is to estimate a cognitive model from limited behavioral data. Given substantial diversity in users' intentions, strategies and abilities, this is a difficult problem and previously unaddressed in HCI. We show advances following an approach that combines (1) computational rationality, to predict how a user adapts to a task when her capabilities are known, and (2) approximate Bayesian computation (ABC) to estimate those capabilities. The benefit is that model parameters are conditioned on both prior knowledge and observations, which improves model validity and helps identify causes for observations. We demonstrate these benefits in a case of menu interaction where the method obtained accurate estimates of users' behavioral and cognitive features from selection time data only. Inverse modeling methods can advance theoretical HCI by bringing complex behavior within reach of modeling. version:1
arxiv-1612-00645 | Centrog Feature technique for vehicle type recognition at day and night times | http://arxiv.org/abs/1612.00645 | id:1612.00645 author:Martins E. Irhebhude, Philip O. Odion, Darius T. Chinyio category:cs.CV  published:2016-12-02 summary:This work proposes a feature-based technique to recognize vehicle types within day and night times. Support vector machine (SVM) classifier is applied on image histogram and CENsus Transformed histogRam Oriented Gradient (CENTROG) features in order to classify vehicle types during the day and night. Thermal images were used for the night time experiments. Although thermal images suffer from low image resolution, lack of colour and poor texture information, they offer the advantage of being unaffected by high intensity light sources such as vehicle headlights which tend to render normal images unsuitable for night time image capturing and subsequent analysis. Since contour is useful in shape based categorisation and the most distinctive feature within thermal images, CENTROG is used to capture this feature information and is used within the experiments. The experimental results so obtained were compared with those obtained by employing the CENsus TRansformed hISTogram (CENTRIST). Experimental results revealed that CENTROG offers better recognition accuracies for both day and night times vehicle types recognition. version:1
arxiv-1612-00637 | A General Framework for Density Based Time Series Clustering Exploiting a Novel Admissible Pruning Strategy | http://arxiv.org/abs/1612.00637 | id:1612.00637 author:Nurjahan Begum, Liudmila Ulanova, Hoang Anh Dau, Jun Wang, Eamonn Keogh category:cs.LG  published:2016-12-02 summary:Time Series Clustering is an important subroutine in many higher-level data mining analyses, including data editing for classifiers, summarization, and outlier detection. It is well known that for similarity search the superiority of Dynamic Time Warping (DTW) over Euclidean distance gradually diminishes as we consider ever larger datasets. However, as we shall show, the same is not true for clustering. Clustering time series under DTW remains a computationally expensive operation. In this work, we address this issue in two ways. We propose a novel pruning strategy that exploits both the upper and lower bounds to prune off a very large fraction of the expensive distance calculations. This pruning strategy is admissible and gives us provably identical results to the brute force algorithm, but is at least an order of magnitude faster. For datasets where even this level of speedup is inadequate, we show that we can use a simple heuristic to order the unavoidable calculations in a most-useful-first ordering, thus casting the clustering into an anytime framework. We demonstrate the utility of our ideas with both single and multidimensional case studies in the domains of astronomy, speech physiology, medicine and entomology. In addition, we show the generality of our clustering framework to other domains by efficiently obtaining semantically significant clusters in protein sequences using the Edit Distance, the discrete data analogue of DTW. version:1
arxiv-1612-00625 | Recognition of Text Image Using Multilayer Perceptron | http://arxiv.org/abs/1612.00625 | id:1612.00625 author:Singh Vijendra, Nisha Vasudeva, Hem Jyotsana Parashar category:cs.CV  published:2016-12-02 summary:The biggest challenge in the field of image processing is to recognize documents both in printed and handwritten format. Optical Character Recognition OCR is a type of document image analysis where scanned digital image that contains either machine printed or handwritten script input into an OCR software engine and translating it into an editable machine readable digital text format. A Neural network is designed to model the way in which the brain performs a particular task or function of interest: The neural network is simulated in software on a digital computer. Character Recognition refers to the process of converting printed Text documents into translated Unicode Text. The printed documents available in the form of books, papers, magazines, etc. are scanned using standard scanners which produce an image of the scanned document. Lines are identifying by an algorithm where we identify top and bottom of line. Then in each line character boundaries are calculated by an algorithm then using these calculation, characters is isolated from the image and then we classify each character by basic back propagation. Each image character is comprised of 30*20 pixels. We have used the Back propagation Neural Network for efficient recognition where the errors were corrected through back propagation and rectified neuron values were transmitted by feed-forward method in the neural network of multiple layers. version:1
arxiv-1612-00615 | A temporal model for multiple sclerosis course evolution | http://arxiv.org/abs/1612.00615 | id:1612.00615 author:Samuele Fiorini, Andrea Tacchino, Giampaolo Brichetto, Alessandro Verri, Annalisa Barla category:stat.ML cs.LG  published:2016-12-02 summary:Multiple Sclerosis is a degenerative condition of the central nervous system that affects nearly 2.5 million of individuals in terms of their physical, cognitive, psychological and social capabilities. Researchers are currently investigating on the use of patient reported outcome measures for the assessment of impact and evolution of the disease on the life of the patients. To date, a clear understanding on the use of such measures to predict the evolution of the disease is still lacking. In this work we resort to regularized machine learning methods for binary classification and multiple output regression. We propose a pipeline that can be used to predict the disease progression from patient reported measures. The obtained model is tested on a data set collected from an ongoing clinical research project. version:1
arxiv-1612-00611 | Predictive Clinical Decision Support System with RNN Encoding and Tensor Decoding | http://arxiv.org/abs/1612.00611 | id:1612.00611 author:Yinchong Yang, Peter A. Fasching, Markus Wallwiener, Tanja N. Fehm, Sara Y. Brucker, Volker Tresp category:cs.LG  published:2016-12-02 summary:With the introduction of the Electric Health Records, large amounts of digital data become available for analysis and decision support. When physicians are prescribing treatments to a patient, they need to consider a large range of data variety and volume, making decisions increasingly complex. Machine learning based Clinical Decision Support systems can be a solution to the data challenges. In this work we focus on a class of decision support in which the physicians' decision is directly predicted. Concretely, the model would assign higher probabilities to decisions that it presumes the physician are more likely to make. Thus the CDS system can provide physicians with rational recommendations. We also address the problem of correlation in target features: Often a physician is required to make multiple (sub-)decisions in a block, and that these decisions are mutually dependent. We propose a solution to the target correlation problem using a tensor factorization model. In order to handle the patients' historical information as sequential data, we apply the so-called Encoder-Decoder-Framework which is based on Recurrent Neural Networks (RNN) as encoders and a tensor factorization model as a decoder, a combination which is novel in machine learning. With experiments with real-world datasets we show that the proposed model does achieve better prediction performances. version:1
arxiv-1611-09419 | Safety-Aware Robot Damage Recovery Using Constrained Bayesian Optimization and Simulated Priors | http://arxiv.org/abs/1611.09419 | id:1611.09419 author:Vaios Papaspyros, Konstantinos Chatzilygeroudis, Vassilis Vassiliades, Jean-Baptiste Mouret category:cs.RO cs.LG  published:2016-11-28 summary:The recently introduced Intelligent Trial-and-Error (IT&E) algorithm showed that robots can adapt to damage in a matter of a few trials. The success of this algorithm relies on two components: prior knowledge acquired through simulation with an intact robot, and Bayesian optimization (BO) that operates on-line, on the damaged robot. While IT&E leads to fast damage recovery, it does not incorporate any safety constraints that prevent the robot from attempting harmful behaviors. In this work, we address this limitation by replacing the BO component with a constrained BO procedure. We evaluate our approach on a simulated damaged humanoid robot that needs to crawl as fast as possible, while performing as few unsafe trials as possible. We compare our new "safety-aware IT&E" algorithm to IT&E and a multi-objective version of IT&E in which the safety constraints are dealt as separate objectives. Our results show that our algorithm outperforms the other approaches, both in crawling speed within the safe regions and number of unsafe trials. version:3
arxiv-1612-00606 | SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation | http://arxiv.org/abs/1612.00606 | id:1612.00606 author:Li Yi, Hao Su, Xingwen Guo, Leonidas Guibas category:cs.CV  published:2016-12-02 summary:In this paper, we study the problem of semantic annotation on 3D models that are represented as shape graphs. A functional view is taken to represent localized information on graphs, so that annotations such as part segment or keypoint are nothing but 0-1 indicator vertex functions. Compared with images that are 2D grids, shape graphs are irregular and non-isomorphic data structures. To enable the prediction of vertex functions on them by convolutional neural networks, we resort to spectral CNN method that enables weight sharing by parameterizing kernels in the spectral domain spanned by graph laplacian eigenbases. Under this setting, our network, named SyncSpecCNN, strive to overcome two key challenges: how to share coefficients and conduct multi-scale analysis in different parts of the graph for a single shape, and how to share information across related but different shapes that may be represented by very different graphs. Towards these goals, we introduce a spectral parameterization of dilated convolutional kernels and a spectral transformer network. Experimentally we tested our SyncSpecCNN on various tasks, including 3D shape part segmentation and 3D keypoint prediction. State-of-the-art performance has been achieved on all benchmark datasets. version:1
arxiv-1612-00604 | Globally Consistent Multi-People Tracking using Motion Patterns | http://arxiv.org/abs/1612.00604 | id:1612.00604 author:Andrii Maksai, Xinchao Wang, Francois Fleuret, Pascal Fua category:cs.CV I.4.8  published:2016-12-02 summary:Many state-of-the-art approaches to people tracking rely on detecting them in each frame independently, grouping detections into short but reliable trajectory segments, and then further grouping them into full trajectories. This grouping typically relies on imposing local smoothness constraints but almost never on enforcing more global constraints on the trajectories. In this paper, we propose an approach to imposing global consistency by first inferring behavioral patterns from the ground truth and then using them to guide the tracking algorithm. When used in conjunction with several state-of-the-art algorithms, this further increases their already good performance. Furthermore, we propose an unsupervised scheme that yields almost similar improvements without the need for ground truth. version:1
arxiv-1612-00144 | BASS Net: Band-Adaptive Spectral-Spatial Feature Learning Neural Network for Hyperspectral Image Classification | http://arxiv.org/abs/1612.00144 | id:1612.00144 author:Anirban Santara, Kaustubh Mani, Pranoot Hatwar, Ankit Singh, Ankur Garg, Kirti Padia, Pabitra Mitra category:cs.CV  published:2016-12-01 summary:Deep learning based landcover classification algorithms have recently been proposed in literature. In hyperspectral images (HSI) they face the challenges of large dimensionality, spatial variability of spectral signatures and scarcity of labeled data. In this article we propose an end-to-end deep learning architecture that extracts band specific spectral-spatial features and performs landcover classification. The architecture has fewer independent connection weights and thus requires lesser number of training data. The method is found to outperform the highest reported accuracies on popular hyperspectral image data sets. version:2
arxiv-1612-00599 | Communication Lower Bounds for Distributed Convex Optimization: Partition Data on Features | http://arxiv.org/abs/1612.00599 | id:1612.00599 author:Zihao Chen, Luo Luo, Zhihua Zhang category:cs.LG stat.ML  published:2016-12-02 summary:Recently, there has been an increasing interest in designing distributed convex optimization algorithms under the setting where the data matrix is partitioned on features. Algorithms under this setting sometimes have many advantages over those under the setting where data is partitioned on samples, especially when the number of features is huge. Therefore, it is important to understand the inherent limitations of these optimization problems. In this paper, with certain restrictions on the communication allowed in the procedures, we develop tight lower bounds on communication rounds for a broad class of non-incremental algorithms under this setting. We also provide a lower bound on communication rounds for a class of (randomized) incremental algorithms. version:1
arxiv-1612-00596 | Learning to Search on Manifolds for 3D Pose Estimation of Articulated Objects | http://arxiv.org/abs/1612.00596 | id:1612.00596 author:Yu Zhang, Chi Xu, Li Cheng category:cs.CV  published:2016-12-02 summary:This paper focuses on the challenging problem of 3D pose estimation of a diverse spectrum of articulated objects from single depth images. A novel structured prediction approach is considered, where 3D poses are represented as skeletal models that naturally operate on manifolds. Given an input depth image, the problem of predicting the most proper articulation of underlying skeletal model is thus formulated as sequentially searching for the optimal skeletal configuration. This is subsequently addressed by convolutional neural nets trained end-to-end to render sequential prediction of the joint locations as regressing a set of tangent vectors of the underlying manifolds. Our approach is examined on various articulated objects including human hand, mouse, and fish benchmark datasets. Empirically it is shown to deliver highly competitive performance with respect to the state-of-the-arts, while operating in real-time (over 30 FPS). version:1
arxiv-1612-00593 | PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation | http://arxiv.org/abs/1612.00593 | id:1612.00593 author:Charles R. Qi, Hao Su, Kaichun Mo, Leonidas J. Guibas category:cs.CV  published:2016-12-02 summary:Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds and well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption. version:1
arxiv-1612-00841 | A Novel Framework based on SVDD to Classify Water Saturation from Seismic Attributes | http://arxiv.org/abs/1612.00841 | id:1612.00841 author:Soumi Chaki, Akhilesh Kumar Verma, Aurobinda Routray, William K. Mohanty, Mamata Jenamani category:cs.LG stat.ML  published:2016-12-02 summary:Water saturation is an important property in reservoir engineering domain. Thus, satisfactory classification of water saturation from seismic attributes is beneficial for reservoir characterization. However, diverse and non-linear nature of subsurface attributes makes the classification task difficult. In this context, this paper proposes a generalized Support Vector Data Description (SVDD) based novel classification framework to classify water saturation into two classes (Class high and Class low) from three seismic attributes seismic impedance, amplitude envelop, and seismic sweetness. G-metric means and program execution time are used to quantify the performance of the proposed framework along with established supervised classifiers. The documented results imply that the proposed framework is superior to existing classifiers. The present study is envisioned to contribute in further reservoir modeling. version:1
arxiv-1612-00585 | Development of a hybrid learning system based on SVM, ANFIS and domain knowledge: DKFIS | http://arxiv.org/abs/1612.00585 | id:1612.00585 author:Soumi Chaki, Aurobinda Routray, William K. Mohanty, Mamata Jenamani category:cs.LG cs.CE stat.AP stat.ML  published:2016-12-02 summary:This paper presents the development of a hybrid learning system based on Support Vector Machines (SVM), Adaptive Neuro-Fuzzy Inference System (ANFIS) and domain knowledge to solve prediction problem. The proposed two-stage Domain Knowledge based Fuzzy Information System (DKFIS) improves the prediction accuracy attained by ANFIS alone. The proposed framework has been implemented on a noisy and incomplete dataset acquired from a hydrocarbon field located at western part of India. Here, oil saturation has been predicted from four different well logs i.e. gamma ray, resistivity, density, and clay volume. In the first stage, depending on zero or near zero and non-zero oil saturation levels the input vector is classified into two classes (Class 0 and Class 1) using SVM. The classification results have been further fine-tuned applying expert knowledge based on the relationship among predictor variables i.e. well logs and target variable - oil saturation. Second, an ANFIS is designed to predict non-zero (Class 1) oil saturation values from predictor logs. The predicted output has been further refined based on expert knowledge. It is apparent from the experimental results that the expert intervention with qualitative judgment at each stage has rendered the prediction into the feasible and realistic ranges. The performance analysis of the prediction in terms of four performance metrics such as correlation coefficient (CC), root mean square error (RMSE), and absolute error mean (AEM), scatter index (SI) has established DKFIS as a useful tool for reservoir characterization. version:1
arxiv-1612-00840 | A novel multiclassSVM based framework to classify lithology from well logs: a real-world application | http://arxiv.org/abs/1612.00840 | id:1612.00840 author:Soumi Chaki, Aurobinda Routray, William K. Mohanty, Mamata Jenamani category:cs.LG stat.AP stat.ML  published:2016-12-02 summary:Support vector machines (SVMs) have been recognized as a potential tool for supervised classification analyses in different domains of research. In essence, SVM is a binary classifier. Therefore, in case of a multiclass problem, the problem is divided into a series of binary problems which are solved by binary classifiers, and finally the classification results are combined following either the one-against-one or one-against-all strategies. In this paper, an attempt has been made to classify lithology using a multiclass SVM based framework using well logs as predictor variables. Here, the lithology is classified into four classes such as sand, shaly sand, sandy shale and shale based on the relative values of sand and shale fractions as suggested by an expert geologist. The available dataset consisting well logs (gamma ray, neutron porosity, density, and P-sonic) and class information from four closely spaced wells from an onshore hydrocarbon field is divided into training and testing sets. We have used one-against-all strategy to combine the results of multiple binary classifiers. The reported results established the superiority of multiclass SVM compared to other classifiers in terms of classification accuracy. The selection of kernel function and associated parameters has also been investigated here. It can be envisaged from the results achieved in this study that the proposed framework based on multiclass SVM can further be used to solve classification problems. In future research endeavor, seismic attributes can be introduced in the framework to classify the lithology throughout a study area from seismic inputs. version:1
arxiv-1612-01349 | A One class Classifier based Framework using SVDD : Application to an Imbalanced Geological Dataset | http://arxiv.org/abs/1612.01349 | id:1612.01349 author:Soumi Chaki, Akhilesh Kumar Verma, Aurobinda Routray, William K. Mohanty, Mamata Jenamani category:cs.LG stat.AP stat.ML  published:2016-12-02 summary:Evaluation of hydrocarbon reservoir requires classification of petrophysical properties from available dataset. However, characterization of reservoir attributes is difficult due to the nonlinear and heterogeneous nature of the subsurface physical properties. In this context, present study proposes a generalized one class classification framework based on Support Vector Data Description (SVDD) to classify a reservoir characteristic water saturation into two classes (Class high and Class low) from four logs namely gamma ray, neutron porosity, bulk density, and P sonic using an imbalanced dataset. A comparison is carried out among proposed framework and different supervised classification algorithms in terms of g metric means and execution time. Experimental results show that proposed framework has outperformed other classifiers in terms of these performance evaluators. It is envisaged that the classification analysis performed in this study will be useful in further reservoir modeling. version:1
arxiv-1612-00584 | Alleviating Overfitting for Polysemous Words for Word Representation Estimation Using Lexicons | http://arxiv.org/abs/1612.00584 | id:1612.00584 author:Yuanzhi Ke, Masafumi Hagiwara category:cs.CL  published:2016-12-02 summary:Though there are some works on improving distributed word representations using lexicons, the improper overfitting of the words that have multiple meanings is a remaining issue deteriorating the learning when lexicons are used, which needs to be solved. An alternative method is to allocate a vector per sense instead a vector per word. However, the word representations estimated in the former way are not as easy to use as the latter one. Our previous work uses a probabilistic method to alleviate the overfitting, but it is not robust with small corpus. In this paper, we propose a new neural network to estimate distributed word representations using a lexicon and a corpus. We add a lexicon layer in continuous bag-of-words model, and a threshold node after the output of the lexicon layer. The threshold rejects the "bad" outputs of the lexicon layer that are less likely to be the same with their inputs. In this way, it alleviates the overfitting of the polysemous words. The proposed neural network can be trained using negative sampling, which maximizing the log probabilities of target words given the context words, by distinguishing the target words from random noises. We compare the proposed neural network with continuous bag-of-words model, the other works improving it, and the previous works estimating distributed word representations using both a lexicon and a corpus. The experimental results show that the proposed neural network is more efficient and balanced for both semantic tasks and syntactic tasks than the previous works, and robust to the size of the corpus. version:1
arxiv-1612-00583 | Active Search for Sparse Signals with Region Sensing | http://arxiv.org/abs/1612.00583 | id:1612.00583 author:Yifei Ma, Roman Garnett, Jeff Schneider category:stat.ML cs.AI cs.LG  published:2016-12-02 summary:Autonomous systems can be used to search for sparse signals in a large space; e.g., aerial robots can be deployed to localize threats, detect gas leaks, or respond to distress calls. Intuitively, search algorithms may increase efficiency by collecting aggregate measurements summarizing large contiguous regions. However, most existing search methods either ignore the possibility of such region observations (e.g., Bayesian optimization and multi-armed bandits) or make strong assumptions about the sensing mechanism that allow each measurement to arbitrarily encode all signals in the entire environment (e.g., compressive sensing). We propose an algorithm that actively collects data to search for sparse signals using only noisy measurements of the average values on rectangular regions (including single points), based on the greedy maximization of information gain. We analyze our algorithm in 1d and show that it requires $\tilde{O}(\frac{n}{\mu^2}+k^2)$ measurements to recover all of $k$ signal locations with small Bayes error, where $\mu$ and $n$ are the signal strength and the size of the search space, respectively. We also show that active designs can be fundamentally more efficient than passive designs with region sensing, contrasting with the results of Arias-Castro, Candes, and Davenport (2013). We demonstrate the empirical performance of our algorithm on a search problem using satellite image data and in high dimensions. version:1
arxiv-1612-00576 | Guided Open Vocabulary Image Captioning with Constrained Beam Search | http://arxiv.org/abs/1612.00576 | id:1612.00576 author:Peter Anderson, Basura Fernando, Mark Johnson, Stephen Gould category:cs.CV  published:2016-12-02 summary:Existing image captioning models do not generalize well to out-of-domain images containing novel scenes or objects. This limitation severely hinders the use of these models in real world applications dealing with images in the wild. We address this problem using a flexible approach that enables existing deep captioning architectures to take advantage of image taggers at test time, without re-training. Our method uses constrained beam search to force the inclusion of selected tag words in the output, and fixed, pretrained word embeddings to facilitate vocabulary expansion to previously unseen tag words. Using this approach we achieve state of the art results for out-of-domain captioning on MS COCO (and improved results for in-domain captioning). In order to demonstrate the scalability of our approach, we generate and publicly release captions for the complete ImageNet classification dataset containing 1.2M images. Each ImageNet caption includes the ground-truth image label. Human evaluations indicate that 27% of the resulting captions are likely to meet or exceed human quality (increasing to 38% for certain categories such as birds). version:1
arxiv-1612-00567 | Shift-Reduce Constituent Parsing with Neural Lookahead Features | http://arxiv.org/abs/1612.00567 | id:1612.00567 author:Jiangming Liu, Yue Zhang category:cs.CL  published:2016-12-02 summary:Transition-based models can be fast and accurate for constituent parsing. Compared with chart-based models, they leverage richer features by extracting history information from a parser stack, which spans over non-local constituents. On the other hand, during incremental parsing, constituent information on the right hand side of the current word is not utilized, which is a relative weakness of shift-reduce parsing. To address this limitation, we leverage a fast neural model to extract lookahead features. In particular, we build a bidirectional LSTM model, which leverages the full sentence information to predict the hierarchy of constituents that each word starts and ends. The results are then passed to a strong transition-based constituent parser as lookahead features. The resulting parser gives 1.3% absolute improvement in WSJ and 2.3% in CTB compared to the baseline, given the highest reported accuracies for fully-supervised parsing. version:1
arxiv-1612-00563 | Self-critical Sequence Training for Image Captioning | http://arxiv.org/abs/1612.00563 | id:1612.00563 author:Steven J. Rennie, Etienne Marcheret, Youssef Mroueh, Jarret Ross, Vaibhava Goel category:cs.LG cs.AI cs.CV  published:2016-12-02 summary:Recently it has been shown that policy-gradient methods for reinforcement learning can be utilized to train deep end-to-end systems directly on non-differentiable metrics for the task at hand. In this paper we consider the problem of optimizing image captioning systems using reinforcement learning, and show that by carefully optimizing our systems using the test metrics of the MSCOCO task, significant gains in performance can be realized. Our systems are built using a new optimization approach that we call self-critical sequence training (SCST). SCST is a form of the popular REINFORCE algorithm that, rather than estimating a "baseline" to normalize the rewards and reduce variance, utilizes the output of its own test-time inference algorithm to normalize the rewards it experiences. Using this approach, estimating the reward signal (as actor-critic methods must do) and estimating normalization (as REINFORCE algorithms typically do) is avoided, while at the same time harmonizing the model with respect to its test-time inference procedure. Empirically we find that directly optimizing the CIDEr metric with SCST and greedy decoding at test-time is highly effective. Our results on the MSCOCO evaluation sever establish a new state-of-the-art on the task, improving the best result in terms of CIDEr from 104.9 to 112.3. version:1
arxiv-1612-01812 | Control Matching via Discharge Code Sequences | http://arxiv.org/abs/1612.01812 | id:1612.01812 author:Dang Nguyen, Wei Luo, Dinh Phung, Svetha Venkatesh category:cs.LG  published:2016-12-02 summary:In this paper, we consider the patient similarity matching problem over a cancer cohort of more than 220,000 patients. Our approach first leverages on Word2Vec framework to embed ICD codes into vector-valued representation. We then propose a sequential algorithm for case-control matching on this representation space of diagnosis codes. The novel practice of applying the sequential matching on the vector representation lifted the matching accuracy measured through multiple clinical outcomes. We reported the results on a large-scale dataset to demonstrate the effectiveness of our method. For such a large dataset where most clinical information has been codified, the new method is particularly relevant. version:1
arxiv-1612-00560 | Zero-Shot Learning via Revealing Data Distribution | http://arxiv.org/abs/1612.00560 | id:1612.00560 author:Bo Zhao, Botong Wu, Tianfu Wu, Yizhou Wang category:cs.CV  published:2016-12-02 summary:This paper presents a method of zero-shot learning (ZSL) which poses ZSL as the missing data problem, rather than the missing label problem. While most popular methods in ZSL focus on learning the mapping function from the image feature space to the label embedding space, the proposed method explores a simple yet effective transductive framework in the reverse mapping. Our method estimates data distribution of unseen classes in the image feature space by transferring knowledge from the label embedding space. It assumes that data of each seen and unseen class follow Gaussian distribution in the image feature space and utilizes Gaussian mixture model to model data. The signature is introduced to describe the data distribution of each class. In experiments, our method obtains 87.38% and 61.08% mean accuracies on the Animals with Attributes (AwA) and the Caltech-UCSD Birds-200-2011 (CUB) datasets respectively, which outperforms the runner-up methods significantly by 4.95% and 6.38%. In addition, we also investigate the extension of our method to open-set classification. version:1
arxiv-1612-00558 | Unsupervised Human Action Detection by Action Matching | http://arxiv.org/abs/1612.00558 | id:1612.00558 author:Basura Fernando, Sareh Shirazi, Stephen Gould category:cs.CV  published:2016-12-02 summary:We propose a new task of unsupervised action detection by action matching. Given two long videos, the objective is to temporally detect all pairs of matching video segments. A pair of video segments are matched if they share the same human action. The task is category independent---it does not matter what action is being performed---and no supervision is used to discover such video segments. Unsupervised action detection by action matching allows us to align videos in a meaningful manner. As such, it can be used to discover new action categories or as an action proposal technique within, say, an action detection pipeline. Moreover, it is a useful pre-processing step for generating video highlights, e.g., from sports videos. We present an effective and efficient method for unsupervised action detection. We use an unsupervised temporal encoding method and exploit the temporal consistency in human actions to obtain candidate action segments. We evaluate our method on this challenging task using three activity recognition benchmarks, namely, the MPII Cooking activities dataset, the THUMOS15 action detection benchmark and a new dataset called the IKEA dataset. On the MPII Cooking dataset we detect action segments with a precision of 21.6% and recall of 11.7% over 946 long video pairs and over 5000 ground truth action segments. Similarly, on THUMOS dataset we obtain 18.4% precision and 25.1% recall over 5094 ground truth action segment pairs. version:1
arxiv-1612-00555 | Transfer Learning via Latent Factor Modeling to Improve Prediction of Surgical Complications | http://arxiv.org/abs/1612.00555 | id:1612.00555 author:Elizabeth C Lorenzi, Zhifei Sun, Erich Huang, Ricardo Henao, Katherine A Heller category:stat.ML  published:2016-12-02 summary:We aim to create a framework for transfer learning using latent factor models to learn the dependence structure between a larger source dataset and a target dataset. The methodology is motivated by our goal of building a risk-assessment model for surgery patients, using both institutional and national surgical outcomes data. The national surgical outcomes data is collected through NSQIP (National Surgery Quality Improvement Program), a database housing almost 4 million patients from over 700 different hospitals. We build a latent factor model with a hierarchical prior on the loadings matrix to appropriately account for the different covariance structure in our data. We extend this model to handle more complex relationships between the populations by deriving a scale mixture formulation using stick-breaking properties. Our model provides a transfer learning framework that utilizes all information from both the source and target data, while modeling the underlying inherent differences between them. version:1
arxiv-1612-00554 | Higher Order Mutual Information Approximation for Feature Selection | http://arxiv.org/abs/1612.00554 | id:1612.00554 author:Jilin Wu, Soumyajit Gupta, Chandrajit Bajaj category:cs.LG  published:2016-12-02 summary:Feature selection is a process of choosing a subset of relevant features so that the quality of prediction models can be improved. An extensive body of work exists on information-theoretic feature selection, based on maximizing Mutual Information (MI) between subsets of features and class labels. The prior methods use a lower order approximation, by treating the joint entropy as a summation of several single variable entropies. This leads to locally optimal selections and misses multi-way feature combinations. We present a higher order MI based approximation technique called Higher Order Feature Selection (HOFS). Instead of producing a single list of features, our method produces a ranked collection of feature subsets that maximizes MI, giving better comprehension (feature ranking) as to which features work best together when selected, due to their underlying interdependent structure. Our experiments demonstrate that the proposed method performs better than existing feature selection approaches while keeping similar running times and computational complexity. version:1
arxiv-1612-00542 | Breast Mass Classification from Mammograms using Deep Convolutional Neural Networks | http://arxiv.org/abs/1612.00542 | id:1612.00542 author:Daniel Lévy, Arzav Jain category:cs.CV cs.LG  published:2016-12-02 summary:Mammography is the most widely used method to screen breast cancer. Because of its mostly manual nature, variability in mass appearance, and low signal-to-noise ratio, a significant number of breast masses are missed or misdiagnosed. In this work, we present how Convolutional Neural Networks can be used to directly classify pre-segmented breast masses in mammograms as benign or malignant, using a combination of transfer learning, careful pre-processing and data augmentation to overcome limited training data. We achieve state-of-the-art results on the DDSM dataset, surpassing human performance, and show interpretability of our model. version:1
arxiv-1612-00534 | Object Detection via End-to-End Integration of Aspect Ratio and Context Aware Part-based Models and Fully Convolutional Networks | http://arxiv.org/abs/1612.00534 | id:1612.00534 author:Bo Li, Tianfu Wu, Shuai Shao, Lun Zhang, Rufeng Chu category:cs.CV  published:2016-12-02 summary:This paper presents a framework of integrating a mixture of part-based models and region-based convolutional networks for accurate and efficient object detection. Each mixture component consists of a small number of parts accounting for both object aspect ratio and contextual information explicitly. The mixture is category-agnostic for the simplicity of scaling up in applications. Both object aspect ratio and context have been extensively studied in traditional object detection systems such as the mixture of deformable part-based models [13]. They are, however, largely ignored in deep neural network based detection systems [17, 16, 39, 8]. The proposed method addresses this issue in two-fold: (i) It remedies the wrapping artifact due to the generic RoI (region-of-interest) pooling (e.g., a 3 x 3 grid) by taking into account object aspect ratios. (ii) It models both global (from the whole image) and local (from the surrounding of a bounding box) context for improving performance. The integrated framework is fully convolutional and enjoys end-to-end training, which we call the aspect ratio and context aware fully convolutional network (ARC-FCN). In experiments, ARC-FCN shows very competitive results on the PASCAL VOC datasets, especially, it outperforms both Faster R-CNN [39] and R-FCN [8] with significantly better mean average precision (mAP) using larger value for the intersection-over-union (IoU) threshold (i.e., 0.7 in the experiments). ARC-FCN is still sufficiently efficient with a test-time speed of 380ms per image, faster than the Faster R-CNN but slower than the R-FCN. version:1
arxiv-1612-00523 | Photorealistic Facial Texture Inference Using Deep Neural Networks | http://arxiv.org/abs/1612.00523 | id:1612.00523 author:Shunsuke Saito, Lingyu Wei, Liwen Hu, Koki Nagano, Hao Li category:cs.CV cs.GR  published:2016-12-02 summary:We present a data-driven inference method that can synthesize a photorealistic texture map of a complete 3D face model given a partial 2D view of a person in the wild. After an initial estimation of shape and low-frequency albedo, we compute a high-frequency partial texture map, without the shading component, of the visible face area. To extract the fine appearance details from this incomplete input, we introduce a multi-scale detail analysis technique based on mid-layer feature correlations extracted from a deep convolutional neural network. We demonstrate that fitting a convex combination of feature correlations from a high-resolution face database can yield a semantically plausible facial detail description of the entire face. A complete and photorealistic texture map can then be synthesized by iteratively optimizing for the reconstructed feature correlations. Using these high-resolution textures and a commercial rendering framework, we can produce high-fidelity 3D renderings that are visually comparable to those obtained with state-of-the-art multi-view face capture systems. We demonstrate successful face reconstructions from a wide range of low resolution input images, including those of historical figures. In addition to extensive evaluations, we validate the realism of our results using a crowdsourced user study. version:1
arxiv-1612-00522 | A Visual Representation for Editing Face Images | http://arxiv.org/abs/1612.00522 | id:1612.00522 author:Jiajun Lu, Kalyan Sunkavalli, Nathan Carr, Sunil Hadap, David Forsyth category:cs.CV cs.GR  published:2016-12-02 summary:We propose a new approach for editing face images, which enables numerous exciting applications including face relighting, makeup transfer and face detail editing. Our face edits are based on a visual representation, which includes geometry, face segmentation, albedo, illumination and detail map. To recover our visual representation, we start by estimating geometry using a morphable face model, then decompose the face image to recover the albedo, and then shade the geometry with the albedo and illumination. The residual between our shaded geometry and the input image produces our detail map, which carries high frequency information that is either insufficiently or incorrectly captured by our shading process. By manipulating the detail map, we can edit face images with reality and identity preserved. Our representation allows various applications. First, it allows a user to directly manipulate various illumination. Second, it allows non-parametric makeup transfer with input face's distinctive identity features preserved. Third, it allows non-parametric modifications to the face appearance by transferring details. For face relighting and detail editing, we evaluate via a user study and our method outperforms other methods. For makeup transfer, we evaluate via an online attractiveness evaluation system, and can reliably make people look younger and more attractive. We also show extensive qualitative comparisons to existing methods, and have significant improvements over previous techniques. version:1
arxiv-1612-00516 | Canonical Correlation Analysis for Analyzing Sequences of Medical Billing Codes | http://arxiv.org/abs/1612.00516 | id:1612.00516 author:Corinne L. Jones, Sham M. Kakade, Lucas W. Thornblade, David R. Flum, Abraham D. Flaxman category:stat.ML cs.LG  published:2016-12-01 summary:We propose using canonical correlation analysis (CCA) to generate features from sequences of medical billing codes. Applying this novel use of CCA to a database of medical billing codes for patients with diverticulitis, we first demonstrate that the CCA embeddings capture meaningful relationships among the codes. We then generate features from these embeddings and establish their usefulness in predicting future elective surgery for diverticulitis, an important marker in efforts for reducing costs in healthcare. version:1
arxiv-1612-00500 | Object-Centric Representation Learning from Unlabeled Videos | http://arxiv.org/abs/1612.00500 | id:1612.00500 author:Ruohan Gao, Dinesh Jayaraman, Kristen Grauman category:cs.CV  published:2016-12-01 summary:Supervised (pre-)training currently yields state-of-the-art performance for representation learning for visual recognition, yet it comes at the cost of (1) intensive manual annotations and (2) an inherent restriction in the scope of data relevant for learning. In this work, we explore unsupervised feature learning from unlabeled video. We introduce a novel object-centric approach to temporal coherence that encourages similar representations to be learned for object-like regions segmented from nearby frames. Our framework relies on a Siamese-triplet network to train a deep convolutional neural network (CNN) representation. Compared to existing temporal coherence methods, our idea has the advantage of lightweight preprocessing of the unlabeled video (no tracking required) while still being able to extract object-level regions from which to learn invariances. Furthermore, as we show in results on several standard datasets, our method typically achieves substantial accuracy gains over competing unsupervised methods for image classification and retrieval tasks. version:1
arxiv-1612-00496 | 3D Bounding Box Estimation Using Deep Learning and Geometry | http://arxiv.org/abs/1612.00496 | id:1612.00496 author:Arsalan Mousavian, Dragomir Anguelov, John Flynn, Jana Kosecka category:cs.CV  published:2016-12-01 summary:We present a method for 3D object detection and pose estimation from a single image. In contrast to current techniques that only regress the 3D orientation of an object, our method first regresses relatively stable 3D object properties using a deep convolutional neural network and then combines these estimates with geometric constraints provided by a 2D object bounding box to produce a complete 3D bounding box. The first network output estimates the 3D object orientation using a novel hybrid discrete-continuous loss, which significantly outperforms the L2 loss. The second output regresses the 3D object dimensions, which have relatively little variance compared to alternatives and can often be predicted for many object types. These estimates, combined with the geometric constraints on translation imposed by the 2D bounding box, enable us to recover a stable and accurate 3D object pose. We evaluate our method on the challenging KITTI object detection benchmark both on the official metric of 3D orientation estimation and also on the accuracy of the obtained 3D bounding boxes. Although conceptually simple, our method outperforms more complex and computationally expensive approaches that leverage semantic segmentation, instance level segmentation and flat ground priors and sub-category detection. version:1
arxiv-1612-00478 | In Teacher We Trust: Learning Compressed Models for Pedestrian Detection | http://arxiv.org/abs/1612.00478 | id:1612.00478 author:Jonathan Shen, Noranart Vesdapunt, Vishnu N. Boddeti, Kris M. Kitani category:cs.CV  published:2016-12-01 summary:Deep convolutional neural networks continue to advance the state-of-the-art in many domains as they grow bigger and more complex. It has been observed that many of the parameters of a large network are redundant, allowing for the possibility of learning a smaller network that mimics the outputs of the large network through a process called Knowledge Distillation. We show, however, that standard Knowledge Distillation is not effective for learning small models for the task of pedestrian detection. To improve this process, we introduce a higher-dimensional hint layer to increase information flow. We also estimate the variance in the outputs of the large network and propose a loss function to incorporate this uncertainty. Finally, we attempt to boost the complexity of the small network without increasing its size by using as input hand-designed features that have been demonstrated to be effective for pedestrian detection. We succeed in training a model that contains $400\times$ fewer parameters than the large network while outperforming AlexNet on the Caltech Pedestrian Dataset. version:1
arxiv-1612-00475 | Transfer Learning Across Patient Variations with Hidden Parameter Markov Decision Processes | http://arxiv.org/abs/1612.00475 | id:1612.00475 author:Taylor Killian, George Konidaris, Finale Doshi-Velez category:stat.ML cs.AI cs.LG  published:2016-12-01 summary:Due to physiological variation, patients diagnosed with the same condition may exhibit divergent, but related, responses to the same treatments. Hidden Parameter Markov Decision Processes (HiP-MDPs) tackle this transfer-learning problem by embedding these tasks into a low-dimensional space. However, the original formulation of HiP-MDP had a critical flaw: the embedding uncertainty was modeled independently of the agent's state uncertainty, requiring an unnatural training procedure in which all tasks visited every part of the state space---possible for robots that can be moved to a particular location, impossible for human patients. We update the HiP-MDP framework and extend it to more robustly develop personalized medicine strategies for HIV treatment. version:1
arxiv-1612-00472 | Unsupervised learning of image motion by recomposing sequences | http://arxiv.org/abs/1612.00472 | id:1612.00472 author:Andrew Jaegle, Stephen Phillips, Daphne Ippolito, Kostas Daniilidis category:cs.CV cs.NE  published:2016-12-01 summary:We propose a new method for learning a representation of image motion in an unsupervised fashion. We do so by learning an image sequence embedding that respects associativity and invertibility properties of composed sequences with known temporal order. This procedure makes minimal assumptions about scene content, and the resulting networks learn to exploit rigid and non-rigid motion cues. We show that a deep neural network trained to respect these constraints implicitly identifies the characteristic motion patterns of many different sequence types. Our network architecture consists of a CNN followed by an LSTM and is structured to learn motion representations over sequences of arbitrary length. We demonstrate that a network trained using our unsupervised procedure on real-world sequences of human actions and vehicle motion can capture semantic regions corresponding to the motion in the scene, and not merely image-level differences, without requiring any motion labels. Furthermore, we present results that suggest our method can be used to extract information useful for independent motion tracking, localization, and nearest neighbor identification. Our results suggest that this representation may be useful for motion-related tasks where explicit labels are often very difficult to obtain. version:1
arxiv-1612-00467 | Neural Document Embeddings for Intensive Care Patient Mortality Prediction | http://arxiv.org/abs/1612.00467 | id:1612.00467 author:Paulina Grnarova, Florian Schmidt, Stephanie L. Hyland, Carsten Eickhoff category:cs.CL  published:2016-12-01 summary:We present an automatic mortality prediction scheme based on the unstructured textual content of clinical notes. Proposing a convolutional document embedding approach, our empirical investigation using the MIMIC-III intensive care database shows significant performance gains compared to previously employed methods such as latent topic distributions or generic doc2vec embeddings. These improvements are especially pronounced for the difficult problem of post-discharge mortality prediction. version:1
arxiv-1612-00437 | Efficient Pose and Cell Segmentation using Column Generation | http://arxiv.org/abs/1612.00437 | id:1612.00437 author:Shaofei Wang, Chong Zhang, Miguel A. Gonzalez-Ballester, Julian Yarkony category:cs.CV  published:2016-12-01 summary:We study the problems of multi-person pose segmentation in natural images and instance segmentation in biological images with crowded cells. We formulate these distinct tasks as integer programs where variables correspond to poses/cells. To optimize, we propose a generic relaxation scheme for solving these combinatorial problems using a column generation formulation where the program for generating a column is solved via exact optimization of very small scale integer programs. This results in efficient exploration of the spaces of poses and cells. version:1
arxiv-1612-00429 | Generalizing Skills with Semi-Supervised Reinforcement Learning | http://arxiv.org/abs/1612.00429 | id:1612.00429 author:Chelsea Finn, Tianhe Yu, Justin Fu, Pieter Abbeel, Sergey Levine category:cs.LG cs.AI cs.RO  published:2016-12-01 summary:Deep reinforcement learning (RL) can acquire complex behaviors from low-level inputs, such as images. However, real-world applications of such methods require generalizing to the vast variability of the real world. Deep networks are known to achieve remarkable generalization when provided with massive amounts of labeled data, but can we provide this breadth of experience to an RL agent, such as a robot? The robot might continuously learn as it explores the world around it, even while deployed. However, this learning requires access to a reward function, which is often hard to measure in real-world domains, where the reward could depend on, for example, unknown positions of objects or the emotional state of the user. Conversely, it is often quite practical to provide the agent with reward functions in a limited set of situations, such as when a human supervisor is present or in a controlled setting. Can we make use of this limited supervision, and still benefit from the breadth of experience an agent might collect on its own? In this paper, we formalize this problem as semisupervised reinforcement learning, where the reward function can only be evaluated in a set of "labeled" MDPs, and the agent must generalize its behavior to the wide range of states it might encounter in a set of "unlabeled" MDPs, by using experience from both settings. Our proposed method infers the task objective in the unlabeled MDPs through an algorithm that resembles inverse RL, using the agent's own prior experience in the labeled MDPs as a kind of demonstration of optimal behavior. We evaluate our method on challenging tasks that require control directly from images, and show that our approach can improve the generalization of a learned deep neural network policy by using experience for which no reward function is available. We also show that our method outperforms direct supervised learning of the reward. version:1
arxiv-1612-00423 | TorontoCity: Seeing the World with a Million Eyes | http://arxiv.org/abs/1612.00423 | id:1612.00423 author:Shenlong Wang, Min Bai, Gellert Mattyus, Hang Chu, Wenjie Luo, Bin Yang, Justin Liang, Joel Cheverie, Sanja Fidler, Raquel Urtasun category:cs.CV  published:2016-12-01 summary:In this paper we introduce the TorontoCity benchmark, which covers the full greater Toronto area (GTA) with 712.5 $km^2$ of land, 8439 $km$ of road and around 400,000 buildings. Our benchmark provides different perspectives of the world captured from airplanes, drones and cars driving around the city. Manually labeling such a large scale dataset is infeasible. Instead, we propose to utilize different sources of high-precision maps to create our ground truth. Towards this goal, we develop algorithms that allow us to align all data sources with the maps while requiring minimal human supervision. We have designed a wide variety of tasks including building height estimation (reconstruction), road centerline and curb extraction, building instance segmentation, building contour extraction (reorganization), semantic labeling and scene type classification (recognition). Our pilot study shows that most of these tasks are still difficult for modern convolutional neural networks. version:1
arxiv-1612-00410 | Deep Variational Information Bottleneck | http://arxiv.org/abs/1612.00410 | id:1612.00410 author:Alexander A. Alemi, Ian Fischer, Joshua V. Dillon, Kevin Murphy category:cs.LG cs.IT math.IT  published:2016-12-01 summary:We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method "Deep Variational Information Bottleneck", or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack. version:1
arxiv-1612-00408 | Computerized Multiparametric MR image Analysis for Prostate Cancer Aggressiveness-Assessment | http://arxiv.org/abs/1612.00408 | id:1612.00408 author:Imon Banerjee, Lewis Hahn, Geoffrey Sonn, Richard Fan, Daniel L. Rubin category:cs.CV  published:2016-12-01 summary:We propose an automated method for detecting aggressive prostate cancer(CaP) (Gleason score >=7) based on a comprehensive analysis of the lesion and the surrounding normal prostate tissue which has been simultaneously captured in T2-weighted MR images, diffusion-weighted images (DWI) and apparent diffusion coefficient maps (ADC). The proposed methodology was tested on a dataset of 79 patients (40 aggressive, 39 non-aggressive). We evaluated the performance of a wide range of popular quantitative imaging features on the characterization of aggressive versus non-aggressive CaP. We found that a group of 44 discriminative predictors among 1464 quantitative imaging features can be used to produce an area under the ROC curve of 0.73. version:1
arxiv-1612-00404 | Learning Shape Abstractions by Assembling Volumetric Primitives | http://arxiv.org/abs/1612.00404 | id:1612.00404 author:Shubham Tulsiani, Hao Su, Leonidas J. Guibas, Alexei A. Efros, Jitendra Malik category:cs.CV  published:2016-12-01 summary:We present a learning framework for abstracting complex shapes by learning to assemble objects using 3D volumetric primitives. In addition to generating simple and geometrically interpretable explanations of 3D objects, our framework also allows us to automatically discover and exploit consistent structure in the data. We demonstrate that using our method allows predicting shape representations which can be leveraged for obtaining a consistent parsing across the instances of a shape collection and constructing an interpretable shape similarity measure. We also examine applications for image-based prediction as well as shape manipulation. version:1
arxiv-1612-00394 | Definition Modeling: Learning to define word embeddings in natural language | http://arxiv.org/abs/1612.00394 | id:1612.00394 author:Thanapon Noraset, Chen Liang, Larry Birnbaum, Doug Downey category:cs.CL  published:2016-12-01 summary:Distributed representations of words have been shown to capture lexical semantics, as demonstrated by their effectiveness in word similarity and analogical relation tasks. But, these tasks only evaluate lexical semantics indirectly. In this paper, we study whether it is possible to utilize distributed representations to generate dictionary definitions of words, as a more direct and transparent representation of the embeddings' semantics. We introduce definition modeling, the task of generating a definition for a given word and its embedding. We present several definition model architectures based on recurrent neural networks, and experiment with the models over multiple data sets. Our results show that a model that controls dependencies between the word being defined and the definition words performs significantly better, and that a character-level convolution layer designed to leverage morphology can complement word-level embeddings. Finally, an error analysis suggests that the errors made by a definition model may provide insight into the shortcomings of word embeddings. version:1
arxiv-1612-00393 | Hypervolume-based Multi-objective Bayesian Optimization with Student-t Processes | http://arxiv.org/abs/1612.00393 | id:1612.00393 author:Joachim van der Herten, Ivo Couckuyt, Tom Dhaene category:stat.ML cs.LG  published:2016-12-01 summary:Student-$t$ processes have recently been proposed as an appealing alternative non-parameteric function prior. They feature enhanced flexibility and predictive variance. In this work the use of Student-$t$ processes are explored for multi-objective Bayesian optimization. In particular, an analytical expression for the hypervolume-based probability of improvement is developed for independent Student-$t$ process priors of the objectives. Its effectiveness is shown on a multi-objective optimization problem which is known to be difficult with traditional Gaussian processes. version:1
arxiv-1612-00390 | Anomaly Detection in Video Using Predictive Convolutional Long Short-Term Memory Networks | http://arxiv.org/abs/1612.00390 | id:1612.00390 author:Jefferson Ryan Medel, Andreas Savakis category:cs.CV  published:2016-12-01 summary:Automating the detection of anomalous events within long video sequences is challenging due to the ambiguity of how such events are defined. We approach the problem by learning generative models that can identify anomalies in videos using limited supervision. We propose end-to-end trainable composite Convolutional Long Short-Term Memory (Conv-LSTM) networks that are able to predict the evolution of a video sequence from a small number of input frames. Regularity scores are derived from the reconstruction errors of a set of predictions with abnormal video sequences yielding lower regularity scores as they diverge further from the actual sequence over time. The models utilize a composite structure and examine the effects of conditioning in learning more meaningful representations. The best model is chosen based on the reconstruction and prediction accuracy. The Conv-LSTM models are evaluated both qualitatively and quantitatively, demonstrating competitive results on anomaly detection datasets. Conv-LSTM units are shown to be an effective tool for modeling and predicting video sequences. version:1
arxiv-1612-00388 | Diet2Vec: Multi-scale analysis of massive dietary data | http://arxiv.org/abs/1612.00388 | id:1612.00388 author:Wesley Tansey, Edward W. Lowe Jr., James G. Scott category:stat.ML cs.LG stat.AP  published:2016-12-01 summary:Smart phone apps that enable users to easily track their diets have become widespread in the last decade. This has created an opportunity to discover new insights into obesity and weight loss by analyzing the eating habits of the users of such apps. In this paper, we present diet2vec: an approach to modeling latent structure in a massive database of electronic diet journals. Through an iterative contract-and-expand process, our model learns real-valued embeddings of users' diets, as well as embeddings for individual foods and meals. We demonstrate the effectiveness of our approach on a real dataset of 55K users of the popular diet-tracking app LoseIt\footnote{http://www.loseit.com/}. To the best of our knowledge, this is the largest fine-grained diet tracking study in the history of nutrition and obesity research. Our results suggest that diet2vec finds interpretable results at all levels, discovering intuitive representations of foods, meals, and diets. version:1
arxiv-1612-00385 | Temporal Attention-Gated Model for Robust Sequence Classification | http://arxiv.org/abs/1612.00385 | id:1612.00385 author:Wenjie Pei, Tadas Baltrušaitis, David M. J. Tax, Louis-Philippe Morency category:cs.CV cs.CL  published:2016-12-01 summary:Typical techniques for sequence classification are designed for well-segmented sequences which has been edited to remove noisy or irrelevant parts. Therefore, such methods cannot be easily applied on noisy sequences which are expected in real-world applications. We present the Temporal Attention-Gated Model (TAGM) which is able to deal with noisy sequences. Our model assimilates ideas from attention models and gated recurrent networks. Specifically, we employ an attention model to measure the relevance of each time step of a sequence to the final decision. We then use the relevant segments based on their attention scores in a novel gated recurrent network to learn the hidden representation for the classification. More importantly, our attention weights provide a physically meaningful interpretation for the salience of each time step in the sequence. We demonstrate the merits of our model in both interpretability and classification performance on a variety of tasks, including speech recognition, textual sentiment analysis and event recognition. version:1
arxiv-1612-00383 | Tuning the Scheduling of Distributed Stochastic Gradient Descent with Bayesian Optimization | http://arxiv.org/abs/1612.00383 | id:1612.00383 author:Valentin Dalibard, Michael Schaarschmidt, Eiko Yoneki category:stat.ML cs.LG  published:2016-12-01 summary:We present an optimizer which uses Bayesian optimization to tune the system parameters of distributed stochastic gradient descent (SGD). Given a specific context, our goal is to quickly find efficient configurations which appropriately balance the load between the available machines to minimize the average SGD iteration time. Our experiments consider setups with over thirty parameters. Traditional Bayesian optimization, which uses a Gaussian process as its model, is not well suited to such high dimensional domains. To reduce convergence time, we exploit the available structure. We design a probabilistic model which simulates the behavior of distributed SGD and use it within Bayesian optimization. Our model can exploit many runtime measurements for inference per evaluation of the objective function. Our experiments show that our resulting optimizer converges to efficient configurations within ten iterations, the optimized configurations outperform those found by generic optimizer in thirty iterations by up to 2X. version:1
arxiv-1612-00380 | Playing Doom with SLAM-Augmented Deep Reinforcement Learning | http://arxiv.org/abs/1612.00380 | id:1612.00380 author:Shehroze Bhatti, Alban Desmaison, Ondrej Miksik, Nantas Nardelli, N. Siddharth, Philip H. S. Torr category:cs.AI cs.CV stat.ML  published:2016-12-01 summary:A number of recent approaches to policy learning in 2D game domains have been successful going directly from raw input images to actions. However when employed in complex 3D environments, they typically suffer from challenges related to partial observability, combinatorial exploration spaces, path planning, and a scarcity of rewarding scenarios. Inspired from prior work in human cognition that indicates how humans employ a variety of semantic concepts and abstractions (object categories, localisation, etc.) to reason about the world, we build an agent-model that incorporates such abstractions into its policy-learning framework. We augment the raw image input to a Deep Q-Learning Network (DQN), by adding details of objects and structural elements encountered, along with the agent's localisation. The different components are automatically extracted and composed into a topological representation using on-the-fly object detection and 3D-scene reconstruction.We evaluate the efficacy of our approach in Doom, a 3D first-person combat game that exhibits a number of challenges discussed, and show that our augmented framework consistently learns better, more effective policies. version:1
arxiv-1612-00377 | Multi-modal Variational Encoder-Decoders | http://arxiv.org/abs/1612.00377 | id:1612.00377 author:Iulian V. Serban, Alexander G. Ororbia II, Joelle Pineau, Aaron Courville category:cs.CL cs.AI cs.LG cs.NE I.5.1; I.2.7  published:2016-12-01 summary:Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors - such as the multivariate Gaussian distribution - yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling. version:1
arxiv-1612-00374 | Spatial Decompositions for Large Scale SVMs | http://arxiv.org/abs/1612.00374 | id:1612.00374 author:Philipp Thomann, Ingo Steinwart, Ingrid Blaschzyk, Mona Meister category:stat.ML cs.LG  published:2016-12-01 summary:Although support vector machines (SVMs) are theoretically well understood, their underlying optimization problem becomes very expensive if, for example, hundreds of thousands of samples and a non-linear kernel are considered. Several approaches have been proposed in the past to address this serious limitation. In this work we investigate a decomposition strategy that learns on small, spatially defined data chunks. Our contributions are two fold: On the theoretical side we establish an oracle inequality for the overall learning method using the hinge loss, and show that the resulting rates match those known for SVMs solving the complete optimization problem with Gaussian kernels. On the practical side we compare our approach to learning SVMs on small, randomly chosen chunks. Here it turns out that for comparable training times our approach is significantly faster during testing and also reduces the test error in most cases significantly. Furthermore, we show that our approach easily scales up to 10 million training samples: including hyper-parameter selection using cross validation, the entire training only takes a few hours on a single machine. Finally, we report an experiment on 32 million training samples. version:1
arxiv-1612-00370 | Optimization of image description metrics using policy gradient methods | http://arxiv.org/abs/1612.00370 | id:1612.00370 author:Siqi Liu, Zhenhai Zhu, Ning Ye, Sergio Guadarrama, Kevin Murphy category:cs.CV cs.CL  published:2016-12-01 summary:In this paper, we propose a novel training procedure for image captioning models based on policy gradient methods. This allows us to directly optimize for the metrics of interest, rather than just maximizing likelihood of human generated captions. We show that by optimizing for standard metrics such as BLEU, CIDEr, METEOR and ROUGE, we can develop a system that improve on the metrics and ranks first on the MSCOCO image captioning leader board, even though our CNN-RNN model is much simpler than state of the art models. We further show that by also optimizing for the recently introduced SPICE metric, which measures semantic quality of captions, we can produce a system that significantly outperforms other methods as measured by human evaluation. Finally, we show how we can leverage extra sources of information, such as pre-trained image tagging models, to further improve quality version:1
arxiv-1611-08240 | AdaScan: Adaptive Scan Pooling in Deep Convolutional Neural Networks for Human Action Recognition in Videos | http://arxiv.org/abs/1611.08240 | id:1611.08240 author:Amlan Kar, Nishant Rai, Karan Sikka, Gaurav Sharma category:cs.CV  published:2016-11-24 summary:We propose a novel method for temporally pooling frames in a video for the task of human action recognition. The method is motivated by the observation that there are only a small number of frames which, together, contain sufficient information to discriminate an action class present in a video, from the rest. The proposed method learns to pool such discriminative and informative frames, while discarding a majority of the non-informative frames in a single temporal scan of the video. Our algorithm does so by continuously predicting the discriminative importance of each video frame and subsequently pooling them in a deep learning framework. We show the effectiveness of our proposed pooling method on standard benchmarks where it consistently improves on baseline pooling methods, with both RGB and optical flow based Convolutional networks. Further, in combination with complementary video representations, we show results that are competitive with respect to the state-of-the-art results on two challenging and publicly available benchmark datasets. version:2
arxiv-1612-00367 | Large-scale Validation of Counterfactual Learning Methods: A Test-Bed | http://arxiv.org/abs/1612.00367 | id:1612.00367 author:Damien Lefortier, Adith Swaminathan, Xiaotao Gu, Thorsten Joachims, Maarten de Rijke category:cs.LG cs.AI stat.ML  published:2016-12-01 summary:The ability to perform effective off-policy learning would revolutionize the process of building better interactive systems, such as search engines and recommendation systems for e-commerce, computational advertising and news. Recent approaches for off-policy evaluation and learning in these settings appear promising. With this paper, we provide real-world data and a standardized test-bed to systematically investigate these algorithms using data from display advertising. In particular, we consider the problem of filling a banner ad with an aggregate of multiple products the user may want to purchase. This paper presents our test-bed, the sanity checks we ran to ensure its validity, and shows results comparing state-of-the-art off-policy learning methods like doubly robust optimization, POEM, and reductions to supervised learning using regression baselines. Our results show experimental evidence that recent off-policy learning methods can improve upon state-of-the-art supervised learning techniques on a large-scale real-world data set. version:1
arxiv-1612-00356 | A Diffeomorphic Approach to Multimodal Registration with Mutual Information: Applications to CLARITY Mouse Brain Images | http://arxiv.org/abs/1612.00356 | id:1612.00356 author:Kwame S. Kutten, Nicolas Charon, Michael I. Miller, J. Tilak Ratnanather, Karl Deisseroth, Li Ye, Joshua T. Vogelstein category:cs.CV  published:2016-12-01 summary:Large Deformation Diffeomorphic Metric Mapping (LDDMM) is a widely used deformable registration algorithm for computing smooth invertible maps between various types of anatomical shapes such as landmarks, curves, surfaces or images. In this work, we specifically focus on the case of images and adopt an optimal control point of view so as to extend the original LDDMM with Sum of Squared Differences (SSD) matching term to a framework more robust to intensity variations, which is critical for cross-modality registration. We implement a mutual information based LDDMM (MI-LDDMM) algorithm and demonstrate its superiority to SSD-LDDMM in aligning 2D phantoms with differing intensity profiles. This algorithm is then used to register CLARITY mouse brain images to a standard mouse atlas despite their differences in grayscale values. We complement the approach by showing how a cascaded multi-scale method improves the optimization while reducing the run time of the algorithm. version:1
arxiv-1612-00347 | Bootstrapping incremental dialogue systems: using linguistic knowledge to learn from minimal data | http://arxiv.org/abs/1612.00347 | id:1612.00347 author:Dimitrios Kalatzis, Arash Eshghi, Oliver Lemon category:cs.CL cs.AI cs.HC  published:2016-12-01 summary:We present a method for inducing new dialogue systems from very small amounts of unannotated dialogue data, showing how word-level exploration using Reinforcement Learning (RL), combined with an incremental and semantic grammar - Dynamic Syntax (DS) - allows systems to discover, generate, and understand many new dialogue variants. The method avoids the use of expensive and time-consuming dialogue act annotations, and supports more natural (incremental) dialogues than turn-based systems. Here, language generation and dialogue management are treated as a joint decision/optimisation problem, and the MDP model for RL is constructed automatically. With an implemented system, we show that this method enables a wide range of dialogue variations to be automatically captured, even when the system is trained from only a single dialogue. The variants include question-answer pairs, over- and under-answering, self- and other-corrections, clarification interaction, split-utterances, and ellipsis. This generalisation property results from the structural knowledge and constraints present within the DS grammar, and highlights some limitations of recent systems built using machine learning techniques only. version:1
arxiv-1612-00343 | Global Minimum for a Finsler Elastica Minimal Path Approach | http://arxiv.org/abs/1612.00343 | id:1612.00343 author:Da Chen, Jean-Marie Mirebeau, Laurent D. Cohen category:cs.CG cs.CV  published:2016-12-01 summary:In this paper, we propose a novel curvature-penalized minimal path model via an orientation-lifted Finsler metric and the Euler elastica curve. The original minimal path model computes the globally minimal geodesic by solving an Eikonal partial differential equation (PDE). Essentially, this first-order model is unable to penalize curvature which is related to the path rigidity property in the classical active contour models. To solve this problem, we present an Eikonal PDE-based Finsler elastica minimal path approach to address the curvature-penalized geodesic energy minimization problem. We were successful at adding the curvature penalization to the classical geodesic energy. The basic idea of this work is to interpret the Euler elastica bending energy via a novel Finsler elastica metric that embeds a curvature penalty. This metric is non-Riemannian, anisotropic and asymmetric, and is defined over an orientation-lifted space by adding to the image domain the orientation as an extra space dimension. Based on this orientation lifting, the proposed minimal path model can benefit from both the curvature and orientation of the paths. Thanks to the fast marching method, the global minimum of the curvature-penalized geodesic energy can be computed efficiently. We introduce two anisotropic image data-driven speed functions that are computed by steerable filters. Based on these orientation-dependent speed functions, we can apply the proposed Finsler elastica minimal path model to the applications of closed contour detection, perceptual grouping and tubular structure extraction. Numerical experiments on both synthetic and real images show that these applications of the proposed model indeed obtain promising results. version:1
arxiv-1612-00341 | A Compositional Object-Based Approach to Learning Physical Dynamics | http://arxiv.org/abs/1612.00341 | id:1612.00341 author:Michael B. Chang, Tomer Ullman, Antonio Torralba, Joshua B. Tenenbaum category:cs.AI cs.LG  published:2016-12-01 summary:We present the Neural Physics Engine (NPE), an object-based neural network architecture for learning predictive models of intuitive physics. We propose a factorization of a physical scene into composable object-based representations and also the NPE architecture whose compositional structure factorizes object dynamics into pairwise interactions. Our approach draws on the strengths of both symbolic and neural approaches: like a symbolic physics engine, the NPE is endowed with generic notions of objects and their interactions, but as a neural network it can also be trained via stochastic gradient descent to adapt to specific object properties and dynamics of different worlds. We evaluate the efficacy of our approach on simple rigid body dynamics in two-dimensional worlds. By comparing to less structured architectures, we show that our model's compositional representation of the structure in physical interactions improves its ability to predict movement, generalize to different numbers of objects, and infer latent properties of objects such as mass. version:1
arxiv-1612-00338 | Hippocampus Temporal Lobe Epilepsy Detection using a Combination of Shape-based Features and Spherical Harmonics Representation | http://arxiv.org/abs/1612.00338 | id:1612.00338 author:Zohreh Kohan, Reza Azmi, Behrouz Gholizadeh category:cs.CV  published:2016-12-01 summary:Most of the temporal lobe epilepsy detection approaches are based on hippocampus deformation and use complicated features, resulting, detection is done with complicated features extraction and pre-processing task. In this paper, a new detection method based on shape-based features and spherical harmonics is proposed which can analysis the hippocampus shape anomaly and detection asymmetry. This method consisted of two main parts; (1) shape feature extraction, and (2) image classification. For evaluation, HFH database is used which is publicly available in this field. Nine different geometry and 256 spherical harmonic features are introduced then selected Eighteen of them that detect the asymmetry in hippocampus significantly in a randomly selected subset of the dataset. Then a support vector machine (SVM) classifier was employed to classify the remaining images of the dataset to normal and epileptic images using our selected features. On a dataset of 25 images, 12 images were used for feature extraction and the rest 13 for classification. The results show that the proposed method has accuracy, specificity and sensitivity of, respectively, 84%, 100%, and 80%. Therefore, the proposed approach shows acceptable result and is straightforward also; complicated pre-processing steps were omitted compared to other methods. version:1
arxiv-1612-00246 | Multilingual Multiword Expressions | http://arxiv.org/abs/1612.00246 | id:1612.00246 author:Lahari Poddar category:cs.CL  published:2016-12-01 summary:The project aims to provide a semi-supervised approach to identify Multiword Expressions in a multilingual context consisting of English and most of the major Indian languages. Multiword expressions are a group of words which refers to some conventional or regional way of saying things. If they are literally translated from one language to another the expression will lose its inherent meaning. To automatically extract multiword expressions from a corpus, an extraction pipeline have been constructed which consist of a combination of rule based and statistical approaches. There are several types of multiword expressions which differ from each other widely by construction. We employ different methods to detect different types of multiword expressions. Given a POS tagged corpus in English or any Indian language the system initially applies some regular expression filters to narrow down the search space to certain patterns (like, reduplication, partial reduplication, compound nouns, compound verbs, conjunct verbs etc.). The word sequences matching the required pattern are subjected to a series of linguistic tests which include verb filtering, named entity filtering and hyphenation filtering test to exclude false positives. The candidates are then checked for semantic relationships among themselves (using Wordnet). In order to detect partial reduplication we make use of Wordnet as a lexical database as well as a tool for lemmatising. We detect complex predicates by investigating the features of the constituent words. Statistical methods are applied to detect collocations. Finally, lexicographers examine the list of automatically extracted candidates to validate whether they are true multiword expressions or not and add them to the multiword dictionary accordingly. version:1
arxiv-1612-00694 | ESE: Efficient Speech Recognition Engine with Compressed LSTM on FPGA | http://arxiv.org/abs/1612.00694 | id:1612.00694 author:Song Han, Junlong Kang, Huizi Mao, Yiming Hu, Xin Li, Yubin Li, Dongliang Xie, Hong Luo, Song Yao, Yu Wang, Huazhong Yang, William J. Dally category:cs.CL  published:2016-12-01 summary:Long Short-Term Memory (LSTM) is widely used in speech recognition. In order to achieve higher prediction accuracy, machine learning scientists have built larger and larger models. Such large model is both computation intensive and memory intensive. Deploying such bulky model results in high power consumption and leads to high total cost of ownership (TCO) of a data center. In order to speedup the prediction and make it energy efficient, we first propose a load-balance-aware pruning method that can compress the LSTM model size by 20x (10x from pruning and 2x from quantization) with negligible loss of the prediction accuracy. The pruned model is friendly for parallel processing. Next, we propose scheduler that encodes and partitions the compressed model to each PE for parallelism, and schedule the complicated LSTM data flow. Finally, we design the hardware architecture, named Efficient Speech Recognition Engine (ESE) that works directly on the compressed model. Implemented on Xilinx XCKU060 FPGA running at 200MHz, ESE has a performance of 282 GOPS working directly on the compressed LSTM network, corresponding to 2.52 TOPS on the uncompressed one, and processes a full LSTM for speech recognition with a power dissipation of 41 Watts. Evaluated on the LSTM for speech recognition benchmark, ESE is 43x and 3x faster than Core i7 5930k CPU and Pascal Titan X GPU implementations. It achieves 40x and 11.5x higher energy efficiency compared with the CPU and GPU respectively. version:1
arxiv-1612-00234 | Video Captioning with Multi-Faceted Attention | http://arxiv.org/abs/1612.00234 | id:1612.00234 author:Xiang Long, Chuang Gan, Gerard de Melo category:cs.CV  published:2016-12-01 summary:Recently, video captioning has been attracting an increasing amount of interest, due to its potential for improving accessibility and information retrieval. While existing methods rely on different kinds of visual features and model structures, they do not fully exploit relevant semantic information. We present an extensible approach to jointly leverage several sorts of visual features and semantic attributes. Our novel architecture builds on LSTMs for sentence generation, with several attention layers and two multimodal layers. The attention mechanism learns to automatically select the most salient visual features or semantic attributes, and the multimodal layer yields overall representations for the input and outputs of the sentence generation component. Experimental results on the challenging MSVD and MSR-VTT datasets show that our framework outperforms the state-of-the-art approaches, while ground truth based semantic attributes are able to further elevate the output quality to a near-human level. version:1
arxiv-1612-00227 | On Coreferring Text-extracted Event Descriptions with the aid of Ontological Reasoning | http://arxiv.org/abs/1612.00227 | id:1612.00227 author:Stefano Borgo, Loris Bozzato, Alessio Palmero Aprosio, Marco Rospocher, Luciano Serafini category:cs.AI cs.CL I.2.4  published:2016-12-01 summary:Systems for automatic extraction of semantic information about events from large textual resources are now available: these tools are capable to generate RDF datasets about text extracted events and this knowledge can be used to reason over the recognized events. On the other hand, text based tasks for event recognition, as for example event coreference (i.e. recognizing whether two textual descriptions refer to the same event), do not take into account ontological information of the extracted events in their process. In this paper, we propose a method to derive event coreference on text extracted event data using semantic based rule reasoning. We demonstrate our method considering a limited (yet representative) set of event types: we introduce a formal analysis on their ontological properties and, on the base of this, we define a set of coreference criteria. We then implement these criteria as RDF-based reasoning rules to be applied on text extracted event data. We evaluate the effectiveness of our approach over a standard coreference benchmark dataset. version:1
arxiv-1612-00222 | Interaction Networks for Learning about Objects, Relations and Physics | http://arxiv.org/abs/1612.00222 | id:1612.00222 author:Peter W. Battaglia, Razvan Pascanu, Matthew Lai, Danilo Rezende, Koray Kavukcuoglu category:cs.AI cs.LG  published:2016-12-01 summary:Reasoning about objects, relations, and physics is central to human intelligence, and a key goal of artificial intelligence. Here we introduce the interaction network, a model which can reason about how objects in complex systems interact, supporting dynamical predictions, as well as inferences about the abstract properties of the system. Our model takes graphs as input, performs object- and relation-centric reasoning in a way that is analogous to a simulation, and is implemented using deep neural networks. We evaluate its ability to reason about several challenging physical domains: n-body problems, rigid-body collision, and non-rigid dynamics. Our results show it can be trained to accurately simulate the physical trajectories of dozens of objects over thousands of time steps, estimate abstract quantities such as energy, and generalize automatically to systems with different numbers and configurations of objects and relations. Our interaction network implementation is the first general-purpose, learnable physics engine, and a powerful general framework for reasoning about object and relations in a wide variety of complex real-world domains. version:1
arxiv-1612-00221 | The Coconut Model with Heterogeneous Strategies and Learning | http://arxiv.org/abs/1612.00221 | id:1612.00221 author:Sven Banisch, Eckehard Olbrich category:q-fin.EC cs.LG nlin.AO 91-08  68T05  60J10  published:2016-12-01 summary:In this paper, we develop an agent-based version of the Diamond search equilibrium model - also called Coconut Model. In this model, agents are faced with production decisions that have to be evaluated based on their expectations about the future utility of the produced entity which in turn depends on the global production level via a trading mechanism. While the original dynamical systems formulation assumes an infinite number of homogeneously adapting agents obeying strong rationality conditions, the agent-based setting allows to discuss the effects of heterogeneous and adaptive expectations and enables the analysis of non-equilibrium trajectories. Starting from a baseline implementation that matches the asymptotic behavior of the original model, we show how agent heterogeneity can be accounted for in the aggregate dynamical equations. We then show that when agents adapt their strategies by a simple temporal difference learning scheme, the system converges to one of the fixed points of the original system. Systematic simulations reveal that this is the only stable equilibrium solution. version:1
arxiv-1612-00220 | Fully Convolutional Crowd Counting On Highly Congested Scenes | http://arxiv.org/abs/1612.00220 | id:1612.00220 author:Mark Marsden, Kevin McGuiness, Suzanne Little, Noel E. O'Connor category:cs.CV  published:2016-12-01 summary:In this paper we advance the state-of-the-art for crowd counting in high density scenes by further exploring the idea of a fully convolutional crowd counting model introduced by (Zhang et al., 2016). Producing an accurate and robust crowd count estimator using computer vision techniques has attracted significant research interest in recent years. Applications for crowd counting systems exist in many diverse areas including city planning, retail, and of course general public safety. Developing a highly generalised counting model that can be deployed in any surveillance scenario with any camera perspective is the key objective for research in this area. Techniques developed in the past have generally performed poorly in highly congested scenes with several thousands of people in frame (Rodriguez et al., 2011). Our approach, influenced by the work of (Zhang et al., 2016), consists of the following contributions: (1) A training set augmentation scheme that minimises redundancy among training samples to improve model generalisation and overall counting performance; (2) a deep, single column, fully convolutional network (FCN) architecture; (3) a multi-scale averaging step during inference. The developed technique can analyse images of any resolution or aspect ratio and achieves state-of-the-art counting performance on the Shanghaitech Part B and UCF CC 50 datasets as well as competitive performance on Shanghaitech Part A. version:1
arxiv-1612-00215 | Learning to Generate Images of Outdoor Scenes from Attributes and Semantic Layouts | http://arxiv.org/abs/1612.00215 | id:1612.00215 author:Levent Karacan, Zeynep Akata, Aykut Erdem, Erkut Erdem category:cs.CV  published:2016-12-01 summary:Automatic image synthesis research has been rapidly growing with deep networks getting more and more expressive. In the last couple of years, we have observed images of digits, indoor scenes, birds, chairs, etc. being automatically generated. The expressive power of image generators have also been enhanced by introducing several forms of conditioning variables such as object names, sentences, bounding box and key-point locations. In this work, we propose a novel deep conditional generative adversarial network architecture that takes its strength from the semantic layout and scene attributes integrated as conditioning variables. We show that our architecture is able to generate realistic outdoor scene images under different conditions, e.g. day-night, sunny-foggy, with clear object boundaries. version:1
arxiv-1612-00212 | Training Bit Fully Convolutional Network for Fast Semantic Segmentation | http://arxiv.org/abs/1612.00212 | id:1612.00212 author:He Wen, Shuchang Zhou, Zhe Liang, Yuxiang Zhang, Dieqiao Feng, Xinyu Zhou, Cong Yao category:cs.CV cs.LG  published:2016-12-01 summary:Fully convolutional neural networks give accurate, per-pixel prediction for input images and have applications like semantic segmentation. However, a typical FCN usually requires lots of floating point computation and large run-time memory, which effectively limits its usability. We propose a method to train Bit Fully Convolution Network (BFCN), a fully convolutional neural network that has low bit-width weights and activations. Because most of its computation-intensive convolutions are accomplished between low bit-width numbers, a BFCN can be accelerated by an efficient bit-convolution implementation. On CPU, the dot product operation between two bit vectors can be reduced to bitwise operations and popcounts, which can offer much higher throughput than 32-bit multiplications and additions. To validate the effectiveness of BFCN, we conduct experiments on the PASCAL VOC 2012 semantic segmentation task and Cityscapes. Our BFCN with 1-bit weights and 2-bit activations, which runs 7.8x faster on CPU or requires less than 1\% resources on FPGA, can achieve comparable performance as the 32-bit counterpart. version:1
arxiv-1611-08207 | Texture Synthesis with Spatial Generative Adversarial Networks | http://arxiv.org/abs/1611.08207 | id:1611.08207 author:Nikolay Jetchev, Urs Bergmann, Roland Vollgraf category:cs.CV stat.ML  published:2016-11-24 summary:Generative adversarial networks (GANs) are a recent approach to train generative models of data, which have been shown to work particularly well on image data. In the current paper we introduce a new model for texture synthesis based on GAN learning. By extending the input noise distribution space from a single vector to a whole spatial tensor, we create an architecture with properties well suited to the task of texture synthesis, which we call spatial GAN (SGAN). To our knowledge, this is the first successful completely data-driven texture synthesis method based on GANs. Our method has the following features which make it a state of the art algorithm for texture synthesis: high image quality of the generated textures, very high scalability w.r.t. the output texture size, fast real-time forward generation, the ability to fuse multiple diverse source images in complex textures. To illustrate these capabilities we present multiple experiments with different classes of texture images and use cases. We also discuss some limitations of our method with respect to the types of texture images it can synthesize, and compare it to other neural techniques for texture generation. version:2
arxiv-1612-00197 | Learning in an Uncertain World: Representing Ambiguity Through Multiple Hypotheses | http://arxiv.org/abs/1612.00197 | id:1612.00197 author:Christian Rupprecht, Iro Laina, Maximilian Baust, Federico Tombari, Gregory D. Hager, Nassir Navab category:cs.CV  published:2016-12-01 summary:Many prediction tasks contain uncertainty. In the case of next-frame or future prediction the uncertainty is inherent in the task itself, as it is impossible to foretell what exactly is going to happen in the future. Another source of uncertainty or ambiguity is the way data is labeled. Sometimes not all objects of interest are annotated in a given image or the annotation is ambiguous, e.g. in the form of occluded joints in human pose estimation. We present a method that is able to handle these problems by predicting not a single output but multiple hypotheses. More precisely, we propose a framework for re-formulating existing single prediction models as multiple hypothesis prediction (MHP) problems as well as a meta loss and an optimization procedure to train the resulting MHP model. We consider three entirely different applications, i.e. future prediction, image classification and human pose estimation, and demonstrate how existing single hypothesis predictors (SHPs) can be turned into MHPs. The performed experiments show that the resulting MHP outperforms the existing SHP and yields additional insights regarding the variation and ambiguity of the predictions. version:1
arxiv-1612-00193 | Learning Potential Energy Landscapes using Graph Kernels | http://arxiv.org/abs/1612.00193 | id:1612.00193 author:G. Ferré, T. Haut, K. Barros category:physics.comp-ph cs.LG stat.ML  published:2016-12-01 summary:Recent machine learning methods make it possible to model potential energy of atomic configurations with chemical-level accuracy (as calculated from ab-initio calculations) and at speeds suitable for molecular dynamics simulation. Best performance is achieved when the known physical constraints are encoded in the machine learning models. For example, the atomic energy is invariant under global translations and rotations; it is also invariant to permutations of same-species atoms. Although simple to state, these symmetries are complicated to encode into machine learning algorithms. In this paper, we present a machine learning approach based on graph theory that naturally incorporates translation, rotation, and permutation symmetries. Specifically, we use a random walk graph kernel to measure the similarity of two adjacency matrices, each of which represents a local atomic environment. We show on a standard benchmark that our Graph Approximated Energy (GRAPE) method is competitive with state of the art kernel methods. Furthermore, the GRAPE framework is flexible and admits many possible extensions. version:1
arxiv-1612-00192 | Flight Dynamics-based Recovery of a UAV Trajectory using Ground Cameras | http://arxiv.org/abs/1612.00192 | id:1612.00192 author:Artem Rozantsev, Sudipta N. Sinha, Debadeepta Dey, Pascal Fua category:cs.CV cs.RO  published:2016-12-01 summary:We propose a new method to estimate the 6-dof trajectory of a flying object such as a quadrotor UAV within a 3D airspace monitored using multiple fixed ground cameras. It is based on a new structure from motion formulation for the 3D reconstruction of a single moving point with known motion dynamics. Our main contribution is a new bundle adjustment procedure which in addition to optimizing the camera poses, regularizes the point trajectory using a prior based on motion dynamics (or specifically flight dynamics). Furthermore, we can infer the underlying control input sent to the UAV's autopilot that determined its flight trajectory. Our method requires neither perfect single-view tracking nor appearance matching across views. For robustness, we allow the tracker to generate multiple detections per frame in each video. The true detections and the data association across videos is estimated using robust multi-view triangulation and subsequently refined during our bundle adjustment procedure. Quantitative evaluation on simulated data and experiments on real videos from indoor and outdoor scenes demonstrates the effectiveness of our method. version:1
arxiv-1612-00181 | Monge's Optimal Transport Distance with Applications for Nearest Neighbour Image Classification | http://arxiv.org/abs/1612.00181 | id:1612.00181 author:Michael Miller, Jan Van lent category:cs.CV math.NA 65N06  published:2016-12-01 summary:This paper focuses on a similarity measure, known as the Wasserstein distance, with which to compare images. The Wasserstein distance results from a partial differential equation (PDE) formulation of Monge's optimal transport problem. We present an efficient numerical solution method for solving Monge's problem. To demonstrate the measure's discriminatory power when comparing images, we use it within the architecture of the $k$-Nearest Neighbour ($k$-NN) machine learning algorithm to illustrate the measure's potential benefits over other more traditional distance metrics and also the state-of-the-art Tangent Space distance on the well-known MNIST dataset. To our knowledge, the PDE formulation of the Wasserstein metric has not been presented for dealing with image comparison, nor has the Wasserstein distance been used within the $k$-nearest neighbour architecture. version:1
arxiv-1612-00155 | Adversarial Images for Variational Autoencoders | http://arxiv.org/abs/1612.00155 | id:1612.00155 author:Pedro Tabacof, Julia Tavares, Eduardo Valle category:cs.NE cs.CV cs.LG  published:2016-12-01 summary:We investigate adversarial attacks for autoencoders. We propose a procedure that distorts the input image to mislead the autoencoder in reconstructing a completely different target image. We attack the internal latent representations, attempting to make the adversarial input produce an internal representation as similar as possible as the target's. We find that autoencoders are much more robust to the attack than classifiers: while some examples have tolerably small input distortion, and reasonable similarity to the target image, there is a quasi-linear trade-off between those aims. We report results on MNIST and SVHN datasets, and also test regular deterministic autoencoders, reaching similar conclusions in all cases. Finally, we show that the usual adversarial attack for classifiers, while being much easier, also presents a direct proportion between distortion on the input, and misdirection on the output. That proportionality however is hidden by the normalization of the output, which maps a linear layer into non-linear probabilities. version:1
arxiv-1612-00814 | Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision | http://arxiv.org/abs/1612.00814 | id:1612.00814 author:Xinchen Yan, Jimei Yang, Ersin Yumer, Yijie Guo, Honglak Lee category:cs.CV cs.GR cs.LG  published:2016-12-01 summary:Understanding the 3D world is a fundamental problem in computer vision. However, learning a good representation of 3D objects is still an open problem due to the high dimensionality of the data and many factors of variation involved. In this work, we investigate the task of single-view 3D object reconstruction from a learning agent's perspective. We formulate the learning process as an interaction between 3D and 2D representations and propose an encoder-decoder network with a novel projection loss defined by the perspective transformation. More importantly, the projection loss enables the unsupervised learning using 2D observation without explicit 3D supervision. We demonstrate the ability of the model in generating 3D volume from a single 2D image with three sets of experiments: (1) learning from single-class objects; (2) learning from multi-class objects and (3) testing on novel object classes. Results show superior performance and better generalization ability for 3D object reconstruction when the projection loss is involved. version:1
arxiv-1612-00151 | A New Method for Classification of Datasets for Data Mining | http://arxiv.org/abs/1612.00151 | id:1612.00151 author:Singh Vijendra, Hemjyotsana Parashar, Nisha Vasudeva category:cs.LG cs.DB stat.ML  published:2016-12-01 summary:Decision tree is an important method for both induction research and data mining, which is mainly used for model classification and prediction. ID3 algorithm is the most widely used algorithm in the decision tree so far. In this paper, the shortcoming of ID3's inclining to choose attributes with many values is discussed, and then a new decision tree algorithm which is improved version of ID3. In our proposed algorithm attributes are divided into groups and then we apply the selection measure 5 for these groups. If information gain is not good then again divide attributes values into groups. These steps are done until we get good classification/misclassification ratio. The proposed algorithms classify the data sets more accurately and efficiently. version:1
arxiv-1612-00148 | Domain Adaptation for Named Entity Recognition in Online Media with Word Embeddings | http://arxiv.org/abs/1612.00148 | id:1612.00148 author:Vivek Kulkarni, Yashar Mehdad, Troy Chevalier category:cs.CL cs.IR  published:2016-12-01 summary:Content on the Internet is heterogeneous and arises from various domains like News, Entertainment, Finance and Technology. Understanding such content requires identifying named entities (persons, places and organizations) as one of the key steps. Traditionally Named Entity Recognition (NER) systems have been built using available annotated datasets (like CoNLL, MUC) and demonstrate excellent performance. However, these models fail to generalize onto other domains like Sports and Finance where conventions and language use can differ significantly. Furthermore, several domains do not have large amounts of annotated labeled data for training robust Named Entity Recognition models. A key step towards this challenge is to adapt models learned on domains where large amounts of annotated training data are available to domains with scarce annotated data. In this paper, we propose methods to effectively adapt models learned on one domain onto other domains using distributed word representations. First we analyze the linguistic variation present across domains to identify key linguistic insights that can boost performance across domains. We propose methods to capture domain specific semantics of word usage in addition to global semantics. We then demonstrate how to effectively use such domain specific knowledge to learn NER models that outperform previous baselines in the domain adaptation setting. version:1
arxiv-1612-00138 | Towards Robust Deep Neural Networks with BANG | http://arxiv.org/abs/1612.00138 | id:1612.00138 author:Andras Rozsa, Manuel Gunther, Terrance E. Boult category:cs.CV  published:2016-12-01 summary:Machine learning models, including state-of-the-art deep neural networks, are vulnerable to small perturbations that cause unexpected classification errors. This unexpected lack of robustness raises fundamental questions about their generalization properties and poses a serious concern for practical deployments. As such perturbations can remain imperceptible - commonly called adversarial examples that demonstrate an inherent inconsistency between vulnerable machine learning models and human perception - some prior work casts this problem as a security issue as well. Despite the significance of the discovered instabilities and ensuing research, their cause is not well understood, and no effective method has been developed to address the problem highlighted by adversarial examples. In this paper, we present a novel theory to explain why this unpleasant phenomenon exists in deep neural networks. Based on that theory, we introduce a simple, efficient and effective training approach, Batch Adjusted Network Gradients (BANG), which significantly improves the robustness of machine learning models. While the BANG technique does not rely on any form of data augmentation or the application of adversarial images for training, the resultant classifiers are more resistant to adversarial perturbations while maintaining or even enhancing classification performance overall. version:1
arxiv-1612-00750 | Non-Negative Matrix Factorizations for Multiplex Network Analysis | http://arxiv.org/abs/1612.00750 | id:1612.00750 author:Vladimir Gligorijevic, Yannis Panagakis, Stefanos Zafeiriou category:cs.SI stat.ML  published:2016-12-01 summary:Networks have been a general tool for representing, analyzing, and modeling relational data arising in several domains. One of the most important aspect of network analysis is community detection or network clustering. Until recently, the major focus have been on discovering community structure in single (i.e., monoplex) networks. However, with the advent of relational data with multiple modalities, multiplex networks, i.e., networks composed of multiple layers representing different aspects of relations, have emerged. Consequently, community detection in multiplex network, i.e., detecting clusters of nodes shared by all layers, has become a new challenge. In this paper, we propose Network Fusion for Composite Community Extraction (NF-CCE), a new class of algorithms, based on four different non-negative matrix factorization models, capable of extracting composite communities in multiplex networks. Each algorithm works in two steps: first, it finds a non-negative, low-dimensional feature representation of each network layer; then, it fuses the feature representation of layers into a common non-negative, low-dimensional feature representation via collective factorization. The composite clusters are extracted from the common feature representation. We demonstrate the superior performance of our algorithms over the state-of-the-art methods on various types of multiplex networks, including biological, social, economic, citation, phone communication, and brain multiplex networks. version:1
arxiv-1612-00137 | RMPE: Regional Multi-person Pose Estimation | http://arxiv.org/abs/1612.00137 | id:1612.00137 author:Haoshu Fang, Shuqin Xie, Cewu Lu category:cs.CV  published:2016-12-01 summary:Multi-person pose estimation in wild images is a challenging problem, where human detector inevitably suffers from errors both in localization and recognition. These undesirable errors would ultimately result in failures of most CNN-based single-person pose estimators. In this paper, a novel regional multi-person pose estimation (RMPE) framework is proposed to facilitate single-person pose estimator in presence of the inaccurate human detector. In particular, our framework consists of three novel techniques, namely, symmetric spatial transformer network (SSTN), deep proposals generator (DPG) and parametric pose non-maximum suppression (NMS). Extensive experimental results have demonstrated the validity and effectiveness of the proposed approach. In comparison to the state-of-the-art approach, the proposed approach significantly achieves 16% relative increase in mAP on MPII (multi person) dataset[1]. Our model and source codes are publicly available. version:1
arxiv-1612-00132 | CDVAE: Co-embedding Deep Variational Auto Encoder for Conditional Variational Generation | http://arxiv.org/abs/1612.00132 | id:1612.00132 author:Jiajun Lu, Aditya Deshpande, David Forsyth category:cs.CV cs.AI cs.GR  published:2016-12-01 summary:Problems such as predicting an optical flow field (Y) for an image (X) are ambiguous: many very distinct solutions are good. Representing this ambiguity requires building a conditional model P(Y X) of the prediction, conditioned on the image. It is hard because training data usually does not contain many different flow fields for the same image. As a result, we need different images to share data to produce good models. We demonstrate an improved method for building conditional models, the Co-Embedding Deep Variational Auto Encoder. Our CDVAE exploits multiple encoding and decoding layers for both X and Y. These are tied during training to produce a model of the joint distribution P(X, Y), which provides the necessary smoothing. Our tying procedure is designed to yield a conditional model easy at test time. We demonstrate our model on three example tasks using real data: image saturation adjustment, image relighting, and motion prediction. We describe quantitative evaluation metrics to evaluate ambiguous generation results. Our results quantitatively and qualitatively advance the state of the art. version:1
arxiv-1612-00119 | Video Scene Parsing with Predictive Feature Learning | http://arxiv.org/abs/1612.00119 | id:1612.00119 author:Xiaojie Jin, Xin Li, Huaxin Xiao, Xiaohui Shen, Zhe Lin, Jimei Yang, Yunpeng Chen, Jian Dong, Luoqi Liu, Zequn Jie, Jiashi Feng, Shuicheng Yan category:cs.CV  published:2016-12-01 summary:In this work, we address the challenging video scene parsing problem by developing effective representation learning methods given limited parsing annotations. In particular, we contribute two novel methods that constitute a unified parsing framework. (1) \textbf{Predictive feature learning}} from nearly unlimited unlabeled video data. Different from existing methods learning features from single frame parsing, we learn spatiotemporal discriminative features by enforcing a parsing network to predict future frames and their parsing maps (if available) given only historical frames. In this way, the network can effectively learn to capture video dynamics and temporal context, which are critical clues for video scene parsing, without requiring extra manual annotations. (2) \textbf{Prediction steering parsing}} architecture that effectively adapts the learned spatiotemporal features to scene parsing tasks and provides strong guidance for any off-the-shelf parsing model to achieve better video scene parsing performance. Extensive experiments over two challenging datasets, Cityscapes and Camvid, have demonstrated the effectiveness of our methods by showing significant improvement over well-established baselines. version:1
arxiv-1611-09921 | Less is More: Learning Prominent and Diverse Topics for Data Summarization | http://arxiv.org/abs/1611.09921 | id:1611.09921 author:Jian Tang, Cheng Li, Ming Zhang, Qiaozhu Mei category:cs.LG cs.CL cs.IR  published:2016-11-29 summary:Statistical topic models efficiently facilitate the exploration of large-scale data sets. Many models have been developed and broadly used to summarize the semantic structure in news, science, social media, and digital humanities. However, a common and practical objective in data exploration tasks is not to enumerate all existing topics, but to quickly extract representative ones that broadly cover the content of the corpus, i.e., a few topics that serve as a good summary of the data. Most existing topic models fit exactly the same number of topics as a user specifies, which have imposed an unnecessary burden to the users who have limited prior knowledge. We instead propose new models that are able to learn fewer but more representative topics for the purpose of data summarization. We propose a reinforced random walk that allows prominent topics to absorb tokens from similar and smaller topics, thus enhances the diversity among the top topics extracted. With this reinforced random walk as a general process embedded in classical topic models, we obtain \textit{diverse topic models} that are able to extract the most prominent and diverse topics from data. The inference procedures of these diverse topic models remain as simple and efficient as the classical models. Experimental results demonstrate that the diverse topic models not only discover topics that better summarize the data, but also require minimal prior knowledge of the users. version:2
arxiv-1612-00101 | Shape Completion using 3D-Encoder-Predictor CNNs and Shape Synthesis | http://arxiv.org/abs/1612.00101 | id:1612.00101 author:Angela Dai, Charles Ruizhongtai Qi, Matthias Nießner category:cs.CV  published:2016-12-01 summary:We introduce a data-driven approach to complete partial 3D shapes through a combination of volumetric deep neural networks and 3D shape synthesis. From a partially-scanned input shape, our method first infers a low-resolution -- but complete -- output. To this end, we introduce a 3D-Encoder-Predictor Network (3D-EPN) which is composed of 3D convolutional layers. The network is trained to predict and fill in missing data, and operates on an implicit surface representation that encodes both known and unknown space. This allows us to predict global structure in unknown areas at high accuracy. We then correlate these intermediary results with 3D geometry from a shape database at test time. In a final pass, we propose a patch-based 3D shape synthesis method that imposes the 3D geometry from these retrieved shapes as constraints on the coarsely-completed mesh. This synthesis process enables us to reconstruct fine-scale detail and generate high-resolution output while respecting the global mesh structure obtained by the 3D-EPN. Although our 3D-EPN outperforms state-of-the-art completion method, the main contribution in our work lies in the combination of a data-driven shape predictor and analytic 3D shape synthesis. In our results, we show extensive evaluations on a newly-introduced shape completion benchmark for both real-world and synthetic data. version:1
arxiv-1612-00100 | Noise-Tolerant Life-Long Matrix Completion via Adaptive Sampling | http://arxiv.org/abs/1612.00100 | id:1612.00100 author:Maria-Florina Balcan, Hongyang Zhang category:cs.LG stat.ML 15-06 F.2.1; G.1.3  published:2016-12-01 summary:We study the problem of recovering an incomplete $m\times n$ matrix of rank $r$ with columns arriving online over time. This is known as the problem of life-long matrix completion, and is widely applied to recommendation system, computer vision, system identification, etc. The challenge is to design provable algorithms tolerant to a large amount of noises, with small sample complexity. In this work, we give algorithms achieving strong guarantee under two realistic noise models. In bounded deterministic noise, an adversary can add any bounded yet unstructured noise to each column. For this problem, we present an algorithm that returns a matrix of a small error, with sample complexity almost as small as the best prior results in the noiseless case. For sparse random noise, where the corrupted columns are sparse and drawn randomly, we give an algorithm that exactly recovers an $\mu_0$-incoherent matrix by probability at least $1-\delta$ with sample complexity as small as $O\left(\mu_0rn\log (r/\delta)\right)$. This result advances the state-of-the-art work and matches the lower bound in a worst case. We also study the scenario where the hidden matrix lies on a mixture of subspaces and show that the sample complexity can be even smaller. Our proposed algorithms perform well experimentally in both synthetic and real-world datasets. version:1
arxiv-1612-00099 | PAG2ADMG: A Novel Methodology to Enumerate Causal Graph Structures | http://arxiv.org/abs/1612.00099 | id:1612.00099 author:Nishant Subramani, Doug Downey category:stat.ML stat.ME  published:2016-12-01 summary:Causal graphs, such as directed acyclic graphs (DAGs) and partial ancestral graphs (PAGs), represent causal relationships among variables in a model. Methods exist for learning DAGs and PAGs from data and for converting DAGs to PAGs. However, these methods only output a single causal graph consistent with the independencies/dependencies (the Markov equivalence class $M$) estimated from the data. However, many distinct graphs may be consistent with $M$, and a data modeler may wish to select among these using domain knowledge. In this paper, we present a method that makes this possible. We introduce PAG2ADMG, the first method for enumerating all causal graphs consistent with $M$, under certain assumptions. PAG2ADMG converts a given PAG into a set of acyclic directed mixed graphs (ADMGs). We prove the correctness of the approach and demonstrate its efficiency relative to brute-force enumeration. version:1
arxiv-1612-00089 | Beyond standard benchmarks: Parameterizing performance evaluation in visual object tracking | http://arxiv.org/abs/1612.00089 | id:1612.00089 author:Luka Čehovin, Alan Lukežič, Aleš Leonardis, Matej Kristan category:cs.CV  published:2016-12-01 summary:Benchmarks have played an important role in advancing the field of visual object tracking. Due to weakly defined and sometimes biased attribute specification, existing benchmarks do not allow fine-grained tracker analysis with respect to specific attributes. Apart from illumination changes and occlusions, the tracking performance is most strongly affected by the object motion. In this paper, we propose a novel approach for tracker evaluation with respect to the motion-related attributes. Our approach utilizes 360 degree videos to generate realistic annotated short-term tracking scenarios with exact specification of the object motion type and extent. A fully annotated dataset of 360 degree videos was constructed and fine-grained performance of 17 state-of-the-art trackers is reported. The proposed approach offers unique tracking insights, is complementary to existing benchmarks, and will be made publicly available. The evaluation system was implemented within a state-of-the-art performance evaluation toolkit and supports straight-forward extension with third-party trackers. version:1
arxiv-1612-00085 | Texture Enhancement via High-Resolution Style Transfer for Single-Image Super-Resolution | http://arxiv.org/abs/1612.00085 | id:1612.00085 author:Il Jun Ahn, Woo Hyun Nam category:cs.CV  published:2016-12-01 summary:Recently, various deep-neural-network (DNN)-based approaches have been proposed for single-image super-resolution (SISR). Despite their promising results on major structure regions such as edges and lines, they still suffer from limited performance on texture regions that consist of very complex and fine patterns. This is because, during the acquisition of a low-resolution (LR) image via down-sampling, these regions lose most of the high frequency information necessary to represent the texture details. In this paper, we present a novel texture enhancement framework for SISR to effectively improve the spatial resolution in the texture regions as well as edges and lines. We call our method, high-resolution (HR) style transfer algorithm. Our framework consists of three steps: (i) generate an initial HR image from an interpolated LR image via an SISR algorithm, (ii) generate an HR style image from the initial HR image via down-scaling and tiling, and (iii) combine the HR style image with the initial HR image via a customized style transfer algorithm. Here, the HR style image is obtained by down-scaling the initial HR image and then repetitively tiling it into an image of the same size as the HR image. This down-scaling and tiling process comes from the idea that texture regions are often composed of small regions that similar in appearance albeit sometimes different in scale. This process creates an HR style image that is rich in details, which can be used to restore high-frequency texture details back into the initial HR image via the style transfer algorithm. Experimental results on a number of texture datasets show that our proposed HR style transfer algorithm provides more visually pleasing results compared with competitive methods. version:1
arxiv-1612-00081 | Two Methods For Wild Variational Inference | http://arxiv.org/abs/1612.00081 | id:1612.00081 author:Qiang Liu, Yihao Feng category:stat.ML  published:2016-11-30 summary:Variational inference provides a powerful tool for approximate probabilistic in- ference on complex, structured models. Typical variational inference methods, however, require to use inference networks with computationally tractable proba- bility density functions. This largely limits the design and implementation of vari- ational inference methods. We consider wild variational inference methods that do not require tractable density functions on the inference networks, and hence can be applied in more challenging cases. As an example of application, we treat stochastic gradient Langevin dynamics (SGLD) as an inference network, and use our methods to automatically adjust the step sizes of SGLD, yielding significant improvement over the hand-designed step size schemes version:1
arxiv-1612-00005 | Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space | http://arxiv.org/abs/1612.00005 | id:1612.00005 author:Anh Nguyen, Jason Yosinski, Yoshua Bengio, Alexey Dosovitskiy, Jeff Clune category:cs.CV  published:2016-11-30 summary:Generating high-resolution, photo-realistic images has been a long-standing goal in machine learning. Recently, Nguyen et al. (2016) showed one interesting way to synthesize novel images by performing gradient ascent in the latent space of a generator network to maximize the activations of one or multiple neurons in a separate classifier network. In this paper we extend this method by introducing an additional prior on the latent code, improving both sample quality and sample diversity, leading to a state-of-the-art generative model that produces high quality images at higher resolutions (227x227) than previous generative models, and does so for all 1000 ImageNet categories. In addition, we provide a unified probabilistic interpretation of related activation maximization methods and call the general class of models "Plug and Play Generative Networks". PPGNs are composed of 1) a generator network G that is capable of drawing a wide range of image types and 2) a replaceable "condition" network C that tells the generator what to draw. We demonstrate the generation of images conditioned on a class (when C is an ImageNet or MIT Places classification network) and also conditioned on a caption (when C is an image captioning network). Our method also improves the state of the art of Multifaceted Feature Visualization, which generates the set of synthetic inputs that activate a neuron in order to better understand how deep neural networks operate. Finally, we show that our model performs reasonably well at the task of image inpainting. While image models are used in this paper, the approach is modality-agnostic and can be applied to many types of data. version:1
arxiv-1611-10351 | Joint Causal Inference on Observational and Experimental Datasets | http://arxiv.org/abs/1611.10351 | id:1611.10351 author:Sara Magliacane, Tom Claassen, Joris M. Mooij category:cs.LG cs.AI stat.ML  published:2016-11-30 summary:We introduce Joint Causal Inference (JCI), a powerful formulation of causal discovery over multiple datasets that allows to jointly learn both the causal structure and targets of interventions from statistical independences in pooled data. Compared with existing constraint-based approaches for causal discovery from multiple data sets, JCI offers several advantages: it allows for several different types of interventions, it can learn intervention targets, it systematically pools data across different datasets which improves the statistical power of independence tests, and it improves on the accuracy and identifiability of the predicted causal relations. A technical complication that arises in JCI are the occurrence of faithfulness violations due to deterministic relations. We propose a simple but effective strategy for dealing with this type of faithfulness violations. We implement it in ACID, a determinism-tolerant extension of Ancestral Causal Inference (ACI) (Magliacane et al., 2016), a recently proposed logic-based causal discovery method that improves reliability of the output by exploiting redundant information in the data. We illustrate the benefits of JCI with ACID with an evaluation on a simulated dataset. version:1
arxiv-1611-10349 | Non-Convex Projected Gradient Descent for Generalized Low-Rank Tensor Regression | http://arxiv.org/abs/1611.10349 | id:1611.10349 author:Han Chen, Garvesh Raskutti, Ming Yuan category:stat.ML  published:2016-11-30 summary:In this paper, we consider the problem of learning high-dimensional tensor regression problems with low-rank structure. One of the core challenges associated with learning high-dimensional models is computation since the underlying optimization problems are often non-convex. While convex relaxations could lead to polynomial-time algorithms they are often slow in practice. On the other hand, limited theoretical guarantees exist for non-convex methods. In this paper we provide a general framework that provides theoretical guarantees for learning high-dimensional tensor regression models under different low-rank structural assumptions using the projected gradient descent algorithm applied to a potentially non-convex constraint set $\Theta$ in terms of its \emph{localized Gaussian width}. We juxtapose our theoretical results for non-convex projected gradient descent algorithms with previous results on regularized convex approaches. The two main differences between the convex and non-convex approach are: (i) from a computational perspective whether the non-convex projection operator is computable and whether the projection has desirable contraction properties and (ii) from a statistical upper bound perspective, the non-convex approach has a superior rate for a number of examples. We provide three concrete examples of low-dimensional structure which address these issues and explain the pros and cons for the non-convex and convex approaches. We supplement our theoretical results with simulations which show that, under several common settings of generalized low rank tensor regression, the projected gradient descent approach is superior both in terms of statistical error and run-time provided the step-sizes of the projected descent algorithm are suitably chosen. version:1
arxiv-1611-09816 | Co-adaptive learning over a countable space | http://arxiv.org/abs/1611.09816 | id:1611.09816 author:Michael Rabadi category:stat.ML cs.LG  published:2016-11-29 summary:Co-adaptation is a special form of on-line learning where an algorithm $\mathcal{A}$ must assist an unknown algorithm $\mathcal{B}$ to perform some task. This is a general framework and has applications in recommendation systems, search, education, and much more. Today, the most common use of co-adaptive algorithms is in brain-computer interfacing (BCI), where algorithms help patients gain and maintain control over prosthetic devices. While previous studies have shown strong empirical results Kowalski et al. (2013); Orsborn et al. (2014) or have been studied in specific examples Merel et al. (2013, 2015), there is no general analysis of the co-adaptive learning problem. Here we will study the co-adaptive learning problem in the online, closed-loop setting. We will prove that, with high probability, co-adaptive learning is guaranteed to outperform learning with a fixed decoder as long as a particular condition is met. version:2
arxiv-1611-10338 | SLA Violation Prediction In Cloud Computing: A Machine Learning Perspective | http://arxiv.org/abs/1611.10338 | id:1611.10338 author:Reyhane Askari Hemmat, Abdelhakim Hafid category:cs.DC cs.LG  published:2016-11-30 summary:Service level agreement (SLA) is an essential part of cloud systems to ensure maximum availability of services for customers. With a violation of SLA, the provider has to pay penalties. In this paper, we explore two machine learning models: Naive Bayes and Random Forest Classifiers to predict SLA violations. Since SLA violations are a rare event in the real world (~0.2 %), the classification task becomes more challenging. In order to overcome these challenges, we use several re-sampling methods. We find that random forests with SMOTE-ENN re-sampling have the best performance among other methods with the accuracy of 99.88 % and F_1 score of 0.9980. version:1
arxiv-1611-10336 | An Artificial Agent for Robust Image Registration | http://arxiv.org/abs/1611.10336 | id:1611.10336 author:Rui Liao, Shun Miao, Pierre de Tournemire, Sasa Grbic, Ali Kamen, Tommaso Mansi, Dorin Comaniciu category:cs.CV  published:2016-11-30 summary:3-D image registration, which involves aligning two or more images, is a critical step in a variety of medical applications from diagnosis to therapy. Image registration is commonly performed by optimizing an image matching metric as a cost function. However, this task is challenging due to the non-convex nature of the matching metric over the plausible registration parameter space and insufficient approaches for a robust optimization. As a result, current approaches are often customized to a specific problem and sensitive to image quality and artifacts. In this paper, we propose a completely different approach to image registration, inspired by how experts perform the task. We first cast the image registration problem as a "strategy learning" process, where the goal is to find the best sequence of motion actions (e.g. up, down, etc.) that yields image alignment. Within this approach, an artificial agent is learned, modeled using deep convolutional neural networks, with 3D raw image data as the input, and the next optimal action as the output. To cope with the dimensionality of the problem, we propose a greedy supervised approach for an end-to-end training, coupled with attention-driven hierarchical strategy. The resulting registration approach inherently encodes both a data-driven matching metric and an optimal registration strategy (policy). We demonstrate, on two 3-D/3-D medical image registration examples with drastically different nature of challenges, that the artificial agent outperforms several state-of-art registration methods by a large margin in terms of both accuracy and robustness. version:1
arxiv-1612-00671 | Reliable Evaluation of Neural Network for Multiclass Classification of Real-world Data | http://arxiv.org/abs/1612.00671 | id:1612.00671 author:Siddharth Dinesh, Tirtharaj Dash category:cs.NE cs.LG  published:2016-11-30 summary:This paper presents a systematic evaluation of Neural Network (NN) for classification of real-world data. In the field of machine learning, it is often seen that a single parameter that is 'predictive accuracy' is being used for evaluating the performance of a classifier model. However, this parameter might not be considered reliable given a dataset with very high level of skewness. To demonstrate such behavior, seven different types of datasets have been used to evaluate a Multilayer Perceptron (MLP) using twelve(12) different parameters which include micro- and macro-level estimation. In the present study, the most common problem of prediction called 'multiclass' classification has been considered. The results that are obtained for different parameters for each of the dataset could demonstrate interesting findings to support the usability of these set of performance evaluation parameters. version:1
arxiv-1611-10328 | The observer-assisted method for adjusting hyper-parameters in deep learning algorithms | http://arxiv.org/abs/1611.10328 | id:1611.10328 author:Maciej Wielgosz category:cs.LG cs.AI  published:2016-11-30 summary:This paper presents a concept of a novel method for adjusting hyper-parameters in Deep Learning (DL) algorithms. An external agent-observer monitors a performance of a selected Deep Learning algorithm. The observer learns to model the DL algorithm using a series of random experiments. Consequently, it may be used for predicting a response of the DL algorithm in terms of a selected quality measurement to a set of hyper-parameters. This allows to construct an ensemble composed of a series of evaluators which constitute an observer-assisted architecture. The architecture may be used to gradually iterate towards to the best achievable quality score in tiny steps governed by a unit of progress. The algorithm is stopped when the maximum number of steps is reached or no further progress is made. version:1
arxiv-1611-10314 | Sync-DRAW: Automatic GIF Generation using Deep Recurrent Attentive Architectures | http://arxiv.org/abs/1611.10314 | id:1611.10314 author:Gaurav Mittal, Tanya Marwah, Vineeth Balasubramanian category:cs.CV  published:2016-11-30 summary:This paper introduces a novel approach for generating GIFs called Synchronized Deep Recurrent Attentive Writer (Sync-DRAW). Sync-DRAW employs a Recurrent Variational Autoencoder (R-VAE) and an attention mechanism in a hierarchical manner to create a temporally dependent sequence of frames that are gradually formed over time. The attention mechanism in Sync-DRAW attends to each individual frame of the GIF in sychronization, while the R-VAE learns a latent distribution for the entire GIF at the global level. We studied the performance of our Sync-DRAW network on the Bouncing MNIST GIFs Dataset and also, the newly available TGIF dataset. Experiments have suggested that Sync-DRAW is efficient in learning the spatial and temporal information of the GIFs and generates frames where objects have high structural integrity. Moreover, we also demonstrate that Sync-DRAW can be extended to even generate GIFs automatically given just text captions. version:1
arxiv-1611-09957 | t-Exponential Triplet Embedding | http://arxiv.org/abs/1611.09957 | id:1611.09957 author:Ehsan Amid, Nikos Vlassis, Manfred K. Warmuth category:cs.AI cs.LG stat.ML  published:2016-11-30 summary:Given a set of relative similarities between objects in the form of triplets "object i is more similar to object j than to object k", we consider the problem of finding an embedding of these objects in a metric space. This problem is generally referred to as triplet embedding. Our main focus in this paper is the case where a subset of triplets are corrupted by noise, such that the order of objects in a triple is reversed. In a crowdsourcing application, for instance, this noise may arise due to varying skill levels or different opinions of the human evaluators. As we show, all existing triplet embedding methods fail to handle even low levels of noise. Inspired by recent advances in robust binary classification and ranking, we introduce a new technique, called t-Exponential Triplet Embedding (t-ETE), that produces high-quality embeddings even in the presence of significant amount of noise in the triplets. By an extensive set of experiments on both synthetic and real-world datasets, we show that our method outperforms all the other methods, giving rise to new insights on real-world data, which have been impossible to observe using the previous techniques. version:1
arxiv-1612-00874 | Multi-resolution Data Fusion for Super-Resolution Electron Microscopy | http://arxiv.org/abs/1612.00874 | id:1612.00874 author:Suhas Sreehari, S. V. Venkatakrishnan, Katherine L. Bouman, Jeffrey P. Simmons, Lawrence F. Drummy, Charles A. Bouman category:cs.CV  published:2016-11-28 summary:Perhaps surprisingly, the total electron microscopy (EM) data collected to date is less than a cubic millimeter. Consequently, there is an enormous demand in the materials and biological sciences to image at greater speed and lower dosage, while maintaining resolution. Traditional EM imaging based on homogeneous raster-order scanning severely limits the volume of high-resolution data that can be collected, and presents a fundamental limitation to understanding physical processes such as material deformation, crack propagation, and pyrolysis. We introduce a novel multi-resolution data fusion (MDF) method for super-resolution computational EM. Our method combines innovative data acquisition with novel algorithmic techniques to dramatically improve the resolution/volume/speed trade-off. The key to our approach is to collect the entire sample at low resolution, while simultaneously collecting a small fraction of data at high resolution. The high-resolution measurements are then used to create a material-specific patch-library that is used within the "plug-and-play" framework to dramatically improve super-resolution of the low-resolution data. We present results using FEI electron microscope data that demonstrate super-resolution factors of 4x, 8x, and 16x, while substantially maintaining high image quality and reducing dosage. version:1
arxiv-1611-08928 | Polysemy Effects and Chronological Memory | http://arxiv.org/abs/1611.08928 | id:1611.08928 author:Francesco Fumarola category:q-bio.NC cs.CL 91E10  published:2016-11-27 summary:The existence of a polysemy effect in episodic memory is demonstrated through an analysis of data from the experiments of Lohnas et al. (2015) and Healey and Kahana (2016). Three word-length related features are reported: (1) the average distance between the serial positions of consecutively recalled words is an increasing function of the second word's length; (2) the recall of words in the order in which they were presented is more likely to occur for shorter words; (3) longer words are easier to recall than shorter words from the same list. These phenomena are reproduced by modeling the fact that shorter words have a larger number of meanings (polysemy). This is shown to be at the root of our tendency to recall verbal sequences in forward order, and a conjecture is put forth regarding the general methods we employ to store information on the chronology of events. version:1
arxiv-1612-01928 | Invariant Representations for Noisy Speech Recognition | http://arxiv.org/abs/1612.01928 | id:1612.01928 author:Dmitriy Serdyuk, Kartik Audhkhasi, Philémon Brakel, Bhuvana Ramabhadran, Samuel Thomas, Yoshua Bengio category:cs.CL cs.CV cs.LG cs.SD stat.ML  published:2016-11-27 summary:Modern automatic speech recognition (ASR) systems need to be robust under acoustic variability arising from environmental, speaker, channel, and recording conditions. Ensuring such robustness to variability is a challenge in modern day neural network-based ASR systems, especially when all types of variability are not seen during training. We attempt to address this problem by encouraging the neural network acoustic model to learn invariant feature representations. We use ideas from recent research on image generation using Generative Adversarial Networks and domain adaptation ideas extending adversarial gradient-based training. A recent work from Ganin et al. proposes to use adversarial training for image domain adaptation by using an intermediate representation from the main target classification network to deteriorate the domain classifier performance through a separate neural network. Our work focuses on investigating neural architectures which produce representations invariant to noise conditions for ASR. We evaluate the proposed architecture on the Aurora-4 task, a popular benchmark for noise robust ASR. We show that our method generalizes better than the standard multi-condition training especially when only a few noise categories are seen during training. version:1
arxiv-1612-01400 | A Distance Function for Comparing Straight-Edge Geometric Figures | http://arxiv.org/abs/1612.01400 | id:1612.01400 author:Apoorva Honnegowda Roopa, Shrisha Rao category:cs.CV cs.CG  published:2016-11-25 summary:This paper defines a distance function that measures the dissimilarity between planar geometric figures formed with straight lines. This function can in turn be used in partial matching of different geometric figures. For a given pair of geometric figures that are graphically isomorphic, one function measures the angular dissimilarity and another function measures the edge length disproportionality. The distance function is then defined as the convex sum of these two functions. The novelty of the presented function is that it satisfies all properties of a distance function and the computation of the same is done by projecting appropriate features to a cartesian plane. To compute the deviation from the angular similarity property, the Euclidean distance between the given angular pairs and the corresponding points on the $y=x$ line is measured. Further while computing the deviation from the edge length proportionality property, the best fit line, for the set of edge lengths, which passes through the origin is found, and the Euclidean distance between the given edge length pairs and the corresponding point on a $y=mx$ line is calculated. Iterative Proportional Fitting Procedure (IPFP) is used to find this best fit line. We demonstrate the behavior of the defined function for some sample pairs of figures. version:1
