arxiv-1612-09438 | Automatic Discoveries of Physical and Semantic Concepts via Association Priors of Neuron Groups | http://arxiv.org/abs/1612.09438 | id:1612.09438 author:Shuai Li, Kui Jia, Xiaogang Wang category:cs.LG  published:2016-12-30 summary:The recent successful deep neural networks are largely trained in a supervised manner. It {\it associates} complex patterns of input samples with neurons in the last layer, which form representations of {\it concepts}. In spite of their successes, the properties of complex patterns associated a learned concept remain elusive. In this work, by analyzing how neurons are associated with concepts in supervised networks, we hypothesize that with proper priors to regulate learning, neural networks can automatically associate neurons in the intermediate layers with concepts that are aligned with real world concepts, when trained only with labels that associate concepts with top level neurons, which is a plausible way for unsupervised learning. We develop a prior to verify the hypothesis and experimentally find the proposed priors help neural networks automatically learn both basic physical concepts at the lower layers, e.g., rotation of filters, and highly semantic concepts at the higher layers, e.g., fine-grained categories of an entry-level category. version:1
arxiv-1612-09434 | Data driven estimation of Laplace-Beltrami operator | http://arxiv.org/abs/1612.09434 | id:1612.09434 author:Frédéric Chazal, Ilaria Giulini, Bertrand Michel category:cs.CG cs.LG math.ST stat.TH  published:2016-12-30 summary:Approximations of Laplace-Beltrami operators on manifolds through graph Lapla-cians have become popular tools in data analysis and machine learning. These discretized operators usually depend on bandwidth parameters whose tuning remains a theoretical and practical problem. In this paper, we address this problem for the unnormalized graph Laplacian by establishing an oracle inequality that opens the door to a well-founded data-driven procedure for the bandwidth selection. Our approach relies on recent results by Lacour and Massart [LM15] on the so-called Lepski's method. version:1
arxiv-1612-09420 | Automatic labeling of molecular biomarkers of whole slide immunohistochemistry images using fully convolutional networks | http://arxiv.org/abs/1612.09420 | id:1612.09420 author:Fahime Sheikhzadeh, Martial Guillaud, Rabab K. Ward category:q-bio.TO cs.CV  published:2016-12-30 summary:This paper addresses the problem of quantifying biomarkers in multi-stained tissues, based on color and spatial information. A deep learning based method that can automatically localize and quantify the cells expressing biomarker(s) in a whole slide image is proposed. The deep learning network is a fully convolutional network (FCN) whose input is the true RGB color image of a tissue and output is a map of the different biomarkers. The FCN relies on a convolutional neural network (CNN) that classifies each cell separately according to the biomarker it expresses. In this study, images of immunohistochemistry (IHC) stained slides were collected and used. More than 4,500 RGB images of cells were manually labeled based on the expressing biomarkers. The labeled cell images were used to train the CNN (obtaining an accuracy of 92% in a test set). The trained CNN is then extended to an FCN that generates a map of all biomarkers in the whole slide image acquired by the scanner (instead of classifying every cell image). To evaluate our method, we manually labeled all nuclei expressing different biomarkers in two whole slide images and used theses as the ground truth. Our proposed method for immunohistochemical analysis compares well with the manual labeling by humans (average F-score of 0.96). version:1
arxiv-1612-08843 | FastMask: Segment Multi-scale Object Candidates in One Shot | http://arxiv.org/abs/1612.08843 | id:1612.08843 author:Hexiang Hu, Shiyi Lan, Yuning Jiang, Zhimin Cao, Fei Sha category:cs.CV cs.AI  published:2016-12-28 summary:Objects appear to scale differently in natural images. This fact requires methods dealing with object-centric tasks e.g. object proposal to have robust performance over scale variances of objects. In the paper we present a novel segment proposal framework, namely FastMask, which takes advantage of the hierarchical structure in deep convolutional neural network to segment multi-scale objects in one shot. Innovatively, we generalize segment proposal network into three different functional components (body, neck and head). We further propose a weight-shared residual neck module as well as a scale-tolerant attentional head module for multi-scale training and efficient one-shot inference. On MS COCO benchmark, the proposed FastMask outperforms all state-of-the-art segment proposal methods in average recall while keeping 2~5 times faster. More impressively, with a slight trade-off in accuracy, FastMask can segment objects in near real time (~13 fps) at 800$\times$600 resolution images, highlighting its potential in practical applications. Our implementation is available on https://github.com/voidrank/FastMask. version:2
arxiv-1612-09411 | Shape Estimation from Defocus Cue for Microscopy Images via Belief Propagation | http://arxiv.org/abs/1612.09411 | id:1612.09411 author:Arnav Bhavsar category:cs.CV  published:2016-12-30 summary:In recent years, the usefulness of 3D shape estimation is being realized in microscopic or close-range imaging, as the 3D information can further be used in various applications. Due to limited depth of field at such small distances, the defocus blur induced in images can provide information about the 3D shape of the object. The task of `shape from defocus' (SFD), involves the problem of estimating good quality 3D shape estimates from images with depth-dependent defocus blur. While the research area of SFD is quite well-established, the approaches have largely demonstrated results on objects with bulk/coarse shape variation. However, in many cases, objects studied under microscopes often involve fine/detailed structures, which have not been explicitly considered in most methods. In addition, given that, in recent years, large data volumes are typically associated with microscopy related applications, it is also important for such SFD methods to be efficient. In this work, we provide an indication of the usefulness of the Belief Propagation (BP) approach in addressing these concerns for SFD. BP has been known to be an efficient combinatorial optimization approach, and has been empirically demonstrated to yield good quality solutions in low-level vision problems such as image restoration, stereo disparity estimation etc. For exploiting the efficiency of BP in SFD, we assume local space-invariance of the defocus blur, which enables the application of BP in a straightforward manner. Even with such an assumption, the ability of BP to provide good quality solutions while using non-convex priors, reflects in yielding plausible shape estimates in presence of fine structures on the objects under microscopy imaging. version:1
arxiv-1612-09401 | Action Recognition Based on Joint Trajectory Maps with Convolutional Neural Networks | http://arxiv.org/abs/1612.09401 | id:1612.09401 author:Pichao Wang, Wanqing Li, Chuankun Li, Yonghong Hou category:cs.CV  published:2016-12-30 summary:Convolutional Neural Networks (ConvNets) have recently shown promising performance in many computer vision tasks, especially image-based recognition. How to effectively apply ConvNets to sequence-based data is still an open problem. This paper proposes an effective yet simple method to represent spatio-temporal information carried in $3D$ skeleton sequences into three $2D$ images by encoding the joint trajectories and their dynamics into color distribution in the images, referred to as Joint Trajectory Maps (JTM), and adopts ConvNets to learn the discriminative features for human action recognition. Such an image-based representation enables us to fine-tune existing ConvNets models for the classification of skeleton sequences without training the networks afresh. The three JTMs are generated in three orthogonal planes and provide complimentary information to each other. The final recognition is further improved through multiply score fusion of the three JTMs. The proposed method was evaluated on four public benchmark datasets, the large NTU RGB+D Dataset, MSRC-12 Kinect Gesture Dataset (MSRC-12), G3D Dataset and UTD Multimodal Human Action Dataset (UTD-MHAD) and achieved the state-of-the-art results. version:1
arxiv-1612-07429 | Physically-Based Rendering for Indoor Scene Understanding Using Convolutional Neural Networks | http://arxiv.org/abs/1612.07429 | id:1612.07429 author:Yinda Zhang, Shuran Song, Ersin Yumer, Manolis Savva, Joon-Young Lee, Hailin Jin, Thomas Funkhouser category:cs.CV  published:2016-12-22 summary:Indoor scene understanding is central to applications such as robot navigation and human companion assistance. Over the last years, data-driven deep neural networks have outperformed many traditional approaches thanks to their representation learning capabilities. One of the bottlenecks in training for better representations is the amount of available per-pixel ground truth data that is required for core scene understanding tasks such as semantic segmentation, normal prediction, and object edge detection. To address this problem, a number of works proposed using synthetic data. However, a systematic study of how such synthetic data is generated is missing. In this work, we introduce a large-scale synthetic dataset with 400K physically-based rendered images from 45K realistic 3D indoor scenes. We study the effects of rendering methods and scene lighting on training for three computer vision tasks: surface normal prediction, semantic segmentation, and object boundary detection. This study provides insights into the best practices for training with synthetic data (more realistic rendering is worth it) and shows that pretraining with our new synthetic dataset can improve results beyond the current state of the art on all three tasks. version:2
arxiv-1612-09346 | Rotation equivariant vector field networks | http://arxiv.org/abs/1612.09346 | id:1612.09346 author:Diego Marcos, Michele Volpi, Nikos Komodakis, Devis Tuia category:cs.CV  published:2016-12-29 summary:We propose a method to encode rotation equivariance or invariance into convolutional neural networks (CNNs). Each convolutional filter is applied with several orientations and returns a vector field that represents the magnitude and angle of the highest scoring rotation at the given spatial location. To propagate information about the main orientation of the different features to each layer in the network, we propose an enriched orientation pooling, i.e. max and argmax operators over the orientation space, allowing to keep the dimensionality of the feature maps low and to propagate only useful information. We name this approach RotEqNet. We apply RotEqNet to three datasets: first, a rotation invariant classification problem, the MNIST-rot benchmark, in which we improve over the state-of-the-art results. Then, a neuron membrane segmentation benchmark, where we show that RotEqNet can be applied successfully to obtain equivariance to rotation with a simple fully convolutional architecture. Finally, we improve significantly the state-of-the-art on the problem of estimating cars' absolute orientation in aerial images, a problem where the output is required to be covariant with respect to the object's orientation. version:1
arxiv-1612-09328 | The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process | http://arxiv.org/abs/1612.09328 | id:1612.09328 author:Hongyuan Mei, Jason Eisner category:cs.LG stat.ML  published:2016-12-29 summary:Many events occur in the world. Some event types are stochastically excited or inhibited---in the sense of having their probabilities elevated or decreased---by patterns in the sequence of previous events. Discovering such patterns can help us predict which type of event will happen next and when. Learning such structure should benefit various applications, including medical prognosis, consumer behavior, and social media activity prediction. We propose to model streams of discrete events in continuous time, by constructing a neurally self-modulating multivariate point process. This generative model allows past events to influence the future in complex ways, by conditioning future event intensities on the hidden state of a recurrent neural network that has consumed the stream of past events. We evaluate our model on multiple datasets and show that it significantly outperforms other strong baselines. version:1
arxiv-1612-09322 | Deep Learning Logo Detection with Data Expansion by Synthesising Context | http://arxiv.org/abs/1612.09322 | id:1612.09322 author:Hang Su, Xiatian Zhu, Shaogang Gong category:cs.CV  published:2016-12-29 summary:Logo detection in unconstrained images is challenging, particularly when only very sparse labelled training images are accessible due to high labelling costs. In this work, we describe a model training image synthesising method capable of improving significantly logo detection performance when only a handful of (e.g., 10) labelled training images captured in realistic context are available, avoiding extensive manual labelling costs. Specifically, we design a novel algorithm for generating Synthetic Context Logo (SCL) training images to increase model robustness against unknown background clutters, resulting in superior logo detection performance. For benchmarking model performance, we introduce a new logo detection dataset TopLogo-10 collected from top 10 most popular clothing/wearable brandname logos captured in rich visual context. Extensive comparisons show the advantages of our proposed SCL model over the state-of-the-art alternatives for logo detection using two real-world logo benchmark datasets: FlickrLogo-32 and our new TopLogo-10. version:1
arxiv-1612-09297 | Communication-efficient Distributed Estimation and Inference for Transelliptical Graphical Models | http://arxiv.org/abs/1612.09297 | id:1612.09297 author:Pan Xu, Lu Tian, Quanquan Gu category:stat.ML  published:2016-12-29 summary:We propose communication-efficient distributed estimation and inference methods for the transelliptical graphical model, a semiparametric extension of the elliptical distribution in the high dimensional regime. In detail, the proposed method distributes the $d$-dimensional data of size $N$ generated from a transelliptical graphical model into $m$ worker machines, and estimates the latent precision matrix on each worker machine based on the data of size $n=N/m$. It then debiases the local estimators on the worker machines and send them back to the master machine. Finally, on the master machine, it aggregates the debiased local estimators by averaging and hard thresholding. We show that the aggregated estimator attains the same statistical rate as the centralized estimator based on all the data, provided that the number of machines satisfies $m \lesssim \min\{N\log d/d,\sqrt{N/(s^2\log d)}\}$, where $s$ is the maximum number of nonzero entries in each column of the latent precision matrix. It is worth noting that our algorithm and theory can be directly applied to Gaussian graphical models, Gaussian copula graphical models and elliptical graphical models, since they are all special cases of transelliptical graphical models. Thorough experiments on synthetic data back up our theory. version:1
arxiv-1612-09283 | Generalized Intersection Kernel | http://arxiv.org/abs/1612.09283 | id:1612.09283 author:Ping Li category:stat.ML cs.LG  published:2016-12-29 summary:Following the very recent line of work on the ``generalized min-max'' (GMM) kernel, this study proposes the ``generalized intersection'' (GInt) kernel and the related ``normalized generalized min-max'' (NGMM) kernel. In computer vision, the (histogram) intersection kernel has been popular, and the GInt kernel generalizes it to data which can have both negative and positive entries. Through an extensive empirical classification study on 40 datasets from the UCI repository, we are able to show that this (tuning-free) GInt kernel performs fairly well. The empirical results also demonstrate that the NGMM kernel typically outperforms the GInt kernel. Interestingly, the NGMM kernel has another interpretation --- it is the ``asymmetrically transformed'' version of the GInt kernel, based on the idea of ``asymmetric hashing''. Just like the GMM kernel, the NGMM kernel can be efficiently linearized through (e.g.,) generalized consistent weighted sampling (GCWS), as empirically validated in our study. Owing to the discrete nature of hashed values, it also provides a scheme for approximate near neighbor search. version:1
arxiv-1701-00705 | Using Big Data to Enhance the Bosch Production Line Performance: A Kaggle Challenge | http://arxiv.org/abs/1701.00705 | id:1701.00705 author:Ankita Mangal, Nishant Kumar category:cs.LG  published:2016-12-29 summary:This paper describes our approach to the Bosch production line performance challenge run by Kaggle.com. Maximizing the production yield is at the heart of the manufacturing industry. At the Bosch assembly line, data is recorded for products as they progress through each stage. Data science methods are applied to this huge data repository consisting records of tests and measurements made for each component along the assembly line to predict internal failures. We found that it is possible to train a model that predicts which parts are most likely to fail. Thus a smarter failure detection system can be built and the parts tagged likely to fail can be salvaged to decrease operating costs and increase the profit margins. version:1
arxiv-1612-09259 | Motifs in Temporal Networks | http://arxiv.org/abs/1612.09259 | id:1612.09259 author:Ashwin Paranjape, Austin R. Benson, Jure Leskovec category:cs.SI physics.soc-ph stat.ML  published:2016-12-29 summary:Networks are a fundamental tool for modeling complex systems in a variety of domains including social and communication networks as well as biology and neuroscience. Small subgraph patterns in networks, called network motifs, are crucial to understanding the structure and function of these systems. However, the role of network motifs in temporal networks, which contain many timestamped links between the nodes, is not yet well understood. Here we develop a notion of a temporal network motif as an elementary unit of temporal networks and provide a general methodology for counting such motifs. We define temporal network motifs as induced subgraphs on sequences of temporal edges, design fast algorithms for counting temporal motifs, and prove their runtime complexity. Our fast algorithms achieve up to 56.5x speedup compared to a baseline method. Furthermore, we use our algorithms to count temporal motifs in a variety of networks. Results show that networks from different domains have significantly different motif counts, whereas networks from the same domain tend to have similar motif counts. We also find that different motifs occur at different time scales, which provides further insights into structure and function of temporal networks. version:1
arxiv-1612-09213 | Verifying Heaps' law using Google Books Ngram data | http://arxiv.org/abs/1612.09213 | id:1612.09213 author:Vladimir V. Bochkarev, Eduard Yu. Lerner, Anna V. Shevlyakova category:cs.CL physics.soc-ph 91F20 J.5; I.2.7; G.3  published:2016-12-29 summary:This article is devoted to the verification of the empirical Heaps law in European languages using Google Books Ngram corpus data. The connection between word distribution frequency and expected dependence of individual word number on text size is analysed in terms of a simple probability model of text generation. It is shown that the Heaps exponent varies significantly within characteristic time intervals of 60-100 years. version:1
arxiv-1612-09205 | Deep neural heart rate variability analysis | http://arxiv.org/abs/1612.09205 | id:1612.09205 author:Tamas Madl category:cs.NE cs.AI cs.LG I.2  published:2016-12-29 summary:Despite of the pain and limited accuracy of blood tests for early recognition of cardiovascular disease, they dominate risk screening and triage. On the other hand, heart rate variability is non-invasive and cheap, but not considered accurate enough for clinical practice. Here, we tackle heart beat interval based classification with deep learning. We introduce an end to end differentiable hybrid architecture, consisting of a layer of biological neuron models of cardiac dynamics (modified FitzHugh Nagumo neurons) and several layers of a standard feed-forward neural network. The proposed model is evaluated on ECGs from 474 stable at-risk (coronary artery disease) patients, and 1172 chest pain patients of an emergency department. We show that it can significantly outperform models based on traditional heart rate variability predictors, as well as approaching or in some cases outperforming clinical blood tests, based only on 60 seconds of inter-beat intervals. version:1
arxiv-1612-09199 | Quantum Clustering and Gaussian Mixtures | http://arxiv.org/abs/1612.09199 | id:1612.09199 author:Mahajabin Rahman, Davi Geiger category:stat.ML cs.CV  published:2016-12-29 summary:The mixture of Gaussian distributions, a soft version of k-means , is considered a state-of-the-art clustering algorithm. It is widely used in computer vision for selecting classes, e.g., color, texture, and shapes. In this algorithm, each class is described by a Gaussian distribution, defined by its mean and covariance. The data is described by a weighted sum of these Gaussian distributions. We propose a new method, inspired by quantum interference in physics. Instead of modeling each class distribution directly, we model a class wave function such that its magnitude square is the class Gaussian distribution. We then mix the class wave functions to create the mixture wave function. The final mixture distribution is then the magnitude square of the mixture wave function. As a result, we observe the quantum class interference phenomena, not present in the Gaussian mixture model. We show that the quantum method outperforms the Gaussian mixture method in every aspect of the estimations. It provides more accurate estimations of all distribution parameters, with much less fluctuations, and it is also more robust to data deformations from the Gaussian assumptions. We illustrate our method for color segmentation as an example application. version:1
arxiv-1612-08425 | Unsupervised Learning for Computational Phenotyping | http://arxiv.org/abs/1612.08425 | id:1612.08425 author:Chris Hodapp category:stat.ML cs.LG  published:2016-12-26 summary:With large volumes of health care data comes the research area of computational phenotyping, making use of techniques such as machine learning to describe illnesses and other clinical concepts from the data itself. The "traditional" approach of using supervised learning relies on a domain expert, and has two main limitations: requiring skilled humans to supply correct labels limits its scalability and accuracy, and relying on existing clinical descriptions limits the sorts of patterns that can be found. For instance, it may fail to acknowledge that a disease treated as a single condition may really have several subtypes with different phenotypes, as seems to be the case with asthma and heart disease. Some recent papers cite successes instead using unsupervised learning. This shows great potential for finding patterns in Electronic Health Records that would otherwise be hidden and that can lead to greater understanding of conditions and treatments. This work implements a method derived strongly from Lasko et al., but implements it in Apache Spark and Python and generalizes it to laboratory time-series data in MIMIC-III. It is released as an open-source tool for exploration, analysis, and visualization, available at https://github.com/Hodapp87/mimic3_phenotyping version:2
arxiv-1612-09162 | High-dimensional Filtering using Nested Sequential Monte Carlo | http://arxiv.org/abs/1612.09162 | id:1612.09162 author:Christian A. Naesseth, Fredrik Lindsten, Thomas B. Schön category:stat.CO stat.ML  published:2016-12-29 summary:Sequential Monte Carlo (SMC) methods comprise one of the most successful approaches to approximate Bayesian filtering. However, SMC without good proposal distributions struggle in high dimensions. We propose nested sequential Monte Carlo (NSMC), a methodology that generalises the SMC framework by requiring only approximate, properly weighted, samples from the SMC proposal distribution, while still resulting in a correct SMC algorithm. This way we can exactly approximate the locally optimal proposal, and extend the class of models for which we can perform efficient inference using SMC. We show improved accuracy over other state-of-the-art methods on several spatio-temporal state space models. version:1
arxiv-1612-09161 | Learning Visual N-Grams from Web Data | http://arxiv.org/abs/1612.09161 | id:1612.09161 author:Ang Li, Allan Jabri, Armand Joulin, Laurens van der Maaten category:cs.CV  published:2016-12-29 summary:Real-world image recognition systems need to recognize tens of thousands of classes that constitute a plethora of visual concepts. The traditional approach of annotating thousands of images per class for training is infeasible in such a scenario, prompting the use of webly supervised data. This paper explores the training of image-recognition systems on large numbers of images and associated user comments. In particular, we develop visual n-gram models that can predict arbitrary phrases that are relevant to the content of an image. Our visual n-gram models are feed-forward convolutional networks trained using new loss functions that are inspired by n-gram models commonly used in language modeling. We demonstrate the merits of our models in phrase prediction, phrase-based image retrieval, relating images and captions, and zero-shot transfer. version:1
arxiv-1612-09158 | The interplay between system identification and machine learning | http://arxiv.org/abs/1612.09158 | id:1612.09158 author:Gianluigi Pillonetto category:cs.SY cs.LG stat.ML  published:2016-12-29 summary:Learning from examples is one of the key problems in science and engineering. It deals with function reconstruction from a finite set of direct and noisy samples. Regularization in reproducing kernel Hilbert spaces (RKHSs) is widely used to solve this task and includes powerful estimators such as regularization networks. Recent achievements include the proof of the statistical consistency of these kernel- based approaches. Parallel to this, many different system identification techniques have been developed but the interaction with machine learning does not appear so strong yet. One reason is that the RKHSs usually employed in machine learning do not embed the information available on dynamic systems, e.g. BIBO stability. In addition, in system identification the independent data assumptions routinely adopted in machine learning are never satisfied in practice. This paper provides new results which strengthen the connection between system identification and machine learning. Our starting point is the introduction of RKHSs of dynamic systems. They contain functionals over spaces defined by system inputs and allow to interpret system identification as learning from examples. In both linear and nonlinear settings, it is shown that this perspective permits to derive in a relatively simple way conditions on RKHS stability (i.e. the property of containing only BIBO stable systems or predictors), also facilitating the design of new kernels for system identification. Furthermore, we prove the convergence of the regularized estimator to the optimal predictor under conditions typical of dynamic systems. version:1
arxiv-1612-09147 | Linear Learning with Sparse Data | http://arxiv.org/abs/1612.09147 | id:1612.09147 author:Ofer Dekel category:cs.LG  published:2016-12-29 summary:Linear predictors are especially useful when the data is high-dimensional and sparse. One of the standard techniques used to train a linear predictor is the Averaged Stochastic Gradient Descent (ASGD) algorithm. We present an efficient implementation of ASGD that avoids dense vector operations. We also describe a translation invariant extension called Centered Averaged Stochastic Gradient Descent (CASGD). version:1
arxiv-1612-09134 | From Virtual to Real World Visual Perception using Domain Adaptation -- The DPM as Example | http://arxiv.org/abs/1612.09134 | id:1612.09134 author:Antonio M. Lopez, Jiaolong Xu, Jose L. Gomez, David Vazquez, German Ros category:cs.CV cs.AI  published:2016-12-29 summary:Supervised learning tends to produce more accurate classifiers than unsupervised learning in general. This implies that training data is preferred with annotations. When addressing visual perception challenges, such as localizing certain object classes within an image, the learning of the involved classifiers turns out to be a practical bottleneck. The reason is that, at least, we have to frame object examples with bounding boxes in thousands of images. A priori, the more complex the model is regarding its number of parameters, the more annotated examples are required. This annotation task is performed by human oracles, which ends up in inaccuracies and errors in the annotations (aka ground truth) since the task is inherently very cumbersome and sometimes ambiguous. As an alternative we have pioneered the use of virtual worlds for collecting such annotations automatically and with high precision. However, since the models learned with virtual data must operate in the real world, we still need to perform domain adaptation (DA). In this chapter we revisit the DA of a deformable part-based model (DPM) as an exemplifying case of virtual- to-real-world DA. As a use case, we address the challenge of vehicle detection for driver assistance, using different publicly available virtual-world data. While doing so, we investigate questions such as: how does the domain gap behave due to virtual-vs-real data with respect to dominant object appearance per domain, as well as the role of photo-realism in the virtual world. version:1
arxiv-1612-09122 | Modeling documents with Generative Adversarial Networks | http://arxiv.org/abs/1612.09122 | id:1612.09122 author:John Glover category:cs.LG  published:2016-12-29 summary:This paper describes a method for using Generative Adversarial Networks to learn distributed representations of natural language documents. We propose a model that is based on the recently proposed Energy-Based GAN, but instead uses a Denoising Autoencoder as the discriminator network. Document representations are extracted from the hidden layer of the discriminator and evaluated both quantitatively and qualitatively. version:1
arxiv-1612-09113 | Deep Semi-Supervised Learning with Linguistically Motivated Sequence Labeling Task Hierarchies | http://arxiv.org/abs/1612.09113 | id:1612.09113 author:Jonathan Godwin, Pontus Stenetorp, Sebastian Riedel category:cs.CL  published:2016-12-29 summary:In this paper we present a novel Neural Network algorithm for conducting semi-supervised learning for sequence labeling tasks arranged in a linguistically motivated hierarchy. This relationship is exploited to regularise the representations of supervised tasks by backpropagating the error of the unsupervised task through the supervised tasks. We introduce a neural network where lower layers are supervised by junior downstream tasks and the final layer task is an auxiliary unsupervised task. The architecture shows improvements of up to two percentage points F1 for Chunking compared to a plausible baseline. version:1
arxiv-1612-09106 | Sequence-to-point learning with neural networks for nonintrusive load monitoring | http://arxiv.org/abs/1612.09106 | id:1612.09106 author:Chaoyun Zhang, Mingjun Zhong, Zongzuo Wang, Nigel Goddard, Charles Sutton category:stat.AP cs.LG  published:2016-12-29 summary:Energy disaggregation (a.k.a nonintrusive load monitoring, NILM), a single-channel blind source separation problem, aims to decompose the mains which records the whole electricity consumption into appliance-wise readings. This problem is difficult because it is inherently unidentifiable. Recent approaches have shown that the identifiability problem could be reduced by introducing domain knowledge into the model. Deep neural networks have been shown to be promising to tackle this problem in literatures. However, it is not clear why and how the neural networks could work for this problem. In this paper, we propose sequence-to-point learning for NILM, where the input is a window of the mains and the output is a single point of the target appliance. We use convolutional neural networks to train the model. Interestingly, we systematically show that the convolutional neural networks can inherently learn the signatures of the target appliances, which are automatically added into the model to reduce the identifiability problem. We applied the proposed neural network approaches to a real-world household energy data, and show that the methods achieve the state-of-the-art performance. version:1
arxiv-1612-09076 | Selecting Bases in Spectral learning of Predictive State Representations via Model Entropy | http://arxiv.org/abs/1612.09076 | id:1612.09076 author:Yunlong Liu, Hexing Zhu category:cs.LG stat.ML  published:2016-12-29 summary:Predictive State Representations (PSRs) are powerful techniques for modelling dynamical systems, which represent a state as a vector of predictions about future observable events (tests). In PSRs, one of the fundamental problems is the learning of the PSR model of the underlying system. Recently, spectral methods have been successfully used to address this issue by treating the learning problem as the task of computing an singular value decomposition (SVD) over a submatrix of a special type of matrix called the Hankel matrix. Under the assumptions that the rows and columns of the submatrix of the Hankel Matrix are sufficient~(which usually means a very large number of rows and columns, and almost fails in practice) and the entries of the matrix can be estimated accurately, it has been proven that the spectral approach for learning PSRs is statistically consistent and the learned parameters can converge to the true parameters. However, in practice, due to the limit of the computation ability, only a finite set of rows or columns can be chosen to be used for the spectral learning. While different sets of columns usually lead to variant accuracy of the learned model, in this paper, we propose an approach for selecting the set of columns, namely basis selection, by adopting a concept of model entropy to measure the accuracy of the learned model. Experimental results are shown to demonstrate the effectiveness of the proposed approach. version:1
arxiv-1612-09057 | Deep Learning and Hierarchal Generative Models | http://arxiv.org/abs/1612.09057 | id:1612.09057 author:Elchanan Mossel category:cs.LG  published:2016-12-29 summary:In this paper we propose a new prism for studying deep learning motivated by connections between deep learning and evolution. Our main contributions are: 1, We introduce of a sequence of increasingly complex hierarchal generative models which interpolate between standard Markov models on trees (phylogenetic models) and deep learning models. 2. Formal definitions of classes of algorithms that are not deep. 3. Rigorous proofs showing that such classes are information theoretically much weaker than optimal "deep" learning algorithms. In our models, deep learning is performed efficiently and proven to classify correctly with high probability. All of the models and results are in the semi-supervised setting. Many open problems and future directions are presented. version:1
arxiv-1612-09529 | Linking the Neural Machine Translation and the Prediction of Organic Chemistry Reactions | http://arxiv.org/abs/1612.09529 | id:1612.09529 author:Juno Nam, Jurae Kim category:cs.LG  published:2016-12-29 summary:Finding the main product of a chemical reaction is one of the important problems of organic chemistry. This paper describes a method of applying a neural machine translation model to the prediction of organic chemical reactions. In order to translate 'reactants and reagents' to 'products', a gated recurrent unit based sequence-to-sequence model and a parser to generate input tokens for model from reaction SMILES strings were built. Training sets are composed of reactions from the patent databases, and reactions manually generated applying the elementary reactions in an organic chemistry textbook of Wade. The trained models were tested by examples and problems in the textbook. The prediction process does not need manual encoding of rules (e.g., SMARTS transformations) to predict products, hence it only needs sufficient training reaction sets to learn new types of reactions. version:1
arxiv-1612-09034 | Geometric descent method for convex composite minimization | http://arxiv.org/abs/1612.09034 | id:1612.09034 author:Shixiang Chen, Shiqian Ma category:math.OC cs.LG stat.ML  published:2016-12-29 summary:In this paper, we extend the geometric descent method recently proposed by Bubeck, Lee and Singh to solving nonsmooth and strongly convex composite problems. We prove that the resulting algorithm, GeoPG, converges with a linear rate $(1-1/\sqrt{\kappa})$, thus achieves the optimal rate among first-order methods, where $\kappa$ is the condition number of the problem. Numerical results on linear regression and logistic regression with elastic net regularization show that GeoPG compares favorably with Nesterov's accelerated proximal gradient method. version:1
arxiv-1612-09022 | A Basic Recurrent Neural Network Model | http://arxiv.org/abs/1612.09022 | id:1612.09022 author:Fathi M. Salem category:cs.NE stat.ML  published:2016-12-29 summary:We present a model of a basic recurrent neural network (or bRNN) that includes a separate linear term with a slightly "stable" fixed matrix to guarantee bounded solutions and fast dynamic response. We formulate a state space viewpoint and adapt the constrained optimization Lagrange Multiplier (CLM) technique and the vector Calculus of Variations (CoV) to derive the (stochastic) gradient descent. In this process, one avoids the commonly used re-application of the circular chain-rule and identifies the error back-propagation with the co-state backward dynamic equations. We assert that this bRNN can successfully perform regression tracking of time-series. Moreover, the "vanishing and exploding" gradients are explicitly quantified and explained through the co-state dynamics and the update laws. The adapted CoV framework, in addition, can correctly and principally integrate new loss functions in the network on any variable and for varied goals, e.g., for supervised learning on the outputs and unsupervised learning on the internal (hidden) states. version:1
arxiv-1612-09007 | A Deep Learning Approach To Multiple Kernel Fusion | http://arxiv.org/abs/1612.09007 | id:1612.09007 author:Huan Song, Jayaraman J. Thiagarajan, Prasanna Sattigeri, Karthikeyan Natesan Ramamurthy, Andreas Spanias category:stat.ML cs.LG  published:2016-12-28 summary:Kernel fusion is a popular and effective approach for combining multiple features that characterize different aspects of data. Traditional approaches for Multiple Kernel Learning (MKL) attempt to learn the parameters for combining the kernels through sophisticated optimization procedures. In this paper, we propose an alternative approach that creates dense embeddings for data using the kernel similarities and adopts a deep neural network architecture for fusing the embeddings. In order to improve the effectiveness of this network, we introduce the kernel dropout regularization strategy coupled with the use of an expanded set of composition kernels. Experiment results on a real-world activity recognition dataset show that the proposed architecture is effective in fusing kernels and achieves state-of-the-art performance. version:1
arxiv-1612-08994 | Here's My Point: Argumentation Mining with Pointer Networks | http://arxiv.org/abs/1612.08994 | id:1612.08994 author:Peter Potash, Alexey Romanov, Anna Rumshisky category:cs.CL  published:2016-12-28 summary:One of the major goals in automated argumentation mining is to uncover the argument structure present in argumentative text. In order to determine this structure, one must understand how different individual components of the overall argument are linked. General consensus in this field dictates that the argument components form a hierarchy of persuasion, which manifests itself in a tree structure. This work provides the first neural network-based approach to argumentation mining, focusing on the two tasks of extracting links between argument components, and classifying types of argument components. In order to solve this problem, we propose to use a joint model that is based on a Pointer Network architecture. A Pointer Network is appealing for this task for the following reasons: 1) It takes into account the sequential nature of argument components; 2) By construction, it enforces certain properties of the tree structure present in argument relations; 3) The hidden representations can be applied to auxiliary tasks. In order to extend the contribution of the original Pointer Network model, we construct a joint model that simultaneously attempts to learn the type of argument component, as well as continuing to predict links between argument components. The proposed joint model achieves state-of-the-art results on two separate evaluation corpora, achieving far superior performance than a regular Pointer Network model. Our results show that optimizing for both tasks, and adding a fully-connected layer prior to recurrent neural network input, is crucial for high performance. version:1
arxiv-1612-08989 | Shamela: A Large-Scale Historical Arabic Corpus | http://arxiv.org/abs/1612.08989 | id:1612.08989 author:Yonatan Belinkov, Alexander Magidow, Maxim Romanov, Avi Shmidman, Moshe Koppel category:cs.CL I.2.7  published:2016-12-28 summary:Arabic is a widely-spoken language with a rich and long history spanning more than fourteen centuries. Yet existing Arabic corpora largely focus on the modern period or lack sufficient diachronic information. We develop a large-scale, historical corpus of Arabic of about 1 billion words from diverse periods of time. We clean this corpus, process it with a morphological analyzer, and enhance it by detecting parallel passages and automatically dating undated texts. We demonstrate its utility with selected case-studies in which we show its application to the digital humanities. version:1
arxiv-1612-08974 | ggRandomForests: Exploring Random Forest Survival | http://arxiv.org/abs/1612.08974 | id:1612.08974 author:John Ehrlinger category:stat.CO stat.ML  published:2016-12-28 summary:Random forest (Leo Breiman 2001a) (RF) is a non-parametric statistical method requiring no distributional assumptions on covariate relation to the response. RF is a robust, nonlinear technique that optimizes predictive accuracy by fitting an ensemble of trees to stabilize model estimates. Random survival forests (RSF) (Ishwaran and Kogalur 2007; Ishwaran et al. 2008) are an extension of Breimans RF techniques allowing efficient nonparametric analysis of time to event data. The randomForestSRC package (Ishwaran and Kogalur 2014) is a unified treatment of Breimans random forest for survival, regression and classification problems. Predictive accuracy makes RF an attractive alternative to parametric models, though complexity and interpretability of the forest hinder wider application of the method. We introduce the ggRandomForests package, tools for visually understand random forest models grown in R (R Core Team 2014) with the randomForestSRC package. The ggRandomForests package is structured to extract intermediate data objects from randomForestSRC objects and generate figures using the ggplot2 (Wickham 2009) graphics package. This document is structured as a tutorial for building random forest for survival with the randomForestSRC package and using the ggRandomForests package for investigating how the forest is constructed. We analyse the Primary Biliary Cirrhosis of the liver data from a clinical trial at the Mayo Clinic (Fleming and Harrington 1991). Our aim is to demonstrate the strength of using Random Forest methods for both prediction and information retrieval, specifically in time to event data settings. version:1
arxiv-1612-08967 | Efficient iterative policy optimization | http://arxiv.org/abs/1612.08967 | id:1612.08967 author:Nicolas Le Roux category:cs.AI cs.LG cs.RO  published:2016-12-28 summary:We tackle the issue of finding a good policy when the number of policy updates is limited. This is done by approximating the expected policy reward as a sequence of concave lower bounds which can be efficiently maximized, drastically reducing the number of policy updates required to achieve good performance. We also extend existing methods to negative rewards, enabling the use of control variates. version:1
arxiv-1612-08936 | Partial Membership Latent Dirichlet Allocation | http://arxiv.org/abs/1612.08936 | id:1612.08936 author:Chao Chen, Alina Zare, Huy Trinh, Gbeng Omotara, J. Tory Cobb, Timotius Lagaunne category:cs.CV stat.ML  published:2016-12-28 summary:Topic models (e.g., pLSA, LDA, sLDA) have been widely used for segmenting imagery. However, these models are confined to crisp segmentation, forcing a visual word (i.e., an image patch) to belong to one and only one topic. Yet, there are many images in which some regions cannot be assigned a crisp categorical label (e.g., transition regions between a foggy sky and the ground or between sand and water at a beach). In these cases, a visual word is best represented with partial memberships across multiple topics. To address this, we present a partial membership latent Dirichlet allocation (PM-LDA) model and an associated parameter estimation algorithm. This model can be useful for imagery where a visual word may be a mixture of multiple topics. Experimental results on visual and sonar imagery show that PM-LDA can produce both crisp and soft semantic image segmentations; a capability previous topic modeling methods do not have. version:1
arxiv-1612-08220 | Understanding Neural Networks through Representation Erasure | http://arxiv.org/abs/1612.08220 | id:1612.08220 author:Jiwei Li, Will Monroe, Dan Jurafsky category:cs.CL  published:2016-12-24 summary:While neural networks have been successfully applied to many natural language processing tasks, they come at the cost of interpretability. In this paper, we propose a general methodology to analyze and interpret decisions from a neural model by observing the effects on the model of erasing various parts of the representation, such as input word-vector dimensions, intermediate hidden units, or input words. We present several approaches to analyzing the effects of such erasure, from computing the relative difference in evaluation metrics, to using reinforcement learning to erase the minimum set of input words in order to flip a neural model's decision. In a comprehensive analysis of multiple NLP tasks, including linguistic feature classification, sentence-level sentiment analysis, and document level sentiment aspect prediction, we show that the proposed methodology not only offers clear explanations about neural model decisions, but also provides a way to conduct error analysis on neural models. version:2
arxiv-1612-08932 | Optimal bandwidth estimation for a fast manifold learning algorithm to detect circular structure in high-dimensional data | http://arxiv.org/abs/1612.08932 | id:1612.08932 author:Susovan Pal, Praneeth Vepakomma category:stat.ML  published:2016-12-28 summary:We provide a way to infer about existence of topological circularity in high-dimensional data sets in $\mathbb{R}^d$ from its projection in $\mathbb{R}^2$ obtained through a fast manifold learning map as a function of the high-dimensional dataset $\mathbb{X}$ and a particular choice of a positive real $\sigma$ known as bandwidth parameter. At the same time we also provide a way to estimate the optimal bandwidth for fast manifold learning in this setting through minimization of these functions of bandwidth. We also provide limit theorems to characterize the behavior of our proposed functions of bandwidth. version:1
arxiv-1612-08927 | Fast color transfer from multiple images | http://arxiv.org/abs/1612.08927 | id:1612.08927 author:Asad Khan, Luo Jiang, Wei Li, Ligang Liu category:cs.CV cs.GR  published:2016-12-28 summary:Color transfer between images uses the statistics information of image effectively. We present a novel approach of local color transfer between images based on the simple statistics and locally linear embedding. A sketching interface is proposed for quickly and easily specifying the color correspondences between target and source image. The user can specify the correspondences of local region using scribes, which more accurately transfers the target color to the source image while smoothly preserving the boundaries, and exhibits more natural output results. Our algorithm is not restricted to one-to-one image color transfer and can make use of more than one target images to transfer the color in different regions in the source image. Moreover, our algorithm does not require to choose the same color style and image size between source and target images. We propose the sub-sampling to reduce the computational load. Comparing with other approaches, our algorithm is much better in color blending in the input data. Our approach preserves the other color details in the source image. Various experimental results show that our approach specifies the correspondences of local color region in source and target images. And it expresses the intention of users and generates more actual and natural results of visual effect. version:1
arxiv-1612-08915 | Bayesian Optimization with Shape Constraints | http://arxiv.org/abs/1612.08915 | id:1612.08915 author:Michael Jauch, Víctor Peña category:stat.ML  published:2016-12-28 summary:In typical applications of Bayesian optimization, minimal assumptions are made about the objective function being optimized. This is true even when researchers have prior information about the shape of the function with respect to one or more argument. We make the case that shape constraints are often appropriate in at least two important application areas of Bayesian optimization: (1) hyperparameter tuning of machine learning algorithms and (2) decision analysis with utility functions. We describe a methodology for incorporating a variety of shape constraints within the usual Bayesian optimization framework and present positive results from simple applications which suggest that Bayesian optimization with shape constraints is a promising topic for further research. version:1
arxiv-1612-08894 | Unsupervised domain adaptation in brain lesion segmentation with adversarial networks | http://arxiv.org/abs/1612.08894 | id:1612.08894 author:Konstantinos Kamnitsas, Christian Baumgartner, Christian Ledig, Virginia F. J. Newcombe, Joanna P. Simpson, Andrew D. Kane, David K. Menon, Aditya Nori, Antonio Criminisi, Daniel Rueckert, Ben Glocker category:cs.CV  published:2016-12-28 summary:Significant advances have been made towards building accurate automatic segmentation systems for a variety of biomedical applications using machine learning. However, the performance of these systems often degrades when they are applied on new data that differ from the training data, for example, due to variations in imaging protocols. Manually annotating new data for each test domain is not a feasible solution. In this work we investigate unsupervised domain adaptation using adversarial neural networks to train a segmentation method which is more invariant to differences in the input data, and which does not require any annotations on the test domain. Specifically, we learn domain-invariant features by learning to counter an adversarial network, which attempts to classify the domain of the input data by observing the activations of the segmentation network. Furthermore, we propose a multi-connected domain discriminator for improved adversarial training. Our system is evaluated using two MR databases of subjects with traumatic brain injuries, acquired using different scanners and imaging protocols. Using our unsupervised approach, we obtain segmentation accuracies which are close to the upper bound of supervised domain adaptation. version:1
arxiv-1612-08879 | Deep Unsupervised Representation Learning for Remote Sensing Images | http://arxiv.org/abs/1612.08879 | id:1612.08879 author:DaoYu Lin category:cs.CV  published:2016-12-28 summary:Scene classification plays a key role in interpreting the remotely sensed high-resolution images. With the development of deep learning, supervised learning in classification of Remote Sensing with convolutional networks (CNNs) has been frequently adopted. However, researchers paid less attention to unsupervised learning in remote sensing with CNNs. In order to filling the gap, this paper proposes a set of CNNs called \textbf{M}ultiple l\textbf{A}ye\textbf{R} fea\textbf{T}ure m\textbf{A}tching(MARTA) generative adversarial networks (GANs) to learn representation using only unlabeled data. There will be two models of MARTA GANs involved: (1) a generative model $G$ that captures the data distribution and provides more training data; (2) a discriminative model $D$ that estimates the possibility that a sample came from the training data rather than $G$ and in this way a well-formed representation of dataset can be learned. Therefore, MARTA GANs obtain the state-of-the-art results which outperform the results got from UC-Merced Land-use dataset and Brazilian Coffee Scenes dataset. version:1
arxiv-1612-08875 | The Pessimistic Limits of Margin-based Losses in Semi-supervised Learning | http://arxiv.org/abs/1612.08875 | id:1612.08875 author:Jesse H. Krijthe, Marco Loog category:stat.ML cs.LG  published:2016-12-28 summary:We show that for linear classifiers defined by convex margin-based surrogate losses that are monotonically decreasing, it is impossible to construct any semi-supervised approach that is able to guarantee an improvement over the supervised classifier measured by this surrogate loss. For non-monotonically decreasing loss functions, we demonstrate safe improvements are possible. version:1
arxiv-1612-08871 | Semantic Video Segmentation by Gated Recurrent Flow Propagation | http://arxiv.org/abs/1612.08871 | id:1612.08871 author:David Nilsson, Cristian Sminchisescu category:cs.CV  published:2016-12-28 summary:Semantic video segmentation is challenging due to the sheer amount of data that needs to be processed and labeled in order to construct accurate models. In this paper we present a deep, end-to-end trainable methodology to video segmentation that is capable of leveraging information present in unlabeled data in order to improve semantic estimates. Our model combines a convolutional architecture and a spatial transformer recurrent layer that are able to temporally propagate labeling information by means of optical flow, adaptively gated based on its locally estimated uncertainty. The flow, the recogition and the gated propagation modules can be trained jointly, end-to-end. The gated recurrent flow propagation component of our model can be plugged-in any static semantic segmentation architecture and turn it into a weakly supervised video processing one. Our extensive experiments in the challenging CityScapes dataset indicate that the resulting model can leverage unlabeled temporal frames next to a labeled one in order to improve both the video segmentation accuracy and the consistency of its temporal labeling, at no additional annotation cost. version:1
arxiv-1612-08825 | Accelerated Convolutions for Efficient Multi-Scale Time to Contact Computation in Julia | http://arxiv.org/abs/1612.08825 | id:1612.08825 author:Alexander Amini, Berthold Horn, Alan Edelman category:cs.CV cs.AI cs.PF  published:2016-12-28 summary:Convolutions have long been regarded as fundamental to applied mathematics, physics and engineering. Their mathematical elegance allows for common tasks such as numerical differentiation to be computed efficiently on large data sets. Efficient computation of convolutions is critical to artificial intelligence in real-time applications, like machine vision, where convolutions must be continuously and efficiently computed on tens to hundreds of kilobytes per second. In this paper, we explore how convolutions are used in fundamental machine vision applications. We present an accelerated n-dimensional convolution package in the high performance computing language, Julia, and demonstrate its efficacy in solving the time to contact problem for machine vision. Results are measured against synthetically generated videos and quantitatively assessed according to their mean squared error from the ground truth. We achieve over an order of magnitude decrease in compute time and allocated memory for comparable machine vision applications. All code is packaged and integrated into the official Julia Package Manager to be used in various other scenarios. version:1
arxiv-1612-08820 | Multivariate mixture model for myocardium segmentation combining multi-source images | http://arxiv.org/abs/1612.08820 | id:1612.08820 author:Xiahai Zhuang category:cs.CV  published:2016-12-28 summary:This paper proposes a method for simultaneous segmentation of multi-source images, using the multivariate mixture model (MvMM) and maximum of log-likelihood (LL) framework. The segmentation is a procedure of texture classification, and the MvMM is used to model the joint intensity distribution of the images. Specifically, the method is applied to the myocardial segmentation combining the complementary texture information from multi-sequence (MS) cardiac magnetic resonance (CMR) images. Furthermore, there exist inter-image mis-registration and intra-image misalignment of slices in the MS CMR images. Hence, the MvMM is formulated with transformations, which are embedded into the LL framework and optimized simultaneously with the segmentation parameters. The proposed method is able to correct the inter- and intra-image misalignment by registering each slice of the MS CMR to a virtual common space, as well as to delineate the indistinguishable boundaries of myocardium consisting of pathologies. Results have shown statistically significant improvement in the segmentation performance of the proposed method with respect to the conventional approaches which can solely segment each image separately. The proposed method has also demonstrated better robustness in the incongruent data, where some images may not fully cover the region of interest and the full coverage can only be reconstructed combining the images from multiple sources. version:1
arxiv-1612-08813 | Optimization of Test Case Generation using Genetic Algorithm (GA) | http://arxiv.org/abs/1612.08813 | id:1612.08813 author:Ahmed Mateen, Marriam Nazir, Salman Afsar Awan category:cs.SE cs.NE  published:2016-12-28 summary:Testing provides means pertaining to assuring software performance. The total aim of software industry is actually to make a certain start associated with high quality software for the end user. However, associated with software testing has quite a few underlying concerns, which are very important and need to pay attention on these issues. These issues are effectively generating, prioritization of test cases, etc. These issues can be overcome by paying attention and focus. Solitary of the greatest Problems in the software testing area is usually how to acquire a great proper set associated with cases to confirm software. Some other strategies and also methodologies are proposed pertaining to shipping care of most of these issues. Genetic Algorithm (GA) belongs to evolutionary algorithms. Evolutionary algorithms have a significant role in the automatic test generation and many researchers are focusing on it. In this study explored software testing related issues by using the GA approach. In addition to right after applying some analysis, better solution produced, that is feasible and reliable. The particular research presents the implementation of GAs because of its generation of optimized test cases. Along these lines, this paper gives proficient system for the optimization of test case generation using genetic algorithm. version:1
arxiv-1612-08810 | The Predictron: End-To-End Learning and Planning | http://arxiv.org/abs/1612.08810 | id:1612.08810 author:David Silver, Hado van Hasselt, Matteo Hessel, Tom Schaul, Arthur Guez, Tim Harley, Gabriel Dulac-Arnold, David Reichert, Neil Rabinowitz, Andre Barreto, Thomas Degris category:cs.LG cs.AI cs.NE  published:2016-12-28 summary:One of the key challenges of artificial intelligence is to learn models that are effective in the context of planning. In this document we introduce the predictron architecture. The predictron consists of a fully abstract model, represented by a Markov reward process, that can be rolled forward multiple "imagined" planning steps. Each forward pass of the predictron accumulates internal rewards and values over multiple planning depths. The predictron is trained end-to-end so as to make these accumulated values accurately approximate the true value function. We applied the predictron to procedurally generated random mazes and a simulator for the game of pool. The predictron yielded significantly more accurate predictions than conventional deep neural network architectures. version:1
arxiv-1612-08796 | Symbolic Representation and Classification of Logos | http://arxiv.org/abs/1612.08796 | id:1612.08796 author:D. S. Guru, N. Vinay Kumar category:cs.CV 68U10  published:2016-12-28 summary:In this paper, a model for classification of logos based on symbolic representation of features is presented. The proposed model makes use of global features of logo images such as color, texture, and shape features for classification. The logo images are broadly classified into three different classes, viz., logo image containing only text, an image with only symbol, and an image with both text and a symbol. In each class, the similar looking logo images are clustered using K-means clustering algorithm. The intra-cluster variations present in each cluster corresponding to each class are then preserved using symbolic interval data. Thus referenced logo images are represented in the form of interval data. A sample logo image is then classified using suitable symbolic classifier. For experimentation purpose, relatively large amount of color logo images is created consisting of 5044 logo images. The classification results are validated with the help of accuracy, precision, recall, F-measure, and time. To check the efficacy of the proposed model, the comparative analyses are given against the other models. The results show that the proposed model outperforms the other models with respect to time and F-measure. version:1
arxiv-1612-08795 | Provable learning of Noisy-or Networks | http://arxiv.org/abs/1612.08795 | id:1612.08795 author:Sanjeev Arora, Rong Ge, Tengyu Ma, Andrej Risteski category:cs.LG cs.DS stat.ML  published:2016-12-28 summary:Many machine learning applications use latent variable models to explain structure in data, whereby visible variables (= coordinates of the given datapoint) are explained as a probabilistic function of some hidden variables. Finding parameters with the maximum likelihood is NP-hard even in very simple settings. In recent years, provably efficient algorithms were nevertheless developed for models with linear structures: topic models, mixture models, hidden markov models, etc. These algorithms use matrix or tensor decomposition, and make some reasonable assumptions about the parameters of the underlying model. But matrix or tensor decomposition seems of little use when the latent variable model has nonlinearities. The current paper shows how to make progress: tensor decomposition is applied for learning the single-layer {\em noisy or} network, which is a textbook example of a Bayes net, and used for example in the classic QMR-DT software for diagnosing which disease(s) a patient may have by observing the symptoms he/she exhibits. The technical novelty here, which should be useful in other settings in future, is analysis of tensor decomposition in presence of systematic error (i.e., where the noise/error is correlated with the signal, and doesn't decrease as number of samples goes to infinity). This requires rethinking all steps of tensor decomposition methods from the ground up. For simplicity our analysis is stated assuming that the network parameters were chosen from a probability distribution but the method seems more generally applicable. version:1
arxiv-1612-08792 | A novel Gaussian mixture model for superpixel segmentation | http://arxiv.org/abs/1612.08792 | id:1612.08792 author:Zhihua Ban, Jianguo Liu, Li Cao category:cs.CV  published:2016-12-28 summary:Superpixel segmentation is used to partition an image into perceptually coherence atomic regions. As a preprocessing step of computer vision applications, it can enormously reduce the number of entries of subsequent algorithms. With each superpixel associated with a Gaussian distribution, we assume that a pixel is generated by first randomly choosing one of the superpixels, and then the pixel is drawn from the corresponding Gaussian density. Unlike most applications of Gaussian mixture model in clustering, data points in our model are assumed to be non-identically distributed. Given an image, a log-likelihood function is constructed for maximizing. Based on a solution derived from the expectation-maximization method, a well designed algorithm is proposed. Our method is of linear complexity with respect to the number of pixels, and it can be implemented using parallel techniques. To the best of our knowledge, our algorithm outperforms the state-of-the-art in accuracy and presents a competitive performance in computational efficiency. version:1
arxiv-1612-08789 | Automatic composition and optimisation of multicomponent predictive systems | http://arxiv.org/abs/1612.08789 | id:1612.08789 author:Manuel Martin Salvador, Marcin Budka, Bogdan Gabrys category:cs.LG  published:2016-12-28 summary:Composition and parametrisation of multicomponent predictive systems (MCPSs) consisting of chains of data transformation steps is a challenging task. This paper is concerned with theoretical considerations and extensive experimental analysis for automating the task of building such predictive systems. In the theoretical part of the paper, we first propose to adopt the Well-handled and Acyclic Workflow (WA-WF) Petri net as a formal representation of MCPSs. We then define the optimisation problem in which the search space consists of suitably parametrised directed acyclic graphs (i.e. WA-WFs) forming the sought MCPS solutions. In the experimental analysis we focus on examining the impact of considerably extending the search space resulting from incorporating multiple sequential data cleaning and preprocessing steps in the process of composing optimised MCPSs, and the quality of the solutions found. In a range of extensive experiments three different optimisation strategies are used to automatically compose MCPSs for 21 publicly available datasets and 7 datasets from real chemical processes. The diversity of the composed MCPSs found is an indication that fully and automatically exploiting different combinations of data cleaning and preprocessing techniques is possible and highly beneficial for different predictive models. Our findings can have a major impact on development of high quality predictive models as well as their maintenance and scalability aspects needed in modern applications and deployment scenarios. version:1
arxiv-1612-07976 | DeMIAN: Deep Modality Invariant Adversarial Network | http://arxiv.org/abs/1612.07976 | id:1612.07976 author:Kuniaki Saito, Yusuke Mukuta, Yoshitaka Ushiku, Tatsuya Harada category:cs.LG stat.ML  published:2016-12-23 summary:Obtaining common representations from different modalities is important in that they are interchangeable with each other in a classification problem. For example, we can train a classifier on image features in the common representations and apply it to the testing of the text features in the representations. Existing multi-modal representation learning methods mainly aim to extract rich information from paired samples and train a classifier by the corresponding labels; however, collecting paired samples and their labels simultaneously involves high labor costs. Addressing paired modal samples without their labels and single modal data with their labels independently is much easier than addressing labeled multi-modal data. To obtain the common representations under such a situation, we propose to make the distributions over different modalities similar in the learned representations, namely modality-invariant representations. In particular, we propose a novel algorithm for modality-invariant representation learning, named Deep Modality Invariant Adversarial Network (DeMIAN), which utilizes the idea of Domain Adaptation (DA). Using the modality-invariant representations learned by DeMIAN, we achieved better classification accuracy than with the state-of-the-art methods, especially for some benchmark datasets of zero-shot learning. version:2
arxiv-1612-08780 | An FFT-based Synchronization Approach to Recognize Human Behaviors using STN-LFP Signal | http://arxiv.org/abs/1612.08780 | id:1612.08780 author:Hosein M. Golshan, Adam O. Hebb, Sara J. Hanrahan, Joshua Nedrud, Mohammad H. Mahoor category:cs.CV q-bio.NC  published:2016-12-28 summary:Classification of human behavior is key to developing closed-loop Deep Brain Stimulation (DBS) systems, which may be able to decrease the power consumption and side effects of the existing systems. Recent studies have shown that the Local Field Potential (LFP) signals from both Subthalamic Nuclei (STN) of the brain can be used to recognize human behavior. Since the DBS leads implanted in each STN can collect three bipolar signals, the selection of a suitable pair of LFPs that achieves optimal recognition performance is still an open problem to address. Considering the presence of synchronized aggregate activity in the basal ganglia, this paper presents an FFT-based synchronization approach to automatically select a relevant pair of LFPs and use the pair together with an SVM-based MKL classifier for behavior recognition purposes. Our experiments on five subjects show the superiority of the proposed approach compared to other methods used for behavior classification. version:1
arxiv-1612-09268 | The ontogeny of discourse structure mimics the development of literature | http://arxiv.org/abs/1612.09268 | id:1612.09268 author:Natalia Bezerra Mota, Sylvia Pinheiro, Mariano Sigman, Diego Fernandez Slezak, Guillermo Cecchi, Mauro Copelli, Sidarta Ribeiro category:q-bio.NC cs.CL physics.soc-ph  published:2016-12-27 summary:Discourse varies with age, education, psychiatric state and historical epoch, but the ontogenetic and cultural dynamics of discourse structure remain to be quantitatively characterized. To this end we investigated word graphs obtained from verbal reports of 200 subjects ages 2-58, and 676 literary texts spanning ~5,000 years. In healthy subjects, lexical diversity, graph size, and long-range recurrence departed from initial near-random levels through a monotonic asymptotic increase across ages, while short-range recurrence showed a corresponding decrease. These changes were explained by education and suggest a hierarchical development of discourse structure: short-range recurrence and lexical diversity stabilize after elementary school, but graph size and long-range recurrence only stabilize after high school. This gradual maturation was blurred in psychotic subjects, who maintained in adulthood a near-random structure. In literature, monotonic asymptotic changes over time were remarkable: While lexical diversity, long-range recurrence and graph size increased away from near-randomness, short-range recurrence declined, from above to below random levels. Bronze Age texts are structurally similar to childish or psychotic discourses, but subsequent texts converge abruptly to the healthy adult pattern around the onset of the Axial Age (800-200 BC), a period of pivotal cultural change. Thus, individually as well as historically, discourse maturation increases the range of word recurrence away from randomness. version:1
arxiv-1612-08712 | Semantic Perceptual Image Compression using Deep Convolution Networks | http://arxiv.org/abs/1612.08712 | id:1612.08712 author:Aaditya Prakash, Nick Moran, Solomon Garber, Antonella DiLillo, James Storer category:cs.MM cs.CV  published:2016-12-27 summary:It has long been considered a significant problem to improve the visual quality of lossy image and video compression. Recent advances in computing power together with the availability of large training data sets has increased interest in the application of deep learning cnns to address image recognition and image processing tasks. Here, we present a powerful cnn tailored to the specific task of semantic image understanding to achieve higher visual quality in lossy compression. A modest increase in complexity is incorporated to the encoder which allows a standard, off-the-shelf jpeg decoder to be used. While jpeg encoding may be optimized for generic images, the process is ultimately unaware of the specific content of the image to be compressed. Our technique makes jpeg content-aware by designing and training a model to identify multiple semantic regions in a given image. Unlike object detection techniques, our model does not require labeling of object positions and is able to identify objects in a single pass. We present a new cnn architecture directed specifically to image compression, which generates a map that highlights semantically-salient regions so that they can be encoded at higher quality as compared to background regions. By adding a complete set of features for every class, and then taking a threshold over the sum of all feature activations, we generate a map that highlights semantically-salient regions so that they can be encoded at a better quality compared to background regions. Experiments are presented on the Kodak PhotoCD dataset and the MIT Saliency Benchmark dataset, in which our algorithm achieves higher visual quality for the same compressed size. version:1
arxiv-1612-08669 | A Hybrid Both Filter and Wrapper Feature Selection Method for Microarray Classification | http://arxiv.org/abs/1612.08669 | id:1612.08669 author:Li-Yeh Chuang, Chao-Hsuan Ke, Cheng-Hong Yang category:cs.LG  published:2016-12-27 summary:Gene expression data is widely used in disease analysis and cancer diagnosis. However, since gene expression data could contain thousands of genes simultaneously, successful microarray classification is rather difficult. Feature selection is an important pre-treatment for any classification process. Selecting a useful gene subset as a classifier not only decreases the computational time and cost, but also increases classification accuracy. In this study, we applied the information gain method as a filter approach, and an improved binary particle swarm optimization as a wrapper approach to implement feature selection; selected gene subsets were used to evaluate the performance of classification. Experimental results show that by employing the proposed method fewer gene subsets needed to be selected and better classification accuracy could be obtained. version:1
arxiv-1612-08650 | Reproducible Pattern Recognition Research: The Case of Optimistic SSL | http://arxiv.org/abs/1612.08650 | id:1612.08650 author:Jesse H. Krijthe, Marco Loog category:stat.ML cs.LG  published:2016-12-27 summary:In this paper, we discuss the approaches we took and trade-offs involved in making a paper on a conceptual topic in pattern recognition research fully reproducible. We discuss our definition of reproducibility, the tools used, how the analysis was set up, show some examples of alternative analyses the code enables and discuss our views on reproducibility. version:1
arxiv-1612-08642 | Bayesian Nonparametric Models for Synchronous Brain-Computer Interfaces | http://arxiv.org/abs/1612.08642 | id:1612.08642 author:Jaime Fernando Delgado Saa, Mujdat Cetin category:cs.CV q-bio.NC  published:2016-12-27 summary:A brain-computer interface (BCI) is a system that aims for establishing a non-muscular communication path for subjects who had suffer from a neurodegenerative disease. Many BCI systems make use of the phenomena of event-related synchronization and de-synchronization of brain waves as a main feature for classification of different cognitive tasks. However, the temporal dynamics of the electroencephalographic (EEG) signals contain additional information that can be incorporated into the inference engine in order to improve the performance of the BCIs. This information about the dynamics of the signals have been exploited previously in BCIs by means of generative and discriminative methods. In particular, hidden Markov models (HMMs) have been used in previous works. These methods have the disadvantage that the model parameters such as the number of hidden states and the number of Gaussian mixtures need to be fix "a priori". In this work, we propose a Bayesian nonparametric model for brain signal classification that does not require "a priori" selection of the number of hidden states and the number of Gaussian mixtures of a HMM. The results show that the proposed model outperform other methods based on HMM as well as the winner algorithm of the BCI competition IV. version:1
arxiv-1612-08633 | A Sparse Nonlinear Classifier Design Using AUC Optimization | http://arxiv.org/abs/1612.08633 | id:1612.08633 author:Vishal Kakkar, Shirish K. Shevade, S Sundararajan, Dinesh Garg category:cs.AI cs.LG stat.ML  published:2016-12-27 summary:AUC (Area under the ROC curve) is an important performance measure for applications where the data is highly imbalanced. Learning to maximize AUC performance is thus an important research problem. Using a max-margin based surrogate loss function, AUC optimization problem can be approximated as a pairwise rankSVM learning problem. Batch learning methods for solving the kernelized version of this problem suffer from scalability and may not result in sparse classifiers. Recent years have witnessed an increased interest in the development of online or single-pass online learning algorithms that design a classifier by maximizing the AUC performance. The AUC performance of nonlinear classifiers, designed using online methods, is not comparable with that of nonlinear classifiers designed using batch learning algorithms on many real-world datasets. Motivated by these observations, we design a scalable algorithm for maximizing AUC performance by greedily adding the required number of basis functions into the classifier model. The resulting sparse classifiers perform faster inference. Our experimental results show that the level of sparsity achievable can be order of magnitude smaller than the Kernel RankSVM model without affecting the AUC performance much. version:1
arxiv-1612-06007 | A Hidden Absorbing Semi-Markov Model for Informatively Censored Temporal Data: Learning and Inference | http://arxiv.org/abs/1612.06007 | id:1612.06007 author:Ahmed M. Alaa, Mihaela van der Schaar category:cs.AI stat.ML  published:2016-12-18 summary:Modeling continuous-time physiological processes that manifest a patient's evolving clinical states is a key step in approaching many problems in healthcare. In this paper, we develop the Hidden Absorbing Semi-Markov Model (HASMM): a versatile probabilistic model that is capable of capturing the modern electronic health record (EHR) data. Unlike exist- ing models, an HASMM accommodates irregularly sampled, temporally correlated, and informatively censored physiological data, and can describe non-stationary clinical state transitions. Learning an HASMM from the EHR data is achieved via a novel forward- filtering backward-sampling Monte-Carlo EM algorithm that exploits the knowledge of the end-point clinical outcomes (informative censoring) in the EHR data, and implements the E-step by sequentially sampling the patients' clinical states in the reverse-time direction while conditioning on the future states. Real-time inferences are drawn via a forward- filtering algorithm that operates on a virtually constructed discrete-time embedded Markov chain that mirrors the patient's continuous-time state trajectory. We demonstrate the di- agnostic and prognostic utility of the HASMM in a critical care prognosis setting using a real-world dataset for patients admitted to the Ronald Reagan UCLA Medical Center. version:2
arxiv-1612-08608 | ASAP: Asynchronous Approximate Data-Parallel Computation | http://arxiv.org/abs/1612.08608 | id:1612.08608 author:Asim Kadav, Erik Kruus category:cs.DC cs.LG  published:2016-12-27 summary:Emerging workloads, such as graph processing and machine learning are approximate because of the scale of data involved and the stochastic nature of the underlying algorithms. These algorithms are often distributed over multiple machines using bulk-synchronous processing (BSP) or other synchronous processing paradigms such as map-reduce. However, data parallel processing primitives such as repeated barrier and reduce operations introduce high synchronization overheads. Hence, many existing data-processing platforms use asynchrony and staleness to improve data-parallel job performance. Often, these systems simply change the synchronous communication to asynchronous between the worker nodes in the cluster. This improves the throughput of data processing but results in poor accuracy of the final output since different workers may progress at different speeds and process inconsistent intermediate outputs. In this paper, we present ASAP, a model that provides asynchronous and approximate processing semantics for data-parallel computation. ASAP provides fine-grained worker synchronization using NOTIFY-ACK semantics that allows independent workers to run asynchronously. ASAP also provides stochastic reduce that provides approximate but guaranteed convergence to the same result as an aggregated all-reduce. In our results, we show that ASAP can reduce synchronization costs and provides 2-10X speedups in convergence and up to 10X savings in network costs for distributed machine learning applications and provides strong convergence guarantees. version:1
arxiv-1612-08549 | Relative Error Bounds for Nonnegative Matrix Factorization under a Geometric Assumption | http://arxiv.org/abs/1612.08549 | id:1612.08549 author:Zhaoqiang Liu, Vincent Y. F. Tan category:stat.ML stat.ME  published:2016-12-27 summary:We propose a geometric assumption on nonnegative data matrices such that under this assumption, we are able to provide upper bounds (both deterministic and probabilistic) on the relative error of nonnegative matrix factorization (NMF). The algorithm we propose first uses the geometric assumption to obtain an exact clustering of the columns of the data matrix; subsequently, it employs several rank-one NMFs to obtain the final decomposition. When applied to data matrices generated from our statistical model, we observe that our proposed algorithm produces factor matrices with comparable relative errors vis-a`-vis classical NMF algorithms but with much faster speeds. On face image and hyperspectral imaging datasets, we demonstrate that our algorithm provides an excellent initialization for applying other NMF algorithms at a low computational cost. Finally, we show on face and text datasets that the combinations of our algorithm and several classical NMF algorithms outperform other algorithms in terms of clustering performance. version:1
arxiv-1612-08544 | Theory-guided Data Science: A New Paradigm for Scientific Discovery | http://arxiv.org/abs/1612.08544 | id:1612.08544 author:Anuj Karpatne, Gowtham Atluri, James Faghmous, Michael Steinbach, Arindam Banerjee, Auroop Ganguly, Shashi Shekhar, Nagiza Samatova, Vipin Kumar category:cs.LG cs.AI stat.ML  published:2016-12-27 summary:Data science models, although successful in a number of commercial domains, have had limited applicability in scientific problems involving complex physical phenomena. Theory-guided data science (TGDS) is an emerging paradigm that aims to leverage the wealth of scientific knowledge for improving the effectiveness of data science models in enabling scientific discovery. The overarching vision of TGDS is to introduce scientific consistency as an essential component for learning generalizable models. Further, by producing scientifically interpretable models, TGDS aims to advance our scientific understanding by discovering novel domain insights. Indeed, the paradigm of TGDS has started to gain prominence in a number of scientific disciplines such as turbulence modeling, material discovery, quantum chemistry, bio-medical science, bio-marker discovery, climate science, and hydrology. In this paper, we formally conceptualize the paradigm of TGDS and present a taxonomy of research themes in TGDS. We describe several approaches for integrating domain knowledge in different research themes using illustrative examples from different disciplines. We also highlight some of the promising avenues of novel research for realizing the full potential of theory-guided data science. version:1
arxiv-1612-08543 | Distributed Real-Time Sentiment Analysis for Big Data Social Streams | http://arxiv.org/abs/1612.08543 | id:1612.08543 author:Amir Hossein Akhavan Rahnama category:stat.ML cs.CL cs.DB cs.DC cs.IR  published:2016-12-27 summary:Big data trend has enforced the data-centric systems to have continuous fast data streams. In recent years, real-time analytics on stream data has formed into a new research field, which aims to answer queries about what-is-happening-now with a negligible delay. The real challenge with real-time stream data processing is that it is impossible to store instances of data, and therefore online analytical algorithms are utilized. To perform real-time analytics, pre-processing of data should be performed in a way that only a short summary of stream is stored in main memory. In addition, due to high speed of arrival, average processing time for each instance of data should be in such a way that incoming instances are not lost without being captured. Lastly, the learner needs to provide high analytical accuracy measures. Sentinel is a distributed system written in Java that aims to solve this challenge by enforcing both the processing and learning process to be done in distributed form. Sentinel is built on top of Apache Storm, a distributed computing platform. Sentinels learner, Vertical Hoeffding Tree, is a parallel decision tree-learning algorithm based on the VFDT, with ability of enabling parallel classification in distributed environments. Sentinel also uses SpaceSaving to keep a summary of the data stream and stores its summary in a synopsis data structure. Application of Sentinel on Twitter Public Stream API is shown and the results are discussed. version:1
arxiv-1612-08534 | Robust LSTM-Autoencoders for Face De-Occlusion in the Wild | http://arxiv.org/abs/1612.08534 | id:1612.08534 author:Fang Zhao, Jiashi Feng, Jian Zhao, Wenhan Yang, Shuicheng Yan category:cs.CV  published:2016-12-27 summary:Face recognition techniques have been developed significantly in recent years. However, recognizing faces with partial occlusion is still challenging for existing face recognizers which is heavily desired in real-world applications concerning surveillance and security. Although much research effort has been devoted to developing face de-occlusion methods, most of them can only work well under constrained conditions, such as all the faces are from a pre-defined closed set. In this paper, we propose a robust LSTM-Autoencoders (RLA) model to effectively restore partially occluded faces even in the wild. The RLA model consists of two LSTM components, which aims at occlusion-robust face encoding and recurrent occlusion removal respectively. The first one, named multi-scale spatial LSTM encoder, reads facial patches of various scales sequentially to output a latent representation, and occlusion-robustness is achieved owing to the fact that the influence of occlusion is only upon some of the patches. Receiving the representation learned by the encoder, the LSTM decoder with a dual channel architecture reconstructs the overall face and detects occlusion simultaneously, and by feat of LSTM, the decoder breaks down the task of face de-occlusion into restoring the occluded part step by step. Moreover, to minimize identify information loss and guarantee face recognition accuracy over recovered faces, we introduce an identity-preserving adversarial training scheme to further improve RLA. Extensive experiments on both synthetic and real datasets of faces with occlusion clearly demonstrate the effectiveness of our proposed RLA in removing different types of facial occlusion at various locations. The proposed method also provides significantly larger performance gain than other de-occlusion methods in promoting recognition performance over partially-occluded faces. version:1
arxiv-1612-08510 | Learning Non-Lambertian Object Intrinsics across ShapeNet Categories | http://arxiv.org/abs/1612.08510 | id:1612.08510 author:Jian Shi, Yue Dong, Hao Su, Stella X. Yu category:cs.CV  published:2016-12-27 summary:We consider the non-Lambertian object intrinsic problem of recovering diffuse albedo, shading, and specular highlights from a single image of an object. We build a large-scale object intrinsics database based on existing 3D models in the ShapeNet database. Rendered with realistic environment maps, millions of synthetic images of objects and their corresponding albedo, shading, and specular ground-truth images are used to train an encoder-decoder CNN. Once trained, the network can decompose an image into the product of albedo and shading components, along with an additive specular component. Our CNN delivers accurate and sharp results in this classical inverse problem of computer vision, sharp details attributed to skip layer connections at corresponding resolutions from the encoder to the decoder. Benchmarked on our ShapeNet and MIT intrinsics datasets, our model consistently outperforms the state-of-the-art by a large margin. We train and test our CNN on different object categories. Perhaps surprising especially from the CNN classification perspective, our intrinsics CNN generalizes very well across categories. Our analysis shows that feature learning at the encoder stage is more crucial for developing a universal representation across categories. We apply our synthetic data trained model to images and videos downloaded from the internet, and observe robust and realistic intrinsics results. Quality non-Lambertian intrinsics could open up many interesting applications such as image-based albedo and specular editing. version:1
arxiv-1612-08504 | Classifying Patents Based on their Semantic Content | http://arxiv.org/abs/1612.08504 | id:1612.08504 author:Antonin Bergeaud, Yoann Potiron, Juste Raimbault category:physics.soc-ph cs.CL  published:2016-12-27 summary:In this paper, we extend some usual techniques of classification resulting from a large-scale data-mining and network approach. This new technology, which in particular is designed to be suitable to big data, is used to construct an open consolidated database from raw data on 4 million patents taken from the US patent office from 1976 onward. To build the pattern network, not only do we look at each patent title, but we also examine their full abstract and extract the relevant keywords accordingly. We refer to this classification as semantic approach in contrast with the more common technological approach which consists in taking the topology when considering US Patent office technological classes. Moreover, we document that both approaches have highly different topological measures and strong statistical evidence that they feature a different model. This suggests that our method is a useful tool to extract endogenous information. version:1
arxiv-1612-08499 | End-to-End Data Visualization by Metric Learning and Coordinate Transformation | http://arxiv.org/abs/1612.08499 | id:1612.08499 author:Lilei Zheng, Ying Zhang, Stefan Duffner, Khalid Idrissi, Christophe Garcia, Atilla Baskurt category:cs.CV  published:2016-12-27 summary:This paper presents a deep nonlinear metric learning framework for data visualization on an image dataset. We propose the Triangular Similarity and prove its equivalence to the Cosine Similarity in measuring a data pair. Based on this novel similarity, a geometrically motivated loss function - the triangular loss - is then developed for optimizing a metric learning system comprising two identical CNNs. It is shown that this deep nonlinear system can be efficiently trained by a hybrid algorithm based on the conventional backpropagation algorithm. More interestingly, benefiting from classical manifold learning theories, the proposed system offers two different views to visualize the outputs, the second of which provides better classification results than the state-of-the-art methods in the visualizable spaces. version:1
arxiv-1612-08498 | Steerable CNNs | http://arxiv.org/abs/1612.08498 | id:1612.08498 author:Taco S. Cohen, Max Welling category:cs.LG stat.ML  published:2016-12-27 summary:It has long been recognized that the invariance and equivariance properties of a representation are critically important for success in many vision tasks. In this paper we present Steerable Convolutional Neural Networks, an efficient and flexible class of equivariant convolutional networks. We show that steerable CNNs achieve state of the art results on the CIFAR image classification benchmark. The mathematical theory of steerable representations reveals a type system in which any steerable representation is a composition of elementary feature types, each one associated with a particular kind of symmetry. We show how the parameter cost of a steerable filter bank depends on the types of the input and output features, and show how to use this knowledge to construct CNNs that utilize parameters effectively. version:1
arxiv-1612-07545 | A Revisit of Hashing Algorithms for Approximate Nearest Neighbor Search | http://arxiv.org/abs/1612.07545 | id:1612.07545 author:Deng Cai category:cs.CV  published:2016-12-22 summary:Approximate Nearest Neighbor (ANN) search is a fundamental problem in many areas of machine learning and data mining. During the past decade, numerous hashing algorithms are proposed to solve this problem. Every proposed algorithm claims outperforms other state-of-the-art methods. However, there are serious drawbacks in the evaluation of existing hashing papers and most of the claims in these papers should be re-examined. 1) Most of the existing papers failed to correctly measure the search time which is essential for the ANN search problem. 2) As a result, most of the papers report the performance increases as the code length increases, which is wrong if we measure the search time correctly. 3) The performance of some hashing algorithms (e.g., LSH) can easily be boosted if one uses multiple hash tables, which is an important factor should be considered in the evaluation while most of the papers failed to do so. In this paper, we carefully revisit many popular hashing algorithms and suggest one possible promising direction. For the sake of reproducibility, all the codes used in the paper are released on Github, which can be used as a testing platform to fairly compare various hashing algorithms. version:2
arxiv-1612-07562 | A note on the function approximation error bound for risk-sensitive reinforcement learning | http://arxiv.org/abs/1612.07562 | id:1612.07562 author:Prasenjit Karmakar, Shalabh Bhatnagar category:cs.LG  published:2016-12-22 summary:In this paper we improve the existing function approximation error bound for the policy evaluation algorithm when the aim is to find the risk-sensitive cost represented using exponential utility. version:2
arxiv-1612-08484 | An Automated CNN Recommendation System for Image Classification Tasks | http://arxiv.org/abs/1612.08484 | id:1612.08484 author:Song Wang, Li Sun, Wei Fan, Jun Sun, Satoshi Naoi, Koichi Shirahata, Takuya Fukagai, Yasumoto Tomita, Atsushi Ike category:cs.CV  published:2016-12-27 summary:Nowadays the CNN is widely used in practical applications for image classification task. However the design of the CNN model is very professional work and which is very difficult for ordinary users. Besides, even for experts of CNN, to select an optimal model for specific task may still need a lot of time (to train many different models). In order to solve this problem, we proposed an automated CNN recommendation system for image classification task. Our system is able to evaluate the complexity of the classification task and the classification ability of the CNN model precisely. By using the evaluation results, the system can recommend the optimal CNN model and which can match the task perfectly. The recommendation process of the system is very fast since we don't need any model training. The experiment results proved that the evaluation methods are very accurate and reliable. version:1
arxiv-1612-08461 | Randomized Block Frank-Wolfe for Convergent Large-Scale Learning | http://arxiv.org/abs/1612.08461 | id:1612.08461 author:Liang Zhang, Gang Wang, Daniel Romero, Georgios B. Giannakis category:math.OC cs.LG cs.NA  published:2016-12-27 summary:Owing to their low-complexity iterations, Frank-Wolfe (FW) solvers are well suited for various large-scale learning tasks. When block-separable constraints are also present, randomized FW has been shown to further reduce complexity by updating only a fraction of coordinate blocks per iteration. In this context, the present work develops feasibility-ensuring step sizes, and provably convergent randomized block Frank-Wolfe (RB-FW) solvers that are flexible in selecting the number of blocks to update per iteration. Convergence rates of RB-FW are established through computational bounds on a primal sub-optimality measure, and on the duality gap. Different from existing convergence analysis, which only applies to a step-size sequence that does not generally lead to feasible iterates, the analysis here includes two classes of step-size sequences that not only guarantee feasibility of the iterates, but also enhance flexibility in choosing decay rates. The novel convergence results are markedly broadened to encompass also nonconvex objectives, and further assert that RB-FW with exact line-search reaches a stationary point at rate $\mathcal{O}(1/\sqrt{t})$. Performance of RB-FW with different step sizes and number of blocks is demonstrated in two applications, namely charging of electrical vehicles and structural support vector machines. Simulated tests demonstrate the impressive performance improvement of RB-FW relative to existing randomized single-block FW methods. version:1
arxiv-1612-08408 | Signature of Geometric Centroids for 3D Local Shape Description and Partial Shape Matching | http://arxiv.org/abs/1612.08408 | id:1612.08408 author:Keke Tang, Peng Song, Xiaoping Chen category:cs.CV  published:2016-12-26 summary:Depth scans acquired from different views may contain nuisances such as noise, occlusion, and varying point density. We propose a novel Signature of Geometric Centroids descriptor, supporting direct shape matching on the scans, without requiring any preprocessing such as scan denoising or converting into a mesh. First, we construct the descriptor by voxelizing the local shape within a uniquely defined local reference frame and concatenating geometric centroid and point density features extracted from each voxel. Second, we compare two descriptors by employing only corresponding voxels that are both non-empty, thus supporting matching incomplete local shape such as those close to scan boundary. Third, we propose a descriptor saliency measure and compute it from a descriptor-graph to improve shape matching performance. We demonstrate the descriptor's robustness and effectiveness for shape matching by comparing it with three state-of-the-art descriptors, and applying it to object/scene reconstruction and 3D object recognition. version:1
arxiv-1612-08406 | Correlated signal inference by free energy exploration | http://arxiv.org/abs/1612.08406 | id:1612.08406 author:Torsten A. Enßlin, Jakob Knollmüller category:stat.ML astro-ph.IM cs.IT cs.LG math.IT 62F15  published:2016-12-26 summary:The inference of correlated signal fields with unknown correlation structures is of high scientific and technological relevance, but poses significant conceptual and numerical challenges. To address these, we develop the correlated signal inference (CSI) algorithm within information field theory (IFT) and discuss its numerical implementation. To this end, we introduce the free energy exploration (FrEE) strategy for numerical information field theory (NIFTy) applications. The FrEE strategy is to let the mathematical structure of the inference problem determine the dynamics of the numerical solver. FrEE uses the Gibbs free energy formalism for all involved unknown fields and correlation structures without marginalization of nuisance quantities. It thereby avoids the complexity marginalization often impose to IFT equations. FrEE simultaneously solves for the mean and the uncertainties of signal, nuisance, and auxiliary fields, while exploiting any analytically calculable quantity. Finally, FrEE uses a problem specific and self-tuning exploration strategy to swiftly identify the optimal field estimates as well as their uncertainty maps. For all estimated fields, properly weighted posterior samples drawn from their exact, fully non-Gaussian distributions can be generated. Here, we develop the FrEE strategies for the CSI of a normal, a log-normal, and a Poisson log-normal IFT signal inference problem and demonstrate their performances via their NIFTy implementations. version:1
arxiv-1612-08392 | Multi-Region Neural Representation: A novel model for decoding visual stimuli in human brains | http://arxiv.org/abs/1612.08392 | id:1612.08392 author:Muhammad Yousefnezhad, Daoqiang Zhang category:stat.ML cs.LG q-bio.NC  published:2016-12-26 summary:Multivariate Pattern (MVP) classification holds enormous potential for decoding visual stimuli in the human brain by employing task-based fMRI data sets. There is a wide range of challenges in the MVP techniques, i.e. decreasing noise and sparsity, defining effective regions of interest (ROIs), visualizing results, and the cost of brain studies. In overcoming these challenges, this paper proposes a novel model of neural representation, which can automatically detect the active regions for each visual stimulus and then utilize these anatomical regions for visualizing and analyzing the functional activities. Therefore, this model provides an opportunity for neuroscientists to ask this question: what is the effect of a stimulus on each of the detected regions instead of just study the fluctuation of voxels in the manually selected ROIs. Moreover, our method introduces analyzing snapshots of brain image for decreasing sparsity rather than using the whole of fMRI time series. Further, a new Gaussian smoothing method is proposed for removing noise of voxels in the level of ROIs. The proposed method enables us to combine different fMRI data sets for reducing the cost of brain studies. Experimental studies on 4 visual categories (words, consonants, objects and nonsense photos) confirm that the proposed method achieves superior performance to state-of-the-art methods. version:1
arxiv-1612-08388 | Clustering Algorithms: A Comparative Approach | http://arxiv.org/abs/1612.08388 | id:1612.08388 author:Mayra Z. Rodriguez, Cesar H. Comin, Dalcimar Casanova, Odemir M. Bruno, Diego R. Amancio, Francisco A. Rodrigues, Luciano da F. Costa category:cs.LG stat.ML  published:2016-12-26 summary:Many real-world systems can be studied in terms of pattern recognition tasks, so that proper use (and understanding) of machine learning methods in practical applications becomes essential. While a myriad of classification methods have been proposed, there is no consensus on which methods are more suitable for a given dataset. As a consequence, it is important to comprehensively compare methods in many possible scenarios. In this context, we performed a systematic comparison of 7 well-known clustering methods available in the R language. In order to account for the many possible variations of data, we considered artificial datasets with several tunable properties (number of classes, separation between classes, etc). In addition, we also evaluated the sensitivity of the clustering methods with regard to their parameters configuration. The results revealed that, when considering the default configurations of the adopted methods, the spectral approach usually outperformed the other clustering algorithms. We also found that the default configuration of the adopted implementations was not accurate. In these cases, a simple approach based on random selection of parameters values proved to be a good alternative to improve the performance. All in all, the reported approach provides subsidies guiding the choice of clustering algorithms. version:1
arxiv-1612-06699 | Unsupervised Perceptual Rewards for Imitation Learning | http://arxiv.org/abs/1612.06699 | id:1612.06699 author:Pierre Sermanet, Kelvin Xu, Sergey Levine category:cs.CV cs.RO  published:2016-12-20 summary:Reward function design and exploration time are arguably the biggest obstacles to the deployment of reinforcement learning (RL) agents in the real world. In many real-world tasks, designing a suitable reward function takes considerable manual engineering and often requires additional and potentially visible sensors to be installed just to measure whether the task has been executed successfully. Furthermore, many interesting tasks consist of multiple steps that must be executed in sequence. Even when the final outcome can be measured, it does not necessarily provide useful feedback on these implicit intermediate steps or sub-goals. To address these issues, we propose leveraging the abstraction power of intermediate visual representations learned by deep models to quickly infer perceptual reward functions from small numbers of demonstrations. We present a method that is able to identify the key intermediate steps of a task from only a handful of demonstration sequences, and automatically identify the most discriminative features for identifying these steps. This method makes use of the features in a pre-trained deep model, but does not require any explicit sub-goal supervision. The resulting reward functions can then be used by an RL agent to learn to perform the task in real-world settings. To evaluate the learned reward functions, we present qualitative results on two real-world tasks and a quantitative evaluation against a human-designed reward function. We also demonstrate that our method can be used to learn a complex real-world door opening skill using a real robot, even when the demonstration used for reward learning is provided by a human using their own hand. To our knowledge, these are the first results showing that complex robotic manipulation skills can be learned directly and without supervised labels from a video of a human performing the task. version:2
arxiv-1612-08375 | Abstractive Headline Generation for Spoken Content by Attentive Recurrent Neural Networks with ASR Error Modeling | http://arxiv.org/abs/1612.08375 | id:1612.08375 author:Lang-Chi Yu, Hung-yi Lee, Lin-shan Lee category:cs.CL  published:2016-12-26 summary:Headline generation for spoken content is important since spoken content is difficult to be shown on the screen and browsed by the user. It is a special type of abstractive summarization, for which the summaries are generated word by word from scratch without using any part of the original content. Many deep learning approaches for headline generation from text document have been proposed recently, all requiring huge quantities of training data, which is difficult for spoken document summarization. In this paper, we propose an ASR error modeling approach to learn the underlying structure of ASR error patterns and incorporate this model in an Attentive Recurrent Neural Network (ARNN) architecture. In this way, the model for abstractive headline generation for spoken content can be learned from abundant text data and the ASR data for some recognizers. Experiments showed very encouraging results and verified that the proposed ASR error model works well even when the input spoken content is recognized by a recognizer very different from the one the model learned from. version:1
arxiv-1612-06676 | Multivariate Industrial Time Series with Cyber-Attack Simulation: Fault Detection Using an LSTM-based Predictive Data Model | http://arxiv.org/abs/1612.06676 | id:1612.06676 author:Pavel Filonov, Andrey Lavrentyev, Artem Vorontsov category:cs.LG stat.ML  published:2016-12-20 summary:We adopted an approach based on an LSTM neural network to monitor and detect faults in industrial multivariate time series data. To validate the approach we created a Modelica model of part of a real gasoil plant. By introducing hacks into the logic of the Modelica model, we were able to generate both the roots and causes of fault behavior in the plant. Having a self-consistent data set with labeled faults, we used an LSTM architecture with a forecasting error threshold to obtain precision and recall quality metrics. The dependency of the quality metric on the threshold level is considered. An appropriate mechanism such as "one handle" was introduced for filtering faults that are outside of the plant operator field of interest. version:2
arxiv-1612-08359 | Extracting Sub-Exposure Images from a Single Capture Through Fourier-based Optical Modulation | http://arxiv.org/abs/1612.08359 | id:1612.08359 author:Shah Rez Khan, Martin Feldman, Bahadir K. Gunturk category:cs.CV  published:2016-12-26 summary:Through pixel-wise optical coding of images during exposure time, it is possible to extract sub-exposure images from a single capture. Such a capability can be used for different purposes, including high-speed imaging, high-dynamic-range imaging and compressed sensing. In this paper, we demonstrate a sub-exposure image extraction method, where the exposure coding pattern is inspired from frequency division multiplexing idea of communication systems. The coding masks modulate sub-exposure images in such a way that they are placed in non-overlapping regions in Fourier domain. The sub-exposure image extraction process involves digital filtering of the captured signal with proper band-pass filters. The prototype imaging system incorporates a Liquid Crystal over Silicon (LCoS) based spatial light modulator synchronized with a camera for pixel-wise exposure coding. version:1
arxiv-1612-08354 | Image-Text Multi-Modal Representation Learning by Adversarial Backpropagation | http://arxiv.org/abs/1612.08354 | id:1612.08354 author:Gwangbeen Park, Woobin Im category:cs.CV cs.CL cs.LG  published:2016-12-26 summary:We present novel method for image-text multi-modal representation learning. In our knowledge, this work is the first approach of applying adversarial learning concept to multi-modal learning and not exploiting image-text pair information to learn multi-modal feature. We only use category information in contrast with most previous methods using image-text pair information for multi-modal embedding. In this paper, we show that multi-modal feature can be achieved without image-text pair information and our method makes more similar distribution with image and text in multi-modal feature space than other methods which use image-text pair information. And we show our multi-modal feature has universal semantic information, even though it was trained for category prediction. Our model is end-to-end backpropagation, intuitive and easily extended to other multi-modal learning work. version:1
arxiv-1612-08333 | Text Summarization using Deep Learning and Ridge Regression | http://arxiv.org/abs/1612.08333 | id:1612.08333 author:Karthik Bangalore Mani category:cs.CL  published:2016-12-26 summary:We develop models and extract relevant features for automatic text summarization and investigate the performance of different models on the DUC 2001 dataset. Two different models were developed, one being a ridge regressor and the other one was a multi-layer perceptron. The hyperparameters were varied and their performance were noted. We segregated the summarization task into 2 main steps, the first being sentence ranking and the second step being sentence selection. In the first step, given a document, we sort the sentences based on their Importance, and in the second step, in order to obtain non-redundant sentences, we weed out the sentences that are have high similarity with the previously selected sentences. version:1
arxiv-1612-06027 | Neural Multi-Source Morphological Reinflection | http://arxiv.org/abs/1612.06027 | id:1612.06027 author:Katharina Kann, Ryan Cotterell, Hinrich Schütze category:cs.CL  published:2016-12-19 summary:We explore the task of multi-source morphological reinflection, which generalizes the standard, single-source version. The input consists of (i) a target tag and (ii) multiple pairs of source form and source tag for a lemma. The motivation is that it is beneficial to have access to more than one source form since different source forms can provide complementary information, e.g., different stems. We further present a novel extension to the encoder- decoder recurrent neural architecture, consisting of multiple encoders, to better solve the task. We show that our new architecture outperforms single-source reinflection models and publish our dataset for multi-source morphological reinflection to facilitate future research. version:2
arxiv-1612-08321 | Generalized Optimal Matching Methods for Causal Inference | http://arxiv.org/abs/1612.08321 | id:1612.08321 author:Nathan Kallus category:stat.ML math.OC math.ST stat.ME stat.TH  published:2016-12-26 summary:We develop an encompassing framework and theory for matching and related methods for causal inference that reveal the connections and motivations behind various existing methods and give rise to new and improved ones. The framework is given by generalizing a new functional analytical characterization of optimal matching as minimizing worst-case conditional mean squared error given the observed data based on specific restrictions and assumptions. By generalizing these, we obtain a new class of generalized optimal matching (GOM) methods, for which we provide a single theory for tractability and consistency that applies generally to GOM. Many commonly used existing methods are included in GOM and using their GOM interpretation we extend these to new methods that judiciously and automatically trade off balance for variance and outperform their standard counterparts. As a subclass of GOM, we develop kernel optimal matching, which, as supported by new theory, is notable for combining the interpretability of matching methods, the non-parametric model-free consistency of optimal matching, the efficiency of well-specified regression, the judicious sample size selection of monotonic imbalance bounding methods, the double robustness of augmented inverse propensity weight estimators, and the model-selection flexibility of Gaussian-process regression. We discuss connections to and non-linear generalizations of equal percent bias reduction and its ramifications. version:1
arxiv-1612-06457 | High Performance Software in Multidimensional Reduction Methods for Image Processing with Application to Ancient Manuscripts | http://arxiv.org/abs/1612.06457 | id:1612.06457 author:Corneliu T. C. Arsene, Peter E. Pormann, Naima Afif, Stephen Church, Mark Dickinson category:cs.CV  published:2016-12-19 summary:Multispectral imaging is an important technique for improving the readability of written or printed text where the letters have faded, either due to deliberate erasing or simply due to the ravages of time. Often the text can be read simply by looking at individual wavelengths, but in some cases the images need further enhancement to maximise the chances of reading the text. There are many possible enhancement techniques and this paper assesses and compares an extended set of dimensionality reduction methods for image processing. We assess 15 dimensionality reduction methods in two different manuscripts. This assessment was performed both subjectively by asking the opinions of scholars who were experts in the languages used in the manuscripts which of the techniques they preferred and also by using the Davies-Bouldin and Dunn indexes for assessing the quality of the resulted image clusters. We found that the Canonical Variates Analysis (CVA) method which was using a Matlab implementation and we have used previously to enhance multispectral images, it was indeed superior to all the other tested methods. However it is very likely that other approaches will be more suitable in specific circumstance so we would still recommend that a range of these techniques are tried. In particular, CVA is a supervised clustering technique so it requires considerably more user time and effort than a non-supervised technique such as the much more commonly used Principle Component Analysis Approach (PCA). If the results from PCA are adequate to allow a text to be read then the added effort required for CVA may not be justified. For the purposes of comparing the computational times and the image results, a CVA method is also implemented in C programming language and using the GNU (GNUs Not Unix) Scientific Library (GSL) and the OpenCV (OPEN source Computer Vision) computer vision programming library. version:2
arxiv-1612-08274 | Globally Optimal Object Tracking with Fully Convolutional Networks | http://arxiv.org/abs/1612.08274 | id:1612.08274 author:Jinho Lee, Brian Kenji Iwana, Shouta Ide, Seiichi Uchida category:cs.CV  published:2016-12-25 summary:Tracking is one of the most important but still difficult tasks in computer vision and pattern recognition. The main difficulties in the tracking field are appearance variation and occlusion. Most traditional tracking methods set the parameters or templates to track target objects in advance and should be modified accordingly. Thus, we propose a new and robust tracking method using a Fully Convolutional Network (FCN) to obtain an object probability map and Dynamic Programming (DP) to seek the globally optimal path through all frames of video. Our proposed method solves the object appearance variation problem with the use of a FCN and deals with occlusion by DP. We show that our method is effective in tracking various single objects through video frames. version:1
arxiv-1612-05695 | Reinforcement Learning Using Quantum Boltzmann Machines | http://arxiv.org/abs/1612.05695 | id:1612.05695 author:Daniel Crawford, Anna Levit, Navid Ghadermarzy, Jaspreet S. Oberoi, Pooya Ronagh category:quant-ph cs.AI cs.LG cs.NE math.OC  published:2016-12-17 summary:We investigate whether quantum annealers with select chip layouts can outperform classical computers in reinforcement learning tasks. We associate a transverse field Ising spin Hamiltonian with a layout of qubits similar to that of a deep Boltzmann machine (DBM) and use simulated quantum annealing (SQA) to numerically simulate quantum sampling from this system. We design a reinforcement learning algorithm in which the set of visible nodes representing the states and actions of an optimal policy are the first and last layers of the deep network. In absence of a transverse field, our simulations show that DBMs train more effectively than restricted Boltzmann machines (RBM) with the same number of weights. Since sampling from Boltzmann distributions of a DBM is not classically feasible, this is evidence of advantage of a non-Turing sampling oracle. We then develop a framework for training the network as a quantum Boltzmann machine (QBM) in the presence of a significant transverse field for reinforcement learning. This further improves the reinforcement learning method using DBMs. version:2
arxiv-1612-08242 | YOLO9000: Better, Faster, Stronger | http://arxiv.org/abs/1612.08242 | id:1612.08242 author:Joseph Redmon, Ali Farhadi category:cs.CV  published:2016-12-25 summary:We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time. version:1
arxiv-1612-08230 | Pancreas Segmentation in Abdominal CT Scan: A Coarse-to-Fine Approach | http://arxiv.org/abs/1612.08230 | id:1612.08230 author:Yuyin Zhou, Lingxi Xie, Wei Shen, Elliot Fishman, Alan Yuille category:cs.CV  published:2016-12-25 summary:Deep neural networks have been widely adopted for automatic organ segmentation from CT-scanned images. However, the segmentation accuracy on some small organs (e.g., the pancreas) is sometimes below satisfaction, arguably because deep networks are easily distracted by the complex and variable background region which occupies a large fraction of the input volume. In this paper, we propose a coarse-to-fine approach to deal with this problem. We train two deep neural networks using different regions of the input volume. The first one, the coarse-scaled model, takes the entire volume as its input. It is used for roughly locating the spatial position of the pancreas. The second one, the fine-scaled model, only sees a small input region covering the pancreas, thus eliminating the background noise and providing more accurate segmentation especially around the boundary areas. At the testing stage, we first use the coarse-scaled model to roughly locate the pancreas, then adopt the fine-scaled model to refine the initial segmentation in an iterative manner to obtain increasingly better segmentation. We evaluate our algorithm on the NIH pancreas segmentation dataset with 82 volumes, and outperform the state-of-the-art [18] by more than 4% measured by the Dice-Sorensen Coefficient (DSC). In addition, we report 62.43% DSC for our worst case, significantly better than 34.11% reported in [18]. version:1
arxiv-1612-08205 | Predicting the Industry of Users on Social Media | http://arxiv.org/abs/1612.08205 | id:1612.08205 author:Konstantinos Pappas, Rada Mihalcea category:cs.CL cs.SI  published:2016-12-24 summary:Automatic profiling of social media users is an important task for supporting a multitude of downstream applications. While a number of studies have used social media content to extract and study collective social attributes, there is a lack of substantial research that addresses the detection of a user's industry. We frame this task as classification using both feature engineering and ensemble learning. Our industry-detection system uses both posted content and profile information to detect a user's industry with 64.3% accuracy, significantly outperforming the majority baseline in a taxonomy of fourteen industry classes. Our qualitative analysis suggests that a person's industry not only affects the words used and their perceived meanings, but also the number and type of emotions being expressed. version:1
arxiv-1612-08178 | JU_KS_Group@FIRE 2016: Consumer Health Information Search | http://arxiv.org/abs/1612.08178 | id:1612.08178 author:Kamal Sarkar, Debanjan Das, Indra Banerjee, Mamta Kumari, Prasenjit Biswas category:cs.IR cs.CL  published:2016-12-24 summary:In this paper, we describe the methodology used and the results obtained by us for completing the tasks given under the shared task on Consumer Health Information Search (CHIS) collocated with the Forum for Information Retrieval Evaluation (FIRE) 2016, ISI Kolkata. The shared task consists of two sub-tasks - (1) task1: given a query and a document/set of documents associated with that query, the task is to classify the sentences in the document as relevant to the query or not and (2) task 2: the relevant sentences need to be further classified as supporting the claim made in the query, or opposing the claim made in the query. We have participated in both the sub-tasks. The percentage accuracy obtained by our developed system for task1 was 73.39 which is third highest among the 9 teams participated in the shared task. version:1
arxiv-1612-08171 | KS_JU@DPIL-FIRE2016:Detecting Paraphrases in Indian Languages Using Multinomial Logistic Regression Model | http://arxiv.org/abs/1612.08171 | id:1612.08171 author:Kamal Sarkar category:cs.CL  published:2016-12-24 summary:In this work, we describe a system that detects paraphrases in Indian Languages as part of our participation in the shared Task on detecting paraphrases in Indian Languages (DPIL) organized by Forum for Information Retrieval Evaluation (FIRE) in 2016. Our paraphrase detection method uses a multinomial logistic regression model trained with a variety of features which are basically lexical and semantic level similarities between two sentences in a pair. The performance of the system has been evaluated against the test set released for the FIRE 2016 shared task on DPIL. Our system achieves the highest f-measure of 0.95 on task1 in Punjabi language.The performance of our system on task1 in Hindi language is f-measure of 0.90. Out of 11 teams participated in the shared task, only four teams participated in all four languages, Hindi, Punjabi, Malayalam and Tamil, but the remaining 7 teams participated in one of the four languages. We also participated in task1 and task2 both for all four Indian Languages. The overall average performance of our system including task1 and task2 overall four languages is F1-score of 0.81 which is the second highest score among the four systems that participated in all four languages. version:1
arxiv-1612-08170 | Joint denoising and distortion correction of atomic scale scanning transmission electron microscopy images | http://arxiv.org/abs/1612.08170 | id:1612.08170 author:Benjamin Berkels, Benedikt Wirth category:cs.CV physics.data-an  published:2016-12-24 summary:Nowadays, modern electron microscopes deliver images at atomic scale. The precise atomic structure encodes information about material properties. Thus, an important ingredient in the image analysis is to locate the centers of the atoms shown in micrographs as precisely as possible. Here, we consider scanning transmission electron microscopy (STEM), which acquires data in a rastering pattern, pixel by pixel. Due to this rastering combined with the magnification to atomic scale, movements of the specimen even at the nanometer scale lead to random image distortions that make precise atom localization difficult. Given a series of STEM images, we derive a Bayesian method that jointly estimates the distortion in each image and reconstructs the underlying atomic grid of the material by fitting the atom bumps with suitable bump functions. The resulting highly non-convex minimization problems are solved numerically with a trust region approach. Well-posedness of the reconstruction method and the model behavior for faster and faster rastering are investigated using variational techniques. The performance of the method is finally evaluated on both synthetic and real experimental data. version:1
arxiv-1612-08169 | Unsupervised Video Segmentation via Spatio-Temporally Nonlocal Appearance Learning | http://arxiv.org/abs/1612.08169 | id:1612.08169 author:Kaihua Zhang, Xuejun Li, Qingshan Liu category:cs.CV  published:2016-12-24 summary:Video object segmentation is challenging due to the factors like rapidly fast motion, cluttered backgrounds, arbitrary object appearance variation and shape deformation. Most existing methods only explore appearance information between two consecutive frames, which do not make full use of the usefully long-term nonlocal information that is helpful to make the learned appearance stable, and hence they tend to fail when the targets suffer from large viewpoint changes and significant non-rigid deformations. In this paper, we propose a simple yet effective approach to mine the long-term sptatio-temporally nonlocal appearance information for unsupervised video segmentation. The motivation of our algorithm comes from the spatio-temporal nonlocality of the region appearance reoccurrence in a video. Specifically, we first generate a set of superpixels to represent the foreground and background, and then update the appearance of each superpixel with its long-term sptatio-temporally nonlocal counterparts generated by the approximate nearest neighbor search method with the efficient KD-tree algorithm. Then, with the updated appearances, we formulate a spatio-temporal graphical model comprised of the superpixel label consistency potentials. Finally, we generate the segmentation by optimizing the graphical model via iteratively updating the appearance model and estimating the labels. Extensive evaluations on the SegTrack and Youtube-Objects datasets demonstrate the effectiveness of the proposed method, which performs favorably against some state-of-art methods. version:1
arxiv-1612-08153 | EgoReID: Cross-view Self-Identification and Human Re-identification in Egocentric and Surveillance Videos | http://arxiv.org/abs/1612.08153 | id:1612.08153 author:Shervin Ardeshir, Sandesh Sharma, Ali Broji category:cs.CV cs.CG  published:2016-12-24 summary:Human identification remains to be one of the challenging tasks in computer vision community due to drastic changes in visual features across different viewpoints, lighting conditions, occlusion, etc. Most of the literature has been focused on exploring human re-identification across viewpoints that are not too drastically different in nature. Cameras usually capture oblique or side views of humans, leaving room for a lot of geometric and visual reasoning. Given the recent popularity of egocentric and top-view vision, re-identification across these two drastically different views can now be explored. Having an egocentric and a top view video, our goal is to identify the cameraman in the content of the top-view video, and also re-identify the people visible in the egocentric video, by matching them to the identities present in the top-view video. We propose a CRF-based method to address the two problems. Our experimental results demonstrates the efficiency of the proposed approach over a variety of video recorded from two views. version:1
arxiv-1507-08726 | Robustness in sparse linear models: relative efficiency based on robust approximate message passing | http://arxiv.org/abs/1507.08726 | id:1507.08726 author:Jelena Bradic category:math.ST stat.ME stat.ML stat.TH  published:2015-07-31 summary:Understanding efficiency in high dimensional linear models is a longstanding problem of interest. Classical work with smaller dimensional problems dating back to Huber and Bickel has illustrated the benefits of efficient loss functions. When the number of parameters $p$ is of the same order as the sample size $n$, $p \approx n$, an efficiency pattern different from the one of Huber was recently established. In this work, we consider the effects of model selection on the estimation efficiency of penalized methods. In particular, we explore whether sparsity, results in new efficiency patterns when $p > n$. In the interest of deriving the asymptotic mean squared error for regularized M-estimators, we use the powerful framework of approximate message passing. We propose a novel, robust and sparse approximate message passing algorithm (RAMP), that is adaptive to the error distribution. Our algorithm includes many non-quadratic and non-differentiable loss functions. We derive its asymptotic mean squared error and show its convergence, while allowing $p, n, s \to \infty$, with $n/p \in (0,1)$ and $n/s \in (1,\infty)$. We identify new patterns of relative efficiency regarding a number of penalized $M$ estimators, when $p$ is much larger than $n$. We show that the classical information bound is no longer reachable, even for light--tailed error distributions. We show that the penalized least absolute deviation estimator dominates the penalized least square estimator, in cases of heavy--tailed distributions. We observe this pattern for all choices of the number of non-zero parameters $s$, both $s \leq n$ and $s \approx n$. In non-penalized problems where $s =p \approx n$, the opposite regime holds. Therefore, we discover that the presence of model selection significantly changes the efficiency patterns. version:2
arxiv-1612-08117 | Improving Human-Machine Cooperative Visual Search With Soft Highlighting | http://arxiv.org/abs/1612.08117 | id:1612.08117 author:Ronald T. Kneusel, Michael C. Mozer category:cs.HC cs.NE  published:2016-12-24 summary:Advances in machine learning have produced systems that attain human-level performance on certain visual tasks, e.g., object identification. Nonetheless, other tasks requiring visual expertise are unlikely to be entrusted to machines for some time, e.g., satellite and medical imagery analysis. We describe a human-machine cooperative approach to visual search, the aim of which is to outperform either human or machine acting alone. The traditional route to augmenting human performance with automatic classifiers is to draw boxes around regions of an image deemed likely to contain a target. Human experts typically reject this type of hard highlighting. We propose instead a soft highlighting technique in which the saliency of regions of the visual field is modulated in a graded fashion based on classifier confidence level. We report on experiments with both synthetic and natural images showing that soft highlighting achieves a performance synergy surpassing that attained by hard highlighting. version:1
arxiv-1612-08116 | Tensors and algebra give interpretable groups for crosstalk mechanisms in breast cancer | http://arxiv.org/abs/1612.08116 | id:1612.08116 author:Anna Seigal, Mariano Beguerisse-Díaz, Birgit Schoeberl, Mario Niepel, Heather A. Harrington category:q-bio.QM math.OC physics.soc-ph q-bio.MN stat.ML  published:2016-12-24 summary:We introduce a tensor-based algebraic clustering method to extract sparse, low-dimensional structure from multidimensional arrays of experimental data. Our methodology is applicable to high dimensional data structures that arise across the sciences. Specifically we introduce a new way to cluster data subject to multi-indexed structural constraints via integer programming. The method can work as a stand-alone clustering tool or in combination with established methods. We implement this approach on a dataset consisting of genetically diverse breast cancer cell lines exposed to a range of signaling molecules, where each experiment is labelled by its combination of cell line and ligand. The data consist of time-course measurements of the immediate-early signaling of mitogen activated protein kinase (MAPK), and phosphoinositide 3-kinase (PI3K)/Protein kinase B (AKT). By respecting the multi-indexed structure of the experimental data, the analysis can be optimized for biological interpretation and therapeutic understanding. We quantify the heterogeneity of breast cancer cell subtypes and systematically explore mechanistic models of MAP Kinase and PI3K (phosphoinositide 3-kinase)/AKT crosstalk based on the results of our method. version:1
arxiv-1612-08109 | Solving Combinatorial Optimization problems with Quantum inspired Evolutionary Algorithm Tuned using a Novel Heuristic Method | http://arxiv.org/abs/1612.08109 | id:1612.08109 author:Nija Mani, Gursaran, Ashish Mani category:cs.AI cs.NE  published:2016-12-23 summary:Quantum inspired Evolutionary Algorithms were proposed more than a decade ago and have been employed for solving a wide range of difficult search and optimization problems. A number of changes have been proposed to improve performance of canonical QEA. However, canonical QEA is one of the few evolutionary algorithms, which uses a search operator with relatively large number of parameters. It is well known that performance of evolutionary algorithms is dependent on specific value of parameters for a given problem. The advantage of having large number of parameters in an operator is that the search process can be made more powerful even with a single operator without requiring a combination of other operators for exploration and exploitation. However, the tuning of operators with large number of parameters is complex and computationally expensive. This paper proposes a novel heuristic method for tuning parameters of canonical QEA. The tuned QEA outperforms canonical QEA on a class of discrete combinatorial optimization problems which, validates the design of the proposed parameter tuning framework. The proposed framework can be used for tuning other algorithms with both large and small number of tunable parameters. version:1
arxiv-1612-08102 | On Spectral Analysis of Directed Signed Graphs | http://arxiv.org/abs/1612.08102 | id:1612.08102 author:Yuemeng Li, Xintao Wu, Aidong Lu category:cs.SI cs.LG physics.soc-ph  published:2016-12-23 summary:It has been shown that the adjacency eigenspace of a network contains key information of its underlying structure. However, there has been no study on spectral analysis of the adjacency matrices of directed signed graphs. In this paper, we derive theoretical approximations of spectral projections from such directed signed networks using matrix perturbation theory. We use the derived theoretical results to study the influences of negative intra cluster and inter cluster directed edges on node spectral projections. We then develop a spectral clustering based graph partition algorithm, SC-DSG, and conduct evaluations on both synthetic and real datasets. Both theoretical analysis and empirical evaluation demonstrate the effectiveness of the proposed algorithm. version:1
arxiv-1612-08083 | Language Modeling with Gated Convolutional Networks | http://arxiv.org/abs/1612.08083 | id:1612.08083 author:Yann N. Dauphin, Angela Fan, Michael Auli, David Grangier category:cs.CL  published:2016-12-23 summary:The pre-dominant approach to language modeling to date is based on recurrent neural networks. In this paper we present a convolutional approach to language modeling. We introduce a novel gating mechanism that eases gradient propagation and which performs better than the LSTM-style gating of (Oord et al, 2016) despite being simpler. We achieve a new state of the art on WikiText-103 as well as a new best single-GPU result on the Google Billion Word benchmark. In settings where latency is important, our model achieves an order of magnitude speed-up compared to a recurrent baseline since computation can be parallelized over time. To our knowledge, this is the first time a non-recurrent approach outperforms strong recurrent models on these tasks. version:1
arxiv-1612-08082 | Constructing Effective Personalized Policies Using Counterfactual Inference from Biased Data Sets with Many Features | http://arxiv.org/abs/1612.08082 | id:1612.08082 author:Onur Atan, William R. Zame, Qiaojun Feng, Mihaela van der Schaar category:stat.ML cs.LG  published:2016-12-23 summary:This paper proposes a novel approach for constructing effective personalized policies when the observed data lacks counter-factual information, is biased and possesses many features. The approach is applicable in a wide variety of settings from healthcare to advertising to education to finance. These settings have in common that the decision maker can observe, for each previous instance, an array of features of the instance, the action taken in that instance, and the reward realized -- but not the rewards of actions that were not taken: the counterfactual information. Learning in such settings is made even more difficult because the observed data is typically biased by the existing policy (that generated the data) and because the array of features that might affect the reward in a particular instance -- and hence should be taken into account in deciding on an action in each particular instance -- is often vast. The approach presented here estimates propensity scores for the observed data, infers counterfactuals, identifies a (relatively small) number of features that are (most) relevant for each possible action and instance, and prescribes a policy to be followed. Comparison of the proposed algorithm against the state-of-art algorithm on actual datasets demonstrates that the proposed algorithm achieves a significant improvement in performance. version:1
arxiv-1612-08049 | Correlation Preserving Sparse Coding Over Multi-level Dictionaries for Image Denoising | http://arxiv.org/abs/1612.08049 | id:1612.08049 author:Rui Chen, Huizhu Jia, Xiaodong Xie, Wen Gao category:cs.CV  published:2016-12-23 summary:In this letter, we propose a novel image denoising method based on correlation preserving sparse coding. Because the instable and unreliable correlations among basis set can limit the performance of the dictionary-driven denoising methods, two effective regularized strategies are employed in the coding process. Specifically, a graph-based regularizer is built for preserving the global similarity correlations, which can adaptively capture both the geometrical structures and discriminative features of textured patches. In particular, edge weights in the graph are obtained by seeking a nonnegative low-rank construction. Besides, a robust locality-constrained coding can automatically preserve not only spatial neighborhood information but also internal consistency present in noisy patches while learning overcomplete dictionary. Experimental results demonstrate that our proposed method achieves state-of-the-art denoising performance in terms of both PSNR and subjective visual quality. version:1
arxiv-1612-08037 | Blind restoration for non-uniform aerial images using non-local Retinex model and shearlet-based higher-order regularization | http://arxiv.org/abs/1612.08037 | id:1612.08037 author:Rui Chen, Huizhu Jia, Xiaodong Xie, Wen Gao category:cs.CV  published:2016-12-23 summary:Aerial images are often degraded by space-varying motion blur and simultaneous uneven illumination. To recover high-quality aerial image from its non-uniform version, we propose a novel patch-wise restoration approach based on a key observation that the degree of blurring is inevitably affected by the illuminated conditions. A non-local Retinex model is developed to accurately estimate the reflectance component from the degraded aerial image. Thereafter the uneven illumination is corrected well. And then non-uniform coupled blurring in the enhanced reflectance image is alleviated and transformed towards uniform distribution, which will facilitate the subsequent deblurring. For constructing the multi-scale sparsified regularizer, the discrete shearlet transform is improved to better represent anisotropic image features in term of directional sensitivity and selectivity. In addition, a new adaptive variant of total generalized variation is proposed for the structure-preserving regularizer. These complementary regularizers are elegantly integrated into an objective function. The final deblurred image with uniform illumination can be extracted by applying the fast alternating direction scheme to solve the derived function. The experimental results demonstrate that our algorithm can not only remove both the space-varying illumination and motion blur in the aerial image effectively but also recover the abundant details of aerial scenes with top-level objective and subjective quality, and outperforms other state-of-the-art restoration methods. version:1
arxiv-1612-08036 | Focused Learning and Proofreading for Delineation of Curvilinear Structures | http://arxiv.org/abs/1612.08036 | id:1612.08036 author:Agata Mosinska, Carlos Becker, Pascal Fua category:cs.CV  published:2016-12-23 summary:Many state-of-the-art delineation methods rely on supervised machine learning algorithms. As a result, they require manually annotated training data, which is tedious to obtain. Furthermore, even minor classification errors may significantly affect the topology of the final result. In this paper we propose a unified approach to address both of these problems by taking into account the influence of a potential misclassification on the resulting delineation. In an Active Learning context, we find parts of linear structures that should be annotated first in order to train an effective classifier. In a proofreading context, we similarly find regions of the resulting reconstruction that should be verified in priority to obtain a nearly-perfect result. In both cases, by focusing the attention of the human expert on the potential classification mistakes, which are the most critical parts of the delineation, we reduce the amount of annotation effort. We demonstrate the effectiveness of our approach on a variety of datasets that comprise both biomedical and aerial imagery. version:1
arxiv-1612-08012 | Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: the LUNA16 challenge | http://arxiv.org/abs/1612.08012 | id:1612.08012 author:Arnaud Arindra Adiyoso Setio, Alberto Traverso, Thomas de Bel, Moira S. N. Berens, Cas van den Bogaard, Piergiorgio Cerello, Hao Chen, Qi Dou, Maria Evelina Fantacci, Bram Geurts, Robbert van der Gugten, Pheng Ann Heng, Bart Jansen, Michael M. J. de Kaste, Valentin Kotov, Jack Yu-Hung Lin, Jeroen T. M. C. Manders, Alexander Sónora-Mengana, Juan Carlos García-Naranjo, Mathias Prokop, Marco Saletta, Cornelia M Schaefer-Prokop, Ernst T. Scholten, Luuk Scholten, Miranda M. Snoeren, Ernesto Lopez Torres, Jef Vandemeulebroucke, Nicole Walasek, Guido C. A. Zuidhof, Bram van Ginneken, Colin Jacobs category:cs.CV  published:2016-12-23 summary:Automatic detection of pulmonary nodules in thoracic computed tomography (CT) scans has been an active area of research for the last two decades. However, there have only been few studies that provide a comparative performance evaluation of different systems on a common database. We have therefore set up the LUNA16 challenge, an objective evaluation framework for automatic nodule detection algorithms using the largest publicly available reference database of chest CT scans, the LIDC-IDRI data set. In LUNA16, participants develop their algorithm and upload their predictions on 888 CT scans in one of the two tracks: 1) the complete nodule detection track where a complete CAD system should be developed, or 2) the false positive reduction track where a provided set of nodule candidates should be classified. This paper describes the setup of LUNA16 and presents the results of the challenge so far. Moreover, the impact of combining individual systems on the detection performance was also investigated. It was observed that the leading solutions employed convolutional networks and used the provided set of nodule candidates. The combination of these solutions achieved an excellent sensitivity of over 95% at fewer than 1.0 false positives per scan. This highlights the potential of combining algorithms to improve the detection performance. Our observer study with four expert readers has shown that the best system detects nodules that were missed by expert readers who originally annotated the LIDC-IDRI data. We released this set of additional nodules for further development of CAD systems. version:1
arxiv-1612-07993 | RSSL: Semi-supervised Learning in R | http://arxiv.org/abs/1612.07993 | id:1612.07993 author:Jesse H. Krijthe category:stat.ML cs.LG  published:2016-12-23 summary:In this paper, we introduce a package for semi-supervised learning research in the R programming language called RSSL. We cover the purpose of the package, the methods it includes and comment on their use and implementation. We then show, using several code examples, how the package can be used to replicate well-known results from the semi-supervised learning literature. version:1
arxiv-1612-07978 | Two-stream convolutional neural network for accurate RGB-D fingertip detection using depth and edge information | http://arxiv.org/abs/1612.07978 | id:1612.07978 author:Hengkai Guo, Guijin Wang, Xinghao Chen category:cs.CV  published:2016-12-23 summary:Accurate detection of fingertips in depth image is critical for human-computer interaction. In this paper, we present a novel two-stream convolutional neural network (CNN) for RGB-D fingertip detection. Firstly edge image is extracted from raw depth image using random forest. Then the edge information is combined with depth information in our CNN structure. We study several fusion approaches and suggest a slow fusion strategy as a promising way of fingertip detection. As shown in our experiments, our real-time algorithm outperforms state-of-the-art fingertip detection methods on the public dataset HandNet with an average 3D error of 9.9mm, and shows comparable accuracy of fingertip estimation on NYU hand dataset. version:1
arxiv-1612-07528 | Cohort of LSTM and lexicon verification for handwriting recognition with gigantic lexicon | http://arxiv.org/abs/1612.07528 | id:1612.07528 author:Bruno Stuner, Clément Chatelain, Thierry Paquet category:cs.CV  published:2016-12-22 summary:Handwriting recognition state of the art methods are based on Long Short Term Memory (LSTM) recurrent neural networks (RNN) coupled with the use of linguistic knowledge. LSTM RNN presents high raw performance and interesting training properties that allow us to break with the standard method at the state of the art. We present a simple and efficient way to extract from a single training a large number of complementary LSTM RNN, called cohort, combined in a cascade architecture with a lexical verification. This process does not require fine tuning, making it easy to use. Our verification allow to deal quickly and efficiently with gigantic lexicon (over 3 million words). We achieve state of the art results for isolated word recognition with very large lexicon and present novel results for an unprecedented gigantic lexicon. version:2
arxiv-1612-07956 | A CRF Based POS Tagger for Code-mixed Indian Social Media Text | http://arxiv.org/abs/1612.07956 | id:1612.07956 author:Kamal Sarkar category:cs.CL  published:2016-12-23 summary:In this work, we describe a conditional random fields (CRF) based system for Part-Of- Speech (POS) tagging of code-mixed Indian social media text as part of our participation in the tool contest on POS tagging for codemixed Indian social media text, held in conjunction with the 2016 International Conference on Natural Language Processing, IIT(BHU), India. We participated only in constrained mode contest for all three language pairs, Bengali-English, Hindi-English and Telegu-English. Our system achieves the overall average F1 score of 79.99, which is the highest overall average F1 score among all 16 systems participated in constrained mode contest. version:1
arxiv-1612-06505 | Parallelized Tensor Train Learning of Polynomial Classifiers | http://arxiv.org/abs/1612.06505 | id:1612.06505 author:Zhongming Chen, Kim Batselier, Johan A. K. Suykens, Ngai Wong category:cs.LG cs.AI  published:2016-12-20 summary:In pattern classification, polynomial classifiers are well-studied methods as they are capable of generating complex decision surfaces. Unfortunately, the use of multivariate polynomials is limited to kernels as in support vector machines, because polynomials quickly become impractical for high-dimensional problems. In this paper, we effectively overcome the curse of dimensionality by employing the tensor train format to represent a polynomial classifier. Based on the structure of tensor trains, two learning algorithms are proposed which involve solving different optimization problems of low computational complexity. Furthermore, we show how both regularization to prevent overfitting and parallelization, which enables the use of large training sets, are incorporated into these methods. Both the efficiency and efficacy of our tensor-based polynomial classifier are then demonstrated on the two popular datasets USPS and MNIST. version:3
arxiv-1612-07940 | Supervised Opinion Aspect Extraction by Exploiting Past Extraction Results | http://arxiv.org/abs/1612.07940 | id:1612.07940 author:Lei Shu, Bing Liu, Hu Xu, Annice Kim category:cs.CL cs.LG  published:2016-12-23 summary:One of the key tasks of sentiment analysis of product reviews is to extract product aspects or features that users have expressed opinions on. In this work, we focus on using supervised sequence labeling as the base approach to performing the task. Although several extraction methods using sequence labeling methods such as Conditional Random Fields (CRF) and Hidden Markov Models (HMM) have been proposed, we show that this supervised approach can be significantly improved by exploiting the idea of concept sharing across multiple domains. For example, "screen" is an aspect in iPhone, but not only iPhone has a screen, many electronic devices have screens too. When "screen" appears in a review of a new domain (or product), it is likely to be an aspect too. Knowing this information enables us to do much better extraction in the new domain. This paper proposes a novel extraction method exploiting this idea in the context of supervised sequence labeling. Experimental results show that it produces markedly better results than without using the past information. version:1
arxiv-1612-07921 | Understanding Non-optical Remote-sensed Images: Needs, Challenges and Ways Forward | http://arxiv.org/abs/1612.07921 | id:1612.07921 author:Amit Kumar Mishra category:cs.CV  published:2016-12-23 summary:Non-optical remote-sensed images are going to be used more often in man- aging disaster, crime and precision agriculture. With more small satellites and unmanned air vehicles planning to carry radar and hyperspectral image sensors there is going to be an abundance of such data in the recent future. Understanding these data in real-time will be crucial in attaining some of the important sustain- able development goals. Processing non-optical images is, in many ways, different from that of optical images. Most of the recent advances in the domain of image understanding has been using optical images. In this article we shall explain the needs for image understanding in non-optical domain and the typical challenges. Then we shall describe the existing approaches and how we can move from there to the desired goal of a reliable real-time image understanding system. version:1
arxiv-1612-07919 | EnhanceNet: Single Image Super-Resolution through Automated Texture Synthesis | http://arxiv.org/abs/1612.07919 | id:1612.07919 author:Mehdi S. M. Sajjadi, Bernhard Schölkopf, Michael Hirsch category:cs.CV  published:2016-12-23 summary:Single image super-resolution is the task of inferring a high-resolution image from a single low-resolution input. Traditionally, the performance of algorithms for this task is measured using pixel-wise reconstruction measures such as peak signal-to-noise ratio (PSNR) which have been shown to correlate poorly with the human perception of image quality. As a result, algorithms minimizing these metrics tend to produce oversmoothed images that lack high-frequency textures and do not look natural despite yielding high PSNR values. We propose a novel combination of automated texture synthesis with a perceptual loss focusing on creating realistic textures rather than optimizing for a pixel-accurate reproduction of ground truth images during training. By using feed-forward fully convolutional neural networks in an adversarial training setting, we achieve a significant boost in image quality at high magnification ratios. Extensive experiments on a number of datasets show the effectiveness of our approach, yielding state-of-the-art results in both quantitative and qualitative benchmarks. version:1
arxiv-1612-07899 | DARN: a Deep Adversial Residual Network for Intrinsic Image Decomposition | http://arxiv.org/abs/1612.07899 | id:1612.07899 author:Louis Lettry, Kenneth Vanhoey, Luc Van Gool category:cs.CV  published:2016-12-23 summary:We present a new deep supervised learning method for intrinsic decomposition of a single image into its albedo and shading components. Our contributions are based on a new fully convolutional neural network that estimates absolute albedo and shading jointly. As opposed to classical intrinsic image decomposition work, it is fully data-driven, hence does not require any physical priors like shading smoothness or albedo sparsity, nor does it rely on geometric information such as depth. Compared to recent deep learning techniques, we simplify the architecture, making it easier to build and train. It relies on a single end-to-end deep sequence of residual blocks and a perceptually-motivated metric formed by two discriminator networks. We train and demonstrate our architecture on the publicly available MPI Sintel dataset and its intrinsic image decomposition augmentation. We additionally discuss and augment the set of quantitative metrics so as to account for the more challenging recovery of non scale-invariant quantities. Results show that our work outperforms the state of the art algorithms both on the qualitative and quantitative aspect, while training convergence time is reduced. version:1
arxiv-1612-07896 | A Base Camp for Scaling AI | http://arxiv.org/abs/1612.07896 | id:1612.07896 author:C. J. C. Burges, T. Hart, Z. Yang, S. Cucerzan, R. W. White, A. Pastusiak, J. Lewis category:cs.AI cs.LG  published:2016-12-23 summary:Modern statistical machine learning (SML) methods share a major limitation with the early approaches to AI: there is no scalable way to adapt them to new domains. Human learning solves this in part by leveraging a rich, shared, updateable world model. Such scalability requires modularity: updating part of the world model should not impact unrelated parts. We have argued that such modularity will require both "correctability" (so that errors can be corrected without introducing new errors) and "interpretability" (so that we can understand what components need correcting). To achieve this, one could attempt to adapt state of the art SML systems to be interpretable and correctable; or one could see how far the simplest possible interpretable, correctable learning methods can take us, and try to control the limitations of SML methods by applying them only where needed. Here we focus on the latter approach and we investigate two main ideas: "Teacher Assisted Learning", which leverages crowd sourcing to learn language; and "Factored Dialog Learning", which factors the process of application development into roles where the language competencies needed are isolated, enabling non-experts to quickly create new applications. We test these ideas in an "Automated Personal Assistant" (APA) setting, with two scenarios: that of detecting user intent from a user-APA dialog; and that of creating a class of event reminder applications, where a non-expert "teacher" can then create specific apps. For the intent detection task, we use a dataset of a thousand labeled utterances from user dialogs with Cortana, and we show that our approach matches state of the art SML methods, but in addition provides full transparency: the whole (editable) model can be summarized on one human-readable page. For the reminder app task, we ran small user studies to verify the efficacy of the approach. version:1
arxiv-1612-07866 | Spectral algorithms for tensor completion | http://arxiv.org/abs/1612.07866 | id:1612.07866 author:Andrea Montanari, Nike Sun category:cs.DS math.ST stat.ML stat.TH  published:2016-12-23 summary:In the tensor completion problem, one seeks to estimate a low-rank tensor based on a random sample of revealed entries. In terms of the required sample size, earlier work revealed a large gap between estimation with unbounded computational resources (using, for instance, tensor nuclear norm minimization) and polynomial-time algorithms. Among the latter, the best statistical guarantees have been proved, for third-order tensors, using the sixth level of the sum-of-squares (SOS) semidefinite programming hierarchy (Barak and Moitra, 2014). However, the SOS approach does not scale well to large problem instances. By contrast, spectral methods --- based on unfolding or matricizing the tensor --- are attractive for their low complexity, but have been believed to require a much larger sample size. This paper presents two main contributions. First, we propose a new unfolding-based method, which outperforms naive ones for symmetric $k$-th order tensors of rank $r$. For this result we make a study of singular space estimation for partially revealed matrices of large aspect ratio, which may be of independent interest. For third-order tensors, our algorithm matches the SOS method in terms of sample size (requiring about $rd^{3/2}$ revealed entries), subject to a worse rank condition ($r\ll d^{3/4}$ rather than $r\ll d^{3/2}$). We complement this result with a different spectral algorithm for third-order tensors in the overcomplete ($r\ge d$) regime. Under a random model, this second approach succeeds in estimating tensors of rank $d\le r \ll d^{3/2}$ from about $rd^{3/2}$ revealed entries. version:1
arxiv-1612-07857 | Human Action Attribute Learning From Video Data Using Low-Rank Representations | http://arxiv.org/abs/1612.07857 | id:1612.07857 author:Tong Wu, Prudhvi Gurram, Raghuveer M. Rao, Waheed U. Bajwa category:stat.ML cs.LG  published:2016-12-23 summary:Representation of human actions as a sequence of human body movements or action attributes enables the development of models for human activity recognition and summarization. We present an extension of the low-rank representation (LRR) model, termed the clustering-aware structure-constrained low-rank representation (CS-LRR) model, for unsupervised learning of human action attributes from video data. Our model is based on the union-of-subspaces (UoS) framework, and integrates spectral clustering into the LRR optimization problem for better subspace clustering results. We lay out an efficient linear alternating direction method to solve the CS-LRR optimization problem. We also introduce a hierarchical subspace clustering approach, termed hierarchical CS-LRR, to learn the attributes without the need for a priori specification of their number. By visualizing and labeling these action attributes, the hierarchical model can be used to semantically summarize long video sequences of human actions at multiple resolutions. A human action or activity can also be uniquely represented as a sequence of transitions from one action attribute to another, which can then be used for human action recognition. We demonstrate the effectiveness of the proposed model for semantic summarization and action recognition through comprehensive experiments on five real-world human action datasets. version:1
arxiv-1612-07850 | Automatic Interpretation of Unordered Point Cloud Data for UAV Navigation in Construction | http://arxiv.org/abs/1612.07850 | id:1612.07850 author:M. D. Phung, C. H. Quach, D. T. Chu, N. Q. Nguyen, T. H. Dinh, Q. P. Ha category:cs.RO cs.CV cs.SY  published:2016-12-23 summary:The objective of this work is to develop a data processing system that can automatically generate waypoints for navigation of an unmanned aerial vehicle (UAV) to inspect surfaces of structures like buildings and bridges. The input includes data recorded by two 2D laser scanners, orthogonally mounted on the UAV, and an inertial measurement unit (IMU). To achieve the goal, algorithms are developed to process the data collected. They are separated into three major groups: (i) the data registration and filtering to generate a 3D model of the structure and control the density of point clouds for data completeness enhancement; (ii) the surface and obstacle detection to assist the UAV in monitoring tasks; and (iii) the waypoint generation to set the flight path. Experiments on different data sets show that the developed system is able to reconstruct a 3D point cloud of the structure, extract its surfaces and objects, and generate waypoints for the UAV to accomplish inspection tasks. version:1
arxiv-1612-07846 | A State Space Approach for Piecewise-Linear Recurrent Neural Networks for Reconstructing Nonlinear Dynamics from Neural Measurements | http://arxiv.org/abs/1612.07846 | id:1612.07846 author:Daniel Durstewitz category:q-bio.NC cs.NE q-bio.QM stat.ML  published:2016-12-23 summary:The computational properties of neural systems are often thought to be implemented in terms of their network dynamics. Hence, recovering the system dynamics from experimentally observed neuronal time series, like multiple single-unit (MSU) recordings or neuroimaging data, is an important step toward understanding its computations. Ideally, one would not only seek a state space representation of the dynamics, but would wish to have access to its governing equations for in-depth analysis. Recurrent neural networks (RNNs) are a computationally powerful and dynamically universal formal framework which has been extensively studied from both the computational and the dynamical systems perspective. Here we develop a semi-analytical maximum-likelihood estimation scheme for piecewise-linear RNNs (PLRNNs) within the statistical framework of state space models, which accounts for noise in both the underlying latent dynamics and the observation process. The Expectation-Maximization algorithm is used to infer the latent state distribution, through a global Laplace approximation, and the PLRNN parameters iteratively. After validating the procedure on toy examples, the approach is applied to MSU recordings from the rodent anterior cingulate cortex obtained during performance of a classical working memory task, delayed alternation. A model with 5 states turned out to be sufficient to capture the essential computational dynamics underlying task performance, including stimulus-selective delay activity. The estimated models were rarely multi-stable, but rather were tuned to exhibit slow dynamics in the vicinity of a bifurcation point. In summary, the present work advances a semi-analytical (thus reasonably fast) maximum-likelihood estimation framework for PLRNNs that may enable to recover the relevant dynamics underlying observed neuronal time series, and directly link them to computational properties. version:1
arxiv-1612-07843 | "What is Relevant in a Text Document?": An Interpretable Machine Learning Approach | http://arxiv.org/abs/1612.07843 | id:1612.07843 author:Leila Arras, Franziska Horn, Grégoire Montavon, Klaus-Robert Müller, Wojciech Samek category:cs.CL cs.IR cs.LG stat.ML  published:2016-12-23 summary:Text documents can be described by a number of abstract concepts such as semantic category, writing style, or sentiment. Machine learning (ML) models have been trained to automatically map documents to these abstract concepts, allowing to annotate very large text collections, more than could be processed by a human in a lifetime. Besides predicting the text's category very accurately, it is also highly desirable to understand how and why the categorization process takes place. In this paper, we demonstrate that such understanding can be achieved by tracing the classification decision back to individual words using layer-wise relevance propagation (LRP), a recently developed technique for explaining predictions of complex non-linear classifiers. We train two word-based ML models, a convolutional neural network (CNN) and a bag-of-words SVM classifier, on a topic categorization task and adapt the LRP method to decompose the predictions of these models onto words. Resulting scores indicate how much individual words contribute to the overall classification decision. This enables one to distill relevant information from text documents without an explicit semantic information extraction step. We further use the word-wise relevance scores for generating novel vector-based document representations which capture semantic information. Based on these document vectors, we introduce a measure of model explanatory power and show that, although the SVM and CNN models perform similarly in terms of classification accuracy, the latter exhibits a higher level of explainability which makes it more comprehensible for humans and potentially more useful for other applications. version:1
arxiv-1612-07833 | Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task | http://arxiv.org/abs/1612.07833 | id:1612.07833 author:Nan Ding, Sebastian Goodman, Fei Sha, Radu Soricut category:cs.CL cs.CV  published:2016-12-22 summary:We introduce a new multi-modal task for computer systems, posed as a combined vision-language comprehension challenge: identifying the most suitable text describing a scene, given several similar options. Accomplishing the task entails demonstrating comprehension beyond just recognizing "keywords" (or key-phrases) and their corresponding visual concepts. Instead, it requires an alignment between the representations of the two modalities that achieves a visually-grounded "understanding" of various linguistic elements and their dependencies. This new task also admits an easy-to-compute and well-studied metric: the accuracy in detecting the true target among the decoys. The paper makes several contributions: an effective and extensible mechanism for generating decoys from (human-created) image captions; an instance of applying this mechanism, yielding a large-scale machine comprehension dataset (based on the COCO images and captions) that we make publicly available; human evaluation results on this dataset, informing a performance upper-bound; and several baseline and competitive learning approaches that illustrate the utility of the proposed task and dataset in advancing both image and language comprehension. We also show that, in a multi-task learning setting, the performance on the proposed task is positively correlated with the end-to-end task of image captioning. version:1
arxiv-1612-07828 | Learning from Simulated and Unsupervised Images through Adversarial Training | http://arxiv.org/abs/1612.07828 | id:1612.07828 author:Ashish Shrivastava, Tomas Pfister, Oncel Tuzel, Josh Susskind, Wenda Wang, Russ Webb category:cs.CV cs.LG cs.NE  published:2016-12-22 summary:With recent progress in graphics, it has become more tractable to train models on synthetic images, potentially avoiding the need for expensive annotations. However, learning from synthetic images may not achieve the desired performance due to a gap between synthetic and real image distributions. To reduce this gap, we propose Simulated+Unsupervised (S+U) learning, where the task is to learn a model to improve the realism of a simulator's output using unlabeled real data, while preserving the annotation information from the simulator. We develop a method for S+U learning that uses an adversarial network similar to Generative Adversarial Networks (GANs), but with synthetic images as inputs instead of random vectors. We make several key modifications to the standard GAN algorithm to preserve annotations, avoid artifacts and stabilize training: (i) a 'self-regularization' term, (ii) a local adversarial loss, and (iii) updating the discriminator using a history of refined images. We show that this enables generation of highly realistic images, which we demonstrate both qualitatively and with a user study. We quantitatively evaluate the generated images by training models for gaze estimation and hand pose estimation. We show a significant improvement over using synthetic images, and achieve state-of-the-art results on the MPIIGaze dataset without any labeled real data. version:1
arxiv-1612-07823 | Learning Auditable Features from Signals Using Unsupervised Temporal Projection | http://arxiv.org/abs/1612.07823 | id:1612.07823 author:Marcell V-Chanlatte, Jyotirmoy V. Deshmukh, Xiaoqing Jin, Sanjit Seshia category:cs.LG cs.LO  published:2016-12-22 summary:To effectively analyze and design cyberphysical systems (CPS), designers today have to combat the data deluge problem, i.e., the burden of processing intractably large amounts of data produced by complex models and experiments. In this work, we utilize monotonic Parametric Signal Temporal Logic (PSTL) to design features for unsupervised classification of time series data. This enables using off-the-shelf machine learning tools to automatically cluster similar traces with respect to a given PSTL formula. We demonstrate how this technique produces simple and interpetable formulas that are amenable to analysis and understanding using a few representative examples. We illustrate this with a number of case studies related to automotive engine testing, highway traffic analysis, and auto-grading massively open online courses. version:1
arxiv-1612-06856 | Temporal Feature Selection on Networked Time Series | http://arxiv.org/abs/1612.06856 | id:1612.06856 author:Haishuai Wang, Jia Wu, Peng Zhang, Chengqi Zhang category:cs.LG  published:2016-12-20 summary:This paper formulates the problem of learning discriminative features (\textit{i.e.,} segments) from networked time series data considering the linked information among time series. For example, social network users are considered to be social sensors that continuously generate social signals (tweets) represented as a time series. The discriminative segments are often referred to as \emph{shapelets} in a time series. Extracting shapelets for time series classification has been widely studied. However, existing works on shapelet selection assume that the time series are independent and identically distributed (i.i.d.). This assumption restricts their applications to social networked time series analysis, since a user's actions can be correlated to his/her social affiliations. In this paper we propose a new Network Regularized Least Squares (NetRLS) feature selection model that combines typical time series data and user network data for analysis. Experiments on real-world networked time series Twitter and DBLP data demonstrate the performance of the proposed method. NetRLS performs better than LTS, the state-of-the-art time series feature selection approach, on real-world data. version:2
arxiv-1612-07796 | Online Semantic Activity Forecasting with DARKO | http://arxiv.org/abs/1612.07796 | id:1612.07796 author:Nicholas Rhinehart, Kris M. Kitani category:cs.CV  published:2016-12-22 summary:We address the problem of continuously observing and forecasting long-term semantic activities of a first-person camera wearer: what the person will do, where they will go, and what goal they are seeking. In contrast to prior work in trajectory forecasting and short-term activity forecasting, our algorithm, DARKO, reasons about the future position, future semantic state, and future high-level goals of the camera-wearer at arbitrary spatial and temporal horizons defined only by the wearer's behaviors. DARKO learns and forecasts online from first-person observations of the user's daily behaviors. We derive novel mathematical results that enable efficient forecasting of different semantic quantities of interest. We apply our method to a dataset of 5 large-scale environments with 3 different environment types, collected from 3 different users, and experimentally validate DARKO on forecasting tasks. version:1
arxiv-1612-07771 | Highway and Residual Networks learn Unrolled Iterative Estimation | http://arxiv.org/abs/1612.07771 | id:1612.07771 author:Klaus Greff, Rupesh K. Srivastava, Jürgen Schmidhuber category:cs.NE cs.AI cs.LG I.2.6; I.5.1  published:2016-12-22 summary:The past year saw the introduction of new architectures such as Highway networks and Residual networks which, for the first time, enabled the training of feedforward networks with dozens to hundreds of layers using simple gradient descent. While depth of representation has been posited as a primary reason for their success, there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer. In this report, we argue that this view is incomplete and does not adequately explain several recent findings. We propose an alternative viewpoint based on unrolled iterative estimation---a group of successive layers iteratively refine their estimates of the same features instead of computing an entirely new representation. We demonstrate that this viewpoint directly leads to the construction of Highway and Residual networks. Finally we provide preliminary experiments to discuss the similarities and differences between the two architectures. version:1
arxiv-1612-07767 | Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics | http://arxiv.org/abs/1612.07767 | id:1612.07767 author:Xin Li, Fuxin Li category:cs.CV  published:2016-12-22 summary:Deep learning has greatly improved visual recognition in recent years. However, recent research has shown that there exist many adversarial examples that can negatively impact the performance of such an architecture. This paper focuses on detecting those adversarial examples by analyzing whether they come from the same distribution as the normal examples. Instead of directly training a deep neural network to detect adversarials, a much simpler approach is proposed based on statistics on outputs from convolutional layers. A cascade classifier is designed to efficiently detect adversarials. Furthermore, trained from one particular adversarial generating mechanism, the resulting classifier can successfully detect adversarials from a completely different mechanism as well. After detecting adversarial examples, we show that many of them can be recovered by simply performing a small average filter on the image. Those findings should provoke us to think more about the classification mechanisms in deep convolutional neural networks. version:1
arxiv-1612-07728 | Statistical limits of spiked tensor models | http://arxiv.org/abs/1612.07728 | id:1612.07728 author:Amelia Perry, Alexander S. Wein, Afonso S. Bandeira category:math.PR cs.IT math.IT math.ST stat.ML stat.TH  published:2016-12-22 summary:We study the statistical limits of both detecting and estimating a rank-one deformation of a symmetric random Gaussian tensor. We establish upper and lower bounds on the critical signal-to-noise ratio, under a variety of priors for the planted vector: (i) a uniformly sampled unit vector, (ii) i.i.d. $\pm 1$ entries, and (iii) a sparse vector where a constant fraction $\rho$ of entries are i.i.d. $\pm 1$ and the rest are zero. For each of these cases, our upper and lower bounds match up to a $1+o(1)$ factor as the order $d$ of the tensor becomes large. For sparse signals (iii), our bounds are also asymptotically tight in the sparse limit $\rho \to 0$ for any fixed $d$ (including the $d=2$ case of sparse PCA). Our upper bounds for (i) demonstrate a phenomenon reminiscent of the work of Baik, Ben Arous and P\'ech\'e: an `eigenvalue' of a perturbed tensor emerges from the bulk at a strictly lower signal-to-noise ratio than when the perturbation itself exceeds the bulk; we quantify the size of this effect. We also provide some general results for larger classes of priors. In particular, the large $d$ asymptotics of the threshold location differs between problems with discrete priors versus continuous priors. Finally, for priors (i) and (ii) we carry out the replica prediction from statistical physics, which is conjectured to give the exact information-theoretic threshold for any fixed $d$. Of independent interest, we introduce a new improvement to the second moment method for contiguity, on which our lower bounds are based. Our technique conditions away from rare `bad' events that depend on interactions between the signal and noise. This enables us to close $\sqrt{2}$-factor gaps present in several previous works. version:1
arxiv-1612-02965 | BaTFLED: Bayesian Tensor Factorization Linked to External Data | http://arxiv.org/abs/1612.02965 | id:1612.02965 author:Nathan H Lazar, Mehmet Gönen, Kemal Sönmez category:stat.ML cs.LG q-bio.QM  published:2016-12-09 summary:The vast majority of current machine learning algorithms are designed to predict single responses or a vector of responses, yet many types of response are more naturally organized as matrices or higher-order tensor objects where characteristics are shared across modes. We present a new machine learning algorithm BaTFLED (Bayesian Tensor Factorization Linked to External Data) that predicts values in a three-dimensional response tensor using input features for each of the dimensions. BaTFLED uses a probabilistic Bayesian framework to learn projection matrices mapping input features for each mode into latent representations that multiply to form the response tensor. By utilizing a Tucker decomposition, the model can capture weights for interactions between latent factors for each mode in a small core tensor. Priors that encourage sparsity in the projection matrices and core tensor allow for feature selection and model regularization. This method is shown to far outperform elastic net and neural net models on 'cold start' tasks from data simulated in a three-mode structure. Additionally, we apply the model to predict dose-response curves in a panel of breast cancer cell lines treated with drug compounds that was used as a Dialogue for Reverse Engineering Assessments and Methods (DREAM) challenge. version:2
arxiv-1612-07697 | Internet-Based Image Retrieval Using End-to-End Trained Deep Distributions | http://arxiv.org/abs/1612.07697 | id:1612.07697 author:A. Vakhitov, A. Kuzmin, V. Lempitsky category:cs.CV  published:2016-12-22 summary:Internet image search engines have long been considered as a promising tool for handling open-vocabulary textual user queries to unannotated image datasets. However, systems that use this tool have to deal with multi-modal and noisy image sets returned by search engines, especially for polysemous queries. Generally, for many queries, only a small part of the returned sets can be relevant to the user intent. In this work, we suggest an approach that explicitly accounts for the complex and noisy structure of the image sets returned by Internet image search engines. Similarly to a considerable number of previous image retrieval works, we train a deep convolutional network that maps images to high-dimensional descriptors. To model image sets obtained from the Internet, our approach then fits a simple probabilistic model that accounts for multi-modality and noise (e.g. a Gaussian mixture model) to the deep descriptors of the images in this set. Finally, the resulting distribution model can be used to search in the unannotated image dataset by evaluating likelihoods of individual images. As our main contribution, we develop an end-to-end training procedure that tunes the parameters of a deep network using an annotated training set, while accounting for the distribution fitting and the subsequent matching. In the experiments, we show that such an end-to-end approach boosts the accuracy of the Internet-based image retrieval for hold-out concepts, as compared to retrieval systems that fit similar distribution models to pre-trained features and to simpler end-to-end trained baselines. version:1
arxiv-1612-07695 | MultiNet: Real-time Joint Semantic Reasoning for Autonomous Driving | http://arxiv.org/abs/1612.07695 | id:1612.07695 author:Marvin Teichmann, Michael Weber, Marius Zoellner, Roberto Cipolla, Raquel Urtasun category:cs.CV cs.RO  published:2016-12-22 summary:While most approaches to semantic reasoning have focused on improving performance, in this paper we argue that computational times are very important in order to enable real time applications such as autonomous driving. Towards this goal, we present an approach to joint classification, detection and semantic segmentation via a unified architecture where the encoder is shared amongst the three tasks. Our approach is very simple, can be trained end-to-end and performs extremely well in the challenging KITTI dataset, outperforming the state-of-the-art in the road segmentation task. Our approach is also very efficient, taking less than 100 ms to perform all tasks. version:1
arxiv-1612-07659 | Structured Sequence Modeling with Graph Convolutional Recurrent Networks | http://arxiv.org/abs/1612.07659 | id:1612.07659 author:Youngjoo Seo, Michaël Defferrard, Pierre Vandergheynst, Xavier Bresson category:stat.ML cs.LG  published:2016-12-22 summary:This paper introduces Graph Convolutional Recurrent Network (GCRN), a deep learning model able to predict structured sequences of data. Precisely, GCRN is a generalization of classical recurrent neural networks (RNN) to data structured by an arbitrary graph. Such structured sequences can represent series of frames in videos, spatio-temporal measurements on a network of sensors, or random walks on a vocabulary graph for natural language modeling. The proposed model combines convolutional neural networks (CNN) on graphs to identify spatial structures and RNN to find dynamic patterns. We study two possible architectures of GCRN, and apply the models to two practical problems: predicting moving MNIST data, and modeling natural language with the Penn Treebank dataset. Experiments show that exploiting simultaneously graph spatial and dynamic information about data can improve both precision and learning speed. version:1
arxiv-1612-07625 | Hardware for Machine Learning: Challenges and Opportunities | http://arxiv.org/abs/1612.07625 | id:1612.07625 author:Vivienne Sze, Yu-Hsin Chen, Joel Emer, Amr Suleiman, Zhengdong Zhang category:cs.CV  published:2016-12-22 summary:Machine learning plays a critical role in extracting meaningful information out of the zetabytes of sensor data collected every day. For some applications, the goal is to analyze and understand the data to identify trends (e.g., surveillance, portable/wearable electronics); in other applications, the goal is to take immediate action based the data (e.g., robotics/drones, self-driving cars, smart Internet of Things). For many of these applications, local embedded processing near the sensor is preferred over the cloud due to privacy or latency concerns, or limitations in the communication bandwidth. However, at the sensor there are often stringent constraints on energy consumption and cost in addition to throughput and accuracy requirements. Furthermore, flexibility is often required such that the processing can be adapted for different applications or environments (e.g., update the weights and model in the classifier). In many applications, machine learning often involves transforming the input data into a higher dimensional space, which, along with programmable weights, increases data movement and consequently energy consumption. In this paper, we will discuss how these challenges can be addressed at various levels of hardware design ranging from architecture, hardware-friendly algorithms, mixed-signal circuits, and advanced technologies (including memories and sensors). version:1
arxiv-1612-07602 | Jointly Extracting Relations with Class Ties via Effective Deep Ranking | http://arxiv.org/abs/1612.07602 | id:1612.07602 author:Hai Ye, Wenhan Chao, Zhunchen Luo category:cs.AI cs.CL  published:2016-12-22 summary:In distant supervised relation extraction, the connection between relations of one entity tuple, which we call class ties, is common. Exploiting this connection may be promising for relation extraction. However, this property is seldom considered by previous work. In this work, to leverage class ties, we propose to make joint relation extraction with a unified model that integrates convolutional neural network with a general pairwise ranking framework, in which two novel ranking loss functions are introduced. Besides, an effective method is proposed to relieve the impact of relation NR (not relation) for model training and test. Experimental results on a widely used dataset show that: (1) Our model is much more superior than the baselines, achieving state-of-the-art performance; (2) Leveraging class ties, joint extraction is indeed better than separated extraction; (3) Relieving the impact of NR will significantly boost our model performance; (4) Our model can primely deal with wrong labeling problem. version:1
arxiv-1612-07600 | Re-evaluating Automatic Metrics for Image Captioning | http://arxiv.org/abs/1612.07600 | id:1612.07600 author:Mert Kilickaya, Aykut Erdem, Nazli Ikizler-Cinbis, Erkut Erdem category:cs.CL cs.CV  published:2016-12-22 summary:The task of generating natural language descriptions from images has received a lot of attention in recent years. Consequently, it is becoming increasingly important to evaluate such image captioning approaches in an automatic manner. In this paper, we provide an in-depth evaluation of the existing image captioning metrics through a series of carefully designed experiments. Moreover, we explore the utilization of the recently proposed Word Mover's Distance (WMD) document metric for the purpose of image captioning. Our findings outline the differences and/or similarities between metrics and their relative robustness by means of extensive correlation, accuracy and distraction based evaluations. Our results also demonstrate that WMD provides strong advantages over other metrics. version:1
arxiv-1612-07597 | Finding Statistically Significant Attribute Interactions | http://arxiv.org/abs/1612.07597 | id:1612.07597 author:Andreas Henelius, Antti Ukkonen, Kai Puolamäki category:stat.ML cs.LG  published:2016-12-22 summary:In many data exploration tasks it is meaningful to identify groups of attribute interactions that are specific to a variable of interest. These interactions are also useful in several practical applications, for example, to gain insight into the structure of the data, in feature selection, and in data anonymisation. We present a novel method, based on statistical significance testing, that can be used to verify if the data set has been created by a given factorized class-conditional joint distribution, where the distribution is parametrized by partition of its attributes. Furthermore, we provide a method, named ASTRID, to automatically find a partition of attributes that describes the distribution that has generated the data. The state-of-the-art classifiers are utilized to capture the interactions present in the data by systematically breaking attribute interactions and observing the effect of this breaking on classifier performance. We empirically demonstrate the utility of the proposed method with real and synthetic data as well as with usage examples. version:1
arxiv-1612-07548 | Non-Deterministic Policy Improvement Stabilizes Approximated Reinforcement Learning | http://arxiv.org/abs/1612.07548 | id:1612.07548 author:Wendelin Böhmer, Rong Guo, Klaus Obermayer category:cs.AI cs.LG stat.ML  published:2016-12-22 summary:This paper investigates a type of instability that is linked to the greedy policy improvement in approximated reinforcement learning. We show empirically that non-deterministic policy improvement can stabilize methods like LSPI by controlling the improvements' stochasticity. Additionally we show that a suitable representation of the value function also stabilizes the solution to some degree. The presented approach is simple and should also be easily transferable to more sophisticated algorithms like deep reinforcement learning. version:1
arxiv-1612-07523 | Robustness of Voice Conversion Techniques Under Mismatched Conditions | http://arxiv.org/abs/1612.07523 | id:1612.07523 author:Monisankha Pal, Dipjyoti Paul, Md Sahidullah, Goutam Saha category:cs.SD cs.LG stat.ML  published:2016-12-22 summary:Most of the existing studies on voice conversion (VC) are conducted in acoustically matched conditions between source and target signal. However, the robustness of VC methods in presence of mismatch remains unknown. In this paper, we report a comparative analysis of different VC techniques under mismatched conditions. The extensive experiments with five different VC techniques on CMU ARCTIC corpus suggest that performance of VC methods substantially degrades in noisy conditions. We have found that bilinear frequency warping with amplitude scaling (BLFWAS) outperforms other methods in most of the noisy conditions. We further explore the suitability of different speech enhancement techniques for robust conversion. The objective evaluation results indicate that spectral subtraction and log minimum mean square error (logMMSE) based speech enhancement techniques can be used to improve the performance in specific noisy conditions. version:1
arxiv-1612-07516 | On Coreset Constructions for the Fuzzy $K$-Means Problem | http://arxiv.org/abs/1612.07516 | id:1612.07516 author:Johannes Blömer, Sascha Brauer, Kathrin Bujna category:cs.LG cs.DS  published:2016-12-22 summary:In this paper, we present coreset constructions for the fuzzy $K$-means problem. First, we show that one can construct a weak coresets for fuzzy $K$-means. Second, we show that there are coresets for fuzzy $K$-means with respect to balanced fuzzy $K$-means solutions. Third, we use these coresets to develop a randomized approximation algorithm whose runtime is polynomial in the number of the given points and the dimension of these points. version:1
arxiv-1612-07512 | Causal Effect Identification in Acyclic Directed Mixed Graphs and Gated Models | http://arxiv.org/abs/1612.07512 | id:1612.07512 author:Jose M. Peña, Marcus Bendtsen category:stat.ML cs.AI  published:2016-12-22 summary:We introduce a new family of graphical models that consists of graphs with possibly directed, undirected and bidirected edges but without directed cycles. We show that these models are suitable for representing causal models with additive error terms. We provide a set of sufficient graphical criteria for the identification of arbitrary causal effects when the new models contain directed and undirected edges but no bidirected edge. We also provide a necessary and sufficient graphical criterion for the identification of the causal effect of a single variable on the rest of the variables. Moreover, we develop an exact algorithm for learning the new models from observational and interventional data via answer set programming. Finally, we introduce gated models for causal effect identification, a new family of graphical models that exploits context specific independences to identify additional causal effects. version:1
arxiv-1612-07495 | Noise Mitigation for Neural Entity Typing and Relation Extraction | http://arxiv.org/abs/1612.07495 | id:1612.07495 author:Yadollah Yaghoobzadeh, Heike Adel, Hinrich Schütze category:cs.CL  published:2016-12-22 summary:In this paper, we address two different types of noise in information extraction models: noise from distant supervision and noise from pipeline input features. Our target tasks are entity typing and relation extraction. For the first noise type, we introduce multi-instance multi-label learning algorithms using neural network models, and apply them to fine-grained entity typing for the first time. This gives our models comparable performance with the state-of-the-art supervised approach which uses global embeddings of entities. For the second noise type, we propose ways to improve the integration of noisy entity type predictions into relation extraction. Our experiments show that probabilistic predictions are more robust than discrete predictions and that joint training of the two tasks performs best. version:1
arxiv-1612-07486 | Continuous multilinguality with language vectors | http://arxiv.org/abs/1612.07486 | id:1612.07486 author:Robert Östling, Jörg Tiedemann category:cs.CL  published:2016-12-22 summary:Most existing models for multilingual natural language processing (NLP) treat language as a discrete category, and make predictions for either one language or the other. In contrast, we propose using continuous vector representations of language. We show that these can be learned efficiently with a character-based neural language model, and used to improve inference about language varieties not seen during training. In experiments with 1303 Bible translations into 990 different languages, we empirically explore the capacity of multilingual language models, and also show that the language vectors capture genetic relationships between languages. version:1
arxiv-1203-3896 | Fast and Adaptive Sparse Precision Matrix Estimation in High Dimensions | http://arxiv.org/abs/1203.3896 | id:1203.3896 author:Weidong Liu, Xi Luo category:stat.ME math.ST stat.AP stat.CO stat.ML stat.TH  published:2012-03-17 summary:This paper proposes a new method for estimating sparse precision matrices in the high dimensional setting. It has been popular to study fast computation and adaptive procedures for this problem. We propose a novel approach, called Sparse Column-wise Inverse Operator, to address these two issues. We analyze an adaptive procedure based on cross validation, and establish its convergence rate under the Frobenius norm. The convergence rates under other matrix norms are also established. This method also enjoys the advantage of fast computation for large-scale problems, via a coordinate descent algorithm. Numerical merits are illustrated using both simulated and real datasets. In particular, it performs favorably on an HIV brain tissue dataset and an ADHD resting-state fMRI dataset. version:2
arxiv-1612-07454 | How to Train Your Deep Neural Network with Dictionary Learning | http://arxiv.org/abs/1612.07454 | id:1612.07454 author:Vanika Singhal, Shikha Singh, Angshul Majumdar category:cs.LG stat.ML  published:2016-12-22 summary:Currently there are two predominant ways to train deep neural networks. The first one uses restricted Boltzmann machine (RBM) and the second one autoencoders. RBMs are stacked in layers to form deep belief network (DBN); the final representation layer is attached to the target to complete the deep neural network. Autoencoders are nested one inside the other to form stacked autoencoders; once the stcaked autoencoder is learnt the decoder portion is detached and the target attached to the deepest layer of the encoder to form the deep neural network. This work proposes a new approach to train deep neural networks using dictionary learning as the basic building block; the idea is to use the features from the shallower layer as inputs for training the next deeper layer. One can use any type of dictionary learning (unsupervised, supervised, discriminative etc.) as basic units till the pre-final layer. In the final layer one needs to use the label consistent dictionary learning formulation for classification. We compare our proposed framework with existing state-of-the-art deep learning techniques on benchmark problems; we are always within the top 10 results. In actual problems of age and gender classification, we are better than the best known techniques. version:1
arxiv-1612-07453 | Deep Blind Compressed Sensing | http://arxiv.org/abs/1612.07453 | id:1612.07453 author:Shikha Singh, Vanika Singhal, Angshul Majumdar category:cs.CV G.1.6; I.4.5  published:2016-12-22 summary:This work addresses the problem of extracting deeply learned features directly from compressive measurements. There has been no work in this area. Existing deep learning tools only give good results when applied on the full signal, that too usually after preprocessing. These techniques require the signal to be reconstructed first. In this work we show that by learning directly from the compressed domain, considerably better results can be obtained. This work extends the recently proposed framework of deep matrix factorization in combination with blind compressed sensing; hence the term deep blind compressed sensing. Simulation experiments have been carried out on imaging via single pixel camera, under-sampled biomedical signals, arising in wireless body area network and compressive hyperspectral imaging. In all cases, the superiority of our proposed deep blind compressed sensing can be envisaged. version:1
arxiv-1612-07801 | Probabilistic graphical model based approach for water mapping using GaoFen-2 (GF-2) high resolution imagery and Landsat 8 time series | http://arxiv.org/abs/1612.07801 | id:1612.07801 author:Luyan Ji, Jie Wang, Xiurui Geng, Peng Gong category:stat.AP cs.CV  published:2016-12-22 summary:The objective of this paper is to evaluate the potential of Gaofen-2 (GF-2) high resolution multispectral sensor (MS) and panchromatic (PAN) imagery on water mapping. Difficulties of water mapping on high resolution data includes: 1) misclassification between water and shadows or other low-reflectance ground objects, which is mostly caused by the spectral similarity within the given band range; 2) small water bodies with size smaller than the spatial resolution of MS image. To solve the confusion between water and low-reflectance objects, the Landsat 8 time series with two shortwave infrared (SWIR) bands is added because water has extremely strong absorption in SWIR. In order to integrate the three multi-sensor, multi-resolution data sets, the probabilistic graphical model (PGM) is utilized here with conditional probability distribution defined mainly based on the size of each object. For comparison, results from the SVM classifier on the PCA fused and MS data, thresholding method on the PAN image, and water index method on the Landsat data are computed. The confusion matrices are calculated for all the methods. The results demonstrate that the PGM method can achieve the best performance with the highest overall accuracy. Moreover, small rivers can also be extracted by adding weight on the PAN result in PGM. Finally, the post-classification procedure is applied on the PGM result to further exclude misclassification in shadow and water-land boundary regions. Accordingly, the producer's, user's and overall accuracy are all increased, indicating the effectiveness of our method. version:1
arxiv-1612-07411 | A Context-aware Attention Network for Interactive Question Answering | http://arxiv.org/abs/1612.07411 | id:1612.07411 author:Huayu Li, Martin Renqiang Min, Yong Ge, Asim Kadav category:cs.CL cs.LG  published:2016-12-22 summary:We develop a new model for Interactive Question Answering (IQA), using Gated-Recurrent-Unit recurrent networks (GRUs) as encoders for statements and questions, and another GRU as a decoder for outputs. Distinct from previous work, our approach employs context-dependent word-level attention for more accurate statement representations and question-guided sentence-level attention for better context modeling. Employing these mechanisms, our model accurately understands when it can output an answer or when it requires generating a supplementary question for additional input. When available, user's feedback is encoded and directly applied to update sentence-level attention to infer the answer. Extensive experiments on QA and IQA datasets demonstrate quantitatively the effectiveness of our model with significant improvement over conventional QA models. version:1
arxiv-1612-07403 | Efficient Action Detection in Untrimmed Videos via Multi-Task Learning | http://arxiv.org/abs/1612.07403 | id:1612.07403 author:Yi Zhu, Shawn Newsam category:cs.CV cs.MM  published:2016-12-22 summary:This paper studies the joint learning of action recognition and temporal localization in long, untrimmed videos. We employ a multi-task learning framework that performs the three highly related steps of action proposal, action recognition, and action localization refinement in parallel instead of the standard sequential pipeline that performs the steps in order. We develop a novel temporal actionness regression module that estimates what proportion of a clip contains action. We use it for temporal localization but it could have other applications like video retrieval, surveillance, summarization, etc. We also introduce random shear augmentation during training to simulate viewpoint change. We evaluate our framework on three popular video benchmarks. Results demonstrate that our joint model is efficient in terms of storage and computation in that we do not need to compute and cache dense trajectory features, and that it is several times faster than its sequential ConvNets counterpart. Yet, despite being more efficient, it outperforms state-of-the-art methods with respect to accuracy. version:1
arxiv-1612-07401 | Microstructure Representation and Reconstruction of Heterogeneous Materials via Deep Belief Network for Computational Material Design | http://arxiv.org/abs/1612.07401 | id:1612.07401 author:Ruijin Cang, Yaopengxiao Xu, Shaohua Chen, Yongming Liu, Yang Jiao, Max Yi Ren category:cond-mat.mtrl-sci cs.LG stat.ML  published:2016-12-22 summary:Integrated Computational Materials Engineering (ICME) aims to accelerate optimal design of complex material systems by integrating material science and design automation. For tractable ICME, it is required that (1) a structural feature space be identified to allow reconstruction of new designs, and (2) the reconstruction process be property-preserving. The majority of existing structural presentation schemes rely on the designer's understanding of specific material systems to identify geometric and statistical features, which could be biased and insufficient for reconstructing physically meaningful microstructures of complex material systems. In this paper, we develop a feature learning mechanism based on convolutional deep belief network to automate a two-way conversion between microstructures and their lower-dimensional feature representations, and to achieves a 1000-fold dimension reduction from the microstructure space. The proposed model is applied to a wide spectrum of heterogeneous material systems with distinct microstructural features including Ti-6Al-4V alloy, Pb63-Sn37 alloy, Fontainebleau sandstone, and Spherical colloids, to produce material reconstructions that are close to the original samples with respect to 2-point correlation functions and mean critical fracture strength. This capability is not achieved by existing synthesis methods that rely on the Markovian assumption of material microstructures. version:1
arxiv-1612-07379 | Automatic Identification of Scenedesmus Polymorphic Microalgae from Microscopic Images | http://arxiv.org/abs/1612.07379 | id:1612.07379 author:Jhony-Heriberto Giraldo-Zuluaga, Geman Diez, Alexander Gomez, Tatiana Martinez, Mariana Peñuela Vasquez, Jesus Francisco Vargas Bonilla, Augusto Salazar category:cs.CV  published:2016-12-21 summary:Microalgae counting is used to measure biomass quantity. Usually, it is performed in a manual way using a Neubauer chamber and expert criterion, with the risk of a high error rate. This paper addresses the methodology for automatic identification of Scenedesmus microalgae (used in the methane production and food industry) and applies it to images captured by a digital microscope. The use of contrast adaptive histogram equalization for pre-processing, and active contours for segmentation are presented. The calculation of statistical features (Histogram of Oriented Gradients, Hu and Zernike moments) with texture features (Haralick and Local Binary Patterns descriptors) are proposed for algae characterization. Scenedesmus algae can build coenobia consisting of 1, 2, 4 and 8 cells. The amount of algae of each coenobium helps to determine the amount of lipids, proteins, and other substances in a given sample of a algae crop. The knowledge of the quantity of those elements improves the quality of bioprocess applications. Classification of coenobia achieves accuracies of 98.63% and 97.32% with Support Vector Machine (SVM) and Artificial Neural Network (ANN), respectively. According to the results it is possible to consider the proposed methodology as an alternative to the traditional technique for algae counting. The database used in this paper is publicly available for download. version:1
arxiv-1612-07374 | Detecting Unusual Input-Output Associations in Multivariate Conditional Data | http://arxiv.org/abs/1612.07374 | id:1612.07374 author:Charmgil Hong, Milos Hauskrecht category:cs.LG stat.ML  published:2016-12-21 summary:Despite tremendous progress in outlier detection research in recent years, the majority of existing methods are designed only to detect unconditional outliers that correspond to unusual data patterns expressed in the joint space of all data attributes. Such methods are not applicable when we seek to detect conditional outliers that reflect unusual responses associated with a given context or condition. This work focuses on multivariate conditional outlier detection, a special type of the conditional outlier detection problem, where data instances consist of multi-dimensional input (context) and output (responses) pairs. We present a novel outlier detection framework that identifies abnormal input-output associations in data with the help of a decomposable conditional probabilistic model that is learned from all data instances. Since components of this model can vary in their quality, we combine them with the help of weights reflecting their reliability in assessment of outliers. We study two ways of calculating the component weights: global that relies on all data, and local that relies only on instances similar to the target instance. Experimental results on data from various domains demonstrate the ability of our framework to successfully identify multivariate conditional outliers. version:1
arxiv-1612-07360 | Top-down Visual Saliency Guided by Captions | http://arxiv.org/abs/1612.07360 | id:1612.07360 author:Vasili Ramanishka, Abir Das, Jianming Zhang, Kate Saenko category:cs.CV  published:2016-12-21 summary:Top-down saliency methods based on deep neural networks have recently been proposed for task-driven visual search. However existing methods focus on object or scene classification tasks and cannot be used to compute saliency heatmaps using a natural language sentence as the top-down input. Current state-of-the-art image and video captioning models can generate accurate sentence captions but are difficult to understand, as they do not expose the internal process by which spatial and temporal regions are mapped to predicted words. In this paper, we expose this mapping and demonstrate that spatio-temporal saliency is learned implicitly by the combination of CNN and LSTM parts of modern encoder-decoder networks. Our approach, which we call Caption-Guided Visual Saliency, can produce spatial or spatio-temporal heatmaps for both given input sentences or sentences predicted by our model. Unlike recent efforts that introduce explicit "attention" layers to selectively attend to certain inputs while generating each word, our approach recovers saliency without the overhead of explicit attention layers, and can be used to analyze a variety of existing model architectures and improve their design. We evaluate our approach on large scale video and image datasets and make several interesting discoveries about the inner workings of captioning models. The source code is publicly available at github.com/VisionLearningGroup/caption-guided-saliency. version:1
arxiv-1612-07335 | Distributed Dictionary Learning | http://arxiv.org/abs/1612.07335 | id:1612.07335 author:Amir Daneshmand, Gesualdo Scutari, Francisco Facchinei category:math.OC cs.LG  published:2016-12-21 summary:The paper studies distributed Dictionary Learning (DL) problems where the learning task is distributed over a multi-agent network with time-varying (nonsymmetric) connectivity. This formulation is relevant, for instance, in big-data scenarios where massive amounts of data are collected/stored in different spatial locations and it is unfeasible to aggregate and/or process all the data in a fusion center, due to resource limitations, communication overhead or privacy considerations. We develop a general distributed algorithmic framework for the (nonconvex) DL problem and establish its asymptotic convergence. The new method hinges on Successive Convex Approximation (SCA) techniques coupled with i) a gradient tracking mechanism instrumental to locally estimate the missing global information; and ii) a consensus step, as a mechanism to distribute the computations among the agents. To the best of our knowledge, this is the first distributed algorithm with provable convergence for the DL problem and, more in general, bi-convex optimization problems over (time-varying) directed graphs. version:1
arxiv-1607-03854 | The Partially Observable Hidden Markov Model and its Application to Keystroke Dynamics | http://arxiv.org/abs/1607.03854 | id:1607.03854 author:John V. Monaco, Charles C. Tappert category:cs.IT cs.CR math.IT stat.ML  published:2016-07-13 summary:The partially observable hidden Markov model is an extension of the hidden Markov Model in which the hidden states are conditioned on an independent Markov chain. The structure of the POHMM is motivated by sequences that contain discrete metadata, such as an event type, that partially reveal the underlying hidden state. Such a scenario is encountered in keystroke dynamics. Under the assumption that the user can be in either an active or passive state of typing, the keyboard key names are event types that partially reveal the hidden state due to the presence of relatively longer time intervals between words and sentences than between letters of a word. Using five public datasets, the proposed model is shown to consistently outperform other anomaly detectors, including the standard HMM, in biometric identification and verification tasks and is generally preferred over the HMM in a Monte Carlo goodness of fit test. version:4
arxiv-1612-07307 | Loss is its own Reward: Self-Supervision for Reinforcement Learning | http://arxiv.org/abs/1612.07307 | id:1612.07307 author:Evan Shelhamer, Parsa Mahmoudieh, Max Argus, Trevor Darrell category:cs.LG  published:2016-12-21 summary:Reinforcement learning, driven by reward, addresses tasks by optimizing policies for expected return. Need the supervision be so narrow? Reward is delayed and sparse for many tasks, so we argue that reward alone is a difficult and impoverished signal for end-to-end optimization. To augment reward, we consider a range of self-supervised tasks that incorporate states, actions, and successors to provide auxiliary losses. These losses offer ubiquitous and instantaneous supervision for representation learning even in the absence of reward. While current results show that learning from reward alone is feasible, pure reinforcement learning methods are constrained by computational and data efficiency issues that can be remedied by auxiliary losses. Self-supervised pre-training improves the data efficiency and policy returns of end-to-end reinforcement learning. version:1
arxiv-1612-07725 | Stacking machine learning classifiers to identify Higgs bosons at the LHC | http://arxiv.org/abs/1612.07725 | id:1612.07725 author:Alexandre Alves category:hep-ph cs.LG physics.data-an  published:2016-12-21 summary:Machine learning (ML) algorithms have been employed in the problem of classifying signal and background events with high accuracy in particle physics. In this paper, we use a widespread ML technique, namely, \emph{stacked generalization}, for the task of discovering a new neutral Higgs boson in gluon fusion. We found that, at the same time it demands far less computation efforts, \emph{stacking} ML algorithms performs almost as well as deep neural networks (DNN) trained exclusively with kinematic distributions for the same task by building either a highly discriminating linear model or a shallower neural network with stacked ML outputs. We also show that it is possible to outperform DNN in this channel by partially exploring correlations among the classifiers outputs in a multivariate statistical analysis. version:1
arxiv-1612-07222 | Bayesian Decision Process for Cost-Efficient Dynamic Ranking via Crowdsourcing | http://arxiv.org/abs/1612.07222 | id:1612.07222 author:Xi Chen, Kevin Jiao, Qihang Lin category:stat.ML cs.LG stat.ME  published:2016-12-21 summary:Rank aggregation based on pairwise comparisons over a set of items has a wide range of applications. Although considerable research has been devoted to the development of rank aggregation algorithms, one basic question is how to efficiently collect a large amount of high-quality pairwise comparisons for the ranking purpose. Because of the advent of many crowdsourcing services, a crowd of workers are often hired to conduct pairwise comparisons with a small monetary reward for each pair they compare. Since different workers have different levels of reliability and different pairs have different levels of ambiguity, it is desirable to wisely allocate the limited budget for comparisons among the pairs of items and workers so that the global ranking can be accurately inferred from the comparison results. To this end, we model the active sampling problem in crowdsourced ranking as a Bayesian Markov decision process, which dynamically selects item pairs and workers to improve the ranking accuracy under a budget constraint. We further develop a computationally efficient sampling policy based on knowledge gradient as well as a moment matching technique for posterior approximation. Experimental evaluations on both synthetic and real data show that the proposed policy achieves high ranking accuracy with a lower labeling cost. version:1
arxiv-1612-07217 | Learning Motion Patterns in Videos | http://arxiv.org/abs/1612.07217 | id:1612.07217 author:Pavel Tokmakov, Karteek Alahari, Cordelia Schmid category:cs.CV  published:2016-12-21 summary:The problem of determining whether an object is in motion, irrespective of the camera motion, is far from being solved. We address this challenging task by learning motion patterns in videos. The core of our approach is a fully convolutional network, which is learnt entirely from synthetic video sequences, and their ground-truth optical flow and motion segmentation. This encoder-decoder style architecture first learns a coarse representation of the optical flow field features, and then refines it iteratively to produce motion labels at the original high-resolution. The output label of each pixel denotes whether it has undergone independent motion, i.e., irrespective of the camera motion. We demonstrate the benefits of this learning framework on the moving object segmentation task, where the goal is to segment all the objects in motion. To this end we integrate an objectness measure into the framework. Our approach outperforms the top method on the recently released DAVIS benchmark dataset, comprising real-world sequences, by 5.6%. We also evaluate on the Berkeley motion segmentation database, achieving state-of-the-art results. version:1
arxiv-1612-07215 | Inverted Bilingual Topic Models for Lexicon Extraction from Non-parallel Data | http://arxiv.org/abs/1612.07215 | id:1612.07215 author:Tengfei Ma category:cs.CL  published:2016-12-21 summary:A good lexicon is an important resource for various cross-lingual tasks such as information retrieval and text mining. In this paper, we focus on extracting translation pairs from non-parallel cross-lingual corpora. Previous lexicon extraction algorithms for non-parallel data generally rely on an accurate seed dictionary and extract translation pairs by using context similarity. However, there are two problems. One, a lot of semantic information is lost if we just use seed dictionary words to construct context vectors and obtain the context similarity. Two, in practice, we may not have a clean seed dictionary. For example, if we use a generic dictionary as a seed dictionary in a special domain, it might be very noisy. To solve these two problems, we propose two new bilingual topic models to better capture the semantic information of each word while discriminating the multiple translations in a noisy seed dictionary. We then use an effective measure to evaluate the similarity of words in different languages and select the optimal translation pairs. Results of experiments using real Japanese-English data demonstrate the effectiveness of our models. version:1
arxiv-1612-07182 | Multi-Agent Cooperation and the Emergence of (Natural) Language | http://arxiv.org/abs/1612.07182 | id:1612.07182 author:Angeliki Lazaridou, Alexander Peysakhovich, Marco Baroni category:cs.CL cs.CV cs.GT cs.LG cs.MA  published:2016-12-21 summary:The current mainstream approach to train natural language systems is to expose them to large amounts of text. This passive learning is problematic if we are interested in developing interactive machines, such as conversational agents. We propose a framework for language learning that relies on multi-agent communication. We study this learning in the context of referential games. In these games, a sender and a receiver see a pair of images. The sender is told one of them is the target and is allowed to send a message from a fixed, arbitrary vocabulary to the receiver. The receiver must rely on this message to identify the target. Thus, the agents develop their own language interactively out of the need to communicate. We show that two networks with simple configurations are able to learn to coordinate in the referential game. We further explore how to make changes to the game environment to cause the "word meanings" induced in the game to better reflect intuitive semantic properties of the images. In addition, we present a simple strategy for grounding the agents' code into natural language. Both of these are necessary steps towards developing machines that are able to communicate with humans productively. version:1
arxiv-1612-07180 | A Unified Framework for Tumor Proliferation Score Prediction in Breast Histopathology | http://arxiv.org/abs/1612.07180 | id:1612.07180 author:Kyunghyun Paeng, Sangheum Hwang, Sunggyun Park, Minsoo Kim, Seokhwi Kim category:cs.CV  published:2016-12-21 summary:Predicting tumor proliferation scores is an important biomarker indicative of breast cancer patients' prognosis. In this paper, we present a unified framework to predict tumor proliferation scores from whole slide images in breast histopathology. The proposed system is offers a fully automated solution to predicting both a molecular data based, and a mitosis counting based tumor proliferation score. The framework integrates three modules, each fine-tuned to maximize the overall performance: an image processing component for handling whole slide images, a deep learning based mitosis detection network, and a proliferation scores prediction module. We have achieved 0.567 quadratic weighted Cohen's kappa in mitosis counting based score prediction and 0.652 F1-score in mitosis detection. On Spearman's correlation coefficient, which evaluates prediction on the molecular data based score, the system obtained 0.6171. Our system won first place in all of the three tasks in Tumor Proliferation Assessment Challenge at MICCAI 2016, outperforming all other approaches. version:1
arxiv-1612-07153 | Trilaminar Multiway Reconstruction Tree for Efficient Large Scale Structure from Motion | http://arxiv.org/abs/1612.07153 | id:1612.07153 author:Kun Sun, Wenbing Tao category:cs.CV  published:2016-12-21 summary:Accuracy and efficiency are two key problems in large scale incremental Structure from Motion (SfM). In this paper, we propose a unified framework to divide the image set into clusters suitable for reconstruction as well as find multiple reliable and stable starting points. Image partitioning performs in two steps. First, some small image groups are selected at places with high image density, and then all the images are clustered according to their optimal reconstruction paths to these image groups. This promises that the scene is always reconstructed from dense places to sparse areas, which can reduce error accumulation when images have weak overlap. To enable faster speed, images outside the selected group in each cluster are further divided to achieve a greater degree of parallelism. Experiments show that our method achieves significant speedup, higher accuracy and better completeness. version:1
arxiv-1612-07603 | Difficulty Adjustable and Scalable Constrained Multi-objective Test Problem Toolkit | http://arxiv.org/abs/1612.07603 | id:1612.07603 author:Zhun Fan, Wenji Li, Xinye Cai, Hui Li, Kaiwen Hu, Qingfu Zhang, Kalyanmoy Deb, Erik D. Goodman category:cs.NE cs.AI  published:2016-12-21 summary:In order to better understand the advantages and disadvantages of a constrained multi-objective evolutionary algorithm (CMOEA), it is important to understand the nature of difficulty of a constrained multi-objective optimization problem (CMOP) that the CMOEA is going to deal with. In this paper, we first propose three primary types of difficulty to characterize the constraints in CMOPs, including feasibility-hardness, convergence-hardness and diversity-hardness. We then develop a general toolkit to construct difficulty adjustable CMOPs with three types of parameterized constraint functions according to the proposed three primary types of difficulty. In fact, combination of the three primary constraint functions with different parameters can lead to construct a large variety of CMOPs and CMaOPs, whose difficulty can be uniquely defined by a triplet with each of its parameter specifying the level of each primary difficulty type respectively. Based on this toolkit, we suggest fifteen difficulty adjustable CMOPs named DAC-MOP1-15 with different types and levels of difficulty. To study the effectiveness of DAC-MOP1-15, two popular CMOEAs - MOEA/D-CDP and NSGA-II-CDP are adopted to test their performances on them. Furthermore, this toolkit also has the ability to scale the number of objectives. Nine difficulty adjustable constrained many-objective optimization problems (DAC-MaOPs) named DAC-MaOP1-9 with the scalability to the number of objectives are also proposed using this toolkit. Two constrained many-objective evolutionary algorithms (CMaOEAs) - CNSGA-III and CMOEA/DD are applied to test their performances on three, five, seven and ten-objective DAC-MaOP1-9 with different difficulty levels and types. version:1
arxiv-1612-07146 | Collaborative Filtering with User-Item Co-Autoregressive Models | http://arxiv.org/abs/1612.07146 | id:1612.07146 author:Chao Du, Chongxuan Li, Yin Zheng, Jun Zhu, Cailiang Liu, Hanning Zhou, Bo Zhang category:cs.LG  published:2016-12-21 summary:Besides the success on object recognition, machine translation and system control in games, (deep) neural networks have achieved state-of-the-art results in collaborative filtering (CF) recently. Previous neural approaches for CF are either user-based or item-based, which cannot leverage all relevant information explicitly. We propose CF-UIcA, a neural co-autoregressive model for CF tasks, which exploit the structural autoregressiveness in the domains of both users and items. Furthermore, we separate the inherent dependence in this structure under a natural assumption and develop an efficient stochastic learning algorithm to handle large scale datasets. We evaluate CF-UIcA on two popular benchmarks: MovieLens 1M and Netflix, and achieve state-of-the-art predictive performance, which demonstrates the effectiveness of CF-UIcA. version:1
arxiv-1612-07141 | Robust Classification of Graph-Based Data | http://arxiv.org/abs/1612.07141 | id:1612.07141 author:Carlos M. Alaíz, Michaël Fanuel, Johan A. K. Suykens category:cs.LG  published:2016-12-21 summary:A graph-based classification method is proposed both for semi-supervised learning in the case of Euclidean data and for classification in the case of graph data. Our manifold learning technique is based on a convex optimization problem involving a convex regularization term and a concave loss function with a trade-off parameter carefully chosen so that the objective function remains convex. As shown experimentally, the advantage of considering a concave loss function is that the learning problem becomes more robust in the presence of noisy labels. Furthermore, the loss function considered is then more similar to a classification loss while several other methods treat graph-based classification problems as regression problems. version:1
arxiv-1612-07130 | Sparse Coding of Neural Word Embeddings for Multilingual Sequence Labeling | http://arxiv.org/abs/1612.07130 | id:1612.07130 author:Gábor Berend category:cs.CL  published:2016-12-21 summary:In this paper we propose and carefully evaluate a sequence labeling framework which solely utilizes sparse indicator features derived from dense distributed word representations. The proposed model obtains (near) state-of-the art performance for both part-of-speech tagging and named entity recognition for a variety of languages. Our model relies only on a few thousand sparse coding-derived features, without applying any modification of the word representations employed for the different tasks. The proposed model has favorable generalization properties as it retains over 89.8% of its average POS tagging accuracy when trained at 1.2% of the total available training data, i.e.~150 sentences per language. version:1
arxiv-1612-05730 | Towards Wide Learning: Experiments in Healthcare | http://arxiv.org/abs/1612.05730 | id:1612.05730 author:Snehasis Banerjee, Tanushyam Chattopadhyay, Swagata Biswas, Rohan Banerjee, Anirban Dutta Choudhury, Arpan Pal, Utpal Garain category:stat.ML cs.LG  published:2016-12-17 summary:In this paper, a Wide Learning architecture is proposed that attempts to automate the feature engineering portion of the machine learning (ML) pipeline. Feature engineering is widely considered as the most time consuming and expert knowledge demanding portion of any ML task. The proposed feature recommendation approach is tested on 3 healthcare datasets: a) PhysioNet Challenge 2016 dataset of phonocardiogram (PCG) signals, b) MIMIC II blood pressure classification dataset of photoplethysmogram (PPG) signals and c) an emotion classification dataset of PPG signals. While the proposed method beats the state of the art techniques for 2nd and 3rd dataset, it reaches 94.38% of the accuracy level of the winner of PhysioNet Challenge 2016. In all cases, the effort to reach a satisfactory performance was drastically less (a few days) than manual feature engineering. version:2
arxiv-1612-07089 | Stochastic Multidimensional Scaling | http://arxiv.org/abs/1612.07089 | id:1612.07089 author:Ketan Rajawat, Sandeep Kumar category:math.OC cs.CV  published:2016-12-21 summary:Multidimensional scaling (MDS) is a popular dimensionality reduction techniques that has been widely used for network visualization and cooperative localization. However, the traditional stress minimization formulation of MDS necessitates the use of batch optimization algorithms that are not scalable to large-sized problems. This paper considers an alternative stochastic stress minimization framework that is amenable to incremental and distributed solutions. A novel linear-complexity stochastic optimization algorithm is proposed that is provably convergent and simple to implement. The applicability of the proposed algorithm to localization and visualization tasks is also expounded. Extensive tests on synthetic and real datasets demonstrate the efficacy of the proposed algorithm. version:1
arxiv-1612-07086 | Recurrent Highway Networks with Language CNN for Image Captioning | http://arxiv.org/abs/1612.07086 | id:1612.07086 author:Jiuxiang Gu, Gang Wang, Tsuhan Chen category:cs.CV cs.LG  published:2016-12-21 summary:In this paper, we propose a Recurrent Highway Network with Language CNN for image caption generation. Our network consists of three sub-networks: the deep Convolutional Neural Network for image representation, the Convolutional Neural Network for language modeling, and the Multimodal Recurrent Highway Network for sequence prediction. Our proposed model can naturally exploit the hierarchical and temporal structure of history words, which are critical for image caption generation. The effectiveness of our model is validated on two datasets MS COCO and Flickr30K. Our extensive experiment results show that our method is competitive with the state-of-the-art methods. version:1
arxiv-1612-07040 | A deep learning approach for predicting the quality of online health expert question-answering services | http://arxiv.org/abs/1612.07040 | id:1612.07040 author:Ze Hu, Zhan Zhang, Qing Chen, Haiqin Yang, Decheng Zuo category:cs.IR cs.CL  published:2016-12-21 summary:Currently, a growing number of health consumers are asking health-related questions online, at any time and from anywhere, which effectively lowers the cost of health care. The most common approach is using online health expert question-answering (HQA) services, as health consumers are more willing to trust answers from professional physicians. However, these answers can be of varying quality depending on circumstance. In addition, as the available HQA services grow, how to predict the answer quality of HQA services via machine learning becomes increasingly important and challenging. In an HQA service, answers are normally short texts, which are severely affected by the data sparsity problem. Furthermore, HQA services lack community features such as best answer and user votes. Therefore, the wisdom of the crowd is not available to rate answer quality. To address these problems, in this paper, the prediction of HQA answer quality is defined as a classification task. First, based on the characteristics of HQA services and feedback from medical experts, a standard for HQA service answer quality evaluation is defined. Next, based on the characteristics of HQA services, several novel non-textual features are proposed, including surface linguistic features and social features. Finally, a deep belief network (DBN)-based HQA answer quality prediction framework is proposed to predict the quality of answers by learning the high-level hidden semantic representation from the physicians' answers. Our results prove that the proposed framework overcomes the problem of overly sparse textual features in short text answers and effectively identifies high-quality answers. version:1
arxiv-1612-07029 | Scale-invariance of ruggedness measures in fractal fitness landscapes | http://arxiv.org/abs/1612.07029 | id:1612.07029 author:Hendrik Richter category:nlin.CD cs.NE q-bio.PE  published:2016-12-21 summary:The paper deals with using chaos to direct trajectories to targets and analyzes ruggedness and fractality of the resulting fitness landscapes. The targeting problem is formulated as a dynamic fitness landscape and four different chaotic maps generating such a landscape are studied. By using a computational approach, we analyze properties of the landscapes and quantify their fractal and rugged characteristics. In particular, it is shown that ruggedness measures such as correlation length and information content are scale-invariant and self-similar. version:1
arxiv-1612-05555 | Neural Networks Classifier for Data Selection in Statistical Machine Translation | http://arxiv.org/abs/1612.05555 | id:1612.05555 author:Álvaro Peris, Mara Chinea-Rios, Francisco Casacuberta category:cs.CL  published:2016-12-16 summary:We address the data selection problem in statistical machine translation (SMT) as a classification task. The new data selection method is based on a neural network classifier. We present a new method description and empirical results proving that our data selection method provides better translation quality, compared to a state-of-the-art method (i.e., Cross entropy). Moreover, the empirical results reported are coherent across different language pairs. version:2
arxiv-1612-07019 | Robust Learning with Kernel Mean p-Power Error Loss | http://arxiv.org/abs/1612.07019 | id:1612.07019 author:Badong Chen, Lei Xing, Xin Wang, Jing Qin, Nanning Zheng category:stat.ML cs.LG  published:2016-12-21 summary:Correntropy is a second order statistical measure in kernel space, which has been successfully applied in robust learning and signal processing. In this paper, we define a nonsecond order statistical measure in kernel space, called the kernel mean-p power error (KMPE), including the correntropic loss (CLoss) as a special case. Some basic properties of KMPE are presented. In particular, we apply the KMPE to extreme learning machine (ELM) and principal component analysis (PCA), and develop two robust learning algorithms, namely ELM-KMPE and PCA-KMPE. Experimental results on synthetic and benchmark data show that the developed algorithms can achieve consistently better performance when compared with some existing methods. version:1
arxiv-1612-07003 | Image biomarker standardisation initiative - feature definitions | http://arxiv.org/abs/1612.07003 | id:1612.07003 author:Alex Zwanenburg, Stefan Leger, Martin Vallières, Steffen Löck, for the Image Biomar category:cs.CV  published:2016-12-21 summary:While analysis of medical images has practically taken place since the first image was recorded, high throughput analysis of medical images is a more recent phenomenon. The aim of such a radiomics process is to provide decision support based on medical imaging. Part of the radiomics process is the conversion of image data into numerical features which capture different medical image aspects, and can be subsequently correlated as biomarkers to e.g. expected oncological treatment outcome. With the growth of the radiomics field, it has become clear that results are often difficult to reproduce, that standards for image processing and feature extraction are missing, and that reporting guidelines are absent. The image biomarker standardisation initiative (IBSI) seeks to address these issues. The current document provides definitions for a large number of image features. version:1
arxiv-1612-05000 | Development of a Real-time Colorectal Tumor Classification System for Narrow-band Imaging zoom-videoendoscopy | http://arxiv.org/abs/1612.05000 | id:1612.05000 author:Tsubasa Hirakawa, Toru Tamaki, Bisser Raytchev, Kazufumi Kaneda, Tetsushi Koide, Shigeto Yoshida, Hiroshi Mieno, Shinji Tanaka category:cs.CV  published:2016-12-15 summary:Colorectal endoscopy is important for the early detection and treatment of colorectal cancer and is used worldwide. A computer-aided diagnosis (CAD) system that provides an objective measure to endoscopists during colorectal endoscopic examinations would be of great value. In this study, we describe a newly developed CAD system that provides real-time objective measures. Our system captures the video stream from an endoscopic system and transfers it to a desktop computer. The captured video stream is then classified by a pretrained classifier and the results are displayed on a monitor. The experimental results show that our developed system works efficiently in actual endoscopic examinations and is medically significant. version:2
arxiv-1612-06962 | Stochastic Runtime Analysis of a Cross Entropy Algorithm for Traveling Salesman Problems | http://arxiv.org/abs/1612.06962 | id:1612.06962 author:Zijun Wu, Rolf Moehring, Jianhui Lai category:cs.DS cs.AI cs.NE  published:2016-12-21 summary:This article analyzes the stochastic runtime of a Cross-Entropy Algorithm on two classes of traveling salesman problems. The algorithm shares main features of the famous Max-Min Ant System with iteration-best reinforcement. For simple instances that have a $\{1,n\}$-valued distance function and a unique optimal solution, we prove a stochastic runtime of $O(n^{6+\epsilon})$ with the vertex-based random solution generation, and a stochastic runtime of $O(n^{3+\epsilon}\ln n)$ with the edge-based random solution generation for an arbitrary $\epsilon\in (0,1)$. These runtimes are very close to the known expected runtime for variants of Max-Min Ant System with best-so-far reinforcement. They are obtained for the stronger notion of stochastic runtime, which means that an optimal solution is obtained in that time with an overwhelming probability, i.e., a probability tending exponentially fast to one with growing problem size. We also inspect more complex instances with $n$ vertices positioned on an $m\times m$ grid. When the $n$ vertices span a convex polygon, we obtain a stochastic runtime of $O(n^{3}m^{5+\epsilon})$ with the vertex-based random solution generation, and a stochastic runtime of $O(n^{2}m^{5+\epsilon})$ for the edge-based random solution generation. When there are $k = O(1)$ many vertices inside a convex polygon spanned by the other $n-k$ vertices, we obtain a stochastic runtime of $O(n^{4}m^{5+\epsilon}+n^{6k-1}m^{\epsilon})$ with the vertex-based random solution generation, and a stochastic runtime of $O(n^{3}m^{5+\epsilon}+n^{3k}m^{\epsilon})$ with the edge-based random solution generation. These runtimes are better than the expected runtime for the so-called $(\mu\!+\!\lambda)$ EA reported in a recent article, and again obtained for the stronger notion of stochastic runtime. version:1
arxiv-1612-06950 | Temporal Tessellation for Video Annotation and Summarization | http://arxiv.org/abs/1612.06950 | id:1612.06950 author:Dotan Kaufman, Gil Levi, Tal Hassner, Lior Wolf category:cs.CV  published:2016-12-21 summary:We present a general approach to video understanding, inspired by semantic transfer techniques successfully used for 2D image understanding. Our method considers a video to be a 1D sequence of clips, each one associated with its own semantics. The nature of these semantics -- natural language captions or other labels -- depends on the task at hand. A test video is processed by forming correspondences between its clips and the clips of reference videos with known semantics, following which, reference semantics can be transferred to the test video. We describe two matching methods, both designed to ensure that (a) reference clips appear similar to test clips and (b), taken together, the semantics of selected reference clips is consistent and maintains temporal coherence. We use our method for video captioning on the LSMDC'16 benchmark and video summarization on the SumMe benchmark. In both cases, our method not only surpasses state of the art results, but importantly, it is the only method we know of that was successfully applied to both video understanding tasks. version:1
arxiv-1612-05628 | A New Softmax Operator for Reinforcement Learning | http://arxiv.org/abs/1612.05628 | id:1612.05628 author:Kavosh Asadi, Michael L. Littman category:cs.AI cs.LG stat.ML  published:2016-12-16 summary:A softmax operator applied to a set of values acts somewhat like the maximization function and somewhat like an average. In sequential decision making, softmax is often used in settings where it is necessary to maximize utility but also to hedge against problems that arise from putting all of one's weight behind a single maximum utility decision. The Boltzmann softmax operator is the most commonly used softmax operator in this setting, but we show that this operator is prone to misbehavior. In this work, we study an alternative softmax operator that, among other properties, is both a non-expansion (ensuring convergent behavior in learning and planning) and differentiable (making it possible to improve decisions via gradient descent methods). We provide proofs of these properties and present empirical comparisons between various softmax operators. version:3
arxiv-1612-06935 | Exploiting Rich Contents for Personalized Video Recommendation | http://arxiv.org/abs/1612.06935 | id:1612.06935 author:Xingzhong Du, Hongzhi Yin, Ling Chen, Yang Wang, Yi Yang, Xiaofang Zhou category:cs.IR cs.LG  published:2016-12-21 summary:Video recommendation has become an essential way of helping people explore the video world and discover the ones that may be of interest to them. However, mainstream collaborative filtering techniques usually suffer from limited performance due to the sparsity of user-video interactions, and hence are ineffective for new video recommendation. Although some recent recommender models such as CTR and CDL, have integrated text information to boost performance, user-generated videos typically include scarce or low-quality text information, which seriously degenerates performance. In this paper, we investigate how to leverage the non-textual content contained in videos to improve the quality of recommendations. We propose to first extract and encode the diverse audio, visual and action information that rich video content provides, then effectively incorporate these features with collaborative filtering using a collaborative embedding regression model (CER). We also study how to fuse multiple types of content features to further improve video recommendation using a novel fusion method that unifies both non-textual and textual features. We conducted extensive experiments on a large video dataset collected from multiple sources. The experimental results reveal that our proposed recommender model and feature fusion method outperform the state-of-the-art methods. version:1
arxiv-1612-06933 | Unsupervised Place Discovery for Visual Place Classification | http://arxiv.org/abs/1612.06933 | id:1612.06933 author:Fei Xiaoxiao, Tanaka Kanji, Inamoto Kouya category:cs.CV  published:2016-12-21 summary:In this study, we explore the use of deep convolutional neural networks (DCNNs) in visual place classification for robotic mapping and localization. An open question is how to partition the robot's workspace into places to maximize the performance (e.g., accuracy, precision, recall) of potential DCNN classifiers. This is a chicken and egg problem: If we had a well-trained DCNN classifier, it is rather easy to partition the robot's workspace into places, but the training of a DCNN classifier requires a set of pre-defined place classes. In this study, we address this problem and present several strategies for unsupervised discovery of place classes ("time cue," "location cue," "time-appearance cue," and "location-appearance cue"). We also evaluate the efficacy of the proposed methods using the publicly available University of Michigan North Campus Long-Term (NCLT) Dataset. version:1
arxiv-1612-06919 | A Statistical Approach to Continuous Self-Calibrating Eye Gaze Tracking for Head-Mounted Virtual Reality Systems | http://arxiv.org/abs/1612.06919 | id:1612.06919 author:Subarna Tripathi, Brian Guenter category:cs.CV  published:2016-12-20 summary:We present a novel, automatic eye gaze tracking scheme inspired by smooth pursuit eye motion while playing mobile games or watching virtual reality contents. Our algorithm continuously calibrates an eye tracking system for a head mounted display. This eliminates the need for an explicit calibration step and automatically compensates for small movements of the headset with respect to the head. The algorithm finds correspondences between corneal motion and screen space motion, and uses these to generate Gaussian Process Regression models. A combination of those models provides a continuous mapping from corneal position to screen space position. Accuracy is nearly as good as achieved with an explicit calibration step. version:1
arxiv-1612-06897 | Fast Domain Adaptation for Neural Machine Translation | http://arxiv.org/abs/1612.06897 | id:1612.06897 author:Markus Freitag, Yaser Al-Onaizan category:cs.CL  published:2016-12-20 summary:Neural Machine Translation (NMT) is a new approach for automatic translation of text from one human language into another. The basic concept in NMT is to train a large Neural Network that maximizes the translation performance on a given parallel corpus. NMT is gaining popularity in the research community because it outperformed traditional SMT approaches in several translation tasks at WMT and other evaluation tasks/benchmarks at least for some language pairs. However, many of the enhancements in SMT over the years have not been incorporated into the NMT framework. In this paper, we focus on one such enhancement namely domain adaptation. We propose an approach for adapting a NMT system to a new domain. The main idea behind domain adaptation is that the availability of large out-of-domain training data and a small in-domain training data. We report significant gains with our proposed method in both automatic metrics and a human subjective evaluation metric on two language pairs. With our adaptation method, we show large improvement on the new domain while the performance of our general domain only degrades slightly. In addition, our approach is fast enough to adapt an already trained system to a new domain within few hours without the need to retrain the NMT model on the combined data which usually takes several days/weeks depending on the volume of the data. version:1
arxiv-1612-06890 | CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning | http://arxiv.org/abs/1612.06890 | id:1612.06890 author:Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C. Lawrence Zitnick, Ross Girshick category:cs.CV cs.CL cs.LG  published:2016-12-20 summary:When building artificial intelligence systems that can reason and answer questions about visual data, we need diagnostic tests to analyze our progress and discover shortcomings. Existing benchmarks for visual question answering can help, but have strong biases that models can exploit to correctly answer questions without reasoning. They also conflate multiple sources of error, making it hard to pinpoint model weaknesses. We present a diagnostic dataset that tests a range of visual reasoning abilities. It contains minimal biases and has detailed annotations describing the kind of reasoning each question requires. We use this dataset to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations. version:1
arxiv-1612-06851 | Beyond Skip Connections: Top-Down Modulation for Object Detection | http://arxiv.org/abs/1612.06851 | id:1612.06851 author:Abhinav Shrivastava, Rahul Sukthankar, Jitendra Malik, Abhinav Gupta category:cs.CV cs.LG  published:2016-12-20 summary:In recent years, we have seen tremendous progress in the field of object detection. Most of the recent improvements have been achieved by targeting deeper feedforward networks. However, many hard object categories, such as bottle and remote, require representation of fine details and not coarse, semantic representations. But most of these fine details are lost in the early convolutional layers. What we need is a way to incorporate finer details from lower layers into the detection architecture. Skip connections have been proposed to combine high-level and low-level features, but we argue that selecting the right features from low-level requires top-down contextual information. Inspired by the human visual pathway, in this paper we propose top-down modulations as a way to incorporate fine details into the detection framework. Our approach supplements the standard bottom-up, feedforward ConvNet with a top-down modulation (TDM) network, connected using lateral connections. These connections are responsible for the modulation of lower layer filters, and the top-down network handles the selection and integration of features. The proposed architecture provides a significant boost on the COCO benchmark for VGG16, ResNet101, and InceptionResNet-v2 architectures. Preliminary experiments using InceptionResNet-v2 achieve 36.8 AP, which is the best performance to-date on the COCO benchmark using a single-model without any bells and whistles (e.g., multi-scale, iterative box refinement, etc.). version:1
arxiv-1612-06836 | Understanding Higher-Order Shape via 3D Shape Attributes | http://arxiv.org/abs/1612.06836 | id:1612.06836 author:David F. Fouhey, Abhinav Gupta, Andrew Zisserman category:cs.CV  published:2016-12-20 summary:In this paper we investigate 3D shape attributes as a means to understand the shape of an object in a single image. To this end, we make a number of contributions: (i) we introduce and define a set of 3D shape attributes, including planarity, symmetry and occupied space; (ii) we show that such properties can be successfully inferred from a single image using a Convolutional Neural Network (CNN); (iii) we introduce a 143K image dataset of sculptures with 2197 works over 242 artists for training and evaluating the CNN; (iv) we show that the 3D attributes trained on this dataset generalize to images of other (non-sculpture) object classes; (v) we show that the CNN also provides a shape embedding that can be used to match previously unseen sculptures largely independent of viewpoint; and furthermore (vi) we analyze how the CNN predicts these attributes. version:1
arxiv-1612-06825 | Center-Focusing Multi-task CNN with Injected Features for Classification of Glioma Nuclear Images | http://arxiv.org/abs/1612.06825 | id:1612.06825 author:Veda Murthy, Le Hou, Dimitris Samaras, Tahsin M. Kurc, Joel H. Saltz category:cs.CV  published:2016-12-20 summary:Classifying the various shapes and attributes of a glioma cell nucleus is crucial for diagnosis and understanding the disease. We investigate automated classification of glioma nuclear shapes and visual attributes using Convolutional Neural Networks (CNNs) on pathology images of automatically segmented nuclei. We propose three methods that improve the performance of a previously-developed semi-supervised CNN. First, we propose a method that allows the CNN to focus on the most important part of an image- the image's center containing the nucleus. Second, we inject (concatenate) pre-extracted VGG features into an intermediate layer of our Semi-Supervised CNN so that during training, the CNN can learn a set of complementary features. Third, we separate the losses of the two groups of target classes (nuclear shapes and attributes) into a single-label loss and a multi-label loss so that the prior knowledge of inter-label exclusiveness can be incorporated. On a dataset of 2078 images, the proposed methods combined reduce the error rate of attribute and shape classification by 21.54% and 15.07% respectively compared to the existing state-of-the-art method on the same dataset. version:1
arxiv-1612-06821 | User Bias Removal in Fine Grained Sentiment Analysis | http://arxiv.org/abs/1612.06821 | id:1612.06821 author:Rahul Wadbude, Vivek Gupta, Dheeraj Mekala, Janish Jindal, Harish Karnick category:cs.CL  published:2016-12-20 summary:Fine-grained sentiment analysis of text reviews has recently gained a lot of attention in the natural language processing community. Most work done earlier focuses on creating efficient feature representations of text reviews for classification. The methods generally ignore other common attributes like user identity, product identity, and helpfulness rating during fine-grained sentiment classification. A major problem in current classification models is noise due to the presence of user bias in review ratings. We propose two simple statistical methods to remove such noise and improve fine-grained sentiment classification. We apply our methods on the SNAP published Amazon Fine Food Reviews dataset and on two major categories Electronics and Movies and TV of the e-Commerce Reviews data-set. After removing user bias, we get improved fine-grained sentiment classification with three commonly used feature representations. version:1
arxiv-1612-06795 | Two decades of local binary patterns: A survey | http://arxiv.org/abs/1612.06795 | id:1612.06795 author:Matti Pietikäinen, Guoying Zhao category:cs.CV  published:2016-12-20 summary:Texture is an important characteristic for many types of images. In recent years very discriminative and computationally efficient local texture descriptors based on local binary patterns (LBP) have been developed, which has led to significant progress in applying texture methods to different problems and applications. Due to this progress, the division between texture descriptors and more generic image or video descriptors has been disappearing. A large number of different variants of LBP have been developed to improve its robustness, and to increase its discriminative power and applicability to different types of problems. In this chapter, the most recent and important variants of LBP in 2D, spatiotemporal, 3D, and 4D domains are surveyed. Interesting new developments of LBP in 1D signal analysis are also considered. Finally, some future challenges for research are presented. version:1
arxiv-1612-06778 | Text classification with sparse composite document vectors | http://arxiv.org/abs/1612.06778 | id:1612.06778 author:Dheeraj Mekala, Vivek Gupta, Harish Karnick category:cs.CL  published:2016-12-20 summary:In this work, we present a modified feature formation technique - graded-weighted Bag of Word Vectors (gwBoWV) by Vivek Gupta, 2016 for faster and better composite document feature representation. We propose a very simple feature construction algorithm that potentially overcomes many weaknesses in current distributional vector representations and other composite document representation methods widely used for text representation. Through extensive experiments on multi-class classification on 20newsgroup dataset and multi-label text classification on Reuters-21578, we achieve better performance results and also a significant reduction in training and prediction time compared to composite document representation methods gwBoWV and TWE Liu et al., 2015b. version:1
arxiv-1612-06738 | Local Sparse Approximation for Image Restoration with Adaptive Block Size Selection | http://arxiv.org/abs/1612.06738 | id:1612.06738 author:Sujit Kumar Sahoo category:cs.CV cs.IR stat.AP  published:2016-12-20 summary:In this paper the problem of image restoration (denoising and inpainting) is approached using sparse approximation of local image blocks. The local image blocks are extracted by sliding square windows over the image. An adaptive block size selection procedure for local sparse approximation is proposed, which affects the global recovery of underlying image. Ideally the adaptive local block selection yields the minimum mean square error (MMSE) in recovered image. This framework gives us a clustered image based on the selected block size, then each cluster is restored separately using sparse approximation. The results obtained using the proposed framework are very much comparable with the recently proposed image restoration techniques. version:1
arxiv-1612-06704 | Action-Driven Object Detection with Top-Down Visual Attentions | http://arxiv.org/abs/1612.06704 | id:1612.06704 author:Donggeun Yoo, Sunggyun Park, Kyunghyun Paeng, Joon-Young Lee, In So Kweon category:cs.CV cs.AI cs.LG  published:2016-12-20 summary:A dominant paradigm for deep learning based object detection relies on a "bottom-up" approach using "passive" scoring of class agnostic proposals. These approaches are efficient but lack of holistic analysis of scene-level context. In this paper, we present an "action-driven" detection mechanism using our "top-down" visual attention model. We localize an object by taking sequential actions that the attention model provides. The attention model conditioned with an image region provides required actions to get closer toward a target object. An action at each time step is weak itself but an ensemble of the sequential actions makes a bounding-box accurately converge to a target object boundary. This attention model we call AttentionNet is composed of a convolutional neural network. During our whole detection procedure, we only utilize the actions from a single AttentionNet without any modules for object proposals nor post bounding-box regression. We evaluate our top-down detection mechanism over the PASCAL VOC series and ILSVRC CLS-LOC dataset, and achieve state-of-the-art performances compared to the major bottom-up detection methods. In particular, our detection mechanism shows a strong advantage in elaborate localization by outperforming Faster R-CNN with a margin of +7.1% over PASCAL VOC 2007 when we increase the IoU threshold for positive detection to 0.7. version:1
arxiv-1612-06703 | Dynamic Action Recognition: A convolutional neural network model for temporally organized joint location data | http://arxiv.org/abs/1612.06703 | id:1612.06703 author:Adhavan Jayabalan, Harish Karunakaran, Shravan Murlidharan, Tesia Shizume category:cs.CV  published:2016-12-20 summary:Motivation: Recognizing human actions in a video is a challenging task which has applications in various fields. Previous works in this area have either used images from a 2D or 3D camera. Few have used the idea that human actions can be easily identified by the movement of the joints in the 3D space and instead used a Recurrent Neural Network (RNN) for modeling. Convolutional neural networks (CNN) have the ability to recognise even the complex patterns in data which makes it suitable for detecting human actions. Thus, we modeled a CNN which can predict the human activity using the joint data. Furthermore, using the joint data representation has the benefit of lower dimensionality than image or video representations. This makes our model simpler and faster than the RNN models. In this study, we have developed a six layer convolutional network, which reduces each input feature vector of the form 15x1961x4 to an one dimensional binary vector which gives us the predicted activity. Results: Our model is able to recognise an activity correctly upto 87% accuracy. Joint data is taken from the Cornell Activity Datasets which have day to day activities like talking, relaxing, eating, cooking etc. version:1
arxiv-1612-07117 | Classification and Learning-to-rank Approaches for Cross-Device Matching at CIKM Cup 2016 | http://arxiv.org/abs/1612.07117 | id:1612.07117 author:Nam Khanh Tran category:cs.IR cs.LG  published:2016-12-20 summary:In this paper, we propose two methods for tackling the problem of cross-device matching for online advertising at CIKM Cup 2016. The first method considers the matching problem as a binary classification task and solve it by utilizing ensemble learning techniques. The second method defines the matching problem as a ranking task and effectively solve it with using learning-to-rank algorithms. The results show that the proposed methods obtain promising results, in which the ranking-based method outperforms the classification-based method for the task. version:1
arxiv-1612-06685 | Stateology: State-Level Interactive Charting of Language, Feelings, and Values | http://arxiv.org/abs/1612.06685 | id:1612.06685 author:Konstantinos Pappas, Steven Wilson, Rada Mihalcea category:cs.CL  published:2016-12-20 summary:People's personality and motivations are manifest in their everyday language usage. With the emergence of social media, ample examples of such usage are procurable. In this paper, we aim to analyze the vocabulary used by close to 200,000 Blogger users in the U.S. with the purpose of geographically portraying various demographic, linguistic, and psychological dimensions at the state level. We give a description of a web-based tool for viewing maps that depict various characteristics of the social media users as derived from this large blog dataset of over two billion words. version:1
arxiv-1612-06671 | Inferring the location of authors from words in their texts | http://arxiv.org/abs/1612.06671 | id:1612.06671 author:Max Berggren, Jussi Karlgren, Robert Östling, Mikael Parkvall category:cs.CL H.3.1; I.2.7  published:2016-12-20 summary:For the purposes of computational dialectology or other geographically bound text analysis tasks, texts must be annotated with their or their authors' location. Many texts are locatable through explicit labels but most have no explicit annotation of place. This paper describes a series of experiments to determine how positionally annotated microblog posts can be used to learn location-indicating words which then can be used to locate blog texts and their authors. A Gaussian distribution is used to model the locational qualities of words. We introduce the notion of placeness to describe how locational words are. We find that modelling word distributions to account for several locations and thus several Gaussian distributions per word, defining a filter which picks out words with high placeness based on their local distributional context, and aggregating locational information in a centroid for each text gives the most useful results. The results are applied to data in the Swedish language. version:1
arxiv-1612-06669 | Enhancing Observability in Distribution Grids using Smart Meter Data | http://arxiv.org/abs/1612.06669 | id:1612.06669 author:Siddharth Bhela, Vassilis Kekatos, Sriharsha Veeramachaneni category:math.OC cs.LG stat.ML  published:2016-12-20 summary:Due to limited metering infrastructure, distribution grids are currently challenged by observability issues. On the other hand, smart meter data, including local voltage magnitudes and power injections, are communicated to the utility operator from grid buses with renewable generation and demand-response programs. This work employs grid data from metered buses towards inferring the underlying grid state. To this end, a coupled formulation of the power flow problem (CPF) is put forth. Exploiting the high variability of injections at metered buses, the controllability of solar inverters, and the relative time-invariance of conventional loads, the idea is to solve the non-linear power flow equations jointly over consecutive time instants. An intuitive and easily verifiable rule pertaining to the locations of metered and non-metered buses on the physical grid is shown to be a necessary and sufficient criterion for local observability in radial networks. To account for noisy smart meter readings, a coupled power system state estimation (CPSSE) problem is further developed. Both CPF and CPSSE tasks are tackled via augmented semi-definite program relaxations. The observability criterion along with the CPF and CPSSE solvers are numerically corroborated using synthetic and actual solar generation and load data on the IEEE 34-bus benchmark feeder. version:1
arxiv-1612-06650 | Partially blind domain adaptation for age prediction from DNA methylation data | http://arxiv.org/abs/1612.06650 | id:1612.06650 author:Lisa Handl, Adrin Jalali, Michael Scherer, Nico Pfeifer category:q-bio.QM stat.ML  published:2016-12-20 summary:Over the last years, huge resources of biological and medical data have become available for research. This data offers great chances for machine learning applications in health care, e.g. for precision medicine, but is also challenging to analyze. Typical challenges include a large number of possibly correlated features and heterogeneity in the data. One flourishing field of biological research in which this is relevant is epigenetics. Here, especially large amounts of DNA methylation data have emerged. This epigenetic mark has been used to predict a donor's 'epigenetic age' and increased epigenetic aging has been linked to lifestyle and disease history. In this paper we propose an adaptive model which performs feature selection for each test sample individually based on the distribution of the input data. The method can be seen as partially blind domain adaptation. We apply the model to the problem of age prediction based on DNA methylation data from a variety of tissues, and compare it to a standard model, which does not take heterogeneity into account. The standard approach has particularly bad performance on one tissue type on which we show substantial improvement with our new adaptive approach even though no samples of that tissue were part of the training data. version:1
arxiv-1612-06623 | Supervised Learning for Optimal Power Flow as a Real-Time Proxy | http://arxiv.org/abs/1612.06623 | id:1612.06623 author:Raphael Canyasse, Gal Dalal, Shie Mannor category:cs.LG  published:2016-12-20 summary:In this work we design and compare different supervised learning algorithms to compute the cost of Alternating Current Optimal Power Flow (ACOPF). The motivation for quick calculation of OPF cost outcomes stems from the growing need of algorithmic-based long-term and medium-term planning methodologies in power networks. Integrated in a multiple time-horizon coordination framework, we refer to this approximation module as a proxy for predicting short-term decision outcomes without the need of actual simulation and optimization of them. Our method enables fast approximate calculation of OPF cost with less than 1% error on average, achieved in run-times that are several orders of magnitude lower than of exact computation. Several test-cases such as IEEE-RTS96 are used to demonstrate the efficiency of our approach. version:1
arxiv-1612-06615 | Deep Motion Features for Visual Tracking | http://arxiv.org/abs/1612.06615 | id:1612.06615 author:Susanna Gladh, Martin Danelljan, Fahad Shahbaz Khan, Michael Felsberg category:cs.CV  published:2016-12-20 summary:Robust visual tracking is a challenging computer vision problem, with many real-world applications. Most existing approaches employ hand-crafted appearance features, such as HOG or Color Names. Recently, deep RGB features extracted from convolutional neural networks have been successfully applied for tracking. Despite their success, these features only capture appearance information. On the other hand, motion cues provide discriminative and complementary information that can improve tracking performance. Contrary to visual tracking, deep motion features have been successfully applied for action recognition and video classification tasks. Typically, the motion features are learned by training a CNN on optical flow images extracted from large amounts of labeled videos. This paper presents an investigation of the impact of deep motion features in a tracking-by-detection framework. We further show that hand-crafted, deep RGB, and deep motion features contain complementary information. To the best of our knowledge, we are the first to propose fusing appearance information with deep motion features for visual tracking. Comprehensive experiments clearly suggest that our fusion approach with deep motion features outperforms standard methods relying on appearance information alone. version:1
arxiv-1612-06598 | WoCE: a framework for clustering ensemble by exploiting the wisdom of Crowds theory | http://arxiv.org/abs/1612.06598 | id:1612.06598 author:Muhammad Yousefnezhad, Sheng-Jun Huang, Daoqiang Zhang category:stat.ML cs.LG  published:2016-12-20 summary:The Wisdom of Crowds (WOC), as a theory in the social science, gets a new paradigm in computer science. The WOC theory explains that the aggregate decision made by a group is often better than those of its individual members if specific conditions are satisfied. This paper presents a novel framework for unsupervised and semi-supervised cluster ensemble by exploiting the WOC theory. We employ four conditions in the WOC theory, i.e., diversity, independency, decentralization and aggregation, to guide both the constructing of individual clustering results and the final combination for clustering ensemble. Firstly, independency criterion, as a novel mapping system on the raw data set, removes the correlation between features on our proposed method. Then, decentralization as a novel mechanism generates high-quality individual clustering results. Next, uniformity as a new diversity metric evaluates the generated clustering results. Further, weighted evidence accumulation clustering method is proposed for the final aggregation without using thresholding procedure. Experimental study on varied data sets demonstrates that the proposed approach achieves superior performance to state-of-the-art methods. version:1
arxiv-1612-06581 | Grammar rules for the isiZulu complex verb | http://arxiv.org/abs/1612.06581 | id:1612.06581 author:C. Maria Keet, Langa Khumalo category:cs.CL I.2.7  published:2016-12-20 summary:The isiZulu verb is known for its morphological complexity, which is a subject for on-going linguistics research, as well as for prospects of computational use, such as controlled natural language interfaces, machine translation, and spellcheckers. To this end, we seek to answer the question as to what the precise grammar rules for the isiZulu complex verb are (and, by extension, the Bantu verb morphology). To this end, we iteratively specify the grammar as a Context Free Grammar, and evaluate it computationally. The grammar presented in this paper covers the subject and object concords, negation, present tense, aspect, mood, and the causative, applicative, stative, and the reciprocal verbal extensions, politeness, the wh-question modifiers, and aspect doubling, ensuring their correct order as they appear in verbs. The grammar conforms to specification. version:1
arxiv-1612-06573 | Detecting Unexpected Obstacles for Self-Driving Cars: Fusing Deep Learning and Geometric Modeling | http://arxiv.org/abs/1612.06573 | id:1612.06573 author:Sebastian Ramos, Stefan Gehrig, Peter Pinggera, Uwe Franke, Carsten Rother category:cs.CV cs.RO  published:2016-12-20 summary:The detection of small road hazards, such as lost cargo, is a vital capability for self-driving cars. We tackle this challenging and rarely addressed problem with a vision system that leverages appearance, contextual as well as geometric cues. To utilize the appearance and contextual cues, we propose a new deep learning-based obstacle detection framework. Here a variant of a fully convolutional network is used to predict a pixel-wise semantic labeling of (i) free-space, (ii) on-road unexpected obstacles, and (iii) background. The geometric cues are exploited using a state-of-the-art detection approach that predicts obstacles from stereo input images via model-based statistical hypothesis tests. We present a principled Bayesian framework to fuse the semantic and stereo-based detection results. The mid-level Stixel representation is used to describe obstacles in a flexible, compact and robust manner. We evaluate our new obstacle detection system on the Lost and Found dataset, which includes very challenging scenes with obstacles of only 5 cm height. Overall, we report a major improvement over the state-of-the-art, with relative performance gains of up to 50%. In particular, we achieve a detection rate of over 90% for distances of up to 50 m. Our system operates at 22 Hz on our self-driving platform. version:1
arxiv-1612-06572 | Unsupervised Dialogue Act Induction using Gaussian Mixtures | http://arxiv.org/abs/1612.06572 | id:1612.06572 author:Tomáš Brychcín, Pavel Král category:cs.CL  published:2016-12-20 summary:This paper introduces a new unsupervised approach for dialogue act induction. Given the sequence of dialogue utterances, the task is to assign them the labels representing their function in the dialogue. Utterances are represented as real-valued vectors encoding their meaning. We model the dialogue as Hidden Markov model with emission probabilities estimated by Gaussian mixtures. We use Gibbs sampling for posterior inference. We present the results on the standard Switchboard-DAMSL corpus. Our algorithm achieves promising results compared with strong supervised baselines and outperforms other unsupervised algorithms. version:1
arxiv-1612-06565 | RIDS: Robust Identification of Sparse Gene Regulatory Networks from Perturbation Experiments | http://arxiv.org/abs/1612.06565 | id:1612.06565 author:Hoi-To Wai, Anna Scaglione, Uzi Harush, Baruch Barzel, Amir Leshem category:q-bio.QM cs.IT math.IT q-bio.MN stat.ML  published:2016-12-20 summary:Reconstructing the causal network in a complex dynamical system plays a crucial role in many applications, from sub-cellular biology to economic systems. Here we focus on inferring gene regulation networks (GRNs) from perturbation or gene deletion experiments. Despite their scientific merit, such perturbation experiments are not often used for such inference due to their costly experimental procedure, requiring significant resources to complete the measurement of every single experiment. To overcome this challenge, we develop the Robust IDentification of Sparse networks (RIDS) method that reconstructs the GRN from a small number of perturbation experiments. Our method uses the gene expression data observed in each experiment and translates that into a steady state condition of the system's nonlinear interaction dynamics. Applying a sparse optimization criterion, we are able to extract the parameters of the underlying weighted network, even from very few experiments. In fact, we demonstrate analytically that, under certain conditions, the GRN can be perfectly reconstructed using $K = \Omega (d_{max})$ perturbation experiments, where $d_{max}$ is the maximum in-degree of the GRN, a small value for realistic sparse networks, indicating that RIDS can achieve high performance with a scalable number of experiments. We test our method on both synthetic and experimental data extracted from the DREAM5 network inference challenge. We show that the RIDS achieves superior performance compared to the state-of-the-art methods, while requiring as few as ~60% less experimental data. Moreover, as opposed to almost all competing methods, RIDS allows us to infer the directionality of the GRN links, allowing us to infer empirical GRNs, without relying on the commonly provided list of transcription factors. version:1
arxiv-1612-06558 | End-to-End Pedestrian Collision Warning System based on a Convolutional Neural Network with Semantic Segmentation | http://arxiv.org/abs/1612.06558 | id:1612.06558 author:Heechul Jung, Min-Kook Choi, Kwon Soon, Woo Young Jung category:cs.CV  published:2016-12-20 summary:Traditional pedestrian collision warning systems sometimes raise alarms even when there is no danger (e.g., when all pedestrians are walking on the sidewalk). These false alarms can make it difficult for drivers to concentrate on their driving. In this paper, we propose a novel framework for an end-to-end pedestrian collision warning system based on a convolutional neural network. Semantic segmentation information is used to train the convolutional neural network and two loss functions, such as cross entropy and Euclidean losses, are minimized. Finally, we demonstrate the effectiveness of our method in reducing false alarms and increasing warning accuracy compared to a traditional histogram of oriented gradients (HoG)-based system. version:1
arxiv-1612-06549 | Exploring Different Dimensions of Attention for Uncertainty Detection | http://arxiv.org/abs/1612.06549 | id:1612.06549 author:Heike Adel, Hinrich Schütze category:cs.CL  published:2016-12-20 summary:Neural networks with attention have proven effective for many natural language processing tasks. In this paper, we develop attention mechanisms for uncertainty detection. In particular, we generalize standardly used attention mechanisms by introducing external attention and sequence-preserving attention. These novel architectures differ from standard approaches in that they use external resources to compute attention weights and preserve sequence information. We compare them to other configurations along different dimensions of attention. Our novel architectures set the new state of the art on a Wikipedia benchmark dataset and perform similar to the state-of-the-art model on a biomedical benchmark which uses a large set of linguistic features. version:1
arxiv-1612-06543 | Wide-Slice Residual Networks for Food Recognition | http://arxiv.org/abs/1612.06543 | id:1612.06543 author:Niki Martinel, Gian Luca Foresti, Christian Micheloni category:cs.CV  published:2016-12-20 summary:Food diary applications represent a tantalizing market. Such applications, based on image food recognition, opened to new challenges for computer vision and pattern recognition algorithms. Recent works in the field are focusing either on hand-crafted representations or on learning these by exploiting deep neural networks. Despite the success of such a last family of works, these generally exploit off-the shelf deep architectures to classify food dishes. Thus, the architectures are not cast to the specific problem. We believe that better results can be obtained if the deep architecture is defined with respect to an analysis of the food composition. Following such an intuition, this work introduces a new deep scheme that is designed to handle the food structure. Specifically, inspired by the recent success of residual deep network, we exploit such a learning scheme and introduce a slice convolution block to capture the vertical food layers. Outputs of the deep residual blocks are combined with the sliced convolution to produce the classification score for specific food categories. To evaluate our proposed architecture we have conducted experimental results on three benchmark datasets. Results demonstrate that our solution shows better performance with respect to existing approaches (e.g., a top-1 accuracy of 90.27% on the Food-101 challenging dataset). version:1
arxiv-1612-06530 | Automatic Generation of Grounded Visual Questions | http://arxiv.org/abs/1612.06530 | id:1612.06530 author:Shijie Zhang, Lizhen Qu, Shaodi You, Zhenglu Yang, Jiawan Zhang category:cs.CV cs.CL  published:2016-12-20 summary:In this paper, we propose a new task and solution for vision and language: generation of grounded visual questions. Visual question answering (VQA) is an emerging topic which links textual questions with visual input. To the best of our knowledge, it lacks automatic method to generate reasonable and versatile questions. So far, almost all the textual questions are generated manually, as well as the corresponding answers. To this end, we propose a system that automatically generates visually grounded questions . First, visual input is analyzed with deep caption model. Second, the captions along with VGG-16 features are used as input for our proposed question generator to generate visually grounded questions. Finally, to enable generating of versatile questions, a question type selection module is provided which selects reasonable question types and provide them as parameters for question generation. This is done using a hybrid LSTM with both visual and answer input. Our system is trained using VQA and Visual7W dataset and shows reasonable results on automatically generating of new visual questions. We also propose a quantitative metric for automatic evaluation of the question quality. version:1
arxiv-1612-06524 | 3D Human Pose Estimation = 2D Pose Estimation + Matching | http://arxiv.org/abs/1612.06524 | id:1612.06524 author:Ching-Hang Chen, Deva Ramanan category:cs.CV  published:2016-12-20 summary:We explore 3D human pose estimation from a single RGB image. While many approaches try to directly predict 3D pose from image measurements, we explore a simple architecture that reasons through intermediate 2D pose predictions. Our approach is based on two key observations (1) Deep neural nets have revolutionized 2D pose estimation, producing accurate 2D predictions even for poses with self occlusions. (2) Big-data sets of 3D mocap data are now readily available, making it tempting to lift predicted 2D poses to 3D through simple memorization (e.g., nearest neighbors). The resulting architecture is trivial to implement with off-the-shelf 2D pose estimation systems and 3D mocap libraries. Importantly, we demonstrate that such methods outperform almost all state-of-the-art 3D pose estimation systems, most of which directly try to regress 3D pose from 2D measurements. version:1
arxiv-1612-06519 | Exploring the Design Space of Deep Convolutional Neural Networks at Large Scale | http://arxiv.org/abs/1612.06519 | id:1612.06519 author:Forrest Iandola category:cs.CV cs.LG cs.NE  published:2016-12-20 summary:In recent years, the research community has discovered that deep neural networks (DNNs) and convolutional neural networks (CNNs) can yield higher accuracy than all previous solutions to a broad array of machine learning problems. To our knowledge, there is no single CNN/DNN architecture that solves all problems optimally. Instead, the "right" CNN/DNN architecture varies depending on the application at hand. CNN/DNNs comprise an enormous design space. Quantitatively, we find that a small region of the CNN design space contains 30 billion different CNN architectures. In this dissertation, we develop a methodology that enables systematic exploration of the design space of CNNs. Our methodology is comprised of the following four themes. 1. Judiciously choosing benchmarks and metrics. 2. Rapidly training CNN models. 3. Defining and describing the CNN design space. 4. Exploring the design space of CNN architectures. Taken together, these four themes comprise an effective methodology for discovering the "right" CNN architectures to meet the needs of practical applications. version:1
arxiv-1612-06508 | Deeply Aggregated Alternating Minimization for Image Restoration | http://arxiv.org/abs/1612.06508 | id:1612.06508 author:Youngjung Kim, Hyungjoo Jung, Dongbo Min, Kwanghoon Sohn category:cs.CV  published:2016-12-20 summary:Regularization-based image restoration has remained an active research topic in computer vision and image processing. It often leverages a guidance signal captured in different fields as an additional cue. In this work, we present a general framework for image restoration, called deeply aggregated alternating minimization (DeepAM). We propose to train deep neural network to advance two of the steps in the conventional AM algorithm: proximal mapping and ?- continuation. Both steps are learned from a large dataset in an end-to-end manner. The proposed framework enables the convolutional neural networks (CNNs) to operate as a prior or regularizer in the AM algorithm. We show that our learned regularizer via deep aggregation outperforms the recent data-driven approaches as well as the nonlocalbased methods. The flexibility and effectiveness of our framework are demonstrated in several image restoration tasks, including single image denoising, RGB-NIR restoration, and depth super-resolution. version:1
arxiv-1612-06496 | Efficiently Computing Piecewise Flat Embeddings for Data Clustering and Image Segmentation | http://arxiv.org/abs/1612.06496 | id:1612.06496 author:Renee T. Meinhold, Tyler L. Hayes, Nathan D. Cahill category:cs.CV  published:2016-12-20 summary:Image segmentation is a popular area of research in computer vision that has many applications in automated image processing. A recent technique called piecewise flat embeddings (PFE) has been proposed for use in image segmentation; PFE transforms image pixel data into a lower dimensional representation where similar pixels are pulled close together and dissimilar pixels are pushed apart. This technique has shown promising results, but its original formulation is not computationally feasible for large images. We propose two improvements to the algorithm for computing PFE: first, we reformulate portions of the algorithm to enable various linear algebra operations to be performed in parallel; second, we propose utilizing an iterative linear solver (preconditioned conjugate gradient) to quickly solve a linear least-squares problem that occurs in the inner loop of a nested iteration. With these two computational improvements, we show on a publicly available image database that PFE can be sped up by an order of magnitude without sacrificing segmentation performance. Our results make this technique more practical for use on large data sets, not only for image segmentation, but for general data clustering problems. version:1
arxiv-1612-06043 | Reducing Redundant Computations with Flexible Attention | http://arxiv.org/abs/1612.06043 | id:1612.06043 author:Raphael Shu, Hideki Nakayama category:cs.CL cs.AI  published:2016-12-19 summary:Recently, attention mechanism plays a key role to achieve high performance for Neural Machine Translation models. It applies a score function to the encoder states to obtain alignment weights. However, as this computation is done for all positions in each decoding step, the attention mechanism greatly increases the computational complexity. In this paper we propose a novel attention model which can reduce redundant attentional computations in a flexible manner. The proposed mechanism tracks the center of attention in each decoding step, and computes position-based penalties. In the test time, the computations of the score function for heavily penalized positions are skipped. In our experiments, we found that the computations in the attention model can be reduced by 54% in average with almost no loss of accuracy. version:2
arxiv-1612-06475 | Span-Based Constituency Parsing with a Structure-Label System and Provably Optimal Dynamic Oracles | http://arxiv.org/abs/1612.06475 | id:1612.06475 author:James Cross, Liang Huang category:cs.CL  published:2016-12-20 summary:Parsing accuracy using efficient greedy transition systems has improved dramatically in recent years thanks to neural networks. Despite striking results in dependency parsing, however, neural models have not surpassed state-of-the-art approaches in constituency parsing. To remedy this, we introduce a new shift-reduce system whose stack contains merely sentence spans, represented by a bare minimum of LSTM features. We also design the first provably optimal dynamic oracle for constituency parsing, which runs in amortized O(1) time, compared to O(n^3) oracles for standard dependency parsing. Training with this oracle, we achieve the best F1 scores on both English and French of any parser that does not use reranking or external data. version:1
arxiv-1612-06470 | Randomized Clustered Nystrom for Large-Scale Kernel Machines | http://arxiv.org/abs/1612.06470 | id:1612.06470 author:Farhad Pourkamali-Anaraki, Stephen Becker category:stat.ML cs.LG  published:2016-12-20 summary:The Nystrom method has been popular for generating the low-rank approximation of kernel matrices that arise in many machine learning problems. The approximation quality of the Nystrom method depends crucially on the number of selected landmark points and the selection procedure. In this paper, we present a novel algorithm to compute the optimal Nystrom low-approximation when the number of landmark points exceed the target rank. Moreover, we introduce a randomized algorithm for generating landmark points that is scalable to large-scale data sets. The proposed method performs K-means clustering on low-dimensional random projections of a data set and, thus, leads to significant savings for high-dimensional data sets. Our theoretical results characterize the tradeoffs between the accuracy and efficiency of our proposed method. Extensive experiments demonstrate the competitive performance as well as the efficiency of our proposed method. version:1
arxiv-1612-06454 | Exploring Structure for Long-Term Tracking of Multiple Objects in Sports Videos | http://arxiv.org/abs/1612.06454 | id:1612.06454 author:Henrique Morimitsu, Isabelle Bloch, Roberto M. Cesar-Jr category:cs.CV  published:2016-12-19 summary:In this paper, we propose a novel approach for exploiting structural relations to track multiple objects that may undergo long-term occlusion and abrupt motion. We use a model-free approach that relies only on annotations given in the first frame of the video to track all the objects online, i.e. without knowledge from future frames. We initialize a probabilistic Attributed Relational Graph (ARG) from the first frame, which is incrementally updated along the video. Instead of using the structural information only to evaluate the scene, the proposed approach considers it to generate new tracking hypotheses. In this way, our method is capable of generating relevant object candidates that are used to improve or recover the track of lost objects. The proposed method is evaluated on several videos of table tennis, volleyball, and on the ACASVA dataset. The results show that our approach is very robust, flexible and able to outperform other state-of-the-art methods in sports videos that present structural patterns. version:1
arxiv-1612-06443 | Binary Distance Transform to Improve Feature Extraction | http://arxiv.org/abs/1612.06443 | id:1612.06443 author:Mariane Barros Neiva, Antoine Manzanera, Odemir Martinez Bruno category:cs.CV  published:2016-12-19 summary:To recognize textures many methods have been developed along the years. However, texture datasets may be hard to be classified due to artefacts such as a variety of scale, illumination and noise. This paper proposes the application of binary distance transform on the original dataset to add information to texture representation and consequently improve recognition. Texture images, usually in grayscale, suffers a binarization prior to distance transform and one of the resulted images are combined with original texture to improve the amount of information. Four datasets are used to evaluate our approach. For Outex dataset, for instance, the proposal outperforms all rates, improvements of an up to 10\%, compared to traditional approach where descriptors are applied on the original dataset, showing the importance of this approach. version:1
arxiv-1612-06435 | Fractal Descriptors of Texture Images Based on the Triangular Prism Dimension | http://arxiv.org/abs/1612.06435 | id:1612.06435 author:João B. Florindo, Odemir M. Bruno category:cs.CV  published:2016-12-19 summary:This work presents a novel descriptor for texture images based on fractal geometry and its application to image analysis. The descriptors are provided by estimating the triangular prism fractal dimension under different scales with a weight exponential parameter, followed by dimensionality reduction using Karhunen-Lo\`{e}ve transform. The efficiency of the proposed descriptors is tested on two well-known texture data sets, that is, Brodatz and Vistex, both for classification and image retrieval. The novel method is also tested concerning invariances in situations when the textures are rotated or affected by Gaussian noise. The obtained results outperform other classical and state-of-the-art descriptors in the literature and demonstrate the power of the triangular descriptors in these tasks, suggesting their use in practical applications of image analysis based on texture features. version:1
arxiv-1612-06423 | Feature Encoding in Band-limited Distributed Surveillance Systems | http://arxiv.org/abs/1612.06423 | id:1612.06423 author:Alireza Rahimpour, Ali Taalimi, Hairong Qi category:cs.CV  published:2016-12-19 summary:Distributed surveillance systems have become popular in recent years due to security concerns. However, transmitting high dimensional data in bandwidth-limited distributed systems becomes a major challenge. In this paper, we address this issue by proposing a novel probabilistic algorithm based on the divergence between the probability distributions of the visual features in order to reduce their dimensionality and thus save the network bandwidth in distributed wireless smart camera networks. We demonstrate the effectiveness of the proposed approach through extensive experiments on two surveillance recognition tasks. version:1
arxiv-1612-06404 | Random Walk Models of Network Formation and Sequential Monte Carlo Methods for Graphs | http://arxiv.org/abs/1612.06404 | id:1612.06404 author:Benjamin Bloem-Reddy, Peter Orbanz category:stat.ME stat.ML  published:2016-12-19 summary:We introduce a class of network models that insert edges by connecting the starting and terminal vertices of a random walk on the network graph. Within the taxonomy of statistical network models, this class is distinguished by permitting the location of a new edge to explicitly depend on the structure of the graph, but being nonetheless statistically and computationally tractable. In the limit of infinite walk length, the model converges to an extension of the preferential attachment model---in this sense, it can be motivated alternatively by asking what preferential attachment is an approximation to. Theoretical properties, including the limiting degree sequence, are studied analytically. If the entire history of the graph is observed, parameters can be estimated by maximum likelihood. If only the final graph is available, its history can be imputed using MCMC. We develop a class of sequential Monte Carlo algorithms that are more generally applicable to sequential random graph models, and may be of interest in their own right. The model parameters can be recovered from a single graph generated by the model. Applications to data clarify the role of the random walk length as a length scale of interactions within the graph. version:1
arxiv-1612-06391 | Talk it up or play it down? (Un)expected correlations between (de-)emphasis and recurrence of discussion points in consequential U.S. economic policy meetings | http://arxiv.org/abs/1612.06391 | id:1612.06391 author:Chenhao Tan, Lillian Lee category:cs.SI cs.CL physics.soc-ph  published:2016-12-19 summary:In meetings where important decisions get made, what items receive more attention may influence the outcome. We examine how different types of rhetorical (de-)emphasis -- including hedges, superlatives, and contrastive conjunctions -- correlate with what gets revisited later, controlling for item frequency and speaker. Our data consists of transcripts of recurring meetings of the Federal Reserve's Open Market Committee (FOMC), where important aspects of U.S. monetary policy are decided on. Surprisingly, we find that words appearing in the context of hedging, which is usually considered a way to express uncertainty, are more likely to be repeated in subsequent meetings, while strong emphasis indicated by superlatives has a slightly negative effect on word recurrence in subsequent meetings. We also observe interesting patterns in how these effects vary depending on social factors such as status and gender of the speaker. For instance, the positive effects of hedging are more pronounced for female speakers than for male speakers. version:1
arxiv-1612-06371 | Asynchronous Temporal Fields for Action Recognition | http://arxiv.org/abs/1612.06371 | id:1612.06371 author:Gunnar A. Sigurdsson, Santosh Divvala, Ali Farhadi, Abhinav Gupta category:cs.CV  published:2016-12-19 summary:Actions are more than just movements and trajectories: we cook to eat and we hold a cup to drink from it. A thorough understanding of videos requires going beyond appearance modeling and necessitates reasoning about the sequence of activities, as well as the higher-level constructs such as intentions. But how do we model and reason about these? We propose a fully-connected temporal CRF model for reasoning over various aspects of activities that includes objects, actions, and intentions, where the potentials are predicted by a deep network. End-to-end training of such structured models is a challenging endeavor: For inference and learning we need to construct mini-batches consisting of whole videos, leading to mini-batches with only a few videos. This causes high-correlation between data points leading to breakdown of the backprop algorithm. To address this challenge, we present an asynchronous variational inference method that allows efficient end-to-end training. Our method achieves a classification mAP of 21.9% on the Charades benchmark, outperforming the state-of-the-art (17.2% mAP), and offers equal gains on the task of temporal localization. version:1
arxiv-1612-06370 | Learning Features by Watching Objects Move | http://arxiv.org/abs/1612.06370 | id:1612.06370 author:Deepak Pathak, Ross Girshick, Piotr Dollár, Trevor Darrell, Bharath Hariharan category:cs.CV cs.AI cs.LG cs.NE stat.ML  published:2016-12-19 summary:This paper presents a novel yet intuitive approach to unsupervised feature learning. Inspired by the human visual system, we explore whether low-level motion-based grouping cues can be used to learn an effective visual representation. Specifically, we use unsupervised motion-based segmentation on videos to obtain segments, which we use as 'pseudo ground truth' to train a convolutional network to segment objects from a single frame. Given the extensive evidence that motion plays a key role in the development of the human visual system, we hope that this straightforward approach to unsupervised learning will be more effective than cleverly designed 'pretext' tasks studied in the literature. Indeed, our extensive experiments show that this is the case. When used for transfer learning on object detection, our representation significantly outperforms previous unsupervised approaches across multiple settings, especially when training data for the target task is scarce. version:1
arxiv-1612-06341 | Dense Supervision for Visual Comparisons via Synthetic Images | http://arxiv.org/abs/1612.06341 | id:1612.06341 author:Aron Yu, Kristen Grauman category:cs.CV  published:2016-12-19 summary:Distinguishing subtle differences in attributes is valuable, yet learning to make visual comparisons remains non-trivial. Not only is the number of possible comparisons quadratic in the number of training images, but also access to images adequately spanning the space of fine-grained visual differences is limited. We propose to overcome the sparsity of supervision problem via synthetically generated images. Building on a state-of-the-art image generation engine, we sample pairs of training images exhibiting slight modifications of individual attributes. Augmenting real training image pairs with these examples, we then train attribute ranking models to predict the relative strength of an attribute in novel pairs of real images. Our results on datasets of faces and fashion images show the great promise of bootstrapping imperfect image generators to counteract sample sparsity for learning to rank. version:1
arxiv-1612-06340 | Learning Human-Understandable Strategies | http://arxiv.org/abs/1612.06340 | id:1612.06340 author:Sam Ganzfried, Farzana Yusuf category:cs.GT cs.AI cs.LG cs.MA  published:2016-12-19 summary:Algorithms for equilibrium computation generally make no attempt to ensure that the computed strategies are understandable by humans. For instance the strategies for the strongest poker agents are represented as massive binary files. In many situations, we would like to compute strategies that can actually be implemented by humans, who may have computational limitations and may only be able to remember a small number of features or components of the strategies that have been computed. We study poker games where private information distributions can be arbitrary. We create a large training set of game instances and solutions, by randomly selecting the private information probabilities, and present algorithms that learn from the training instances in order to perform well in games with unseen information distributions. One approach first clusters the training points into a small number of clusters and then creates a small decision tree based on the cluster centers. This approach produces low test error and could be easily implemented by humans since it only requires memorizing a small number of "if-then" rules. version:1
arxiv-1612-06321 | Image Retrieval with Deep Local Features and Attention-based Keypoints | http://arxiv.org/abs/1612.06321 | id:1612.06321 author:Hyeonwoo Noh, Andre Araujo, Jack Sim, Bohyung Han category:cs.CV  published:2016-12-19 summary:We introduce a local feature descriptor for large-scale image retrieval applications, called DELF (DEep Local Feature). The new feature is based on convolutional neural networks, which are trained without object- and patch-level annotations on a landmark image dataset. To enhance DELF's image retrieval performance, we also propose an attention mechanism for keypoint selection, which shares most network layers with the descriptor. This new framework can be used in image retrieval as a drop-in replacement for other keypoint detectors and descriptors, enabling more accurate feature matching and geometric verification. Our technique is particularly useful for the large-scale setting, where a system must operate with high precision. In this case, our system produces reliable confidence scores to reject false positives effectively---in particular, our system is robust against queries that have no correct match in the database. We present an evaluation methodology for this challenging retrieval setting, using standard and large-scale datasets. We show that recently proposed methods do not perform well in this setup; DELF outperforms several recent global and local descriptors by substantial margins. version:1
arxiv-1612-06305 | Handwritten Signature Verification Using Hand-Worn Devices | http://arxiv.org/abs/1612.06305 | id:1612.06305 author:Ben Nassi, Alona Levy, Yuval Elovici, Erez Shmueli category:cs.CR cs.CV cs.CY  published:2016-12-19 summary:Online signature verification technologies, such as those available in banks and post offices, rely on dedicated digital devices such as tablets or smart pens to capture, analyze and verify signatures. In this paper, we suggest a novel method for online signature verification that relies on the increasingly available hand-worn devices, such as smartwatches or fitness trackers, instead of dedicated ad-hoc devices. Our method uses a set of known genuine and forged signatures, recorded using the motion sensors of a hand-worn device, to train a machine learning classifier. Then, given the recording of an unknown signature and a claimed identity, the classifier can determine whether the signature is genuine or forged. In order to validate our method, it was applied on 1980 recordings of genuine and forged signatures that we collected from 66 subjects in our institution. Using our method, we were able to successfully distinguish between genuine and forged signatures with a high degree of accuracy (0.98 AUC and 0.05 EER). version:1
arxiv-1612-06299 | Simple Black-Box Adversarial Perturbations for Deep Networks | http://arxiv.org/abs/1612.06299 | id:1612.06299 author:Nina Narodytska, Shiva Prasad Kasiviswanathan category:cs.LG cs.CR stat.ML  published:2016-12-19 summary:Deep neural networks are powerful and popular learning models that achieve state-of-the-art pattern recognition performance on many computer vision, speech, and language processing tasks. However, these networks have also been shown susceptible to carefully crafted adversarial perturbations which force misclassification of the inputs. Adversarial examples enable adversaries to subvert the expected system behavior leading to undesired consequences and could pose a security risk when these systems are deployed in the real world. In this work, we focus on deep convolutional neural networks and demonstrate that adversaries can easily craft adversarial examples even without any internal knowledge of the target network. Our attacks treat the network as an oracle (black-box) and only assume that the output of the network can be observed on the probed inputs. Our first attack is based on a simple idea of adding perturbation to a randomly selected single pixel or a small set of them. We then improve the effectiveness of this attack by carefully constructing a small set of pixels to perturb by using the idea of greedy local-search. Our proposed attacks also naturally extend to a stronger notion of misclassification. Our extensive experimental results illustrate that even these elementary attacks can reveal a deep neural network's vulnerabilities. The simplicity and effectiveness of our proposed schemes mean that they could serve as a litmus test for designing robust networks. version:1
arxiv-1612-04440 | Disentangling Space and Time in Video with Hierarchical Variational Auto-encoders | http://arxiv.org/abs/1612.04440 | id:1612.04440 author:Will Grathwohl, Aaron Wilson category:cs.CV cs.LG stat.ML  published:2016-12-14 summary:There are many forms of feature information present in video data. Principle among them are object identity information which is largely static across multiple video frames, and object pose and style information which continuously transforms from frame to frame. Most existing models confound these two types of representation by mapping them to a shared feature space. In this paper we propose a probabilistic approach for learning separable representations of object identity and pose information using unsupervised video data. Our approach leverages a deep generative model with a factored prior distribution that encodes properties of temporal invariances in the hidden feature set. Learning is achieved via variational inference. We present results of learning identity and pose information on a dataset of moving characters as well as a dataset of rotating 3D objects. Our experimental results demonstrate our model's success in factoring its representation, and demonstrate that the model achieves improved performance in transfer learning tasks. version:2
arxiv-1612-06259 | Photo-Quality Evaluation based on Computational Aesthetics: Review of Feature Extraction Techniques | http://arxiv.org/abs/1612.06259 | id:1612.06259 author:Dimitris Spathis category:cs.CV  published:2016-12-19 summary:Researchers try to model the aesthetic quality of photographs into low and high- level features, drawing inspiration from art theory, psychology and marketing. We attempt to describe every feature extraction measure employed in the above process. The contribution of this literature review is the taxonomy of each feature by its implementation complexity, considering real-world applications and integration in mobile apps and digital cameras. Also, we discuss the machine learning results along with some unexplored research areas as future work. version:1
arxiv-1612-06246 | Corralling a Band of Bandit Algorithms | http://arxiv.org/abs/1612.06246 | id:1612.06246 author:Alekh Agarwal, Haipeng Luo, Behnam Neyshabur, Robert E. Schapire category:cs.LG stat.ML  published:2016-12-19 summary:We study the problem of combining multiple bandit algorithms (that is, online learning algorithms with partial feedback) with the goal of creating a master algorithm that performs almost as well as the best base algorithm if it were to be run on its own. The main challenge is that when run with a master, base algorithms unavoidably receive much less feedback and it is thus critical that the master not starve a base algorithm that might performs uncompetitively initially but would eventually outperform others if given enough feedback. We address this difficulty by devising a version of Online Mirror Descent with a special mirror map together with a sophisticated learning rate scheme. We show that this approach manages to achieve a more delicate balance between exploiting and exploring base algorithms than previous works yielding superior regret bounds. Our results are applicable to many settings, such as multi-armed bandits, contextual bandits, and convex bandits. As examples, we present two main applications. The first is to create an algorithm that enjoys worst-case robustness while at the same time performing much better when the environment is relatively easy. The second is to create an algorithm that works simultaneously under different assumptions of the environment, such as different priors or different loss structures. version:1
arxiv-1612-06212 | A recurrent neural network without chaos | http://arxiv.org/abs/1612.06212 | id:1612.06212 author:Thomas Laurent, James von Brecht category:cs.NE cs.CL cs.LG  published:2016-12-19 summary:We introduce an exceptionally simple gated recurrent neural network (RNN) that achieves performance comparable to well-known gated architectures, such as LSTMs and GRUs, on the word-level language modeling task. We prove that our model has simple, predicable and non-chaotic dynamics. This stands in stark contrast to more standard gated architectures, whose underlying dynamical systems exhibit chaotic behavior. version:1
arxiv-1612-06176 | An extended Perona-Malik model based on probabilistic models | http://arxiv.org/abs/1612.06176 | id:1612.06176 author:Lars M. Mescheder, Dirk A. Lorenz category:cs.CV math.NA stat.ML  published:2016-12-19 summary:The Perona-Malik model has been very successful at restoring images from noisy input. In this paper, we reinterpret the Perona-Malik model in the language of Gaussian scale mixtures and derive some extensions of the model. Specifically, we show that the expectation-maximization (EM) algorithm applied to Gaussian scale mixtures leads to the lagged-diffusivity algorithm for computing stationary points of the Perona-Malik diffusion equations. Moreover, we show how mean field approximations to these Gaussian scale mixtures lead to a modification of the lagged-diffusivity algorithm that better captures the uncertainties in the restoration. Since this modification can be hard to compute in practice we propose relaxations to the mean field objective to make the algorithm computationally feasible. Our numerical experiments show that this modified lagged-diffusivity algorithm often performs better at restoring textured areas and fuzzy edges than the unmodified algorithm. As a second application of the Gaussian scale mixture framework, we show how an efficient sampling procedure can be obtained for the probabilistic model, making the computation of the conditional mean and other expectations algorithmically feasible. Again, the resulting algorithm has a strong resemblance to the lagged-diffusivity algorithm. Finally, we show that a probabilistic version of the Mumford-Shah segementation model can be obtained in the same framework with a discrete edge-prior. version:1
arxiv-1612-06170 | Crowd collectiveness measure via graph-based node clique learning | http://arxiv.org/abs/1612.06170 | id:1612.06170 author:Weiya Ren category:cs.CV cs.SI  published:2016-12-19 summary:Collectiveness motions of crowd systems have attracted a great deal of attentions in recently years. In this paper, we try to measure the collectiveness of a crowd system by the proposed node clique learning method. The proposed method is a graph based method, and investigates the influence from one node to other nodes. A node is represented by a set of nodes which named a clique, which is obtained by spreading information from this node to other nodes in graph. Then only nodes with sufficient information are selected as the clique of this node. The motion coherence between two nodes is defined by node cliques comparing. The collectiveness of a node and the collectiveness of the crowd system are defined by the nodes coherence. Self-driven particle (SDP) model and the crowd motion database are used to test the ability of the proposed method in measuring collectiveness. version:1
arxiv-1612-06152 | Few-Shot Object Recognition from Machine-Labeled Web Images | http://arxiv.org/abs/1612.06152 | id:1612.06152 author:Zhongwen Xu, Linchao Zhu, Yi Yang category:cs.CV  published:2016-12-19 summary:With the tremendous advances of Convolutional Neural Networks (ConvNets) on object recognition, we can now obtain reliable enough machine-labeled annotations easily by predictions from off-the-shelf ConvNets. In this work, we present an abstraction memory based framework for few-shot learning, building upon machine-labeled image annotations. Our method takes some large-scale machine-annotated datasets (e.g., OpenImages) as an external memory bank. In the external memory bank, the information is stored in the memory slots with the form of key-value, where image feature is regarded as key and label embedding serves as value. When queried by the few-shot examples, our model selects visually similar data from the external memory bank, and writes the useful information obtained from related external data into another memory bank, i.e., abstraction memory. Long Short-Term Memory (LSTM) controllers and attention mechanisms are utilized to guarantee the data written to the abstraction memory is correlated to the query example. The abstraction memory concentrates information from the external memory bank, so that it makes the few-shot recognition effective. In the experiments, we firstly confirm that our model can learn to conduct few-shot object recognition on clean human-labeled data from ImageNet dataset. Then, we demonstrate that with our model, machine-labeled image annotations are very effective and abundant resources to perform object recognition on novel categories. Experimental results show that our proposed model with machine-labeled annotations achieves great performance, only with a gap of 1% between of the one with human-labeled annotations. version:1
arxiv-1612-06141 | Domain specialization: a post-training domain adaptation for Neural Machine Translation | http://arxiv.org/abs/1612.06141 | id:1612.06141 author:Christophe Servan, Josep Crego, Jean Senellart category:cs.CL  published:2016-12-19 summary:Domain adaptation is a key feature in Machine Translation. It generally encompasses terminology, domain and style adaptation, especially for human post-editing workflows in Computer Assisted Translation (CAT). With Neural Machine Translation (NMT), we introduce a new notion of domain adaptation that we call "specialization" and which is showing promising results both in the learning speed and in adaptation accuracy. In this paper, we propose to explore this approach under several perspectives. version:1
arxiv-1612-06140 | Domain Control for Neural Machine Translation | http://arxiv.org/abs/1612.06140 | id:1612.06140 author:Catherine Kobus, Josep Crego, Jean Senellart category:cs.CL  published:2016-12-19 summary:Machine translation systems are very sensitive to the domains they were trained on. Several domain adaptation techniques have been deeply studied. We propose a new technique for neural machine translation (NMT) that we call domain control which is performed at runtime using a unique neural network covering multiple domains. The presented approach shows quality improvements when compared to dedicated domains translating on any of the covered domains and even on out-of-domain data. In addition, model parameters do not need to be re-estimated for each domain, making this effective to real use cases. Evaluation is carried out on English-to-French translation for two different testing scenarios. We first consider the case where an end-user performs translations on a known domain. Secondly, we consider the scenario where the domain is not known and predicted at the sentence level before translating. Results show consistent accuracy improvements for both conditions. version:1
arxiv-1612-06139 | Neural Machine Translation from Simplified Translations | http://arxiv.org/abs/1612.06139 | id:1612.06139 author:Josep Crego, Jean Senellart category:cs.CL  published:2016-12-19 summary:Text simplification aims at reducing the lexical, grammatical and structural complexity of a text while keeping the same meaning. In the context of machine translation, we introduce the idea of simplified translations in order to boost the learning ability of deep neural translation models. We conduct preliminary experiments showing that translation complexity is actually reduced in a translation of a source bi-text compared to the target reference of the bi-text while using a neural machine translation (NMT) system learned on the exact same bi-text. Based on knowledge distillation idea, we then train an NMT system using the simplified bi-text, and show that it outperforms the initial system that was built over the reference data set. Performance is further boosted when both reference and automatic translations are used to learn the network. We perform an elementary analysis of the translated corpus and report accuracy results of the proposed approach on English-to-French and English-to-German translation tasks. version:1
arxiv-1612-06138 | Boosting Neural Machine Translation | http://arxiv.org/abs/1612.06138 | id:1612.06138 author:Dakun Zhang, Jungi Kim, Josep Crego, Jean Senellart category:cs.CL  published:2016-12-19 summary:Training efficiency is one of the main problems for Neural Machine Translation (NMT). Deep networks, very large data and many training iterations are necessary to achieve state-of-the-art performance for NMT. This results in very high computation cost and slow down research and industrialization. In this paper, we first investigate the instability by randomizations for NMT training, and further propose an efficient training method based on data boosting and bootstrapping with no modifications to the neural network. Experiments show that this method can converge much faster compared with a baseline system and achieve stable improvement up to 2.36 BLEU points with 80% training cost. version:1
arxiv-1612-06131 | Monte Carlo sampling for stochastic weight functions | http://arxiv.org/abs/1612.06131 | id:1612.06131 author:Daan Frenkel, K. Julian Schrenk, Stefano Martiniani category:cond-mat.stat-mech physics.comp-ph stat.ME stat.ML  published:2016-12-19 summary:Conventional Monte Carlo simulations are stochastic in the sense that the acceptance of a trial move is decided by comparing a computed acceptance probability with a random number, uniformly distributed between 0 and 1. Here we consider the case that the weight determining the acceptance probability itself is fluctuating. This situation is common in many numerical studies. We show that it is possible to construct a rigorous Monte Carlo algorithm that visits points in state space with a probability proportional to their average weight. The same approach has the potential to transform the methodology of a certain class of high-throughput experiments or the analysis of noisy datasets. version:1
arxiv-1612-06129 | Active and Continuous Exploration with Deep Neural Networks and Expected Model Output Changes | http://arxiv.org/abs/1612.06129 | id:1612.06129 author:Christoph Käding, Erik Rodner, Alexander Freytag, Joachim Denzler category:cs.CV  published:2016-12-19 summary:The demands on visual recognition systems do not end with the complexity offered by current large-scale image datasets, such as ImageNet. In consequence, we need curious and continuously learning algorithms that actively acquire knowledge about semantic concepts which are present in available unlabeled data. As a step towards this goal, we show how to perform continuous active learning and exploration, where an algorithm actively selects relevant batches of unlabeled examples for annotation. These examples could either belong to already known or to yet undiscovered classes. Our algorithm is based on a new generalization of the Expected Model Output Change principle for deep architectures and is especially tailored to deep neural networks. Furthermore, we show easy-to-implement approximations that yield efficient techniques for active selection. Empirical experiments show that our method outperforms currently used heuristics. version:1
arxiv-1612-06098 | Cross-Modal Manifold Learning for Cross-modal Retrieval | http://arxiv.org/abs/1612.06098 | id:1612.06098 author:Sailesh Conjeti, Anees Kazi, Nassir Navab, Amin Katouzian category:cs.CV  published:2016-12-19 summary:This paper presents a new scalable algorithm for cross-modal similarity preserving retrieval in a learnt manifold space. Unlike existing approaches that compromise between preserving global and local geometries, the proposed technique respects both simultaneously during manifold alignment. The global topologies are maintained by recovering underlying mapping functions in the joint manifold space by deploying partially corresponding instances. The inter-, and intra-modality affinity matrices are then computed to reinforce original data skeleton using perturbed minimum spanning tree (pMST), and maximizing the affinity among similar cross-modal instances, respectively. The performance of proposed algorithm is evaluated upon two multimodal image datasets (coronary atherosclerosis histology and brain MRI) for two applications: classification, and regression. Our exhaustive validations and results demonstrate the superiority of our technique over comparative methods and its feasibility for improving computer-assisted diagnosis systems, where disease-specific complementary information shall be aggregated and interpreted across modalities to form the final decision. version:1
arxiv-1612-06096 | X-ray In-Depth Decomposition: Can Deep Learning Reveal The Latent Structures? | http://arxiv.org/abs/1612.06096 | id:1612.06096 author:Shadi Albarqouni, Javad Fotouhi, Nassir Navab category:cs.CV  published:2016-12-19 summary:X-ray radiography is the most readily available imaging modality and has a broad range of applications that spans from diagnosis to intra-operative guidance in cardiac, orthopedics, and trauma procedures. Proper interpretation of the hidden and obscured anatomy in X-ray images remains a challenge and often requires high radiation dose and imaging from several perspectives. In this work, we aim at decomposing the conventional X-ray image into d X-ray components of independent, non-overlapped, clipped sub-volumes using deep learning approach. Despite the challenging aspects of modelling such a highly ill-posed problem, exciting and encouraging results are obtained paving the path for further contributions in this direction. version:1
arxiv-1612-06093 | Transfer Learning based Dynamic Multiobjective Optimization Algorithms | http://arxiv.org/abs/1612.06093 | id:1612.06093 author:Min Jiang, Zhongqiang Huang, Liming Qiu, Wenzhen Huang, Gary G. Yen category:cs.NE  published:2016-12-19 summary:One of the major distinguishing features of the dynamic multiobjective optimization problems (DMOPs) is the optimization objectives will change over time, thus tracking the varying Pareto-optimal front becomes a challenge. One of the promising solutions is reusing the "experiences" to construct a prediction model via statistical machine learning approaches. However most of the existing methods ignore the non-independent and identically distributed nature of data used to construct the prediction model. In this paper, we propose an algorithmic framework, called Tr-DMOEA, which integrates transfer learning and population-based evolutionary algorithm for solving the DMOPs. This approach takes the transfer learning method as a tool to help reuse the past experience for speeding up the evolutionary process, and at the same time, any population based multiobjective algorithms can benefit from this integration without any extensive modifications. To verify this, we incorporate the proposed approach into the development of three well-known algorithms, nondominated sorting genetic algorithm II (NSGA-II), multiobjective particle swarm optimization (MOPSO), and the regularity model-based multiobjective estimation of distribution algorithm (RM-MEDA), and then employ twelve benchmark functions to test these algorithms as well as compare with some chosen state-of-the-art designs. The experimental results confirm the effectiveness of the proposed method through exploiting machine learning technology. version:1
arxiv-1612-06083 | Hierarchical Partitioning of the Output Space in Multi-label Data | http://arxiv.org/abs/1612.06083 | id:1612.06083 author:Yannis Papanikolaou, Ioannis Katakis, Grigorios Tsoumakas category:stat.ML cs.LG  published:2016-12-19 summary:Hierarchy Of Multi-label classifiers (HOMER) is a multi-label learning algorithm that breaks the initial learning task to several, easier sub-tasks by first constructing a hierarchy of labels from a given label set and secondly employing a given base multi-label classifier (MLC) to the resulting sub-problems. The primary goal is to effectively address class imbalance and scalability issues that often arise in real-world multi-label classification problems. In this work, we present the general setup for a HOMER model and a simple extension of the algorithm that is suited for MLCs that output rankings. Furthermore, we provide a detailed analysis of the properties of the algorithm, both from an aspect of effectiveness and computational complexity. A secondary contribution involves the presentation of a balanced variant of the k means algorithm, which serves in the first step of the label hierarchy construction. We conduct extensive experiments on six real-world datasets, studying empirically HOMER's parameters and providing examples of instantiations of the algorithm with different clustering approaches and MLCs, The empirical results demonstrate a significant improvement over the given base MLC. version:1
arxiv-1612-06070 | On Random Weights for Texture Generation in One Layer Neural Networks | http://arxiv.org/abs/1612.06070 | id:1612.06070 author:Mihir Mongia, Kundan Kumar, Akram Erraqabi, Yoshua Bengio category:cs.CV cs.LG  published:2016-12-19 summary:Recent work in the literature has shown experimentally that one can use the lower layers of a trained convolutional neural network (CNN) to model natural textures. More interestingly, it has also been experimentally shown that only one layer with random filters can also model textures although with less variability. In this paper we ask the question as to why one layer CNNs with random filters are so effective in generating textures? We theoretically show that one layer convolutional architectures (without a non-linearity) paired with the an energy function used in previous literature, can in fact preserve and modulate frequency coefficients in a manner so that random weights and pretrained weights will generate the same type of images. Based on the results of this analysis we question whether similar properties hold in the case where one uses one convolution layer with a non-linearity. We show that in the case of ReLu non-linearity there are situations where only one input will give the minimum possible energy whereas in the case of no nonlinearity, there are always infinite solutions that will give the minimum possible energy. Thus we can show that in certain situations adding a ReLu non-linearity generates less variable images. version:1
arxiv-1612-06067 | A Convex Program for Mixed Linear Regression with a Recovery Guarantee for Well-Separated Data | http://arxiv.org/abs/1612.06067 | id:1612.06067 author:Paul Hand, Babhru Joshi category:math.OC stat.ML  published:2016-12-19 summary:We introduce a convex approach for mixed linear regression over $d$ features. This approach is a second-order cone program, based on L1 minimization, which assigns an estimate regression coefficient in $\mathbb{R}^{d}$ for each data point. These estimates can then be clustered using, for example, $k$-means. For problems with two or more mixture classes, we prove that the convex program exactly recovers all of the mixture components in the noiseless setting under technical conditions that include a well-separation assumption on the data. Under these assumptions, recovery is possible if each class has at least $d$ independent measurements. We also explore an iteratively reweighted least squares implementation of this method on real and synthetic data. version:1
arxiv-1612-06062 | Improving Tweet Representations using Temporal and User Context | http://arxiv.org/abs/1612.06062 | id:1612.06062 author:Ganesh J, Manish Gupta, Vasudeva Varma category:cs.CL cs.AI  published:2016-12-19 summary:In this work we propose a novel representation learning model which computes semantic representations for tweets accurately. Our model systematically exploits the chronologically adjacent tweets ('context') from users' Twitter timelines for this task. Further, we make our model user-aware so that it can do well in modeling the target tweet by exploiting the rich knowledge about the user such as the way the user writes the post and also summarizing the topics on which the user writes. We empirically demonstrate that the proposed models outperform the state-of-the-art models in predicting the user profile attributes like spouse, education and job by 19.66%, 2.27% and 2.22% respectively. version:1
arxiv-1612-06061 | Mixing Times and Structural Inference for Bernoulli Autoregressive Processes | http://arxiv.org/abs/1612.06061 | id:1612.06061 author:Dimitrios Katselis, Carolyn L. Beck, R. Srikant category:stat.ML  published:2016-12-19 summary:We introduce a novel multivariate random process producing Bernoulli outputs per dimension, that can possibly formalize binary interactions in various graphical structures and can be used to model opinion dynamics, epidemics, financial and biological time series data, etc. We call this a Bernoulli Autoregressive Process (BAR). A BAR process models a discrete-time vector random sequence of $p$ scalar Bernoulli processes with autoregressive dynamics and corresponds to a particular Markov Chain. The benefit from the autoregressive dynamics is the description of a $2^p\times 2^p$ transition matrix by at most $pd$ effective parameters for some $d\ll p$ or by two sparse matrices of dimensions $p\times p^2$ and $p\times p$, respectively, parameterizing the transitions. Additionally, we show that the BAR process mixes rapidly, by proving that the mixing time is $O(\log p)$. The hidden constant in the previous mixing time bound depends explicitly on the values of the chain parameters and implicitly on the maximum allowed in-degree of a node in the corresponding graph. For a network with $p$ nodes, where each node has in-degree at most $d$ and corresponds to a scalar Bernoulli process generated by a BAR, we provide a greedy algorithm that can efficiently learn the structure of the underlying directed graph with a sample complexity proportional to the mixing time of the BAR process. The sample complexity of the proposed algorithm is nearly order-optimal as it is only a $\log p$ factor away from an information-theoretic lower bound. We present simulation results illustrating the performance of our algorithm in various setups, including a model for a biological signaling network. version:1
arxiv-1612-06053 | Dual Deep Network for Visual Tracking | http://arxiv.org/abs/1612.06053 | id:1612.06053 author:Zhizhen Chi, Hongyang Li, Huchuan Lu, Ming-Hsuan Yang category:cs.CV  published:2016-12-19 summary:Visual tracking addresses the problem of identifying and localizing an unknown target in a video given the target specified by a bounding box in the first frame. In this paper, we propose a dual network to better utilize features among layers for visual tracking. It is observed that features in higher layers encode semantic context while its counterparts in lower layers are sensitive to discriminative appearance. Thus we exploit the hierarchical features in different layers of a deep model and design a dual structure to obtain better feature representation from various streams, which is rarely investigated in previous work. To highlight geometric contours of the target, we integrate the hierarchical feature maps with an edge detector as the coarse prior maps to further embed local details around the target. To leverage the robustness of our dual network, we train it with random patches measuring the similarities between the network activation and target appearance, which serves as a regularization to enforce the dual network to focus on target object. The proposed dual network is updated online in a unique manner based on the observation that the target being tracked in consecutive frames should share more similar feature representations than those in the surrounding background. It is also found that for a target object, the prior maps can help further enhance performance by passing message into the output maps of the dual network. Therefore, an independent component analysis with reference algorithm (ICA-R) is employed to extract target context using prior maps as guidance. Online tracking is conducted by maximizing the posterior estimate on the final maps with stochastic and periodic update. Quantitative and qualitative evaluations on two large-scale benchmark data sets show that the proposed algorithm performs favourably against the state-of-the-arts. version:1
arxiv-1612-06052 | Training Ternary Neural Networks with Exact Proximal Operator | http://arxiv.org/abs/1612.06052 | id:1612.06052 author:Penghang Yin, Shuai Zhang, Jack Xin, Yingyong Qi category:cs.LG  published:2016-12-19 summary:In this paper, we propose a stochastic proximal gradient method to train ternary weight neural networks (TNN). The proposed method features weight ternarization via an exact formula of proximal operator. Our experiments show that our trained TNN are able to preserve the state-of-the-art performance on MNIST and CIFAR10 benchmark datesets. version:1
arxiv-1612-06018 | Self-Correcting Models for Model-Based Reinforcement Learning | http://arxiv.org/abs/1612.06018 | id:1612.06018 author:Erik Talvitie category:cs.LG cs.AI I.2.6; I.2.8  published:2016-12-19 summary:When an agent cannot represent a perfectly accurate model of its environment's dynamics, model-based reinforcement learning (MBRL) can fail catastrophically. Planning involves composing the predictions of the model; when flawed predictions are composed, even minor errors can compound and render the model useless for planning. Hallucinated Replay (Talvitie 2014) trains the model to "correct" itself when it produces errors, substantially improving MBRL with flawed models. This paper theoretically analyzes this approach, illuminates settings in which it is likely to be effective or ineffective, and presents a novel error bound, showing that a model's ability to self-correct is more tightly related to MBRL performance than one-step prediction error. These results inspire an MBRL algorithm for deterministic MDPs with performance guarantees that are robust to model class limitations. version:1
arxiv-1612-06017 | Parsing Images of Overlapping Organisms with Deep Singling-Out Networks | http://arxiv.org/abs/1612.06017 | id:1612.06017 author:Victor Yurchenko, Victor Lempitsky category:cs.CV  published:2016-12-19 summary:This work is motivated by the mostly unsolved task of parsing biological images with multiple overlapping articulated model organisms (such as worms or larvae). We present a general approach that separates the two main challenges associated with such data, individual object shape estimation and object groups disentangling. At the core of the approach is a deep feed-forward singling-out network (SON) that is trained to map each local patch to a vectorial descriptor that is sensitive to the characteristics (e.g. shape) of a central object, while being invariant to the variability of all other surrounding elements. Given a SON, a local image patch can be matched to a gallery of isolated elements using their SON-descriptors, thus producing a hypothesis about the shape of the central element in that patch. The image-level optimization based on integer programming can then pick a subset of the hypotheses to explain (parse) the whole image and disentangle groups of organisms. While sharing many similarities with existing "analysis-by-synthesis" approaches, our method avoids the need for stochastic search in the high-dimensional configuration space and numerous rendering operations at test-time. We show that our approach can parse microscopy images of three popular model organisms (the C.Elegans roundworms, the Drosophila larvae, and the E.Coli bacteria) even under significant crowding and overlaps between organisms. We speculate that the overall approach is applicable to a wider class of image parsing problems concerned with crowded articulated objects, for which rendering training images is possible. version:1
arxiv-1612-06003 | Inexact Proximal Gradient Methods for Non-convex and Non-smooth Optimization | http://arxiv.org/abs/1612.06003 | id:1612.06003 author:Bin Gu, Zhouyuan Huo, Heng Huang category:cs.LG stat.ML  published:2016-12-18 summary:Non-convex and non-smooth optimization plays an important role in machine learning. Proximal gradient method is one of the most important methods for solving the non-convex and non-smooth problems, where a proximal operator need to be solved exactly for each step. However, in a lot of problems the proximal operator does not have an analytic solution, or is expensive to obtain an exact solution. In this paper, we propose inexact proximal gradient methods (not only a basic inexact proximal gradient method (IPG), but also a Nesterov's accelerated inexact proximal gradient method (AIPG)) for non-convex and non-smooth optimization, which tolerate an error in the calculation of the proximal operator. Theoretical analysis shows that IPG and AIPG have the same convergence rates as in the error-free case, provided that the errors decrease at appropriate rates. version:1
arxiv-1612-06000 | Sample-efficient Deep Reinforcement Learning for Dialog Control | http://arxiv.org/abs/1612.06000 | id:1612.06000 author:Kavosh Asadi, Jason D. Williams category:cs.AI cs.LG stat.ML  published:2016-12-18 summary:Representing a dialog policy as a recurrent neural network (RNN) is attractive because it handles partial observability, infers a latent representation of state, and can be optimized with supervised learning (SL) or reinforcement learning (RL). For RL, a policy gradient approach is natural, but is sample inefficient. In this paper, we present 3 methods for reducing the number of dialogs required to optimize an RNN-based dialog policy with RL. The key idea is to maintain a second RNN which predicts the value of the current policy, and to apply experience replay to both networks. On two tasks, these methods reduce the number of dialogs/episodes required by about a third, vs. standard policy gradient methods. version:1
arxiv-1612-05970 | Adversarial Deep Structural Networks for Mammographic Mass Segmentation | http://arxiv.org/abs/1612.05970 | id:1612.05970 author:Wentao Zhu, Xiaohui Xie category:cs.CV cs.LG  published:2016-12-18 summary:Mass segmentation is an important task in mammogram analysis, providing effective morphological features and regions of interest (ROI) for mass detection and classification. Inspired by the success of using deep convolutional features for natural image analysis and conditional random fields (CRF) for structural learning, we propose an end-to-end network for mammographic mass segmentation. The network employs a fully convolutional network (FCN) to model potential function, followed by a CRF to perform structural learning. Because the mass distribution varies greatly with pixel position, the FCN is combined with position priori for the task. Due to the small size of mammogram datasets, we use adversarial training to control over-fitting. Four models with different convolutional kernels are further fused to improve the segmentation results. Experimental results on two public datasets, INbreast and DDSM-BCRP, show that our end-to-end network combined with adversarial training achieves the-state-of-the-art results. version:1
arxiv-1612-05968 | Deep Multi-instance Networks with Sparse Label Assignment for Whole Mammogram Classification | http://arxiv.org/abs/1612.05968 | id:1612.05968 author:Wentao Zhu, Qi Lou, Yeeleng Scott Vang, Xiaohui Xie category:cs.CV cs.LG  published:2016-12-18 summary:Mammogram classification is directly related to computer-aided diagnosis of breast cancer. Traditional methods requires great effort to annotate the training data by costly manual labeling and specialized computational models to detect these annotations during test. Inspired by the success of using deep convolutional features for natural image analysis and multi-instance learning for labeling a set of instances/patches, we propose end-to-end trained deep multi-instance networks for mass classification based on whole mammogram without the aforementioned costly need to annotate the training data. We explore three different schemes to construct deep multi-instance networks for whole mammogram classification. Experimental results on the INbreast dataset demonstrate the robustness of proposed deep networks compared to previous work using segmentation and detection annotations in the training. version:1
arxiv-1612-05907 | Optimal tuning for divide-and-conquer kernel ridge regression with massive data | http://arxiv.org/abs/1612.05907 | id:1612.05907 author:Ganggang Xu, Zuofeng Shang, Guang Cheng category:stat.ML  published:2016-12-18 summary:We propose a first data-driven tuning procedure for divide-and-conquer kernel ridge regression (Zhang et al., 2015). While the proposed criterion is computationally scalable for massive data sets, it is also shown to be asymptotically optimal under mild conditions. The effectiveness of our method is illustrated by extensive simulations and an application to Million Song Dataset. version:1
arxiv-1612-05890 | Learning a No-Reference Quality Metric for Single-Image Super-Resolution | http://arxiv.org/abs/1612.05890 | id:1612.05890 author:Chao Ma, Chih-Yuan Yang, Xiaokang Yang, Ming-Hsuan Yang category:cs.CV  published:2016-12-18 summary:Numerous single-image super-resolution algorithms have been proposed in the literature, but few studies address the problem of performance evaluation based on visual perception. While most super-resolution images are evaluated by fullreference metrics, the effectiveness is not clear and the required ground-truth images are not always available in practice. To address these problems, we conduct human subject studies using a large set of super-resolution images and propose a no-reference metric learned from visual perceptual scores. Specifically, we design three types of low-level statistical features in both spatial and frequency domains to quantify super-resolved artifacts, and learn a two-stage regression model to predict the quality scores of super-resolution images without referring to ground-truth images. Extensive experimental results show that the proposed metric is effective and efficient to assess the quality of super-resolution images based on human perception. version:1
arxiv-1612-05888 | Building Diversified Multiple Trees for Classification in High Dimensional Noise Data | http://arxiv.org/abs/1612.05888 | id:1612.05888 author:Jiuyong Li, Lin Liu, Jixue Liu, Ryan Green category:cs.LG stat.ML  published:2016-12-18 summary:It is common that a trained classification model is applied to the operating data that is deviated from the training data because of noise. This paper demonstrate an ensemble classifier, Diversified Multiple Trees (DMT) is more robust to classify noised data than other widely used ensemble methods. DMT is tested on three real world biological data sets from different laboratories in comparison with four benchmark ensemble classifiers. Experimental results show that DMT is significantly more accurate than other benchmark ensemble classifiers on noised test data. We also discussed a limitation of DMT and its possible variations. version:1
arxiv-1612-05877 | Deep Learning on Lie Groups for Skeleton-based Action Recognition | http://arxiv.org/abs/1612.05877 | id:1612.05877 author:Zhiwu Huang, Chengde Wan, Thomas Probst, Luc Van Gool category:cs.CV  published:2016-12-18 summary:In recent years, skeleton-based action recognition has become a popular 3D classification problem. State-of-the-art methods typically first represent each motion sequence as a high-dimensional trajectory on a Lie group with an additional dynamic time warping, and then shallowly learn favorable Lie group features. In this paper we incorporate the Lie group structure into a deep network architecture to learn more appropriate Lie group features for 3D action recognition. Within the network structure, we design rotation mapping layers to transform the input Lie group features into desirable ones, which are aligned better in the temporal domain. To reduce the high feature dimensionality, the architecture is equipped with rotation pooling layers for the elements on the Lie group. Furthermore, we propose a logarithm mapping layer to map the resulting manifold data into a tangent space that facilitates the application of regular output layers for the final classification. Evaluations of the proposed network for standard 3D human action recognition datasets clearly demonstrate its superiority over existing shallow Lie group feature learning methods as well as most conventional deep learning methods. version:1
arxiv-1612-05872 | 3D Shape Induction from 2D Views of Multiple Objects | http://arxiv.org/abs/1612.05872 | id:1612.05872 author:Matheus Gadelha, Subhransu Maji, Rui Wang category:cs.CV  published:2016-12-18 summary:In this paper we investigate the problem of inducing a distribution over three-dimensional structures given two-dimensional views of multiple objects taken from unknown viewpoints. Our approach called "projective generative adversarial networks" (PrGANs) trains a deep generative model of 3D shapes whose projections match the distributions of the input 2D views. The addition of a projection module allows us to infer the underlying 3D shape distribution without using any 3D, viewpoint information, or annotation during the learning phase. We show that our approach produces 3D shapes of comparable quality to GANs trained on 3D data for a number of shape categories including chairs, airplanes, and cars. Experiments also show that the disentangled representation of 2D shapes into geometry and viewpoint leads to a good generative model of 2D shapes. The key advantage is that our model allows us to predict 3D, viewpoint, and generate novel views from an input image in a completely unsupervised manner. version:1
arxiv-1612-02913 | Field-Programmable Crossbar Array (FPCA) for Reconfigurable Computing | http://arxiv.org/abs/1612.02913 | id:1612.02913 author:Mohammed A. Zidan, YeonJoo Jeong, Jong Hong Shin, Chao Du, Zhengya Zhang, Wei D. Lu category:cs.ET cs.AR cs.NE  published:2016-12-09 summary:For decades, advances in electronics were directly related to the scaling of CMOS transistors according to Moore's law. However, both the CMOS scaling and the classical computer architecture are approaching fundamental and practical limits, and new computing architectures based on emerging devices, such as non-volatile memories e.g. resistive memory (RRAM) devices, are expected to sustain the exponential growth of computing capability. Here we propose a novel memory-centric, reconfigurable, general purpose computing platform to handle the explosive amount of data in a fast and energy-efficient manner. The proposed computing architecture is based on a single physical resistive memory-centric fabric that can be optimally reconfigured and utilized to perform different computing and data storage tasks in a massively parallel approach. The system can be tailored to achieve maximal energy efficiency based on the data flow by dynamically allocating the basic computing fabric to storage, arithmetic, and analog computing including neuromorphic computing tasks. version:2
arxiv-1612-05846 | Efficient Global Spatial-Angular Sparse Coding for Diffusion MRI with Separable Dictionaries | http://arxiv.org/abs/1612.05846 | id:1612.05846 author:Evan Schwab, René Vidal, Nicolas Charon category:stat.ML cs.CV q-bio.QM  published:2016-12-18 summary:Diffusion MRI (dMRI) can reconstruct neuronal fibers in the brain, in vivo, by measuring water diffusion along angular gradient directions in q-space. High angular resolution diffusion imaging (HARDI) can produce better estimates of fiber orientation than the popularly used diffusion tensor imaging, but the high number of samples needed to estimate diffusivity requires lengthy patient scan times. To accelerate dMRI, compressed sensing (CS) has been utilized by exploiting a sparse representation of the data, discovered through sparse coding. The sparser the representation, the fewer samples are needed to reconstruct a high resolution signal with limited information loss and so a focus of much dMRI research has been finding the sparsest possible dictionary representation. All prior methods, however, rely on an angular model of q-space signals in each voxel which fundamentally limits the global sparsity level since at least one dictionary atom is needed for each voxel. In contrast, we formulate a global spatial-angular representation of dMRI that will allow us to sparsely model an entire dMRI brain signal below the limit of one atom per voxel using joint spatial-angular sparse coding. But a main challenge is optimizing over large-scale dMRI data. In this work, we present extensions to a number of sparse coding algorithms that are better suited for large-scale problems by exploiting the separable Kronecker structure of our global spatial-angular dictionary. We compare the complexity and speed of our methods with prior Kronecker sparse coding algorithms and show promising sparsity results on phantom and real HARDI brain data for various dictionary choices. With great efficiency our method achieves significantly sparser HARDI representations than the state-of-the-art which has the potential achieve new levels of HARDI acceleration within a unified (k,q)-CS framework. version:1
arxiv-1612-05836 | EgoTransfer: Transferring Motion Across Egocentric and Exocentric Domains using Deep Neural Networks | http://arxiv.org/abs/1612.05836 | id:1612.05836 author:Shervin Ardeshir, Krishna Regmi, Ali Borji category:cs.CV cs.LG cs.NE  published:2016-12-17 summary:Mirror neurons have been observed in the primary motor cortex of primate species, in particular in humans and monkeys. A mirror neuron fires when a person performs a certain action, and also when he observes the same action being performed by another person. A crucial step towards building fully autonomous intelligent systems with human-like learning abilities is the capability in modeling the mirror neuron. On one hand, the abundance of egocentric cameras in the past few years has offered the opportunity to study a lot of vision problems from the first-person perspective. A great deal of interesting research has been done during the past few years, trying to explore various computer vision tasks from the perspective of the self. On the other hand, videos recorded by traditional static cameras, capture humans performing different actions from an exocentric third-person perspective. In this work, we take the first step towards relating motion information across these two perspectives. We train models that predict motion in an egocentric view, by observing it from an exocentric view, and vice versa. This allows models to predict how an egocentric motion would look like from outside. To do so, we train linear and nonlinear models and evaluate their performance in terms of retrieving the egocentric (exocentric) motion features, while having access to an exocentric (egocentric) motion feature. Our experimental results demonstrate that motion information can be successfully transferred across the two views. version:1
arxiv-1612-05794 | A new recurrent neural network based predictive model for Faecal Calprotectin analysis: A retrospective study | http://arxiv.org/abs/1612.05794 | id:1612.05794 author:Zeeshan Khawar Malik, Zain U. Hussain, Ziad Kobti, Charlie W. Lees, Newton Howard, Amir Hussain category:cs.LG  published:2016-12-17 summary:Faecal Calprotectin (FC) is a surrogate marker for intestinal inflammation, termed Inflammatory Bowel Disease (IBD), but not for cancer. In this retrospective study of 804 patients, an enhanced benchmark predictive model for analyzing FC is developed, based on a novel state-of-the-art Echo State Network (ESN), an advanced dynamic recurrent neural network which implements a biologically plausible architecture, and a supervised learning mechanism. The proposed machine learning driven predictive model is benchmarked against a conventional logistic regression model, demonstrating statistically significant performance improvements. version:1
arxiv-1612-05753 | Learning to predict where to look in interactive environments using deep recurrent q-learning | http://arxiv.org/abs/1612.05753 | id:1612.05753 author:Sajad Mousavi, Ali Borji, Nasser Mozayani category:cs.CV cs.LG  published:2016-12-17 summary:Bottom-Up (BU) saliency models do not perform well in complex interactive environments where humans are actively engaged in tasks (e.g., sandwich making and playing the video games). In this paper, we leverage Reinforcement Learning (RL) to highlight task-relevant locations of input frames. We propose a soft attention mechanism combined with the Deep Q-Network (DQN) model to teach an RL agent how to play a game and where to look by focusing on the most pertinent parts of its visual input. Our evaluations on several Atari 2600 games show that the soft attention based model could predict fixation locations significantly better than bottom-up models such as Itti-Kochs saliency and Graph-Based Visual Saliency (GBVS) models. version:1
arxiv-1612-05740 | Machine Learning, Linear and Bayesian Models for Logistic Regression in Failure Detection Problems | http://arxiv.org/abs/1612.05740 | id:1612.05740 author:B. Pavlyshenko category:cs.LG stat.ML  published:2016-12-17 summary:In this work, we study the use of logistic regression in manufacturing failures detection. As a data set for the analysis, we used the data from Kaggle competition Bosch Production Line Performance. We considered the use of machine learning, linear and Bayesian models. For machine learning approach, we analyzed XGBoost tree based classifier to obtain high scored classification. Using the generalized linear model for logistic regression makes it possible to analyze the influence of the factors under study. The Bayesian approach for logistic regression gives the statistical distribution for the parameters of the model. It can be useful in the probabilistic analysis, e.g. risk assessment. version:1
arxiv-1612-05734 | Web-based Semantic Similarity for Emotion Recognition in Web Objects | http://arxiv.org/abs/1612.05734 | id:1612.05734 author:Valentina Franzoni, Giulio Biondi, Alfredo Milani, Yuanxi Li category:cs.CL cs.AI cs.SI  published:2016-12-17 summary:In this project we propose a new approach for emotion recognition using web-based similarity (e.g. confidence, PMI and PMING). We aim to extract basic emotions from short sentences with emotional content (e.g. news titles, tweets, captions), performing a web-based quantitative evaluation of semantic proximity between each word of the analyzed sentence and each emotion of a psychological model (e.g. Plutchik, Ekman, Lovheim). The phases of the extraction include: text preprocessing (tokenization, stop words, filtering), search engine automated query, HTML parsing of results (i.e. scraping), estimation of semantic proximity, ranking of emotions according to proximity measures. The main idea is that, since it is possible to generalize semantic similarity under the assumption that similar concepts co-occur in documents indexed in search engines, therefore also emotions can be generalized in the same way, through tags or terms that express them in a particular language, ranking emotions. Training results are compared to human evaluation, then additional comparative tests on results are performed, both for the global ranking correlation (e.g. Kendall, Spearman, Pearson) both for the evaluation of the emotion linked to each single word. Different from sentiment analysis, our approach works at a deeper level of abstraction, aiming at recognizing specific emotions and not only the positive/negative sentiment, in order to predict emotions as semantic data. version:1
arxiv-1612-05729 | Exploiting sparsity to build efficient kernel based collaborative filtering for top-N item recommendation | http://arxiv.org/abs/1612.05729 | id:1612.05729 author:Mirko Polato, Fabio Aiolli category:cs.IR cs.AI cs.LG  published:2016-12-17 summary:The increasing availability of implicit feedback datasets has raised the interest in developing effective collaborative filtering techniques able to deal asymmetrically with unambiguous positive feedback and ambiguous negative feedback. In this paper, we propose a principled kernel-based collaborative filtering method for top-N item recommendation with implicit feedback. We present an efficient implementation using the linear kernel, and we show how to generalize it to kernels of the dot product family preserving the efficiency. We also investigate on the elements which influence the sparsity of a standard cosine kernel. This analysis shows that the sparsity of the kernel strongly depends on the properties of the dataset, in particular on the long tail distribution. We compare our method with state-of-the-art algorithms achieving good results both in terms of efficiency and effectiveness. version:1
arxiv-1612-05719 | Microscopic Muscle Image Enhancement | http://arxiv.org/abs/1612.05719 | id:1612.05719 author:Xiangfei Kong, Lin Yang category:cs.CV  published:2016-12-17 summary:We propose a robust image enhancement algorithm dedicated for muscle fiber specimen images captured by optical microscopes. Blur or out of focus problems are prevalent in muscle images during the image acquisition stage. Traditional image deconvolution methods do not work since they assume the blur kernels are known and also produce ring artifacts. We provide a compact framework which involves a novel spatially non-uniform blind deblurring approach specialized to muscle images which automatically detects and alleviates degraded regions. Ring artifacts problems are addressed and a kernel propagation strategy is proposed to speedup the algorithm and deals with the high non-uniformity of the blur kernels on muscle images. Experiments show that the proposed framework performs well on muscle images taken with modern advanced optical microscopes. Our framework is free of laborious parameter settings and is computationally efficient. version:1
arxiv-1612-05712 | A Fusion Method Based on Decision Reliability Ratio for Finger Vein Verification | http://arxiv.org/abs/1612.05712 | id:1612.05712 author:Liao Ni, Yi Zhang, He Zheng, Shilei Liu, Houjun Huang, Wenxin Li category:cs.CV  published:2016-12-17 summary:Finger vein verification has developed a lot since its first proposal, but there is still not a perfect algorithm. It is proved that algorithms with the same overall accuracy may have different misclassified patterns. We could make use of this complementation to fuse individual algorithms together for more precise result. According to our observation, algorithm has different confidence on its decisions but it is seldom considered in fusion methods. Our work is first to define decision reliability ratio to quantify this confidence, and then propose the Maximum Decision Reliability Ratio (MDRR) fusion method incorporating Weighted Voting. Experiment conducted on a data set of 1000 fingers and 5 images per finger proves the effectiveness of the method. The classifier obtained by MDRR method gets an accuracy of 99.42% while the maximum accuracy of the original individual classifiers is 97.77%. The experiment results also show the MDRR outperforms the traditional fusion methods as Voting, Weighted Voting, Sum and Weighted Sum. version:1
arxiv-1612-05708 | Mutual information for fitting deep nonlinear models | http://arxiv.org/abs/1612.05708 | id:1612.05708 author:Jacob S. Hunter, Nathan O. Hodas category:math.OC cs.LG stat.ML  published:2016-12-17 summary:Deep nonlinear models pose a challenge for fitting parameters due to lack of knowledge of the hidden layer and the potentially non-affine relation of the initial and observed layers. In the present work we investigate the use of information theoretic measures such as mutual information and Kullback-Leibler (KL) divergence as objective functions for fitting such models without knowledge of the hidden layer. We investigate one model as a proof of concept and one application of cogntive performance. We further investigate the use of optimizers with these methods. Mutual information is largely successful as an objective, depending on the parameters. KL divergence is found to be similarly succesful, given some knowledge of the statistics of the hidden layer. version:1
arxiv-1612-02814 | Task-Guided and Path-Augmented Heterogeneous Network Embedding for Author Identification | http://arxiv.org/abs/1612.02814 | id:1612.02814 author:Ting Chen, Yizhou Sun category:cs.LG cs.AI cs.IR stat.ML  published:2016-12-08 summary:In this paper, we study the problem of author identification under double-blind review setting, which is to identify potential authors given information of an anonymized paper. Different from existing approaches that rely heavily on feature engineering, we propose to use network embedding approach to address the problem, which can automatically represent nodes into lower dimensional feature vectors. However, there are two major limitations in recent studies on network embedding: (1) they are usually general-purpose embedding methods, which are independent of the specific tasks; and (2) most of these approaches can only deal with homogeneous networks, where the heterogeneity of the network is ignored. Hence, challenges faced here are two folds: (1) how to embed the network under the guidance of the author identification task, and (2) how to select the best type of information due to the heterogeneity of the network. To address the challenges, we propose a task-guided and path-augmented heterogeneous network embedding model. In our model, nodes are first embedded as vectors in latent feature space. Embeddings are then shared and jointly trained according to task-specific and network-general objectives. We extend the existing unsupervised network embedding to incorporate meta paths in heterogeneous networks, and select paths according to the specific task. The guidance from author identification task for network embedding is provided both explicitly in joint training and implicitly during meta path selection. Our experiments demonstrate that by using path-augmented network embedding with task guidance, our model can obtain significantly better accuracy at identifying the true authors comparing to existing methods. version:2
arxiv-1612-05688 | A User Simulator for Task-Completion Dialogues | http://arxiv.org/abs/1612.05688 | id:1612.05688 author:Xiujun Li, Zachary C. Lipton, Bhuwan Dhingra, Lihong Li, Jianfeng Gao, Yun-Nung Chen category:cs.LG cs.AI cs.CL  published:2016-12-17 summary:Despite widespread interests in reinforcement-learning for task-oriented dialogue systems, several obstacles can frustrate research and development progress. First, reinforcement learners typically require interaction with the environment, so conventional dialogue corpora cannot be used directly. Second, each task presents specific challenges, requiring separate corpus of task-specific annotated data. Third, collecting and annotating human-machine or human-human conversations for task-oriented dialogues requires extensive domain knowledge. Because building an appropriate dataset can be both financially costly and time-consuming, one popular approach is to build a user simulator based upon a corpus of example dialogues. Then, one can train reinforcement learning agents in an online fashion as they interact with the simulator. Dialogue agents trained on these simulators can serve as an effective starting point. Once agents master the simulator, they may be deployed in a real environment to interact with humans, and continue to be trained online. To ease empirical algorithmic comparisons in dialogues, this paper introduces a new, publicly available simulation framework, where our simulator, designed for the movie-booking domain, leverages both rules and collected data. The simulator supports two tasks: movie ticket booking and movie seeking. Finally, we demonstrate several agents and detail the procedure to add and test your own agent in the proposed framework. version:1
arxiv-1612-05678 | Causal Discovery as Semi-Supervised Learning | http://arxiv.org/abs/1612.05678 | id:1612.05678 author:Chris. J. Oates, Sach Mukherjee category:stat.ML  published:2016-12-16 summary:In this short report, we discuss an approach to estimating causal graphs in which indicators of causal influence between variables are treated as labels in a machine learning formulation. Available data on the variables of interest are used as "inputs" to estimate the labels. We frame the problem as one of semi-supervised learning: available interventional data or background knowledge provide labels on some edges in the graph and the remaining edges are treated as unlabelled objects. To illustrate the key ideas, we consider a simple approach to feature construction (rooted in bivariate kernel density estimation) and embed this within a semi-supervised manifold framework. Results on yeast knockout data demonstrate that the proposed approach can identify causal relationships as validated by unseen interventional experiments. An advantage of the formulation we propose is that by reframing causal discovery as semi-supervised learning, it allows a range of data-driven approaches to be brought to bear on causal discovery, without demanding specification of full probability models or explicit models of underlying mechanisms. version:1
arxiv-1612-03929 | Online Sequence-to-Sequence Active Learning for Open-Domain Dialogue Generation | http://arxiv.org/abs/1612.03929 | id:1612.03929 author:Nabiha Asghar, Pascal Poupart, Xin Jiang, Hang Li category:cs.CL cs.AI cs.NE  published:2016-12-12 summary:We propose an online, end-to-end, neural generative conversational model for open-domain dialog. It is trained using a unique combination of offline two-phase supervised learning and online human-in-the-loop active learning. While most existing research proposes offline supervision or hand-crafted reward functions for online reinforcement, we devise a novel interactive learning mechanism based on a diversity-promoting heuristic for response generation and one-character user-feedback at each step. Experiments show that our model inherently promotes the generation of meaningful, relevant and interesting responses, and can be used to train agents with customized personas, moods and conversational styles. version:3
arxiv-1612-04887 | A Data-Driven Compressive Sensing Framework Tailored For Energy-Efficient Wearable Sensing | http://arxiv.org/abs/1612.04887 | id:1612.04887 author:Kai Xu, Yixing Li, Fengbo Ren category:cs.LG cs.IT math.IT  published:2016-12-15 summary:Compressive sensing (CS) is a promising technology for realizing energy-efficient wireless sensors for long-term health monitoring. However, conventional model-driven CS frameworks suffer from limited compression ratio and reconstruction quality when dealing with physiological signals due to inaccurate models and the overlook of individual variability. In this paper, we propose a data-driven CS framework that can learn signal characteristics and personalized features from any individual recording of physiologic signals to enhance CS performance with a minimized number of measurements. Such improvements are accomplished by a co-training approach that optimizes the sensing matrix and the dictionary towards improved restricted isometry property and signal sparsity, respectively. Experimental results upon ECG signals show that the proposed method, at a compression ratio of 10x, successfully reduces the isometry constant of the trained sensing matrices by 86% against random matrices and improves the overall reconstructed signal-to-noise ratio by 15dB over conventional model-driven approaches. version:2
arxiv-1612-05203 | CSVideoNet: A Recurrent Convolutional Neural Network for Compressive Sensing Video Reconstruction | http://arxiv.org/abs/1612.05203 | id:1612.05203 author:Kai Xu, Fengbo Ren category:cs.CV cs.LG  published:2016-12-15 summary:In this paper, we develop a deep neural network architecture called "CSVideoNet" that can learn visual representations from random measurements for compressive sensing (CS) video reconstruction. CSVideoNet is an end-to-end trainable and non-iterative model that combines convolutional neural networks (CNNs) with a recurrent neural networks (RNN) to facilitate video reconstruction by leveraging temporal-spatial features. The proposed network can accept random measurements with a multi-level compression ratio (CR). The lightly and aggressively compressed measurements offer background information and object details, respectively. This is similar to the variable bit rate techniques widely used in conventional video coding approaches. The RNN employed by CSVideoNet can leverage temporal coherence that exists in adjacent video frames to extrapolate motion features and merge them with spatial visual features extracted by the CNNs to further enhance reconstruction quality, especially at high CRs. We test our CSVideoNet on the UCF-101 dataset. Experimental results show that CSVideoNet outperforms the existing video CS reconstruction approaches. The results demonstrate that our method can preserve relatively excellent visual details from original videos even at a 100x CR, which is difficult to realize with the reference approaches. Also, the non-iterative nature of CSVideoNet results in an decrease in runtime by three orders of magnitude over iterative reconstruction algorithms. Furthermore, CSVideoNet can enhance the CR of CS cameras beyond the limitation of conventional approaches, ensuring a reduction in bandwidth for data transmission. These benefits are especially favorable to high-frame-rate video applications. version:2
arxiv-1612-05614 | An MM Algorithm for Split Feasibility Problems | http://arxiv.org/abs/1612.05614 | id:1612.05614 author:Jason Xu, Eric C. Chi, Meng Yang, Kenneth Lange category:math.OC math.NA stat.CO stat.ML  published:2016-12-16 summary:The classical split feasibility problem seeks a point in the intersection of finitely many closed convex domain constraints, whose image under a linear mapping also lies in the intersection of finitely many closed convex range constraints. Split feasibility generalizes important inverse problems including convex feasibility, linear complementarity, and regression with constraint sets. When a feasible point does not exist, solution methods that proceed by minimizing a proximity function can be used to obtain optimal approximate solutions to the problem. We present an extension of the proximity function approach that generalizes the linear split feasibility problem to allow for nonlinear mappings. Our algorithm is based on the principle of majorization-minimization, is amenable to quasi-Newton acceleration, and comes complete with convergence guarantees under mild assumptions. Furthermore, we show that the Euclidean norm appearing in the proximity function of the nonlinear split feasibility problem can be replaced by arbitrary Bregman divergences. We explore several examples illustrating the merits of nonlinear formulations over the linear case, with a focus on optimization for intensity-modulated radiation therapy data. version:1
arxiv-1612-05612 | Local Asymptotics for some Stochastic Optimization Problems: Optimality, Constraint Identification, and Dual Averaging | http://arxiv.org/abs/1612.05612 | id:1612.05612 author:John Duchi, Feng Ruan category:math.ST math.OC stat.ML stat.TH  published:2016-12-16 summary:We study local complexity measures for stochastic convex optimization problems, providing a local minimax theory analogous to that of H\'ajek and Le Cam for classical statistical problems, and providing efficient procedures based on Nesterov's dual averaging that (often) adaptively achieve optimal convergence guarantees. Our results strongly leverage the geometry of the optimization problem at hand, providing function-specific lower bounds and convergence results. We show how variants of dual averaging---a stochastic gradient-based procedure---guarantee finite time identification of constraints in optimization problems, while stochastic gradient procedures provably fail. Additionally, we highlight a gap between optimization problems with linear and nonlinear constraints: all of our stochastic-gradient-based procedures are suboptimal even for the simplest nonlinear constraints. version:1
arxiv-1612-05601 | Real-Time Detection and Localisation of Fetal Standard Scan Planes in 2D Freehand Ultrasound | http://arxiv.org/abs/1612.05601 | id:1612.05601 author:Christian F. Baumgartner, Konstantinos Kamnitsas, Jacqueline Matthew, Tara P. Fletcher, Sandra Smith, Lisa M. Koch, Bernhard Kainz, Daniel Rueckert category:cs.CV  published:2016-12-16 summary:Identifying and interpreting fetal standard scan planes during 2D ultrasound mid-pregnancy examinations are highly complex tasks which require years of training. Apart from guiding the probe to the correct location, it can be equally difficult for a non-expert to identify relevant structures within the image. Automatic image processing can provide tools to help experienced as well as inexperienced operators with these tasks. In this paper, we propose a novel method based on convolutional neural networks which can automatically detect 13 fetal standard views in freehand 2D ultrasound data as well as provide a localisation of the fetal structures via a bounding box. An important contribution is that the network learns to localise the target anatomy using weak supervision only. The network architecture is designed to operate in real-time while providing optimal output for the localisation task. We present results for real-time annotation, retrospective frame retrieval from saved videos, and localisation on a very large and challenging dataset consisting of images and video recordings of full clinical anomaly screenings. The proposed method annotated video frames with an average F1-score of 0.86, and obtained a 90.09% accuracy for retrospective frame retrieval. Moreover, we achieved an accuracy of 77.8% on the localisation task. version:1
arxiv-1612-05596 | Event-driven Random Back-Propagation: Enabling Neuromorphic Deep Learning Machines | http://arxiv.org/abs/1612.05596 | id:1612.05596 author:Emre Neftci, Charles Augustine, Somnath Paul, Georgios Detorakis category:cs.NE cs.AI  published:2016-12-16 summary:An ongoing challenge in neuromorphic computing is to devise general and computationally efficient models of inference and learning which are compatible with the spatial and temporal constraints of the brain. The gradient descent backpropagation rule is a powerful algorithm that is ubiquitous in deep learning, but it relies on the immediate availability of network-wide information stored with high-precision memory. However, recent work shows that exact backpropagated weights are not essential for learning deep representations. Random backpropagation replaces feedback weights with random ones and encourages the network to adjust its feed-forward weights to learn pseudo-inverses of the (random) feedback weights. Here, we demonstrate an event-driven random backpropagation (eRBP) rule that uses an error-modulated synaptic plasticity for learning deep representations in neuromorphic computing hardware. The rule is very suitable for implementation in neuromorphic hardware using a two-compartment leaky integrate & fire neuron and a membrane-voltage modulated, spike-driven plasticity rule. Our results show that using eRBP, deep representations are rapidly learned without using backpropagated gradients, achieving nearly identical classification accuracies compared to artificial neural network simulations on GPUs, while being robust to neural and synaptic state quantizations during learning. version:1
arxiv-1612-05571 | Delta Networks for Optimized Recurrent Network Computation | http://arxiv.org/abs/1612.05571 | id:1612.05571 author:Daniel Neil, Jun Haeng Lee, Tobi Delbruck, Shih-Chii Liu category:cs.NE  published:2016-12-16 summary:Many neural networks exhibit stability in their activation patterns over time in response to inputs from sensors operating under real-world conditions. By capitalizing on this property of natural signals, we propose a Recurrent Neural Network (RNN) architecture called a delta network in which each neuron transmits its value only when the change in its activation exceeds a threshold. The execution of RNNs as delta networks is attractive because their states must be stored and fetched at every timestep, unlike in convolutional neural networks (CNNs). We show that a naive run-time delta network implementation offers modest improvements on the number of memory accesses and computes, but optimized training techniques confer higher accuracy at higher speedup. With these optimizations, we demonstrate a 9X reduction in cost with negligible loss of accuracy for the TIDIGITS audio digit recognition benchmark. Similarly, on the large Wall Street Journal speech recognition benchmark even existing networks can be greatly accelerated as delta networks, and a 5.7x improvement with negligible loss of accuracy can be obtained through training. Finally, on an end-to-end CNN trained for steering angle prediction in a driving dataset, the RNN cost can be reduced by a substantial 100X. version:1
arxiv-1612-05536 | A new cut-based genetic algorithm for graph partitioning applied to cell formation | http://arxiv.org/abs/1612.05536 | id:1612.05536 author:Boulif Menouar category:cs.DM cs.NE 90C59  published:2016-12-16 summary:Cell formation is a critical step in the design of cellular manufacturing systems. Recently, it was tackled using a cut-based-graph-partitioning model. This model meets real-life production systems requirements as it uses the actual amount of product flows, it looks for the suitable number of cells, and it takes into account the natural constraints such as operation sequences, maximum cell size, cohabitation and non-cohabitation constraints. Based on this model, we propose an original encoding representation to solve the problem by using a genetic algorithm. We discuss the performance of this new GA in comparison to some approaches taken from the literature on a set of medium sized instances. Given the results we obtained, it is reasonable to assume that the new GA will provide similar results for large real-life problems. Keywords: Group Technology, Manufacturing Cell Formation, Graph Partitioning, Graph Cuts, Genetic Algorithm, Encoding representation. version:1
arxiv-1612-05535 | Quantum Machine Learning without Measurements | http://arxiv.org/abs/1612.05535 | id:1612.05535 author:Unai Alvarez-Rodriguez, Lucas Lamata, Pablo Escandell-Montero, José D. Martín-Guerrero, Enrique Solano category:quant-ph cond-mat.mes-hall cond-mat.supr-con cs.AI stat.ML  published:2016-12-16 summary:We propose a quantum machine learning algorithm for efficiently solving a class of problems encoded in quantum controlled unitary operations. The central physical mechanism of the protocol is the iteration of a quantum time-delayed equation that introduces feedback in the dynamics and eliminates the necessity of intermediate measurements. The performance of the quantum algorithm is analyzed by comparing the results obtained in numerical simulations with the outcome of classical machine learning methods for the same problem. The use of time-delayed equations enhances the toolbox of the field of quantum machine learning, which may enable unprecedented applications in quantum technologies. version:1
arxiv-1612-05533 | Deep Reinforcement Learning with Successor Features for Navigation across Similar Environments | http://arxiv.org/abs/1612.05533 | id:1612.05533 author:Jingwei Zhang, Jost Tobias Springenberg, Joschka Boedecker, Wolfram Burgard category:cs.RO cs.AI cs.LG  published:2016-12-16 summary:In this paper we consider the problem of robot navigation in simple maze-like environments where the robot has to rely on its onboard sensors to perform the navigation task. In particular, we are interested in solutions to this navigation task that do not require mapping and localization. Additionally, we require that our solution can quickly adapt to new situations (e.g., changing navigation goals and new environments). To meet these criteria we frame this task as a sequence of reinforcement learning problems over related tasks. We propose a successor feature based deep reinforcement learning algorithm that can learn to transfer knowledge from previously mastered navigation tasks to new problem instances. Our algorithm can substantially decrease the required learning time after the first task instance has been solved, which makes it easily adaptable to changing environments. We validate our method in both simulated and real robot experiments with a Robotino and compare it to a set of baseline methods including classical planning-based navigation. version:1
arxiv-1612-05519 | Edge-exchangeable graphs and sparsity (NIPS 2016) | http://arxiv.org/abs/1612.05519 | id:1612.05519 author:Diana Cai, Trevor Campbell, Tamara Broderick category:stat.ML  published:2016-12-16 summary:Many popular network models rely on the assumption of (vertex) exchangeability, in which the distribution of the graph is invariant to relabelings of the vertices. However, the Aldous-Hoover theorem guarantees that these graphs are dense or empty with probability one, whereas many real-world graphs are sparse. We present an alternative notion of exchangeability for random graphs, which we call edge exchangeability, in which the distribution of a graph sequence is invariant to the order of the edges. We demonstrate that edge-exchangeable models, unlike models that are traditionally vertex-exchangeable, can exhibit sparsity. To do so, we outline a general framework for graph generative models; by contrast to the pioneering work of Caron and Fox (2015), models within our framework are stationary across steps of the graph sequence. In particular, our model grows the graph by instantiating more latent atoms of a single random measure as the dataset size increases, rather than adding new atoms to the measure. version:1
arxiv-1612-05515 | On the crucial impact of the coupling projector-backprojector in iterative tomographic reconstruction | http://arxiv.org/abs/1612.05515 | id:1612.05515 author:Filippo Arcadu, Marco Stampanoni, Federica Marone category:cs.CV  published:2016-12-16 summary:The performance of an iterative reconstruction algorithm for X-ray tomography is strongly determined by the features of the used forward and backprojector. For this reason, a large number of studies has focused on the to design of projectors with increasingly higher accuracy and speed. To what extent the accuracy of an iterative algorithm is affected by the mathematical affinity and the similarity between the actual implementation of the forward and backprojection, referred here as "coupling projector-backprojector", has been an overlooked aspect so far. The experimental study presented here shows that the reconstruction quality and the convergence of an iterative algorithm greatly rely on a good matching between the implementation of the tomographic operators. In comparison, other aspects like the accuracy of the standalone operators, the usage of physical constraints or the choice of stopping criteria may even play a less relevant role. version:1
arxiv-1612-05478 | Video Propagation Networks | http://arxiv.org/abs/1612.05478 | id:1612.05478 author:Varun Jampani, Raghudeep Gadde, Peter V. Gehler category:cs.CV  published:2016-12-16 summary:In this paper we propose a technique that propagates information forward through video data. The method is conceptually simple and can be applied to tasks that require the propagation of structured information, such as semantic labels, based on video content. We propose a 'Video Propagation Network' that processes video frames in an adaptive manner. The model is applied online: it propagates information forward without the need to access future frames other than the current ones. In particular, we combine two components, a temporal bilateral network for dense and video adaptive filtering, followed by a spatial network to refine features and increased flexibility. We present experiments on video object segmentation and semantic video segmentation and show increased performance comparing to the best previous task-specific methods, while having favorable runtime. Additionally we demonstrate our approach on an example regression task of propagating color in a grayscale video. version:1
arxiv-1612-05476 | A Study of Lagrangean Decompositions and Dual Ascent Solvers for Graph Matching | http://arxiv.org/abs/1612.05476 | id:1612.05476 author:Paul Swoboda, Carsten Rother, Hassan Abu Alhaija, Dagmar Kainmueller, Bogdan Savchynskyy category:cs.CV  published:2016-12-16 summary:We study the quadratic assignment problem, in computer vision also known as graph matching. Two leading solvers for this problem optimize the Lagrange decomposition duals with sub-gradient and dual ascent (also known as message passing) updates. We explore s direction further and propose several additional Lagrangean relaxations of the graph matching problem along with corresponding algorithms, which are all based on a common dual ascent framework. Our extensive empirical evaluation gives several theoretical insights and suggests a new state-of-the-art any-time solver for the considered problem. Our improvement over state-of-the-art is particularly visible on a new dataset with large-scale sparse problem instances containing more than 500 graph nodes each. version:1
arxiv-1612-05460 | A Dual Ascent Framework for Lagrangean Decomposition of Combinatorial Problems | http://arxiv.org/abs/1612.05460 | id:1612.05460 author:Paul Swoboda, Jan Kuske, Bogdan Savchynskyy category:cs.DS cs.CV  published:2016-12-16 summary:We propose a general dual ascent framework for Lagrangean decomposition of combinatorial problems. Although methods of this type have shown their efficiency for a number of problems, so far there was no general algorithm applicable to multiple problem types. In his work, we propose such a general algorithm. It depends on several parameters, which can be used to optimize its performance in each particular setting. We demonstrate efficacy of our method on graph matching and multicut problems, where it outperforms state-of-the-art solvers including those based on subgradient optimization and off-the-shelf linear programming solvers. version:1
arxiv-1612-05441 | A Message Passing Algorithm for the Minimum Cost Multicut Problem | http://arxiv.org/abs/1612.05441 | id:1612.05441 author:Paul Swoboda, Bjoern Andres category:cs.DS cs.CV  published:2016-12-16 summary:We propose a dual decomposition and linear program relaxation of the NP -hard minimum cost multicut problem. Unlike other polyhedral relaxations of the multicut polytope, it is amenable to efficient optimization by message passing. Like other polyhedral elaxations, it can be tightened efficiently by cutting planes. We define an algorithm that alternates between message passing and efficient separation of cycle- and odd-wheel inequalities. This algorithm is more efficient than state-of-the-art algorithms based on linear programming, including algorithms written in the framework of leading commercial software, as we show in experiments with large instances of the problem from applications in computer vision, biomedical image analysis and data mining. version:1
arxiv-1612-05424 | Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks | http://arxiv.org/abs/1612.05424 | id:1612.05424 author:Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, Dilip Krishnan category:cs.CV  published:2016-12-16 summary:Collecting well-annotated image datasets to train modern machine learning algorithms is prohibitively expensive for many tasks. One appealing alternative is rendering synthetic data where ground-truth annotations are generated automatically. Unfortunately, models trained purely on rendered images often fail to generalize to real images. To address this shortcoming, prior work introduced unsupervised domain adaptation algorithms that attempt to map representations between the two domains or learn to extract features that are domain-invariant. In this work, we present a new approach that learns, in an unsupervised manner, a transformation in the pixel space from one domain to the other. Our generative adversarial network (GAN)-based method adapts source-domain images to appear as if drawn from the target domain. Our approach not only produces plausible samples, but also outperforms the state-of-the-art on a number of unsupervised domain adaptation scenarios by large margins. Finally, we demonstrate that the adaptation process generalizes to object classes unseen during training. version:1
arxiv-1612-05420 | A Two-Phase Approach Towards Identifying Argument Structure in Natural Language | http://arxiv.org/abs/1612.05420 | id:1612.05420 author:Arkanath Pathak, Pawan Goyal, Plaban Bhowmick category:cs.CL  published:2016-12-16 summary:We propose a new approach for extracting argument structure from natural language texts that contain an underlying argument. Our approach comprises of two phases: Score Assignment and Structure Prediction. The Score Assignment phase trains models to classify relations between argument units (Support, Attack or Neutral). To that end, different training strategies have been explored. We identify different linguistic and lexical features for training the classifiers. Through ablation study, we observe that our novel use of word-embedding features is most effective for this task. The Structure Prediction phase makes use of the scores from the Score Assignment phase to arrive at the optimal structure. We perform experiments on three argumentation datasets, namely, AraucariaDB, Debatepedia and Wikipedia. We also propose two baselines and observe that the proposed approach outperforms baseline systems for the final task of Structure Prediction. version:1
arxiv-1612-05400 | Deep Residual Hashing | http://arxiv.org/abs/1612.05400 | id:1612.05400 author:Sailesh Conjeti, Abhijit Guha Roy, Amin Katouzian, Nassir Navab category:cs.CV  published:2016-12-16 summary:Hashing aims at generating highly compact similarity preserving code words which are well suited for large-scale image retrieval tasks. Most existing hashing methods first encode the images as a vector of hand-crafted features followed by a separate binarization step to generate hash codes. This two-stage process may produce sub-optimal encoding. In this paper, for the first time, we propose a deep architecture for supervised hashing through residual learning, termed Deep Residual Hashing (DRH), for an end-to-end simultaneous representation learning and hash coding. The DRH model constitutes four key elements: (1) a sub-network with multiple stacked residual blocks; (2) hashing layer for binarization; (3) supervised retrieval loss function based on neighbourhood component analysis for similarity preserving embedding; and (4) hashing related losses and regularisation to control the quantization error and improve the quality of hash coding. We present results of extensive experiments on a large public chest x-ray image database with co-morbidities and discuss the outcome showing substantial improvements over the latest state-of-the art methods. version:1
