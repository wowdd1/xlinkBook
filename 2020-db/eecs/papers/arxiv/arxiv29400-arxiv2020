arxiv-1707-08713 | Determining Semantic Textual Similarity using Natural Deduction Proofs | http://arxiv.org/abs/1707.08713 | id:1707.08713 author:Hitomi Yanaka, Koji Mineshima, Pascual Martinez-Gomez, Daisuke Bekki category:cs.CL  published:2017-07-27 summary:Determining semantic textual similarity is a core research subject in natural language processing. Since vector-based models for sentence representation often use shallow information, capturing accurate semantics is difficult. By contrast, logical semantic representations capture deeper levels of sentence semantics, but their symbolic nature does not offer graded notions of textual similarity. We propose a method for determining semantic textual similarity by combining shallow features with features extracted from natural deduction proofs of bidirectional entailment relations between sentence pairs. For the natural deduction proofs, we use ccg2lambda, a higher-order automatic inference system, which converts Combinatory Categorial Grammar (CCG) derivation trees into semantic representations and conducts natural deduction proofs. Experiments show that our system was able to outperform other logic-based systems and that features derived from the proofs are effective for learning textual similarity. version:1
arxiv-1707-08712 | Signal and Noise Statistics Oblivious Sparse Reconstruction using OMP/OLS | http://arxiv.org/abs/1707.08712 | id:1707.08712 author:Sreejith Kallummil, Sheetal Kalyani category:stat.ML  published:2017-07-27 summary:Orthogonal matching pursuit (OMP) and orthogonal least squares (OLS) are widely used for sparse signal reconstruction in under-determined linear regression problems. The performance of these compressed sensing (CS) algorithms depends crucially on the \textit{a priori} knowledge of either the sparsity of the signal ($k_0$) or noise variance ($\sigma^2$). Both $k_0$ and $\sigma^2$ are unknown in general and extremely difficult to estimate in under determined models. This limits the application of OMP and OLS in many practical situations. In this article, we develop two computationally efficient frameworks namely TF-IGP and RRT-IGP for using OMP and OLS even when $k_0$ and $\sigma^2$ are unavailable. Both TF-IGP and RRT-IGP are analytically shown to accomplish successful sparse recovery under the same set of restricted isometry conditions on the design matrix required for OMP/OLS with \textit{a priori} knowledge of $k_0$ and $\sigma^2$. Numerical simulations also indicate a highly competitive performance of TF-IGP and RRT-IGP in comparison to OMP/OLS with \textit{a priori} knowledge of $k_0$ and $\sigma^2$. version:1
arxiv-1707-08705 | A Jointly Learned Deep Architecture for Facial Attribute Analysis and Face Detection in the Wild | http://arxiv.org/abs/1707.08705 | id:1707.08705 author:Keke He, Yanwei Fu, Xiangyang Xue category:cs.CV  published:2017-07-27 summary:Facial attribute analysis in the real world scenario is very challenging mainly because of complex face variations. Existing works of analyzing face attributes are mostly based on the cropped and aligned face images. However, this result in the capability of attribute prediction heavily relies on the preprocessing of face detector. To address this problem, we present a novel jointly learned deep architecture for both facial attribute analysis and face detection. Our framework can process the natural images in the wild and our experiments on CelebA and LFWA datasets clearly show that the state-of-the-art performance is obtained. version:1
arxiv-1707-08704 | Anytime Exact Belief Propagation | http://arxiv.org/abs/1707.08704 | id:1707.08704 author:Gabriel Azevedo Ferreira, Quentin Bertrand, Charles Maussion, Rodrigo de Salvo Braz category:cs.AI  published:2017-07-27 summary:Statistical Relational Models and, more recently, Probabilistic Programming, have been making strides towards an integration of logic and probabilistic reasoning. A natural expectation for this project is that a probabilistic logic reasoning algorithm reduces to a logic reasoning algorithm when provided a model that only involves 0-1 probabilities, exhibiting all the advantages of logic reasoning such as short-circuiting, intelligibility, and the ability to provide proof trees for a query answer. In fact, we can take this further and require that these characteristics be present even for probabilistic models with probabilities \emph{near} 0 and 1, with graceful degradation as the model becomes more uncertain. We also seek inference that has amortized constant time complexity on a model's size (even if still exponential in the induced width of a more directly relevant portion of it) so that it can be applied to huge knowledge bases of which only a relatively small portion is relevant to typical queries. We believe that, among the probabilistic reasoning algorithms, Belief Propagation is the most similar to logic reasoning: messages are propagated among neighboring variables, and the paths of message-passing are similar to proof trees. However, Belief Propagation is either only applicable to tree models, or approximate (and without guarantees) for precision and convergence. In this paper we present work in progress on an Anytime Exact Belief Propagation algorithm that is very similar to Belief Propagation but is exact even for graphical models with cycles, while exhibiting soft short-circuiting, amortized constant time complexity in the model size, and which can provide probabilistic proof trees. version:1
arxiv-1707-08691 | Adaptive and Resilient Revenue Maximizing Resource Allocation and Pricing in Cloud Computing Environments | http://arxiv.org/abs/1707.08691 | id:1707.08691 author:Muhammad Junaid Farooq, Quanyan Zhu category:cs.DC  published:2017-07-27 summary:Cloud computing is becoming an essential component of modern computer and communication systems. The available resources at the cloud such as computing nodes, storage, databases, etc. are often packaged in the form of virtual machines (VMs) to be used by remotely located client applications for computational tasks. However, the cloud has a limited number of VMs available, which have to be efficiently utilized to generate higher productivity and subsequently generate maximum revenue. Client applications generate requests with computational tasks at random times with random complexity to be processed by the cloud. The cloud service provider (CSP) has to decide whether to allocate a VM to a task at hand or to wait for a higher complexity task in the future. We propose a threshold-based mechanism to optimally decide the allocation and pricing of VMs to sequentially arriving requests in order to maximize the revenue of the CSP over a finite time horizon. Moreover, we develop an adaptive and resilient framework based that can counter the effect of realtime changes in the number of available VMs at the cloud server, the frequency and nature of arriving tasks on the revenue of the CSP. version:1
arxiv-1707-08689 | Multi-Robot Transfer Learning: A Dynamical System Perspective | http://arxiv.org/abs/1707.08689 | id:1707.08689 author:Mohamed K. Helwa, Angela P. Schoellig category:cs.RO cs.LG cs.SY  published:2017-07-27 summary:Multi-robot transfer learning allows a robot to use data generated by a second, similar robot to improve its own behavior. The potential advantages are reducing the time of training and the unavoidable risks that exist during the training phase. Transfer learning algorithms aim to find an optimal transfer map between different robots. In this paper, we investigate, through a theoretical study of single-input single-output (SISO) systems, the properties of such optimal transfer maps. We first show that the optimal transfer learning map is, in general, a dynamic system. The main contribution of the paper is to provide an algorithm for determining the properties of this optimal dynamic map including its order and regressors (i.e., the variables it depends on). The proposed algorithm does not require detailed knowledge of the robots' dynamics, but relies on basic system properties easily obtainable through simple experimental tests. We validate the proposed algorithm experimentally through an example of transfer learning between two different quadrotor platforms. Experimental results show that an optimal dynamic map, with correct properties obtained from our proposed algorithm, achieves 60-70% reduction of transfer learning error compared to the cases when the data is directly transferred or transferred using an optimal static map. version:1
arxiv-1707-08682 | Context-aware Single-Shot Detector | http://arxiv.org/abs/1707.08682 | id:1707.08682 author:Wei Xiang, Dong-Qing Zhang, Vassilis Athitsos, Heather Yu category:cs.CV  published:2017-07-27 summary:SSD is one of the state-of-the-art object detection algorithms, and it combines high detection accuracy with real-time speed. However, it is widely recognized that SSD is less accurate in detecting small objects compared to large objects, because it ignores the context from outside the proposal boxes. In this paper, we present CSSD--a shorthand for context-aware single-shot multibox object detector. CSSD is built on top of SSD, with additional layers modeling multi-scale contexts. We describe two variants of CSSD, which differ in their context layers, using dilated convolution layers (DiCSSD) and deconvolution layers (DeCSSD) respectively. The experimental results show that the multi-scale context modeling significantly improves the detection accuracy. In addition, we study the relationship between effective receptive fields (ERFs) and the theoretical receptive fields (TRFs), particularly on a VGGNet. The empirical results further strengthen our conclusion that SSD coupled with context layers achieves better detection results especially for small objects ($+3.2\% {\rm AP}_{@0.5}$ on MS-COCO compared to the newest SSD), while maintaining comparable runtime performance. version:1
arxiv-1707-08680 | Entropy-Based $Sim(3)$ Calibration of 2D Lidars to Egomotion Sensors | http://arxiv.org/abs/1707.08680 | id:1707.08680 author:Jacob Lambert, Lee Clement, Matthew Giamou, Jonathan Kelly category:cs.RO  published:2017-07-27 summary:This paper explores the use of an entropy-based technique for point cloud reconstruction with the goal of calibrating a lidar to a sensor capable of providing egomotion information. We extend recent work in this area to the problem of recovering the $Sim(3)$ transformation between a 2D lidar and a rigidly attached monocular camera, where the scale of the camera trajectory is not known a priori. We demonstrate the robustness of our approach on realistic simulations in multiple environments, as well as on data collected from a hand-held sensor rig. Given a non-degenerate trajectory and a sufficient number of lidar measurements, our calibration procedure achieves millimetre-scale and sub-degree accuracy. Moreover, our method relaxes the need for specific scene geometry, fiducial markers, or overlapping sensor fields of view, which had previously limited similar techniques. version:1
arxiv-1707-07847 | Enabling Efficient Question Answer Retrieval via Hyperbolic Neural Networks | http://arxiv.org/abs/1707.07847 | id:1707.07847 author:Yi Tay, Luu Anh Tuan, Siu Cheung Hui category:cs.IR cs.CL  published:2017-07-25 summary:Many state-of-the-art deep learning models for question answer retrieval are highly complex, often having a huge number of parameters or complicated word interaction mechanisms. This paper studies if it is possible to achieve equally competitive performance with smaller and faster neural architectures. Overall, our proposed approach is a simple neural network that performs question-answer matching and ranking in Hyperbolic space. We show that QA embeddings learned in Hyperbolic space results in highly competitive performance on multiple benchmarks, outperforming models with significantly much larger parameters. Our proposed approach (90K parameters) remains competitive to models with millions of parameters such as Attentive Pooling BiLSTMs or Multi-Perspective Convolutional Neural Networks (MP-CNN). version:2
arxiv-1707-03505 | Proximally Guided Stochastic Subgradient Method for Nonsmooth, Nonconvex Problems | http://arxiv.org/abs/1707.03505 | id:1707.03505 author:Damek Davis, Benjamin Grimmer category:math.OC cs.LG  published:2017-07-12 summary:In this paper we introduce a stochastic projected subgradient method for weakly convex (i.e., uniformly prox-regular) nonsmooth, nonconvex functions---a wide class of functions which includes the additive and convex composite classes. At a high-level the method is an inexact proximal point iteration in which the strongly convex proximal subproblems are quickly solved with a specialized stochastic projected subgradient method. The primary contribution of this paper is a simple proof that the proposed algorithm converges at the same rate as the stochastic gradient method for smooth nonconvex problems. This result validates the use of stochastic subgradient methods in nonsmooth, nonconvex optimization as is common when optimizing neural networks. version:2
arxiv-1707-08668 | A Tale of Two DRAGGNs: A Hybrid Approach for Interpreting Action-Oriented and Goal-Oriented Instructions | http://arxiv.org/abs/1707.08668 | id:1707.08668 author:Siddharth Karamcheti, Edward C. Williams, Dilip Arumugam, Mina Rhee, Nakul Gopalan, Lawson L. S. Wong, Stefanie Tellex category:cs.AI cs.CL  published:2017-07-26 summary:Robots operating alongside humans in diverse, stochastic environments must be able to accurately interpret natural language commands. These instructions often fall into one of two categories: those that specify a goal condition or target state, and those that specify explicit actions, or how to perform a given task. Recent approaches have used reward functions as a semantic representation of goal-based commands, which allows for the use of a state-of-the-art planner to find a policy for the given task. However, these reward functions cannot be directly used to represent action-oriented commands. We introduce a new hybrid approach, the Deep Recurrent Action-Goal Grounding Network (DRAGGN), for task grounding and execution that handles natural language from either category as input, and generalizes to unseen environments. Our robot-simulation results demonstrate that a system successfully interpreting both goal-oriented and action-oriented task specifications brings us closer to robust natural language understanding for human-robot interaction. version:1
arxiv-1707-08660 | Temporal dynamics of semantic relations in word embeddings: an application to predicting armed conflict participants | http://arxiv.org/abs/1707.08660 | id:1707.08660 author:Andrey Kutuzov, Erik Velldal, Lilja Øvrelid category:cs.CL  published:2017-07-26 summary:This paper deals with using word embedding models to trace the temporal dynamics of semantic relations between pairs of words. The set-up is similar to the well-known analogies task, but expanded with a time dimension. To this end, we apply incremental updating of the models with new training texts, including incremental vocabulary expansion, coupled with learned transformation matrices that let us map between members of the relation. The proposed approach is evaluated on the task of predicting insurgent armed groups based on geographical locations. The gold standard data for the time span 1994--2010 is extracted from the UCDP Armed Conflicts dataset. The results show that the method is feasible and outperforms the baselines, but also that important work still remains to be done. version:1
arxiv-1707-08645 | Learning a Target Sample Re-Generator for Cross-Database Micro-Expression Recognition | http://arxiv.org/abs/1707.08645 | id:1707.08645 author:Yuan Zong, Xiaohua Huang, Wenming Zheng, Zhen Cui, Guoying Zhao category:cs.CV  published:2017-07-26 summary:In this paper, we investigate the cross-database micro-expression recognition problem, where the training and testing samples are from two different micro-expression databases. Under this setting, the training and testing samples would have different feature distributions and hence the performance of most existing micro-expression recognition methods may decrease greatly. To solve this problem, we propose a simple yet effective method called Target Sample Re-Generator (TSRG) in this paper. By using TSRG, we are able to re-generate the samples from target micro-expression database and the re-generated target samples would share same or similar feature distributions with the original source samples. For this reason, we can then use the classifier learned based on the labeled source samples to accurately predict the micro-expression categories of the unlabeled target samples. To evaluate the performance of the proposed TSRG method, extensive cross-database micro-expression recognition experiments designed based on SMIC and CASME II databases are conducted. Compared with recent state-of-the-art cross-database emotion recognition methods, the proposed TSRG achieves more promising results. version:1
arxiv-1707-09428 | A unified method for super-resolution recovery and real exponential-sum separation | http://arxiv.org/abs/1707.09428 | id:1707.09428 author:Charles K. Chui, Hrushikesh N. Mhaskar category:math.NA cs.LG  published:2017-07-26 summary:In this paper, motivated by diffraction of traveling light waves, a simple mathematical model is proposed, both for the multivariate super-resolution problem and the problem of blind-source separation of real-valued exponential sums. This model facilitates the development of a unified theory and a unified solution of both problems in this paper. Our consideration of the super-resolution problem is aimed at applications to fluorescence microscopy and observational astronomy, and the motivation for our consideration of the second problem is the current need of extracting multivariate exponential features in magnetic resonance spectroscopy (MRS) for the neurologist and radiologist as well as for providing a mathematical tool for isotope separation in Nuclear Chemistry. The unified method introduced in this paper can be easily realized by processing only finitely many data, sampled at locations that are not necessarily prescribed in advance, with computational scheme consisting only of matrix - vector multiplication, peak finding, and clustering. version:1
arxiv-1707-09319 | A Fourier-invariant method for locating point-masses and computing their attributes | http://arxiv.org/abs/1707.09319 | id:1707.09319 author:Charles K. Chui, Hrushikesh N. Mhaskar category:stat.OT cs.LG math.NA  published:2017-07-26 summary:Motivated by the interest of observing the growth of cancer cells among normal living cells and exploring how galaxies and stars are truly formed, the objective of this paper is to introduce a rigorous and effective method for counting point-masses, determining their spatial locations, and computing their attributes. Based on computation of Hermite moments that are Fourier-invariant, our approach facilitates the processing of both spatial and Fourier data in any dimension. version:1
arxiv-1707-08630 | Optimizing Filter Size in Convolutional Neural Networks for Facial Action Unit Recognition | http://arxiv.org/abs/1707.08630 | id:1707.08630 author:Shizhong Han, Zibo Meng, James O'Reilly, Jie Cai, Xiaofeng Wang, Yan Tong category:cs.CV  published:2017-07-26 summary:Recognizing facial action units (AUs) during spontaneous facial displays is a challenging problem. Most recently, CNNs have shown promise for facial AU recognition, where predefined and fixed convolution filter sizes are employed. In order to achieve the best performance, the optimal filter size is often empirically found by conducting extensive experimental validation. Such a training process suffers from expensive training cost, especially as the network becomes deeper. In addition, AUs activated by different facial muscles produce facial appearance changes at different scales and thus prefer different filter sizes. This paper proposes a novel Optimized Filter Size CNN (OFS-CNN), where the filter sizes and weights of all convolutional layers are learned simultaneously from the training data along with learning convolution filters. Specifically, the filter size is defined as a continuous variable, which is optimized by minimizing the training loss. Experimental results on four AU-coded databases have shown that the proposed OFS-CNN outperforms traditional CNNs with fixed filter sizes and achieves state-of-the-art recognition performance for AU recognition. Furthermore, the OFS-CNN also beats traditional CNNs using the best filter size obtained by exhaustive search and is capable of estimating optimal filter size for varying image resolution. version:1
arxiv-1707-08626 | Robust Rigid Point Registration based on Convolution of Adaptive Gaussian Mixture Models | http://arxiv.org/abs/1707.08626 | id:1707.08626 author:Can Pu, Nanbo Li, Robert B Fisher category:cs.CV cs.AI cs.RO  published:2017-07-26 summary:Matching 3D rigid point clouds in complex environments robustly and accurately is still a core technique used in many applications. This paper proposes a new architecture combining error estimation from sample covariances and dual global probability alignment based on the convolution of adaptive Gaussian Mixture Models (GMM) from point clouds. Firstly, a novel adaptive GMM is defined using probability distributions from the corresponding points. Then rigid point cloud alignment is performed by maximizing the global probability from the convolution of dual adaptive GMMs in the whole 2D or 3D space, which can be efficiently optimized and has a large zone of accurate convergence. Thousands of trials have been conducted on 200 models from public 2D and 3D datasets to demonstrate superior robustness and accuracy in complex environments with unpredictable noise, outliers, occlusion, initial rotation, shape and missing points. version:1
arxiv-1707-07548 | Towards Accurate Markerless Human Shape and Pose Estimation over Time | http://arxiv.org/abs/1707.07548 | id:1707.07548 author:Yinghao Huang, Federica Bogo, Christoph Classner, Angjoo Kanazawa, Peter V. Gehler, Ijaz Akhter, Michael J. Black category:cs.CV  published:2017-07-24 summary:Existing marker-less motion capture methods often assume known backgrounds, static cameras, and sequence specific motion priors, which narrows its application scenarios. Here we propose a fully automatic method that given multi-view video, estimates 3D human motion and body shape. We take recent SMPLify \cite{bogo2016keep} as the base method, and extend it in several ways. First we fit the body to 2D features detected in multi-view images. Second, we use a CNN method to segment the person in each image and fit the 3D body model to the contours to further improves accuracy. Third we utilize a generic and robust DCT temporal prior to handle the left and right side swapping issue sometimes introduced by the 2D pose estimator. Validation on standard benchmarks shows our results are comparable to the state of the art and also provide a realistic 3D shape avatar. We also demonstrate accurate results on HumanEva and on challenging dance sequences from YouTube in monocular case. version:2
arxiv-1707-08616 | Guiding Reinforcement Learning Exploration Using Natural Language | http://arxiv.org/abs/1707.08616 | id:1707.08616 author:Brent Harrison, Upol Ehsan, Mark O. Riedl category:cs.AI cs.CL cs.LG stat.ML  published:2017-07-26 summary:In this work we present a technique to use natural language to help reinforcement learning generalize to unseen environments. This technique uses neural machine translation to learn associations between natural language behavior descriptions and state-action information. We then use this learned model to guide agent exploration to make it more effective at learning in unseen environments. We evaluate this technique using the popular arcade game, Frogger, under ideal and non-ideal conditions. This evaluation shows that our modified policy shaping algorithm improves over a Q-learning agent as well as a baseline version of policy shaping. version:1
arxiv-1707-08608 | Enforcing Constraints on Outputs with Unconstrained Inference | http://arxiv.org/abs/1707.08608 | id:1707.08608 author:Jay Yoon Lee, Michael Wick, Jean-Baptiste Tristan, Jaime Carbonell category:cs.CL  published:2017-07-26 summary:Increasingly, practitioners apply neural networks to complex problems in natural language processing (NLP), such as syntactic parsing, that have rich output structures. Many such applications require deterministic constraints on the output values; for example, requiring that the sequential outputs encode a valid tree. While hidden units might capture such properties, the network is not always able to learn them from the training data alone, and practitioners must then resort to post-processing. In this paper, we present an inference method for neural networks that enforces deterministic constraints on outputs without performing post-processing or expensive discrete search over the feasible space. Instead, for each input, we nudge the continuous weights until the network's unconstrained inference procedure generates an output that satisfies the constraints. We find that our method reduces the number of violating outputs by up to 94%, while improving accuracy in constituency parsing. version:1
arxiv-1707-06541 | Discretization-free Knowledge Gradient Methods for Bayesian Optimization | http://arxiv.org/abs/1707.06541 | id:1707.06541 author:Jian Wu, Peter I. Frazier category:stat.ML cs.AI cs.LG math.OC math.PR  published:2017-07-20 summary:This paper studies Bayesian ranking and selection (R&S) problems with correlated prior beliefs and continuous domains, i.e. Bayesian optimization (BO). Knowledge gradient methods [Frazier et al., 2008, 2009] have been widely studied for discrete R&S problems, which sample the one-step Bayes-optimal point. When used over continuous domains, previous work on the knowledge gradient [Scott et al., 2011, Wu and Frazier, 2016, Wu et al., 2017] often rely on a discretized finite approximation. However, the discretization introduces error and scales poorly as the dimension of domain grows. In this paper, we develop a fast discretization-free knowledge gradient method for Bayesian optimization. Our method is not restricted to the fully sequential setting, but useful in all settings where knowledge gradient can be used over continuous domains. We show how our method can be generalized to handle (i) batch of points suggestion (parallel knowledge gradient); (ii) the setting where derivative information is available in the optimization process (derivative-enabled knowledge gradient). In numerical experiments, we demonstrate that the discretization-free knowledge gradient method finds global optima significantly faster than previous Bayesian optimization algorithms on both synthetic test functions and real-world applications, especially when function evaluations are noisy; and derivative-enabled knowledge gradient can further improve the performances, even outperforming the gradient-based optimizer such as BFGS when derivative information is available. version:2
arxiv-1707-08600 | Pileup Mitigation with Machine Learning (PUMML) | http://arxiv.org/abs/1707.08600 | id:1707.08600 author:Patrick T. Komiske, Eric M. Metodiev, Benjamin Nachman, Matthew D. Schwartz category:hep-ph hep-ex stat.ML  published:2017-07-26 summary:Pileup involves the contamination of the energy distribution arising from the primary collision of interest (leading vertex) by radiation from soft collisions (pileup). We develop a new technique for removing this contamination using machine learning and convolutional neural networks. The network takes as input the energy distribution of charged leading vertex particles, charged pileup particles, and all neutral particles and outputs the energy distribution of particles coming from leading vertex alone. The PUMML algorithm performs remarkably well at eliminating pileup distortion on a wide range of simple and complex jet observables. We test the robustness of the algorithm in a number of ways and discuss how the network can be trained directly on data. version:1
arxiv-1707-08588 | Self-organized Hierarchical Softmax | http://arxiv.org/abs/1707.08588 | id:1707.08588 author:Yikang Shen, Shawn Tan, Chrisopher Pal, Aaron Courville category:cs.CL cs.LG  published:2017-07-26 summary:We propose a new self-organizing hierarchical softmax formulation for neural-network-based language models over large vocabularies. Instead of using a predefined hierarchical structure, our approach is capable of learning word clusters with clear syntactical and semantic meaning during the language model training process. We provide experiments on standard benchmarks for language modeling and sentence compression tasks. We find that this approach is as fast as other efficient softmax approximations, while achieving comparable or even better performance relative to similar full softmax models. version:1
arxiv-1704-06369 | NormFace: L2 Hypersphere Embedding for Face Verification | http://arxiv.org/abs/1704.06369 | id:1704.06369 author:Feng Wang, Xiang Xiang, Jian Cheng, Alan L. Yuille category:cs.CV  published:2017-04-21 summary:Thanks to the recent developments of Convolutional Neural Networks, the performance of face verification methods has increased rapidly. In a typical face verification method, feature normalization is a critical step for boosting performance. This motivates us to introduce and study the effect of normalization during training. But we find this is non-trivial, despite normalization being differentiable. We identify and study four issues related to normalization through mathematical analysis, which yields understanding and helps with parameter settings. Based on this analysis we propose two strategies for training using normalized features. The first is a modification of softmax loss, which optimizes cosine similarity instead of inner-product. The second is a reformulation of metric learning by introducing an agent vector for each class. We show that both strategies, and small variants, consistently improve performance by between 0.2% to 0.4% on the LFW dataset based on two models. This is significant because the performance of the two models on LFW dataset is close to saturation at over 98%. Codes and models are released on https://github.com/happynear/NormFace version:4
arxiv-1707-08561 | Quantum machine learning: a classical perspective | http://arxiv.org/abs/1707.08561 | id:1707.08561 author:Carlo Ciliberto, Mark Herbster, Alessandro Davide Ialongo, Massimiliano Pontil, Andrea Rocchetto, Simone Severini, Leonard Wossnig category:quant-ph cs.LG stat.ML  published:2017-07-26 summary:Recently, increased computational power and data availability, as well as algorithmic advances, have led machine learning techniques to impressive results in regression, classification, data-generation and reinforcement learning tasks. Despite these impressive results, the proximity to the physical limits of chip fabrication alongside the increasing size of datasets are motivating a growing number of researchers to explore the possibility of harnessing the power of quantum computation to speed-up classical machine learning algorithms. Here we review the literature in quantum machine learning and discuss perspectives for a mixed readership of classical machine learning and quantum computation experts. Particular emphasis will be placed on clarifying the limitations of quantum algorithms, how they compare with their best classical counterparts and why quantum resources are expected to provide advantages for learning problems. Learning in the presence of noise and certain computationally hard problems in machine learning are identified as promising directions for the field. Practical questions, like how to upload classical data into quantum form, will also be addressed. version:1
arxiv-1707-08559 | Video Highlight Prediction Using Audience Chat Reactions | http://arxiv.org/abs/1707.08559 | id:1707.08559 author:Cheng-Yang Fu, Joon Lee, Mohit Bansal, Alexander C. Berg category:cs.CL cs.AI cs.CV cs.LG cs.MM  published:2017-07-26 summary:Sports channel video portals offer an exciting domain for research on multimodal, multilingual analysis. We present methods addressing the problem of automatic video highlight prediction based on joint visual features and textual analysis of the real-world audience discourse with complex slang, in both English and traditional Chinese. We present a novel dataset based on League of Legends championships recorded from North American and Taiwanese Twitch.tv channels (will be released for further research), and demonstrate strong results on these using multimodal, character-level CNN-RNN model architectures. version:1
arxiv-1707-08554 | Interpatient Respiratory Motion Model Transfer for Virtual Reality Simulations of Liver Punctures | http://arxiv.org/abs/1707.08554 | id:1707.08554 author:Andre Mastmeyer, Matthias Wilms, Heinz Handels category:cs.CV  published:2017-07-26 summary:Current virtual reality (VR) training simulators of liver punctures often rely on static 3D patient data and use an unrealistic (sinusoidal) periodic animation of the respiratory movement. Existing methods for the animation of breathing motion support simple mathematical or patient-specific, estimated breathing models. However with personalized breathing models for each new patient, a heavily dose relevant or expensive 4D data acquisition is mandatory for keyframe-based motion modeling. Given the reference 4D data, first a model building stage using linear regression motion field modeling takes place. Then the methodology shown here allows the transfer of existing reference respiratory motion models of a 4D reference patient to a new static 3D patient. This goal is achieved by using non-linear inter-patient registration to warp one personalized 4D motion field model to new 3D patient data. This cost- and dose-saving new method is shown here visually in a qualitative proof-of-concept study. version:1
arxiv-1706-09880 | A Fixed-Point of View on Gradient Methods for Big Data | http://arxiv.org/abs/1706.09880 | id:1706.09880 author:Alexander Jung category:stat.ML  published:2017-06-29 summary:Interpreting gradient methods as fixed-point iterations, we provide a detailed analysis of those methods for minimizing convex objective functions. Due to their conceptual and algorithmic simplicity, gradient methods are widely used in machine learning for massive datasets (big data). In particular, stochastic gradient methods are considered the de- facto standard for training deep neural networks. Studying gradient methods within the realm of fixed-point theory provides us with powerful tools to analyze their convergence properties. In particular, gradient methods using inexact or noisy gradients, such as stochastic gradient descent, can be studied conveniently using well-known results on inexact fixed-point iterations. Moreover, as we demonstrate in this paper, the fixed-point approach allows an elegant derivation of accelerations for basic gradient methods. In particular, we will show how gradient descent can be accelerated by a fixed-point preserving transformation of an operator associated with the objective function. version:3
arxiv-1707-08553 | Direct Load Control of Thermostatically Controlled Loads Based on Sparse Observations Using Deep Reinforcement Learning | http://arxiv.org/abs/1707.08553 | id:1707.08553 author:Frederik Ruelens, Bert J. Claessens, Peter Vrancx, Fred Spiessens, Geert Deconinck category:cs.LG  published:2017-07-26 summary:This paper considers a demand response agent that must find a near-optimal sequence of decisions based on sparse observations of its environment. Extracting a relevant set of features from these observations is a challenging task and may require substantial domain knowledge. One way to tackle this problem is to store sequences of past observations and actions in the state vector, making it high dimensional, and apply techniques from deep learning. This paper investigates the capabilities of different deep learning techniques, such as convolutional neural networks and recurrent neural networks, to extract relevant features for finding near-optimal policies for a residential heating system and electric water heater that are hindered by sparse observations. Our simulation results indicate that in this specific scenario, feeding sequences of time-series to an LSTM network, which is a specific type of recurrent neural network, achieved a higher performance than stacking these time-series in the input of a convolutional neural network or deep neural network. version:1
arxiv-1707-08552 | A Robust Multi-Batch L-BFGS Method for Machine Learning | http://arxiv.org/abs/1707.08552 | id:1707.08552 author:Albert S. Berahas, Martin Takáč category:math.OC cs.LG stat.ML  published:2017-07-26 summary:This paper describes an implementation of the L-BFGS method designed to deal with two adversarial situations. The first occurs in distributed computing environments where some of the computational nodes devoted to the evaluation of the function and gradient are unable to return results on time. A similar challenge occurs in a multi-batch approach in which the data points used to compute function and gradients are purposely changed at each iteration to accelerate the learning process. Difficulties arise because L-BFGS employs gradient differences to update the Hessian approximations, and when these gradients are computed using different data points the updating process can be unstable. This paper shows how to perform stable quasi-Newton updating in the multi-batch setting, studies the convergence properties for both convex and nonconvex functions, and illustrates the behavior of the algorithm in a distributed computing platform on binary classification logistic regression and neural network training problems that arise in machine learning. version:1
arxiv-1707-08939 | Strawman: an Ensemble of Deep Bag-of-Ngrams for Sentiment Analysis | http://arxiv.org/abs/1707.08939 | id:1707.08939 author:Kyunghyun Cho category:cs.CL  published:2017-07-26 summary:This paper describes a builder entry, named "strawman", to the sentence-level sentiment analysis task of the "Build It, Break It" shared task of the First Workshop on Building Linguistically Generalizable NLP Systems. The goal of a builder is to provide an automated sentiment analyzer that would serve as a target for breakers whose goal is to find pairs of minimally-differing sentences that break the analyzer. version:1
arxiv-1707-08551 | TensorLayer: A Versatile Library for Efficient Deep Learning Development | http://arxiv.org/abs/1707.08551 | id:1707.08551 author:Hao Dong, Akara Supratak, Luo Mai, Fangde Liu, Axel Oehmichen, Simiao Yu, Yike Guo category:cs.LG cs.DC stat.ML  published:2017-07-26 summary:Deep learning has enabled major advances in the fields of computer vision, natural language processing, and multimedia among many others. Developing a deep learning system is arduous and complex, as it involves constructing neural network architectures, managing training/trained models, tuning optimization process, preprocessing and organizing data, etc. TensorLayer is a versatile Python library that aims at helping researchers and engineers efficiently develop deep learning systems. It offers rich abstractions for neural networks, model and data management, and parallel workflow mechanism. While boosting efficiency, TensorLayer maintains both performance and scalability. TensorLayer was released in September 2016 on GitHub, and has helped people from academia and industry develop real-world applications of deep learning. version:1
arxiv-1707-05967 | Measuring Thematic Fit with Distributional Feature Overlap | http://arxiv.org/abs/1707.05967 | id:1707.05967 author:Enrico Santus, Emmanuele Chersoni, Alessandro Lenci, Philippe Blache category:cs.CL  published:2017-07-19 summary:In this paper, we introduce a new distributional method for modeling predicate-argument thematic fit judgments. We use a syntax-based DSM to build a prototypical representation of verb-specific roles: for every verb, we extract the most salient second order contexts for each of its roles (i.e. the most salient dimensions of typical role fillers), and then we compute thematic fit as a weighted overlap between the top features of candidate fillers and role prototypes. Our experiments show that our method consistently outperforms a baseline re-implementing a state-of-the-art system, and achieves better or comparable results to those reported in the literature for the other unsupervised systems. Moreover, it provides an explicit representation of the features characterizing verb-specific semantic roles. version:2
arxiv-1707-04682 | Rethinking Reprojection: Closing the Loop for Pose-aware ShapeReconstruction from a Single Image | http://arxiv.org/abs/1707.04682 | id:1707.04682 author:Rui Zhu, Hamed Kiani Galoogahi, Chaoyang Wang, Simon Lucey category:cs.CV  published:2017-07-15 summary:An emerging problem in computer vision is the reconstruction of 3D shape and pose of an object from a single image. Hitherto, the problem has been addressed through the application of canonical deep learning methods to regress from the image directly to the 3D shape and pose labels. These approaches, however, are problematic from two perspectives. First, they are minimizing the error between 3D shapes and pose labels - with little thought about the nature of this label error when reprojecting the shape back onto the image. Second, they rely on the onerous and ill-posed task of hand labeling natural images with respect to 3D shape and pose. In this paper we define the new task of pose-aware shape reconstruction from a single image, and we advocate that cheaper 2D annotations of objects silhouettes in natural images can be utilized. We design architectures of pose-aware shape reconstruction which re-project the predicted shape back on to the image using the predicted pose. Our evaluation on several object categories demonstrates the superiority of our method for predicting pose-aware 3D shapes from natural images. version:2
arxiv-1707-08525 | A Guided Spatial Transformer Network for Histology Cell Differentiation | http://arxiv.org/abs/1707.08525 | id:1707.08525 author:Marc Aubreville, Maximilian Krappmann, Christof Bertram, Robert Klopfleisch, Andreas Maier category:cs.CV  published:2017-07-26 summary:Identification and counting of cells and mitotic figures is a standard task in diagnostic histopathology. Due to the large overall cell count on histological slides and the potential sparse prevalence of some relevant cell types or mitotic figures, retrieving annotation data for sufficient statistics is a tedious task and prone to a significant error in assessment. Automatic classification and segmentation is a classic task in digital pathology, yet it is not solved to a sufficient degree. We present a novel approach for cell and mitotic figure classification, based on a deep convolutional network with an incorporated Spatial Transformer Network. The network was trained on a novel data set with ten thousand mitotic figures, about ten times more than previous data sets. The algorithm is able to derive the cell class (mitotic tumor cells, non-mitotic tumor cells and granulocytes) and their position within an image. The mean accuracy of the algorithm in a five-fold cross-validation is 91.45%. In our view, the approach is a promising step into the direction of a more objective and accurate, semi-automatized mitosis counting supporting the pathologist. version:1
arxiv-1706-04859 | Sobolev Training for Neural Networks | http://arxiv.org/abs/1706.04859 | id:1706.04859 author:Wojciech Marian Czarnecki, Simon Osindero, Max Jaderberg, Grzegorz Świrszcz, Razvan Pascanu category:cs.LG  published:2017-06-15 summary:At the heart of deep learning we aim to use neural networks as function approximators - training them to produce outputs from inputs in emulation of a ground truth function or data creation process. In many cases we only have access to input-output pairs from the ground truth, however it is becoming more common to have access to derivatives of the target output with respect to the input - for example when the ground truth function is itself a neural network such as in network compression or distillation. Generally these target derivatives are not computed, or are ignored. This paper introduces Sobolev Training for neural networks, which is a method for incorporating these target derivatives in addition the to target values while training. By optimising neural networks to not only approximate the function's outputs but also the function's derivatives we encode additional information about the target function within the parameters of the neural network. Thereby we can improve the quality of our predictors, as well as the data-efficiency and generalization capabilities of our learned function approximation. We provide theoretical justifications for such an approach as well as examples of empirical evidence on three distinct domains: regression on classical optimisation datasets, distilling policies of an agent playing Atari, and on large-scale applications of synthetic gradients. In all three domains the use of Sobolev Training, employing target derivatives in addition to target values, results in models with higher accuracy and stronger generalisation. version:3
arxiv-1703-01945 | Point-Cloud-Based Aerial Fragmentation Analysis for Application in the Minerals Industry | http://arxiv.org/abs/1703.01945 | id:1703.01945 author:Thomas Bamford, Kamran Esmaeili, Angela P. Schoellig category:cs.RO  published:2017-03-06 summary:This work investigates the application of Unmanned Aerial Vehicle (UAV) technology for measurement of rock fragmentation without placement of scale objects in the scene to determine image scale. Commonly practiced image-based rock fragmentation analysis requires a technician to walk to a rock pile, place a scale object of known size in the area of interest, and capture individual 2D images. Our previous work has used UAV technology for the first time to acquire real-time rock fragmentation data and has shown comparable quality of results; however, it still required the (potentially dangerous) placement of scale objects, and continued to make the assumption that the rock pile surface is planar and that the scale objects lie on the surface plane. This work improves our UAV-based approach to enable rock fragmentation measurement without placement of scale objects and without the assumption of planarity. This is achieved by first generating a point cloud of the rock pile from 2D images, taking into account intrinsic and extrinsic camera parameters, and then taking 2D images for fragmentation analysis. This work represents an important step towards automating post-blast rock fragmentation analysis. In experiments, a rock pile with known size distribution was photographed by the UAV with and without using scale objects. For fragmentation analysis without scale objects, a point cloud of the rock pile was generated and used to compute image scale. Comparison of the rock size distributions show that this point-cloud-based method enables producing measurements with better or comparable accuracy (within 10% of the ground truth) to the manual method with scale objects. version:3
arxiv-1707-02786 | Unsupervised Learning of Task-Specific Tree Structures with Tree-LSTMs | http://arxiv.org/abs/1707.02786 | id:1707.02786 author:Jihun Choi, Kang Min Yoo, Sang-goo Lee category:cs.CL  published:2017-07-10 summary:For years, recursive neural networks (RvNNs) have shown to be suitable for representing text into fixed-length vectors and achieved good performance on several natural language processing tasks. However, the main drawback of RvNN is that it requires explicit tree structure (e.g. parse tree), which makes data preparation and model implementation hard. In this paper, we propose a novel tree-structured long short-term memory (Tree-LSTM) architecture that efficiently learns how to compose task-specific tree structures only from plain text data. To achieve this property, our model uses Straight-Through (ST) Gumbel-Softmax estimator to decide the parent node among candidates and to calculate gradients of the discrete decision. We evaluate the proposed model on natural language interface and sentiment analysis and show that our model outperforms or at least comparable to previous Tree-LSTM-based works. Especially in the natural language interface task, our model establishes the new state-of-the-art accuracy of 85.4%. We also find that our model converges significantly faster and needs less memory than other models of complex structures. version:2
arxiv-1707-08496 | Fast Distributed Approximation for Max-Cut | http://arxiv.org/abs/1707.08496 | id:1707.08496 author:Keren Censor-Hillel, Rina Levy, Hadas Shachnai category:cs.DS cs.DC  published:2017-07-26 summary:Finding a maximum cut is a fundamental task in many computational settings. Surprisingly, it has been insufficiently studied in the classic distributed settings, where vertices communicate by synchronously sending messages to their neighbors according to the underlying graph, known as the $\mathcal{LOCAL}$ or $\mathcal{CONGEST}$ models. We amend this by obtaining almost optimal algorithms for Max-Cut on a wide class of graphs in these models. In particular, for any $\epsilon > 0$, we develop randomized approximation algorithms achieving a ratio of $(1-\epsilon)$ to the optimum for Max-Cut on bipartite graphs in the $\mathcal{CONGEST}$ model, and on general graphs in the $\mathcal{LOCAL}$ model. We further present efficient deterministic algorithms, including a $1/3$-approximation for Max-Dicut in our models, thus improving the best known (randomized) ratio of $1/4$. Our algorithms make non-trivial use of the greedy approach of Buchbinder et al. (SIAM Journal on Computing, 2015) for maximizing an unconstrained (non-monotone) submodular function, which may be of independent interest. version:1
arxiv-1707-08454 | Making the best of data derived from a daily practice in clinical legal medicine for research and practice - the example of Spe3dLab | http://arxiv.org/abs/1707.08454 | id:1707.08454 author:Vincent Laugier, Eric Stindel, Alcibiade Lichterowicz, Séverine Ansart, Thomas Lefèvre category:cs.CY cs.AI  published:2017-07-26 summary:Forensic science suffers from a lack of studies with high-quality design, such as randomized controlled trials (RCT). Evidence in forensic science may be of insufficient quality, which is a major concern. Results from RCT are criticized for providing artificial results that are not useful in real life and unfit for individualized prescription. Various sources of collected data (e.g. data collected in routine practice) could be exploited for distinct goals. Obstacles remain before such data can be practically accessed and used, including technical issues. We present an easy-to-use software dedicated to innovative data analyses for practitioners and researchers. We provide 2 examples in forensics. Spe3dLab has been developed by 3 French teams: a bioinformatics laboratory (LaTIM), a private partner (Tekliko) and a department of forensic medicine (Jean Verdier Hospital). It was designed to be open source, relying on documented and maintained libraries, query-oriented and capable of handling the entire data process from capture to export of best predictive models for their integration in information systems. Spe3dLab was used for 2 specific forensics applications: i) the search for multiple causal factors and ii) the best predictive model of the functional impairment (total incapacity to work, TIW) of assault survivors. 2,892 patients were included over a 6-month period. Time to evaluation was the only direct cause identified for TIW, and victim category was an indirect cause. The specificity and sensitivity of the predictive model were 99.9% and 90%, respectively. Spe3dLab is a quick and efficient tool for accessing observational, routinely collected data and performing innovative analyses. Analyses can be exported for validation and routine use by practitioners, e.g., for computer-aided evaluation of complex problems. It can provide a fully integrated solution for individualized medicine. version:1
arxiv-1707-08493 | Dynamic Clustering Algorithms via Small-Variance Analysis of Markov Chain Mixture Models | http://arxiv.org/abs/1707.08493 | id:1707.08493 author:Trevor Campbell, Brian Kulis, Jonathan How category:stat.ML  published:2017-07-26 summary:Bayesian nonparametrics are a class of probabilistic models in which the model size is inferred from data. A recently developed methodology in this field is small-variance asymptotic analysis, a mathematical technique for deriving learning algorithms that capture much of the flexibility of Bayesian nonparametric inference algorithms, but are simpler to implement and less computationally expensive. Past work on small-variance analysis of Bayesian nonparametric inference algorithms has exclusively considered batch models trained on a single, static dataset, which are incapable of capturing time evolution in the latent structure of the data. This work presents a small-variance analysis of the maximum a posteriori filtering problem for a temporally varying mixture model with a Markov dependence structure, which captures temporally evolving clusters within a dataset. Two clustering algorithms result from the analysis: D-Means, an iterative clustering algorithm for linearly separable, spherical clusters; and SD-Means, a spectral clustering algorithm derived from a kernelized, relaxed version of the clustering problem. Empirical results from experiments demonstrate the advantages of using D-Means and SD-Means over contemporary clustering algorithms, in terms of both computational cost and clustering accuracy. version:1
arxiv-1707-08488 | A New Framework for Synthetic Aperture Sonar Micronavigation | http://arxiv.org/abs/1707.08488 | id:1707.08488 author:Salvatore Caporale, Yvan Petillot category:cs.SY cs.RO 93C85 I.2.9  published:2017-07-26 summary:Synthetic aperture imaging systems achieve constant azimuth resolution by coherently summating the observations acquired along the aperture path. At this aim, their locations have to be known with subwavelength accuracy. In underwater Synthetic Aperture Sonar (SAS), the nature of propagation and navigation in water makes the retrieval of this information challenging. Inertial sensors have to be employed in combination with signal processing techniques, which are usually referred to as micronavigation. In this paper we propose a novel micronavigation approach based on the minimization of an error function between two contiguous pings having some mutual information. This error is obtained by comparing the vector space intersections between the pings orthogonal projectors. The effectiveness and generality of the proposed approach is demonstrated by means of simulations and by means of an experiment performed in a controlled environment. version:1
arxiv-1707-07540 | Pound: A ROS node for Reducing Delay and Jitter in Wireless Multi-Robot Networks | http://arxiv.org/abs/1707.07540 | id:1707.07540 author:Danilo Tardioli, Ramviyas Parasuraman, Petter Ögren category:cs.NI cs.RO  published:2017-07-20 summary:The Robot Operating System (ROS) is rapidly becoming the de facto framework for building robotics systems, thanks to its flexibility and the large acceptance that it has received in the robotics community. With the growth of its popularity, it has started to be used in multi-robot systems as well. However, the TCP connections that the platform relies on for connecting the so-called ROS nodes, presents several issues in terms of limited-bandwidth, delays and jitter, when used in wireless ad-hoc networks. In this paper, we present a thorough analysis of the problem and propose a new ROS node called Pound to improve the wireless communication performance. Pound allows the use of multiple ROS cores and introduces a priority scheme favoring more important flows over less important ones, thus reducing delay and jitter over single-hop and multihop networks. We compare Pound to the state-of-the-art solutions and show that it performs equally well, or better in all the test cases, including a control-over-network example. version:2
arxiv-1707-08475 | DARLA: Improving Zero-Shot Transfer in Reinforcement Learning | http://arxiv.org/abs/1707.08475 | id:1707.08475 author:Irina Higgins, Arka Pal, Andrei A. Rusu, Loic Matthey, Christopher P Burgess, Alexander Pritzel, Matthew Botvinick, Charles Blundell, Alexander Lerchner category:stat.ML cs.AI cs.LG  published:2017-07-26 summary:Domain adaptation is an important open problem in deep reinforcement learning (RL). In many scenarios of interest data is hard to obtain, so agents may learn a source policy in a setting where data is readily available, with the hope that it generalises well to the target domain. We propose a new multi-stage RL agent, DARLA (DisentAngled Representation Learning Agent), which learns to see before learning to act. DARLA's vision is based on learning a disentangled representation of the observed environment. Once DARLA can see, it is able to acquire source policies that are robust to many domain shifts - even with no access to the target domain. DARLA significantly outperforms conventional baselines in zero-shot domain adaptation scenarios, an effect that holds across a variety of RL environments (Jaco arm, DeepMind Lab) and base RL algorithms (DQN, A3C and EC). version:1
arxiv-1707-08470 | Implicit Entity Linking in Tweets | http://arxiv.org/abs/1707.08470 | id:1707.08470 author:Sujan Perera, Pablo N. Mendes, Adarsh Alex, Amit Sheth, Krishnaprasad Thirunarayan category:cs.CL cs.AI  published:2017-07-26 summary:Over the years, Twitter has become one of the largest communication platforms providing key data to various applications such as brand monitoring, trend detection, among others. Entity linking is one of the major tasks in natural language understanding from tweets and it associates entity mentions in text to corresponding entries in knowledge bases in order to provide unambiguous interpretation and additional con- text. State-of-the-art techniques have focused on linking explicitly mentioned entities in tweets with reasonable success. However, we argue that in addition to explicit mentions i.e. The movie Gravity was more ex- pensive than the mars orbiter mission entities (movie Gravity) can also be mentioned implicitly i.e. This new space movie is crazy. you must watch it!. This paper introduces the problem of implicit entity linking in tweets. We propose an approach that models the entities by exploiting their factual and contextual knowledge. We demonstrate how to use these models to perform implicit entity linking on a ground truth dataset with 397 tweets from two domains, namely, Movie and Book. Specifically, we show: 1) the importance of linking implicit entities and its value addition to the standard entity linking task, and 2) the importance of exploiting contextual knowledge associated with an entity for linking their implicit mentions. We also make the ground truth dataset publicly available to foster the research in this new research area. version:1
arxiv-1707-08458 | Men Are from Mars, Women Are from Venus: Evaluation and Modelling of Verbal Associations | http://arxiv.org/abs/1707.08458 | id:1707.08458 author:Ekaterina Vylomova, Andrei Shcherbakov, Yuriy Philippovich, Galina Cherkasova category:cs.CL  published:2017-07-26 summary:We present a quantitative analysis of human word association pairs and study the types of relations presented in the associations. We put our main focus on the correlation between response types and respondent characteristics such as occupation and gender by contrasting syntagmatic and paradigmatic associations. Finally, we propose a personalised distributed word association model and show the importance of incorporating demographic factors into the models commonly used in natural language processing. version:1
arxiv-1707-08438 | Context-Independent Polyphonic Piano Onset Transcription with an Infinite Training Dataset | http://arxiv.org/abs/1707.08438 | id:1707.08438 author:Samuel Li category:stat.ML cs.SD  published:2017-07-26 summary:Many of the recent approaches to polyphonic piano note onset transcription require training a machine learning model on a large piano database. However, such approaches are limited by dataset availability; additional training data is difficult to produce, and proposed systems often perform poorly on novel recording conditions. We propose a method to quickly synthesize arbitrary quantities of training data, avoiding the need for curating large datasets. Various aspects of piano note dynamics - including nonlinearity of note signatures with velocity, different articulations, temporal clustering of onsets, and nonlinear note partial interference - are modeled to match the characteristics of real pianos. Our method also avoids the disentanglement problem, a recently noted issue affecting machine-learning based approaches. We train a feed-forward neural network with two hidden layers on our generated training data and achieve both good transcription performance on the large MAPS piano dataset and excellent generalization qualities. version:1
arxiv-1707-01009 | Visually Grounded Word Embeddings and Richer Visual Features for Improving Multimodal Neural Machine Translation | http://arxiv.org/abs/1707.01009 | id:1707.01009 author:Jean-Benoit Delbrouck, Stéphane Dupont, Omar Seddati category:cs.CL  published:2017-07-04 summary:In Multimodal Neural Machine Translation (MNMT), a neural model generates a translated sentence that describes an image, given the image itself and one source descriptions in English. This is considered as the multimodal image caption translation task. The images are processed with Convolutional Neural Network (CNN) to extract visual features exploitable by the translation model. So far, the CNNs used are pre-trained on object detection and localization task. We hypothesize that richer architecture, such as dense captioning models, may be more suitable for MNMT and could lead to improved translations. We extend this intuition to the word-embeddings, where we compute both linguistic and visual representation for our corpus vocabulary. We combine and compare different confi version:4
arxiv-1707-08423 | Non-Stationary Bandits with Habituation and Recovery Dynamics | http://arxiv.org/abs/1707.08423 | id:1707.08423 author:Yonatan Mintz, Anil Aswani, Philip Kaminsky, Elena Flowers, Yoshimi Fukuoka category:math.OC cs.LG  published:2017-07-26 summary:Many settings require a decision maker to repeatedly choose from a set of interventions to apply to an individual without knowing the interventions' efficacy a priori. However, repeated application of a specific intervention may reduce its efficacy, while abstaining from applying an intervention may cause its efficacy to recover. Such phenomena are observed in many real world settings such as personalized healthcare-adherence improving interventions and targeted online advertising. Though finding an optimal intervention policy for models with this structure is PSPACE-complete, we propose and analyze a new class of models called ROGUE (Reducing or Gaining Unknown Efficacy) bandits, which we show in this paper can capture these phenomena and can be efficiently solved. We first present a consistent maximum likelihood approach to estimate the parameters of these models, and conduct a statistical analysis to construct finite sample concentration bounds. These statistical bounds are used to derive an upper confidence bound strategy that we call the ROGUE Upper Confidence Bound (ROGUE-UCB) algorithm. Our theoretical analysis shows that the ROGUE-UCB algorithm achieves logarithmic in time regret, unlike existing algorithms which result in linear regret. We conclude with a numerical experiment using real world data from a personalized healthcare-adherence improving intervention to increase physical activity. Here, the goal is to optimize the selection of messages (e.g., confidence increasing vs. knowledge increasing) to send to each individual each day to increase adherence and physical activity. Our results show that ROGUE-UCB performs better in terms of aggregated regret and average reward when compared to state of the art algorithms, and the use of ROGUE-UCB increases daily step counts by roughly 1,000 steps a day (about a half-mile more of walking) as compared to other algorithms. version:1
arxiv-1707-08418 | The Advantage of Evidential Attributes in Social Networks | http://arxiv.org/abs/1707.08418 | id:1707.08418 author:Salma Ben Dhaou, Kuang Zhou, Mouloud Kharoune, Arnaud Martin, Boutheina Ben Yaghlane category:cs.AI cs.SI  published:2017-07-26 summary:Nowadays, there are many approaches designed for the task of detecting communities in social networks. Among them, some methods only consider the topological graph structure, while others take use of both the graph structure and the node attributes. In real-world networks, there are many uncertain and noisy attributes in the graph. In this paper, we will present how we detect communities in graphs with uncertain attributes in the first step. The numerical, probabilistic as well as evidential attributes are generated according to the graph structure. In the second step, some noise will be added to the attributes. We perform experiments on graphs with different types of attributes and compare the detection results in terms of the Normalized Mutual Information (NMI) values. The experimental results show that the clustering with evidential attributes gives better results comparing to those with probabilistic and numerical attributes. This illustrates the advantages of evidential attributes. version:1
arxiv-1609-04600 | When to make a step? Tackling the timing problem in multi-contact locomotion by TOPP-MPC | http://arxiv.org/abs/1609.04600 | id:1609.04600 author:Stéphane Caron, Quang-Cuong Pham category:cs.RO  published:2016-09-15 summary:We present a model predictive controller (MPC) for multi-contact locomotion where predictive optimizations are realized by time-optimal path parameterization (TOPP). A key feature of this solution is that, contrary to existing planners where step timings are provided as inputs, here the timing between contact switches is computed as output of a fast nonlinear optimization. This is particularly appealing to multi-contact locomotion, where proper timings depend on terrain topology and suitable heuristics are unknown. We show how to formulate legged locomotion as a TOPP problem and demonstrate the behavior of the resulting TOPP-MPC controller in simulations with a model of the HRP-4 humanoid robot. version:2
arxiv-1707-08401 | Detecting and classifying lesions in mammograms with Deep Learning | http://arxiv.org/abs/1707.08401 | id:1707.08401 author:Dezső Ribli, Anna Horváth, Zsuzsa Unger, Péter Pollner, István Csabai category:cs.CV  published:2017-07-26 summary:In the last two decades Computer Aided Diagnostics (CAD) systems were developed to help radiologists analyze screening mammograms. The benefits of current CAD technologies appear to be contradictory and they should be improved to be ultimately considered useful. Since 2012 deep convolutional neural networks (CNN) have been a tremendous success in image recognition, reaching human performance. These methods have greatly surpassed the traditional approaches, which are similar to currently used CAD solutions. Deep CNN-s have the potential to revolutionize medical image analysis. We propose a CAD system based on one of the most successful object detection frameworks, Faster R-CNN. The system detects and classifies malignant or benign lesions on a mammogram without any human intervention. Our approach described here has achieved the 2nd place in the Digital Mammography DREAM Challenge with $ AUC = 0.85 $. The proposed method also sets the state of the art classification performance on the public INbreast database, $ AUC = 0.95$. When used as a detector, the system reaches high sensitivity with very few false positive marks per image on the INbreast dataset. version:1
arxiv-1707-08398 | A Harmony Search Based Wrapper Feature Selection Method for Holistic Bangla word Recognition | http://arxiv.org/abs/1707.08398 | id:1707.08398 author:Supratim Das, Pawan Kumar Singh, Showmik Bhowmik, Ram Sarkar, Mita Nasipuri category:cs.CV 68T10  published:2017-07-26 summary:A lot of search approaches have been explored for the selection of features in pattern classification domain in order to discover significant subset of the features which produces better accuracy. In this paper, we introduced a Harmony Search (HS) algorithm based feature selection method for feature dimensionality reduction in handwritten Bangla word recognition problem. This algorithm has been implemented to reduce the feature dimensionality of a technique described in one of our previous papers by S. Bhowmik et al.[1]. In the said paper, a set of 65 elliptical features were computed for handwritten Bangla word recognition purpose and a recognition accuracy of 81.37% was achieved using Multi Layer Perceptron (MLP) classifier. In the present work, a subset containing 48 features (approximately 75% of said feature vector) has been selected by HS based wrapper feature selection method which produces an accuracy rate of 90.29%. Reasonable outcomes also validates that the introduced algorithm utilizes optimal number of features while showing higher classification accuracies when compared to two standard evolutionary algorithms like Genetic Algorithm (GA), Particle Swarm Optimization (PSO) and statistical feature dimensionality reduction technique like Principal Component Analysis (PCA). This confirms the suitability of HS algorithm to the holistic handwritten word recognition problem. version:1
arxiv-1707-08391 | Maximum entropy based non-negative optoacoustic tomographic image reconstruction | http://arxiv.org/abs/1707.08391 | id:1707.08391 author:Jaya Prakash, Subhamoy Mandal, Daniel Razansky, Vasilis Ntziachristos category:physics.med-ph cs.CV  published:2017-07-26 summary:Optoacoustic (photoacoustic) tomography reconstructs maps of the initial pressure rise induced by the absorption of light pulses in tissue. In practice, due to inaccurate assumptions in the forward model employed, noise and other experimental factors, the images often contain errors, occasionally manifested as negative values. We present optoacoustic tomography based on an entropy maximization algorithm that uses logarithmic regularization as a potent method for imparting non-negative image reconstruction. We experimentally investigate the performance achieved by the entropy maximization scheme on phantoms and in vivo samples. The findings demonstrate that the proposed scheme reconstructs physically relevant image values devoid of unwanted negative contrast, thus improving quantitative imaging performance. version:1
arxiv-1707-08386 | Reduction of Overfitting in Diabetes Prediction Using Deep Learning Neural Network | http://arxiv.org/abs/1707.08386 | id:1707.08386 author:Akm Ashiquzzaman, Abdul Kawsar Tushar, Md. Rashedul Islam, Jong-Myon Kim category:cs.CV  published:2017-07-26 summary:Augmented accuracy in prediction of diabetes will open up new frontiers in health prognostics. Data overfitting is a performance-degrading issue in diabetes prognosis. In this study, a prediction system for the disease of diabetes is pre-sented where the issue of overfitting is minimized by using the dropout method. Deep learning neural network is used where both fully connected layers are fol-lowed by dropout layers. The output performance of the proposed neural network is shown to have outperformed other state-of-art methods and it is recorded as by far the best performance for the Pima Indians Diabetes Data Set. version:1
arxiv-1707-08385 | A Novel Transfer Learning Approach upon Hindi, Arabic, and Bangla Numerals using Convolutional Neural Networks | http://arxiv.org/abs/1707.08385 | id:1707.08385 author:Abdul Kawsar Tushar, Akm Ashiquzzaman, Afia Afrin, Md. Rashedul Islam category:cs.CV  published:2017-07-26 summary:Increased accuracy in predictive models for handwritten character recognition will open up new frontiers for optical character recognition. Major drawbacks of predictive machine learning models are headed by the elongated training time taken by some models, and the requirement that training and test data be in the same feature space and consist of the same distribution. In this study, these obstacles are minimized by presenting a model for transferring knowledge from one task to another. This model is presented for the recognition of handwritten numerals in Indic languages. The model utilizes convolutional neural networks with backpropagation for error reduction and dropout for data overfitting. The output performance of the proposed neural network is shown to have closely matched other state-of-the-art methods using only a fraction of time used by the state-of-the-arts. version:1
arxiv-1707-08384 | Sequential design of experiments to estimate a probability of exceeding a threshold in a multi-fidelity stochastic simulator | http://arxiv.org/abs/1707.08384 | id:1707.08384 author:Rémi Stroh, Séverine Demeyer, Nicolas Fischer, Julien Bect, Emmanuel Vazquez category:stat.CO stat.ME stat.ML  published:2017-07-26 summary:In this article, we consider a stochastic numerical simulator to assess the impact of some factors on a phenomenon. The simulator is seen as a black box with inputs and outputs. The quality of a simulation, hereafter referred to as fidelity, is assumed to be tunable by means of an additional input of the simulator (e.g., a mesh size parameter): high-fidelity simulations provide more accurate results, but are time-consuming. Using a limited computation-time budget, we want to estimate, for any value of the physical inputs, the probability that a certain scalar output of the simulator will exceed a given critical threshold at the highest fidelity level. The problem is addressed in a Bayesian framework, using a Gaussian process model of the multi-fidelity simulator. We consider a Bayesian estimator of the probability, together with an associated measure of uncertainty, and propose a new multi-fidelity sequential design strategy, called Maximum Speed of Uncertainty Reduction (MSUR), to select the value of physical inputs and the fidelity level of new simulations. The MSUR strategy is tested on an example. version:1
arxiv-1707-08381 | Prediction of amino acid side chain conformation using a deep neural network | http://arxiv.org/abs/1707.08381 | id:1707.08381 author:Ke Liu, Xiangyan Sun, Jun Ma, Zhenyu Zhou, Qilin Dong, Shengwen Peng, Junqiu Wu, Suocheng Tan, Günter Blobel, Jie Fan category:q-bio.BM cs.LG stat.ML  published:2017-07-26 summary:A deep neural network based architecture was constructed to predict amino acid side chain conformation with unprecedented accuracy. Amino acid side chain conformation prediction is essential for protein homology modeling and protein design. Current widely-adopted methods use physics-based energy functions to evaluate side chain conformation. Here, using a deep neural network architecture without physics-based assumptions, we have demonstrated that side chain conformation prediction accuracy can be improved by more than 25%, especially for aromatic residues compared with current standard methods. More strikingly, the prediction method presented here is robust enough to identify individual conformational outliers from high resolution structures in a protein data bank without providing its structural factors. We envisage that our amino acid side chain predictor could be used as a quality check step for future protein structure model validation and many other potential applications such as side chain assignment in Cryo-electron microscopy, crystallography model auto-building, protein folding and small molecule ligand docking. version:1
arxiv-1707-08378 | Product recognition in store shelves as a sub-graph isomorphism problem | http://arxiv.org/abs/1707.08378 | id:1707.08378 author:Alessio Tonioni, Luigi Di Stefano category:cs.CV  published:2017-07-26 summary:The arrangement of products in store shelves is carefully planned to maximize sales and keep customers happy. However, verifying compliance of real shelves to the ideal layout is a costly task routinely performed by the store personnel. In this paper, we propose a computer vision pipeline to recognize products on shelves and verify compliance to the planned layout. We deploy local invariant features together with a novel formulation of the product recognition problem as a sub-graph isomorphism between the items appearing in the given image and the ideal layout. This allows for auto-localizing the given image within the aisle or store and improving recognition dramatically. version:1
arxiv-1707-08369 | Updating Singular Value Decomposition for Rank One Matrix Perturbation | http://arxiv.org/abs/1707.08369 | id:1707.08369 author:Ratnik Gandhi, Amoli Rajgor category:cs.LG math.NA  published:2017-07-26 summary:An efficient Singular Value Decomposition (SVD) algorithm is an important tool for distributed and streaming computation in big data problems. It is observed that update of singular vectors of a rank-1 perturbed matrix is similar to a Cauchy matrix-vector product. With this observation, in this paper, we present an efficient method for updating Singular Value Decomposition of rank-1 perturbed matrix in $O(n^2 \ \text{log}(\frac{1}{\epsilon}))$ time. The method uses Fast Multipole Method (FMM) for updating singular vectors in $O(n \ \text{log} (\frac{1}{\epsilon}))$ time, where $\epsilon$ is the precision of computation. version:1
arxiv-1707-08364 | Deep Interactive Region Segmentation and Captioning | http://arxiv.org/abs/1707.08364 | id:1707.08364 author:Ali Sharifi Boroujerdi, Maryam Khanian, Michael Breuss category:cs.CV 68T45  published:2017-07-26 summary:With recent innovations in dense image captioning, it is now possible to describe every object of the scene with a caption while objects are determined by bounding boxes. However, interpretation of such an output is not trivial due to the existence of many overlapping bounding boxes. Furthermore, in current captioning frameworks, the user is not able to involve personal preferences to exclude out of interest areas. In this paper, we propose a novel hybrid deep learning architecture for interactive region segmentation and captioning where the user is able to specify an arbitrary region of the image that should be processed. To this end, a dedicated Fully Convolutional Network (FCN) named Lyncean FCN (LFCN) is trained using our special training data to isolate the User Intention Region (UIR) as the output of an efficient segmentation. In parallel, a dense image captioning model is utilized to provide a wide variety of captions for that region. Then, the UIR will be explained with the caption of the best match bounding box. To the best of our knowledge, this is the first work that provides such a comprehensive output. Our experiments show the superiority of the proposed approach over state-of-the-art interactive segmentation methods on several well-known datasets. In addition, replacement of the bounding boxes with the result of the interactive segmentation leads to a better understanding of the dense image captioning output as well as accuracy enhancement for the object detection in terms of Intersection over Union (IoU). version:1
arxiv-1608-06767 | On-line Joint Limit Avoidance for Torque Controlled Robots by Joint Space Parametrization | http://arxiv.org/abs/1608.06767 | id:1608.06767 author:Marie Charbonneau, Francesco Nori, Daniele Pucci category:cs.RO  published:2016-08-24 summary:This paper proposes control laws ensuring the stabilization of a time-varying desired joint trajectory, as well as joint limit avoidance, in the case of fully-actuated manipulators. The key idea is to perform a parametrization of the feasible joint space in terms of exogenous states. It follows that the control of these states allows for joint limit avoidance. One of the main outcomes of this paper is that position terms in control laws are replaced by parametrized terms, where joint limits must be avoided. Stability and convergence of time-varying reference trajectories obtained with the proposed method are demonstrated to be in the sense of Lyapunov. The introduced control laws are verified by carrying out experiments on two degrees-of-freedom of the humanoid robot iCub. version:2
arxiv-1707-08359 | An Optimization Based Control Framework for Balancing and Walking: Implementation on the iCub Robot | http://arxiv.org/abs/1707.08359 | id:1707.08359 author:Marie Charbonneau, Gabriele Nava, Francesco Nori, Daniele Pucci category:cs.RO  published:2017-07-26 summary:A whole-body torque control framework adapted for balancing and walking tasks is presented in this paper. In the proposed approach, centroidal momentum terms are excluded in favor of a hierarchy of high-priority position and orientation tasks and a low-priority postural task. More specifically, the controller stabilizes the position of the center of mass, the orientation of the pelvis frame, as well as the position and orientation of the feet frames. The low-priority postural task provides reference positions for each joint of the robot. Joint torques and contact forces to stabilize tasks are obtained through quadratic programming optimization. Besides the exclusion of centroidal momentum terms, part of the novelty of the approach lies in the definition of control laws in SE(3) which do not require the use of Euler parameterization. Validation of the framework was achieved in a scenario where the robot kept balance while walking in place. Experiments have been conducted with the iCub robot, in simulation and in real-world experiments. version:1
arxiv-1707-08357 | Performance Comparison of Various STM Concurrency Control Protocols Using Synchrobench | http://arxiv.org/abs/1707.08357 | id:1707.08357 author:Ajay Singh, Sathya Peri, G Monika, Anila Kumari category:cs.DC  published:2017-07-26 summary:Writing concurrent programs for shared memory multiprocessor systems is a nightmare. This hinders users to exploit the full potential of multiprocessors. STM (Software Transactional Memory) is a promising concurrent programming paradigm which addresses woes of programming for multiprocessor systems. In this paper, we implement BTO (Basic Timestamp Ordering), SGT (Serialization Graph Testing) and MVTO(Multi-Version Time-Stamp Ordering) concurrency control protocols and build an STM(Software Transactional Memory) library to evaluate the performance of these protocols. The deferred write approach is followed to implement the STM. A SET data structure is implemented using the transactions of our STM library. And this transactional SET is used as a test application to evaluate the STM. The performance of the protocols is rigorously compared against the linked-list module of the Synchrobench benchmark. Linked list module implements SET data structure using lazy-list, lock-free list, lock-coupling list and ESTM (Elastic Software Transactional Memory). Our analysis shows that for a number of threads greater than 60 and update rate 70%, BTO takes (17% to 29%) and (6% to 24%) less CPU time per thread when compared against lazy-list and lock-coupling list respectively. MVTO takes (13% to 24%) and (3% to 24%) less CPU time per thread when compared against lazy-list and lock-coupling list respectively. BTO and MVTO have similar per thread CPU time. BTO and MVTO outperform SGT by 9% to 36%. version:1
arxiv-1707-08352 | General Latent Feature Modeling for Data Exploration Tasks | http://arxiv.org/abs/1707.08352 | id:1707.08352 author:Isabel Valera, Melanie F. Pradier, Zoubin Ghahramani category:stat.ML cs.LG  published:2017-07-26 summary:This paper introduces a general Bayesian non- parametric latent feature model suitable to per- form automatic exploratory analysis of heterogeneous datasets, where the attributes describing each object can be either discrete, continuous or mixed variables. The proposed model presents several important properties. First, it accounts for heterogeneous data while can be inferred in linear time with respect to the number of objects and attributes. Second, its Bayesian nonparametric nature allows us to automatically infer the model complexity from the data, i.e., the number of features necessary to capture the latent structure in the data. Third, the latent features in the model are binary-valued variables, easing the interpretability of the obtained latent features in data exploration tasks. version:1
arxiv-1707-08350 | Modelling the Scene Dependent Imaging in Cameras with a Deep Neural Network | http://arxiv.org/abs/1707.08350 | id:1707.08350 author:Seonghyeon Nam, Seon Joo Kim category:cs.CV  published:2017-07-26 summary:We present a novel deep learning framework that models the scene dependent image processing inside cameras. Often called as the radiometric calibration, the process of recovering RAW images from processed images (JPEG format in the sRGB color space) is essential for many computer vision tasks that rely on physically accurate radiance values. All previous works rely on the deterministic imaging model where the color transformation stays the same regardless of the scene and thus they can only be applied for images taken under the manual mode. In this paper, we propose a data-driven approach to learn the scene dependent and locally varying image processing inside cameras under the automode. Our method incorporates both the global and the local scene context into pixel-wise features via multi-scale pyramid of learnable histogram layers. The results show that we can model the imaging pipeline of different cameras that operate under the automode accurately in both directions (from RAW to sRGB, from sRGB to RAW) and we show how we can apply our method to improve the performance of image deblurring. version:1
arxiv-1707-08349 | Can string kernels pass the test of time in Native Language Identification? | http://arxiv.org/abs/1707.08349 | id:1707.08349 author:Radu Tudor Ionescu, Marius Popescu category:cs.CL  published:2017-07-26 summary:We describe a machine learning approach for the 2017 shared task on Native Language Identification (NLI). The proposed approach combines several kernels using multiple kernel learning. While most of our kernels are based on character p-grams (also known as n-grams) extracted from essays or speech transcripts, we also use a kernel based on i-vectors, a low-dimensional representation of audio recordings, provided by the shared task organizers. For the learning stage, we choose Kernel Discriminant Analysis (KDA) over Kernel Ridge Regression (KRR), because the former classifier obtains better results than the latter one on the development set. In our previous work, we have used a similar machine learning approach to achieve state-of-the-art NLI results. The goal of this paper is to demonstrate that our shallow and simple approach based on string kernels (with minor improvements) can pass the test of time and reach state-of-the-art performance in the 2017 NLI shared task, despite the recent advances in natural language processing. We participated in all three tracks, in which the competitors were allowed to use only the essays (essay track), only the speech transcripts (speech track), or both (fusion track). Using only the data provided by the organizers for training our models, we have reached a macro F1 score of 86.95% in the closed essay track, a macro F1 score of 87.55% in the closed speech track, and a macro F1 score of 93.19% in the closed fusion track. With these scores, our team (UnibucKernel) ranked in the first group of teams in all three tracks, while attaining the best scores in the speech and the fusion tracks. version:1
arxiv-1707-08347 | RankIQA: Learning from Rankings for No-reference Image Quality Assessment | http://arxiv.org/abs/1707.08347 | id:1707.08347 author:Xialei Liu, Joost van de Weijer, Andrew D. Bagdanov category:cs.CV  published:2017-07-26 summary:We propose a no-reference image quality assessment (NR-IQA) approach that learns from rankings (RankIQA). To address the problem of limited IQA dataset size, we train a Siamese Network to rank images in terms of image quality by using synthetically generated distortions for which relative image quality is known. These ranked image sets can be automatically generated without laborious human labeling. We then use fine-tuning to transfer the knowledge represented in the trained Siamese Network to a traditional CNN that estimates absolute image quality from single images. We demonstrate how our approach can be made significantly more efficient than traditional Siamese Networks by forward propagating a batch of images through a single network and backpropagating gradients derived from all pairs of images in the batch. Experiments on the TID2013 benchmark show that we improve the state-of-the-art by over 5%. Furthermore, on the LIVE benchmark we show that our approach is superior to existing NR-IQA techniques and that we even outperform the state-of-the-art in full-reference IQA (FR-IQA) methods without having to resort to high-quality reference images to infer IQA. version:1
arxiv-1707-08342 | Declarative Sequential Pattern Mining of Care Pathways | http://arxiv.org/abs/1707.08342 | id:1707.08342 author:Thomas Guyet, André Happe, Yann Dauxais category:cs.AI  published:2017-07-26 summary:Sequential pattern mining algorithms are widely used to explore care pathways database, but they generate a deluge of patterns, mostly redundant or useless. Clinicians need tools to express complex mining queries in order to generate less but more significant patterns. These algorithms are not versatile enough to answer complex clinician queries. This article proposes to apply a declarative pattern mining approach based on Answer Set Programming paradigm. It is exemplified by a pharmaco-epidemiological study investigating the possible association between hospitalization for seizure and antiepileptic drug switch from a french medico-administrative database. version:1
arxiv-1707-08340 | Structure-Preserving Image Super-resolution via Contextualized Multi-task Learning | http://arxiv.org/abs/1707.08340 | id:1707.08340 author:Yukai Shi, Keze Wang, Chongyu Chen, Li Xu, Liang Lin category:cs.CV  published:2017-07-26 summary:Single image super resolution (SR), which refers to reconstruct a higher-resolution (HR) image from the observed low-resolution (LR) image, has received substantial attention due to its tremendous application potentials. Despite the breakthroughs of recently proposed SR methods using convolutional neural networks (CNNs), their generated results usually lack of preserving structural (high-frequency) details. In this paper, regarding global boundary context and residual context as complimentary information for enhancing structural details in image restoration, we develop a contextualized multi-task learning framework to address the SR problem. Specifically, our method first extracts convolutional features from the input LR image and applies one deconvolutional module to interpolate the LR feature maps in a content-adaptive way. Then, the resulting feature maps are fed into two branched sub-networks. During the neural network training, one sub-network outputs salient image boundaries and the HR image, and the other sub-network outputs the local residual map, i.e., the residual difference between the generated HR image and ground-truth image. On several standard benchmarks (i.e., Set5, Set14 and BSD200), our extensive evaluations demonstrate the effectiveness of our SR method on achieving both higher restoration quality and computational efficiency compared with several state-of-the-art SR approaches. The source code and some SR results can be found at: http://hcp.sysu.edu.cn/structure-preserving-image-super-resolution/ version:1
arxiv-1707-08325 | Asymmetric Deep Supervised Hashing | http://arxiv.org/abs/1707.08325 | id:1707.08325 author:Qing-Yuan Jiang, Wu-Jun Li category:cs.LG stat.ML  published:2017-07-26 summary:Hashing has been widely used for large-scale approximate nearest neighbor search because of its storage and search efficiency. Recent work has found that deep supervised hashing can significantly outperform non-deep supervised hashing in many applications. However, most existing deep supervised hashing methods adopt a symmetric strategy to learn one deep hash function for both query points and database (retrieval) points. The training of these symmetric deep supervised hashing methods is typically time-consuming, which makes them hard to effectively utilize the supervised information for cases with large-scale database. In this paper, we propose a novel deep supervised hashing method, called asymmetric deep supervised hashing (ADSH), for large-scale nearest neighbor search. ADSH treats the query points and database points in an asymmetric way. More specifically, ADSH learns a deep hash function only for query points, while the hash codes for database points are directly learned. The training of ADSH is much more efficient than that of traditional symmetric deep supervised hashing methods. Experiments show that ADSH can achieve state-of-the-art performance in real applications. version:1
arxiv-1707-08316 | Learning Sparse Representations in Reinforcement Learning with Sparse Coding | http://arxiv.org/abs/1707.08316 | id:1707.08316 author:Lei Le, Raksha Kumaraswamy, Martha White category:cs.AI cs.LG stat.ML  published:2017-07-26 summary:A variety of representation learning approaches have been investigated for reinforcement learning; much less attention, however, has been given to investigating the utility of sparse coding. Outside of reinforcement learning, sparse coding representations have been widely used, with non-convex objectives that result in discriminative representations. In this work, we develop a supervised sparse coding objective for policy evaluation. Despite the non-convexity of this objective, we prove that all local minima are global minima, making the approach amenable to simple optimization strategies. We empirically show that it is key to use a supervised objective, rather than the more straightforward unsupervised sparse coding approach. We compare the learned representations to a canonical fixed sparse representation, called tile-coding, demonstrating that the sparse coding representation outperforms a wide variety of tilecoding representations. version:1
arxiv-1707-07958 | Residual Conv-Deconv Grid Network for Semantic Segmentation | http://arxiv.org/abs/1707.07958 | id:1707.07958 author:Damien Fourure, Rémi Emonet, Elisa Fromont, Damien Muselet, Alain Tremeau, Christian Wolf category:cs.CV  published:2017-07-25 summary:This paper presents GridNet, a new Convolutional Neural Network (CNN) architecture for semantic image segmentation (full scene labelling). Classical neural networks are implemented as one stream from the input to the output with subsampling operators applied in the stream in order to reduce the feature maps size and to increase the receptive field for the final prediction. However, for semantic image segmentation, where the task consists in providing a semantic class to each pixel of an image, feature maps reduction is harmful because it leads to a resolution loss in the output prediction. To tackle this problem, our GridNet follows a grid pattern allowing multiple interconnected streams to work at different resolutions. We show that our network generalizes many well known networks such as conv-deconv, residual or U-Net networks. GridNet is trained from scratch and achieves competitive results on the Cityscapes dataset. version:2
arxiv-1707-08313 | Cascaded Scene Flow Prediction using Semantic Segmentation | http://arxiv.org/abs/1707.08313 | id:1707.08313 author:Zhile Ren, Deqing Sun, Jan Kautz, Erik B. Sudderth category:cs.CV  published:2017-07-26 summary:Given two consecutive frames from a pair of stereo cameras, 3D scene flow methods simultaneously estimate the 3D geometry and motion of the observed scene. Many existing approaches use superpixels for regularization, but may predict inconsistent shapes and motions inside rigidly moving objects. We instead assume that scenes consist of foreground objects rigidly moving in front of a static background, and use semantic cues to produce pixel-accurate scene flow estimates. Our cascaded classification framework accurately models 3D scenes by iteratively refining semantic segmentation masks, stereo correspondences, 3D rigid motion estimates, and optical flow fields. We evaluate our method on the challenging KITTI autonomous driving benchmark, and show that accounting for the motion of segmented vehicles leads to state-of-the-art performance. version:1
arxiv-1707-08998 | ASDA : Analyseur Syntaxique du Dialecte Alg{é}rien dans un but d'analyse s{é}mantique | http://arxiv.org/abs/1707.08998 | id:1707.08998 author:Imène Guellil, Faiçal Azouaou category:cs.CL  published:2017-07-26 summary:Opinion mining and sentiment analysis in social media is a research issue having a great interest in the scientific community. However, before begin this analysis, we are faced with a set of problems. In particular, the problem of the richness of languages and dialects within these media. To address this problem, we propose in this paper an approach of construction and implementation of Syntactic analyzer named ASDA. This tool represents a parser for the Algerian dialect that label the terms of a given corpus. Thus, we construct a labeling table containing for each term its stem, different prefixes and suffixes, allowing us to determine the different grammatical parts a sort of POS tagging. This labeling will serve us later in the semantic processing of the Algerian dialect, like the automatic translation of this dialect or sentiment analysis version:1
arxiv-1707-08309 | Probabilistic Graphical Models for Credibility Analysis in Evolving Online Communities | http://arxiv.org/abs/1707.08309 | id:1707.08309 author:Subhabrata Mukherjee category:cs.SI cs.AI cs.CL cs.IR stat.ML  published:2017-07-26 summary:One of the major hurdles preventing the full exploitation of information from online communities is the widespread concern regarding the quality and credibility of user-contributed content. Prior works in this domain operate on a static snapshot of the community, making strong assumptions about the structure of the data (e.g., relational tables), or consider only shallow features for text classification. To address the above limitations, we propose probabilistic graphical models that can leverage the joint interplay between multiple factors in online communities --- like user interactions, community dynamics, and textual content --- to automatically assess the credibility of user-contributed online content, and the expertise of users and their evolution with user-interpretable explanation. To this end, we devise new models based on Conditional Random Fields for different settings like incorporating partial expert knowledge for semi-supervised learning, and handling discrete labels as well as numeric ratings for fine-grained analysis. This enables applications such as extracting reliable side-effects of drugs from user-contributed posts in healthforums, and identifying credible content in news communities. Online communities are dynamic, as users join and leave, adapt to evolving trends, and mature over time. To capture this dynamics, we propose generative models based on Hidden Markov Model, Latent Dirichlet Allocation, and Brownian Motion to trace the continuous evolution of user expertise and their language model over time. This allows us to identify expert users and credible content jointly over time, improving state-of-the-art recommender systems by explicitly considering the maturity of users. This also enables applications such as identifying helpful product reviews, and detecting fake and anomalous reviews with limited information. version:1
arxiv-1707-08308 | Tensor Regression Networks | http://arxiv.org/abs/1707.08308 | id:1707.08308 author:Jean Kossaifi, Zachary C. Lipton, Aran Khanna, Tommaso Furlanello, Anima Anandkumar category:cs.LG  published:2017-07-26 summary:To date, most convolutional neural network architectures output predictions by flattening 3rd-order activation tensors, and applying fully-connected output layers. This approach has two drawbacks: (i) we lose rich, multi-modal structure during the flattening process and (ii) fully-connected layers require many parameters. We present the first attempt to circumvent these issues by expressing the output of a neural network directly as the the result of a multi-linear mapping from an activation tensor to the output. By imposing low-rank constraints on the regression tensor, we can efficiently solve problems for which existing solutions are badly parametrized. Our proposed tensor regression layer replaces flattening operations and fully-connected layers by leveraging multi-modal structure in the data and expressing the regression weights via a low rank tensor decomposition. Additionally, we combine tensor regression with tensor contraction to further increase efficiency. Augmenting the VGG and ResNet architectures, we demonstrate large reductions in the number of parameters with negligible impact on performance on the ImageNet dataset. version:1
arxiv-1707-08040 | A Simple Exponential Family Framework for Zero-Shot Learning | http://arxiv.org/abs/1707.08040 | id:1707.08040 author:Vinay Kumar Verma, Piyush Rai category:cs.LG cs.CV stat.ML  published:2017-07-25 summary:We present a simple generative framework for learning to predict previously unseen classes, based on estimating class-attribute-gated class-conditional distributions. We model each class-conditional distribution as an exponential family distribution and the parameters of the distribution of each seen/unseen class are defined as functions of the respective observed class attributes. These functions can be learned using only the seen class data and can be used to predict the parameters of the class-conditional distribution of each unseen class. Unlike most existing methods for zero-shot learning that represent classes as fixed embeddings in some vector space, our generative model naturally represents each class as a probability distribution. It is simple to implement and also allows leveraging additional unlabeled data from unseen classes to improve the estimates of their class-conditional distributions using transductive/semi-supervised learning. Moreover, it extends seamlessly to few-shot learning by easily updating these distributions when provided with a small number of additional labelled examples from unseen classes. Through a comprehensive set of experiments on several benchmark data sets, we demonstrate the efficacy of our framework. version:2
arxiv-1707-08301 | Graph-Based Classification of Omnidirectional Images | http://arxiv.org/abs/1707.08301 | id:1707.08301 author:Renata Khasanova, Pascal Frossard category:cs.CV cs.LG  published:2017-07-26 summary:Omnidirectional cameras are widely used in such areas as robotics and virtual reality as they provide a wide field of view. Their images are often processed with classical methods, which might unfortunately lead to non-optimal solutions as these methods are designed for planar images that have different geometrical properties than omnidirectional ones. In this paper we study image classification task by taking into account the specific geometry of omnidirectional cameras with graph-based representations. In particular, we extend deep learning architectures to data on graphs; we propose a principled way of graph construction such that convolutional filters respond similarly for the same pattern on different positions of the image regardless of lens distortions. Our experiments show that the proposed method outperforms current techniques for the omnidirectional image classification problem. version:1
arxiv-1707-06742 | Machine Teaching: A New Paradigm for Building Machine Learning Systems | http://arxiv.org/abs/1707.06742 | id:1707.06742 author:Patrice Y. Simard, Saleema Amershi, David M. Chickering, Alicia Edelman Pelton, Soroush Ghorashi, Christopher Meek, Gonzalo Ramos, Jina Suh, Johan Verwey, Mo Wang, John Wernsing category:cs.LG cs.AI cs.HC cs.SE stat.ML  published:2017-07-21 summary:The current processes for building machine learning systems require practitioners with deep knowledge of machine learning. This significantly limits the number of machine learning systems that can be created and has led to a mismatch between the demand for machine learning systems and the ability for organizations to build them. We believe that in order to meet this growing demand for machine learning systems we must significantly increase the number of individuals that can teach machines. We postulate that we can achieve this goal by making the process of teaching machines easy, fast and above all, universally accessible. While machine learning focuses on creating new algorithms and improving the accuracy of "learners", the machine teaching discipline focuses on the efficacy of the "teachers". Machine teaching as a discipline is a paradigm shift that follows and extends principles of software engineering and programming languages. We put a strong emphasis on the teacher and the teacher's interaction with data, as well as crucial components such as techniques and design principles of interaction and visualization. In this paper, we present our position regarding the discipline of machine teaching and articulate fundamental machine teaching principles. We also describe how, by decoupling knowledge about machine learning algorithms from the process of teaching, we can accelerate innovation and empower millions of new uses for machine learning models. version:2
arxiv-1707-08290 | Fast calculation of entropy with Zhang's estimator | http://arxiv.org/abs/1707.08290 | id:1707.08290 author:Antoni Lozano, Bernardino Casas, Chris Bentz, Ramon Ferrer-i-Cancho category:cs.CL  published:2017-07-26 summary:Entropy is a fundamental property of a repertoire. Here, we present an efficient algorithm to estimate the entropy of types with the help of Zhang's estimator. The algorithm takes advantage of the fact that the number of different frequencies in a text is in general much smaller than the number of types. We justify the convenience of the algorithm by means of an analysis of the statistical properties of texts from more than 1000 languages. Our work opens up various possibilities for future research. version:1
arxiv-1707-08289 | Fast Deep Matting for Portrait Animation on Mobile Phone | http://arxiv.org/abs/1707.08289 | id:1707.08289 author:Bingke Zhu, Yingying Chen, Jinqiao Wang, Si Liu, Bo Zhang, Ming Tang category:cs.CV  published:2017-07-26 summary:Image matting plays an important role in image and video editing. However, the formulation of image matting is inherently ill-posed. Traditional methods usually employ interaction to deal with the image matting problem with trimaps and strokes, and cannot run on the mobile phone in real-time. In this paper, we propose a real-time automatic deep matting approach for mobile devices. By leveraging the densely connected blocks and the dilated convolution, a light full convolutional network is designed to predict a coarse binary mask for portrait images. And a feathering block, which is edge-preserving and matting adaptive, is further developed to learn the guided filter and transform the binary mask into alpha matte. Finally, an automatic portrait animation system based on fast deep matting is built on mobile devices, which does not need any interaction and can realize real-time matting with 15 fps. The experiments show that the proposed approach achieves comparable results with the state-of-the-art matting solvers. version:1
arxiv-1707-08287 | Unsupervised Motion Artifact Detection in Wrist-Measured Electrodermal Activity Data | http://arxiv.org/abs/1707.08287 | id:1707.08287 author:Yuning Zhang, Maysam Haghdan, Kevin S. Xu category:cs.HC cs.LG I.5.4; H.1.2  published:2017-07-26 summary:One of the main benefits of a wrist-worn computer is its ability to collect a variety of physiological data in a minimally intrusive manner. Among these data, electrodermal activity (EDA) is readily collected and provides a window into a person's emotional and sympathetic responses. EDA data collected using a wearable wristband are easily influenced by motion artifacts (MAs) that may significantly distort the data and degrade the quality of analyses performed on the data if not identified and removed. Prior work has demonstrated that MAs can be successfully detected using supervised machine learning algorithms on a small data set collected in a lab setting. In this paper, we demonstrate that unsupervised learning algorithms perform competitively with supervised algorithms for detecting MAs on EDA data collected in both a lab-based setting and a real-world setting comprising about 23 hours of data. We also find, somewhat surprisingly, that incorporating accelerometer data as well as EDA improves detection accuracy only slightly for supervised algorithms and significantly degrades the accuracy of unsupervised algorithms. version:1
arxiv-1707-08105 | Learning Bag-of-Features Pooling for Deep Convolutional Neural Networks | http://arxiv.org/abs/1707.08105 | id:1707.08105 author:Nikolaos Passalis, Anastasios Tefas category:cs.CV  published:2017-07-25 summary:Convolutional Neural Networks (CNNs) are well established models capable of achieving state-of-the-art classification accuracy for various computer vision tasks. However, they are becoming increasingly larger, using millions of parameters, while they are restricted to handling images of fixed size. In this paper, a quantization-based approach, inspired from the well-known Bag-of-Features model, is proposed to overcome these limitations. The proposed approach, called Convolutional BoF (CBoF), uses RBF neurons to quantize the information extracted from the convolutional layers and it is able to natively classify images of various sizes as well as to significantly reduce the number of parameters in the network. In contrast to other global pooling operators and CNN compression techniques the proposed method utilizes a trainable pooling layer that it is end-to-end differentiable, allowing the network to be trained using regular back-propagation and to achieve greater distribution shift invariance than competitive methods. The ability of the proposed method to reduce the parameters of the network and increase the classification accuracy over other state-of-the-art techniques is demonstrated using three image datasets. version:2
arxiv-1707-08265 | Dragon: A Computation Graph Virtual Machine Based Deep Learning Framework | http://arxiv.org/abs/1707.08265 | id:1707.08265 author:Ting Pan category:cs.SE cs.LG cs.MS cs.NE  published:2017-07-26 summary:Deep Learning has made a great progress for these years. However, it is still difficult to master the implement of various models because different researchers may release their code based on different frameworks or interfaces. In this paper, we proposed a computation graph based framework which only aims to introduce well-known interfaces. It will help a lot when reproducing a newly model or transplanting models that were implemented by other frameworks. Additionally, we implement numerous recent models covering both Computer Vision and Nature Language Processing. We demonstrate that our framework will not suffer from model-starving because it is much easier to make full use of the works that are already done. version:1
arxiv-1707-00860 | Conditional generation of multi-modal data using constrained embedding space mapping | http://arxiv.org/abs/1707.00860 | id:1707.00860 author:Subhajit Chaudhury, Sakyasingha Dasgupta, Asim Munawar, Md. A. Salam Khan, Ryuki Tachibana category:cs.LG cs.AI cs.CV  published:2017-07-04 summary:We present a conditional generative model that maps low-dimensional embeddings of multiple modalities of data to a common latent space hence extracting semantic relationships between them. The embedding specific to a modality is first extracted and subsequently a constrained optimization procedure is performed to project the two embedding spaces to a common manifold. The individual embeddings are generated back from this common latent space. However, in order to enable independent conditional inference for separately extracting the corresponding embeddings from the common latent space representation, we deploy a proxy variable trick - wherein, the single shared latent space is replaced by the respective separate latent spaces of each modality. We design an objective function, such that, during training we can force these separate spaces to lie close to each other, by minimizing the distance between their probability distribution functions. Experimental results demonstrate that the learned joint model can generalize to learning concepts of double MNIST digits with additional attributes of colors,from both textual and speech input. version:2
arxiv-1707-08262 | SLEEPNET: Automated Sleep Staging System via Deep Learning | http://arxiv.org/abs/1707.08262 | id:1707.08262 author:Siddharth Biswal, Joshua Kulas, Haoqi Sun, Balaji Goparaju, M Brandon Westover, Matt T Bianchi, Jimeng Sun category:cs.LG  published:2017-07-26 summary:Sleep disorders, such as sleep apnea, parasomnias, and hypersomnia, affect 50-70 million adults in the United States (Hillman et al., 2006). Overnight polysomnography (PSG), including brain monitoring using electroencephalography (EEG), is a central component of the diagnostic evaluation for sleep disorders. While PSG is conventionally performed by trained technologists, the recent rise of powerful neural network learning algorithms combined with large physiological datasets offers the possibility of automation, potentially making expert-level sleep analysis more widely available. We propose SLEEPNET (Sleep EEG neural network), a deployed annotation tool for sleep staging. SLEEPNET uses a deep recurrent neural network trained on the largest sleep physiology database assembled to date, consisting of PSGs from over 10,000 patients from the Massachusetts General Hospital (MGH) Sleep Laboratory. SLEEPNET achieves human-level annotation performance on an independent test set of 1,000 EEGs, with an average accuracy of 85.76% and algorithm-expert inter-rater agreement (IRA) of kappa = 79.46%, comparable to expert-expert IRA. version:1
arxiv-1508-06924 | Using Thought-Provoking Children's Questions to Drive Artificial Intelligence Research | http://arxiv.org/abs/1508.06924 | id:1508.06924 author:Erik T. Mueller, Henry Minsky category:cs.AI  published:2015-08-27 summary:We propose to use thought-provoking children's questions (TPCQs), namely Highlights BrainPlay questions, as a new method to drive artificial intelligence research and to evaluate the capabilities of general-purpose AI systems. These questions are designed to stimulate thought and learning in children, and they can be used to do the same thing in AI systems, while demonstrating the system's reasoning capabilities to the evaluator. We introduce the TPCQ task, which which takes a TPCQ question as input and produces as output (1) answers to the question and (2) learned generalizations. We discuss how BrainPlay questions stimulate learning. We analyze 244 BrainPlay questions, and we report statistics on question type, question class, answer cardinality, answer class, types of knowledge needed, and types of reasoning needed. We find that BrainPlay questions span many aspects of intelligence. Because the answers to BrainPlay questions and the generalizations learned from them are often highly open-ended, we suggest using human judges for evaluation. version:3
arxiv-1707-08255 | Navigability with Imperfect Information | http://arxiv.org/abs/1707.08255 | id:1707.08255 author:Kaya Deuser, Pavel Naumov category:cs.AI cs.LO  published:2017-07-26 summary:The article studies navigability of an autonomous agent in a maze where some rooms may be indistinguishable. In a previous work the authors have shown that the properties of navigability in such a setting depend on whether an agent has perfect recall. Navigability by an agent with perfect recall is a transitive relation and without is not transitive. This article introduces a notion of restricted navigability and shows that a certain form of transitivity holds for restricted navigability, even for an agent without perfect recall. The main technical result is a sound and complete logical system describing the properties of restricted navigability. version:1
arxiv-1707-08254 | Efficient Yet Deep Convolutional Neural Networks for Semantic Segmentation | http://arxiv.org/abs/1707.08254 | id:1707.08254 author:Sharif Amit Kamran, Ali Shihab Sabbir category:cs.CV  published:2017-07-26 summary:Semantic Segmentation using deep convolutional neural network pose more complex challenge for any GPU intensive work, as it has to compute million of parameters resulting to huge consumption of memory. Moreover, extracting finer features and conducting supervised training tends to increase the complexity furthermore. With the introduction of Fully Convolutional Neural Network, which uses finer strides and utilizes deconvolutional layers for upsampling, it has been a go to for any image segmentation task. We propose two segmentation architecture transferring weights from the popular classification neural net VGG19 and VGG16 which were trained on Imagenet classification dataset, transform all the fully connected layers to convolutional layers, use dilated convolution for decreasing the parameters, moreover we add more finer strides and attach four skip architectures which are concatenated with the deconvolutional layers in steps. We train on two stages, first with PASCAL VOC2012 training data and then with SBD training and validation set. With our model, FCN-2s-Dilated-VGG19 we yield better score for PASCAL VOC2012 test set with a meanIOU of 69 percent which is 1.8 percent better than FCN-8s. And with FCN-2s-Dilated-VGG16 we score a meanIOU of 67.6 percent. On the other hand our model consumes up to 10-20 percent less memory than FCN-8s for training with NVIDIA Pascal GPUs, making it more efficient and less memory consuming architecture for pixel-wise segmentation. version:1
arxiv-1707-08250 | Proceedings Sixteenth Conference on Theoretical Aspects of Rationality and Knowledge | http://arxiv.org/abs/1707.08250 | id:1707.08250 author:Jérôme Lang category:cs.GT cs.AI cs.CR cs.LO  published:2017-07-25 summary:This volume consists of papers presented at the Sixteenth Conference on Theoretical Aspects of Rationality and Knowledge (TARK) held at the University of Liverpool, UK, from July 24 to 26, 2017. TARK conferences bring together researchers from a wide variety of fields, including Computer Science (especially, Artificial Intelligence, Cryptography, Distributed Computing), Economics (especially, Decision Theory, Game Theory, Social Choice Theory), Linguistics, Philosophy (especially, Philosophical Logic), and Cognitive Psychology, in order to further understand the issues involving reasoning about rationality and knowledge. version:1
arxiv-1707-08234 | Optimal Testing of Self-Driving Cars | http://arxiv.org/abs/1707.08234 | id:1707.08234 author:Jeremy Morton, Tim A. Wheeler, Mykel J. Kochenderfer category:cs.AI  published:2017-07-25 summary:Automotive manufacturers attempting to bring autonomous vehicles to market must make the case that their product is sufficiently safe for public deployment. Much of this case will likely rely upon outcomes from real-world testing, requiring manufacturers to be strategic about how they allocate testing resources in order to maximize their chances of demonstrating system safety. This work frames the partially observable and belief-dependent problem of autonomous vehicle test scheduling as a Markov decision process, which can be solved efficiently to yield exact, optimal manufacturer testing policies. By solving for policies over a wide range of problem formulations, we are able to provide high-level guidance for manufacturers and regulators on issues relating to the real-world testing of autonomous vehicles. This guidance spans an array of topics, including circumstances under which manufacturers should continue testing despite observed incidents, when manufacturers should test aggressively, and when regulators should increase or reduce the real-world testing requirements for an autonomous vehicle. version:1
arxiv-1707-05850 | A Short Survey of Biomedical Relation Extraction Techniques | http://arxiv.org/abs/1707.05850 | id:1707.05850 author:Elham Shahab category:cs.CL  published:2017-07-18 summary:Biomedical information is growing rapidly in the recent years and retrieving useful data through information extraction system is getting more attention. In the current research, we focus on different aspects of relation extraction techniques in biomedical domain and briefly describe the state-of-the-art for relation extraction between a variety of biological elements. version:3
arxiv-1707-08216 | A Gossip Algorithm based Clock Synchronization Scheme for Smart Grid Applications | http://arxiv.org/abs/1707.08216 | id:1707.08216 author:Imtiaz Parvez, Arif I. Sarwat, Jonathan Pinto, Zakaria Parvez, Mohammad Aqib Khandaker category:cs.SY cs.DC  published:2017-07-25 summary:The uprising interest in multi-agent based networked system, and the numerous number of applications in the distributed control of the smart grid leads us to address the problem of time synchronization in the smart grid. Utility companies look for new packet based time synchronization solutions with Global Positioning System (GPS) level accuracies beyond traditional packet methods such as Network Time Proto- col (NTP). However GPS based solutions have poor reception in indoor environments and dense urban canyons as well as GPS antenna installation might be costly. Some smart grid nodes such as Phasor Measurement Units (PMUs), fault detection, Wide Area Measurement Systems (WAMS) etc., requires synchronous accuracy as low as 1 ms. On the other hand, 1 sec accuracy is acceptable in management information domain. Acknowledging this, in this study, we introduce gossip algorithm based clock synchronization method among network entities from the decision control and communication point of view. Our method synchronizes clock within dense network with a bandwidth limited environment. Our technique has been tested in different kinds of network topologies- complete, star and random geometric network and demonstrated satisfactory performance. version:1
arxiv-1707-09416 | Vision-Based Assessment of Parkinsonism and Levodopa-Induced Dyskinesia with Deep Learning Pose Estimation | http://arxiv.org/abs/1707.09416 | id:1707.09416 author:Michael H. Li, Tiago A. Mestre, Susan H. Fox, Babak Taati category:cs.CV cs.LG  published:2017-07-25 summary:Objective: To apply deep learning pose estimation algorithms for vision-based assessment of parkinsonism and levodopa-induced dyskinesia (LID). Methods: Nine participants with Parkinson's disease (PD) and LID completed a levodopa infusion protocol, where symptoms were assessed at regular intervals using the Unified Dyskinesia Rating Scale (UDysRS) and Unified Parkinson's Disease Rating Scale (UPDRS). A state-of-the-art deep learning pose estimation method was used to extract movement trajectories from videos of PD assessments. Features of the movement trajectories were used to detect and estimate the severity of parkinsonism and LID using random forest. Communication and drinking tasks were used to assess LID, while leg agility and toe tapping tasks were used to assess parkinsonism. Feature sets from tasks were also combined to predict total UDysRS and UPDRS Part III scores. Results: For LID, the communication task yielded the best results for dyskinesia (severity estimation: r = 0.661, detection: AUC = 0.930). For parkinsonism, leg agility had better results for severity estimation (r = 0.618), while toe tapping was better for detection (AUC = 0.773). UDysRS and UPDRS Part III scores were predicted with r = 0.741 and 0.530, respectively. Conclusion: This paper presents the first application of deep learning for vision-based assessment of parkinsonism and LID and demonstrates promising performance for the future translation of deep learning to PD clinical practices. Significance: The proposed system provides insight into the potential of computer vision and deep learning for clinical application in PD. version:1
arxiv-1707-08214 | DReLUs: Dual Rectified Linear Units | http://arxiv.org/abs/1707.08214 | id:1707.08214 author:Fréderic Godin, Jonas Degrave, Joni Dambre, Wesley De Neve category:cs.CL cs.LG cs.NE  published:2017-07-25 summary:Rectified Linear Units (ReLUs) are widely used in feed-forward neural networks, and in convolutional neural networks in particular. However, they can be rarely found in recurrent neural networks due to the unboundedness and the positive image of the rectified linear activation function. In this paper, we introduce Dual Rectified Linear Units (DReLUs), a novel type of rectified unit that comes with a positive and negative image that is unbounded. We show that we can successfully replace the tanh activation function in the recurrent step of quasi recurrent neural networks. In addition, DReLUs are less prone to the vanishing gradient problem, they are noise robust, and they induce sparse activations. Therefore, we are able to stack up to eight quasi recurrent layers, making it possible to improve the current state-of-the-art in character-level language modeling over architectures based on shallow Long Short-Term Memory (LSTM). version:1
arxiv-1707-08213 | An Algorithm for the 2D Radix-2 Sliding Window Fourier Transform | http://arxiv.org/abs/1707.08213 | id:1707.08213 author:Lee F. Richardson, William F. Eddy category:cs.DS stat.CO stat.ML  published:2017-07-25 summary:We present a new algorithm for the 2D Radix-2 Sliding Window Fourier Transform (SWFT). Our algorithm avoids repeating calculations in overlapping windows by using a tree representation of the Cooley-Tukey Fast Fourier Transform (FFT). For an $N_0 \times N_1$ array and $n_0 = 2^{m_0} \times n_1 = 2^{m_1}$ windows, our algorithm takes $O(N_0 N_1 n_0 n_1)$ operations, which is faster than taking a 2D FFT in each window. We provide a C implementation of the algorithm, compare ours with existing algorithms, and show how the algorithm extends to higher dimensions. version:1
arxiv-1707-08212 | Physical problem solving: Joint planning with symbolic, geometric, and dynamic constraints | http://arxiv.org/abs/1707.08212 | id:1707.08212 author:Ilker Yildirim, Tobias Gerstenberg, Basil Saeed, Marc Toussaint, Josh Tenenbaum category:cs.AI cs.RO stat.ML  published:2017-07-25 summary:In this paper, we present a new task that investigates how people interact with and make judgments about towers of blocks. In Experiment~1, participants in the lab solved a series of problems in which they had to re-configure three blocks from an initial to a final configuration. We recorded whether they used one hand or two hands to do so. In Experiment~2, we asked participants online to judge whether they think the person in the lab used one or two hands. The results revealed a close correspondence between participants' actions in the lab, and the mental simulations of participants online. To explain participants' actions and mental simulations, we develop a model that plans over a symbolic representation of the situation, executes the plan using a geometric solver, and checks the plan's feasibility by taking into account the physical constraints of the scene. Our model explains participants' actions and judgments to a high degree of quantitative accuracy. version:1
arxiv-1707-06387 | Representing Hybrid Automata by Action Language Modulo Theories | http://arxiv.org/abs/1707.06387 | id:1707.06387 author:Joohyung Lee, Nikhil Loney, Yunsong Meng category:cs.AI cs.FL cs.LO  published:2017-07-20 summary:Both hybrid automata and action languages are formalisms for describing the evolution of dynamic systems. This paper establishes a formal relationship between them. We show how to succinctly represent hybrid automata in an action language which in turn is defined as a high-level notation for answer set programming modulo theories (ASPMT) --- an extension of answer set programs to the first-order level similar to the way satisfiability modulo theories (SMT) extends propositional satisfiability (SAT). We first show how to represent linear hybrid automata with convex invariants by an action language modulo theories. A further translation into SMT allows for computing them using SMT solvers that support arithmetic over reals. Next, we extend the representation to the general class of non-linear hybrid automata allowing even non-convex invariants. We represent them by an action language modulo ODE (Ordinary Differential Equations), which can be compiled into satisfiability modulo ODE. We developed a prototype system cplus2aspmt based on these translations, which allows for a succinct representation of hybrid transition systems that can be computed effectively by the state-of-the-art SMT solver dReal. version:2
arxiv-1707-06325 | Computing LPMLN Using ASP and MLN Solvers | http://arxiv.org/abs/1707.06325 | id:1707.06325 author:Joohyung Lee, Samidh Talsania, Yi Wang category:cs.AI cs.LO  published:2017-07-19 summary:LPMLN is a recent addition to probabilistic logic programming languages. Its main idea is to overcome the rigid nature of the stable model semantics by assigning a weight to each rule in a way similar to Markov Logic is defined. We present two implementations of LPMLN, $\text{LPMLN2ASP}$ and $\text{LPMLN2MLN}$. System $\text{LPMLN2ASP}$ translates LPMLN programs into the input language of answer set solver $\text{CLINGO}$, and using weak constraints and stable model enumeration, it can compute most probable stable models as well as exact conditional and marginal probabilities. System $\text{LPMLN2MLN}$ translates LPMLN programs into the input language of Markov Logic solvers, such as $\text{ALCHEMY}$, $\text{TUFFY}$, and $\text{ROCKIT}$, and allows for performing approximate probabilistic inference on LPMLN programs. We also demonstrate the usefulness of the LPMLN systems for computing other languages, such as ProbLog and Pearl's Causal Models, that are shown to be translatable into LPMLN. (Under consideration for acceptance in TPLP) version:2
arxiv-1707-04796 | A Pipeline for Generating Ground Truth Labels for Real RGBD Data of Cluttered Scenes | http://arxiv.org/abs/1707.04796 | id:1707.04796 author:Pat Marion, Peter R. Florence, Lucas Manuelli, Russ Tedrake category:cs.CV cs.RO  published:2017-07-15 summary:Deep neural network (DNN) architectures have been shown to outperform traditional pipelines for object segmentation and pose estimation using RGBD data, but the performance of these DNN pipelines is directly tied to how representative the training data is of the true data. Hence a key requirement for employing these methods in practice is to have a large set of labeled data for your specific robotic manipulation task, a requirement that is not generally satisfied by existing datasets. In this paper we develop a pipeline to rapidly generate high quality RGBD data with pixelwise labels and object poses. We use an RGBD camera to collect video of a scene from multiple viewpoints and leverage existing reconstruction techniques to produce a 3D dense reconstruction. We label the 3D reconstruction using a human assisted ICP-fitting of object meshes. By reprojecting the results of labeling the 3D scene we can produce labels for each RGBD image of the scene. This pipeline enabled us to collect over 1,000,000 labeled object instances in just a few days. We use this dataset to answer questions related to how much training data is required, and of what quality the data must be, to achieve high performance from a DNN architecture. version:2
arxiv-1707-08183 | A Unified Joint Matrix Factorization Framework for Data Integration | http://arxiv.org/abs/1707.08183 | id:1707.08183 author:Lihua Zhang, Shihua Zhang category:cs.CV I.5.1; G.1.6; H.2.8  published:2017-07-25 summary:Nonnegative matrix factorization (NMF) is a powerful tool in data exploratory analysis by discovering the hidden features and part-based patterns from high-dimensional data. NMF and its variants have been successfully applied into diverse fields such as pattern recognition, signal processing, data mining, bioinformatics and so on. Recently, NMF has been extended to analyze multiple matrices simultaneously. However, a unified framework is still lacking. In this paper, we introduce a sparse multiple relationship data regularized joint matrix factorization (JMF) framework and two adapted prediction models for pattern recognition and data integration. Next, we present four update algorithms to solve this framework. The merits and demerits of these algorithms are systematically explored. Furthermore, extensive computational experiments using both synthetic data and real data demonstrate the effectiveness of JMF framework and related algorithms on pattern recognition and data mining. version:1
arxiv-1707-08172 | The RepEval 2017 Shared Task: Multi-Genre Natural Language Inference with Sentence Representations | http://arxiv.org/abs/1707.08172 | id:1707.08172 author:Nikita Nangia, Adina Williams, Angeliki Lazaridou, Samuel R. Bowman category:cs.CL  published:2017-07-25 summary:This paper presents the results of the RepEval 2017 Shared Task, which evaluated neural network sentence representation learning models on the Multi-Genre Natural Language Inference corpus (MultiNLI) recently introduced by Williams et al. (2017). All of the five participating teams beat the bidirectional LSTM (BiLSTM) and continuous bag of words baselines reported in Williams et al.. The best single model used stacked BiLSTMs with residual connections to extract sentence features and reached 74.5% accuracy on the genre-matched test set. Surprisingly, the results of the competition were fairly consistent across the genre-matched and genre-mismatched test sets, and across subsets of the test data representing a variety of linguistic phenomena, suggesting that all of the submitted systems learned reasonably domain-independent representations for sentence meaning. version:1
arxiv-1707-08167 | On The Robustness of a Neural Network | http://arxiv.org/abs/1707.08167 | id:1707.08167 author:El Mahdi El Mhamdi, Rachid Guerraoui, Sebastien Rouault category:stat.ML cs.AI cs.DC cs.LG cs.NE  published:2017-07-25 summary:With the development of neural networks based machine learning and their usage in mission critical applications, voices are rising against the \textit{black box} aspect of neural networks as it becomes crucial to understand their limits and capabilities. With the rise of neuromorphic hardware, it is even more critical to understand how a neural network, as a distributed system, tolerates the failures of its computing nodes, neurons, and its communication channels, synapses. Experimentally assessing the robustness of neural networks involves the quixotic venture of testing all the possible failures, on all the possible inputs, which ultimately hits a combinatorial explosion for the first, and the impossibility to gather all the possible inputs for the second. In this paper, we prove an upper bound on the expected error of the output when a subset of neurons crashes. This bound involves dependencies on the network parameters that can be seen as being too pessimistic in the average case. It involves a polynomial dependency on the Lipschitz coefficient of the neurons activation function, and an exponential dependency on the depth of the layer where a failure occurs. We back up our theoretical results with experiments illustrating the extent to which our prediction matches the dependencies between the network parameters and robustness. Our results show that the robustness of neural networks to the average crash can be estimated without the need to neither test the network on all failure configurations, nor access the training set used to train the network, both of which are practically impossible requirements. version:1
arxiv-1707-08151 | Speeding-up ProbLog's Parameter Learning | http://arxiv.org/abs/1707.08151 | id:1707.08151 author:Francisco H. O. V. de Faria, Arthur C. Gusmão, Fabio G. Cozman, Denis D. Mauá category:cs.AI 97R40  published:2017-07-25 summary:ProbLog is a state-of-art combination of logic programming and probabilities; in particular ProbLog offers parameter learning through a variant of the EM algorithm. However, the resulting learning algorithm is rather slow, even when the data are complete. In this short paper we offer some insights that lead to orders of magnitude improvements in ProbLog's parameter learning speed with complete data. version:1
arxiv-1707-08150 | Safe Robotic Grasping: Minimum Impact-Force Grasp Selection | http://arxiv.org/abs/1707.08150 | id:1707.08150 author:Nikos Mavrakis, Amir M. Ghalamzan E., Rustam Stolkin category:cs.RO  published:2017-07-25 summary:This paper addresses the problem of selecting from a choice of possible grasps, so that impact forces will be minimised if a collision occurs while the robot is moving the grasped object along a post-grasp trajectory. Such considerations are important for safety in human-robot interaction, where even a certified "human-safe" (e.g. compliant) arm may become hazardous once it grasps and begins moving an object, which may have significant mass, sharp edges or other dangers. Additionally, minimising collision forces is critical to preserving the longevity of robots which operate in uncertain and hazardous environments, e.g. robots deployed for nuclear decommissioning, where removing a damaged robot from a contaminated zone for repairs may be extremely difficult and costly. Also, unwanted collisions between a robot and critical infrastructure (e.g. pipework) in such high-consequence environments can be disastrous. In this paper, we investigate how the safety of the post-grasp motion can be considered during the pre-grasp approach phase, so that the selected grasp is optimal in terms applying minimum impact forces if a collision occurs during a desired post-grasp manipulation. We build on the methods of augmented robot-object dynamics models and "effective mass" and propose a method for combining these concepts with modern grasp and trajectory planners, to enable the robot to achieve a grasp which maximises the safety of the post-grasp trajectory, by minimising potential collision forces. We demonstrate the effectiveness of our approach through several experiments with both simulated and real robots. version:1
arxiv-1707-08149 | Patch-based Carcinoma Detection on Confocal Laser Endomicroscopy Images - A Cross-Site Robustness Assessment | http://arxiv.org/abs/1707.08149 | id:1707.08149 author:Marc Aubreville, Miguel Goncalves, Christian Knipfer, Nicolai Oetter, Tobias Wuerfl, Helmut Neumann, Florian Stelzle, Christopher Bohr, Andreas Maier category:cs.CV  published:2017-07-25 summary:Deep learning technologies such as convolutional neural networks (CNN) provide powerful methods for image recognition and have recently been employed in the field of automated carcinoma detection in confocal laser endomicroscopy (CLE) images. CLE is a (sub-)surface microscopic imaging technique that reaches magnifications of up to 1000x and is thus suitable for in vivo structural tissue analysis. In this work, we aim to evaluate the prospects of a priorly developed deep learning-based algorithm targeted at the identification of oral squamous cell carcinoma with regard to its generalization to further anatomic locations of squamous cell carcinomas in the area of head and neck. We applied the algorithm on images acquired from the vocal fold area of five patients with histologically verified squamous cell carcinoma and presumably healthy control images of the clinically normal contra-lateral vocal cord. We find that the network trained on the oral cavity data reaches an accuracy of 89.45% and an area-under-the-curve (AUC) value of 0.955, when applied on the vocal cords data. Compared to the state of the art, we achieve very similar results, yet with an algorithm that was trained on a completely disjunct data set. Concatenating both data sets yielded further improvements in cross-validation with an accuracy of 90.81% and AUC of 0.970. In this study, for the first time to our knowledge, a deep learning mechanism for the identification of oral carcinomas using CLE Images could be applied to other disciplines in the area of head and neck. This study shows the prospect of the algorithmic approach to generalize well on other malignant entities of the head and neck, regardless of the anatomical location and furthermore in an examiner-independent manner. version:1
arxiv-1707-08148 | Automatic Image Transformation for Inducing Affect | http://arxiv.org/abs/1707.08148 | id:1707.08148 author:Afsheen Rafaqat Ali, Mohsen Ali category:cs.CV  published:2017-07-25 summary:Current image transformation and recoloring algorithms try to introduce artistic effects in the photographed images, based on user input of target image(s) or selection of pre-designed filters. These manipulations, although intended to enhance the impact of an image on the viewer, do not include the option of image transformation by specifying the affect information. In this paper we present an automatic image-transformation method that transforms the source image such that it can induce an emotional affect on the viewer, as desired by the user. Our proposed novel image emotion transfer algorithm does not require a user-specified target image. The proposed algorithm uses features extracted from top layers of deep convolutional neural network and the user-specified emotion distribution to select multiple target images from an image database for color transformation, such that the resultant image has desired emotional impact. Our method can handle more diverse set of photographs than the previous methods. We conducted a detailed user study showing the effectiveness of our proposed method. A discussion and reasoning of failure cases has also been provided, indicating inherent limitation of color-transfer based methods in the use of emotion assignment. version:1
arxiv-1707-08147 | Human-in-the-loop optimisation: mixed initiative grasping for optimally facilitating post-grasp manipulative actions | http://arxiv.org/abs/1707.08147 | id:1707.08147 author:Amir M. Ghalamzan Esfahani, Firas Abi-Farraj, Paolo Robuffo Giordano, Rustam Stolkin category:cs.RO  published:2017-07-25 summary:This paper addresses the problem of mixed initiative, shared control for master-slave grasping and manipulation. We propose a novel system, in which an autonomous agent assists a human in teleoperating a remote slave arm/gripper, using a haptic master device. Our system is designed to exploit the human operator's expertise in selecting stable grasps (still an open research topic in autonomous robotics). Meanwhile, a-priori knowledge of: i) the slave robot kinematics, and ii) the desired post-grasp manipulative trajectory, are fed to an autonomous agent which transmits force cues to the human, to encourage maximally manipulable grasp pose selections. Specifically, the autonomous agent provides force cues to the human, during the reach-to-grasp phase, which encourage the human to select grasp poses which maximise manipulation capability during the post-grasp object manipulation phase. We introduce a task-relevant velocity manipulability cost function (TOV), which is used to identify the maximum kinematic capability of a manipulator during post-grasp motions, and feed this back as force cues to the human during the pre-grasp phase. We show that grasps which minimise TOV result in significantly reduced control effort of the manipulator, compared to other feasible grasps. We demonstrate the effectiveness of our approach by experiments with both real and simulated robots. version:1
arxiv-1707-05721 | Submodular Mini-Batch Training in Generative Moment Matching Networks | http://arxiv.org/abs/1707.05721 | id:1707.05721 author:Jun Qi, Xiaodong He, Adith Swaminathan, Li Deng category:cs.LG  published:2017-07-18 summary:Generative moment matching network (GMMN), which is based on the maximum mean discrepancy (MMD) measure, is a generative model for unsupervised learning, where the mini-batch stochastic gradient descent is applied for the update of param- eters. In this work, instead of obtaining a mini-batch randomly, each mini-batch in the iterations is selected in a submodular way such that the most informative subset of data is more likely to be chosen. In such a framework, the training objective is reformulated as optimizing a mixed continuous and submodular function with a cardinality constraint. A Majorization Minimization-like algorithm is used to iteratively solve the problem. Specifically, in each iteration of the training process, a mini-batch is first selected by solving a submodular maximization problem, and then the mini-batch stochastic gradient descent is conducted. Our experiments on the MNIST and Labeled Faces in the Wild (LFW) databases show the effectiveness of the submodular mini-batch training in the GMMN frameworks. version:2
arxiv-1707-02387 | Generating Realtime Motion Plans from Complex Natural Language Commands Using Dynamic Grounding Graphs | http://arxiv.org/abs/1707.02387 | id:1707.02387 author:Jae Sung Park, Biao Jia, Mohit Bansal, Dinesh Manocha category:cs.RO  published:2017-07-08 summary:We present an algorithm for combining natural language processing (NLP) and realtime robot motion planning to automatically generate safe robot movements. We present a novel method to map the complex natural language commands into appropriate cost function and constraint parameters for optimization-based motion planning. Given NLP commands, we generate a factor graph named Dynamic Grounding Graph (DGG). The coefficients of this factor graph are learned based on conditional random fields and used to dynamically generate the constraints for motion planning. We directly map the cost function to the parameters of the motion planner to generate collision-free and smooth paths in complex scenes with moving obstacles, by modeling intricate motion planning parameters such as speed, orientation, position, as well as smoothness, repulsion, and avoidance. We highlight the performance of our approach in a simulated environment as well as via a human interacting with a 7-DOF Fetch robot with complex NLP commands. version:2
arxiv-1707-08139 | Analogs of Linguistic Structure in Deep Representations | http://arxiv.org/abs/1707.08139 | id:1707.08139 author:Jacob Andreas, Dan Klein category:cs.CL cs.NE  published:2017-07-25 summary:We investigate the compositional structure of message vectors computed by a deep network trained on a communication game. By comparing truth-conditional representations of encoder-produced message vectors to human-produced referring expressions, we are able to identify aligned (vector, utterance) pairs with the same meaning. We then search for structured relationships among these aligned pairs to discover simple vector space transformations corresponding to negation, conjunction, and disjunction. Our results suggest that neural representations are capable of spontaneously developing a "syntax" with functional analogues to qualitative properties of natural language. version:1
arxiv-1707-08134 | Optimizing Scrubbing by Netlist Analysis for FPGA Configuration Bit Classification and Floorplanning | http://arxiv.org/abs/1707.08134 | id:1707.08134 author:Bernhard Schmidt, Daniel Ziener, Jürgen Teich, Christian Zöllner category:cs.AR  published:2017-07-25 summary:Existing scrubbing techniques for SEU mitigation on FPGAs do not guarantee an error-free operation after SEU recovering if the affected configuration bits do belong to feedback loops of the implemented circuits. In this paper, we a) provide a netlist-based circuit analysis technique to distinguish so-called critical configuration bits from essential bits in order to identify configuration bits which will need also state-restoring actions after a recovered SEU and which not. Furthermore, b) an alternative classification approach using fault injection is developed in order to compare both classification techniques. Moreover, c) we will propose a floorplanning approach for reducing the effective number of scrubbed frames and d), experimental results will give evidence that our optimization methodology not only allows to detect errors earlier but also to minimize the Mean-Time-To-Repair (MTTR) of a circuit considerably. In particular, we show that by using our approach, the MTTR for datapath-intensive circuits can be reduced by up to 48.5% in comparison to standard approaches. version:1
arxiv-1707-08101 | Learning to Singulate Objects using a Push Proposal Network | http://arxiv.org/abs/1707.08101 | id:1707.08101 author:Andreas Eitel, Nico Hauff, Wolfram Burgard category:cs.RO cs.LG cs.NE  published:2017-07-25 summary:A key challenge for manipulation in unstructured environments is action selection. We present a novel neural network-based approach that separates unknown objects in clutter by selecting favourable push actions. Our network is trained from data collected through large-scale interaction of a PR2 robot with randomly organized tabletop scenes. The model is designed to propose meaningful push actions based on segmented RGB-D images. We evaluate our approach by singulating up to six unknown objects in clutter. We demonstrate that our method enables the robot to perform the task with a high success rate and a low number of required push actions. Our results based on real-world experiments show that our network is able to generalize to novel objects of various sizes and shapes, as well as to arbitrary object configurations. Highlights of our experiments can be viewed in the following video: https://youtu.be/jWbUJOrSacI . version:1
arxiv-1707-08098 | From Image to Text Classification: A Novel Approach based on Clustering Word Embeddings | http://arxiv.org/abs/1707.08098 | id:1707.08098 author:Andrei M. Butnaru, Radu Tudor Ionescu category:cs.CL  published:2017-07-25 summary:In this paper, we propose a novel approach for text classification based on clustering word embeddings, inspired by the bag of visual words model, which is widely used in computer vision. After each word in a collection of documents is represented as word vector using a pre-trained word embeddings model, a k-means algorithm is applied on the word vectors in order to obtain a fixed-size set of clusters. The centroid of each cluster is interpreted as a super word embedding that embodies all the semantically related word vectors in a certain region of the embedding space. Every embedded word in the collection of documents is then assigned to the nearest cluster centroid. In the end, each document is represented as a bag of super word embeddings by computing the frequency of each super word embedding in the respective document. We also diverge from the idea of building a single vocabulary for the entire collection of documents, and propose to build class-specific vocabularies for better performance. Using this kind of representation, we report results on two text mining tasks, namely text categorization by topic and polarity classification. On both tasks, our model yields better performance than the standard bag of words. version:1
arxiv-1707-08095 | Line-Circle: A Geometric Filter for Single Camera Edge-Based Object Detection | http://arxiv.org/abs/1707.08095 | id:1707.08095 author:Seyed Amir Tafrishi, Vahid E. Kandjani category:cs.RO cs.CV  published:2017-07-25 summary:This paper presents a state-of-the-art approach in object detection for being applied in future SLAM problems. Although, many SLAM methods are proposed to create suitable autonomy for mobile robots namely ground vehicles, they still face overconfidence and large computations during entrance to immense spaces with many landmarks. In particular, they suffer from impractical applications via sole reliance on the limited sensors like camera. Proposed method claims that unmanned ground vehicles without having huge amount of database for object definition and highly advance prediction parameters can deal with incoming objects during straight motion of camera in real-time. Line-Circle (LC) filter tries to apply detection, tracking and learning to each defined experts to obtain more information for judging scene without over-calculation. In this filter, circle expert let us summarize edges in groups. The Interactive feedback learning between each expert creates minimal error that fights against overwhelming landmark signs in crowded scenes without mapping. Our experts basically are dependent on trust factors' covariance with geometric definitions to ignore, emerge and compare detected landmarks. The experiment for validating the model is taken place utilizing a camera beside an IMU sensor for location estimation. version:1
arxiv-1707-08084 | ShotgunWSD: An unsupervised algorithm for global word sense disambiguation inspired by DNA sequencing | http://arxiv.org/abs/1707.08084 | id:1707.08084 author:Andrei M. Butnaru, Radu Tudor Ionescu, Florentina Hristea category:cs.CL  published:2017-07-25 summary:In this paper, we present a novel unsupervised algorithm for word sense disambiguation (WSD) at the document level. Our algorithm is inspired by a widely-used approach in the field of genetics for whole genome sequencing, known as the Shotgun sequencing technique. The proposed WSD algorithm is based on three main steps. First, a brute-force WSD algorithm is applied to short context windows (up to 10 words) selected from the document in order to generate a short list of likely sense configurations for each window. In the second step, these local sense configurations are assembled into longer composite configurations based on suffix and prefix matching. The resulted configurations are ranked by their length, and the sense of each word is chosen based on a voting scheme that considers only the top k configurations in which the word appears. We compare our algorithm with other state-of-the-art unsupervised WSD algorithms and demonstrate better performance, sometimes by a very large margin. We also show that our algorithm can yield better performance than the Most Common Sense (MCS) baseline on one data set. Moreover, our algorithm has a very small number of parameters, is robust to parameter tuning, and, unlike other bio-inspired methods, it gives a deterministic solution (it does not involve random choices). version:1
arxiv-1707-07498 | Accelerating Approximate Bayesian Computation with Quantile Regression: Application to Cosmological Redshift Distributions | http://arxiv.org/abs/1707.07498 | id:1707.07498 author:Tomasz Kacprzak, Jörg Herbel, Adam Amara, Alexandre Réfrégier category:astro-ph.CO stat.ML  published:2017-07-24 summary:Approximate Bayesian Computation (ABC) is a method to obtain a posterior distribution without a likelihood function, using simulations and a set of distance metrics. For that reason, it has recently been gaining popularity as an analysis tool in cosmology and astrophysics. Its drawback, however, is a slow convergence rate. We propose a novel method, which we call qABC, to accelerate ABC with Quantile Regression. In this method, we create a model of quantiles of distance measure as a function of input parameters. This model is trained on a small number of simulations and estimates which regions of the prior space are likely to be accepted into the posterior. Other regions are then immediately rejected. This procedure is then repeated as more simulations are available. We apply it to the practical problem of estimation of redshift distribution of cosmological samples, using forward modelling developed in previous work. The qABC method converges to nearly same posterior as the basic ABC. It uses, however, only 20\% of the number of simulations compared to basic ABC, achieving a fivefold gain in execution time for our problem. For other problems the acceleration rate may vary; it depends on how close the prior is to the final posterior. We discuss possible improvements and extensions to this method. version:2
arxiv-1707-08077 | A comparison of single-trial EEG classification and EEG-informed fMRI across three MR compatible EEG recording systems | http://arxiv.org/abs/1707.08077 | id:1707.08077 author:Josef Faller, Linbi Hong, Jennifer Cummings, Paul Sajda category:q-bio.NC stat.ML  published:2017-07-25 summary:Simultaneously recorded electroencephalography (EEG) and functional magnetic resonance imaging (fMRI) can be used to non-invasively measure the spatiotemporal dynamics of the human brain. One challenge is dealing with the artifacts that each modality introduces into the other when the two are recorded concurrently, for example the ballistocardiogram (BCG). We conducted a preliminary comparison of three different MR compatible EEG recording systems and assessed their performance in terms of single-trial classification of the EEG when simultaneously collecting fMRI. We found tradeoffs across all three systems, for example varied ease of setup and improved classification accuracy with reference electrodes (REF) but not for pulse artifact subtraction (PAS) or reference layer adaptive filtering (RLAF). version:1
arxiv-1707-01943 | A causal framework for explaining the predictions of black-box sequence-to-sequence models | http://arxiv.org/abs/1707.01943 | id:1707.01943 author:David Alvarez-Melis, Tommi S. Jaakkola category:cs.LG  published:2017-07-06 summary:We interpret the predictions of any black-box structured input-structured output model around a specific input-output pair. Our method returns an "explanation" consisting of groups of input-output tokens that are causally related. These dependencies are inferred by querying the black-box model with perturbed inputs, generating a graph over tokens from the responses, and solving a partitioning problem to select the most relevant components. We focus the general approach on sequence-to-sequence problems, adopting a variational autoencoder to yield meaningful input perturbations. We test our method across several NLP sequence generation tasks. version:2
arxiv-1707-08052 | Challenges in Data-to-Document Generation | http://arxiv.org/abs/1707.08052 | id:1707.08052 author:Sam Wiseman, Stuart M. Shieber, Alexander M. Rush category:cs.CL  published:2017-07-25 summary:Recent neural models have shown significant progress on the problem of generating short descriptive texts conditioned on a small number of database records. In this work, we suggest a slightly more difficult data-to-text generation task, and investigate how effective current approaches are on this task. In particular, we introduce a new, large-scale corpus of data records paired with descriptive documents, propose a series of extractive evaluation methods for analyzing performance, and obtain baseline results using current neural generation methods. Experiments show that these models produce fluent text, but fail to convincingly approximate human-generated documents. Moreover, even templated baselines exceed the performance of these neural models on some metrics, though copy- and reconstruction-based extensions lead to noticeable improvements. version:1
arxiv-1705-09045 | Cross-Domain Perceptual Reward Functions | http://arxiv.org/abs/1705.09045 | id:1705.09045 author:Ashley D. Edwards, Srijan Sood, Charles L. Isbell Jr category:cs.AI  published:2017-05-25 summary:In reinforcement learning, we often define goals by specifying rewards within desirable states. One problem with this approach is that we typically need to redefine the rewards each time the goal changes, which often requires some understanding of the solution in the agents environment. When humans are learning to complete tasks, we regularly utilize alternative sources that guide our understanding of the problem. Such task representations allow one to specify goals on their own terms, thus providing specifications that can be appropriately interpreted across various environments. This motivates our own work, in which we represent goals in environments that are different from the agents. We introduce Cross-Domain Perceptual Reward (CDPR) functions, learned rewards that represent the visual similarity between an agents state and a cross-domain goal image. We report results for learning the CDPRs with a deep neural network and using them to solve two tasks with deep reinforcement learning. version:3
arxiv-1707-08041 | Synthesising Sign Language from semantics, approaching "from the target and back" | http://arxiv.org/abs/1707.08041 | id:1707.08041 author:Michael Filhol, Gilles Falquet category:cs.CL  published:2017-07-25 summary:We present a Sign Language modelling approach allowing to build grammars and create linguistic input for Sign synthesis through avatars. We comment on the type of grammar it allows to build, and observe a resemblance between the resulting expressions and traditional semantic representations. Comparing the ways in which the paradigms are designed, we name and contrast two essentially different strategies for building higher-level linguistic input: "source-and-forward" vs. "target-and-back". We conclude by favouring the latter, acknowledging the power of being able to automatically generate output from semantically relevant input straight into articulations of the target language. version:1
arxiv-1707-08037 | Automatic Liver Segmentation Using an Adversarial Image-to-Image Network | http://arxiv.org/abs/1707.08037 | id:1707.08037 author:Dong Yang, Daguang Xu, S. Kevin Zhou, Bogdan Georgescu, Mingqing Chen, Sasa Grbic, Dimitris Metaxas, Dorin Comaniciu category:cs.CV  published:2017-07-25 summary:Automatic liver segmentation in 3D medical images is essential in many clinical applications, such as pathological diagnosis of hepatic diseases, surgical planning, and postoperative assessment. However, it is still a very challenging task due to the complex background, fuzzy boundary, and various appearance of liver. In this paper, we propose an automatic and efficient algorithm to segment liver from 3D CT volumes. A deep image-to-image network (DI2IN) is first deployed to generate the liver segmentation, employing a convolutional encoder-decoder architecture combined with multi-level feature concatenation and deep supervision. Then an adversarial network is utilized during training process to discriminate the output of DI2IN from ground truth, which further boosts the performance of DI2IN. The proposed method is trained on an annotated dataset of 1000 CT volumes with various different scanning protocols (e.g., contrast and non-contrast, various resolution and position) and large variations in populations (e.g., ages and pathology). Our approach outperforms the state-of-the-art solutions in terms of segmentation accuracy and computing efficiency. version:1
arxiv-1707-08029 | Price and Profit Awareness in Recommender Systems | http://arxiv.org/abs/1707.08029 | id:1707.08029 author:Dietmar Jannach, Gediminas Adomavicius category:cs.IR cs.AI  published:2017-07-25 summary:Academic research in the field of recommender systems mainly focuses on the problem of maximizing the users' utility by trying to identify the most relevant items for each user. However, such items are not necessarily the ones that maximize the utility of the service provider (e.g., an online retailer) in terms of the business value, such as profit. One approach to increasing the providers' utility is to incorporate purchase-oriented information, e.g., the price, sales probabilities, and the resulting profit, into the recommendation algorithms. In this paper we specifically focus on price- and profit-aware recommender systems. We provide a brief overview of the relevant literature and use numerical simulations to illustrate the potential business benefit of such approaches. version:1
arxiv-1707-08015 | Predicting Exploitation of Disclosed Software Vulnerabilities Using Open-source Data | http://arxiv.org/abs/1707.08015 | id:1707.08015 author:Benjamin L. Bullough, Anna K. Yanchenko, Christopher L. Smith, Joseph R. Zipkin category:cs.CR stat.AP stat.ML  published:2017-07-25 summary:Each year, thousands of software vulnerabilities are discovered and reported to the public. Unpatched known vulnerabilities are a significant security risk. It is imperative that software vendors quickly provide patches once vulnerabilities are known and users quickly install those patches as soon as they are available. However, most vulnerabilities are never actually exploited. Since writing, testing, and installing software patches can involve considerable resources, it would be desirable to prioritize the remediation of vulnerabilities that are likely to be exploited. Several published research studies have reported moderate success in applying machine learning techniques to the task of predicting whether a vulnerability will be exploited. These approaches typically use features derived from vulnerability databases (such as the summary text describing the vulnerability) or social media posts that mention the vulnerability by name. However, these prior studies share multiple methodological shortcomings that inflate predictive power of these approaches. We replicate key portions of the prior work, compare their approaches, and show how selection of training and test data critically affect the estimated performance of predictive models. The results of this study point to important methodological considerations that should be taken into account so that results reflect real-world utility. version:1
arxiv-1705-01425 | Data-Driven Synthesis of Smoke Flows with CNN-based Feature Descriptors | http://arxiv.org/abs/1705.01425 | id:1705.01425 author:Mengyu Chu, Nils Thuerey category:cs.GR cs.LG  published:2017-05-03 summary:We present a novel data-driven algorithm to synthesize high-resolution flow simulations with reusable repositories of space-time flow data. In our work, we employ a descriptor learning approach to encode the similarity between fluid regions with differences in resolution and numerical viscosity. We use convolutional neural networks to generate the descriptors from fluid data such as smoke density and flow velocity. At the same time, we present a deformation limiting patch advection method which allows us to robustly track deformable fluid regions. With the help of this patch advection, we generate stable space-time data sets from detailed fluids for our repositories. We can then use our learned descriptors to quickly localize a suitable data set when running a new simulation. This makes our approach very efficient, and resolution independent. We will demonstrate with several examples that our method yields volumes with very high effective resolutions, and non-dissipative small scale details that naturally integrate into the motions of the underlying flow. version:2
arxiv-1707-05615 | Category Level Pick and Place Using Deep Reinforcement Learning | http://arxiv.org/abs/1707.05615 | id:1707.05615 author:Marcus Gualtieri, Andreas ten Pas, Robert Platt category:cs.RO  published:2017-07-18 summary:This paper proposes a new formulation of robotic pick and place. We formulate pick and place as a deep RL problem where the actions are grasp and place poses for the robot's hand, and the state is encoded with the observed geometry local to a selected grasp. This framework is well-suited to learning pick and place tasks involving novel objects in clutter. We present experiments demonstrating that our method works well on a new variant of pick and place tasks which we call category level pick and place where the category of the object to be manipulated is known but its exact appearance and geometry is unknown. The results show, even though these are novel objects and they are presented in clutter, our method can still grasp, re-grasp, and place them in a desired pose with high probability. version:2
arxiv-1707-08008 | Boosted Zero-Shot Learning with Semantic Correlation Regularization | http://arxiv.org/abs/1707.08008 | id:1707.08008 author:Te Pi, Xi Li, Zhongfei, Zhang category:cs.LG  published:2017-07-25 summary:We study zero-shot learning (ZSL) as a transfer learning problem, and focus on the two key aspects of ZSL, model effectiveness and model adaptation. For effective modeling, we adopt the boosting strategy to learn a zero-shot classifier from weak models to a strong model. For adaptable knowledge transfer, we devise a Semantic Correlation Regularization (SCR) approach to regularize the boosted model to be consistent with the inter-class semantic correlations. With SCR embedded in the boosting objective, and with a self-controlled sample selection for learning robustness, we propose a unified framework, Boosted Zero-shot classification with Semantic Correlation Regularization (BZ-SCR). By balancing the SCR-regularized boosted model selection and the self-controlled sample selection, BZ-SCR is capable of capturing both discriminative and adaptable feature-to-class semantic alignments, while ensuring the reliability and adaptability of the learned samples. The experiments on two ZSL datasets show the superiority of BZ-SCR over the state-of-the-arts. version:1
arxiv-1707-08005 | Towards Evolutional Compression | http://arxiv.org/abs/1707.08005 | id:1707.08005 author:Yunhe Wang, Chang Xu, Jiayan Qiu, Chao Xu, Dacheng Tao category:stat.ML cs.LG  published:2017-07-25 summary:Compressing convolutional neural networks (CNNs) is essential for transferring the success of CNNs to a wide variety of applications to mobile devices. In contrast to directly recognizing subtle weights or filters as redundant in a given CNN, this paper presents an evolutionary method to automatically eliminate redundant convolution filters. We represent each compressed network as a binary individual of specific fitness. Then, the population is upgraded at each evolutionary iteration using genetic operations. As a result, an extremely compact CNN is generated using the fittest individual. In this approach, either large or small convolution filters can be redundant, and filters in the compressed network are more distinct. In addition, since the number of filters in each convolutional layer is reduced, the number of filter channels and the size of feature maps are also decreased, naturally improving both the compression and speed-up ratios. Experiments on benchmark deep CNN models suggest the superiority of the proposed algorithm over the state-of-the-art compression methods. version:1
arxiv-1707-08000 | Un modèle pour la représentation des connaissances temporelles dans les documents historiques | http://arxiv.org/abs/1707.08000 | id:1707.08000 author:Sahar Aljalbout, Gilles Falquet category:cs.AI  published:2017-07-25 summary:Processing and publishing the data of the historical sciences in the semantic web is an interesting challenge in which the representation of temporal aspects plays a key role. We propose in this paper a model of temporal knowledge representation adapted to work on historical documents. This model is based on the notion of fluent that is represented in RDF graphs. We show how this model allows to represent the knowledge necessary to the historians and how it can be used to reason on this knowledge using the SWRL and SPARQL languages. This model is being used in a project to digitize, study and publish the manuscripts of linguist Ferdinand de Saussure. version:1
arxiv-1707-07999 | Evidence combination for a large number of sources | http://arxiv.org/abs/1707.07999 | id:1707.07999 author:Kuang Zhou, Arnaud Martin, Quan Pan category:cs.AI  published:2017-07-25 summary:The theory of belief functions is an effective tool to deal with the multiple uncertain information. In recent years, many evidence combination rules have been proposed in this framework, such as the conjunctive rule, the cautious rule, the PCR (Proportional Conflict Redistribution) rules and so on. These rules can be adopted for different types of sources. However, most of these rules are not applicable when the number of sources is large. This is due to either the complexity or the existence of an absorbing element (such as the total conflict mass function for the conjunctive-based rules when applied on unreliable evidence). In this paper, based on the assumption that the majority of sources are reliable, a combination rule for a large number of sources, named LNS (stands for Large Number of Sources), is proposed on the basis of a simple idea: the more common ideas one source shares with others, the morereliable the source is. This rule is adaptable for aggregating a large number of sources among which some are unreliable. It will keep the spirit of the conjunctive rule to reinforce the belief on the focal elements with which the sources are in agreement. The mass on the empty set will be kept as an indicator of the conflict. Moreover, it can be used to elicit the major opinion among the experts. The experimental results on synthetic mass functionsverify that the rule can be effectively used to combine a large number of mass functions and to elicit the major opinion. version:1
arxiv-1707-07998 | Bottom-Up and Top-Down Attention for Image Captioning and VQA | http://arxiv.org/abs/1707.07998 | id:1707.07998 author:Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen Gould, Lei Zhang category:cs.CV  published:2017-07-25 summary:Top-down visual attention mechanisms have been used extensively in image captioning and visual question answering (VQA) to enable deeper image understanding through fine-grained analysis and even multiple steps of reasoning. In this work, we propose a combined bottom-up and top-down attention mechanism that enables attention to be calculated at the level of objects and other salient image regions. This is the natural basis for attention to be considered. Within our approach, the bottom-up mechanism (based on Faster R-CNN) proposes image regions, each with an associated feature vector, while the top-down mechanism determines feature weightings. Applying this approach to image captioning, our results on the MSCOCO test server establish a new state-of-the-art for the task, improving the best published result in terms of CIDEr score from 114.7 to 117.9 and BLEU-4 from 35.2 to 36.9. Demonstrating the broad applicability of the method, applying the same approach to VQA we obtain a new state-of-the-art on the VQA v2.0 dataset with 70.2% overall accuracy. version:1
arxiv-1703-00688 | Dynamic Walking over Rough Terrains by Nonlinear Predictive Control of the Floating-base Inverted Pendulum | http://arxiv.org/abs/1703.00688 | id:1703.00688 author:Stéphane Caron, Abderrahmane Kheddar category:cs.RO  published:2017-03-02 summary:We present a real-time pattern generator for dynamic walking over rough terrains. Our method automatically finds step durations, a critical issue over rough terrains where they depend on terrain topology. To achieve this level of generality, we consider a Floating-base Inverted Pendulum (FIP) model where the center of mass can translate freely and the zero-tilting moment point is allowed to leave the contact surface. This model is equivalent to a linear inverted pendulum with variable center-of-mass height, but its equations of motion remain linear. Our solution then follows three steps: (i) we characterize the FIP contact-stability condition; (ii) we compute feedforward controls by solving a nonlinear optimization over receding-horizon FIP trajectories. Despite running at 30 Hz in a model-predictive fashion, simulations show that the latter is too slow to stabilize dynamic motions. To remedy this, we (iii) linearize FIP feedback control into a constrained linear-quadratic regulator that runs at 300 Hz. We finally demonstrate our solution in simulations with a model of the HRP-4 humanoid robot, including noise and delays over state estimation and foot force control. version:2
arxiv-1707-07976 | Scaled Nuclear Norm Minimization for Low-Rank Tensor Completion | http://arxiv.org/abs/1707.07976 | id:1707.07976 author:Morteza Ashraphijuo, Xiaodong Wang category:stat.ML cs.NA  published:2017-07-25 summary:Minimizing the nuclear norm of a matrix has been shown to be very efficient in reconstructing a low-rank sampled matrix. Furthermore, minimizing the sum of nuclear norms of matricizations of a tensor has been shown to be very efficient in recovering a low-Tucker-rank sampled tensor. In this paper, we propose to recover a low-TT-rank sampled tensor by minimizing a weighted sum of nuclear norms of unfoldings of the tensor. We provide numerical results to show that our proposed method requires significantly less number of samples to recover to the original tensor in comparison with simply minimizing the sum of nuclear norms since the structure of the unfoldings in the TT tensor model is fundamentally different from that of matricizations in the Tucker tensor model. version:1
arxiv-1707-08468 | A Decidable Very Expressive Description Logic for Databases (Extended Version) | http://arxiv.org/abs/1707.08468 | id:1707.08468 author:Alessandro Artale, Enrico Franconi, Rafael Peñaloza, Francesco Sportelli category:cs.AI  published:2017-07-25 summary:We introduce $\mathcal{DLR}^+$, an extension of the n-ary propositionally closed description logic $\mathcal{DLR}$ to deal with attribute-labelled tuples (generalising the positional notation), projections of relations, and global and local objectification of relations, able to express inclusion, functional, key, and external uniqueness dependencies. The logic is equipped with both TBox and ABox axioms. We show how a simple syntactic restriction on the appearance of projections sharing common attributes in a $\mathcal{DLR}^+$ knowledge base makes reasoning in the language decidable with the same computational complexity as $\mathcal{DLR}$. The obtained $\mathcal{DLR}^\pm$ n-ary description logic is able to encode more thoroughly conceptual data models such as EER, UML, and ORM. version:1
arxiv-1707-07938 | Error Bounds for Piecewise Smooth and Switching Regression | http://arxiv.org/abs/1707.07938 | id:1707.07938 author:Fabien Lauer category:stat.ML cs.LG  published:2017-07-25 summary:The paper deals with regression problems, in which the nonsmooth target is assumed to switch between different operating modes. Specifically, piecewise smooth (PWS) regression considers target functions switching deterministically via a partition of the input space, while switching regression considers arbitrary switching laws. The paper derives generalization error bounds in these two settings by following the approach based on Rademacher complexities. For PWS regression, our derivation involves a chaining argument and a decomposition of the covering numbers of PWS classes in terms of the ones of their component functions and the capacity of the classifier partitioning the input space. This yields error bounds with a radical dependency on the number of modes. For switching regression, the decomposition can be performed directly at the level of the Rademacher complexities, which yields bounds with a linear dependency on the number of modes. By using once more chaining and a decomposition at the level of covering numbers, we show how to recover a radical dependency, however at the cost of a slightly worse convergence rate. Examples of applications are given in particular for PWS and swichting regression with linear and kernel-based component functions. version:1
arxiv-1707-07932 | Functional connectivity patterns of autism spectrum disorder identified by deep feature learning | http://arxiv.org/abs/1707.07932 | id:1707.07932 author:Hongyoon Choi category:cs.CV q-bio.NC  published:2017-07-25 summary:Autism spectrum disorder (ASD) is regarded as a brain disease with globally disrupted neuronal networks. Even though fMRI studies have revealed abnormal functional connectivity in ASD, they have not reached a consensus of the disrupted patterns. Here, a deep learning-based feature extraction method identifies multivariate and nonlinear functional connectivity patterns of ASD. Resting-state fMRI data of 972 subjects (465 ASD 507 normal controls) acquired from the Autism Brain Imaging Data Exchange were used. A functional connectivity matrix of each subject was generated using 90 predefined brain regions. As a data-driven feature extraction method without prior knowledge such as subjects diagnosis, variational autoencoder (VAE) summarized the functional connectivity matrix into 2 features. Those feature values of ASD patients were statistically compared with those of controls. A feature was significantly different between ASD and normal controls. The extracted features were visualized by VAE-based generator which can produce virtual functional connectivity matrices. The ASD-related feature was associated with frontoparietal connections, interconnections of the dorsal medial frontal cortex and corticostriatal connections. It also showed a trend of negative correlation with full-scale IQ. A data-driven feature extraction based on deep learning could identify complex patterns of functional connectivity of ASD. This approach will help discover complex patterns of abnormalities in brain connectivity in various brain disorders. version:1
arxiv-1707-07930 | Structural Regularities in Text-based Entity Vector Spaces | http://arxiv.org/abs/1707.07930 | id:1707.07930 author:Christophe Van Gysel, Maarten de Rijke, Evangelos Kanoulas category:cs.IR cs.AI cs.CL  published:2017-07-25 summary:Entity retrieval is the task of finding entities such as people or products in response to a query, based solely on the textual documents they are associated with. Recent semantic entity retrieval algorithms represent queries and experts in finite-dimensional vector spaces, where both are constructed from text sequences. We investigate entity vector spaces and the degree to which they capture structural regularities. Such vector spaces are constructed in an unsupervised manner without explicit information about structural aspects. For concreteness, we address these questions for a specific type of entity: experts in the context of expert finding. We discover how clusterings of experts correspond to committees in organizations, the ability of expert representations to encode the co-author graph, and the degree to which they encode academic rank. We compare latent, continuous representations created using methods based on distributional semantics (LSI), topic models (LDA) and neural networks (word2vec, doc2vec, SERT). Vector spaces created using neural methods, such as doc2vec and SERT, systematically perform better at clustering than LSI, LDA and word2vec. When it comes to encoding entity relations, SERT performs best. version:1
arxiv-1707-07923 | Enhancing Convolutional Neural Networks for Face Recognition with Occlusion Maps and Batch Triplet Loss | http://arxiv.org/abs/1707.07923 | id:1707.07923 author:Daniel Sáez Trigueros, Li Meng, Margaret Hartnett category:cs.CV  published:2017-07-25 summary:Despite the recent success of convolutional neural networks for computer vision applications, unconstrained face recognition remains a challenge. In this work, we make two contributions to the field. Firstly, we consider the problem of face recognition with partial occlusions and show how current approaches might suffer significant performance degradation when dealing with this kind of face images. We propose a simple method to find out which parts of the human face are more important to achieve a high recognition rate, and use that information during training to force a convolutional neural network to learn discriminative features from all the face regions more equally, including those that typical approaches tend to pay less attention to. We test the accuracy of the proposed method when dealing with real-life occlusions using the AR face database. Secondly, we propose a novel loss function called batch triplet loss that improves the performance of the triplet loss by adding an extra term to the loss function to cause minimisation of the standard deviation of both positive and negative scores. We show consistent improvement in the Labeled Faces in the Wild (LFW) benchmark by combining both proposed adjustments to the convolutional neural network training. version:1
arxiv-1707-07922 | Question Dependent Recurrent Entity Network for Question Answering | http://arxiv.org/abs/1707.07922 | id:1707.07922 author:Andrea Madotto, Giuseppe Attardi category:cs.CL  published:2017-07-25 summary:Question Answering is a task which requires building models that are able to automatically reply to questions given by humans. In the recent years, growing interest has been shown in tasks that require reasoning abilities in order to answer questions. Thus, in this study, we introduced a model to accomplish different Question Answering tasks, which are: Reasoning Question Answering and Reading Comprehension. Specially, we analysed and improved a novel model called Recurrent Entity Network, which follows the Memory Network framework. We named our model Question Dependent Recurrent Entity Network since our main contribution is to include the question into the memorization process. Our model has been validated by using both synthetic and real datasets. For the best of our knowledge, we achieved a new state-of-the-art in the Reasoning Question Answering task i.e bAbI tasks, and promising results in the Reading Comprehension one. Finally, we also studied the behavior of our model, through a visualization, in comparison with the original one. version:1
arxiv-1707-07911 | Machine Translation at Booking.com: Journey and Lessons Learned | http://arxiv.org/abs/1707.07911 | id:1707.07911 author:Pavel Levin, Nishikant Dhanuka, Maxim Khalilov category:cs.CL  published:2017-07-25 summary:We describe our recently developed neural machine translation (NMT) system and benchmark it against our own statistical machine translation (SMT) system as well as two other general purpose online engines (statistical and neural). We present automatic and human evaluation results of the translation output provided by each system. We also analyze the effect of sentence length on the quality of output for SMT and NMT systems. version:1
arxiv-1707-07907 | Mutual Alignment Transfer Learning | http://arxiv.org/abs/1707.07907 | id:1707.07907 author:Markus Wulfmeier, Ingmar Posner, Pieter Abbeel category:cs.AI  published:2017-07-25 summary:Training robots for operation in the real world is a complex, time consuming and potentially expensive task. Despite significant success of reinforcement learning in games and simulations, research in real robot applications has not been able to match similar progress. While sample complexity can be reduced by training policies in simulation, these can perform sub-optimally on the real platform given imperfect calibration of model dynamics. We present an approach - supplemental to fine tuning on the real robot - to further benefit from parallel access to a simulator during training. The developed approach harnesses auxiliary rewards to guide the exploration for the real world agent based on the proficiency of the agent in simulation and vice versa. In this context, we demonstrate empirically that the reciprocal alignment for both agents provides further benefit as the agent in simulation can adjust to optimize its behaviour for states commonly visited by the real-world agent. version:1
arxiv-1707-07901 | Partial Transfer Learning with Selective Adversarial Networks | http://arxiv.org/abs/1707.07901 | id:1707.07901 author:Zhangjie Cao, Mingsheng Long, Jianmin Wang, Michael I. Jordan category:cs.LG  published:2017-07-25 summary:Adversarial learning has been successfully embedded into deep networks to learn transferable features, which reduce distribution discrepancy between the source and target domains. Existing domain adversarial networks assume fully shared label space across domains. In the presence of big data, there is strong motivation of transferring both classification and representation models from existing big domains to unknown small domains. This paper introduces partial transfer learning, which relaxes the shared label space assumption to that the target label space is only a subspace of the source label space. Previous methods typically match the whole source domain to the target domain, which are prone to negative transfer for the partial transfer problem. We present Selective Adversarial Network (SAN), which simultaneously circumvents negative transfer by selecting out the outlier source classes and promotes positive transfer by maximally matching the data distributions in the shared label space. Experiments demonstrate that our models exceed state-of-the-art results for partial transfer learning tasks on several benchmark datasets. version:1
arxiv-1707-07890 | Spatiotemporal Modeling for Crowd Counting in Videos | http://arxiv.org/abs/1707.07890 | id:1707.07890 author:Feng Xiong, Xingjian Shi, Dit-Yan Yeung category:cs.CV  published:2017-07-25 summary:Region of Interest (ROI) crowd counting can be formulated as a regression problem of learning a mapping from an image or a video frame to a crowd density map. Recently, convolutional neural network (CNN) models have achieved promising results for crowd counting. However, even when dealing with video data, CNN-based methods still consider each video frame independently, ignoring the strong temporal correlation between neighboring frames. To exploit the otherwise very useful temporal information in video sequences, we propose a variant of a recent deep learning model called convolutional LSTM (ConvLSTM) for crowd counting. Unlike the previous CNN-based methods, our method fully captures both spatial and temporal dependencies. Furthermore, we extend the ConvLSTM model to a bidirectional ConvLSTM model which can access long-range information in both directions. Extensive experiments using four publicly available datasets demonstrate the reliability of our approach and the effectiveness of incorporating temporal information to boost the accuracy of crowd counting. In addition, we also conduct some transfer learning experiments to show that once our model is trained on one dataset, its learning experience can be transferred easily to a new dataset which consists of only very few video frames for model adaptation. version:1
arxiv-1706-08501 | A Simulator for Hedonic Games | http://arxiv.org/abs/1706.08501 | id:1706.08501 author:Luke Harold Miles category:cs.MA cs.AI  published:2017-06-26 summary:Hedonic games are meant to model how coalitions of people form and break apart in the real world. However, it is difficult to run simulations when everything must be done by hand on paper. We present an online software that allows fast and visual simulation of several types of hedonic games. http://lukemiles.org/hedonic-games/ version:2
arxiv-1707-07885 | Wind models and cross-site interpolation for the refugee reception islands in Greece | http://arxiv.org/abs/1707.07885 | id:1707.07885 author:Harris V. Georgiou category:stat.AP stat.ML  published:2017-07-25 summary:In this study, the wind data series from five locations in Aegean Sea islands, the most active `hotspots' in terms of refugee influx during the Oct/2015 - Jan/2016 period, are investigated. The analysis of the three-per-site data series includes standard statistical analysis and parametric distributions, auto-correlation analysis, cross-correlation analysis between the sites, as well as various ARMA models for estimating the feasibility and accuracy of such spatio-temporal linear regressors for predictive analytics. Strong correlations are detected across specific sites and appropriately trained ARMA(7,5) models achieve 1-day look-ahead error (RMSE) of less than 1.9 km/h on average wind speed. The results show that such data-driven statistical approaches are extremely useful in identifying unexpected and sometimes counter-intuitive associations between the available spatial data nodes, which is very important when designing corresponding models for short-term forecasting of sea condition, especially average wave height and direction, which is in fact what defines the associated weather risk of crossing these passages in refugee influx patterns. version:1
arxiv-1707-07863 | Analyzing First-Person Stories Based on Socializing, Eating and Sedentary Patterns | http://arxiv.org/abs/1707.07863 | id:1707.07863 author:Pedro Herruzo, Laura Portell, Alberto Soto, Beatriz Remeseiro category:cs.CV  published:2017-07-25 summary:First-person stories can be analyzed by means of egocentric pictures acquired throughout the whole active day with wearable cameras. This manuscript presents an egocentric dataset with more than 45,000 pictures from four people in different environments such as working or studying. All the images were manually labeled to identify three patterns of interest regarding people's lifestyle: socializing, eating and sedentary. Additionally, two different approaches are proposed to classify egocentric images into one of the 12 target categories defined to characterize these three patterns. The approaches are based on machine learning and deep learning techniques, including traditional classifiers and state-of-art convolutional neural networks. The experimental results obtained when applying these methods to the egocentric dataset demonstrated their adequacy for the problem at hand. version:1
arxiv-1707-07857 | Motion-Appearance Interactive Encoding for Object Segmentation in Unconstrained Videos | http://arxiv.org/abs/1707.07857 | id:1707.07857 author:Chunchao Guo, Jianhuang Lai, Xiaohua Xie category:cs.CV I.4.6; I.4.8  published:2017-07-25 summary:We present a novel method of integrating motion and appearance cues for foreground object segmentation in unconstrained videos. Unlike conventional methods encoding motion and appearance patterns individually, our method puts particular emphasis on their mutual assistance. Specifically, we propose using an interactively constrained encoding (ICE) scheme to incorporate motion and appearance patterns into a graph that leads to a spatiotemporal energy optimization. The reason of utilizing ICE is that both motion and appearance cues for the same target share underlying correlative structure, thus can be exploited in a deeply collaborative manner. We perform ICE not only in the initialization but also in the refinement stage of a two-layer framework for object segmentation. This scheme allows our method to consistently capture structural patterns about object perceptions throughout the whole framework. Our method can be operated on superpixels instead of raw pixels to reduce the number of graph nodes by two orders of magnitude. Moreover, we propose to partially explore the multi-object localization problem with inter-occlusion by weighted bipartite graph matching. Comprehensive experiments on three benchmark datasets (i.e., SegTrack, MOViCS, and GaTech) demonstrate the effectiveness of our approach compared with extensive state-of-the-art methods. version:1
arxiv-1707-07660 | Thread Reconstruction in Conversational Data using Neural Coherence Models | http://arxiv.org/abs/1707.07660 | id:1707.07660 author:Dat Tien Nguyen, Shafiq Joty, Basma El Amel Boussaha, Maarten de Rijke category:cs.IR cs.CL  published:2017-07-24 summary:Discussion forums are an important source of information. They are often used to answer specific questions a user might have and to discover more about a topic of interest. Discussions in these forums may evolve in intricate ways, making it difficult for users to follow the flow of ideas. We propose a novel approach for automatically identifying the underlying thread structure of a forum discussion. Our approach is based on a neural model that computes coherence scores of possible reconstructions and then selects the highest scoring, i.e., the most coherent one. Preliminary experiments demonstrate promising results outperforming a number of strong baseline methods. version:2
arxiv-1707-06792 | Graphical posterior predictive classifier: Bayesian model averaging with particle Gibbs | http://arxiv.org/abs/1707.06792 | id:1707.06792 author:Tatjana Pavlenko, Felix Leopoldo Rios category:stat.ML  published:2017-07-21 summary:In this study, we present a multi-class graphical Bayesian predictive classifier that incorporates the uncertainty in the model selection into the standard Bayesian formalism. For each class, the dependence structure underlying the observed features is represented by a set of decomposable Gaussian graphical models. Emphasis is then placed on the Bayesian model averaging which takes full account of the class-specific model uncertainty by averaging over the posterior graph model probabilities. Even though the decomposability assumption severely reduces the model space, the size of the class of decomposable models is still immense, rendering the explicit Bayesian averaging over all the models infeasible. To address this issue, we consider the particle Gibbs strategy of Olsson et al. (2016) for posterior sampling from decomposable graphical models which utilizes the Christmas tree algorithm of Rios et al. (2016) as proposal kernel. We also derive the a strong hyper Markov law which we call the hyper normal Wishart law that allow to perform the resultant Bayesian calculations locally. The proposed predictive graphical classifier reveals superior performance compared to the ordinary Bayesian predictive rule that does not account for the model uncertainty, as well as to a number of out-of-the-box classifiers. version:2
arxiv-1707-01408 | Video Representation Learning and Latent Concept Mining for Large-scale Multi-label Video Classification | http://arxiv.org/abs/1707.01408 | id:1707.01408 author:Po-Yao Huang, Ye Yuan, Zhenzhong Lan, Lu Jiang, Alexander G. Hauptmann category:cs.CV  published:2017-07-05 summary:We report on CMU Informedia Lab's system used in Google's YouTube 8 Million Video Understanding Challenge. In this multi-label video classification task, our pipeline achieved 84.675% and 84.662% GAP on our evaluation split and the official test set. We attribute the good performance to three components: 1) Refined video representation learning with residual links and hypercolumns 2) Latent concept mining which captures interactions among concepts. 3) Learning with temporal segments and weighted multi-model ensemble. We conduct experiments to validate and analyze the contribution of our models. We also share some unsuccessful trials leveraging conventional approaches such as recurrent neural networks for video representation learning for this large-scale video dataset. All the codes to reproduce our results are publicly available at https://github.com/Martini09/informedia-yt8m-release. version:3
arxiv-1707-07835 | Towards Semantic Query Segmentation | http://arxiv.org/abs/1707.07835 | id:1707.07835 author:Ajinkya Kale, Thrivikrama Taula, Sanjika Hewavitharana, Amit Srivastava category:cs.IR cs.CL  published:2017-07-25 summary:Query Segmentation is one of the critical components for understanding users' search intent in Information Retrieval tasks. It involves grouping tokens in the search query into meaningful phrases which help downstream tasks like search relevance and query understanding. In this paper, we propose a novel approach to segment user queries using distributed query embeddings. Our key contribution is a supervised approach to the segmentation task using low-dimensional feature vectors for queries, getting rid of traditional hand tuned and heuristic NLP features which are quite expensive. We benchmark on a 50,000 human-annotated web search engine query corpus achieving comparable accuracy to state-of-the-art techniques. The advantage of our technique is its fast and does not use external knowledge-base like Wikipedia for score boosting. This helps us generalize our approach to other domains like eCommerce without any fine-tuning. We demonstrate the effectiveness of this method on another 50,000 human-annotated eCommerce query corpus from eBay search logs. Our approach is easy to implement and generalizes well across different search domains proving the power of low-dimensional embeddings in query segmentation task, opening up a new direction of research for this problem. version:1
arxiv-1707-07833 | ssEMnet: Serial-section Electron Microscopy Image Registration using a Spatial Transformer Network with Learned Features | http://arxiv.org/abs/1707.07833 | id:1707.07833 author:Inwan Yoo, David G. C. Hildebrand, Willie F. Tobin, Wei-Chung Allen Lee, Won-Ki Jeong category:cs.CV  published:2017-07-25 summary:The alignment of serial-section electron microscopy (ssEM) images is critical for efforts in neuroscience that seek to reconstruct neuronal circuits. However, each ssEM plane contains densely packed structures that vary from one section to the next, which makes matching features across images a challenge. Advances in deep learning has resulted in unprecedented performance in similar computer vision problems, but to our knowledge, they have not been successfully applied to ssEM image co-registration. In this paper, we introduce a novel deep network model that combines a spatial transformer for image deformation and a convolutional autoencoder for unsupervised feature learning for robust ssEM image alignment. This results in improved accuracy and robustness while requiring substantially less user intervention than conventional methods. We evaluate our method by comparing registration quality across several datasets. version:1
arxiv-1707-07831 | Linear Discriminant Generative Adversarial Networks | http://arxiv.org/abs/1707.07831 | id:1707.07831 author:Zhun Sun, Mete Ozay, Takayuki Okatani category:stat.ML cs.LG  published:2017-07-25 summary:We develop a novel method for training of GANs for unsupervised and class conditional generation of images, called Linear Discriminant GAN (LD-GAN). The discriminator of an LD-GAN is trained to maximize the linear separability between distributions of hidden representations of generated and targeted samples, while the generator is updated based on the decision hyper-planes computed by performing LDA over the hidden representations. LD-GAN provides a concrete metric of separation capacity for the discriminator, and we experimentally show that it is possible to stabilize the training of LD-GAN simply by calibrating the update frequencies between generators and discriminators in the unsupervised case, without employment of normalization methods and constraints on weights. In the class conditional generation tasks, the proposed method shows improved training stability together with better generalization performance compared to WGAN that employs an auxiliary classifier. version:1
arxiv-1707-07830 | Improving Robustness of Feature Representations to Image Deformations using Powered Convolution in CNNs | http://arxiv.org/abs/1707.07830 | id:1707.07830 author:Zhun Sun, Mete Ozay, Takayuki Okatani category:cs.CV  published:2017-07-25 summary:In this work, we address the problem of improvement of robustness of feature representations learned using convolutional neural networks (CNNs) to image deformation. We argue that higher moment statistics of feature distributions could be shifted due to image deformations, and the shift leads to degrade of performance and cannot be reduced by ordinary normalization methods as observed in experimental analyses. In order to attenuate this effect, we apply additional non-linearity in CNNs by combining power functions with learnable parameters into convolution operation. In the experiments, we observe that CNNs which employ the proposed method obtain remarkable boost in both the generalization performance and the robustness under various types of deformations using large scale benchmark datasets. For instance, a model equipped with the proposed method obtains 3.3\% performance boost in mAP on Pascal Voc object detection task using deformed images, compared to the reference model, while both models provide the same performance using original images. To the best of our knowledge, this is the first work that studies robustness of deep features learned using CNNs to a wide range of deformations for object recognition and detection. version:1
arxiv-1707-07825 | Multiple-Kernel Local-Patch Descriptor | http://arxiv.org/abs/1707.07825 | id:1707.07825 author:Arun Mukundan, Giorgos Tolias, Ondrej Chum category:cs.CV  published:2017-07-25 summary:We propose a multiple-kernel local-patch descriptor based on efficient match kernels of patch gradients. It combines two parametrizations of gradient position and direction, each parametrization provides robustness to a different type of patch miss-registration: polar parametrization for noise in the patch dominant orientation detection, Cartesian for imprecise location of the feature point. Even though handcrafted, the proposed method consistently outperforms the state-of-the-art methods on two local patch benchmarks. version:1
arxiv-1707-07821 | Concept Drift Detection and Adaptation with Hierarchical Hypothesis Testing | http://arxiv.org/abs/1707.07821 | id:1707.07821 author:Shujian Yu, Zubin Abraham, Heng Wang, Mohak Shah, José C. Príncipe category:stat.ML cs.LG  published:2017-07-25 summary:In a streaming environment, there is often a need for statistical prediction models to detect and adapt to concept drifts (i.e., changes in the underlying relationship between the response and predictor data streams being modeled) so as to mitigate deteriorating predictive performance over time. Various concept drift detection approaches have been proposed in the past decades. However, they do not perform well across different concept drift types (e.g., gradual or abrupt, recurrent or irregular) and different data stream distributions (e.g., balanced and imbalanced labels). This paper presents a novel framework for statistical prediction models (such as a classifier) that detects and also adapts to the various concept drift types, even in the presence of imbalanced data labels. The framework leverages a hierarchical set of hypothesis tests in an online fashion to detect concept drifts and employs an adaptive training strategy to significantly boost its adaptation capability. The performance of the proposed concept drift detection and adaptation framework is compared to benchmark approaches using both simulated and real-world datasets spanning the breadth of concept drift types. The proposed approaches significantly outperform benchmark solutions in terms of precision, delay of detection as well as the adaptability across different concepts, regardless of data characteristics. version:1
arxiv-1707-07381 | Group-wise Deep Co-saliency Detection | http://arxiv.org/abs/1707.07381 | id:1707.07381 author:Lina Wei, Shanshan Zhao, Omar El Farouk Bourahla, Xi Li, Fei Wu category:cs.CV  published:2017-07-24 summary:In this paper, we propose an end-to-end group-wise deep co-saliency detection approach to address the co-salient object discovery problem based on the fully convolutional network (FCN) with group input and group output. The proposed approach captures the group-wise interaction information for group images by learning a semantics-aware image representation based on a convolutional neural network, which adaptively learns the group-wise features for co-saliency detection. Furthermore, the proposed approach discovers the collaborative and interactive relationships between group-wise feature representation and single-image individual feature representation, and model this in a collaborative learning framework. Finally, we set up a unified end-to-end deep learning scheme to jointly optimize the process of group-wise feature representation learning and the collaborative learning, leading to more reliable and robust co-saliency detection results. Experimental results demonstrate the effectiveness of our approach in comparison with the state-of-the-art approaches. version:2
arxiv-1707-07819 | Detecting Semantic Parts on Partially Occluded Objects | http://arxiv.org/abs/1707.07819 | id:1707.07819 author:Jianyu Wang, Cihang Xie, Zhishuai Zhang, Jun Zhu, Lingxi Xie, Alan Yuille category:cs.CV  published:2017-07-25 summary:In this paper, we address the task of detecting semantic parts on partially occluded objects. We consider a scenario where the model is trained using non-occluded images but tested on occluded images. The motivation is that there are infinite number of occlusion patterns in real world, which cannot be fully covered in the training data. So the models should be inherently robust and adaptive to occlusions instead of fitting / learning the occlusion patterns in the training data. Our approach detects semantic parts by accumulating the confidence of local visual cues. Specifically, the method uses a simple voting method, based on log-likelihood ratio tests and spatial constraints, to combine the evidence of local cues. These cues are called visual concepts, which are derived by clustering the internal states of deep networks. We evaluate our voting scheme on the VehicleSemanticPart dataset with dense part annotations. We randomly place two, three or four irrelevant objects onto the target object to generate testing images with various occlusions. Experiments show that our algorithm outperforms several competitors in semantic part detection when occlusions are present. version:1
arxiv-1707-07815 | Graph-Theoretic Spatiotemporal Context Modeling for Video Saliency Detection | http://arxiv.org/abs/1707.07815 | id:1707.07815 author:Lina Wei, Fangfang Wang, Xi Li, Fei Wu, Jun Xiao category:cs.CV  published:2017-07-25 summary:As an important and challenging problem in computer vision, video saliency detection is typically cast as a spatiotemporal context modeling problem over consecutive frames. As a result, a key issue in video saliency detection is how to effectively capture the intrinsical properties of atomic video structures as well as their associated contextual interactions along the spatial and temporal dimensions. Motivated by this observation, we propose a graph-theoretic video saliency detection approach based on adaptive video structure discovery, which is carried out within a spatiotemporal atomic graph. Through graph-based manifold propagation, the proposed approach is capable of effectively modeling the semantically contextual interactions among atomic video structures for saliency detection while preserving spatial smoothness and temporal consistency. Experiments demonstrate the effectiveness of the proposed approach over several benchmark datasets. version:1
arxiv-1707-07212 | "i have a feeling trump will win..................": Forecasting Winners and Losers from User Predictions on Twitter | http://arxiv.org/abs/1707.07212 | id:1707.07212 author:Sandesh Swamy, Alan Ritter, Marie-Catherine de Marneffe category:cs.CL  published:2017-07-22 summary:Social media users often make explicit predictions about upcoming events. Such statements vary in the degree of certainty the author expresses toward the outcome:"Leonardo DiCaprio will win Best Actor" vs. "Leonardo DiCaprio may win" or "No way Leonardo wins!". Can popular beliefs on social media predict who will win? To answer this question, we build a corpus of tweets annotated for veridicality on which we train a log-linear classifier that detects positive veridicality with high precision. We then forecast uncertain outcomes using the wisdom of crowds, by aggregating users' explicit predictions. Our method for forecasting winners is fully automated, relying only on a set of contenders as input. It requires no training data of past outcomes and outperforms sentiment and tweet volume baselines on a broad range of contest prediction tasks. We further demonstrate how our approach can be used to measure the reliability of individual accounts' predictions and retrospectively identify surprise outcomes. version:2
arxiv-1707-08114 | A Survey on Multi-Task Learning | http://arxiv.org/abs/1707.08114 | id:1707.08114 author:Yu Zhang, Qiang Yang category:cs.LG cs.AI  published:2017-07-25 summary:Multi-Task Learning (MTL) is a learning paradigm in machine learning and its aim is to leverage useful information contained in multiple related tasks to help improve the generalization performance of all the tasks. In this paper, we give a survey for MTL. First, we classify different MTL algorithms into several categories: feature learning approach, low-rank approach, task clustering approach, task relation learning approach, dirty approach, multi-level approach and deep learning approach. In order to compare different approaches, we discuss the characteristics of each approach. In order to improve the performance of learning tasks further, MTL can be combined with other learning paradigms including semi-supervised learning, active learning, reinforcement learning, multi-view learning and graphical models. When the number of tasks is large or the data dimensionality is high, batch MTL models are difficult to handle this situation and online, parallel and distributed MTL models as well as feature hashing are reviewed to reveal the computational and storage advantages. Many real-world applications use MTL to boost their performance and we introduce some representative works. Finally, we present theoretical analyses and discuss several future directions for MTL. version:1
arxiv-1606-00626 | The Challenge of Non-Technical Loss Detection using Artificial Intelligence: A Survey | http://arxiv.org/abs/1606.00626 | id:1606.00626 author:Patrick Glauner, Jorge Augusto Meira, Petko Valtchev, Radu State, Franck Bettinger category:cs.AI  published:2016-06-02 summary:Detection of non-technical losses (NTL) which include electricity theft, faulty meters or billing errors has attracted increasing attention from researchers in electrical engineering and computer science. NTLs cause significant harm to the economy, as in some countries they may range up to 40% of the total electricity distributed. The predominant research direction is employing artificial intelligence to predict whether a customer causes NTL. This paper first provides an overview of how NTLs are defined and their impact on economies, which include loss of revenue and profit of electricity providers and decrease of the stability and reliability of electrical power grids. It then surveys the state-of-the-art research efforts in a up-to-date and comprehensive review of algorithms, features and data sets used. It finally identifies the key scientific and engineering challenges in NTL detection and suggests how they could be addressed in the future. version:3
arxiv-1707-09959 | Correction of "Cloud Removal By Fusing Multi-Source and Multi-Temporal Images" | http://arxiv.org/abs/1707.09959 | id:1707.09959 author:Chengyue Zhang, Zhiwei Li, Qing Cheng, Xinghua Li, Huanfeng Shen category:cs.CV  published:2017-07-25 summary:Remote sensing images often suffer from cloud cover. Cloud removal is required in many applications of remote sensing images. Multitemporal-based methods are popular and effective to cope with thick clouds. This paper contributes to a summarization and experimental comparation of the existing multitemporal-based methods. Furthermore, we propose a spatiotemporal-fusion with poisson-adjustment method to fuse multi-sensor and multi-temporal images for cloud removal. The experimental results show that the proposed method has potential to address the problem of accuracy reduction of cloud removal in multi-temporal images with significant changes. version:1
arxiv-1707-09873 | Representation Learning on Large and Small Data | http://arxiv.org/abs/1707.09873 | id:1707.09873 author:Chun-Nan Chou, Chuen-Kai Shie, Fu-Chieh Chang, Jocelyn Chang, Edward Y. Chang category:cs.CV  published:2017-07-25 summary:Deep learning owes its success to three key factors: scale of data, enhanced models to learn representations from data, and scale of computation. This book chapter presented the importance of the data-driven approach to learn good representations from both big data and small data. In terms of big data, it has been widely accepted in the research community that the more data the better for both representation and classification improvement. The question is then how to learn representations from big data, and how to perform representation learning when data is scarce. We addressed the first question by presenting CNN model enhancements in the aspects of representation, optimization, and generalization. To address the small data challenge, we showed transfer representation learning to be effective. Transfer representation learning transfers the learned representation from a source domain where abundant training data is available to a target domain where training data is scarce. Transfer representation learning gave the OM and melanoma diagnosis modules of our XPRIZE Tricorder device (which finished $2^{nd}$ out of $310$ competing teams) a significant boost in diagnosis accuracy. version:1
arxiv-1707-09875 | SAR Target Recognition Using the Multi-aspect-aware Bidirectional LSTM Recurrent Neural Networks | http://arxiv.org/abs/1707.09875 | id:1707.09875 author:Fan Zhang, Chen Hu, Qiang Yin, Wei Li, Hengchao Li, Wen Hong category:cs.CV cs.LG  published:2017-07-25 summary:The outstanding pattern recognition performance of deep learning brings new vitality to the synthetic aperture radar (SAR) automatic target recognition (ATR). However, there is a limitation in current deep learning based ATR solution that each learning process only handle one SAR image, namely learning the static scattering information, while missing the space-varying information. It is obvious that multi-aspect joint recognition introduced space-varying scattering information should improve the classification accuracy and robustness. In this paper, a novel multi-aspect-aware method is proposed to achieve this idea through the bidirectional Long Short-Term Memory (LSTM) recurrent neural networks based space-varying scattering information learning. Specifically, we first select different aspect images to generate the multi-aspect space-varying image sequences. Then, the Gabor filter and three-patch local binary pattern (TPLBP) are progressively implemented to extract a comprehensive spatial features, followed by dimensionality reduction with the Multi-layer Perceptron (MLP) network. Finally, we design a bidirectional LSTM recurrent neural network to learn the multi-aspect features with further integrating the softmax classifier to achieve target recognition. Experimental results demonstrate that the proposed method can achieve 99.9% accuracy for 10-class recognition. Besides, its anti-noise and anti-confusion performance are also better than the conventional deep learning based methods. version:1
arxiv-1704-05201 | Stein Variational Adaptive Importance Sampling | http://arxiv.org/abs/1704.05201 | id:1704.05201 author:Jun Han, Qiang Liu category:stat.ML  published:2017-04-18 summary:We propose a novel adaptive importance sampling algorithm which incorporates Stein variational gradient decent algorithm (SVGD) with importance sampling (IS). Our algorithm leverages the nonparametric transforms in SVGD to iteratively decrease the KL divergence between our importance proposal and the target distribution. The advantages of this algorithm are twofold: first, our algorithm turns SVGD into a standard IS algorithm, allowing us to use standard diagnostic and analytic tools of IS to evaluate and interpret the results; second, we do not restrict the choice of our importance proposal to predefined distribution families like traditional (adaptive) IS methods. Empirical experiments demonstrate that our algorithm performs well on evaluating partition functions of restricted Boltzmann machines and testing likelihood of variational auto-encoders. version:6
arxiv-1707-07806 | Macro Grammars and Holistic Triggering for Efficient Semantic Parsing | http://arxiv.org/abs/1707.07806 | id:1707.07806 author:Yuchen Zhang, Panupong Pasupat, Percy Liang category:cs.CL  published:2017-07-25 summary:To learn a semantic parser from denotations, a learning algorithm must search over a combinatorially large space of logical forms for ones consistent with the annotated denotations. We propose a new online learning algorithm that searches faster as training progresses. The two key ideas are using macro grammars to cache the abstract patterns of useful logical forms found thus far, and holistic triggering to efficiently retrieve the most relevant patterns based on sentence similarity. On the WikiTableQuestions dataset, we first expand the search space of an existing model to improve the state-of-the-art accuracy from 38.7% to 42.7%, and then use macro grammars and holistic triggering to achieve an 11x speedup and an accuracy of 43.7%. version:1
arxiv-1707-07794 | Relational Learning and Feature Extraction by Querying over Heterogeneous Information Networks | http://arxiv.org/abs/1707.07794 | id:1707.07794 author:Parisa Kordjamshidi, Sameer Singh, Daniel Khashabi, Christos Christodoulopoulos, Mark Summons, Saurabh Sinha, Dan Roth category:cs.AI cs.DB  published:2017-07-25 summary:Many real world systems need to operate on heterogeneous information networks that consist of numerous interacting components of different types. Examples include systems that perform data analysis on biological information networks; social networks; and information extraction systems processing unstructured data to convert raw text to knowledge graphs. Many previous works describe specialized approaches to perform specific types of analysis, mining and learning on such networks. In this work, we propose a unified framework consisting of a data model -a graph with a first order schema along with a declarative language for constructing, querying and manipulating such networks in ways that facilitate relational and structured machine learning. In particular, we provide an initial prototype for a relational and graph traversal query language where queries are directly used as relational features for structured machine learning models. Feature extraction is performed by making declarative graph traversal queries. Learning and inference models can directly operate on this relational representation and augment it with new data and knowledge that, in turn, is integrated seamlessly into the relational structure to support new predictions. We demonstrate this system's capabilities by showcasing tasks in natural language processing and computational biology domains. version:1
arxiv-1707-07788 | Space Efficient Breadth-First and Level Traversals of Consistent Global States of Parallel Programs | http://arxiv.org/abs/1707.07788 | id:1707.07788 author:Himanshu Chauhan, Vijay Garg category:cs.DC  published:2017-07-25 summary:Enumerating consistent global states of a computation is a fundamental problem in parallel computing with applications to debug- ging, testing and runtime verification of parallel programs. Breadth-first search (BFS) enumeration is especially useful for these applications as it finds an erroneous consistent global state with the least number of events possible. The total number of executed events in a global state is called its rank. BFS also allows enumeration of all global states of a given rank or within a range of ranks. If a computation on n processes has m events per process on average, then the traditional BFS (Cooper-Marzullo and its variants) requires $\mathcal{O}(\frac{m^{n-1}}{n})$ space in the worst case, whereas ou r algorithm performs the BFS requires $\mathcal{O}(m^2n^2)$ space. Thus, we reduce the space complexity for BFS enumeration of consistent global states exponentially. and give the first polynomial space algorithm for this task. In our experimental evaluation of seven benchmarks, traditional BFS fails in many cases by exhausting the 2 GB heap space allowed to the JVM. In contrast, our implementation uses less than 60 MB memory and is also faster in many cases. version:1
arxiv-1707-08991 | Efficient Deformable Shape Correspondence via Kernel Matching | http://arxiv.org/abs/1707.08991 | id:1707.08991 author:Amit Boyarski, Alex Bronstein, Michael Bronstein, Daniel Cremers, Ron Kimmel, Zorah Lähner, Or Litany, Tal Remez, Emanuele Rodolà, Ron Slossberg, Matthias Vestner category:cs.CV  published:2017-07-25 summary:We present a method to match three dimensional shapes under non-isometric deformations, topology changes and partiality. We formulate the problem as matching between a set of pair-wise and point-wise descriptors, imposing a continuity prior on the mapping, and propose a projected descent optimization procedure inspired by difference of convex functions (DC) programming. Surprisingly, in spite of the highly non-convex nature of the resulting quadratic assignment problem, our method converges to a semantically meaningful and continuous mapping in most of our experiments, and scales well. We provide preliminary theoretical analysis and several interpretations of the method. version:1
arxiv-1707-09240 | Human Pose Forecasting via Deep Markov Models | http://arxiv.org/abs/1707.09240 | id:1707.09240 author:Sam Toyer, Anoop Cherian, Tengda Han, Stephen Gould category:cs.CV cs.LG  published:2017-07-24 summary:Human pose forecasting is an important problem in computer vision with applications to human-robot interaction, visual surveillance, and autonomous driving. Usually, forecasting algorithms use 3D skeleton sequences and are trained to forecast for a few milliseconds into the future. Long-range forecasting is challenging due to the difficulty of estimating how long a person continues an activity. To this end, our contributions are threefold: (i) we propose a generative framework for poses using variational autoencoders based on Deep Markov Models (DMMs); (ii) we evaluate our pose forecasts using a pose-based action classifier, which we argue better reflects the subjective quality of pose forecasts than distance in coordinate space; (iii) last, for evaluation of the new model, we introduce a 480,000-frame video dataset called Ikea Furniture Assembly (Ikea FA), which depicts humans repeatedly assembling and disassembling furniture. We demonstrate promising results for our approach on both Ikea FA and the existing NTU RGB+D dataset. version:1
arxiv-1707-08476 | Guidelines for Artificial Intelligence Containment | http://arxiv.org/abs/1707.08476 | id:1707.08476 author:James Babcock, Janos Kramar, Roman V. Yampolskiy category:cs.AI cs.CR  published:2017-07-24 summary:With almost daily improvements in capabilities of artificial intelligence it is more important than ever to develop safety software for use by the AI research community. Building on our previous work on AI Containment Problem we propose a number of guidelines which should help AI safety researchers to develop reliable sandboxing software for intelligent programs of all levels. Such safety container software will make it possible to study and analyze intelligent artificial agent while maintaining certain level of safety against information leakage, social engineering attacks and cyberattacks from within the container. version:1
arxiv-1707-07699 | Monitoring Partially Synchronous Distributed Systems using SMT Solvers | http://arxiv.org/abs/1707.07699 | id:1707.07699 author:Vidhya Tekken Valapil, Sorrachai Yingchareonthawornchai, Sandeep Kulkarni, Eric Torng, Murat Demirbas category:cs.DC  published:2017-07-24 summary:In this paper, we discuss the feasibility of monitoring partially synchronous distributed systems to detect latent bugs, i.e., errors caused by concurrency and race conditions among concurrent processes. We present a monitoring framework where we model both system constraints and latent bugs as Satisfiability Modulo Theories (SMT) formulas, and we detect the presence of latent bugs using an SMT solver. We demonstrate the feasibility of our framework using both synthetic applications where latent bugs occur at any time with random probability and an application involving exclusive access to a shared resource with a subtle timing bug. We illustrate how the time required for verification is affected by parameters such as communication frequency, latency, and clock skew. Our results show that our framework can be used for real-life applications, and because our framework uses SMT solvers, the range of appropriate applications will increase as these solvers become more efficient over time. version:1
arxiv-1707-07662 | Towards Real-Time Search Planning in Subsea Environments | http://arxiv.org/abs/1707.07662 | id:1707.07662 author:James McMahon, Harun Yetkin, Artur Wolek, Zachary Waters, Dan Stilwell category:cs.RO cs.AI I.2.8; I.2.9  published:2017-07-24 summary:We address the challenge of computing search paths in real-time for subsea applications where the goal is to locate an unknown number of targets on the seafloor. Our approach maximizes a formal definition of search effectiveness given finite search effort. We account for false positive measurements and variation in the performance of the search sensor due to geographic variation of the seafloor. We compare near-optimal search paths that can be computed in real-time with optimal search paths for which real-time computation is infeasible. We show how sonar data acquired for locating targets at a specific location can also be used to characterize the performance of the search sonar at that location. Our approach is illustrated with numerical experiments where search paths are planned using sonar data previously acquired from Boston Harbor. version:1
arxiv-1707-07659 | An Improved Approximate Consensus Algorithm in the Presence of Mobile Faults | http://arxiv.org/abs/1707.07659 | id:1707.07659 author:Lewis Tseng category:cs.DC  published:2017-07-24 summary:This paper explores the problem of reaching approximate consensus in synchronous point-to-point networks, where each pair of nodes is able to communicate with each other directly and reliably. We consider the mobile Byzantine fault model proposed by Garay '94 -- in the model, an omniscient adversary can corrupt up to $f$ nodes in each round, and at the beginning of each round, faults may "move" in the system (i.e., different sets of nodes may become faulty in different rounds). Recent work by Bonomi et al. '16 proposed a simple iterative approximate consensus algorithm which requires at least $4f+1$ nodes. This paper proposes a novel technique of using "confession" (a mechanism to allow others to ignore past behavior) and a variant of reliable broadcast to improve the fault-tolerance level. In particular, we present an approximate consensus algorithm that requires only $\lceil 7f/2\rceil + 1$ nodes, an $\lfloor f/2 \rfloor$ improvement over the state-of-the-art algorithms. Moreover, we also show that the proposed algorithm is optimal within a family of round-based algorithms. version:1
arxiv-1707-07596 | Adversarial Sets for Regularising Neural Link Predictors | http://arxiv.org/abs/1707.07596 | id:1707.07596 author:Pasquale Minervini, Thomas Demeester, Tim Rocktäschel, Sebastian Riedel category:cs.AI  published:2017-07-24 summary:In adversarial training, a set of models learn together by pursuing competing goals, usually defined on single data instances. However, in relational learning and other non-i.i.d domains, goals can also be defined over sets of instances. For example, a link predictor for the is-a relation needs to be consistent with the transitivity property: if is-a(x_1, x_2) and is-a(x_2, x_3) hold, is-a(x_1, x_3) needs to hold as well. Here we use such assumptions for deriving an inconsistency loss, measuring the degree to which the model violates the assumptions on an adversarially-generated set of examples. The training objective is defined as a minimax problem, where an adversary finds the most offending adversarial examples by maximising the inconsistency loss, and the model is trained by jointly minimising a supervised loss and the inconsistency loss on the adversarial examples. This yields the first method that can use function-free Horn clauses (as in Datalog) to regularise any neural link predictor, with complexity independent of the domain size. We show that for several link prediction models, the optimisation problem faced by the adversary has efficient closed-form solutions. Experiments on link prediction benchmarks indicate that given suitable prior knowledge, our method can significantly improve neural link predictors on all relevant metrics. version:1
arxiv-1707-05340 | PDD Graph: Bridging Electronic Medical Records and Biomedical Knowledge Graphs via Entity Linking | http://arxiv.org/abs/1707.05340 | id:1707.05340 author:Meng Wang, Jiaheng Zhang, Jun Liu, Wei Hu, Sen Wang, Xue Li, Wenqiang Liu category:cs.DB cs.AI cs.IR  published:2017-07-17 summary:Electronic medical records contain multi-format electronic medical data that consist of an abundance of medical knowledge. Facing with patient's symptoms, experienced caregivers make right medical decisions based on their professional knowledge that accurately grasps relationships between symptoms, diagnosis and corresponding treatments. In this paper, we aim to capture these relationships by constructing a large and high-quality heterogenous graph linking patients, diseases, and drugs (PDD) in EMRs. Specifically, we propose a novel framework to extract important medical entities from MIMIC-III (Medical Information Mart for Intensive Care III) and automatically link them with the existing biomedical knowledge graphs, including ICD-9 ontology and DrugBank. The PDD graph presented in this paper is accessible on the Web via the SPARQL endpoint, and provides a pathway for medical discovery and applications, such as effective treatment recommendations. version:2
arxiv-1707-07518 | A Loosely-Coupled Approach for Metric Scale Estimation in Monocular Vision-Inertial Systems | http://arxiv.org/abs/1707.07518 | id:1707.07518 author:Ariane Spaenlehauer, Vincent Fremont, Y. Ahmet Sekercioglu, Isabelle Fantoni category:cs.RO  published:2017-07-24 summary:In monocular vision systems, lack of knowledge about metric distances caused by the inherent scale ambiguity can be a strong limitation for some applications. We offer a method for fusing inertial measurements with monocular odometry or tracking to estimate metric distances in inertial-monocular systems and to increase the rate of pose estimates. As we performed the fusion in a loosely-coupled manner, each input block can be easily replaced with one's preference, which makes our method quite flexible. We experimented our method using the ORB-SLAM algorithm for the monocular tracking input and Euler forward integration to process the inertial measurements. We chose sets of data recorded on UAVs to design a suitable system for flying robots. version:1
arxiv-1707-07478 | A Wait-free Multi-word Atomic (1,N) Register for Large-scale Data Sharing on Multi-core Machines | http://arxiv.org/abs/1707.07478 | id:1707.07478 author:Mauro Ianni, Alessandro Pellegrini, Francesco Quaglia category:cs.DC  published:2017-07-24 summary:We present a multi-word atomic (1,N) register for multi-core machines exploiting Read-Modify-Write (RMW) instructions to coordinate the writer and the readers in a wait-free manner. Our proposal, called Anonymous Readers Counting (ARC), enables large-scale data sharing by admitting up to $2^{32}-2$ concurrent readers on off-the-shelf 64-bits machines, as opposed to the most advanced RMW-based approach which is limited to 58 readers. Further, ARC avoids multiple copies of the register content when accessing it---this affects classical register's algorithms based on atomic read/write operations on single words. Thus it allows for higher scalability with respect to the register size. Moreover, ARC explicitly reduces improves performance via a proper limitation of RMW instructions in case of read operations, and by supporting constant time for read operations and amortized constant time for write operations. A proof of correctness of our register algorithm is also provided, together with experimental data for a comparison with literature proposals. Beyond assessing ARC on physical platforms, we carry out as well an experimentation on virtualized infrastructures, which shows the resilience of wait-free synchronization as provided by ARC with respect to CPU-steal times, proper of more modern paradigms such as cloud computing. version:1
arxiv-1707-09872 | Full-Network Embedding in a Multimodal Embedding Pipeline | http://arxiv.org/abs/1707.09872 | id:1707.09872 author:Armand Vilalta, Dario Garcia-Gasulla, Ferran Parés, Eduard Ayguadé, Jesus Labarta, Ulises Cortés, Toyotaro Suzumura category:cs.CV cs.CL cs.NE  published:2017-07-24 summary:The current state-of-the-art for image annotation and image retrieval tasks is obtained through deep neural networks, which combine an image representation and a text representation into a shared embedding space. In this paper we evaluate the impact of using the Full-Network embedding in this setting, replacing the original image representation in a competitive multimodal embedding generation scheme. Unlike the one-layer image embeddings typically used by most approaches, the Full-Network embedding provides a multi-scale representation of images, which results in richer characterizations. To measure the influence of the Full-Network embedding, we evaluate its performance on three different datasets, and compare the results with the original multimodal embedding generation scheme when using a one-layer image embedding, and with the rest of the state-of-the-art. Results for image annotation and image retrieval tasks indicate that the Full-Network embedding is consistently superior to the one-layer embedding. These results motivate the integration of the Full-Network embedding on any multimodal embedding generation scheme, something feasible thanks to the flexibility of the approach. version:1
arxiv-1602-08481 | Tight Bounds for Distributed Graph Computations | http://arxiv.org/abs/1602.08481 | id:1602.08481 author:Gopal Pandurangan, Peter Robinson, Michele Scquizzato category:cs.DC cs.DS  published:2016-02-26 summary:Motivated by the need to understand the algorithmic foundations of distributed large-scale graph computations, we study some fundamental graph problems in a message-passing model for distributed computing where $k \geq 2$ machines jointly perform computations on graphs with $n$ nodes (typically, $n \gg k$). We present (almost) tight bounds for the round complexity of two fundamental graph problems, namely triangle enumeration and PageRank computation. Our tight lower bounds, a main contribution of the paper, are established through an information-theoretic approach that relates the round complexity to the minimal amount of information required by machines for solving a problem. Our approach, as demonstrated in the case of triangle enumeration, can yield stronger round lower bounds as well as message-time tradeoffs compared to approaches that use communication complexity techniques. We then present algorithms that (almost) match the lower bounds; these algorithms exhibit a round complexity which scales superlinearly in $k$, improving significantly over previous results. Specifically, we show the following results: 1. Triangle enumeration: We show a lower bound of $\tilde{\Omega}(m/k^{5/3})$ rounds, where $m$ is the number of edges of the graph. ($\tilde \Omega$ hides a $1/\text{polylog}(n)$ factor; $\tilde O$ hides a $\text{polylog}(n)$ factor and an additive $\text{polylog}(n)$ term.) This result implies the first non-trivial lower bound of $\tilde\Omega(n^{1/3})$ rounds for the congested clique model. We also present a distributed algorithm that enumerates all the triangles of a graph in $\tilde{O}(m/k^{5/3})$ rounds. 2. PageRank: We show a lower bound of $\tilde{\Omega}(n/k^2)$ rounds and an $\tilde{O}(n/k^2)$ rounds algorithm. version:4
arxiv-1707-07452 | Next Generation Cloud Computing: New Trends and Research Directions | http://arxiv.org/abs/1707.07452 | id:1707.07452 author:Blesson Varghese, Rajkumar Buyya category:cs.DC  published:2017-07-24 summary:The landscape of cloud computing has significantly changed over the last decade. Not only have more providers and service offerings crowded the space, but also cloud infrastructure that was traditionally limited to single provider data centers is now evolving. In this paper, we firstly discuss the changing cloud infrastructure and consider the use of infrastructure from multiple providers and the benefit of decentralising computing away from data centers. These trends have resulted in the need for a variety of new computing architectures that will be offered by future cloud infrastructure. These architectures are anticipated to impact areas, such as connecting people and devices, data-intensive computing, the service space and self-learning systems. Finally, we lay out a roadmap of challenges that will need to be addressed for realising the potential of next generation cloud systems. version:1
arxiv-1707-09871 | Feature Extraction via Recurrent Random Deep Ensembles and its Application in Gruop-level Happiness Estimation | http://arxiv.org/abs/1707.09871 | id:1707.09871 author:Shitao Tang, Yichen Pan category:cs.CV cs.LG  published:2017-07-24 summary:This paper presents a novel ensemble framework to extract highly discriminative feature representation of image and its application for group-level happpiness intensity prediction in wild. In order to generate enough diversity of decisions, n convolutional neural networks are trained by bootstrapping the training set and extract n features for each image from them. A recurrent neural network (RNN) is then used to remember which network extracts better feature and generate the final feature representation for one individual image. Several group emotion models (GEM) are used to aggregate face fea- tures in a group and use parameter-optimized support vector regressor (SVR) to get the final results. Through extensive experiments, the great effectiveness of the proposed recurrent random deep ensembles (RRDE) is demonstrated in both structural and decisional ways. The best result yields a 0.55 root-mean-square error (RMSE) on validation set of HAPPEI dataset, significantly better than the baseline of 0.78. version:1
arxiv-1707-07426 | Tail-Tolerant Distributed Search | http://arxiv.org/abs/1707.07426 | id:1707.07426 author:Naama Kraus, David Carmel, Idit Keidar category:cs.IR cs.DC  published:2017-07-24 summary:Today's search engines process billions of online user queries a day over huge collections of data. In order to scale, they distribute query processing among many nodes, where each node holds and searches over a subset of the index called shard. Responses from some nodes occasionally fail to arrive within a reasonable time-interval due to various reasons, such as high server load and network congestion. Search engines typically need to respond in a timely manner, and therefore skip such tail latency responses, which causes degradation in search quality. In this paper, we tackle response misses due to high tail latencies with the goal of maximizing search quality. Search providers today use redundancy in the form of Replication for mitigating response misses, by constructing multiple copies of each shard and searching all replicas. This approach is not ideal, as it wastes resources on searching duplicate data. We propose two strategies to reduce this waste. First, we propose rSmartRed, an optimal shard selection scheme for replicated indexes. Second, when feasible, we propose to replace Replication with Repartition, which constructs independent index instances instead of exact copies. We analytically prove that rSmartRed's selection is optimal for Replication, and that Repartition achieves better search quality compared to Replication. We confirm our results with an empirical study using two real-world datasets, showing that rSmartRed improves recall compared to currently used approaches. We additionally show that Repartition improves over Replication in typical scenarios. version:1
arxiv-1707-07673 | Evaluation of Semantic Web Technologies for Storing Computable Definitions of Electronic Health Records Phenotyping Algorithms | http://arxiv.org/abs/1707.07673 | id:1707.07673 author:Vaclav Papez, Spiros Denaxas, Harry Hemingway category:cs.AI cs.SE  published:2017-07-24 summary:Electronic Health Records are electronic data generated during or as a byproduct of routine patient care. Structured, semi-structured and unstructured EHR offer researchers unprecedented phenotypic breadth and depth and have the potential to accelerate the development of precision medicine approaches at scale. A main EHR use-case is defining phenotyping algorithms that identify disease status, onset and severity. Phenotyping algorithms utilize diagnoses, prescriptions, laboratory tests, symptoms and other elements in order to identify patients with or without a specific trait. No common standardized, structured, computable format exists for storing phenotyping algorithms. The majority of algorithms are stored as human-readable descriptive text documents making their translation to code challenging due to their inherent complexity and hinders their sharing and re-use across the community. In this paper, we evaluate the two key Semantic Web Technologies, the Web Ontology Language and the Resource Description Framework, for enabling computable representations of EHR-driven phenotyping algorithms. version:1
arxiv-1707-09870 | Extremely Low Bit Neural Network: Squeeze the Last Bit Out with ADMM | http://arxiv.org/abs/1707.09870 | id:1707.09870 author:Cong Leng, Hao Li, Shenghuo Zhu, Rong Jin category:cs.CV  published:2017-07-24 summary:Although deep learning models are highly effective for various tasks, such as detection and classification, the high computational cost prohibits the deployment in scenarios where either memory or computational resources are limited. In this paper, we focus on model compression and acceleration of deep models. We model a low bit quantized neural network as a constrained optimization problem. Then, with the use of ADMM, we decouple the discrete constraint and parameters of network. We also show how the resulting subproblems can be efficiently solved with extragradient and iterative quantization. The effectiveness of the proposed method has been demonstrated in extensive experiments on convolutional neural network for image recognition, object detection, and recurrent neural network for language model. version:1
arxiv-1707-07385 | End-to-End Navigation in Unknown Environments using Neural Networks | http://arxiv.org/abs/1707.07385 | id:1707.07385 author:Arbaaz Khan, Clark Zhang, Nikolay Atanasov, Konstantinos Karydis, Daniel D. Lee, Vijay Kumar category:cs.RO  published:2017-07-24 summary:We investigate how a neural network can learn perception actions loops for navigation in unknown environments. Specifically, we consider how to learn to navigate in environments populated with cul-de-sacs that represent convex local minima that the robot could fall into instead of finding a set of feasible actions that take it to the goal. Traditional methods rely on maintaining a global map to solve the problem of over coming a long cul-de-sac. However, due to errors induced from local and global drift, it is highly challenging to maintain such a map for long periods of time. One way to mitigate this problem is by using learning techniques that do not rely on hand engineered map representations and instead output appropriate control policies directly from their sensory input. We first demonstrate that such a problem cannot be solved directly by deep reinforcement learning due to the sparse reward structure of the environment. Further, we demonstrate that deep supervised learning also cannot be used directly to solve this problem. We then investigate network models that offer a combination of reinforcement learning and supervised learning and highlight the significance of adding fully differentiable memory units to such networks. We evaluate our networks on their ability to generalize to new environments and show that adding memory to such networks offers huge jumps in performance version:1
arxiv-1707-07383 | Continuous-Time Gaussian Process Motion Planning via Probabilistic Inference | http://arxiv.org/abs/1707.07383 | id:1707.07383 author:Mustafa Mukadam, Jing Dong, Xinyan Yan, Frank Dellaert, Byron Boots category:cs.RO  published:2017-07-24 summary:We introduce a novel formulation of motion planning, for continuous-time trajectories, as probabilistic inference. We first show how smooth continuous-time trajectories can be represented by a small number of states using sparse Gaussian process (GP) models. We next develop an efficient gradient-based optimization algorithm that exploits this sparsity and Gaussian process interpolation. We call this algorithm the Gaussian Process Motion Planner (GPMP). We then detail how motion planning problems can be formulated as probabilistic inference on a factor graph. This forms the basis for GPMP2, a very efficient algorithm that combines GP representations of trajectories with fast, structure-exploiting inference via numerical optimization. Finally, we extend GPMP2 to an incremental algorithm, iGPMP2, that can efficiently replan when conditions change. We benchmark our algorithms against several sampling-based and trajectory optimization-based motion planning algorithms on planning problems in multiple environments. Our evaluation reveals that GPMP2 is several times faster than previous algorithms while retaining robustness. We also benchmark iGPMP2 on replanning problems, and show that it can find successful solutions in a fraction of the time required by GPMP2 to replan from scratch. version:1
arxiv-1706-05772 | Look No Further: Adapting the Localization Sensory Window to the Temporal Characteristics of the Environment | http://arxiv.org/abs/1706.05772 | id:1706.05772 author:Jake Bruce, Adam Jacobson, Michael Milford category:cs.RO 68T40  published:2017-06-19 summary:Many localization algorithms use a spatiotemporal window of sensory information in order to recognize spatial locations, and the length of this window is often a sensitive parameter that must be tuned to the specifics of the application. This letter presents a general method for environment-driven variation of the length of the spatiotemporal window based on searching for the most significant localization hypothesis, to use as much context as is appropriate but not more. We evaluate this approach on benchmark datasets using visual and Wi-Fi sensor modalities and a variety of sensory comparison front-ends under in-order and out-of-order traversals of the environment. Our results show that the system greatly reduces the maximum distance traveled without localization compared to a fixed-length approach while achieving competitive localization accuracy, and our proposed method achieves this performance without deployment-time tuning. version:2
arxiv-1703-01416 | Real-Time Trajectory Replanning for MAVs using Uniform B-splines and a 3D Circular Buffer | http://arxiv.org/abs/1703.01416 | id:1703.01416 author:Vladyslav Usenko, Lukas von Stumberg, Andrej Pangercic, Daniel Cremers category:cs.RO  published:2017-03-04 summary:In this paper, we present a real-time approach to local trajectory replanning for microaerial vehicles (MAVs). Current trajectory generation methods for multicopters achieve high success rates in cluttered environments, but assume that the environment is static and require prior knowledge of the map. In the presented study, we use the results of such planners and extend them with a local replanning algorithm that can handle unmodeled (possibly dynamic) obstacles while keeping the MAV close to the global trajectory. To ensure that the proposed approach is real-time capable, we maintain information about the environment around the MAV in an occupancy grid stored in a three-dimensional circular buffer, which moves together with a drone, and represent the trajectories by using uniform B-splines. This representation ensures that the trajectory is sufficiently smooth and simultaneously allows for efficient optimization. version:2
arxiv-1704-04852 | Downwash-Aware Trajectory Planning for Large Quadrotor Teams | http://arxiv.org/abs/1704.04852 | id:1704.04852 author:James A. Preiss, Wolfgang Hönig, Nora Ayanian, Gaurav S. Sukhatme category:cs.RO  published:2017-04-17 summary:We describe a method for formation-change trajectory planning for large quadrotor teams in obstacle-rich environments. Our method decomposes the planning problem into two stages: a discrete planner operating on a graph representation of the workspace, and a continuous refinement that converts the non-smooth graph plan into a set of C^k-continuous trajectories, locally optimizing an integral-squared-derivative cost. We account for the downwash effect, allowing safe flight in dense formations. We demonstrate the computational efficiency in simulation with up to 200 robots and the physical plausibility with an experiment with 32 nano-quadrotors. Our approach can compute safe and smooth trajectories for hundreds of quadrotors in dense environments with obstacles in a few minutes. version:2
arxiv-1707-07672 | Controlling a remotely located Robot using Hand Gestures in real time: A DSP implementation | http://arxiv.org/abs/1707.07672 | id:1707.07672 author:J L Raheja, G A Rajsekhar, Ankit Chaudhary category:cs.HC cs.RO  published:2017-07-23 summary:Telepresence is a necessity for present time as we can't reach everywhere and also it is useful in saving human life at dangerous places. A robot, which could be controlled from a distant location, can solve these problems. This could be via communication waves or networking methods. Also controlling should be in real time and smooth so that it can actuate on every minor signal in an effective way. This paper discusses a method to control a robot over the network from a distant location. The robot was controlled by hand gestures which were captured by the live camera. A DSP board TMS320DM642EVM was used to implement image pre-processing and fastening the whole system. PCA was used for gesture classification and robot actuation was done according to predefined procedures. Classification information was sent over the network in the experiment. This method is robust and could be used to control any kind of robot over distance. version:1
arxiv-1704-00082 | Moderately Complex Paxos Made Simple: High-Level Specification of Distributed Algorithm | http://arxiv.org/abs/1704.00082 | id:1704.00082 author:Yanhong A. Liu, Saksham Chand, Scott D. Stoller category:cs.DC  published:2017-03-31 summary:This paper presents simpler specifications of more complex variants of the Paxos algorithm for distributed consensus, as a case study of high-level specification of distributed algorithms. The development of the specifications uses a method and language for expressing complex control flows and synchronization conditions precisely at a high level. We show that English and pseudocode descriptions of algorithms can be captured precisely at a high level, yielding clearer and simpler specifications than ever before. The resulting specifications have allowed us to easily discover a main liveness violation that was unknown in a previous specification. We also show that the resulting specifications can be executed directly and optimized cleanly, yielding drastic performance improvement. Finally, we show that the resulting specifications can be formally verified using a proof system, with proofs an order of magnitude smaller than prior proofs, and allowing us to detect and fix a subtle safety violation that was unknown in an early specification. version:2
arxiv-1707-07263 | A GPU Based Memory Optimized Parallel Method For FFT Implementation | http://arxiv.org/abs/1707.07263 | id:1707.07263 author:Fan Zhang, Chen Hu, Qiang Yin, Wei Hu category:cs.DC  published:2017-07-23 summary:FFT (fast Fourier transform) plays a very important role in many fields, such as digital signal processing, digital image processing and so on. However, in application, FFT becomes a factor of affecting the processing efficiency, especially in remote sensing, which large amounts of data need to be processed with FFT. So shortening the FFT computation time is particularly important. GPU (Graphics Processing Unit) has been used in many common areas and its acceleration effect is very obvious compared with CPU (Central Processing Unit) platform. In this paper, we present a new parallel method to execute FFT on GPU. Based on GPU storage system and hardware processing pipeline, we improve the way of data storage. We divided the data into parts reasonably according the size of data to make full use of the characteristics of the GPU. We propose the memory optimized method based on share memory and texture memory to reduce the number of global memory access to achieve better efficiency. The results show that the GPU-based memory optimized FFT implementation not only can increase over 100% than FFTW library in CPU platform, but also can improve over 30% than CUFFT library in GPU platform. version:1
arxiv-1707-07239 | A New Approach to Time-Optimal Path Parameterization based on Reachability Analysis | http://arxiv.org/abs/1707.07239 | id:1707.07239 author:Hung Pham, Quang-Cuong Pham category:cs.RO  published:2017-07-23 summary:Time-Optimal Path Parameterization (TOPP) is a well-studied problem in robotics and has a wide range of applications. There are two main families of methods to address TOPP: Numerical Integration (NI) and Convex Optimization (CO). NI-based methods are fast but difficult to implement and suffer from robustness issues, while CO-based approaches are more robust but at the same time significantly slower. Here we propose a new approach to TOPP based on Reachability Analysis (RA). The key insight is to recursively compute reachable and controllable sets at discretized positions on the path by solving small Linear Programs (LPs). The resulting algorithm is faster than NI-based methods and as robust as CO-based ones (100% success rate), as confirmed by extensive numerical evaluations. Moreover, the proposed approach offers unique additional benefits: Admissible Velocity Propagation and robustness to parametric uncertainty can be derived from it in a simple and natural way. version:1
arxiv-1707-09869 | A comment on the paper Prediction of Kidney Function from Biopsy Images using Convolutional Neural Networks | http://arxiv.org/abs/1707.09869 | id:1707.09869 author:Washington LC dos-Santos, Angelo A Duarte, Luiz AR de Freitas category:cs.CV  published:2017-07-23 summary:This letter presente a comment on the paper Prediction of Kidney Function from Biopsy Images using Convolutional Neural Networks by Ledbetter et al. (2017) version:1
arxiv-1706-02086 | Preliminary Performance Estimations and Benchmark Results for a Software-based Fault-Tolerance Approach aboard Miniaturized Satellite Computers | http://arxiv.org/abs/1706.02086 | id:1706.02086 author:Christian M. Fuchs, Todor Stefanov, Nadia Murillo, Aske Plaat category:cs.DC  published:2017-06-07 summary:Modern embedded technology is a driving factor in satellite miniaturization, contributing to a massive boom in satellite launches and a rapidly evolving new space industry. Miniaturized satellites however suffer from low reliability, as traditional hardware-based fault-tolerance (FT) concepts are ineffective for on-board computers (OBCs) utilizing modern systems-on-a-chip (SoC). Larger satellites therefore continue to rely on proven processors with large feature sizes. Software-based concepts have largely been ignored by the space industry as they were researched only in theory, and have not yet reached the level of maturity necessary for implementation. In related work, we presented the first integral, real-world solution to enable fault-tolerant general-purpose computing with modern multiprocessor-SoCs (MPSoCs) for spaceflight, thereby enabling their use in future high-priority space missions. The presented multi-stage approach consists of three FT stages, combining coarse-grained thread-level distributed self-validation, FPGA reconfiguration, and mixed criticality to assure long-term FT and excellent scalability for both resource constrained and critical high-priority space missions. As part of the ongoing implementation effort towards a hardware prototype, several software implementations were achieved and tested. This document contains an outline of the conducted tests, performance evaluation results, and supplementary information not included in the actual paper. It is being continuously expanded and updated. version:2
arxiv-1707-07233 | Brain Computer Interface for Gesture Control of a Social Robot: an Offline Study | http://arxiv.org/abs/1707.07233 | id:1707.07233 author:Reza Abiri, Griffin Heise, Xiaopeng Zhao, Yang Jiang, Fateme Abiri category:cs.RO cs.HC  published:2017-07-23 summary:Brain computer interface (BCI) provides promising applications in neuroprosthesis and neurorehabilitation by controlling computers and robotic devices based on the patient's intentions. Here, we have developed a novel BCI platform that controls a personalized social robot using noninvasively acquired brain signals. Scalp electroencephalogram (EEG) signals are collected from a user in real-time during tasks of imaginary movements. The imagined body kinematics are decoded using a regression model to calculate the user-intended velocity. Then, the decoded kinematic information is mapped to control the gestures of a social robot. The platform here may be utilized as a human-robot-interaction framework by combining with neurofeedback mechanisms to enhance the cognitive capability of persons with dementia. version:1
arxiv-1703-02130 | Demand Estimation and Chance-Constrained Fleet Management for Ride Hailing | http://arxiv.org/abs/1703.02130 | id:1703.02130 author:Justin Miller, Jonathan P. How category:cs.RO  published:2017-03-06 summary:In autonomous Mobility on Demand (MOD) systems, customers request rides from a fleet of shared vehicles that can be automatically positioned in response to customer demand. Recent approaches to MOD systems have focused on environments where customers can only request rides through an app or by waiting at a station. This paper develops MOD fleet management approaches for ride hailing, where customers may instead request rides simply by hailing a passing vehicle, an approach of particular importance for campus MOD systems. The challenge for ride hailing is that customer demand is not explicitly provided as it would be with an app, but rather customers are only served if a vehicle happens to be located at the arrival location. This work focuses on maximizing the number of served hailing customers in an MOD system by learning and utilizing customer demand. A Bayesian framework is used to define a novel customer demand model which incorporates observed pedestrian traffic to estimate customer arrival locations with a quantification of uncertainty. An exploration planner is proposed which routes MOD vehicles in order to reduce arrival rate uncertainty. A robust ride hailing fleet management planner is proposed which routes vehicles under the presence of uncertainty using a chance-constrained formulation. Simulation of a real-world MOD system on MIT's campus demonstrates the effectiveness of the planners. The customer demand model and exploration planner are demonstrated to reduce estimation error over time and the ride hailing planner is shown to improve the fraction of served customers in the system by 73\% over a baseline exploration approach. version:3
arxiv-1707-07217 | Deep Learning in Robotics: A Review of Recent Research | http://arxiv.org/abs/1707.07217 | id:1707.07217 author:Harry A. Pierson, Michael S. Gashler category:cs.RO  published:2017-07-22 summary:Advances in deep learning over the last decade have led to a flurry of research in the application of deep artificial neural networks to robotic systems, with at least thirty papers published on the subject between 2014 and the present. This review discusses the applications, benefits, and limitations of deep learning vis-\`a-vis physical robotic systems, using contemporary research as exemplars. It is intended to communicate recent advances to the wider robotics community and inspire additional interest in and application of deep learning in robotics. version:1
arxiv-1705-02550 | Toward Low-Flying Autonomous MAV Trail Navigation using Deep Neural Networks for Environmental Awareness | http://arxiv.org/abs/1705.02550 | id:1705.02550 author:Nikolai Smolyanskiy, Alexey Kamenev, Jeffrey Smith, Stan Birchfield category:cs.RO  published:2017-05-07 summary:We present a micro aerial vehicle (MAV) system, built with inexpensive off-the-shelf hardware, for autonomously following trails in unstructured, outdoor environments such as forests. The system introduces a deep neural network (DNN) called TrailNet for estimating the view orientation and lateral offset of the MAV with respect to the trail center. The DNN-based controller achieves stable flight without oscillations by avoiding overconfident behavior through a loss function that includes both label smoothing and entropy reward. In addition to the TrailNet DNN, the system also utilizes vision modules for environmental awareness, including another DNN for object detection and a visual odometry component for estimating depth for the purpose of low-level obstacle detection. All vision systems run in real time on board the MAV via a Jetson TX1. We provide details on the hardware and software used, as well as implementation details. We present experiments showing the ability of our system to navigate forest trails more robustly than previous techniques, including autonomous flights of 1 km. version:3
arxiv-1707-04294 | Ergodic Coverage In Constrained Environments Using Stochastic Trajectory Optimization | http://arxiv.org/abs/1707.04294 | id:1707.04294 author:Elif Ayvali, Hadi Salman, Howie Choset category:cs.RO  published:2017-07-13 summary:In search and surveillance applications in robotics, it is intuitive to spatially distribute robot trajectories with respect to the probability of locating targets in the domain. Ergodic coverage is one such approach to trajectory planning in which a robot is directed such that the percentage of time spent in a region is in proportion to the probability of locating targets in that region. In this work, we extend the ergodic coverage algorithm to robots operating in constrained environments and present a formulation that can capture sensor footprint and avoid obstacles and restricted areas in the domain. We demonstrate that our formulation easily extends to coordination of multiple robots equipped with different sensing capabilities to perform ergodic coverage of a domain. version:2
arxiv-1706-10102 | Tableaux for Policy Synthesis for MDPs with PCTL* Constraints | http://arxiv.org/abs/1706.10102 | id:1706.10102 author:Peter Baumgartner, Sylvie Thiébaux, Felipe Trevizan category:cs.LO cs.AI  published:2017-06-30 summary:Markov decision processes (MDPs) are the standard formalism for modelling sequential decision making in stochastic environments. Policy synthesis addresses the problem of how to control or limit the decisions an agent makes so that a given specification is met. In this paper we consider PCTL*, the probabilistic counterpart of CTL*, as the specification language. Because in general the policy synthesis problem for PCTL* is undecidable, we restrict to policies whose execution history memory is finitely bounded a priori. Surprisingly, no algorithm for policy synthesis for this natural and expressive framework has been developed so far. We close this gap and describe a tableau-based algorithm that, given an MDP and a PCTL* specification, derives in a non-deterministic way a system of (possibly nonlinear) equalities and inequalities. The solutions of this system, if any, describe the desired (stochastic) policies. Our main result in this paper is the correctness of our method, i.e., soundness, completeness and termination. version:2
arxiv-1707-07137 | AutOMP: An Automatic OpenMP Parallelization Generator for Variable-Oriented High-Performance Scientific Codes | http://arxiv.org/abs/1707.07137 | id:1707.07137 author:Gal Oren, Yehuda Ganan, Guy Malamud category:cs.DC  published:2017-07-22 summary:OpenMP is a cross-platform API that extends C, C++ and Fortran and provides shared-memory parallelism platform for those languages. The use of many cores and HPC technologies for scientific computing has been spread since the 1990s, and now takes part in many fields of research. The relative ease of implementing OpenMP, along with the development of multi-core shared memory processors (such as Intel Xeon Phi) makes OpenMP a favorable method for parallelization in the process of modernizing a legacy codes. Legacy scientific codes are usually holding large number of physical arrays which being used and updated by the code routines. In most of the cases the parallelization of such code focuses on loop parallelization. A key step in this parallelization is deciding which of the variables in the parallelized scope should be private (so each thread will hold a copy of them), and which variables should be shared across the threads. Other important step is finding which variables should be synchronized after the loop execution. In this work we present an automatic pre-processor that preforms these stages - AutOMP (Automatic OpenMP). AutOMP recognize all the variables assignments inside a loop. These variables will be private unless the assignment is of an array element which depend on the loop index variable. Afterwards, AutOMP finds the places where threads synchronization is needed, and which reduction operator is to be used. At last, the program provides the parallelization command to be used for parallelizing the loop. version:1
arxiv-1707-07083 | Computing the $k$-resilience of a Synchronized Multi-Robot System | http://arxiv.org/abs/1707.07083 | id:1707.07083 author:Sergey Bereg, Luis-Evaristo Caraballo, José-Miguel Díaz-Báñez, Mario A. Lopez category:cs.RO  published:2017-07-22 summary:We study an optimization problem that arises in the design of covering strategies for multi-robot systems. Consider a team of $n$ cooperating robots traveling along predetermined closed and disjoint trajectories. Each robot needs to periodically communicate information to nearby robots. At places where two trajectories are within range of each other, a communication link is established, allowing two robots to exchange information, provided they are "synchronized", i.e., they visit the link at the same time. In this setting a communication graph is defined and a system of robots is called \emph{synchronized} if every pair of neighbors is synchronized. If one or more robots leave the system, then some trajectories are left unattended. To handle such cases in a synchronized system, when a live robot arrives to a communication link and detects the absence of the neighbor, it shifts to the neighboring trajectory to assume the unattended task. If enough robots leave, it may occur that a live robot enters a state of \emph{starvation}, failing to permanently meet other robots during flight. To measure the tolerance of the system under this phenomenon we define the \emph{$k$-resilience} as the minimum number of robots whose removal may cause $k$ surviving robots to enter a state of starvation. We show that the problem of computing the $k$-resilience is NP-hard if $k$ is part of the input, even if the communication graph is a tree. We propose algorithms to compute the $k$-resilience for constant values of $k$ in general communication graphs and show more efficient algorithms for systems whose communication graph is a tree. version:1
arxiv-1707-07082 | Gyroscope Calibration via Magnetometer | http://arxiv.org/abs/1707.07082 | id:1707.07082 author:Yuanxin Wu, Ling Pei category:cs.RO  published:2017-07-22 summary:Magnetometers, gyroscopes and accelerometers are commonly used sensors in a variety of applications. The paper proposes a novel gyroscope calibration method in the homogeneous magnetic field by the help of magnetometer. It is shown that, with sufficient rotation excitation, the homogeneous magnetic field vector can be exploited to serve as a good reference for calibrating low-cost gyroscopes. The calibration parameters include the gyroscope scale factor, non-orthogonal coefficient and bias for three axes, as well as its misalignment to the magnetometer frame. Simulation and field test results demonstrate the method's effectiveness. version:1
arxiv-1609-00098 | SpECTRE: A Task-based Discontinuous Galerkin Code for Relativistic Astrophysics | http://arxiv.org/abs/1609.00098 | id:1609.00098 author:Lawrence E. Kidder, Scott E. Field, Francois Foucart, Erik Schnetter, Saul A. Teukolsky, Andy Bohn, Nils Deppe, Peter Diener, François Hébert, Jonas Lippuner, Jonah Miller, Christian D. Ott, Mark A. Scheel, Trevor Vincent category:astro-ph.HE cs.DC gr-qc physics.comp-ph  published:2016-09-01 summary:We introduce a new relativistic astrophysics code, SpECTRE, that combines a discontinuous Galerkin method with a task-based parallelism model. SpECTRE's goal is to achieve more accurate solutions for challenging relativistic astrophysics problems such as core-collapse supernovae and binary neutron star mergers. The robustness of the discontinuous Galerkin method allows for the use of high-resolution shock capturing methods in regions where (relativistic) shocks are found, while exploiting high-order accuracy in smooth regions. A task-based parallelism model allows efficient use of the largest supercomputers for problems with a heterogeneous workload over disparate spatial and temporal scales. We argue that the locality and algorithmic structure of discontinuous Galerkin methods will exhibit good scalability within a task-based parallelism framework. We demonstrate the code on a wide variety of challenging benchmark problems in (non)-relativistic (magneto)-hydrodynamics. We demonstrate the code's scalability including its strong scaling on the NCSA Blue Waters supercomputer up to the machine's full capacity of 22,380 nodes using 671,400 threads. version:2
arxiv-1707-06959 | A Framework for Easing the Development of Applications Embedding Answer Set Programming | http://arxiv.org/abs/1707.06959 | id:1707.06959 author:Francesco Calimeri, Davide Fuscà, Stefano Germano, Simona Perri, Jessica Zangari category:cs.AI  published:2017-07-21 summary:Answer Set Programming (ASP) is a well-established declarative problem solving paradigm which became widely used in AI and recognized as a powerful tool for knowledge representation and reasoning (KRR), especially for its high expressiveness and the ability to deal also with incomplete knowledge. Recently, thanks to the availability of a number of robust and efficient implementations, ASP has been increasingly employed in a number of different domains, and used for the development of industrial-level and enterprise applications. This made clear the need for proper development tools and interoperability mechanisms for easing interaction and integration with external systems in the widest range of real-world scenarios, including mobile applications and educational contexts. In this work we present a framework for integrating the KRR capabilities of ASP into generic applications. We show the use of the framework by illustrating proper specializations for some relevant ASP systems over different platforms, including the mobile setting; furthermore, the potential of the framework for educational purposes is illustrated by means of the development of several ASP-based applications. version:1
arxiv-1707-06913 | Mathematical Estimation of Logical Masking Capability of Majority/Minority Gates Used in Nanoelectronic Circuits | http://arxiv.org/abs/1707.06913 | id:1707.06913 author:P Balasubramanian, R T Naayagi category:cs.AR  published:2017-07-21 summary:In nanoelectronic circuit synthesis, the majority gate and the inverter form the basic combinational logic primitives. This paper deduces the mathematical formulae to estimate the logical masking capability of majority gates, which are used extensively in nanoelectronic digital circuit synthesis. The mathematical formulae derived to evaluate the logical masking capability of majority gates holds well for minority gates, and a comparison with the logical masking capability of conventional gates such as NOT, AND/NAND, OR/NOR, and XOR/XNOR is provided. It is inferred from this research work that the logical masking capability of majority/minority gates is similar to that of XOR/XNOR gates, and with an increase of fan-in the logical masking capability of majority/minority gates also increases. version:1
arxiv-1707-06909 | Redundant Logic Insertion and Fault Tolerance Improvement in Combinational Circuits | http://arxiv.org/abs/1707.06909 | id:1707.06909 author:P Balasubramanian, R T Naayagi category:cs.AR  published:2017-07-21 summary:This paper presents a novel method to identify and insert redundant logic into a combinational circuit to improve its fault tolerance without having to replicate the entire circuit as is the case with conventional redundancy techniques. In this context, it is discussed how to estimate the fault masking capability of a combinational circuit using the truth-cum-fault enumeration table, and then it is shown how to identify the logic that can introduced to add redundancy into the original circuit without affecting its native functionality and with the aim of improving its fault tolerance though this would involve some trade-off in the design metrics. However, care should be taken while introducing redundant logic since redundant logic insertion may give rise to new internal nodes and faults on those may impact the fault tolerance of the resulting circuit. The combinational circuit that is considered and its redundant counterparts are all implemented in semi-custom design style using a 32/28nm CMOS digital cell library and their respective design metrics and fault tolerances are compared. version:1
arxiv-1707-06895 | Towards learning domain-independent planning heuristics | http://arxiv.org/abs/1707.06895 | id:1707.06895 author:Pawel Gomoluch, Dalal Alrajeh, Alessandra Russo, Antonio Bucchiarone category:cs.AI  published:2017-07-21 summary:Automated planning remains one of the most general paradigms in Artificial Intelligence, providing means of solving problems coming from a wide variety of domains. One of the key factors restricting the applicability of planning is its computational complexity resulting from exponentially large search spaces. Heuristic approaches are necessary to solve all but the simplest problems. In this work, we explore the possibility of obtaining domain-independent heuristic functions using machine learning. This is a part of a wider research program whose objective is to improve practical applicability of planning in systems for which the planning domains evolve at run time. The challenge is therefore the learning of (corrections of) domain-independent heuristics that can be reused across different planning domains. version:1
arxiv-1705-04448 | R2-D2: ColoR-inspired Convolutional NeuRal Network (CNN)-based AndroiD Malware Detections | http://arxiv.org/abs/1705.04448 | id:1705.04448 author:TonTon Hsien-De Huang, Chia-Mu Yu, Hung-Yu Kao category:cs.CR cs.AI  published:2017-05-12 summary:Machine Learning (ML) has found it particularly useful in malware detection. However, as the malware evolves very fast, the stability of the feature extracted from malware serves as a critical issue in malware detection. The recent success of deep learning in image recognition, natural language processing, and machine translation indicates a potential solution for stabilizing the malware detection effectiveness. We present a color-inspired convolutional neural network-based Android malware detection, R2-D2, which can detect malware without extracting pre-selected features (e.g., the control-flow of op-code, classes, methods of functions and the timing they are invoked etc.) from Android apps. In particular, we develop a color representation for translating Android apps into rgb color code and transform them to a fixed-sized encoded image. After that, the encoded image is fed to convolutional neural network for automatic feature extraction and learning, reducing the expert's intervention.We have run our system over 1 million malware samples and 1 million benign samples through our back-end (600 million monthly active users and 10k new malware samples per day), showing that R2-D2 can effectively detect the malware. Furthermore, we will keep our research results on http://R2D2.TWMAN.ORG if there any update. version:2
arxiv-1707-06813 | On the Computation of Paracoherent Answer Sets | http://arxiv.org/abs/1707.06813 | id:1707.06813 author:Giovanni Amendola, Carmine Dodaro, Wolfgang Faber, Nicola Leone, Francesco Ricca category:cs.LO cs.AI  published:2017-07-21 summary:Answer Set Programming (ASP) is a well-established formalism for nonmonotonic reasoning. An ASP program can have no answer set due to cyclic default negation. In this case, it is not possible to draw any conclusion, even if this is not intended. Recently, several paracoherent semantics have been proposed that address this issue, and several potential applications for these semantics have been identified. However, paracoherent semantics have essentially been inapplicable in practice, due to the lack of efficient algorithms and implementations. In this paper, this lack is addressed, and several different algorithms to compute semi-stable and semi-equilibrium models are proposed and implemented into an answer set solving framework. An empirical performance comparison among the new algorithms on benchmarks from ASP competitions is given as well. version:1
arxiv-1707-06791 | Learning Competing Constraints and Task Priorities from Demonstrations of Bimanual Skills | http://arxiv.org/abs/1707.06791 | id:1707.06791 author:João Silvério, Sylvain Calinon, Leonel Rozo, Darwin G. Caldwell category:cs.RO  published:2017-07-21 summary:As bimanual robots become increasingly popular, learning and control algorithms must take into account new constraints and challenges imposed by this morphology. Most research on learning bimanual skills has focused on learning coordination between end-effectors, exploiting operational space formulations. However, motion patterns in bimanual scenarios are not exclusive to operational space, also occurring at the joint level. Moreover, bimanual operation offers the possibility to carry out more than one manipulation task at the same time, which in turn introduces the problem of task prioritization in bimanual settings. Here we address the aforementioned problems from a robot learning perspective. We go beyond operational space and present a principled approach to simultaneously learn operational and configuration space constraints, as well as the evolution of task priorities from demonstrations. Our method extends the Task-Parameterized Gaussian Mixture Model (TP-GMM) to the use of projection operators which allow for tackling such problems. The approach is validated in two different bimanual tasks with the COMAN and WALK-MAN humanoids that either require the consideration of constraints in both operational and configuration spaces, or the prioritization of tasks. version:1
arxiv-1707-06776 | Rendezvous on a Line by Location-Aware Robots Despite the Presence of Byzantine Faults | http://arxiv.org/abs/1707.06776 | id:1707.06776 author:Huda Chuangpishit, Jurek Czyzowicz, Evangelos Kranakis, Danny Krizanc category:cs.DC  published:2017-07-21 summary:A set of mobile robots is placed at points of an infinite line. The robots are equipped with GPS devices and they may communicate their positions on the line to a central authority. The collection contains an unknown subset of "spies", i.e., byzantine robots, which are indistinguishable from the non-faulty ones. The set of the non-faulty robots need to rendezvous in the shortest possible time in order to perform some task, while the byzantine robots may try to delay their rendezvous for as long as possible. The problem facing a central authority is to determine trajectories for all robots so as to minimize the time until the non-faulty robots have rendezvoused. The trajectories must be determined without knowledge of which robots are faulty. Our goal is to minimize the competitive ratio between the time required to achieve the first rendezvous of the non-faulty robots and the time required for such a rendezvous to occur under the assumption that the faulty robots are known at the start. We provide a bounded competitive ratio algorithm, where the central authority is informed only of the set of initial robot positions, without knowing which ones or how many of them are faulty. When an upper bound on the number of byzantine robots is known to the central authority, we provide algorithms with better competitive ratios. In some instances we are able to show these algorithms are optimal. version:1
arxiv-1707-06766 | Outcome-Oriented Predictive Process Monitoring: Review and Benchmark | http://arxiv.org/abs/1707.06766 | id:1707.06766 author:Irene Teinemaa, Marlon Dumas, Marcello La Rosa, Fabrizio Maria Maggi category:cs.AI  published:2017-07-21 summary:Predictive business process monitoring refers to the act of making predictions about the future state of ongoing cases of a business process, based on their incomplete execution traces and logs of historical (completed) traces. Motivated by the increasingly pervasive availability of fine-grained event data about business process executions, the problem of predictive process monitoring has received substantial attention in the past years. In particular, a considerable number of methods have been put forward to address the problem of outcome-oriented predictive process monitoring, which refers to classifying each ongoing case of a process according to a given set of possible outcomes - e.g. Will the customer complain or not? Will an order be delivered, cancelled or withdrawn? Unfortunately, different authors have used different datasets, experimental settings, evaluation measures and baselines to assess their proposals, resulting in poor comparability and an unclear picture of the relative merits and applicability of different methods. To address this gap, this article presents a systematic review and taxonomy of outcome-oriented predictive process monitoring methods, and a comparative experimental evaluation of eleven representative methods using a benchmark covering twelve predictive process monitoring tasks based on four real-life event logs. version:1
arxiv-1707-09958 | ($k,q$)-Compressed Sensing for dMRI with Joint Spatial-Angular Sparsity Prior | http://arxiv.org/abs/1707.09958 | id:1707.09958 author:Evan Schwab, René Vidal, Nicolas Charon category:cs.CV  published:2017-07-21 summary:Advanced diffusion magnetic resonance imaging (dMRI) techniques, like diffusion spectrum imaging (DSI) and high angular resolution diffusion imaging (HARDI), remain underutilized compared to diffusion tensor imaging because the scan times needed to produce accurate estimations of fiber orientation are significantly longer. To accelerate DSI and HARDI, recent methods from compressed sensing (CS) exploit a sparse underlying representation of the data in the spatial and angular domains to undersample in the respective $k$- and $q$-spaces. State-of-the-art frameworks, however, impose sparsity in the spatial and angular domains separately and involve the sum of the corresponding sparse regularizers. In contrast, we propose a unified ($k,q$)-CS formulation which imposes sparsity jointly in the spatial-angular domain to further increase sparsity of dMRI signals and reduce the required subsampling rate. To efficiently solve this large-scale global reconstruction problem, we introduce a novel adaptation of the FISTA algorithm that exploits dictionary separability. We show on phantom and real HARDI data that our approach achieves significantly more accurate signal reconstructions than the state of the art while sampling only $2$-$4\%$ of the ($k,q$)-space, allowing for the potential of new levels of dMRI acceleration. version:1
arxiv-1609-09827 | Sprout: A functional caching approach to minimize service latency in erasure-coded storage | http://arxiv.org/abs/1609.09827 | id:1609.09827 author:Vaneet Aggarwal, Yih-Farn R. Chen, Tian Lan, Yu Xiang category:cs.DC cs.IT math.IT  published:2016-09-30 summary:Modern distributed storage systems often use erasure codes to protect against disk and node failures to increase reliability, while trying to meet the latency requirements of the applications and clients. Storage systems may have caches at the proxy or client ends in order to reduce the latency. In this paper, we consider a novel caching framework with erasure code called functional caching. Functional Caching involves using erasure-coded chunks in the cache such that the code formed by the chunks in storage nodes and cache combined are maximal-distance-separable (MDS) erasure codes. Based on the arrival rates of different files, placement of file chunks on the servers, and service time distribution of storage servers, an optimal functional caching placement and the access probabilities of the file request from different disks are considered. The proposed algorithm gives significant latency improvement in both simulations and a prototyped solution in an open-source, cloud storage deployment. version:3
arxiv-1707-06140 | NuCypher KMS: Decentralized key management system | http://arxiv.org/abs/1707.06140 | id:1707.06140 author:Michael Egorov, MacLane Wilkison category:cs.CR cs.DC  published:2017-07-19 summary:NuCypher KMS is a decentralized Key Management System (KMS) that addresses the limitations of using consensus networks to securely store and manipulate private, encrypted data. It provides encryption and cryptographic access controls, performed by a decentralized network, leveraging proxy re-encryption. Unlike centralized KMS as a service solutions, it doesn't require trusting a service provider. NuCypher KMS enables sharing of sensitive data for both decentralized and centralized applications, providing security infrastructure for applications from healthcare to identity management to decentralized content marketplaces. version:2
arxiv-1707-06665 | Social Hash Partitioner: A Scalable Distributed Hypergraph Partitioner | http://arxiv.org/abs/1707.06665 | id:1707.06665 author:Igor Kabiljo, Brian Karrer, Mayank Pundir, Sergey Pupyrev, Alon Shalita, Alessandro Presta, Yaroslav Akhremtsev category:cs.DS cs.DC  published:2017-07-20 summary:We design and implement a distributed algorithm for balanced $k$-way hypergraph partitioning that minimizes fanout, a fundamental hypergraph quantity also known as the communication volume and ($k-1$)-cut metric, by optimizing a novel objective called probabilistic fanout. This choice allows a simple local search heuristic to achieve comparable solution quality to the best existing hypergraph partitioners. Our algorithm is arbitrarily scalable due to a careful design that controls computational complexity, space complexity, and communication. In practice, we commonly process hypergraphs with billions of vertices and hyperedges in a few hours. We explain how the algorithm's scalability, both in terms of hypergraph size and bucket count, is limited only by the number of machines available. We perform an extensive comparison to existing distributed hypergraph partitioners and find that our approach is able to optimize hypergraphs roughly $100$ times bigger on the same set of machines. We call the resulting tool Social Hash Partitioner (SHP), and accompanying this paper, we open-source the most scalable version based on recursive bisection. version:1
arxiv-1707-06617 | Functional Co-Optimization of Articulated Robots | http://arxiv.org/abs/1707.06617 | id:1707.06617 author:Andrew Spielberg, Brandon Araki, Cynthia Sung, Russ Tedrake, Daniela Rus category:cs.RO  published:2017-07-20 summary:We present parametric trajectory optimization, a method for simultaneously computing physical parameters, actuation requirements, and robot motions for more efficient robot designs. In this scheme, robot dimensions, masses, and other physical parameters are solved for concurrently with traditional motion planning variables, including dynamically consistent robot states, actuation inputs, and contact forces. Our method requires minimal user domain knowledge, requiring only a coarse guess of the target robot configuration sequence and a parameterized robot topology as input. We demonstrate our results on four simulated robots, one of which we physically fabricated in order to demonstrate physical consistency. We demonstrate that by optimizing robot body parameters alongside robot trajectories, motion planning problems which would otherwise be infeasible can be made feasible, and actuation requirements can be significantly reduced. version:1
arxiv-1707-06607 | Applying MAPP Algorithm for Cooperative Path Finding in Urban Environments | http://arxiv.org/abs/1707.06607 | id:1707.06607 author:Anton Andreychuk, Konstantin Yakovlev category:cs.AI cs.MA  published:2017-07-20 summary:The paper considers the problem of planning a set of non-conflict trajectories for the coalition of intelligent agents (mobile robots). Two divergent approaches, e.g. centralized and decentralized, are surveyed and analyzed. Decentralized planner - MAPP is described and applied to the task of finding trajectories for dozens UAVs performing nap-of-the-earth flight in urban environments. Results of the experimental studies provide an opportunity to claim that MAPP is a highly efficient planner for solving considered types of tasks. version:1
arxiv-1703-00461 | Reactive Trajectory Generation in an Unknown Environment | http://arxiv.org/abs/1703.00461 | id:1703.00461 author:Kenan Cole, Adam Wickenheiser category:math.OC cs.RO  published:2017-03-01 summary:Autonomous trajectory generation for unmanned aerial vehicles (UAVs) in unknown environments continues to be an important research area as UAVs become more prolific. We define a trajectory generation algorithm for a vehicle in an unknown environment with wind disturbances, that relies only on the vehicle's on-board distance sensors and communication with other vehicles within a finite region to generate a smooth, collision-free trajectory up to the fourth derivative. The proposed trajectory generation algorithm can be used in conjunction with high-level planners and low-level motion controllers. The algorithm provides guarantees that the trajectory does not violate the vehicle's thrust limitation, sensor constraints, or a user-defined clearance radius around other vehicles and obstacles. Simulation results of a quadrotor moving through an unknown environment with a moving obstacle demonstrates the trajectory generation performance. version:2
arxiv-1707-06564 | A Customisable Underwater Robot | http://arxiv.org/abs/1707.06564 | id:1707.06564 author:Guido Schillaci, Fabio Schillaci, Verena V. Hafner category:cs.RO  published:2017-07-20 summary:We present a model of a configurable underwater drone, whose parts are optimised for 3D printing processes. We show how - through the use of printable adapters - several thrusters and ballast configurations can be implemented, allowing different maneuvering possibilities. After introducing the model and illustrating a set of possible configurations, we present a functional prototype based on open source hardware and software solutions. The prototype has been successfully tested in several dives in rivers and lakes around Berlin. The reliability of the printed models has been tested only in relatively shallow waters. However, we strongly believe that their availability as freely downloadable models will motivate the general public to build and to test underwater drones, thus speeding up the development of innovative solutions and applications. The models and their documentation will be available for download at the following link: https://adapt.informatik.hu-berlin.de/schillaci/underwater.html. version:1
arxiv-1707-06560 | An ASM-based Characterization of Starvation-free Systems | http://arxiv.org/abs/1707.06560 | id:1707.06560 author:Alessandro Bianchi, Sebastiano Pizzutilo, Gennaro Vessio category:cs.DC  published:2017-07-20 summary:Abstract State Machines (ASMs) have been successfully applied for modeling critical and complex systems in a wide range of application domains. However, unlike other well-known formalisms, e.g. Petri nets, ASMs lack inherent, domain-independent characterisations of computationally important properties. Here, we provide an ASM-based characterisation of the starvation-free property. The classic, informal notion of starvation, usually provided in literature, is analysed and expressed as a necessary condition in terms of ASMs. Thus, we enrich the ASM framework with the notion of vulnerable rule as a practical tool for analysing starvation issues in an operational fashion version:1
arxiv-1612-09145 | Ergodic Effects in Token Circulation | http://arxiv.org/abs/1612.09145 | id:1612.09145 author:Adrian Kosowski, Przemysław Uznański category:cs.DS cs.DC  published:2016-12-29 summary:We consider a dynamical process in a network which distributes all tokens located at a node among its neighbors, in a round-robin manner. We show that in the recurrent state of this dynamics (i.e., disregarding a polynomially long initialization phase of the system), the number of particles located on a given edge, averaged over an interval of time, is tightly concentrated around the average particle density in the system. Formally, for a system of $k$ particles in a graph of $m$ edges, during any interval of length $T$, this time-averaged value is $k/m \pm \widetilde{O}(1/T)$, whenever $\gcd(m,k) = \widetilde{O}(1)$ (and so, e.g., whenever $m$ is a prime number). To achieve these bounds, we link the behavior of the studied dynamics to ergodic properties of traversals based on Eulerian circuits on a symmetric directed graph. These results are proved through sum set methods and are likely to be of independent interest. As a corollary, we also obtain bounds on the idleness of the studied dynamics, i.e., on the longest possible time between two consecutive appearances of a token on an edge, taken over all edges. Designing trajectories for $k$ tokens in a way which minimizes idleness is fundamental to the study of the patrolling problem in networks. Our results immediately imply a bound of $\widetilde{O}(m/k)$ on the idleness of the studied process, showing that it is a distributed $\widetilde{O}(1)$-competitive solution to the patrolling task, for all of the covered cases. Our work also provides some further insights may be interesting in load-balancing applications. version:2
arxiv-1707-06470 | A Comparison of Support Vector Machines Training GPU-Accelerated Open Source Implementations | http://arxiv.org/abs/1707.06470 | id:1707.06470 author:Jan Vanek, Josef Michalek, Josef Psutka category:cs.DC 68W10 D.1.3; I.5.5  published:2017-07-20 summary:Last several years, GPUs are used to accelerate computations in many computer science domains. We focused on GPU accelerated Support Vector Machines (SVM) training with non-linear kernel functions. We had searched for all available GPU accelerated C++ open-source implementations and created an open-source C++ benchmark project. We modifed all the implementations to run on actual hardware and software and in both Windows and Linux operating systems. The benchmark project offers making a fair and direct comparison of the individual implementations under the same conditions, datasets, and hardware. In addition, we selected the most popular datasets in the community and tested them. Finally, based on the evaluation, we recommended the best-performing implementations for dense and sparse datasets. version:1
arxiv-1707-06446 | Sequential Lifted Bayesian Filtering in Multiset Rewriting Systems | http://arxiv.org/abs/1707.06446 | id:1707.06446 author:Max Schröder, Stefan Lüdtke, Sebastian Bader, Frank Krüger, Thomas Kirste category:cs.AI  published:2017-07-20 summary:Bayesian Filtering for plan and activity recognition is challenging for scenarios that contain many observation equivalent entities (i.e. entities that produce the same observations). This is due to the combinatorial explosion in the number of hypotheses that need to be tracked. However, this class of problems exhibits a certain symmetry that can be exploited for state space representation and inference. We analyze current state of the art methods and find that none of them completely fits the requirements arising in this problem class. We sketch a novel inference algorithm that provides a solution by incorporating concepts from Lifted Inference algorithms, Probabilistic Multiset Rewriting Systems, and Computational State Space Models. Two experiments confirm that this novel algorithm has the potential to perform efficient probabilistic inference on this problem class. version:1
arxiv-1707-06420 | DICE Fault Injection Tool | http://arxiv.org/abs/1707.06420 | id:1707.06420 author:Craig Sheridan, Darren Whigham, Matej Artač category:cs.DC B.8.1  published:2017-07-20 summary:In this paper, we describe the motivation, innovation, design, running example and future development of a Fault Inject Tool (FIT). This tool enables controlled causing of cloud platform issues such as resource stress and service or VM outages, the purpose being to observe the subsequent effect on deployed applications. It is being designed for use in a DevOps workflow for tighter correlation between application design and cloud operation, although not limited to this usage, and helps improve resiliency for data intensive applications by bringing together fault tolerance, stress testing and benchmarking in a single tool. version:1
arxiv-1707-06403 | Improved Cloud resource allocation: how INDIGO-DataCloud is overcoming the current limitations in Cloud schedulers | http://arxiv.org/abs/1707.06403 | id:1707.06403 author:Alvaro Lopez Garcia, Lisa Zangrando, Massimo Sgaravatto, Vincent Llorens, Sara Vallero, Valentina Zaccolo, Stefano Bagnasco, Sonia Taneja, Stefano Dal Pra, Davide Salomoni, Giacinto Donvito category:cs.DC  published:2017-07-20 summary:Performing efficient resource provisioning is a fundamental aspect for any resource provider. Local Resource Management Systems (LRMS) have been used in data centers for decades in order to obtain the best usage of the resources, providing their fair usage and partitioning for the users. In contrast, current cloud schedulers are normally based on the immediate allocation of resources on a first-come, first-served basis, meaning that a request will fail if there are no resources (e.g. OpenStack) or it will be trivially queued ordered by entry time (e.g. OpenNebula). Moreover, these scheduling strategies are based on a static partitioning of the resources, meaning that existing quotas cannot be exceeded, even if there are idle resources allocated to other projects. This is a consequence of the fact that cloud instances are not associated with a maximum execution time and leads to a situation where the resources are under-utilized. These facts have been identified by the INDIGO-DataCloud project as being too simplistic for accommodating scientific workloads in an efficient way, leading to an underutilization of the resources, a non desirable situation in scientific data centers. In this work, we will present the work done in the scheduling area during the first year of the INDIGO project and the foreseen evolutions. version:1
arxiv-1707-06398 | Self-stabilizing Localization of the Middle Point of a Line Segment by an Oblivious Robot with Limited Visibility | http://arxiv.org/abs/1707.06398 | id:1707.06398 author:Akihiro Monde, Yukiko Yamauchi, Shuji Kijima, Masafumi Yamashita category:cs.DC  published:2017-07-20 summary:This paper poses a question about a simple localization problem, which is arisen from self-stabilizing location problems by oblivious mobile autonomous robots with limited visibility. The question is if an oblivious mobile robot on a line-segment can localize the middle point of the line-segment in finite steps observing the direction (i.e., Left or Right) and distance to the nearest end point. This problem is also akin to (a continuous version of) binary search, and could be closely related to computable real functions. Contrary to appearances, it is far from trivial if this simple problem is solvable or not, and unsettled yet. This paper is concerned with three variants of the original problem, minimally relaxing, and presents self-stabilizing algorithms for them. We also show an easy impossibility theorem for bilaterally symmetric algorithms. version:1
arxiv-1707-06393 | Deja vu: Scalable Place Recognition Using Mutually Supportive Feature Frequencies | http://arxiv.org/abs/1707.06393 | id:1707.06393 author:Adam Jacobson, Walter Scheirer, Michael Milford category:cs.RO  published:2017-07-20 summary:Learning and recognition is a fundamental process performed in many robot operations such as mapping and localization. The majority of approaches share some common characteristics, such as attempting to extract salient features, landmarks or signatures, and growth in data storage and computational requirements as the size of the environment increases. In biological systems, spatial encoding in the brain is definitively known to be performed using a fixed-size neural encoding framework - the place, head-direction and grid cells found in the mammalian hippocampus and entorhinal cortex. Particularly paradoxically, one of the main encoding centers - the grid cells - represents the world using a highly aliased, repetitive encoding structure where one neuron represents an unbounded number of places in the world. Inspired by this system, in this paper we invert the normal approach used in forming mapping and localization algorithms, by developing a novel place recognition algorithm that seeks out and leverages repetitive, mutually complementary landmark frequencies in the world. The combinatorial encoding capacity of multiple different frequencies enables not only the ability to achieve efficient data storage, but also the potential for sub-linear storage growth in a learning and recall system. Using both ground-based and aerial camera datasets, we demonstrate the system finding and utilizing these frequencies to achieve successful place recognition, and discuss how this approach might scale to arbitrarily large global datasets and dimensions. version:1
arxiv-1707-06391 | Deterministic Dispersion of Mobile Robots in Dynamic Rings | http://arxiv.org/abs/1707.06391 | id:1707.06391 author:Ankush Agarwalla, John Augustine, William K. Moses Jr., Madhav Sankar K., Arvind Krishna Sridhar category:cs.DC cs.DS F.2.2; G.2.2  published:2017-07-20 summary:In this work, we study the problem of dispersion of mobile robots on dynamic rings. The problem of dispersion of $n$ robots on an $n$ node graph, introduced by Augustine and Moses Jr.~\cite{AM17}, requires robots to coordinate with each other and reach a configuration where exactly one robot is present on each node. This problem has real world applications and applies whenever we want to minimize the total cost of $n$ agents sharing $n$ resources, located at various places, subject to the constraint that the cost of an agent moving to a different resource is comparatively much smaller than the cost of multiple agents sharing a resource (e.g. smart electric cars sharing recharge stations). The study of this problem also provides indirect benefits to the study of exploration by mobile robots and the study of load balancing on graphs. We solve the problem of dispersion in the presence of two types of dynamism in the underlying graph: (i) vertex permutation and (ii) 1-interval connectivity. We introduce the notion of vertex permutation dynamism and have it mean that for a given set of nodes, in every round, the adversary ensures a ring structure is maintained, but the connections between the nodes may change. We use the idea of 1-interval connectivity from Di Luna et al.~\cite{LDFS16}, where for a given ring, in each round, the adversary chooses at most one edge to remove. We assume robots have full visibility and present asymptotically time optimal algorithms to achieve dispersion in the presence of both types of dynamism when robots have chirality. When robots do not have chirality, we present asymptotically time optimal algorithms to achieve dispersion subject to certain constraints. Finally, we provide impossibility results for dispersion when robots have no visibility. version:1
arxiv-1707-09867 | Unmixing dynamic PET images for voxel-based kinetic component analysis | http://arxiv.org/abs/1707.09867 | id:1707.09867 author:Yanna Cruz Cavalcanti, Thomas Oberlin, Nicolas Dobigeon, Simon Stute, Maria Ribeiro, Clovis Tauber category:cs.CV physics.data-an stat.ME  published:2017-07-19 summary:To analyze dynamic positron emission tomography (PET) images, various generic multivariate data analysis techniques have been considered in the literature, such as clustering, principal component analysis (PCA), independent component analysis (ICA) and non-negative matrix factorization (NMF). Nevertheless, these conventional approaches generally fail to recover a reliable, understandable and interpretable description of the data. In this paper, we propose an alternative analysis paradigm based on the concept of linear unmixing as an efficient and meaningful way to analyze dynamic PET images. The time-activity curves (TACs) measured in the voxels are modeled as linear combinations of elementary component signatures weighted by their respective concentrations in each voxel. Additionally to the non-negativity constraint of NMF, the proposed unmixing approach ensures an exhaustive description of the mixtures by a sum-to-one constraint of the mixing coefficients. Besides, it allows both the noise and partial volume effects to be handled. Moreover, the proposed method accounts for any possible fluctuations in the exchange rate of the tracer between the free compartment and a specifically bound ligand compartment. Indeed, it explicitly models the spatial variability of the corresponding signature through a perturbed specific binding component. The performance of the method is assessed on both synthetic and real data and compared to other conventional analysis methods. version:1
arxiv-1705-10960 | Effective Target Aware Visual Navigation for UAVs | http://arxiv.org/abs/1705.10960 | id:1705.10960 author:Ciro Potena, Daniele Nardi, Alberto Pretto category:cs.RO  published:2017-05-31 summary:In this paper we propose an effective vision-based navigation method that allows a multirotor vehicle to simultaneously reach a desired goal pose in the environment while constantly facing a target object or landmark. Standard techniques such as Position-Based Visual Servoing (PBVS) and Image-Based Visual Servoing (IBVS) in some cases (e.g., while the multirotor is performing fast maneuvers) do not allow to constantly maintain the line of sight with a target of interest. Instead, we compute the optimal trajectory by solving a non-linear optimization problem that minimizes the target re-projection error while meeting the UAVs dynamic constraints. The desired trajectory is then tracked by means of a real-time Non-linear Model Predictive Controller (NMPC): This implicitly allows the multirotor to satisfy both the required constraints. We successfully evaluate the proposed approach in simulated and real experiments. We also present a performance comparison against a typical PBVS approach and a recent Hybrid visual servoing technique. version:2
arxiv-1707-05982 | Closed-form Solution for IMU based LSD-SLAM Point Cloud Conversion into the Scaled 3D World Environment | http://arxiv.org/abs/1707.05982 | id:1707.05982 author:Sergey Triputen, Kristiaan Schreve, Viktor Tkachev, Matthias Ratsch category:cs.RO  published:2017-07-19 summary:SLAM is a very popular research stream in computer vision and robotics nowadays. For more effective SLAM implementation it is necessary to have reliable informa- tion about the environment, also the data should be aligned and scaled according to the real world coordinate system. Monocular SLAM research is an attractive sub-stream, because of the low equipment cost, size and weight. In this paper we present a way to build a conversion from LSD-SLAM coordinate space to the real world coordinates using a true metric scale with IMU sensor data implementation. The causes of differences between the real and calculated spaces are explained and the possibility of conversions between the spaces is proved. Additionally, a closed-form solution for inter space trans- formation calculation is presented. The synthetic method of generating high level accurate and well controlled input data for the LSD-SLAM algorithm is presented. Finally, the reconstructed 3D environment representation is delivered as an output of the implemented conversion. version:1
arxiv-1707-05978 | Relative Pose Based Redundancy Removal: Collaborative RGB-D Data Transmission in Mobile Visual Sensor Networks | http://arxiv.org/abs/1707.05978 | id:1707.05978 author:Xiaoqin Wang, Y. Ahmet Sekercioglu, Tom Drummond, Vincent Fremont, Enrico Natalizio, Isabelle Fantoni category:cs.RO  published:2017-07-19 summary:The Relative Pose based Redundancy Removal(RPRR) scheme is presented, which has been designed for mobile RGB-D sensor networks operating under bandwidth-constrained operational scenarios. Participating sensor nodes detect the redundant visual and depth information to prevent their transmission leading to a significant improvement in wireless channel usage efficiency and power savings. Experimental results show that wireless channel utilization is improved by 250% and battery consumption is halved when the RPRR scheme is used instead of sending the sensor images independently. version:1
arxiv-1707-05975 | Real-Time Impulse Noise Removal from MR Images for Radiosurgery Applications | http://arxiv.org/abs/1707.05975 | id:1707.05975 author:Zohreh HosseinKhani, Mohsen Hajabdollahi, Nader Karimi, S. M. Reza Soroushmehr, Shahram Shirani, Shadrokh Samavi, Kayvan Najarian category:cs.AR physics.med-ph  published:2017-07-19 summary:In the recent years image processing techniques are used as a tool to improve detection and diagnostic capabilities in the medical applications. Medical applications have been so much affected by these techniques which some of them are embedded in medical instruments such as MRI, CT and other medical devices. Among these techniques, medical image enhancement algorithms play an essential role in removal of the noise which can be produced by medical instruments and during image transfer. It has been proved that impulse noise is a major type of noise, which is produced during medical operations, such as MRI, CT, and angiography, by their image capturing devices. An embeddable hardware module which is able to denoise medical images before and during surgical operations could be very helpful. In this paper an accurate algorithm is proposed for real-time removal of impulse noise in medical images. All image blocks are divided into three categories of edge, smooth, and disordered areas. A different reconstruction method is applied to each category of blocks for the purpose of noise removal. The proposed method is tested on MR images. Simulation results show acceptable denoising accuracy for various levels of noise. Also an FPAG implementation of our denoising algorithm shows acceptable hardware resource utilization. Hence, the algorithm is suitable for embedding in medical hardware instruments such as radiosurgery devices. version:1
arxiv-1702-08695 | Online Robot Introspection via Wrench-based Action Grammars | http://arxiv.org/abs/1702.08695 | id:1702.08695 author:Juan Rojas, Shuangqi Luo, Dingqiao Zhu, Yunlong Du, Hongbin Lin, Zhengjie Huang, Wenwei Kuang, Kensuke Harada category:cs.RO  published:2017-02-28 summary:Robotic failure is all too common in unstructured robot tasks. Despite well-designed controllers, robots often fail due to unexpected events. How do robots measure unexpected events? Many do not. Most robots are driven by the sense-plan act paradigm, however more recently robots are undergoing a sense-plan-act-verify paradigm. In this work, we present a principled methodology to bootstrap online robot introspection for contact tasks. In effect, we are trying to enable the robot to answer the question: what did I do? Is my behavior as expected or not? To this end, we analyze noisy wrench data and postulate that the latter inherently contains patterns that can be effectively represented by a vocabulary. The vocabulary is generated by segmenting and encoding the data. When the wrench information represents a sequence of sub-tasks, we can think of the vocabulary forming a sentence (set of words with grammar rules) for a given sub-task; allowing the latter to be uniquely represented. The grammar, which can also include unexpected events, was classified in offline and online scenarios as well as for simulated and real robot experiments. Multiclass Support Vector Machines (SVMs) were used offline, while online probabilistic SVMs were are used to give temporal confidence to the introspection result. The contribution of our work is the presentation of a generalizable online semantic scheme that enables a robot to understand its high-level state whether nominal or abnormal. It is shown to work in offline and online scenarios for a particularly challenging contact task: snap assemblies. We perform the snap assembly in one-arm simulated and real one-arm experiments and a simulated two-arm experiment. This verification mechanism can be used by high-level planners or reasoning systems to enable intelligent failure recovery or determine the next most optima manipulation skill to be used. version:2
arxiv-1707-05972 | Drone-based Object Counting by Spatially Regularized Regional Proposal Network | http://arxiv.org/abs/1707.05972 | id:1707.05972 author:Meng-Ru Hsieh, Yen-Liang Lin, Winston H. Hsu category:cs.CV  published:2017-07-19 summary:Existing counting methods often adopt regression-based approaches and thus cannot precisely localize the target objects, which hinders the further applications and analysis (e.g., high-level understanding and fine-grained classification). In addition, most of prior work mainly focus on counting objects in the static environments with fixed cameras. Motivated by the advent of unmanned flying vehicles (i.e., drone), we are interested in detecting and counting objects in such dynamic environments. We propose a Layout Proposal Networks (LPNs) and spatial kernels to simultaneously count and localize target objects (e.g., cars) in the Drone videos. Different from the conventional region proposal methods, we leverage the spatial layout information (e.g., cars often park regularly) and introduce the spatially regularized constraints into our network to improve the localization accuracy. To evaluate our counting method, we present a new large-scale car parking lot dataset (CARPK) that contains nearly 90,000 cars captured from different parking lots. To the best of our knowledge, it is the first and the largest drone view dataset that supports object counting, and provides the bounding box annotations. version:1
arxiv-1707-05970 | Generic Black-Box End-to-End Attack against RNNs and Other API Calls Based Malware Classifiers | http://arxiv.org/abs/1707.05970 | id:1707.05970 author:Ishai Rosenberg, Asaf Shabtai, Lior Rokach, Yuval Elovici category:cs.CR cs.LG cs.NE  published:2017-07-19 summary:Deep neural networks are being used to solve complex classification problems, in which other machine learning classifiers, such as SVM, fall short. Recurrent Neural Networks (RNNs) have been used for tasks that involves sequential inputs, like speech to text. In the cyber security domain, RNNs based on API calls have been able to classify unsigned malware better than other classifiers. In this paper we present a black-box attack against RNNs, focusing on finding adversarial API call sequences that would be misclassified by a RNN without affecting the malware functionality. We also show that the this attack is effective against many classifiers, due-to the transferability principle between RNN variants, feed-forward DNNs and state-of-the-art traditional machine learning classifiers. Finally, we introduce the transferability by transitivity principle, causing an attack against generalized classifier like RNN variants to be transferable to less generalized classifiers like feed-forward DNNs. We conclude by discussing possible defense mechanisms. version:1
arxiv-1707-05647 | Fast Screening Algorithm for Rotation and Scale Invariant Template Matching | http://arxiv.org/abs/1707.05647 | id:1707.05647 author:Bolin Liu, Xiao Shu, Xiaolin Wu category:cs.CV  published:2017-07-18 summary:This paper presents a generic pre-processor for expediting conventional template matching techniques. Instead of locating the best matched patch in the reference image to a query template via exhaustive search, the proposed algorithm rules out regions with no possible matches with minimum computational efforts. While working on simple patch features, such as mean, variance and gradient, the fast pre-screening is highly discriminative. Its computational efficiency is gained by using a novel octagonal-star-shaped template and the inclusion-exclusion principle to extract and compare patch features. Moreover, it can handle arbitrary rotation and scaling of reference images effectively. Extensive experiments demonstrate that the proposed algorithm greatly reduces the search space while never missing the best match. version:2
arxiv-1707-05961 | Multidimensional classification of hippocampal shape features discriminates Alzheimer's disease and mild cognitive impairment from normal aging | http://arxiv.org/abs/1707.05961 | id:1707.05961 author:Emilie Gerardin, Gaël Chételat, Marie Chupin, Rémi Cuingnet, Béatrice Desgranges, Ho-Sung Kim, Marc Niethammer, Bruno Dubois, Stéphane Lehéricy, Line Garnero, Francis Eustache, Olivier Colliot category:cs.CV q-bio.NC stat.ML  published:2017-07-19 summary:We describe a new method to automatically discriminate between patients with Alzheimer's disease (AD) or mild cognitive impairment (MCI) and elderly controls, based on multidimensional classification of hippocampal shape features. This approach uses spherical harmonics (SPHARM) coefficients to model the shape of the hippocampi, which are segmented from magnetic resonance images (MRI) using a fully automatic method that we previously developed. SPHARM coefficients are used as features in a classification procedure based on support vector machines (SVM). The most relevant features for classification are selected using a bagging strategy. We evaluate the accuracy of our method in a group of 23 patients with AD (10 males, 13 females, age $\pm$ standard-deviation (SD) = 73 $\pm$ 6 years, mini-mental score (MMS) = 24.4 $\pm$ 2.8), 23 patients with amnestic MCI (10 males, 13 females, age $\pm$ SD = 74 $\pm$ 8 years, MMS = 27.3 $\pm$ 1.4) and 25 elderly healthy controls (13 males, 12 females, age $\pm$ SD = 64 $\pm$ 8 years), using leave-one-out cross-validation. For AD vs controls, we obtain a correct classification rate of 94%, a sensitivity of 96%, and a specificity of 92%. For MCI vs controls, we obtain a classification rate of 83%, a sensitivity of 83%, and a specificity of 84%. This accuracy is superior to that of hippocampal volumetry and is comparable to recently published SVM-based whole-brain classification methods, which relied on a different strategy. This new method may become a useful tool to assist in the diagnosis of Alzheimer's disease. version:1
arxiv-1707-05956 | When Unsupervised Domain Adaptation Meets Tensor Representations | http://arxiv.org/abs/1707.05956 | id:1707.05956 author:Hao Lu, Lei Zhang, Zhiguo Cao, Wei Wei, Ke Xian, Chunhua Shen, Anton van den Hengel category:cs.CV  published:2017-07-19 summary:Domain adaption (DA) allows machine learning methods trained on data sampled from one distribution to be applied to data sampled from another. It is thus of great practical importance to the application of such methods. Despite the fact that tensor representations are widely used in Computer Vision to capture multi-linear relationships that affect the data, most existing DA methods are applicable to vectors only. This renders them incapable of reflecting and preserving important structure in many problems. We thus propose here a learning-based method to adapt the source and target tensor representations directly, without vectorization. In particular, a set of alignment matrices is introduced to align the tensor representations from both domains into the invariant tensor subspace. These alignment matrices and the tensor subspace are modeled as a joint optimization problem and can be learned adaptively from the data using the proposed alternative minimization scheme. Extensive experiments show that our approach is capable of preserving the discriminative power of the source domain, of resisting the effects of label noise, and works effectively for small sample sizes, and even one-shot DA. We show that our method outperforms the state-of-the-art on the task of cross-domain visual recognition in both efficacy and efficiency, and particularly that it outperforms all comparators when applied to DA of the convolutional activations of deep convolutional networks. version:1
arxiv-1707-05950 | Image Projective Invariants | http://arxiv.org/abs/1707.05950 | id:1707.05950 author:Erbo Li, Hanlin Mo, Dong Xu, Hua Li category:cs.CV  published:2017-07-19 summary:In this paper, we propose relative projective differential invariants (RPDIs) which are invariant to general projective transformations. By using RPDIs and the structural frame of integral invariant, projective weighted moment invariants (PIs) can be constructed very easily. It is first proved that a kind of projective invariants exists in terms of weighted integration of images, with relative differential invariants as the weight functions. Then, some simple instances of PIs are given. In order to ensure the stability and discriminability of PIs, we discuss how to calculate partial derivatives of discrete images more accurately. Since the number of pixels in discrete images before and after the geometric transformation may be different, we design the method to normalize the number of pixels. These ways enhance the performance of PIs. Finally, we carry out some experiments based on synthetic and real image datasets. We choose commonly used moment invariants for comparison. The results indicate that PIs have better performance than other moment invariants in image retrieval and classification. With PIs, one can compare the similarity between images under the projective transformation without knowing the parameters of the transformation, which provides a good tool to shape analysis in image processing, computer vision and pattern recognition. version:1
arxiv-1707-05947 | Generalization Bounds of SGLD for Non-convex Learning: Two Theoretical Viewpoints | http://arxiv.org/abs/1707.05947 | id:1707.05947 author:Wenlong Mou, Liwei Wang, Xiyu Zhai, Kai Zheng category:cs.LG math.OC stat.ML  published:2017-07-19 summary:Algorithm-dependent generalization error bounds are central to statistical learning theory. A learning algorithm may use a large hypothesis space, but the limited number of iterations controls its model capacity and generalization error. The impacts of stochastic gradient methods on generalization error for non-convex learning problems not only have important theoretical consequences, but are also critical to generalization errors of deep learning. In this paper, we study the generalization errors of Stochastic Gradient Langevin Dynamics (SGLD) with non-convex objectives. Two theories are proposed with non-asymptotic discrete-time analysis, using Stability and PAC-Bayesian results respectively. The stability-based theory obtains a bound of $O\left(\frac{1}{n}L\sqrt{\beta T_k}\right)$, where $L$ is uniform Lipschitz parameter, $\beta$ is inverse temperature, and $T_k$ is aggregated step sizes. For PAC-Bayesian theory, though the bound has a slower $O(1/\sqrt{n})$ rate, the contribution of each step is shown with an exponentially decaying factor by imposing $\ell^2$ regularization, and the uniform Lipschitz constant is also replaced by actual norms of gradients along trajectory. Our bounds have no implicit dependence on dimensions, norms or other capacity measures of parameter, which elegantly characterizes the phenomenon of "Fast Training Guarantees Generalization" in non-convex settings. This is the first algorithm-dependent result with reasonable dependence on aggregated step sizes for non-convex learning, and has important implications to statistical learning aspects of stochastic gradient methods in complicated models such as deep learning. version:1
arxiv-1707-05938 | Face Alignment Robust to Pose, Expressions and Occlusions | http://arxiv.org/abs/1707.05938 | id:1707.05938 author:Vishnu Naresh Boddeti, Myung-Cheol Roh, Jongju Shin, Takaharu Oguri, Takeo Kanade category:cs.CV  published:2017-07-19 summary:We propose an Ensemble of Robust Constrained Local Models for alignment of faces in the presence of significant occlusions and of any unknown pose and expression. To account for partial occlusions we introduce, Robust Constrained Local Models, that comprises of a deformable shape and local landmark appearance model and reasons over binary occlusion labels. Our occlusion reasoning proceeds by a hypothesize-and-test search over occlusion labels. Hypotheses are generated by Constrained Local Model based shape fitting over randomly sampled subsets of landmark detector responses and are evaluated by the quality of face alignment. To span the entire range of facial pose and expression variations we adopt an ensemble of independent Robust Constrained Local Models to search over a discretized representation of pose and expression. We perform extensive evaluation on a large number of face images, both occluded and unoccluded. We find that our face alignment system trained entirely on facial images captured "in-the-lab" exhibits a high degree of generalization to facial images captured "in-the-wild". Our results are accurate and stable over a wide spectrum of occlusions, pose and expression variations resulting in excellent performance on many real-world face datasets. version:1
arxiv-1707-05411 | Hybrid PS-V Technique: A Novel Sensor Fusion Approach for Fast Mobile Eye-Tracking with Sensor-Shift Aware Correction | http://arxiv.org/abs/1707.05411 | id:1707.05411 author:Ioannis Rigas, Hayes Raffle, Oleg V. Komogortsev category:cs.CV cs.HC  published:2017-07-17 summary:This paper introduces and evaluates a hybrid technique that fuses efficiently the eye-tracking principles of photosensor oculography (PSOG) and video oculography (VOG). The main concept of this novel approach is to use a few fast and power-economic photosensors as the core mechanism for performing high speed eye-tracking, whereas in parallel, use a video sensor operating at low sampling-rate (snapshot mode) to perform dead-reckoning error correction when sensor movements occur. In order to evaluate the proposed method, we simulate the functional components of the technique and present our results in experimental scenarios involving various combinations of horizontal and vertical eye and sensor movements. Our evaluation shows that the developed technique can be used to provide robustness to sensor shifts that otherwise could induce error larger than 5 deg. Our analysis suggests that the technique can potentially enable high speed eye-tracking at low power profiles, making it suitable to be used in emerging head-mounted devices, e.g. AR/VR headsets. version:2
arxiv-1707-05413 | Photosensor Oculography: Survey and Parametric Analysis of Designs using Model-Based Simulation | http://arxiv.org/abs/1707.05413 | id:1707.05413 author:Ioannis Rigas, Hayes Raffle, Oleg V. Komogortsev category:cs.CV cs.HC  published:2017-07-17 summary:This paper presents a renewed overview of photosensor oculography (PSOG), an eye-tracking technique based on the principle of using simple photosensors to measure the amount of reflected (usually infrared) light when the eye rotates. Photosensor oculography can provide measurements with high precision, low latency and reduced power consumption, and thus it appears as an attractive option for performing eye-tracking in the emerging head-mounted interaction devices, e.g. augmented and virtual reality (AR/VR) headsets. In our current work we employ an adjustable simulation framework as a common basis for performing an exploratory study of the eye-tracking behavior of different photosensor oculography designs. With the performed experiments we explore the effects from the variation of some basic parameters of the designs on the resulting accuracy and cross-talk, which are crucial characteristics for the seamless operation of human-computer interaction applications based on eye-tracking. Our experimental results reveal the design trade-offs that need to be adopted to tackle the competing conditions that lead to optimum performance of different eye-tracking characteristics. We also present the transformations that arise in the eye-tracking output when sensor shifts occur, and assess the resulting degradation in accuracy for different combinations of eye movements and sensor shifts. version:2
arxiv-1707-06527 | Single-Channel Multi-talker Speech Recognition with Permutation Invariant Training | http://arxiv.org/abs/1707.06527 | id:1707.06527 author:Yanmin Qian, Xuankai Chang, Dong Yu category:cs.SD cs.CL cs.LG I.2.7  published:2017-07-19 summary:Although great progresses have been made in automatic speech recognition (ASR), significant performance degradation is still observed when recognizing multi-talker mixed speech. In this paper, we propose and evaluate several architectures to address this problem under the assumption that only a single channel of mixed signal is available. Our technique extends permutation invariant training (PIT) by introducing the front-end feature separation module with the minimum mean square error (MSE) criterion and the back-end recognition module with the minimum cross entropy (CE) criterion. More specifically, during training we compute the average MSE or CE over the whole utterance for each possible utterance-level output-target assignment, pick the one with the minimum MSE or CE, and optimize for that assignment. This strategy elegantly solves the label permutation problem observed in the deep learning based multi-talker mixed speech separation and recognition systems. The proposed architectures are evaluated and compared on an artificially mixed AMI dataset with both two- and three-talker mixed speech. The experimental results indicate that our proposed architectures can cut the word error rate (WER) by 45.0% and 25.0% relatively against the state-of-the-art single-talker speech recognition system across all speakers when their energies are comparable, for two- and three-talker mixed speech, respectively. To our knowledge, this is the first work on the multi-talker mixed speech recognition on the challenging speaker-independent spontaneous large vocabulary continuous speech task. version:1
arxiv-1707-05929 | Learning Unified Embedding for Apparel Recognition | http://arxiv.org/abs/1707.05929 | id:1707.05929 author:Yang Song, Yuan Li, Bo Wu, Chao-Yeh Chen, Xiao Zhang, Hartwig Adam category:cs.CV  published:2017-07-19 summary:In apparel recognition, specialized models (e.g. models trained for a particular vertical like dresses) can significantly outperform general models (i.e. models that cover a wide range of verticals). Therefore, deep neural network models are often trained separately for different verticals. However, using specialized models for different verticals is not scalable and expensive to deploy. This paper addresses the problem of learning one unified embedding model for multiple object verticals (e.g. all apparel classes) without sacrificing accuracy. The problem is tackled from two aspects: training data and training difficulty. On the training data aspect, we figure out that for a single model trained with triplet loss, there is an accuracy sweet spot in terms of how many verticals are trained together. To ease the training difficulty, a novel learning scheme is proposed by using the output from specialized models as learning targets so that L2 loss can be used instead of triplet loss. This new loss makes the training easier and make it possible for more efficient use of the feature space. The end result is a unified model which can achieve the same retrieval accuracy as a number of separate specialized models, while having the model complexity as one. The effectiveness of our approach is shown in experiments. version:1
arxiv-1707-05928 | Deep Active Learning for Named Entity Recognition | http://arxiv.org/abs/1707.05928 | id:1707.05928 author:Yanyao Shen, Hyokun Yun, Zachary C. Lipton, Yakov Kronrod, Animashree Anandkumar category:cs.CL  published:2017-07-19 summary:Deep neural networks have advanced the state of the art in named entity recognition. However, under typical training procedures, advantages over classical methods emerge only with large datasets. As a result, deep learning is employed only when large public datasets or a large budget for manually labeling data is available. In this work, we show that by combining deep learning with active learning, we can outperform classical methods even with a significantly smaller amount of training data. version:1
arxiv-1707-05926 | Equivalence between LINE and Matrix Factorization | http://arxiv.org/abs/1707.05926 | id:1707.05926 author:Qiao Wang, Zheng Wang, Xiaojun Ye category:cs.LG  published:2017-07-19 summary:LINE [1], as an efficient network embedding method, has shown its effectiveness in dealing with large-scale undirected, directed, and/or weighted networks. Particularly, it proposes to preserve both the local structure (represented by First-order Proximity) and global structure (represented by Second-order Proximity) of the network. In this study, we prove that LINE with these two proximities (LINE(1st) and LINE(2nd)) are actually factoring two different matrices separately. Specifically, LINE(1st) is factoring a matrix M (1), whose entries are the doubled Pointwise Mutual Information (PMI) of vertex pairs in undirected networks, shifted by a constant. LINE(2nd) is factoring a matrix M (2), whose entries are the PMI of vertex and context pairs in directed networks, shifted by a constant. We hope this finding would provide a basis for further extensions and generalizations of LINE. version:1
arxiv-1707-05922 | Improving Output Uncertainty Estimation and Generalization in Deep Learning via Neural Network Gaussian Processes | http://arxiv.org/abs/1707.05922 | id:1707.05922 author:Tomoharu Iwata, Zoubin Ghahramani category:stat.ML  published:2017-07-19 summary:We propose a simple method that combines neural networks and Gaussian processes. The proposed method can estimate the uncertainty of outputs and flexibly adjust target functions where training data exist, which are advantages of Gaussian processes. The proposed method can also achieve high generalization performance for unseen input configurations, which is an advantage of neural networks. With the proposed method, neural networks are used for the mean functions of Gaussian processes. We present a scalable stochastic inference procedure, where sparse Gaussian processes are inferred by stochastic variational inference, and the parameters of neural networks and kernels are estimated by stochastic gradient descent methods, simultaneously. We use two real-world spatio-temporal data sets to demonstrate experimentally that the proposed method achieves better uncertainty estimation and generalization performance than neural networks and Gaussian processes. version:1
arxiv-1707-06226 | The Role of Conversation Context for Sarcasm Detection in Online Interactions | http://arxiv.org/abs/1707.06226 | id:1707.06226 author:Debanjan Ghosh, Alexander Richard Fabbri, Smaranda Muresan category:cs.CL cs.AI cs.LG  published:2017-07-19 summary:Computational models for sarcasm detection have often relied on the content of utterances in isolation. However, speaker's sarcastic intent is not always obvious without additional context. Focusing on social media discussions, we investigate two issues: (1) does modeling of conversation context help in sarcasm detection and (2) can we understand what part of conversation context triggered the sarcastic reply. To address the first issue, we investigate several types of Long Short-Term Memory (LSTM) networks that can model both the conversation context and the sarcastic response. We show that the conditional LSTM network (Rocktaschel et al., 2015) and LSTM networks with sentence level attention on context and response outperform the LSTM model that reads only the response. To address the second issue, we present a qualitative analysis of attention weights produced by the LSTM models with attention and discuss the results compared with human performance on the task. version:1
arxiv-1706-06681 | Graph-based Neural Multi-Document Summarization | http://arxiv.org/abs/1706.06681 | id:1706.06681 author:Michihiro Yasunaga, Rui Zhang, Kshitijh Meelu, Ayush Pareek, Krishnan Srinivasan, Dragomir Radev category:cs.CL cs.LG  published:2017-06-20 summary:We propose a neural multi-document summarization (MDS) system that incorporates sentence relation graphs. We employ a Graph Convolutional Network (GCN) on the relation graphs, with sentence embeddings obtained from Recurrent Neural Networks as input node features. Through multiple layer-wise propagation, the GCN generates high-level hidden sentence features for salience estimation. We then use a greedy heuristic to extract salient sentences while avoiding redundancy. In our experiments on DUC 2004, we consider three types of sentence relation graphs and demonstrate the advantage of combining sentence relations in graphs with the representation power of deep neural networks. Our model improves upon traditional graph-based extractive approaches and the vanilla GRU sequence model with no graph, and it achieves competitive results against other state-of-the-art multi-document summarization systems. version:2
arxiv-1707-05911 | Recognizing and Curating Photo Albums via Event-Specific Image Importance | http://arxiv.org/abs/1707.05911 | id:1707.05911 author:Yufei Wang, Zhe Lin, Xiaohui Shen, Radomir Mech, Gavin Miller, Garrison W. Cottrell category:cs.CV  published:2017-07-19 summary:Automatic organization of personal photos is a problem with many real world ap- plications, and can be divided into two main tasks: recognizing the event type of the photo collection, and selecting interesting images from the collection. In this paper, we attempt to simultaneously solve both tasks: album-wise event recognition and image- wise importance prediction. We collected an album dataset with both event type labels and image importance labels, refined from an existing CUFED dataset. We propose a hybrid system consisting of three parts: A siamese network-based event-specific image importance prediction, a Convolutional Neural Network (CNN) that recognizes the event type, and a Long Short-Term Memory (LSTM)-based sequence level event recognizer. We propose an iterative updating procedure for event type and image importance score prediction. We experimentally verified that image importance score prediction and event type recognition can each help the performance of the other. version:1
arxiv-1707-05909 | Recovering Latent Signals from a Mixture of Measurements using a Gaussian Process Prior | http://arxiv.org/abs/1707.05909 | id:1707.05909 author:Felipe Tobar, Gonzalo Rios, Tomás Valdivia, Pablo Guerrero category:stat.ML cs.LG  published:2017-07-19 summary:In sensing applications, sensors cannot always measure the latent quantity of interest at the required resolution, sometimes they can only acquire a blurred version of it due the sensor's transfer function. To recover latent signals when only noisy mixed measurements of the signal are available, we propose the Gaussian process mixture of measurements (GPMM), which models the latent signal as a Gaussian process (GP) and allows us to perform Bayesian inference on such signal conditional to a set of noisy mixture of measurements. We describe how to train GPMM, that is, to find the hyperparameters of the GP and the mixing weights, and how to perform inference on the latent signal under GPMM; additionally, we identify the solution to the underdetermined linear system resulting from a sensing application as a particular case of GPMM. The proposed model is validated in the recovery of three signals: a smooth synthetic signal, a real-world heart-rate time series and a step function, where GPMM outperformed the standard GP in terms of estimation error, uncertainty representation and recovery of the spectral content of the latent signal. version:1
arxiv-1707-05905 | Secure SURF with Fully Homomorphic Encryption | http://arxiv.org/abs/1707.05905 | id:1707.05905 author:Thomas Shortell, Ali Shokoufandeh category:cs.CV cs.CR  published:2017-07-19 summary:Cloud computing is an important part of today's world because offloading computations is a method to reduce costs. In this paper, we investigate computing the Speeded Up Robust Features (SURF) using Fully Homomorphic Encryption (FHE). Performing SURF in FHE enables a method to offload the computations while maintaining security and privacy of the original data. In support of this research, we developed a framework to compute SURF via a rational number based compatible with FHE. Although floating point (R) to rational numbers (Q) conversion introduces error, our research provides tight bounds on the magnitude of error in terms of parameters of FHE. We empirically verified the proposed method against a set of images at different sizes and showed that our framework accurately computes most of the SURF keypoints in FHE. version:1
arxiv-1707-05904 | Hybrid Conditional Planning using Answer Set Programming | http://arxiv.org/abs/1707.05904 | id:1707.05904 author:Ibrahim Faruk Yalciner, Ahmed Nouman, Volkan Patoglu, Esra Erdem category:cs.AI cs.LO cs.RO  published:2017-07-19 summary:We introduce a parallel offline algorithm for computing hybrid conditional plans, called HCP-ASP, oriented towards robotics applications. HCP-ASP relies on modeling actuation actions and sensing actions in an expressive nonmonotonic language of answer set programming (ASP), and computation of the branches of a conditional plan in parallel using an ASP solver. In particular, thanks to external atoms, continuous feasibility checks (like collision checks) are embedded into formal representations of actuation actions and sensing actions in ASP; and thus each branch of a hybrid conditional plan describes a feasible execution of actions to reach their goals. Utilizing nonmonotonic constructs and nondeterministic choices, partial knowledge about states and nondeterministic effects of sensing actions can be explicitly formalized in ASP; and thus each branch of a conditional plan can be computed by an ASP solver without necessitating a conformant planner and an ordering of sensing actions in advance. We apply our method in a service robotics domain and report experimental evaluations. Furthermore, we present performance comparisons with other compilation based conditional planners on standardized benchmark domains. This paper is under consideration for acceptance in TPLP. version:1
arxiv-1707-05900 | MIT SuperCloud Portal Workspace: Enabling HPC Web Application Deployment | http://arxiv.org/abs/1707.05900 | id:1707.05900 author:Andrew Prout, William Arcand, David Bestor, Bill Bergeron, Chansup Byun, Vijay Gadepally, Matthew Hubbell, Michael Houle, Michael Jones, Peter Michaleas, Lauren Milechin, Julie Mullen, Antonio Rosa, Siddharth Samsi, Albert Reuther, Jeremy Kepner category:cs.DC cs.HC cs.SE  published:2017-07-19 summary:The MIT SuperCloud Portal Workspace enables the secure exposure of web services running on high performance computing (HPC) systems. The portal allows users to run any web application as an HPC job and access it from their workstation while providing authentication, encryption, and access control at the system level to prevent unintended access. This capability permits users to seamlessly utilize existing and emerging tools that present their user interface as a website on an HPC system creating a portal workspace. Performance measurements indicate that the MIT SuperCloud Portal Workspace incurs marginal overhead when compared to a direct connection of the same service. version:1
arxiv-1707-05878 | On-line Building Energy Optimization using Deep Reinforcement Learning | http://arxiv.org/abs/1707.05878 | id:1707.05878 author:Elena Mocanu, Decebal Constantin Mocanu, Phuong H. Nguyen, Antonio Liotta, Michael E. Webber, Madeleine Gibescu, J. G. Slootweg category:cs.LG cs.AI math.OC  published:2017-07-18 summary:Unprecedented high volumes of data are becoming available with the growth of the advanced metering infrastructure. These are expected to benefit planning and operation of the future power system, and to help the customers transition from a passive to an active role. In this paper, we explore for the first time in the smart grid context the benefits of using Deep Reinforcement Learning, a hybrid type of methods that combines Reinforcement Learning with Deep Learning, to perform on-line optimization of schedules for building energy management systems. The learning procedure was explored using two methods, Deep Q-learning and Deep Policy Gradient, both of them being extended to perform multiple actions simultaneously. The proposed approach was validated on the large-scale Pecan Street Inc. database. This highly-dimensional database includes information about photovoltaic power generation, electric vehicles as well as buildings appliances. Moreover, these on-line energy scheduling strategies could be used to provide real-time feedback to consumers to encourage more efficient use of electricity. version:1
arxiv-1707-05867 | Reconciling Graphs and Sets of Sets | http://arxiv.org/abs/1707.05867 | id:1707.05867 author:Michael Mitzenmacher, Tom Morgan category:cs.DS cs.DC  published:2017-07-18 summary:We explore a generalization of set reconciliation, where the goal is to reconcile sets of sets. Alice and Bob each have a parent set consisting of $s$ child sets, each containing at most $h$ elements from a universe of size $u$. They want to reconcile their sets of sets in a scenario where the total number of differences between all of their child sets (under the minimum difference matching between their child sets) is $d$. We give several algorithms for this problem, and discuss applications to reconciliation problems on graphs, databases, and collections of documents. We specifically focus on graph reconciliation, providing protocols based on sets of sets reconciliation for random graphs from $G(n,p)$ and for forests of rooted trees. version:1
arxiv-1707-05861 | On Adaptive Propensity Score Truncation in Causal Inference | http://arxiv.org/abs/1707.05861 | id:1707.05861 author:Cheng Ju, Joshua Schwab, Mark J. van der Laan category:stat.ME stat.CO stat.ML  published:2017-07-18 summary:The positivity assumption, or the experimental treatment assignment (ETA) assumption, is important for identifiability in causal inference. Even if the positivity assumption holds, practical violations of this assumption may jeopardize the finite sample performance of the causal estimator. One of the consequences of practical violations of the positivity assumption is extreme values in the estimated propensity score (PS). A common practice to address this issue is truncating the PS estimate when constructing PS-based estimators. In this study, we propose a novel adaptive truncation method, Positivity-C-TMLE, based on the collaborative targeted maximum likelihood estimation (C-TMLE) methodology. We demonstrate the outstanding performance of our novel approach in a variety of simulations by comparing it with other commonly studied estimators. Results show that by adaptively truncating the estimated PS with a more targeted objective function, the Positivity-C-TMLE estimator achieves the best performance for both point estimation and confidence interval coverage among all estimators considered. version:1
arxiv-1707-05858 | Logic Programming approaches for routing fault-free and maximally-parallel Wavelength Routed Optical Networks on Chip (Application paper) | http://arxiv.org/abs/1707.05858 | id:1707.05858 author:Marco Gavanelli, Maddalena Nonato, Andrea Peano, Davide Bertozzi category:cs.AI  published:2017-07-18 summary:One promising trend in digital system integration consists of boosting on-chip communication performance by means of silicon photonics, thus materializing the so-called Optical Networks-on-Chip (ONoCs). Among them, wavelength routing can be used to route a signal to destination by univocally associating a routing path to the wavelength of the optical carrier. Such wavelengths should be chosen so to minimize interferences among optical channels and to avoid routing faults. As a result, physical parameter selection of such networks requires the solution of complex constrained optimization problems. In previous work, published in the proceedings of the International Conference on Computer-Aided Design, we proposed and solved the problem of computing the maximum parallelism obtainable in the communication between any two endpoints while avoiding misrouting of optical signals. The underlying technology, only quickly mentioned in that paper, is Answer Set Programming (ASP). In this work, we detail the ASP approach we used to solve such problem. Another important design issue is to select the wavelengths of optical carriers such that they are spread across the available spectrum, in order to reduce the likelihood that, due to imperfections in the manufacturing process, unintended routing faults arise. We show how to address such problem in Constraint Logic Programming on Finite Domains (CLP(FD)). This paper is under consideration for possible publication on Theory and Practice of Logic Programming. version:1
arxiv-1707-05853 | EncodingWord Confusion Networks with Recurrent Neural Networks for Dialog State Tracking | http://arxiv.org/abs/1707.05853 | id:1707.05853 author:Glorianna Jagfeld, Ngoc Thang Vu category:cs.CL  published:2017-07-18 summary:This paper presents our novel method to encode word confusion networks, which can represent a rich hypothesis space of automatic speech recognition systems, via recurrent neural networks. We demonstrate the utility of our approach for the task of dialog state tracking in spoken dialog systems that relies on automatic speech recognition output. Encoding confusion networks outperforms encoding the best hypothesis of the automatic speech recognition in a neural system for dialog state tracking on the well-known second Dialog State Tracking Challenge dataset. version:1
arxiv-1704-00874 | The string of diamonds is nearly tight for rumour spreading | http://arxiv.org/abs/1704.00874 | id:1704.00874 author:Omer Angel, Abbas Mehrabian, Yuval Peres category:math.PR cs.DC cs.SI C.2.1; G.2.2; G.3  published:2017-04-04 summary:For a rumour spreading protocol, the spread time is defined as the first time that everyone learns the rumour. We compare the synchronous push&pull rumour spreading protocol with its asynchronous variant, and show that for any $n$-vertex graph and any starting vertex, the ratio between their expected spread times is bounded by $O \left({n}^{1/3}{\log^{2/3} n}\right)$. This improves the $O(\sqrt n)$ upper bound of Giakkoupis, Nazari, and Woelfel (in Proceedings of ACM Symposium on Principles of Distributed Computing, 2016). Our bound is tight up to a factor of $O(\log n)$, as illustrated by the string of diamonds graph. We also show that if for a pair $\alpha,\beta$ of real numbers, there exists infinitely many graphs for which the two spread times are $n^{\alpha}$ and $n^{\beta}$ in expectation, then $0\leq\alpha \leq 1$ and $\alpha \leq \beta \leq \frac13 + \frac23 \alpha$; and we show each such pair $\alpha,\beta$ is achievable. version:2
arxiv-1707-05847 | The Devil is in the Decoder | http://arxiv.org/abs/1707.05847 | id:1707.05847 author:Zbigniew Wojna, Vittorio Ferrari, Sergio Guadarrama, Nathan Silberman, Liang-Chieh Chen, Alireza Fathi, Jasper Uijlings category:cs.CV  published:2017-07-18 summary:Many machine vision applications require predictions for every pixel of the input image (for example semantic segmentation, boundary detection). Models for such problems usually consist of encoders which decreases spatial resolution while learning a high-dimensional representation, followed by decoders who recover the original input resolution and result in low-dimensional predictions. While encoders have been studied rigorously, relatively few studies address the decoder side. Therefore this paper presents an extensive comparison of a variety of decoders for a variety of pixel-wise prediction tasks. Our contributions are: (1) Decoders matter: we observe significant variance in results between different types of decoders on various problems. (2) We introduce a novel decoder: bilinear additive upsampling. (3) We introduce new residual-like connections for decoders. (4) We identify two decoder types which give a consistently high performance. version:1
arxiv-1707-05841 | Linear Time Complexity Deep Fourier Scattering Network and Extension to Nonlinear Invariants | http://arxiv.org/abs/1707.05841 | id:1707.05841 author:Randall Balestriero, Herve Glotin category:stat.ML cs.LG  published:2017-07-18 summary:In this paper we propose a scalable version of a state-of-the-art deterministic time-invariant feature extraction approach based on consecutive changes of basis and nonlinearities, namely, the scattering network. The first focus of the paper is to extend the scattering network to allow the use of higher order nonlinearities as well as extracting nonlinear and Fourier based statistics leading to the required invariants of any inherently structured input. In order to reach fast convolutions and to leverage the intrinsic structure of wavelets, we derive our complete model in the Fourier domain. In addition of providing fast computations, we are now able to exploit sparse matrices due to extremely high sparsity well localized in the Fourier domain. As a result, we are able to reach a true linear time complexity with inputs in the Fourier domain allowing fast and energy efficient solutions to machine learning tasks. Validation of the features and computational results will be presented through the use of these invariant coefficients to perform classification on audio recordings of bird songs captured in multiple different soundscapes. In the end, the applicability of the presented solutions to deep artificial neural networks is discussed. version:1
arxiv-1707-05840 | Multiscale Residual Mixture of PCA: Dynamic Dictionaries for Optimal Basis Learning | http://arxiv.org/abs/1707.05840 | id:1707.05840 author:Randall Balestriero category:stat.ML cs.LG  published:2017-07-18 summary:In this paper we are interested in the problem of learning an over-complete basis and a methodology such that the reconstruction or inverse problem does not need optimization. We analyze the optimality of the presented approaches, their link to popular already known techniques s.a. Artificial Neural Networks,k-means or Oja's learning rule. Finally, we will see that one approach to reach the optimal dictionary is a factorial and hierarchical approach. The derived approach lead to a formulation of a Deep Oja Network. We present results on different tasks and present the resulting very efficient learning algorithm which brings a new vision on the training of deep nets. Finally, the theoretical work shows that deep frameworks are one way to efficiently have over-complete (combinatorially large) dictionary yet allowing easy reconstruction. We thus present the Deep Residual Oja Network (DRON). We demonstrate that a recursive deep approach working on the residuals allow exponential decrease of the error w.r.t. the depth. version:1
arxiv-1707-05828 | A deep learning approach to diabetic blood glucose prediction | http://arxiv.org/abs/1707.05828 | id:1707.05828 author:H. N. Mhaskar, S. V. Pereverzyev, M. D. van der Walt category:cs.LG math.NA  published:2017-07-18 summary:We consider the question of 30-minute prediction of blood glucose levels measured by continuous glucose monitoring devices, using clinical data. While most studies of this nature deal with one patient at a time, we take a certain percentage of patients in the data set as training data, and test on the remainder of the patients; i.e., the machine need not re-calibrate on the new patients in the data set. We demonstrate how deep learning can outperform shallow networks in this example. One novelty is to demonstrate how a parsimonious deep representation can be constructed using domain knowledge. version:1
arxiv-1707-05821 | Discovering Class-Specific Pixels for Weakly-Supervised Semantic Segmentation | http://arxiv.org/abs/1707.05821 | id:1707.05821 author:Arslan Chaudhry, Puneet K. Dokania, Philip H. S. Torr category:cs.CV  published:2017-07-18 summary:We propose an approach to discover class-specific pixels for the weakly-supervised semantic segmentation task. We show that properly combining saliency and attention maps allows us to obtain reliable cues capable of significantly boosting the performance. First, we propose a simple yet powerful hierarchical approach to discover the class-agnostic salient regions, obtained using a salient object detector, which otherwise would be ignored. Second, we use fully convolutional attention maps to reliably localize the class-specific regions in a given image. We combine these two cues to discover class-specific pixels which are then used as an approximate ground truth for training a CNN. While solving the weakly supervised semantic segmentation task, we ensure that the image-level classification task is also solved in order to enforce the CNN to assign at least one pixel to each object present in the image. Experimentally, on the PASCAL VOC12 val and test sets, we obtain the mIoU of 60.8% and 61.9%, achieving the performance gains of 5.1% and 5.2% compared to the published state-of-the-art results. The code is made publicly available. version:1
arxiv-1707-03742 | Large-scale Multiview 3D Hand Pose Dataset | http://arxiv.org/abs/1707.03742 | id:1707.03742 author:Francisco Gomez-Donoso, Sergio Orts-Escolano, Miguel Cazorla category:cs.HC cs.CV  published:2017-07-12 summary:Accurate hand pose estimation at joint level has several uses on human-robot interaction, user interfacing and virtual reality applications. Yet, it currently is not a solved problem. The novel deep learning techniques could make a great improvement on this matter but they need a huge amount of annotated data. The hand pose datasets released so far present some issues that make them impossible to use on deep learning methods such as the few number of samples, high-level abstraction annotations or samples consisting in depth maps. In this work, we introduce a multiview hand pose dataset in which we provide color images of hands and different kind of annotations for each, i.e the bounding box and the 2D and 3D location on the joints in the hand. Besides, we introduce a simple yet accurate deep learning architecture for real-time robust 2D hand pose estimation. version:3
arxiv-1707-05809 | A Novel Deep Learning Architecture for Testis Histology Image Classification | http://arxiv.org/abs/1707.05809 | id:1707.05809 author:Chia-Yu Kao, Leonard McMillan category:cs.CV  published:2017-07-18 summary:Unlike other histology analysis, classification of tubule status in testis histology is very challenging due to their high similarity of texture and shape. Traditional deep learning networks have difficulties to capture nuance details among different tubule categories. In this paper, we propose a novel deep learning architecture for feature learning, image classification, and image reconstruction. It is based on stacked auto-encoders with an additional layer, called a hyperlayer, which is created to capture features of an image at different layers in the network. This addition effectively combines features at different scales and thus provides a more complete profile for further classification. Evaluation is performed on a set of 10,542 tubule image patches. We demonstrate our approach with two experiments on two different subsets of the dataset. The results show that the features learned from our architecture achieve more than 98% accuracy and represent an improvement over traditional deep network architectures. version:1
arxiv-1707-05807 | Improving Gibbs Sampler Scan Quality with DoGS | http://arxiv.org/abs/1707.05807 | id:1707.05807 author:Ioannis Mitliagkas, Lester Mackey category:stat.ML cs.LG math.PR stat.ME  published:2017-07-18 summary:The pairwise influence matrix of Dobrushin has long been used as an analytical tool to bound the rate of convergence of Gibbs sampling. In this work, we use Dobrushin influence as the basis of a practical tool to certify and efficiently improve the quality of a discrete Gibbs sampler. Our Dobrushin-optimized Gibbs samplers (DoGS) offer customized variable selection orders for a given sampling budget and variable subset of interest, explicit bounds on total variation distance to stationarity, and certifiable improvements over the standard systematic and uniform random scan Gibbs samplers. In our experiments with joint image segmentation and object recognition, Markov chain Monte Carlo maximum likelihood estimation, and Ising model inference, DoGS consistently deliver higher-quality inferences with significantly smaller sampling budgets than standard Gibbs samplers. version:1
arxiv-1707-05776 | Optimizing the Latent Space of Generative Networks | http://arxiv.org/abs/1707.05776 | id:1707.05776 author:Piotr Bojanowski, Armand Joulin, David Lopez-Paz, Arthur Szlam category:stat.ML cs.CV cs.LG  published:2017-07-18 summary:Generative Adversarial Networks (GANs) have been shown to be able to sample impressively realistic images. GAN training consists of a saddle point optimization problem that can be thought of as an adversarial game between a generator which produces the images, and a discriminator, which judges if the images are real. Both the generator and the discriminator are commonly parametrized as deep convolutional neural networks. The goal of this paper is to disentangle the contribution of the optimization procedure and the network parametrization to the success of GANs. To this end we introduce and study Generative Latent Optimization (GLO), a framework to train a generator without the need to learn a discriminator, thus avoiding challenging adversarial optimization problems. We show experimentally that GLO enjoys many of the desirable properties of GANs: learning from large data, synthesizing visually-appealing samples, interpolating meaningfully between samples, and performing linear arithmetic with noise vectors. version:1
arxiv-1707-05754 | AirCode: Unobtrusive Physical Tags for Digital Fabrication | http://arxiv.org/abs/1707.05754 | id:1707.05754 author:Dingzeyu Li, Avinash S. Nair, Shree K. Nayar, Changxi Zheng category:cs.HC cs.CV cs.GR  published:2017-07-18 summary:We present AirCode, a technique that allows the user to tag physically fabricated objects with given information. An AirCode tag consists of a group of carefully designed air pockets placed beneath the object surface. These air pockets are easily produced during the fabrication process of the object, without any additional material or postprocessing. Meanwhile, the air pockets affect only the scattering light transport under the surface, and thus are hard to notice to our naked eyes. But, by using a computational imaging method, the tags become detectable. We present a tool that automates the design of air pockets for the user to encode information. AirCode system also allows the user to retrieve the information from captured images via a robust decoding algorithm. We demonstrate our tagging technique with applications for metadata embedding, robotic grasping, as well as conveying object affordances. version:1
arxiv-1707-05743 | Transitioning between Convolutional and Fully Connected Layers in Neural Networks | http://arxiv.org/abs/1707.05743 | id:1707.05743 author:Shazia Akbar, Mohammad Peikari, Sherine Salama, Sharon Nofech-Mozes, Anne Martel category:cs.CV  published:2017-07-18 summary:Digital pathology has advanced substantially over the last decade however tumor localization continues to be a challenging problem due to highly complex patterns and textures in the underlying tissue bed. The use of convolutional neural networks (CNNs) to analyze such complex images has been well adopted in digital pathology. However in recent years, the architecture of CNNs have altered with the introduction of inception modules which have shown great promise for classification tasks. In this paper, we propose a modified "transition" module which learns global average pooling layers from filters of varying sizes to encourage class-specific filters at multiple spatial resolutions. We demonstrate the performance of the transition module in AlexNet and ZFNet, for classifying breast tumors in two independent datasets of scanned histology sections, of which the transition module was superior. version:1
arxiv-1707-05740 | Skeleton Based Human Action Recognition with Global Context-Aware Attention LSTM Networks | http://arxiv.org/abs/1707.05740 | id:1707.05740 author:Jun Liu, Gang Wang, Ling-Yu Duan, Ping Hu, Alex C. Kot category:cs.CV  published:2017-07-18 summary:Human action recognition in 3D skeleton sequences has attracted a lot of research attention. Recently, Long Short-Term Memory (LSTM) networks have shown promising performance in this task due to their strengths in modeling the dependencies and dynamics in sequential data. As not all skeletal joints are informative for action recognition, and the irrelevant joints often bring noise which can degrade the performance, we need to pay more attention to the informative ones. However, the original LSTM network does not have explicit attention ability. In this paper, we propose a new class of LSTM network, Global Context-Aware Attention LSTM (GCA-LSTM), for skeleton based action recognition. This network is capable of selectively focusing on the informative joints in each frame of each skeleton sequence by using a global context memory cell. To further improve the attention capability of our network, we also introduce a recurrent attention mechanism, with which the attention performance of the network can be enhanced progressively. Moreover, we propose a stepwise training scheme in order to train our network effectively. Our approach achieves state-of-the-art performance on five challenging benchmark datasets for skeleton based action recognition. version:1
arxiv-1707-05733 | Choosing Smartly: Adaptive Multimodal Fusion for Object Detection in Changing Environments | http://arxiv.org/abs/1707.05733 | id:1707.05733 author:Oier Mees, Andreas Eitel, Wolfram Burgard category:cs.RO cs.AI cs.CV cs.LG  published:2017-07-18 summary:Object detection is an essential task for autonomous robots operating in dynamic and changing environments. A robot should be able to detect objects in the presence of sensor noise that can be induced by changing lighting conditions for cameras and false depth readings for range sensors, especially RGB-D cameras. To tackle these challenges, we propose a novel adaptive fusion approach for object detection that learns weighting the predictions of different sensor modalities in an online manner. Our approach is based on a mixture of convolutional neural network (CNN) experts and incorporates multiple modalities including appearance, depth and motion. We test our method in extensive robot experiments, in which we detect people in a combined indoor and outdoor scenario from RGB-D data, and we demonstrate that our method can adapt to harsh lighting changes and severe camera motion blur. Furthermore, we present a new RGB-D dataset for people detection in mixed in- and outdoor environments, recorded with a mobile robot. version:1
arxiv-1707-05729 | Robust Bayesian Optimization with Student-t Likelihood | http://arxiv.org/abs/1707.05729 | id:1707.05729 author:Ruben Martinez-Cantin, Michael McCourt, Kevin Tee category:cs.LG cs.AI stat.ML  published:2017-07-18 summary:Bayesian optimization has recently attracted the attention of the automatic machine learning community for its excellent results in hyperparameter tuning. BO is characterized by the sample efficiency with which it can optimize expensive black-box functions. The efficiency is achieved in a similar fashion to the learning to learn methods: surrogate models (typically in the form of Gaussian processes) learn the target function and perform intelligent sampling. This surrogate model can be applied even in the presence of noise; however, as with most regression methods, it is very sensitive to outlier data. This can result in erroneous predictions and, in the case of BO, biased and inefficient exploration. In this work, we present a GP model that is robust to outliers which uses a Student-t likelihood to segregate outliers and robustly conduct Bayesian optimization. We present numerical results evaluating the proposed method in both artificial functions and real problems. version:1
arxiv-1707-05720 | Grounding Spatio-Semantic Referring Expressions for Human-Robot Interaction | http://arxiv.org/abs/1707.05720 | id:1707.05720 author:Mohit Shridhar, David Hsu category:cs.RO cs.AI cs.CL  published:2017-07-18 summary:The human language is one of the most natural interfaces for humans to interact with robots. This paper presents a robot system that retrieves everyday objects with unconstrained natural language descriptions. A core issue for the system is semantic and spatial grounding, which is to infer objects and their spatial relationships from images and natural language expressions. We introduce a two-stage neural-network grounding pipeline that maps natural language referring expressions directly to objects in the images. The first stage uses visual descriptions in the referring expressions to generate a candidate set of relevant objects. The second stage examines all pairwise relationships between the candidates and predicts the most likely referred object according to the spatial descriptions in the referring expressions. A key feature of our system is that by leveraging a large dataset of images labeled with text descriptions, it allows unrestricted object types and natural language referring expressions. Preliminary results indicate that our system outperforms a near state-of-the-art object comprehension system on standard benchmark datasets. We also present a robot system that follows voice commands to pick and place previously unseen objects. version:1
arxiv-1707-06100 | Discovering topics in text datasets by visualizing relevant words | http://arxiv.org/abs/1707.06100 | id:1707.06100 author:Franziska Horn, Leila Arras, Grégoire Montavon, Klaus-Robert Müller, Wojciech Samek category:cs.CL  published:2017-07-18 summary:When dealing with large collections of documents, it is imperative to quickly get an overview of the texts' contents. In this paper we show how this can be achieved by using a clustering algorithm to identify topics in the dataset and then selecting and visualizing relevant words, which distinguish a group of documents from the rest of the texts, to summarize the contents of the documents belonging to each topic. We demonstrate our approach by discovering trending topics in a collection of New York Times article snippets. version:1
arxiv-1707-05697 | An Iterative BP-CNN Architecture for Channel Decoding | http://arxiv.org/abs/1707.05697 | id:1707.05697 author:Fei Liang, Cong Shen, Feng Wu category:stat.ML cs.IT math.IT  published:2017-07-18 summary:Inspired by recent advances in deep learning, we propose a novel iterative BP-CNN architecture for channel decoding under correlated noise. This architecture concatenates a trained convolutional neural network (CNN) with a standard belief-propagation (BP) decoder. The standard BP decoder is used to estimate the coded bits, followed by a CNN to remove the estimation errors of the BP decoder and obtain a more accurate estimation of the channel noise. Iterating between BP and CNN will gradually improve the decoding SNR and hence result in better decoding performance. To train a well-behaved CNN model, we define a new loss function which involves not only the accuracy of the noise estimation but also the normality test for the estimation errors, i.e., to measure how likely the estimation errors follow a Gaussian distribution. The introduction of the normality test to the CNN training shapes the residual noise distribution and further reduces the BER of the iterative decoding, compared to using the standard quadratic loss function. We carry out extensive experiments to analyze and verify the proposed framework. The iterative BP-CNN decoder has better BER performance with lower complexity, is suitable for parallel implementation, does not rely on any specific channel model or encoding method, and is robust against training mismatches. All of these features make it a good candidate for decoding modern channel codes. version:1
arxiv-1707-05691 | Learning Fashion Compatibility with Bidirectional LSTMs | http://arxiv.org/abs/1707.05691 | id:1707.05691 author:Xintong Han, Zuxuan Wu, Yu-Gang Jiang, Larry S. Davis category:cs.CV  published:2017-07-18 summary:The ubiquity of online fashion shopping demands effective recommendation services for customers. In this paper, we study two types of fashion recommendation: (i) suggesting an item that matches existing components in a set to form a stylish outfit (a collection of fashion items), and (ii) generating an outfit with multimodal (images/text) specifications from a user. To this end, we propose to jointly learn a visual-semantic embedding and the compatibility relationships among fashion items in an end-to-end fashion. More specifically, we consider a fashion outfit to be a sequence (usually from top to bottom and then accessories) and each item in the outfit as a time step. Given the fashion items in an outfit, we train a bidirectional LSTM (Bi-LSTM) model to sequentially predict the next item conditioned on previous ones to learn their compatibility relationships. Further, we learn a visual-semantic space by regressing image features to their semantic representations aiming to inject attribute and category information as a regularization for training the LSTM. The trained network can not only perform the aforementioned recommendations effectively but also predict the compatibility of a given outfit. We conduct extensive experiments on our newly collected Polyvore dataset, and the results provide strong qualitative and quantitative evidence that our framework outperforms alternative methods. version:1
arxiv-1707-05685 | Hashed Binary Search Sampling for Convolutional Network Training with Large Overhead Image Patches | http://arxiv.org/abs/1707.05685 | id:1707.05685 author:Dalton Lunga, Lexie Yang, Budhendra Bhaduri category:cs.CV  published:2017-07-18 summary:Very large overhead imagery associated with ground truth maps has the potential to generate billions of training image patches for machine learning algorithms. However, random sampling selection criteria often leads to redundant and noisy-image patches for model training. With minimal research efforts behind this challenge, the current status spells missed opportunities to develop supervised learning algorithms that generalize over wide geographical scenes. In addition, much of the computational cycles for large scale machine learning are poorly spent crunching through noisy and redundant image patches. We demonstrate a potential framework to address these challenges specifically, while evaluating a human settlement detection task. A novel binary search tree sampling scheme is fused with a kernel based hashing procedure that maps image patches into hash-buckets using binary codes generated from image content. The framework exploits inherent redundancy within billions of image patches to promote mostly high variance preserving samples for accelerating algorithmic training and increasing model generalization. version:1
arxiv-1707-05683 | Exploiting Convolutional Representations for Multiscale Human Settlement Detection | http://arxiv.org/abs/1707.05683 | id:1707.05683 author:Dalton Lunga, Dilip Patlolla, Lexie Yang, Jeanette Weaver, Budhendra Bhadhuri category:cs.CV  published:2017-07-18 summary:We test this premise and explore representation spaces from a single deep convolutional network and their visualization to argue for a novel unified feature extraction framework. The objective is to utilize and re-purpose trained feature extractors without the need for network retraining on three remote sensing tasks i.e. superpixel mapping, pixel-level segmentation and semantic based image visualization. By leveraging the same convolutional feature extractors and viewing them as visual information extractors that encode different image representation spaces, we demonstrate a preliminary inductive transfer learning potential on multiscale experiments that incorporate edge-level details up to semantic-level information. version:1
arxiv-1707-05668 | Empirical evaluation of a Q-Learning Algorithm for Model-free Autonomous Soaring | http://arxiv.org/abs/1707.05668 | id:1707.05668 author:Erwan Lecarpentier, Sebastian Rapp, Marc Melo, Emmanuel Rachelson category:cs.LG  published:2017-07-18 summary:Autonomous unpowered flight is a challenge for control and guidance systems: all the energy the aircraft might use during flight has to be harvested directly from the atmosphere. We investigate the design of an algorithm that optimizes the closed-loop control of a glider's bank and sideslip angles, while flying in the lower convective layer of the atmosphere in order to increase its mission endurance. Using a Reinforcement Learning approach, we demonstrate the possibility for real-time adaptation of the glider's behaviour to the time-varying and noisy conditions associated with thermal soaring flight. Our approach is online, data-based and model-free, hence avoids the pitfalls of aerological and aircraft modelling and allow us to deal with uncertainties and non-stationarity. Additionally, we put a particular emphasis on keeping low computational requirements in order to make on-board execution feasible. This article presents the stochastic, time-dependent aerological model used for simulation, together with a standard aircraft model. Then we introduce an adaptation of a Q-learning algorithm and demonstrate its ability to control the aircraft and improve its endurance by exploiting updrafts in non-stationary scenarios. version:1
arxiv-1707-05662 | Learning Powers of Poisson Binomial Distributions | http://arxiv.org/abs/1707.05662 | id:1707.05662 author:Dimitris Fotakis, Vasilis Kontonis, Piotr Krysta, Paul Spirakis category:cs.DS cs.LG math.ST stat.TH  published:2017-07-18 summary:We introduce the problem of simultaneously learning all powers of a Poisson Binomial Distribution (PBD). A PBD of order $n$ is the distribution of a sum of $n$ mutually independent Bernoulli random variables $X_i$, where $\mathbb{E}[X_i] = p_i$. The $k$'th power of this distribution, for $k$ in a range $[m]$, is the distribution of $P_k = \sum_{i=1}^n X_i^{(k)}$, where each Bernoulli random variable $X_i^{(k)}$ has $\mathbb{E}[X_i^{(k)}] = (p_i)^k$. The learning algorithm can query any power $P_k$ several times and succeeds in learning all powers in the range, if with probability at least $1- \delta$: given any $k \in [m]$, it returns a probability distribution $Q_k$ with total variation distance from $P_k$ at most $\epsilon$. We provide almost matching lower and upper bounds on query complexity for this problem. We first show a lower bound on the query complexity on PBD powers instances with many distinct parameters $p_i$ which are separated, and we almost match this lower bound by examining the query complexity of simultaneously learning all the powers of a special class of PBD's resembling the PBD's of our lower bound. We study the fundamental setting of a Binomial distribution, and provide an optimal algorithm which uses $O(1/\epsilon^2)$ samples. Diakonikolas, Kane and Stewart [COLT'16] showed a lower bound of $\Omega(2^{1/\epsilon})$ samples to learn the $p_i$'s within error $\epsilon$. The question whether sampling from powers of PBDs can reduce this sampling complexity, has a negative answer since we show that the exponential number of samples is inevitable. Having sampling access to the powers of a PBD we then give a nearly optimal algorithm that learns its $p_i$'s. To prove our two last lower bounds we extend the classical minimax risk definition from statistics to estimating functions of sequences of distributions. version:1
arxiv-1705-02966 | You said that? | http://arxiv.org/abs/1705.02966 | id:1705.02966 author:Joon Son Chung, Amir Jamaludin, Andrew Zisserman category:cs.CV  published:2017-05-08 summary:We present a method for generating a video of a talking face. The method takes as inputs: (i) still images of the target face, and (ii) an audio speech segment; and outputs a video of the target face lip synched with the audio. The method runs in real time and is applicable to faces and audio not seen at training time. To achieve this we propose an encoder-decoder CNN model that uses a joint embedding of the face and audio to generate synthesised talking face video frames. The model is trained on tens of hours of unlabelled videos. We also show results of re-dubbing videos using speech from a different person. version:2
arxiv-1707-05653 | Faster Than Real-time Facial Alignment: A 3D Spatial Transformer Network Approach in Unconstrained Poses | http://arxiv.org/abs/1707.05653 | id:1707.05653 author:Chandraskehar Bhagavatula, Chenchen Zhu, Khoa Luu, Marios Savvides category:cs.CV  published:2017-07-18 summary:Facial alignment involves finding a set of landmark points on an image with a known semantic meaning. However, this semantic meaning of landmark points is often lost in 2D approaches where landmarks are either moved to visible boundaries or ignored as the pose of the face changes. In order to extract consistent alignment points across large poses, the 3D structure of the face must be considered in the alignment step. However, extracting a 3D structure from a single 2D image usually requires alignment in the first place. We present our novel approach to simultaneously extract the 3D shape of the face and the semantically consistent 2D alignment through a 3D Spatial Transformer Network (3DSTN) to model both the camera projection matrix and the warping parameters of a 3D model. By utilizing a generic 3D model and a Thin Plate Spline (TPS) warping function, we are able to generate subject specific 3D shapes without the need for a large 3D shape basis. In addition, our proposed network can be trained in an end-to-end framework on entirely synthetic data from the 300W-LP dataset. Unlike other 3D methods, our approach only requires one pass through the network resulting in a faster than real-time alignment. Evaluations of our model on the Annotated Facial Landmarks in the Wild (AFLW) and AFLW2000-3D datasets show our method achieves state-of-the-art performance over other 3D approaches to alignment. version:1
arxiv-1707-05635 | Spherical Paragraph Model | http://arxiv.org/abs/1707.05635 | id:1707.05635 author:Ruqing Zhang, Jiafeng Guo, Yanyan Lan, Jun Xu, Xueqi Cheng category:cs.CL  published:2017-07-18 summary:Representing texts as fixed-length vectors is central to many language processing tasks. Most traditional methods build text representations based on the simple Bag-of-Words (BoW) representation, which loses the rich semantic relations between words. Recent advances in natural language processing have shown that semantically meaningful representations of words can be efficiently acquired by distributed models, making it possible to build text representations based on a better foundation called the Bag-of-Word-Embedding (BoWE) representation. However, existing text representation methods using BoWE often lack sound probabilistic foundations or cannot well capture the semantic relatedness encoded in word vectors. To address these problems, we introduce the Spherical Paragraph Model (SPM), a probabilistic generative model based on BoWE, for text representation. SPM has good probabilistic interpretability and can fully leverage the rich semantics of words, the word co-occurrence information as well as the corpus-wide information to help the representation learning of texts. Experimental results on topical classification and sentiment analysis demonstrate that SPM can achieve new state-of-the-art performances on several benchmark datasets. version:1
arxiv-1707-05612 | VSE++: Improved Visual-Semantic Embeddings | http://arxiv.org/abs/1707.05612 | id:1707.05612 author:Fartash Faghri, David J. Fleet, Jamie Ryan Kiros, Sanja Fidler category:cs.LG cs.CL cs.CV  published:2017-07-18 summary:This paper investigates the problem of image-caption retrieval using joint visual-semantic embeddings. We introduce a very simple change to the loss function used in the original formulation by Kiros et al. (2014), which leads to drastic improvements in the retrieval performance. In particular, the original paper uses the rank loss which computes the sum of violations across the negative training examples. Instead, we penalize the model according to the hardest negative examples. We then make several additional modifications according to the current best practices in image-caption retrieval. We showcase our model on the MS-COCO and Flickr30K datasets through comparisons and ablation studies. On MS-COCO, we improve caption retrieval by 21% in R@1 with respect to the original formulation. Our results outperform the state-of-the-art results by 8.8% in caption retrieval and 11.3% in image retrieval at R@1. On Flickr30K, we more than double R@1 as reported by Kiros et al. (2014) in both image and caption retrieval, and achieve near state-of-the-art performance. We further show that similar improvements also apply to the Order-embeddings by Vendrov et al. (2015) which builds on a similar loss function. version:1
arxiv-1707-05609 | Solving $\ell^p\!$-norm regularization with tensor kernels | http://arxiv.org/abs/1707.05609 | id:1707.05609 author:Saverio Salzo, Johan A. K. Suykens, Lorenzo Rosasco category:stat.ML math.OC  published:2017-07-18 summary:In this paper, we discuss how a suitable family of tensor kernels can be used to efficiently solve nonparametric extensions of $\ell^p$ regularized learning methods. Our main contribution is proposing a fast dual algorithm, and showing that it allows to solve the problem efficiently. Our results contrast recent findings suggesting kernel methods cannot be extended beyond Hilbert setting. Numerical experiments confirm the effectiveness of the method. version:1
arxiv-1707-05594 | On Optimizing Distributed Tucker Decomposition for Dense Tensors | http://arxiv.org/abs/1707.05594 | id:1707.05594 author:Venkatesan T Chakaravarthy, Jee W Choi, Douglas J Joseph, Xing Liu, Prakash Murali, Yogish Sabharwal, Dheeraj Sreedhar category:cs.DC  published:2017-07-18 summary:The Tucker decomposition expresses a given tensor as the product of a small core tensor and a set of factor matrices. Apart from providing data compression, the construction is useful in performing analysis such as principal component analysis (PCA)and finds applications in diverse domains such as signal processing, computer vision and text analytics. Our objective is to develop an efficient distributed implementation for the case of dense tensors. The implementation is based on the HOOI (Higher Order Orthogonal Iterator) procedure, wherein the tensor-times-matrix product forms the core routine. Prior work have proposed heuristics for reducing the computational load and communication volume incurred by the routine. We study the two metrics in a formal and systematic manner, and design strategies that are optimal under the two fundamental metrics. Our experimental evaluation on a large benchmark of tensors shows that the optimal strategies provide significant reduction in load and volume compared to prior heuristics, and provide up to 7x speed-up in the overall running time. version:1
arxiv-1707-05589 | On the State of the Art of Evaluation in Neural Language Models | http://arxiv.org/abs/1707.05589 | id:1707.05589 author:Gábor Melis, Chris Dyer, Phil Blunsom category:cs.CL  published:2017-07-18 summary:Ongoing innovations in recurrent neural network architectures have provided a steady influx of apparently state-of-the-art results on language modelling benchmarks. However, these have been evaluated using differing code bases and limited computational resources, which represent uncontrolled sources of experimental variation. We reevaluate several popular architectures and regularisation methods with large-scale automatic black-box hyperparameter tuning and arrive at the somewhat surprising conclusion that standard LSTM architectures, when properly regularised, outperform more recent models. We establish a new state of the art on the Penn Treebank and Wikitext-2 corpora, as well as strong baselines on the Hutter Prize dataset. version:1
arxiv-1707-05587 | Graph learning under sparsity priors | http://arxiv.org/abs/1707.05587 | id:1707.05587 author:Hermina Petric Maretic, Dorina Thanou, Pascal Frossard category:cs.LG cs.SI stat.ML  published:2017-07-18 summary:Graph signals offer a very generic and natural representation for data that lives on networks or irregular structures. The actual data structure is however often unknown a priori but can sometimes be estimated from the knowledge of the application domain. If this is not possible, the data structure has to be inferred from the mere signal observations. This is exactly the problem that we address in this paper, under the assumption that the graph signals can be represented as a sparse linear combination of a few atoms of a structured graph dictionary. The dictionary is constructed on polynomials of the graph Laplacian, which can sparsely represent a general class of graph signals composed of localized patterns on the graph. We formulate a graph learning problem, whose solution provides an ideal fit between the signal observations and the sparse graph signal model. As the problem is non-convex, we propose to solve it by alternating between a signal sparse coding and a graph update step. We provide experimental results that outline the good graph recovery performance of our method, which generally compares favourably to other recent network inference algorithms. version:1
arxiv-1707-05576 | Domain Adaptation for Resume Classification Using Convolutional Neural Networks | http://arxiv.org/abs/1707.05576 | id:1707.05576 author:Luiza Sayfullina, Eric Malmi, Yiping Liao, Alex Jung category:cs.CV  published:2017-07-18 summary:We propose a novel method for classifying resume data of job applicants into 27 different job categories using convolutional neural networks. Since resume data is costly and hard to obtain due to its sensitive nature, we use domain adaptation. In particular, we train a classifier on a large number of freely available job description snippets and then use it to classify resume data. We empirically verify a reasonable classification performance of our approach despite having only a small amount of labeled resume data available. version:1
