arxiv-1604-06721 | Exploiting Deep Semantics and Compositionality of Natural Language for Human-Robot-Interaction | http://arxiv.org/abs/1604.06721 | id:1604.06721 author:Manfred Eppe, Sean Trott, Jerome Feldman category:cs.AI cs.CL cs.RO  published:2016-04-22 summary:We develop a natural language interface for human robot interaction that implements reasoning about deep semantics in natural language. To realize the required deep analysis, we employ methods from cognitive linguistics, namely the modular and compositional framework of Embodied Construction Grammar (ECG) [Feldman, 2009]. Using ECG, robots are able to solve fine-grained reference resolution problems and other issues related to deep semantics and compositionality of natural language. This also includes verbal interaction with humans to clarify commands and queries that are too ambiguous to be executed safely. We implement our NLU framework as a ROS package and present proof-of-concept scenarios with different robots, as well as a survey on the state of the art. version:1
arxiv-1604-06720 | Learning rotation invariant convolutional filters for texture classification | http://arxiv.org/abs/1604.06720 | id:1604.06720 author:Diego Marcos, Michele Volpi, Devis Tuia category:cs.CV  published:2016-04-22 summary:We present a method for learning discriminative steerable filters using a shallow Convolutional Neural Network (CNN). We encode rotation invariance directly in the model by tying the weights of groups of filters to several rotated versions of the canonical filter in the group. These filters can be used to extract rotation invariant features well-suited for image classification. We test this learning procedure on a texture classification benchmark, where the orientations of the training images differ from those of the test images. We obtain results comparable to or better than the state-of-the-art. Besides numerical advantages, our proposed rotation invariant CNN decreases the number of parameters to be learned, thus showing more robustness in small training set scenarios than a standard CNN. version:1
arxiv-1604-06665 | Multiscale Segmentation via Bregman Distances and Nonlinear Spectral Analysis | http://arxiv.org/abs/1604.06665 | id:1604.06665 author:Leonie Zeune, Guus van Dalum, Leon W. M. M. Terstappen, S. A. van Gils, Christoph Brune category:math.NA cs.CV math.SP  published:2016-04-22 summary:In biomedical imaging reliable segmentation of objects (e.g. from small cells up to large organs) is of fundamental importance for automated medical diagnosis. New approaches for multi-scale segmentation can considerably improve performance in case of natural variations in intensity, size and shape. This paper aims at segmenting objects of interest based on shape contours and automatically finding multiple objects with different scales. The overall strategy of this work is to combine nonlinear segmentation with scales spaces and spectral decompositions recently introduced in literature. For this we generalize a variational segmentation model based on total variation using Bregman distances to construct an inverse scale space. This offers the new model to be accomplished by a scale analysis approach based on a spectral decomposition of the total variation. As a result we obtain a very efficient, (nearly) parameter-free multiscale segmentation method that comes with an adaptive regularization parameter choice. The added benefit of our method is demonstrated by systematic synthetic tests and its usage in a new biomedical toolbox for identifying and classifying circulating tumor cells. Due to the nature of nonlinear diffusion underlying, the mathematical concepts in this work offer promising extensions to nonlocal classification problems. version:1
arxiv-1604-06650 | Detecting state of aggression in sentences using CNN | http://arxiv.org/abs/1604.06650 | id:1604.06650 author:Rodmonga Potapova, Denis Gordeev category:cs.CL  published:2016-04-22 summary:In this article we study verbal expression of aggression and its detection using machine learning and neural networks methods. We test our results using our corpora of messages from anonymous imageboards. We also compare Random forest classifier with convolutional neural network for "Movie reviews with one sentence per review" corpus. version:1
arxiv-1604-06648 | Automatic verbal aggression detection for Russian and American imageboards | http://arxiv.org/abs/1604.06648 | id:1604.06648 author:Denis Gordeev category:cs.CL  published:2016-04-22 summary:The problem of aggression for Internet communities is rampant. Anonymous forums usually called imageboards are notorious for their aggressive and deviant behaviour even in comparison with other Internet communities. This study is aimed at studying ways of automatic detection of verbal expression of aggression for the most popular American (4chan.org) and Russian (2ch.hk) imageboards. A set of 1,802,789 messages was used for this study. The machine learning algorithm word2vec was applied to detect the state of aggression. A decent result is obtained for English (88%), the results for Russian are yet to be improved. version:1
arxiv-1604-06646 | Synthetic Data for Text Localisation in Natural Images | http://arxiv.org/abs/1604.06646 | id:1604.06646 author:Ankush Gupta, Andrea Vedaldi, Andrew Zisserman category:cs.CV  published:2016-04-22 summary:In this paper we introduce a new method for text detection in natural images. The method comprises two contributions: First, a fast and scalable engine to generate synthetic images of text in clutter. This engine overlays synthetic text to existing background images in a natural way, accounting for the local 3D scene geometry. Second, we use the synthetic images to train a Fully-Convolutional Regression Network (FCRN) which efficiently performs text detection and bounding-box regression at all locations and multiple scales in an image. We discuss the relation of FCRN to the recently-introduced YOLO detector, as well as other end-to-end object detection systems based on deep learning. The resulting detection network significantly out performs current methods for text detection in natural images, achieving an F-measure of 84.2% on the standard ICDAR 2013 benchmark. Furthermore, it can process 15 images per second on a GPU. version:1
arxiv-1604-06637 | $γ$-regression: Robust and Sparse Regression based on $γ$-divergence | http://arxiv.org/abs/1604.06637 | id:1604.06637 author:Takayuki Kawashima, Hironori Fujisawa category:stat.ME stat.ML  published:2016-04-22 summary:In high-dimensional data, many sparse regression methods have been proposed. However, they may not be robust against outliers. Recently, the use of density power weight has been studied for robust parameter estimation and the corresponding divergences have been discussed. One of such divergences is the $\gamma$-divergence and the robust estimator using the $\gamma$-divergence is known for having a strong robustness. In this paper, we consider the robust and sparse regression based on $\gamma$-divergence. We extend the $\gamma$-divergence to the regression problem and show that it has a strong robustness under heavy contamination even when outliers are heterogeneous. The loss function is constructed by an empirical estimate of the $\gamma$-divergence with sparse regularization and the parameter estimate is defined as the minimizer of the loss function. To obtain the robust and sparse estimate, we propose an efficient update algorithm which has a monotone decreasing property of the loss function. Particularly, we discuss a linear regression problem with $L_1$ regularization in detail. In numerical experiments, we see that the proposed method outperforms past sparse and robust methods. version:1
arxiv-1604-06635 | Bridging LSTM Architecture and the Neural Dynamics during Reading | http://arxiv.org/abs/1604.06635 | id:1604.06635 author:Peng Qian, Xipeng Qiu, Xuanjing Huang category:cs.CL cs.AI cs.LG cs.NE  published:2016-04-22 summary:Recently, the long short-term memory neural network (LSTM) has attracted wide interest due to its success in many tasks. LSTM architecture consists of a memory cell and three gates, which looks similar to the neuronal networks in the brain. However, there still lacks the evidence of the cognitive plausibility of LSTM architecture as well as its working mechanism. In this paper, we study the cognitive plausibility of LSTM by aligning its internal architecture with the brain activity observed via fMRI when the subjects read a story. Experiment results show that the artificial memory vector in LSTM can accurately predict the observed sequential brain activities, indicating the correlation between LSTM architecture and the cognitive process of story reading. version:1
arxiv-1604-06620 | Optimizing top precision performance measure of content-based image retrieval by learning similarity function | http://arxiv.org/abs/1604.06620 | id:1604.06620 author:Jingbin Wang, Lihui Shi, Haoxiang Wang, Jiandong Meng, Jim Jing-Yan Wang, Qingquan Sun, Yi Gu category:cs.CV  published:2016-04-22 summary:In this paper we study the problem of content-based image retrieval. In this problem, the most popular performance measure is the top precision measure, and the most important component of a retrieval system is the similarity function used to compare a query image against a database image. However, up to now, there is no existing similarity learning method proposed to optimize the top precision measure. To fill this gap, in this paper, we propose a novel similarity learning method to maximize the top precision measure. We model this problem as a minimization problem with an objective function as the combination of the losses of the relevant images ranked behind the top-ranked irrelevant image, and the squared $\ell_2$ norm of the similarity function parameter. This minimization problem is solved as a quadratic programming problem. The experiments over two benchmark data sets show the advantages of the proposed method over other similarity learning methods when the top precision is used as the performance measure. version:1
arxiv-1601-01272 | Recurrent Memory Networks for Language Modeling | http://arxiv.org/abs/1601.01272 | id:1601.01272 author:Ke Tran, Arianna Bisazza, Christof Monz category:cs.CL  published:2016-01-06 summary:Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge. In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data. We demonstrate the power of RMN on language modeling and sentence completion tasks. On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin. version:2
arxiv-1604-06607 | K-Bit-Swap: A New Operator For Real-Coded Evolutionary Algorithms | http://arxiv.org/abs/1604.06607 | id:1604.06607 author:Aram Ter-Sarkisov, Stephen Marsland category:cs.NE I.2  published:2016-04-22 summary:There has been a variety of crossover operators proposed for Real-Coded Genetic Algorithms (RCGAs), which recombine values from the same location in pairs of strings. In this article we present a recombination operator for RC- GAs that selects the locations randomly in both parents, and compare it to mainstream crossover operators in a set of experiments on a range of standard multidimensional optimization problems and a clustering problem. We present two variants of the operator, either selecting both bits uniformly at random in the strings, or sampling the second bit from a normal distribution centered at the selected location in the first string. While the operator is biased towards exploitation of fitness space, the random selection of the second bit for swap- ping makes it slightly less exploitation-biased. Extensive statistical analysis using a non-parametric test shows the advantage of the new recombination operators on a range of test functions. version:1
arxiv-1601-06971 | Sentiment Analysis of Twitter Data: A Survey of Techniques | http://arxiv.org/abs/1601.06971 | id:1601.06971 author:Vishal. A. Kharde, Prof. Sheetal. Sonawane category:cs.CL I.2.7  published:2016-01-26 summary:With the advancement of web technology and its growth, there is a huge volume of data present in the web for internet users and a lot of data is generated too. Internet has become a platform for online learning, exchanging ideas and sharing opinions. Social networking sites like Twitter, Facebook, Google+ are rapidly gaining popularity as they allow people to share and express their views about topics,have discussion with different communities, or post messages across the world. There has been lot of work in the field of sentiment analysis of twitter data. This survey focuses mainly on sentiment analysis of twitter data which is helpful to analyze the information in the tweets where opinions are highly unstructured, heterogeneous and are either positive or negative, or neutral in some cases. In this paper, we provide a survey and a comparative analyses of existing techniques for opinion mining like machine learning and lexicon-based approaches, together with evaluation metrics. Using various machine learning algorithms like Naive Bayes, Max Entropy, and Support Vector Machine, we provide a research on twitter data streams.General challenges and applications of Sentiment Analysis on Twitter are also discussed in this paper. version:3
arxiv-1604-06583 | SweLL on the rise: Swedish Learner Language corpus for European Reference Level studies | http://arxiv.org/abs/1604.06583 | id:1604.06583 author:Elena Volodina, Ildikó Pilán, Ingegerd Enström, Lorena Llozhi, Peter Lundkvist, Gunlög Sundberg, Monica Sandell category:cs.CL  published:2016-04-22 summary:We present a new resource for Swedish, SweLL, a corpus of Swedish Learner essays linked to learners' performance according to the Common European Framework of Reference (CEFR). SweLL consists of three subcorpora - SpIn, SW1203 and Tisus, collected from three different educational establishments. The common metadata for all subcorpora includes age, gender, native languages, time of residence in Sweden, type of written task. Depending on the subcorpus, learner texts may contain additional information, such as text genres, topics, grades. Five of the six CEFR levels are represented in the corpus: A1, A2, B1, B2 and C1 comprising in total 339 essays. C2 level is not included since courses at C2 level are not offered. The work flow consists of collection of essays and permits, essay digitization and registration, meta-data annotation, automatic linguistic annotation. Inter-rater agreement is presented on the basis of SW1203 subcorpus. The work on SweLL is still ongoing with more than 100 essays waiting in the pipeline. This article both describes the resource and the "how-to" behind the compilation of SweLL. version:1
arxiv-1604-06582 | Kernelized Covariance for Action Recognition | http://arxiv.org/abs/1604.06582 | id:1604.06582 author:Jacopo Cavazza, Andrea Zunino, Marco San Biagio, Vittorio Murino category:cs.CV  published:2016-04-22 summary:In this paper we aim at increasing the descriptive power of the covariance matrix, limited in capturing linear mutual dependencies between variables only. We present a rigorous and principled mathematical pipeline to recover the kernel trick for computing the covariance matrix, enhancing it to model more complex, non-linear relationships conveyed by the raw data. To this end, we propose Kernelized-COV, which generalizes the original covariance representation without compromising the efficiency of the computation. In the experiments, we validate the proposed framework against many previous approaches in the literature, scoring on par or superior with respect to the state of the art on benchmark datasets for 3D action recognition. version:1
arxiv-1604-06577 | CT-Mapper: Mapping Sparse Multimodal Cellular Trajectories using a Multilayer Transportation Network | http://arxiv.org/abs/1604.06577 | id:1604.06577 author:Fereshteh Asgari, Alexis Sultan, Haoyi Xiong, Vincent Gauthier, Mounim El-Yacoubi category:cs.SI cs.LG  published:2016-04-22 summary:Mobile phone data have recently become an attractive source of information about mobility behavior. Since cell phone data can be captured in a passive way for a large user population, they can be harnessed to collect well-sampled mobility information. In this paper, we propose CT-Mapper, an unsupervised algorithm that enables the mapping of mobile phone traces over a multimodal transport network. One of the main strengths of CT-Mapper is its capability to map noisy sparse cellular multimodal trajectories over a multilayer transportation network where the layers have different physical properties and not only to map trajectories associated with a single layer. Such a network is modeled by a large multilayer graph in which the nodes correspond to metro/train stations or road intersections and edges correspond to connections between them. The mapping problem is modeled by an unsupervised HMM where the observations correspond to sparse user mobile trajectories and the hidden states to the multilayer graph nodes. The HMM is unsupervised as the transition and emission probabilities are inferred using respectively the physical transportation properties and the information on the spatial coverage of antenna base stations. To evaluate CT-Mapper we collected cellular traces with their corresponding GPS trajectories for a group of volunteer users in Paris and vicinity (France). We show that CT-Mapper is able to accurately retrieve the real cell phone user paths despite the sparsity of the observed trace trajectories. Furthermore our transition probability model is up to 20% more accurate than other naive models. version:1
arxiv-1604-06573 | Convolutional Two-Stream Network Fusion for Video Action Recognition | http://arxiv.org/abs/1604.06573 | id:1604.06573 author:Christoph Feichtenhofer, Axel Pinz, Andrew Zisserman category:cs.CV  published:2016-04-22 summary:Recent applications of Convolutional Neural Networks (ConvNets) for human action recognition in videos have proposed different solutions for incorporating the appearance and motion information. We study a number of ways of fusing ConvNet towers both spatially and temporally in order to best take advantage of this spatio-temporal information. We make the following findings: (i) that rather than fusing at the softmax layer, a spatial and temporal network can be fused at a convolution layer without loss of performance, but with a substantial saving in parameters; (ii) that it is better to fuse such networks spatially at the last convolutional layer than earlier, and that additionally fusing at the class prediction layer can boost accuracy; finally (iii) that pooling of abstract convolutional features over spatiotemporal neighbourhoods further boosts performance. Based on these studies we propose a new ConvNet architecture for spatiotemporal fusion of video snippets, and evaluate its performance on standard benchmarks where this architecture achieves state-of-the-art results. version:1
arxiv-1604-06570 | A Classifier-guided Approach for Top-down Salient Object Detection | http://arxiv.org/abs/1604.06570 | id:1604.06570 author:Hisham Cholakkal, Jubin Johnson, Deepu Rajan category:cs.CV  published:2016-04-22 summary:We propose a framework for top-down salient object detection that incorporates a tightly coupled image classification module. The classifier is trained on novel category-aware sparse codes computed on object dictionaries used for saliency modeling. A misclassification indicates that the corresponding saliency model is inaccurate. Hence, the classifier selects images for which the saliency models need to be updated. The category-aware sparse coding produces better image classification accuracy as compared to conventional sparse coding with a reduced computational complexity. A saliency-weighted max-pooling is proposed to improve image classification, which is further used to refine the saliency maps. Experimental results on Graz-02 and PASCAL VOC-07 datasets demonstrate the effectiveness of salient object detection. Although the role of the classifier is to support salient object detection, we evaluate its performance in image classification and also illustrate the utility of thresholded saliency maps for image segmentation. version:1
arxiv-1602-07125 | Car Type Recognition with Deep Neural Networks | http://arxiv.org/abs/1602.07125 | id:1602.07125 author:Heikki Huttunen, Fatemeh Shokrollahi Yancheshmeh, Ke Chen category:cs.CV  published:2016-02-23 summary:In this paper we study automatic recognition of cars of four types: Bus, Truck, Van and Small car. For this problem we consider two data driven frameworks: a deep neural network and a support vector machine using SIFT features. The accuracy of the methods is validated with a database of over 6500 images, and the resulting prediction accuracy is over 97 %. This clearly exceeds the accuracies of earlier studies that use manually engineered feature extraction pipelines. version:2
arxiv-1512-01337 | Neural Generative Question Answering | http://arxiv.org/abs/1512.01337 | id:1512.01337 author:Jun Yin, Xin Jiang, Zhengdong Lu, Lifeng Shang, Hang Li, Xiaoming Li category:cs.CL  published:2015-12-04 summary:This paper presents an end-to-end neural network model, named Neural Generative Question Answering (GENQA), that can generate answers to simple factoid questions, based on the facts in a knowledge-base. More specifically, the model is built on the encoder-decoder framework for sequence-to-sequence learning, while equipped with the ability to enquire the knowledge-base, and is trained on a corpus of question-answer pairs, with their associated triples in the knowledge-base. Empirical study shows the proposed model can effectively deal with the variations of questions and answers, and generate right and natural answers by referring to the facts in the knowledge-base. The experiment on question answering demonstrates that the proposed model can outperform an embedding-based QA model as well as a neural dialogue model trained on the same data. version:4
arxiv-1511-06654 | Tracklet Association by Online Target-Specific Metric Learning and Coherent Dynamics Estimation | http://arxiv.org/abs/1511.06654 | id:1511.06654 author:Bing Wang, Gang Wang, Kap Luk Chan, Li Wang category:cs.CV  published:2015-11-20 summary:In this paper, we present a novel method based on online target-specific metric learning and coherent dynamics estimation for tracklet (track fragment) association by network flow optimization in long-term multi-person tracking. Our proposed framework aims to exploit appearance and motion cues to prevent identity switches during tracking and to recover missed detections. Furthermore, target-specific metrics (appearance cue) and motion dynamics (motion cue) are proposed to be learned and estimated online, i.e. during the tracking process. Our approach is effective even when such cues fail to identify or follow the target due to occlusions or object-to-object interactions. We also propose to learn the weights of these two tracking cues to handle the difficult situations, such as severe occlusions and object-to-object interactions effectively. Our method has been validated on several public datasets and the experimental results show that it outperforms several state-of-the-art tracking methods. version:2
arxiv-1512-01596 | Creation of a Deep Convolutional Auto-Encoder in Caffe | http://arxiv.org/abs/1512.01596 | id:1512.01596 author:Volodymyr Turchenko, Artur Luczak category:cs.NE cs.CV cs.LG 68Txx F.1.1; I.2.6; I.5.1  published:2015-12-04 summary:The development of a deep (stacked) convolutional auto-encoder in the Caffe deep learning framework is presented in this paper. We describe simple principles which we used to create this model in Caffe. The proposed model of convolutional auto-encoder does not have pooling/unpooling layers yet. The results of our experimental research show comparable accuracy of dimensionality reduction in comparison with a classic auto-encoder on the example of MNIST dataset. version:3
arxiv-1604-06529 | Dependency Parsing with LSTMs: An Empirical Evaluation | http://arxiv.org/abs/1604.06529 | id:1604.06529 author:Adhiguna Kuncoro, Yuichiro Sawai, Kevin Duh, Yuji Matsumoto category:cs.CL cs.LG cs.NE  published:2016-04-22 summary:We propose a transition-based dependency parser using Recurrent Neural Networks with Long Short-Term Memory (LSTM) units. This extends the feedforward neural network parser of Chen and Manning (2014) and enables modelling of entire sequences of shift/reduce transition decisions. On the Google Web Treebank, our LSTM parser is competitive with the best feedforward parser on overall accuracy and notably achieves more than 3% improvement for long-range dependencies, which has proved difficult for previous transition-based parsers due to error propagation and limited context information. Our findings additionally suggest that dropout regularisation on the embedding layer is crucial to improve the LSTM's generalisation. version:1
arxiv-1604-04280 | Variational inference for rare variant detection in deep, heterogeneous next-generation sequencing data | http://arxiv.org/abs/1604.04280 | id:1604.04280 author:Fan Zhang, Patrick Flaherty category:q-bio.GN stat.ML  published:2016-04-14 summary:The detection of rare variants is important for understanding the genetic heterogeneity in mixed samples. Recently, next-generation sequencing (NGS) technologies have enabled the identification of single nucleotide variants (SNVs) in mixed samples with high resolution. Yet, the noise inherent in the biological processes involved in next-generation sequencing necessitates the use of statistical methods to identify true rare variants. We propose a novel Bayesian statistical model and a variational expectation-maximization (EM) algorithm to estimate non-reference allele frequency (NRAF) and identify SNVs in heterogeneous cell populations. We demonstrate that our variational EM algorithm has comparable sensitivity and specificity compared with a Markov Chain Monte Carlo (MCMC) sampling inference algorithm, and is more computationally efficient on tests of low coverage ($27\times$ and $298\times$) data. Furthermore, we show that our model with a variational EM inference algorithm has higher specificity than many state-of-the-art algorithms. In an analysis of a directed evolution longitudinal yeast data set, we are able to identify a time-series trend in non-reference allele frequency and detect novel variants that have not yet been reported. Our model also detects the emergence of a beneficial variant earlier than was previously shown, and a pair of concomitant variants. version:2
arxiv-1604-06525 | Opt: A Domain Specific Language for Non-linear Least Squares Optimization in Graphics and Imaging | http://arxiv.org/abs/1604.06525 | id:1604.06525 author:Zachary DeVito, Michael Mara, Michael Zollhöfer, Gilbert Bernstein, Jonathan Ragan-Kelley, Christian Theobalt, Pat Hanrahan, Matthew Fisher, Matthias Nießner category:cs.GR cs.CV cs.PL  published:2016-04-22 summary:Many graphics and vision problems are naturally expressed as optimizations with either linear or non-linear least squares objective functions over visual data, such as images and meshes. The mathematical descriptions of these functions are extremely concise, but their implementation in real code is tedious, especially when optimized for real-time performance in interactive applications. We propose a new language, Opt (available under http://optlang.org), in which a user simply writes energy functions over image- or graph-structured unknowns, and a compiler automatically generates state-of-the-art GPU optimization kernels. The end result is a system in which real-world energy functions in graphics and vision applications are expressible in tens of lines of code. They compile directly into highly-optimized GPU solver implementations with performance competitive with the best published hand-tuned, application-specific GPU solvers, and 1-2 orders of magnitude beyond a general-purpose auto-generated solver. version:1
arxiv-1604-06397 | Improving Human Action Recognition by Non-action Classification | http://arxiv.org/abs/1604.06397 | id:1604.06397 author:Yang Wang, Minh Hoai category:cs.CV  published:2016-04-21 summary:In this paper we consider the task of recognizing human actions in realistic video where human actions are dominated by irrelevant factors. We first study the benefits of removing non-action video segments, which are the ones that do not portray any human action. We then learn a non-action classifier and use it to down-weight irrelevant video segments. The non-action classifier is trained using ActionThread, a dataset with shot-level annotation for the occurrence or absence of a human action. The non-action classifier can be used to identify non-action shots with high precision and subsequently used to improve the performance of action recognition systems. version:2
arxiv-1512-04650 | Agreement-based Joint Training for Bidirectional Attention-based Neural Machine Translation | http://arxiv.org/abs/1512.04650 | id:1512.04650 author:Yong Cheng, Shiqi Shen, Zhongjun He, Wei He, Hua Wu, Maosong Sun, Yang Liu category:cs.CL  published:2015-12-15 summary:The attentional mechanism has proven to be effective in improving end-to-end neural machine translation. However, due to the intricate structural divergence between natural languages, unidirectional attention-based models might only capture partial aspects of attentional regularities. We propose agreement-based joint training for bidirectional attention-based end-to-end neural machine translation. Instead of training source-to-target and target-to-source translation models independently,our approach encourages the two complementary models to agree on word alignment matrices on the same training data. Experiments on Chinese-English and English-French translation tasks show that agreement-based joint training significantly improves both alignment and translation quality over independent training. version:2
arxiv-1601-02129 | Temporal Action Localization in Untrimmed Videos via Multi-stage CNNs | http://arxiv.org/abs/1601.02129 | id:1601.02129 author:Zheng Shou, Dongang Wang, Shih-Fu Chang category:cs.CV  published:2016-01-09 summary:We address temporal action localization in untrimmed long videos. This is important because videos in real applications are usually unconstrained and contain multiple action instances plus video content of background scenes or other activities. To address this challenging issue, we exploit the effectiveness of deep networks in temporal action localization via three segment-based 3D ConvNets: (1) a proposal network identifies candidate segments in a long video that may contain actions; (2) a classification network learns one-vs-all action classification model to serve as initialization for the localization network; and (3) a localization network fine-tunes on the learned classification network to localize each action instance. We propose a novel loss function for the localization network to explicitly consider temporal overlap and therefore achieve high temporal localization accuracy. Only the proposal network and the localization network are used during prediction. On two large-scale benchmarks, our approach achieves significantly superior performances compared with other state-of-the-art systems: mAP increases from 1.7% to 7.4% on MEXaction2 and increases from 15.0% to 19.0% on THUMOS 2014, when the overlap threshold for evaluation is set to 0.5. version:2
arxiv-1511-04512 | Zero-Shot Learning via Joint Latent Similarity Embedding | http://arxiv.org/abs/1511.04512 | id:1511.04512 author:Ziming Zhang, Venkatesh Saligrama category:cs.CV  published:2015-11-14 summary:Zero-shot recognition (ZSR) deals with the problem of predicting class labels for target domain instances based on source domain side information (e.g. attributes) of unseen classes. We formulate ZSR as a binary prediction problem. Our resulting classifier is class-independent. It takes an arbitrary pair of source and target domain instances as input and predicts whether or not they come from the same class, i.e. whether there is a match. We model the posterior probability of a match since it is a sufficient statistic and propose a latent probabilistic model in this context. We develop a joint discriminative learning framework based on dictionary learning to jointly learn the parameters of our model for both domains, which ultimately leads to our class-independent classifier. Many of the existing embedding methods can be viewed as special cases of our probabilistic model. On ZSR our method shows 4.90\% improvement over the state-of-the-art in accuracy averaged across four benchmark datasets. We also adapt ZSR method for zero-shot retrieval and show 22.45\% improvement accordingly in mean average precision (mAP). version:2
arxiv-1604-06506 | Online Action Detection | http://arxiv.org/abs/1604.06506 | id:1604.06506 author:Roeland De Geest, Efstratios Gavves, Amir Ghodrati, Zhenyang Li, Cees Snoek, Tinne Tuytelaars category:cs.CV  published:2016-04-21 summary:In online action detection, the goal is to detect the start of an action in a video stream as soon as it happens. For instance, if a child is chasing a ball, an autonomous car should recognize what is going on and respond immediately. This is a very challenging problem for four reasons. First, only partial actions are observed. Second, there is a large variability in negative data. Third, the start of the action is unknown, so it is unclear over what time window the information should be integrated. Finally, in real world data, large within-class variability exists. This problem has been addressed before, but only to some extent. Our contributions to online action detection are threefold. First, we introduce a realistic dataset composed of 27 episodes from 6 popular TV series. The dataset spans over 16 hours of footage annotated with 30 action classes, totaling about 5,000 action instances. Second, we analyze and compare various baseline methods, showing this is a challenging problem for which none of the methods provides a good solution. Third, we analyze the change in performance when there is a variation in viewpoint, occlusion, truncation, etc. We introduce an evaluation protocol for fair comparison. The dataset, the baselines and the models will all be made publicly available to encourage further research on online action detection on realistic data. version:1
arxiv-1512-01563 | State of the Art Control of Atari Games Using Shallow Reinforcement Learning | http://arxiv.org/abs/1512.01563 | id:1512.01563 author:Yitao Liang, Marlos C. Machado, Erik Talvitie, Michael Bowling category:cs.LG  published:2015-12-04 summary:The recently introduced Deep Q-Networks (DQN) algorithm has gained attention as one of the first successful combinations of deep neural networks and reinforcement learning. Its promise was demonstrated in the Arcade Learning Environment (ALE), a challenging framework composed of dozens of Atari 2600 games used to evaluate general competency in AI. It achieved dramatically better results than earlier approaches, showing that its ability to learn good representations is quite robust and general. This paper attempts to understand the principles that underlie DQN's impressive performance and to better contextualize its success. We systematically evaluate the importance of key representational biases encoded by DQN's network by proposing simple linear representations that make use of these concepts. Incorporating these characteristics, we obtain a computationally practical feature set that achieves competitive performance to DQN in the ALE. Besides offering insight into the strengths and weaknesses of DQN, we provide a generic representation for the ALE, significantly reducing the burden of learning a representation for each game. Moreover, we also provide a simple, reproducible benchmark for the sake of comparison to future work in the ALE. version:2
arxiv-1511-04524 | Efficient Training of Very Deep Neural Networks for Supervised Hashing | http://arxiv.org/abs/1511.04524 | id:1511.04524 author:Ziming Zhang, Yuting Chen, Venkatesh Saligrama category:cs.CV cs.LG cs.NE  published:2015-11-14 summary:In this paper, we propose training very deep neural networks (DNNs) for supervised learning of hash codes. Existing methods in this context train relatively "shallow" networks limited by the issues arising in back propagation (e.e. vanishing gradients) as well as computational efficiency. We propose a novel and efficient training algorithm inspired by alternating direction method of multipliers (ADMM) that overcomes some of these limitations. Our method decomposes the training process into independent layer-wise local updates through auxiliary variables. Empirically we observe that our training algorithm always converges and its computational complexity is linearly proportional to the number of edges in the networks. Empirically we manage to train DNNs with 64 hidden layers and 1024 nodes per layer for supervised hashing in about 3 hours using a single GPU. Our proposed very deep supervised hashing (VDSH) method significantly outperforms the state-of-the-art on several benchmark datasets. version:2
arxiv-1604-06498 | Stabilized Sparse Online Learning for Sparse Data | http://arxiv.org/abs/1604.06498 | id:1604.06498 author:Yuting Ma, Tian Zheng category:stat.ML cs.LG  published:2016-04-21 summary:Stochastic gradient descent (SGD) is commonly used for optimization in large-scale machine learning problems. Langford et al. (2009) introduce a sparse online learning method to induce sparsity via truncated gradient. With high-dimensional sparse data, however, the method suffers from slow convergence and high variance due to the heterogeneity in feature sparsity. To mitigate this issue, we introduce a stabilized truncated stochastic gradient descent algorithm. We employ a soft-thresholding scheme on the weight vector where the imposed shrinkage is adaptive to the amount of information available in each feature. The variability in the resulted sparse weight vector is further controlled by stability selection integrated with the informative truncation. To facilitate better convergence, we adopt an annealing strategy on the truncation rate, which leads to a balanced trade-off between exploration and exploitation in learning a sparse weight vector. Numerical experiments show that our algorithm compares favorably with the original algorithm in terms of prediction accuracy, achieved sparsity and stability. version:1
arxiv-1510-00384 | Off-the-Grid Recovery of Piecewise Constant Images from Few Fourier Samples | http://arxiv.org/abs/1510.00384 | id:1510.00384 author:Greg Ongie, Mathews Jacob category:cs.CV  published:2015-10-01 summary:We introduce a method to recover a continuous domain representation of a piecewise constant two-dimensional image from few low-pass Fourier samples. Assuming the edge set of the image is localized to the zero set of a trigonometric polynomial, we show the Fourier coefficients of the partial derivatives of the image satisfy a linear annihilation relation. We present necessary and sufficient conditions for unique recovery of the image from finite low-pass Fourier samples using the annihilation relation. We also propose a practical two-stage recovery algorithm which is robust to model-mismatch and noise. In the first stage we estimate a continuous domain representation of the edge set of the image. In the second stage we perform an extrapolation in Fourier domain by a least squares two-dimensional linear prediction, which recovers the exact Fourier coefficients of the underlying image. We demonstrate our algorithm on the super-resolution recovery of MRI phantoms and real MRI data from low-pass Fourier samples, which shows benefits over standard approaches for single-image super-resolution MRI. version:2
arxiv-1604-06486 | Humans and deep networks largely agree on which kinds of variation make object recognition harder | http://arxiv.org/abs/1604.06486 | id:1604.06486 author:Saeed Reza Kheradpisheh, Masoud Ghodrati, Mohammad Ganjtabesh, Timothée Masquelier category:cs.CV q-bio.NC  published:2016-04-21 summary:View-invariant object recognition is a challenging problem, which has attracted much attention among the psychology, neuroscience, and computer vision communities. Humans are notoriously good at it, even if some variations are presumably more difficult to handle than others (e.g. 3D rotations). Humans are thought to solve the problem through hierarchical processing along the ventral stream, which progressively extracts more and more invariant visual features. This feed-forward architecture has inspired a new generation of bio-inspired computer vision systems called deep convolutional neural networks (DCNN), which are currently the best algorithms for object recognition in natural images. Here, for the first time, we systematically compared human feed-forward vision and DCNNs at view-invariant object recognition using the same images and controlling for both the kinds of transformation as well as their magnitude. We used four object categories and images were rendered from 3D computer models. In total, 89 human subjects participated in 10 experiments in which they had to discriminate between two or four categories after rapid presentation with backward masking. We also tested two recent DCNNs on the same tasks. We found that humans and DCNNs largely agreed on the relative difficulties of each kind of variation: rotation in depth is by far the hardest transformation to handle, followed by scale, then rotation in plane, and finally position. This suggests that humans recognize objects mainly through 2D template matching, rather than by constructing 3D object models, and that DCNNs are not too unreasonable models of human feed-forward vision. Also, our results show that the variation levels in rotation in depth and scale strongly modulate both humans' and DCNNs' recognition performances. We thus argue that these variations should be controlled in the image datasets used in vision research. version:1
arxiv-1604-04004 | Understanding How Image Quality Affects Deep Neural Networks | http://arxiv.org/abs/1604.04004 | id:1604.04004 author:Samuel Dodge, Lina Karam category:cs.CV  published:2016-04-14 summary:Image quality is an important practical challenge that is often overlooked in the design of machine vision systems. Commonly, machine vision systems are trained and tested on high quality image datasets, yet in practical applications the input images can not be assumed to be of high quality. Recently, deep neural networks have obtained state-of-the-art performance on many machine vision tasks. In this paper we provide an evaluation of 4 state-of-the-art deep neural network models for image classification under quality distortions. We consider five types of quality distortions: blur, noise, contrast, JPEG, and JPEG2000 compression. We show that the existing networks are susceptible to these quality distortions, particularly to blur and noise. These results enable future work in developing deep neural networks that are more invariant to quality distortions. version:2
arxiv-1604-06481 | Visual Congruent Ads for Image Search | http://arxiv.org/abs/1604.06481 | id:1604.06481 author:Yannis Kalantidis, Ayman Farahat, Lyndon Kennedy, Ricardo Baeza-Yates, David A. Shamma category:cs.CV cs.HC  published:2016-04-21 summary:The quality of user experience online is affected by the relevance and placement of advertisements. We propose a new system for selecting and displaying visual advertisements in image search result sets. Our method compares the visual similarity of candidate ads to the image search results and selects the most visually similar ad to be displayed. The method further selects an appropriate location in the displayed image grid to minimize the perceptual visual differences between the ad and its neighbors. We conduct an experiment with about 900 users and find that our proposed method provides significant improvement in the users' overall satisfaction with the image search experience, without diminishing the users' ability to see the ad or recall the advertised brand. version:1
arxiv-1604-06480 | LOH and behold: Web-scale visual search, recommendation and clustering using Locally Optimized Hashing | http://arxiv.org/abs/1604.06480 | id:1604.06480 author:Yannis Kalantidis, Lyndon Kennedy, Huy Nguyen, Clayton Mellina, David A. Shamma category:cs.CV cs.IR cs.MM  published:2016-04-21 summary:We present a multimedia system based on a novel matching signature able to perform de-duplucation, search, clustering and visual recommendations in a way that is easily implemented in generic distributed computing environments. Starting from a state-of-the-art algorithm, we propose a novel hashing-based matching system that allow for fast search and is easily implemented in distributed system languages like PIG, as it only requires set intersections and summations to compute. We make the following contributions: a) we propose a novel hashing method for visual search using locally optimized codes that performs on-par with other state-of-the-art hashing approaches but offers more flexibility in terms of ranking, b) we extend our matching framework to multiple image queries and provide a simple and scalable solution that can efficiently produce visual recommendations for query sets of thousands of images and cluster collections of hundreds of millions of images, c) we show that this same representation can be used for efficient de-duplication of image search results, performing better than traditional hashing approaches, while still requiring only a few milliseconds to run. In this paper we display results on datasets of up to 100 Million images, but in practice our system can find and rank similar images for millions of users from a search set of hundreds of millions of images in a runtime on the order of one hour on a large Hadoop cluster. version:1
arxiv-1604-06474 | On Detection and Structural Reconstruction of Small-World Random Networks | http://arxiv.org/abs/1604.06474 | id:1604.06474 author:T. Tony Cai, Tengyuan Liang, Alexander Rakhlin category:math.ST cs.LG stat.TH  published:2016-04-21 summary:In this paper, we study detection and fast reconstruction of the celebrated Watts-Strogatz (WS) small-world random graph model \citep{watts1998collective} which aims to describe real-world complex networks that exhibit both high clustering and short average length properties. The WS model with neighborhood size $k$ and rewiring probability probability $\beta$ can be viewed as a continuous interpolation between a deterministic ring lattice graph and the Erd\H{o}s-R\'{e}nyi random graph. We study both the computational and statistical aspects of detecting the deterministic ring lattice structure (or local geographical links, strong ties) in the presence of random connections (or long range links, weak ties), and for its recovery. The phase diagram in terms of $(k,\beta)$ is partitioned into several regions according to the difficulty of the problem. We propose distinct methods for the various regions. version:1
arxiv-1604-06443 | Robust Estimators in High Dimensions without the Computational Intractability | http://arxiv.org/abs/1604.06443 | id:1604.06443 author:Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, Alistair Stewart category:cs.DS cs.IT cs.LG math.IT math.ST stat.ML stat.TH  published:2016-04-21 summary:We study high-dimensional distribution learning in an agnostic setting where an adversary is allowed to arbitrarily corrupt an $\varepsilon$-fraction of the samples. Such questions have a rich history spanning statistics, machine learning and theoretical computer science. Even in the most basic settings, the only known approaches are either computationally inefficient or lose dimension-dependent factors in their error guarantees. This raises the following question:Is high-dimensional agnostic distribution learning even possible, algorithmically? In this work, we obtain the first computationally efficient algorithms with dimension-independent error guarantees for agnostically learning several fundamental classes of high-dimensional distributions: (1) a single Gaussian, (2) a product distribution on the hypercube, (3) mixtures of two product distributions (under a natural balancedness condition), and (4) mixtures of spherical Gaussians. Our algorithms achieve error that is independent of the dimension, and in many cases scales nearly-linearly with the fraction of adversarially corrupted samples. Moreover, we develop a general recipe for detecting and correcting corruptions in high-dimensions, that may be applicable to many other problems. version:1
arxiv-1604-06427 | Analysis of the Entropy-guided Switching Trimmed Mean Deviation-based Anisotropic Diffusion filter | http://arxiv.org/abs/1604.06427 | id:1604.06427 author:Uche A. Nnolim category:cs.CV  published:2016-04-21 summary:This report describes the experimental analysis of a proposed switching filter-anisotropic diffusion hybrid for the filtering of the fixed value (salt and pepper) impulse noise (FVIN). The filter works well at both low and high noise densities though it was specifically designed for high noise density levels. The filter combines the switching mechanism of decision-based filters and the partial differential equation-based formulation to yield a powerful system capable of recovering the image signals at very high noise levels. Experimental results indicate that the filter surpasses other filters, especially at very high noise levels. Additionally, its adaptive nature ensures that the performance is guided by the metrics obtained from the noisy input image. The filter algorithm is of both global and local nature, where the former is chosen to reduce computation time and complexity, while the latter is used for best results. version:1
arxiv-1601-02522 | Stationary signal processing on graphs | http://arxiv.org/abs/1601.02522 | id:1601.02522 author:Nathanaël Perraudin, Pierre Vandergheynst category:cs.DS stat.AP stat.ML  published:2016-01-11 summary:Graphs are a central tool in machine learning and information processing as they allow to conveniently capture the structure of complex datasets. In this context, it is of high importance to develop flexible models of signals defined over graphs or networks. In this paper, we generalize the traditional concept of wide sense stationarity to signals defined over the vertices of arbitrary weighted undirected graphs. We show that stationarity is intimately linked to statistical invariance under a localization operator reminiscent of translation. We prove that stationary graph signals are characterized by a well-defined Power Spectral Density that can be efficiently estimated even for large graphs. We leverage this new concept to derive Wiener-type estimation procedures of noisy and partially observed signals and illustrate the performance of this new model for denoising and regression. version:3
arxiv-1511-03908 | Learning Human Identity from Motion Patterns | http://arxiv.org/abs/1511.03908 | id:1511.03908 author:Natalia Neverova, Christian Wolf, Griffin Lacey, Lex Fridman, Deepak Chandra, Brandon Barbello, Graham Taylor category:cs.LG cs.CV cs.NE  published:2015-11-12 summary:We present a large-scale study exploring the capability of temporal deep neural networks to interpret natural human kinematics and introduce the first method for active biometric authentication with mobile inertial sensors. At Google, we have created a first-of-its-kind dataset of human movements, passively collected by 1500 volunteers using their smartphones daily over several months. We (1) compare several neural architectures for efficient learning of temporal multi-modal data representations, (2) propose an optimized shift-invariant dense convolutional mechanism (DCWRNN), and (3) incorporate the discriminatively-trained dynamic features in a probabilistic generative framework taking into account temporal characteristics. Our results demonstrate that human kinematics convey important information about user identity and can serve as a valuable component of multi-modal authentication systems. version:4
arxiv-1604-06361 | Row-less Universal Schema | http://arxiv.org/abs/1604.06361 | id:1604.06361 author:Patrick Verga, Andrew McCallum category:cs.CL  published:2016-04-21 summary:Universal schema jointly embeds knowledge bases and textual patterns to reason about entities and relations for automatic knowledge base construction and information extraction. In the past, entity pairs and relations were represented as learned vectors with compatibility determined by a scoring function, limiting generalization to unseen text patterns and entities. Recently, 'column-less' versions of Universal Schema have used compositional pattern encoders to generalize to all text patterns. In this work we take the next step and propose a 'row-less' model of universal schema, removing explicit entity pair representations. Instead of learning vector representations for each entity pair in our training set, we treat an entity pair as a function of its relation types. In experimental results on the FB15k-237 benchmark we demonstrate that we can match the performance of a comparable model with explicit entity pair representations using a model of attention over relation types. We further demonstrate that the model per- forms with nearly the same accuracy on entity pairs never seen during training. version:1
arxiv-1604-06338 | Robust Audio Event Recognition with 1-Max Pooling Convolutional Neural Networks | http://arxiv.org/abs/1604.06338 | id:1604.06338 author:Huy Phan, Lars Hertel, Marco Maass, Alfred Mertins category:cs.NE cs.LG cs.SD  published:2016-04-21 summary:We present in this paper a simple, yet efficient convolutional neural network (CNN) architecture for robust audio event recognition. Opposing to deep CNN architectures with multiple convolutional and pooling layers topped up with multiple fully connected layers, the proposed network consists of only three layers: convolutional, pooling, and softmax layer. It has two features to be distinguishable from the deep architectures that have been proposed for the task: varying-size convolutional filters at the convolutional layer and 1-max pooling scheme at the pooling layer. In intuition, the network tends to select the most discriminative features from the whole audio signals for recognition. Our proposed CNN not only shows state-of-the-art performance on the standard task of robust audio event recognition but also outperforms other deep architectures up to 4.5% in terms of recognition accuracy, which is equivalent to 76.3% relative error reduction. version:1
arxiv-1604-06335 | Markov models for ocular fixation locations in the presence and absence of colour | http://arxiv.org/abs/1604.06335 | id:1604.06335 author:Adam B. Kashlak, Eoin Devane, Helge Dietert, Henry Jackson category:stat.AP stat.ML  published:2016-04-21 summary:We propose to model the fixation locations of the human eye when observing a still image by a Markovian point process in R 2 . Our approach is data driven using k-means clustering of the fixation locations to identify distinct salient regions of the image, which in turn correspond to the states of our Markov chain. Bayes factors are computed as model selection criterion to determine the number of clusters. Furthermore, we demonstrate that the behaviour of the human eye differs from this model when colour information is removed from the given image. version:1
arxiv-1604-05213 | Non-contact hemodynamic imaging reveals the jugular venous pulse waveform | http://arxiv.org/abs/1604.05213 | id:1604.05213 author:Robert Amelard, Richard L Hughson, Danielle K Greaves, Kaylen J Pfisterer, Jason Leung, David A Clausi, Alexander Wong category:physics.med-ph cs.CV physics.optics  published:2016-04-15 summary:Cardiovascular monitoring is important to prevent diseases from progressing. The jugular venous pulse (JVP) waveform offers important clinical information about cardiac health, but is not routinely examined due to its invasive catheterisation procedure. Here, we demonstrate for the first time that the JVP can be consistently observed in a non-contact manner using a novel light-based photoplethysmographic imaging system, coded hemodynamic imaging (CHI). While traditional monitoring methods measure the JVP at a single location, CHI's wide-field imaging capabilities were able to observe the jugular venous pulse's spatial flow profile for the first time. The important inflection points in the JVP were observed, meaning that cardiac abnormalities can be assessed through JVP distortions. CHI provides a new way to assess cardiac health through non-contact light-based JVP monitoring, and can be used in non-surgical environments for cardiac assessment. version:2
arxiv-1508-01217 | Bayesian Approximate Kernel Regression with Variable Selection | http://arxiv.org/abs/1508.01217 | id:1508.01217 author:Lorin Crawford, Kris C. Wood, Xiang Zhou, Sayan Mukherjee category:stat.ME q-bio.QM stat.AP stat.ML  published:2015-08-05 summary:Nonlinear kernel regression models are often used in statistics and machine learning due to greater accuracy than linear models. Variable selection for kernel regression models is a challenge partly because, unlike the linear regression setting, there is no clear concept of an effect size for regression coefficients. In this paper, we propose a novel framework that provides an analog of the effect size of each explanatory variable for Bayesian kernel regression models when the kernel is shift-invariant---for example the Gaussian kernel. We use function analytic properties of shift-invariant reproducing kernel Hilbert spaces (RKHS) to define a linear vector space that (1) captures nonlinear structure and (2) can be projected onto the original explanatory variables. The projection onto the original explanatory variables serves as the analog of effect sizes. The specific function analytic property we use is that shift-invariant kernel functions can be approximated via random Fourier bases. Based on the random Fourier expansion we propose a computationally efficient class of Bayesian approximate kernel regression (BAKR) models for both nonlinear regression and binary classification for which one can compute an analog of effect sizes. By adapting some classical results in compressive sensing we state conditions under which BAKR can recover a sparse set of effect sizes, simultaneous variable selection and regression. We illustrate the utility of BAKR by examining, in some detail, two important problems in statistical genetics: genomic selection (predicting phenotype from genotype) and association mapping (inference of significant variables or loci). State-of-the-art methods for genomic selection and association mapping are based on kernel regression and linear models, respectively. BAKR is the first method that is competitive in both settings. version:2
arxiv-1604-06318 | TI-POOLING: transformation-invariant pooling for feature learning in Convolutional Neural Networks | http://arxiv.org/abs/1604.06318 | id:1604.06318 author:Dmitry Laptev, Nikolay Savinov, Joachim M. Buhmann, Marc Pollefeys category:cs.CV  published:2016-04-21 summary:In this paper we present a deep neural network topology that incorporates a simple to implement transformation invariant pooling operator (TI-POOLING). This operator is able to efficiently handle prior knowledge on nuisance variations in the data, such as rotation or scale changes. Most current methods usually make use of dataset augmentation to address this issue, but this requires larger number of model parameters and more training data, and results in significantly increased training time and larger chance of under- or overfitting. The main reason for these drawbacks is that the learned model needs to capture adequate features for all the possible transformations of the input. On the other hand, we formulate features in convolutional neural networks to be transformation-invariant. We achieve that using parallel siamese architectures for the considered transformation set and applying the TI-POOLING operator on their outputs before the fully-connected layers. We show that this topology internally finds the most optimal "canonical" instance of the input image for training and therefore limits the redundancy in learned features. This more efficient use of training data results in better performance on popular benchmark datasets with smaller number of parameters when comparing to standard convolutional neural networks with dataset augmentation and to other baselines. version:1
arxiv-1604-06285 | A Novel Approach to Dropped Pronoun Translation | http://arxiv.org/abs/1604.06285 | id:1604.06285 author:Longyue Wang, Zhaopeng Tu, Xiaojun Zhang, Hang Li, Andy Way, Qun Liu category:cs.CL  published:2016-04-21 summary:Dropped Pronouns (DP) in which pronouns are frequently dropped in the source language but should be retained in the target language are challenge in machine translation. In response to this problem, we propose a semi-supervised approach to recall possibly missing pronouns in the translation. Firstly, we build training data for DP generation in which the DPs are automatically labelled according to the alignment information from a parallel corpus. Secondly, we build a deep learning-based DP generator for input sentences in decoding when no corresponding references exist. More specifically, the generation is two-phase: (1) DP position detection, which is modeled as a sequential labelling task with recurrent neural networks; and (2) DP prediction, which employs a multilayer perceptron with rich features. Finally, we integrate the above outputs into our translation system to recall missing pronouns by both extracting rules from the DP-labelled training data and translating the DP-generated input sentences. Experimental results show that our approach achieves a significant improvement of 1.58 BLEU points in translation performance with 66% F-score for DP generation accuracy. version:1
arxiv-1604-06274 | Chinese Song Iambics Generation with Neural Attention-based Model | http://arxiv.org/abs/1604.06274 | id:1604.06274 author:Qixin Wang, Tianyi Luo, Dong Wang, Chao Xing category:cs.CL  published:2016-04-21 summary:Learning and generating Chinese poems is a charming yet challenging task. Traditional approaches involve various language modeling and machine translation techniques, however, they perform not as well when generating poems with complex pattern constraints, for example Song iambics, a famous type of poems that involve variable-length sentences and strict rhythmic patterns. This paper applies the attention-based sequence-to-sequence model to generate Chinese Song iambics. Specifically, we encode the cue sentences by a bi-directional Long-Short Term Memory (LSTM) model and then predict the entire iambic with the information provided by the encoder, in the form of an attention-based LSTM that can regularize the generation process by the fine structure of the input cues. Several techniques are investigated to improve the model, including global context integration, hybrid style training, character vector initialization and adaptation. Both the automatic and subjective evaluation results show that our model indeed can learn the complex structural and rhythmic patterns of Song iambics, and the generation is rather successful. version:1
arxiv-1604-06258 | Automatic 3D Reconstruction of Manifold Meshes via Delaunay Triangulation and Mesh Sweeping | http://arxiv.org/abs/1604.06258 | id:1604.06258 author:Andrea Romanoni, Amaël Delaunoy, Marc Pollefeys, Matteo Matteucci category:cs.CV  published:2016-04-21 summary:In this paper we propose a new approach to incrementally initialize a manifold surface for automatic 3D reconstruction from images. More precisely we focus on the automatic initialization of a 3D mesh as close as possible to the final solution; indeed many approaches require a good initial solution for further refinement via multi-view stereo techniques. Our novel algorithm automatically estimates an initial manifold mesh for surface evolving multi-view stereo algorithms, where the manifold property needs to be enforced. It bootstraps from 3D points extracted via Structure from Motion, then iterates between a state-of-the-art manifold reconstruction step and a novel mesh sweeping algorithm that looks for new 3D points in the neighborhood of the reconstructed manifold to be added in the manifold reconstruction. The experimental results show quantitatively that the mesh sweeping improves the resolution and the accuracy of the manifold reconstruction, allowing a better convergence of state-of-the-art surface evolution multi-view stereo algorithms. version:1
arxiv-1512-08808 | Sparse group factor analysis for biclustering of multiple data sources | http://arxiv.org/abs/1512.08808 | id:1512.08808 author:Kerstin Bunte, Eemeli Leppäaho, Inka Saarinen, Samuel Kaski category:cs.LG cs.IR stat.ML  published:2015-12-29 summary:Motivation: Modelling methods that find structure in data are necessary with the current large volumes of genomic data, and there have been various efforts to find subsets of genes exhibiting consistent patterns over subsets of treatments. These biclustering techniques have focused on one data source, often gene expression data. We present a Bayesian approach for joint biclustering of multiple data sources, extending a recent method Group Factor Analysis (GFA) to have a biclustering interpretation with additional sparsity assumptions. The resulting method enables data-driven detection of linear structure present in parts of the data sources. Results: Our simulation studies show that the proposed method reliably infers bi-clusters from heterogeneous data sources. We tested the method on data from the NCI-DREAM drug sensitivity prediction challenge, resulting in an excellent prediction accuracy. Moreover, the predictions are based on several biclusters which provide insight into the data sources, in this case on gene expression, DNA methylation, protein abundance, exome sequence, functional connectivity fingerprints and drug sensitivity. version:2
arxiv-1604-06243 | Evaluation of the Effect of Improper Segmentation on Word Spotting | http://arxiv.org/abs/1604.06243 | id:1604.06243 author:Sounak Dey, Anguelos Nicolaou, Josep Llados, Umapada Pal category:cs.CV  published:2016-04-21 summary:Word spotting is an important recognition task in historical document analysis. In most cases methods are developed and evaluated assuming perfect word segmentations. In this paper we propose an experimental framework to quantify the effect of goodness of word segmentation has on the performance achieved by word spotting methods in identical unbiased conditions. The framework consists of generating systematic distortions on segmentation and retrieving the original queries from the distorted dataset. We apply the framework on the George Washington and Barcelona Marriage Dataset and on several established and state-of-the-art methods. The experiments allow for an estimate of the end-to-end performance of word spotting methods. version:1
arxiv-1511-06522 | Integrating Deep Features for Material Recognition | http://arxiv.org/abs/1511.06522 | id:1511.06522 author:Yan Zhang, Mete Ozay, Xing Liu, Takayuki Okatani category:cs.CV cs.LG  published:2015-11-20 summary:We propose a method for integration of features extracted using deep representations of Convolutional Neural Networks (CNNs) each of which is learned using a different image dataset of objects and materials for material recognition. Given a set of representations of multiple pre-trained CNNs, we first compute activations of features using the representations on the images to select a set of samples which are best represented by the features. Then, we measure the uncertainty of the features by computing the entropy of class distributions for each sample set. Finally, we compute the contribution of each feature to representation of classes for feature selection and integration. We examine the proposed method on three benchmark datasets for material recognition. Experimental results show that the proposed method achieves state-of-the-art performance by integrating deep features. Additionally, we introduce a new material dataset called EFMD by extending Flickr Material Database (FMD). By the employment of the EFMD with transfer learning for updating the learned CNN models, we achieve 84.0%+/-1.8% accuracy on the FMD dataset which is close to human performance that is 84.9%. version:6
arxiv-1604-05907 | Local Binary Pattern for Word Spotting in Handwritten Historical Document | http://arxiv.org/abs/1604.05907 | id:1604.05907 author:Sounak Dey, Anguelos Nicolaou, Josep Llados, Umapada Pal category:cs.CV  published:2016-04-20 summary:Digital libraries store images which can be highly degraded and to index this kind of images we resort to word spot- ting as our information retrieval system. Information retrieval for handwritten document images is more challenging due to the difficulties in complex layout analysis, large variations of writing styles, and degradation or low quality of historical manuscripts. This paper presents a simple innovative learning-free method for word spotting from large scale historical documents combining Local Binary Pattern (LBP) and spatial sampling. This method offers three advantages: firstly, it operates in completely learning free paradigm which is very different from unsupervised learning methods, secondly, the computational time is significantly low because of the LBP features which are very fast to compute, and thirdly, the method can be used in scenarios where annotations are not available. Finally we compare the results of our proposed retrieval method with the other methods in the literature. version:2
arxiv-1511-03855 | Feature Learning based Deep Supervised Hashing with Pairwise Labels | http://arxiv.org/abs/1511.03855 | id:1511.03855 author:Wu-Jun Li, Sheng Wang, Wang-Cheng Kang category:cs.LG cs.CV H.3.1  published:2015-11-12 summary:Recent years have witnessed wide application of hashing for large-scale image retrieval. However, most existing hashing methods are based on hand-crafted features which might not be optimally compatible with the hashing procedure. Recently, deep hashing methods have been proposed to perform simultaneous feature learning and hash-code learning with deep neural networks, which have shown better performance than traditional hashing methods with hand-crafted features. Most of these deep hashing methods are supervised whose supervised information is given with triplet labels. For another common application scenario with pairwise labels, there have not existed methods for simultaneous feature learning and hash-code learning. In this paper, we propose a novel deep hashing method, called deep pairwise-supervised hashing(DPSH), to perform simultaneous feature learning and hash-code learning for applications with pairwise labels. Experiments on real datasets show that our DPSH method can outperform other methods to achieve the state-of-the-art performance in image retrieval applications. version:2
arxiv-1604-06225 | OCR Error Correction Using Character Correction and Feature-Based Word Classification | http://arxiv.org/abs/1604.06225 | id:1604.06225 author:Ido Kissos, Nachum Dershowitz category:cs.IR cs.CL  published:2016-04-21 summary:This paper explores the use of a learned classifier for post-OCR text correction. Experiments with the Arabic language show that this approach, which integrates a weighted confusion matrix and a shallow language model, improves the vast majority of segmentation and recognition errors, the most frequent types of error on our dataset. version:1
arxiv-1604-06195 | Articulated Hand Pose Estimation Review | http://arxiv.org/abs/1604.06195 | id:1604.06195 author:Emad Barsoum category:cs.CV  published:2016-04-21 summary:With the increase number of companies focusing on commercializing Augmented Reality (AR), Virtual Reality (VR) and wearable devices, the need for a hand based input mechanism is becoming essential in order to make the experience natural, seamless and immersive. Hand pose estimation has progressed drastically in recent years due to the introduction of commodity depth cameras. Hand pose estimation based on vision is still a challenging problem due to its complexity from self-occlusion (between fingers), close similarity between fingers, dexterity of the hands, speed of the pose and the high dimension of the hand kinematic parameters. Articulated hand pose estimation is still an open problem and under intensive research from both academia and industry. The 2 approaches used for hand pose estimation are: discriminative and generative. Generative approach is a model based that tries to fit a hand model to the observed data. Discriminative approach is appearance based, usually implemented with machine learning (ML) and require a large amount of training data. Recent hand pose estimation uses hybrid approach by combining both discriminative and generative methods into a single hand pipeline. In this paper, we focus on reviewing recent progress of hand pose estimation from depth sensor. We will survey discriminative methods, generative methods and hybrid methods. This paper is not a comprehensive review of all hand pose estimation techniques, it is a subset of some of the recent state-of-the-art techniques. version:1
arxiv-1604-06194 | Dynamic matrix factorization with social influence | http://arxiv.org/abs/1604.06194 | id:1604.06194 author:Aleksandr Y. Aravkin, Kush R. Varshney, Liu Yang category:stat.ML cs.IR cs.SI math.OC  published:2016-04-21 summary:Matrix factorization is a key component of collaborative filtering-based recommendation systems because it allows us to complete sparse user-by-item ratings matrices under a low-rank assumption that encodes the belief that similar users give similar ratings and that similar items garner similar ratings. This paradigm has had immeasurable practical success, but it is not the complete story for understanding and inferring the preferences of people. First, peoples' preferences and their observable manifestations as ratings evolve over time along general patterns of trajectories. Second, an individual person's preferences evolve over time through influence of their social connections. In this paper, we develop a unified process model for both types of dynamics within a state space approach, together with an efficient optimization scheme for estimation within that model. The model combines elements from recent developments in dynamic matrix factorization, opinion dynamics and social learning, and trust-based recommendation. The estimation builds upon recent advances in numerical nonlinear optimization. Empirical results on a large-scale data set from the Epinions website demonstrate consistent reduction in root mean squared error by consideration of the two types of dynamics. version:1
arxiv-1604-05781 | What we write about when we write about causality: Features of causal statements across large-scale social discourse | http://arxiv.org/abs/1604.05781 | id:1604.05781 author:Thomas C. McAndrew, Joshua C. Bongard, Christopher M. Danforth, Peter S. Dodds, Paul D. H. Hines, James P. Bagrow category:cs.CY cs.CL cs.SI  published:2016-04-20 summary:Identifying and communicating relationships between causes and effects is important for understanding our world, but is affected by language structure, cognitive and emotional biases, and the properties of the communication medium. Despite the increasing importance of social media, much remains unknown about causal statements made online. To study real-world causal attribution, we extract a large-scale corpus of causal statements made on the Twitter social network platform as well as a comparable random control corpus. We compare causal and control statements using statistical language and sentiment analysis tools. We find that causal statements have a number of significant lexical and grammatical differences compared with controls and tend to be more negative in sentiment than controls. Causal statements made online tend to focus on news and current events, medicine and health, or interpersonal relationships, as shown by topic models. By quantifying the features and potential biases of causality communication, this study improves our understanding of the accuracy of information and opinions found online. version:2
arxiv-1604-06187 | Evolutionary Image Transition Based on Theoretical Insights of Random Processes | http://arxiv.org/abs/1604.06187 | id:1604.06187 author:Aneta Neumann, Bradley Alexander, Frank Neumann category:cs.NE  published:2016-04-21 summary:Evolutionary algorithms have been widely studied from a theoretical perspective. In particular, the area of runtime analysis has contributed significantly to a theoretical understanding and provided insights into the working behaviour of these algorithms. We study how these insights into evolutionary processes can be used for evolutionary art. We introduce the notion of evolutionary image transition which transfers a given starting image into a target image through an evolutionary process. Combining standard mutation effects known from the optimization of the classical benchmark function OneMax and different variants of random walks, we present ways of performing evolutionary image transition with different artistic effects. version:1
arxiv-1604-06182 | The THUMOS Challenge on Action Recognition for Videos "in the Wild" | http://arxiv.org/abs/1604.06182 | id:1604.06182 author:Haroon Idrees, Amir R. Zamir, Yu-Gang Jiang, Alex Gorban, Ivan Laptev, Rahul Sukthankar, Mubarak Shah category:cs.CV  published:2016-04-21 summary:Automatically recognizing and localizing wide ranges of human actions has crucial importance for video understanding. Towards this goal, the THUMOS challenge was introduced in 2013 to serve as a benchmark for action recognition. Until then, video action recognition, including THUMOS challenge, had focused primarily on the classification of pre-segmented (i.e., trimmed) videos, which is an artificial task. In THUMOS 2014, we elevated action recognition to a more practical level by introducing temporally untrimmed videos. These also include `background videos' which share similar scenes and backgrounds as action videos, but are devoid of the specific actions. The three editions of the challenge organized in 2013--2015 have made THUMOS a common benchmark for action classification and detection and the annual challenge is widely attended by teams from around the world. In this paper we describe the THUMOS benchmark in detail and give an overview of data collection and annotation procedures. We present the evaluation protocols used to quantify results in the two THUMOS tasks of action classification and temporal detection. We also present results of submissions to the THUMOS 2015 challenge and review the participating approaches. Additionally, we include a comprehensive empirical study evaluating the differences in action recognition between trimmed and untrimmed videos, and how well methods trained on trimmed videos generalize to untrimmed videos. We conclude by proposing several directions and improvements for future THUMOS challenges. version:1
arxiv-1604-06154 | Deep Adaptive Network: An Efficient Deep Neural Network with Sparse Binary Connections | http://arxiv.org/abs/1604.06154 | id:1604.06154 author:Xichuan Zhou, Shengli Li, Kai Qin, Kunping Li, Fang Tang, Shengdong Hu, Shujun Liu, Zhi Lin category:cs.LG cs.CV cs.NE  published:2016-04-21 summary:Deep neural networks are state-of-the-art models for understanding the content of images, video and raw input data. However, implementing a deep neural network in embedded systems is a challenging task, because a typical deep neural network, such as a Deep Belief Network using 128x128 images as input, could exhaust Giga bytes of memory and result in bandwidth and computing bottleneck. To address this challenge, this paper presents a hardware-oriented deep learning algorithm, named as the Deep Adaptive Network, which attempts to exploit the sparsity in the neural connections. The proposed method adaptively reduces the weights associated with negligible features to zero, leading to sparse feedforward network architecture. Furthermore, since the small proportion of important weights are significantly larger than zero, they can be robustly thresholded and represented using single-bit integers (-1 and +1), leading to implementations of deep neural networks with sparse and binary connections. Our experiments showed that, for the application of recognizing MNIST handwritten digits, the features extracted by a two-layer Deep Adaptive Network with about 25% reserved important connections achieved 97.2% classification accuracy, which was almost the same with the standard Deep Belief Network (97.3%). Furthermore, for efficient hardware implementations, the sparse-and-binary-weighted deep neural network could save about 99.3% memory and 99.9% computation units without significant loss of classification accuracy for pattern recognition applications. version:1
arxiv-1604-06153 | Nonextensive information theoretical machine | http://arxiv.org/abs/1604.06153 | id:1604.06153 author:Chaobing Song, Shu-Tao Xia category:cs.LG  published:2016-04-21 summary:In this paper, we propose a new discriminative model named \emph{nonextensive information theoretical machine (NITM)} based on nonextensive generalization of Shannon information theory. In NITM, weight parameters are treated as random variables. Tsallis divergence is used to regularize the distribution of weight parameters and maximum unnormalized Tsallis entropy distribution is used to evaluate fitting effect. On the one hand, it is showed that some well-known margin-based loss functions such as $\ell_{0/1}$ loss, hinge loss, squared hinge loss and exponential loss can be unified by unnormalized Tsallis entropy. On the other hand, Gaussian prior regularization is generalized to Student-t prior regularization with similar computational complexity. The model can be solved efficiently by gradient-based convex optimization and its performance is illustrated on standard datasets. version:1
arxiv-1306-6263 | Persian Heritage Image Binarization Competition (PHIBC 2012) | http://arxiv.org/abs/1306.6263 | id:1306.6263 author:Seyed Morteza Ayatollahi, Hossein Ziaei Nafchi category:cs.CV  published:2013-06-26 summary:The first competition on the binarization of historical Persian documents and manuscripts (PHIBC 2012) has been organized in conjunction with the first Iranian conference on pattern recognition and image analysis (PRIA 2013). The main objective of PHIBC 2012 is to evaluate performance of the binarization methodologies, when applied on the Persian heritage images. This paper provides a report on the methodology and performance of the three submitted algorithms based on evaluation measures has been used. version:2
arxiv-1604-06133 | Embedded all relevant feature selection with Random Ferns | http://arxiv.org/abs/1604.06133 | id:1604.06133 author:Miron Bartosz Kursa category:cs.LG  published:2016-04-20 summary:Many machine learning methods can produce variable importance scores expressing the usability of each feature in context of the produced model; those scores on their own are yet not sufficient to generate feature selection, especially when an all relevant selection is required. Although there are wrapper methods aiming to solve this problem, they introduce a substantial increase in the required computational effort. In this paper I investigate an idea of incorporating all relevant selection within the training process by producing importance for implicitly generated shadows, attributes irrelevant by design. I propose and evaluate such a method in context of random ferns classifier. Experiment results confirm the effectiveness of such approach, although show that fully stochastic nature of random ferns limits its applicability either to small dimensions or as a part of a broader feature selection procedure. version:1
arxiv-1604-03692 | Learning Social Affordance for Human-Robot Interaction | http://arxiv.org/abs/1604.03692 | id:1604.03692 author:Tianmin Shu, M. S. Ryoo, Song-Chun Zhu category:cs.RO cs.AI cs.CV cs.LG  published:2016-04-13 summary:In this paper, we present an approach for robot learning of social affordance from human activity videos. We consider the problem in the context of human-robot interaction: Our approach learns structural representations of human-human (and human-object-human) interactions, describing how body-parts of each agent move with respect to each other and what spatial relations they should maintain to complete each sub-event (i.e., sub-goal). This enables the robot to infer its own movement in reaction to the human body motion, allowing it to naturally replicate such interactions. We introduce the representation of social affordance and propose a generative model for its weakly supervised learning from human demonstration videos. Our approach discovers critical steps (i.e., latent sub-events) in an interaction and the typical motion associated with them, learning what body-parts should be involved and how. The experimental results demonstrate that our Markov Chain Monte Carlo (MCMC) based learning algorithm automatically discovers semantically meaningful interactive affordance from RGB-D videos, which allows us to generate appropriate full body motion for an agent. version:2
arxiv-1604-06119 | Network of Experts for Large-Scale Image Categorization | http://arxiv.org/abs/1604.06119 | id:1604.06119 author:Karim Ahmed, Mohammad Haris Baig, Lorenzo Torresani category:cs.CV  published:2016-04-20 summary:We present a tree-structured network architecture for large-scale image classification. The trunk of the network contains convolutional layers optimized over all classes. At a given depth, the trunk splits into separate branches, each dedicated to discriminate a different subset of classes. Each branch acts as an expert classifying a set of categories that are difficult to tell apart, while the trunk provides common knowledge to all experts in the form of shared features. The training of our "network of experts" is completely end-to-end: the partition of categories into disjoint subsets is learned simultaneously with the parameters of the network trunk and the experts are trained jointly by minimizing a single learning objective over all classes. The proposed structure can be built from any existing convolutional neural network (CNN). We demonstrate its generality by adapting 3 popular CNNs for image categorization into the form of networks of experts. Our experiments on CIFAR100 and ImageNet show that in each case our method yields a substantial improvement in accuracy over the base CNN, and gives the best reported result on CIFAR100. Finally, the improvement in accuracy comes at little additional cost: compared to the base network, the training time of our model is about 1.5X and the number of parameters is comparable or in some cases even lower. version:1
arxiv-1604-06113 | Speaker Cluster-Based Speaker Adaptive Training for Deep Neural Network Acoustic Modeling | http://arxiv.org/abs/1604.06113 | id:1604.06113 author:Wei Chu, Ruxin Chen category:cs.CL  published:2016-04-20 summary:A speaker cluster-based speaker adaptive training (SAT) method under deep neural network-hidden Markov model (DNN-HMM) framework is presented in this paper. During training, speakers that are acoustically adjacent to each other are hierarchically clustered using an i-vector based distance metric. DNNs with speaker dependent layers are then adaptively trained for each cluster of speakers. Before decoding starts, an unseen speaker in test set is matched to the closest speaker cluster through comparing i-vector based distances. The previously trained DNN of the matched speaker cluster is used for decoding utterances of the test speaker. The performance of the proposed method on a large vocabulary spontaneous speech recognition task is evaluated on a training set of with 1500 hours of speech, and a test set of 24 speakers with 1774 utterances. Comparing to a speaker independent DNN with a baseline word error rate of 11.6%, a relative 6.8% reduction in word error rate is observed from the proposed method. version:1
arxiv-1508-00715 | Multi-Modal Bayesian Embeddings for Learning Social Knowledge Graphs | http://arxiv.org/abs/1508.00715 | id:1508.00715 author:Zhilin Yang, Jie Tang, William Cohen category:cs.CL cs.SI  published:2015-08-04 summary:We study the extent to which online social networks can be connected to open knowledge bases. The problem is referred to as learning social knowledge graphs. We propose a multi-modal Bayesian embedding model, GenVector, to learn latent topics that generate word and network embeddings. GenVector leverages large-scale unlabeled data with embeddings and represents data of two modalities---i.e., social network users and knowledge concepts---in a shared latent topic space. Experiments on three datasets show that the proposed method clearly outperforms state-of-the-art methods. We then deploy the method on AMiner, a large-scale online academic search system with a network of 38,049,189 researchers with a knowledge base with 35,415,011 concepts. Our method significantly decreases the error rate in an online A/B test with live users. version:2
arxiv-1604-06083 | Automatic Graphic Logo Detection via Fast Region-based Convolutional Networks | http://arxiv.org/abs/1604.06083 | id:1604.06083 author:Gonçalo Oliveira, Xavier Frazão, André Pimentel, Bernardete Ribeiro category:cs.CV  published:2016-04-20 summary:Brand recognition is a very challenging topic with many useful applications in localization recognition, advertisement and marketing. In this paper we present an automatic graphic logo detection system that robustly handles unconstrained imaging conditions. Our approach is based on Fast Region-based Convolutional Networks (FRCN) proposed by Ross Girshick, which have shown state-of-the-art performance in several generic object recognition tasks (PASCAL Visual Object Classes challenges). In particular, we use two CNN models pre-trained with the ILSVRC ImageNet dataset and we look at the selective search of windows `proposals' in the pre-processing stage and data augmentation to enhance the logo recognition rate. The novelty lies in the use of transfer learning to leverage powerful Convolutional Neural Network models trained with large-scale datasets and repurpose them in the context of graphic logo detection. Another benefit of this framework is that it allows for multiple detections of graphic logos using regions that are likely to have an object. Experimental results with the FlickrLogos-32 dataset show not only the promising performance of our developed models with respect to noise and other transformations a graphic logo can be subject to, but also its superiority over state-of-the-art systems with hand-crafted models and features. version:1
arxiv-1604-06076 | Question Answering via Integer Programming over Semi-Structured Knowledge | http://arxiv.org/abs/1604.06076 | id:1604.06076 author:Daniel Khashabi, Tushar Khot, Ashish Sabharwal, Peter Clark, Oren Etzioni, Dan Roth category:cs.AI cs.CL  published:2016-04-20 summary:Answering science questions posed in natural language is an important AI challenge. Answering such questions often requires non-trivial inference and knowledge that goes beyond factoid retrieval. Yet, most systems for this task are based on relatively shallow Information Retrieval (IR) and statistical correlation techniques operating on large unstructured corpora. We propose a structured inference system for this task, formulated as an Integer Linear Program (ILP), that answers natural language questions using a semi-structured knowledge base derived from text, including questions requiring multi-step inference and a combination of multiple facts. On a dataset of real, unseen science questions, our system significantly outperforms (+14%) the best previous attempt at structured reasoning for this task, which used Markov Logic Networks (MLNs). It also improves upon a previous ILP formulation by 17.7%. When combined with unstructured inference methods, the ILP system significantly boosts overall performance (+10%). Finally, we show our approach is substantially more robust to a simple answer perturbation compared to statistical correlation methods. version:1
arxiv-1403-3142 | ARSENAL: Automatic Requirements Specification Extraction from Natural Language | http://arxiv.org/abs/1403.3142 | id:1403.3142 author:Shalini Ghosh, Daniel Elenius, Wenchao Li, Patrick Lincoln, Natarajan Shankar, Wilfried Steiner category:cs.CL cs.SE  published:2014-03-13 summary:Requirements are informal and semi-formal descriptions of the expected behavior of a complex system from the viewpoints of its stakeholders (customers, users, operators, designers, and engineers). However, for the purpose of design, testing, and verification for critical systems, we can transform requirements into formal models that can be analyzed automatically. ARSENAL is a framework and methodology for systematically transforming natural language (NL) requirements into analyzable formal models and logic specifications. These models can be analyzed for consistency and implementability. The ARSENAL methodology is specialized to individual domains, but the approach is general enough to be adapted to new domains. version:3
arxiv-1603-05296 | Clustering of Sparse and Approximately Sparse Graphs by Semidefinite Programming | http://arxiv.org/abs/1603.05296 | id:1603.05296 author:Aleksis Pirinen, Brendan Ames category:math.OC stat.ML  published:2016-03-16 summary:As a model problem for clustering, we consider the densest k-disjoint-clique problem of partitioning a weighted complete graph into k disjoint subgraphs such that the sum of the densities of these subgraphs is maximized. We establish that such subgraphs can be recovered from the solution of a particular semidefinite relaxation with high probability if the input graph is sampled from a distribution of clusterable graphs. Specifically, the semidefinite relaxation is exact if the graph consists of k large disjoint subgraphs, corresponding to clusters, with weight concentrated within these subgraphs, plus a moderate number of outliers. Further, we establish that if noise is weakly obscuring these clusters, i.e, the between-cluster edges are assigned very small weights, then we can recover significantly smaller clusters. For example, we show that in approximately sparse graphs, where the between-cluster weights tend to zero as the size n of the graph tends to infinity, we can recover clusters of size polylogarithmic in n. Empirical evidence from numerical simulations is also provided to support these theoretical phase transitions to perfect recovery of the cluster structure. version:2
arxiv-1604-06036 | Random Projection Estimation of Discrete-Choice Models with Large Choice Sets | http://arxiv.org/abs/1604.06036 | id:1604.06036 author:Khai X. Chiong, Matthew Shum category:stat.ML  published:2016-04-20 summary:We introduce sparse random projection, an important dimension-reduction tool from machine learning, for the estimation of discrete-choice models with high-dimensional choice sets. Initially, high-dimensional data are compressed into a lower-dimensional Euclidean space using random projections. Subsequently, estimation proceeds using cyclic monotonicity moment inequalities implied by the multinomial choice model; the estimation procedure is semi-parametric and does not require explicit distributional assumptions to be made regarding the random utility errors. The random projection procedure is justified via the Johnson-Lindenstrauss Lemma -- the pairwise distances between data points are preserved during data compression, which we exploit to show convergence of our estimator. The estimator works well in simulations and in an application to a supermarket scanner dataset. version:1
arxiv-1604-06020 | Constructive Preference Elicitation by Setwise Max-margin Learning | http://arxiv.org/abs/1604.06020 | id:1604.06020 author:Stefano Teso, Andrea Passerini, Paolo Viappiani category:stat.ML cs.AI cs.LG 68T05  published:2016-04-20 summary:In this paper we propose an approach to preference elicitation that is suitable to large configuration spaces beyond the reach of existing state-of-the-art approaches. Our setwise max-margin method can be viewed as a generalization of max-margin learning to sets, and can produce a set of "diverse" items that can be used to ask informative queries to the user. Moreover, the approach can encourage sparsity in the parameter space, in order to favor the assessment of utility towards combinations of weights that concentrate on just few features. We present a mixed integer linear programming formulation and show how our approach compares favourably with Bayesian preference elicitation alternatives and easily scales to realistic datasets. version:1
arxiv-1604-05993 | Greedy Criterion in Orthogonal Greedy Learning | http://arxiv.org/abs/1604.05993 | id:1604.05993 author:Lin Xu, Shaobo Lin, Jinshan Zeng, Xia Liu, Zongben Xu category:cs.LG  published:2016-04-20 summary:Orthogonal greedy learning (OGL) is a stepwise learning scheme that starts with selecting a new atom from a specified dictionary via the steepest gradient descent (SGD) and then builds the estimator through orthogonal projection. In this paper, we find that SGD is not the unique greedy criterion and introduce a new greedy criterion, called "$\delta$-greedy threshold" for learning. Based on the new greedy criterion, we derive an adaptive termination rule for OGL. Our theoretical study shows that the new learning scheme can achieve the existing (almost) optimal learning rate of OGL. Plenty of numerical experiments are provided to support that the new scheme can achieve almost optimal generalization performance, while requiring less computation than OGL. version:1
arxiv-1604-05978 | A topological insight into restricted Boltzmann machines | http://arxiv.org/abs/1604.05978 | id:1604.05978 author:Decebal Constantin Mocanu, Elena Mocanu, Phuong H. Nguyen, Madeleine Gibescu, Antonio Liotta category:cs.NE cs.AI cs.SI  published:2016-04-20 summary:Restricted Boltzmann Machines (RBMs) and models derived from them have been successfully used as basic building blocks in deep artificial neural networks for automatic features extraction, unsupervised weights initialization, but also as density estimators. Thus, their generative and discriminative capabilities, but also their computational time are instrumental to a wide range of applications. Our main contribution is to look at RBMs from a topological perspective, bringing insights from network science. Firstly, here we show that RBMs and Gaussian RBMs (GRBMs) are bipartite graphs which naturally have a small-world topology. Secondly, we demonstrate both on synthetic and real-world databases that by constraining RBMs and GRBMs to a scale-free topology (while still considering local neighborhoods and data distribution), we reduce the number of weights that need to be computed by a few orders of magnitude, at virtually no loss in generative performance. Thirdly, we show that, given the same number of weights, our proposed sparse models (which by design have a higher number of hidden neurons) achieve better generative capabilities than standard fully connected RBMs and GRBMs (which by design have a smaller number of hidden neurons) at no additional computational costs. version:1
arxiv-1604-05976 | Computational Drug Repositioning Using Continuous Self-controlled Case Series | http://arxiv.org/abs/1604.05976 | id:1604.05976 author:Zhaobin Kuang, James Thomson, Michael Caldwell, Peggy Peissig, Ron Stewart, David Page category:stat.AP stat.ML  published:2016-04-20 summary:Computational Drug Repositioning (CDR) is the task of discovering potential new indications for existing drugs by mining large-scale heterogeneous drug-related data sources. Leveraging the patient-level temporal ordering information between numeric physiological measurements and various drug prescriptions provided in Electronic Health Records (EHRs), we propose a Continuous Self-controlled Case Series (CSCCS) model for CDR. As an initial evaluation, we look for drugs that can control Fasting Blood Glucose (FBG) level in our experiments. Applying CSCCS to the Marshfield Clinic EHR, well-known drugs that are indicated for controlling blood glucose level are rediscovered. Furthermore, some drugs with recent literature support for the potential effect of blood glucose level control are also identified. version:1
arxiv-1604-02245 | Infrared Colorization Using Deep Convolutional Neural Networks | http://arxiv.org/abs/1604.02245 | id:1604.02245 author:Matthias Limmer, Hendrik P. A. Lensch category:cs.CV cs.GR H.5.1; I.4.8; I.5.1  published:2016-04-08 summary:This paper proposes a method for transferring the RGB color spectrum to near-infrared (NIR) images using deep multi-scale convolutional neural networks. A direct and integrated transfer between NIR and RGB pixels is trained. The trained model does not require any user guidance or a reference image database in the recall phase to produce images with a natural appearance. To preserve the rich details of the NIR image, its high frequency features are transferred to the estimated RGB image. The presented approach is trained and evaluated on a real-world dataset containing a large amount of road scene images in summer. The dataset was captured by a multi-CCD NIR/RGB camera, which ensures a perfect pixel to pixel registration. version:2
arxiv-1604-05933 | Parametric Object Motion from Blur | http://arxiv.org/abs/1604.05933 | id:1604.05933 author:Jochen Gast, Anita Sellent, Stefan Roth category:cs.CV  published:2016-04-20 summary:Motion blur can adversely affect a number of vision tasks, hence it is generally considered a nuisance. We instead treat motion blur as a useful signal that allows to compute the motion of objects from a single image. Drawing on the success of joint segmentation and parametric motion models in the context of optical flow estimation, we propose a parametric object motion model combined with a segmentation mask to exploit localized, non-uniform motion blur. Our parametric image formation model is differentiable w.r.t. the motion parameters, which enables us to generalize marginal-likelihood techniques from uniform blind deblurring to localized, non-uniform blur. A two-stage pipeline, first in derivative space and then in image space, allows to estimate both parametric object motion as well as a motion segmentation from a single image alone. Our experiments demonstrate its ability to cope with very challenging cases of object motion blur. version:1
arxiv-1604-03286 | Scan, Attend and Read: End-to-End Handwritten Paragraph Recognition with MDLSTM Attention | http://arxiv.org/abs/1604.03286 | id:1604.03286 author:Théodore Bluche, Jérôme Louradour, Ronaldo Messina category:cs.CV  published:2016-04-12 summary:We present an attention-based model for end-to-end handwriting recognition. Our system does not require any segmentation of the input paragraph. The model is inspired by the differentiable attention models presented recently for speech recognition, image captioning or translation. The main difference is the covert and overt attention, implemented as a multi-dimensional LSTM network. Our principal contribution towards handwriting recognition lies in the automatic transcription without a prior segmentation into lines, which was crucial in previous approaches. To the best of our knowledge this is the first successful attempt of end-to-end multi-line handwriting recognition. We carried out experiments on the well-known IAM Database. The results are encouraging and bring hope to perform full paragraph transcription in the near future. version:2
arxiv-1604-05878 | A Factorization Machine Framework for Testing Bigram Embeddings in Knowledgebase Completion | http://arxiv.org/abs/1604.05878 | id:1604.05878 author:Johannes Welbl, Guillaume Bouchard, Sebastian Riedel category:cs.CL cs.AI cs.NE stat.ML  published:2016-04-20 summary:Embedding-based Knowledge Base Completion models have so far mostly combined distributed representations of individual entities or relations to compute truth scores of missing links. Facts can however also be represented using pairwise embeddings, i.e. embeddings for pairs of entities and relations. In this paper we explore such bigram embeddings with a flexible Factorization Machine model and several ablations from it. We investigate the relevance of various bigram types on the fb15k237 dataset and find relative improvements compared to a compositional model. version:1
arxiv-1604-05875 | Distributed Entity Disambiguation with Per-Mention Learning | http://arxiv.org/abs/1604.05875 | id:1604.05875 author:Tiep Mai, Bichen Shi, Patrick K. Nicholson, Deepak Ajwani, Alessandra Sala category:cs.CL cs.IR  published:2016-04-20 summary:Entity disambiguation, or mapping a phrase to its canonical representation in a knowledge base, is a fundamental step in many natural language processing applications. Existing techniques based on global ranking models fail to capture the individual peculiarities of the words and hence, either struggle to meet the accuracy requirements of many real-world applications or they are too complex to satisfy real-time constraints of applications. In this paper, we propose a new disambiguation system that learns specialized features and models for disambiguating each ambiguous phrase in the English language. To train and validate the hundreds of thousands of learning models for this purpose, we use a Wikipedia hyperlink dataset with more than 170 million labelled annotations. We provide an extensive experimental evaluation to show that the accuracy of our approach compares favourably with respect to many state-of-the-art disambiguation systems. The training required for our approach can be easily distributed over a cluster. Furthermore, updating our system for new entities or calibrating it for special ones is a computationally fast process, that does not affect the disambiguation of the other entities. version:1
arxiv-1604-05865 | Estimating 3D Trajectories from 2D Projections via Disjunctive Factored Four-Way Conditional Restricted Boltzmann Machines | http://arxiv.org/abs/1604.05865 | id:1604.05865 author:Decebal Constantin Mocanu, Haitham Bou Ammar, Luis Puig, Eric Eaton, Antonio Liotta category:cs.CV cs.AI  published:2016-04-20 summary:Estimation, recognition, and near-future prediction of 3D trajectories based on their two dimensional projections available from one camera source is an exceptionally difficult problem due to uncertainty in the trajectories and environment, high dimensionality of the specific trajectory states, lack of enough labeled data and so on. In this article, we propose a solution to solve this problem based on a novel deep learning model dubbed Disjunctive Factored Four-Way Conditional Restricted Boltzmann Machine (DFFW-CRBM). Our method improves state-of-the-art deep learning techniques for high dimensional time-series modeling by introducing a novel tensor factorization capable of driving forth order Boltzmann machines to considerably lower energy levels, at no computational costs. DFFW-CRBMs are capable of accurately estimating, recognizing, and performing near-future prediction of three-dimensional trajectories from their 2D projections while requiring limited amount of labeled data. We evaluate our method on both simulated and real-world data, showing its effectiveness in predicting and classifying complex ball trajectories and human activities. version:1
arxiv-1604-05848 | Scene Parsing with Integration of Parametric and Non-parametric Models | http://arxiv.org/abs/1604.05848 | id:1604.05848 author:Bing Shuai, Zhen Zuo, Gang Wang, Bing Wang category:cs.CV  published:2016-04-20 summary:We adopt Convolutional Neural Networks (CNNs) to be our parametric model to learn discriminative features and classifiers for local patch classification. Based on the occurrence frequency distribution of classes, an ensemble of CNNs (CNN-Ensemble) are learned, in which each CNN component focuses on learning different and complementary visual patterns. The local beliefs of pixels are output by CNN-Ensemble. Considering that visually similar pixels are indistinguishable under local context, we leverage the global scene semantics to alleviate the local ambiguity. The global scene constraint is mathematically achieved by adding a global energy term to the labeling energy function, and it is practically estimated in a non-parametric framework. A large margin based CNN metric learning method is also proposed for better global belief estimation. In the end, the integration of local and global beliefs gives rise to the class likelihood of pixels, based on which maximum marginal inference is performed to generate the label prediction maps. Even without any post-processing, we achieve state-of-the-art results on the challenging SiftFlow and Barcelona benchmarks. version:1
arxiv-1604-05819 | Trading-Off Cost of Deployment Versus Accuracy in Learning Predictive Models | http://arxiv.org/abs/1604.05819 | id:1604.05819 author:Daniel P. Robinson, Suchi Saria category:stat.ML cs.LG  published:2016-04-20 summary:Predictive models are finding an increasing number of applications in many industries. As a result, a practical means for trading-off the cost of deploying a model versus its effectiveness is needed. Our work is motivated by risk prediction problems in healthcare. Cost-structures in domains such as healthcare are quite complex, posing a significant challenge to existing approaches. We propose a novel framework for designing cost-sensitive structured regularizers that is suitable for problems with complex cost dependencies. We draw upon a surprising connection to boolean circuits. In particular, we represent the problem costs as a multi-layer boolean circuit, and then use properties of boolean circuits to define an extended feature vector and a group regularizer that exactly captures the underlying cost structure. The resulting regularizer may then be combined with a fidelity function to perform model prediction, for example. For the challenging real-world application of risk prediction for sepsis in intensive care units, the use of our regularizer leads to models that are in harmony with the underlying cost structure and thus provide an excellent prediction accuracy versus cost tradeoff. version:1
arxiv-1604-05817 | Depth Image Inpainting: Improving Low Rank Matrix Completion with Low Gradient Regularization | http://arxiv.org/abs/1604.05817 | id:1604.05817 author:Hongyang Xue, Shengming Zhang, Deng Cai category:cs.CV  published:2016-04-20 summary:We consider the case of inpainting single depth images. Without corresponding color images, previous or next frames, depth image inpainting is quite challenging. One natural solution is to regard the image as a matrix and adopt the low rank regularization just as inpainting color images. However, the low rank assumption does not make full use of the properties of depth images. A shallow observation may inspire us to penalize the non-zero gradients by sparse gradient regularization. However, statistics show that though most pixels have zero gradients, there is still a non-ignorable part of pixels whose gradients are equal to 1. Based on this specific property of depth images , we propose a low gradient regularization method in which we reduce the penalty for gradient 1 while penalizing the non-zero gradients to allow for gradual depth changes. The proposed low gradient regularization is integrated with the low rank regularization into the low rank low gradient approach for depth image inpainting. We compare our proposed low gradient regularization with sparse gradient regularization. The experimental results show the effectiveness of our proposed approach. version:1
arxiv-1604-05816 | Deep CNNs for HEp-2 Cells Classification : A Cross-specimen Analysis | http://arxiv.org/abs/1604.05816 | id:1604.05816 author:Hongwei Li, Jianguo Zhang, Wei-Shi Zheng category:cs.CV  published:2016-04-20 summary:Automatic classification of Human Epithelial Type-2 (HEp-2) cells staining patterns is an important and yet a challenging problem. Although both shallow and deep methods have been applied, the study of deep convolutional networks (CNNs) on this topic is shallow to date, thus failed to claim its top position for this problem. In this paper, we propose a novel study of using CNNs for HEp-2 cells classification focusing on cross-specimen analysis, a key evaluation for generalization. For the first time, our study reveals several key factors of using CNNs for HEp-2 cells classification. Our proposed system achieves state-of-the-art classification accuracy on public benchmark dataset. Comparative experiments on different training data reveals that adding different specimens,rather than increasing in numbers by affine transformations, helps to train a good deep model. This opens a new avenue for adopting deep CNNs to HEp-2 cells classification. version:1
arxiv-1604-05813 | Sherlock: Sparse Hierarchical Embeddings for Visually-aware One-class Collaborative Filtering | http://arxiv.org/abs/1604.05813 | id:1604.05813 author:Ruining He, Chunbin Lin, Jianguo Wang, Julian McAuley category:cs.IR cs.CV  published:2016-04-20 summary:Building successful recommender systems requires uncovering the underlying dimensions that describe the properties of items as well as users' preferences toward them. In domains like clothing recommendation, explaining users' preferences requires modeling the visual appearance of the items in question. This makes recommendation especially challenging, due to both the complexity and subtlety of people's 'visual preferences,' as well as the scale and dimensionality of the data and features involved. Ultimately, a successful model should be capable of capturing considerable variance across different categories and styles, while still modeling the commonalities explained by `global' structures in order to combat the sparsity (e.g. cold-start), variability, and scale of real-world datasets. Here, we address these challenges by building such structures to model the visual dimensions across different product categories. With a novel hierarchical embedding architecture, our method accounts for both high-level (colorfulness, darkness, etc.) and subtle (e.g. casualness) visual characteristics simultaneously. version:1
arxiv-1505-00468 | VQA: Visual Question Answering | http://arxiv.org/abs/1505.00468 | id:1505.00468 author:Aishwarya Agrawal, Jiasen Lu, Stanislaw Antol, Margaret Mitchell, C. Lawrence Zitnick, Dhruv Batra, Devi Parikh category:cs.CL cs.CV  published:2015-05-03 summary:We propose the task of free-form and open-ended Visual Question Answering (VQA). Given an image and a natural language question about the image, the task is to provide an accurate natural language answer. Mirroring real-world scenarios, such as helping the visually impaired, both the questions and answers are open-ended. Visual questions selectively target different areas of an image, including background details and underlying context. As a result, a system that succeeds at VQA typically needs a more detailed understanding of the image and complex reasoning than a system producing generic image captions. Moreover, VQA is amenable to automatic evaluation, since many open-ended answers contain only a few words or a closed set of answers that can be provided in a multiple-choice format. We provide a dataset containing ~0.25M images, ~0.76M questions, and ~10M answers (www.visualqa.org), and discuss the information it provides. Numerous baselines and methods for VQA are provided and compared with human performance. version:6
arxiv-1604-05800 | A Deep Neural Network for Chinese Zero Pronoun Resolution | http://arxiv.org/abs/1604.05800 | id:1604.05800 author:Yin Qingyu, Zhang Weinan, Zhang Yu, Liu Ting category:cs.CL  published:2016-04-20 summary:This paper investigates the problem of Chinese zero pronoun resolution. Most existing approaches are based on machine learning algorithms, using hand-crafted features, which is labor-intensive. More- over, semantic information that is essential in the resolution of noun phrases has not been addressed enough by previous approaches on zero pronoun resolution. This is because that zero pronouns have no descriptive information, which makes it almost impossible to calculate semantic similarity between the zero pronoun and its candidate antecedents. To deal with these problems, we aim at exploring learn- ing algorithms that are capable of generating semantic representations for zero pronouns, capturing the intricate related- ness between zero pronouns and candidate antecedents, and meanwhile less dependent on extensive feature engineering. To achieve this goal, in this paper, we propose a zero pronoun-specific neural network for Chinese zero pronoun resolution task. Experimental results show that our approach significantly outperforms the state-of-the- art method. version:1
arxiv-1604-05792 | Multi-agent evolutionary systems for the generation of complex virtual worlds | http://arxiv.org/abs/1604.05792 | id:1604.05792 author:Jan Kruse, Andy M. Connor category:cs.NE  published:2016-04-20 summary:Modern films, games and virtual reality applications are dependent on convincing computer graphics. Highly complex models are a requirement for the successful delivery of many scenes and environments. While workflows such as rendering, compositing and animation have been streamlined to accommodate increasing demands, modelling complex models is still a laborious task. This paper introduces the computational benefits of an Interactive Genetic Algorithm (IGA) to computer graphics modelling while compensating the effects of user fatigue, a common issue with Interactive Evolutionary Computation. An intelligent agent is used in conjunction with an IGA that offers the potential to reduce the effects of user fatigue by learning from the choices made by the human designer and directing the search accordingly. This workflow accelerates the layout and distribution of basic elements to form complex models. It captures the designer's intent through interaction, and encourages playful discovery. version:1
arxiv-1604-05791 | Procedural urban environments for FPS games | http://arxiv.org/abs/1604.05791 | id:1604.05791 author:Jan Kruse, Ricardo Sosa, Andy M. Connor category:cs.AI cs.HC cs.NE  published:2016-04-20 summary:This paper presents a novel approach to procedural generation of urban maps for First Person Shooter (FPS) games. A multi-agent evolutionary system is employed to place streets, buildings and other items inside the Unity3D game engine, resulting in playable video game levels. A computational agent is trained using machine learning techniques to capture the intent of the game designer as part of the multi-agent system, and to enable a semi-automated aesthetic selection for the underlying genetic algorithm. version:1
arxiv-1602-09065 | Evaluation of Deep Learning based Pose Estimation for Sign Language Recognition | http://arxiv.org/abs/1602.09065 | id:1602.09065 author:Srujana Gattupalli, Amir Ghaderi, Vassilis Athitsos category:cs.CV  published:2016-02-29 summary:Human body pose estimation and hand detection are two important tasks for systems that perform computer vision-based sign language recognition(SLR). However, both tasks are challenging, especially when the input is color videos, with no depth information. Many algorithms have been proposed in the literature for these tasks, and some of the most successful recent algorithms are based on deep learning. In this paper, we introduce a dataset for human pose estimation for SLR domain. We evaluate the performance of two deep learning based pose estimation methods, by performing user-independent experiments on our dataset. We also perform transfer learning, and we obtain results that demonstrate that transfer learning can improve pose estimation accuracy. The dataset and results from these methods can create a useful baseline for future works. version:3
arxiv-1604-05766 | Track and Transfer: Watching Videos to Simulate Strong Human Supervision for Weakly-Supervised Object Detection | http://arxiv.org/abs/1604.05766 | id:1604.05766 author:Krishna Kumar Singh, Fanyi Xiao, Yong Jae Lee category:cs.CV  published:2016-04-19 summary:The status quo approach to training object detectors requires expensive bounding box annotations. Our framework takes a markedly different direction: we transfer tracked object boxes from weakly-labeled videos to weakly-labeled images to automatically generate pseudo ground-truth boxes, which replace manually annotated bounding boxes. We first mine discriminative regions in the weakly-labeled image collection that frequently/rarely appear in the positive/negative images. We then match those regions to videos and retrieve the corresponding tracked object boxes. Finally, we design a hough transform algorithm to vote for the best box to serve as the pseudo GT for each image, and use them to train an object detector. Together, these lead to state-of-the-art weakly-supervised detection results on the PASCAL 2007 and 2010 datasets. version:1
arxiv-1604-05753 | Sketching and Neural Networks | http://arxiv.org/abs/1604.05753 | id:1604.05753 author:Amit Daniely, Nevena Lazic, Yoram Singer, Kunal Talwar category:cs.LG cs.AI  published:2016-04-19 summary:High-dimensional sparse data present computational and statistical challenges for supervised learning. We propose compact linear sketches for reducing the dimensionality of the input, followed by a single layer neural network. We show that any sparse polynomial function can be computed, on nearly all sparse binary vectors, by a single layer neural network that takes a compact sketch of the vector as input. Consequently, when a set of sparse binary vectors is approximately separable using a sparse polynomial, there exists a single-layer neural network that takes a short sketch as input and correctly classifies nearly all the points. Previous work has proposed using sketches to reduce dimensionality while preserving the hypothesis class. However, the sketch size has an exponential dependence on the degree in the case of polynomial classifiers. In stark contrast, our approach of using improper learning, using a larger hypothesis class allows the sketch size to have a logarithmic dependence on the degree. Even in the linear case, our approach allows us to improve on the pesky $O({1}/{{\gamma}^2})$ dependence of random projections, on the margin $\gamma$. We empirically show that our approach leads to more compact neural networks than related methods such as feature hashing at equal or better performance. version:1
arxiv-1604-05747 | Syntactic and semantic classification of verb arguments using dependency-based and rich semantic features | http://arxiv.org/abs/1604.05747 | id:1604.05747 author:Francesco Elia category:cs.CL  published:2016-04-19 summary:Corpus Pattern Analysis (CPA) has been the topic of Semeval 2015 Task 15, aimed at producing a system that can aid lexicographers in their efforts to build a dictionary of meanings for English verbs using the CPA annotation process. CPA parsing is one of the subtasks which this annotation process is made of and it is the focus of this report. A supervised machine-learning approach has been implemented, in which syntactic features derived from parse trees and semantic features derived from WordNet and word embeddings are used. It is shown that this approach performs well, even with the data sparsity issues that characterize the dataset, and can obtain better results than other system by a margin of about 4% f-score. version:1
arxiv-1511-05099 | Yin and Yang: Balancing and Answering Binary Visual Questions | http://arxiv.org/abs/1511.05099 | id:1511.05099 author:Peng Zhang, Yash Goyal, Douglas Summers-Stay, Dhruv Batra, Devi Parikh category:cs.CL cs.CV cs.LG  published:2015-11-16 summary:The complex compositional structure of language makes problems at the intersection of vision and language challenging. But language also provides a strong prior that can result in good superficial performance, without the underlying models truly understanding the visual content. This can hinder progress in pushing state of art in the computer vision aspects of multi-modal AI. In this paper, we address binary Visual Question Answering (VQA) on abstract scenes. We formulate this problem as visual verification of concepts inquired in the questions. Specifically, we convert the question to a tuple that concisely summarizes the visual concept to be detected in the image. If the concept can be found in the image, the answer to the question is "yes", and otherwise "no". Abstract scenes play two roles (1) They allow us to focus on the high-level semantics of the VQA task as opposed to the low-level recognition problems, and perhaps more importantly, (2) They provide us the modality to balance the dataset such that language priors are controlled, and the role of vision is essential. In particular, we collect fine-grained pairs of scenes for every question, such that the answer to the question is "yes" for one scene, and "no" for the other for the exact same question. Indeed, language priors alone do not perform better than chance on our balanced dataset. Moreover, our proposed approach matches the performance of a state-of-the-art VQA approach on the unbalanced dataset, and outperforms it on the balanced dataset. version:5
arxiv-1511-05175 | Convolutional Models for Joint Object Categorization and Pose Estimation | http://arxiv.org/abs/1511.05175 | id:1511.05175 author:Mohamed Elhoseiny, Tarek El-Gaaly, Amr Bakry, Ahmed Elgammal category:cs.CV cs.AI cs.LG  published:2015-11-16 summary:In the task of Object Recognition, there exists a dichotomy between the categorization of objects and estimating object pose, where the former necessitates a view-invariant representation, while the latter requires a representation capable of capturing pose information over different categories of objects. With the rise of deep architectures, the prime focus has been on object category recognition. Deep learning methods have achieved wide success in this task. In contrast, object pose regression using these approaches has received relatively much less attention. In this paper we show how deep architectures, specifically Convolutional Neural Networks (CNN), can be adapted to the task of simultaneous categorization and pose estimation of objects. We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations of CNNs represent object pose information and how this contradicts with object category representations. We extensively experiment on two recent large and challenging multi-view datasets. Our models achieve better than state-of-the-art performance on both datasets. version:6
arxiv-1512-07506 | Recovering 6D Object Pose and Predicting Next-Best-View in the Crowd | http://arxiv.org/abs/1512.07506 | id:1512.07506 author:Andreas Doumanoglou, Rigas Kouskouridas, Sotiris Malassiotis, Tae-Kyun Kim category:cs.CV  published:2015-12-23 summary:Object detection and 6D pose estimation in the crowd (scenes with multiple object instances, severe foreground occlusions and background distractors), has become an important problem in many rapidly evolving technological areas such as robotics and augmented reality. Single shot-based 6D pose estimators with manually designed features are still unable to tackle the above challenges, motivating the research towards unsupervised feature learning and next-best-view estimation. In this work, we present a complete framework for both single shot-based 6D object pose estimation and next-best-view prediction based on Hough Forests, the state of the art object pose estimator that performs classification and regression jointly. Rather than using manually designed features we a) propose an unsupervised feature learnt from depth-invariant patches using a Sparse Autoencoder and b) offer an extensive evaluation of various state of the art features. Furthermore, taking advantage of the clustering performed in the leaf nodes of Hough Forests, we learn to estimate the reduction of uncertainty in other views, formulating the problem of selecting the next-best-view. To further improve pose estimation, we propose an improved joint registration and hypotheses verification module as a final refinement step to reject false detections. We provide two additional challenging datasets inspired from realistic scenarios to extensively evaluate the state of the art and our framework. One is related to domestic environments and the other depicts a bin-picking scenario mostly found in industrial settings. We show that our framework significantly outperforms state of the art both on public and on our datasets. version:2
arxiv-1509-05715 | MAGMA: Multi-level accelerated gradient mirror descent algorithm for large-scale convex composite minimization | http://arxiv.org/abs/1509.05715 | id:1509.05715 author:Vahan Hovhannisyan, Panos Parpas, Stefanos Zafeiriou category:math.OC cs.CV  published:2015-09-18 summary:Composite convex optimization models arise in several applications, and are especially prevalent in inverse problems with a sparsity inducing norm and in general convex optimization with simple constraints. The most widely used algorithms for convex composite models are accelerated first order methods, however they can take a large number of iterations to compute an acceptable solution for large-scale problems. In this paper we propose to speed up first order methods by taking advantage of the structure present in many applications and in image processing in particular. Our method is based on multi-level optimization methods and exploits the fact that many applications that give rise to large scale models can be modelled using varying degrees of fidelity. We use Nesterov's acceleration techniques together with the multi-level approach to achieve $\mathcal{O}(1/\sqrt{\epsilon})$ convergence rate, where $\epsilon$ denotes the desired accuracy. The proposed method has a better convergence rate than any other existing multi-level method for convex problems, and in addition has the same rate as accelerated methods, which is known to be optimal for first-order methods. Moreover, as our numerical experiments show, on large-scale face recognition problems our algorithm is several times faster than the state of the art. version:2
arxiv-1502-03044 | Show, Attend and Tell: Neural Image Caption Generation with Visual Attention | http://arxiv.org/abs/1502.03044 | id:1502.03044 author:Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard Zemel, Yoshua Bengio category:cs.LG cs.CV  published:2015-02-10 summary:Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO. version:3
arxiv-1401-3590 | An Enhanced Method For Evaluating Automatic Video Summaries | http://arxiv.org/abs/1401.3590 | id:1401.3590 author:Karim M. Mahmoud category:cs.CV cs.IR  published:2014-01-14 summary:Evaluation of automatic video summaries is a challenging problem. In the past years, some evaluation methods are presented that utilize only a single feature like color feature to detect similarity between automatic video summaries and ground-truth user summaries. One of the drawbacks of using a single feature is that sometimes it gives a false similarity detection which makes the assessment of the quality of the generated video summary less perceptual and not accurate. In this paper, a novel method for evaluating automatic video summaries is presented. This method is based on comparing automatic video summaries generated by video summarization techniques with ground-truth user summaries. The objective of this evaluation method is to quantify the quality of video summaries, and allow comparing different video summarization techniques utilizing both color and texture features of the video frames and using the Bhattacharya distance as a dissimilarity measure due to its advantages. Our Experiments show that the proposed evaluation method overcomes the drawbacks of other methods and gives a more perceptual evaluation of the quality of the automatic video summaries. version:3
arxiv-1604-05633 | Online Human Action Detection using Joint Classification-Regression Recurrent Neural Networks | http://arxiv.org/abs/1604.05633 | id:1604.05633 author:Yanghao Li, Cuiling Lan, Junliang Xing, Wenjun Zeng, Chunfeng Yuan, Jiaying Liu category:cs.CV  published:2016-04-19 summary:Human action recognition from well-segmented 3D skeleton data has been intensively studied and attracting an increasing attention. Online action detection goes one step further and is more challenging, which identifies the action type and localizes the action positions on the fly from the untrimmed stream. In this paper, we study the problem of online action detection from the streaming skeleton data. We propose a multi-task end-to-end Joint Classification-Regression Recurrent Neural Network to better explore the action type and temporal localization information. By employing a joint classification and regression optimization objective, this network is capable of automatically localizing the start and end points of actions more accurately. Specifically, by leveraging the merits of the deep Long Short-Term Memory (LSTM) subnetwork, the proposed model automatically captures the complex long-range temporal dynamics, which naturally avoids the typical sliding window design and thus ensures high computational efficiency. Furthermore, the subtask of regression optimization provides the ability to forecast the action prior to its occurrence. To evaluate our proposed model, we build a large streaming video dataset with annotations. Experimental results on our dataset and the public G3D dataset both demonstrate very promising performance of our scheme. version:1
arxiv-1511-06931 | Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems | http://arxiv.org/abs/1511.06931 | id:1511.06931 author:Jesse Dodge, Andreea Gane, Xiang Zhang, Antoine Bordes, Sumit Chopra, Alexander Miller, Arthur Szlam, Jason Weston category:cs.CL cs.LG  published:2015-11-21 summary:A long-term goal of machine learning is to build intelligent conversational agents. One recent popular approach is to train end-to-end models on a large amount of real dialog transcripts between humans (Sordoni et al., 2015; Vinyals & Le, 2015; Shang et al., 2015). However, this approach leaves many questions unanswered as an understanding of the precise successes and shortcomings of each model is hard to assess. A contrasting recent proposal are the bAbI tasks (Weston et al., 2015b) which are synthetic data that measure the ability of learning machines at various reasoning tasks over toy language. Unfortunately, those tests are very small and hence may encourage methods that do not scale. In this work, we propose a suite of new tasks of a much larger scale that attempt to bridge the gap between the two regimes. Choosing the domain of movies, we provide tasks that test the ability of models to answer factual questions (utilizing OMDB), provide personalization (utilizing MovieLens), carry short conversations about the two, and finally to perform on natural dialogs from Reddit. We provide a dataset covering 75k movie entities and with 3.5M training examples. We present results of various models on these tasks, and evaluate their performance. version:6
arxiv-1604-05605 | Right whale recognition using convolutional neural networks | http://arxiv.org/abs/1604.05605 | id:1604.05605 author:Andrei Polzounov, Ilmira Terpugova, Deividas Skiparis, Andrei Mihai category:cs.CV 68  published:2016-04-19 summary:We studied the feasibility of recognizing individual right whales (Eubalaena glacialis) using convolutional neural networks. Prior studies have shown that CNNs can be used in wide range of classification and categorization tasks such as automated human face recognition. To test applicability of deep learning to whale recognition we have developed several models based on best practices from literature. Here, we describe the performance of the models. We conclude that machine recognition of whales is feasible and comment on the difficulty of the problem version:1
arxiv-1603-03915 | Robust Scene Text Recognition with Automatic Rectification | http://arxiv.org/abs/1603.03915 | id:1603.03915 author:Baoguang Shi, Xinggang Wang, Pengyuan Lyu, Cong Yao, Xiang Bai category:cs.CV  published:2016-03-12 summary:Recognizing text in natural images is a challenging task with many unsolved problems. Different from those in documents, words in natural images often possess irregular shapes, which are caused by perspective distortion, curved character placement, etc. We propose RARE (Robust text recognizer with Automatic REctification), a recognition model that is robust to irregular text. RARE is a specially-designed deep neural network, which consists of a Spatial Transformer Network (STN) and a Sequence Recognition Network (SRN). In testing, an image is firstly rectified via a predicted Thin-Plate-Spline (TPS) transformation, into a more "readable" image for the following SRN, which recognizes text through a sequence recognition approach. We show that the model is able to recognize several types of irregular text, including perspective text and curved text. RARE is end-to-end trainable, requiring only images and associated text labels, making it convenient to train and deploy the model in practical systems. State-of-the-art or highly-competitive performance achieved on several benchmarks well demonstrates the effectiveness of the proposed model. version:2
arxiv-1604-05592 | WarpNet: Weakly Supervised Matching for Single-view Reconstruction | http://arxiv.org/abs/1604.05592 | id:1604.05592 author:Angjoo Kanazawa, David W. Jacobs, Manmohan Chandraker category:cs.CV  published:2016-04-19 summary:We present an approach to matching images of objects in fine-grained datasets without using part annotations, with an application to the challenging problem of weakly supervised single-view reconstruction. This is in contrast to prior works that require part annotations, since matching objects across class and pose variations is challenging with appearance features alone. We overcome this challenge through a novel deep learning architecture, WarpNet, that aligns an object in one image with a different object in another. We exploit the structure of the fine-grained dataset to create artificial data for training this network in an unsupervised-discriminative learning approach. The output of the network acts as a spatial prior that allows generalization at test time to match real images across variations in appearance, viewpoint and articulation. On the CUB-200-2011 dataset of bird categories, we improve the AP over an appearance-only network by 13.6%. We further demonstrate that our WarpNet matches, together with the structure of fine-grained datasets, allow single-view reconstructions with quality comparable to using annotated point correspondences. version:1
arxiv-1604-05590 | Locating a Small Cluster Privately | http://arxiv.org/abs/1604.05590 | id:1604.05590 author:Kobbi Nissim, Uri Stemmer, Salil Vadhan category:cs.DS cs.CR cs.LG  published:2016-04-19 summary:We present a new algorithm for locating a small cluster of points with differential privacy [Dwork, McSherry, Nissim, and Smith, 2006]. Our algorithm has implications to private data exploration, clustering, and removal of outliers. Furthermore, we use it to significantly relax the requirements of the sample and aggregate technique [Nissim, Raskhodnikova, and Smith, 2007], which allows compiling of "off the shelf" (non-private) analyses into analyses that preserve differential privacy. version:1
arxiv-1604-05091 | End-to-End Tracking and Semantic Segmentation Using Recurrent Neural Networks | http://arxiv.org/abs/1604.05091 | id:1604.05091 author:Peter Ondruska, Julie Dequaire, Dominic Zeng Wang, Ingmar Posner category:cs.LG cs.AI cs.CV cs.NE cs.RO  published:2016-04-18 summary:In this work we present a novel end-to-end framework for tracking and classifying a robot's surroundings in complex, dynamic and only partially observable real-world environments. The approach deploys a recurrent neural network to filter an input stream of raw laser measurements in order to directly infer object locations, along with their identity in both visible and occluded areas. To achieve this we first train the network using unsupervised Deep Tracking, a recently proposed theoretical framework for end-to-end space occupancy prediction. We show that by learning to track on a large amount of unsupervised data, the network creates a rich internal representation of its environment which we in turn exploit through the principle of inductive transfer of knowledge to perform the task of it's semantic classification. As a result, we show that only a small amount of labelled data suffices to steer the network towards mastering this additional task. Furthermore we propose a novel recurrent neural network architecture specifically tailored to tracking and semantic classification in real-world robotics applications. We demonstrate the tracking and classification performance of the method on real-world data collected at a busy road junction. Our evaluation shows that the proposed end-to-end framework compares favourably to a state-of-the-art, model-free tracking solution and that it outperforms a conventional one-shot training scheme for semantic classification. version:2
arxiv-1604-05576 | Using Apache Lucene to Search Vector of Locally Aggregated Descriptors | http://arxiv.org/abs/1604.05576 | id:1604.05576 author:Giuseppe Amato, Paolo Bolettieri, Fabrizio Falchi, Claudio Gennaro, Lucia Vadicamo category:cs.CV cs.IR I.4; I.5.4; H.3.3  published:2016-04-19 summary:Surrogate Text Representation (STR) is a profitable solution to efficient similarity search on metric space using conventional text search engines, such as Apache Lucene. This technique is based on comparing the permutations of some reference objects in place of the original metric distance. However, the Achilles heel of STR approach is the need to reorder the result set of the search according to the metric distance. This forces to use a support database to store the original objects, which requires efficient random I/O on a fast secondary memory (such as flash-based storages). In this paper, we propose to extend the Surrogate Text Representation to specifically address a class of visual metric objects known as Vector of Locally Aggregated Descriptors (VLAD). This approach is based on representing the individual sub-vectors forming the VLAD vector with the STR, providing a finer representation of the vector and enabling us to get rid of the reordering phase. The experiments on a publicly available dataset show that the extended STR outperforms the baseline STR achieving satisfactory performance near to the one obtained with the original VLAD vectors. version:1
arxiv-1604-01962 | Automatic Content-aware Non-Photorealistic Rendering of Images | http://arxiv.org/abs/1604.01962 | id:1604.01962 author:Akshay Gadi Patil, Shanmuganathan Raman category:cs.CV  published:2016-04-07 summary:Non-photorealistic rendering techniques work on image features and often manipulate a set of characteristics such as edges and texture to achieve a desired depiction of the scene. Most computational photography methods decompose an image using edge preserving filters and work on the resulting base and detail layers independently to achieve desired visual effects. We propose a new approach for content-aware non-photorealistic rendering of images where we manipulate the visually salient and the non-salient regions separately. We propose a novel content-aware framework in order to render an image for applications such as detail exaggeration, artificial blurring and image abstraction. The processed regions of the image are blended seamlessly for all these applications. We demonstrate that content awareness of the proposed method leads to automatic generation of non-photorealistic rendering of the same image for the different applications mentioned above. version:4
arxiv-1604-05525 | An Attentive Neural Architecture for Fine-grained Entity Type Classification | http://arxiv.org/abs/1604.05525 | id:1604.05525 author:Sonse Shimaoka, Pontus Stenetorp, Kentaro Inui, Sebastian Riedel category:cs.CL  published:2016-04-19 summary:In this work we propose a novel attention-based neural network model for the task of fine-grained entity type classification that unlike previously proposed models recursively composes representations of entity mention contexts. Our model achieves state-of-the-art performance with 74.94% loose micro F1-score on the well-established FIGER dataset, a relative improvement of 2.59%. We also investigate the behavior of the attention mechanism of our model and observe that it can learn contextual linguistic expressions that indicate the fine-grained category memberships of an entity. version:1
arxiv-1604-05499 | Exploring Segment Representations for Neural Segmentation Models | http://arxiv.org/abs/1604.05499 | id:1604.05499 author:Yijia Liu, Wanxiang Che, Jiang Guo, Bing Qin, Ting Liu category:cs.CL  published:2016-04-19 summary:Many natural language processing (NLP) tasks can be generalized into segmentation problem. In this paper, we combine semi-CRF with neural network to solve NLP segmentation tasks. Our model represents a segment both by composing the input units and embedding the entire segment. We thoroughly study different composition functions and different segment embeddings. We conduct extensive experiments on two typical segmentation tasks: named entity recognition (NER) and Chinese word segmentation (CWS). Experimental results show that our neural semi-CRF model benefits from representing the entire segment and achieves the state-of-the-art performance on CWS benchmark dataset and competitive results on the CoNLL03 dataset. version:1
arxiv-1604-05495 | Deep Saliency with Encoded Low level Distance Map and High Level Features | http://arxiv.org/abs/1604.05495 | id:1604.05495 author:Gayoung Lee, Yu-Wing Tai, Junmo Kim category:cs.CV  published:2016-04-19 summary:Recent advances in saliency detection have utilized deep learning to obtain high level features to detect salient regions in a scene. These advances have demonstrated superior results over previous works that utilize hand-crafted low level features for saliency detection. In this paper, we demonstrate that hand-crafted features can provide complementary information to enhance performance of saliency detection that utilizes only high level features. Our method utilizes both high level and low level features for saliency detection under a unified deep learning framework. The high level features are extracted using the VGG-net, and the low level features are compared with other parts of an image to form a low level distance map. The low level distance map is then encoded using a convolutional neural network(CNN) with multiple 1X1 convolutional and ReLU layers. We concatenate the encoded low level distance map and the high level features, and connect them to a fully connected neural network classifier to evaluate the saliency of a query region. Our experiments show that our method can further improve the performance of state-of-the-art deep learning-based saliency detection methods. version:1
arxiv-1604-05468 | Understanding Rating Behaviour and Predicting Ratings by Identifying Representative Users | http://arxiv.org/abs/1604.05468 | id:1604.05468 author:Rahul Kamath, Masanao Ochi, Yutaka Matsuo category:cs.IR cs.AI cs.CL cs.LG  published:2016-04-19 summary:Online user reviews describing various products and services are now abundant on the web. While the information conveyed through review texts and ratings is easily comprehensible, there is a wealth of hidden information in them that is not immediately obvious. In this study, we unlock this hidden value behind user reviews to understand the various dimensions along which users rate products. We learn a set of users that represent each of these dimensions and use their ratings to predict product ratings. Specifically, we work with restaurant reviews to identify users whose ratings are influenced by dimensions like 'Service', 'Atmosphere' etc. in order to predict restaurant ratings and understand the variation in rating behaviour across different cuisines. While previous approaches to obtaining product ratings require either a large number of user ratings or a few review texts, we show that it is possible to predict ratings with few user ratings and no review text. Our experiments show that our approach outperforms other conventional methods by 16-27% in terms of RMSE. version:1
arxiv-1604-05459 | An Online Structural Plasticity Rule for Generating Better Reservoirs | http://arxiv.org/abs/1604.05459 | id:1604.05459 author:Subhrajit Roy, Arindam Basu category:cs.NE  published:2016-04-19 summary:In this article, a novel neuro-inspired low-resolution online unsupervised learning rule is proposed to train the reservoir or liquid of Liquid State Machine. The liquid is a sparsely interconnected huge recurrent network of spiking neurons. The proposed learning rule is inspired from structural plasticity and trains the liquid through formation and elimination of synaptic connections. Hence, the learning involves rewiring of the reservoir connections similar to structural plasticity observed in biological neural networks. The network connections can be stored as a connection matrix and updated in memory by using Address Event Representation (AER) protocols which are generally employed in neuromorphic systems. On investigating the 'pairwise separation property' we find that trained liquids provide 1.36 $\pm$ 0.18 times more inter-class separation while retaining similar intra-class separation as compared to random liquids. Moreover, analysis of the 'linear separation property' reveals that trained liquids are 2.05 $\pm$ 0.27 times better than random liquids. Furthermore, we show that our liquids are able to retain the 'generalization' ability and 'generality' of random liquids. A memory analysis shows that trained liquids have 83.67 $\pm$ 5.79 ms longer fading memory than random liquids which have shown 92.8 $\pm$ 5.03 ms fading memory for a particular type of spike train inputs. We also throw some light on the dynamics of the evolution of recurrent connections within the liquid. Moreover, compared to 'Separation Driven Synaptic Modification' - a recently proposed algorithm for iteratively refining reservoirs, our learning rule provides 9.30%, 15.21% and 12.52% more liquid separations and 2.8%, 9.1% and 7.9% better classification accuracies for four, eight and twelve class pattern recognition tasks respectively. version:1
arxiv-1604-05451 | Parts for the Whole: The DCT Norm for Extreme Visual Recovery | http://arxiv.org/abs/1604.05451 | id:1604.05451 author:Yunhe Wang, Chang Xu, Shan You, Dacheng Tao, Chao Xu category:cs.CV  published:2016-04-19 summary:Here we study the extreme visual recovery problem, in which over 90\% of pixel values in a given image are missing. Existing low rank-based algorithms are only effective for recovering data with at most 90\% missing values. Thus, we exploit visual data's smoothness property to help solve this challenging extreme visual recovery problem. Based on the Discrete Cosine Transformation (DCT), we propose a novel DCT norm that involves all pixels and produces smooth estimations in any view. Our theoretical analysis shows that the total variation (TV) norm, which only achieves local smoothness, is a special case of the proposed DCT norm. We also develop a new visual recovery algorithm by minimizing the DCT and nuclear norms to achieve a more visually pleasing estimation. Experimental results on a benchmark image dataset demonstrate that the proposed approach is superior to state-of-the-art methods in terms of peak signal-to-noise ratio and structural similarity. version:1
arxiv-1604-05449 | Streaming Label Learning for Modeling Labels on the Fly | http://arxiv.org/abs/1604.05449 | id:1604.05449 author:Shan You, Chang Xu, Yunhe Wang, Chao Xu, Dacheng Tao category:stat.ML cs.LG  published:2016-04-19 summary:It is challenging to handle a large volume of labels in multi-label learning. However, existing approaches explicitly or implicitly assume that all the labels in the learning process are given, which could be easily violated in changing environments. In this paper, we define and study streaming label learning (SLL), i.e., labels are arrived on the fly, to model newly arrived labels with the help of the knowledge learned from past labels. The core of SLL is to explore and exploit the relationships between new labels and past labels and then inherit the relationship into hypotheses of labels to boost the performance of new classifiers. In specific, we use the label self-representation to model the label relationship, and SLL will be divided into two steps: a regression problem and a empirical risk minimization (ERM) problem. Both problems are simple and can be efficiently solved. We further show that SLL can generate a tighter generalization error bound for new labels than the general ERM framework with trace norm or Frobenius norm regularization. Finally, we implement extensive experiments on various benchmark datasets to validate the new setting. And results show that SLL can effectively handle the constantly emerging new labels and provides excellent classification performance. version:1
arxiv-1501-02629 | Scaling-up Empirical Risk Minimization: Optimization of Incomplete U-statistics | http://arxiv.org/abs/1501.02629 | id:1501.02629 author:Stéphan Clémençon, Aurélien Bellet, Igor Colin category:stat.ML cs.LG  published:2015-01-12 summary:In a wide range of statistical learning problems such as ranking, clustering or metric learning among others, the risk is accurately estimated by $U$-statistics of degree $d\geq 1$, i.e. functionals of the training data with low variance that take the form of averages over $k$-tuples. From a computational perspective, the calculation of such statistics is highly expensive even for a moderate sample size $n$, as it requires averaging $O(n^d)$ terms. This makes learning procedures relying on the optimization of such data functionals hardly feasible in practice. It is the major goal of this paper to show that, strikingly, such empirical risks can be replaced by drastically computationally simpler Monte-Carlo estimates based on $O(n)$ terms only, usually referred to as incomplete $U$-statistics, without damaging the $O_{\mathbb{P}}(1/\sqrt{n})$ learning rate of Empirical Risk Minimization (ERM) procedures. For this purpose, we establish uniform deviation results describing the error made when approximating a $U$-process by its incomplete version under appropriate complexity assumptions. Extensions to model selection, fast rate situations and various sampling techniques are also considered, as well as an application to stochastic gradient descent for ERM. Finally, numerical examples are displayed in order to provide strong empirical evidence that the approach we promote largely surpasses more naive subsampling techniques. version:4
arxiv-1604-05442 | Improving Raw Image Storage Efficiency by Exploiting Similarity | http://arxiv.org/abs/1604.05442 | id:1604.05442 author:Binqi Zhang, Chen Wang, Bing Bing Zhou, Albert Y. Zomaya category:cs.DC cs.CV  published:2016-04-19 summary:To improve the temporal and spatial storage efficiency, researchers have intensively studied various techniques, including compression and deduplication. Through our evaluation, we find that methods such as photo tags or local features help to identify the content-based similar- ity between raw images. The images can then be com- pressed more efficiently to get better storage space sav- ings. Furthermore, storing similar raw images together enables rapid data sorting, searching and retrieval if the images are stored in a distributed and large-scale envi- ronment by reducing fragmentation. In this paper, we evaluated the compressibility by designing experiments and observing the results. We found that on a statistical basis the higher similarity photos have, the better com- pression results are. This research helps provide a clue for future large-scale storage system design. version:1
arxiv-1604-05429 | Comparative Study of Instance Based Learning and Back Propagation for Classification Problems | http://arxiv.org/abs/1604.05429 | id:1604.05429 author:Nadia Kanwal, Erkan Bostanci category:cs.LG  published:2016-04-19 summary:The paper presents a comparative study of the performance of Back Propagation and Instance Based Learning Algorithm for classification tasks. The study is carried out by a series of experiments will all possible combinations of parameter values for the algorithms under evaluation. The algorithm's classification accuracy is compared over a range of datasets and measurements like Cross Validation, Kappa Statistics, Root Mean Squared Value and True Positive vs False Positive rate have been used to evaluate their performance. Along with performance comparison, techniques of handling missing values have also been compared that include Mean or Mode replacement and Multiple Imputation. The results showed that parameter adjustment plays vital role in improving an algorithm's accuracy and therefore, Back Propagation has shown better results as compared to Instance Based Learning. Furthermore, the problem of missing values was better handled by Multiple imputation method, however, not suitable for less amount of data. version:1
arxiv-1604-04029 | Multi-Source Multi-View Clustering via Discrepancy Penalty | http://arxiv.org/abs/1604.04029 | id:1604.04029 author:Weixiang Shao, Jiawei Zhang, Lifang He, Philip S. Yu category:cs.LG  published:2016-04-14 summary:With the advance of technology, entities can be observed in multiple views. Multiple views containing different types of features can be used for clustering. Although multi-view clustering has been successfully applied in many applications, the previous methods usually assume the complete instance mapping between different views. In many real-world applications, information can be gathered from multiple sources, while each source can contain multiple views, which are more cohesive for learning. The views under the same source are usually fully mapped, but they can be very heterogeneous. Moreover, the mappings between different sources are usually incomplete and partially observed, which makes it more difficult to integrate all the views across different sources. In this paper, we propose MMC (Multi-source Multi-view Clustering), which is a framework based on collective spectral clustering with a discrepancy penalty across sources, to tackle these challenges. MMC has several advantages compared with other existing methods. First, MMC can deal with incomplete mapping between sources. Second, it considers the disagreements between sources while treating views in the same source as a cohesive set. Third, MMC also tries to infer the instance similarities across sources to enhance the clustering performance. Extensive experiments conducted on real-world data demonstrate the effectiveness of the proposed approach. version:2
arxiv-1604-05413 | Cognitive state classification using transformed fMRI data | http://arxiv.org/abs/1604.05413 | id:1604.05413 author:Hariharan Ramasangu, Neelam Sinha category:cs.CV I.4.7; I.5.2; I.5.4  published:2016-04-19 summary:One approach, for understanding human brain functioning, is to analyze the changes in the brain while performing cognitive tasks. Towards this, Functional Magnetic Resonance (fMR) images of subjects performing well-defined tasks are widely utilized for task-specific analyses. In this work, we propose a procedure to enable classification between two chosen cognitive tasks, using their respective fMR image sequences. The time series of expert-marked anatomically-mapped relevant voxels are processed and fed as input to the classical Naive Bayesian and SVM classifiers. The processing involves use of random sieve function, phase information in the data transformed using Fourier and Hilbert transformations. This processing results in improved classification, as against using the voxel intensities directly, as illustrated. The novelty of the proposed method lies in utilizing the phase information in the transformed domain, for classifying between the cognitive tasks along with random sieve function chosen with a particular probability distribution. The proposed classification procedure is applied on a publicly available dataset, StarPlus data, with 6 subjects performing the two distinct cognitive tasks of watching either a picture or a sentence. The classification accuracy stands at an average of 65.6%(using Naive Bayes classifier) and 76.4%(using SVM classifier) for raw data. The corresponding classification accuracy stands at 96.8% and 97.5% for Fourier transformed data. For Hilbert transformed data, it is 93.7% and 99%, for 6 subjects, on 2 cognitive tasks. version:1
arxiv-1602-03822 | Neural Network Support Vector Detection via a Soft-Label, Hybrid K-Means Classifier | http://arxiv.org/abs/1602.03822 | id:1602.03822 author:Robert A. Murphy category:cs.LG 60D05  62C99  published:2016-02-11 summary:We use random geometric graphs to describe clusters of higher dimensional data points which are bijectively mapped to a (possibly) lower dimensional space where an equivalent random cluster model is used to calculate the expected number of modes to be found when separating the data of a multi-modal data set into distinct clusters. Furthermore, as a function of the expected number of modes and the number of data points in the sample, an upper bound on a given distance measure is found such that data points have the greatest correlation if their mutual distances from a common center is less than or equal to the calculated bound. Anomalies are exposed, which lie outside of the union of all regularized clusters of data points. Similar to finding a hyperplane which can be shifted along its normal to expose the maximal distance between binary classes, it is shown that the union of regularized clusters can be used to define a hyperplane which can be shifted by a certain amount to separate the data into binary classes and that the shifted hyperplane defines the activation function for a two-class discriminating neural network. Lastly, this neural network is used to detect the set of support vectors which determines the maximally-separating region between the binary classes. version:5
arxiv-1504-00702 | End-to-End Training of Deep Visuomotor Policies | http://arxiv.org/abs/1504.00702 | id:1504.00702 author:Sergey Levine, Chelsea Finn, Trevor Darrell, Pieter Abbeel category:cs.LG cs.CV cs.RO  published:2015-04-02 summary:Policy search methods can allow robots to learn control policies for a wide range of tasks, but practical applications of policy search often require hand-engineered components for perception, state estimation, and low-level control. In this paper, we aim to answer the following question: does training the perception and control systems jointly end-to-end provide better performance than training each component separately? To this end, we develop a method that can be used to learn policies that map raw image observations directly to torques at the robot's motors. The policies are represented by deep convolutional neural networks (CNNs) with 92,000 parameters, and are trained using a partially observed guided policy search method, which transforms policy search into supervised learning, with supervision provided by a simple trajectory-centric reinforcement learning method. We evaluate our method on a range of real-world manipulation tasks that require close coordination between vision and control, such as screwing a cap onto a bottle, and present simulated comparisons to a range of prior policy search methods. version:5
arxiv-1604-05393 | An Adaptive Learning Mechanism for Selection of Increasingly More Complex Systems | http://arxiv.org/abs/1604.05393 | id:1604.05393 author:Fouad Khan category:cs.IT cs.LG math.IT  published:2016-04-19 summary:Recently it has been demonstrated that causal entropic forces can lead to the emergence of complex phenomena associated with human cognitive niche such as tool use and social cooperation. Here I show that even more fundamental traits associated with human cognition such as 'self-awareness' can easily be demonstrated to be arising out of merely a selection for 'better regulators'; i.e. systems which respond comparatively better to threats to their existence which are internal to themselves. A simple model demonstrates how indeed the average self-awareness for a universe of systems continues to rise as less self-aware systems are eliminated. The model also demonstrates however that the maximum attainable self-awareness for any system is limited by the plasticity and energy availability for that typology of systems. I argue that this rise in self-awareness may be the reason why systems tend towards greater complexity. version:1
arxiv-1604-05383 | Learning Dense Correspondence via 3D-guided Cycle Consistency | http://arxiv.org/abs/1604.05383 | id:1604.05383 author:Tinghui Zhou, Philipp Krähenbühl, Mathieu Aubry, Qixing Huang, Alexei A. Efros category:cs.CV  published:2016-04-18 summary:Discriminative deep learning approaches have shown impressive results for problems where human-labeled ground truth is plentiful, but what about tasks where labels are difficult or impossible to obtain? This paper tackles one such problem: establishing dense visual correspondence across different object instances. For this task, although we do not know what the ground-truth is, we know it should be consistent across instances of that category. We exploit this consistency as a supervisory signal to train a convolutional neural network to predict cross-instance correspondences between pairs of images depicting objects of the same category. For each pair of training images we find an appropriate 3D CAD model and render two synthetic views to link in with the pair, establishing a correspondence flow 4-cycle. We use ground-truth synthetic-to-synthetic correspondences, provided by the rendering engine, to train a ConvNet to predict synthetic-to-real, real-to-real and real-to-synthetic correspondences that are cycle-consistent with the ground-truth. At test time, no CAD models are required. We demonstrate that our end-to-end trained ConvNet supervised by cycle-consistency outperforms state-of-the-art pairwise matching methods in correspondence-related tasks. version:1
arxiv-1604-05377 | Churn analysis using deep convolutional neural networks and autoencoders | http://arxiv.org/abs/1604.05377 | id:1604.05377 author:Artit Wangperawong, Cyrille Brun, Olav Laudy, Rujikorn Pavasuthipaisit category:stat.ML cs.LG cs.NE  published:2016-04-18 summary:Customer temporal behavioral data was represented as images in order to perform churn prediction by leveraging deep learning architectures prominent in image classification. Supervised learning was performed on labeled data of over 6 million customers using deep convolutional neural networks, which achieved an AUC of 0.743 on the test dataset using no more than 12 temporal features for each customer. Unsupervised learning was conducted using autoencoders to better understand the reasons for customer churn. Images that maximally activate the hidden units of an autoencoder trained with churned customers reveal ample opportunities for action to be taken to prevent churn among strong data, no voice users. version:1
arxiv-1604-05372 | Clustering Comparable Corpora of Russian and Ukrainian Academic Texts: Word Embeddings and Semantic Fingerprints | http://arxiv.org/abs/1604.05372 | id:1604.05372 author:Andrey Kutuzov, Mikhail Kopotev, Tatyana Sviridenko, Lyubov Ivanova category:cs.CL  published:2016-04-18 summary:We present our experience in applying distributional semantics (neural word embeddings) to the problem of representing and clustering documents in a bilingual comparable corpus. Our data is a collection of Russian and Ukrainian academic texts, for which topics are their academic fields. In order to build language-independent semantic representations of these documents, we train neural distributional models on monolingual corpora and learn the optimal linear transformation of vectors from one language to another. The resulting vectors are then used to produce `semantic fingerprints' of documents, serving as input to a clustering algorithm. The presented method is compared to several baselines including `orthographic translation' with Levenshtein edit distance and outperforms them by a large margin. We also show that language-independent `semantic fingerprints' are superior to multi-lingual clustering algorithms proposed in the previous work, at the same time requiring less linguistic resources. version:1
arxiv-1510-06335 | Time-Sensitive Bayesian Information Aggregation for Crowdsourcing Systems | http://arxiv.org/abs/1510.06335 | id:1510.06335 author:Matteo Venanzi, John Guiver, Pushmeet Kohli, Nick Jennings category:cs.AI cs.LG  published:2015-10-21 summary:Crowdsourcing systems commonly face the problem of aggregating multiple judgments provided by potentially unreliable workers. In addition, several aspects of the design of efficient crowdsourcing processes, such as defining worker's bonuses, fair prices and time limits of the tasks, involve knowledge of the likely duration of the task at hand. Bringing this together, in this work we introduce a new time--sensitive Bayesian aggregation method that simultaneously estimates a task's duration and obtains reliable aggregations of crowdsourced judgments. Our method, called BCCTime, builds on the key insight that the time taken by a worker to perform a task is an important indicator of the likely quality of the produced judgment. To capture this, BCCTime uses latent variables to represent the uncertainty about the workers' completion time, the tasks' duration and the workers' accuracy. To relate the quality of a judgment to the time a worker spends on a task, our model assumes that each task is completed within a latent time window within which all workers with a propensity to genuinely attempt the labelling task (i.e., no spammers) are expected to submit their judgments. In contrast, workers with a lower propensity to valid labeling, such as spammers, bots or lazy labelers, are assumed to perform tasks considerably faster or slower than the time required by normal workers. Specifically, we use efficient message-passing Bayesian inference to learn approximate posterior probabilities of (i) the confusion matrix of each worker, (ii) the propensity to valid labeling of each worker, (iii) the unbiased duration of each task and (iv) the true label of each task. Using two real-world public datasets for entity linking tasks, we show that BCCTime produces up to 11% more accurate classifications and up to 100% more informative estimates of a task's duration compared to state-of-the-art methods. version:2
arxiv-1604-05288 | Uniform Coherence | http://arxiv.org/abs/1604.05288 | id:1604.05288 author:Scott Garrabrant, Benya Fallenstein, Abram Demski, Nate Soares category:cs.AI cs.LG math.PR  published:2016-04-18 summary:While probability theory is normally applied to external environments, there has been some recent interest in probabilistic modeling of the outputs of computations that are too expensive to run. Since mathematical logic is a powerful tool for reasoning about computer programs, we consider this problem from the perspective of integrating probability and logic. Recent work on assigning probabilities to mathematical statements has used the concept of coherent distributions, which satisfy logical constraints such as the probability of a sentence and its negation summing to one. Although there are algorithms which converge to a coherent probability distribution in the limit, this yields only weak guarantees about finite approximations of these distributions. In our setting, this is a significant limitation: Coherent distributions assign probability one to all statements provable in a specific logical theory, such as Peano Arithmetic, which can prove what the output of any terminating computation is; thus, a coherent distribution must assign probability one to the output of any terminating computation. To model uncertainty about computations, we propose to work with approximations to coherent distributions. We introduce uniform coherence, a strengthening of coherence that provides appropriate constraints on finite approximations, and propose an algorithm which satisfies this criterion. version:1
arxiv-1603-08983 | Adaptive Computation Time for Recurrent Neural Networks | http://arxiv.org/abs/1603.08983 | id:1603.08983 author:Alex Graves category:cs.NE  published:2016-03-29 summary:This paper introduces Adaptive Computation Time (ACT), an algorithm that allows recurrent neural networks to learn how many computational steps to take between receiving an input and emitting an output. ACT requires minimal changes to the network architecture, is deterministic and differentiable, and does not add any noise to the parameter gradients. Experimental results are provided for four synthetic problems: determining the parity of binary vectors, applying binary logic operations, adding integers, and sorting real numbers. Overall, performance is dramatically improved by the use of ACT, which successfully adapts the number of computational steps to the requirements of the problem. We also present character-level language modelling results on the Hutter prize Wikipedia dataset. In this case ACT does not yield large gains in performance; however it does provide intriguing insight into the structure of the data, with more computation allocated to harder-to-predict transitions, such as spaces between words and ends of sentences. This suggests that ACT or other adaptive computation methods could provide a generic method for inferring segment boundaries in sequence data. version:4
arxiv-1604-05280 | Asymptotic Convergence in Online Learning with Unbounded Delays | http://arxiv.org/abs/1604.05280 | id:1604.05280 author:Scott Garrabrant, Nate Soares, Jessica Taylor category:cs.LG cs.AI math.PR  published:2016-04-18 summary:We study the problem of predicting the results of computations that are too expensive to run, via the observation of the results of smaller computations. We model this as an online learning problem with delayed feedback, where the length of the delay is unbounded, which we study mainly in a stochastic setting. We show that in this setting, consistency is not possible in general, and that optimal forecasters might not have average regret going to zero. However, it is still possible to give algorithms that converge asymptotically to Bayes-optimal predictions, by evaluating forecasters on specific sparse independent subsequences of their predictions. We give an algorithm that does this, which converges asymptotically on good behavior, and give very weak bounds on how long it takes to converge. We then relate our results back to the problem of predicting large computations in a deterministic setting. version:1
arxiv-1604-05559 | Efficient Calculation of Bigram Frequencies in a Corpus of Short Texts | http://arxiv.org/abs/1604.05559 | id:1604.05559 author:Melvyn Drag, Gauthaman Vasudevan category:cs.CL  published:2016-04-18 summary:We show that an efficient and popular method for calculating bigram frequencies is unsuitable for bodies of short texts and offer a simple alternative. Our method has the same computational complexity as the old method and offers an exact count instead of an approximation. version:1
arxiv-1604-05263 | Chained Gaussian Processes | http://arxiv.org/abs/1604.05263 | id:1604.05263 author:Alan D. Saul, James Hensman, Aki Vehtari, Neil D. Lawrence category:stat.ML cs.LG  published:2016-04-18 summary:Gaussian process models are flexible, Bayesian non-parametric approaches to regression. Properties of multivariate Gaussians mean that they can be combined linearly in the manner of additive models and via a link function (like in generalized linear models) to handle non-Gaussian data. However, the link function formalism is restrictive, link functions are always invertible and must convert a parameter of interest to a linear combination of the underlying processes. There are many likelihoods and models where a non-linear combination is more appropriate. We term these more general models Chained Gaussian Processes: the transformation of the GPs to the likelihood parameters will not generally be invertible, and that implies that linearisation would only be possible with multiple (localized) links, i.e. a chain. We develop an approximate inference procedure for Chained GPs that is scalable and applicable to any factorized likelihood. We demonstrate the approximation on a range of likelihood functions. version:1
arxiv-1604-05257 | Risk-Averse Multi-Armed Bandit Problems under Mean-Variance Measure | http://arxiv.org/abs/1604.05257 | id:1604.05257 author:Sattar Vakili, Qing Zhao category:cs.LG  published:2016-04-18 summary:The multi-armed bandit problems have been studied mainly under the measure of expected total reward accrued over a horizon of length $T$. In this paper, we address the issue of risk in multi-armed bandit problems and develop parallel results under the measure of mean-variance, a commonly adopted risk measure in economics and mathematical finance. We show that the model-specific regret and the model-independent regret in terms of the mean-variance of the reward process are lower bounded by $\Omega(\log T)$ and $\Omega(T^{2/3})$, respectively. We then show that variations of the UCB policy and the DSEE policy developed for the classic risk-neutral MAB achieve these lower bounds. version:1
arxiv-1604-05251 | Kernel Distribution Embeddings: Universal Kernels, Characteristic Kernels and Kernel Metrics on Distributions | http://arxiv.org/abs/1604.05251 | id:1604.05251 author:Carl-Johann Simon-Gabriel, Bernhard Schölkopf category:stat.ML math.FA math.PR G.3  published:2016-04-18 summary:Kernel mean embeddings have recently attracted the attention of the machine learning community. They map measures $\mu$ from some set $M$ to functions in a reproducing kernel Hilbert space (RKHS) with kernel $k$. The RKHS distance of two mapped measures is a semi-metric $d_k$ over $M$. We study three questions. (I) For a given kernel, what sets $M$ can be embedded? (II) When is the embedding injective over $M$ (in which case $d_k$ is a metric)? (III) How does the $d_k$-induced topology compare to other topologies on $M$? The existing machine learning literature has addressed these questions in cases where $M$ is (a subset of) the finite regular Borel measures. We unify, improve and generalise those results. Our approach naturally leads to continuous and possibly even injective embeddings of (Schwartz-) distributions, i.e., generalised measures, but the reader is free to focus on measures only. In particular, we systemise and extend various (partly known) equivalences between different notions of universal, characteristic and strictly positive definite kernels, and show that on an underlying locally compact Hausdorff space, $d_k$ metrises the weak convergence of probability measures if and only if $k$ is continuous and characteristic. version:1
arxiv-1604-05307 | Learning Sparse Additive Models with Interactions in High Dimensions | http://arxiv.org/abs/1604.05307 | id:1604.05307 author:Hemant Tyagi, Anastasios Kyrillidis, Bernd Gärtner, Andreas Krause category:cs.LG cs.IT math.IT stat.ML  published:2016-04-18 summary:A function $f: \mathbb{R}^d \rightarrow \mathbb{R}$ is referred to as a Sparse Additive Model (SPAM), if it is of the form $f(\mathbf{x}) = \sum_{l \in \mathcal{S}}\phi_{l}(x_l)$, where $\mathcal{S} \subset [d]$, $ \mathcal{S} \ll d$. Assuming $\phi_l$'s and $\mathcal{S}$ to be unknown, the problem of estimating $f$ from its samples has been studied extensively. In this work, we consider a generalized SPAM, allowing for second order interaction terms. For some $\mathcal{S}_1 \subset [d], \mathcal{S}_2 \subset {[d] \choose 2}$, the function $f$ is assumed to be of the form: $$f(\mathbf{x}) = \sum_{p \in \mathcal{S}_1}\phi_{p} (x_p) + \sum_{(l,l^{\prime}) \in \mathcal{S}_2}\phi_{(l,l^{\prime})} (x_{l},x_{l^{\prime}}).$$ Assuming $\phi_{p},\phi_{(l,l^{\prime})}$, $\mathcal{S}_1$ and, $\mathcal{S}_2$ to be unknown, we provide a randomized algorithm that queries $f$ and exactly recovers $\mathcal{S}_1,\mathcal{S}_2$. Consequently, this also enables us to estimate the underlying $\phi_p, \phi_{(l,l^{\prime})}$. We derive sample complexity bounds for our scheme and also extend our analysis to include the situation where the queries are corrupted with noise -- either stochastic, or arbitrary but bounded. Lastly, we provide simulation results on synthetic data, that validate our theoretical findings. version:1
arxiv-1604-05210 | Pieces-of-parts for supervoxel segmentation with global context: Application to DCE-MRI tumour delineation | http://arxiv.org/abs/1604.05210 | id:1604.05210 author:Benjamin Irving, James M Franklin, Bartlomiej W Papiez, Ewan M Anderson, Ricky A Sharma, Fergus V Gleeson, Sir Michael Brady, Julia A Schnabel category:cs.CV  published:2016-04-18 summary:Rectal tumour segmentation in dynamic contrast-enhanced MRI (DCE-MRI) is a challenging task, and an automated and consistent method would be highly desirable to improve the modelling and prediction of patient outcomes from tissue contrast enhancement characteristics - particularly in routine clinical practice. A framework is developed to automate DCE-MRI tumour segmentation, by introducing: perfusion-supervoxels to over-segment and classify DCE-MRI volumes using the dynamic contrast enhancement characteristics; and the pieces-of-parts graphical model, which adds global (anatomic) constraints that further refine the supervoxel components that comprise the tumour. The framework was evaluated on 23 DCE-MRI scans of patients with rectal adenocarcinomas, and achieved a voxelwise area-under the receiver operating characteristic curve (AUC) of 0.97 compared to expert delineations. Creating a binary tumour segmentation, 21 of the 23 cases were segmented correctly with a median Dice similarity coefficient (DSC) of 0.63, which is close to the inter-rater variability of this challenging task. A sec- ond study is also included to demonstrate the method's generalisability and achieved a DSC of 0.71. The framework achieves promising results for the underexplored area of rectal tumour segmentation in DCE-MRI, and the methods have potential to be applied to other DCE-MRI and supervoxel segmentation problems version:1
arxiv-1604-05198 | Locally Imposing Function for Generalized Constraint Neural Networks - A Study on Equality Constraints | http://arxiv.org/abs/1604.05198 | id:1604.05198 author:Linlin Cao, Ran He, Bao-Gang Hu category:cs.NE cs.LG stat.ML  published:2016-04-18 summary:This work is a further study on the Generalized Constraint Neural Network (GCNN) model [1], [2]. Two challenges are encountered in the study, that is, to embed any type of prior information and to select its imposing schemes. The work focuses on the second challenge and studies a new constraint imposing scheme for equality constraints. A new method called locally imposing function (LIF) is proposed to provide a local correction to the GCNN prediction function, which therefore falls within Locally Imposing Scheme (LIS). In comparison, the conventional Lagrange multiplier method is considered as Globally Imposing Scheme (GIS) because its added constraint term exhibits a global impact to its objective function. Two advantages are gained from LIS over GIS. First, LIS enables constraints to fire locally and explicitly in the domain only where they need on the prediction function. Second, constraints can be implemented within a network setting directly. We attempt to interpret several constraint methods graphically from a viewpoint of the locality principle. Numerical examples confirm the advantages of the proposed method. In solving boundary value problems with Dirichlet and Neumann constraints, the GCNN model with LIF is possible to achieve an exact satisfaction of the constraints. version:1
arxiv-1604-05144 | ScribbleSup: Scribble-Supervised Convolutional Networks for Semantic Segmentation | http://arxiv.org/abs/1604.05144 | id:1604.05144 author:Di Lin, Jifeng Dai, Jiaya Jia, Kaiming He, Jian Sun category:cs.CV  published:2016-04-18 summary:Large-scale data is of crucial importance for learning semantic segmentation models, but annotating per-pixel masks is a tedious and inefficient procedure. We note that for the topic of interactive image segmentation, scribbles are very widely used in academic research and commercial software, and are recognized as one of the most user-friendly ways of interacting. In this paper, we propose to use scribbles to annotate images, and develop an algorithm to train convolutional networks for semantic segmentation supervised by scribbles. Our algorithm is based on a graphical model that jointly propagates information from scribbles to unmarked pixels and learns network parameters. We present competitive object semantic segmentation results on the PASCAL VOC dataset by using scribbles as annotations. Scribbles are also favored for annotating stuff (e.g., water, sky, grass) that has no well-defined shape, and our method shows excellent results on the PASCAL-CONTEXT dataset thanks to extra inexpensive scribble annotations. Our scribble annotations on PASCAL VOC are available at http://research.microsoft.com/en-us/um/people/jifdai/downloads/scribble_sup version:1
arxiv-1604-05132 | Using Self-Contradiction to Learn Confidence Measures in Stereo Vision | http://arxiv.org/abs/1604.05132 | id:1604.05132 author:Christian Mostegel, Markus Rumpler, Friedrich Fraundorfer, Horst Bischof category:cs.CV  published:2016-04-18 summary:Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision. However, acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction, active sensing devices and/or synthetic scenes. To overcome this problem, we propose a new, flexible, and scalable way for generating training data that only requires a set of stereo images as input. The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm. This enables us to generate a huge amount of training data in a fully automated manner. Among other experiments, we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data. version:1
arxiv-1512-02497 | Deep Exemplar 2D-3D Detection by Adapting from Real to Rendered Views | http://arxiv.org/abs/1512.02497 | id:1512.02497 author:Francisco Massa, Bryan Russell, Mathieu Aubry category:cs.CV cs.LG cs.NE  published:2015-12-08 summary:This paper presents an end-to-end convolutional neural network (CNN) for 2D-3D exemplar detection. We demonstrate that the ability to adapt the features of natural images to better align with those of CAD rendered views is critical to the success of our technique. We show that the adaptation can be learned by compositing rendered views of textured object models on natural images. Our approach can be naturally incorporated into a CNN detection pipeline and extends the accuracy and speed benefits from recent advances in deep learning to 2D-3D exemplar detection. We applied our method to two tasks: instance detection, where we evaluated on the IKEA dataset, and object category detection, where we out-perform Aubry et al. for "chair" detection on a subset of the Pascal VOC dataset. version:2
arxiv-1511-00363 | BinaryConnect: Training Deep Neural Networks with binary weights during propagations | http://arxiv.org/abs/1511.00363 | id:1511.00363 author:Matthieu Courbariaux, Yoshua Bengio, Jean-Pierre David category:cs.LG cs.CV cs.NE  published:2015-11-02 summary:Deep Neural Networks (DNN) have achieved state-of-the-art results in a wide range of tasks, with the best results obtained with large training sets and large models. In the past, GPUs enabled these breakthroughs because of their greater computational speed. In the future, faster computation at both training and test time is likely to be crucial for further progress and for consumer applications on low-power devices. As a result, there is much interest in research and development of dedicated hardware for Deep Learning (DL). Binary weights, i.e., weights which are constrained to only two possible values (e.g. -1 or 1), would bring great benefits to specialized DL hardware by replacing many multiply-accumulate operations by simple accumulations, as multipliers are the most space and power-hungry components of the digital implementation of neural networks. We introduce BinaryConnect, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated. Like other dropout schemes, we show that BinaryConnect acts as regularizer and we obtain near state-of-the-art results with BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN. version:3
arxiv-1601-05991 | Speech vocoding for laboratory phonology | http://arxiv.org/abs/1601.05991 | id:1601.05991 author:Milos Cernak, Stefan Benus, Alexandros Lazaridis category:cs.CL cs.SD  published:2016-01-22 summary:Using phonological speech vocoding, we propose a platform for exploring relations between phonology and speech processing, and in broader terms, for exploring relations between the abstract and physical structures of a speech signal. Our goal is to make a step towards bridging phonology and speech processing and to contribute to the program of Laboratory Phonology. We show three application examples for laboratory phonology: compositional phonological speech modelling, a comparison of phonological systems and an experimental phonological parametric text-to-speech (TTS) system. The featural representations of the following three phonological systems are considered in this work: (i) Government Phonology (GP), (ii) the Sound Pattern of English (SPE), and (iii) the extended SPE (eSPE). Comparing GP- and eSPE-based vocoded speech, we conclude that the latter achieves slightly better results than the former. However, GP - the most compact phonological speech representation - performs comparably to the systems with a higher number of phonological features. The parametric TTS based on phonological speech representation, and trained from an unlabelled audiobook in an unsupervised manner, achieves intelligibility of 85% of the state-of-the-art parametric speech synthesis. We envision that the presented approach paves the way for researchers in both fields to form meaningful hypotheses that are explicitly testable using the concepts developed and exemplified in this paper. On the one hand, laboratory phonologists might test the applied concepts of their theoretical models, and on the other hand, the speech processing community may utilize the concepts developed for the theoretical phonological models for improvements of the current state-of-the-art applications. version:2
arxiv-1604-05096 | Pixel-level Encoding and Depth Layering for Instance-level Semantic Labeling | http://arxiv.org/abs/1604.05096 | id:1604.05096 author:Jonas Uhrig, Marius Cordts, Uwe Franke, Thomas Brox category:cs.CV  published:2016-04-18 summary:Recent approaches for instance-aware semantic labeling have augmented convolutional neural networks (CNNs) with complex multi-task architectures or computationally expensive graphical models. We present a method that leverages a fully convolutional network (FCN) to predict semantic labels, depth and an instance-based encoding using each pixel's direction towards its corresponding instance center. Subsequently, we apply low-level computer vision techniques to generate state-of-the-art instance segmentation on the street scene datasets KITTI and Cityscapes. Our approach outperforms existing works by a large margin and can additionally predict absolute distances of individual instances from a monocular image as well as a pixel-level semantic labeling. version:1
arxiv-1604-05085 | Mastering $2048$ with Delayed Temporal Coherence Learning, Multi-State Weight Promotion, Redundant Encoding and Carousel Shaping | http://arxiv.org/abs/1604.05085 | id:1604.05085 author:Wojciech Jaśkowski category:cs.AI cs.LG I.2.6; I.2.8  published:2016-04-18 summary:$2048$ is an engaging single-player, nondeterministic video puzzle game, which, thanks to the simple rules and hard-to-master gameplay, has gained massive popularity in recent years. As $2048$ can be conveniently embedded into the discrete-state Markov decision processes framework, we treat it as a testbed for evaluating existing and new methods in reinforcement learning. With the aim to develop a strong $2048$ playing program, we employ temporal difference learning with systematic n-tuple networks. We show that this basic method can be significantly improved with temporal coherence learning, multi-stage function approximator with weight promotion, carousel shaping, and redundant encoding. In addition, we demonstrate how to take advantage of the characteristics of the n-tuple network, to improve the algorithmic effectiveness of the learning process by i) delaying the (decayed) update and applying lock-free optimistic parallelism to effortlessly make advantage of multiple CPU cores. This way, we were able to develop the best known $2048$ playing program to date, which confirms the effectiveness of the introduced methods for discrete-state Markov decision problems. version:1
arxiv-1604-05080 | Demonstrating Hybrid Learning in a Flexible Neuromorphic Hardware System | http://arxiv.org/abs/1604.05080 | id:1604.05080 author:Simon Friedmann, Johannes Schemmel, Andreas Gruebl, Andreas Hartel, Matthias Hock, Karlheinz Meier category:q-bio.NC cond-mat.dis-nn cs.NE  published:2016-04-18 summary:We present results from a new approach to learning and plasticity in neuromorphic hardware systems: to enable flexibility in implementable learning mechanisms while keeping high efficiency associated with neuromorphic implementations, we combine a general-purpose processor with full-custom analog elements. This processor is operating in parallel with a fully parallel neuromorphic system consisting of an array of synapses connected to analog, continuous time neuron circuits. Novel analog correlation sensor circuits process spike events for each synapse in parallel and in real-time. The processor uses this pre-processing to compute new weights possibly using additional information following its program. Therefore, learning rules can be defined in software giving a large degree of flexibility. Synapses realize correlation detection geared towards Spike-Timing Dependent Plasticity (STDP) as central computational primitive in the analog domain. Operating at a speed-up factor of 1000 compared to biological time-scale, we measure time-constants from tens to hundreds of micro-seconds. We analyze variability across multiple chips and demonstrate learning using a multiplicative STDP rule. We conclude, that the presented approach will enable flexible and efficient learning as a platform for neuroscientific research and technological applications. version:1
arxiv-1604-05073 | Speed-Constrained Tuning for Statistical Machine Translation Using Bayesian Optimization | http://arxiv.org/abs/1604.05073 | id:1604.05073 author:Daniel Beck, Adrià de Gispert, Gonzalo Iglesias, Aurelien Waite, Bill Byrne category:cs.CL  published:2016-04-18 summary:We address the problem of automatically finding the parameters of a statistical machine translation system that maximize BLEU scores while ensuring that decoding speed exceeds a minimum value. We propose the use of Bayesian Optimization to efficiently tune the speed-related decoding parameters by easily incorporating speed as a noisy constraint function. The obtained parameter values are guaranteed to satisfy the speed constraint with an associated confidence margin. Across three language pairs and two speed constraint values, we report overall optimization time reduction compared to grid and random search. We also show that Bayesian Optimization can decouple speed and BLEU measurements, resulting in a further reduction of overall optimization time as speed is measured over a small subset of sentences. version:1
arxiv-1212-3276 | Learning Sparse Low-Threshold Linear Classifiers | http://arxiv.org/abs/1212.3276 | id:1212.3276 author:Sivan Sabato, Shai Shalev-Shwartz, Nathan Srebro, Daniel Hsu, Tong Zhang category:stat.ML cs.LG  published:2012-12-13 summary:We consider the problem of learning a non-negative linear classifier with a $1$-norm of at most $k$, and a fixed threshold, under the hinge-loss. This problem generalizes the problem of learning a $k$-monotone disjunction. We prove that we can learn efficiently in this setting, at a rate which is linear in both $k$ and the size of the threshold, and that this is the best possible rate. We provide an efficient online learning algorithm that achieves the optimal rate, and show that in the batch case, empirical risk minimization achieves this rate as well. The rates we show are tighter than the uniform convergence rate, which grows with $k^2$. version:3
arxiv-1307-1827 | Loss minimization and parameter estimation with heavy tails | http://arxiv.org/abs/1307.1827 | id:1307.1827 author:Daniel Hsu, Sivan Sabato category:cs.LG stat.ML  published:2013-07-07 summary:This work studies applications and generalizations of a simple estimation technique that provides exponential concentration under heavy-tailed distributions, assuming only bounded low-order moments. We show that the technique can be used for approximate minimization of smooth and strongly convex losses, and specifically for least squares linear regression. For instance, our $d$-dimensional estimator requires just $\tilde{O}(d\log(1/\delta))$ random samples to obtain a constant factor approximation to the optimal least squares loss with probability $1-\delta$, without requiring the covariates or noise to be bounded or subgaussian. We provide further applications to sparse linear regression and low-rank covariance matrix estimation with similar allowances on the noise and covariate distributions. The core technique is a generalization of the median-of-means estimator to arbitrary metric spaces. version:7
arxiv-1604-05027 | Most Likely Separation of Intensity and Warping Effects in Image Registration | http://arxiv.org/abs/1604.05027 | id:1604.05027 author:Line Kühnel, Stefan Sommer, Akshay Pai, Lars Lau Raket category:cs.CV  published:2016-04-18 summary:This paper introduces a class of mixed-effects models for joint modeling of spatially correlated intensity variation and warping variation in 2D images. Spatially correlated intensity variation and warp variation are modeled as random effects, resulting in a nonlinear mixed-effects model that enables simultaneous estimation of template and model parameters by optimization of the likelihood function. We propose an algorithm for fitting the model which alternates estimation of variance parameters and image registration, thus avoiding potential estimation bias resulting from treating registration as a preprocessing step. We apply the model to datasets of facial images and 2D brain magnetic resonance images to illustrate the simultaneous estimation and prediction of intensity and warp effects. version:1
arxiv-1604-05024 | Empirical study of PROXTONE and PROXTONE$^+$ for Fast Learning of Large Scale Sparse Models | http://arxiv.org/abs/1604.05024 | id:1604.05024 author:Ziqiang Shi, Rujie Liu category:cs.LG cs.AI  published:2016-04-18 summary:PROXTONE is a novel and fast method for optimization of large scale non-smooth convex problem \cite{shi2015large}. In this work, we try to use PROXTONE method in solving large scale \emph{non-smooth non-convex} problems, for example training of sparse deep neural network (sparse DNN) or sparse convolutional neural network (sparse CNN) for embedded or mobile device. PROXTONE converges much faster than first order methods, while first order method is easy in deriving and controlling the sparseness of the solutions. Thus in some applications, in order to train sparse models fast, we propose to combine the merits of both methods, that is we use PROXTONE in the first several epochs to reach the neighborhood of an optimal solution, and then use the first order method to explore the possibility of sparsity in the following training. We call such method PROXTONE plus (PROXTONE$^+$). Both PROXTONE and PROXTONE$^+$ are tested in our experiments, and which demonstrate both methods improved convergence speed twice as fast at least on diverse sparse model learning problems, and at the same time reduce the size to 0.5\% for DNN models. The source of all the algorithms is available upon request. version:1
arxiv-1604-05008 | Forecasting Volatility in Indian Stock Market using Artificial Neural Network with Multiple Inputs and Outputs | http://arxiv.org/abs/1604.05008 | id:1604.05008 author:Tamal Datta Chaudhuri, Indranil Ghosh category:cs.NE  published:2016-04-18 summary:Volatility in stock markets has been extensively studied in the applied finance literature. In this paper, Artificial Neural Network models based on various back propagation algorithms have been constructed to predict volatility in the Indian stock market through volatility of NIFTY returns and volatility of gold returns. This model considers India VIX, CBOE VIX, volatility of crude oil returns (CRUDESDR), volatility of DJIA returns (DJIASDR), volatility of DAX returns (DAXSDR), volatility of Hang Seng returns (HANGSDR) and volatility of Nikkei returns (NIKKEISDR) as predictor variables. Three sets of experiments have been performed over three time periods to judge the effectiveness of the approach. version:1
arxiv-1604-04994 | Selective Convolutional Descriptor Aggregation for Fine-Grained Image Retrieval | http://arxiv.org/abs/1604.04994 | id:1604.04994 author:Xiu-Shen Wei, Jian-Hao Luo, Jianxin Wu category:cs.CV  published:2016-04-18 summary:Deep convolutional models pre-trained for the ImageNet classification task have been successfully adopted to tasks in other domains, such as texture description and object proposal generation, but these tasks require annotations for images in the new domain. In this paper, we focus on a novel and challenging task in the pure unsupervised setting: fine-grained image retrieval. Even with image labels, fine-grained images are difficult to classify, let alone the unsupervised retrieval task. We propose the Selective Convolutional Descriptor Aggregation (SCDA) method. SCDA firstly localizes the main object(s) in fine-grained images, a step that discards noisy background and keeps useful deep descriptors. The selected descriptors are then aggregated and dimensionality reduced into a short feature vector using the best practices we found. SCDA is unsupervised, using no image label or bounding box annotation. Experiments on four fine-grained datasets confirm the effectiveness of SCDA. Visualization of the SCDA features shows that they correspond to visual attributes (even subtle ones), which might explain SCDA's high accuracy in fine-grained retrieval. version:1
arxiv-1604-03159 | Phase Transitions and a Model Order Selection Criterion for Spectral Graph Clustering | http://arxiv.org/abs/1604.03159 | id:1604.03159 author:Pin-Yu Chen, Alfred O. Hero category:cs.SI stat.ML  published:2016-04-11 summary:One of the longstanding open problems in spectral graph clustering (SGC) is the so-called model order selection problem: automated selection of the correct number of clusters. This is equivalent to the problem of finding the number of connected components or communities in an undirected graph. We propose a solution to the SGC model selection problem under a random interconnection model (RIM) using a novel selection criterion that is based on an asymptotic phase transition analysis. Our solution can more generally be applied to discovering hidden block diagonal structure in symmetric non-negative matrices. Numerical experiments on simulated graphs validate the phase transition analysis, and real-world network data is used to validate the performance of the proposed model selection procedure. version:2
arxiv-1604-04970 | Visual Aesthetic Quality Assessment with Multi-task Deep Learning | http://arxiv.org/abs/1604.04970 | id:1604.04970 author:Yueying Kao, Ran He, Kaiqi Huang category:cs.CV cs.LG cs.NE  published:2016-04-18 summary:This paper considers the problem of assessing visual aesthetic quality with semantic information. We cast the assessment problem as the main task among a multi-task deep model, and argue that semantic recognition offers the key to addressing this problem. Based on convolutional neural networks, we propose a general multi-task framework with four different structures. In each structure, aesthetic quality assessment task and semantic recognition task are leveraged, and different features are explored to improve the quality assessment. Moreover, an effective strategy of keeping a balanced effect between the semantic task and aesthetic task is developed to optimize the parameters of our framework. The correlation analysis among the tasks validates the importance of the semantic recognition in aesthetic quality assessment. Extensive experiments verify the effectiveness of the proposed multi-task framework, and further corroborate the above proposition. version:1
arxiv-1604-04960 | Gaussian Copula Variational Autoencoders for Mixed Data | http://arxiv.org/abs/1604.04960 | id:1604.04960 author:Suwon Suh, Seungjin Choi category:stat.ML cs.LG  published:2016-04-18 summary:The variational autoencoder (VAE) is a generative model with continuous latent variables where a pair of probabilistic encoder (bottom-up) and decoder (top-down) is jointly learned by stochastic gradient variational Bayes. We first elaborate Gaussian VAE, approximating the local covariance matrix of the decoder as an outer product of the principal direction at a position determined by a sample drawn from Gaussian distribution. We show that this model, referred to as VAE-ROC, better captures the data manifold, compared to the standard Gaussian VAE where independent multivariate Gaussian was used to model the decoder. Then we extend the VAE-ROC to handle mixed categorical and continuous data. To this end, we employ Gaussian copula to model the local dependency in mixed categorical and continuous data, leading to {\em Gaussian copula variational autoencoder} (GCVAE). As in VAE-ROC, we use the rank-one approximation for the covariance in the Gaussian copula, to capture the local dependency structure in the mixed data. Experiments on various datasets demonstrate the useful behaviour of VAE-ROC and GCVAE, compared to the standard VAE. version:1
arxiv-1604-04953 | Fully Convolutional Recurrent Network for Handwritten Chinese Text Recognition | http://arxiv.org/abs/1604.04953 | id:1604.04953 author:Zecheng Xie, Zenghui Sun, Lianwen Jin, Ziyong Feng, Shuye Zhang category:cs.CV  published:2016-04-18 summary:This paper proposes an end-to-end framework, namely fully convolutional recurrent network (FCRN) for handwritten Chinese text recognition (HCTR). Unlike traditional methods that rely heavily on segmentation, our FCRN is trained with online text data directly and learns to associate the pen-tip trajectory with a sequence of characters. FCRN consists of four parts: a path-signature layer to extract signature features from the input pen-tip trajectory, a fully convolutional network to learn informative representation, a sequence modeling layer to make per-frame predictions on the input sequence and a transcription layer to translate the predictions into a label sequence. The FCRN is end-to-end trainable in contrast to conventional methods whose components are separately trained and tuned. We also present a refined beam search method that efficiently integrates the language model to decode the FCRN and significantly improve the recognition results. We evaluate the performance of the proposed method on the test sets from the databases CASIA-OLHWDB and ICDAR 2013 Chinese handwriting recognition competition, and both achieve state-of-the-art performance with correct rates of 96.40% and 95.00%, respectively. version:1
arxiv-1507-05131 | Optimal Estimation of Low Rank Density Matrices | http://arxiv.org/abs/1507.05131 | id:1507.05131 author:Vladimir Koltchinskii, Dong Xia category:stat.ML  published:2015-07-17 summary:The density matrices are positively semi-definite Hermitian matrices of unit trace that describe the state of a quantum system. The goal of the paper is to develop minimax lower bounds on error rates of estimation of low rank density matrices in trace regression models used in quantum state tomography (in particular, in the case of Pauli measurements) with explicit dependence of the bounds on the rank and other complexity parameters. Such bounds are established for several statistically relevant distances, including quantum versions of Kullback-Leibler divergence (relative entropy distance) and of Hellinger distance (so called Bures distance), and Schatten $p$-norm distances. Sharp upper bounds and oracle inequalities for least squares estimator with von Neumann entropy penalization are obtained showing that minimax lower bounds are attained (up to logarithmic factors) for these distances. version:4
arxiv-1604-04942 | Global optimization of factor models using alternating minimization | http://arxiv.org/abs/1604.04942 | id:1604.04942 author:Lei Le, Martha White category:stat.ML cs.LG  published:2016-04-17 summary:Learning new representations in machine learning is often tackled using a factorization of the data. For many such problems, including sparse coding and matrix completion, learning these factorizations can be difficult, in terms of efficiency and to guarantee that the solution is a global minimum. Recently, a general class of objectives have been introduced, called induced regularized factor models (RFMs), which have an induced convex form that enables global optimization. Though attractive theoretically, this induced form is impractical, particularly for large or growing datasets. In this work, we investigate the use of a practical alternating minimization algorithms for induced RFMs, that ensure convergence to global optima. We characterize the stationary points of these models, and, using these insights, highlight practical choices for the objectives. We then provide theoretical and empirical evidence that alternating minimization, from a random initialization, converges to global minima for a large subclass of induced RFMs. In particular, we prove that induced RFMs do not have degenerate saddlepoints and that local minima are actually global minima. Finally, we provide an extensive investigation into practical optimization choices for using alternating minimization for induced RFMs, for both batch and stochastic gradient descent. version:1
arxiv-1511-07356 | Recombinator Networks: Learning Coarse-to-Fine Feature Aggregation | http://arxiv.org/abs/1511.07356 | id:1511.07356 author:Sina Honari, Jason Yosinski, Pascal Vincent, Christopher Pal category:cs.CV  published:2015-11-23 summary:Deep neural networks with alternating convolutional, max-pooling and decimation layers are widely used in state of the art architectures for computer vision. Max-pooling purposefully discards precise spatial information in order to create features that are more robust, and typically organized as lower resolution spatial feature maps. On some tasks, such as whole-image classification, max-pooling derived features are well suited; however, for tasks requiring precise localization, such as pixel level prediction and segmentation, max-pooling destroys exactly the information required to perform well. Precise localization may be preserved by shallow convnets without pooling but at the expense of robustness. Can we have our max-pooled multi-layered cake and eat it too? Several papers have proposed summation and concatenation based methods for combining upsampled coarse, abstract features with finer features to produce robust pixel level predictions. Here we introduce another model --- dubbed Recombinator Networks --- where coarse features inform finer features early in their formation such that finer features can make use of several layers of computation in deciding how to use coarse features. The model is trained once, end-to-end and performs better than summation-based architectures, reducing the error from the previous state of the art on two facial keypoint datasets, AFW and AFLW, by 30\% and beating the current state-of-the-art on 300W without using extra data. We improve performance even further by adding a denoising prediction model based on a novel convnet formulation. version:2
arxiv-1604-04939 | Multi-view Learning as a Nonparametric Nonlinear Inter-Battery Factor Analysis | http://arxiv.org/abs/1604.04939 | id:1604.04939 author:Andreas Damianou, Neil D. Lawrence, Carl Henrik Ek category:stat.ML cs.LG math.PR  published:2016-04-17 summary:Factor analysis aims to determine latent factors, or traits, which summarize a given data set. Inter-battery factor analysis extends this notion to multiple views of the data. In this paper we show how a nonlinear, nonparametric version of these models can be recovered through the Gaussian process latent variable model. This gives us a flexible formalism for multi-view learning where the latent variables can be used both for exploratory purposes and for learning representations that enable efficient inference for ambiguous estimation tasks. Learning is performed in a Bayesian manner through the formulation of a variational compression scheme which gives a rigorous lower bound on the log likelihood. Our Bayesian framework provides strong regularization during training, allowing the structure of the latent space to be determined efficiently and automatically. We demonstrate this by producing the first (to our knowledge) published results of learning from dozens of views, even when data is scarce. We further show experimental results on several different types of multi-view data sets and for different kinds of tasks, including exploratory data analysis, generation, ambiguity modelling through latent priors and classification. version:1
arxiv-1511-06499 | The Variational Gaussian Process | http://arxiv.org/abs/1511.06499 | id:1511.06499 author:Dustin Tran, Rajesh Ranganath, David M. Blei category:stat.ML cs.LG cs.NE stat.CO  published:2015-11-20 summary:Variational inference is a powerful tool for approximate inference, and it has been recently applied for representation learning with deep generative models. We develop the variational Gaussian process (VGP), a Bayesian nonparametric variational family, which adapts its shape to match complex posterior distributions. The VGP generates approximate posterior samples by generating latent inputs and warping them through random non-linear mappings; the distribution over random mappings is learned during inference, enabling the transformed outputs to adapt to varying complexity. We prove a universal approximation theorem for the VGP, demonstrating its representative power for learning any model. For inference we present a variational objective inspired by auto-encoders and perform black box inference over a wide class of models. The VGP achieves new state-of-the-art results for unsupervised learning, inferring models such as the deep latent Gaussian model and the recently proposed DRAW. version:4
arxiv-1604-04931 | Regularizing Solutions to the MEG Inverse Problem Using Space-Time Separable Covariance Functions | http://arxiv.org/abs/1604.04931 | id:1604.04931 author:Arno Solin, Pasi Jylänki, Jaakko Kauramäki, Tom Heskes, Marcel A. J. van Gerven, Simo Särkkä category:stat.AP stat.ML  published:2016-04-17 summary:In magnetoencephalography (MEG) the conventional approach to source reconstruction is to solve the underdetermined inverse problem independently over time and space. Here we present how the conventional approach can be extended by regularizing the solution in space and time by a Gaussian process (Gaussian random field) model. Assuming a separable covariance function in space and time, the computational complexity of the proposed model becomes (without any further assumptions or restrictions) $\mathcal{O}(t^3 + n^3 + m^2n)$, where $t$ is the number of time steps, $m$ is the number of sources, and $n$ is the number of sensors. We apply the method to both simulated and empirical data, and demonstrate the efficiency and generality of our Bayesian source reconstruction approach which subsumes various classical approaches in the literature. version:1
arxiv-1604-04926 | Some medical applications of example-based super-resolution | http://arxiv.org/abs/1604.04926 | id:1604.04926 author:Ramin Zabih category:cs.CV  published:2016-04-17 summary:Example-based super-resolution (EBSR) reconstructs a high-resolution image from a low-resolution image, given a training set of high-resolution images. In this note I propose some applications of EBSR to medical imaging. A particular interesting application, which I call "x-ray voxelization", approximates the result of a CT scan from an x-ray image. version:1
arxiv-1604-04906 | Generating Semi-Synthetic Validation Benchmarks for Embryomics | http://arxiv.org/abs/1604.04906 | id:1604.04906 author:Johannes Stegmaier, Julian Arz, Benjamin Schott, Jens C. Otte, Andrei Kobitski, G. Ulrich Nienhaus, Uwe Strähle, Peter Sanders, Ralf Mikut category:cs.CV q-bio.CB q-bio.QM  published:2016-04-17 summary:Systematic validation is an essential part of algorithm development. The enormous dataset sizes and the complexity observed in many recent time-resolved 3D fluorescence microscopy imaging experiments, however, prohibit a comprehensive manual ground truth generation. Moreover, existing simulated benchmarks in this field are often too simple or too specialized to sufficiently validate the observed image analysis problems. We present a new semi-synthetic approach to generate realistic 3D+t benchmarks that combines challenging cellular movement dynamics of real embryos with simulated fluorescent nuclei and artificial image distortions including various parametrizable options like cell numbers, acquisition deficiencies or multiview simulations. We successfully applied the approach to simulate the development of a zebrafish embryo with thousands of cells over 14 hours of its early existence. version:1
arxiv-1406-4175 | From Denoising to Compressed Sensing | http://arxiv.org/abs/1406.4175 | id:1406.4175 author:Christopher A. Metzler, Arian Maleki, Richard G. Baraniuk category:cs.IT math.IT math.ST stat.ML stat.TH  published:2014-06-16 summary:A denoising algorithm seeks to remove noise, errors, or perturbations from a signal. Extensive research has been devoted to this arena over the last several decades, and as a result, today's denoisers can effectively remove large amounts of additive white Gaussian noise. A compressed sensing (CS) reconstruction algorithm seeks to recover a structured signal acquired using a small number of randomized measurements. Typical CS reconstruction algorithms can be cast as iteratively estimating a signal from a perturbed observation. This paper answers a natural question: How can one effectively employ a generic denoiser in a CS reconstruction algorithm? In response, we develop an extension of the approximate message passing (AMP) framework, called Denoising-based AMP (D-AMP), that can integrate a wide class of denoisers within its iterations. We demonstrate that, when used with a high performance denoiser for natural images, D-AMP offers state-of-the-art CS recovery performance while operating tens of times faster than competing methods. We explain the exceptional performance of D-AMP by analyzing some of its theoretical features. A key element in D-AMP is the use of an appropriate Onsager correction term in its iterations, which coerces the signal perturbation at each iteration to be very close to the white Gaussian noise that denoisers are typically designed to remove. version:5
arxiv-1604-04893 | An Initial Seed Selection Algorithm for K-means Clustering of Georeferenced Data to Improve Replicability of Cluster Assignments for Mapping Application | http://arxiv.org/abs/1604.04893 | id:1604.04893 author:Fouad Khan category:cs.LG cs.DS  published:2016-04-17 summary:K-means is one of the most widely used clustering algorithms in various disciplines, especially for large datasets. However the method is known to be highly sensitive to initial seed selection of cluster centers. K-means++ has been proposed to overcome this problem and has been shown to have better accuracy and computational efficiency than k-means. In many clustering problems though -such as when classifying georeferenced data for mapping applications- standardization of clustering methodology, specifically, the ability to arrive at the same cluster assignment for every run of the method i.e. replicability of the methodology, may be of greater significance than any perceived measure of accuracy, especially when the solution is known to be non-unique, as in the case of k-means clustering. Here we propose a simple initial seed selection algorithm for k-means clustering along one attribute that draws initial cluster boundaries along the 'deepest valleys' or greatest gaps in dataset. Thus, it incorporates a measure to maximize distance between consecutive cluster centers which augments the conventional k-means optimization for minimum distance between cluster center and cluster members. Unlike existing initialization methods, no additional parameters or degrees of freedom are introduced to the clustering algorithm. This improves the replicability of cluster assignments by as much as 100% over k-means and k-means++, virtually reducing the variance over different runs to zero, without introducing any additional parameters to the clustering process. Further, the proposed method is more computationally efficient than k-means++ and in some cases, more accurate. version:1
arxiv-1604-04879 | Mahalanobis Distance Metric Learning Algorithm for Instance-based Data Stream Classification | http://arxiv.org/abs/1604.04879 | id:1604.04879 author:Jorge Luis Rivero Perez, Bernardete Ribeiro, Carlos Morell Perez category:cs.LG  published:2016-04-17 summary:With the massive data challenges nowadays and the rapid growing of technology, stream mining has recently received considerable attention. To address the large number of scenarios in which this phenomenon manifests itself suitable tools are required in various research fields. Instance-based data stream algorithms generally employ the Euclidean distance for the classification task underlying this problem. A novel way to look into this issue is to take advantage of a more flexible metric due to the increased requirements imposed by the data stream scenario. In this paper we present a new algorithm that learns a Mahalanobis metric using similarity and dissimilarity constraints in an online manner. This approach hybridizes a Mahalanobis distance metric learning algorithm and a k-NN data stream classification algorithm with concept drift detection. First, some basic aspects of Mahalanobis distance metric learning are described taking into account key properties as well as online distance metric learning algorithms. Second, we implement specific evaluation methodologies and comparative metrics such as Q statistic for data stream classification algorithms. Finally, our algorithm is evaluated on different datasets by comparing its results with one of the best instance-based data stream classification algorithm of the state of the art. The results demonstrate that our proposal is better version:1
arxiv-1604-04873 | From Incremental Meaning to Semantic Unit (phrase by phrase) | http://arxiv.org/abs/1604.04873 | id:1604.04873 author:Andreas Scherbakov, Ekaterina Vylomova, Fei Liu, Timothy Baldwin category:cs.CL 68T50 I.2.7  published:2016-04-17 summary:This paper describes an experimental approach to Detection of Minimal Semantic Units and their Meaning (DiMSUM), explored within the framework of SemEval 2016 Task 10. The approach is primarily based on a combination of word embeddings and parserbased features, and employs unidirectional incremental computation of compositional embeddings for multiword expressions. version:1
arxiv-1604-04848 | Two Points Fundamental Matrix | http://arxiv.org/abs/1604.04848 | id:1604.04848 author:Gil Ben-Artzi, Tavi Halperin, Michael Werman, Shmuel Peleg category:cs.CV  published:2016-04-17 summary:It is well known that computing the fundamental matrix of two uncalibrated cameras requires at least seven corresponding points. We present a method to compute the fundamental matrix between two cameras with only two pairs of corresponding points. Given these two points, we show how to find three pairs of corresponding epipolar lines, from which the fundamental matrix can be computed. Two pairs of epipolar lines, incident to the two pairs of corresponding points, are found by maximizing stereo consistency between lines; corresponding epipolar lines yield a good stereo correspondence. These two epipolar lines intersect at the epipoles, giving a third pair of corresponding points. A third pair of matching epipolar lines, needed to compute the fundamental matrix, is found from lines incident to the epipoles. We validate our method using real-world images and compare it to state-of-the-art methods. Our approach is more accurate by a factor of five compared to the standard method using seven corresponding points, and its accuracy is comparable to the 8-points algorithm. version:1
arxiv-1604-04842 | Subjects and Their Objects: Localizing Interactees for a Person-Centric View of Importance | http://arxiv.org/abs/1604.04842 | id:1604.04842 author:Chao-Yeh Chen, Kristen Grauman category:cs.CV  published:2016-04-17 summary:Understanding images with people often entails understanding their \emph{interactions} with other objects or people. As such, given a novel image, a vision system ought to infer which other objects/people play an important role in a given person's activity. However, existing methods are limited to learning action-specific interactions (e.g., how the pose of a tennis player relates to the position of his racquet when serving the ball) for improved recognition, making them unequipped to reason about novel interactions with actions or objects unobserved in the training data. We propose to predict the "interactee" in novel images---that is, to localize the \emph{object} of a person's action. Given an arbitrary image with a detected person, the goal is to produce a saliency map indicating the most likely positions and scales where that person's interactee would be found. To that end, we explore ways to learn the generic, action-independent connections between (a) representations of a person's pose, gaze, and scene cues and (b) the interactee object's position and scale. We provide results on a newly collected UT Interactee dataset spanning more than 10,000 images from SUN, PASCAL, and COCO. We show that the proposed interaction-informed saliency metric has practical utility for four tasks: contextual object detection, image retargeting, predicting object importance, and data-driven natural language scene description. All four scenarios reveal the value in linking the subject to its object in order to understand the story of an image. version:1
arxiv-1604-04835 | SSP: Semantic Space Projection for Knowledge Graph Embedding with Text Descriptions | http://arxiv.org/abs/1604.04835 | id:1604.04835 author:Han Xiao, Minlie Huang, Xiaoyan Zhu category:cs.CL cs.LG  published:2016-04-17 summary:Knowledge graph embedding represents the entities and relations as numerical vectors, and then knowledge analysis could be promoted as a numerical method. So far, most methods merely concentrate on the fact triples that are composed by the symbolic entities and relations, while the textual information which is supposed to be most critical in NLP could hardly play a reasonable role. For this end, this paper proposes the method SSP which jointly learns from the symbolic triples and textual descriptions. Our model could interact both two information sources by characterizing the correlations, by which means, the textual descriptions could make effects to discover semantic relevance and offer precise semantic embedding. Extensive experiments show our method achieves the substantial improvements against the state-of-the-art baselines on the tasks of knowledge graph completion and entity classification. version:1
arxiv-1604-04834 | Probabilistic Receiver Architecture Combining BP, MF, and EP for Multi-Signal Detection | http://arxiv.org/abs/1604.04834 | id:1604.04834 author:Daniel J. Jakubisin, R. Michael Buehrer, Claudio R. C. M. da Silva category:cs.IT math.IT stat.ML  published:2016-04-17 summary:Receiver algorithms which combine belief propagation (BP) with the mean field (MF) approximation are well-suited for inference of both continuous and discrete random variables. In wireless scenarios involving detection of multiple signals, the standard construction of the combined BP-MF framework includes the equalization or multi-user detection functions within the MF subgraph. In this paper, we show that the MF approximation is not particularly effective for multi-signal detection. We develop a new factor graph construction for application of the BP-MF framework to problems involving the detection of multiple signals. We then develop a low-complexity variant to the proposed construction in which Gaussian BP is applied to the equalization factors. In this case, the factor graph of the joint probability distribution is divided into three subgraphs: (i) a MF subgraph comprised of the observation factors and channel estimation, (ii) a Gaussian BP subgraph which is applied to multi-signal detection, and (iii) a discrete BP subgraph which is applied to demodulation and decoding. Expectation propagation is used to approximate discrete distributions with a Gaussian distribution and links the discrete BP and Gaussian BP subgraphs. The result is a probabilistic receiver architecture with strong theoretical justification which can be applied to multi-signal detection. version:1
arxiv-1604-04825 | Visual saliency detection: a Kalman filter based approach | http://arxiv.org/abs/1604.04825 | id:1604.04825 author:Sourya Roy, Pabitra Mitra category:cs.CV  published:2016-04-17 summary:In this paper we propose a Kalman filter aided saliency detection model which is based on the conjecture that salient regions are considerably different from our "visual expectation" or they are "visually surprising" in nature. In this work, we have structured our model with an immediate objective to predict saliency in static images. However, the proposed model can be easily extended for space-time saliency prediction. Our approach was evaluated using two publicly available benchmark data sets and results have been compared with other existing saliency models. The results clearly illustrate the superior performance of the proposed model over other approaches. version:1
arxiv-1604-04812 | Structured Sparse Convolutional Autoencoder | http://arxiv.org/abs/1604.04812 | id:1604.04812 author:Ehsan Hosseini-Asl, Jacek M. Zurada category:cs.LG cs.NE  published:2016-04-17 summary:This paper aims to improve the feature learning in Convolutional Networks (Convnet) by capturing the structure of objects. A new sparsity function is imposed on the extracted featuremap to capture the structure and shape of the learned object, extracting interpretable features to improve the prediction performance. The proposed algorithm is based on organizing the activation within and across featuremap by constraining the node activities through $\ell_{2}$ and $\ell_{1}$ normalization in a structured form. version:1
arxiv-1604-04808 | Learning Models for Actions and Person-Object Interactions with Transfer to Question Answering | http://arxiv.org/abs/1604.04808 | id:1604.04808 author:Arun Mallya, Svetlana Lazebnik category:cs.CV  published:2016-04-16 summary:In this paper, we propose a convolutional deep network model which utilizes local and global context through feature fusion to make human activity label predictions and achieve state-of-the-art performance on two different activity recognition datasets, the HICO and MPII Human Pose Dataset. We use Multiple Instance Learning to handle the lack of full person instance-label supervision and weighted loss to handle the unbalanced training data. Further, we show how expert knowledge from these specialized datasets can be transferred to improve accuracy on the Visual Question Answering (VQA) task, in the form of multiple choice fill-in-the-blank questions (Visual Madlibs). Specifically, we tackle two types of questions on person's activity and person-object relationship and show improvements over generic features trained on the ImageNet classification task. version:1
arxiv-1604-04802 | Supervised and Unsupervised Ensembling for Knowledge Base Population | http://arxiv.org/abs/1604.04802 | id:1604.04802 author:Nazneen Fatema Rajani, Raymond J. Mooney category:cs.CL cs.LG  published:2016-04-16 summary:We present results on combining supervised and unsupervised methods to ensemble multiple systems for two popular Knowledge Base Population (KBP) tasks, Cold Start Slot Filling (CSSF) and Tri-lingual Entity Discovery and Linking (TEDL). We demonstrate that our combined system along with auxiliary features outperforms the best performing system for both tasks in the 2015 competition, several ensembling baselines, as well as the state-of-the-art stacking approach to ensembling KBP systems. The success of our technique on two different and challenging problems demonstrates the power and generality of our combined approach to ensembling. version:1
arxiv-1511-06481 | Variance Reduction in SGD by Distributed Importance Sampling | http://arxiv.org/abs/1511.06481 | id:1511.06481 author:Guillaume Alain, Alex Lamb, Chinnadhurai Sankar, Aaron Courville, Yoshua Bengio category:stat.ML cs.LG  published:2015-11-20 summary:Humans are able to accelerate their learning by selecting training materials that are the most informative and at the appropriate level of difficulty. We propose a framework for distributing deep learning in which one set of workers search for the most informative examples in parallel while a single worker updates the model on examples selected by importance sampling. This leads the model to update using an unbiased estimate of the gradient which also has minimum variance when the sampling proposal is proportional to the L2-norm of the gradient. We show experimentally that this method reduces gradient variance even in a context where the cost of synchronization across machines cannot be ignored, and where the factors for importance sampling are not updated instantly across the training set. version:7
arxiv-1604-04789 | A Hierarchical Genetic Optimization of a Fuzzy Logic System for Flow Control in Micro Grids | http://arxiv.org/abs/1604.04789 | id:1604.04789 author:Enrico De Santis, Alireza Sadeghian, Antonello Rizzi category:cs.AI cs.NE  published:2016-04-16 summary:Computational Intelligence techniques are today widely used to solve complex engineering problems. Bio-inspired algorithms like Genetic Algorithms and Fuzzy Inference Systems are nowadays adopted as hybrids techniques in the commercial and industrial environment. In this paper, we present an interesting application of the FUZZY-GA paradigm to Smart Grids. In particular, this study focuses on the possibility of tuning a Fuzzy Rule Base trying to discover, by means of a GA, a minimal fuzzy rules set in a Fuzzy Logic Controller (FLC) adopted to perform decision making for the power flow management task in a microgrid. The RB optimization is obtained through Hierarchical Genetic Algorithm, based on an encoding scheme inspired by Nature, applied to the optimization of the FIS parameters. Tests show how the proposed controller scheme is effective in maximizing the economic return when dealing with the problem of power flows management in a microgrid, equipped with an energy storage system. version:1
arxiv-1604-04784 | ACD: Action Concept Discovery from Image-Sentence Corpora | http://arxiv.org/abs/1604.04784 | id:1604.04784 author:Jiyang Gao, Chen Sun, Ram Nevatia category:cs.CV  published:2016-04-16 summary:Action classification in still images is an important task in computer vision. It is challenging as the appearances of ac- tions may vary depending on their context (e.g. associated objects). Manually labeling of context information would be time consuming and difficult to scale up. To address this challenge, we propose a method to automatically discover and cluster action concepts, and learn their classifiers from weakly supervised image-sentence corpora. It obtains candidate action concepts by extracting verb-object pairs from sentences and verifies their visualness with the associated images. Candidate action concepts are then clustered by using a multi-modal representation with image embeddings from deep convolutional networks and text embeddings from word2vec. More than one hundred human action concept classifiers are learned from the Flickr 30k dataset with no additional human effort and promising classification results are obtained. We further apply the AdaBoost algorithm to automatically select and combine relevant action concepts given an action query. Promising results have been shown on the PASCAL VOC 2012 action classification benchmark, which has zero overlap with Flickr30k. version:1
arxiv-1604-04767 | Efficient Dictionary Learning with Sparseness-Enforcing Projections | http://arxiv.org/abs/1604.04767 | id:1604.04767 author:Markus Thom, Matthias Rapp, Günther Palm category:cs.LG cs.CV cs.NE  published:2016-04-16 summary:Learning dictionaries suitable for sparse coding instead of using engineered bases has proven effective in a variety of image processing tasks. This paper studies the optimization of dictionaries on image data where the representation is enforced to be explicitly sparse with respect to a smooth, normalized sparseness measure. This involves the computation of Euclidean projections onto level sets of the sparseness measure. While previous algorithms for this optimization problem had at least quasi-linear time complexity, here the first algorithm with linear time complexity and constant space complexity is proposed. The key for this is the mathematically rigorous derivation of a characterization of the projection's result based on a soft-shrinkage function. This theory is applied in an original algorithm called Easy Dictionary Learning (EZDL), which learns dictionaries with a simple and fast-to-compute Hebbian-like learning rule. The new algorithm is efficient, expressive and particularly simple to implement. It is demonstrated that despite its simplicity, the proposed learning algorithm is able to generate a rich variety of dictionaries, in particular a topographic organization of atoms or separable atoms. Further, the dictionaries are as expressive as those of benchmark learning algorithms in terms of the reproduction quality on entire images, and result in an equivalent denoising performance. EZDL learns approximately 30 % faster than the already very efficient Online Dictionary Learning algorithm, and is therefore eligible for rapid data set analysis and problems with vast quantities of learning samples. version:1
arxiv-1604-04764 | Closed loop interactions between spiking neural network and robotic simulators based on MUSIC and ROS | http://arxiv.org/abs/1604.04764 | id:1604.04764 author:Philipp Weidel, Mikael Djurfeldt, Renato Duarte, Abigail Morrison category:cs.NE cs.RO  published:2016-04-16 summary:In order to properly assess the function and computational properties of simulated neural systems, it is necessary to account for the nature of the stimuli that drive the system. However, providing stimuli that are rich and yet both reproducible and amenable to experimental manipulations is technically challenging, and even more so if a closed-loop scenario is required. In this work, we present a novel approach to solve this problem, connecting robotics and neural network simulators. We implement a middleware solution that bridges the Robotic Operating System (ROS) to the Multi-Simulator Coordinator (MUSIC). This enables any robotic and neural simulators that implement the corresponding interfaces to be efficiently coupled, allowing real-time performance for a wide range of configurations. This work extends the toolset available for researchers in both neurorobotics and computational neuroscience, and creates the opportunity to perform closed-loop experiments of arbitrary complexity to address questions in multiple areas, including embodiment, agency, and reinforcement learning. version:1
arxiv-1604-04018 | Multi-Oriented Text Detection with Fully Convolutional Networks | http://arxiv.org/abs/1604.04018 | id:1604.04018 author:Zheng Zhang, Chengquan Zhang, Wei Shen, Cong Yao, Wenyu Liu, Xiang Bai category:cs.CV  published:2016-04-14 summary:In this paper, we propose a novel approach for text detec- tion in natural images. Both local and global cues are taken into account for localizing text lines in a coarse-to-fine pro- cedure. First, a Fully Convolutional Network (FCN) model is trained to predict the salient map of text regions in a holistic manner. Then, text line hypotheses are estimated by combining the salient map and character components. Fi- nally, another FCN classifier is used to predict the centroid of each character, in order to remove the false hypotheses. The framework is general for handling text in multiple ori- entations, languages and fonts. The proposed method con- sistently achieves the state-of-the-art performance on three text detection benchmarks: MSRA-TD500, ICDAR2015 and ICDAR2013. version:2
arxiv-1604-04741 | Smoothed Hierarchical Dirichlet Process: A Non-Parametric Approach to Constraint Measures | http://arxiv.org/abs/1604.04741 | id:1604.04741 author:Cheng Luo, Yang Xiang, Richard Yi Da Xu category:stat.ML  published:2016-04-16 summary:Time-varying mixture densities occur in many scenarios, for example, the distributions of keywords that appear in publications may evolve from year to year, video frame features associated with multiple targets may evolve in a sequence. Any models that realistically cater to this phenomenon must exhibit two important properties: the underlying mixture densities must have an unknown number of mixtures, and there must be some "smoothness" constraints in place for the adjacent mixture densities. The traditional Hierarchical Dirichlet Process (HDP) may be suited to the first property, but certainly not the second. This is due to how each random measure in the lower hierarchies is sampled independent of each other and hence does not facilitate any temporal correlations. To overcome such shortcomings, we proposed a new Smoothed Hierarchical Dirichlet Process (sHDP). The key novelty of this model is that we place a temporal constraint amongst the nearby discrete measures $\{G_j\}$ in the form of symmetric Kullback-Leibler (KL) Divergence with a fixed bound $B$. Although the constraint we place only involves a single scalar value, it nonetheless allows for flexibility in the corresponding successive measures. Remarkably, it also led us to infer the model within the stick-breaking process where the traditional Beta distribution used in stick-breaking is now replaced by a new constraint calculated from $B$. We present the inference algorithm and elaborate on its solutions. Our experiment using NIPS keywords has shown the desirable effect of the model. version:1
arxiv-1604-04724 | Automatic Segmentation of Dynamic Objects from an Image Pair | http://arxiv.org/abs/1604.04724 | id:1604.04724 author:Sri Raghu Malireddi, Shanmuganathan Raman category:cs.CV  published:2016-04-16 summary:Automatic segmentation of objects from a single image is a challenging problem which generally requires training on large number of images. We consider the problem of automatically segmenting only the dynamic objects from a given pair of images of a scene captured from different positions. We exploit dense correspondences along with saliency measures in order to first localize the interest points on the dynamic objects from the two images. We propose a novel approach based on techniques from computational geometry in order to automatically segment the dynamic objects from both the images using a top-down segmentation strategy. We discuss how the proposed approach is unique in novelty compared to other state-of-the-art segmentation algorithms. We show that the proposed approach for segmentation is efficient in handling large motions and is able to achieve very good segmentation of the objects for different scenes. We analyse the results with respect to the manually marked ground truth segmentation masks created using our own dataset and provide key observations in order to improve the work in future. version:1
arxiv-1604-04706 | DS-MLR: Exploiting Double Separability for Scaling up Distributed Multinomial Logistic Regression | http://arxiv.org/abs/1604.04706 | id:1604.04706 author:Parameswaran Raman, Shin Matsushima, Xinhua Zhang, Hyokun Yun, S. V. N. Vishwanathan category:cs.LG stat.ML  published:2016-04-16 summary:Multinomial logistic regression is a popular tool in the arsenal of machine learning algorithms, yet scaling it to datasets with very large number of data points and classes has not been trivial. This is primarily because one needs to compute the log-partition function on every data point. This makes distributing the computation hard. In this paper, we present a distributed stochastic gradient descent based optimization method (DS-MLR) for scaling up multinomial logistic regression problems to very large data. Our algorithm exploits double-separability, an attractive property we observe in the objective functions of several models in machine learning, that allows us to distribute both data and model parameters simultaneously across multiple machines. In addition to being easily parallelizable, our algorithm achieves good test accuracy within a short period of time, with a low overall time and memory footprint as demonstrated by empirical results on both single and multi-machine settings. For instance, on a dataset with 93,805 training instances and 12,294 classes, we achieve close to optimal f-score in 10,000 seconds using 2 machines each having 12 cores. version:1
arxiv-1604-04696 | Phone-based Metric as a Predictor for Basic Personality Traits | http://arxiv.org/abs/1604.04696 | id:1604.04696 author:Bjarke Mønsted, Anders Mollgaard, Joachim Mathiesen category:cs.SI cs.LG physics.soc-ph  published:2016-04-16 summary:Basic personality traits are typically assessed through questionnaires. Here we consider phone-based metrics as a way to asses personality traits. We use data from smartphones with custom data-collection software distributed to 730 individuals. The data includes information about location, physical motion, face-to-face contacts, online social network friends, text messages and calls. The data is further complemented by questionnaire-based data on basic personality traits. From the phone-based metrics, we define a set of behavioral variables, which we use in a prediction of basic personality traits. We find that predominantly, the Big Five personality traits extraversion and, to some degree, neuroticism are strongly expressed in our data. As an alternative to the Big Five, we investigate whether other linear combinations of the 44 questions underlying the Big Five Inventory are more predictable. In a tertile classification problem, basic dimensionality reduction techniques, such as independent component analysis, increase the predictability relative to the baseline from $11\%$ to $23\%$. Finally, from a supervised linear classifier, we were able to further improve this predictability to $33\%$. In all cases, the most predictable projections had an overweight of the questions related to extraversion and neuroticism. In addition, our findings indicate that the score system underlying the Big Five Inventory disregards a part of the information available in the 44 questions. version:1
arxiv-1604-04693 | Subcategory-aware Convolutional Neural Networks for Object Proposals and Detection | http://arxiv.org/abs/1604.04693 | id:1604.04693 author:Yu Xiang, Wongun Choi, Yuanqing Lin, Silvio Savarese category:cs.CV  published:2016-04-16 summary:In CNN-based object detection methods, region proposal becomes a bottleneck when objects exhibit significant scale variation, occlusion or truncation. In addition, these methods mainly focus on 2D object detection and cannot estimate detailed properties of objects. In this paper, we propose subcategory-aware CNNs for object detection. We introduce a novel region proposal network that uses subcategory information to guide the proposal generating process, and a new detection network for joint detection and subcategory classification. By using subcategories related to object pose, we achieve state-of-the-art performance on both detection and pose estimation on commonly used benchmarks. version:1
arxiv-1509-03917 | Dropping Convexity for Faster Semi-definite Optimization | http://arxiv.org/abs/1509.03917 | id:1509.03917 author:Srinadh Bhojanapalli, Anastasios Kyrillidis, Sujay Sanghavi category:stat.ML cs.DS cs.IT cs.LG cs.NA math.IT math.OC  published:2015-09-14 summary:We study the minimization of a convex function $f(X)$ over the set of $n\times n$ positive semi-definite matrices, but when the problem is recast as $\min_U g(U) := f(UU^\top)$, with $U \in \mathbb{R}^{n \times r}$ and $r \leq n$. We study the performance of gradient descent on $g$---which we refer to as Factored Gradient Descent (FGD)---under standard assumptions on the original function $f$. We provide a rule for selecting the step size and, with this choice, show that the local convergence rate of FGD mirrors that of standard gradient descent on the original $f$: i.e., after $k$ steps, the error is $O(1/k)$ for smooth $f$, and exponentially small in $k$ when $f$ is (restricted) strongly convex. In addition, we provide a procedure to initialize FGD for (restricted) strongly convex objectives and when one only has access to $f$ via a first-order oracle; for several problem instances, such proper initialization leads to global convergence guarantees. FGD and similar procedures are widely used in practice for problems that can be posed as matrix factorization. To the best of our knowledge, this is the first paper to provide precise convergence rate guarantees for general convex functions under standard convex assumptions. version:3
arxiv-1604-04678 | Anatomy-Aware Measurement of Segmentation Accuracy | http://arxiv.org/abs/1604.04678 | id:1604.04678 author:Hamid R. Tizhoosh, Ahmed A. Othman category:cs.CV  published:2016-04-16 summary:Quantifying the accuracy of segmentation and manual delineation of organs, tissue types and tumors in medical images is a necessary measurement that suffers from multiple problems. One major shortcoming of all accuracy measures is that they neglect the anatomical significance or relevance of different zones within a given segment. Hence, existing accuracy metrics measure the overlap of a given segment with a ground-truth without any anatomical discrimination inside the segment. For instance, if we understand the rectal wall or urethral sphincter as anatomical zones, then current accuracy measures ignore their significance when they are applied to assess the quality of the prostate gland segments. In this paper, we propose an anatomy-aware measurement scheme for segmentation accuracy of medical images. The idea is to create a ``master gold'' based on a consensus shape containing not just the outline of the segment but also the outlines of the internal zones if existent or relevant. To apply this new approach to accuracy measurement, we introduce the anatomy-aware extensions of both Dice coefficient and Jaccard index and investigate their effect using 500 synthetic prostate ultrasound images with 20 different segments for each image. We show that through anatomy-sensitive calculation of segmentation accuracy, namely by considering relevant anatomical zones, not only the measurement of individual users can change but also the ranking of users' segmentation skills may require reordering. version:1
arxiv-1604-04677 | Sentence-Level Grammatical Error Identification as Sequence-to-Sequence Correction | http://arxiv.org/abs/1604.04677 | id:1604.04677 author:Allen Schmaltz, Yoon Kim, Alexander M. Rush, Stuart M. Shieber category:cs.CL  published:2016-04-16 summary:We demonstrate that an attention-based encoder-decoder model can be used for sentence-level grammatical error identification for the Automated Evaluation of Scientific Writing (AESW) Shared Task 2016. The attention-based encoder-decoder models can be used for the generation of corrections, in addition to error identification, which is of interest for certain end-user applications. We show that a character-based encoder-decoder model is particularly effective, outperforming other results on the AESW Shared Task on its own, and showing gains over a word-based counterpart. Our final model--a combination of three character-based encoder-decoder models, one word-based encoder-decoder model, and a sentence-level CNN--is the highest performing system on the AESW 2016 binary prediction Shared Task. version:1
arxiv-1604-04676 | Generating Binary Tags for Fast Medical Image Retrieval Based on Convolutional Nets and Radon Transform | http://arxiv.org/abs/1604.04676 | id:1604.04676 author:Xinran Liu, Hamid R. Tizhoosh, Jonathan Kofman category:cs.CV  published:2016-04-16 summary:Content-based image retrieval (CBIR) in large medical image archives is a challenging and necessary task. Generally, different feature extraction methods are used to assign expressive and invariant features to each image such that the search for similar images comes down to feature classification and/or matching. The present work introduces a new image retrieval method for medical applications that employs a convolutional neural network (CNN) with recently introduced Radon barcodes. We combine neural codes for global classification with Radon barcodes for the final retrieval. We also examine image search based on regions of interest (ROI) matching after image retrieval. The IRMA dataset with more than 14,000 x-rays images is used to evaluate the performance of our method. Experimental results show that our approach is superior to many published works. version:1
arxiv-1604-04675 | Radon Features and Barcodes for Medical Image Retrieval via SVM | http://arxiv.org/abs/1604.04675 | id:1604.04675 author:Shujin Zhu, H. R. Tizhoosh category:cs.CV  published:2016-04-16 summary:For more than two decades, research has been performed on content-based image retrieval (CBIR). By combining Radon projections and the support vector machines (SVM), a content-based medical image retrieval method is presented in this work. The proposed approach employs the normalized Radon projections with corresponding image category labels to build an SVM classifier, and the Radon barcode database which encodes every image in a binary format is also generated simultaneously to tag all images. To retrieve similar images when a query image is given, Radon projections and the barcode of the query image are generated. Subsequently, the k-nearest neighbor search method is applied to find the images with minimum Hamming distance of the Radon barcode within the same class predicted by the trained SVM classifier that uses Radon features. The performance of the proposed method is validated by using the IRMA 2009 dataset with 14,410 x-ray images in 57 categories. The results demonstrate that our method has the capacity to retrieve similar responses for the correctly identified query image and even for those mistakenly classified by SVM. The approach further is very fast and has low memory requirement. version:1
arxiv-1604-04673 | Evolutionary Projection Selection for Radon Barcodes | http://arxiv.org/abs/1604.04673 | id:1604.04673 author:Hamid R. Tizhoosh, Shahryar Rahnamayan category:cs.CV  published:2016-04-16 summary:Recently, Radon transformation has been used to generate barcodes for tagging medical images. The under-sampled image is projected in certain directions, and each projection is binarized using a local threshold. The concatenation of the thresholded projections creates a barcode that can be used for tagging or annotating medical images. A small number of equidistant projections, e.g., 4 or 8, is generally used to generate short barcodes. However, due to the diverse nature of digital images, and since we are only working with a small number of projections (to keep the barcode short), taking equidistant projections may not be the best course of action. In this paper, we proposed to find $n$ optimal projections, whereas $n\!<\!180$, in order to increase the expressiveness of Radon barcodes. We show examples for the exhaustive search for the simple case when we attempt to find 4 best projections out of 16 equidistant projections and compare it with the evolutionary approach in order to establish the benefit of the latter when operating on a small population size as in the case of micro-DE. We randomly selected 10 different classes from IRMA dataset (14,400 x-ray images in 58 classes) and further randomly selected 5 images per class for our tests. version:1
arxiv-1604-04661 | Parallelizing Word2Vec in Shared and Distributed Memory | http://arxiv.org/abs/1604.04661 | id:1604.04661 author:Shihao Ji, Nadathur Satish, Sheng Li, Pradeep Dubey category:cs.DC cs.CL stat.ML  published:2016-04-15 summary:Word2Vec is a widely used algorithm for extracting low-dimensional vector representations of words. It generated considerable excitement in the machine learning and natural language processing (NLP) communities recently due to its exceptional performance in many NLP applications such as named entity recognition, sentiment analysis, machine translation and question answering. State-of-the-art algorithms including those by Mikolov et al. have been parallelized for multi-core CPU architectures but are based on vector-vector operations that are memory-bandwidth intensive and do not efficiently use computational resources. In this work, we improve reuse of various data structures in the algorithm through the use of minibatching, hence allowing us to express the problem using matrix multiply operations. We also explore different techniques to parallelize word2vec computation across nodes in a compute cluster, and demonstrate good strong scalability up to 32 nodes. In combination, these techniques allow us to scale up the computation near linearly across cores and nodes, and process hundreds of millions of words per second, which is the fastest word2vec implementation to the best of our knowledge. version:1
arxiv-1604-04653 | Bags of Local Convolutional Features for Scalable Instance Search | http://arxiv.org/abs/1604.04653 | id:1604.04653 author:Eva Mohedano, Amaia Salvador, Kevin McGuinness, Ferran Marques, Noel E. O'Connor, Xavier Giro-i-Nieto category:cs.CV cs.MM  published:2016-04-15 summary:This work proposes a simple instance retrieval pipeline based on encoding the convolutional features of CNN using the bag of words aggregation scheme (BoW). Assigning each local array of activations in a convolutional layer to a visual word produces an \textit{assignment map}, a compact representation that relates regions of an image with a visual word. We use the assignment map for fast spatial reranking, obtaining object localizations that are used for query expansion. We demonstrate the suitability of the BoW representation based on local CNN features for instance retrieval, achieving competitive performance on the Oxford and Paris buildings benchmarks. We show that our proposed system for CNN feature aggregation with BoW outperforms state-of-the-art techniques using sum pooling at a subset of the challenging TRECVid INS benchmark. version:1
arxiv-1604-04639 | ModelWizard: Toward Interactive Model Construction | http://arxiv.org/abs/1604.04639 | id:1604.04639 author:Dylan Hutchison category:cs.PL cs.LG  published:2016-04-15 summary:Data scientists engage in model construction to discover machine learning models that well explain a dataset, in terms of predictiveness, understandability and generalization across domains. Questions such as "what if we model common cause Z" and "what if Y's dependence on X reverses" inspire many candidate models to consider and compare, yet current tools emphasize constructing a final model all at once. To more naturally reflect exploration when debating numerous models, we propose an interactive model construction framework grounded in composable operations. Primitive operations capture core steps refining data and model that, when verified, form an inductive basis to prove model validity. Derived, composite operations enable advanced model families, both generic and specialized, abstracted away from low-level details. We prototype our envisioned framework in ModelWizard, a domain-specific language embedded in F# to construct Tabular models. We enumerate language design and demonstrate its use through several applications, emphasizing how language may facilitate creation of complex models. To future engineers designing data science languages and tools, we offer ModelWizard's design as a new model construction paradigm, speeding discovery of our universe's structure. version:1
arxiv-1408-0856 | Convex Biclustering | http://arxiv.org/abs/1408.0856 | id:1408.0856 author:Eric C. Chi, Genevera I. Allen, Richard G. Baraniuk category:stat.ME stat.ML  published:2014-08-05 summary:In the biclustering problem, we seek to simultaneously group observations and features. While biclustering has applications in a wide array of domains, ranging from text mining to collaborative filtering, the problem of identifying structure in high dimensional genomic data motivates this work. In this context, biclustering enables us to identify subsets of genes that are co-expressed only within a subset of experimental conditions. We present a convex formulation of the biclustering problem that possesses a unique global minimizer and an iterative algorithm, COBRA, that is guaranteed to identify it. Our approach generates an entire solution path of possible biclusters as a single tuning parameter is varied. We also show how to reduce the problem of selecting this tuning parameter to solving a trivial modification of the convex biclustering problem. The key contributions of our work are its simplicity, interpretability, and algorithmic guarantees - features that arguably are lacking in the current alternative algorithms. We demonstrate the advantages of our approach, which includes stably and reproducibly identifying biclusterings, on simulated and real microarray data. version:4
arxiv-1604-04618 | Make Up Your Mind: The Price of Online Queries in Differential Privacy | http://arxiv.org/abs/1604.04618 | id:1604.04618 author:Mark Bun, Thomas Steinke, Jonathan Ullman category:cs.CR cs.DS cs.LG  published:2016-04-15 summary:We consider the problem of answering queries about a sensitive dataset subject to differential privacy. The queries may be chosen adversarially from a larger set Q of allowable queries in one of three ways, which we list in order from easiest to hardest to answer: Offline: The queries are chosen all at once and the differentially private mechanism answers the queries in a single batch. Online: The queries are chosen all at once, but the mechanism only receives the queries in a streaming fashion and must answer each query before seeing the next query. Adaptive: The queries are chosen one at a time and the mechanism must answer each query before the next query is chosen. In particular, each query may depend on the answers given to previous queries. Many differentially private mechanisms are just as efficient in the adaptive model as they are in the offline model. Meanwhile, most lower bounds for differential privacy hold in the offline setting. This suggests that the three models may be equivalent. We prove that these models are all, in fact, distinct. Specifically, we show that there is a family of statistical queries such that exponentially more queries from this family can be answered in the offline model than in the online model. We also exhibit a family of search queries such that exponentially more queries from this family can be answered in the online model than in the adaptive model. We also investigate whether such separations might hold for simple queries like threshold queries over the real line. version:1
arxiv-1604-04615 | On deterministic conditions for subspace clustering under missing data | http://arxiv.org/abs/1604.04615 | id:1604.04615 author:Wenqi Wang, Shuchin Aeron, Vaneet Aggarwal category:cs.IT math.IT stat.ML  published:2016-04-15 summary:In this paper we present deterministic analysis of sufficient conditions for sparse subspace clustering under missing data, when data is assumed to come from a Union of Subspaces (UoS) model. In this context we consider two cases, namely Case I when all the points are sampled at the same co-ordinates, and Case II when points are sampled at different locations. We show that results for Case I directly follow from several existing results in the literature, while results for Case II are not as straightforward and we provide a set of dual conditions under which, perfect clustering holds true. We provide extensive set of simulation results for clustering as well as completion of data under missing entries, under the UoS model. Our experimental results indicate that in contrast to the full data case, accurate clustering does not imply accurate subspace identification and completion, indicating the natural order of relative hardness of these problems. version:1
arxiv-1510-00277 | Similarity of symbol frequency distributions with heavy tails | http://arxiv.org/abs/1510.00277 | id:1510.00277 author:Martin Gerlach, Francesc Font-Clos, Eduardo G. Altmann category:physics.soc-ph cs.CL physics.data-an  published:2015-10-01 summary:Quantifying the similarity between symbolic sequences is a traditional problem in Information Theory which requires comparing the frequencies of symbols in different sequences. In numerous modern applications, ranging from DNA over music to texts, the distribution of symbol frequencies is characterized by heavy-tailed distributions (e.g., Zipf's law). The large number of low-frequency symbols in these distributions poses major difficulties to the estimation of the similarity between sequences, e.g., they hinder an accurate finite-size estimation of entropies. Here we show analytically how the systematic (bias) and statistical (fluctuations) errors in these estimations depend on the sample size~$N$ and on the exponent~$\gamma$ of the heavy-tailed distribution. Our results are valid for the Shannon entropy $(\alpha=1)$, its corresponding similarity measures (e.g., the Jensen-Shanon divergence), and also for measures based on the generalized entropy of order $\alpha$. For small $\alpha$'s, including $\alpha=1$, the errors decay slower than the $1/N$-decay observed in short-tailed distributions. For $\alpha$ larger than a critical value $\alpha^* = 1+1/\gamma \leq 2$, the $1/N$-decay is recovered. We show the practical significance of our results by quantifying the evolution of the English language over the last two centuries using a complete $\alpha$-spectrum of measures. We find that frequent words change more slowly than less frequent words and that $\alpha=2$ provides the most robust measure to quantify language change. version:2
arxiv-1604-04600 | Estimation of low rank density matrices: bounds in Schatten norms and other distances | http://arxiv.org/abs/1604.04600 | id:1604.04600 author:Dong Xia, Vladimir Koltchinskii category:stat.ML math.ST stat.TH  published:2016-04-15 summary:Let ${\mathcal S}_m$ be the set of all $m\times m$ density matrices (Hermitian positively semi-definite matrices of unit trace). Consider a problem of estimation of an unknown density matrix $\rho\in {\mathcal S}_m$ based on outcomes of $n$ measurements of observables $X_1,\dots, X_n\in {\mathbb H}_m$ (${\mathbb H}_m$ being the space of $m\times m$ Hermitian matrices) for a quantum system identically prepared $n$ times in state $\rho.$ Outcomes $Y_1,\dots, Y_n$ of such measurements could be described by a trace regression model in which ${\mathbb E}_{\rho}(Y_j X_j)={\rm tr}(\rho X_j), j=1,\dots, n.$ The design variables $X_1,\dots, X_n$ are often sampled at random from the uniform distribution in an orthonormal basis $\{E_1,\dots, E_{m^2}\}$ of ${\mathbb H}_m$ (such as Pauli basis). The goal is to estimate the unknown density matrix $\rho$ based on the data $(X_1,Y_1), \dots, (X_n,Y_n).$ Let $$ \hat Z:=\frac{m^2}{n}\sum_{j=1}^n Y_j X_j $$ and let $\check \rho$ be the projection of $\hat Z$ onto the convex set ${\mathcal S}_m$ of density matrices. It is shown that for estimator $\check \rho$ the minimax lower bounds in classes of low rank density matrices (established earlier) are attained up logarithmic factors for all Schatten $p$-norm distances, $p\in [1,\infty]$ and for Bures version of quantum Hellinger distance. Moreover, for a slightly modified version of estimator $\check \rho$ the same property holds also for quantum relative entropy (Kullback-Leibler) distance between density matrices. version:1
arxiv-1604-00981 | Revisiting Distributed Synchronous SGD | http://arxiv.org/abs/1604.00981 | id:1604.00981 author:Jianmin Chen, Rajat Monga, Samy Bengio, Rafal Jozefowicz category:cs.LG cs.DC cs.NE  published:2016-04-04 summary:The recent success of deep learning approaches for domains like speech recognition (Hinton et al., 2012) and computer vision (Ioffe & Szegedy, 2015) stems from many algorithmic improvements but also from the fact that the size of available training data has grown significantly over the years, together with the computing power, in terms of both CPUs and GPUs. While a single GPU often provides algorithmic simplicity and speed up to a given scale of data and model, there exist an operating point where a distributed implementation of training algorithms for deep architectures becomes necessary. Previous works have been focusing on asynchronous SGD training, which works well up to a few dozens of workers for some models. In this work, we show that synchronous SGD training, with the help of backup workers, can not only achieve better accuracy, but also reach convergence faster with respect to wall time, i.e. use more workers more efficiently. version:2
arxiv-1604-04574 | Learning Temporal Regularity in Video Sequences | http://arxiv.org/abs/1604.04574 | id:1604.04574 author:Mahmudul Hasan, Jonghyun Choi, Jan Neumann, Amit K. Roy-Chowdhury, Larry S. Davis category:cs.CV  published:2016-04-15 summary:Perceiving meaningful activities in a long video sequence is a challenging problem due to ambiguous definition of 'meaningfulness' as well as clutters in the scene. We approach this problem by learning a generative model for regular motion patterns, termed as regularity, using multiple sources with very limited supervision. Specifically, we propose two methods that are built upon the autoencoders for their ability to work with little to no supervision. We first leverage the conventional handcrafted spatio-temporal local features and learn a fully connected autoencoder on them. Second, we build a fully convolutional feed-forward autoencoder to learn both the local features and the classifiers as an end-to-end learning framework. Our model can capture the regularities from multiple datasets. We evaluate our methods in both qualitative and quantitative ways - showing the learned regularity of videos in various aspects and demonstrating competitive performance on anomaly detection datasets as an application. version:1
arxiv-1604-04573 | CNN-RNN: A Unified Framework for Multi-label Image Classification | http://arxiv.org/abs/1604.04573 | id:1604.04573 author:Jiang Wang, Yi Yang, Junhua Mao, Zhiheng Huang, Chang Huang, Wei Xu category:cs.CV cs.LG cs.NE  published:2016-04-15 summary:While deep convolutional neural networks (CNNs) have shown a great success in single-label image classification, it is important to note that real world images generally contain multiple labels, which could correspond to different objects, scenes, actions and attributes in an image. Traditional approaches to multi-label image classification learn independent classifiers for each category and employ ranking or thresholding on the classification results. These techniques, although working well, fail to explicitly exploit the label dependencies in an image. In this paper, we utilize recurrent neural networks (RNNs) to address this problem. Combined with CNNs, the proposed CNN-RNN framework learns a joint image-label embedding to characterize the semantic label dependency as well as the image-label relevance, and it can be trained end-to-end from scratch to integrate both information in a unified framework. Experimental results on public benchmark datasets demonstrate that the proposed architecture achieves better performance than the state-of-the-art multi-label classification model version:1
arxiv-1604-04558 | Accessing accurate documents by mining auxiliary document information | http://arxiv.org/abs/1604.04558 | id:1604.04558 author:Jinju Joby, Jyothi Korra category:cs.IR cs.AI cs.LG  published:2016-04-15 summary:Earlier techniques of text mining included algorithms like k-means, Naive Bayes, SVM which classify and cluster the text document for mining relevant information about the documents. The need for improving the mining techniques has us searching for techniques using the available algorithms. This paper proposes one technique which uses the auxiliary information that is present inside the text documents to improve the mining. This auxiliary information can be a description to the content. This information can be either useful or completely useless for mining. The user should assess the worth of the auxiliary information before considering this technique for text mining. In this paper, a combination of classical clustering algorithms is used to mine the datasets. The algorithm runs in two stages which carry out mining at different levels of abstraction. The clustered documents would then be classified based on the necessary groups. The proposed technique is aimed at improved results of document clustering. version:1
arxiv-1604-04539 | Unsupervised single-particle deep classification via statistical manifold learning | http://arxiv.org/abs/1604.04539 | id:1604.04539 author:Jiayi Wu, Yongbei Ma, Charles Condgon, Bevin Brett, Shuobing Chen, Qi Ouyang, Youdong Mao category:physics.data-an cs.CV q-bio.QM  published:2016-04-15 summary:Structural heterogeneity in single-particle images presents a major challenge for high-resolution cryo-electron microscopy (cryo-EM) structure determination. Here we introduce a statistical manifold learning approach for unsupervised single-particle deep classification. When optimized for Intel high-performance computing (HPC) processors, our approach can generate thousands of reference-free class averages within several hours from hundreds of thousands of single-particle cryo-EM images. Deep classification thus assists in computational purification of single-particle datasets for high-resolution reconstruction. version:1
arxiv-1505-04870 | Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models | http://arxiv.org/abs/1505.04870 | id:1505.04870 author:Bryan A. Plummer, Liwei Wang, Chris M. Cervantes, Juan C. Caicedo, Julia Hockenmaier, Svetlana Lazebnik category:cs.CV cs.CL  published:2015-05-19 summary:The Flickr30k dataset has become a standard benchmark for sentence-based image description. This paper presents Flickr30k Entities, which augments the 158k captions from Flickr30k with 244k coreference chains, linking mentions of the same entities across different captions for the same image, and associating them with 276k manually annotated bounding boxes. Such annotations are essential for continued progress in automatic image description and grounded language understanding. They enable us to define a new benchmark for localization of textual entity mentions in an image. We present a strong baseline for this task that combines an image-text embedding, detectors for common objects, a color classifier, and a bias towards selecting larger objects. While our baseline rivals in accuracy more complex state-of-the-art models, we show that its gains cannot be easily parlayed into improvements on such tasks as image-sentence retrieval, thus underlining the limitations of current methods and the need for further research. version:3
arxiv-1604-04528 | Tracking Human-like Natural Motion Using Deep Recurrent Neural Networks | http://arxiv.org/abs/1604.04528 | id:1604.04528 author:Youngbin Park, Sungphill Moon, Il Hong Suh category:cs.CV cs.LG cs.NE cs.RO  published:2016-04-15 summary:Kinect skeleton tracker is able to achieve considerable human body tracking performance in convenient and a low-cost manner. However, The tracker often captures unnatural human poses such as discontinuous and vibrated motions when self-occlusions occur. A majority of approaches tackle this problem by using multiple Kinect sensors in a workspace. Combination of the measurements from different sensors is then conducted in Kalman filter framework or optimization problem is formulated for sensor fusion. However, these methods usually require heuristics to measure reliability of measurements observed from each Kinect sensor. In this paper, we developed a method to improve Kinect skeleton using single Kinect sensor, in which supervised learning technique was employed to correct unnatural tracking motions. Specifically, deep recurrent neural networks were used for improving joint positions and velocities of Kinect skeleton, and three methods were proposed to integrate the refined positions and velocities for further enhancement. Moreover, we suggested a novel measure to evaluate naturalness of captured motions. We evaluated the proposed approach by comparison with the ground truth obtained using a commercial optical maker-based motion capture system. version:1
arxiv-1604-03169 | Using Deep Learning for Image-Based Plant Disease Detection | http://arxiv.org/abs/1604.03169 | id:1604.03169 author:Sharada Prasanna Mohanty, David Hughes, Marcel Salathe category:cs.CV  published:2016-04-11 summary:Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. When testing the model on a set of images collected from trusted online sources - i.e. taken under conditions different from the images used for training - the model still achieves an accuracy of 31.4%. While this accuracy is much higher than the one based on random selection (2.6%), a more diverse set of training data is needed to improve the general accuracy. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path towards smartphone-assisted crop disease diagnosis on a massive global scale. version:2
arxiv-1604-04505 | A short note on extension theorems and their connection to universal consistency in machine learning | http://arxiv.org/abs/1604.04505 | id:1604.04505 author:Andreas Christmann, Florian Dumpert, Dao-Hong Xiang category:stat.ML cs.LG  published:2016-04-15 summary:Statistical machine learning plays an important role in modern statistics and computer science. One main goal of statistical machine learning is to provide universally consistent algorithms, i.e., the estimator converges in probability or in some stronger sense to the Bayes risk or to the Bayes decision function. Kernel methods based on minimizing the regularized risk over a reproducing kernel Hilbert space (RKHS) belong to these statistical machine learning methods. It is in general unknown which kernel yields optimal results for a particular data set or for the unknown probability measure. Hence various kernel learning methods were proposed to choose the kernel and therefore also its RKHS in a data adaptive manner. Nevertheless, many practitioners often use the classical Gaussian RBF kernel or certain Sobolev kernels with good success. The goal of this short note is to offer one possible theoretical explanation for this empirical fact. version:1
arxiv-1604-04494 | Long-term Temporal Convolutions for Action Recognition | http://arxiv.org/abs/1604.04494 | id:1604.04494 author:Gül Varol, Ivan Laptev, Cordelia Schmid category:cs.CV  published:2016-04-15 summary:Typical human actions last several seconds and exhibit characteristic spatio-temporal structure. Recent methods attempt to capture this structure and learn action representations with convolutional neural networks. Such representations, however, are typically learned at the level of a few video frames failing to model actions at their full temporal extent. In this work we learn video representations using neural networks with long-term temporal convolutions (LTC). We demonstrate that LTC-CNN models with increased temporal extents improve the accuracy of action recognition. We also study the impact of different low-level representations, such as raw values of video pixels and optical flow vector fields and demonstrate the importance of high-quality optical flow estimation for learning accurate action models. We report state-of-the-art results on two challenging benchmarks for human action recognition UCF101 (92.7%) and HMDB51 (67.2%). version:1
arxiv-1604-04473 | Probing the Intra-Component Correlations within Fisher Vector for Material Classification | http://arxiv.org/abs/1604.04473 | id:1604.04473 author:Xiaopeng Hong, Xianbiao Qi, Guoying Zhao, Matti Pietikäinen category:cs.CV  published:2016-04-15 summary:Fisher vector (FV) has become a popular image representation. One notable underlying assumption of the FV framework is that local descriptors are well decorrelated within each cluster so that the covariance matrix for each Gaussian can be simplified to be diagonal. Though the FV usually relies on the Principal Component Analysis (PCA) to decorrelate local features, the PCA is applied to the entire training data and hence it only diagonalizes the \textit{universal} covariance matrix, rather than those w.r.t. the local components. As a result, the local decorrelation assumption is usually not supported in practice. To relax this assumption, this paper proposes a completed model of the Fisher vector, which is termed as the Completed Fisher vector (CFV). The CFV is a more general framework of the FV, since it encodes not only the variances but also the correlations of the whitened local descriptors. The CFV thus leads to improved discriminative power. We take the task of material categorization as an example and experimentally show that: 1) the CFV outperforms the FV under all parameter settings; 2) the CFV is robust to the changes in the number of components in the mixture; 3) even with a relatively small visual vocabulary the CFV still works well on two challenging datasets. version:1
arxiv-1604-04451 | Delta divergence: A novel decision cognizant measure of classifier incongruence | http://arxiv.org/abs/1604.04451 | id:1604.04451 author:Josef Kittler, Cemre Zor category:cs.LG cs.IT math.IT stat.ML  published:2016-04-15 summary:Disagreement between two classifiers regarding the class membership of an observation in pattern recognition can be indicative of an anomaly and its nuance. As in general classifiers base their decision on class aposteriori probabilities, the most natural approach to detecting classifier incongruence is to use divergence. However, existing divergences are not particularly suitable to gauge classifier incongruence. In this paper, we postulate the properties that a divergence measure should satisfy and propose a novel divergence measure, referred to as Delta divergence. In contrast to existing measures, it is decision cognizant. The focus in Delta divergence on the dominant hypotheses has a clutter reducing property, the significance of which grows with increasing number of classes. The proposed measure satisfies other important properties such as symmetry, and independence of classifier confidence. The relationship of the proposed divergence to some baseline measures is demonstrated experimentally, showing its superiority. version:1
arxiv-1604-04434 | Bayesian linear regression with Student-t assumptions | http://arxiv.org/abs/1604.04434 | id:1604.04434 author:Chaobing Song, Shu-Tao Xia category:cs.LG stat.ML  published:2016-04-15 summary:As an automatic method of determining model complexity using the training data alone, Bayesian linear regression provides us a principled way to select hyperparameters. But one often needs approximation inference if distribution assumption is beyond Gaussian distribution. In this paper, we propose a Bayesian linear regression model with Student-t assumptions (BLRS), which can be inferred exactly. In this framework, both conjugate prior and expectation maximization (EM) algorithm are generalized. Meanwhile, we prove that the maximum likelihood solution is equivalent to the standard Bayesian linear regression with Gaussian assumptions (BLRG). The $q$-EM algorithm for BLRS is nearly identical to the EM algorithm for BLRG. It is showed that $q$-EM for BLRS can converge faster than EM for BLRG for the task of predicting online news popularity. version:1
arxiv-1604-04428 | The Artificial Mind's Eye: Resisting Adversarials for Convolutional Neural Networks using Internal Projection | http://arxiv.org/abs/1604.04428 | id:1604.04428 author:Harm Berntsen, Wouter Kuijper, Tom Heskes category:cs.LG cs.NE  published:2016-04-15 summary:We introduce a novel type of artificial neural network structure and training procedure that results in networks that are provably, quantitatively more robust to adversarial samples than classical, end-to-end trained classifiers. The main idea of our approach is to force the network to make predictions on what the given instance of the class under consideration would look like and subsequently test those predictions. By forcing the network to redraw the relevant parts of the image and subsequently comparing this new image to the original, we are having the network give a 'proof' of the presence of the object. version:1
arxiv-1408-2700 | Co-Localization of Audio Sources in Images Using Binaural Features and Locally-Linear Regression | http://arxiv.org/abs/1408.2700 | id:1408.2700 author:Antoine Deleforge, Radu Horaud, Yoav Schechner, Laurent Girin category:cs.SD cs.MM stat.AP stat.ML  published:2014-08-12 summary:This paper addresses the problem of localizing audio sources using binaural measurements. We propose a supervised formulation that simultaneously localizes multiple sources at different locations. The approach is intrinsically efficient because, contrary to prior work, it relies neither on source separation, nor on monaural segregation. The method starts with a training stage that establishes a locally-linear Gaussian regression model between the directional coordinates of all the sources and the auditory features extracted from binaural measurements. While fixed-length wide-spectrum sounds (white noise) are used for training to reliably estimate the model parameters, we show that the testing (localization) can be extended to variable-length sparse-spectrum sounds (such as speech), thus enabling a wide range of realistic applications. Indeed, we demonstrate that the method can be used for audio-visual fusion, namely to map speech signals onto images and hence to spatially align the audio and visual modalities, thus enabling to discriminate between speaking and non-speaking faces. We release a novel corpus of real-room recordings that allow quantitative evaluation of the co-localization method in the presence of one or two sound sources. Experiments demonstrate increased accuracy and speed relative to several state-of-the-art methods. version:4
arxiv-1603-09732 | Robust Head-Pose Estimation Based on Partially-Latent Mixture of Linear Regression | http://arxiv.org/abs/1603.09732 | id:1603.09732 author:Vincent Drouard, Radu Horaud, Antoine Deleforge, Silèye Ba, Georgios Evangelidis category:cs.CV  published:2016-03-31 summary:Head-pose estimation has many applications, such as social-event analysis, human-robot and human-computer interaction, driving assistance, and so forth. Head-pose estimation is challenging because it must cope with changing illumination conditions, face orientation and appearance variabilities, partial occlusions of facial landmarks, as well as bounding-box-to-face alignment problems. We propose a mixture of linear regression method that learns how to map high-dimensional feature vectors (extracted from bounding-boxes of faces) onto both head-pose parameters and bounding-box shifts, such that at runtime they are simultaneously predicted. We describe in detail the mapping method that combines the merits of manifold learning and of mixture of linear regression. We validate our method with three publicly available datasets and we thoroughly benchmark four variants of the proposed algorithm with several state-of-the-art head-pose estimation methods. version:2
arxiv-1602-07455 | Automatically Proving Mathematical Theorems with Evolutionary Algorithms and Proof Assistants | http://arxiv.org/abs/1602.07455 | id:1602.07455 author:Li-An Yang, Jui-Pin Liu, Chao-Hong Chen, Ying-ping Chen category:cs.NE cs.LO  published:2016-02-24 summary:Mathematical theorems are human knowledge able to be accumulated in the form of symbolic representation, and proving theorems has been considered intelligent behavior. Based on the BHK interpretation and the Curry-Howard isomorphism, proof assistants, software capable of interacting with human for constructing formal proofs, have been developed in the past several decades. Since proofs can be considered and expressed as programs, proof assistants simplify and verify a proof by computationally evaluating the program corresponding to the proof. Thanks to the transformation from logic to computation, it is now possible to generate or search for formal proofs directly in the realm of computation. Evolutionary algorithms, known to be flexible and versatile, have been successfully applied to handle a variety of scientific and engineering problems in numerous disciplines for also several decades. Examining the feasibility of establishing the link between evolutionary algorithms, as the program generator, and proof assistants, as the proof verifier, in order to automatically find formal proofs to a given logic sentence is the primary goal of this study. In the article, we describe in detail our first, ad-hoc attempt to fully automatically prove theorems as well as the preliminary results. Ten simple theorems from various branches of mathematics were proven, and most of these theorems cannot be proven by using the tactic auto alone in Coq, the adopted proof assistant. The implication and potential influence of this study are discussed, and the developed source code with the obtained experimental results are released as open source. version:2
arxiv-1604-04397 | Low-Rank Matrix Recovery using Gabidulin Codes in Characteristic Zero | http://arxiv.org/abs/1604.04397 | id:1604.04397 author:Sven Müelich, Sven Puchinger, Martin Bossert category:cs.IT cs.CV math.IT  published:2016-04-15 summary:We present a new approach on low-rank matrix recovery (LRMR) based on Gabidulin Codes. Since most applications of LRMR deal with matrices over infinite fields, we use the recently introduced generalization of Gabidulin codes to fields of characterstic zero. We show that LRMR can be reduced to decoding of Gabidulin codes and discuss which field extensions can be used in the code construction. version:1
arxiv-1506-02267 | Computationally Efficient Bayesian Learning of Gaussian Process State Space Models | http://arxiv.org/abs/1506.02267 | id:1506.02267 author:Andreas Svensson, Arno Solin, Simo Särkkä, Thomas B. Schön category:stat.CO stat.ML  published:2015-06-07 summary:Gaussian processes allow for flexible specification of prior assumptions of unknown dynamics in state space models. We present a procedure for efficient Bayesian learning in Gaussian process state space models, where the representation is formed by projecting the problem onto a set of approximate eigenfunctions derived from the prior covariance structure. Learning under this family of models can be conducted using a carefully crafted particle MCMC algorithm. This scheme is computationally efficient and yet allows for a fully Bayesian treatment of the problem. Compared to conventional system identification tools or existing learning methods, we show competitive performance and reliable quantification of uncertainties in the model. version:2
arxiv-1604-04383 | Composition of Deep and Spiking Neural Networks for Very Low Bit Rate Speech Coding | http://arxiv.org/abs/1604.04383 | id:1604.04383 author:Milos Cernak, Alexandros Lazaridis, Afsaneh Asaei, Philip N. Garner category:cs.SD cs.CL  published:2016-04-15 summary:Most current very low bit rate (VLBR) speech coding systems use hidden Markov model (HMM) based speech recognition/synthesis techniques. This allows transmission of information (such as phonemes) segment by segment that decreases the bit rate. However, the encoder based on a phoneme speech recognition may create bursts of segmental errors. Segmental errors are further propagated to optional suprasegmental (such as syllable) information coding. Together with the errors of voicing detection in pitch parametrization, HMM-based speech coding creates speech discontinuities and unnatural speech sound artefacts. In this paper, we propose a novel VLBR speech coding framework based on neural networks (NNs) for end-to-end speech analysis and synthesis without HMMs. The speech coding framework relies on phonological (sub-phonetic) representation of speech, and it is designed as a composition of deep and spiking NNs: a bank of phonological analysers at the transmitter, and a phonological synthesizer at the receiver, both realised as deep NNs, and a spiking NN as an incremental and robust encoder of syllable boundaries for coding of continuous fundamental frequency (F0). A combination of phonological features defines much more sound patterns than phonetic features defined by HMM-based speech coders, and the finer analysis/synthesis code contributes into smoother encoded speech. Listeners significantly prefer the NN-based approach due to fewer discontinuities and speech artefacts of the encoded speech. A single forward pass is required during the speech encoding and decoding. The proposed VLBR speech coding operates at bit rate about 360 bits/sec. version:1
arxiv-1604-04382 | Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks | http://arxiv.org/abs/1604.04382 | id:1604.04382 author:Chuan Li, Michael Wand category:cs.CV  published:2016-04-15 summary:This paper proposes Markovian Generative Adversarial Networks (MGANs), a method for training generative neural networks for efficient texture synthesis. While deep neural network approaches have recently demonstrated remarkable results in terms of synthesis quality, they still come at considerable computational costs (minutes of run-time for low-res images). Our paper addresses this efficiency issue. Instead of a numerical deconvolution in previous work, we precompute a feed-forward, strided convolutional network that captures the feature statistics of Markovian patches and is able to directly generate outputs of arbitrary dimensions. Such network can directly decode brown noise to realistic texture, or photos to artistic paintings. With adversarial training, we obtain quality comparable to recent neural texture synthesis methods. As no optimization is required any longer at generation time, our run-time performance (0.25M pixel images at 25Hz) surpasses previous neural texture synthesizers by a significant margin (at least 500 times faster). We apply this idea to texture synthesis, style transfer, and video stylization. version:1
arxiv-1604-04378 | Match-SRNN: Modeling the Recursive Matching Structure with Spatial RNN | http://arxiv.org/abs/1604.04378 | id:1604.04378 author:Shengxian Wan, Yanyan Lan, Jun Xu, Jiafeng Guo, Liang Pang, Xueqi Cheng category:cs.CL cs.AI cs.LG cs.NE  published:2016-04-15 summary:Semantic matching, which aims to determine the matching degree between two texts, is a fundamental problem for many NLP applications. Recently, deep learning approach has been applied to this problem and significant improvements have been achieved. In this paper, we propose to view the generation of the global interaction between two texts as a recursive process: i.e. the interaction of two texts at each position is a composition of the interactions between their prefixes as well as the word level interaction at the current position. Based on this idea, we propose a novel deep architecture, namely Match-SRNN, to model the recursive matching structure. Firstly, a tensor is constructed to capture the word level interactions. Then a spatial RNN is applied to integrate the local interactions recursively, with importance determined by four types of gates. Finally, the matching score is calculated based on the global interaction. We show that, after degenerated to the exact matching scenario, Match-SRNN can approximate the dynamic programming process of longest common subsequence. Thus, there exists a clear interpretation for Match-SRNN. Our experiments on two semantic matching tasks showed the effectiveness of Match-SRNN, and its ability of visualizing the learned matching structure. version:1
arxiv-1604-04377 | DARI: Distance metric And Representation Integration for Person Verification | http://arxiv.org/abs/1604.04377 | id:1604.04377 author:Guangrun Wang, Liang Lin, Shengyong Ding, Ya Li, Qing Wang category:cs.CV  published:2016-04-15 summary:The past decade has witnessed the rapid development of feature representation learning and distance metric learning, whereas the two steps are often discussed separately. To explore their interaction, this work proposes an end-to-end learning framework called DARI, i.e. Distance metric And Representation Integration, and validates the effectiveness of DARI in the challenging task of person verification. Given the training images annotated with the labels, we first produce a large number of triplet units, and each one contains three images, i.e. one person and the matched/mismatch references. For each triplet unit, the distance disparity between the matched pair and the mismatched pair tends to be maximized. We solve this objective by building a deep architecture of convolutional neural networks. In particular, the Mahalanobis distance matrix is naturally factorized as one top fully-connected layer that is seamlessly integrated with other bottom layers representing the image feature. The image feature and the distance metric can be thus simultaneously optimized via the one-shot backward propagation. On several public datasets, DARI shows very promising performance on re-identifying individuals cross cameras against various challenges, and outperforms other state-of-the-art approaches. version:1
arxiv-1604-04372 | The Chow Form of the Essential Variety in Computer Vision | http://arxiv.org/abs/1604.04372 | id:1604.04372 author:Gunnar Fløystad, Joe Kileel, Giorgio Ottaviani category:math.AG cs.CV math.AC  published:2016-04-15 summary:The Chow form of the essential variety in computer vision is calculated. Our derivation uses secant varieties, Ulrich sheaves and representation theory. Numerical experiments show that our formula can detect noisy point correspondences between two images. version:1
arxiv-1604-04358 | StalemateBreaker: A Proactive Content-Introducing Approach to Automatic Human-Computer Conversation | http://arxiv.org/abs/1604.04358 | id:1604.04358 author:Xiang Li, Lili Mou, Rui Yan, Ming Zhang category:cs.CL cs.AI cs.IR  published:2016-04-15 summary:Existing open-domain human-computer conversation systems are typically passive: they either synthesize or retrieve a reply provided a human-issued utterance. It is generally presumed that humans should take the role to lead the conversation and introduce new content when a stalemate occurs, and that the computer only needs to "respond." In this paper, we propose StalemateBreaker, a conversation system that can proactively introduce new content when appropriate. We design a pipeline to determine when, what, and how to introduce new content during human-computer conversation. We further propose a novel reranking algorithm Bi-PageRank-HITS to enable rich interaction between conversation context and candidate replies. Experiments show that both the content-introducing approach and the reranking algorithm are effective. Our full StalemateBreaker model outperforms a state-of-the-practice conversation system by +14.4% p@1 when a stalemate occurs. version:1
arxiv-1602-06586 | Recovering Structured Probability Matrices | http://arxiv.org/abs/1602.06586 | id:1602.06586 author:Qingqing Huang, Sham M. Kakade, Weihao Kong, Gregory Valiant category:cs.LG  published:2016-02-21 summary:We consider the problem of accurately recovering a matrix B of size M by M , which represents a probability distribution over M2 outcomes, given access to an observed matrix of "counts" generated by taking independent samples from the distribution B. How can structural properties of the underlying matrix B be leveraged to yield computationally efficient and information theoretically optimal reconstruction algorithms? When can accurate reconstruction be accomplished in the sparse data regime? This basic problem lies at the core of a number of questions that are currently being considered by different communities, including building recommendation systems and collaborative filtering in the sparse data regime, community detection in sparse random graphs, learning structured models such as topic models or hidden Markov models, and the efforts from the natural language processing community to compute "word embeddings". Our results apply to the setting where B has a low rank structure. For this setting, we propose an efficient algorithm that accurately recovers the underlying M by M matrix using Theta(M) samples. This result easily translates to Theta(M) sample algorithms for learning topic models and learning hidden Markov Models. These linear sample complexities are optimal, up to constant factors, in an extremely strong sense: even testing basic properties of the underlying matrix (such as whether it has rank 1 or 2) requires Omega(M) samples. We provide an even stronger lower bound where distinguishing whether a sequence of observations were drawn from the uniform distribution over M observations versus being generated by an HMM with two hidden states requires Omega(M) observations. This precludes sublinear-sample hypothesis tests for basic properties, such as identity or uniformity, as well as sublinear sample estimators for quantities such as the entropy rate of HMMs. version:4
arxiv-1604-04339 | High-performance Semantic Segmentation Using Very Deep Fully Convolutional Networks | http://arxiv.org/abs/1604.04339 | id:1604.04339 author:Zifeng Wu, Chunhua Shen, Anton van den Hengel category:cs.CV  published:2016-04-15 summary:We propose a method for high-performance semantic image segmentation (or semantic pixel labelling) based on very deep residual networks, which achieves the state-of-the-art performance. A few design factors are carefully considered to this end. We make the following contributions. (i) First, we evaluate different variations of a fully convolutional residual network so as to find the best configuration, including the number of layers, the resolution of feature maps, and the size of field-of-view. Our experiments show that further enlarging the field-of-view and increasing the resolution of feature maps are typically beneficial, which however inevitably leads to a higher demand for GPU memories. To walk around the limitation, we propose a new method to simulate a high resolution network with a low resolution network, which can be applied during training and/or testing. (ii) Second, we propose an online bootstrapping method for training. We demonstrate that online bootstrapping is critically important for achieving good accuracy. (iii) Third we apply the traditional dropout to some of the residual blocks, which further improves the performance. (iv) Finally, our method achieves the currently best mean intersection-over-union 78.3\% on the PASCAL VOC 2012 dataset, as well as on the recent dataset Cityscapes. version:1
arxiv-1604-04337 | Facial expression recognition based on local region specific features and support vector machines | http://arxiv.org/abs/1604.04337 | id:1604.04337 author:Deepak Ghimire, Sunghwan Jeong, Joonwhoan Lee, Sang Hyun Park category:cs.CV  published:2016-04-15 summary:Facial expressions are one of the most powerful, natural and immediate means for human being to communicate their emotions and intensions. Recognition of facial expression has many applications including human-computer interaction, cognitive science, human emotion analysis, personality development etc. In this paper, we propose a new method for the recognition of facial expressions from single image frame that uses combination of appearance and geometric features with support vector machines classification. In general, appearance features for the recognition of facial expressions are computed by dividing face region into regular grid (holistic representation). But, in this paper we extracted region specific appearance features by dividing the whole face region into domain specific local regions. Geometric features are also extracted from corresponding domain specific regions. In addition, important local regions are determined by using incremental search approach which results in the reduction of feature dimension and improvement in recognition accuracy. The results of facial expressions recognition using features from domain specific regions are also compared with the results obtained using holistic representation. The performance of the proposed facial expression recognition system has been validated on publicly available extended Cohn-Kanade (CK+) facial expression data sets. version:1
arxiv-1604-04334 | Recognition of facial expressions based on salient geometric features and support vector machines | http://arxiv.org/abs/1604.04334 | id:1604.04334 author:Deepak Ghimire, Joonwhoan Lee, Ze-Nian Li, Sunghwan Jeong category:cs.CV  published:2016-04-15 summary:Facial expressions convey nonverbal cues which play an important role in interpersonal relations, and are widely used in behavior interpretation of emotions, cognitive science, and social interactions. In this paper we analyze different ways of representing geometric feature and present a fully automatic facial expression recognition (FER) system using salient geometric features. In geometric feature-based FER approach, the first important step is to initialize and track dense set of facial points as the expression evolves over time in consecutive frames. In the proposed system, facial points are initialized using elastic bunch graph matching (EBGM) algorithm and tracking is performed using Kanade-Lucas-Tomaci (KLT) tracker. We extract geometric features from point, line and triangle composed of tracking results of facial points. The most discriminative line and triangle features are extracted using feature selective multi-class AdaBoost with the help of extreme learning machine (ELM) classification. Finally the geometric features for FER are extracted from the boosted line, and triangles composed of facial points. The recognition accuracy using features from point, line and triangle are analyzed independently. The performance of the proposed FER system is evaluated on three different data sets: namely CK+, MMI and MUG facial expression data sets. version:1
arxiv-1604-04333 | Latent Model Ensemble with Auto-localization | http://arxiv.org/abs/1604.04333 | id:1604.04333 author:Miao Sun, Tony X. Han, Xun Xu category:cs.CV  published:2016-04-15 summary:Deep Convolutional Neural Networks (CNN) have exhibited superior performance in many visual recognition tasks including image classification, object detection, and scene label- ing, due to their large learning capacity and resistance to overfit. For the image classification task, most of the current deep CNN- based approaches take the whole size-normalized image as input and have achieved quite promising results. Compared with the previously dominating approaches based on feature extraction, pooling, and classification, the deep CNN-based approaches mainly rely on the learning capability of deep CNN to achieve superior results: the burden of minimizing intra-class variation while maximizing inter-class difference is entirely dependent on the implicit feature learning component of deep CNN; we rely upon the implicitly learned filters and pooling component to select the discriminative regions, which correspond to the activated neurons. However, if the irrelevant regions constitute a large portion of the image of interest, the classification performance of the deep CNN, which takes the whole image as input, can be heavily affected. To solve this issue, we propose a novel latent CNN framework, which treats the most discriminate region as a latent variable. We can jointly learn the global CNN with the latent CNN to avoid the aforementioned big irrelevant region issue, and our experimental results show the evident advantage of the proposed latent CNN over traditional deep CNN: latent CNN outperforms the state-of-the-art performance of deep CNN on standard benchmark datasets including the CIFAR-10, CIFAR- 100, MNIST and PASCAL VOC 2007 Classification dataset. version:1
arxiv-1604-04326 | Improving the Robustness of Deep Neural Networks via Stability Training | http://arxiv.org/abs/1604.04326 | id:1604.04326 author:Stephan Zheng, Yang Song, Thomas Leung, Ian Goodfellow category:cs.CV cs.LG  published:2016-04-15 summary:In this paper we address the issue of output instability of deep neural networks: small perturbations in the visual input can significantly distort the feature embeddings and output of a neural network. Such instability affects many deep architectures with state-of-the-art performance on a wide range of computer vision tasks. We present a general stability training method to stabilize deep networks against small input distortions that result from various types of common image processing, such as compression, rescaling, and cropping. We validate our method by stabilizing the state-of-the-art Inception architecture against these types of distortions. In addition, we demonstrate that our stabilized model gives robust state-of-the-art performance on large-scale near-duplicate detection, similar-image ranking, and classification on noisy datasets. version:1
arxiv-1511-03995 | LLNet: A Deep Autoencoder Approach to Natural Low-light Image Enhancement | http://arxiv.org/abs/1511.03995 | id:1511.03995 author:Kin Gwn Lore, Adedotun Akintayo, Soumik Sarkar category:cs.CV  published:2015-11-12 summary:In surveillance, monitoring and tactical reconnaissance, gathering the right visual information from a dynamic environment and accurately processing such data are essential ingredients to making informed decisions which determines the success of an operation. Camera sensors are often cost-limited in ability to clearly capture objects without defects from images or videos taken in a poorly-lit environment. The goal in many applications is to enhance the brightness, contrast and reduce noise content of such images in an on-board real-time manner. We propose a deep autoencoder-based approach to identify signal features from low-light images handcrafting and adaptively brighten images without over-amplifying the lighter parts in images (i.e., without saturation of image pixels) in high dynamic range. We show that a variant of the recently proposed stacked-sparse denoising autoencoder can learn to adaptively enhance and denoise from synthetically darkened and noisy training examples. The network can then be successfully applied to naturally low-light environment and/or hardware degraded images. Results show significant credibility of deep learning based approaches both visually and by quantitative comparison with various popular enhancing, state-of-the-art denoising and hybrid enhancing-denoising techniques. version:3
arxiv-1503-00173 | Signal Processing on Graphs: Causal Modeling of Big Data | http://arxiv.org/abs/1503.00173 | id:1503.00173 author:Jonathan Mei, José M. F. Moura category:cs.IT math.IT stat.ML  published:2015-02-28 summary:Often, Big Data applications collect a large number of time series, for example, the financial data of companies quoted in a stock exchange, the health care data of all patients that visit the emergency room of a hospital, or the temperature sequences continuously measured by weather stations across the US. A first task in the analytics of these data is to derive a low dimensional representation, a graph or discrete manifold, that describes well the interrelations among the time series and their intrarelations across time. This paper presents a computationally tractable algorithm for estimating this graph structure from the available data. This graph is directed and weighted, possibly representing causal relations, not just reciprocal correlations as in many existing approaches in the literature. A detailed convergence analysis is carried out. The algorithm is demonstrated on random graph and real network time series datasets, and its performance is compared to that of related methods. The adjacency matrices estimated with the new method are close to the true graph in the simulated data and consistent with prior physical knowledge in the real dataset tested. version:2
arxiv-1604-04293 | Unsupervised Nonlinear Spectral Unmixing based on a Multilinear Mixing Model | http://arxiv.org/abs/1604.04293 | id:1604.04293 author:Qi Wei, Marcus Chen, Jean-Yves Tourneret, Simon Godsill category:cs.CV  published:2016-04-14 summary:In the community of remote sensing, nonlinear mixing models have recently received particular attention in hyperspectral image processing. In this paper, we present a novel nonlinear spectral unmixing method following the recent multilinear mixing model of [1], which includes an infinite number of terms related to interactions between different endmembers. The proposed unmixing method is unsupervised in the sense that the endmembers are estimated jointly with the abundances and other parameters of interest, i.e., the transition probability of undergoing further interactions. Non-negativity and sum-to one constraints are imposed on abundances while only nonnegativity is considered for endmembers. The resulting unmixing problem is formulated as a constrained nonlinear optimization problem, which is solved by a block coordinate descent strategy, consisting of updating the endmembers, abundances and transition probability iteratively. The proposed method is evaluated and compared with linear unmixing methods for synthetic and real hyperspectral datasets acquired by the AVIRIS sensor. The advantage of using non-linear unmixing as opposed to linear unmixing is clearly shown in these examples. version:1
arxiv-1603-04017 | Clustering Financial Time Series: How Long is Enough? | http://arxiv.org/abs/1603.04017 | id:1603.04017 author:Gautier Marti, Sébastien Andler, Frank Nielsen, Philippe Donnat category:stat.ML q-fin.ST  published:2016-03-13 summary:Researchers have used from 30 days to several years of daily returns as source data for clustering financial time series based on their correlations. This paper sets up a statistical framework to study the validity of such practices. We first show that clustering correlated random variables from their observed values is statistically consistent. Then, we also give a first empirical answer to the much debated question: How long should the time series be? If too short, the clusters found can be spurious; if too long, dynamics can be smoothed out. version:2
arxiv-1604-04279 | Learning Visual Storylines with Skipping Recurrent Neural Networks | http://arxiv.org/abs/1604.04279 | id:1604.04279 author:Gunnar A. Sigurdsson, Xinlei Chen, Abhinav Gupta category:cs.CV  published:2016-04-14 summary:What does a typical visit to Paris look like? Do people first take photos of the Louvre and then the Eiffel Tower? Can we visually model a temporal event like "Paris Vacation" using current frameworks? In this paper, we explore how we can automatically learn the temporal aspects, or storylines of visual concepts from web data. Previous attempts focus on consecutive image-to-image transitions and are unsuccessful at recovering the long-term underlying story. Our novel Skipping Recurrent Neural Network (S-RNN) model, does not attempt to predict each and every data point in the sequence, like classic RNNs. Rather, S-RNN uses a framework that skips through the images in the photo stream to explore the space of all ordered subsets of the albums via an efficient sampling procedure. This approach reduces the negative impact of strong short-term correlations, and recovers the latent story more accurately. We show how our learned storylines can be used to analyze, predict, and summarize photo albums from Flickr. Our experimental results provide strong qualitative and quantitative evidence that S-RNN is significantly better than other candidate methods such as LSTMs on learning long-term correlations and recovering latent storylines. Moreover, we show how storylines can help machines better understand and summarize photo streams by inferring a brief personalized story of each individual album. version:1
arxiv-1506-04714 | Slow and steady feature analysis: higher order temporal coherence in video | http://arxiv.org/abs/1506.04714 | id:1506.04714 author:Dinesh Jayaraman, Kristen Grauman category:cs.CV  published:2015-06-15 summary:How can unlabeled video augment visual learning? Existing methods perform "slow" feature analysis, encouraging the representations of temporally close frames to exhibit only small differences. While this standard approach captures the fact that high-level visual signals change slowly over time, it fails to capture *how* the visual content changes. We propose to generalize slow feature analysis to "steady" feature analysis. The key idea is to impose a prior that higher order derivatives in the learned feature space must be small. To this end, we train a convolutional neural network with a regularizer on tuples of sequential frames from unlabeled video. It encourages feature changes over time to be smooth, i.e., similar to the most recent changes. Using five diverse datasets, including unlabeled YouTube and KITTI videos, we demonstrate our method's impact on object, scene, and action recognition tasks. We further show that our features learned from unlabeled video can even surpass a standard heavily supervised pretraining approach. version:2
arxiv-1602-08680 | Measuring and Predicting Tag Importance for Image Retrieval | http://arxiv.org/abs/1602.08680 | id:1602.08680 author:Shangwen Li, Sanjay Purushotham, Chen Chen, Yuzhuo Ren, C. -C. Jay Kuo category:cs.CV  published:2016-02-28 summary:Textual data such as tags, sentence descriptions are combined with visual cues to reduce the semantic gap for image retrieval applications in today's Multimodal Image Retrieval (MIR) systems. However, all tags are treated as equally important in these systems, which may result in misalignment between visual and textual modalities during MIR training. This will further lead to degenerated retrieval performance at query time. To address this issue, we investigate the problem of tag importance prediction, where the goal is to automatically predict the tag importance and use it in image retrieval. To achieve this, we first propose a method to measure the relative importance of object and scene tags from image sentence descriptions. Using this as the ground truth, we present a tag importance prediction model by exploiting joint visual, semantic and context cues. The Structural Support Vector Machine (SSVM) formulation is adopted to ensure efficient training of the prediction model. Then, the Canonical Correlation Analysis (CCA) is employed to learn the relation between the image visual feature and tag importance to obtain robust retrieval performance. Experimental results on three real-world datasets show a significant performance improvement of the proposed MIR with Tag Importance Prediction (MIR/TIP) system over other MIR systems. version:2
arxiv-1604-04213 | Modeling Electrical Daily Demand in Presence of PHEVs in Smart Grids with Supervised Learning | http://arxiv.org/abs/1604.04213 | id:1604.04213 author:Marco Pellegrini, Farshad Rassaei category:cs.LG  published:2016-04-14 summary:Replacing a portion of current light duty vehicles (LDV) with plug-in hybrid electric vehicles (PHEVs) offers the possibility to reduce the dependence on petroleum fuels together with environmental and economic benefits. The charging activity of PHEVs will certainly introduce new load to the power grid. In the framework of the development of a smarter grid, the primary focus of the present study is to propose a model for the electrical daily demand in presence of PHEVs charging. Expected PHEV demand is modeled by the PHEV charging time and the starting time of charge according to real world data. A normal distribution for starting time of charge is assumed. Several distributions for charging time are considered: uniform distribution, Gaussian with positive support, Rician distribution and a non-uniform distribution coming from driving patterns in real-world data. We generate daily demand profiles by using real-world residential profiles throughout 2014 in the presence of different expected PHEV demand models. Support vector machines (SVMs), a set of supervised machine learning models, are employed in order to find the best model to fit the data. SVMs with radial basis function (RBF) and polynomial kernels were tested. Model performances are evaluated by means of mean squared error (MSE) and mean absolute percentage error (MAPE). Best results are obtained with RBF kernel: maximum (worst) values for MSE and MAPE were about 2.89 10-8 and 0.023, respectively. version:1
arxiv-1501-03209 | Neural Implementation of Probabilistic Models of Cognition | http://arxiv.org/abs/1501.03209 | id:1501.03209 author:Milad Kharratzadeh, Thomas R. Shultz category:cs.NE q-bio.NC  published:2015-01-13 summary:Bayesian models of cognition hypothesize that human brains make sense of data by representing probability distributions and applying Bayes' rule to find the best explanation for available data. Understanding the neural mechanisms underlying probabilistic models remains important because Bayesian models provide a computational framework, rather than specifying mechanistic processes. Here, we propose a deterministic neural-network model which estimates and represents probability distributions from observable events --- a phenomenon related to the concept of probability matching. Our model learns to represent probabilities without receiving any representation of them from the external world, but rather by experiencing the occurrence patterns of individual events. Our neural implementation of probability matching is paired with a neural module applying Bayes' rule, forming a comprehensive neural scheme to simulate human Bayesian learning and inference. Our model also provides novel explanations of base-rate neglect, a notable deviation from Bayes. version:2
arxiv-1604-04191 | 1-bit Matrix Completion: PAC-Bayesian Analysis of a Variational Approximation | http://arxiv.org/abs/1604.04191 | id:1604.04191 author:Vincent Cottet, Pierre Alquier category:stat.ML  published:2016-04-14 summary:Due to challenging applications such as collaborative filtering, the matrix completion problem has been widely studied in the past few years. Different approaches rely on different structure assumptions on the matrix in hand. Here, we focus on the completion of a (possibly) low-rank matrix with binary entries, the so-called 1-bit matrix completion problem. Our approach relies on tools from machine learning theory: empirical risk minimization and its convex relaxations. We propose an algorithm to compute a variational approximation of the pseudo-posterior. Thanks to the convex relaxation, the corresponding minimization problem is bi-convex, and thus the method behaves well in practice. We also study the performance of this variational approximation through PAC-Bayesian learning bounds. On the contrary to previous works that focused on upper bounds on the estimation error of M with various matrix norms, we are able to derive from this analysis a PAC bound on the prediction error of our algorithm. We focus essentially on convex relaxation through the hinge loss, for which we present the complete analysis, a complete simulation study and a test on the MovieLens data set. However, we also discuss a variational approximation to deal with the logistic loss. version:1
arxiv-1601-00034 | Stochastic Neural Networks with Monotonic Activation Functions | http://arxiv.org/abs/1601.00034 | id:1601.00034 author:Siamak Ravanbakhsh, Barnabas Poczos, Jeff Schneider, Dale Schuurmans, Russell Greiner category:stat.ML cs.LG cs.NE  published:2016-01-01 summary:We propose a Laplace approximation that creates a stochastic unit from any smooth monotonic activation function, using only Gaussian noise. This paper investigates the application of this stochastic approximation in training a family of Restricted Boltzmann Machines (RBM) that are closely linked to Bregman divergences. This family, that we call exponential family RBM (Exp-RBM), is a subset of the exponential family Harmoniums that expresses family members through a choice of smooth monotonic non-linearity for each neuron. Using contrastive divergence along with our Gaussian approximation, we show that Exp-RBM can learn useful representations using novel stochastic units. version:2
arxiv-1604-04182 | Consistently Estimating Markov Chains with Noisy Aggregate Data | http://arxiv.org/abs/1604.04182 | id:1604.04182 author:Garrett Bernstein, Daniel Sheldon category:cs.LG stat.ML  published:2016-04-14 summary:We address the problem of estimating the parameters of a time-homogeneous Markov chain given only noisy, aggregate data. This arises when a population of individuals behave independently according to a Markov chain, but individual sample paths cannot be observed due to limitations of the observation process or the need to protect privacy. Instead, only population-level counts of the number of individuals in each state at each time step are available. When these counts are exact, a conditional least squares (CLS) estimator is known to be consistent and asymptotically normal. We initiate the study of method of moments estimators for this problem to handle the more realistic case when observations are additionally corrupted by noise. We show that CLS can be interpreted as a simple "plug-in" method of moments estimator. However, when observations are noisy, it is not consistent because it fails to account for additional variance introduced by the noise. We develop a new, simpler method of moments estimator that bypasses this problem and is consistent under noisy observations. version:1
arxiv-1512-02017 | Visualizing Deep Convolutional Neural Networks Using Natural Pre-Images | http://arxiv.org/abs/1512.02017 | id:1512.02017 author:Aravindh Mahendran, Andrea Vedaldi category:cs.CV 68T45  published:2015-12-07 summary:Image representations, from SIFT and bag of visual words to Convolutional Neural Networks (CNNs) are a crucial component of almost all computer vision systems. However, our understanding of them remains limited. In this paper we study several landmark representations, both shallow and deep, by a number of complementary visualization techniques. These visualizations are based on the concept of "natural pre-image", namely a natural-looking image whose representation has some notable property. We study in particular three such visualizations: inversion, in which the aim is to reconstruct an image from its representation, activation maximization, in which we search for patterns that maximally stimulate a representation component, and caricaturization, in which the visual patterns that a representation detects in an image are exaggerated. We pose these as a regularized energy-minimization framework and demonstrate its generality and effectiveness. In particular, we show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too. Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance. version:3
arxiv-1604-04173 | Distribution-Free Predictive Inference For Regression | http://arxiv.org/abs/1604.04173 | id:1604.04173 author:Jing Lei, Max G'Sell, Alessandro Rinaldo, Ryan J. Tibshirani, Larry Wasserman category:stat.ME math.ST stat.ML stat.TH  published:2016-04-14 summary:We develop a general framework for distribution-free predictive inference in regression, using conformal inference. The proposed methodology allows construction of prediction bands for the response variable using any estimator of the regression function. The resulting prediction band preserves the consistency properties of the original estimator under standard assumptions, while guaranteeing finite sample marginal coverage even when the assumptions do not hold. We analyze and compare, both empirically and theoretically, two major variants of our conformal procedure: the full conformal inference and split conformal inference, along with a related jackknife method. These methods offer different tradeoffs between statistical accuracy (length of resulting prediction intervals) and computational efficiency. As extensions, we develop a method for constructing valid in-sample prediction intervals called rank-one-out conformal inference, which has essentially the same computational efficiency as split conformal inference. We also describe an extension of our procedures for producing prediction bands with varying local width, in order to adapt to heteroskedascity in the data distribution. Lastly, we propose a model-free notion of variable importance, called leave-one-covariate-out or LOCO inference. Accompanying our paper is an R package conformalInference that implements all of the proposals we have introduced. In the spirit of reproducibility, all empirical results in this paper can be easily (re)generated using this package. version:1
arxiv-1603-04595 | Nested Invariance Pooling and RBM Hashing for Image Instance Retrieval | http://arxiv.org/abs/1603.04595 | id:1603.04595 author:Olivier Morère, Jie Lin, Antoine Veillard, Vijay Chandrasekhar, Tomaso Poggio category:cs.CV cs.IR  published:2016-03-15 summary:The goal of this work is the computation of very compact binary hashes for image instance retrieval. Our approach has two novel contributions. The first one is Nested Invariance Pooling (NIP), a method inspired from i-theory, a mathematical theory for computing group invariant transformations with feed-forward neural networks. NIP is able to produce compact and well-performing descriptors with visual representations extracted from convolutional neural networks. We specifically incorporate scale, translation and rotation invariances but the scheme can be extended to any arbitrary sets of transformations. We also show that using moments of increasing order throughout nesting is important. The NIP descriptors are then hashed to the target code size (32-256 bits) with a Restricted Boltzmann Machine with a novel batch-level regularization scheme specifically designed for the purpose of hashing (RBMH). A thorough empirical evaluation with state-of-the-art shows that the results obtained both with the NIP descriptors and the NIP+RBMH hashes are consistently outstanding across a wide range of datasets. version:2
arxiv-1604-04153 | Learning to Generate Genotypes with Neural Networks | http://arxiv.org/abs/1604.04153 | id:1604.04153 author:Alexander W. Churchill, Siddharth Sigtia, Chrisantha Fernando category:cs.NE  published:2016-04-14 summary:Neural networks and evolutionary computation have a rich intertwined history. They most commonly appear together when an evolutionary algorithm optimises the parameters and topology of a neural network for reinforcement learning problems, or when a neural network is applied as a surrogate fitness function to aid the evolutionary optimisation of expensive fitness functions. In this paper we take a different approach, asking the question of whether a neural network can be used to provide a mutation distribution for an evolutionary algorithm, and what advantages this approach may offer? Two modern neural network models are investigated, a Denoising Autoencoder modified to produce stochastic outputs and the Neural Autoregressive Distribution Estimator. Results show that the neural network approach to learning genotypes is able to solve many difficult discrete problems, such as MaxSat and HIFF, and regularly outperforms other evolutionary techniques. version:1
arxiv-1604-04146 | A Discrete Firefly Algorithm to Solve a Rich Vehicle Routing Problem Modelling a Newspaper Distribution System with Recycling Policy | http://arxiv.org/abs/1604.04146 | id:1604.04146 author:E. Osaba, Xin-She Yang, F. Diaz, E. Onieva, A. D. Masegosa, A. Perallos category:cs.NE cs.AI math.OC 78M32  published:2016-04-14 summary:A real-world newspaper distribution problem with recycling policy is tackled in this work. In order to meet all the complex restrictions contained in such a problem, it has been modeled as a rich vehicle routing problem, which can be more specifically considered as an asymmetric and clustered vehicle routing problem with simultaneous pickup and deliveries, variable costs and forbidden paths (AC-VRP-SPDVCFP). This is the first study of such a problem in the literature. For this reason, a benchmark composed by 15 instances has been also proposed. In the design of this benchmark, real geographical positions have been used, located in the province of Bizkaia, Spain. For the proper treatment of this AC-VRP-SPDVCFP, a discrete firefly algorithm (DFA) has been developed. This application is the first application of the firefly algorithm to any rich vehicle routing problem. To prove that the proposed DFA is a promising technique, its performance has been compared with two other well-known techniques: an evolutionary algorithm and an evolutionary simulated annealing. Our results have shown that the DFA has outperformed these two classic meta-heuristics. version:1
arxiv-1604-04144 | Self-taught learning of a deep invariant representation for visual tracking via temporal slowness principle | http://arxiv.org/abs/1604.04144 | id:1604.04144 author:Jason Kuen, Kian Ming Lim, Chin Poo Lee category:cs.CV cs.LG cs.NE  published:2016-04-14 summary:Visual representation is crucial for a visual tracking method's performances. Conventionally, visual representations adopted in visual tracking rely on hand-crafted computer vision descriptors. These descriptors were developed generically without considering tracking-specific information. In this paper, we propose to learn complex-valued invariant representations from tracked sequential image patches, via strong temporal slowness constraint and stacked convolutional autoencoders. The deep slow local representations are learned offline on unlabeled data and transferred to the observational model of our proposed tracker. The proposed observational model retains old training samples to alleviate drift, and collect negative samples which are coherent with target's motion pattern for better discriminative tracking. With the learned representation and online training samples, a logistic regression classifier is adopted to distinguish target from background, and retrained online to adapt to appearance changes. Subsequently, the observational model is integrated into a particle filter framework to peform visual tracking. Experimental results on various challenging benchmark sequences demonstrate that the proposed tracker performs favourably against several state-of-the-art trackers. version:1
arxiv-1604-04142 | On Reducing the Number of Visual Words in the Bag-of-Features Representation | http://arxiv.org/abs/1604.04142 | id:1604.04142 author:Giuseppe Amato, Fabrizio Falchi, Claudio Gennaro category:cs.CV cs.IR  published:2016-04-14 summary:A new class of applications based on visual search engines are emerging, especially on smart-phones that have evolved into powerful tools for processing images and videos. The state-of-the-art algorithms for large visual content recognition and content based similarity search today use the "Bag of Features" (BoF) or "Bag of Words" (BoW) approach. The idea, borrowed from text retrieval, enables the use of inverted files. A very well known issue with this approach is that the query images, as well as the stored data, are described with thousands of words. This poses obvious efficiency problems when using inverted files to perform efficient image matching. In this paper, we propose and compare various techniques to reduce the number of words describing an image to improve efficiency and we study the effects of this reduction on effectiveness in landmark recognition and retrieval scenarios. We show that very relevant improvement in performance are achievable still preserving the advantages of the BoF base approach. version:1
arxiv-1604-04138 | An Improved Discrete Bat Algorithm for Symmetric and Asymmetric Traveling Salesman Problems | http://arxiv.org/abs/1604.04138 | id:1604.04138 author:Eneko Osaba, Xin-She Yang, Fernando Diaz, Pedro Lopez-Garcia, Roberto Carballedo category:cs.NE cs.AI math.OC 78M32  published:2016-04-14 summary:Bat algorithm is a population metaheuristic proposed in 2010 which is based on the echolocation or bio-sonar characteristics of microbats. Since its first implementation, the bat algorithm has been used in a wide range of fields. In this paper, we present a discrete version of the bat algorithm to solve the well-known symmetric and asymmetric traveling salesman problems. In addition, we propose an improvement in the basic structure of the classic bat algorithm. To prove that our proposal is a promising approximation method, we have compared its performance in 37 instances with the results obtained by five different techniques: evolutionary simulated annealing, genetic algorithm, an island based distributed genetic algorithm, a discrete firefly algorithm and an imperialist competitive algorithm. In order to obtain fair and rigorous comparisons, we have conducted three different statistical tests along the paper: the Student's $t$-test, the Holm's test, and the Friedman test. We have also compared the convergence behaviour shown by our proposal with the ones shown by the evolutionary simulated annealing, and the discrete firefly algorithm. The experimentation carried out in this study has shown that the presented improved bat algorithm outperforms significantly all the other alternatives in most of the cases. version:1
arxiv-1604-04125 | Filling in the details: Perceiving from low fidelity images | http://arxiv.org/abs/1604.04125 | id:1604.04125 author:Farahnaz Ahmed Wick, Michael L. Wick, Marc Pomplun category:cs.CV cs.LG cs.NE  published:2016-04-14 summary:Humans perceive their surroundings in great detail even though most of our visual field is reduced to low-fidelity color-deprived (e.g. dichromatic) input by the retina. In contrast, most deep learning architectures are computationally wasteful in that they consider every part of the input when performing an image processing task. Yet, the human visual system is able to perform visual reasoning despite having only a small fovea of high visual acuity. With this in mind, we wish to understand the extent to which connectionist architectures are able to learn from and reason with low acuity, distorted inputs. Specifically, we train autoencoders to generate full-detail images from low-detail "foveations" of those images and then measure their ability to reconstruct the full-detail images from the foveated versions. By varying the type of foveation, we can study how well the architectures can cope with various types of distortion. We find that the autoencoder compensates for lower detail by learning increasingly global feature functions. In many cases, the learnt features are suitable for reconstructing the original full-detail image. For example, we find that the networks accurately perceive color in the periphery, even when 75\% of the input is achromatic. version:1
arxiv-1509-07838 | Training Deep Networks with Structured Layers by Matrix Backpropagation | http://arxiv.org/abs/1509.07838 | id:1509.07838 author:Catalin Ionescu, Orestis Vantzos, Cristian Sminchisescu category:cs.CV cs.AI  published:2015-09-25 summary:Deep neural network architectures have recently produced excellent results in a variety of areas in artificial intelligence and visual recognition, well surpassing traditional shallow architectures trained using hand-designed features. The power of deep networks stems both from their ability to perform local computations followed by pointwise non-linearities over increasingly larger receptive fields, and from the simplicity and scalability of the gradient-descent training procedure based on backpropagation. An open problem is the inclusion of layers that perform global, structured matrix computations like segmentation (e.g. normalized cuts) or higher-order pooling (e.g. log-tangent space metrics defined over the manifold of symmetric positive definite matrices) while preserving the validity and efficiency of an end-to-end deep training framework. In this paper we propose a sound mathematical apparatus to formally integrate global structured computation into deep computation architectures. At the heart of our methodology is the development of the theory and practice of backpropagation that generalizes to the calculus of adjoint matrix variations. The proposed matrix backpropagation methodology applies broadly to a variety of problems in machine learning or computational perception. Here we illustrate it by performing visual segmentation experiments using the BSDS and MSCOCO benchmarks, where we show that deep networks relying on second-order pooling and normalized cuts layers, trained end-to-end using matrix backpropagation, outperform counterparts that do not take advantage of such global layers. version:4
arxiv-1511-04599 | DeepFool: a simple and accurate method to fool deep neural networks | http://arxiv.org/abs/1511.04599 | id:1511.04599 author:Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Pascal Frossard category:cs.LG  published:2015-11-14 summary:State-of-the-art deep neural networks have achieved impressive results on many image classification tasks. However, these same architectures have been shown to be unstable to small, well sought, perturbations of the images. Despite the importance of this phenomenon, no effective methods have been proposed to accurately compute the robustness of state-of-the-art deep classifiers to such perturbations on large-scale datasets. In this paper, we fill this gap and propose the DeepFool algorithm to efficiently compute perturbations that fool deep networks, and thus reliably quantify the robustness of these classifiers. Extensive experimental results show that our approach outperforms recent methods in the task of computing adversarial perturbations and making classifiers more robust. version:2
arxiv-1511-06973 | Ask Me Anything: Free-form Visual Question Answering Based on Knowledge from External Sources | http://arxiv.org/abs/1511.06973 | id:1511.06973 author:Qi Wu, Peng Wang, Chunhua Shen, Anthony Dick, Anton van den Hengel category:cs.CV  published:2015-11-22 summary:We propose a method for visual question answering which combines an internal representation of the content of an image with information extracted from a general knowledge base to answer a broad range of image-based questions. This allows more complex questions to be answered using the predominant neural network-based approach than has previously been possible. It particularly allows questions to be asked about the contents of an image, even when the image itself does not contain the whole answer. The method constructs a textual representation of the semantic content of an image, and merges it with textual information sourced from a knowledge base, to develop a deeper understanding of the scene viewed. Priming a recurrent neural network with this combined information, and the submitted question, leads to a very flexible visual question answering approach. We are specifically able to answer questions posed in natural language, that refer to information not contained in the image. We demonstrate the effectiveness of our model on two publicly available datasets, Toronto COCO-QA and MS COCO-VQA and show that it produces the best reported results in both cases. version:2
arxiv-1507-03409 | Unconstrained Facial Landmark Localization with Backbone-Branches Fully-Convolutional Networks | http://arxiv.org/abs/1507.03409 | id:1507.03409 author:Zhujin Liang, Shengyong Ding, Liang Lin category:cs.CV  published:2015-07-13 summary:This paper investigates how to rapidly and accurately localize facial landmarks in unconstrained, cluttered environments rather than in the well segmented face images. We present a novel Backbone-Branches Fully-Convolutional Neural Network (BB-FCN), which produces facial landmark response maps directly from raw images without relying on pre-process or sliding window approaches. BB-FCN contains one backbone and a number of network branches with each corresponding to one landmark type, and it operates in a progressive manner. Specifically, the backbone roughly detects the locations of facial landmarks by taking the whole image as input, and the branches further refine the localizations based on a local observation from the backbone's intermediate feature map. Moreover, our backbone-branches architecture does not contain full-connection layers for location regression, leading to efficient learning and inference. Our extensive experiments show that our model achieves superior performances over other state-of-the-arts under both the constrained (i.e. with face regions) and the "in the wild" scenarios. version:3
arxiv-1604-04054 | Optimal Rates For Regularization Of Statistical Inverse Learning Problems | http://arxiv.org/abs/1604.04054 | id:1604.04054 author:Gilles Blanchard, Nicole Mücke category:stat.ML  published:2016-04-14 summary:We consider a statistical inverse learning problem, where we observe the image of a function $f$ through a linear operator $A$ at i.i.d. random design points $X_i$, superposed with an additive noise. The distribution of the design points is unknown and can be very general. We analyze simultaneously the direct (estimation of $Af$) and the inverse (estimation of $f$) learning problems. In this general framework, we obtain strong and weak minimax optimal rates of convergence (as the number of observations $n$ grows large) for a large class of spectral regularization methods over regularity classes defined through appropriate source conditions. This improves on or completes previous results obtained in related settings. The optimality of the obtained rates is shown not only in the exponent in $n$ but also in the explicit dependency of the constant factor in the variance of the noise and the radius of the source condition set. version:1
arxiv-1604-04053 | Object Detection from Video Tubelets with Convolutional Neural Networks | http://arxiv.org/abs/1604.04053 | id:1604.04053 author:Kai Kang, Wanli Ouyang, Hongsheng Li, Xiaogang Wang category:cs.CV  published:2016-04-14 summary:Deep Convolution Neural Networks (CNNs) have shown impressive performance in various vision tasks such as image classification, object detection and semantic segmentation. For object detection, particularly in still images, the performance has been significantly increased last year thanks to powerful deep networks (e.g. GoogleNet) and detection frameworks (e.g. Regions with CNN features (R-CNN)). The lately introduced ImageNet task on object detection from video (VID) brings the object detection task into the video domain, in which objects' locations at each frame are required to be annotated with bounding boxes. In this work, we introduce a complete framework for the VID task based on still-image object detection and general object tracking. Their relations and contributions in the VID task are thoroughly studied and evaluated. In addition, a temporal convolution network is proposed to incorporate temporal information to regularize the detection results and shows its effectiveness for the task. version:1
arxiv-1604-04048 | Deep Feature Based Contextual Model for Object Detection | http://arxiv.org/abs/1604.04048 | id:1604.04048 author:Wenqing Chu, Deng Cai category:cs.CV  published:2016-04-14 summary:Object detection is one of the most active areas in computer vision, which has made significant improvement in recent years. Current state-of-the-art object detection methods mostly adhere to the framework of regions with convolutional neural network (R-CNN) and only use local appearance features inside object bounding boxes. Since these approaches ignore the contextual information around the object proposals, the outcome of these detectors may generate a semantically incoherent interpretation of the input image. In this paper, we propose an ensemble object detection system which incorporates the local appearance, the contextual information in term of relationships among objects and the global scene based contextual feature generated by a convolutional neural network. The system is formulated as a fully connected conditional random field (CRF) defined on object proposals and the contextual constraints among object proposals are modeled as edges naturally. Furthermore, a fast mean field approximation method is utilized to inference in this CRF model efficiently. The experimental results demonstrate that our approach achieves a higher mean average precision (mAP) on PASCAL VOC 2007 datasets compared to the baseline algorithm Faster R-CNN. version:1
arxiv-1603-06318 | Harnessing Deep Neural Networks with Logic Rules | http://arxiv.org/abs/1603.06318 | id:1603.06318 author:Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, Eric Xing category:cs.LG cs.AI cs.CL stat.ML  published:2016-03-21 summary:Combining deep neural networks with structured logic rules is desirable to harness flexibility and reduce unpredictability of the neural models. We propose a general framework capable of enhancing various types of neural networks (e.g., CNNs and RNNs) with declarative first-order logic rules. Specifically, we develop an iterative distillation method that transfers the structured information of logic rules into the weights of neural networks. We deploy the framework on a CNN for sentiment analysis, and an RNN for named entity recognition. With a few highly intuitive rules, we obtain substantial improvements and achieve state-of-the-art or comparable results to previous best-performing systems. version:2
arxiv-1604-04026 | Fast Parallel Randomized Algorithm for Nonnegative Matrix Factorization with KL Divergence for Large Sparse Datasets | http://arxiv.org/abs/1604.04026 | id:1604.04026 author:Duy Khuong Nguyen, Tu Bao Ho category:math.OC cs.LG cs.NA  published:2016-04-14 summary:Nonnegative Matrix Factorization (NMF) with Kullback-Leibler Divergence (NMF-KL) is one of the most significant NMF problems and equivalent to Probabilistic Latent Semantic Indexing (PLSI), which has been successfully applied in many applications. For sparse count data, a Poisson distribution and KL divergence provide sparse models and sparse representation, which describe the random variation better than a normal distribution and Frobenius norm. Specially, sparse models provide more concise understanding of the appearance of attributes over latent components, while sparse representation provides concise interpretability of the contribution of latent components over instances. However, minimizing NMF with KL divergence is much more difficult than minimizing NMF with Frobenius norm; and sparse models, sparse representation and fast algorithms for large sparse datasets are still challenges for NMF with KL divergence. In this paper, we propose a fast parallel randomized coordinate descent algorithm having fast convergence for large sparse datasets to archive sparse models and sparse representation. The proposed algorithm's experimental results overperform the current studies' ones in this problem. version:1
arxiv-1511-06078 | Learning Deep Structure-Preserving Image-Text Embeddings | http://arxiv.org/abs/1511.06078 | id:1511.06078 author:Liwei Wang, Yin Li, Svetlana Lazebnik category:cs.CV cs.CL cs.LG  published:2015-11-19 summary:This paper proposes a method for learning joint embeddings of images and text using a two-branch neural network with multiple layers of linear projections followed by nonlinearities. The network is trained using a large margin objective that combines cross-view ranking constraints with within-view neighborhood structure preservation constraints inspired by metric learning literature. Extensive experiments show that our approach gains significant improvements in accuracy for image-to-text and text-to-image retrieval. Our method achieves new state-of-the-art results on the Flickr30K and MSCOCO image-sentence datasets and shows promise on the new task of phrase localization on the Flickr30K Entities dataset. version:2
arxiv-1307-0048 | Simple one-pass algorithm for penalized linear regression with cross-validation on MapReduce | http://arxiv.org/abs/1307.0048 | id:1307.0048 author:Kun Yang category:stat.ML cs.DC cs.LG  published:2013-06-28 summary:In this paper, we propose a one-pass algorithm on MapReduce for penalized linear regression \[f_\lambda(\alpha, \beta) = \ Y - \alpha\mathbf{1} - X\beta\ _2^2 + p_{\lambda}(\beta)\] where $\alpha$ is the intercept which can be omitted depending on application; $\beta$ is the coefficients and $p_{\lambda}$ is the penalized function with penalizing parameter $\lambda$. $f_\lambda(\alpha, \beta)$ includes interesting classes such as Lasso, Ridge regression and Elastic-net. Compared to latest iterative distributed algorithms requiring multiple MapReduce jobs, our algorithm achieves huge performance improvement; moreover, our algorithm is exact compared to the approximate algorithms such as parallel stochastic gradient decent. Moreover, what our algorithm distinguishes with others is that it trains the model with cross validation to choose optimal $\lambda$ instead of user specified one. Key words: penalized linear regression, lasso, elastic-net, ridge, MapReduce version:3
arxiv-1603-00560 | Learnt quasi-transitive similarity for retrieval from large collections of faces | http://arxiv.org/abs/1603.00560 | id:1603.00560 author:Ognjen Arandjelovic category:cs.CV  published:2016-03-02 summary:We are interested in identity-based retrieval of face sets from large unlabelled collections acquired in uncontrolled environments. Given a baseline algorithm for measuring the similarity of two face sets, the meta-algorithm introduced in this paper seeks to leverage the structure of the data corpus to make the best use of the available baseline. In particular, we show how partial transitivity of inter-personal similarity can be exploited to improve the retrieval of particularly challenging sets which poorly match the query under the baseline measure. We: (i) describe the use of proxy sets as a means of computing the similarity between two sets, (ii) introduce transitivity meta-features based on the similarity of salient modes of appearance variation between sets, (iii) show how quasi-transitivity can be learnt from such features without any labelling or manual intervention, and (iv) demonstrate the effectiveness of the proposed methodology through experiments on the notoriously challenging YouTube database and two successful baselines from the literature. version:2
arxiv-1601-05150 | Factors in Finetuning Deep Model for object detection | http://arxiv.org/abs/1601.05150 | id:1601.05150 author:Wanli Ouyang, Xiaogang Wang, Cong Zhang, Xiaokang Yang category:cs.CV  published:2016-01-20 summary:Finetuning from a pretrained deep model is found to yield state-of-the-art performance for many vision tasks. This paper investigates many factors that influence the performance in finetuning for object detection. There is a long-tailed distribution of sample numbers for classes in object detection. Our analysis and empirical results show that classes with more samples have higher impact on the feature learning. And it is better to make the sample number more uniform across classes. Generic object detection can be considered as multiple equally important tasks. Detection of each class is a task. These classes/tasks have their individuality in discriminative visual appearance representation. Taking this individuality into account, we cluster objects into visually similar class groups and learn deep representations for these groups separately. A hierarchical feature learning scheme is proposed. In this scheme, the knowledge from the group with large number of classes is transferred for learning features in its sub-groups. Finetuned on the GoogLeNet model, experimental results show 4.7% absolute mAP improvement of our approach on the ImageNet object detection dataset without increasing much computational cost at the testing stage. version:2
arxiv-1508-02087 | A Linearly-Convergent Stochastic L-BFGS Algorithm | http://arxiv.org/abs/1508.02087 | id:1508.02087 author:Philipp Moritz, Robert Nishihara, Michael I. Jordan category:math.OC cs.LG math.NA stat.CO stat.ML  published:2015-08-09 summary:We propose a new stochastic L-BFGS algorithm and prove a linear convergence rate for strongly convex and smooth functions. Our algorithm draws heavily from a recent stochastic variant of L-BFGS proposed in Byrd et al. (2014) as well as a recent approach to variance reduction for stochastic gradient descent from Johnson and Zhang (2013). We demonstrate experimentally that our algorithm performs well on large-scale convex and non-convex optimization problems, exhibiting linear convergence and rapidly solving the optimization problems to high levels of precision. Furthermore, we show that our algorithm performs well for a wide-range of step sizes, often differing by several orders of magnitude. version:2
arxiv-1502-03240 | Conditional Random Fields as Recurrent Neural Networks | http://arxiv.org/abs/1502.03240 | id:1502.03240 author:Shuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, Zhizhong Su, Dalong Du, Chang Huang, Philip H. S. Torr category:cs.CV  published:2015-02-11 summary:Pixel-level labelling tasks, such as semantic segmentation, play a central role in image understanding. Recent approaches have attempted to harness the capabilities of deep learning techniques for image recognition to tackle pixel-level labelling tasks. One central issue in this methodology is the limited capacity of deep learning techniques to delineate visual objects. To solve this problem, we introduce a new form of convolutional neural network that combines the strengths of Convolutional Neural Networks (CNNs) and Conditional Random Fields (CRFs)-based probabilistic graphical modelling. To this end, we formulate mean-field approximate inference for the Conditional Random Fields with Gaussian pairwise potentials as Recurrent Neural Networks. This network, called CRF-RNN, is then plugged in as a part of a CNN to obtain a deep network that has desirable properties of both CNNs and CRFs. Importantly, our system fully integrates CRF modelling with CNNs, making it possible to train the whole deep network end-to-end with the usual back-propagation algorithm, avoiding offline post-processing methods for object delineation. We apply the proposed method to the problem of semantic image segmentation, obtaining top results on the challenging Pascal VOC 2012 segmentation benchmark. version:3
arxiv-1604-03986 | Theoretically-Grounded Policy Advice from Multiple Teachers in Reinforcement Learning Settings with Applications to Negative Transfer | http://arxiv.org/abs/1604.03986 | id:1604.03986 author:Yusen Zhan, Haitham Bou Ammar, Matthew E. taylor category:cs.LG  published:2016-04-13 summary:Policy advice is a transfer learning method where a student agent is able to learn faster via advice from a teacher. However, both this and other reinforcement learning transfer methods have little theoretical analysis. This paper formally defines a setting where multiple teacher agents can provide advice to a student and introduces an algorithm to leverage both autonomous exploration and teacher's advice. Our regret bounds justify the intuition that good teachers help while bad teachers hurt. Using our formalization, we are also able to quantify, for the first time, when negative transfer can occur within such a reinforcement learning setting. version:1
arxiv-1604-03968 | Visual Storytelling | http://arxiv.org/abs/1604.03968 | id:1604.03968 author:Ting-Hao, Huang, Francis Ferraro, Nasrin Mostafazadeh, Ishan Misra, Aishwarya Agrawal, Jacob Devlin, Ross Girshick, Xiaodong He, Pushmeet Kohli, Dhruv Batra, C. Lawrence Zitnick, Devi Parikh, Lucy Vanderwende, Michel Galley, Margaret Mitchell category:cs.CL cs.AI cs.CV  published:2016-04-13 summary:We introduce the first dataset for sequential vision-to-language, and explore how this data may be used for the task of visual storytelling. The first release of this dataset, SIND v.1, includes 81,743 unique photos in 20,211 sequences, aligned to both descriptive (caption) and story language. We establish several strong baselines for the storytelling task, and motivate an automatic metric to benchmark progress. Modelling concrete description as well as figurative and social language, as provided in this dataset and the storytelling task, has the potential to move artificial intelligence from basic understandings of typical visual scenes towards more and more human-like understanding of grounded event structure and subjective expression. version:1
arxiv-1512-00389 | Accelerated graph-based nonlinear denoising filters | http://arxiv.org/abs/1512.00389 | id:1512.00389 author:Andrew Knyazev, Alexander Malyshev category:cs.CV math.NA 65F30 I.4.3; G.1.3  published:2015-12-01 summary:Denoising filters, such as bilateral, guided, and total variation filters, applied to images on general graphs may require repeated application if noise is not small enough. We formulate two acceleration techniques of the resulted iterations: conjugate gradient method and Nesterov's acceleration. We numerically show efficiency of the accelerated nonlinear filters for image denoising and demonstrate 2-12 times speed-up, i.e., the acceleration techniques reduce the number of iterations required to reach a given peak signal-to-noise ratio (PSNR) by the above indicated factor of 2-12. version:2
arxiv-1604-03924 | Max-Information, Differential Privacy, and Post-Selection Hypothesis Testing | http://arxiv.org/abs/1604.03924 | id:1604.03924 author:Ryan Rogers, Aaron Roth, Adam Smith, Om Thakkar category:cs.LG  published:2016-04-13 summary:In this paper, we initiate a principled study of how the generalization properties of approximate differential privacy can be used to perform adaptive hypothesis testing, while giving statistically valid $p$-value corrections. We do this by observing that the guarantees of algorithms with bounded approximate max-information are sufficient to correct the $p$-values of adaptively chosen hypotheses, and then by proving that algorithms that satisfy $(\epsilon,\delta)$-differential privacy have bounded approximate max information when their inputs are drawn from a product distribution. This substantially extends the known connection between differential privacy and max-information, which previously was only known to hold for (pure) $(\epsilon,0)$-differential privacy. It also extends our understanding of max-information as a partially unifying measure controlling the generalization properties of adaptive data analyses. We also show a lower bound, proving that (despite the strong composition properties of max-information), when data is drawn from a product distribution, $(\epsilon,\delta)$-differentially private algorithms can come first in a composition with other algorithms satisfying max-information bounds, but not necessarily second if the composition is required to itself satisfy a nontrivial max-information bound. This, in particular, implies that the connection between $(\epsilon,\delta)$-differential privacy and max-information holds only for inputs drawn from product distributions, unlike the connection between $(\epsilon,0)$-differential privacy and max-information. version:1
arxiv-1604-03915 | Removing Clouds and Recovering Ground Observations in Satellite Image Sequences via Temporally Contiguous Robust Matrix Completion | http://arxiv.org/abs/1604.03915 | id:1604.03915 author:Jialei Wang, Peder A. Olsen, Andrew R. Conn, Aurelie C. Lozano category:cs.CV cs.LG  published:2016-04-13 summary:We consider the problem of removing and replacing clouds in satellite image sequences, which has a wide range of applications in remote sensing. Our approach first detects and removes the cloud-contaminated part of the image sequences. It then recovers the missing scenes from the clean parts using the proposed "TECROMAC" (TEmporally Contiguous RObust MAtrix Completion) objective. The objective function balances temporal smoothness with a low rank solution while staying close to the original observations. The matrix whose the rows are pixels and columnsare days corresponding to the image, has low-rank because the pixels reflect land-types such as vegetation, roads and lakes and there are relatively few variations as a result. We provide efficient optimization algorithms for TECROMAC, so we can exploit images containing millions of pixels. Empirical results on real satellite image sequences, as well as simulated data, demonstrate that our approach is able to recover underlying images from heavily cloud-contaminated observations. version:1
arxiv-1604-03912 | Inverse Reinforcement Learning with Simultaneous Estimation of Rewards and Dynamics | http://arxiv.org/abs/1604.03912 | id:1604.03912 author:Michael Herman, Tobias Gindele, Jörg Wagner, Felix Schmitt, Wolfram Burgard category:cs.AI cs.LG cs.SY stat.ML  published:2016-04-13 summary:Inverse Reinforcement Learning (IRL) describes the problem of learning an unknown reward function of a Markov Decision Process (MDP) from observed behavior of an agent. Since the agent's behavior originates in its policy and MDP policies depend on both the stochastic system dynamics as well as the reward function, the solution of the inverse problem is significantly influenced by both. Current IRL approaches assume that if the transition model is unknown, additional samples from the system's dynamics are accessible, or the observed behavior provides enough samples of the system's dynamics to solve the inverse problem accurately. These assumptions are often not satisfied. To overcome this, we present a gradient-based IRL approach that simultaneously estimates the system's dynamics. By solving the combined optimization problem, our approach takes into account the bias of the demonstrations, which stems from the generating policy. The evaluation on a synthetic MDP and a transfer learning task shows improvements regarding the sample efficiency as well as the accuracy of the estimated reward functions and transition models. version:1
arxiv-1604-03901 | Single-Image Depth Perception in the Wild | http://arxiv.org/abs/1604.03901 | id:1604.03901 author:Weifeng Chen, Zhao Fu, Dawei Yang, Jia Deng category:cs.CV cs.AI  published:2016-04-13 summary:This paper studies single-image depth perception in the wild, i.e., recovering depth from a single image taken in unconstrained settings. We introduce a new dataset "Depth in the Wild" consisting of images in the wild annotated with relative depth between pairs of random points. We also propose a new algorithm that learns to estimate metric depth using annotations of relative depth. Compared to the state of the art, our algorithm is simpler and performs better. Experiments show that our algorithm, combined with existing RGB-D data and our new relative depth annotations, significantly improves single-image depth perception in the wild. version:1
arxiv-1512-01355 | Staple: Complementary Learners for Real-Time Tracking | http://arxiv.org/abs/1512.01355 | id:1512.01355 author:Luca Bertinetto, Jack Valmadre, Stuart Golodetz, Ondrej Miksik, Philip Torr category:cs.CV  published:2015-12-04 summary:Correlation Filter-based trackers have recently achieved excellent performance, showing great robustness to challenging situations exhibiting motion blur and illumination changes. However, since the model that they learn depends strongly on the spatial layout of the tracked object, they are notoriously sensitive to deformation. Models based on colour statistics have complementary traits: they cope well with variation in shape, but suffer when illumination is not consistent throughout a sequence. Moreover, colour distributions alone can be insufficiently discriminative. In this paper, we show that a simple tracker combining complementary cues in a ridge regression framework can operate faster than 80 FPS and outperform not only all entries in the popular VOT14 competition, but also recent and far more sophisticated trackers according to multiple benchmarks. version:2
arxiv-1604-03887 | Algorithms for stochastic optimization with expectation constraints | http://arxiv.org/abs/1604.03887 | id:1604.03887 author:Guanghui Lan, Zhiqiang Zhou category:math.OC stat.ML  published:2016-04-13 summary:This paper considers the problem of minimizing an expectation function over a closed convex set, coupled with functional constraints given in the form of expectation. We present a new stochastic approximation (SA) type algorithm, namely the alternating mirror-descent SA (AMD-SA) algorithm, to minimize these expectation constrained problems, and show that it exhibits the optimal rate of convergence when the objective and constraint functions are convex or strongly convex. We also present a variant of this algorithm to solve a special class of structured nonconvex problems and establish its rate of convergence. It is worth noting that all theses algorithms are primal methods which do not require the estimation of the dual variables. We also provide some promising preliminary numerical results for these algorithms applied to some portfolio optimization and machine learning problems. version:1
arxiv-1604-03882 | The Effect of Distortions on the Prediction of Visual Attention | http://arxiv.org/abs/1604.03882 | id:1604.03882 author:Milind S. Gide, Samuel F. Dodge, Lina J. Karam category:cs.CV  published:2016-04-13 summary:Existing saliency models have been designed and evaluated for predicting the saliency in distortion-free images. However, in practice, the image quality is affected by a host of factors at several stages of the image processing pipeline such as acquisition, compression and transmission. Several studies have explored the effect of distortion on human visual attention; however, none of them have considered the performance of visual saliency models in the presence of distortion. Furthermore, given that one potential application of visual saliency prediction is to aid pooling of objective visual quality metrics, it is important to compare the performance of existing saliency models on distorted images. In this paper, we evaluate several state-of-the-art visual attention models over different databases consisting of distorted images with various types of distortions such as blur, noise and compression with varying levels of distortion severity. This paper also introduces new improved performance evaluation metrics that are shown to overcome shortcomings in existing performance metrics. We find that the performance of most models improves with moderate and high levels of distortions as compared to the near distortion-free case. In addition, model performance is also found to decrease with an increase in image complexity. version:1
arxiv-1604-03880 | Detangling People: Individuating Multiple Close People and Their Body Parts via Region Assembly | http://arxiv.org/abs/1604.03880 | id:1604.03880 author:Hao Jiang, Kristen Grauman category:cs.CV  published:2016-04-13 summary:Today's person detection methods work best when people are in common upright poses and appear reasonably well spaced out in the image. However, in many real images, that's not what people do. People often appear quite close to each other, e.g., with limbs linked or heads touching, and their poses are often not pedestrian-like. We propose an approach to detangle people in multi-person images. We formulate the task as a region assembly problem. Starting from a large set of overlapping regions from body part semantic segmentation and generic object proposals, our optimization approach reassembles those pieces together into multiple person instances. It enforces that the composed body part regions of each person instance obey constraints on relative sizes, mutual spatial relationships, foreground coverage, and exclusive label assignments when overlapping. Since optimal region assembly is a challenging combinatorial problem, we present a Lagrangian relaxation method to accelerate the lower bound estimation, thereby enabling a fast branch and bound solution for the global optimum. As output, our method produces a pixel-level map indicating both 1) the body part labels (arm, leg, torso, and head), and 2) which parts belong to which individual person. Our results on three challenging datasets show our method is robust to clutter, occlusion, and complex poses. It outperforms a variety of competing methods, including existing detector CRF methods and region CNN approaches. In addition, we demonstrate its impact on a proxemics recognition task, which demands a precise representation of "whose body part is where" in crowded images. version:1
arxiv-1604-03832 | Reversible Image Merging for Low-level Machine Vision | http://arxiv.org/abs/1604.03832 | id:1604.03832 author:Mikhail Kharinov category:cs.CV  published:2016-04-13 summary:In this paper a hierarchical model for pixel clustering and image segmentation is developed. In the model an image is hierarchically structured. The original image is treated as a set of nested images, which are capable to reversibly merge with each other. An object is defined as a structural element of an image, so that, an image is regarded as a maximal object. The simulating of none-hierarchical optimal pixel clustering by hierarchical clustering is studied. To generate a hierarchy of optimized piecewise constant image approximations, estimated by the standard deviation of approximation from the image, the conversion of any hierarchy of approximations into the hierarchy described in relation to the number of intensity levels by convex sequence of total squared errors is proposed. version:1
arxiv-1604-03829 | Animation and Chirplet-Based Development of a PIR Sensor Array for Intruder Classification in an Outdoor Environment | http://arxiv.org/abs/1604.03829 | id:1604.03829 author:Raviteja Upadrashta, Tarun Choubisa, A. Praneeth, Tony G., Aswath V. S., P. Vijay Kumar, Sripad Kowshik, Hari Prasad Gokul R, T. V. Prabhakar category:cs.LG  published:2016-04-13 summary:This paper presents the development of a passive infra-red sensor tower platform along with a classification algorithm to distinguish between human intrusion, animal intrusion and clutter arising from wind-blown vegetative movement in an outdoor environment. The research was aimed at exploring the potential use of wireless sensor networks as an early-warning system to help mitigate human-wildlife conflicts occurring at the edge of a forest. There are three important features to the development. Firstly, the sensor platform employs multiple sensors arranged in the form of a two-dimensional array to give it a key spatial-resolution capability that aids in classification. Secondly, given the challenges of collecting data involving animal intrusion, an Animation-based Simulation tool for Passive Infra-Red sEnsor (ASPIRE) was developed that simulates signals corresponding to human and animal intrusion and some limited models of vegetative clutter. This speeded up the process of algorithm development by allowing us to test different hypotheses in a time-efficient manner. Finally, a chirplet-based model for intruder signal was developed that significantly helped boost classification accuracy despite drawing data from a smaller number of sensors. An SVM-based classifier was used which made use of chirplet, energy and signal cross-correlation-based features. The average accuracy obtained for intruder detection and classification on real-world and simulated data sets was in excess of 97%. version:1
arxiv-1512-00486 | Loss Functions for Top-k Error: Analysis and Insights | http://arxiv.org/abs/1512.00486 | id:1512.00486 author:Maksim Lapin, Matthias Hein, Bernt Schiele category:stat.ML cs.CV cs.LG  published:2015-12-01 summary:In order to push the performance on realistic computer vision tasks, the number of classes in modern benchmark datasets has significantly increased in recent years. This increase in the number of classes comes along with increased ambiguity between the class labels, raising the question if top-1 error is the right performance measure. In this paper, we provide an extensive comparison and evaluation of established multiclass methods comparing their top-k performance both from a practical as well as from a theoretical perspective. Moreover, we introduce novel top-k loss functions as modifications of the softmax and the multiclass SVM losses and provide efficient optimization schemes for them. In the experiments, we compare on various datasets all of the proposed and established methods for top-k error optimization. An interesting insight of this paper is that the softmax loss yields competitive top-k performance for all k simultaneously. For a specific top-k error, our new top-k losses lead typically to further improvements while being faster to train than the softmax. version:2
arxiv-1510-00850 | Spectral Clustering over the Logistic Random Dot Product Graph | http://arxiv.org/abs/1510.00850 | id:1510.00850 author:Luke O'Connor, Muriel Médard, Soheil Feizi category:stat.ML  published:2015-10-03 summary:Inference of clusters over networks is a central problem in machine learning. Commonly, it is formulated as a discrete optimization, and a continuous relaxation is used to obtain a spectral algorithm. An alternative problem formulation arises by considering a latent space model, in which edge probabilities are determined by continuous latent positions. A model of particular interest is the Random Dot Product Graph (RDPG), which can be fit using an efficient spectral method; however, this method is based on a heuristic that can fail, even in simple cases. In this paper, we consider a closely related latent space model, the Logistic RDPG, which uses a logistic link function to map from latent position inner products to edge likelihoods. Over this model, we show that asymptotically exact maximum likelihood inference of the latent position vectors can be achieved using a spectral method. Our method involves computing the top eigenvectors of a normalized adjacency matrix and scaling the eigenvectors using a regression step. Through simulations, we show that this method is more accurate and more robust than existing spectral and semidefinite network clustering methods. In particular, the novel regression scaling step is essential to the performance gain of the proposed method. version:2
arxiv-1604-03763 | A General Distributed Dual Coordinate Optimization Framework for Regularized Loss Minimization | http://arxiv.org/abs/1604.03763 | id:1604.03763 author:Shun Zheng, Fen Xia, Wei Xu, Tong Zhang category:cs.LG cs.DC  published:2016-04-13 summary:In modern large-scale machine learning applications, the training data are often partitioned and stored on multiple machines. It is customary to employ the "data parallelism" approach, where the aggregated training loss is minimized without moving data across machines. In this paper, we introduce a novel distributed dual formulation for regularized loss minimization problems that can directly handle data parallelism under the distributed computing environment. This formulation allows us to systematically derive dual coordinate optimization procedures, which we refer to as Distributed Alternating Dual Maximization (DADM). The method extends earlier studies about distributed SDCA algorithms and has a rigorous theoretical analysis. Based on the new formulation, we also develop an accelerated DADM algorithm by generalizing the acceleration technique from the accelerated SDCA algorithm to the distributed setting. Our empirical studies show that our novel approach significantly improves the previous state-of-the-art distributed dual coordinate optimization algorithms. version:1
arxiv-1604-03755 | VConv-DAE: Deep Volumetric Shape Learning Without Object Labels | http://arxiv.org/abs/1604.03755 | id:1604.03755 author:Abhishek Sharma, Oliver Grau, Mario Fritz category:cs.CV cs.GR  published:2016-04-13 summary:With the advent of affordable depth sensors, 3D capture becomes more and more ubiquitous and already has made its way into commercial products. Yet, capturing the geometry or complete shapes of everyday objects using scanning devices (eg. Kinect) still comes with several challenges that result in noise or even incomplete shapes. Recent success in deep learning has shown how to learn complex shape distributions in a data-driven way from large scale 3D CAD Model collections and to utilize them for 3D processing on volumetric representations and thereby circumventing problems of topology and tessellation. Prior work has shown encouraging results on problems ranging from shape completion to recognition. We provide an analysis of such approaches and discover that training as well as the resulting representation are strongly and unnecessarily tied to the notion of object labels. Furthermore, deep learning research argues ~\cite{Vincent08} that learning representation with over-complete model are more prone to overfitting compared to the approach that learns from noisy data. Thus, we investigate a full convolutional volumetric denoising auto encoder that is trained in a unsupervised fashion. It outperforms prior work on recognition as well as more challenging tasks like denoising and shape completion. In addition, our approach is atleast two order of magnitude faster at test time and thus, provides a path to scaling up 3D deep learning. version:1
arxiv-1604-03744 | Variational Bayesian Inference of Line Spectra | http://arxiv.org/abs/1604.03744 | id:1604.03744 author:Mihai-Alin Badiu, Thomas Lundgaard Hansen, Bernard Henri Fleury category:cs.IT math.IT stat.ML  published:2016-04-13 summary:In this paper, we address the fundamental problem of line spectral estimation in a Bayesian framework. We target model order and parameter estimation via variational inference in a probabilistic model in which the frequencies are continuous-valued, i.e., not restricted to a grid; and the coefficients are governed by a Bernoulli-Gaussian prior model turning model order selection into binary sequence detection. Unlike earlier works which retain only point estimates of the frequencies, we undertake a more complete Bayesian treatment by estimating the posterior probability density functions (pdfs) of the frequencies and computing expectations over them. Thus, we additionally capture and operate with the uncertainty of the frequency estimates. Aiming to maximize the model evidence, variational optimization provides analytic approximations of the posterior pdfs and also gives estimates of the additional parameters. We propose an accurate representation of the pdfs of the frequencies by mixtures of von Mises pdfs, which yields closed-form expectations. We define the algorithm VALSE in which the estimates of the pdfs and parameters are iteratively updated. VALSE is a gridless, convergent method, does not require parameter tuning, can easily include prior knowledge about the frequencies and provides approximate posterior pdfs based on which the uncertainty in line spectral estimation can be quantified. Simulation results show that accounting for the uncertainty of frequency estimates, rather than computing just point estimates, significantly improves the performance. The performance of VALSE is superior to that of state-of-the-art methods and closely approaches the Cram\'er-Rao bound computed for the true model order. version:1
arxiv-1604-03736 | A Differentiable Transition Between Additive and Multiplicative Neurons | http://arxiv.org/abs/1604.03736 | id:1604.03736 author:Wiebke Köpp, Patrick van der Smagt, Sebastian Urban category:cs.LG stat.ML  published:2016-04-13 summary:Existing approaches to combine both additive and multiplicative neural units either use a fixed assignment of operations or require discrete optimization to determine what function a neuron should perform. However, this leads to an extensive increase in the computational complexity of the training procedure. We present a novel, parameterizable transfer function based on the mathematical concept of non-integer functional iteration that allows the operation each neuron performs to be smoothly and, most importantly, differentiablely adjusted between addition and multiplication. This allows the decision between addition and multiplication to be integrated into the standard backpropagation training procedure. version:1
arxiv-1604-03734 | DENSER Cities: A System for Dense Efficient Reconstructions of Cities | http://arxiv.org/abs/1604.03734 | id:1604.03734 author:Michael Tanner, Pedro Pinies, Lina Maria Paz, Paul Newman category:cs.CV cs.RO  published:2016-04-13 summary:This paper is about the efficient generation of dense, colored models of city-scale environments from range data and in particular, stereo cameras. Better maps make for better understanding; better understanding leads to better robots, but this comes at a cost. The computational and memory requirements of large dense models can be prohibitive. We provide the theory and the system needed to create city-scale dense reconstructions. To do so, we apply a regularizer over a compressed 3D data structure while dealing with the complex boundary conditions this induces during the data-fusion stage. We show that only with these considerations can we swiftly create neat, large, "well behaved" reconstructions. We evaluate our system using the KITTI dataset and provide statistics for the metric errors in all surfaces created compared to those measured with 3D laser. Our regularizer reduces the median error by 40% in 3.4 km of dense reconstructions with a median accuracy of 6 cm. For subjective analysis, we provide a qualitative review of 6.1 km of our dense reconstructions in an attached video. These are the largest dense reconstructions from a single passive camera we are aware of in the literature. version:1
arxiv-1604-08426 | A Novel Method to Study Bottom-up Visual Saliency and its Neural Mechanism | http://arxiv.org/abs/1604.08426 | id:1604.08426 author:Cheng Chen, Xilin Zhang, Yizhou Wang, Fang Fang category:cs.CV q-bio.NC  published:2016-04-13 summary:In this study, we propose a novel method to measure bottom-up saliency maps of natural images. In order to eliminate the influence of top-down signals, backward masking is used to make stimuli (natural images) subjectively invisible to subjects, however, the bottom-up saliency can still orient the subjects attention. To measure this orientation/attention effect, we adopt the cueing effect paradigm by deploying discrimination tasks at each location of an image, and measure the discrimination performance variation across the image as the attentional effect of the bottom-up saliency. Such attentional effects are combined to construct a final bottomup saliency map. Based on the proposed method, we introduce a new bottom-up saliency map dataset of natural images to benchmark computational models. We compare several state-of-the-art saliency models on the dataset. Moreover, the proposed paradigm is applied to investigate the neural basis of the bottom-up visual saliency map by analyzing psychophysical and fMRI experimental results. Our findings suggest that the bottom-up saliency maps of natural images are constructed in V1. It provides a strong scientific evidence to resolve the long standing dispute in neuroscience about where the bottom-up saliency map is constructed in human brain. version:1
arxiv-1501-03659 | Quantifying uncertainties on excursion sets under a Gaussian random field prior | http://arxiv.org/abs/1501.03659 | id:1501.03659 author:Dario Azzimonti, Julien Bect, Clément Chevalier, David Ginsbourger category:math.ST stat.CO stat.ML stat.TH  published:2015-01-15 summary:We focus on the problem of estimating and quantifying uncertainties on the excursion set of a function under a limited evaluation budget. We adopt a Bayesian approach where the objective function is assumed to be a realization of a Gaussian random field. In this setting, the posterior distribution on the objective function gives rise to a posterior distribution on excursion sets. Several approaches exist to summarize the distribution of such sets based on random closed set theory. While the recently proposed Vorob'ev approach exploits analytical formulae, further notions of variability require Monte Carlo estimators relying on Gaussian random field conditional simulations. In the present work we propose a method to choose Monte Carlo simulation points and obtain quasi-realizations of the conditional field at fine designs through affine predictors. The points are chosen optimally in the sense that they minimize the posterior expected distance in measure between the excursion set and its reconstruction. The proposed method reduces the computational costs due to Monte Carlo simulations and enables the computation of quasi-realizations on fine designs in large dimensions. We apply this reconstruction approach to obtain realizations of an excursion set on a fine grid which allow us to give a new measure of uncertainty based on the distance transform of the excursion set. Finally we present a safety engineering test case where the simulation method is employed to compute a Monte Carlo estimate of a contour line. version:2
arxiv-1603-09272 | Bayesian inference in hierarchical models by combining independent posteriors | http://arxiv.org/abs/1603.09272 | id:1603.09272 author:Ritabrata Dutta, Paul Blomstedt, Samuel Kaski category:stat.CO stat.ME stat.ML  published:2016-03-30 summary:Hierarchical models are versatile tools for joint modeling of data sets arising from different, but related, sources. Fully Bayesian inference may, however, become computationally prohibitive if the source-specific data models are complex, or if the number of sources is very large. To facilitate computation, we propose an approach, where inference is first made independently for the parameters of each data set, whereupon the obtained posterior samples are used as observed data in a substitute hierarchical model, based on a scaled likelihood function. Compared to direct inference in a full hierarchical model, the approach has the advantage of being able to speed up convergence by breaking down the initial large inference problem into smaller individual subproblems with better convergence properties. Moreover it enables parallel processing of the possibly complex inferences of the source-specific parameters, which may otherwise create a computational bottleneck if processed jointly as part of a hierarchical model. The approach is illustrated with both simulated and real data. version:2
arxiv-1604-00999 | RGBD Datasets: Past, Present and Future | http://arxiv.org/abs/1604.00999 | id:1604.00999 author:Michael Firman category:cs.CV cs.RO  published:2016-04-04 summary:Since the launch of the Microsoft Kinect, scores of RGBD datasets have been released. These have propelled advances in areas from reconstruction to gesture recognition. In this paper we explore the field, reviewing datasets across eight categories: semantics, object pose estimation, camera tracking, scene reconstruction, object tracking, human actions, faces and identification. By extracting relevant information in each category we help researchers to find appropriate data for their needs, and we consider which datasets have succeeded in driving computer vision forward and why. Finally, we examine the future of RGBD datasets. We identify key areas which are currently underexplored, and suggest that future directions may include synthetic data and dense reconstructions of static and dynamic scenes. version:2
arxiv-1604-03650 | Deep3D: Fully Automatic 2D-to-3D Video Conversion with Deep Convolutional Neural Networks | http://arxiv.org/abs/1604.03650 | id:1604.03650 author:Junyuan Xie, Ross Girshick, Ali Farhadi category:cs.CV  published:2016-04-13 summary:As 3D movie viewing becomes mainstream and Virtual Reality (VR) market emerges, the demand for 3D contents is growing rapidly. Producing 3D videos, however, remains challenging. In this paper we propose to use deep neural networks for automatically converting 2D videos and images to stereoscopic 3D format. In contrast to previous automatic 2D-to-3D conversion algorithms, which have separate stages and need ground truth depth map as supervision, our approach is trained end-to-end directly on stereo pairs extracted from 3D movies. This novel training scheme makes it possible to exploit orders of magnitude more data and significantly increases performance. Indeed, Deep3D outperforms baselines in both quantitative and human subject evaluations. version:1
arxiv-1604-03058 | High Performance Binarized Neural Networks trained on the ImageNet Classification Task | http://arxiv.org/abs/1604.03058 | id:1604.03058 author:Xundong Wu category:cs.CV cs.LG cs.NE  published:2016-04-11 summary:We trained Binarized Neural Networks (BNNs) on the high resolution ImageNet LSVRC-2102 dataset classification task and achieved a good performance. With a moderate size network of 10 layers, we obtained top-5 classification accuracy rate of 81 percent on validation set which is much better than previous published results. We expect training networks of a much better performance through increase network depth would be straight forward by following our current strategies. A detailed discussion on strategies used in the network training is included as well as preliminary analysis. version:2
arxiv-1604-03640 | Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex | http://arxiv.org/abs/1604.03640 | id:1604.03640 author:Qianli Liao, Tomaso Poggio category:cs.LG cs.NE  published:2016-04-13 summary:We discuss relations between Residual Networks (ResNet), Recurrent Neural Networks (RNNs) and the primate visual cortex. We begin with the observation that a shallow RNN is exactly equivalent to a very deep ResNet with weight sharing among the layers. A direct implementation of such a RNN, although having orders of magnitude fewer parameters, leads to a performance similar to the corresponding ResNet. We propose 1) a generalization of both RNN and ResNet architectures and 2) the conjecture that a class of moderately deep RNNs is a biologically-plausible model of the ventral stream in visual cortex. We demonstrate the effectiveness of the architectures by testing them on the CIFAR-10 dataset. version:1
