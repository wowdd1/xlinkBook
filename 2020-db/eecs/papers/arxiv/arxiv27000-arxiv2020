arxiv-1703-10701 | Concurrent Segmentation and Localization for Tracking of Surgical Instruments | http://arxiv.org/abs/1703.10701 | id:1703.10701 author:Iro Laina, Nicola Rieke, Christian Rupprecht, Josué Page Vizcaíno, Abouzar Eslami, Federico Tombari, Nassir Navab category:cs.CV  published:2017-03-30 summary:Instrument tracking is an essential requirement for various computer-assisted interventions. To overcome problems such as specular reflection and motion blur, we propose a novel method that takes advantage of the interdependency between localization and segmentation of the tool. In particular, we reformulate the 2D pose estimation as a heatmap regression and thereby enable a robust, concurrent regression of both tasks. Throughout experimental results, we demonstrate that this modeling leads to a significantly higher accuracy than directly regressing the tool's coordinates. The performance is compared to state-of-the-art on a Retinal Microsurgery benchmark and the EndoVis Challenge. version:1
arxiv-1703-10698 | Neutral evolution and turnover over centuries of English word popularity | http://arxiv.org/abs/1703.10698 | id:1703.10698 author:Damian Ruck, R. Alexander Bentley, Alberto Acerbi, Philip Garnett, Daniel J. Hruschka category:cs.CL physics.soc-ph  published:2017-03-30 summary:Here we test Neutral models against the evolution of English word frequency and vocabulary at the population scale, as recorded in annual word frequencies from three centuries of English language books. Against these data, we test both static and dynamic predictions of two neutral models, including the relation between corpus size and vocabulary size, frequency distributions, and turnover within those frequency distributions. Although a commonly used Neutral model fails to replicate all these emergent properties at once, we find that modified two-stage Neutral model does replicate the static and dynamic properties of the corpus data. This two-stage model is meant to represent a relatively small corpus (population) of English books, analogous to a `canon', sampled by an exponentially increasing corpus of books in the wider population of authors. More broadly, this mode -- a smaller neutral model within a larger neutral model -- could represent more broadly those situations where mass attention is focused on a small subset of the cultural variants. version:1
arxiv-1703-10667 | TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition | http://arxiv.org/abs/1703.10667 | id:1703.10667 author:Chih-Yao Ma, Min-Hung Chen, Zsolt Kira, Ghassan AlRegib category:cs.CV  published:2017-03-30 summary:Recent two-stream deep Convolutional Neural Networks (ConvNets) have made significant progress in recognizing human actions in videos. Despite their success, methods extending the basic two-stream ConvNet have not systematically explored possible network architectures to further exploit spatiotemporal dynamics within video sequences. Further, such networks often use different baseline two-stream networks. Therefore, the differences and the distinguishing factors between various methods using Recurrent Neural Networks (RNN) or convolutional networks on temporally-constructed feature vectors (Temporal-ConvNet) are unclear. In this work, we first demonstrate a strong baseline two-stream ConvNet using ResNet-101. We use this baseline to thoroughly examine the use of both RNNs and Temporal-ConvNets for extracting spatiotemporal information. Building upon our experimental results, we then propose and investigate two different networks to further integrate spatiotemporal information: 1) temporal segment RNN and 2) Inception-style Temporal-ConvNet. We demonstrate that using both RNNs (using LSTMs) and Temporal-ConvNets on spatiotemporal feature matrices are able to exploit spatiotemporal dynamics to improve the overall performance. However, each of these methods require proper care to achieve state-of-the-art performance; for example, LSTMs require pre-segmented data or else they cannot fully exploit temporal information. Our analysis identifies specific limitations for each method that could form the basis of future work. Our experimental results on UCF101 and HMDB51 datasets achieve state-of-the-art performances, 94.1% and 69.0%, respectively, without requiring extensive temporal augmentation. version:1
arxiv-1703-10663 | Near Perfect Protein Multi-Label Classification with Deep Neural Networks | http://arxiv.org/abs/1703.10663 | id:1703.10663 author:Balazs Szalkai, Vince Grolmusz category:q-bio.BM cs.LG stat.ML  published:2017-03-30 summary:Artificial neural networks (ANNs) have gained a well-deserved popularity among machine learning tools upon their recent successful applications in image- and sound processing and classification problems. ANNs have also been applied for predicting the family or function of a protein, knowing its residue sequence. Here we present two new ANNs with multi-label classification ability, showing impressive accuracy when classifying protein sequences into 698 UniProt families (AUC=99.99%) and 983 Gene Ontology classes (AUC=99.45%). version:1
arxiv-1703-10660 | Towards a Visual Privacy Advisor: Understanding and Predicting Privacy Risks in Images | http://arxiv.org/abs/1703.10660 | id:1703.10660 author:Tribhuvanesh Orekondy, Bernt Schiele, Mario Fritz category:cs.CV cs.CR cs.CY cs.SI  published:2017-03-30 summary:With an increasing number of users sharing information online, privacy implications entailing such actions are a major concern. For explicit content, such as user profile or GPS data, devices (e.g. mobile phones) as well as web services (e.g. Facebook) offer to set privacy settings in order to enforce the users' privacy preferences. We propose the first approach that extends this concept to image content in the spirit of a Visual Privacy Advisor. First, we categorize personal information in images into 68 image attributes and collect a dataset, which allows us to train models that predict such information directly from images. Second, we run a user study to understand the privacy preferences of different users w.r.t. such attributes. Third, we propose models that predict user specific privacy score from images in order to enforce the users' privacy preferences. Our model is trained to predict the user specific privacy risk and even outperforms the judgment of the users, who often fail to follow their own privacy preferences on image data. version:1
arxiv-1703-10651 | What-If Reasoning with Counterfactual Gaussian Processes | http://arxiv.org/abs/1703.10651 | id:1703.10651 author:Peter Schulam, Suchi Saria category:stat.ML cs.AI cs.LG  published:2017-03-30 summary:Answering "What if?" questions is important in many domains. For example, would a patient's disease progression slow down if I were to give them a dose of drug A? Ideally, we answer our question using an experiment, but this is not always possible (e.g., it may be unethical). As an alternative, we can use non-experimental data to learn models that make counterfactual predictions of what we would observe had we run an experiment. In this paper, we propose a model to make counterfactual predictions about how continuous-time trajectories (time series) respond to sequences of actions taken in continuous-time. We develop our model within the potential outcomes framework of Neyman and Rubin. One challenge is that the assumptions commonly made to learn potential outcome (counterfactual) models from observational data are not applicable in continuous-time as-is. We therefore propose a model using marked point processes and Gaussian processes, and develop alternative assumptions that allow us to learn counterfactual models from continuous-time observational data. We evaluate our approach on two tasks from health care: disease trajectory prediction and personalized treatment planning. version:1
arxiv-1703-10645 | Relevance Subject Machine: A Novel Person Re-identification Framework | http://arxiv.org/abs/1703.10645 | id:1703.10645 author:Igor Fedorov, Ritwik Giri, Bhaskar D. Rao, Truong Q. Nguyen category:cs.CV  published:2017-03-30 summary:We propose a novel method called the Relevance Subject Machine (RSM) to solve the person re-identification (re-id) problem. RSM falls under the category of Bayesian sparse recovery algorithms and uses the sparse representation of the input video under a pre-defined dictionary to identify the subject in the video. Our approach focuses on the multi-shot re-id problem, which is the prevalent problem in many video analytics applications. RSM captures the essence of the multi-shot re-id problem by constraining the support of the sparse codes for each input video frame to be the same. Our proposed approach is also robust enough to deal with time varying outliers and occlusions by introducing a sparse, non-stationary noise term in the model error. We provide a novel Variational Bayesian based inference procedure along with an intuitive interpretation of the proposed update rules. We evaluate our approach over several commonly used re-id datasets and show superior performance over current state-of-the-art algorithms. Specifically, for ILIDS-VID, a recent large scale re-id dataset, RSM shows significant improvement over all published approaches, achieving an 11.5% (absolute) improvement in rank 1 accuracy over the closest competing algorithm considered. version:1
arxiv-1703-10642 | Deep Neural Network Optimized to Resistive Memory with Nonlinear Current-Voltage Characteristics | http://arxiv.org/abs/1703.10642 | id:1703.10642 author:Hyungjun Kim, Taesu Kim, Jinseok Kim, Jae-Joon Kim category:cs.ET cs.NE  published:2017-03-30 summary:Artificial Neural Network computation relies on intensive vector-matrix multiplications. Recently, the emerging nonvolatile memory (NVM) crossbar array showed a feasibility of implementing such operations with high energy efficiency, thus there are many works on efficiently utilizing emerging NVM crossbar array as analog vector-matrix multiplier. However, its nonlinear I-V characteristics restrain critical design parameters, such as the read voltage and weight range, resulting in substantial accuracy loss. In this paper, instead of optimizing hardware parameters to a given neural network, we propose a methodology of reconstructing a neural network itself optimized to resistive memory crossbar arrays. To verify the validity of the proposed method, we simulated various neural network with MNIST and CIFAR-10 dataset using two different specific Resistive Random Access Memory (RRAM) model. Simulation results show that our proposed neural network produces significantly higher inference accuracies than conventional neural network when the synapse devices have nonlinear I-V characteristics. version:1
arxiv-1703-10631 | Interpretable Learning for Self-Driving Cars by Visualizing Causal Attention | http://arxiv.org/abs/1703.10631 | id:1703.10631 author:Jinkyu Kim, John Canny category:cs.CV cs.LG  published:2017-03-30 summary:Deep neural perception and control networks are likely to be a key component of self-driving vehicles. These models need to be explainable - they should provide easy-to-interpret rationales for their behavior - so that passengers, insurance companies, law enforcement, developers etc., can understand what triggered a particular behavior. Here we explore the use of visual explanations. These explanations take the form of real-time highlighted regions of an image that causally influence the network's output (steering control). Our approach is two-stage. In the first stage, we use a visual attention model to train a convolution network end-to-end from images to steering angle. The attention model highlights image regions that potentially influence the network's output. Some of these are true influences, but some are spurious. We then apply a causal filtering step to determine which input regions actually influence the output. This produces more succinct visual explanations and more accurately exposes the network's behavior. We demonstrate the effectiveness of our model on three datasets totaling 16 hours of driving. We first show that training with attention does not degrade the performance of the end-to-end network. Then we show that the network causally cues on a variety of features that are used by humans while driving. version:1
arxiv-1703-10622 | Diving into the shallows: a computational perspective on large-scale shallow learning | http://arxiv.org/abs/1703.10622 | id:1703.10622 author:Siyuan Ma, Mikhail Belkin category:stat.ML cs.LG  published:2017-03-30 summary:Remarkable success of deep neural networks has not been easy to analyze theoretically. It has been particularly hard to disentangle relative significance of architecture and optimization in achieving accurate classification on large datasets. On the flip side, shallow methods have encountered obstacles in scaling to large data, despite excellent performance on smaller datasets, and extensive theoretical analysis. Practical methods, such as variants of gradient descent used so successfully in deep learning, seem to perform below par when applied to kernel methods. This difficulty has sometimes been attributed to the limitations of shallow architecture. In this paper we identify a basic limitation in gradient descent-based optimization in conjunctions with smooth kernels. An analysis demonstrates that only a vanishingly small fraction of the function space is reachable after a fixed number of iterations drastically limiting its power and resulting in severe over-regularization. The issue is purely algorithmic, persisting even in the limit of infinite data. To address this issue, we introduce EigenPro iteration, based on a simple preconditioning scheme using a small number of approximately computed eigenvectors. It turns out that even this small amount of approximate second-order information results in significant improvement of performance for large-scale kernel methods. Using EigenPro in conjunction with stochastic gradient descent we demonstrate scalable state-of-the-art results for kernel methods on a modest computational budget. Finally, these results indicate a need for a broader computational perspective on modern large-scale learning to complement more traditional statistical and convergence analyses. In particular, systematic analysis concentrating on the approximation power of algorithms with a fixed computation budget will lead to progress both in theory and practice. version:1
arxiv-1703-10603 | Atomic Convolutional Networks for Predicting Protein-Ligand Binding Affinity | http://arxiv.org/abs/1703.10603 | id:1703.10603 author:Joseph Gomes, Bharath Ramsundar, Evan N. Feinberg, Vijay S. Pande category:cs.LG physics.chem-ph stat.ML  published:2017-03-30 summary:Empirical scoring functions based on either molecular force fields or cheminformatics descriptors are widely used, in conjunction with molecular docking, during the early stages of drug discovery to predict potency and binding affinity of a drug-like molecule to a given target. These models require expert-level knowledge of physical chemistry and biology to be encoded as hand-tuned parameters or features rather than allowing the underlying model to select features in a data-driven procedure. Here, we develop a general 3-dimensional spatial convolution operation for learning atomic-level chemical interactions directly from atomic coordinates and demonstrate its application to structure-based bioactivity prediction. The atomic convolutional neural network is trained to predict the experimentally determined binding affinity of a protein-ligand complex by direct calculation of the energy associated with the complex, protein, and ligand given the crystal structure of the binding pose. Non-covalent interactions present in the complex that are absent in the protein-ligand sub-structures are identified and the model learns the interaction strength associated with these features. We test our model by predicting the binding free energy of a subset of protein-ligand complexes found in the PDBBind dataset and compare with state-of-the-art cheminformatics and machine learning-based approaches. We find that all methods achieve experimental accuracy and that atomic convolutional networks either outperform or perform competitively with the cheminformatics based methods. Unlike all previous protein-ligand prediction systems, atomic convolutional networks are end-to-end and fully-differentiable. They represent a new data-driven, physics-based deep learning model paradigm that offers a strong foundation for future improvements in structure-based bioactivity prediction. version:1
arxiv-1703-10593 | Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks | http://arxiv.org/abs/1703.10593 | id:1703.10593 author:Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros category:cs.CV  published:2017-03-30 summary:Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain $X$ to a target domain $Y$ in the absence of paired examples. Our goal is to learn a mapping $G: X \rightarrow Y$ such that the distribution of images from $G(X)$ is indistinguishable from the distribution $Y$ using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping $F: Y \rightarrow X$ and introduce a cycle consistency loss to push $F(G(X)) \approx X$ (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach. version:1
arxiv-1703-10584 | Geometric Affordances from a Single Example via the Interaction Tensor | http://arxiv.org/abs/1703.10584 | id:1703.10584 author:Eduardo Ruiz, Walterio Mayol-Cuevas category:cs.CV  published:2017-03-30 summary:This paper develops and evaluates a new tensor field representation to express the geometric affordance of one object over another. We expand the well known bisector surface representation to one that is weight-driven and that retains the provenance of surface points with directional vectors. We also incorporate the notion of affordance keypoints which allow for faster decisions at a point of query and with a compact and straightforward descriptor. Using a single interaction example, we are able to generalize to previously-unseen scenarios; both synthetic and also real scenes captured with RGBD sensors. We show how our interaction tensor allows for significantly better performance over alternative formulations. Evaluations also include crowdsourcing comparisons that confirm the validity of our affordance proposals, which agree on average 84% of the time with human judgments, and which is 20-40% better than the baseline methods. version:1
arxiv-1703-10580 | MoFA: Model-based Deep Convolutional Face Autoencoder for Unsupervised Monocular Reconstruction | http://arxiv.org/abs/1703.10580 | id:1703.10580 author:Ayush Tewari, Michael Zollhöfer, Hyeongwoo Kim, Pablo Garrido, Florian Bernard, Patrick Pérez, Christian Theobalt category:cs.CV  published:2017-03-30 summary:In this work we propose a novel model-based deep convolutional autoencoder that addresses the highly challenging problem of reconstructing a 3D human face from a single in-the-wild color image. To this end, we combine a convolutional encoder network with an expert-designed generative model that serves as decoder. The core innovation is our new differentiable parametric decoder that encapsulates image formation analytically based on a generative model. Our decoder takes as input a code vector with exactly defined semantic meaning that encodes detailed face pose, shape, expression, skin reflectance and scene illumination. Due to this new way of combining CNN-based with model-based face reconstruction, the CNN-based encoder learns to extract semantically meaningful parameters from a single monocular input image. For the first time, a CNN encoder and an expert-designed generative model can be trained end-to-end in an unsupervised manner, which renders training on very large (unlabeled) real world data feasible. The obtained reconstructions compare favorably to current state-of-the-art approaches in terms of quality and richness of representation. version:1
arxiv-1703-10571 | Bootstrapping Labelled Dataset Construction for Cow Tracking and Behavior Analysis | http://arxiv.org/abs/1703.10571 | id:1703.10571 author:Aram Ter-Sarkisov, Robert Ross, John Kelleher category:cs.CV cs.AI cs.LG  published:2017-03-30 summary:This paper introduces a new approach to the long-term tracking of an object in a challenging environment. The object is a cow and the environment is an enclosure in a cowshed. Some of the key challenges in this domain are a cluttered background, low contrast and high similarity between moving objects which greatly reduces the efficiency of most existing approaches, including those based on background subtraction. Our approach is split into object localization, instance segmentation, learning and tracking stages. Our solution is compared to a range of semi-supervised object tracking algorithms and we show that the performance is strong and well suited to subsequent analysis. We present our solution as a first step towards broader tracking and behavior monitoring for cows in precision agriculture with the ultimate objective of early detection of lameness. version:1
arxiv-1703-10553 | Learning Convolutional Networks for Content-weighted Image Compression | http://arxiv.org/abs/1703.10553 | id:1703.10553 author:Mu Li, Wangmeng Zuo, Shuhang Gu, Debin Zhao, David Zhang category:cs.CV  published:2017-03-30 summary:Lossy image compression is generally formulated as a joint rate-distortion optimization to learn encoder, quantizer, and decoder. However, the quantizer is non-differentiable, and discrete entropy estimation usually is required for rate control. These make it very challenging to develop a convolutional network (CNN)-based image compression system. In this paper, motivated by that the local information content is spatially variant in an image, we suggest that the bit rate of the different parts of the image should be adapted to local content. And the content aware bit rate is allocated under the guidance of a content-weighted importance map. Thus, the sum of the importance map can serve as a continuous alternative of discrete entropy estimation to control compression rate. And binarizer is adopted to quantize the output of encoder due to the binarization scheme is also directly defined by the importance map. Furthermore, a proxy function is introduced for binary operation in backward propagation to make it differentiable. Therefore, the encoder, decoder, binarizer and importance map can be jointly optimized in an end-to-end manner by using a subset of the ImageNet database. In low bit rate image compression, experiments show that our system significantly outperforms JPEG and JPEG 2000 by structural similarity (SSIM) index, and can produce the much better visual result with sharp edges, rich textures, and fewer artifacts. version:1
arxiv-1703-10545 | FairJudge: Trustworthy User Prediction in Rating Platforms | http://arxiv.org/abs/1703.10545 | id:1703.10545 author:Srijan Kumar, Bryan Hooi, Disha Makhija, Mohit Kumar, Christos Faloutsos, V. S. Subrahamanian category:cs.SI cs.AI stat.ML  published:2017-03-30 summary:Rating platforms enable large-scale collection of user opinion about items (products, other users, etc.). However, many untrustworthy users give fraudulent ratings for excessive monetary gains. In the paper, we present FairJudge, a system to identify such fraudulent users. We propose three metrics: (i) the fairness of a user that quantifies how trustworthy the user is in rating the products, (ii) the reliability of a rating that measures how reliable the rating is, and (iii) the goodness of a product that measures the quality of the product. Intuitively, a user is fair if it provides reliable ratings that are close to the goodness of the product. We formulate a mutually recursive definition of these metrics, and further address cold start problems and incorporate behavioral properties of users and products in the formulation. We propose an iterative algorithm, FairJudge, to predict the values of the three metrics. We prove that FairJudge is guaranteed to converge in a bounded number of iterations, with linear time complexity. By conducting five different experiments on five rating platforms, we show that FairJudge significantly outperforms nine existing algorithms in predicting fair and unfair users. We reported the 100 most unfair users in the Flipkart network to their review fraud investigators, and 80 users were correctly identified (80% accuracy). The FairJudge algorithm is already being deployed at Flipkart. version:1
arxiv-1703-10534 | The Informativeness of k-Means for Learning Gaussian Mixture Models | http://arxiv.org/abs/1703.10534 | id:1703.10534 author:Zhaoqiang Liu, Vincent Y. F. Tan category:stat.ML cs.IT cs.LG math.IT stat.ME  published:2017-03-30 summary:The learning of Gaussian mixture models (GMMs) is a classical problem in machine learning and applied statistics. This can also be interpreted as a clustering problem. Indeed, given data samples independently generated from a GMM, we would like to find the correct target clustering of the samples according to which Gaussian they were generated from. Despite the large number of algorithms designed to find the correct target clustering, many practitioners prefer to use the k-means algorithm because of its simplicity. k-means tries to find an optimal clustering which minimizes the sum of squared distances between each point and its cluster center. In this paper, we provide sufficient conditions for the closeness of any optimal clustering and the correct target clustering of the samples which are independently generated from a GMM. Moreover, to achieve significantly faster running time and reduced memory usage, we show that under weaker conditions on the GMM, any optimal clustering for the samples with reduced dimensionality is also close to the correct target clustering. These results provide intuition for the informativeness of k-means as an algorithm for learning a GMM, further substantiating the conclusions in Kumar and Kannan [2010]. We verify the correctness of our theorems using numerical experiments and show, using datasets with reduced dimensionality, significant speed ups for the time required to perform clustering. version:1
arxiv-1703-10530 | Efficient optimization for Hierarchically-structured Interacting Segments (HINTS) | http://arxiv.org/abs/1703.10530 | id:1703.10530 author:Hossam Isack, Olga Veksler, Ipek Oguz, Milan Sonka, Yuri Boykov category:cs.CV  published:2017-03-30 summary:We propose an effective optimization algorithm for a general hierarchical segmentation model with geometric interactions between segments. Any given tree can specify a partial order over object labels defining a hierarchy. It is well-established that segment interactions, such as inclusion/exclusion and margin constraints, make the model significantly more discriminant. However, existing optimization methods do not allow full use of such models. Generic -expansion results in weak local minima, while common binary multi-layered formulations lead to non-submodularity, complex high-order potentials, or polar domain unwrapping and shape biases. In practice, applying these methods to arbitrary trees does not work except for simple cases. Our main contribution is an optimization method for the Hierarchically-structured Interacting Segments (HINTS) model with arbitrary trees. Our Path-Moves algorithm is based on multi-label MRF formulation and can be seen as a combination of well-known a-expansion and Ishikawa techniques. We show state-of-the-art biomedical segmentation for many diverse examples of complex trees. version:1
arxiv-1703-10513 | On Bayesian Exponentially Embedded Family for Model Order Selection | http://arxiv.org/abs/1703.10513 | id:1703.10513 author:Zhenghan Zhu, Steven Kay category:stat.ML cs.LG  published:2017-03-30 summary:In this paper, we derive a Bayesian model order selection rule by using the exponentially embedded family method, termed Bayesian EEF. Unlike many other Bayesian model selection methods, the Bayesian EEF can use vague proper priors and improper noninformative priors to be objective in the elicitation of parameter priors. Moreover, the penalty term of the rule is shown to be the sum of half of the parameter dimension and the estimated mutual information between parameter and observed data. This helps to reveal the EEF mechanism in selecting model orders and may provide new insights into the open problems of choosing an optimal penalty term for model order selection and choosing a good prior from information theoretic viewpoints. The important example of linear model order selection is given to illustrate the algorithms and arguments. Lastly, the Bayesian EEF that uses Jeffreys prior coincides with the EEF rule derived by frequentist strategies. This shows another interesting relationship between the frequentist and Bayesian philosophies for model selection. version:1
arxiv-1703-10501 | A Paradigm Shift: Detecting Human Rights Violations Through Web Images | http://arxiv.org/abs/1703.10501 | id:1703.10501 author:Grigorios Kalliatakis, Shoaib Ehsan, Klaus D. McDonald-Maier category:cs.CV cs.CY  published:2017-03-30 summary:The growing presence of devices carrying digital cameras, such as mobile phones and tablets, combined with ever improving internet networks have enabled ordinary citizens, victims of human rights abuse, and participants in armed conflicts, protests, and disaster situations to capture and share via social media networks images and videos of specific events. This paper discusses the potential of images in human rights context including the opportunities and challenges they present. This study demonstrates that real-world images have the capacity to contribute complementary data to operational human rights monitoring efforts when combined with novel computer vision approaches. The analysis is concluded by arguing that if images are to be used effectively to detect and identify human rights violations by rights advocates, greater attention to gathering task-specific visual concepts from large-scale web images is required. version:1
arxiv-1703-10476 | Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training | http://arxiv.org/abs/1703.10476 | id:1703.10476 author:Rakshith Shetty, Marcus Rohrbach, Lisa Anne Hendricks, Mario Fritz, Bernt Schiele category:cs.CV cs.AI cs.CL  published:2017-03-30 summary:While strong progress has been made in image captioning over the last years, machine and human captions are still quite distinct. A closer look reveals that this is due to the deficiencies in the generated word distribution, vocabulary size, and strong bias in the generators towards frequent captions. Furthermore, humans -- rightfully so -- generate multiple, diverse captions, due to the inherent ambiguity in the captioning task which is not considered in today's systems. To address these challenges, we change the training objective of the caption generator from reproducing groundtruth captions to generating a set of captions that is indistinguishable from human generated captions. Instead of handcrafting such a learning target, we employ adversarial training in combination with an approximate Gumbel sampler to implicitly match the generated distribution to the human one. While our method achieves comparable performance to the state-of-the-art in terms of the correctness of the captions, we generate a set of diverse captions, that are significantly less biased and match the word statistics better in several aspects. version:1
arxiv-1703-10458 | Application of a Shallow Neural Network to Short-Term Stock Trading | http://arxiv.org/abs/1703.10458 | id:1703.10458 author:Abhinav Madahar, Yuze Ma, Kunal Patel category:cs.NE cs.LG  published:2017-03-30 summary:Machine learning is increasingly prevalent in stock market trading. Though neural networks have seen success in computer vision and natural language processing, they have not been as useful in stock market trading. To demonstrate the applicability of a neural network in stock trading, we made a single-layer neural network that recommends buying or selling shares of a stock by comparing the highest high of 10 consecutive days with that of the next 10 days, a process repeated for the stock's year-long historical data. A chi-squared analysis found that the neural network can accurately and appropriately decide whether to buy or sell shares for a given stock, showing that a neural network can make simple decisions about the stock market. version:1
arxiv-1703-10444 | On Fundamental Limits of Robust Learning | http://arxiv.org/abs/1703.10444 | id:1703.10444 author:Jiashi Feng category:cs.LG stat.ML  published:2017-03-30 summary:We consider the problems of robust PAC learning from distributed and streaming data, which may contain malicious errors and outliers, and analyze their fundamental complexity questions. In particular, we establish lower bounds on the communication complexity for distributed robust learning performed on multiple machines, and on the space complexity for robust learning from streaming data on a single machine. These results demonstrate that gaining robustness of learning algorithms is usually at the expense of increased complexities. As far as we know, this work gives the first complexity results for distributed and online robust PAC learning. version:1
arxiv-1703-10423 | Minimum energy path calculations with Gaussian process regression | http://arxiv.org/abs/1703.10423 | id:1703.10423 author:Olli-Pekka Koistinen, Emile Maras, Aki Vehtari, Hannes Jónsson category:physics.chem-ph physics.atm-clus physics.comp-ph stat.CO stat.ML  published:2017-03-30 summary:The calculation of minimum energy paths for transitions such as atomic and/or spin re-arrangements is an important task in many contexts and can often be used to determine the mechanism and rate of transitions. An important challenge is to reduce the computational effort in such calculations, especially when ab initio or electron density functional calculations are used to evaluate the energy since they can require large computational effort. Gaussian process regression is used here to reduce significantly the number of energy evaluations needed to find minimum energy paths of atomic rearrangements. By using results of previous calculations to construct an approximate energy surface and then converge to the minimum energy path on that surface in each Gaussian process iteration, the number of energy evaluations is reduced significantly as compared with regular nudged elastic band calculations. For a test problem involving rearrangements of a heptamer island on a crystal surface, the number of energy evaluations is reduced to less than a fifth. The scaling of the computational effort with the number of degrees of freedom as well as various possible further improvements to this approach are discussed. version:1
arxiv-1703-10371 | Born to Learn: the Inspiration, Progress, and Future of Evolved Plastic Artificial Neural Networks | http://arxiv.org/abs/1703.10371 | id:1703.10371 author:Andrea Soltoggio, Kenneth O. Stanley, Sebastian Risi category:cs.NE cs.AI  published:2017-03-30 summary:Biological neural networks are systems of extraordinary computational capabilities shaped by evolution, development, and lifetime learning. The interplay of these elements leads to the emergence of adaptive behavior and intelligence, but the complexity of the whole system of interactions is an obstacle to the understanding of the key factors at play. Inspired by such intricate natural phenomena, Evolved Plastic Artificial Neural Networks (EPANNs) use simulated evolution in-silico to breed plastic neural networks, artificial systems composed of sensors, outputs, and plastic components that change in response to sensory-output experiences in an environment. These systems may reveal key algorithmic ingredients of adaptation, autonomously discover novel adaptive algorithms, and lead to hypotheses on the emergence of biological adaptation. EPANNs have seen considerable progress over the last two decades. Current scientific and technological advances in artificial neural networks are now setting the conditions for radically new approaches and results. In particular, the limitations of hand-designed structures and algorithms currently used in most deep neural networks could be overcome by more flexible and innovative solutions. This paper brings together a variety of inspiring ideas that define the field of EPANNs. The main computational methods and results are reviewed. Finally, new opportunities and developments are presented. version:1
arxiv-1703-10893 | Audio-Visual Speech Enhancement based on Multimodal Deep Convolutional Neural Network | http://arxiv.org/abs/1703.10893 | id:1703.10893 author:Jen-Cheng Hou, Syu-Siang Wang, Ying-Hui Lai, Jen-Chun Lin, Yu Tsao, Hsiu-Wen Chang, Hsin-Min Wang category:cs.SD cs.MM stat.ML  published:2017-03-30 summary:Speech enhancement (SE) aims to reduce noise in speech signals. Most SE techniques focus on addressing audio information only.In this work, inspired by multimodal learning, which utilizes data from different modalities, and the recent success of convolutional neural networks (CNNs) in SE, we propose an audio-visual deep CNN (AVDCNN) SE model, which incorporates audio and visual streams into a unified network model.In the proposed AVDCNN SE model,audio and visual features are first processed using individual CNNs, and then, fused into a joint network to generate enhanced speech at an output layer. The AVDCNN model is trained in an end-to-end manner, and parameters are jointly learned through back-propagation. We evaluate enhanced speech using five objective criteria. Results show that the AVDCNN yields notably better performance as compared to an audio-only CNN-based SE model, confirming the effectiveness of integrating visual information into the SE process. version:1
arxiv-1703-10356 | End-to-End MAP Training of a Hybrid HMM-DNN Model | http://arxiv.org/abs/1703.10356 | id:1703.10356 author:Lior Fritz, David Burshtein category:cs.LG cs.CL cs.NE  published:2017-03-30 summary:An hybrid of a hidden Markov model (HMM) and a deep neural network (DNN) is considered. End-to-end training using gradient descent is suggested, similarly to the training of connectionist temporal classification (CTC). We use a maximum a-posteriori (MAP) criterion with a simple language model in the training stage, and a standard HMM decoder without approximations. Recognition results are presented using speech databases. Our method compares favorably to CTC in terms of performance, robustness and quality of alignments. version:1
arxiv-1703-10355 | From Deep to Shallow: Transformations of Deep Rectifier Networks | http://arxiv.org/abs/1703.10355 | id:1703.10355 author:Senjian An, Farid Boussaid, Mohammed Bennamoun, Jiankun Hu category:cs.LG stat.ML  published:2017-03-30 summary:In this paper, we introduce transformations of deep rectifier networks, enabling the conversion of deep rectifier networks into shallow rectifier networks. We subsequently prove that any rectifier net of any depth can be represented by a maximum of a number of functions that can be realized by a shallow network with a single hidden layer. The transformations of both deep rectifier nets and deep residual nets are conducted to demonstrate the advantages of the residual nets over the conventional neural nets and the advantages of the deep neural nets over the shallow neural nets. In summary, for two rectifier nets with different depths but with same total number of hidden units, the corresponding single hidden layer representation of the deeper net is much more complex than the corresponding single hidden representation of the shallower net. Similarly, for a residual net and a conventional rectifier net with the same structure except for the skip connections in the residual net, the corresponding single hidden layer representation of the residual net is much more complex than the corresponding single hidden layer representation of the conventional net. version:1
arxiv-1703-10344 | Automated News Suggestions for Populating Wikipedia Entity Pages | http://arxiv.org/abs/1703.10344 | id:1703.10344 author:Besnik Fetahu, Katja Markert, Avishek Anand category:cs.IR cs.CL cs.SI  published:2017-03-30 summary:Wikipedia entity pages are a valuable source of information for direct consumption and for knowledge-base construction, update and maintenance. Facts in these entity pages are typically supported by references. Recent studies show that as much as 20\% of the references are from online news sources. However, many entity pages are incomplete even if relevant information is already available in existing news articles. Even for the already present references, there is often a delay between the news article publication time and the reference time. In this work, we therefore look at Wikipedia through the lens of news and propose a novel news-article suggestion task to improve news coverage in Wikipedia, and reduce the lag of newsworthy references. Our work finds direct application, as a precursor, to Wikipedia page generation and knowledge-base acceleration tasks that rely on relevant and high quality input sources. We propose a two-stage supervised approach for suggesting news articles to entity pages for a given state of Wikipedia. First, we suggest news articles to Wikipedia entities (article-entity placement) relying on a rich set of features which take into account the \emph{salience} and \emph{relative authority} of entities, and the \emph{novelty} of news articles to entity pages. Second, we determine the exact section in the entity page for the input article (article-section placement) guided by class-based section templates. We perform an extensive evaluation of our approach based on ground-truth data that is extracted from external references in Wikipedia. We achieve a high precision value of up to 93\% in the \emph{article-entity} suggestion stage and upto 84\% for the \emph{article-section placement}. Finally, we compare our approach against competitive baselines and show significant improvements. version:1
arxiv-1703-10342 | Efficient Benchmarking of Algorithm Configuration Procedures via Model-Based Surrogates | http://arxiv.org/abs/1703.10342 | id:1703.10342 author:Katharina Eggensperger, Marius Lindauer, Holger H. Hoos, Frank Hutter, Kevin Leyton-Brown category:cs.AI stat.ML  published:2017-03-30 summary:The optimization of algorithm (hyper-)parameters is crucial for achieving peak performance across a wide range of domains, ranging from deep neural networks to solvers for hard combinatorial problems. The resulting algorithm configuration (AC) problem has attracted much attention from the machine learning community. However, the proper evaluation of new AC procedures is hindered by two key hurdles. First, AC benchmarks are hard to set up. Second and even more significantly, they are computationally expensive: a single run of an AC procedure involves many costly runs of the target algorithm whose performance is to be optimized in a given AC benchmark scenario. One common workaround is to optimize cheap-to-evaluate artificial benchmark functions (e.g., Branin) instead of actual algorithms; however, these have different properties than realistic AC problems. Here, we propose an alternative benchmarking approach that is similarly cheap to evaluate but much closer to the original AC problem: replacing expensive benchmarks by surrogate benchmarks constructed from AC benchmarks. These surrogate benchmarks approximate the response surface corresponding to true target algorithm performance using a regression model, and the original and surrogate benchmark share the same (hyper-)parameter space. In our experiments, we construct and evaluate surrogate benchmarks for hyperparameter optimization as well as for AC problems that involve performance optimization of solvers for hard combinatorial problems, drawing training data from the runs of existing AC procedures. We show that our surrogate benchmarks capture overall important characteristics of the AC scenarios, such as high- and low-performing regions, from which they were derived, while being much easier to use and orders of magnitude cheaper to evaluate. version:1
arxiv-1703-10339 | Finding News Citations for Wikipedia | http://arxiv.org/abs/1703.10339 | id:1703.10339 author:Besnik Fetahu, Katja Markert, Wolfgang Nejdl, Avishek Anand category:cs.IR cs.CL cs.SI  published:2017-03-30 summary:An important editing policy in Wikipedia is to provide citations for added statements in Wikipedia pages, where statements can be arbitrary pieces of text, ranging from a sentence to a paragraph. In many cases citations are either outdated or missing altogether. In this work we address the problem of finding and updating news citations for statements in entity pages. We propose a two-stage supervised approach for this problem. In the first step, we construct a classifier to find out whether statements need a news citation or other kinds of citations (web, book, journal, etc.). In the second step, we develop a news citation algorithm for Wikipedia statements, which recommends appropriate citations from a given news collection. Apart from IR techniques that use the statement to query the news collection, we also formalize three properties of an appropriate citation, namely: (i) the citation should entail the Wikipedia statement, (ii) the statement should be central to the citation, and (iii) the citation should be from an authoritative source. We perform an extensive evaluation of both steps, using 20 million articles from a real-world news collection. Our results are quite promising, and show that we can perform this task with high precision and at scale. version:1
arxiv-1703-10332 | Dynamic Computational Time for Visual Attention | http://arxiv.org/abs/1703.10332 | id:1703.10332 author:Zhichao Li, Yi Yang, Xiao Liu, Shilei Wen, Wei Xu category:cs.CV  published:2017-03-30 summary:We propose a dynamic computational time model to accelerate the average processing time for recurrent visual attention (RAM). Rather than attention with a fixed number of steps for each input image, the model learns to decide when to stop on the fly. To achieve this, we add an additional continue/stop action per time step to RAM and use reinforcement learning to learn both the optimal attention policy and stopping policy. The modification is simple but could dramatically save the average computational time while keeping the same recognition performance as RAM. Experimental results on CUB-200-2011 and Stanford Cars dataset demonstrate the dynamic computational model can work effectively for fine-grained image recognition.The source code of this paper can be obtained from https://github.com/baidu-research/DT-RAM version:1
arxiv-1703-10304 | Planecell: Representing the 3D Space with Planes | http://arxiv.org/abs/1703.10304 | id:1703.10304 author:Lei Fan, Ziyu Pan, Long Chen, Kai Huang category:cs.CV  published:2017-03-30 summary:Reconstruction based on the stereo camera has received considerable attention recently, but two particular challenges still remain. The first concerns the need to aggregate similar pixels in an effective approach, and the second is to maintain as much of the available information as possible while ensuring sufficient accuracy. To overcome these issues, we propose a new 3D representation method, namely, planecell, that extracts planarity from the depth-assisted image segmentation and then projects these depth planes into the 3D world. An energy function formulated from Conditional Random Field that generalizes the planar relationships is maximized to merge coplanar segments. We evaluate our method with a variety of reconstruction baselines on both KITTI and Middlebury datasets, and the results indicate the superiorities compared to other 3D space representation methods in accuracy, memory requirements and further applications. version:1
arxiv-1703-10295 | DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling | http://arxiv.org/abs/1703.10295 | id:1703.10295 author:Lachlan Tychsen-Smith, Lars Petersson category:cs.CV  published:2017-03-30 summary:We define the object detection from imagery problem as estimating a very large but extremely sparse bounding box dependent probability distribution. Subsequently we develop a novel sparse distribution estimation scheme called Directed Sparse Sampling, and employ it in a single end-to-end CNN based detection model. This methodology extends and formalizes previous state-of-the-art detection models with an additional emphasis on high evaluation rates and reduced manual engineering. The resulting model is scene adaptive, does not require manually defined reference bounding boxes and produces highly competitive results on MSCOCO, Pascal VOC 2007 and Pascal VOC 2012 with real-time evaluation rates. Further analysis suggests our model performs particularly well when finegrained object localization is desirable. We argue that this advantage stems from the much larger set of available regions-of-interest relative to other methods. version:1
arxiv-1703-08544 | Data-Mining Textual Responses to Uncover Misconception Patterns | http://arxiv.org/abs/1703.08544 | id:1703.08544 author:Joshua J. Michalenko, Andrew S. Lan, Richard G. Baraniuk category:stat.ML cs.CL  published:2017-03-24 summary:An important, yet largely unstudied, problem in student data analysis is to detect misconceptions from students' responses to open-response questions. Misconception detection enables instructors to deliver more targeted feedback on the misconceptions exhibited by many students in their class, thus improving the quality of instruction. In this paper, we propose a new natural language processing-based framework to detect the common misconceptions among students' textual responses to short-answer questions. We propose a probabilistic model for students' textual responses involving misconceptions and experimentally validate it on a real-world student-response dataset. Experimental results show that our proposed framework excels at classifying whether a response exhibits one or more misconceptions. More importantly, it can also automatically detect the common misconceptions exhibited across responses from multiple students to multiple questions; this property is especially important at large scale, since instructors will no longer need to manually specify all possible misconceptions that students might exhibit. version:2
arxiv-1703-10284 | Enter the Matrix: A Virtual World Approach to Safely Interruptable Autonomous Systems | http://arxiv.org/abs/1703.10284 | id:1703.10284 author:Mark O. Riedl, Brent Harrison category:cs.AI cs.LG  published:2017-03-30 summary:Robots and autonomous systems that operate around humans will likely always rely on kill switches that stop their execution and allow them to be remote-controlled for the safety of humans or to prevent damage to the system. It is theoretically possible for an autonomous system with sufficient sensor and effector capability and using reinforcement learning to learn that the kill switch deprives it of long-term reward and learn to act to disable the switch or otherwise prevent a human operator from using the switch. This is referred to as the big red button problem. We present a technique which prevents a reinforcement learning agent from learning to disable the big red button. Our technique interrupts the agent or robot by placing it in a virtual simulation where it continues to receive reward. We illustrate our technique in a simple grid world environment. version:1
arxiv-1703-10277 | Semantic Instance Segmentation via Deep Metric Learning | http://arxiv.org/abs/1703.10277 | id:1703.10277 author:Alireza Fathi, Zbigniew Wojna, Vivek Rathod, Peng Wang, Hyun Oh Song, Sergio Guadarrama, Kevin P. Murphy category:cs.CV  published:2017-03-30 summary:We propose a new method for semantic instance segmentation, by first computing how likely two pixels are to belong to the same object, and then by grouping similar pixels together. Our similarity metric is based on a deep, fully convolutional embedding model. Our grouping method is based on selecting all points that are sufficiently similar to a set of "seed points", chosen from a deep, fully convolutional scoring model. We show competitive results on the Pascal VOC instance segmentation benchmark. version:1
arxiv-1703-08729 | Solving SDPs for synchronization and MaxCut problems via the Grothendieck inequality | http://arxiv.org/abs/1703.08729 | id:1703.08729 author:Song Mei, Theodor Misiakiewicz, Andrea Montanari, Roberto I. Oliveira category:math.OC stat.ML  published:2017-03-25 summary:A number of statistical estimation problems can be addressed by semidefinite programs (SDP). While SDPs are solvable in polynomial time using interior point methods, in practice generic SDP solvers do not scale well to high-dimensional problems. In order to cope with this problem, Burer and Monteiro proposed a non-convex rank-constrained formulation, which has good performance in practice but is still poorly understood theoretically. In this paper we study the rank-constrained version of SDPs arising in MaxCut and in synchronization problems. We establish a Grothendieck-type inequality that proves that all the local maxima and dangerous saddle points are within a small multiplicative gap from the global maximum. We use this structural information to prove that SDPs can be solved within a known accuracy, by applying the Riemannian trust-region method to this non-convex problem, while constraining the rank to be of order one. For the MaxCut problem, our inequality implies that any local maximizer of the rank-constrained SDP provides a $ (1 - 1/(k-1)) \times 0.878$ approximation of the MaxCut, when the rank is fixed to $k$. We then apply our results to data matrices generated according to the Gaussian ${\mathbb Z}_2$ synchronization problem, and the two-groups stochastic block model with large bounded degree. We prove that the error achieved by local maximizers undergoes a phase transition at the same threshold as for information-theoretically optimal methods. version:2
arxiv-1703-10239 | SeGAN: Segmenting and Generating the Invisible | http://arxiv.org/abs/1703.10239 | id:1703.10239 author:Kiana Ehsani, Roozbeh Mottaghi, Ali Farhadi category:cs.CV  published:2017-03-29 summary:Objects often occlude each other in scenes; Inferring their appearance beyond their visible parts plays an important role in scene understanding, depth estimation, object interaction and manipulation. In this paper, we study the challenging problem of completing the appearance of occluded objects. Doing so requires knowing which pixels to paint (segmenting the invisible parts of objects) and what color to paint them (generating the invisible parts). Our proposed novel solution, SeGAN, jointly optimizes for both segmentation and generation of the invisible parts of objects. Our experimental results show that: (a) SeGAN can learn to generate the appearance of the occluded parts of objects; (b) SeGAN outperforms state-of-the-art segmentation baselines for the invisible parts of objects; (c) trained on synthetic photo realistic images, SeGAN can reliably segment natural images; (d) by reasoning about occluder occludee relations, our method can infer depth layering. version:1
arxiv-1703-10230 | Numerical Gaussian Processes for Time-dependent and Non-linear Partial Differential Equations | http://arxiv.org/abs/1703.10230 | id:1703.10230 author:Maziar Raissi, Paris Perdikaris, George Em Karniadakis category:stat.ML cs.NA math.AP math.DS math.NA 65C20  68T05  65M75  published:2017-03-29 summary:We introduce the concept of numerical Gaussian processes, which we define as Gaussian processes with covariance functions resulting from temporal discretization of time-dependent partial differential equations. Numerical Gaussian processes, by construction, are designed to deal with cases where: (1) all we observe are noisy data on black-box initial conditions, and (2) we are interested in quantifying the uncertainty associated with such noisy data in our solutions to time-dependent partial differential equations. Our method circumvents the need for spatial discretization of the differential operators by proper placement of Gaussian process priors. This is an attempt to construct structured and data-efficient learning machines, which are explicitly informed by the underlying physics that possibly generated the observed data. The effectiveness of the proposed approach is demonstrated through several benchmark problems involving linear and nonlinear time-dependent operators. In all examples, we are able to recover accurate approximations of the latent solutions, and consistently propagate uncertainty, even in cases involving very long time integration. version:1
arxiv-1703-10200 | Learning High Dynamic Range from Outdoor Panoramas | http://arxiv.org/abs/1703.10200 | id:1703.10200 author:Jinsong Zhang, Jean-François Lalonde category:cs.CV  published:2017-03-29 summary:Outdoor lighting has extremely high dynamic range. This makes the process of capturing outdoor environment maps notoriously challenging since special equipment must be used. In this work, we propose an alternative approach. We first capture lighting with a regular, LDR omnidirectional camera, and aim to recover the HDR after the fact via a novel, learning-based tonemapping method. We propose a deep autoencoder framework which regresses linear, high dynamic range data from non-linear, saturated, low dynamic range panoramas. We validate our method through a wide set of experiments on synthetic data, as well as on a novel dataset of real photographs with ground truth. Our approach finds applications in a variety of settings, ranging from outdoor light capture to image matching. version:1
arxiv-1703-10196 | Detecting Human Interventions on the Landscape: KAZE Features, Poisson Point Processes, and a Construction Dataset | http://arxiv.org/abs/1703.10196 | id:1703.10196 author:Edward Boyda, Colin McCormick, Dan Hammer category:cs.CV  published:2017-03-29 summary:We present an algorithm capable of identifying a wide variety of human-induced change on the surface of the planet by analyzing matches between local features in time-sequenced remote sensing imagery. We evaluate feature sets, match protocols, and the statistical modeling of feature matches. With application of KAZE features, k-nearest-neighbor descriptor matching, and geometric proximity and bi-directional match consistency checks, average match rates increase more than two-fold over the previous standard. In testing our platform, we developed a small, labeled benchmark dataset expressing large-scale residential, industrial, and civic construction, along with null instances, in California between the years 2010 and 2012. On the benchmark set, our algorithm makes precise, accurate change proposals on two-thirds of scenes. Further, the detection threshold can be tuned so that all or almost all proposed detections are true positives. version:1
arxiv-1703-10186 | Colors in Context: A Pragmatic Neural Model for Grounded Language Understanding | http://arxiv.org/abs/1703.10186 | id:1703.10186 author:Will Monroe, Robert X. D. Hawkins, Noah D. Goodman, Christopher Potts category:cs.CL  published:2017-03-29 summary:We present a model of pragmatic referring expression interpretation in a grounded communication task (identifying colors from descriptions) that draws upon predictions from two recurrent neural network classifiers, a speaker and a listener, unified by a recursive pragmatic reasoning framework. Experiments show that this combined pragmatic model interprets color descriptions more accurately than the classifiers from which it is built. We observe that pragmatic reasoning helps primarily in the hardest cases: when the model must distinguish very similar colors, or when few utterances adequately express the target color. Our findings make use of a newly-collected corpus of human utterances in color reference games, which exhibit a variety of pragmatic behaviors. We also show that the embedded speaker model reproduces many of these pragmatic behaviors. version:1
arxiv-1703-10155 | CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training | http://arxiv.org/abs/1703.10155 | id:1703.10155 author:Jianmin Bao, Dong Chen, Fang Wen, Houqiang Li, Gang Hua category:cs.CV  published:2017-03-29 summary:We present variational generative adversarial networks, a general learning framework that combines a variational auto-encoder with a generative adversarial network, for synthesizing images of fine-grained categories, such as faces of a specific person or objects in a category. Our approach models an image as a composition of label and latent attributes in a probabilistic model. By varying the fine-grained category label fed to the resulting generative model, we can generate images in a specific category by randomly drawn values on a latent attribute vector. The novelty of our approach comes from two aspects. Firstly, we propose to adopt a cross entropy loss for the discriminative and classifier network, but a mean discrepancy objective for the generative network. This kind of asymmetric loss function makes the training of the GAN more stable. Secondly, we adopt an encoder network to learn the relationship between the latent space and the real image space, and use pairwise feature matching to keep the structure of generated images. We experiment with natural images of faces, flowers, and birds, and demonstrate that the proposed models are capable of generating realistic and diverse samples with fine-grained category labels. We further show that our models can be applied to other tasks, such as image inpainting, super-resolution, and data augmentation for training better face recognition models. version:1
arxiv-1703-10152 | Automatic Argumentative-Zoning Using Word2vec | http://arxiv.org/abs/1703.10152 | id:1703.10152 author:Haixia Liu category:cs.CL  published:2017-03-29 summary:In comparison with document summarization on the articles from social media and newswire, argumentative zoning (AZ) is an important task in scientific paper analysis. Traditional methodology to carry on this task relies on feature engineering from different levels. In this paper, three models of generating sentence vectors for the task of sentence classification were explored and compared. The proposed approach builds sentence representations using learned embeddings based on neural network. The learned word embeddings formed a feature space, to which the examined sentence is mapped to. Those features are input into the classifiers for supervised classification. Using 10-cross-validation scheme, evaluation was conducted on the Argumentative-Zoning (AZ) annotated articles. The results showed that simply averaging the word vectors in a sentence works better than the paragraph to vector algorithm and by integrating specific cuewords into the loss function of the neural network can improve the classification performance. In comparison with the hand-crafted features, the word2vec method won for most of the categories. However, the hand-crafted features showed their strength on classifying some of the categories. version:1
arxiv-1703-10146 | Community detection and stochastic block models: recent developments | http://arxiv.org/abs/1703.10146 | id:1703.10146 author:Emmanuel Abbe category:math.PR cs.CC cs.IT cs.SI math.IT stat.ML  published:2017-03-29 summary:The stochastic block model (SBM) is a random graph model with planted clusters. It is widely employed as a canonical model to study clustering and community detection, and provides generally a fertile ground to study the statistical and computational tradeoffs that arise in network and data sciences. This note surveys the recent developments that establish the fundamental limits for community detection in the SBM, both with respect to information-theoretic and computational thresholds, and for various recovery requirements such as exact, partial and weak recovery (a.k.a., detection). The main results discussed are the phase transitions for exact recovery at the Chernoff-Hellinger threshold, the phase transition for weak recovery at the Kesten-Stigum threshold, the optimal distortion-SNR tradeoff for partial recovery, the learning of the SBM parameters and the gap between information-theoretic and computational thresholds. The note also covers some of the algorithms developed in the quest of achieving the limits, in particular two-round algorithms via graph-splitting, semi-definite programming, linearized belief propagation, classical and nonbacktracking spectral methods. A few open problems are also discussed. version:1
arxiv-1703-10131 | Unrestricted Facial Geometry Reconstruction Using Image-to-Image Translation | http://arxiv.org/abs/1703.10131 | id:1703.10131 author:Matan Sela, Elad Richardson, Ron Kimmel category:cs.CV  published:2017-03-29 summary:It has been recently shown that neural networks can recover the geometric structure of a face from a single given image. A common denominator of most existing face geometry reconstruction methods is the restriction of the solution space to some low-dimensional subspace. While such a model significantly simplifies the reconstruction problem, it is inherently limited in its expressiveness. As an alternative, we propose an Image-to-Image translation network that maps the input image to a depth image and a facial correspondence map. This explicit pixel-based mapping can then be utilized to provide high quality reconstructions of diverse faces under extreme expressions. In the spirit of recent approaches, the network is trained only with synthetic data, and is then evaluated on "in-the-wild" facial images. Both qualitative and quantitative analyses demonstrate the accuracy and the robustness of our approach. As an additional analysis of the proposed network, we show that it can be used as a geometric constraint for facial image translation tasks. version:1
arxiv-1703-10125 | Google Map Aided Visual Navigation for UAVs in GPS-denied Environment | http://arxiv.org/abs/1703.10125 | id:1703.10125 author:Mo Shan, Fei Wang, Feng Lin, Zhi Gao, Ya Z. Tang, Ben M. Chen category:cs.CV  published:2017-03-29 summary:We propose a framework for Google Map aided UAV navigation in GPS-denied environment. Geo-referenced navigation provides drift-free localization and does not require loop closures. The UAV position is initialized via correlation, which is simple and efficient. We then use optical flow to predict its position in subsequent frames. During pose tracking, we obtain inter-frame translation either by motion field or homography decomposition, and we use HOG features for registration on Google Map. We employ particle filter to conduct a coarse to fine search to localize the UAV. Offline test using aerial images collected by our quadrotor platform shows promising results as our approach eliminates the drift in dead-reckoning, and the small localization error indicates the superiority of our approach as a supplement to GPS. version:1
arxiv-1703-10121 | The Top 10 Topics in Machine Learning Revisited: A Quantitative Meta-Study | http://arxiv.org/abs/1703.10121 | id:1703.10121 author:Patrick Glauner, Manxing Du, Victor Paraschiv, Andrey Boytsov, Isabel Lopez Andrade, Jorge Meira, Petko Valtchev, Radu State category:cs.LG cs.AI stat.ML  published:2017-03-29 summary:Which topics of machine learning are most commonly addressed in research? This question was initially answered in 2007 by doing a qualitative survey among distinguished researchers. In our study, we revisit this question from a quantitative perspective. Concretely, we collect 54K abstracts of papers published between 2007 and 2016 in leading machine learning journals and conferences. We then use machine learning in order to determine the top 10 topics in machine learning. We not only include models, but provide a holistic view across optimization, data, features, etc. This quantitative approach allows reducing the bias of surveys. It reveals new and up-to-date insights into what the 10 most prolific topics in machine learning research are. This allows researchers to identify popular topics as well as new and rising topics for their research. version:1
arxiv-1703-10114 | Improved Lossy Image Compression with Priming and Spatially Adaptive Bit Rates for Recurrent Networks | http://arxiv.org/abs/1703.10114 | id:1703.10114 author:Nick Johnston, Damien Vincent, David Minnen, Michele Covell, Saurabh Singh, Troy Chinen, Sung Jin Hwang, Joel Shor, George Toderici category:cs.CV  published:2017-03-29 summary:We propose a method for lossy image compression based on recurrent, convolutional neural networks that outperforms BPG (4:2:0 ), WebP, JPEG2000, and JPEG as measured by MS-SSIM. We introduce three improvements over previous research that lead to this state-of-the-art result. First, we show that training with a pixel-wise loss weighted by SSIM increases reconstruction quality according to several metrics. Second, we modify the recurrent architecture to improve spatial diffusion, which allows the network to more effectively capture and propagate image information through the network's hidden state. Finally, in addition to lossless entropy coding, we use a spatially adaptive bit allocation algorithm to more efficiently use the limited number of bits to encode visually complex image regions. We evaluate our method on the Kodak and Tecnick image sets and compare against standard codecs as well recently published methods based on deep neural networks. version:1
arxiv-1703-10106 | Pose-conditioned Spatio-Temporal Attention for Human Action Recognition | http://arxiv.org/abs/1703.10106 | id:1703.10106 author:Fabien Baradel, Christian Wolf, Julien Mille category:cs.CV  published:2017-03-29 summary:We address human action recognition from multi-modal video data involving articulated pose and RGB frames and propose a two-stream approach. The pose stream is processed with a convolutional model taking as input a 3D tensor holding data from a sub-sequence. A specific joint ordering, which respects the topology of the human body, ensures that different convolutional layers correspond to meaningful levels of abstraction. The raw RGB stream is handled by a spatio-temporal soft-attention mechanism conditioned on features from the pose network. An LSTM network receives input from a set of image locations at each instant. A trainable glimpse sensor extracts features on a set of predefined locations specified by the pose stream, namely the 4 hands of the two people involved in the activity. Appearance features give important cues on hand motion and on objects held in each hand. We show that it is of high interest to shift the attention to different hands at different time steps depending on the activity itself. Finally a temporal attention mechanism learns how to fuse LSTM features over time. We evaluate the method on 3 datasets. State-of-the-art results are achieved on the largest dataset for human activity recognition, namely NTU-RGB+D, as well as on the SBU Kinect Interaction dataset. Performance close to state-of-the-art is achieved on the smaller MSR Daily Activity 3D dataset. version:1
arxiv-1703-10094 | Learning Inverse Mapping by Autoencoder based Generative Adversarial Nets | http://arxiv.org/abs/1703.10094 | id:1703.10094 author:Junyu Luo category:cs.LG  published:2017-03-29 summary:Generative Adversarial Net has shown its great ability in generating samples. The inverse mapping of generator also contains a great value. Some works have been developed to construct the inverse function of generator. However, the existing ways of training the inverse model of GANs have many shortcomings. In this paper, we propose a new approach of training the inverse model of generator by regarding a pre-trained generator as the decoder part of an autoencoder network. This model does not directly minimize the difference between original input and inverse output, but try to minimize the difference between the generated data by using original input and inverse output. This strategy overcome the difficulty in training a inverse model of a non one-to-one function. And the inverse mapping we learned can be directly used in image searching and processing. version:1
arxiv-1703-10090 | A Short Review of Ethical Challenges in Clinical Natural Language Processing | http://arxiv.org/abs/1703.10090 | id:1703.10090 author:Simon Šuster, Stéphan Tulkens, Walter Daelemans category:cs.CL cs.CY  published:2017-03-29 summary:Clinical NLP has an immense potential in contributing to how clinical practice will be revolutionized by the advent of large scale processing of clinical records. However, this potential has remained largely untapped due to slow progress primarily caused by strict data access policies for researchers. In this paper, we discuss the concern for privacy and the measures it entails. We also suggest sources of less sensitive data. Finally, we draw attention to biases that can compromise the validity of empirical research and lead to socially harmful applications. version:1
arxiv-1703-10089 | Time Series Forecasting using RNNs: an Extended Attention Mechanism to Model Periods and Handle Missing Values | http://arxiv.org/abs/1703.10089 | id:1703.10089 author:Yagmur G. Cinar, Hamid Mirisaee, Parantapa Goswami, Eric Gaussier, Ali Ait-Bachir, Vadim Strijov category:cs.LG cs.NE  published:2017-03-29 summary:In this paper, we study the use of recurrent neural networks (RNNs) for modeling and forecasting time series. We first illustrate the fact that standard sequence-to-sequence RNNs neither capture well periods in time series nor handle well missing values, even though many real life times series are periodic and contain missing values. We then propose an extended attention mechanism that can be deployed on top of any RNN and that is designed to capture periods and make the RNN more robust to missing values. We show the effectiveness of this novel model through extensive experiments with multiple univariate and multivariate datasets. version:1
arxiv-1703-10069 | Multiagent Bidirectionally-Coordinated Nets for Learning to Play StarCraft Combat Games | http://arxiv.org/abs/1703.10069 | id:1703.10069 author:Peng Peng, Quan Yuan, Ying Wen, Yaodong Yang, Zhenkun Tang, Haitao Long, Jun Wang category:cs.AI cs.LG  published:2017-03-29 summary:Real-world artificial intelligence (AI) applications often require multiple agents to work in a collaborative effort. Efficient learning for intra-agent communication and coordination is an indispensable step towards general AI. In this paper, we take StarCraft combat game as the test scenario, where the task is to coordinate multiple agents as a team to defeat their enemies. To maintain a scalable yet effective communication protocol, we introduce a multiagent bidirectionally-coordinated network (BiCNet ['bIknet]) with a vectorised extension of actor-critic formulation. We show that BiCNet can handle different types of combats under diverse terrains with arbitrary numbers of AI agents for both sides. Our analysis demonstrates that without any supervisions such as human demonstrations or labelled data, BiCNet could learn various types of coordination strategies that is similar to these of experienced game players. Moreover, BiCNet is easily adaptable to the tasks with heterogeneous agents. In our experiments, we evaluate our approach against multiple baselines under different scenarios; it shows state-of-the-art performance, and possesses potential values for large-scale real-world applications. version:1
arxiv-1703-10065 | Hierarchical Classification for Spoken Arabic Dialect Identification using Prosody: Case of Algerian Dialects | http://arxiv.org/abs/1703.10065 | id:1703.10065 author:Soumia Bougrine, Hadda Cherroun, Djelloul Ziadi category:cs.CL  published:2017-03-29 summary:In daily communications, Arabs use local dialects which are hard to identify automatically using conventional classification methods. The dialect identification challenging task becomes more complicated when dealing with an under-resourced dialects belonging to a same county/region. In this paper, we start by analyzing statistically Algerian dialects in order to capture their specificities related to prosody information which are extracted at utterance level after a coarse-grained consonant/vowel segmentation. According to these analysis findings, we propose a Hierarchical classification approach for spoken Arabic algerian Dialect IDentification (HADID). It takes advantage from the fact that dialects have an inherent property of naturally structured into hierarchy. Within HADID, a top-down hierarchical classification is applied, in which we use Deep Neural Networks (DNNs) method to build a local classifier for every parent node into the hierarchy dialect structure. Our framework is implemented and evaluated on Algerian Arabic dialects corpus. Whereas, the hierarchy dialect structure is deduced from historic and linguistic knowledges. The results reveal that within {\HD}, the best classifier is DNNs compared to Support Vector Machine. In addition, compared with a baseline Flat classification system, our HADID gives an improvement of 63.5% in term of precision. Furthermore, overall results evidence the suitability of our prosody-based HADID for speaker independent dialect identification while requiring less than 6s test utterances. version:1
arxiv-1703-10062 | Exploring Heritability of Functional Brain Networks with Inexact Graph Matching | http://arxiv.org/abs/1703.10062 | id:1703.10062 author:Sofia Ira Ktena, Salim Arslan, Sarah Parisot, Daniel Rueckert category:q-bio.NC cs.NE  published:2017-03-29 summary:Data-driven brain parcellations aim to provide a more accurate representation of an individual's functional connectivity, since they are able to capture individual variability that arises due to development or disease. This renders comparisons between the emerging brain connectivity networks more challenging, since correspondences between their elements are not preserved. Unveiling these correspondences is of major importance to keep track of local functional connectivity changes. We propose a novel method based on graph edit distance for the comparison of brain graphs directly in their domain, that can accurately reflect similarities between individual networks while providing the network element correspondences. This method is validated on a dataset of 116 twin subjects provided by the Human Connectome Project. version:1
arxiv-1703-10034 | Probabilistic Line Searches for Stochastic Optimization | http://arxiv.org/abs/1703.10034 | id:1703.10034 author:Maren Mahsereci, Philipp Hennig category:cs.LG stat.ML  published:2017-03-29 summary:In deterministic optimization, line searches are a standard tool ensuring stability and efficiency. Where only stochastic gradients are available, no direct equivalent has so far been formulated, because uncertain gradients do not allow for a strict sequence of decisions collapsing the search space. We construct a probabilistic line search by combining the structure of existing deterministic methods with notions from Bayesian optimization. Our method retains a Gaussian process surrogate of the univariate optimization objective, and uses a probabilistic belief over the Wolfe conditions to monitor the descent. The algorithm has very low computational cost, and no user-controlled parameters. Experiments show that it effectively removes the need to define a learning rate for stochastic gradient descent. version:1
arxiv-1703-10025 | Flow-Guided Feature Aggregation for Video Object Detection | http://arxiv.org/abs/1703.10025 | id:1703.10025 author:Xizhou Zhu, Yujie Wang, Jifeng Dai, Lu Yuan, Yichen Wei category:cs.CV  published:2017-03-29 summary:Extending state-of-the-art object detectors from image to video is challenging. The accuracy of detection suffers from degenerated object appearances in videos, e.g., motion blur, video defocus, rare poses, etc. Existing work attempts to exploit temporal information on box level, but such methods are not trained end-to-end. We present flow-guided feature aggregation, an accurate and end-to-end learning framework for video object detection. It leverages temporal coherence on feature level instead. It improves the per-frame features by aggregation of nearby features along the motion paths, and thus improves the video recognition accuracy. Our method significantly improves upon strong single-frame baselines in ImageNet VID, especially for more challenging fast moving objects. Our framework is principled, and on par with the best engineered systems winning the ImageNet VID challenges 2016, without additional bells-and-whistles. The code would be released. version:1
arxiv-1703-10010 | Optimal Policies for Observing Time Series and Related Restless Bandit Problems | http://arxiv.org/abs/1703.10010 | id:1703.10010 author:Christopher R. Dance, Tomi Silander category:stat.ML  published:2017-03-29 summary:The trade-off between the cost of acquiring and processing data, and uncertainty due to a lack of data is fundamental in machine learning. A basic instance of this trade-off is the problem of deciding when to make noisy and costly observations of a discrete-time Gaussian random walk, so as to minimise the posterior variance plus observation costs. We present the first proof that a simple policy, which observes when the posterior variance exceeds a threshold, is optimal for this problem. The proof generalises to a wide range of cost functions other than the posterior variance. This result implies that optimal policies for linear-quadratic-Gaussian control with costly observations have a threshold structure. It also implies that the restless bandit problem of observing multiple such time series, has a well-defined Whittle index. We discuss computation of that index, give closed-form formulae for it, and compare the performance of the associated index policy with heuristic policies. The proof is based on a new verification theorem that demonstrates threshold structure for Markov decision processes, and on the relation between binary sequences known as mechanical words and the dynamics of discontinuous nonlinear maps, which frequently arise in physics, control and biology. version:1
arxiv-1703-09990 | Object categorization in finer levels requires higher spatial frequencies, and therefore takes longer | http://arxiv.org/abs/1703.09990 | id:1703.09990 author:Matin N. Ashtiani, Saeed Reza Kheradpisheh, Timothée Masquelier, Mohammad Ganjtabesh category:q-bio.NC cs.CV  published:2017-03-29 summary:The human visual system contains a hierarchical sequence of modules that take part in visual perception at different levels of abstraction, i.e., superordinate, basic, and subordinate levels. One important question is to identify the "entry" level at which the visual representation is commenced in the process of object recognition. For a long time, it was believed that the basic level had advantage over two others; a claim that has been challenged recently. Here we used a series of psychophysics experiments, based on a rapid presentation paradigm, as well as two computational models, with bandpass filtered images to study the processing order of the categorization levels. In these experiments, we investigated the type of visual information required for categorizing objects in each level by varying the spatial frequency bands of the input image. The results of our psychophysics experiments and computational models are consistent. They indicate that the different spatial frequency information had different effects on object categorization in each level. In the absence of high frequency information, subordinate and basic level categorization are performed inaccurately, while superordinate level is performed well. This means that, low frequency information is sufficient for superordinate level, but not for the basic and subordinate levels. These finer levels require high frequency information, which appears to take longer to be processed, leading to longer reaction times. Finally, to avoid the ceiling effect, we evaluated the robustness of the results by adding different amounts of noise to the input images and repeating the experiments. As expected, the categorization accuracy decreased and the reaction time increased significantly, but the trends were the same.This shows that our results are not due to a ceiling effect. version:1
arxiv-1703-09983 | Iterative Object and Part Transfer for Fine-Grained Recognition | http://arxiv.org/abs/1703.09983 | id:1703.09983 author:Zhiqiang Shen, Yu-Gang Jiang, Dequan Wang, Xiangyang Xue category:cs.CV  published:2017-03-29 summary:The aim of fine-grained recognition is to identify sub-ordinate categories in images like different species of birds. Existing works have confirmed that, in order to capture the subtle differences across the categories, automatic localization of objects and parts is critical. Most approaches for object and part localization relied on the bottom-up pipeline, where thousands of region proposals are generated and then filtered by pre-trained object/part models. This is computationally expensive and not scalable once the number of objects/parts becomes large. In this paper, we propose a nonparametric data-driven method for object and part localization. Given an unlabeled test image, our approach transfers annotations from a few similar images retrieved in the training set. In particular, we propose an iterative transfer strategy that gradually refine the predicted bounding boxes. Based on the located objects and parts, deep convolutional features are extracted for recognition. We evaluate our approach on the widely-used CUB200-2011 dataset and a new and large dataset called Birdsnap. On both datasets, we achieve better results than many state-of-the-art approaches, including a few using oracle (manually annotated) bounding boxes in the test images. version:1
arxiv-1703-09975 | Improving Spectral Clustering using the Asymptotic Value of the Normalised Cut | http://arxiv.org/abs/1703.09975 | id:1703.09975 author:David Hofmeyr category:stat.ML  published:2017-03-29 summary:Spectral clustering is a popular and versatile clustering method based on a relaxation of the normalised graph cut objective. Despite its popularity, however, there is no single agreed upon method for tuning the important scaling parameter, nor for determining automatically the number of clusters to extract. Popular heuristics exist, but corresponding theoretical results are scarce. In this paper we investigate the asymptotic value of the normalised cut for an increasing sample assumed to arise from an underlying probability distribution, and based on this result provide recommendations for improving spectral clustering methodology. A corresponding algorithm is proposed with strong empirical performance. version:1
arxiv-1703-09971 | A Geometric Framework for Stochastic Shape Analysis | http://arxiv.org/abs/1703.09971 | id:1703.09971 author:Alexis Arnaudon, Darryl D. Holm, Stefan Sommer category:cs.CV math.DS math.NA  published:2017-03-29 summary:We introduce a stochastic model of diffeomorphisms, whose action on a variety of data types descends to stochastic models of shapes, images and landmarks. The stochasticity is introduced in the vector field which transports the data in the Large Deformation Diffeomorphic Metric Mapping (LDDMM) framework for shape analysis and image registration. The stochasticity thereby models errors or uncertainties of the flow in following the prescribed deformation velocity. The approach is illustrated in the example of finite dimensional landmark manifolds, whose stochastic evolution is studied both via the Fokker-Planck equation and by numerical simulations. We derive two approaches for inferring parameters of the stochastic model from landmark configurations observed at discrete time points. The first of the two approaches matches moments of the Fokker-Planck equation to sample moments of the data, while the second approach employs an Expectation-Maximisation based algorithm using a Monte Carlo bridge sampling scheme to optimise the data likelihood. We derive and numerically test the ability of the two approaches to infer the spatial correlation length of the underlying noise. version:1
arxiv-1703-09964 | Image Restoration using Autoencoding Priors | http://arxiv.org/abs/1703.09964 | id:1703.09964 author:Siavash Arjomand Bigdeli, Matthias Zwicker category:cs.CV cs.GR  published:2017-03-29 summary:We propose to leverage denoising autoencoder networks as priors to address image restoration problems. We build on the key observation that the output of an optimal denoising autoencoder is a local mean of the true data density, and the autoencoder error (the difference between the output and input of the trained autoencoder) is a mean shift vector. We use the magnitude of this mean shift vector, that is, the distance to the local mean, as the negative log likelihood of our natural image prior. For image restoration, we maximize the likelihood using gradient descent by backpropagating the autoencoder error. A key advantage of our approach is that we do not need to train separate networks for different image restoration tasks, such as non-blind deconvolution with different kernels, or super-resolution at different magnification factors. We demonstrate state of the art results for non-blind deconvolution and super-resolution using the same autoencoding prior. version:1
arxiv-1703-09477 | Convergence of the Forward-Backward Algorithm: Beyond the Worst Case with the Help of Geometry | http://arxiv.org/abs/1703.09477 | id:1703.09477 author:Guillaume Garrigos, Lorenzo Rosasco, Silvia Villa category:math.OC stat.ML  published:2017-03-28 summary:We provide a comprehensive study of the convergence of forward-backward algorithm under suitable geometric conditions leading to fast rates. We present several new results and collect in a unified view a variety of results scattered in the literature, often providing simplified proofs. Novel contributions include the analysis of infinite dimensional convex minimization problems, allowing the case where minimizers might not exist. Further, we analyze the relation between different geometric conditions, and discuss novel connections with a priori conditions in linear inverse problems, including source conditions, restricted isometry properties and partial smoothness. version:2
arxiv-1703-09956 | Marginal likelihood based model comparison in Fuzzy Bayesian Learning | http://arxiv.org/abs/1703.09956 | id:1703.09956 author:Indranil Pan, Dirk Bester category:stat.ML cs.LG  published:2017-03-29 summary:In a recent paper [1] we introduced the Fuzzy Bayesian Learning (FBL) paradigm where expert opinions can be encoded in the form of fuzzy rule bases and the hyper-parameters of the fuzzy sets can be learned from data using a Bayesian approach. The present paper extends this work for selecting the most appropriate rule base among a set of competing alternatives, which best explains the data, by calculating the model evidence or marginal likelihood. We explain why this is an attractive alternative over simply minimizing a mean squared error metric of prediction and show the validity of the proposition using synthetic examples and a real world case study in the financial services sector. version:1
arxiv-1703-09947 | Efficient Private ERM for Smooth Objectives | http://arxiv.org/abs/1703.09947 | id:1703.09947 author:Jiaqi Zhang, Kai Zheng, Wenlong Mou, Liwei Wang category:cs.LG cs.DS stat.ML  published:2017-03-29 summary:In this paper, we consider efficient differentially private empirical risk minimization from the viewpoint of optimization algorithms. For strongly convex and smooth objectives, we prove that gradient descent with output perturbation not only achieves nearly optimal utility, but also significantly improves the running time of previous state-of-the-art private optimization algorithms, for both $\epsilon$-DP and $(\epsilon, \delta)$-DP. For non-convex but smooth objectives, we propose an RRPSGD (Random Round Private Stochastic Gradient Descent) algorithm, which provably converges to a stationary point with privacy guarantee. Besides the expected utility bounds, we also provide guarantees in high probability form. Experiments demonstrate that our algorithm consistently outperforms existing method in both utility and running time. version:1
arxiv-1703-09933 | Sentiment Recognition in Egocentric Photostreams | http://arxiv.org/abs/1703.09933 | id:1703.09933 author:Estefania Talavera, Nicola Strisciuglio, Nicolai Petkov, Petia Radeva category:cs.CV  published:2017-03-29 summary:Lifelogging is a process of collecting rich source of information about daily life of people. In this paper, we introduce the problem of sentiment analysis in egocentric events focusing on the moments that compose the images recalling positive, neutral or negative feelings to the observer. We propose a method for the classification of the sentiments in egocentric pictures based on global and semantic image features extracted by Convolutional Neural Networks. We carried out experiments on an egocentric dataset, which we organized in 3 classes on the basis of the sentiment that is recalled to the user (positive, negative or neutral). version:1
arxiv-1703-09930 | Adaptive Gaussian process approximation for Bayesian inference with expensive likelihood functions | http://arxiv.org/abs/1703.09930 | id:1703.09930 author:Hongqiao Wang, Jinglai Li category:stat.CO stat.ML  published:2017-03-29 summary:We consider Bayesian inference problems with computationally intensive likelihood functions. We propose a Gaussian process (GP) based method to approximate the joint distribution of the unknown parameters and the data. In particular, we write the joint density approximately as a product of an approximate posterior density and an exponentiated GP surrogate. We then provide an adaptive algorithm to construct such an approximation, where an active learning method is used to choose the design points. With numerical examples, we illustrate that the proposed method has competitive performance against existing approaches for Bayesian computation. version:1
arxiv-1703-09926 | Hierarchical Surrogate Modeling for Illumination Algorithms | http://arxiv.org/abs/1703.09926 | id:1703.09926 author:Alexander Hagg category:cs.NE  published:2017-03-29 summary:Evolutionary illumination is a recent technique that allows producing many diverse, optimal solutions in a map of manually defined features. To support the large amount of objective function evaluations, surrogate model assistance was recently introduced. Illumination models need to represent many more, diverse optimal regions than classical surrogate models. In this PhD thesis, we propose to decompose the sample set, decreasing model complexity, by hierarchically segmenting the training set according to their coordinates in feature space. An ensemble of diverse models can then be trained to serve as a surrogate to illumination. version:1
arxiv-1703-09916 | Towards thinner convolutional neural networks through Gradually Global Pruning | http://arxiv.org/abs/1703.09916 | id:1703.09916 author:Zhengtao Wang, Ce Zhu, Zhiqiang Xia, Qi Guo, Yipeng Liu category:cs.CV  published:2017-03-29 summary:Deep network pruning is an effective method to reduce the storage and computation cost of deep neural networks when applying them to resource-limited devices. Among many pruning granularities, neuron level pruning will remove redundant neurons and filters in the model and result in thinner networks. In this paper, we propose a gradually global pruning scheme for neuron level pruning. In each pruning step, a small percent of neurons were selected and dropped across all layers in the model. We also propose a simple method to eliminate the biases in evaluating the importance of neurons to make the scheme feasible. Compared with layer-wise pruning scheme, our scheme avoid the difficulty in determining the redundancy in each layer and is more effective for deep networks. Our scheme would automatically find a thinner sub-network in original network under a given performance. version:1
arxiv-1703-09913 | Who's Better, Who's Best: Skill Determination in Video using Deep Ranking | http://arxiv.org/abs/1703.09913 | id:1703.09913 author:Hazel Doughty, Dima Damen, Walterio Mayol-Cuevas category:cs.CV  published:2017-03-29 summary:This paper presents a method for assessing skill of performance from video, for a variety of tasks, ranging from drawing to surgery and rolling dough. We formulate the problem as pairwise and overall ranking of video collections, and propose a supervised deep ranking model to learn discriminative features between pairs of videos exhibiting different amounts of skill. We utilise a two-stream Temporal Segment Network to capture both the type and quality of motions and the evolving task state. Results demonstrate our method is applicable to a variety of tasks, with the percentage of correctly ordered pairs of videos ranging from 70% to 82% for four datasets. We demonstrate the robustness of our approach via sensitivity analysis of its parameters. We see this work as effort toward the automated and objective organisation of how-to videos and overall, generic skill determination in video. version:1
arxiv-1703-09912 | One Network to Solve Them All --- Solving Linear Inverse Problems using Deep Projection Models | http://arxiv.org/abs/1703.09912 | id:1703.09912 author:J. H. Rick Chang, Chun-Liang Li, Barnabas Poczos, B. V. K. Vijaya Kumar, Aswin C. Sankaranarayanan category:cs.CV I.4.5  published:2017-03-29 summary:While deep learning methods have achieved state-of-the-art performance in many challenging inverse problems like image inpainting and super-resolution, they invariably involve problem-specific training of the networks. Under this approach, different problems require different networks. In scenarios where we need to solve a wide variety of problems, e.g., on a mobile camera, it is inefficient and costly to use these specially-trained networks. On the other hand, traditional methods using signal priors can be used in all linear inverse problems but often have worse performance on challenging tasks. In this work, we provide a middle ground between the two kinds of methods --- we propose a general framework to train a single deep neural network that solves arbitrary linear inverse problems. The proposed network acts as a proximal operator for an optimization algorithm and projects non-image signals onto the set of natural images defined by the decision boundary of a classifier. In our experiments, the proposed framework demonstrates superior performance over traditional methods using a wavelet sparsity prior and achieves comparable performance of specially-trained networks on tasks including compressive sensing and pixel-wise inpainting. version:1
arxiv-1703-09911 | Learning with Privileged Information for Multi-Label Classification | http://arxiv.org/abs/1703.09911 | id:1703.09911 author:Shiyu Chen, Shangfei Wang, Tanfang Chen, Xiaoxiao Shi category:cs.CV  published:2017-03-29 summary:In this paper, we propose a novel approach for learning multi-label classifiers with the help of privileged information. Specifically, we use similarity constraints to capture the relationship between available information and privileged information, and use ranking constraints to capture the dependencies among multiple labels. By integrating similarity constraints and ranking constraints into the learning process of classifiers, the privileged information and the dependencies among multiple labels are exploited to construct better classifiers during training. A maximum margin classifier is adopted, and an efficient learning algorithm of the proposed method is also developed. We evaluate the proposed method on two applications: multiple object recognition from images with the help of implicit information about object importance conveyed by the list of manually annotated image tags; and multiple facial action unit detection from low-resolution images augmented by high-resolution images. Experimental results demonstrate that the proposed method can effectively take full advantage of privileged information and dependencies among multiple labels for better object recognition and better facial action unit detection. version:1
arxiv-1703-09902 | Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation | http://arxiv.org/abs/1703.09902 | id:1703.09902 author:Albert Gatt, Emiel Krahmer category:cs.CL cs.AI cs.NE I.2.7; H.5  published:2017-03-29 summary:This paper surveys the current state of the art in Natural Language Generation (NLG), defined as the task of generating text or speech from non-linguistic input. A survey of NLG is timely in view of the changes that the field has undergone over the past decade or so, especially in relation to new (usually data-driven) methods, as well as new applications of NLG technology. This survey therefore aims to (a) give an up-to-date synthesis of research on the core tasks in NLG and the architectures adopted in which such tasks are organised; (b) highlight a number of relatively recent research topics that have arisen partly as a result of growing synergies between NLG and other areas of artificial intelligence; (c) draw attention to the challenges in NLG evaluation, relating them to similar challenges faced in other areas of Natural Language Processing, with an emphasis on different evaluation methods and the relationships between them. version:1
arxiv-1703-09891 | LabelBank: Revisiting Global Perspectives for Semantic Segmentation | http://arxiv.org/abs/1703.09891 | id:1703.09891 author:Hexiang Hu, Zhiwei Deng, Guang-Tong Zhou, Fei Sha, Greg Mori category:cs.CV cs.AI cs.LG  published:2017-03-29 summary:Semantic segmentation requires a detailed labeling of image pixels by object category. Information derived from local image patches is necessary to describe the detailed shape of individual objects. However, this information is ambiguous and can result in noisy labels. Global inference of image content can instead capture the general semantic concepts present. We advocate that holistic inference of image concepts provides valuable information for detailed pixel labeling. We propose a generic framework to leverage holistic information in the form of a LabelBank for pixel-level segmentation. We show the ability of our framework to improve semantic segmentation performance in a variety of settings. We learn models for extracting a holistic LabelBank from visual cues, attributes, and/or textual descriptions. We demonstrate improvements in semantic segmentation accuracy on standard datasets across a range of state-of-the-art segmentation architectures and holistic inference approaches. version:1
arxiv-1703-09880 | Novel Structured Low-rank algorithm to recover spatially smooth exponential image time series | http://arxiv.org/abs/1703.09880 | id:1703.09880 author:Arvind Balachandrasekaran, Mathews Jacob category:cs.CV  published:2017-03-29 summary:We propose a structured low rank matrix completion algorithm to recover a time series of images consisting of linear combination of exponential parameters at every pixel, from under-sampled Fourier measurements. The spatial smoothness of these parameters is exploited along with the exponential structure of the time series at every pixel, to derive an annihilation relation in the $k-t$ domain. This annihilation relation translates into a structured low rank matrix formed from the $k-t$ samples. We demonstrate the algorithm in the parameter mapping setting and show significant improvement over state of the art methods. version:1
arxiv-1703-09865 | Experience-based Optimization: A Coevolutionary Approach | http://arxiv.org/abs/1703.09865 | id:1703.09865 author:Shengcai Liu, Ke Tang, Xin Yao category:cs.NE  published:2017-03-29 summary:This paper studies improving solvers based on their past solving experiences, and focuses on improving solvers by offline training. Specifically, the key issues of offline training methods are discussed, and research belonging to this category but from different areas are reviewed in a unified framework. Existing training methods generally adopt a two-stage strategy in which selecting the training instances and training instances are treated in two independent phases. This paper proposes a new training method, dubbed LiangYi, which addresses these two issues simultaneously. LiangYi includes a training module for a population-based solver and an instance sampling module for updating the training instances. The idea behind LiangYi is to promote the population-based solver by training it (with the training module) to improve its performance on those instances (discovered by the sampling module) on which it performs badly, while keeping the good performances obtained by it on previous instances. An instantiation of LiangYi on the Travelling Salesman Problem is also proposed. Empirical results on a huge testing set containing 10000 instances showed LiangYi could train solvers that perform significantly better than the solvers trained by other state-of-the-art training method. Moreover, empirical investigation of the behaviours of LiangYi confirmed it was able to continuously improve the solver through training. version:1
arxiv-1703-09859 | Click Here: Human-Localized Keypoints as Guidance for Viewpoint Estimation | http://arxiv.org/abs/1703.09859 | id:1703.09859 author:Ryan Szeto, Jason J. Corso category:cs.CV  published:2017-03-29 summary:We motivate and address a human-in-the-loop variant of the monocular viewpoint estimation task in which the location and class of one semantic object keypoint is available at test time. In order to leverage the keypoint information, we devise a Convolutional Neural Network called Click-Here CNN (CH-CNN) that integrates the keypoint information with activations from the layers that process the image. It transforms the keypoint information into a 2D map that can be used to weigh features from certain parts of the image more heavily. The weighted sum of these spatial features is combined with global image features to provide relevant information to the prediction layers. To train our network, we collect a novel dataset of 3D keypoint annotations on thousands of CAD models, and synthetically render millions of images with 2D keypoint information. On test instances from PASCAL 3D+, our model achieves a mean class accuracy of 90.7%, whereas the state-of-the-art baseline only obtains 85.7% accuracy, justifying our argument for human-in-the-loop inference. version:1
arxiv-1703-09856 | Automatic Detection of Knee Joints and Quantification of Knee Osteoarthritis Severity using Convolutional Neural Networks | http://arxiv.org/abs/1703.09856 | id:1703.09856 author:Joseph Antony, Kevin McGuinness, Kieran Moran, Noel E O'Connor category:cs.CV  published:2017-03-29 summary:This paper introduces a new approach to automatically quantify the severity of knee OA using X-ray images. Automatically quantifying knee OA severity involves two steps: first, automatically localizing the knee joints; next, classifying the localized knee joint images. We introduce a new approach to automatically detect the knee joints using a fully convolutional neural network (FCN). We train convolutional neural networks (CNN) from scratch to automatically quantify the knee OA severity optimizing a weighted ratio of two loss functions: categorical cross-entropy and mean-squared loss. This joint training further improves the overall quantification of knee OA severity, with the added benefit of naturally producing simultaneous multi-class classification and regression outputs. Two public datasets are used to evaluate our approach, the Osteoarthritis Initiative (OAI) and the Multicenter Osteoarthritis Study (MOST), with extremely promising results that outperform existing approaches. version:1
arxiv-1703-09851 | Solar Power Forecasting Using Support Vector Regression | http://arxiv.org/abs/1703.09851 | id:1703.09851 author:Mohamed Abuella, Badrul Chowdhury category:cs.LG cs.CE stat.AP  published:2017-03-29 summary:Generation and load balance is required in the economic scheduling of generating units in the smart grid. Variable energy generations, particularly from wind and solar energy resources, are witnessing a rapid boost, and, it is anticipated that with a certain level of their penetration, they can become noteworthy sources of uncertainty. As in the case of load demand, energy forecasting can also be used to mitigate some of the challenges that arise from the uncertainty in the resource. While wind energy forecasting research is considered mature, solar energy forecasting is witnessing a steadily growing attention from the research community. This paper presents a support vector regression model to produce solar power forecasts on a rolling basis for 24 hours ahead over an entire year, to mimic the practical business of energy forecasting. Twelve weather variables are considered from a high-quality benchmark dataset and new variables are extracted. The added value of the heat index and wind speed as additional variables to the model is studied across different seasons. The support vector regression model performance is compared with artificial neural networks and multiple linear regression models for energy forecasting. version:1
arxiv-1703-09844 | Multi-Scale Dense Convolutional Networks for Efficient Prediction | http://arxiv.org/abs/1703.09844 | id:1703.09844 author:Gao Huang, Danlu Chen, Tianhong Li, Felix Wu, Laurens van der Maaten, Kilian Q. Weinberger category:cs.LG  published:2017-03-29 summary:This paper studies convolutional networks that require limited computational resources at test time. We develop a new network architecture that performs on par with state-of-the-art convolutional networks, whilst facilitating prediction in two settings: (1) an anytime-prediction setting in which the network's prediction for one example is progressively updated, facilitating the output of a prediction at any time; and (2) a batch computational budget setting in which a fixed amount of computation is available to classify a set of examples that can be spent unevenly across 'easier' and 'harder' examples. Our network architecture uses multi-scale convolutions and progressively growing feature representations, which allows for the training of multiple classifiers at intermediate layers of the network. Experiments on three image-classification datasets demonstrate the efficacy of our architecture, in particular, when measured in terms of classification accuracy as a function of the amount of compute available. version:1
arxiv-1703-09833 | Theory II: Landscape of the Empirical Risk in Deep Learning | http://arxiv.org/abs/1703.09833 | id:1703.09833 author:Tomaso Poggio, Qianli Liao category:cs.LG cs.CV cs.NE  published:2017-03-28 summary:Previous theoretical work on deep learning and neural network optimization tend to focus on avoiding saddle points and local minima. However, the practical observation is that, at least for the most successful Deep Convolutional Neural Networks (DCNNs) for visual processing, practitioners can always increase the network size to fit the training data (an extreme example would be [1]). The most successful DCNNs such as VGG and ResNets are best used with a small degree of "overparametrization". In this work, we characterize with a mix of theory and experiments, the landscape of the empirical risk of overparametrized DCNNs. We first prove the existence of a large number of degenerate global minimizers with zero empirical error (modulo inconsistent equations). The zero-minimizers -- in the case of classification -- have a non-zero margin. The same minimizers are degenerate and thus very likely to be found by SGD that will furthermore select with higher probability the zero-minimizer with larger margin, as discussed in Theory III (to be released). We further experimentally explored and visualized the landscape of empirical risk of a DCNN on CIFAR-10 during the entire training process and especially the global minima. Finally, based on our theoretical and experimental results, we propose an intuitive model of the landscape of DCNN's empirical loss surface, which might not be as complicated as people commonly believe. version:1
arxiv-1703-09825 | Semi-Supervised Affective Meaning Lexicon Expansion Using Semantic and Distributed Word Representations | http://arxiv.org/abs/1703.09825 | id:1703.09825 author:Areej Alhothali, Jesse Hoey category:cs.CL  published:2017-03-28 summary:In this paper, we propose an extension to graph-based sentiment lexicon induction methods by incorporating distributed and semantic word representations in building the similarity graph to expand a three-dimensional sentiment lexicon. We also implemented and evaluated the label propagation using four different word representations and similarity metrics. Our comprehensive evaluation of the four approaches was performed on a single data set, demonstrating that all four methods can generate a significant number of new sentiment assignments with high accuracy. The highest correlations (tau=0.51) and the lowest error (mean absolute error < 1.1%), obtained by combining both the semantic and the distributional features, outperformed the distributional-based and semantic-based label-propagation models and approached a supervised algorithm. version:1
arxiv-1703-09817 | Learning Similarity Function for Pronunciation Variations | http://arxiv.org/abs/1703.09817 | id:1703.09817 author:Einat Naaman, Yossi Adi, Joseph Keshet category:cs.CL  published:2017-03-28 summary:A significant source of errors in Automatic Speech Recognition (ASR) systems is due to pronunciation variations which occur in spontaneous and conversational speech. Usually ASR systems use a finite lexicon that provides one or more pronunciations for each word. In this paper, we focus on learning a similarity function between two pronunciations. The pronunciation can be the canonical and the surface pronunciations of the same word or it can be two surface pronunciations of different words. This task generalizes problems such as lexical access (the problem of learning the mapping between words and their possible pronunciations), and defining word neighborhoods. It can also be used to dynamically increase the size of the pronunciation lexicon, or in predicting ASR errors. We propose two methods, which are based on recurrent neural networks, to learn the similarity function. The first is based on binary classification, and the second is based on learning the ranking of the pronunciations. We demonstrate the efficiency of our approach on the task of lexical access using a subset from the Switchboard conversational speech corpus. Results suggest that our method is superior to previous methods which are based on graphical Bayesian methods. version:1
arxiv-1703-09813 | Gradient-based Regularization Parameter Selection for Problems with Non-smooth Penalty Functions | http://arxiv.org/abs/1703.09813 | id:1703.09813 author:Jean Feng, Noah Simon category:stat.ML  published:2017-03-28 summary:In high-dimensional and/or non-parametric regression problems, regularization (or penalization) is used to control model complexity and induce desired structure. Each penalty has a weight parameter that indicates how strongly the structure corresponding to that penalty should be enforced. Typically the parameters are chosen to minimize the error on a separate validation set using a simple grid search or a gradient-free optimization method. It is more efficient to tune parameters if the gradient can be determined, but this is often difficult for problems with non-smooth penalty functions. Here we show that for many penalized regression problems, the validation loss is actually smooth almost-everywhere with respect to the penalty parameters. We can therefore apply a modified gradient descent algorithm to tune parameters. Through simulation studies on example regression problems, we find that increasing the number of penalty parameters and tuning them using our method can decrease the generalization error. version:1
arxiv-1703-09194 | Sticking the Landing: An Asymptotically Zero-Variance Gradient Estimator for Variational Inference | http://arxiv.org/abs/1703.09194 | id:1703.09194 author:Geoffrey Roeder, Yuhuai Wu, David Duvenaud category:stat.ML cs.LG  published:2017-03-27 summary:We propose a simple and general variant of the standard reparameterized gradient estimator for the variational evidence lower bound. Specifically, we remove a part of the total derivative with respect to the variational parameters that corresponds to the score function. Removing this term produces an unbiased gradient estimator whose variance approaches zero as the approximate posterior approaches the exact posterior. We analyze the behavior of this gradient estimator theoretically and empirically, and generalize it to more complex variational distributions such as mixtures and importance-weighted posteriors. version:2
arxiv-1703-09788 | ProcNets: Learning to Segment Procedures in Untrimmed and Unconstrained Videos | http://arxiv.org/abs/1703.09788 | id:1703.09788 author:Luowei Zhou, Chenliang Xu, Jason J. Corso category:cs.CV  published:2017-03-28 summary:We propose a temporal segmentation and procedure learning model for long untrimmed and unconstrained videos, e.g., videos from YouTube. The proposed model segments a video into segments that constitute a procedure and learns the underlying temporal dependency among the procedure segments. The output procedure segments can be applied for other tasks, such as video description generation or activity recognition. Two aspects distinguish our work from the existing literature. First, we introduce the problem of learning long-range temporal structure for procedure segments within a video, in contrast to the majority of efforts that focus on understanding short-range temporal structure. Second, the proposed model segments an unseen video with only visual evidence and can automatically determine the number of segments to predict. For evaluation, there is no large-scale dataset with annotated procedure steps available. Hence, we collect a new cooking video dataset, named YouCookII, with the procedure steps localized and described. Our ProcNets model achieves state-of-the-art performance in procedure segmentation. version:1
arxiv-1703-09775 | Deep scattering transform applied to note onset detection and instrument recognition | http://arxiv.org/abs/1703.09775 | id:1703.09775 author:D. Cazau, G. Revillon, O. Adam category:stat.ML cs.SD  published:2017-03-28 summary:Automatic Music Transcription (AMT) is one of the oldest and most well-studied problems in the field of music information retrieval. Within this challenging research field, onset detection and instrument recognition take important places in transcription systems, as they respectively help to determine exact onset times of notes and to recognize the corresponding instrument sources. The aim of this study is to explore the usefulness of multiscale scattering operators for these two tasks on plucked string instrument and piano music. After resuming the theoretical background and illustrating the key features of this sound representation method, we evaluate its performances comparatively to other classical sound representations. Using both MIDI-driven datasets with real instrument samples and real musical pieces, scattering is proved to outperform other sound representations for these AMT subtasks, putting forward its richer sound representation and invariance properties. version:1
arxiv-1703-09772 | Particle Filtering for PLCA model with Application to Music Transcription | http://arxiv.org/abs/1703.09772 | id:1703.09772 author:D. Cazau, G. Revillon, W. Yuancheng, O. Adam category:stat.ML cs.LG cs.SD  published:2017-03-28 summary:Automatic Music Transcription (AMT) consists in automatically estimating the notes in an audio recording, through three attributes: onset time, duration and pitch. Probabilistic Latent Component Analysis (PLCA) has become very popular for this task. PLCA is a spectrogram factorization method, able to model a magnitude spectrogram as a linear combination of spectral vectors from a dictionary. Such methods use the Expectation-Maximization (EM) algorithm to estimate the parameters of the acoustic model. This algorithm presents well-known inherent defaults (local convergence, initialization dependency), making EM-based systems limited in their applications to AMT, particularly in regards to the mathematical form and number of priors. To overcome such limits, we propose in this paper to employ a different estimation framework based on Particle Filtering (PF), which consists in sampling the posterior distribution over larger parameter ranges. This framework proves to be more robust in parameter estimation, more flexible and unifying in the integration of prior knowledge in the system. Note-level transcription accuracies of 61.8 $\%$ and 59.5 $\%$ were achieved on evaluation sound datasets of two different instrument repertoires, including the classical piano (from MAPS dataset) and the marovany zither, and direct comparisons to previous PLCA-based approaches are provided. Steps for further development are also outlined. version:1
arxiv-1703-09771 | Deep 6-DOF Tracking | http://arxiv.org/abs/1703.09771 | id:1703.09771 author:Mathieu Garon, Jean-François Lalonde category:cs.CV  published:2017-03-28 summary:We present a temporal 6-DOF tracking method which leverages deep learning to achieve state-of-the-art performance on challenging datasets of real world capture. Our method is both more accurate and more robust to occlusions than the existing best performing approaches while maintaining real-time performance. To assess its efficacy, we evaluate our approach on several challenging RGBD sequences of real objects in a variety of conditions. Notably, we systematically evaluate robustness to occlusions through a series of sequences where the object to be tracked is increasingly occluded. Finally, our approach is purely data-driven and does not require any hand-designed features: robust tracking is automatically learned from data. version:1
arxiv-1703-09766 | Unifying the Stochastic Spectral Descent for Restricted Boltzmann Machines with Bernoulli or Gaussian Inputs | http://arxiv.org/abs/1703.09766 | id:1703.09766 author:Kai Fan category:stat.ML cs.LG  published:2017-03-28 summary:Stochastic gradient descent based algorithms are typically used as the general optimization tools for most deep learning models. A Restricted Boltzmann Machine (RBM) is a probabilistic generative model that can be stacked to construct deep architectures. For RBM with Bernoulli inputs, non-Euclidean algorithm such as stochastic spectral descent (SSD) has been specifically designed to speed up the convergence with improved use of the gradient estimation by sampling methods. However, the existing algorithm and corresponding theoretical justification depend on the assumption that the possible configurations of inputs are finite, like binary variables. The purpose of this paper is to generalize SSD for Gaussian RBM being capable of mod- eling continuous data, regardless of the previous assumption. We propose the gradient descent methods in non-Euclidean space of parameters, via de- riving the upper bounds of logarithmic partition function for RBMs based on Schatten-infinity norm. We empirically show that the advantage and improvement of SSD over stochastic gradient descent (SGD). version:1
arxiv-1703-09752 | Collective Anomaly Detection based on Long Short Term Memory Recurrent Neural Network | http://arxiv.org/abs/1703.09752 | id:1703.09752 author:Loic Bontemps, Van Loi Cao, James McDermott, Nhien-An Le-Khac category:cs.LG cs.CR  published:2017-03-28 summary:Intrusion detection for computer network systems becomes one of the most critical tasks for network administrators today. It has an important role for organizations, governments and our society due to its valuable resources on computer networks. Traditional misuse detection strategies are unable to detect new and unknown intrusion. Besides, anomaly detection in network security is aim to distinguish between illegal or malicious events and normal behavior of network systems. Anomaly detection can be considered as a classification problem where it builds models of normal network behavior, which it uses to detect new patterns that significantly deviate from the model. Most of the cur- rent research on anomaly detection is based on the learning of normally and anomaly behaviors. They do not take into account the previous, re- cent events to detect the new incoming one. In this paper, we propose a real time collective anomaly detection model based on neural network learning and feature operating. Normally a Long Short Term Memory Recurrent Neural Network (LSTM RNN) is trained only on normal data and it is capable of predicting several time steps ahead of an input. In our approach, a LSTM RNN is trained with normal time series data before performing a live prediction for each time step. Instead of considering each time step separately, the observation of prediction errors from a certain number of time steps is now proposed as a new idea for detecting collective anomalies. The prediction errors from a number of the latest time steps above a threshold will indicate a collective anomaly. The model is built on a time series version of the KDD 1999 dataset. The experiments demonstrate that it is possible to offer reliable and efficient for collective anomaly detection. version:1
arxiv-1703-09746 | Coordinating Filters for Faster Deep Neural Networks | http://arxiv.org/abs/1703.09746 | id:1703.09746 author:Wei Wen, Cong Xu, Chunpeng Wu, Yandan Wang, Yiran Chen, Hai Li category:cs.CV I.2.6; I.5.1  published:2017-03-28 summary:Very large-scale Deep Neural Networks (DNNs) have achieved remarkable successes in a large variety of computer vision tasks. However, the high computation intensity of DNNs makes it challenging to deploy these models on resource-limited systems. Some studies used low-rank approaches that approximate the filters by low-rank basis to accelerate the testing. Those works directly decomposed the pre-trained DNNs by Low-Rank Approximations (LRA). How to train DNNs toward lower-rank space for more efficient DNNs, however, remains as an open area. To solve the issue, in this work, we propose Force Regularization, which uses attractive forces to enforce filters so as to coordinate more weight information into lower-rank space. We mathematically and empirically prove that after applying our technique, standard LRA methods can reconstruct filters using much lower basis and thus result in faster DNNs. The effectiveness of our approach is comprehensively evaluated in ResNets, AlexNet, and GoogLeNet. In AlexNet, for example, Force Regularization gains 2x speedup on modern GPU without accuracy loss and 4.05x speedup on CPU by paying small accuracy degradation. Moreover, Force Regularization better initializes the low-rank DNNs such that the fine-tuning can converge faster toward higher accuracy. The obtained lower-rank DNNs can be further sparsified, proving that Force Regularization can be integrated with state-of-the-art sparsity-based acceleration methods. version:1
arxiv-1703-09744 | Feature Analysis and Selection for Training an End-to-End Autonomous Vehicle Controller Using the Deep Learning Approach | http://arxiv.org/abs/1703.09744 | id:1703.09744 author:Shun Yang, Wenshuo Wang, Chang Liu, Kevin Deng, J. Karl Hedrick category:cs.CV cs.SY  published:2017-03-28 summary:Deep learning-based approaches have been widely used for training controllers for autonomous vehicles due to their powerful ability to approximate nonlinear functions or policies. However, the training process usually requires large labeled data sets and takes a lot of time. In this paper, we analyze the influences of features on the performance of controllers trained using the convolutional neural networks (CNNs), which gives a guideline of feature selection to reduce computation cost. We collect a large set of data using The Open Racing Car Simulator (TORCS) and classify the image features into three categories (sky-related, roadside-related, and road-related features).We then design two experimental frameworks to investigate the importance of each single feature for training a CNN controller.The first framework uses the training data with all three features included to train a controller, which is then tested with data that has one feature removed to evaluate the feature's effects. The second framework is trained with the data that has one feature excluded, while all three features are included in the test data. Different driving scenarios are selected to test and analyze the trained controllers using the two experimental frameworks. The experiment results show that (1) the road-related features are indispensable for training the controller, (2) the roadside-related features are useful to improve the generalizability of the controller to scenarios with complicated roadside information, and (3) the sky-related features have limited contribution to train an end-to-end autonomous vehicle controller. version:1
arxiv-1703-09725 | An Epipolar Line from a Single Pixel | http://arxiv.org/abs/1703.09725 | id:1703.09725 author:Tavi Halperin, Michael Werman category:cs.CV  published:2017-03-28 summary:We exploit the following observation to directly find epipolar lines. For a pixel p in Image A all pixels corresponding to p in Image B are on the same epipolar line, or equivalently the image of the line spanning A's center and p is an epipolar line in B. Computing the epipolar geometry from feature points between cameras with very different viewpoints is often error prone as an object's appearance can vary greatly between images. This paper extends earlier work based on the dynamics of the scene which was successful in these cases. The algorithms introduced here for finding corresponding epipolar lines accelerate and robustify previous methods for computing the epipolar geometry in dynamic scenes. version:1
arxiv-1703-09695 | Semi and Weakly Supervised Semantic Segmentation Using Generative Adversarial Network | http://arxiv.org/abs/1703.09695 | id:1703.09695 author:Nasim Souly, Concetto Spampinato, Mubarak Shah category:cs.CV  published:2017-03-28 summary:Semantic segmentation has been a long standing challenging task in computer vision. It aims at assigning a label to each image pixel and needs significant number of pixellevel annotated data, which is often unavailable. To address this lack, in this paper, we leverage, on one hand, massive amount of available unlabeled or weakly labeled data, and on the other hand, non-real images created through Generative Adversarial Networks. In particular, we propose a semi-supervised framework ,based on Generative Adversarial Networks (GANs), which consists of a generator network to provide extra training examples to a multi-class classifier, acting as discriminator in the GAN framework, that assigns sample a label y from the K possible classes or marks it as a fake sample (extra class). The underlying idea is that adding large fake visual data forces real samples to be close in the feature space, enabling a bottom-up clustering process, which, in turn, improves multiclass pixel classification. To ensure higher quality of generated images for GANs with consequent improved pixel classification, we extend the above framework by adding weakly annotated data, i.e., we provide class level information to the generator. We tested our approaches on several challenging benchmarking visual datasets, i.e. PASCAL, SiftFLow, Stanford and CamVid, achieving competitive performance also compared to state-of-the-art semantic segmentation method version:1
arxiv-1703-09690 | Efficient Two-Dimensional Sparse Coding Using Tensor-Linear Combination | http://arxiv.org/abs/1703.09690 | id:1703.09690 author:Fei Jiang, Xiao-Yang Liu, Hongtao Lu, Ruimin Shen category:cs.CV  published:2017-03-28 summary:Sparse coding (SC) is an automatic feature extraction and selection technique that is widely used in unsupervised learning. However, conventional SC vectorizes the input images, which breaks apart the local proximity of pixels and destructs the elementary object structures of images. In this paper, we propose a novel two-dimensional sparse coding (2DSC) scheme that represents the input images as the tensor-linear combinations under a novel algebraic framework. 2DSC learns much more concise dictionaries because it uses the circular convolution operator, since the shifted versions of atoms learned by conventional SC are treated as the same ones. We apply 2DSC to natural images and demonstrate that 2DSC returns meaningful dictionaries for large patches. Moreover, for mutli-spectral images denoising, the proposed 2DSC reduces computational costs with competitive performance in comparison with the state-of-the-art algorithms. version:1
arxiv-1703-09684 | An Analysis of Visual Question Answering Algorithms | http://arxiv.org/abs/1703.09684 | id:1703.09684 author:Kushal Kafle, Christopher Kanan category:cs.CV cs.AI cs.CL  published:2017-03-28 summary:In visual question answering (VQA), an algorithm must answer text-based questions about images. While multiple datasets for VQA have been created since late 2014, they all have flaws in both their content and the way algorithms are evaluated on them. As a result, evaluation scores are inflated and predominantly determined by answering easier questions, making it difficult to compare different methods. In this paper, we analyze existing VQA algorithms using a new dataset. It contains over 1.6 million questions organized into 12 different categories. We also introduce questions that are meaningless for a given image to force a VQA system to reason about image content. We propose new evaluation schemes that compensate for over-represented question-types and make it easier to study the strengths and weaknesses of algorithms. We analyze the performance of both baseline and state-of-the-art VQA models, including multi-modal compact bilinear pooling (MCB), neural module networks, and recurrent answering units. Our experiments establish how attention helps certain categories more than others, determine which models work better than others, and explain how simple models (e.g. MLP) can surpass more complex models (MCB) by simply learning to answer large, easy question categories. version:1
arxiv-1703-09700 | Inverse Reinforcement Learning from Summary Data | http://arxiv.org/abs/1703.09700 | id:1703.09700 author:Antti Kangasrääsiö, Samuel Kaski category:cs.LG cs.AI stat.ML  published:2017-03-28 summary:Inverse reinforcement learning (IRL) aims to explain observed complex behavior by fitting reinforcement learning models to behavioral data. However, traditional IRL methods are only applicable when the observations are in the form of state-action paths. This is a problem in many real-world modelling settings, where only more limited observations are easily available. To address this issue, we extend the traditional IRL problem formulation. We call this new formulation the inverse reinforcement learning from summary data (IRL-SD) problem, where instead of state-action paths, only summaries of the paths are observed. We propose exact and approximate methods for both maximum likelihood and full posterior estimation for IRL-SD problems. Through case studies we compare these methods, demonstrating that the approximate methods can be used to solve moderate-sized IRL-SD problems in reasonable time. version:1
arxiv-1703-09646 | Hybrid Clustering based on Content and Connection Structure using Joint Nonnegative Matrix Factorization | http://arxiv.org/abs/1703.09646 | id:1703.09646 author:Rundong Du, Barry Drake, Haesun Park category:cs.LG stat.ML  published:2017-03-28 summary:We present a hybrid method for latent information discovery on the data sets containing both text content and connection structure based on constrained low rank approximation. The new method jointly optimizes the Nonnegative Matrix Factorization (NMF) objective function for text clustering and the Symmetric NMF (SymNMF) objective function for graph clustering. We propose an effective algorithm for the joint NMF objective function, based on a block coordinate descent (BCD) framework. The proposed hybrid method discovers content associations via latent connections found using SymNMF. The method can also be applied with a natural conversion of the problem when a hypergraph formulation is used or the content is associated with hypergraph edges. Experimental results show that by simultaneously utilizing both content and connection structure, our hybrid method produces higher quality clustering results compared to the other NMF clustering methods that uses content alone (standard NMF) or connection structure alone (SymNMF). We also present some interesting applications to several types of real world data such as citation recommendations of papers. The hybrid method proposed in this paper can also be applied to general data expressed with both feature space vectors and pairwise similarities and can be extended to the case with multiple feature spaces or multiple similarity measures. version:1
arxiv-1703-09631 | Algebraic Variety Models for High-Rank Matrix Completion | http://arxiv.org/abs/1703.09631 | id:1703.09631 author:Greg Ongie, Rebecca Willett, Robert D. Nowak, Laura Balzano category:stat.ML  published:2017-03-28 summary:We consider a generalization of low-rank matrix completion to the case where the data belongs to an algebraic variety, i.e. each data point is a solution to a system of polynomial equations. In this case the original matrix is possibly high-rank, but it becomes low-rank after mapping each column to a higher dimensional space of monomial features. Many well-studied extensions of linear models, including affine subspaces and their union, can be described by a variety model. In addition, varieties can be used to model a richer class of nonlinear quadratic and higher degree curves and surfaces. We study the sampling requirements for matrix completion under a variety model with a focus on a union of affine subspaces. We also propose an efficient matrix completion algorithm that minimizes a convex or non-convex surrogate of the rank of the matrix of monomial features. Our algorithm uses the well-known "kernel trick" to avoid working directly with the high-dimensional monomial matrix. We show the proposed algorithm is able to recover synthetically generated data up to the predicted sampling complexity bounds. The proposed algorithm also outperforms standard low rank matrix completion and subspace clustering techniques in experiments with real data. version:1
arxiv-1703-08098 | An overview of embedding models of entities and relationships for knowledge base completion | http://arxiv.org/abs/1703.08098 | id:1703.08098 author:Dat Quoc Nguyen category:cs.CL cs.AI cs.IR  published:2017-03-23 summary:Knowledge bases of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge bases are typically incomplete, it is useful to be able to perform knowledge base completion, i.e., predict whether a relationship not in the knowledge base is likely to be true. This article presents an overview of embedding models of entities and relationships for knowledge base completion, with up-to-date experimental results on two standard evaluation tasks of link prediction (i.e. entity prediction) and triple classification. version:2
arxiv-1703-10252 | Linguistic Matrix Theory | http://arxiv.org/abs/1703.10252 | id:1703.10252 author:Dimitrios Kartsaklis, Sanjaye Ramgoolam, Mehrnoosh Sadrzadeh category:cs.CL hep-th math.CO  published:2017-03-28 summary:Recent research in computational linguistics has developed algorithms which associate matrices with adjectives and verbs, based on the distribution of words in a corpus of text. These matrices are linear operators on a vector space of context words. They are used to construct the meaning of composite expressions from that of the elementary constituents, forming part of a compositional distributional approach to semantics. We propose a Matrix Theory approach to this data, based on permutation symmetry along with Gaussian weights and their perturbations. A simple Gaussian model is tested against word matrices created from a large corpus of text. We characterize the cubic and quartic departures from the model, which we propose, alongside the Gaussian parameters, as signatures for comparison of linguistic corpora. We propose that perturbed Gaussian models with permutation symmetry provide a promising framework for characterizing the nature of universality in the statistical properties of word matrices. The matrix theory framework developed here exploits the view of statistics as zero dimensional perturbative quantum field theory. It perceives language as a physical system realizing a universality class of matrix statistics characterized by permutation symmetry. version:1
arxiv-1703-09580 | Early Stopping without a Validation Set | http://arxiv.org/abs/1703.09580 | id:1703.09580 author:Maren Mahsereci, Lukas Balles, Christoph Lassner, Philipp Hennig category:cs.LG stat.ML  published:2017-03-28 summary:Early stopping is a widely used technique to prevent poor generalization performance when training an over-expressive model by means of gradient-based optimization. To find a good point to halt the optimizer, a common practice is to split the dataset into a training and a smaller validation set to obtain an ongoing estimate of the generalization performance. In this paper we propose a novel early stopping criterion which is based on fast-to-compute, local statistics of the computed gradients and entirely removes the need for a held-out validation set. Our experiments show that this is a viable approach in the setting of least-squares and logistic regression as well as neural networks. version:1
arxiv-1703-07684 | Predicting Deeper into the Future of Semantic Segmentation | http://arxiv.org/abs/1703.07684 | id:1703.07684 author:Natalia Neverova, Pauline Luc, Camille Couprie, Jakob Verbeek, Yann LeCun category:cs.CV cs.LG  published:2017-03-22 summary:The ability to predict and therefore to anticipate the future is an important attribute of intelligence. It is also of utmost importance in real-time systems, e.g. in robotics or autonomous driving, which depend on visual scene understanding for decision making. While prediction of the raw RGB pixel values in future video frames has been studied in previous work, here we focus on predicting semantic segmentations of future frames. More precisely, given a sequence of semantically segmented video frames, our goal is to predict segmentation maps of not yet observed video frames that lie up to a second or further in the future. We develop an autoregressive convolutional neural network that learns to iteratively generate multiple frames. Our results on the Cityscapes dataset show that directly predicting future segmentations is substantially better than predicting and then segmenting future RGB frames. Our best model predicts trajectories of cars and pedestrians much more accurately than baselines that copy the most recent semantic segmentation (25%) or warp it using optical flow (10%). Prediction results up to half a second in the future are visually convincing, the mean IoU of predicted segmentations reaching two thirds of the real future segmentations. version:2
arxiv-1703-07523 | Deeply-Supervised CNN for Prostate Segmentation | http://arxiv.org/abs/1703.07523 | id:1703.07523 author:Qikui Zhu, Bo Du, Baris Turkbey, Peter L . Choyke, Pingkun Yan category:cs.CV  published:2017-03-22 summary:Prostate segmentation from Magnetic Resonance (MR) images plays an important role in image guided interven- tion. However, the lack of clear boundary specifically at the apex and base, and huge variation of shape and texture between the images from different patients make the task very challenging. To overcome these problems, in this paper, we propose a deeply supervised convolutional neural network (CNN) utilizing the convolutional information to accurately segment the prostate from MR images. The proposed model can effectively detect the prostate region with additional deeply supervised layers compared with other approaches. Since some information will be abandoned after convolution, it is necessary to pass the features extracted from early stages to later stages. The experimental results show that significant segmentation accuracy improvement has been achieved by our proposed method compared to other reported approaches. version:3
arxiv-1703-09554 | Lucid Data Dreaming for Object Tracking | http://arxiv.org/abs/1703.09554 | id:1703.09554 author:Anna Khoreva, Rodrigo Benenson, Eddy Ilg, Thomas Brox, Bernt Schiele category:cs.CV  published:2017-03-28 summary:Convolutional networks reach top quality in pixel-level object tracking but require a large amount of training data (1k ~ 10k) to deliver such results. We propose a new training strategy which achieves state-of-the-art results across three evaluation datasets while using 20x ~ 100x less annotated data than competing methods. Instead of using large training sets hoping to generalize across domains, we generate in-domain training data using the provided annotation on the first frame of each video to synthesize ("lucid dream") plausible future video frames. In-domain per-video training data allows us to train high quality appearance- and motion-based models, as well as tune the post-processing stage. This approach allows to reach competitive results even when training from only a single annotated frame, without ImageNet pre-training. Our results indicate that using a larger training set is not automatically better, and that for the tracking task a smaller training set that is closer to the target domain is more effective. This changes the mindset regarding how many training samples and general "objectness" knowledge are required for the object tracking task. version:1
arxiv-1703-09550 | Important New Developments in Arabographic Optical Character Recognition (OCR) | http://arxiv.org/abs/1703.09550 | id:1703.09550 author:Maxim Romanov, Matthew Thomas Miller, Sarah Bowen Savant, Benjamin Kiessling category:cs.CV cs.DL  published:2017-03-28 summary:The OpenITI team has achieved Optical Character Recognition (OCR) accuracy rates for classical Arabic-script texts in the high nineties. These numbers are based on our tests of seven different Arabic-script texts of varying quality and typefaces, totaling over 7,000 lines. These accuracy rates not only represent a distinct improvement over the actual accuracy rates of the various proprietary OCR options for classical Arabic-script texts, but, equally important, they are produced using an open-source OCR software, thus enabling us to make this Arabic-script OCR technology freely available to the broader Islamic, Persian, and Arabic Studies communities. version:1
arxiv-1703-09529 | Objects as context for part detection | http://arxiv.org/abs/1703.09529 | id:1703.09529 author:Abel Gonzalez-Garcia, Davide Modolo, Vittorio Ferrari category:cs.CV  published:2017-03-28 summary:We present a semantic part detection approach that effectively leverages object information. We use the object appearance and its class as indicators of what parts to expect. We also model the expected relative location of parts inside the objects based on their appearance. We achieve this with a new network module, called OffsetNet, that efficiently predicts a variable number of part locations within a given object. Our model incorporates all these cues to detect parts in the context of their objects. This leads to significantly higher performance for the challenging task of part detection compared to using part appearance alone (+5 mAP on the PASCAL-Part dataset). We also compare to other part detection methods on both PASCAL-Part and CUB200-2011 datasets. version:1
arxiv-1703-09528 | A Nonparametric Bayesian Clustering to Discover Latent Covariance Structure of Multiple Time Series | http://arxiv.org/abs/1703.09528 | id:1703.09528 author:Anh Tong, Jaesik Choi category:stat.ML  published:2017-03-28 summary:Analyzing time series data is important to predict future events and changes in finance, manufacturing and administrative decisions. Gaussian processes (GPs) solve regression and classification problems by choosing appropriate kernels capturing covariance structure of data. In time series analysis, GP based regression methods recently demonstrate competitive performance by decomposing temporal covariance structure. Such covariance structure decomposition allows exploiting shared parameters over a set of multiple but selected time series. In this paper, we propose an efficient variational inference algorithm for nonparametric clustering over multiple GP covariance structures. We handle multiple time series by placing an Indian Buffet Process (IBP) prior on the presence of the additive shared kernels. We propose a new variational inference algorithm to learn the nonparametric Bayesian models for the clustering and regression problems. Experiments are conducted on both synthetic data sets and real world data sets, showing promising results in term of structure discoveries. In addition, our model learns GP kernels faster but still preserves a good predictive performance. version:1
arxiv-1703-09527 | Is This a Joke? Detecting Humor in Spanish Tweets | http://arxiv.org/abs/1703.09527 | id:1703.09527 author:Santiago Castro, Matías Cubero, Diego Garat, Guillermo Moncecchi category:cs.CL cs.AI  published:2017-03-28 summary:While humor has been historically studied from a psychological, cognitive and linguistic standpoint, its study from a computational perspective is an area yet to be explored in Computational Linguistics. There exist some previous works, but a characterization of humor that allows its automatic recognition and generation is far from being specified. In this work we build a crowdsourced corpus of labeled tweets, annotated according to its humor value, letting the annotators subjectively decide which are humorous. A humor classifier for Spanish tweets is assembled based on supervised learning, reaching a precision of 84% and a recall of 69%. version:1
arxiv-1703-09507 | L2-constrained Softmax Loss for Discriminative Face Verification | http://arxiv.org/abs/1703.09507 | id:1703.09507 author:Rajeev Ranjan, Carlos D. Castillo, Rama Chellappa category:cs.CV  published:2017-03-28 summary:In recent years, the performance of face verification systems has significantly improved using deep convolutional neural networks (DCNNs). A typical pipeline for face verification includes training a deep network for subject classification with softmax loss, using the penultimate layer output as the feature descriptor, and generating a cosine similarity score given a pair of face images. The softmax loss function does not optimize the features to have higher similarity score for positive pairs and lower similarity score for negative pairs, which leads to a performance gap. In this paper, we add an L2-constraint to the feature descriptors which restricts them to lie on a hypersphere of a fixed radius. This module can be easily implemented using existing deep learning frameworks. We show that integrating this simple step in the training pipeline significantly boosts the performance of face verification. Specifically, we achieve state-of-the-art results on the challenging IJB-A dataset, achieving True Accept Rates of 0.863 and 0.910 at False Accept Rates 0.0001 and 0.001 respectively on the face verification protocol. version:1
arxiv-1703-09499 | Locally Preserving Projection on Symmetric Positive Definite Matrix Lie Group | http://arxiv.org/abs/1703.09499 | id:1703.09499 author:Yangyang Li, Ruqian Lu category:cs.CV cs.NA F.2.2  published:2017-03-28 summary:Symmetric Positive Definite (SPD) matrices have been widely used as feature descriptors in image recognition. However, the dimension of an SPD matrix built by image feature descriptors is usually high. So SPD matrices oriented dimensionality reduction techniques are needed. The existing manifold learning algorithms only apply to reduce the dimension of high dimensional vector-form data. For high dimensional SPD matrices, it is impossible to directly use manifold learning algorithms to reduce the dimension of matrix-form data, but we need first transform the matrix into a long vector and then reduce the dimension of this vector. This however breaks the spatial structure of the SPD matrix space. To overcome this limitation, we propose a new dimension reduction algorithm on SPD matrix space to transform the high dimensional SPD matrices to lower dimensional SPD matrices. Our work is based on the fact that the set of all SPD matrices with the same size is known to have a Lie group structure and we aims to transform the manifold learning algorithm to SPD matrix Lie group. We make use of the basic idea of manifold learning algorithm LPP (locality preserving projection) to construct the corresponding Laplacian matrix on SPD matrix Lie group. Thus we call our approach Lie-LPP to emphasize its Lie group character. Finally our method gets a lower dimensional and more discriminable SPD matrix Lie group. We also show by experiments that our approach achieves effective results on Human action recognition and Human face recognition. version:1
arxiv-1703-07957 | Robust SfM with Little Image Overlap | http://arxiv.org/abs/1703.07957 | id:1703.07957 author:Yohann Salaun, Renaud Marlet, Pascal Monasse category:cs.CV  published:2017-03-23 summary:Usual Structure-from-Motion (SfM) techniques require at least trifocal overlaps to calibrate cameras and reconstruct a scene. We consider here scenarios of reduced image sets with little overlap, possibly as low as two images at most seeing the same part of the scene. We propose a new method, based on line coplanarity hypotheses, for estimating the relative scale of two independent bifocal calibrations sharing a camera, without the need of any trifocal information or Manhattan-world assumption. We use it to compute SfM in a chain of up-to-scale relative motions. For accuracy, we however also make use of trifocal information for line and/or point features, when present, relaxing usual trifocal constraints. For robustness to wrong assumptions and mismatches, we embed all constraints in a parameterless RANSAC-like approach. Experiments show that we can calibrate datasets that previously could not, and that this wider applicability does not come at the cost of inaccuracy. version:2
arxiv-1703-09480 | Simulated Data Experiments for Time Series Classification Part 1: Accuracy Comparison with Default Settings | http://arxiv.org/abs/1703.09480 | id:1703.09480 author:Anthony Bagnall, Aaron Bostrom, James Large, Jason Lines category:cs.LG stat.ML  published:2017-03-28 summary:There are now a broad range of time series classification (TSC) algorithms designed to exploit different representations of the data. These have been evaluated on a range of problems hosted at the UCR-UEA TSC Archive (www.timeseriesclassification.com), and there have been extensive comparative studies. However, our understanding of why one algorithm outperforms another is still anecdotal at best. This series of experiments is meant to help provide insights into what sort of discriminatory features in the data lead one set of algorithms that exploit a particular representation to be better than other algorithms. We categorise five different feature spaces exploited by TSC algorithms then design data simulators to generate randomised data from each representation. We describe what results we expected from each class of algorithm and data representation, then observe whether these prior beliefs are supported by the experimental evidence. We provide an open source implementation of all the simulators to allow for the controlled testing of hypotheses relating to classifier performance on different data representations. We identify many surprising results that confounded our expectations, and use these results to highlight how an over simplified view of classifier structure can often lead to erroneous prior beliefs. We believe ensembling can often overcome prior bias, and our results support the belief by showing that the ensemble approach adopted by the Hierarchical Collective of Transform based Ensembles (HIVE-COTE) is significantly better than the alternatives when the data representation is unknown, and is significantly better than, or not significantly significantly better than, or not significantly worse than, the best other approach on three out of five of the individual simulators. version:1
arxiv-1703-09474 | Robust Depth-based Person Re-identification | http://arxiv.org/abs/1703.09474 | id:1703.09474 author:Ancong Wu, Wei-Shi Zheng, Jianhuang Lai category:cs.CV  published:2017-03-28 summary:Person re-identification (re-id) aims to match people across non-overlapping camera views. So far the RGB-based appearance is widely used in most existing works. However, when people appeared in extreme illumination or changed clothes, the RGB appearance-based re-id methods tended to fail. To overcome this problem, we propose to exploit depth information to provide more invariant body shape and skeleton information regardless of illumination and color change. More specifically, we exploit depth voxel covariance descriptor and further propose a locally rotation invariant depth shape descriptor called Eigen-depth feature to describe pedestrian body shape. We prove that the distance between any two covariance matrices on the Riemannian manifold is equivalent to the Euclidean distance between the corresponding Eigen-depth features. Furthermore, we propose a kernelized implicit feature transfer scheme to estimate Eigen-depth feature implicitly from RGB image when depth information is not available. We find that combining the estimated depth features with RGB-based appearance features can sometimes help to better reduce visual ambiguities of appearance features caused by illumination and similar clothes. The effectiveness of our models was validated on publicly available depth pedestrian datasets as compared to related methods for person re-identification. version:1
arxiv-1703-09471 | Adversarial Image Perturbation for Privacy Protection -- A Game Theory Perspective | http://arxiv.org/abs/1703.09471 | id:1703.09471 author:Seong Joon Oh, Mario Fritz, Bernt Schiele category:cs.CV cs.CR cs.GT  published:2017-03-28 summary:Users like sharing personal photos with others through social media. At the same time, they might want to make automatic identification in such photos difficult or even impossible. Classic obfuscation methods such as blurring are not only unpleasant but also not as effective as one would expect. Recent studies on adversarial image perturbations (AIP) suggest that it is possible to confuse recognition systems effectively without unpleasant artifacts. However, in the presence of counter measures against AIPs, it is unclear how effective AIP would be in particular when the choice of counter measure is unknown. Game theory provides tools for studying the interaction between agents with uncertainties in the strategies. We introduce a general game theoretical framework for the user-recogniser dynamics, and present a case study that involves current state of the art AIP and person recognition techniques. We derive the optimal strategy for the user that assures an upper bound on the recognition rate independent of the recogniser's counter measure. version:1
arxiv-1703-09470 | Learned Spectral Super-Resolution | http://arxiv.org/abs/1703.09470 | id:1703.09470 author:Silvano Galliani, Charis Lanaras, Dimitrios Marmanis, Emmanuel Baltsavias, Konrad Schindler category:cs.CV cs.LG  published:2017-03-28 summary:We describe a novel method for blind, single-image spectral super-resolution. While conventional super-resolution aims to increase the spatial resolution of an input image, our goal is to spectrally enhance the input, i.e., generate an image with the same spatial resolution, but a greatly increased number of narrow (hyper-spectral) wave-length bands. Just like the spatial statistics of natural images has rich structure, which one can exploit as prior to predict high-frequency content from a low resolution image, the same is also true in the spectral domain: the materials and lighting conditions of the observed world induce structure in the spectrum of wavelengths observed at a given pixel. Surprisingly, very little work exists that attempts to use this diagnosis and achieve blind spectral super-resolution from single images. We start from the conjecture that, just like in the spatial domain, we can learn the statistics of natural image spectra, and with its help generate finely resolved hyper-spectral images from RGB input. Technically, we follow the current best practice and implement a convolutional neural network (CNN), which is trained to carry out the end-to-end mapping from an entire RGB image to the corresponding hyperspectral image of equal size. We demonstrate spectral super-resolution both for conventional RGB images and for multi-spectral satellite data, outperforming the state-of-the-art. version:1
arxiv-1703-09469 | Experimental Analysis of Design Elements of Scalarizing Functions-based Multiobjective Evolutionary Algorithms | http://arxiv.org/abs/1703.09469 | id:1703.09469 author:Mansoureh Aghabeig, Andrzej Jaszkiewicz category:cs.NE  published:2017-03-28 summary:In this paper we systematically study the importance, i.e., the influence on performance, of the main design elements that differentiate scalarizing functions-based multiobjective evolutionary algorithms (MOEAs). This class of MOEAs includes Multiobjecitve Genetic Local Search (MOGLS) and Multiobjective Evolutionary Algorithm Based on Decomposition (MOEA/D) and proved to be very successful in multiple computational experiments and practical applications. The two algorithms share the same common structure and differ only in two main aspects. Using three different multiobjective combinatorial optimization problems, i.e., the multiobjective symmetric traveling salesperson problem, the traveling salesperson problem with profits, and the multiobjective set covering problem, we show that the main differentiating design element is the mechanism for parent selection, while the selection of weight vectors, either random or uniformly distributed, is practically negligible if the number of uniform weight vectors is sufficiently large. version:1
arxiv-1703-09210 | StyleBank: An Explicit Representation for Neural Image Style Transfer | http://arxiv.org/abs/1703.09210 | id:1703.09210 author:Dongdong Chen, Lu Yuan, Jing Liao, Nenghai Yu, Gang Hua category:cs.CV  published:2017-03-27 summary:We propose StyleBank, which is composed of multiple convolution filter banks and each filter bank explicitly represents one style, for neural image style transfer. To transfer an image to a specific style, the corresponding filter bank is operated on top of the intermediate feature embedding produced by a single auto-encoder. The StyleBank and the auto-encoder are jointly learnt, where the learning is conducted in such a way that the auto-encoder does not encode any style information thanks to the flexibility introduced by the explicit filter bank representation. It also enables us to conduct incremental learning to add a new image style by learning a new filter bank while holding the auto-encoder fixed. The explicit style representation along with the flexible network design enables us to fuse styles at not only the image level, but also the region level. Our method is the first style transfer network that links back to traditional texton mapping methods, and hence provides new understanding on neural style transfer. Our method is easy to train, runs in real-time, and produces results that qualitatively better or at least comparable to existing methods. version:2
arxiv-1703-09211 | Coherent Online Video Style Transfer | http://arxiv.org/abs/1703.09211 | id:1703.09211 author:Dongdong Chen, Jing Liao, Lu Yuan, Nenghai Yu, Gang Hua category:cs.CV  published:2017-03-27 summary:Training a feed-forward network for fast neural style transfer of images is proven to be successful. However, the naive extension to process video frame by frame is prone to producing flickering results. We propose the first end-to-end network for online video style transfer, which generates temporally coherent stylized video sequences in near real-time. Two key ideas include an efficient network by incorporating short-term coherence, and propagating short-term coherence to long-term, which ensures the consistency over larger period of time. Our network can incorporate different image stylization networks. We show that the proposed method clearly outperforms the per-frame baseline both qualitatively and quantitatively. Moreover, it can achieve visually comparable coherence to optimization-based video style transfer, but is three orders of magnitudes faster in runtime. version:2
arxiv-1703-09439 | A practical approach to dialogue response generation in closed domains | http://arxiv.org/abs/1703.09439 | id:1703.09439 author:Yichao Lu, Phillip Keung, Shaonan Zhang, Jason Sun, Vikas Bhardwaj category:cs.CL cs.NE  published:2017-03-28 summary:We describe a prototype dialogue response generation model for the customer service domain at Amazon. The model, which is trained in a weakly supervised fashion, measures the similarity between customer questions and agent answers using a dual encoder network, a Siamese-like neural network architecture. Answer templates are extracted from embeddings derived from past agent answers, without turn-by-turn annotations. Responses to customer inquiries are generated by selecting the best template from the final set of templates. We show that, in a closed domain like customer service, the selected templates cover $>$70\% of past customer inquiries. Furthermore, the relevance of the model-selected templates is significantly higher than templates selected by a standard tf-idf baseline. version:1
arxiv-1703-09438 | Octree Generating Networks: Efficient Convolutional Architectures for High-resolution 3D Outputs | http://arxiv.org/abs/1703.09438 | id:1703.09438 author:Maxim Tatarchenko, Alexey Dosovitskiy, Thomas Brox category:cs.CV  published:2017-03-28 summary:We present a deep convolutional decoder architecture that can generate volumetric 3D outputs in a compute- and memory-efficient manner by using an octree representation. The network learns to predict both the structure of the octree, and the occupancy values of individual cells. This makes it a particularly valuable technique for generating 3D shapes. In contrast to standard decoders acting on regular voxel grids, the architecture does not have cubic complexity. This allows representing much higher resolution outputs with a limited memory budget. We demonstrate this in several application domains, including 3D convolutional autoencoders, generation of objects and whole scenes from high-level representations, and shape from a single image. version:1
arxiv-1703-09436 | Evaluation of Classifiers for Image Segmentation: Applications for Eucalypt Forest Inventory | http://arxiv.org/abs/1703.09436 | id:1703.09436 author:Rodrigo M. Ferreira, Ricardo M. Marcacini category:cs.CV  published:2017-03-28 summary:The task of counting eucalyptus trees from aerial images collected by unmanned aerial vehicles (UAVs) has been frequently explored by techniques of estimation of the basal area, i.e, by determining the expected number of trees based on sampling techniques. An alternative is the use of machine learning to identify patterns that represent a tree unit, and then search for the occurrence of these patterns throughout the image. This strategy depends on a supervised image segmentation step to define predefined interest regions. Thus, it is possible to automate the counting of eucalyptus trees in these images, thereby increasing the efficiency of the eucalyptus forest inventory management. In this paper, we evaluated 20 different classifiers for the image segmentation task. A real sample was used to analyze the counting trees task considering a practical environment. The results show that it possible to automate this task with 0.7% counting error, in particular, by using strategies based on a combination of classifiers. Moreover, we present some performance considerations about each classifier that can be useful as a basis for decision-making in future tasks. version:1
arxiv-1703-09400 | Diving Deep into Clickbaits: Who Use Them to What Extents in Which Topics with What Effects? | http://arxiv.org/abs/1703.09400 | id:1703.09400 author:Md Main Uddin Rony, Naeemul Hassan, Mohammad Yousuf category:cs.SI cs.CL  published:2017-03-28 summary:The use of alluring headlines (clickbait) to tempt the readers has become a growing practice nowadays. For the sake of existence in the highly competitive media industry, most of the on-line media including the mainstream ones, have started following this practice. Although the wide-spread practice of clickbait makes the reader's reliability on media vulnerable, a large scale analysis to reveal this fact is still absent. In this paper, we analyze 1.67 million Facebook posts created by 153 media organizations to understand the extent of clickbait practice, its impact and user engagement by using our own developed clickbait detection model. The model uses distributed sub-word embeddings learned from a large corpus. The accuracy of the model is 98.3%. Powered with this model, we further study the distribution of topics in clickbait and non-clickbait contents. version:1
arxiv-1703-09398 | This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive Content in Text Body, More Similar to Satire than Real News | http://arxiv.org/abs/1703.09398 | id:1703.09398 author:Benjamin D. Horne, Sibel Adali category:cs.SI cs.CL  published:2017-03-28 summary:The problem of fake news has gained a lot of attention as it is claimed to have had a significant impact on 2016 US Presidential Elections. Fake news is not a new problem and its spread in social networks is well-studied. Often an underlying assumption in fake news discussion is that it is written to look like real news, fooling the reader who does not check for reliability of the sources or the arguments in its content. Through a unique study of three data sets and features that capture the style and the language of articles, we show that this assumption is not true. Fake news in most cases is more similar to satire than to real news, leading us to conclude that persuasion in fake news is achieved through heuristics rather than the strength of arguments. We show overall title structure and the use of proper nouns in titles are very significant in differentiating fake from real. This leads us to conclude that fake news is targeted for audiences who are not likely to read beyond titles and is aimed at creating mental associations between entities and claims. version:1
arxiv-1703-07023 | Encouraging LSTMs to Anticipate Actions Very Early | http://arxiv.org/abs/1703.07023 | id:1703.07023 author:Mohammad Sadegh Aliakbarian, Fatemehsadat Saleh, Mathieu Salzmann, Basura Fernando, Lars Petersson, Lars Andersson category:cs.CV  published:2017-03-21 summary:In contrast to the widely studied problem of recognizing an action given a complete sequence, action anticipation aims to identify the action from only partially available videos. As such, it is therefore key to the success of computer vision applications requiring to react as early as possible, such as autonomous navigation. In this paper, we propose a new action anticipation method that achieves high prediction accuracy even in the presence of a very small percentage of a video sequence. To this end, we develop a multi-stage LSTM architecture that leverages context- and action-aware features, and introduce a novel loss function that encourages the model to predict the correct class as early as possible. Our experiments on standard benchmark datasets evidence the benefits of our approach; We outperform the state-of-the-art action anticipation methods for early prediction by a relative increase in accuracy of 22.0% on JHMDB-21, 14.0% on UT-Interaction and 49.9% on UCF-101. version:2
arxiv-1703-09397 | Solving Non-parametric Inverse Problem in Continuous Markov Random Field using Loopy Belief Propagation | http://arxiv.org/abs/1703.09397 | id:1703.09397 author:Muneki Yasuda, Shun Kataoka category:stat.ML cond-mat.dis-nn cs.LG  published:2017-03-28 summary:In this paper, we address the inverse problem, or the statistical machine learning problem, in Markov random fields with a non-parametric pair-wise energy function with continuous variables. The inverse problem is formulated by maximum likelihood estimation. The exact treatment of maximum likelihood estimation is intractable because of two problems: (1) it includes the evaluation of the partition function and (2) it is formulated in the form of functional optimization. We avoid Problem (1) by using Bethe approximation. Bethe approximation is an approximation technique equivalent to the loopy belief propagation. Problem (2) can be solved by using orthonormal function expansion. Orthonormal function expansion can reduce a functional optimization problem to a function optimization problem. Our method can provide an analytic form of the solution of the inverse problem within the framework of Bethe approximation. version:1
arxiv-1703-09393 | Mixture of Counting CNNs: Adaptive Integration of CNNs Specialized to Specific Appearance for Crowd Counting | http://arxiv.org/abs/1703.09393 | id:1703.09393 author:Shohei Kumagai, Kazuhiro Hotta, Takio Kurita category:cs.CV  published:2017-03-28 summary:This paper proposes a crowd counting method. Crowd counting is difficult because of large appearance changes of a target which caused by density and scale changes. Conventional crowd counting methods generally utilize one predictor (e,g., regression and multi-class classifier). However, such only one predictor can not count targets with large appearance changes well. In this paper, we propose to predict the number of targets using multiple CNNs specialized to a specific appearance, and those CNNs are adaptively selected according to the appearance of a test image. By integrating the selected CNNs, the proposed method has the robustness to large appearance changes. In experiments, we confirm that the proposed method can count crowd with lower counting error than a CNN and integration of CNNs with fixed weights. Moreover, we confirm that each predictor automatically specialized to a specific appearance. version:1
arxiv-1703-09391 | Fast Optimization of Wildfire Suppression Policies with SMAC | http://arxiv.org/abs/1703.09391 | id:1703.09391 author:Sean McGregor, Rachel Houtman, Claire Montgomery, Ronald Metoyer, Thomas G. Dietterich category:cs.LG stat.ML  published:2017-03-28 summary:Managers of US National Forests must decide what policy to apply for dealing with lightning-caused wildfires. Conflicts among stakeholders (e.g., timber companies, home owners, and wildlife biologists) have often led to spirited political debates and even violent eco-terrorism. One way to transform these conflicts into multi-stakeholder negotiations is to provide a high-fidelity simulation environment in which stakeholders can explore the space of alternative policies and understand the tradeoffs therein. Such an environment needs to support fast optimization of MDP policies so that users can adjust reward functions and analyze the resulting optimal policies. This paper assesses the suitability of SMAC---a black-box empirical function optimization algorithm---for rapid optimization of MDP policies. The paper describes five reward function components and four stakeholder constituencies. It then introduces a parameterized class of policies that can be easily understood by the stakeholders. SMAC is applied to find the optimal policy in this class for the reward functions of each of the stakeholder constituencies. The results confirm that SMAC is able to rapidly find good policies that make sense from the domain perspective. Because the full-fidelity forest fire simulator is far too expensive to support interactive optimization, SMAC is applied to a surrogate model constructed from a modest number of runs of the full-fidelity simulator. To check the quality of the SMAC-optimized policies, the policies are evaluated on the full-fidelity simulator. The results confirm that the surrogate values estimates are valid. This is the first successful optimization of wildfire management policies using a full-fidelity simulation. The same methodology should be applicable to other contentious natural resource management problems where high-fidelity simulation is extremely expensive. version:1
arxiv-1703-09390 | Factoring Exogenous State for Model-Free Monte Carlo | http://arxiv.org/abs/1703.09390 | id:1703.09390 author:Sean McGregor, Rachel Houtman, Claire Montgomery, Ronald Metoyer, Thomas G. Dietterich category:cs.LG stat.ML  published:2017-03-28 summary:Policy analysts wish to visualize a range of policies for large simulator-defined Markov Decision Processes (MDPs). One visualization approach is to invoke the simulator to generate on-policy trajectories and then visualize those trajectories. When the simulator is expensive, this is not practical, and some method is required for generating trajectories for new policies without invoking the simulator. The method of Model-Free Monte Carlo (MFMC) can do this by stitching together state transitions for a new policy based on previously-sampled trajectories from other policies. This "off-policy Monte Carlo simulation" method works well when the state space has low dimension but fails as the dimension grows. This paper describes a method for factoring out some of the state and action variables so that MFMC can work in high-dimensional MDPs. The new method, MFMCi, is evaluated on a very challenging wildfire management MDP. version:1
arxiv-1703-09387 | Adversarial Transformation Networks: Learning to Generate Adversarial Examples | http://arxiv.org/abs/1703.09387 | id:1703.09387 author:Shumeet Baluja, Ian Fischer category:cs.NE cs.AI cs.CV  published:2017-03-28 summary:Multiple different approaches of generating adversarial examples have been proposed to attack deep neural networks. These approaches involve either directly computing gradients with respect to the image pixels, or directly solving an optimization on the image pixels. In this work, we present a fundamentally new method for generating adversarial examples that is fast to execute and provides exceptional diversity of output. We efficiently train feed-forward neural networks in a self-supervised manner to generate adversarial examples against a target network or set of networks. We call such a network an Adversarial Transformation Network (ATN). ATNs are trained to generate adversarial examples that minimally modify the classifier's outputs given the original input, while constraining the new classification to match an adversarial target class. We present methods to train ATNs and analyze their effectiveness targeting a variety of MNIST classifiers as well as the latest state-of-the-art ImageNet classifier Inception ResNet v2. version:1
arxiv-1703-09379 | Robust Guided Image Filtering | http://arxiv.org/abs/1703.09379 | id:1703.09379 author:Wei Liu, Xiaogang Chen, Chunhua Shen, Jingyi Yu, Qiang Wu, Jie Yang category:cs.CV  published:2017-03-28 summary:The process of using one image to guide the filtering process of another one is called Guided Image Filtering (GIF). The main challenge of GIF is the structure inconsistency between the guidance image and the target image. Besides, noise in the target image is also a challenging issue especially when it is heavy. In this paper, we propose a general framework for Robust Guided Image Filtering (RGIF), which contains a data term and a smoothness term, to solve the two issues mentioned above. The data term makes our model simultaneously denoise the target image and perform GIF which is robust against the heavy noise. The smoothness term is able to make use of the property of both the guidance image and the target image which is robust against the structure inconsistency. While the resulting model is highly non-convex, it can be solved through the proposed Iteratively Re-weighted Least Squares (IRLS) in an efficient manner. For challenging applications such as guided depth map upsampling, we further develop a data-driven parameter optimization scheme to properly determine the parameter in our model. This optimization scheme can help to preserve small structures and sharp depth edges even for a large upsampling factor (8x for example). Moreover, the specially designed structure of the data term and the smoothness term makes our model perform well in edge-preserving smoothing for single-image tasks (i.e., the guidance image is the target image itself). This paper is an extension of our previous work [1], [2]. version:1
arxiv-1703-09370 | Ensembles of Deep LSTM Learners for Activity Recognition using Wearables | http://arxiv.org/abs/1703.09370 | id:1703.09370 author:Yu Guan, Thomas Ploetz category:cs.LG cs.AI cs.CV  published:2017-03-28 summary:Recently, deep learning (DL) methods have been introduced very successfully into human activity recognition (HAR) scenarios in ubiquitous and wearable computing. Especially the prospect of overcoming the need for manual feature design combined with superior classification capabilities render deep neural networks very attractive for real-life HAR application. Even though DL-based approaches now outperform the state-of-the-art in a number of recognitions tasks of the field, yet substantial challenges remain. Most prominently, issues with real-life datasets, typically including imbalanced datasets and problematic data quality, still limit the effectiveness of activity recognition using wearables. In this paper we tackle such challenges through Ensembles of deep Long Short Term Memory (LSTM) networks. We have developed modified training procedures for LSTM networks and combine sets of diverse LSTM learners into classifier collectives. We demonstrate, both formally and empirically, that Ensembles of deep LSTM learners outperform the individual LSTM networks. Through an extensive experimental evaluation on three standard benchmarks (Opportunity, PAMAP2, Skoda) we demonstrate the excellent recognition capabilities of our approach and its potential for real-life applications of human activity recognition. version:1
arxiv-1703-07475 | PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding | http://arxiv.org/abs/1703.07475 | id:1703.07475 author:Chunhui Liu, Yueyu Hu, Yanghao Li, Sijie Song, Jiaying Liu category:cs.CV  published:2017-03-22 summary:Despite the fact that many 3D human activity benchmarks being proposed, most existing action datasets focus on the action recognition tasks for the segmented videos. There is a lack of standard large-scale benchmarks, especially for current popular data-hungry deep learning based methods. In this paper, we introduce a new large scale benchmark (PKU-MMD) for continuous multi-modality 3D human action understanding and cover a wide range of complex human activities with well annotated information. PKU-MMD contains 1076 long video sequences in 51 action categories, performed by 66 subjects in three camera views. It contains almost 20,000 action instances and 5.4 million frames in total. Our dataset also provides multi-modality data sources, including RGB, depth, Infrared Radiation and Skeleton. With different modalities, we conduct extensive experiments on our dataset in terms of two scenarios and evaluate different methods by various metrics, including a new proposed evaluation protocol 2D-AP. We believe this large-scale dataset will benefit future researches on action detection for the community. version:2
arxiv-1703-09342 | Graph Regularized Tensor Sparse Coding for Image Representation | http://arxiv.org/abs/1703.09342 | id:1703.09342 author:Fei Jiang, Xiao-Yang Liu, Hongtao Lu, Ruimin Shen category:cs.CV  published:2017-03-27 summary:Sparse coding (SC) is an unsupervised learning scheme that has received an increasing amount of interests in recent years. However, conventional SC vectorizes the input images, which destructs the intrinsic spatial structures of the images. In this paper, we propose a novel graph regularized tensor sparse coding (GTSC) for image representation. GTSC preserves the local proximity of elementary structures in the image by adopting the newly proposed tubal-tensor representation. Simultaneously, it considers the intrinsic geometric properties by imposing graph regularization that has been successfully applied to uncover the geometric distribution for the image data. Moreover, the returned sparse representations by GTSC have better physical explanations as the key operation (i.e., circular convolution) in the tubal-tensor model preserves the shifting invariance property. Experimental results on image clustering demonstrate the effectiveness of the proposed scheme. version:1
arxiv-1703-09327 | Iterative Noise Injection for Scalable Imitation Learning | http://arxiv.org/abs/1703.09327 | id:1703.09327 author:Michael Laskey, Jonathan Lee, Wesley Hsieh, Richard Liaw, Jeffrey Mahler, Roy Fox, Ken Goldberg category:cs.LG  published:2017-03-27 summary:In Imitation Learning, a supervisor's policy is observed and the intended behavior is learned. A known problem with this approach is covariate shift, which occurs because the agent visits different states than the supervisor. Rolling out the current agent's policy, an on-policy method, allows for collecting data along a distribution similar to the updated agent's policy. However this approach can become less effective as the demonstrations are collected in very large batch sizes, which reduces the relevance of data collected in previous iterations. In this paper, we propose to alleviate the covariate shift via the injection of artificial noise into the supervisor's policy. We prove an improved bound on the loss due to the covariate shift, and introduce an algorithm that leverages our analysis to estimate the level of $\epsilon$-greedy noise to inject. In a driving simulator domain where an agent learns an image-to-action deep network policy, our algorithm Dart achieves a better performance than DAgger with 75% fewer demonstrations. version:1
arxiv-1703-09310 | Adaptive Simulation-based Training of AI Decision-makers using Bayesian Optimization | http://arxiv.org/abs/1703.09310 | id:1703.09310 author:Brett W. Israelsen, Nisar Ahmed, Kenneth Center, Roderick Green, Winston Bennett Jr category:cs.LG cs.AI cs.RO stat.ML  published:2017-03-27 summary:This work studies how an AI-controlled dog-fighting agent with tunable decision-making parameters can learn to optimize performance against an intelligent adversary, as measured by a stochastic objective function evaluated on simulated combat engagements. Gaussian process Bayesian optimization (GPBO) techniques are developed to automatically learn global Gaussian Process (GP) surrogate models, which provide statistical performance predictions in both explored and unexplored areas of the parameter space. This allows a learning engine to sample full-combat simulations at parameter values that are most likely to optimize performance and also provide highly informative data points for improving future predictions. However, standard GPBO methods do not provide a reliable surrogate model for the highly volatile objective functions found in aerial combat, and thus do not reliably identify global maxima. These issues are addressed by novel Repeat Sampling (RS) and Hybrid Repeat/Multi-point Sampling (HRMS) techniques. Simulation studies show that HRMS improves the accuracy of GP surrogate models, allowing AI decision-makers to more accurately predict performance and efficiently tune parameters. version:1
arxiv-1703-09296 | Femoral ROIs and Entropy for Texture-based Detection of Osteoarthritis from High-Resolution Knee Radiographs | http://arxiv.org/abs/1703.09296 | id:1703.09296 author:Jiří Hladůvka, Bui Thi Mai Phuong, Richard Ljuhar, Davul Ljuhar, Ana M Rodrigues, Jaime C Branco, Helena Canhão category:cs.CV  published:2017-03-27 summary:The relationship between knee osteoarthritis progression and changes in tibial bone structure has long been recognized and various texture descriptors have been proposed to detect early osteoarthritis (OA) from radiographs. This work aims to investigate (1) femoral textures as an OA indicator and (2) the potential of entropy as a computationally efficient alternative to established texture descriptors. We design a robust semi-automatically placed layout for regions of interest (ROI), compute the Hurst coefficient and the entropy in each ROI, and employ statistical and machine learning methods to evaluate feature combinations. Based on 153 high-resolution radiographs, our results identify medial femur as an effective univariate descriptor, with significance comparable to medial tibia. Entropy is shown to contribute to classification performance. A linear five-feature classifier combining femur, entropic and standard texture descriptors, achieves AUC of 0.85, outperforming the state-of-the-art by roughly 0.1. version:1
arxiv-1703-09260 | Goal-Driven Dynamics Learning via Bayesian Optimization | http://arxiv.org/abs/1703.09260 | id:1703.09260 author:Somil Bansal, Roberto Calandra, Ted Xiao, Sergey Levine, Claire J. Tomlin category:cs.SY cs.LG  published:2017-03-27 summary:Real-world robots are becoming increasingly complex and commonly act in poorly understood environments where it is extremely challenging to model or learn their true dynamics. Therefore, it might be desirable to take a task-specific approach, wherein the focus is on explicitly learning the dynamics model which achieves the best control performance for the task at hand, rather than learning the true dynamics. In this work, we use Bayesian optimization in an active learning framework where a locally linear dynamics model is learned with the intent of maximizing the control performance, and used in conjunction with optimal control schemes to efficiently design a controller for a given task. This model is updated directly based on the performance observed in experiments on the physical system in an iterative manner until a desired performance is achieved. We demonstrate the efficacy of the proposed approach through simulations and real experiments on a quadrotor testbed. version:1
arxiv-1703-09245 | Discriminative Transfer Learning for General Image Restoration | http://arxiv.org/abs/1703.09245 | id:1703.09245 author:Lei Xiao, Felix Heide, Wolfgang Heidrich, Bernhard Schölkopf, Michael Hirsch category:cs.CV  published:2017-03-27 summary:Recently, several discriminative learning approaches have been proposed for effective image restoration, achieving convincing trade-off between image quality and computational efficiency. However, these methods require separate training for each restoration task (e.g., denoising, deblurring, demosaicing) and problem condition (e.g., noise level of input images). This makes it time-consuming and difficult to encompass all tasks and conditions during training. In this paper, we propose a discriminative transfer learning method that incorporates formal proximal optimization and discriminative learning for general image restoration. The method requires a single-pass training and allows for reuse across various problems and conditions while achieving an efficiency comparable to previous discriminative approaches. Furthermore, after being trained, our model can be easily transferred to new likelihood terms to solve untrained tasks, or be combined with existing priors to further improve image restoration quality. version:1
arxiv-1703-09244 | Adversarial Source Identification Game with Corrupted Training | http://arxiv.org/abs/1703.09244 | id:1703.09244 author:Mauro Barni, Benedetta Tondi category:cs.CR stat.ML  published:2017-03-27 summary:We study a variant of the source identification game with training data in which part of the training data is corrupted by an attacker. In the addressed scenario, the defender aims at deciding whether a test sequence has been drawn according to a discrete memoryless source $X \sim P_X$, whose statistics are known to him through the observation of a training sequence generated by $X$. In order to undermine the correct decision under the alternative hypothesis that the test sequence has not been drawn from $X$, the attacker can modify a sequence produced by a source $Y \sim P_Y$ up to a certain distortion, and corrupt the training sequence either by adding some fake samples or by replacing some samples with fake ones. We derive the unique rationalizable equilibrium of the two versions of the game in the asymptotic regime and by assuming that the defender bases its decision by relying only on the first order statistics of the test and the training sequences. By mimicking Stein's lemma, we derive the best achievable performance for the defender when the first type error probability is required to tend to zero exponentially fast with an arbitrarily small, yet positive, error exponent. We then use such a result to analyze the ultimate distinguishability of any two sources as a function of the allowed distortion and the fraction of corrupted samples injected into the training sequence. version:1
arxiv-1703-09207 | Fairness in Criminal Justice Risk Assessments: The State of the Art | http://arxiv.org/abs/1703.09207 | id:1703.09207 author:Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, Aaron Roth category:stat.ML  published:2017-03-27 summary:Objectives: Discussions of fairness in criminal justice risk assessments typically lack conceptual precision. Rhetoric too often substitutes for careful analysis. In this paper, we seek to clarify the tradeoffs between different kinds of fairness and between fairness and accuracy. Methods: We draw on the existing literatures in criminology, computer science and statistics to provide an integrated examination of fairness and accuracy in criminal justice risk assessments. We also provide an empirical illustration using data from arraignments. Results: We show that there are at least six kinds of fairness, some of which are incompatible with one another and with accuracy. Conclusions: Except in trivial cases, it is impossible to maximize accuracy and fairness at the same time, and impossible simultaneously to satisfy all kinds of fairness. In practice, a major complication is different base rates across different legally protected groups. There is a need to consider challenging tradeoffs. version:1
arxiv-1703-09202 | Biologically inspired protection of deep networks from adversarial attacks | http://arxiv.org/abs/1703.09202 | id:1703.09202 author:Aran Nayebi, Surya Ganguli category:stat.ML cs.LG q-bio.NC  published:2017-03-27 summary:Inspired by biophysical principles underlying nonlinear dendritic computation in neural circuits, we develop a scheme to train deep neural networks to make them robust to adversarial attacks. Our scheme generates highly nonlinear, saturated neural networks that achieve state of the art performance on gradient based adversarial examples on MNIST, despite never being exposed to adversarially chosen examples during training. Moreover, these networks exhibit unprecedented robustness to targeted, iterative schemes for generating adversarial examples, including second-order methods. We further identify principles governing how these networks achieve their robustness, drawing on methods from information geometry. We find these networks progressively create highly flat and compressed internal representations that are sensitive to very few input dimensions, while still solving the task. Moreover, they employ highly kurtotic weight distributions, also found in the brain, and we demonstrate how such kurtosis can protect even linear classifiers from adversarial attack. version:1
arxiv-1703-09200 | Deep Poincare Map For Robust Medical Image Segmentation | http://arxiv.org/abs/1703.09200 | id:1703.09200 author:Yuanhan Mo, Fangde Liu, Jingqing Zhang, Guang Yang, Taigang He, Yike Guo category:cs.CV  published:2017-03-27 summary:Precise segmentation is a prerequisite for an accurate quantification of the imaged objects. It is a very challenging task in many medical imaging applications due to relatively poor image quality and data scarcity. In this work, we present an innovative segmentation paradigm, named Deep Poincare Map (DPM), by coupling the dynamical system theory with a novel deep learning based approach. Firstly, we model the image segmentation process as a dynamical system, in which limit cycle models the boundary of the region of interest (ROI). Secondly, instead of segmenting the ROI directly, convolutional neural network is employed to predict the vector field of the dynamical system. Finally, the boundary of the ROI is identified using the Poincare map and the flow integration. We demonstrate that our segmentation model can be built using a very limited number of train- ing data. By cross-validation, we can achieve a mean Dice score of 94% compared to the manual delineation (ground truth) of the left ventricle ROI defined by clinical experts on a cardiac MRI dataset. Compared with other state-of-the-art methods, we can conclude that the proposed DPM method is adaptive, accurate and robust. It is straightforward to apply this method for other medical imaging applications. version:1
arxiv-1703-09199 | Introduction To The Monogenic Signal | http://arxiv.org/abs/1703.09199 | id:1703.09199 author:Christopher P. Bridge category:cs.CV  published:2017-03-27 summary:The monogenic signal is an image analysis methodology that was introduced by Felsberg and Sommer in 2001 and has been employed for a variety of purposes in image processing and computer vision research. In particular, it has been found to be useful in the analysis of ultrasound imagery in several research scenarios mostly in work done within the BioMedIA lab at Oxford. However, the literature on the monogenic signal can be difficult to penetrate due to the lack of a single resource to explain the various principles from basics. The purpose of this document is therefore to introduce the principles, purpose, applications, and limitations of the methodology. It assumes some background knowledge from the fields of image and signal processing, in particular a good knowledge of Fourier transforms as applied to signals and images. We will not attempt to provide a thorough math- ematical description or derivation of the monogenic signal, but rather focus on developing an intuition for understanding and using the methodology and refer the reader elsewhere for a more mathematical treatment. version:1
arxiv-1703-09197 | Deep Architectures for Modulation Recognition | http://arxiv.org/abs/1703.09197 | id:1703.09197 author:Nathan E West, Timothy J. O'Shea category:cs.LG  published:2017-03-27 summary:We survey the latest advances in machine learning with deep neural networks by applying them to the task of radio modulation recognition. Results show that radio modulation recognition is not limited by network depth and further work should focus on improving learned synchronization and equalization. Advances in these areas will likely come from novel architectures designed for these tasks or through novel training methods. version:1
arxiv-1703-09185 | Private Learning on Networks: Part II | http://arxiv.org/abs/1703.09185 | id:1703.09185 author:Shripad Gade, Nitin H. Vaidya category:cs.DC cs.LG math.OC  published:2017-03-27 summary:Widespread deployment of distributed machine learning algorithms has raised new privacy challenges. The focus of this paper is on improving privacy of each participant's local information (such as dataset or loss function) while collaboratively learning underlying model. We present two iterative algorithms for privacy preserving distributed learning. Our algorithms involves adding structured randomization to the state estimates. We prove deterministic correctness (in every execution) of our algorithm despite the iterates being perturbed by non-zero mean random variables. We motivate privacy using privacy analysis of a special case of our algorithm referred to as Function Sharing strategy (presented in [1]). version:1
arxiv-1703-09179 | Transfer learning for music classification and regression tasks | http://arxiv.org/abs/1703.09179 | id:1703.09179 author:Keunwoo Choi, György Fazekas, Mark Sandler, Kyunghyun Cho category:cs.CV cs.AI cs.MM cs.SD  published:2017-03-27 summary:In this paper, we present a transfer learning approach for music classification and regression tasks. We propose to use a pretrained convnet feature, a concatenated feature vector using activations of feature maps of multiple layers in a trained convolutional network. We show that how this convnet feature can serve as a general-purpose music representation. In the experiment, a convnet is trained for music tagging and then transferred for many music-related classification and regression tasks as well as an audio-related classification task. In experiments, the convnet feature outperforms the baseline MFCC feature in all tasks and many reported approaches of aggregating MFCCs and low- and high-level music features. version:1
arxiv-1703-09167 | A Study on the Extraction and Analysis of a Large Set of Eye Movement Features during Reading | http://arxiv.org/abs/1703.09167 | id:1703.09167 author:Ioannis Rigas, Lee Friedman, Oleg Komogortsev category:cs.CV cs.HC q-bio.QM  published:2017-03-27 summary:This work presents a study on the extraction and analysis of a set of 101 categories of eye movement features from three types of eye movement events: fixations, saccades, and post-saccadic oscillations. The eye movements were recorded during a reading task. For the categories of features with multiple instances in a recording we extract corresponding feature subtypes by calculating descriptive statistics on the distributions of these instances. A unified framework of detailed descriptions and mathematical formulas are provided for the extraction of the feature set. The analysis of feature values is performed using a large database of eye movement recordings from a normative population of 298 subjects. We demonstrate the central tendency and overall variability of feature values over the experimental population, and more importantly, we quantify the test-retest reliability (repeatability) of each separate feature. The described methods and analysis can provide valuable tools in fields exploring the eye movements, such as in behavioral studies, attention and cognition research, medical research, biometric recognition, and human-computer interaction. version:1
arxiv-1703-09165 | PWLS-ULTRA: An Efficient Clustering and Learning-Based Approach for Low-Dose 3D CT Image Reconstruction | http://arxiv.org/abs/1703.09165 | id:1703.09165 author:Xuehang Zheng, Saiprasad Ravishankar, Yong Long, Jeffrey A. Fessler category:stat.ML  published:2017-03-27 summary:The development of computed tomography (CT) image reconstruction methods that significantly reduce patient radiation exposure while maintaining high image quality is an important area of research in low-dose CT (LDCT) imaging. We propose a new penalized weighted least squares (PWLS) reconstruction method that exploits regularization based on an efficient Union of Learned TRAnsforms (PWLS-ULTRA). The union of square transforms is pre-learned from numerous image patches extracted from a dataset of CT images or volumes. The proposed PWLS-based cost function is optimized by alternating between an image update step, and a sparse coding and clustering step. The CT image update step is accelerated by a relaxed linearized augmented Lagrangian method with ordered-subsets that reduces the number of forward and backward projections. Simulations with 2D and 3D axial CT scans of the XCAT phantom and 3D helical chest scans show that for low-dose levels, the proposed method significantly improves the quality of reconstructed images compared to PWLS reconstruction with a nonadaptive edge-preserving regularizer (PWLS-EP). PWLS with regularization based on a union of learned transforms leads to better image reconstructions than using a single learned square transform or a learned overcomplete synthesis dictionary. We also incorporate patch-based weights in PWLS-ULTRA that enhance image quality and help improve image resolution uniformity. version:1
arxiv-1703-09161 | A Dynamic Programming Solution to Bounded Dejittering Problems | http://arxiv.org/abs/1703.09161 | id:1703.09161 author:Lukas F. Lang category:math.OC cs.CV  published:2017-03-27 summary:We propose a dynamic programming solution to image dejittering problems with bounded displacements and obtain efficient algorithms for the removal of line jitter, line pixel jitter, and pixel jitter. version:1
arxiv-1703-09157 | Reweighted Infrared Patch-Tensor Model With Both Non-Local and Local Priors for Single-Frame Small Target Detection | http://arxiv.org/abs/1703.09157 | id:1703.09157 author:Yimian Dai, Yiquan Wu category:cs.CV  published:2017-03-27 summary:Many state-of-the-art methods have been proposed for infrared small target detection. They work well on the images with homogeneous backgrounds and high-contrast targets. However, when facing highly heterogeneous backgrounds, they would not perform very well, mainly due to: 1) the existence of strong edges and other interfering components, 2) not utilizing the priors fully. Inspired by this, we propose a novel method to exploit both local and non-local priors simultaneously. Firstly, we employ a new infrared patch-tensor (IPT) model to represent the image and preserve its spatial correlations. Exploiting the target sparse prior and background non-local self-correlation prior, the target-background separation is modeled as a robust low-rank tensor recovery problem. Moreover, with the help of the structure tensor and reweighted idea, we design an entry-wise local-structure-adaptive and sparsity enhancing weight to replace the globally constant weighting parameter. The decomposition could be achieved via the element-wise reweighted higher-order robust principal component analysis with an additional convergence condition according to the practical situation of target detection. Extensive experiments demonstrate that our model outperforms the other state-of-the-arts, in particular for the images with very dim targets and heavy clutters. version:1
arxiv-1703-09146 | GPU Activity Prediction using Representation Learning | http://arxiv.org/abs/1703.09146 | id:1703.09146 author:Aswin Raghavan, Mohamed Amer, Timothy Shields, David Zhang, Sek Chai category:cs.LG  published:2017-03-27 summary:GPU activity prediction is an important and complex problem. This is due to the high level of contention among thousands of parallel threads. This problem was mostly addressed using heuristics. We propose a representation learning approach to address this problem. We model any performance metric as a temporal function of the executed instructions with the intuition that the flow of instructions can be identified as distinct activities of the code. Our experiments show high accuracy and non-trivial predictive power of representation learning on a benchmark. version:1
arxiv-1703-09145 | Multi-Path Region-Based Convolutional Neural Network for Accurate Detection of Unconstrained "Hard Faces" | http://arxiv.org/abs/1703.09145 | id:1703.09145 author:Yuguang Liu, Martin D. Levine category:cs.CV  published:2017-03-27 summary:Large-scale variations still pose a challenge in unconstrained face detection. To the best of our knowledge, no current face detection algorithm can detect a face as large as 800 x 800 pixels while simultaneously detecting another one as small as 8 x 8 pixels within a single image with equally high accuracy. We propose a two-stage cascaded face detection framework, Multi-Path Region-based Convolutional Neural Network (MP-RCNN), that seamlessly combines a deep neural network with a classic learning strategy, to tackle this challenge. The first stage is a Multi-Path Region Proposal Network (MP-RPN) that proposes faces at three different scales. It simultaneously utilizes three parallel outputs of the convolutional feature maps to predict multi-scale candidate face regions. The "atrous" convolution trick (convolution with up-sampled filters) and a newly proposed sampling layer for "hard" examples are embedded in MP-RPN to further boost its performance. The second stage is a Boosted Forests classifier, which utilizes deep facial features pooled from inside the candidate face regions as well as deep contextual features pooled from a larger region surrounding the candidate face regions. This step is included to further remove hard negative samples. Experiments show that this approach achieves state-of-the-art face detection performance on the WIDER FACE dataset "hard" partition, outperforming the former best result by 9.6% for the Average Precision. version:1
arxiv-1703-09068 | Automatic Decomposition of Self-Triggering Kernels of Hawkes Processes | http://arxiv.org/abs/1703.09068 | id:1703.09068 author:Rafael Lima, Jaesik Choi category:cs.LG  published:2017-03-27 summary:Hawkes Processes capture self- and mutual-excitation between events when the arrival of one event makes future ones more likely to happen in time-series data. Identification of the temporal covariance kernel can reveal the underlying structure to better predict future events. In this paper, we present a new framework to represent time-series events with a composition of self-triggering kernels of Hawkes Processes. That is, the input time-series events are decomposed into multiple Hawkes Processes with heterogeneous kernels. Our automatic decomposition procedure is composed of three main steps: (1) discretized kernel estimation through frequency domain inversion equation associated with the covariance density, (2) greedy kernel decomposition through four base kernels and their combinations (addition and multiplication), and (3) automated report generation. We demonstrate that the new automatic decomposition procedure performs better to predict future events than the existing framework in real-world data. version:1
arxiv-1703-09137 | Where to put the Image in an Image Caption Generator | http://arxiv.org/abs/1703.09137 | id:1703.09137 author:Marc Tanti, Albert Gatt, Kenneth P. Camilleri category:cs.NE cs.CL cs.CV  published:2017-03-27 summary:When a neural language model is used for caption generation, the image information can be fed to the neural network either by directly incorporating it in a recurrent neural network -- conditioning the language model by injecting image features -- or in a layer following the recurrent neural network -- conditioning the language model by merging the image features. While merging implies that visual features are bound at the end of the caption generation process, injecting can bind the visual features at a variety stages. In this paper we empirically show that late binding is superior to early binding in terms of different evaluation metrics. This suggests that the different modalities (visual and linguistic) for caption generation should not be jointly encoded by the RNN; rather, the multimodal integration should be delayed to a subsequent stage. Furthermore, this suggests that recurrent neural networks should not be viewed as actually generating text, but only as encoding it for prediction in a subsequent layer. version:1
arxiv-1703-09112 | Sparse Multi-Output Gaussian Processes for Medical Time Series Prediction | http://arxiv.org/abs/1703.09112 | id:1703.09112 author:Li-Fang Cheng, Gregory Darnell, Corey Chivers, Michael E Draugelis, Kai Li, Barbara E Engelhardt category:stat.ML  published:2017-03-27 summary:In real-time monitoring of hospital patients, high-quality inference of patients' health status using all information available from clinical covariates and lab tests are essential to enable successful medical interventions and improve patient outcomes. In this work, we develop and explore a Bayesian nonparametric model based on Gaussian process (GP) regression for hospital patient monitoring. Our method, MedGP, incorporates 24 clinical and lab covariates and supports a rich reference data set from which the relationships between these observed covariates may be inferred and exploited for high-quality inference of patient state over time. To do this, we develop a highly structured sparse GP kernel to enable tractable computation over tens of thousands of time points while estimating correlations among clinical covariates, patients, and periodicity in high-dimensional time series measurements of physiological signals. We apply MedGP to data from hundreds of thousands of patients treated at the Hospital of the University of Pennsylvania. MedGP has a number of benefits over current methods, including (i) not requiring an alignment of the time series data, (ii) quantifying confidence intervals in the predictions, (iii) exploiting a vast and rich database of patients, and (iv) providing interpretable relationships among clinical covariates. We evaluate and compare results from MedGP on the task of online state prediction for three different patient subgroups. version:1
arxiv-1703-09076 | Active Convolution: Learning the Shape of Convolution for Image Classification | http://arxiv.org/abs/1703.09076 | id:1703.09076 author:Yunho Jeon, Junmo Kim category:cs.CV  published:2017-03-27 summary:In recent years, deep learning has achieved great success in many computer vision applications. Convolutional neural networks (CNNs) have lately emerged as a major approach to image classification. Most research on CNNs thus far has focused on developing architectures such as the Inception and residual networks. The convolution layer is the core of the CNN, but few studies have addressed the convolution unit itself. In this paper, we introduce a convolution unit called the active convolution unit (ACU). A new convolution has no fixed shape, because of which we can define any form of convolution. Its shape can be learned through backpropagation during training. Our proposed unit has a few advantages. First, the ACU is a generalization of convolution; it can define not only all conventional convolutions, but also convolutions with fractional pixel coordinates. We can freely change the shape of the convolution, which provides greater freedom to form CNN structures. Second, the shape of the convolution is learned while training and there is no need to tune it by hand. Third, the ACU can learn better than a conventional unit, where we obtained the improvement simply by changing the conventional convolution to an ACU. We tested our proposed method on plain and residual networks, and the results showed significant improvement using our method on various datasets and architectures in comparison with the baseline. version:1
arxiv-1703-07737 | In Defense of the Triplet Loss for Person Re-Identification | http://arxiv.org/abs/1703.07737 | id:1703.07737 author:Alexander Hermans, Lucas Beyer, Bastian Leibe category:cs.CV cs.NE  published:2017-03-22 summary:In the past few years, the field of computer vision has gone through a revolution fueled mainly by the advent of large datasets and the adoption of deep convolutional neural networks for end-to-end learning. The person re-identification subfield is no exception to this, thanks to the notable publication of the Market-1501 and MARS datasets and several strong deep learning approaches. Unfortunately, a prevailing belief in the community seems to be that the triplet loss is inferior to using surrogate losses (classification, verification) followed by a separate metric learning step. We show that, for models trained from scratch as well as pretrained ones, using a variant of the triplet loss to perform end-to-end deep metric learning outperforms any other published method by a large margin. version:2
arxiv-1703-09046 | Bootstrapping a Lexicon for Emotional Arousal in Software Engineering | http://arxiv.org/abs/1703.09046 | id:1703.09046 author:Mika V. Mäntylä, Nicole Novielli, Filippo Lanubile, Maëlick Claes, Miikka Kuutila category:cs.SE cs.CL  published:2017-03-27 summary:Emotional arousal increases activation and performance but may also lead to burnout in software development. We present the first version of a Software Engineering Arousal lexicon (SEA) that is specifically designed to address the problem of emotional arousal in the software developer ecosystem. SEA is built using a bootstrapping approach that combines word embedding model trained on issue-tracking data and manual scoring of items in the lexicon. We show that our lexicon is able to differentiate between issue priorities, which are a source of emotional activation and then act as a proxy for arousal. The best performance is obtained by combining SEA (428 words) with a previously created general purpose lexicon by Warriner et al. (13,915 words) and it achieves Cohen's d effect sizes up to 0.5. version:1
arxiv-1703-09039 | Efficient Processing of Deep Neural Networks: A Tutorial and Survey | http://arxiv.org/abs/1703.09039 | id:1703.09039 author:Vivienne Sze, Yu-Hsin Chen, Tien-Ju Yang, Joel Emer category:cs.CV  published:2017-03-27 summary:Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of deep neural network to improve energy-efficiency and throughput without sacrificing performance accuracy or increasing hardware cost are critical to enabling the wide deployment of DNNs in AI systems. This article aims to provide a comprehensive tutorial and survey about the recent advances towards the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various platforms and architectures that support DNNs, and highlight key trends in recent efficient processing techniques that reduce the computation cost of DNNs either solely via hardware design changes or via joint hardware design and network algorithm changes. It will also summarize various development resources that can enable researchers and practitioners to quickly get started on DNN design, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic co-design, being proposed in academia and industry. The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand trade-offs between various architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand of recent implementation trends and opportunities. version:1
arxiv-1703-09035 | Deep Deterministic Policy Gradient for Urban Traffic Light Control | http://arxiv.org/abs/1703.09035 | id:1703.09035 author:Noe Casas category:cs.NE  published:2017-03-27 summary:Traffic light timing optimization is still an active line of research despite the wealth of scientific literature on the topic, and the problem remains unsolved for any non-toy scenario. One of the key issues with traffic light optimization is the large scale of the input information that is available for the controlling agent, namely all the traffic data that is continually sampled by the traffic detectors that cover the urban network. This issue has in the past forced researchers to focus on agents that work on localized parts of the traffic network, typically on individual intersections, and to coordinate every individual agent in a multi-agent setup. In order to overcome the large scale of the available state information, we propose to rely on the ability of deep Learning approaches to handle large input spaces, in the form of Deep Deterministic Policy Gradient (DDPG) algorithm. We performed several experiments with a range of models, from the very simple one (one intersection) to the more complex one (a big city section). version:1
arxiv-1703-09026 | Trespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video | http://arxiv.org/abs/1703.09026 | id:1703.09026 author:Davide Moltisanti, Michael Wray, Walterio Mayol-Cuevas, Dima Damen category:cs.CV  published:2017-03-27 summary:Manual annotations of temporal bounds for object interactions (i.e. start and end times) are typical training input to recognition, localization and detection algorithms. For three publicly available egocentric datasets, we uncover inconsistencies in ground truth temporal bounds within and across annotators and datasets. We systematically assess the robustness of state-of-the-art approaches to changes in labeled temporal bounds, for object interaction recognition. As boundaries are trespassed, a drop of up to 10% is observed for both Improved Dense Trajectories and Two-Stream Convolutional Neural Network. We demonstrate that such disagreement stems from a limited understanding of the distinct phases of an action, and propose annotating based on the Rubicon Boundaries, inspired by a similarly named cognitive model, for consistent temporal bounds of object interactions. Evaluated on a public dataset, we report a 4% increase in overall accuracy, and an increase in accuracy for 55% of classes when Rubicon Boundaries are used for temporal annotations. version:1
arxiv-1703-09013 | A Sentence Simplification System for Improving Relation Extraction | http://arxiv.org/abs/1703.09013 | id:1703.09013 author:Christina Niklaus, Bernhard Bermeitinger, Siegfried Handschuh, André Freitas category:cs.CL  published:2017-03-27 summary:In this demo paper, we present a text simplification approach that is directed at improving the performance of state-of-the-art Open Relation Extraction (RE) systems. As syntactically complex sentences often pose a challenge for current Open RE approaches, we have developed a simplification framework that performs a pre-processing step by taking a single sentence as input and using a set of syntactic-based transformation rules to create a textual input that is easier to process for subsequently applied Open RE systems. version:1
arxiv-1703-09651 | Structural Damage Identification Using Artificial Neural Network and Synthetic data | http://arxiv.org/abs/1703.09651 | id:1703.09651 author:Divya Shyam Singha, G. B. L. Chowdarya, D Roy Mahapatraa category:cs.LG cs.CE  published:2017-03-27 summary:This paper presents real-time vibration based identification technique using measured frequency response functions(FRFs) under random vibration loading. Artificial Neural Networks (ANNs) are trained to map damage fingerprints to damage characteristic parameters. Principal component statistical analysis(PCA) technique was used to tackle the problem of high dimensionality and high noise of data, which is common for industrial structures. The present study considers Crack, Rivet hole expansion and redundant uniform mass as damages on the structure. Frequency response function data after being reduced in size using PCA is fed to individual neural networks to localize and predict the severity of damage on the structure. The system of ANNs trained with both numerical and experimental model data to make the system reliable and robust. The methodology is applied to a numerical model of stiffened panel structure, where damages are confined close to the stiffener. The results showed that, in all the cases considered, it is possible to localize and predict severity of the damage occurrence with very good accuracy and reliability. version:1
arxiv-1703-08972 | Thompson Sampling for Linear-Quadratic Control Problems | http://arxiv.org/abs/1703.08972 | id:1703.08972 author:Marc Abeille, Alessandro Lazaric category:stat.ML  published:2017-03-27 summary:We consider the exploration-exploitation tradeoff in linear quadratic (LQ) control problems, where the state dynamics is linear and the cost function is quadratic in states and controls. We analyze the regret of Thompson sampling (TS) (a.k.a. posterior-sampling for reinforcement learning) in the frequentist setting, i.e., when the parameters characterizing the LQ dynamics are fixed. Despite the empirical and theoretical success in a wide range of problems from multi-armed bandit to linear bandit, we show that when studying the frequentist regret TS in control problems, we need to trade-off the frequency of sampling optimistic parameters and the frequency of switches in the control policy. This results in an overall regret of $O(T^{2/3})$, which is significantly worse than the regret $O(\sqrt{T})$ achieved by the optimism-in-face-of-uncertainty algorithm in LQ control problems. version:1
arxiv-1703-08970 | Multimodal deep learning approach for joint EEG-EMG data compression and classification | http://arxiv.org/abs/1703.08970 | id:1703.08970 author:Ahmed Ben Said, Amr Mohamed, Tarek Elfouly, Khaled Harras, Z. Jane Wang category:cs.LG  published:2017-03-27 summary:In this paper, we present a joint compression and classification approach of EEG and EMG signals using a deep learning approach. Specifically, we build our system based on the deep autoencoder architecture which is designed not only to extract discriminant features in the multimodal data representation but also to reconstruct the data from the latent representation using encoder-decoder layers. Since autoencoder can be seen as a compression approach, we extend it to handle multimodal data at the encoder layer, reconstructed and retrieved at the decoder layer. We show through experimental results, that exploiting both multimodal data intercorellation and intracorellation 1) Significantly reduces signal distortion particularly for high compression levels 2) Achieves better accuracy in classifying EEG and EMG signals recorded and labeled according to the sentiments of the volunteer. version:1
arxiv-1703-08966 | Mastering Sketching: Adversarial Augmentation for Structured Prediction | http://arxiv.org/abs/1703.08966 | id:1703.08966 author:Edgar Simo-Serra, Satoshi Iizuka, Hiroshi Ishikawa category:cs.CV  published:2017-03-27 summary:We present an integral framework for training sketch simplification networks that convert challenging rough sketches into clean line drawings. Our approach augments a simplification network with a discriminator network, training both networks jointly so that the discriminator network discerns whether a line drawing is a real training data or the output of the simplification network, which in turn tries to fool it. This approach has two major advantages. First, because the discriminator network learns the structure in line drawings, it encourages the output sketches of the simplification network to be more similar in appearance to the training sketches. Second, we can also train the simplification network with additional unsupervised data, using the discriminator network as a substitute teacher. Thus, by adding only rough sketches without simplified line drawings, or only line drawings without the original rough sketches, we can improve the quality of the sketch simplification. We show how our framework can be used to train models that significantly outperform the state of the art in the sketch simplification task, despite using the same architecture for inference. We additionally present an approach to optimize for a single image, which improves accuracy at the cost of additional computation time. Finally, we show that, using the same framework, it is possible to train the network to perform the inverse problem, i.e., convert simple line sketches into pencil drawings, which is not possible using the standard mean squared error loss. We validate our framework with two user tests, where our approach is preferred to the state of the art in sketch simplification 92.3% of the time and obtains 1.2 more points on a scale of 1 to 5. version:1
arxiv-1703-08448 | Object Region Mining with Adversarial Erasing: A Simple Classification to Semantic Segmentation Approach | http://arxiv.org/abs/1703.08448 | id:1703.08448 author:Yunchao Wei, Jiashi Feng, Xiaodan Liang, Ming-Ming Cheng, Yao Zhao, Shuicheng Yan category:cs.CV  published:2017-03-24 summary:We investigate a principle way to progressively mine discriminative object regions using classification networks to address the weakly-supervised semantic segmentation problems. Classification networks are only responsive to small and sparse discriminative regions from the object of interest, which deviates from the requirement of the segmentation task that needs to localize dense, interior and integral regions for pixel-wise inference. To mitigate this gap, we propose a new adversarial erasing approach for localizing and expanding object regions progressively. Starting with a single small object region, our proposed approach drives the classification network to sequentially discover new and complement object regions by erasing the current mined regions in an adversarial manner. These localized regions eventually constitute a dense and complete object region for learning semantic segmentation. To further enhance the quality of the discovered regions by adversarial erasing, an online prohibitive segmentation learning approach is developed to collaborate with adversarial erasing by providing auxiliary segmentation supervision modulated by the more reliable classification scores. Despite its apparent simplicity, the proposed approach achieves 55.0% and 55.7% mean Intersection-over-Union (mIoU) scores on PASCAL VOC 2012 val and test sets, which are the new state-of-the-arts. version:2
arxiv-1703-08937 | A Scale Free Algorithm for Stochastic Bandits with Bounded Kurtosis | http://arxiv.org/abs/1703.08937 | id:1703.08937 author:Tor Lattimore category:stat.ML  published:2017-03-27 summary:Existing strategies for finite-armed stochastic bandits mostly depend on a parameter of scale that must be known in advance. Sometimes this is in the form of a bound on the payoffs, or the knowledge of a variance or subgaussian parameter. The notable exceptions are the analysis of Gaussian bandits with unknown mean and variance by Cowan and Katehakis [2015] and of uniform distributions with unknown support [Cowan and Katehakis, 2015]. The results derived in these specialised cases are generalised here to the non-parametric setup, where the learner knows only a bound on the kurtosis of the noise, which is a scale free measure of the extremity of outliers. version:1
arxiv-1703-08933 | Multiple Instance Learning with the Optimal Sub-Pattern Assignment Metric | http://arxiv.org/abs/1703.08933 | id:1703.08933 author:Quang N. Tran, Ba-Ngu Vo, Dinh Phung, Ba-Tuong Vo, Thuong Nguyen category:cs.LG  published:2017-03-27 summary:Multiple instance data are sets or multi-sets of unordered elements. Using metrics or distances for sets, we propose an approach to several multiple instance learning tasks, such as clustering (unsupervised learning), classification (supervised learning), and novelty detection (semi-supervised learning). In particular, we introduce the Optimal Sub-Pattern Assignment metric to multiple instance learning so as to provide versatile design choices. Numerical experiments on both simulated and real data are presented to illustrate the versatility of the proposed solution. version:1
arxiv-1703-05870 | DropRegion Training of Inception Font Network for High-Performance Chinese Font Recognition | http://arxiv.org/abs/1703.05870 | id:1703.05870 author:Shuangping Huangm Zhuoyao Zhong, Lianwen Jin, Shuye Zhang, Haobin Wang category:cs.CV  published:2017-03-17 summary:Chinese font recognition (CFR) has gained significant attention in recent years. However, due to the sparsity of labeled font samples and the structural complexity of Chinese characters, CFR is still a challenging task. In this paper, a DropRegion method is proposed to generate a large number of stochastic variant font samples whose local regions are selectively disrupted and an inception font network (IFN) with two additional convolutional neural network (CNN) structure elements, i.e., a cascaded cross-channel parametric pooling (CCCP) and global average pooling, is designed. Because the distribution of strokes in a font image is non-stationary, an elastic meshing technique that adaptively constructs a set of local regions with equalized information is developed. Thus, DropRegion is seamlessly embedded in the IFN, which enables end-to-end training; the proposed DropRegion-IFN can be used for high performance CFR. Experimental results have confirmed the effectiveness of our new approach for CFR. version:2
arxiv-1703-08919 | MIHash: Online Hashing with Mutual Information | http://arxiv.org/abs/1703.08919 | id:1703.08919 author:Fatih Cakir, Kun He, Sarah Adel Bargal, Stan Sclaroff category:cs.CV  published:2017-03-27 summary:Learning-based adaptive hashing methods are widely used for nearest neighbor retrieval. Recently, online hashing methods have demonstrated a good performance-complexity tradeoff by learning hash functions from streaming data. In this paper, we aim to advance the state-of-the-art for online hashing. We first address a key challenge that has often been ignored: the binary codes for indexed data must be recomputed to keep pace with updates to the hash functions. We propose an efficient quality measure for hash functions, based on an information-theoretic quantity, mutual information, and use it successfully as a criterion to eliminate unnecessary hash table updates. Next, we show that mutual information can also be used as an objective in learning hash functions, using gradient-based optimization. Experiments on image retrieval benchmarks (including a 2.5M image dataset) confirm the effectiveness of our formulation, both in reducing hash table recomputations and in learning high-quality hash functions. version:1
arxiv-1703-08917 | A Visual Measure of Changes to Weighted Self-Organizing Map Patterns | http://arxiv.org/abs/1703.08917 | id:1703.08917 author:Younjin Chung, Joachim Gudmundsson, Masahiro Takatsuka category:cs.CV  published:2017-03-27 summary:Estimating output changes by input changes is the main task in causal analysis. In previous work, input and output Self-Organizing Maps (SOMs) were associated for causal analysis of multivariate and nonlinear data. Based on the association, a weight distribution of the output conditional on a given input was obtained over the output map space. Such a weighted SOM pattern of the output changes when the input changes. In order to analyze the change, it is important to measure the difference of the patterns. Many methods have been proposed for the dissimilarity measure of patterns. However, it remains a major challenge when attempting to measure how the patterns change. In this paper, we propose a visualization approach that simplifies the comparison of the difference in terms of the pattern property. Using this approach, the change can be analyzed by integrating colors and star glyph shapes representing the property dissimilarity. Ecological data is used to demonstrate the usefulness of our approach and the experimental results show that our approach provides the change information effectively. version:1
arxiv-1703-08912 | Exploiting Color Name Space for Salient Object Detection | http://arxiv.org/abs/1703.08912 | id:1703.08912 author:Jing Lou, Huan Wang, Longtao Chen, Qingyuan Xia, Wei Zhu, Mingwu Ren category:cs.CV I.4  published:2017-03-27 summary:In this paper, we will investigate the contribution of color names for salient object detection. Each input image is first converted to the color name space, which is consisted of 11 probabilistic channels. By exploring the topological structure relationship between the figure and the ground, we obtain a saliency map through a linear combination of a set of sequential attention maps. To overcome the limitation of only exploiting the surroundedness cue, two global cues with respect to color names are invoked for guiding the computation of another weighted saliency map. Finally, we integrate the two saliency maps into a unified framework to infer the saliency result. In addition, an improved post-processing procedure is introduced to effectively suppress the background while uniformly highlight the salient objects. Experimental results show that the proposed model produces more accurate saliency maps and performs well against 23 saliency models in terms of three evaluation metrics on three public datasets. version:1
arxiv-1703-09570 | A Tidy Data Model for Natural Language Processing using cleanNLP | http://arxiv.org/abs/1703.09570 | id:1703.09570 author:Taylor Arnold category:cs.CL stat.CO  published:2017-03-27 summary:The package cleanNLP provides a set of fast tools for converting a textual corpus into a set of normalized tables. The underlying natural language processing pipeline utilizes Stanford's CoreNLP library, exposing a number of annotation tasks for text written in English, French, German, and Spanish. Annotators include tokenization, part of speech tagging, named entity recognition, entity linking, sentiment analysis, dependency parsing, coreference resolution, and information extraction. version:1
arxiv-1703-08897 | Transductive Zero-Shot Learning with Adaptive Structural Embedding | http://arxiv.org/abs/1703.08897 | id:1703.08897 author:Yunlong Yu, Zhong Ji, Jichang Guo, Yanwei Pang category:cs.CV  published:2017-03-27 summary:Zero-shot learning (ZSL) endows the computer vision system with the inferential capability to recognize instances of a new category that has never seen before. Two fundamental challenges in it are visual-semantic embedding and domain adaptation in cross-modality learning and unseen class prediction steps, respectively. To address both challenges, this paper presents two corresponding methods named Adaptive STructural Embedding (ASTE) and Self-PAsed Selective Strategy (SPASS), respectively. Specifically, ASTE formulates the visualsemantic interactions in a latent structural SVM framework to adaptively adjust the slack variables to embody the different reliableness among training instances. In this way, the reliable instances are imposed with small punishments, wheras the less reliable instances are imposed with more severe punishments. Thus, it ensures a more discriminative embedding. On the other hand, SPASS offers a framework to alleviate the domain shift problem in ZSL, which exploits the unseen data in an easy to hard fashion. Particularly, SPASS borrows the idea from selfpaced learning by iteratively selecting the unseen instances from reliable to less reliable to gradually adapt the knowledge from the seen domain to the unseen domain. Subsequently, by combining SPASS and ASTE, we present a self-paced Transductive ASTE (TASTE) method to progressively reinforce the classification capacity. Extensive experiments on three benchmark datasets (i.e., AwA, CUB, and aPY) demonstrate the superiorities of ASTE and TASTE. Furthermore, we also propose a fast training (FT) strategy to improve the efficiency of most of existing ZSL methods. The FT strategy is surprisingly simple and general enough, which can speed up the training time of most existing methods by 4~300 times while holding the previous performance. version:1
arxiv-1703-08893 | Transductive Zero-Shot Learning with a Self-training dictionary approach | http://arxiv.org/abs/1703.08893 | id:1703.08893 author:Yunlong Yu, Zhong Ji, Xi Li, Jichang Guo, Zhongfei Zhang, Haibin Ling, Fei Wu category:cs.CV  published:2017-03-27 summary:As an important and challenging problem in computer vision, zero-shot learning (ZSL) aims at automatically recognizing the instances from unseen object classes without training data. To address this problem, ZSL is usually carried out in the following two aspects: 1) capturing the domain distribution connections between seen classes data and unseen classes data; and 2) modeling the semantic interactions between the image feature space and the label embedding space. Motivated by these observations, we propose a bidirectional mapping based semantic relationship modeling scheme that seeks for crossmodal knowledge transfer by simultaneously projecting the image features and label embeddings into a common latent space. Namely, we have a bidirectional connection relationship that takes place from the image feature space to the latent space as well as from the label embedding space to the latent space. To deal with the domain shift problem, we further present a transductive learning approach that formulates the class prediction problem in an iterative refining process, where the object classification capacity is progressively reinforced through bootstrapping-based model updating over highly reliable instances. Experimental results on three benchmark datasets (AwA, CUB and SUN) demonstrate the effectiveness of the proposed approach against the state-of-the-art approaches. version:1
arxiv-1703-08885 | Question Answering from Unstructured Text by Retrieval and Comprehension | http://arxiv.org/abs/1703.08885 | id:1703.08885 author:Yusuke Watanabe, Bhuwan Dhingra, Ruslan Salakhutdinov category:cs.CL  published:2017-03-26 summary:Open domain Question Answering (QA) systems must interact with external knowledge sources, such as web pages, to find relevant information. Information sources like Wikipedia, however, are not well structured and difficult to utilize in comparison with Knowledge Bases (KBs). In this work we present a two-step approach to question answering from unstructured text, consisting of a retrieval step and a comprehension step. For comprehension, we present an RNN based attention model with a novel mixture mechanism for selecting answers from either retrieved articles or a fixed vocabulary. For retrieval we introduce a hand-crafted model and a neural model for ranking relevant articles. We achieve state-of-the-art performance on W IKI M OVIES dataset, reducing the error by 40%. Our experimental results further demonstrate the importance of each of the introduced components. version:1
arxiv-1703-08866 | Multi-View Deep Learning for Consistent Semantic Mapping with RGB-D Cameras | http://arxiv.org/abs/1703.08866 | id:1703.08866 author:Lingni Ma, Jörg Stückler, Christian Kerl, Daniel Cremers category:cs.CV  published:2017-03-26 summary:Visual scene understanding is an important capability that enables robots to purposefully act in their environment. In this paper, we propose a novel approach to object-class segmentation from multiple RGB-D views using deep learning. We train a deep neural network to predict object-class semantics that is consistent from several view points in a semi-supervised way. At test time, the semantics predictions of our network can be fused more consistently in semantic keyframe maps than predictions of a network trained on individual views. We base our network architecture on a recent single-view deep learning approach to RGB and depth fusion for semantic object-class segmentation and enhance it with multi-scale loss minimization. We obtain the camera trajectory using RGB-D SLAM and warp the predictions of RGB-D images into ground-truth annotated frames in order to enforce multi-view consistency during training. At test time, predictions from multiple views are fused into keyframes. We propose and analyze several methods for enforcing multi-view consistency during training and testing. We evaluate the benefit of multi-view consistency training and demonstrate that pooling of deep features and fusion over multiple views outperforms single-view baselines on the NYUDv2 benchmark for semantic segmentation. Our end-to-end trained network achieves state-of-the-art performance on the NYUDv2 dataset in single-view segmentation as well as multi-view semantic fusion. version:1
arxiv-1703-08864 | Learning Simpler Language Models with the Delta Recurrent Neural Network Framework | http://arxiv.org/abs/1703.08864 | id:1703.08864 author:Alexander G. Ororbia II, Tomas Mikolov, David Reitter category:cs.CL  published:2017-03-26 summary:Learning useful information across long time lags is a critical and difficult problem for temporal neural models in tasks like language modeling. Existing architectures that address the issue are often complex and costly to train. The Delta Recurrent Neural Network (Delta-RNN) framework is a simple and high-performing design that unifies previously proposed gated neural models. The Delta-RNN models maintain longer-term memory by learning to interpolate between a fast-changing data-driven representation and a slowly changing, implicitly stable state. This requires hardly any more parameters than a classical simple recurrent network. The models outperform popular complex architectures, such as the Long Short Term Memory (LSTM) and the Gated Recurrent Unit (GRU) and achieve state-of-the art performance in language modeling at character and word levels and yield comparable performance at the subword level. version:1
arxiv-1703-06959 | CSI: A Hybrid Deep Model for Fake News | http://arxiv.org/abs/1703.06959 | id:1703.06959 author:Natali Ruchansky, Sungyong Seo, Yan Liu category:cs.LG cs.SI  published:2017-03-20 summary:In the recent political climate, the topic of fake news has drawn attention both from the public and the academic communities. Such misinformation has been cited to have a strong impact on public opinion, presenting the opportunity for malicious manipulation. Detecting fake news is an important, yet challenging problem since it is often difficult for humans to distinguish misinformation. However, there have been three generally agreed upon characteristics of fake news: the text, the response received, and the source users promoting it. Existing work has largely focused on tailoring solutions to a particular characteristic, but the complexity of the fake news epidemic limited their success and generality. In this work, we propose a model that combines all three characteristics for a more accurate and automated prediction. Specifically, we incorporate the behavior of both parties, users and articles, and the group behavior of users who propagate fake news. Motivated by the three characteristics, we propose a model called CSI, which is composed of three modules: Capture, Score, and Integrate. The first module uses a Recurrent Neural Network (RNN) to capture the temporal pattern of user activity that occurred with a given article, and the second captures the behavior of users over time. The two are then integrated with the third module to classify an article as fake or not. Through experimental analysis on real-world data, we demonstrate that CSI achieves higher accuracy than existing models. Further, we show that each module captures relevant behavioral information both on users and articles with respect to the propagation of fake news. version:2
arxiv-1703-08840 | Inferring The Latent Structure of Human Decision-Making from Raw Visual Inputs | http://arxiv.org/abs/1703.08840 | id:1703.08840 author:Yunzhu Li, Jiaming Song, Stefano Ermon category:cs.LG cs.AI cs.CV  published:2017-03-26 summary:The goal of imitation learning is to match example expert behavior, without access to a reinforcement signal. Expert demonstrations provided by humans, however, often show significant variability due to latent factors that are not explicitly modeled. We introduce an extension to the Generative Adversarial Imitation Learning method that can infer the latent structure of human decision-making in an unsupervised way. Our method can not only imitate complex behaviors, but also learn interpretable and meaningful representations. We demonstrate that the approach is applicable to high-dimensional environments including raw visual inputs. In the highway driving domain, we show that a model learned from demonstrations is able to both produce different styles of human-like driving behaviors and accurately anticipate human actions. Our method surpasses various baselines in terms of performance and functionality. version:1
arxiv-1703-08838 | Distributed Voting/Ranking with Optimal Number of States per Node | http://arxiv.org/abs/1703.08838 | id:1703.08838 author:Saber Salehkaleybar, Arsalan Sharif-Nassab, S. Jamaloddin Golestani category:cs.DC cs.LG  published:2017-03-26 summary:Considering a network with $n$ nodes, where each node initially votes for one (or more) choices out of $K$ possible choices, we present a Distributed Multi-choice Voting/Ranking (DMVR) algorithm to determine either the choice with maximum vote (the voting problem) or to rank all the choices in terms of their acquired votes (the ranking problem). The algorithm consolidates node votes across the network by updating the states of interacting nodes using two key operations, the union and the intersection. The proposed algorithm is simple, independent from network size, and easily scalable in terms of the number of choices $K$, using only $K\times 2^{K-1}$ nodal states for voting, and $K\times K!$ nodal states for ranking. We prove the number of states to be optimal in the ranking case, this optimality is conjectured to also apply to the voting case. The time complexity of the algorithm is analyzed in complete graphs. We show that the time complexity for both ranking and voting is $O(\log(n))$ for given vote percentages, and is inversely proportional to the minimum of the vote percentage differences among various choices. version:1
arxiv-1703-08837 | Person Re-Identification by Camera Correlation Aware Feature Augmentation | http://arxiv.org/abs/1703.08837 | id:1703.08837 author:Ying-Cong Chen, Xiatian Zhu, Wei-Shi Zheng, Jian-Huang Lai category:cs.CV  published:2017-03-26 summary:The challenge of person re-identification (re-id) is to match individual images of the same person captured by different non-overlapping camera views against significant and unknown cross-view feature distortion. While a large number of distance metric/subspace learning models have been developed for re-id, the cross-view transformations they learned are view-generic and thus potentially less effective in quantifying the feature distortion inherent to each camera view. Learning view-specific feature transformations for re-id (i.e., view-specific re-id), an under-studied approach, becomes an alternative resort for this problem. In this work, we formulate a novel view-specific person re-identification framework from the feature augmentation point of view, called Camera coRrelation Aware Feature augmenTation (CRAFT). Specifically, CRAFT performs cross-view adaptation by automatically measuring camera correlation from cross-view visual data distribution and adaptively conducting feature augmentation to transform the original features into a new adaptive space. Through our augmentation framework, view-generic learning algorithms can be readily generalized to learn and optimize view-specific sub-models whilst simultaneously modelling view-generic discrimination information. Therefore, our framework not only inherits the strength of view-generic model learning but also provides an effective way to take into account view specific characteristics. Our CRAFT framework can be extended to jointly learn view-specific feature transformations for person re-id across a large network with more than two cameras, a largely under-investigated but realistic re-id setting. Additionally, we present a domain-generic deep person appearance representation which is designed particularly to be towards view invariant for facilitating cross-view adaptation by CRAFT. version:1
arxiv-1703-08836 | Learned multi-patch similarity | http://arxiv.org/abs/1703.08836 | id:1703.08836 author:Wilfried Hartmann, Silvano Galliani, Michal Havlena, Konrad Schindler, Luc Van Gool category:cs.CV cs.LG  published:2017-03-26 summary:Estimating a depth map from multiple views of a scene is a fundamental task in computer vision. As soon as more than two viewpoints are available, one faces the very basic question how to measure similarity across >2 image patches. Surprisingly, no direct solution exists, instead it is common to fall back to more or less robust averaging of two-view similarities. Encouraged by the success of machine learning, and in particular convolutional neural networks, we propose to learn a matching function which directly maps multiple image patches to a scalar similarity score. Experiments on several multi-view datasets demonstrate that this approach has advantages over methods based on pairwise patch similarity. version:1
arxiv-1703-08831 | Token-based Function Computation with Memory | http://arxiv.org/abs/1703.08831 | id:1703.08831 author:Saber Salehkaleybar, S. Jamaloddin Golestani category:cs.DC stat.ML  published:2017-03-26 summary:In distributed function computation, each node has an initial value and the goal is to compute a function of these values in a distributed manner. In this paper, we propose a novel token-based approach to compute a wide class of target functions to which we refer as "Token-based function Computation with Memory" (TCM) algorithm. In this approach, node values are attached to tokens and travel across the network. Each pair of travelling tokens would coalesce when they meet, forming a token with a new value as a function of the original token values. In contrast to the Coalescing Random Walk (CRW) algorithm, where token movement is governed by random walk, meeting of tokens in our scheme is accelerated by adopting a novel chasing mechanism. We proved that, compared to the CRW algorithm, the TCM algorithm results in a reduction of time complexity by a factor of at least $\sqrt{n/\log(n)}$ in Erd\"os-Renyi and complete graphs, and by a factor of $\log(n)/\log(\log(n))$ in torus networks. Simulation results show that there is at least a constant factor improvement in the message complexity of TCM algorithm in all considered topologies. Robustness of the CRW and TCM algorithms in the presence of node failure is analyzed. We show that their robustness can be improved by running multiple instances of the algorithms in parallel. version:1
arxiv-1703-08825 | Surrogate Model of Multi-Period Flexibility from a Home Energy Management System | http://arxiv.org/abs/1703.08825 | id:1703.08825 author:Rui Pinto, Ricardo Bessa, Manuel Matos category:cs.NE cs.AI  published:2017-03-26 summary:Near-future electric distribution grids operation will have to rely on demand-side flexibility, both by implementation of demand response strategies and by taking advantage of the intelligent management of increasingly common small-scale energy storage. Home energy management systems (HEMS) will play a crucial role on the flexibility provision to both system operators and market players like aggregators. Modeling multi-period flexibility from residential consumers (HEMS flexibility), such as battery storage and electric water heater, while complying with internal constraints (comfort levels, data privacy) and uncertainty is a complex task. This paper describes a computational method that is capable of efficiently define and learn the feasible flexibility set from controllable resources connected to a HEMS. An Evolutionary Particle Swarm Optimization (EPSO) algorithm is adopted and reshaped to derive a set of feasible temporal trajectories for the residential net-load, considering storage, flexible appliances, and predefined costumer preferences, as well as load and photovoltaic (PV) forecast uncertainty. A support vector data description (SVDD) algorithm is used to build models capable of classifying feasible and unfeasible HEMS operating trajectories upon request from an optimization/control algorithm operated by a DSO or market player. version:1
arxiv-1703-08816 | Uncertainty Quantification in the Classification of High Dimensional Data | http://arxiv.org/abs/1703.08816 | id:1703.08816 author:Andrea L. Bertozzi, Xiyang Luo, Andrew M. Stuart, Konstantinos C. Zygalakis category:cs.LG stat.ML  published:2017-03-26 summary:Classification of high dimensional data finds wide-ranging applications. In many of these applications equipping the resulting classification with a measure of uncertainty may be as important as the classification itself. In this paper we introduce, develop algorithms for, and investigate the properties of, a variety of Bayesian models for the task of binary classification; via the posterior distribution on the classification labels, these methods automatically give measures of uncertainty. The methods are all based around the graph formulation of semi-supervised learning. We provide a unified framework which brings together a variety of methods which have been introduced in different communities within the mathematical sciences. We study probit classification, generalize the level-set method for Bayesian inverse problems to the classification setting, and generalize the Ginzburg-Landau optimization-based classifier to a Bayesian setting; we also show that the probit and level set approaches are natural relaxations of the harmonic function approach. We introduce efficient numerical methods, suited to large data-sets, for both MCMC-based sampling as well as gradient-based MAP estimation. Through numerical experiments we study classification accuracy and uncertainty quantification for our models; these experiments showcase a suite of datasets commonly used to evaluate graph-based semi-supervised learning algorithms. version:1
arxiv-1703-06412 | TAC-GAN - Text Conditioned Auxiliary Classifier Generative Adversarial Network | http://arxiv.org/abs/1703.06412 | id:1703.06412 author:Ayushman Dash, John Cristian Borges Gamboa, Sheraz Ahmed, Marcus Liwicki, Muhammad Zeshan Afzal category:cs.CV  published:2017-03-19 summary:In this work, we present the Text Conditioned Auxiliary Classifier Generative Adversarial Network, (TAC-GAN) a text to image Generative Adversarial Network (GAN) for synthesizing images from their text descriptions. Former approaches have tried to condition the generative process on the textual data; but allying it to the usage of class information, known to diversify the generated samples and improve their structural coherence, has not been explored. We trained the presented TAC-GAN model on the Oxford-102 dataset of flowers, and evaluated the discriminability of the generated images with Inception-Score, as well as their diversity using the Multi-Scale Structural Similarity Index (MS-SSIM). Our approach outperforms the state-of-the-art models, i.e., its inception score is 3.45, corresponding to a relative increase of 7.8% compared to the recently introduced StackGan. A comparison of the mean MS-SSIM scores of the training and generated samples per class shows that our approach is able to generate highly diverse images with an average MS-SSIM of 0.14 over all generated classes. version:2
arxiv-1703-08774 | Who Said What: Modeling Individual Labelers Improves Classification | http://arxiv.org/abs/1703.08774 | id:1703.08774 author:Melody Y. Guan, Varun Gulshan, Andrew M. Dai, Geoffrey E. Hinton category:cs.LG cs.CV  published:2017-03-26 summary:Data are often labeled by many different experts with each expert only labeling a small fraction of the data and each data point being labeled by several experts. This reduces the workload on individual experts and also gives a better estimate of the unobserved ground truth. When experts disagree, the standard approaches are to treat the majority opinion as the correct label or to model the correct label as a distribution. These approaches, however, do not make any use of potentially valuable information about which expert produced which label. To make use of this extra information, we propose modeling the experts individually and then learning averaging weights for combining them, possibly in sample-specific ways. This allows us to give more weight to more reliable experts and take advantage of the unique strengths of individual experts at classifying certain types of data. Here we show that our approach leads to improvements in computer-aided diagnosis of diabetic retinopathy. We also show that our method performs better than competing algorithms by Welinder and Perona, and by Mnih and Hinton. Our work offers an innovative approach for dealing with the myriad real-world settings that use expert opinions to define labels for training. version:1
arxiv-1703-08772 | Multivariate Regression with Gross Errors on Manifold-valued Data | http://arxiv.org/abs/1703.08772 | id:1703.08772 author:Xiaowei Zhang, Xudong Shi, Yu Sun, Li Cheng category:stat.ML cs.CV math.OC  published:2017-03-26 summary:We consider the topic of multivariate regression on manifold-valued output, that is, for a multivariate observation, its output response lies on a manifold. Moreover, we propose a new regression model to deal with the presence of grossly corrupted manifold-valued responses, a bottleneck issue commonly encountered in practical scenarios. Our model first takes a correction step on the grossly corrupted responses via geodesic curves on the manifold, and then performs multivariate linear regression on the corrected data. This results in a nonconvex and nonsmooth optimization problem on manifolds. To this end, we propose a dedicated approach named PALMR, by utilizing and extending the proximal alternating linearized minimization techniques. Theoretically, we investigate its convergence property, where it is shown to converge to a critical point under mild conditions. Empirically, we test our model on both synthetic and real diffusion tensor imaging data, and show that our model outperforms other multivariate regression models when manifold-valued responses contain gross errors, and is effective in identifying gross errors. version:1
arxiv-1703-08764 | Structured Learning of Tree Potentials in CRF for Image Segmentation | http://arxiv.org/abs/1703.08764 | id:1703.08764 author:Fayao Liu, Guosheng Lin, Ruizhi Qiao, Chunhua Shen category:cs.CV  published:2017-03-26 summary:We propose a new approach to image segmentation, which exploits the advantages of both conditional random fields (CRFs) and decision trees. In the literature, the potential functions of CRFs are mostly defined as a linear combination of some pre-defined parametric models, and then methods like structured support vector machines (SSVMs) are applied to learn those linear coefficients. We instead formulate the unary and pairwise potentials as nonparametric forests---ensembles of decision trees, and learn the ensemble parameters and the trees in a unified optimization problem within the large-margin framework. In this fashion, we easily achieve nonlinear learning of potential functions on both unary and pairwise terms in CRFs. Moreover, we learn class-wise decision trees for each object that appears in the image. Due to the rich structure and flexibility of decision trees, our approach is powerful in modelling complex data likelihoods and label relationships. The resulting optimization problem is very challenging because it can have exponentially many variables and constraints. We show that this challenging optimization can be efficiently solved by combining a modified column generation and cutting-planes techniques. Experimental results on both binary (Graz-02, Weizmann horse, Oxford flower) and multi-class (MSRC-21, PASCAL VOC 2012) segmentation datasets demonstrate the power of the learned nonlinear nonparametric potentials. version:1
arxiv-1703-08025 | Saliency-guided video classification via adaptively weighted learning | http://arxiv.org/abs/1703.08025 | id:1703.08025 author:Yunzhen Zhao, Yuxin Peng category:cs.CV  published:2017-03-23 summary:Video classification is productive in many practical applications, and the recent deep learning has greatly improved its accuracy. However, existing works often model video frames indiscriminately, but from the view of motion, video frames can be decomposed into salient and non-salient areas naturally. Salient and non-salient areas should be modeled with different networks, for the former present both appearance and motion information, and the latter present static background information. To address this problem, in this paper, video saliency is predicted by optical flow without supervision firstly. Then two streams of 3D CNN are trained individually for raw frames and optical flow on salient areas, and another 2D CNN is trained for raw frames on non-salient areas. For the reason that these three streams play different roles for each class, the weights of each stream are adaptively learned for each class. Experimental results show that saliency-guided modeling and adaptively weighted learning can reinforce each other, and we achieve the state-of-the-art results. version:2
arxiv-1703-08748 | LEPOR: An Augmented Machine Translation Evaluation Metric | http://arxiv.org/abs/1703.08748 | id:1703.08748 author:Lifeng Han category:cs.CL  published:2017-03-26 summary:Machine translation (MT) was developed as one of the hottest research topics in the natural language processing (NLP) literature. One important issue in MT is that how to evaluate the MT system reasonably and tell us whether the translation system makes an improvement or not. The traditional manual judgment methods are expensive, time-consuming, unrepeatable, and sometimes with low agreement. On the other hand, the popular automatic MT evaluation methods have some weaknesses. Firstly, they tend to perform well on the language pairs with English as the target language, but weak when English is used as source. Secondly, some methods rely on many additional linguistic features to achieve good performance, which makes the metric unable to replicate and apply to other language pairs easily. Thirdly, some popular metrics utilize incomprehensive factors, which result in low performance on some practical tasks. In this thesis, to address the existing problems, we design novel MT evaluation methods and investigate their performances on different languages. Firstly, we design augmented factors to yield highly accurate evaluation.Secondly, we design a tunable evaluation model where weighting of factors can be optimised according to the characteristics of languages. Thirdly, in the enhanced version of our methods, we design concise linguistic feature using POS to show that our methods can yield even higher performance when using some external linguistic resources. Finally, we introduce the practical performance of our metrics in the ACL-WMT workshop shared tasks, which show that the proposed methods are robust across different languages. version:1
arxiv-1703-10039 | Cohesion-based Online Actor-Critic Reinforcement Learning for mHealth Intervention | http://arxiv.org/abs/1703.10039 | id:1703.10039 author:Feiyun Zhu, Peng Liao, Xinliang Zhu, Yaowen Yao, Junzhou Huang category:cs.LG  published:2017-03-25 summary:In the wake of the vast population of smart device users worldwide, mobile health (mHealth) technologies are hopeful to generate positive and wide influence on people's health. They are able to provide flexible, affordable and portable health guides to device users. Current online decision-making methods for mHealth assume that the users are completely heterogeneous. They share no information among users and learn a separate policy for each user. However, data for each user is very limited in size to support the separate online learning, leading to unstable policies that contain lots of variances. Besides, we find the truth that a user may be similar with some, but not all, users, and connected users tend to have similar behaviors. In this paper, we propose a network cohesion constrained (actor-critic) Reinforcement Learning (RL) method for mHealth. The goal is to explore how to share information among similar users to better convert the limited user information into sharper learned policies. To the best of our knowledge, this is the first online actor-critic RL for mHealth and first network cohesion constrained (actor-critic) RL method in all applications. The network cohesion is important to derive effective policies. We come up with a novel method to learn the network by using the warm start trajectory, which directly reflects the users' property. The optimization of our model is difficult and very different from the general supervised learning due to the indirect observation of values. As a contribution, we propose two algorithms for the proposed online RLs. Apart from mHealth, the proposed methods can be easily applied or adapted to other health-related tasks. Extensive experiment results on the HeartSteps dataset demonstrates that in a variety of parameter settings, the proposed two methods obtain obvious improvements over the state-of-the-art methods. version:1
arxiv-1703-08738 | Sketch-based Face Editing in Video Using Identity Deformation Transfer | http://arxiv.org/abs/1703.08738 | id:1703.08738 author:Long Zhao, Fangda Han, Mubbasir Kapadia, Vladimir Pavlovic, Dimitris Metaxas category:cs.CV  published:2017-03-25 summary:We address the problem of using hand-drawn sketch to edit facial identity, such as enlarging the shape or modifying the position of eyes or mouth, in the whole video. This task is formulated as a 3D face model reconstruction and deformation problem. We first introduce a two-stage real-time 3D face model fitting schema to recover facial identity and expressions from the video. We recognize the user's editing intention from the input sketch as a set of facial modifications. A novel identity deformation algorithm is then proposed to transfer these deformations from 2D space to 3D facial identity directly, while preserving the facial expressions. Finally, these changes are propagated to the whole video with the modified identity. Experimental results demonstrate that our method can effectively edit facial identity in video based on the input sketch with high consistency and fidelity. version:1
arxiv-1703-08737 | Learning to Predict: A Fast Re-constructive Method to Generate Multimodal Embeddings | http://arxiv.org/abs/1703.08737 | id:1703.08737 author:Guillem Collell, Teddy Zhang, Marie-Francine Moens category:stat.ML  published:2017-03-25 summary:Integrating visual and linguistic information into a single multimodal representation is an unsolved problem with wide-reaching applications to both natural language processing and computer vision. In this paper, we present a simple method to build multimodal representations by learning a language-to-vision mapping and using its output to build multimodal embeddings. In this sense, our method provides a cognitively plausible way of building representations, consistent with the inherently re-constructive and associative nature of human memory. Using seven benchmark concept similarity tests we show that the mapped vectors not only implicitly encode multimodal information, but also outperform strong unimodal baselines and state-of-the-art multimodal methods, thus exhibiting more "human-like" judgments---particularly in zero-shot settings. version:1
arxiv-1703-08710 | Count-ception: Counting by Fully Convolutional Redundant Counting | http://arxiv.org/abs/1703.08710 | id:1703.08710 author:Joseph Paul Cohen, Henry Z. Lo, Yoshua Bengio category:cs.CV cs.LG stat.ML  published:2017-03-25 summary:Counting objects in digital images is a process that should be replaced by machines. This tedious task is time consuming and prone to errors due to fatigue of human annotators. The goal is to have a system that takes as input an image and returns a count of the objects inside and justification for the prediction in the form of object localization. We repose a problem, originally posed by Lempitsky and Zisserman, to instead predict a count map which contains redundant counts based on the receptive field of a smaller regression network. The regression network predicts a count of the objects that exist inside this frame. By processing the image in a fully convolutional way each pixel is going to be accounted for some number of times, the number of windows which include it, which is the size of each window, (i.e., 32x32 = 1024). To recover the true count take the average over the redundant predictions. Our contribution is redundant counting instead of predicting a density map in order to average over errors. We also propose a novel deep neural network architecture adapted from the Inception family of networks called the Count-ception network. Together our approach results in a 20% gain over the state of the art method by Xie, Noble, and Zisserman in 2016. version:1
arxiv-1703-06182 | Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability | http://arxiv.org/abs/1703.06182 | id:1703.06182 author:Shayegan Omidshafiei, Jason Pazis, Christopher Amato, Jonathan P. How, John Vian category:cs.LG cs.AI  published:2017-03-17 summary:Many real-world tasks involve multiple agents with partial observability and limited communication. Learning is challenging in these settings due to local viewpoints of agents, which perceive the world as non-stationary due to concurrently-exploring teammates. Approaches that learn specialized policies for individual tasks face major problems when applied to the real world: not only do agents have to learn and store a distinct policy for each task, but in practice the identity of the task is often non-observable, making these algorithms inapplicable. This paper formalizes and addresses the problem of multi-task multi-agent reinforcement learning under partial observability. We introduce a decentralized single-task learning approach that is robust to concurrent interactions of teammates, and present an approach for distilling single-task policies into a unified policy that performs well across multiple related tasks, without explicit provision of task identity. version:2
arxiv-1703-08705 | Comparing Rule-Based and Deep Learning Models for Patient Phenotyping | http://arxiv.org/abs/1703.08705 | id:1703.08705 author:Sebastian Gehrmann, Franck Dernoncourt, Yeran Li, Eric T. Carlson, Joy T. Wu, Jonathan Welt, John Foote Jr., Edward T. Moseley, David W. Grant, Patrick D. Tyler, Leo Anthony Celi category:cs.CL cs.AI cs.NE stat.ML  published:2017-03-25 summary:Objective: We investigate whether deep learning techniques for natural language processing (NLP) can be used efficiently for patient phenotyping. Patient phenotyping is a classification task for determining whether a patient has a medical condition, and is a crucial part of secondary analysis of healthcare data. We assess the performance of deep learning algorithms and compare them with classical NLP approaches. Materials and Methods: We compare convolutional neural networks (CNNs), n-gram models, and approaches based on cTAKES that extract pre-defined medical concepts from clinical notes and use them to predict patient phenotypes. The performance is tested on 10 different phenotyping tasks using 1,610 discharge summaries extracted from the MIMIC-III database. Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The average F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our model having an F1-score up to 37 points higher than alternative approaches. We additionally assess the interpretability of our model by presenting a method that extracts the most salient phrases for a particular prediction. Conclusion: We show that NLP methods based on deep learning improve the performance of patient phenotyping. Our CNN-based algorithm automatically learns the phrases associated with each patient phenotype. As such, it reduces the annotation complexity for clinical domain experts, who are normally required to develop task-specific annotation rules and identify relevant phrases. Our method performs well in terms of both performance and interpretability, which indicates that deep learning is an effective approach to patient phenotyping based on clinicians' notes. version:1
arxiv-1703-08701 | Morphological Analysis for the Maltese Language: The Challenges of a Hybrid System | http://arxiv.org/abs/1703.08701 | id:1703.08701 author:Claudia Borg, Albert Gatt category:cs.CL I.2.7  published:2017-03-25 summary:Maltese is a morphologically rich language with a hybrid morphological system which features both concatenative and non-concatenative processes. This paper analyses the impact of this hybridity on the performance of machine learning techniques for morphological labelling and clustering. In particular, we analyse a dataset of morphologically related word clusters to evaluate the difference in results for concatenative and nonconcatenative clusters. We also describe research carried out in morphological labelling, with a particular focus on the verb category. Two evaluations were carried out, one using an unseen dataset, and another one using a gold standard dataset which was manually labelled. The gold standard dataset was split into concatenative and non-concatenative to analyse the difference in results between the two morphological systems. version:1
arxiv-1703-08697 | Improving the Accuracy of the CogniLearn System for Cognitive Behavior Assessment | http://arxiv.org/abs/1703.08697 | id:1703.08697 author:Amir Ghaderi, Srujana Gattupalli, Dylan Ebert, Ali Sharifara, Vassilis Athitsos, Fillia Makedon category:cs.CV  published:2017-03-25 summary:HTKS is a game-like cognitive assessment method, designed for children between four and eight years of age. During the HTKS assessment, a child responds to a sequence of requests, such as "touch your head" or "touch your toes". The cognitive challenge stems from the fact that the children are instructed to interpret these requests not literally, but by touching a different body part than the one stated. In prior work, we have developed the CogniLearn system, that captures data from subjects performing the HTKS game, and analyzes the motion of the subjects. In this paper we propose some specific improvements that make the motion analysis module more accurate. As a result of these improvements, the accuracy in recognizing cases where subjects touch their toes has gone from 76.46% in our previous work to 97.19% in this paper. version:1
arxiv-1703-06264 | Non-Associative Learning Representation in the Nervous System of the Nematode Caenorhabditis elegans | http://arxiv.org/abs/1703.06264 | id:1703.06264 author:Ramin M. Hasani, Magdalena Fuchs, Victoria Beneder, Radu Grosu category:q-bio.NC cs.NE q-bio.QM  published:2017-03-18 summary:Caenorhabditis elegans (C. elegans) illustrated remarkable behavioral plasticities including complex non-associative and associative learning representations. Understanding the principles of such mechanisms presumably leads to constructive inspirations for the design of efficient learning algorithms. In the present study, we postulate a novel approach on modeling single neurons and synapses to study the mechanisms underlying learning in the C. elegans nervous system. In this regard, we construct a precise mathematical model of sensory neurons where we include multi-scale details from genes, ion channels and ion pumps, together with a dynamic model of synapses comprised of neurotransmitters and receptors kinetics. We recapitulate mechanosensory habituation mechanism, a non-associative learning process, in which elements of the neural network tune their parameters as a result of repeated input stimuli. Accordingly, we quantitatively demonstrate the roots of such plasticity in the neuronal and synaptic-level representations. Our findings can potentially give rise to the development of new bio-inspired learning algorithms. version:3
arxiv-1703-06270 | SIM-CE: An Advanced Simulink Platform for Studying the Brain of Caenorhabditis elegans | http://arxiv.org/abs/1703.06270 | id:1703.06270 author:Ramin M. Hasani, Victoria Beneder, Magdalena Fuchs, David Lung, Radu Grosu category:q-bio.NC cs.NE q-bio.QM stat.ML  published:2017-03-18 summary:We introduce SIM-CE, an advanced, user-friendly modeling and simulation environment in Simulink for performing multi-scale behavioral analysis of the nervous system of Caenorhabditis elegans (C. elegans). SIM-CE contains an implementation of the mathematical models of C. elegans's neurons and synapses, in Simulink, which can be easily extended and particularized by the user. The Simulink model is able to capture both complex dynamics of ion channels and additional biophysical detail such as intracellular calcium concentration. We demonstrate the performance of SIM-CE by carrying out neuronal, synaptic and neural-circuit-level behavioral simulations. Such environment enables the user to capture unknown properties of the neural circuits, test hypotheses and determine the origin of many behavioral plasticities exhibited by the worm. version:3
arxiv-1703-07195 | GP-GAN: Towards Realistic High-Resolution Image Blending | http://arxiv.org/abs/1703.07195 | id:1703.07195 author:Huikai Wu, Shuai Zheng, Junge Zhang, Kaiqi Huang category:cs.CV  published:2017-03-21 summary:Recent advances in generative adversarial networks (GANs) have shown promising potentials in conditional image generation. However, how to generate high-resolution images remains an open problem. In this paper, we aim at generating high-resolution well-blended images given composited copy-and-paste ones, i.e. realistic high-resolution image blending. To achieve this goal, we propose Gaussian-Poisson GAN (GP-GAN), a framework that combines the strengths of classical gradient-based approaches and GANs, which is the first work that explores the capability of GANs in high-resolution image blending task to the best of our knowledge. Particularly, we propose Gaussian-Poisson Equation to formulate the high-resolution image blending problem, which is a joint optimisation constrained by the gradient and colour information. Gradient filters can obtain gradient information. For generating the colour information, we propose Blending GAN to learn the mapping between the composited image and the well-blended one. Compared to the alternative methods, our approach can deliver high-resolution, realistic images with fewer bleedings and unpleasant artefacts. Experiments confirm that our approach achieves the state-of-the-art performance on Transient Attributes dataset. A user study on Amazon Mechanical Turk finds that majority of workers are in favour of the proposed approach. version:2
arxiv-1703-08651 | More is Less: A More Complicated Network with Less Inference Complexity | http://arxiv.org/abs/1703.08651 | id:1703.08651 author:Xuanyi Dong, Junshi Huang, Yi Yang, Shuicheng Yan category:cs.CV  published:2017-03-25 summary:In this paper, we present a novel and general network structure towards accelerating the inference process of convolutional neural networks, which is more complicated in network structure yet with less inference complexity. The core idea is to equip each original convolutional layer with another low-cost collaborative layer (LCCL), and the element-wise multiplication of the ReLU outputs of these two parallel layers produces the layer-wise output. The combined layer is potentially more discriminative than the original convolutional layer, and its inference is faster for two reasons: 1) the zero cells of the LCCL feature maps will remain zero after element-wise multiplication, and thus it is safe to skip the calculation of the corresponding high-cost convolution in the original convolutional layer, 2) LCCL is very fast if it is implemented as a 1*1 convolution or only a single filter shared by all channels. Extensive experiments on the CIFAR-10, CIFAR-100 and ILSCRC-2012 benchmarks show that our proposed network structure can accelerate the inference process by 32\% on average with negligible performance drop. version:1
arxiv-1703-08646 | Simplifying the Bible and Wikipedia Using Statistical Machine Translation | http://arxiv.org/abs/1703.08646 | id:1703.08646 author:Yohan Jo category:cs.CL  published:2017-03-25 summary:I started this work with the hope of generating a text synthesizer (like a musical synthesizer) that can imitate certain linguistic styles. Most of the report focuses on text simplification using statistical machine translation (SMT) techniques. I applied MOSES to a parallel corpus of the Bible (King James Version and Easy-to-Read Version) and that of Wikipedia articles (normal and simplified). I report the importance of the three main components of SMT---phrase translation, language model, and recording---by changing their weights and comparing the resulting quality of simplified text in terms of METEOR and BLEU. Toward the end of the report will be presented some examples of text "synthesized" into the King James style. version:1
arxiv-1703-08088 | Rapid-Rate: A Framework for Semi-supervised Real-time Sentiment Trend Detection in Unstructured Big Data | http://arxiv.org/abs/1703.08088 | id:1703.08088 author:Vineet John category:cs.CL 68T50  published:2017-03-23 summary:Commercial establishments like restaurants, service centres and retailers have several sources of customer feedback about products and services, most of which need not be as structured as rated reviews provided by services like Yelp, or Amazon, in terms of sentiment conveyed. For instance, Amazon provides a fine-grained score on a numeric scale for product reviews. Some sources, however, like social media (Twitter, Facebook), mailing lists (Google Groups) and forums (Quora) contain text data that is much more voluminous, but unstructured and unlabelled. It might be in the best interests of a business establishment to assess the general sentiment towards their brand on these platforms as well. This text could be pipelined into a system with a built-in prediction model, with the objective of generating real-time graphs on opinion and sentiment trends. Although such tasks like the one described about have been explored with respect to document classification problems in the past, the implementation described in this paper, by virtue of learning a continuous function rather than a discrete one, offers a lot more depth of insight as compared to document classification approaches. This study aims to explore the validity of such a continuous function predicting model to quantify sentiment about an entity, without the additional overhead of manual labelling, and computational preprocessing & feature extraction. This research project also aims to design and implement a re-usable document regression pipeline as a framework, Rapid-Rate, that can be used to predict document scores in real-time. version:2
arxiv-1703-08628 | AMAT: Medial Axis Transform for Natural Images | http://arxiv.org/abs/1703.08628 | id:1703.08628 author:Stavros Tsogkas, Sven Dickinson category:cs.CV  published:2017-03-24 summary:The medial axis transform (MAT) is a powerful shape abstraction that has been successfully used in shape editing, matching and retrieval. Despite its long history, the MAT has not found widespread use in tasks involving natural images, due to the lack of a generalization that accommodates color and texture. In this paper we introduce Appearance-MAT (AMAT), by framing the MAT of natural images as a weighted geometric set cover problem. We make the following contributions: i) we extend previous medial point detection methods for color images, by associating each medial point with a local scale; ii) inspired by the invertibility property of the binary MAT, we also associate each medial point with a local encoding that allows us to invert the AMAT, reconstructing the input image; iii) we describe a clustering scheme that takes advantage of the additional scale and appearance information to group individual points into medial branches, providing a shape decomposition of the underlying image regions. In our experiments, we show state-of-the-art performance in medial point detection on Berkeley Medial AXes (BMAX500), a new dataset of medial axes based on the established BSDS500 database. We also measure the quality of reconstructed images from the same dataset, obtained by inverting their computed AMAT. Our approach delivers significantly better reconstruction quality with respect to three baselines, using just 10% of the image pixels. Our code is available at https://github.com/tsogkas/amat. version:1
arxiv-1703-08619 | Binarsity: a penalization for one-hot encoded features | http://arxiv.org/abs/1703.08619 | id:1703.08619 author:Mokhtar Z. Alaya, Simon Bussy, Stéphane Gaïffas, Agathe Guilloux category:stat.ML  published:2017-03-24 summary:This paper deals with the problem of large-scale linear supervised learning in settings where a large number of continuous features are available. We propose to combine the well-known trick of one-hot encoding of continuous features with a new penalization called binarsity. In each group of binary features coming from the one-hot encoding of a single raw continuous feature, this penalization uses total-variation regularization together with an extra linear constraint to avoid collinearity within groups. Non-asymptotic oracle inequalities for generalized linear models are proposed, and numerical experiments illustrate the good performances of our approach on several datasets. It is also noteworthy that our method has a numerical complexity comparable to standard $\ell_1$ penalization. version:1
arxiv-1703-08617 | Temporal Non-Volume Preserving Approach to Facial Age-Progression and Age-Invariant Face Recognition | http://arxiv.org/abs/1703.08617 | id:1703.08617 author:Chi Nhan Duong, Kha Gia Quach, Khoa Luu, T. Hoang Ngan le, Marios Savvides category:cs.CV  published:2017-03-24 summary:Modeling the long-term facial aging process is extremely challenging due to the presence of large and non-linear variations during the face development stages. In order to efficiently address the problem, this work first decomposes the aging process into multiple short-term stages. Then, a novel generative probabilistic model, named Temporal Non-Volume Preserving (TNVP) transformation, is presented to model the facial aging process at each stage. Unlike Generative Adversarial Networks (GANs), which requires an empirical balance threshold, and Restricted Boltzmann Machines (RBM), an intractable model, our proposed TNVP approach guarantees a tractable density function, exact inference and evaluation for embedding the feature transformations between faces in consecutive stages. Our model shows its advantages not only in capturing the non-linear age related variance in each stage but also producing a smooth synthesis in age progression across faces. Our approach can model any face in the wild provided with only four basic landmark points. Moreover, the structure can be transformed into a deep convolutional network while keeping the advantages of probabilistic models with tractable log-likelihood density estimation. Our method is evaluated in both terms of synthesizing age-progressed faces and cross-age face verification and consistently shows the state-of-the-art results in various face aging databases, i.e. FG-NET, MORPH, AginG Faces in the Wild (AGFW), and Cross-Age Celebrity Dataset (CACD). A large-scale face verification on Megaface challenge 1 is also performed to further show the advantages of our proposed approach. version:1
arxiv-1703-08612 | Jointly Optimizing Placement and Inference for Beacon-based Localization | http://arxiv.org/abs/1703.08612 | id:1703.08612 author:Charles Schaff, David Yunis, Ayan Chakrabarti, Matthew R. Walter category:cs.RO cs.LG  published:2017-03-24 summary:The ability of robots to estimate their location is crucial for a wide variety of autonomous operations. In settings where GPS is unavailable, range- or bearing-only observations relative to a set of fixed beacons provide an effective means of estimating a robot's location as it navigates. The accuracy of such a beacon-based localization system depends both on how beacons are spatially distributed in the environment, and how the robot's location is inferred based on noisy measurements of range or bearing. However, it is computationally challenging to search for a placement and an inference strategy that, together, are optimal. Existing methods decouple these decisions, forgoing optimality for tractability. We propose a new optimization approach to jointly determine the beacon placement and inference algorithm. We model inference as a neural network and incorporate beacon placement as a differentiable neural layer. This formulation allows us to optimize placement and inference by jointly training the inference network and beacon layer. We evaluate our method on different localization problems and demonstrate performance that exceeds hand-crafted baselines. version:1
arxiv-1703-07464 | No Fuss Distance Metric Learning using Proxies | http://arxiv.org/abs/1703.07464 | id:1703.07464 author:Yair Movshovitz-Attias, Alexander Toshev, Thomas K. Leung, Sergey Ioffe, Saurabh Singh category:cs.CV  published:2017-03-21 summary:We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity. Traditionally, for this problem supervision is expressed in the form of sets of points that follow an ordinal relationship -- an anchor point $x$ is similar to a set of positive points $Y$, and dissimilar to a set of negative points $Z$, and a loss defined over these distances is minimized. While the specifics of the optimization differ, in this work we collectively call this type of supervision Triplets and all methods that follow this pattern Triplet-Based methods. These methods are challenging to optimize. A main issue is the need for finding informative triplets, which is usually achieved by a variety of tricks such as increasing the batch size, hard or semi-hard triplet mining, etc, but even with these tricks, the convergence rate of such methods is slow. In this paper we propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss. This proxy-based loss is empirically better behaved. As a result, the proxy-loss improves on state-of-art results for three standard zero-shot learning datasets, by up to 15% points, while converging three times as fast as other triplet-based losses. version:2
arxiv-1703-08595 | Low Precision Neural Networks using Subband Decomposition | http://arxiv.org/abs/1703.08595 | id:1703.08595 author:Sek Chai, Aswin Raghavan, David Zhang, Mohamed Amer, Tim Shields category:cs.LG  published:2017-03-24 summary:Large-scale deep neural networks (DNN) have been successfully used in a number of tasks from image recognition to natural language processing. They are trained using large training sets on large models, making them computationally and memory intensive. As such, there is much interest in research development for faster training and test time. In this paper, we present a unique approach using lower precision weights for more efficient and faster training phase. We separate imagery into different frequency bands (e.g. with different information content) such that the neural net can better learn using less bits. We present this approach as a complement existing methods such as pruning network connections and encoding learning weights. We show results where this approach supports more stable learning with 2-4X reduction in precision with 17X reduction in DNN parameters. version:1
arxiv-1703-08581 | Sequence-to-Sequence Models Can Directly Transcribe Foreign Speech | http://arxiv.org/abs/1703.08581 | id:1703.08581 author:Ron J. Weiss, Jan Chorowski, Navdeep Jaitly, Yonghui Wu, Zhifeng Chen category:cs.CL cs.LG stat.ML  published:2017-03-24 summary:We present a recurrent encoder-decoder deep neural network architecture that directly translates speech in one language into text in another. The model does not explicitly transcribe the speech into text in the source language, nor does it require supervision from the ground truth source language transcription during training. We apply a slightly modified sequence-to-sequence with attention architecture that has previously been used for speech recognition and show that it can be repurposed for this more complex task, illustrating the power of attention-based models. A single model trained end-to-end obtains state-of-the-art performance on the Fisher Callhome Spanish-English speech translation task, outperforming a cascade of independently trained sequence-to-sequence speech recognition and machine translation models by 1.8 BLEU points on the Fisher test set. In addition, we find that making use of the training data in both languages by multi-task training sequence-to-sequence speech translation and recognition models with a shared encoder network can improve performance by a further 1.4 BLEU points. version:1
arxiv-1703-08580 | Deep Residual Learning for Instrument Segmentation in Robotic Surgery | http://arxiv.org/abs/1703.08580 | id:1703.08580 author:Daniil Pakhomov, Vittal Premachandran, Max Allan, Mahdi Azizian, Nassir Navab category:cs.CV  published:2017-03-24 summary:Detection, tracking, and pose estimation of surgical instruments are crucial tasks for computer assistance during minimally invasive robotic surgery. In the majority of cases, the first step is the automatic segmentation of surgical tools. Prior work has focused on binary segmentation, where the objective is to label every pixel in an image as tool or background. We improve upon previous work in two major ways. First, we leverage recent techniques such as deep residual learning and dilated convolutions to advance binary-segmentation performance. Second, we extend the approach to multi-class segmentation, which lets us segment different parts of the tool, in addition to background. We demonstrate the performance of this method on the MICCAI Endoscopic Vision Challenge Robotic Instruments dataset. version:1
arxiv-1703-08577 | Balancing Selection Pressures, Multiple Objectives, and Neural Modularity to Coevolve Cooperative Agent Behavior | http://arxiv.org/abs/1703.08577 | id:1703.08577 author:Alex C. Rollins, Jacob Schrum category:cs.NE  published:2017-03-24 summary:Previous research using evolutionary computation in Multi-Agent Systems indicates that assigning fitness based on team vs.\ individual behavior has a strong impact on the ability of evolved teams of artificial agents to exhibit teamwork in challenging tasks. However, such research only made use of single-objective evolution. In contrast, when a multiobjective evolutionary algorithm is used, populations can be subject to individual-level objectives, team-level objectives, or combinations of the two. This paper explores the performance of cooperatively coevolved teams of agents controlled by artificial neural networks subject to these types of objectives. Specifically, predator agents are evolved to capture scripted prey agents in a torus-shaped grid world. Because of the tension between individual and team behaviors, multiple modes of behavior can be useful, and thus the effect of modular neural networks is also explored. Results demonstrate that fitness rewarding individual behavior is superior to fitness rewarding team behavior, despite being applied to a cooperative task. However, the use of networks with multiple modules allows predators to discover intelligent behavior, regardless of which type of objectives are used. version:1
arxiv-1703-08537 | Crowdsourcing Universal Part-Of-Speech Tags for Code-Switching | http://arxiv.org/abs/1703.08537 | id:1703.08537 author:Victor Soto, Julia Hirschberg category:cs.CL  published:2017-03-24 summary:Code-switching is the phenomenon by which bilingual speakers switch between multiple languages during communication. The importance of developing language technologies for codeswitching data is immense, given the large populations that routinely code-switch. High-quality linguistic annotations are extremely valuable for any NLP task, and performance is often limited by the amount of high-quality labeled data. However, little such data exists for code-switching. In this paper, we describe crowd-sourcing universal part-of-speech tags for the Miami Bangor Corpus of Spanish-English code-switched speech. We split the annotation task into three subtasks: one in which a subset of tokens are labeled automatically, one in which questions are specifically designed to disambiguate a subset of high frequency words, and a more general cascaded approach for the remaining data in which questions are displayed to the worker following a decision tree structure. Each subtask is extended and adapted for a multilingual setting and the universal tagset. The quality of the annotation process is measured using hidden check questions annotated with gold labels. The overall agreement between gold standard labels and the majority vote is between 0.95 and 0.96 for just three labels and the average recall across part-of-speech tags is between 0.87 and 0.99, depending on the task. version:1
arxiv-1703-08535 | PonyGE2: Grammatical Evolution in Python | http://arxiv.org/abs/1703.08535 | id:1703.08535 author:Michael Fenton, James McDermott, David Fagan, Stefan Forstenlechner, Michael O'Neill, Erik Hemberg category:cs.NE  published:2017-03-24 summary:Grammatical Evolution (GE) is a population-based evolutionary algorithm, where a formal grammar is used in the genotype to phenotype mapping process. PonyGE2 is an open source implementation of GE in Python, developed at UCD's Natural Computing Research and Applications group. It is intended as an advertisement and a starting-point for those new to GE, a reference for students and researchers, a rapid-prototyping medium for our own experiments, and a Python workout. As well as providing the characteristic genotype to phenotype mapping of GE, a search algorithm engine is also provided. A number of sample problems and tutorials on how to use and adapt PonyGE2 have been developed. version:1
arxiv-1703-08524 | Joint Modeling of Event Sequence and Time Series with Attentional Twin Recurrent Neural Networks | http://arxiv.org/abs/1703.08524 | id:1703.08524 author:Shuai Xiao, Junchi Yan, Mehrdad Farajtabar, Le Song, Xiaokang Yang, Hongyuan Zha category:cs.LG  published:2017-03-24 summary:A variety of real-world processes (over networks) produce sequences of data whose complex temporal dynamics need to be studied. More especially, the event timestamps can carry important information about the underlying network dynamics, which otherwise are not available from the time-series evenly sampled from continuous signals. Moreover, in most complex processes, event sequences and evenly-sampled times series data can interact with each other, which renders joint modeling of those two sources of data necessary. To tackle the above problems, in this paper, we utilize the rich framework of (temporal) point processes to model event data and timely update its intensity function by the synergic twin Recurrent Neural Networks (RNNs). In the proposed architecture, the intensity function is synergistically modulated by one RNN with asynchronous events as input and another RNN with time series as input. Furthermore, to enhance the interpretability of the model, the attention mechanism for the neural point process is introduced. The whole model with event type and timestamp prediction output layers can be trained end-to-end and allows a black-box treatment for modeling the intensity. We substantiate the superiority of our model in synthetic data and three real-world benchmark datasets. version:1
arxiv-1703-08520 | Rejection-free Ensemble MCMC with applications to Factorial Hidden Markov Models | http://arxiv.org/abs/1703.08520 | id:1703.08520 author:Kaspar Märtens, Michalis K Titsias, Christopher Yau category:stat.CO stat.ME stat.ML  published:2017-03-24 summary:Bayesian inference for complex models is challenging due to the need to explore high-dimensional spaces and multimodality and standard Monte Carlo samplers can have difficulties effectively exploring the posterior. We introduce a general purpose rejection-free ensemble Markov Chain Monte Carlo (MCMC) technique to improve on existing poorly mixing samplers. This is achieved by combining parallel tempering and an auxiliary variable move to exchange information between the chains. We demonstrate this ensemble MCMC scheme on Bayesian inference in Factorial Hidden Markov Models. This high-dimensional inference problem is difficult due to the exponentially sized latent variable space. Existing sampling approaches mix slowly and can get trapped in local modes. We show that the performance of these samplers is improved by our rejection-free ensemble technique and that the method is attractive and "easy-to-use" since no parameter tuning is required. version:1
arxiv-1703-08516 | Radiomics strategies for risk assessment of tumour failure in head-and-neck cancer | http://arxiv.org/abs/1703.08516 | id:1703.08516 author:Martin Vallières, Emily Kay-Rivest, Léo Jean Perrin, Xavier Liem, Christophe Furstoss, Hugo J. W. L. Aerts, Nader Khaouam, Phuc Felix Nguyen-Tan, Chang-Shu Wang, Khalil Sultanem, Jan Seuntjens, Issam El Naqa category:cs.CV  published:2017-03-24 summary:Quantitative extraction of high-dimensional mineable data from medical images is a process known as radiomics. Radiomics is foreseen as an essential prognostic tool for cancer risk assessment and the quantification of intratumoural heterogeneity. In this work, 1615 radiomic features (quantifying tumour image intensity, shape, texture) extracted from pre-treatment FDG-PET and CT images of 300 patients from four different cohorts were analyzed for the risk assessment of locoregional recurrences (LR) and distant metastases (DM) in head-and-neck cancer. Prediction models combining radiomic and clinical variables were constructed via random forests and imbalance-adjustment strategies using two of the four cohorts. Independent validation of the prediction and prognostic performance of the models was carried out on the other two cohorts (LR: AUC = 0.69 and CI = 0.67; DM: AUC = 0.86 and CI = 0.88). Furthermore, the results obtained via Kaplan-Meier analysis demonstrated the potential of radiomics for assessing the risk of specific tumour outcomes using multiple stratification groups. This could have important clinical impact, notably by allowing for a better personalization of chemo-radiation treatments for head-and-neck cancer patients from different risk groups. version:1
arxiv-1703-08513 | Interactive Natural Language Acquisition in a Multi-modal Recurrent Neural Architecture | http://arxiv.org/abs/1703.08513 | id:1703.08513 author:Stefan Heinrich, Stefan Wermter category:cs.CL q-bio.NC  published:2017-03-24 summary:The human brain is one of the most complex dynamic systems that enables us to communicate in natural language. We have a good understanding of some principles underlying natural languages and language processing, some knowledge about socio-cultural conditions framing acquisition, and some insights about where activity is occurring in the brain. However, we were not yet able to understand the behavioural and mechanistic characteristics for natural language and how mechanisms in the brain allow to acquire and process language. In an effort to bridge the gap between insights from behavioural psychology and neuroscience, the goal of this paper is to contribute a computational understanding of the appropriate characteristics that favour language acquisition, in a brain-inspired neural architecture. Accordingly, we provide concepts and refinements in cognitive modelling regarding principles and mechanisms in the brain - such as the hierarchical abstraction of context - in a plausible recurrent architecture. On this basis, we propose neurocognitively plausible model for embodied language acquisition from real world interaction of a humanoid robot with its environment. The model is capable of learning language production grounded in both, temporal dynamic somatosensation and vision. In particular, the architecture consists of a continuous time recurrent neural network, where parts have different leakage characteristics and thus operate on multiple timescales for every modality and the association of the higher level nodes of all modalities into cell assemblies. Thus, this model features hierarchical concept abstraction in sensation as well as concept decomposition in production, multi-modal integration, and self-organisation of latent representations. version:1
arxiv-1703-08497 | Local Deep Neural Networks for Age and Gender Classification | http://arxiv.org/abs/1703.08497 | id:1703.08497 author:Zukang Liao, Stavros Petridis, Maja Pantic category:cs.CV  published:2017-03-24 summary:Local deep neural networks have been recently introduced for gender recognition. Although, they achieve very good performance they are very computationally expensive to train. In this work, we introduce a simplified version of local deep neural networks which significantly reduces the training time. Instead of using hundreds of patches per image, as suggested by the original method, we propose to use 9 overlapping patches per image which cover the entire face region. This results in a much reduced training time, since just 9 patches are extracted per image instead of hundreds, at the expense of a slightly reduced performance. We tested the proposed modified local deep neural networks approach on the LFW and Adience databases for the task of gender and age classification. For both tasks and both databases the performance is up to 1% lower compared to the original version of the algorithm. We have also investigated which patches are more discriminative for age and gender classification. It turns out that the mouth and eyes regions are useful for age classification, whereas just the eye region is useful for gender classification. version:1
arxiv-1703-08493 | Multi-stage Multi-recursive-input Fully Convolutional Networks for Neuronal Boundary Detection | http://arxiv.org/abs/1703.08493 | id:1703.08493 author:Wei Shen, Bin Wang, Yuan Jiang, Yan Wang, Alan Yuille category:cs.CV  published:2017-03-24 summary:In the field of connectomics, neuroscientists seek to identify cortical connectivity comprehensively. Neuronal boundary detection from the Electron Microscopy (EM) images is often done to assist the automatic reconstruction of neuronal circuit. But the segmentation of EM images is a challenging problem, as it requires the detector to be able to detect both filament-like thin and blob-like thick membrane, while suppressing the ambiguous intracellular structure. In this paper, we propose multi-stage multi-recursive-input fully convolutional networks to address this problem. The multiple recursive inputs for one stage, i.e., the multiple side outputs with different receptive field sizes learned from the lower stage, provide multi-scale contextual boundary information for the consecutive learning. This design is biologically-plausible, as it likes a human visual system to compare different possible segmentation solutions to address the ambiguous boundary issue. Our multi-stage networks are trained end-to-end. It achieves promising results on a public available mouse piriform cortex dataset, which significantly outperforms other competitors. version:1
arxiv-1703-08492 | Content-Based Image Retrieval Based on Late Fusion of Binary and Local Descriptors | http://arxiv.org/abs/1703.08492 | id:1703.08492 author:Nouman Ali, Danish Ali Mazhar, Zeshan Iqbal, Rehan Ashraf, Jawad Ahmed, Farrukh Zeeshan Khan category:cs.CV  published:2017-03-24 summary:One of the challenges in Content-Based Image Retrieval (CBIR) is to reduce the semantic gaps between low-level features and high-level semantic concepts. In CBIR, the images are represented in the feature space and the performance of CBIR depends on the type of selected feature representation. Late fusion also known as visual words integration is applied to enhance the performance of image retrieval. The recent advances in image retrieval diverted the focus of research towards the use of binary descriptors as they are reported computationally efficient. In this paper, we aim to investigate the late fusion of Fast Retina Keypoint (FREAK) and Scale Invariant Feature Transform (SIFT). The late fusion of binary and local descriptor is selected because among binary descriptors, FREAK has shown good results in classification-based problems while SIFT is robust to translation, scaling, rotation and small distortions. The late fusion of FREAK and SIFT integrates the performance of both feature descriptors for an effective image retrieval. Experimental results and comparisons show that the proposed late fusion enhances the performances of image retrieval. version:1
arxiv-1703-08481 | Long-Term Evolution of Genetic Programming Populations | http://arxiv.org/abs/1703.08481 | id:1703.08481 author:W. B. Langdon category:cs.NE  published:2017-03-24 summary:We evolve binary mux-6 trees for up to 100000 generations evolving some programs with more than a hundred million nodes. Our unbounded Long-Term Evolution Experiment LTEE GP appears not to evolve building blocks but does suggests a limit to bloat. We do see periods of tens even hundreds of generations where the population is 100 percent functionally converged. The distribution of tree sizes is not as predicted by theory. version:1
arxiv-1703-08475 | Overcoming Catastrophic Forgetting by Incremental Moment Matching | http://arxiv.org/abs/1703.08475 | id:1703.08475 author:Sang-Woo Lee, Jin-Hwa Kim, Jung-Woo Ha, Byoung-Tak Zhang category:cs.LG cs.AI  published:2017-03-24 summary:Catastrophic forgetting is a problem which refers to losing the information of the first task after training from the second task in continual learning of neural networks. To resolve this problem, we propose the incremental moment matching (IMM), which uses the Bayesian neural network framework. IMM assumes that the posterior distribution of parameters of neural networks is approximated with Gaussian distribution and incrementally matches the moment of the posteriors, which are trained for the first and second task, respectively. To make our Gaussian assumption reasonable, the IMM procedure utilizes various transfer learning techniques including weight transfer, L2-norm of old and new parameters, and a newly proposed variant of dropout using old parameters. We analyze our methods on the MNIST and CIFAR-10 datasets, and then evaluate them on a real-world life-log dataset collected using Google Glass. Experimental results show that IMM produces state-of-the-art performance in a variety of datasets. version:1
arxiv-1703-08472 | Medical Image Retrieval using Deep Convolutional Neural Network | http://arxiv.org/abs/1703.08472 | id:1703.08472 author:Adnan Qayyum, Syed Muhammad Anwar, Muhammad Awais, Muhammad Majid category:cs.CV  published:2017-03-24 summary:With a widespread use of digital imaging data in hospitals, the size of medical image repositories is increasing rapidly. This causes difficulty in managing and querying these large databases leading to the need of content based medical image retrieval (CBMIR) systems. A major challenge in CBMIR systems is the semantic gap that exists between the low level visual information captured by imaging devices and high level semantic information perceived by human. The efficacy of such systems is more crucial in terms of feature representations that can characterize the high-level information completely. In this paper, we propose a framework of deep learning for CBMIR system by using deep Convolutional Neural Network (CNN) that is trained for classification of medical images. An intermodal dataset that contains twenty four classes and five modalities is used to train the network. The learned features and the classification results are used to retrieve medical images. For retrieval, best results are achieved when class based predictions are used. An average classification accuracy of 99.77% and a mean average precision of 0.69 is achieved for retrieval task. The proposed method is best suited to retrieve multimodal medical images for different body organs. version:1
arxiv-1703-08471 | Batch-normalized joint training for DNN-based distant speech recognition | http://arxiv.org/abs/1703.08471 | id:1703.08471 author:Mirco Ravanelli, Philemon Brakel, Maurizio Omologo, Yoshua Bengio category:cs.CL cs.LG  published:2017-03-24 summary:Improving distant speech recognition is a crucial step towards flexible human-machine interfaces. Current technology, however, still exhibits a lack of robustness, especially when adverse acoustic conditions are met. Despite the significant progress made in the last years on both speech enhancement and speech recognition, one potential limitation of state-of-the-art technology lies in composing modules that are not well matched because they are not trained jointly. To address this concern, a promising approach consists in concatenating a speech enhancement and a speech recognition deep neural network and to jointly update their parameters as if they were within a single bigger network. Unfortunately, joint training can be difficult because the output distribution of the speech enhancement system may change substantially during the optimization procedure. The speech recognition module would have to deal with an input distribution that is non-stationary and unnormalized. To mitigate this issue, we propose a joint training approach based on a fully batch-normalized architecture. Experiments, conducted using different datasets, tasks and acoustic conditions, revealed that the proposed framework significantly overtakes other competitive solutions, especially in challenging environments. version:1
arxiv-1703-08440 | K-Means Clustering using Tabu Search with Quantized Means | http://arxiv.org/abs/1703.08440 | id:1703.08440 author:Kojo Sarfo Gyamfi, James Brusey, Andrew Hunt category:cs.LG  published:2017-03-24 summary:The Tabu Search (TS) metaheuristic has been proposed for K-Means clustering as an alternative to Lloyd's algorithm, which for all its ease of implementation and fast runtime, has the major drawback of being trapped at local optima. While the TS approach can yield superior performance, it involves a high computational complexity. Moreover, the difficulty in parameter selection in the existing TS approach does not make it any more attractive. This paper presents an alternative, low-complexity formulation of the TS optimization procedure for K-Means clustering. This approach does not require many parameter settings. We initially constrain the centers to points in the dataset. We then aim at evolving these centers using a unique neighborhood structure that makes use of gradient information of the objective function. This results in an efficient exploration of the search space, after which the means are refined. The proposed scheme is implemented in MATLAB and tested on four real-world datasets, and it achieves a significant improvement over the existing TS approach in terms of the intra cluster sum of squares and computational time. version:1
arxiv-1703-08434 | Linear classifier design under heteroscedasticity in Linear Discriminant Analysis | http://arxiv.org/abs/1703.08434 | id:1703.08434 author:Kojo Sarfo Gyamfi, James Brusey, Andrew Hunt, Elena Gaura category:cs.LG  published:2017-03-24 summary:Under normality and homoscedasticity assumptions, Linear Discriminant Analysis (LDA) is known to be optimal in terms of minimising the Bayes error for binary classification. In the heteroscedastic case, LDA is not guaranteed to minimise this error. Assuming heteroscedasticity, we derive a linear classifier, the Gaussian Linear Discriminant (GLD), that directly minimises the Bayes error for binary classification. In addition, we also propose a local neighbourhood search (LNS) algorithm to obtain a more robust classifier if the data is known to have a non-normal distribution. We evaluate the proposed classifiers on two artificial and ten real-world datasets that cut across a wide range of application areas including handwriting recognition, medical diagnosis and remote sensing, and then compare our algorithm against existing LDA approaches and other linear classifiers. The GLD is shown to outperform the original LDA procedure in terms of the classification accuracy under heteroscedasticity. While it compares favourably with other existing heteroscedastic LDA approaches, the GLD requires as much as 60 times lower training time on some datasets. Our comparison with the support vector machine (SVM) also shows that, the GLD, together with the LNS, requires as much as 150 times lower training time to achieve an equivalent classification accuracy on some of the datasets. Thus, our algorithms can provide a cheap and reliable option for classification in a lot of expert systems. version:1
arxiv-1703-08428 | Calendar.help: Designing a Workflow-Based Scheduling Agent with Humans in the Loop | http://arxiv.org/abs/1703.08428 | id:1703.08428 author:Justin Cranshaw, Emad Elwany, Todd Newman, Rafal Kocielnik, Bowen Yu, Sandeep Soni, Jaime Teevan, Andrés Monroy-Hernández category:cs.HC cs.AI cs.CL  published:2017-03-24 summary:Although information workers may complain about meetings, they are an essential part of their work life. Consequently, busy people spend a significant amount of time scheduling meetings. We present Calendar.help, a system that provides fast, efficient scheduling through structured workflows. Users interact with the system via email, delegating their scheduling needs to the system as if it were a human personal assistant. Common scheduling scenarios are broken down using well-defined workflows and completed as a series of microtasks that are automated when possible and executed by a human otherwise. Unusual scenarios fall back to a trained human assistant who executes them as unstructured macrotasks. We describe the iterative approach we used to develop Calendar.help, and share the lessons learned from scheduling thousands of meetings during a year of real-world deployments. Our findings provide insight into how complex information tasks can be broken down into repeatable components that can be executed efficiently to improve productivity. version:1
arxiv-1703-08403 | Asymmetric Learning Vector Quantization for Efficient Nearest Neighbor Classification in Dynamic Time Warping Spaces | http://arxiv.org/abs/1703.08403 | id:1703.08403 author:Brijnesh Jain, David Schultz category:cs.LG stat.ML  published:2017-03-24 summary:The nearest neighbor method together with the dynamic time warping (DTW) distance is one of the most popular approaches in time series classification. This method suffers from high storage and computation requirements for large training sets. As a solution to both drawbacks, this article extends learning vector quantization (LVQ) from Euclidean spaces to DTW spaces. The proposed LVQ scheme uses asymmetric weighted averaging as update rule. Empirical results exhibited superior performance of asymmetric generalized LVQ (GLVQ) over other state-of-the-art prototype generation methods for nearest neighbor classification. version:1
arxiv-1703-08132 | Weakly Supervised Action Learning with RNN based Fine-to-coarse Modeling | http://arxiv.org/abs/1703.08132 | id:1703.08132 author:Alexander Richard, Hilde Kuehne, Juergen Gall category:cs.CV  published:2017-03-23 summary:We present an approach for weakly supervised learning of human actions. Given a set of videos and an ordered list of the occurring actions, the goal is to infer start and end frames of the related action classes within the video and to train the respective action classifiers without any need for hand labeled frame boundaries. To address this task, we propose a combination of a discriminative representation of subactions, modeled by a recurrent neural network, and a coarse probabilistic model to allow for a temporal alignment and inference over long sequences. While this system alone already generates good results, we show that the performance can be further improved by approximating the number of subactions to the characteristics of the different action classes. To this end, we adapt the number of subaction classes by iterating realignment and reestimation during training. The proposed system is evaluated on two benchmark datasets, the Breakfast and the Hollywood extended dataset, showing a competitive performance on various weak learning tasks such as temporal action segmentation and action alignment. version:2
arxiv-1703-08383 | Smart Augmentation - Learning an Optimal Data Augmentation Strategy | http://arxiv.org/abs/1703.08383 | id:1703.08383 author:Joseph Lemley, Shabab Bazrafkan, Peter Corcoran category:cs.AI cs.LG stat.ML  published:2017-03-24 summary:A recurring problem faced when training neural networks is that there is typically not enough data to maximize the generalization capability of deep neural networks(DNN). There are many techniques to address this, including data augmentation, dropout, and transfer learning. In this paper, we introduce an additional method which we call Smart Augmentation and we show how to use it to increase the accuracy and reduce overfitting on a target network. Smart Augmentation works by creating a network that learns how to generate augmented data during the training process of a target network in a way that reduces that networks loss. This allows us to learn augmentations that minimize the error of that network. Smart Augmentation has shown the potential to increase accuracy by demonstrably significant measures on all datasets tested. In addition, it has shown potential to achieve similar or improved performance levels with significantly smaller network sizes in a number of tested cases. version:1
arxiv-1703-08378 | Feature Fusion using Extended Jaccard Graph and Stochastic Gradient Descent for Robot | http://arxiv.org/abs/1703.08378 | id:1703.08378 author:Shenglan Liu, Muxin Sun, Wei Wang, Feilong Wang category:cs.CV cs.LG cs.RO  published:2017-03-24 summary:Robot vision is a fundamental device for human-robot interaction and robot complex tasks. In this paper, we use Kinect and propose a feature graph fusion (FGF) for robot recognition. Our feature fusion utilizes RGB and depth information to construct fused feature from Kinect. FGF involves multi-Jaccard similarity to compute a robust graph and utilize word embedding method to enhance the recognition results. We also collect DUT RGB-D face dataset and a benchmark datset to evaluate the effectiveness and efficiency of our method. The experimental results illustrate FGF is robust and effective to face and object datasets in robot applications. version:1
arxiv-1703-08366 | A Hybrid Deep Learning Approach for Texture Analysis | http://arxiv.org/abs/1703.08366 | id:1703.08366 author:Hussein Adly, Mohamed Moustafa category:cs.CV  published:2017-03-24 summary:Texture classification is a problem that has various applications such as remote sensing and forest species recognition. Solutions tend to be custom fit to the dataset used but fails to generalize. The Convolutional Neural Network (CNN) in combination with Support Vector Machine (SVM) form a robust selection between powerful invariant feature extractor and accurate classifier. The fusion of experts provides stability in classification rates among different datasets. version:1
arxiv-1703-08359 | Scalable Person Re-identification on Supervised Smoothed Manifold | http://arxiv.org/abs/1703.08359 | id:1703.08359 author:Song Bai, Xiang Bai, Qi Tian category:cs.CV  published:2017-03-24 summary:Most existing person re-identification algorithms either extract robust visual features or learn discriminative metrics for person images. However, the underlying manifold which those images reside on is rarely investigated. That raises a problem that the learned metric is not smooth with respect to the local geometry structure of the data manifold. In this paper, we study person re-identification with manifold-based affinity learning, which did not receive enough attention from this area. An unconventional manifold-preserving algorithm is proposed, which can 1) make the best use of supervision from training data, whose label information is given as pairwise constraints; 2) scale up to large repositories with low on-line time complexity; and 3) be plunged into most existing algorithms, serving as a generic postprocessing procedure to further boost the identification accuracies. Extensive experimental results on five popular person re-identification benchmarks consistently demonstrate the effectiveness of our method. Especially, on the largest CUHK03 and Market-1501, our method outperforms the state-of-the-art alternatives by a large margin with high efficiency, which is more appropriate for practical applications. version:1
arxiv-1703-08131 | Online Distributed Learning Over Networks in RKH Spaces Using Random Fourier Features | http://arxiv.org/abs/1703.08131 | id:1703.08131 author:Pantelis Bouboulis, Symeon Chouvardas, Sergios Theodoridis category:cs.LG  published:2017-03-23 summary:We present a novel diffusion scheme for online kernel-based learning over networks. So far, a major drawback of any online learning algorithm, operating in a reproducing kernel Hilbert space (RKHS), is the need for updating a growing number of parameters as time iterations evolve. Besides complexity, this leads to an increased need of communication resources, in a distributed setting. In contrast, the proposed method approximates the solution as a fixed-size vector (of larger dimension than the input space) using Random Fourier Features. This paves the way to use standard linear combine-then-adapt techniques. To the best of our knowledge, this is the first time that a complete protocol for distributed online learning in RKHS is presented. Conditions for asymptotic convergence and boundness of the networkwise regret are also provided. The simulated tests illustrate the performance of the proposed scheme. version:2
arxiv-1703-08324 | Are crossing dependencies really scarce? | http://arxiv.org/abs/1703.08324 | id:1703.08324 author:Ramon Ferrer-i-Cancho, Carlos Gomez-Rodriguez, J. L. Esteban category:physics.soc-ph cond-mat.stat-mech cs.CL physics.data-an  published:2017-03-24 summary:The syntactic structure of a sentence can be modelled as a tree, where vertices correspond to words and edges indicate syntactic dependencies. It has been claimed recurrently that the number of edge crossings in real sentences is small. However, a baseline or null hypothesis has been lacking. Here we quantify the amount of crossings of real sentences and compare it to the predictions of a series of baselines. We conclude that crossings are really scarce in real sentences. Their scarcity is unexpected by the hubiness of the trees. Indeed, real sentences are close to linear trees, where the potential number of crossings is maximized. version:1
arxiv-1703-08013 | A learning-based approach to text image retrieval: using CNN features and improved similarity metrics | http://arxiv.org/abs/1703.08013 | id:1703.08013 author:Mao Tan, Si-Ping Yuan, Yong-Xin Su category:cs.CV cs.IR cs.LG  published:2017-03-23 summary:Text content can have different visual presentation ways with roughly similar characters. While conventional text image retrieval depends on complex model of OCR-based text recognition and text similarity detection, this paper proposes a new learning-based approach to text image retrieval with the purpose of finding out the original or similar text through a query text image. Firstly, features of text images are extracted by the CNN network to obtain the deep visual representations. Then, the dimension of CNN features is reduced by PCA method to improve the efficiency of similarity detection. Based on that, an improved similarity metrics with article theme relevance filtering is proposed to improve the retrieval accuracy. In experimental procedure, we collect a group of academic papers both including English and Chinese as the text database, and cut them into pieces of text image. A text image with changed text content is used as the query image, experimental results show that the proposed approach has good ability to retrieve the original text content. version:2
arxiv-1703-08314 | Interacting Conceptual Spaces I : Grammatical Composition of Concepts | http://arxiv.org/abs/1703.08314 | id:1703.08314 author:Joe Bolt, Bob Coecke, Fabrizio Genovese, Martha Lewis, Dan Marsden, Robin Piedeleu category:cs.LO cs.CL  published:2017-03-24 summary:The categorical compositional approach to meaning has been successfully applied in natural language processing, outperforming other models in mainstream empirical language processing tasks. We show how this approach can be generalized to conceptual space models of cognition. In order to do this, first we introduce the category of convex relations as a new setting for categorical compositional semantics, emphasizing the convex structure important to conceptual space applications. We then show how to construct conceptual spaces for various types such as nouns, adjectives and verbs. Finally we show by means of examples how concepts can be systematically combined to establish the meanings of composite phrases from the meanings of their constituent parts. This provides the mathematical underpinnings of a new compositional approach to cognition. version:1
arxiv-1703-08014 | Sparse Inertial Poser: Automatic 3D Human Pose Estimation from Sparse IMUs | http://arxiv.org/abs/1703.08014 | id:1703.08014 author:Timo von Marcard, Bodo Rosenhahn, Michael J. Black, Gerard Pons-Moll category:cs.CV cs.GR  published:2017-03-23 summary:We address the problem of making human motion capture in the wild more practical by using a small set of inertial sensors attached to the body. Since the problem is heavily under-constrained, previous methods either use a large number of sensors, which is intrusive, or they require additional video input. We take a different approach and constrain the problem by: (i) making use of a realistic statistical body model that includes anthropometric constraints and (ii) using a joint optimization framework to fit the model to orientation and acceleration measurements over multiple frames. The resulting tracker Sparse Inertial Poser (SIP) enables 3D human pose estimation using only 6 sensors (attached to the wrists, lower legs, back and head) and works for arbitrary human motions. Experiments on the recently released TNT15 dataset show that, using the same number of sensors, SIP achieves higher accuracy than the dataset baseline without using any video data. We further demonstrate the effectiveness of SIP on newly recorded challenging motions in outdoor scenarios such as climbing or jumping over a wall. version:2
arxiv-1703-08294 | Multi-Level Discovery of Deep Options | http://arxiv.org/abs/1703.08294 | id:1703.08294 author:Roy Fox, Sanjay Krishnan, Ion Stoica, Ken Goldberg category:cs.LG  published:2017-03-24 summary:Augmenting an agent's control with useful higher-level behaviors called options can greatly reduce the sample complexity of reinforcement learning, but manually designing options is infeasible in high-dimensional and abstract state spaces. While recent work has proposed several techniques for automated option discovery, they do not scale to multi-level hierarchies and to expressive representations such as deep networks. We present Discovery of Deep Options (DDO), a policy-gradient algorithm that discovers parametrized options from a set of demonstration trajectories, and can be used recursively to discover additional levels of the hierarchy. The scalability of our approach to multi-level hierarchies stems from the decoupling of low-level option discovery from high-level meta-control policy learning, facilitated by under-parametrization of the high level. We demonstrate that using the discovered options to augment the action space of Deep Q-Network agents can accelerate learning by guiding exploration in tasks where random actions are unlikely to reach valuable states. We show that DDO is effective in adding options that accelerate learning in 4 out of 5 Atari RAM environments chosen in our experiments. We also show that DDO can discover structure in robot-assisted surgical videos and kinematics that match expert annotation with 72% accuracy. version:1
arxiv-1703-08289 | Deep Direct Regression for Multi-Oriented Scene Text Detection | http://arxiv.org/abs/1703.08289 | id:1703.08289 author:Wenhao He, Xu-Yao Zhang, Fei Yin, Cheng-Lin Liu category:cs.CV  published:2017-03-24 summary:In this paper, we first provide a new perspective to divide existing high performance object detection methods into direct and indirect regressions. Direct regression performs boundary regression by predicting the offsets from a given point, while indirect regression predicts the offsets from some bounding box proposals. Then we analyze the drawbacks of the indirect regression, which the recent state-of-the-art detection structures like Faster-RCNN and SSD follows, for multi-oriented scene text detection, and point out the potential superiority of direct regression. To verify this point of view, we propose a deep direct regression based method for multi-oriented scene text detection. Our detection framework is simple and effective with a fully convolutional network and one-step post processing. The fully convolutional network is optimized in an end-to-end way and has bi-task outputs where one is pixel-wise classification between text and non-text, and the other is direct regression to determine the vertex coordinates of quadrilateral text boundaries. The proposed method is particularly beneficial for localizing incidental scene texts. On the ICDAR2015 Incidental Scene Text benchmark, our method achieves the F1-measure of 81%, which is a new state-of-the-art and significantly outperforms previous approaches. On other standard datasets with focused scene texts, our method also reaches the state-of-the-art performance. version:1
arxiv-1703-08283 | Experimental Identification of Hard Data Sets for Classification and Feature Selection Methods with Insights on Method Selection | http://arxiv.org/abs/1703.08283 | id:1703.08283 author:Cuiju Luan, Guozhu Dong category:cs.LG  published:2017-03-24 summary:The paper first reports an experimentally identified list of benchmark data sets that are hard for representative classification and feature selection methods. This was done after systematically evaluating a total of 54 combinations of methods, involving nine state-of-the-art classification algorithms and six commonly used feature selection methods, on 129 data sets from the UCI repository (some data sets with known high classification accuracy were excluded). In this paper, a data set for classification is called hard if none of the 54 combinations can achieve an AUC over 0.8 and none of them can achieve an F-Measure value over 0.8; it is called easy otherwise. A total of 17 out of the 129 data sets were found to be hard in that sense. This paper also compares the performance of different methods, and it produces rankings of classification methods, separately on the hard data sets and on the easy data sets. This paper is the first to rank methods separately for hard data sets and for easy data sets. It turns out that the classifier rankings resulting from our experiments are somehow different from those in the literature and hence they offer new insights on method selection. version:1
arxiv-1703-08274 | View Adaptive Recurrent Neural Networks for High Performance Human Action Recognition from Skeleton Data | http://arxiv.org/abs/1703.08274 | id:1703.08274 author:Pengfei Zhang, Cuiling Lan, Junliang Xing, Wenjun Zeng, Jianru Xue, Nanning Zheng category:cs.CV  published:2017-03-24 summary:Skeleton-based human action recognition has recently attracted increasing attention due to the popularity of 3D skeleton data. One main challenge lies in the large view variations in captured human actions. We propose a novel view adaptation scheme to automatically regulate observation viewpoints during the occurrence of an action. Rather than re-positioning the skeletons based on a human defined prior criterion, we design a view adaptive recurrent neural network (RNN) with LSTM architecture, which enables the network itself to adapt to the most suitable observation viewpoints from end to end. Extensive experiment analyses show that the proposed view adaptive RNN model strives to (1) transform the skeletons of various views to much more consistent viewpoints and (2) maintain the continuity of the action rather than transforming every frame to the same position with the same body orientation. Our model achieves state-of-the-art performance on three benchmark datasets. On the current largest NTU RGB+D dataset, our scheme outperforms the state of the art by an impressive 6% gain in accuracy. version:1
arxiv-1703-08267 | A Nonconvex Splitting Method for Symmetric Nonnegative Matrix Factorization: Convergence Analysis and Optimality | http://arxiv.org/abs/1703.08267 | id:1703.08267 author:Songtao Lu, Mingyi Hong, Zhengdao Wang category:math.OC stat.ML  published:2017-03-24 summary:Symmetric nonnegative matrix factorization (SymNMF) has important applications in data analytics problems such as document clustering, community detection and image segmentation. In this paper, we propose a novel nonconvex variable splitting method for solving SymNMF. The proposed algorithm is guaranteed to converge to the set of Karush-Kuhn-Tucker (KKT) points of the nonconvex SymNMF problem. Furthermore, it achieves a global sublinear convergence rate. We also show that the algorithm can be efficiently implemented in parallel. Further, sufficient conditions are provided which guarantee the global and local optimality of the obtained solutions. Extensive numerical results performed on both synthetic and real data sets suggest that the proposed algorithm converges quickly to a local minimum solution. version:1
arxiv-1703-09784 | Perception Driven Texture Generation | http://arxiv.org/abs/1703.09784 | id:1703.09784 author:Yanhai Gan, Huifang Chi, Ying Gao, Jun Liu, Guoqiang Zhong, Junyu Dong category:cs.CV cs.AI cs.LG  published:2017-03-24 summary:This paper investigates a novel task of generating texture images from perceptual descriptions. Previous work on texture generation focused on either synthesis from examples or generation from procedural models. Generating textures from perceptual attributes have not been well studied yet. Meanwhile, perceptual attributes, such as directionality, regularity and roughness are important factors for human observers to describe a texture. In this paper, we propose a joint deep network model that combines adversarial training and perceptual feature regression for texture generation, while only random noise and user-defined perceptual attributes are required as input. In this model, a preliminary trained convolutional neural network is essentially integrated with the adversarial framework, which can drive the generated textures to possess given perceptual attributes. An important aspect of the proposed model is that, if we change one of the input perceptual features, the corresponding appearance of the generated textures will also be changed. We design several experiments to validate the effectiveness of the proposed method. The results show that the proposed method can produce high quality texture images with desired perceptual properties. version:1
arxiv-1703-08251 | The Dependence of Machine Learning on Electronic Medical Record Quality | http://arxiv.org/abs/1703.08251 | id:1703.08251 author:Long Ho, David Ledbetter, Melissa Aczon, Randall Wetzel category:stat.ML  published:2017-03-23 summary:There is growing interest in applying machine learning methods to Electronic Medical Records (EMR). Across different institutions, however, EMR quality can vary widely. This work investigated the impact of this disparity on the performance of three advanced machine learning algorithms: logistic regression, multilayer perceptron, and recurrent neural network. The EMR disparity was emulated using different permutations of the EMR collected at Children's Hospital Los Angeles (CHLA) Pediatric Intensive Care Unit (PICU) and Cardiothoracic Intensive Care Unit (CTICU). The algorithms were trained using patients from the PICU to predict in-ICU mortality for patients in a held out set of PICU and CTICU patients. The disparate patient populations between the PICU and CTICU provide an estimate of generalization errors across different ICUs. We quantified and evaluated the generalization of these algorithms on varying EMR size, input types, and fidelity of data. version:1
arxiv-1703-08245 | On the Robustness of Convolutional Neural Networks to Internal Architecture and Weight Perturbations | http://arxiv.org/abs/1703.08245 | id:1703.08245 author:Nicholas Cheney, Martin Schrimpf, Gabriel Kreiman category:cs.LG cs.CV  published:2017-03-23 summary:Deep convolutional neural networks are generally regarded as robust function approximators. So far, this intuition is based on perturbations to external stimuli such as the images to be classified. Here we explore the robustness of convolutional neural networks to perturbations to the internal weights and architecture of the network itself. We show that convolutional networks are surprisingly robust to a number of internal perturbations in the higher convolutional layers but the bottom convolutional layers are much more fragile. For instance, Alexnet shows less than a 30% decrease in classification performance when randomly removing over 70% of weight connections in the top convolutional or dense layers but performance is almost at chance with the same perturbation in the first convolutional layer. Finally, we suggest further investigations which could continue to inform the robustness of convolutional networks to internal perturbations. version:1
arxiv-1703-08244 | TokTrack: A Complete Token Provenance and Change Tracking Dataset for the English Wikipedia | http://arxiv.org/abs/1703.08244 | id:1703.08244 author:Fabian Flöck, Kenan Erdogan, Maribel Acosta category:cs.CL  published:2017-03-23 summary:We present a dataset that contains every instance of all tokens (~ words) ever written in undeleted, non-redirect English Wikipedia articles until October 2016, in total 13,545,349,787 instances. Each token is annotated with (i) the article revision it was originally created in, and (ii) lists with all the revisions in which the token was ever deleted and (potentially) re-added and re-deleted from its article, enabling a complete and straightforward tracking of its history. This data would be exceedingly hard to create by an average potential user as it is (i) very expensive to compute and as (ii) accurately tracking the history of each token in revisioned documents is a non-trivial task. Adapting a state-of-the-art algorithm, we have produced a dataset that allows for a range of analyses and metrics, already popular in research and going beyond, to be generated on complete-Wikipedia scale; ensuring quality and allowing researchers to forego expensive text-comparison computation, which so far has hindered scalable usage. We show how this data enables, on token-level, computation of provenance, measuring survival of content over time, very detailed conflict metrics, and fine-grained interactions of editors like partial reverts, re-additions and other metrics, in the process gaining several novel insights. version:1
arxiv-1703-08238 | Semi-Automatic Segmentation and Ultrasonic Characterization of Solid Breast Lesions | http://arxiv.org/abs/1703.08238 | id:1703.08238 author:Mohammad Saad Billah, Tahmida Binte Mahmud category:cs.CV  published:2017-03-23 summary:Characterization of breast lesions is an essential prerequisite to detect breast cancer in an early stage. Automatic segmentation makes this categorization method robust by freeing it from subjectivity and human error. Both spectral and morphometric features are successfully used for differentiating between benign and malignant breast lesions. In this thesis, we used empirical mode decomposition method for semi-automatic segmentation. Sonographic features like ehcogenicity, heterogeneity, FNPA, margin definition, Hurst coefficient, compactness, roundness, aspect ratio, convexity, solidity, form factor were calculated to be used as our characterization parameters. All of these parameters did not give desired comparative results. But some of them namely echogenicity, heterogeneity, margin definition, aspect ratio and convexity gave good results and were used for characterization. version:1
arxiv-1703-06993 | SORT: Second-Order Response Transform for Visual Recognition | http://arxiv.org/abs/1703.06993 | id:1703.06993 author:Yan Wang, Lingxi Xie, Chenxi Liu, Ya Zhang, Wenjun Zhang, Alan Yuille category:cs.CV  published:2017-03-20 summary:In this paper, we reveal the importance and benefits of introducing second-order operations into deep neural networks. We propose a novel approach named Second-Order Response Transform (SORT), which appends element-wise product transform to the linear sum of a two-branch network module. A direct advantage of SORT is to facilitate cross-branch response propagation, so that each branch can update its weights based on the current status of the other branch. Moreover, SORT augments the family of transform operations and increases the nonlinearity of the network, making it possible to learn flexible functions to fit the complicated distribution of feature space. SORT can be applied to a wide range of network architectures, including a branched variant of a chain-styled network and a residual network, with very light-weighted modifications. We observe consistent accuracy gain on both small (CIFAR10, CIFAR100 and SVHN) and big (ILSVRC2012) datasets. In addition, SORT is very efficient, as the extra computation overhead is less than 5%. version:2
arxiv-1703-07022 | Recurrent Topic-Transition GAN for Visual Paragraph Generation | http://arxiv.org/abs/1703.07022 | id:1703.07022 author:Xiaodan Liang, Zhiting Hu, Hao Zhang, Chuang Gan, Eric P. Xing category:cs.CV cs.AI cs.LG  published:2017-03-21 summary:A natural image usually conveys rich semantic content and can be viewed from different angles. Existing image description methods are largely restricted by small sets of biased visual paragraph annotations, and fail to cover rich underlying semantics. In this paper, we investigate a semi-supervised paragraph generative framework that is able to synthesize diverse and semantically coherent paragraph descriptions by reasoning over local semantic regions and exploiting linguistic knowledge. The proposed Recurrent Topic-Transition Generative Adversarial Network (RTT-GAN) builds an adversarial framework between a structured paragraph generator and multi-level paragraph discriminators. The paragraph generator generates sentences recurrently by incorporating region-based visual and language attention mechanisms at each step. The quality of generated paragraph sentences is assessed by multi-level adversarial discriminators from two aspects, namely, plausibility at sentence level and topic-transition coherence at paragraph level. The joint adversarial training of RTT-GAN drives the model to generate realistic paragraphs with smooth logical transition between sentence topics. Extensive quantitative experiments on image and video paragraph datasets demonstrate the effectiveness of our RTT-GAN in both supervised and semi-supervised settings. Qualitative results on telling diverse stories for an image also verify the interpretability of RTT-GAN. version:2
arxiv-1704-01464 | Effect of Super Resolution on High Dimensional Features for Unsupervised Face Recognition in the Wild | http://arxiv.org/abs/1704.01464 | id:1704.01464 author:Ahmed ElSayed, Ausif Mahmood, Tarek Sobh category:cs.CV  published:2017-03-23 summary:Majority of the face recognition algorithms use query faces captured from uncontrolled, in the wild, environment. Often caused by the cameras limited capabilities, it is common for these captured facial images to be blurred or low resolution. Super resolution algorithms are therefore crucial in improving the resolution of such images especially when the image size is small requiring enlargement. This paper aims to demonstrate the effect of one of the state-of-the-art algorithms in the field of image super resolution. To demonstrate the functionality of the algorithm, various before and after 3D face alignment cases are provided using the images from the Labeled Faces in the Wild (lfw). Resulting images are subject to testing on a closed set face recognition protocol using unsupervised algorithms with high dimension extracted features. The inclusion of super resolution algorithm resulted in significant improved recognition rate over recently reported results obtained from unsupervised algorithms. version:1
arxiv-1703-08136 | Visually grounded learning of keyword prediction from untranscribed speech | http://arxiv.org/abs/1703.08136 | id:1703.08136 author:Herman Kamper, Shane Settle, Gregory Shakhnarovich, Karen Livescu category:cs.CL cs.CV  published:2017-03-23 summary:During language acquisition, infants have the benefit of visual cues to ground spoken language. Robots similarly have access to audio and visual sensors. Recent work has shown that images and spoken captions can be mapped into a meaningful common space, allowing images to be retrieved using speech and vice versa. In this setting of images paired with untranscribed spoken captions, we consider whether computer vision systems can be used to obtain textual labels for the speech. Concretely, we use an image-to-words multi-label visual classifier to tag images with soft textual labels, and then train a neural network to map from the speech to these soft targets. We show that the resulting speech system is able to predict which words occur in an utterance---acting as a spoken bag-of-words classifier---without seeing any parallel speech and text. We find that the model often confuses semantically related words, e.g. "man" and "person", making it even more effective as a semantic keyword spotter. version:1
arxiv-1703-08135 | An embedded segmental k-means model for unsupervised segmentation and clustering of speech | http://arxiv.org/abs/1703.08135 | id:1703.08135 author:Herman Kamper, Karen Livescu, Sharon Goldwater category:cs.CL cs.LG  published:2017-03-23 summary:Unsupervised segmentation and clustering of unlabelled speech are core problems in zero-resource speech processing. Most competitive approaches lie at methodological extremes: some follow a Bayesian approach, defining probabilistic models with convergence guarantees, while others opt for more efficient heuristic techniques. Here we introduce an approximation to a segmental Bayesian model that falls in between, with a clear objective function but using hard clustering and segmentation rather than full Bayesian inference. Like its Bayesian counterpart, this embedded segmental k-means model (ES-KMeans) represents arbitrary-length word segments as fixed-dimensional acoustic word embeddings. On English and Xitsonga data, ES-KMeans outperforms a leading heuristic method in word segmentation, giving similar scores to the Bayesian model while being five times faster with fewer hyperparameters. However, there is a trade-off in cluster purity, with the Bayesian model's purer clusters yielding about 10% better unsupervised word error rates. version:1
arxiv-1703-08120 | Recurrent and Contextual Models for Visual Question Answering | http://arxiv.org/abs/1703.08120 | id:1703.08120 author:Abhijit Sharang, Eric Lau category:cs.CL cs.CV  published:2017-03-23 summary:We propose a series of recurrent and contextual neural network models for multiple choice visual question answering on the Visual7W dataset. Motivated by divergent trends in model complexities in the literature, we explore the balance between model expressiveness and simplicity by studying incrementally more complex architectures. We start with LSTM-encoding of input questions and answers; build on this with context generation by LSTM-encodings of neural image and question representations and attention over images; and evaluate the diversity and predictive power of our models and the ensemble thereof. All models are evaluated against a simple baseline inspired by the current state-of-the-art, consisting of involving simple concatenation of bag-of-words and CNN representations for the text and images, respectively. Generally, we observe marked variation in image-reasoning performance between our models not obvious from their overall performance, as well as evidence of dataset bias. Our standalone models achieve accuracies up to $64.6\%$, while the ensemble of all models achieves the best accuracy of $66.67\%$, within $0.5\%$ of the current state-of-the-art for Visual7W. version:1
arxiv-1703-08119 | Quality Resilient Deep Neural Networks | http://arxiv.org/abs/1703.08119 | id:1703.08119 author:Samuel Dodge, Lina Karam category:cs.CV  published:2017-03-23 summary:We study deep neural networks for classification of images with quality distortions. We first show that networks fine-tuned on distorted data greatly outperform the original networks when tested on distorted data. However, fine-tuned networks perform poorly on quality distortions that they have not been trained for. We propose a mixture of experts ensemble method that is robust to different types of distortions. The "experts" in our model are trained on a particular type of distortion. The output of the model is a weighted sum of the expert models, where the weights are determined by a separate gating network. The gating network is trained to predict optimal weights for a particular distortion type and level. During testing, the network is blind to the distortion level and type, yet can still assign appropriate weights to the expert models. We additionally investigate weight sharing methods for the mixture model and show that improved performance can be achieved with a large reduction in the number of unique network parameters. version:1
arxiv-1703-08110 | Training Mixture Models at Scale via Coresets | http://arxiv.org/abs/1703.08110 | id:1703.08110 author:Mario Lucic, Matthew Faulkner, Andreas Krause, Dan Feldman category:stat.ML  published:2017-03-23 summary:How can we train a statistical mixture model on a massive data set? In this paper, we show how to construct coresets for mixtures of Gaussians and natural generalizations. A coreset is a weighted subset of the data, which guarantees that models fitting the coreset also provide a good fit for the original data set. We show that, perhaps surprisingly, Gaussian mixtures admit coresets of size polynomial in dimension and the number of mixture components, while being independent of the data set size. Hence, one can compute a $(1+ \varepsilon)$-approximation for the optimal model on a significantly smaller data set. More importantly, such coresets can be efficiently constructed both in distributed and streaming settings. Our results rely on a novel reduction of statistical estimation to problems in computational geometry and new complexity results for mixtures of Gaussians. As a by-product of our analysis, we prove that the pseudo-dimension of arbitrary mixtures of Gaussians is polynomial in the ambient dimension. Empirical evaluation on several real-world datasets suggest that our coreset-based approach enables significant reduction in training-time with negligible approximation error. version:1
arxiv-1703-08089 | A Bag-of-Words Equivalent Recurrent Neural Network for Action Recognition | http://arxiv.org/abs/1703.08089 | id:1703.08089 author:Alexander Richard, Juergen Gall category:cs.CV  published:2017-03-23 summary:The traditional bag-of-words approach has found a wide range of applications in computer vision. The standard pipeline consists of a generation of a visual vocabulary, a quantization of the features into histograms of visual words, and a classification step for which usually a support vector machine in combination with a non-linear kernel is used. Given large amounts of data, however, the model suffers from a lack of discriminative power. This applies particularly for action recognition, where the vast amount of video features needs to be subsampled for unsupervised visual vocabulary generation. Moreover, the kernel computation can be very expensive on large datasets. In this work, we propose a recurrent neural network that is equivalent to the traditional bag-of-words approach but enables for the application of discriminative training. The model further allows to incorporate the kernel computation into the neural network directly, solving the complexity issue and allowing to represent the complete classification system within a single network. We evaluate our method on four recent action recognition benchmarks and show that the conventional model as well as sparse coding methods are outperformed. version:1
arxiv-1703-08085 | Unifying Framework for Crowd-sourcing via Graphon Estimation | http://arxiv.org/abs/1703.08085 | id:1703.08085 author:Christina E. Lee, Devavrat Shah category:stat.ML  published:2017-03-23 summary:We consider the question of inferring true answers associated with tasks based on potentially noisy answers obtained through a micro-task crowd-sourcing platform such as Amazon Mechanical Turk. We propose a generic, non-parametric model for this setting: for a given task $i$, $1\leq i \leq T$, the response of worker $j$, $1\leq j\leq W$ for this task is correct with probability $F_{ij}$, where matrix $F = [F_{ij}]_{i\leq T, j\leq W}$ may satisfy one of a collection of regularity conditions including low rank, which can express the popular Dawid-Skene model; piecewise constant, which occurs when there is finitely many worker and task types; monotonic under permutation, when there is some ordering of worker skills and task difficulties; or Lipschitz with respect to an associated latent non-parametric function. This model, contains most, if not all, of the previously proposed models to the best of our knowledge. We show that the question of estimating the true answers to tasks can be reduced to solving the Graphon estimation problem, for which there has been much recent progress. By leveraging these techniques, we provide a crowdsourcing inference algorithm along with theoretical bounds on the fraction of incorrectly estimated tasks. Subsequently, we have a solution for inferring the true answers for tasks using noisy answers collected from crowd-sourcing platform under a significantly larger class of models. Concretely, we establish that if the $(i,j)$th element of $F$, $F_{ij}$, is equal to a Lipschitz continuous function over latent features associated with the task $i$ and worker $j$ for all $i, j$, then all task answers can be inferred correctly with high probability by soliciting $\tilde{O}(\ln(T)^{3/2})$ responses per task even without any knowledge of the Lipschitz function, task and worker features, or the matrix $F$. version:1
arxiv-1703-08084 | Multimodal Compact Bilinear Pooling for Multimodal Neural Machine Translation | http://arxiv.org/abs/1703.08084 | id:1703.08084 author:Jean-Benoit Delbrouck, Stephane Dupont category:cs.CL  published:2017-03-23 summary:In state-of-the-art Neural Machine Translation, an attention mechanism is used during decoding to enhance the translation. At every step, the decoder uses this mechanism to focus on different parts of the source sentence to gather the most useful information before outputting its target word. Recently, the effectiveness of the attention mechanism has also been explored for multimodal tasks, where it becomes possible to focus both on sentence parts and image regions. Approaches to pool two modalities usually include element-wise product, sum or concatenation. In this paper, we evaluate the more advanced Multimodal Compact Bilinear pooling method, which takes the outer product of two vectors to combine the attention features for the two modalities. This has been previously investigated for visual question answering. We try out this approach for multimodal image caption translation and show improvements compared to basic combination methods. version:1
arxiv-1703-08068 | Sequential Recurrent Neural Networks for Language Modeling | http://arxiv.org/abs/1703.08068 | id:1703.08068 author:Youssef Oualil, Clayton Greenberg, Mittul Singh, Dietrich Klakow category:cs.CL  published:2017-03-23 summary:Feedforward Neural Network (FNN)-based language models estimate the probability of the next word based on the history of the last N words, whereas Recurrent Neural Networks (RNN) perform the same task based only on the last word and some context information that cycles in the network. This paper presents a novel approach, which bridges the gap between these two categories of networks. In particular, we propose an architecture which takes advantage of the explicit, sequential enumeration of the word history in FNN structure while enhancing each word representation at the projection layer through recurrent context information that evolves in the network. The context integration is performed using an additional word-dependent weight matrix that is also learned during the training. Extensive experiments conducted on the Penn Treebank (PTB) and the Large Text Compression Benchmark (LTCB) corpus showed a significant reduction of the perplexity when compared to state-of-the-art feedforward as well as recurrent neural network architectures. version:1
arxiv-1703-08065 | Robustness of Maximum Correntropy Estimation Against Large Outliers | http://arxiv.org/abs/1703.08065 | id:1703.08065 author:Badong Chen, Lei Xing, Haiquan Zhao, Bin Xu, Jose C. Principe category:stat.ML  published:2017-03-23 summary:The maximum correntropy criterion (MCC) has recently been successfully applied in robust regression, classification and adaptive filtering, where the correntropy is maximized instead of minimizing the well-known mean square error (MSE) to improve the robustness with respect to outliers (or impulsive noises). Considerable efforts have been devoted to develop various robust adaptive algorithms under MCC, but so far little insight has been gained as to how the optimal solution will be affected by outliers. In this work, we study this problem in the context of parameter estimation for a simple linear errors-in-variables (EIV) model where all variables are scalar. Under certain conditions, we derive an upper bound on the absolute value of the estimation error and show that the optimal solution under MCC can be very close to the true value of the unknown parameter even with outliers (whose values can be arbitrarily large) in both input and output variables. An illustrative example is presented to verify and clarify the theory. version:1
arxiv-1703-08052 | Dynamic Bernoulli Embeddings for Language Evolution | http://arxiv.org/abs/1703.08052 | id:1703.08052 author:Maja Rudolph, David Blei category:stat.ML cs.CL  published:2017-03-23 summary:Word embeddings are a powerful approach for unsupervised analysis of language. Recently, Rudolph et al. (2016) developed exponential family embeddings, which cast word embeddings in a probabilistic framework. Here, we develop dynamic embeddings, building on exponential family embeddings to capture how the meanings of words change over time. We use dynamic embeddings to analyze three large collections of historical texts: the U.S. Senate speeches from 1858 to 2009, the history of computer science ACM abstracts from 1951 to 2014, and machine learning papers on the Arxiv from 2007 to 2015. We find dynamic embeddings provide better fits than classical embeddings and capture interesting patterns about how language changes. version:1
arxiv-1703-08050 | Is Second-order Information Helpful for Large-scale Visual Recognition? | http://arxiv.org/abs/1703.08050 | id:1703.08050 author:Peihua Li, Jiangtao Xie, Qilong Wang, Wangmeng Zuo category:cs.CV  published:2017-03-23 summary:By stacking deeper layers of convolutions and nonlinearity, convolutional networks (ConvNets) effectively learn from low-level to high-level features and discriminative representations. Since the end goal of large-scale recognition is to delineate the complex boundaries of thousands of classes in a large-dimensional space, adequate exploration of feature distributions is important for realizing full potentials of ConvNets. However, state-of-the-art works concentrate only on deeper or wider architecture design, while rarely exploring feature statistics higher than first-order. We take a step towards addressing this problem. Our method consists in covariance pooling, instead of the most commonly used first-order pooling, of high-level convolutional features. The main challenges involved are robust covariance estimation given a small sample of large-dimensional features and usage of the manifold structure of covariance matrices. To address these challenges, we present a Matrix Power Normalized Covariance (MPN-COV) method. We develop the forward and backward propagation formulas regarding the nonlinear matrix functions such that MPN-COV can be trained end-to-end. In addition, we analyze both qualitatively and quantitatively its advantage over the widely used Log-Euclidean metric. On the ImageNet 2012 validation set, by combining MPN-COV we achieve over 4%, 3% and 2.5% gains for AlexNet, VGG-M and VGG-16, respectively; integration of MPN-COV into 50-layer ResNet outperforms ResNet-101 and is comparable to ResNet-152, both of which use first-order, global average pooling. version:1
arxiv-1703-08033 | Generative Adversarial Residual Pairwise Networks for One Shot Learning | http://arxiv.org/abs/1703.08033 | id:1703.08033 author:Akshay Mehrotra, Ambedkar Dukkipati category:cs.CV cs.NE  published:2017-03-23 summary:Deep neural networks achieve unprecedented performance levels over many tasks and scale well with large quantities of data, but performance in the low-data regime and tasks like one shot learning still lags behind. While recent work suggests many hypotheses from better optimization to more complicated network structures, in this work we hypothesize that having a learnable and more expressive similarity objective is an essential missing component. Towards overcoming that, we propose a network design inspired by deep residual networks that allows the efficient computation of this more expressive pairwise similarity objective. Further, we argue that regularization is key in learning with small amounts of data, and propose an additional generator network based on the Generative Adversarial Networks where the discriminator is our residual pairwise network. This provides a strong regularizer by leveraging the generated data samples. The proposed model can generate plausible variations of exemplars over unseen classes and outperforms strong discriminative baselines for few shot classification tasks. Notably, our residual pairwise network design outperforms previous state-of-theart on the challenging mini-Imagenet dataset for one shot learning by getting over 55% accuracy for the 5-way classification task over unseen classes. version:1
arxiv-1703-08031 | Distribution of Gaussian Process Arc Lengths | http://arxiv.org/abs/1703.08031 | id:1703.08031 author:Justin D. Bewsher, Alessandra Tosi, Michael A. Osborne, Stephen J. Roberts category:stat.ML  published:2017-03-23 summary:We present the first treatment of the arc length of the Gaussian Process (GP) with more than a single output dimension. GPs are commonly used for tasks such as trajectory modelling, where path length is a crucial quantity of interest. Previously, only paths in one dimension have been considered, with no theoretical consideration of higher dimensional problems. We fill the gap in the existing literature by deriving the moments of the arc length for a stationary GP with multiple output dimensions. A new method is used to derive the mean of a one-dimensional GP over a finite interval, by considering the distribution of the arc length integrand. This technique is used to derive an approximate distribution over the arc length of a vector valued GP in $\mathbb{R}^n$ by moment matching the distribution. Numerical simulations confirm our theoretical derivations. version:1
arxiv-1703-08002 | A network of deep neural networks for distant speech recognition | http://arxiv.org/abs/1703.08002 | id:1703.08002 author:Mirco Ravanelli, Philemon Brakel, Maurizio Omologo, Yoshua Bengio category:cs.CL cs.LG  published:2017-03-23 summary:Despite the remarkable progress recently made in distant speech recognition, state-of-the-art technology still suffers from a lack of robustness, especially when adverse acoustic conditions characterized by non-stationary noises and reverberation are met. A prominent limitation of current systems lies in the lack of matching and communication between the various technologies involved in the distant speech recognition process. The speech enhancement and speech recognition modules are, for instance, often trained independently. Moreover, the speech enhancement normally helps the speech recognizer, but the output of the latter is not commonly used, in turn, to improve the speech enhancement. To address both concerns, we propose a novel architecture based on a network of deep neural networks, where all the components are jointly trained and better cooperate with each other thanks to a full communication scheme between them. Experiments, conducted using different datasets, tasks and acoustic conditions, revealed that the proposed framework can overtake other competitive solutions, including recent joint training approaches. version:1
arxiv-1703-08001 | Nonlinear Spectral Image Fusion | http://arxiv.org/abs/1703.08001 | id:1703.08001 author:Martin Benning, Michael Möller, Raz Z. Nossek, Martin Burger, Daniel Cremers, Guy Gilboa, Carola-Bibiane Schönlieb category:cs.CV math.NA  published:2017-03-23 summary:In this paper we demonstrate that the framework of nonlinear spectral decompositions based on total variation (TV) regularization is very well suited for image fusion as well as more general image manipulation tasks. The well-localized and edge-preserving spectral TV decomposition allows to select frequencies of a certain image to transfer particular features, such as wrinkles in a face, from one image to another. We illustrate the effectiveness of the proposed approach in several numerical experiments, including a comparison to the competing techniques of Poisson image editing, linear osmosis, wavelet fusion and Laplacian pyramid fusion. We conclude that the proposed spectral TV image decomposition framework is a valuable tool for semi- and fully-automatic image editing and fusion. version:1
arxiv-1703-08000 | Weakly Supervised Object Localization Using Things and Stuff Transfer | http://arxiv.org/abs/1703.08000 | id:1703.08000 author:Miaojing Shi, Holger Caesar, Vittorio Ferrari category:cs.CV  published:2017-03-23 summary:We propose to help weakly supervised object localization for classes where location annotations are not available, by transferring things and stuff knowledge from a source set with available annotations. The source and target classes might share similar appearance (e.g. bear fur is similar to cat fur) or appear against similar background (e.g. horse and sheep appear against grass). To exploit this, we acquire three types of knowledge from the source set: a segmentation model trained on both thing and stuff classes; similarity relations between target and source classes; and co-occurrence relations between thing and stuff classes in the source. The segmentation model is used to generate thing and stuff segmentation maps on a target image, while the class similarity and co-occurrence knowledge help refining them. We then incorporate these maps as new cues into a multiple instance learning framework (MIL), propagating the transferred knowledge from the pixel level to the object proposal level. In extensive experiments, we conduct our transfer from the PASCAL Context dataset (source) to the ILSVRC, COCO and PASCAL VOC 2007 datasets (targets). We evaluate our transfer across widely different thing classes, including some that are not similar in appearance, but appear against similar background. The results demonstrate significant improvement over standard MIL, and we outperform the state-of-the-art in the transfer setting. version:1
arxiv-1703-07980 | Discriminatively Boosted Image Clustering with Fully Convolutional Auto-Encoders | http://arxiv.org/abs/1703.07980 | id:1703.07980 author:Fengfu Li, Hong Qiao, Bo Zhang, Xuanyang Xi category:cs.CV cs.LG  published:2017-03-23 summary:Traditional image clustering methods take a two-step approach, feature learning and clustering, sequentially. However, recent research results demonstrated that combining the separated phases in a unified framework and training them jointly can achieve a better performance. In this paper, we first introduce fully convolutional auto-encoders for image feature learning and then propose a unified clustering framework to learn image representations and cluster centers jointly based on a fully convolutional auto-encoder and soft $k$-means scores. At initial stages of the learning procedure, the representations extracted from the auto-encoder may not be very discriminative for latter clustering. We address this issue by adopting a boosted discriminative distribution, where high score assignments are highlighted and low score ones are de-emphasized. With the gradually boosted discrimination, clustering assignment scores are discriminated and cluster purities are enlarged. Experiments on several vision benchmark datasets show that our methods can achieve a state-of-the-art performance. version:1
arxiv-1703-07971 | Image-based Localization using Hourglass Networks | http://arxiv.org/abs/1703.07971 | id:1703.07971 author:Iaroslav Melekhov, Juha Ylioinas, Juho Kannala, Esa Rahtu category:cs.CV  published:2017-03-23 summary:In this paper, we propose an encoder-decoder convolutional neural network (CNN) architecture for estimating camera pose (orientation and location) from a single RGB-image. The architecture has a hourglass shape consisting of a chain of convolution and up-convolution layers followed by a regression part. The up-convolution layers are introduced to preserve the fine-grained information of the input image. Following the common practice, we train our model in end-to-end manner utilizing transfer learning from large scale classification data. The experiments demonstrate the performance of the approach on data exhibiting different lighting conditions, reflections, and motion blur. The results indicate a clear improvement over the previous state-of-the-art even when compared to methods that utilize sequence of test frames instead of a single frame. version:1
arxiv-1703-07950 | Failures of Deep Learning | http://arxiv.org/abs/1703.07950 | id:1703.07950 author:Shai Shalev-Shwartz, Ohad Shamir, Shaked Shammah category:cs.LG  published:2017-03-23 summary:In recent years, Deep Learning has become the go-to solution for a broad range of applications, often outperforming state-of-the-art. However, it is important, for both theoreticians and practitioners, to gain a deeper understanding of the difficulties and limitations associated with common approaches and algorithms. We describe four families of problems for which some of the commonly used existing algorithms fail or suffer significant difficulty. We illustrate the failures through practical experiments, and provide theoretical insights explaining their source, and how they might be remedied. version:1
arxiv-1703-07943 | The role of zero synapses in unsupervised feature learning | http://arxiv.org/abs/1703.07943 | id:1703.07943 author:Haiping Huang category:q-bio.NC cond-mat.dis-nn cond-mat.stat-mech cs.LG cs.NE  published:2017-03-23 summary:Synapses in real neural circuits can take discrete values, including zero (silent or potential) synapses. The computational role of zero synapses in unsupervised feature learning of unlabeled noisy data is still unclear, yet important to understand how the sparseness of synaptic activity is shaped during learning and its relationship with receptive field formation. Here, we formulate this kind of sparse feature learning by statistical mechanics approach. We find that learning decreases the fraction of zero synapses, and when the fraction decreases rapidly around a critical data size, the intrinsically structured receptive field starts to develop. Further increasing the data size refines the receptive field, while a very small fraction of zero synapses remain to act as contour detectors. This feature is discovered not only in a handwritten digits dataset, but also in retinal neural activity measured in a natural movie stimuli experiment. version:1
arxiv-1703-07940 | Unsupervised Basis Function Adaptation for Reinforcement Learning | http://arxiv.org/abs/1703.07940 | id:1703.07940 author:Edward Barker, Charl Ras category:cs.LG cs.AI stat.ML  published:2017-03-23 summary:When using reinforcement learning (RL) algorithms to evaluate a policy it is common, given a large state space, to introduce some form of approximation architecture for the value function (VF). The exact form of this architecture can have a significant effect on the accuracy of the VF estimate, however, and determining a suitable approximation architecture can often be a highly complex task. Consequently there is a large amount of interest in the potential for allowing RL algorithms to adaptively generate (i.e. to learn) approximation architectures. We investigate a method of adapting approximation architectures which uses feedback regarding the frequency with which an agent has visited certain states to guide which areas of the state space to approximate with greater detail. We introduce an algorithm based upon this idea which adapts a state aggregation approximation architecture on-line. Assuming $S$ states, we demonstrate theoretically that - provided the following relatively non-restrictive assumptions are satisfied: (a) the number of cells $X$ in the state aggregation architecture is of order $\sqrt{S}\ln{S}\log_2{S}$ or greater, (b) the policy and transition function are close to deterministic, and (c) the prior for the transition function is uniformly distributed - our algorithm can guarantee, assuming we use an appropriate scoring function to measure VF error, error which is arbitrarily close to zero as $S$ becomes large. It is able to do this despite having only $O(X\log_2{S})$ space complexity (and negligible time complexity). We conclude by generating a set of empirical results which support the theoretical results. version:1
arxiv-1703-07939 | Recurrent Multimodal Interaction for Referring Image Segmentation | http://arxiv.org/abs/1703.07939 | id:1703.07939 author:Chenxi Liu, Zhe Lin, Xiaohui Shen, Jimei Yang, Xin Lu, Alan Yuille category:cs.CV  published:2017-03-23 summary:In this paper we are interested in the problem of image segmentation given natural language descriptions, i.e. referring expressions. Existing works tackle this problem by first modeling images and sentences independently and then segment images by combining these two types of representations. We argue that learning word-to-image interaction is more native in the sense of jointly modeling two modalities for the image segmentation task, and we propose convolutional multimodal LSTM to encode the sequential interactions between individual words, visual information, and spatial information. We show that our proposed model outperforms the baseline model on benchmark datasets. In addition, we analyze the intermediate output of the proposed multimodal LSTM approach and empirically explains how this approach enforces a more effective word-to-image interaction. version:1
arxiv-1703-07938 | Planar Object Tracking in the Wild: A Benchmark | http://arxiv.org/abs/1703.07938 | id:1703.07938 author:Pengpeng Liang, Yifan Wu, Haibin Ling category:cs.CV  published:2017-03-23 summary:Planar object tracking plays an important role in computer vision and related fields. While several benchmarks have been constructed for evaluating state-of-the-art algorithms, there is a lack of video sequences captured in the wild rather than in constrained laboratory environment. In this paper, we present a carefully designed planar object tracking benchmark containing 210 videos of 30 planar objects sampled in the natural environment. In particular, for each object, we shoot seven videos involving various challenging factors, namely scale change, rotation, perspective distortion, motion blur, occlusion, out-of-view, and unconstrained. The ground truth is carefully annotated semi-manually to ensure the quality. Moreover, eleven state-of-the-art algorithms are evaluated on the benchmark using two evaluation metrics, with detailed analysis provided for the evaluation results. We expect the proposed benchmark to benefit future studies on planar object tracking. version:1
arxiv-1703-07928 | Guided Perturbations: Self Corrective Behavior in Convolutional Neural Networks | http://arxiv.org/abs/1703.07928 | id:1703.07928 author:Swami Sankaranarayanan, Arpit Jain, Ser Nam Lim category:cs.CV cs.AI stat.ML  published:2017-03-23 summary:Convolutional Neural Networks have been a subject of great importance over the past decade and great strides have been made in their utility for producing state of the art performance in many computer vision problems. However, the behavior of deep networks is yet to be fully understood and is still an active area of research. In this work, we present an intriguing behavior: pre-trained CNNs can be made to improve their predictions by structurally perturbing the input. We observe that these perturbations - referred as Guided Perturbations - enable a trained network to improve its prediction performance without any learning or change in network weights. We perform various ablative experiments to understand how these perturbations affect the local context and feature representations. Furthermore, we demonstrate that this idea can improve performance of several existing approaches on semantic segmentation and scene labeling tasks on the PASCAL VOC dataset and supervised classification tasks on MNIST and CIFAR10 datasets. version:1
arxiv-1703-07920 | Changing Fashion Cultures | http://arxiv.org/abs/1703.07920 | id:1703.07920 author:Kaori Abe, Teppei Suzuki, Shunya Ueta, Akio Nakamura, Yutaka Satoh, Hirokatsu Kataoka category:cs.CV cs.DB cs.MM  published:2017-03-23 summary:The paper presents a novel concept that analyzes and visualizes worldwide fashion trends. Our goal is to reveal cutting-edge fashion trends without displaying an ordinary fashion style. To achieve the fashion-based analysis, we created a new fashion culture database (FCDB), which consists of 76 million geo-tagged images in 16 cosmopolitan cities. By grasping a fashion trend of mixed fashion styles,the paper also proposes an unsupervised fashion trend descriptor (FTD) using a fashion descriptor, a codeword vetor, and temporal analysis. To unveil fashion trends in the FCDB, the temporal analysis in FTD effectively emphasizes consecutive features between two different times. In experiments, we clearly show the analysis of fashion trends and fashion-based city similarity. As the result of large-scale data collection and an unsupervised analyzer, the proposed approach achieves world-level fashion visualization in a time series. The code, model, and FCDB will be publicly available after the construction of the project page. version:1
arxiv-1703-07915 | Perspective: Energy Landscapes for Machine Learning | http://arxiv.org/abs/1703.07915 | id:1703.07915 author:Andrew J. Ballard, Ritankar Das, Stefano Martiniani, Dhagash Mehta, Levent Sagun, Jacob D. Stevenson, David J. Wales category:stat.ML cond-mat.dis-nn cs.CV cs.LG  published:2017-03-23 summary:Machine learning techniques are being increasingly used as flexible non-linear fitting and prediction tools in the physical sciences. Fitting functions that exhibit multiple solutions as local minima can be analysed in terms of the corresponding machine learning landscape. Methods to explore and visualise molecular potential energy landscapes can be applied to these machine learning landscapes to gain new insight into the solution space involved in training and the nature of the corresponding predictions. In particular, we can define quantities analogous to molecular structure, thermodynamics, and kinetics, and relate these emergent properties to the structure of the underlying landscape. This Perspective aims to describe these analogies with examples from recent applications, and suggest avenues for new interdisciplinary research. version:1
arxiv-1703-07914 | Adversarial synapses: Hebbian/anti-Hebbian learning optimizes min-max objectives | http://arxiv.org/abs/1703.07914 | id:1703.07914 author:Cengiz Pehlevan, Anirvan Sengupta, Dmitri B. Chklovskii category:q-bio.NC cs.NE  published:2017-03-23 summary:A promising approach towards understanding neural networks is to view them as implementations of online algorithms optimizing principled objectives. Existing neural algorithms capturing both neural activity dynamics and synaptic weight updates implement the same operation, either minimization or maximization of the objective, with respect to each variable. Here, we derive neural networks from principled min-max objectives: by minimizing with respect to neural activity and feedforward synaptic weights, and maximizing with respect to lateral synaptic weights. In turn, the min-max objectives are obtained via the Hubbard-Stratonovich (HS) transform of similarity matching objectives. The resulting networks perform dimensionality reduction of the input data resorting only to biologically plausible local learning rules. The min-max nature of the objective is reflected in the antagonism between Hebbian feedforward and anti-Hebbian lateral learning in derived networks. We prove that the only stable fixed points of the network dynamics correspond to the principal subspace projection (PSP) or the principal subspace whitening (PSW). Finally, from the min-max objectives we derive novel formulations of dimensionality reduction using fractional matrix exponents. version:1
arxiv-1703-07910 | Bidirectional-Convolutional LSTM Based Spectral-Spatial Feature Learning for Hyperspectral Image Classification | http://arxiv.org/abs/1703.07910 | id:1703.07910 author:Qingshan Liu, Feng Zhou, Renlong Hang, Xiaotong Yuan category:cs.CV  published:2017-03-23 summary:This paper proposes a novel deep learning framework named bidirectional-convolutional long short term memory (Bi-CLSTM) network to automatically learn the spectral-spatial feature from hyperspectral images (HSIs). In the network, the issue of spectral feature extraction is considered as a sequence learning problem, and a recurrent connection operator across the spectral domain is used to address it. Meanwhile, inspired from the widely used convolutional neural network (CNN), a convolution operator across the spatial domain is incorporated into the network to extract the spatial feature. Besides, to sufficiently capture the spectral information, a bidirectional recurrent connection is proposed. In the classification phase, the learned features are concatenated into a vector and fed to a softmax classifier via a fully-connected operator. To validate the effectiveness of the proposed Bi-CLSTM framework, we compare it with several state-of-the-art methods, including the CNN framework, on three widely used HSIs. The obtained results show that Bi-CLSTM can improve the classification performance as compared to other methods. version:1
arxiv-1703-07909 | Data Driven Exploratory Attacks on Black Box Classifiers in Adversarial Domains | http://arxiv.org/abs/1703.07909 | id:1703.07909 author:Tegjyot Singh Sethi, Mehmed Kantardzic category:stat.ML cs.CR cs.LG  published:2017-03-23 summary:While modern day web applications aim to create impact at the civilization level, they have become vulnerable to adversarial activity, where the next cyber-attack can take any shape and can originate from anywhere. The increasing scale and sophistication of attacks, has prompted the need for a data driven solution, with machine learning forming the core of many cybersecurity systems. Machine learning was not designed with security in mind, and the essential assumption of stationarity, requiring that the training and testing data follow similar distributions, is violated in an adversarial domain. In this paper, an adversary's view point of a classification based system, is presented. Based on a formal adversarial model, the Seed-Explore-Exploit framework is presented, for simulating the generation of data driven and reverse engineering attacks on classifiers. Experimental evaluation, on 10 real world datasets and using the Google Cloud Prediction Platform, demonstrates the innate vulnerability of classifiers and the ease with which evasion can be carried out, without any explicit information about the classifier type, the training data or the application domain. The proposed framework, algorithms and empirical evaluation, serve as a white hat analysis of the vulnerabilities, and aim to foster the development of secure machine learning frameworks. version:1
arxiv-1703-08173 | Single Image Super-resolution with a Parameter Economic Residual-like Convolutional Neural Network | http://arxiv.org/abs/1703.08173 | id:1703.08173 author:Yudong Liang, Ze Yang, Kai Zhang, Yihui He, Jinjun Wang, Nanning Zheng category:cs.CV  published:2017-03-23 summary:Recent years have witnessed great success of convolutional neural network (CNN) for various problems both in low and high level visions. Especially noteworthy is the residual network which was originally proposed to handle high-level vision problems and enjoys several merits. This paper aims to extend the merits of residual network, such as skip connection induced fast training, for a typical low-level vision problem, i.e., single image super-resolution. In general, the two main challenges of existing deep CNN for supper-resolution lie in the gradient exploding/vanishing problem and large amount of parameters or computational cost as CNN goes deeper. Correspondingly, the skip connections or identity mapping shortcuts are utilized to avoid gradient exploding/vanishing problem. To tackle with the second problem, a parameter economic CNN architecture which has carefully designed width, depth and skip connections was proposed. Different residual-like architectures for image superresolution has also been compared. Experimental results have demonstrated that the proposed CNN model can not only achieve state-of-the-art PSNR and SSIM results for single image super-resolution but also produce visually pleasant results. This paper has extended the mmm 2017 paper with more experiments and explanations. version:1
arxiv-1703-07904 | Cross-Validation with Confidence | http://arxiv.org/abs/1703.07904 | id:1703.07904 author:Jing Lei category:stat.ME stat.ML  published:2017-03-23 summary:Cross-validation is one of the most popular model selection methods in statistics and machine learning. Despite its wide applicability, traditional cross-validation methods tend to select overfitting models, unless the ratio between the training and testing sample sizes is much smaller than conventional choices. We argue that such an overfitting tendency of cross-validation is due to the ignorance of the uncertainty in the testing sample. Starting from this observation, we develop a new, statistically principled inference tool based on cross-validation that takes into account the uncertainty in the testing sample. This new method outputs a small set of highly competitive candidate models containing the best one with guaranteed probability. As a consequence, our method can achieve consistent variable selection in a classical linear regression setting, for which existing cross-validation methods require unconventional split ratios. We demonstrate the performance of the proposed method in several simulated and real data examples. version:1
arxiv-1703-09783 | Two-Stream RNN/CNN for Action Recognition in 3D Videos | http://arxiv.org/abs/1703.09783 | id:1703.09783 author:Rui Zhao, Haider Ali, Patrick van der Smagt category:cs.CV cs.LG  published:2017-03-22 summary:The recognition of actions from video sequences has many applications in health monitoring, assisted living, surveillance, and smart homes. Despite advances in sensing, in particular related to 3D video, the methodologies to process the data are still subject to research. We demonstrate superior results by a system which combines recurrent neural networks with convolutional neural networks in a voting approach. The gated-recurrent-unit-based neural networks are particularly well-suited to distinguish actions based on long-term information from optical tracking data; the 3D-CNNs focus more on detailed, recent information from video data. The resulting features are merged in an SVM which then classifies the movement. In this architecture, our method improves recognition rates of state-of-the-art methods by 14% on standard data sets. version:1
arxiv-1704-01985 | Recognizing Multi-talker Speech with Permutation Invariant Training | http://arxiv.org/abs/1704.01985 | id:1704.01985 author:Dong Yu, Xuankai Chang, Yanmin Qian category:cs.SD cs.LG I.2.7  published:2017-03-22 summary:In this paper, we propose a novel technique for direct recognition of multiple speech streams given the single channel of mixed speech, without first separating them. Our technique is based on permutation invariant training (PIT) for automatic speech recognition (ASR). In PIT-ASR, we compute the average cross entropy (CE) over all frames in the whole utterance for each possible output-target assignment, pick the one with the minimum CE, and optimize for that assignment. PIT-ASR forces all the frames of the same speaker to be aligned with the same output layer. This strategy elegantly solves the label permutation problem and speaker tracing problem in one shot. Our experiments on artificially mixed AMI data showed that the proposed approach is very promising. version:1
arxiv-1703-09779 | A Holistic Approach for Optimizing DSP Block Utilization of a CNN implementation on FPGA | http://arxiv.org/abs/1703.09779 | id:1703.09779 author:Kamel Abdelouahab, Cedric Bourrasset, Maxime Pelcat, François Berry, Jean-Charles Quinton, Jocelyn Serot category:cs.CV  published:2017-03-21 summary:Deep Neural Networks are becoming the de-facto standard models for image understanding, and more generally for computer vision tasks. As they involve highly parallelizable computations, CNN are well suited to current fine grain programmable logic devices. Thus, multiple CNN accelerators have been successfully implemented on FPGAs. Unfortunately, FPGA resources such as logic elements or DSP units remain limited. This work presents a holistic method relying on approximate computing and design space exploration to optimize the DSP block utilization of a CNN implementation on an FPGA. This method was tested when implementing a reconfigurable OCR convolutional neural network on an Altera Stratix V device and varying both data representation and CNN topology in order to find the best combination in terms of DSP block utilization and classification accuracy. This exploration generated dataflow architectures of 76 CNN topologies with 5 different fixed point representation. Most efficient implementation performs 883 classifications/sec at 256 x 256 resolution using 8% of the available DSP blocks. version:1
arxiv-1703-09749 | Developpement de Methodes Automatiques pour la Reutilisation des Composants Logiciels | http://arxiv.org/abs/1703.09749 | id:1703.09749 author:Kouakou Ive Arsene Koffi, Konan Marcellin Brou, Souleymane Oumtanaga category:cs.SE cs.CL cs.DB  published:2017-03-21 summary:The large amount of information and the increasing complexity of applications constrain developers to have stand-alone and reusable components from libraries and component markets.Our approach consists in developing methods to evaluate the quality of the software component of these libraries, on the one hand and moreover to optimize the financial cost and the adaptation's time of these selected components. Our objective function defines a metric that maximizes the value of the software component quality by minimizing the financial cost and maintenance time. This model should make it possible to classify the components and order them in order to choose the most optimized. MOTS-CLES : d{\'e}veloppement de m{\'e}thode, r{\'e}utilisation, composants logiciels, qualit{\'e} de composant KEYWORDS:method development, reuse, software components, component quality . version:1
arxiv-1703-09800 | Disruptive Event Classification using PMU Data in Distribution Networks | http://arxiv.org/abs/1703.09800 | id:1703.09800 author:Iman Niazazari, Hanif Livani category:cs.LG cs.SY  published:2017-03-20 summary:Proliferation of advanced metering devices with high sampling rates in distribution grids, e.g., micro-phasor measurement units ({\mu}PMU), provides unprecedented potentials for wide-area monitoring and diagnostic applications, e.g., situational awareness, health monitoring of distribution assets. Unexpected disruptive events interrupting the normal operation of assets in distribution grids can eventually lead to permanent failure with expensive replacement cost over time. Therefore, disruptive event classification provides useful information for preventive maintenance of the assets in distribution networks. Preventive maintenance provides wide range of benefits in terms of time, avoiding unexpected outages, maintenance crew utilization, and equipment replacement cost. In this paper, a PMU-data-driven framework is proposed for classification of disruptive events in distribution networks. The two disruptive events, i.e., malfunctioned capacitor bank switching and malfunctioned regulator on-load tap changer (OLTC) switching are considered and distinguished from the normal abrupt load change in distribution grids. The performance of the proposed framework is verified using the simulation of the events in the IEEE 13-bus distribution network. The event classification is formulated using two different algorithms as; i) principle component analysis (PCA) together with multi-class support vector machine (SVM), and ii) autoencoder along with softmax classifier. The results demonstrate the effectiveness of the proposed algorithms and satisfactory classification accuracies. version:1
arxiv-1703-10217 | Smartphone Based Colorimetric Detection via Machine Learning | http://arxiv.org/abs/1703.10217 | id:1703.10217 author:Ali Y. Mutlu, Volkan Kılıç, Gizem K. Özdemir, Abdullah Bayram, Nesrin Horzum, Mehmet E. Solmaz category:cs.CV  published:2017-03-17 summary:We report the application of machine learning to smartphone based colorimetric detection of pH values. The strip images were used as the training set for Least Squares-Support Vector Machine (LS-SVM) classifier algorithms that were able to successfully classify the distinct pH values. The difference in the obtained image formats was found not to significantly affect the performance of the proposed machine learning approach. Moreover, the influence of the illumination conditions on the perceived color of pH strips was investigated and further experiments were carried out to study effect of color change on the learning model. Test results on JPEG, RAW and RAW-corrected image formats captured in different lighting conditions lead to perfect classification accuracy, sensitivity and specificity, which proves that the colorimetric detection using machine learning based systems is able to adapt to various experimental conditions and is a great candidate for smartphone based sensing in paper-based colorimetric assays. version:1
