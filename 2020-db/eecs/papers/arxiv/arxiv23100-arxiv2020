arxiv-1611-07369 | Geometry of 3D Environments and Sum of Squares Polynomials | http://arxiv.org/abs/1611.07369 | id:1611.07369 author:Amir Ali Ahmadi, Georgina Hall, Ameesh Makadia, Vikas Sindhwani category:math.OC cs.CG cs.CV cs.GR  published:2016-11-22 summary:Motivated by applications in robotics and computer vision, we study problems related to spatial reasoning of a 3D environment using sublevel sets of polynomials. These include: tightly containing a cloud of points (e.g., representing an obstacle) with convex or nearly-convex basic semialgebraic sets, computation of Euclidean distances between two such sets, separation of two convex basic semalgebraic sets that overlap, and tight containment of the union of several basic semialgebraic sets with a single convex one. We use algebraic techniques from sum of squares optimization that reduce all these tasks to semidefinite programs of small size and present numerical experiments in realistic scenarios. version:1
arxiv-1611-07343 | Limbo: A Fast and Flexible Library for Bayesian Optimization | http://arxiv.org/abs/1611.07343 | id:1611.07343 author:Antoine Cully, Konstantinos Chatzilygeroudis, Federico Allocati, Jean-Baptiste Mouret category:cs.LG cs.AI cs.RO stat.ML  published:2016-11-22 summary:Limbo is an open-source C++11 library for Bayesian optimization which is designed to be both highly flexible and very fast. It can be used to optimize functions for which the gradient is unknown, evaluations are expensive, and runtime cost matters (e.g., on embedded systems or robots). Benchmarks on standard functions show that Limbo is about 2 times faster than BayesOpt (another C++ library) for a similar accuracy. version:1
arxiv-1611-07289 | PVR: Patch-to-Volume Reconstruction for Large Area Motion Correction of Fetal MRI | http://arxiv.org/abs/1611.07289 | id:1611.07289 author:Amir Alansary, Bernhard Kainz, Martin Rajchl, Maria Murgasova, Mellisa Damodaram, David F. A. Lloyd, Alice Davidson, Steven G. McDonagh, Mary Rutherford, Joseph V. Hajnal, Daniel Rueckert category:cs.CV  published:2016-11-22 summary:In this paper we present a novel method for the correction of motion artifacts that are present in fetal Magnetic Resonance Imaging (MRI) scans of the whole uterus. Contrary to current slice-to-volume registration (SVR) methods, requiring an inflexible anatomical enclosure of a single investigated organ, the proposed patch-to-volume reconstruction (PVR) approach is able to reconstruct a large field of view of non-rigidly deforming structures. It relaxes rigid motion assumptions by introducing a specific amount of redundant information that is exploited with parallelized patch-wise optimization, super-resolution, and automatic outlier rejection. We further describe and provide an efficient parallel implementation of PVR allowing its execution within reasonable time on commercially available graphics processing units (GPU), enabling its use in the clinical practice. We evaluate PVR's computational overhead compared to standard methods and observe improved reconstruction accuracy in presence of affine motion artifacts of approximately 30% compared to conventional SVR in synthetic experiments. Furthermore, we have evaluated our method qualitatively and quantitatively on real fetal MRI data subject to maternal breathing and sudden fetal movements. We evaluate peak-signal-to-noise ratio (PSNR), structural similarity index (SSIM), and cross correlation (CC) with respect to the originally acquired data and provide a method for visual inspection of reconstruction uncertainty. With these experiments we demonstrate successful application of PVR motion compensation to the whole uterus, the human fetus, and the human placenta. version:1
arxiv-1611-07285 | Active learning with version spaces for object detection | http://arxiv.org/abs/1611.07285 | id:1611.07285 author:Soumya Roy, Vinay P. Namboodiri, Arijit Biswas category:cs.CV  published:2016-11-22 summary:Given an image, we would like to learn to detect objects belonging to particular object categories. Common object detection methods train on large annotated datasets which are annotated in terms of bounding boxes that contain the object of interest. Previous works on object detection model the problem as a structured regression problem which ranks the correct bounding boxes more than the background ones. In this paper we develop algorithms which actively obtain annotations from human annotators for a small set of images, instead of all images, thereby reducing the annotation effort. Towards this goal, we make the following contributions: 1. We develop a principled version space based active learning method that solves for object detection as a structured prediction problem in a weakly supervised setting 2. We derive the relation between our proposed method with other active learning techniques such as maximum model change 3. Additionally, we propose two variants of the margin-based querying strategy 4. We analyse the results on standard object detection benchmarks that show that with only 20% of the data we can obtain more than 95% of the localization accuracy of full supervision. Our methods outperform random sampling and the classical uncertainty-based active learning algorithms like entropy version:1
arxiv-1611-07270 | Investigating the influence of noise and distractors on the interpretation of neural networks | http://arxiv.org/abs/1611.07270 | id:1611.07270 author:Pieter-Jan Kindermans, Kristof Schütt, Klaus-Robert Müller, Sven Dähne category:stat.ML cs.LG  published:2016-11-22 summary:Understanding neural networks is becoming increasingly important. Over the last few years different types of visualisation and explanation methods have been proposed. However, none of them explicitly considered the behaviour in the presence of noise and distracting elements. In this work, we will show how noise and distracting dimensions can influence the result of an explanation model. This gives a new theoretical insights to aid selection of the most appropriate explanation model within the deep-Taylor decomposition framework. version:1
arxiv-1611-05244 | Deep Transfer Learning for Person Re-identification | http://arxiv.org/abs/1611.05244 | id:1611.05244 author:Mengyue Geng, Yaowei Wang, Tao Xiang, Yonghong Tian category:cs.CV  published:2016-11-16 summary:Person re-identification (Re-ID) poses a unique challenge to deep learning: how to learn a deep model with millions of parameters on a small training set of few or no labels. In this paper, a number of deep transfer learning models are proposed to address the data sparsity problem. First, a deep network architecture is designed which differs from existing deep Re-ID models in that (a) it is more suitable for transferring representations learned from large image classification datasets, and (b) classification loss and verification loss are combined, each of which adopts a different dropout strategy. Second, a two-stepped fine-tuning strategy is developed to transfer knowledge from auxiliary datasets. Third, given an unlabelled Re-ID dataset, a novel unsupervised deep transfer learning model is developed based on co-training. The proposed models outperform the state-of-the-art deep Re-ID models by large margins: we achieve Rank-1 accuracy of 85.4\%, 83.7\% and 56.3\% on CUHK03, Market1501, and VIPeR respectively, whilst on VIPeR, our unsupervised model (45.1\%) beats most supervised models. version:2
arxiv-1611-07256 | Adaptive Design of Experiments for Conservative Estimation of Excursion Sets | http://arxiv.org/abs/1611.07256 | id:1611.07256 author:Dario Azzimonti, David Ginsbourger, Clément Chevalier, Julien Bect, Yann Richet category:stat.ME math.ST stat.ML stat.TH  published:2016-11-22 summary:We consider a Gaussian process model trained on few evaluations of an expensive-to-evaluate deterministic function and we study the problem of estimating a fixed excursion set of this function. We review the concept of conservative estimates, recently introduced in this framework, and, in particular, we focus on estimates based on Vorob'ev quantiles. We present a method that sequentially selects new evaluations of the function in order to reduce the uncertainty on such estimates. The sequential strategies are first benchmarked on artificial test cases generated from Gaussian process realizations in two and five dimensions, and then applied to two reliability engineering test cases. version:1
arxiv-1611-07252 | Interpretable Recurrent Neural Networks Using Sequential Sparse Recovery | http://arxiv.org/abs/1611.07252 | id:1611.07252 author:Scott Wisdom, Thomas Powers, James Pitton, Les Atlas category:stat.ML cs.LG  published:2016-11-22 summary:Recurrent neural networks (RNNs) are powerful and effective for processing sequential data. However, RNNs are usually considered "black box" models whose internal structure and learned parameters are not interpretable. In this paper, we propose an interpretable RNN based on the sequential iterative soft-thresholding algorithm (SISTA) for solving the sequential sparse recovery problem, which models a sequence of correlated observations with a sequence of sparse latent vectors. The architecture of the resulting SISTA-RNN is implicitly defined by the computational structure of SISTA, which results in a novel stacked RNN architecture. Furthermore, the weights of the SISTA-RNN are perfectly interpretable as the parameters of a principled statistical model, which in this case include a sparsifying dictionary, iterative step size, and regularization parameters. In addition, on a particular sequential compressive sensing task, the SISTA-RNN trains faster and achieves better performance than conventional state-of-the-art black box RNNs, including long-short term memory (LSTM) RNNs. version:1
arxiv-1611-07245 | Deep Single and Direct Multi-View Depth Fusion | http://arxiv.org/abs/1611.07245 | id:1611.07245 author:José M. Fácil, Alejo Concha, Luis Montesano, Javier Civera category:cs.CV cs.RO  published:2016-11-22 summary:Dense 3D mapping from a monocular sequence is a key technology for several applications and still a research problem. This paper leverages recent results on single-view CNN-based depth estimation and fuses them with direct multi-view depth estimation. Both approaches present complementary strengths. Multi-view depth estimation is highly accurate but only in high-texture and high-parallax cases. Single-view depth captures the local structure of mid-level regions, including textureless areas, but the estimated depth lacks global coherence. The single and multi-view fusion we propose has several challenges. First, both depths are related by a non-rigid deformation that depends on the image content. And second, the selection of multi-view points of high accuracy might be difficult for low-parallax configurations. We present contributions for both problems. Our results in the public datasets of NYU and TUM shows that our algorithm outperforms the individual single and multi-view approaches. version:1
arxiv-1611-05724 | Unimodal Thompson Sampling for Graph-Structured Arms | http://arxiv.org/abs/1611.05724 | id:1611.05724 author:Stefano Paladino, Francesco Trovò, Marcello Restelli, Nicola Gatti category:cs.LG stat.ML  published:2016-11-17 summary:We study, to the best of our knowledge, the first Bayesian algorithm for unimodal Multi-Armed Bandit (MAB) problems with graph structure. In this setting, each arm corresponds to a node of a graph and each edge provides a relationship, unknown to the learner, between two nodes in terms of expected reward. Furthermore, for any node of the graph there is a path leading to the unique node providing the maximum expected reward, along which the expected reward is monotonically increasing. Previous results on this setting describe the behavior of frequentist MAB algorithms. In our paper, we design a Thompson Sampling-based algorithm whose asymptotic pseudo-regret matches the lower bound for the considered setting. We show that -as it happens in a wide number of scenarios- Bayesian MAB algorithms dramatically outperform frequentist ones. In particular, we provide a thorough experimental evaluation of the performance of our and state-of-the-art algorithms as the properties of the graph vary. version:2
arxiv-1611-07233 | CAS-CNN: A Deep Convolutional Neural Network for Image Compression Artifact Suppression | http://arxiv.org/abs/1611.07233 | id:1611.07233 author:Lukas Cavigelli, Pascal Hager, Luca Benini category:cs.CV cs.AI cs.GR cs.IR cs.MM  published:2016-11-22 summary:Lossy image compression algorithms are pervasively used to reduce the size of images transmitted over the web and recorded on data storage media. However, we pay for their high compression rate with visual artifacts degrading the user experience. Deep convolutional neural networks have become a widespread tool to address high-level computer vision tasks very successfully. Recently, they have found their way into the areas of low-level computer vision and image processing to solve regression problems mostly with relatively shallow networks. We present a novel 12-layer deep convolutional network for image compression artifact suppression with hierarchical skip connections and a multi-scale loss function. We achieve a boost of up to 1.79 dB in PSNR over ordinary JPEG and an improvement of up to 0.36 dB over the best previous ConvNet result. We show that a network trained for a specific quality factor (QF) is resilient to the QF used to compress the input image - a single network trained for QF 60 provides a PSNR gain of more than 1.5 dB over the wide QF range from 40 to 76. version:1
arxiv-1611-07232 | Compositional Learning of Relation Paths Embedding for Knowledge Base Completion | http://arxiv.org/abs/1611.07232 | id:1611.07232 author:Xixun Lin, Yanchun Liang, Renchu Guan category:cs.CL  published:2016-11-22 summary:Nowadays, large-scale knowledge bases containing billions of facts have reached impressive sizes; however, they are still far from completion. In addition, most existing methods only consider the direct links between entities, ignoring the vital impact about the semantic of relation paths. In this paper, we study the problem of how to better embed entities and relations into different low dimensional spaces. A compositional learning model of relation paths embedding (RPE) is proposed to take full advantage of additional semantic information expressed by relation paths. More specifically, using corresponding projection matrices, RPE can simultaneously embed entities into corresponding relation and path spaces. It is also suggested that type constraints could be extended from traditional relation-specific to the new proposed path-specific ones. Both of the two type constraints can be seamlessly incorporated into RPE and decrease the errors in prediction. Experiments are conducted on the benchmark datasets and the proposed model achieves significant and consistent improvements compared with the state-of-the-art algorithms for knowledge base completion. version:1
arxiv-1611-07231 | A Spatial and Temporal Non-Local Filter Based Data Fusion | http://arxiv.org/abs/1611.07231 | id:1611.07231 author:Qing Cheng, Huiqing Liu, Huanfeng Shen, Penghai Wu, Liangpei Zhang category:cs.CV  published:2016-11-22 summary:The trade-off in remote sensing instruments that balances the spatial resolution and temporal frequency limits our capacity to monitor spatial and temporal dynamics effectively. The spatiotemporal data fusion technique is considered as a cost-effective way to obtain remote sensing data with both high spatial resolution and high temporal frequency, by blending observations from multiple sensors with different advantages or characteristics. In this paper, we develop the spatial and temporal non-local filter based fusion model (STNLFFM) to enhance the prediction capacity and accuracy, especially for complex changed landscapes. The STNLFFM method provides a new transformation relationship between the fine-resolution reflectance images acquired from the same sensor at different dates with the help of coarse-resolution reflectance data, and makes full use of the high degree of spatiotemporal redundancy in the remote sensing image sequence to produce the final prediction. The proposed method was tested over both the Coleambally Irrigation Area study site and the Lower Gwydir Catchment study site. The results show that the proposed method can provide a more accurate and robust prediction, especially for heterogeneous landscapes and temporally dynamic areas. version:1
arxiv-1611-07218 | Object detection can be improved using human-derived contextual expectations | http://arxiv.org/abs/1611.07218 | id:1611.07218 author:Harish Katti, Marius V. Peelen, S. P. Arun category:cs.CV q-bio.NC  published:2016-11-22 summary:Each object in the world occurs in a specific context: cars are seen on highways but not in forests. Contextual information is generally thought to facilitate computation by constraining locations to search. But can knowing context yield tangible benefits in object detection? For it to do so, scene context needs to be learned independently from target features. However this is impossible in traditional object detection where classifiers are trained on images containing both target features and surrounding coarse scene features. In contrast, we humans have the opportunity to learn context and target features separately, such as when we see highways without cars. Here we show for the first time that human-derived scene expectations can be used to improve object detection performance in machines. To measure these expectations, we asked human subjects to indicate the scale, location and likelihood at which targets may occur on scenes containing no targets. Humans showed highly systematic expectations that we could accurately predict using scene features. We then augmented state-of-the-art object detectors (based on deep neural networks) with these human-derived expectations on novel scenes to produce a significant (1-3%) improvement in detecting cars and people in scenes. This improvement was due to low-confidence detector matches being correctly relabeled as targets when they occurred in likely scenes. version:1
arxiv-1611-07212 | Recurrent Attention Models for Depth-Based Person Identification | http://arxiv.org/abs/1611.07212 | id:1611.07212 author:Albert Haque, Alexandre Alahi, Li Fei-Fei category:cs.CV  published:2016-11-22 summary:We present an attention-based model that reasons on human body shape and motion dynamics to identify individuals in the absence of RGB information, hence in the dark. Our approach leverages unique 4D spatio-temporal signatures to address the identification problem across days. Formulated as a reinforcement learning task, our model is based on a combination of convolutional and recurrent neural networks with the goal of identifying small, discriminative regions indicative of human identity. We demonstrate that our model produces state-of-the-art results on several published datasets given only depth images. We further study the robustness of our model towards viewpoint, appearance, and volumetric changes. Finally, we share insights gleaned from interpretable 2D, 3D, and 4D visualizations of our model's spatio-temporal attention. version:1
arxiv-1611-07206 | Learning to Distill: The Essence Vector Modeling Framework | http://arxiv.org/abs/1611.07206 | id:1611.07206 author:Kuan-Yu Chen, Shih-Hung Liu, Berlin Chen, Hsin-Min Wang category:cs.CL  published:2016-11-22 summary:In the context of natural language processing, representation learning has emerged as a newly active research subject because of its excellent performance in many applications. Learning representations of words is a pioneering study in this school of research. However, paragraph (or sentence and document) embedding learning is more suitable/reasonable for some tasks, such as sentiment classification and document summarization. Nevertheless, as far as we are aware, there is relatively less work focusing on the development of unsupervised paragraph embedding methods. Classic paragraph embedding methods infer the representation of a given paragraph by considering all of the words occurring in the paragraph. Consequently, those stop or function words that occur frequently may mislead the embedding learning process to produce a misty paragraph representation. Motivated by these observations, our major contributions in this paper are twofold. First, we propose a novel unsupervised paragraph embedding method, named the essence vector (EV) model, which aims at not only distilling the most representative information from a paragraph but also excluding the general background information to produce a more informative low-dimensional vector representation for the paragraph. Second, in view of the increasing importance of spoken content processing, an extension of the EV model, named the denoising essence vector (D-EV) model, is proposed. The D-EV model not only inherits the advantages of the EV model but also can infer a more robust representation for a given spoken paragraph against imperfect speech recognition. version:1
arxiv-1611-07191 | Distributable Consistent Multi-Graph Matching | http://arxiv.org/abs/1611.07191 | id:1611.07191 author:Nan Hu, Boris Thibert, Leonidas Guibas category:cs.DS cs.CV  published:2016-11-22 summary:In this paper we propose an optimization-based framework to multiple graph matching. The framework takes as input maps computed between pairs of graphs, and outputs maps that 1) are consistent among all pairs of graphs, and 2) preserve edge connectivity between pairs of graphs. We show how to formulate this as solving a piece-wise low-rank matrix recovery problem using a generalized message passing scheme. We also present necessary and sufficient conditions under which such global consistency is guaranteed. The key feature of our approach is that it is scalable to large datasets, while still produce maps whose quality is competent against state-of-the-art global optimization-based techniques. version:1
arxiv-1611-07174 | An Experimental Comparison of Deep Neural Networks for End-to-end Speech Recognition | http://arxiv.org/abs/1611.07174 | id:1611.07174 author:Zewang Zhang, Zheng Sun, Jiaqi Liu, Jingwen Chen, Zhao Huo, Xiao Zhang category:cs.CL cs.LG  published:2016-11-22 summary:Performance of end-to-end automatic speech recognition (ASR) systems can significantly be improved by the increasing large speech corpus and deeper neural network. Given the arising problem of training speed and recent success of deep convolutional neural network in ASR, we build a novel deep recurrent convolutional network for acoustic modeling and apply deep residual learning framework to it, our experiments show that it has not only faster convergence speed but better recognition accuracy over traditional deep convolutional recurrent network. We mainly compare convergence speed of two acoustic models, which are novel deep recurrent convolutional networks and traditional deep convolutional recurrent networks. With faster convergence speed, our novel deep recurrent convolutional networks can reach the comparable performance. We further show that applying deep residual learning can boost both convergence speed and recognition accuracy of our novel recurret convolutional networks. Finally, we evaluate all our experimental networks by phoneme error rate (PER) with newly proposed bidirectional statistical language model. Our evaluation results show that our model applied with deep residual learning can reach the best PER of 17.33% with fastest convergence speed in TIMIT database. version:1
arxiv-1611-07161 | Optimal Learning for Stochastic Optimization with Nonlinear Parametric Belief Models | http://arxiv.org/abs/1611.07161 | id:1611.07161 author:Xinyu He, Warren B. Powell category:stat.ML  published:2016-11-22 summary:We consider the problem of estimating the expected value of information (the knowledge gradient) for Bayesian learning problems where the belief model is nonlinear in the parameters. Our goal is to maximize some metric, while simultaneously learning the unknown parameters of the nonlinear belief model, by guiding a sequential experimentation process which is expensive. We overcome the problem of computing the expected value of an experiment, which is computationally intractable, by using a sampled approximation, which helps to guide experiments but does not provide an accurate estimate of the unknown parameters. We then introduce a resampling process which allows the sampled model to adapt to new information, exploiting past experiments. We show theoretically that the method converges asymptotically to the true parameters, while simultaneously maximizing our metric. We show empirically that the process exhibits rapid convergence, yielding good results with a very small number of experiments. version:1
arxiv-1611-07156 | Exploiting Web Images for Dataset Construction: A Domain Robust Approach | http://arxiv.org/abs/1611.07156 | id:1611.07156 author:Yazhou Yao, Jian Zhang, Fumin Shen, Xiansheng Hua, Jingsong Xu, Zhenmin Tang category:cs.CV cs.MM  published:2016-11-22 summary:Labelled image datasets have played a critical role in high-level image understanding; however the process of manual labelling is both time-consuming and labor intensive. To reduce the cost of manual labelling, there has been increased research interest in automatically constructing image datasets by exploiting web images. Datasets constructed by existing methods tend to have a weak domain adaptation ability, which is known as the "dataset bias problem". To address this issue, we present a novel image dataset construction framework which can be generalized well to unseen target domains. In specific, the given queries are first expanded by searching in the Google Books Ngrams Corpus to obtain a richer semantic description, from which the visually non-salient and less relevant expansions are filtered out. By treating each unfiltered expansion as a "bag" and the retrieved images as "instances", image selection can be formulated as a multi-instance learning problem with constrained positive bags. We propose to solve the employed problems by the cutting-plane and concave-convex procedure (CCCP) algorithm. Using this approach, images from different distributions will be retained while noisy images will be filtered out. To verify the effectiveness of our proposed approach, we build a domain-robust image dataset with 20 categories, which we refer to as DRID-20. We compare DRID-20 with three publicly available datasets STL-10, CIFAR-10 and ImageNet. The experimental results confirm the effectiveness of our dataset in terms of image classification ability, cross-dataset generalization ability and dataset diversity. We further run object detection on PASCAL VOC 2007 using our data, and the results demonstrate the superiority of our method to the weakly supervised and web-supervised state-of-the-art detection methods. version:1
arxiv-1611-06612 | RefineNet: Multi-Path Refinement Networks with Identity Mappings for High-Resolution Semantic Segmentation | http://arxiv.org/abs/1611.06612 | id:1611.06612 author:Guosheng Lin, Anton Milan, Chunhua Shen, Ian Reid category:cs.CV  published:2016-11-20 summary:Recently, very deep convolutional neural networks (CNNs) have shown outstanding performance in object recognition and have also been the first choice for dense classification problems such as semantic segmentation. However, repeated subsampling operations like pooling or convolution striding in deep CNNs lead to a significant decrease in the initial image resolution. Here, we present RefineNet, a generic multi-path refinement network that explicitly exploits all the information available along the down-sampling process to enable high-resolution prediction using long-range residual connections. In this way, the deeper layers that capture high-level semantic features can be directly refined using fine-grained features from earlier convolutions. The individual components of RefineNet employ residual connections following the identity mapping mindset, which allows for effective end-to-end training. Further, we introduce chained residual pooling, which captures rich background context in an efficient manner. We carry out comprehensive experiments and set new state-of-the-art results on seven public datasets. In particular, we achieve an intersection-over-union score of 83.4 on the challenging PASCAL VOC 2012 dataset, which is the best reported result to date. version:2
arxiv-1611-07151 | Fast and Energy-Efficient CNN Inference on IoT Devices | http://arxiv.org/abs/1611.07151 | id:1611.07151 author:Mohammad Motamedi, Daniel Fong, Soheil Ghiasi category:cs.DC cs.LG  published:2016-11-22 summary:Convolutional Neural Networks (CNNs) exhibit remarkable performance in various machine learning tasks. As sensor-equipped internet of things (IoT) devices permeate into every aspect of modern life, it is increasingly important to run CNN inference, a computationally intensive application, on resource constrained devices. We present a technique for fast and energy-efficient CNN inference on mobile SoC platforms, which are projected to be a major player in the IoT space. We propose techniques for efficient parallelization of CNN inference targeting mobile GPUs, and explore the underlying tradeoffs. Experiments with running Squeezenet on three different mobile devices confirm the effectiveness of our approach. For further study, please refer to the project repository available on our GitHub page: https://github.com/mtmd/Mobile_ConvNet version:1
arxiv-1611-07145 | Learning Multi-level Deep Representations for Image Emotion Classification | http://arxiv.org/abs/1611.07145 | id:1611.07145 author:Tianrong Rao, Min Xu, Dong Xu category:cs.CV  published:2016-11-22 summary:In this paper, we propose a new deep network that learns multi-level deep representations for image emotion classification (MldrNet). Image emotion can be recognized through image semantics, image aesthetics and low-level visual features from both global and local views. Existing image emotion classification works using hand-crafted features or deep features mainly focus on either low-level visual features or semantic-level image representations without taking all factors into consideration. Our proposed MldrNet unifies deep representations of three levels, i.e. image semantics, image aesthetics and low-level visual features through multiple instance learning (MIL) in order to effectively cope with noisy labeled data, such as images collected from the Internet. Extensive experiments on both Internet images and abstract paintings demonstrate the proposed method outperforms the state-of-the-art methods using deep features or hand-crafted features. The proposed approach also outperforms the state-of-the-art methods with at least 6% performance improvement in terms of overall classification accuracy. version:1
arxiv-1611-07143 | Learning Multi-level Features For Sensor-based Human Action Recognition | http://arxiv.org/abs/1611.07143 | id:1611.07143 author:Yan Xu, Zhengyang Shen, Xin Zhang, Yifan Gao, Shujian Deng, Yipei Wang, Yubo Fan, Eric I-Chao Chang category:cs.CV I.5.2  published:2016-11-22 summary:This paper proposes a multi-level feature learning framework for human action recognition using body-worn inertial sensors. The framework consists of three phases, respectively designed to analyze signal-based (low-level), components (mid-level) and semantic (high-level) information. Low-level features, extracted from raw signals, capture the time and frequency domain property while mid-level representations, obtained through the dictionary learning method, learn the composition of the action. The Max-margin Latent Pattern Learning (MLPL) method is proposed and implemented on the concatenation of low- and mid-level features to learn high-level semantic descriptions of latent action patterns as the output of our framework. Various experiments on Opp, Skoda and WISDM datasets show that the semantic feature learned by this framework possesses higher representation ability than low- and mid-level features. Compared with existing methods, the proposed method achieves state-of-the-art performances. version:1
arxiv-1611-07139 | A Natural Language Query Interface for Searching Personal Information on Smartwatches | http://arxiv.org/abs/1611.07139 | id:1611.07139 author:Reza Rawassizadeh, Chelsea Dobbins, Manouchehr Nourizadeh, Zahra Ghamchili, Michael Pazzani category:cs.HC cs.CL cs.IR  published:2016-11-22 summary:Currently, personal assistant systems, run on smartphones and use natural language interfaces. However, these systems rely mostly on the web for finding information. Mobile and wearable devices can collect an enormous amount of contextual personal data such as sleep and physical activities. These information objects and their applications are known as quantified-self, mobile health or personal informatics, and they can be used to provide a deeper insight into our behavior. To our knowledge, existing personal assistant systems do not support all types of quantified-self queries. In response to this, we have undertaken a user study to analyze a set of "textual questions/queries" that users have used to search their quantified-self or mobile health data. Through analyzing these questions, we have constructed a light-weight natural language based query interface, including a text parser algorithm and a user interface, to process the users' queries that have been used for searching quantified-self information. This query interface has been designed to operate on small devices, i.e. smartwatches, as well as augmenting the personal assistant systems by allowing them to process end users' natural language queries about their quantified-self data. version:1
arxiv-1611-07138 | A new approach to Laplacian solvers and flow problems | http://arxiv.org/abs/1611.07138 | id:1611.07138 author:Patrick Rebeschini, Sekhar Tatikonda category:math.OC cs.DS stat.ML  published:2016-11-22 summary:This paper investigates message-passing algorithms for solving systems of linear equations in the Laplacian matrices of graphs and to compute electric flows. These two problems are fundamental primitives that arise in several domains such as computer science, electrical engineering, operations research, and machine learning. Despite the extensive literature on approximately solving these problems in quasi-linear time, the algorithms that have been proposed are typically centralized and involve multiple graph theoretic constructions or sampling mechanisms that make them difficult to implement and analyze. On the other hand, message-passing routines are distributed, simple, and easy to implement. In this paper we establish a framework to analyze message-passing algorithms to solve voltage and flow problems. We characterize the error committed by the algorithms in d-regular graphs with equal weights. We show that the convergence of the algorithms is controlled by the total variation distance between the distributions of non-backtracking random walks that start from neighbor nodes. More broadly, our analysis of message-passing introduces new insights to address generic optimization problems with constraints. version:1
arxiv-1611-07136 | Cascaded Neural Networks with Selective Classifiers and its evaluation using Lung X-ray CT Images | http://arxiv.org/abs/1611.07136 | id:1611.07136 author:Masaharu Sakamoto, Hiroki Nakano category:cs.CV  published:2016-11-22 summary:Lung nodule detection is a class imbalanced problem because nodules are found with much lower frequency than non-nodules. In the class imbalanced problem, conventional classifiers tend to be overwhelmed by the majority class and ignore the minority class. We therefore propose cascaded convolutional neural networks to cope with the class imbalanced problem. In the proposed approach, cascaded convolutional neural networks that perform as selective classifiers filter out obvious non-nodules. Successively, a convolutional neural network trained with a balanced data set calculates nodule probabilities. The proposed method achieved the detection sensitivity of 85.3% and 90.7% at 1 and 4 false positives per scan in FROC curve, respectively. version:1
arxiv-1611-06596 | Object Recognition with and without Objects | http://arxiv.org/abs/1611.06596 | id:1611.06596 author:Zhuotun Zhu, Lingxi Xie, Alan L. Yuille category:cs.CV  published:2016-11-20 summary:While recent deep neural network models have given promising performance on object recognition, they rely implicitly on the visual contents of the whole image. In this paper, we train deep neural networks on the foreground (object) and background (context) regions of images respectively. Considering human recognition in the same situations, networks trained on pure background without objects achieves highly reasonable recognition performance that beats humans to a large margin if only given context. However, humans still outperform networks with pure object available, which indicates networks and human beings have different mechanisms in understanding an image. Furthermore, we straightforwardly combine multiple trained networks to explore the different visual clues learned by different networks. Experiments show that useful visual hints can be learned separately and then combined to achieve higher performance, which confirms the advantages of the proposed framework. version:2
arxiv-1611-06455 | Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline | http://arxiv.org/abs/1611.06455 | id:1611.06455 author:Zhiguang Wang, Weizhong Yan, Tim Oates category:cs.LG cs.NE stat.ML  published:2016-11-20 summary:We propose a simple but strong baseline for time series classification from scratch with deep neural networks. Our proposed baseline models are pure end-to-end without any heavy preprocessing on the raw data or feature crafting. The FCN achieves premium performance to other state-of-the-art approaches. Our exploration of the very deep neural networks with the ResNet structure achieves competitive performance under the same simple experiment settings. The simple MLP baseline is also comparable to the 1NN-DTW as a previous golden baseline. Our models provides a simple choice for the real world application and a good starting point for the future research. An overall analysis is provided to discuss the generalization of our models, learned features, network structures and the classification semantics. version:2
arxiv-1611-06448 | PsyPhy: A Psychophysics Driven Evaluation Framework for Visual Recognition | http://arxiv.org/abs/1611.06448 | id:1611.06448 author:Brandon RichardWebster, Samuel E. Anthony, Walter J. Scheirer category:cs.CV  published:2016-11-19 summary:By providing substantial amounts of data and standardized evaluation protocols, datasets in computer vision have helped fuel advances across all areas of visual recognition. But even in light of breakthrough results on recent benchmarks, it is still fair to ask if our recognition algorithms are doing as well as we think they are. The vision sciences at large make use of a very different evaluation regime known as Visual Psychophysics to study visual perception. Psychophysics is the quantitative examination of the relationships between controlled stimuli and the behavioral responses they elicit in experimental test subjects. Instead of using summary statistics to gauge performance, psychophysics directs us to construct item-response curves made up of individual stimulus responses to find perceptual thresholds, thus allowing one to identify the exact point at which a subject can no longer reliably recognize the stimulus class. In this paper, we introduce a comprehensive evaluation framework for visual recognition models that is underpinned by this methodology. Over millions of procedurally rendered 3D scenes and 2D images, we compare the performance of well-known convolutional neural networks. Our results bring into question recent claims of human-like performance, and provide a path forward for correcting newly surfaced algorithmic deficiencies. version:2
arxiv-1611-07119 | Max-Margin Deep Generative Models for (Semi-)Supervised Learning | http://arxiv.org/abs/1611.07119 | id:1611.07119 author:Chongxuan Li, Jun Zhu, Bo Zhang category:cs.CV cs.LG stat.ML  published:2016-11-22 summary:Deep generative models (DGMs) are effective on learning multilayered representations of complex data and performing inference of input data by exploring the generative ability. However, it is relatively insufficient to empower the discriminative ability of DGMs on making accurate predictions. This paper presents max-margin deep generative models (mmDGMs) and a class-conditional variant (mmDCGMs), which explore the strongly discriminative principle of max-margin learning to improve the predictive performance of DGMs in both supervised and semi-supervised learning, while retaining the generative capability. In semi-supervised learning, we use the predictions of a max-margin classifier as the missing labels instead of performing full posterior inference for efficiency; we also introduce additional max-margin and label-balance regularization terms of unlabeled data for effectiveness. We develop an efficient doubly stochastic subgradient algorithm for the piecewise linear objectives in different settings. Empirical results on various datasets demonstrate that: (1) max-margin learning can significantly improve the prediction performance of DGMs and meanwhile retain the generative ability; (2) in supervised learning, mmDGMs are competitive to the best fully discriminative networks when employing convolutional neural networks as the generative and recognition models; and (3) in semi-supervised learning, mmDCGMs can perform efficient inference and achieve state-of-the-art classification results on several benchmarks. version:1
arxiv-1611-07115 | Tree Space Prototypes: Another Look at Making Tree Ensembles Interpretable | http://arxiv.org/abs/1611.07115 | id:1611.07115 author:Hui Fen Tan, Giles Hooker, Martin T. Wells category:stat.ML cs.LG  published:2016-11-22 summary:Ensembles of decision trees have good prediction accuracy but suffer from a lack of interpretability. We propose a new approach for interpreting tree ensembles by finding prototypes in tree space, utilizing the naturally-learned similarity measure from the tree ensemble. Demonstrating the method on random forests, we show that the method benefits from unique aspects of tree ensembles by leveraging tree structure to sequentially find prototypes. The method provides good prediction accuracy when found prototypes are used in nearest-prototype classifiers, while using fewer prototypes than competitor methods. We are investigating the sensitivity of the method to different prototype-finding procedures and demonstrating it on higher-dimensional data. version:1
arxiv-1611-07103 | Generation of discrete random variables in scalable framework | http://arxiv.org/abs/1611.07103 | id:1611.07103 author:Giacomo Aletti category:stat.ME math.ST stat.ML stat.TH  published:2016-11-21 summary:In this paper, we face the problem of simulating discrete random variables with general and varying distribution in a scalable framework, where fully parallelizable operations should be preferred. Compared with classical algorithms, we add randomness, that will be analyzed with a fully parallelizable operation, and we leave the final simulation of the random variable to a single associative operator. We characterize the set of algorithms that work in this way, and some classes of them related to an additive or multiplicative local noise. As a consequence, we could define a natural way to solve some popular simulation problems. version:1
arxiv-1611-07100 | Interpreting Finite Automata for Sequential Data | http://arxiv.org/abs/1611.07100 | id:1611.07100 author:Christian Albert Hammerschmidt, Qin Lin, Sicco Verwer, Radu State category:stat.ML cs.AI I.2.6  published:2016-11-21 summary:Automaton models are often seen as interpretable models. Interpretability itself is not well defined: it remains unclear what interpretability means without first explicitly specifying objectives or desired attributes. In this paper, we identify the key properties used to interpret automata and propose a modification of a state-merging approach to learn variants of finite state automata. We apply the approach to problems beyond typical grammar inference tasks. Additionally, we cover several use-cases for prediction, classification, and clustering on sequential data in both supervised and unsupervised scenarios to show how the identified key properties are applicable in a wide range of contexts. version:1
arxiv-1611-07098 | Risk-Sensitive Learning and Pricing for Demand Response | http://arxiv.org/abs/1611.07098 | id:1611.07098 author:Kia Khezeli, Eilyan Bitar category:cs.LG math.OC  published:2016-11-21 summary:We consider the setting in which an electric power utility seeks to curtail its peak electricity demand by offering a fixed group of customers a uniform price for reductions in consumption relative to their predetermined baselines. The underlying demand curve, which describes the aggregate reduction in consumption in response to the offered price, is assumed to be affine and subject to unobservable random shocks. Assuming that both the parameters of the demand curve and the distribution of the random shocks are initially unknown to the utility, we investigate the extent to which the utility might dynamically adjust its offered prices to maximize its cumulative risk-sensitive payoff over a finite number of $T$ days. In order to do so effectively, the utility must design its pricing policy to balance the tradeoff between the need to learn the unknown demand model (exploration) and maximize its payoff (exploitation) over time. In this paper, we propose such a pricing policy, which is shown to exhibit an expected payoff loss over $T$ days that is at most $O(\sqrt{T})$, relative to an oracle pricing policy that knows the underlying demand model. Moreover, the proposed pricing policy is shown to yield a sequence of prices that converge to the oracle optimal prices in the mean square sense. version:1
arxiv-1611-07096 | Structured Prediction by Least Squares Estimated Conditional Risk Minimization | http://arxiv.org/abs/1611.07096 | id:1611.07096 author:Chong Yang Goh, Patrick Jaillet category:stat.ML cs.LG  published:2016-11-21 summary:We propose a general approach for supervised learning with structured output spaces, such as combinatorial and polyhedral sets, that is based on minimizing estimated conditional risk functions. Given a loss function defined over pairs of output labels, we first estimate the conditional risk function by solving a (possibly infinite) collection of regularized least squares problems. A prediction is made by solving an auxiliary optimization problem that minimizes the estimated conditional risk function over the output space. We apply this method to a class of problems with discrete combinatorial outputs and additive pairwise losses, and show that the auxiliary problem can be solved efficiently by exact linear programming relaxations in several important cases, including variants of hierarchical multilabel classification and multilabel ranking problems. We demonstrate how the same approach can also be extended to vector regression problems with convex constraints and losses. Evaluations of this approach on hierarchical multilabel classification show that it compares favorably with several existing methods in terms of predictive accuracy, and has computational advantages over them when applied to large hierarchies. version:1
arxiv-1611-07093 | Using Empirical Covariance Matrix in Enhancing Prediction Accuracy of Linear Models with Missing Information | http://arxiv.org/abs/1611.07093 | id:1611.07093 author:Ahmadreza Moradipari, Ashkan Esmaeili, Sina Shahsavari, Farokh Marvasti category:stat.ML stat.ME  published:2016-11-21 summary:Inference and Estimation in Missing Information (MI) scenarios is an important topic in Statistical Learning Theory and Machine Learning (ML). In ML literature, attempts have been carried out to enhance prediction through precise feature selection methods. In sparse linear models, Lasso is well- known in extracting the desired support of the signal and resisting against noisy systems. When sparse models are also suffering from MI, the sparse recovery and inference of the missing models are taken into account simultaneously. In this paper, we will introduce an approach which enjoys sparse regression and covariance matrix estimation in improving matrix completion accuracy, and as a result enhancing feature selection preciseness which leads to reduction in prediction Mean Squared Error (MSE). We will compare the effect of employing covariance matrix in enhancing estimation accuracy to the case it is not used in feature selection. Simulations will show the improvement in the performance as compared to the case we do not use the covariance matrix estimation. version:1
arxiv-1611-07078 | A Deep Learning Approach for Joint Video Frame and Reward Prediction in Atari Games | http://arxiv.org/abs/1611.07078 | id:1611.07078 author:Felix Leibfried, Nate Kushman, Katja Hofmann category:cs.AI cs.LG stat.ML  published:2016-11-21 summary:Reinforcement learning is concerned with learning to interact with environments that are initially unknown. State-of-the-art reinforcement learning approaches, such as DQN, are model-free and learn to act effectively across a wide range of environments such as Atari games, but require huge amounts of data. Model-based techniques are more data-efficient, but need to acquire explicit knowledge about the environment dynamics or the reward structure. In this paper we take a step towards using model-based techniques in environments with high-dimensional visual state space when system dynamics and the reward structure are both unknown and need to be learned, by demonstrating that it is possible to learn both jointly. Empirical evaluation on five Atari games demonstrate accurate cumulative reward prediction of up to 200 frames. We consider these positive results as opening up important directions for model-based RL in complex, initially unknown environments. version:1
arxiv-1611-05435 | Convolutional Gated Recurrent Networks for Video Segmentation | http://arxiv.org/abs/1611.05435 | id:1611.05435 author:Mennatullah Siam, Sepehr Valipour, Martin Jagersand, Nilanjan Ray category:cs.CV  published:2016-11-16 summary:Semantic segmentation has recently witnessed major progress, where fully convolutional neural networks have shown to perform well. However, most of the previous work focused on improving single image segmentation. To our knowledge, no prior work has made use of temporal video information in a recurrent network. In this paper, we introduce a novel approach to implicitly utilize temporal data in videos for online semantic segmentation. The method relies on a fully convolutional network that is embedded into a gated recurrent architecture. This design receives a sequence of consecutive video frames and outputs the segmentation of the last frame. Convolutional gated recurrent networks are used for the recurrent part to preserve spatial connectivities in the image. Our proposed method can be applied in both online and batch segmentation. This architecture is tested for both binary and semantic video segmentation tasks. Experiments are conducted on the recent benchmarks in SegTrack V2, Davis, CityScapes, and Synthia. Using recurrent fully convolutional networks improved the baseline network performance in all of our experiments. Namely, 5% and 3% improvement of F-measure in SegTrack2 and Davis respectively, 5.7% improvement in mean IoU in Synthia and 3.5% improvement in categorical mean IoU in CityScapes. The performance of the RFCN network depends on its baseline fully convolutional network. Thus RFCN architecture can be seen as a method to improve its baseline segmentation network by exploiting spatiotemporal information in videos. version:2
arxiv-1611-07065 | Recurrent Neural Networks With Limited Numerical Precision | http://arxiv.org/abs/1611.07065 | id:1611.07065 author:Joachim Ott, Zhouhan Lin, Ying Zhang, Shih-Chii Liu, Yoshua Bengio category:cs.NE  published:2016-11-21 summary:Recurrent Neural Networks (RNNs) produce state-of-art performance on many machine learning tasks but their demand on resources in terms of memory and computational power are often high. Therefore, there is a great interest in optimizing the computations performed with these models especially when considering development of specialized low-power hardware for deep networks. One way of reducing the computational needs is to limit the numerical precision of the network weights and biases, and this will be addressed for the case of RNNs. We present results from the use of different stochastic and deterministic reduced precision training methods applied to two major RNN types, which are then tested on three datasets. The results show that the stochastic and deterministic ternarization, pow2- ternarization, and exponential quantization methods gave rise to low-precision RNNs that produce similar and even higher accuracy on certain datasets, therefore providing a path towards training more efficient implementations of RNNs in specialized hardware. version:1
arxiv-1611-07056 | The Recycling Gibbs Sampler for Efficient Learning | http://arxiv.org/abs/1611.07056 | id:1611.07056 author:Luca Martino, Victor Elvira, Gustau Camps-Valls category:stat.CO cs.LG stat.ML  published:2016-11-21 summary:Monte Carlo methods are essential tools for Bayesian inference. Gibbs sampling is a well-known Markov chain Monte Carlo (MCMC) algorithm, extensively used in signal processing, machine learning, and statistics, employed to draw samples from complicated high-dimensional posterior distributions. The key point for the successful application of the Gibbs sampler is the ability to draw efficiently samples from the full-conditional probability density functions. Since in the general case this is not possible, in order to speed up the convergence of the chain, it is required to generate auxiliary samples whose information is eventually disregarded. In this work, we show that these auxiliary samples can be recycled within the Gibbs estimators, improving their efficiency with no extra cost. This novel scheme arises naturally after pointing out the relationship between the standard Gibbs sampler and the chain rule used for sampling purposes. Numerical simulations involving simple and real inference problems confirm the excellent performance of the proposed scheme in terms of accuracy and computational efficiency. In particular we give empirical evidence of performance in a toy example, inference of Gaussian processes hyperparameters, and learning dependence graphs through regression. version:1
arxiv-1611-07054 | An Efficient Training Algorithm for Kernel Survival Support Vector Machines | http://arxiv.org/abs/1611.07054 | id:1611.07054 author:Sebastian Pölsterl, Nassir Navab, Amin Katouzian category:cs.LG cs.AI stat.ML G.1.6; I.5.1; J.3  published:2016-11-21 summary:Survival analysis is a fundamental tool in medical research to identify predictors of adverse events and develop systems for clinical decision support. In order to leverage large amounts of patient data, efficient optimisation routines are paramount. We propose an efficient training algorithm for the kernel survival support vector machine (SSVM). We directly optimise the primal objective function and employ truncated Newton optimisation and order statistic trees to significantly lower computational costs compared to previous training algorithms, which require $O(n^4)$ space and $O(p n^6)$ time for datasets with $n$ samples and $p$ features. Our results demonstrate that our proposed optimisation scheme allows analysing data of a much larger scale with no loss in prediction performance. Experiments on synthetic and 5 real-world datasets show that our technique outperforms existing kernel SSVM formulations if the amount of right censoring is high ($\geq85\%$), and performs comparably otherwise. version:1
arxiv-1611-07051 | Gaussian Process Structure Learning via Probabilistic Inverse Compilation | http://arxiv.org/abs/1611.07051 | id:1611.07051 author:Ulrich Schaechtle, Vikash K. Mansinghka category:stat.ML  published:2016-11-21 summary:There is a widespread need for techniques that can learn interpretable models from data. Recent work by Duvenaud et al. (2013) and Lloyd et al. (2014) showed that it is possible to use Gaussian Processes (GPs) to discover symbolic structure in univariate time series. This abstract shows how to reimplement the approach from Duvenaud et al. (2013) using under 100 lines of probabilistic code in Venture (Mansinghka et al., 2014; Lu, 2016), improving on a previous implementation from Schaechtle et al. (2015). The key idea is to formulate structure learning as a kind of probabilistic inverse compilation, where the kernel structure is represented as source code and the resulting GP model is represented as an executable probabilistic program produced by compiling that source code. Figures 1 and 2 give an overview of the inverse compilation framework. Figure 3 shows example kernel structures, including program source, an English summary, and typical data corresponding to the given structure. Figure 4 shows the complete Venture source code for reimplementing the approach from Duvenaud et al. (2013), and Figure 5 shows an application to real-world time series data describing air travel volume. version:1
arxiv-1611-07012 | GRAM: Graph-based Attention Model for Healthcare Representation Learning | http://arxiv.org/abs/1611.07012 | id:1611.07012 author:Edward Choi, Mohammad Taha Bahadori, Le Song, Walter F. Stewart, Jimeng Sun category:cs.LG stat.ML  published:2016-11-21 summary:Deep learning methods exhibit promising performance for predictive modeling in healthcare, but two important challenges remain: -Data insufficiency: Often in healthcare predictive modeling, the sample size is insufficient for deep learning methods to achieve satisfactory results. -Interpretation: The representations learned by deep learning models should align with medical knowledge. To address these challenges, we propose a GRaph-based Attention Model, GRAM that supplements electronic health records (EHR) with hierarchical information inherent to medical ontologies. Based on the data volume and the ontology structure, GRAM represents a medical concept as a combination of its ancestors in the ontology via an attention mechanism. We compared predictive performance (i.e. accuracy, data needs, interpretability) of GRAM to various methods including the recurrent neural network (RNN) in two sequential diagnoses prediction tasks and one heart failure prediction task. Compared to the basic RNN, GRAM achieved 10% higher accuracy for predicting diseases rarely observed in the training data and 3% improved area under the ROC curve for predicting heart failure using an order of magnitude less training data. Additionally, unlike other methods, the medical concept representations learned by GRAM are well aligned with the medical ontology. Finally, GRAM exhibits intuitive attention behaviors by adaptively generalizing to higher level concepts when facing data insufficiency at the lower level concepts. version:1
arxiv-1611-07004 | Image-to-Image Translation with Conditional Adversarial Networks | http://arxiv.org/abs/1611.07004 | id:1611.07004 author:Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros category:cs.CV  published:2016-11-21 summary:We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either. version:1
arxiv-1611-06997 | Coherent Dialogue with Attention-based Language Models | http://arxiv.org/abs/1611.06997 | id:1611.06997 author:Hongyuan Mei, Mohit Bansal, Matthew R. Walter category:cs.CL cs.AI  published:2016-11-21 summary:We model coherent conversation continuation via RNN-based dialogue models equipped with a dynamic attention mechanism. Our attention-RNN language model dynamically increases the scope of attention on the history as the conversation continues, as opposed to standard attention (or alignment) models with a fixed input scope in a sequence-to-sequence model. This allows each generated word to be associated with the most relevant words in its corresponding conversation history. We evaluate the model on two popular dialogue datasets, the open-domain MovieTriples dataset and the closed-domain Ubuntu Troubleshoot dataset, and achieve significant improvements over the state-of-the-art and baselines on several metrics, including complementary diversity-based metrics, human evaluation, and qualitative visualizations. We also show that a vanilla RNN with dynamic attention outperforms more complex memory models (e.g., LSTM and GRU) by allowing for flexible, long-distance memory. We promote further coherence via topic modeling-based reranking. version:1
arxiv-1611-06996 | Spatial contrasting for deep unsupervised learning | http://arxiv.org/abs/1611.06996 | id:1611.06996 author:Elad Hoffer, Itay Hubara, Nir Ailon category:stat.ML cs.LG  published:2016-11-21 summary:Convolutional networks have marked their place over the last few years as the best performing model for various visual tasks. They are, however, most suited for supervised learning from large amounts of labeled data. Previous attempts have been made to use unlabeled data to improve model performance by applying unsupervised techniques. These attempts require different architectures and training methods. In this work we present a novel approach for unsupervised training of Convolutional networks that is based on contrasting between spatial regions within images. This criterion can be employed within conventional neural networks and trained using standard techniques such as SGD and back-propagation, thus complementing supervised methods. version:1
arxiv-1611-06987 | Precise Relaxation of the Mumford-Shah Functional | http://arxiv.org/abs/1611.06987 | id:1611.06987 author:Thomas Möllenhoff, Daniel Cremers category:cs.CV  published:2016-11-21 summary:Jumps, edges and cutoffs are prevalent in our world across many modalities. The Mumford-Shah functional is a classical and elegant approach for modeling such discontinuities but global optimization of this non-convex functional remains challenging. The state of the art are convex representations based on the theory of calibrations. The major drawback of these approaches is the ultimate discretization of the co-domain into labels. For the case of total variation regularization, this issue has been partially resolved by recent sublabel-accurate relaxations, a generalization of which to other regularizers is not straightforward. In this work, we show that sublabel-accurate lifting approaches can be derived by discretizing a continuous relaxation of the Mumford-Shah functional by means of finite elements. We thereby unify and generalize existing functional lifting approaches. We show the efficiency of the proposed discretizations on discontinuity-preserving denoising tasks. version:1
arxiv-1611-06986 | Robust end-to-end deep audiovisual speech recognition | http://arxiv.org/abs/1611.06986 | id:1611.06986 author:Ramon Sanabria, Florian Metze, Fernando De La Torre category:cs.CL cs.LG cs.SD  published:2016-11-21 summary:Speech is one of the most effective ways of communication among humans. Even though audio is the most common way of transmitting speech, very important information can be found in other modalities, such as vision. Vision is particularly useful when the acoustic signal is corrupted. Multi-modal speech recognition however has not yet found wide-spread use, mostly because the temporal alignment and fusion of the different information sources is challenging. This paper presents an end-to-end audiovisual speech recognizer (AVSR), based on recurrent neural networks (RNN) with a connectionist temporal classification (CTC) loss function. CTC creates sparse "peaky" output activations, and we analyze the differences in the alignments of output targets (phonemes or visemes) between audio-only, video-only, and audio-visual feature representations. We present the first such experiments on the large vocabulary IBM ViaVoice database, which outperform previously published approaches on phone accuracy in clean and noisy conditions. version:1
arxiv-1611-06981 | Multiple-View Spectral Clustering for Group-wise Functional Community Detection | http://arxiv.org/abs/1611.06981 | id:1611.06981 author:Nathan D. Cahill, Harmeet Singh, Chao Zhang, Daryl A. Corcoran, Alison M. Prengaman, Paul S. Wenger, John F. Hamilton, Peter Bajorski, Andrew M. Michael category:cs.CV cs.NE  published:2016-11-21 summary:Functional connectivity analysis yields powerful insights into our understanding of the human brain. Group-wise functional community detection aims to partition the brain into clusters, or communities, in which functional activity is inter-regionally correlated in a common manner across a group of subjects. In this article, we show how to use multiple-view spectral clustering to perform group-wise functional community detection. In a series of experiments on 291 subjects from the Human Connectome Project, we compare three versions of multiple-view spectral clustering: MVSC (uniform weights), MVSCW (weights based on subject-specific embedding quality), and AASC (weights optimized along with the embedding) with the competing technique of Joint Diagonalization of Laplacians (JDL). Results show that multiple-view spectral clustering not only yields group-wise functional communities that are more consistent than JDL when using randomly selected subsets of individual brains, but it is several orders of magnitude faster than JDL. version:1
arxiv-1611-07305 | Correlation Clustering with Low-Rank Matrices | http://arxiv.org/abs/1611.07305 | id:1611.07305 author:Nate Veldt, Anthony Wirth, David F. Gleich category:cs.LG cs.DS cs.NA  published:2016-11-21 summary:Correlation clustering is a technique for aggregating data based on qualitative information about which pairs of objects are labeled 'similar' or 'dissimilar.' Because the optimization problem is NP-hard, much of the previous literature focuses on finding approximation algorithms. In this paper we explore a new approach to correlation clustering by considering how to solve the problem when the data to be clustered can be represented by a low-rank matrix. Many real-world datasets are known to be inherently low-dimensional, and our goal is to establish a tractable approach to correlation clustering in this important setting. We prove in particular that correlation clustering can be solved in polynomial time when the underlying matrix is positive semidefinite with small constant rank, but that the task remains NP-hard in the presence of even one negative eigenvalue. Based on our theoretical results, we develop an algorithm for efficiently solving low-rank positive semidefinite correlation clustering by employing a procedure for zonotope vertex enumeration. We demonstrate the effectiveness and speed of our algorithm by using it to solve several clustering problems on both synthetic and real-world data. version:1
arxiv-1611-06973 | RhoanaNet Pipeline: Dense Automatic Neural Annotation | http://arxiv.org/abs/1611.06973 | id:1611.06973 author:Seymour Knowles-Barley, Verena Kaynig, Thouis Ray Jones, Alyssa Wilson, Joshua Morgan, Dongil Lee, Daniel Berger, Narayanan Kasthuri, Jeff W. Lichtman, Hanspeter Pfister category:q-bio.NC cs.CV  published:2016-11-21 summary:Reconstructing a synaptic wiring diagram, or connectome, from electron microscopy (EM) images of brain tissue currently requires many hours of manual annotation or proofreading (Kasthuri and Lichtman, 2010; Lichtman and Sanes, 2008; Seung, 2009). The desire to reconstruct ever larger and more complex networks has pushed the collection of ever larger EM datasets. A cubic millimeter of raw imaging data would take up 1 PB of storage and present an annotation project that would be impractical without relying heavily on automatic segmentation methods. The RhoanaNet image processing pipeline was developed to automatically segment large volumes of EM data and ease the burden of manual proofreading and annotation. Based on (Kaynig et al., 2015), we updated every stage of the software pipeline to provide better throughput performance and higher quality segmentation results. We used state of the art deep learning techniques to generate improved membrane probability maps, and Gala (Nunez-Iglesias et al., 2014) was used to agglomerate 2D segments into 3D objects. We applied the RhoanaNet pipeline to four densely annotated EM datasets, two from mouse cortex, one from cerebellum and one from mouse lateral geniculate nucleus (LGN). All training and test data is made available for benchmark comparisons. The best segmentation results obtained gave $V^\text{Info}_\text{F-score}$ scores of 0.9054 and 09182 for the cortex datasets, 0.9438 for LGN, and 0.9150 for Cerebellum. The RhoanaNet pipeline is open source software. All source code, training data, test data, and annotations for all four benchmark datasets are available at www.rhoana.org. version:1
arxiv-1611-06969 | Kernel Cross-View Collaborative Representation based Classification for Person Re-Identification | http://arxiv.org/abs/1611.06969 | id:1611.06969 author:Raphael Prates, William Robson Schwartz category:cs.CV  published:2016-11-21 summary:Person re-identification aims at the maintenance of a global identity as a person moves among non-overlapping surveillance cameras. It is a hard task due to different illumination conditions, viewpoints and the small number of annotated individuals from each pair of cameras (small-sample-size problem). Collaborative Representation based Classification (CRC) has been employed successfully to address the small-sample-size problem in computer vision. However, the original CRC formulation is not well-suited for person re-identification since it does not consider that probe and gallery samples are from different cameras. Furthermore, it is a linear model, while appearance changes caused by different camera conditions indicate a strong nonlinear transition between cameras. To overcome such limitations, we propose the Kernel Cross-View Collaborative Representation based Classification (Kernel X-CRC) that represents probe and gallery images by balancing representativeness and similarity nonlinearly. It assumes that a probe and its corresponding gallery image are represented with similar coding vectors using individuals from the training set. Experimental results demonstrate that our assumption is true when using a high-dimensional feature vector and becomes more compelling when dealing with a low-dimensional and discriminative representation computed using a common subspace learning method. We achieve state-of-the-art for rank-1 matching rates in two person re-identification datasets (PRID450S and GRID) and the second best results on VIPeR and CUHK01 datasets. version:1
arxiv-1611-06950 | Statistical Learning for OCR Text Correction | http://arxiv.org/abs/1611.06950 | id:1611.06950 author:Jie Mei, Aminul Islam, Yajing Wu, Abidalrahman Moh'd, Evangelos E. Milios category:cs.CV cs.CL cs.LG  published:2016-11-21 summary:The accuracy of Optical Character Recognition (OCR) is crucial to the success of subsequent applications used in text analyzing pipeline. Recent models of OCR post-processing significantly improve the quality of OCR-generated text, but are still prone to suggest correction candidates from limited observations while insufficiently accounting for the characteristics of OCR errors. In this paper, we show how to enlarge candidate suggestion space by using external corpus and integrating OCR-specific features in a regression approach to correct OCR-generated errors. The evaluation results show that our model can correct 61.5% of the OCR-errors (considering the top 1 suggestion) and 71.5% of the OCR-errors (considering the top 3 suggestions), for cases where the theoretical correction upper-bound is 78%. version:1
arxiv-1611-06949 | Dense Captioning with Joint Inference and Visual Context | http://arxiv.org/abs/1611.06949 | id:1611.06949 author:Linjie Yang, Kevin Tang, Jianchao Yang, Li-Jia Li category:cs.CV  published:2016-11-21 summary:Dense captioning is a newly emerging computer vision topic for understanding images with dense language descriptions. The goal is to densely detect visual concepts (e.g., objects, object parts, and interactions between them) from images, labeling each with a short descriptive phrase. We identify two key challenges of dense captioning that need to be properly addressed when tackling the problem. First, dense visual concept annotations in each image are associated with highly overlapping target regions, making accurate localization of each visual concept challenging. Second, the large amount of visual concepts makes it hard to recognize each of them by appearance alone. We propose a new model pipeline based on two novel ideas, joint inference and context fusion, to alleviate these two challenges. We design our model architecture in a methodical manner and thoroughly evaluate the variations in architecture. Our final model, compact and efficient, achieves state-of-the-art accuracy on Visual Genome for dense captioning with a relative gain of 73\% compared to the previous best algorithm. Qualitative experiments also reveal the semantic capabilities of our model in dense captioning. version:1
arxiv-1611-06945 | A Metaprogramming and Autotuning Framework for Deploying Deep Learning Applications | http://arxiv.org/abs/1611.06945 | id:1611.06945 author:Matthew W. Moskewicz, Ali Jannesari, Kurt Keutzer category:cs.NE cs.DC cs.MS  published:2016-11-21 summary:In recent years, deep neural networks (DNNs), have yielded strong results on a wide range of applications. Graphics Processing Units (GPUs) have been one key enabling factor leading to the current popularity of DNNs. However, despite increasing hardware flexibility and software programming toolchain maturity, high efficiency GPU programming remains difficult: it suffers from high complexity, low productivity, and low portability. GPU vendors such as NVIDIA have spent enormous effort to write special-purpose DNN libraries. However, on other hardware targets, especially mobile GPUs, such vendor libraries are not generally available. Thus, the development of portable, open, high-performance, energy-efficient GPU code for DNN operations would enable broader deployment of DNN-based algorithms. Toward this end, this work presents a framework to enable productive, high-efficiency GPU programming for DNN computations across hardware platforms and programming models. In particular, the framework provides specific support for metaprogramming, autotuning, and DNN-tailored data types. Using our framework, we explore implementing DNN operations on three different hardware targets: NVIDIA, AMD, and Qualcomm GPUs. On NVIDIA GPUs, we show both portability between OpenCL and CUDA as well competitive performance compared to the vendor library. On Qualcomm GPUs, we show that our framework enables productive development of target-specific optimizations, and achieves reasonable absolute performance. Finally, On AMD GPUs, we show initial results that indicate our framework can yield reasonable performance on a new platform with minimal effort. version:1
arxiv-1611-06939 | Predicting 1p19q Chromosomal Deletion of Low-Grade Gliomas from MR Images using Deep Learning | http://arxiv.org/abs/1611.06939 | id:1611.06939 author:Zeynettin Akkus, Issa Ali, Jiri Sedlar, Timothy L. Kline, Jay P. Agrawal, Ian F. Parney, Caterina Giannini, Bradley J. Erickson category:cs.CV  published:2016-11-21 summary:Objective: Several studies have associated codeletion of chromosome arms 1p/19q in low-grade gliomas (LGG) with positive response to treatment and longer progression free survival. Therefore, predicting 1p/19q status is crucial for effective treatment planning of LGG. In this study, we predict the 1p/19q status from MR images using convolutional neural networks (CNN), which could be a noninvasive alternative to surgical biopsy and histopathological analysis. Method: Our method consists of three main steps: image registration, tumor segmentation, and classification of 1p/19q status using CNN. We included a total of 159 LGG with 3 image slices each who had biopsy-proven 1p/19q status (57 nondeleted and 102 codeleted) and preoperative postcontrast-T1 (T1C) and T2 images. We divided our data into training, validation, and test sets. The training data was balanced for equal class probability and then augmented with iterations of random translational shift, rotation, and horizontal and vertical flips to increase the size of the training set. We shuffled and augmented the training data to counter overfitting in each epoch. Finally, we evaluated several configurations of a multi-scale CNN architecture until training and validation accuracies became consistent. Results: The results of the best performing configuration on the unseen test set were 93.3% (sensitivity), 82.22% (specificity), and 87.7% (accuracy). Conclusion: Multi-scale CNN with their self-learning capability provides promising results for predicting 1p/19q status noninvasively based on T1C and T2 images. Significance: Predicting 1p/19q status noninvasively from MR images would allow selecting effective treatment strategies for LGG patients without the need for surgical biopsy. version:1
arxiv-1611-06937 | Using inspiration from synaptic plasticity rules to optimize traffic flow in distributed engineered networks | http://arxiv.org/abs/1611.06937 | id:1611.06937 author:Jonathan Y. Suen, Saket Navlakha category:cs.NE q-bio.NC  published:2016-11-21 summary:Controlling the flow and routing of data is a fundamental problem in many distributed networks, including transportation systems, integrated circuits, and the Internet. In the brain, synaptic plasticity rules have been discovered that regulate network activity in response to environmental inputs, which enable circuits to be stable yet flexible. Here, we develop a new neuro-inspired model for network flow control that only depends on modifying edge weights in an activity-dependent manner. We show how two fundamental plasticity rules (long-term potentiation and long-term depression) can be cast as a distributed gradient descent algorithm for regulating traffic flow in engineered networks. We then characterize, both via simulation and analytically, how different forms of edge-weight update rules affect network routing efficiency and robustness. We find a close correspondence between certain classes of synaptic weight update rules derived experimentally in the brain and rules commonly used in engineering, suggesting common principles to both. version:1
arxiv-1611-06933 | Unsupervised Learning for Lexicon-Based Classification | http://arxiv.org/abs/1611.06933 | id:1611.06933 author:Jacob Eisenstein category:cs.LG cs.CL stat.ML I.2.6; I.2.7  published:2016-11-21 summary:In lexicon-based classification, documents are assigned labels by comparing the number of words that appear from two opposed lexicons, such as positive and negative sentiment. Creating such words lists is often easier than labeling instances, and they can be debugged by non-experts if classification performance is unsatisfactory. However, there is little analysis or justification of this classification heuristic. This paper describes a set of assumptions that can be used to derive a probabilistic justification for lexicon-based classification, as well as an analysis of its expected accuracy. One key assumption behind lexicon-based classification is that all words in each lexicon are equally predictive. This is rarely true in practice, which is why lexicon-based approaches are usually outperformed by supervised classifiers that learn distinct weights on each word from labeled instances. This paper shows that it is possible to learn such weights without labeled data, by leveraging co-occurrence statistics across the lexicons. This offers the best of both worlds: light supervision in the form of lexicons, and data-driven classification with higher accuracy than traditional word-counting heuristics. version:1
arxiv-1611-05319 | Guidefill: GPU Accelerated, Artist Guided Geometric Inpainting for 3D Conversion | http://arxiv.org/abs/1611.05319 | id:1611.05319 author:L. Robert Hocking, Russell MacKenzie, Carola-Bibiane Schoenlieb category:cs.CV  published:2016-11-16 summary:The conversion of traditional film into stereo 3D has become an important problem in the past decade. One of the main bottlenecks is a disocclusion step, which in commercial 3D conversion is usually done by teams of artists armed with a toolbox of inpainting algorithms. A current difficulty in this is that most available algorithms are either too slow for interactive use, or provide no intuitive means for users to tweak the output. In this paper we present a new fast inpainting algorithm based on transporting along automatically detected splines, which the user may edit. Our algorithm is implemented on the GPU and fills the inpainting domain in successive shells that adapt their shape on the fly. In order to allocate GPU resources as efficiently as possible, we propose a parallel algorithm to track the inpainting interface as it evolves, ensuring that no resources are wasted on pixels that are not currently being worked on. Theoretical analysis of the time and processor complexiy of our algorithm without and with tracking (as well as numerous numerical experiments) demonstrate the merits of the latter. Our transport mechanism is similar to the one used in coherence transport, but improves upon it by corrected a "kinking" phenomena whereby extrapolated isophotes may bend at the boundary of the inpainting domain. Theoretical results explaining this phenomena and its resolution are presented. Although our method ignores texture, in many cases this is not a problem due to the thin inpainting domains in 3D conversion. Experimental results show that our method can achieve a visual quality that is competitive with the state-of-the-art while maintaining interactive speeds and providing the user with an intuitive interface to tweak the results. version:2
arxiv-1611-06928 | Memory Lens: How Much Memory Does an Agent Use? | http://arxiv.org/abs/1611.06928 | id:1611.06928 author:Christoph Dann, Katja Hofmann, Sebastian Nowozin category:cs.AI stat.ML  published:2016-11-21 summary:We propose a new method to study the internal memory used by reinforcement learning policies. We estimate the amount of relevant past information by estimating mutual information between behavior histories and the current action of an agent. We perform this estimation in the passive setting, that is, we do not intervene but merely observe the natural behavior of the agent. Moreover, we provide a theoretical justification for our approach by showing that it yields an implementation-independent lower bound on the minimal memory capacity of any agent that implement the observed policy. We demonstrate our approach by estimating the use of memory of DQN policies on concatenated Atari frames, demonstrating sharply different use of memory across 49 games. The study of memory as information that flows from the past to the current action opens avenues to understand and improve successful reinforcement learning algorithms. version:1
arxiv-1611-06906 | Multi-Scale Anisotropic Fourth-Order Diffusion Improves Ridge and Valley Localization | http://arxiv.org/abs/1611.06906 | id:1611.06906 author:Shekoufeh Gorgi Zadeh, Stephan Didas, Maximilian W. M. Wintergerst, Thomas Schultz category:cs.CV  published:2016-11-21 summary:Ridge and valley enhancing filters are widely used in applications such as vessel detection in medical image computing. When images are degraded by noise or include vessels at different scales, such filters are an essential step for meaningful and stable vessel localization. In this work, we propose a novel multi-scale anisotropic fourth-order diffusion equation that allows us to smooth along vessels, while sharpening them in the orthogonal direction. The proposed filter uses a fourth order diffusion tensor whose eigentensors and eigenvalues are determined from the local Hessian matrix, at a scale that is automatically selected for each pixel. We discuss efficient implementation using a Fast Explicit Diffusion scheme and demonstrate results on synthetic images and vessels in fundus images. Compared to previous isotropic and anisotropic fourth-order filters, as well as established second-order vessel enhancing filters, our newly proposed one better restores the centerlines in all cases. version:1
arxiv-1611-05916 | Squared Earth Mover's Distance-based Loss for Training Deep Neural Networks | http://arxiv.org/abs/1611.05916 | id:1611.05916 author:Le Hou, Chen-Ping Yu, Dimitris Samaras category:cs.CV  published:2016-11-17 summary:Deep neural networks (DNNs) especially convolutional neural networks (CNNs) have achieved state-of-the-art performances in many applications, and they have been shown to be especially powerful in multi-class classification tasks. Existing DNNs and CNNs are typically trained with a soft-max cross-entropy loss which only considers the ground-truth class by maximizing the predicted probability of the correct label. This cross-entropy loss ignores the intricate inter-class relationships that exist in the data. In this work, we propose to use the exact squared Earth Mover's Distance (EMD) as a loss function for multi-class classification tasks. The squared EMD loss uses the predicted probabilities of all classes and penalizes the miss-predictions accordingly. In experiments, we evaluate our squared EMD loss in ordered-classes datasets such as age estimation and image aesthetic judgment. We also generalize the squared EMD loss to classification datasets with orderless-classes such as the ImageNet. Our results show that the squared EMD loss allows networks to achieve lower errors than the standard cross-entropy loss, and result in state-of-the-art performances on two age estimation datasets and one image aesthetic judgment dataset. version:2
arxiv-1611-06882 | Learning From Graph Neighborhoods Using LSTMs | http://arxiv.org/abs/1611.06882 | id:1611.06882 author:Rakshit Agrawal, Luca de Alfaro, Vassilis Polychronopoulos category:cs.LG cs.AI stat.ML  published:2016-11-21 summary:Many prediction problems can be phrased as inferences over local neighborhoods of graphs. The graph represents the interaction between entities, and the neighborhood of each entity contains information that allows the inferences or predictions. We present an approach for applying machine learning directly to such graph neighborhoods, yielding predicitons for graph nodes on the basis of the structure of their local neighborhood and the features of the nodes in it. Our approach allows predictions to be learned directly from examples, bypassing the step of creating and tuning an inference model or summarizing the neighborhoods via a fixed set of hand-crafted features. The approach is based on a multi-level architecture built from Long Short-Term Memory neural nets (LSTMs); the LSTMs learn how to summarize the neighborhood from data. We demonstrate the effectiveness of the proposed technique on a synthetic example and on real-world data related to crowdsourced grading, Bitcoin transactions, and Wikipedia edit reversions. version:1
arxiv-1611-06880 | The subset-matched Jaccard index for evaluation of Segmentation for Plant Images | http://arxiv.org/abs/1611.06880 | id:1611.06880 author:Jonathan Bell, Hannah M. Dee category:cs.CV  published:2016-11-21 summary:We describe a new measure for the evaluation of region level segmentation of objects, as applied to evaluating the accuracy of leaf-level segmentation of plant images. The proposed approach enforces the rule that a region (e.g. a leaf) in either the image being evaluated or the ground truth image evaluated against can be mapped to no more than one region in the other image. We call this measure the subset-matched Jaccard index. version:1
arxiv-1611-06878 | SANet: Structure-Aware Network for Visual Tracking | http://arxiv.org/abs/1611.06878 | id:1611.06878 author:Heng Fan, Haibin Ling category:cs.CV  published:2016-11-21 summary:Convolutional neural network (CNN) has drawn increasing interest in visual tracking owing to its powerfulness in feature extraction. Most existing CNN-based trackers treat tracking as a classification problem. However, these trackers are sensitive to similar distractors because their CNN models mainly focus on inter-class classification. To deal with this problem, we use self-structure information of object to distinguish it from distractors. Specifically, we utilize recurrent neural network (RNN) to model object structure, and incorporate it into CNN to improve its robustness in presence of similar distractors. Considering that convolutional layers in different levels characterize the object from different perspectives, we use multiple RNNs to model object structure in different levels respectively. In addition, we present a skip concatenation strategy to fuse CNN and RNN feature maps, and thus are able to provide the next layer with richer information, which further improves the performance of the proposed model. Extensive experimental results on three large-scale benchmarks, OTB100, TC-128 and VOT2015, show that the proposed algorithm outperforms other state-of-the-art methods. version:1
arxiv-1611-06863 | Probabilistic structure discovery in time series data | http://arxiv.org/abs/1611.06863 | id:1611.06863 author:David Janz, Brooks Paige, Tom Rainforth, Jan-Willem van de Meent, Frank Wood category:stat.ML cs.LG  published:2016-11-21 summary:Existing methods for structure discovery in time series data construct interpretable, compositional kernels for Gaussian process regression models. While the learned Gaussian process model provides posterior mean and variance estimates, typically the structure is learned via a greedy optimization procedure. This restricts the space of possible solutions and leads to over-confident uncertainty estimates. We introduce a fully Bayesian approach, inferring a full posterior over structures, which more reliably captures the uncertainty of the model. version:1
arxiv-1611-06824 | Options Discovery with Budgeted Reinforcement Learning | http://arxiv.org/abs/1611.06824 | id:1611.06824 author:Aurélia Léon, Ludovic Denoyer category:cs.LG cs.AI  published:2016-11-21 summary:We consider the problem of learning hierarchical policies for Reinforcement Learning able to discover options, an option corresponding to a sub-policy over a set of primitive actions. Different models have been proposed during the last decade that usually rely on a predefined set of options. We specifically address the problem of automatically discovering options in decision processes. We describe a new RL learning framework called Bi-POMDP, and a new learning model called Budgeted Option Neural Network (BONN) able to discover options based on a budgeted learning objective. Since Bi-POMDP are more general than POMDP, our model can also be used to discover options for classical RL tasks. The BONN model is evaluated on different classical RL problems, demonstrating both quantitative and qualitative interesting results. version:1
arxiv-1611-06800 | MDL-motivated compression of GLM ensembles increases interpretability and retains predictive power | http://arxiv.org/abs/1611.06800 | id:1611.06800 author:Boris Hayete, Matthew Valko, Alex Greenfield, Raymond Yan category:stat.ML  published:2016-11-21 summary:Over the years, ensemble methods have become a staple of machine learning. Similarly, generalized linear models (GLMs) have become very popular for a wide variety of statistical inference tasks. The former have been shown to enhance out- of-sample predictive power and the latter possess easy interpretability. Recently, ensembles of GLMs have been proposed as a possibility. On the downside, this approach loses the interpretability that GLMs possess. We show that minimum description length (MDL)-motivated compression of the inferred ensembles can be used to recover interpretability without much, if any, downside to performance and illustrate on a number of standard classification data sets. version:1
arxiv-1611-06791 | Generalized Dropout | http://arxiv.org/abs/1611.06791 | id:1611.06791 author:Suraj Srinivas, R. Venkatesh Babu category:cs.LG cs.AI cs.CV cs.NE  published:2016-11-21 summary:Deep Neural Networks often require good regularizers to generalize well. Dropout is one such regularizer that is widely used among Deep Learning practitioners. Recent work has shown that Dropout can also be viewed as performing Approximate Bayesian Inference over the network parameters. In this work, we generalize this notion and introduce a rich family of regularizers which we call Generalized Dropout. One set of methods in this family, called Dropout++, is a version of Dropout with trainable parameters. Classical Dropout emerges as a special case of this method. Another member of this family selects the width of neural network layers. Experiments show that these methods help in improving generalization performance over Dropout. version:1
arxiv-1611-06788 | Bidirectional Tree-Structured LSTM with Head Lexicalization | http://arxiv.org/abs/1611.06788 | id:1611.06788 author:Zhiyang Teng, Yue Zhang category:cs.CL  published:2016-11-21 summary:Sequential LSTM has been extended to model tree structures, giving competitive results for a number of tasks. Existing methods model constituent trees by bottom-up combinations of constituent nodes, making direct use of input word information only for leaf nodes. This is different from sequential LSTMs, which contain reference to input words for each node. In this paper, we propose a method for automatic head-lexicalization for tree-structure LSTMs, propagating head words from leaf nodes to every constituent node. In addition, enabled by head lexicalization, we build a tree LSTM in the top-down direction, which corresponds to bidirectional sequential LSTM structurally. Experiments show that both extensions give better representations of tree structures. Our final model gives the best results on the Standford Sentiment Treebank and highly competitive results on the TREC question type classification task. version:1
arxiv-1611-06779 | TextBoxes: A Fast Text Detector with a Single Deep Neural Network | http://arxiv.org/abs/1611.06779 | id:1611.06779 author:Minghui Liao, Baoguang Shi, Xiang Bai, Xinggang Wang, Wenyu Liu category:cs.CV  published:2016-11-21 summary:This paper presents an end-to-end trainable fast scene text detector, named TextBoxes, which detects scene text with both high accuracy and efficiency in a single network forward pass, involving no post-process except for a standard non-maximum suppression. TextBoxes outperforms competing methods in terms of text localization accuracy and is much faster, taking only 0.09s per image in a fast implementation. Furthermore, combined with a text recognizer, TextBoxes significantly outperforms state-of-the-art approaches on word spotting and end-to-end text recognition tasks. version:1
arxiv-1611-06777 | Effective Deterministic Initialization for $k$-Means-Like Methods via Local Density Peaks Searching | http://arxiv.org/abs/1611.06777 | id:1611.06777 author:Fengfu Li, Hong Qiao, Bo Zhang category:cs.LG cs.CV  published:2016-11-21 summary:The $k$-means clustering algorithm is popular but has the following main drawbacks: 1) the number of clusters, $k$, needs to be provided by the user in advance, 2) it can easily reach local minima with randomly selected initial centers, 3) it is sensitive to outliers, and 4) it can only deal with well separated hyperspherical clusters. In this paper, we propose a Local Density Peaks Searching (LDPS) initialization framework to address these issues. The LDPS framework includes two basic components: one of them is the local density that characterizes the density distribution of a data set, and the other is the local distinctiveness index (LDI) which we introduce to characterize how distinctive a data point is compared with its neighbors. Based on these two components, we search for the local density peaks which are characterized with high local densities and high LDIs to deal with 1) and 2). Moreover, we detect outliers characterized with low local densities but high LDIs, and exclude them out before clustering begins. Finally, we apply the LDPS initialization framework to $k$-medoids, which is a variant of $k$-means and chooses data samples as centers, with diverse similarity measures other than the Euclidean distance to fix the last drawback of $k$-means. Combining the LDPS initialization framework with $k$-means and $k$-medoids, we obtain two novel clustering methods called LDPS-means and LDPS-medoids, respectively. Experiments on synthetic data sets verify the effectiveness of the proposed methods, especially when the ground truth of the cluster number $k$ is large. Further, experiments on several real world data sets, Handwritten Pendigits, Coil-20, Coil-100 and Olivetti Face Database, illustrate that our methods give a superior performance than the analogous approaches on both estimating $k$ and unsupervised object categorization. version:1
arxiv-1611-06764 | Efficient Convolutional Neural Network with Binary Quantization Layer | http://arxiv.org/abs/1611.06764 | id:1611.06764 author:Mahdyar Ravanbakhsh, Hossein Mousavi, Moin Nabi, Lucio Marcenaro, Carlo Regazzoni category:cs.CV  published:2016-11-21 summary:In this paper we introduce a novel method for segmentation that can benefit from general semantics of Convolutional Neural Network (CNN). Our segmentation proposes visually and semantically coherent image segments. We use binary encoding of CNN features to overcome the difficulty of the clustering on the high-dimensional CNN feature space. These binary encoding can be embedded into the CNN as an extra layer at the end of the network. This results in real-time segmentation. To the best of our knowledge our method is the first attempt on general semantic image segmentation using CNN. All the previous papers were limited to few number of category of the images (e.g. PASCAL VOC). Experiments show that our segmentation algorithm outperform the state-of-the-art non-semantic segmentation methods by a large margin. version:1
arxiv-1611-06759 | Emergence of Compositional Representations in Restricted Boltzmann Machines | http://arxiv.org/abs/1611.06759 | id:1611.06759 author:Jérôme Tubiana, Rémi Monasson category:physics.data-an cond-mat.dis-nn cs.LG stat.ML  published:2016-11-21 summary:Extracting automatically the complex set of features composing real high-dimensional data is crucial for achieving high performance in machine--learning tasks. Restricted Boltzmann Machines (RBM) are empirically known to be efficient for this purpose, and to be able to generate distributed and graded representations of the data. We characterize the structural conditions (sparsity of the weights, low effective temperature, nonlinearities in the activation functions of hidden units, and adaptation of fields maintaining the activity in the visible layer) allowing RBM to operate in such a compositional phase. Evidence is provided by the replica analysis of an adequate statistical ensemble of random RBMs and by RBM trained on the handwritten digits dataset MNIST. version:1
arxiv-1611-06757 | Non-Local Color Image Denoising with Convolutional Neural Networks | http://arxiv.org/abs/1611.06757 | id:1611.06757 author:Stamatios Lefkimmiatis category:cs.CV cs.AI  published:2016-11-21 summary:We propose a novel deep network architecture for grayscale and color image denoising that is based on a non-local image model. Our motivation for the overall design of the proposed network stems from variational methods that exploit the inherent non-local self-similarity property of natural images. We build on this concept and introduce deep networks that perform non-local processing and at the same time they significantly benefit from discriminative learning. Experiments on the Berkeley segmentation dataset, comparing several state-of-the-art methods, show that the proposed non-local models achieve the best reported denoising performance both for grayscale and color images for all the tested noise levels. It is also worth noting that this increase in performance comes at no extra cost on the capacity of the network compared to existing alternative deep network architectures. In addition, we highlight a direct link of the proposed non-local models to convolutional neural networks. This connection is of significant importance since it allows our models to take full advantage of the latest advances on GPU computing in deep learning and makes them amenable to efficient implementations through their inherent parallelism. version:1
arxiv-1611-06748 | Crowd Counting by Adapting Convolutional Neural Networks with Side Information | http://arxiv.org/abs/1611.06748 | id:1611.06748 author:Di Kang, Debarun Dhar, Antoni B. Chan category:cs.CV  published:2016-11-21 summary:Computer vision tasks often have side information available that is helpful to solve the task. For example, for crowd counting, the camera perspective (e.g., camera angle and height) gives a clue about the appearance and scale of people in the scene. While side information has been shown to be useful for counting systems using traditional hand-crafted features, it has not been fully utilized in counting systems based on deep learning. In order to incorporate the available side information, we propose an adaptive convolutional neural network (ACNN), where the convolutional filter weights adapt to the current scene context via the side information. In particular, we model the filter weights as a low-dimensional manifold, parametrized by the side information, within the high-dimensional space of filter weights. With the help of side information and adaptive weights, the ACNN can disentangle the variations related to the side information, and extract discriminative features related to the current context. Since existing crowd counting datasets do not contain ground-truth side information, we collect a new dataset with the ground-truth camera angle and height as the side information. On experiments in crowd counting, the ACNN improves counting accuracy compared to a plain CNN with a similar number of parameters. We also apply ACNN to image deconvolution to show its potential effectiveness on other computer vision applications. version:1
arxiv-1611-06740 | Variational Fourier features for Gaussian processes | http://arxiv.org/abs/1611.06740 | id:1611.06740 author:James Hensman, Nicolas Durrande, Arno Solin category:stat.ML  published:2016-11-21 summary:This work brings together two powerful concepts in Gaussian processes: the variational approach to sparse approximation and the spectral representation of Gaussian processes. This gives rise to an approximation that inherits the benefits of the variational approach but with the representational power and computational scalability of spectral representations. The work hinges on a key result that there exist spectral features related to a finite domain of the Gaussian process which exhibit almost-independent covariances. We derive these expressions for Matern kernels in one dimension, and generalize to more dimensions using kernels with specific structures. Under the assumption of additive Gaussian noise, our method requires only a single pass through the dataset, making for very fast and accurate computation. We fit a model to 4 million training points in just a few minutes on a standard laptop. With non-conjugate likelihoods, our MCMC scheme reduces the cost of computation from O(NM2) (for a sparse Gaussian process) to O(NM) per iteration, where N is the number of data and M is the number of features. version:1
arxiv-1611-07308 | Variational Graph Auto-Encoders | http://arxiv.org/abs/1611.07308 | id:1611.07308 author:Thomas N. Kipf, Max Welling category:stat.ML cs.LG  published:2016-11-21 summary:We introduce the variational graph auto-encoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph convolutional network (GCN) encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets. version:1
arxiv-1611-06730 | On the convergence of gradient-like flows with noisy gradient input | http://arxiv.org/abs/1611.06730 | id:1611.06730 author:Panayotis Mertikopoulos, Mathias Staudigl category:math.OC cs.LG math.DS  published:2016-11-21 summary:In view of solving convex optimization problems with noisy gradient input, we analyze the asymptotic behavior of gradient-like flows that are subject to stochastic disturbances. Specifically, we focus on the widely studied class of mirror descent methods for constrained convex programming and we examine the dynamics' convergence and concentration properties in the presence of noise. In the small noise limit, we show that the dynamics converge to the solution set of the underlying problem (a.s.). Otherwise, if the noise is persistent, we estimate the measure of the dynamics' long-run concentration around interior solutions and their convergence to boundary solutions that are sufficiently "robust". Finally, we show that a rectified variant of the method with a decreasing sensitivity parameter converges irrespective of the magnitude of the noise or the structure of the underlying convex program, and we derive an explicit estimate for its rate of convergence. version:1
arxiv-1611-06722 | False-Friend Detection and Entity Matching via Unsupervised Transliteration | http://arxiv.org/abs/1611.06722 | id:1611.06722 author:Yanqing Chen, Steven Skiena category:cs.CL  published:2016-11-21 summary:Transliterations play an important role in multilingual entity reference resolution, because proper names increasingly travel between languages in news and social media. Previous work associated with machine translation targets transliteration only single between language pairs, focuses on specific classes of entities (such as cities and celebrities) and relies on manual curation, which limits the expression power of transliteration in multilingual environment. By contrast, we present an unsupervised transliteration model covering 69 major languages that can generate good transliterations for arbitrary strings between any language pair. Our model yields top-(1, 20, 100) averages of (32.85%, 60.44%, 83.20%) in matching gold standard transliteration compared to results from a recently-published system of (26.71%, 50.27%, 72.79%). We also show the quality of our model in detecting true and false friends from Wikipedia high frequency lexicons. Our method indicates a strong signal of pronunciation similarity and boosts the probability of finding true friends in 68 out of 69 languages. version:1
arxiv-1611-06694 | Training Sparse Neural Networks | http://arxiv.org/abs/1611.06694 | id:1611.06694 author:Suraj Srinivas, Akshayvarun Subramanya, R. Venkatesh Babu category:cs.CV cs.LG  published:2016-11-21 summary:Deep neural networks with lots of parameters are typically used for large-scale computer vision tasks such as image classification. This is a result of using dense matrix multiplications and convolutions. However, sparse computations are known to be much more efficient. In this work, we train and build neural networks which implicitly use sparse computations. We introduce additional gate variables to perform parameter selection and show that this is equivalent to using a spike-and-slab prior. We experimentally validate our method on both small and large networks and achieve state-of-the-art compression results for sparse neural network models. version:1
arxiv-1611-06689 | Multi-Modality Fusion based on Consensus-Voting and 3D Convolution for Isolated Gesture Recognition | http://arxiv.org/abs/1611.06689 | id:1611.06689 author:Jiali Duan, Shuai Zhou, Jun Wan, Xiaoyuan Guo, Stan Z. Li category:cs.CV  published:2016-11-21 summary:Recently, the popularity of depth-sensors such as Kinect has made depth videos easily available while its advantages have not been fully exploited. This paper investigates, for gesture recognition, to explore the spatial and temporal information complementarily embedded in RGB and depth sequences. We propose a convolutional twostream consensus voting network (2SCVN) which explicitly models both the short-term and long-term structure of the RGB sequences. To alleviate distractions from background, a 3d depth-saliency ConvNet stream (3DDSN) is aggregated in parallel to identify subtle motion characteristics. These two components in an unified framework significantly improve the recognition accuracy. On the challenging Chalearn IsoGD benchmark, our proposed method outperforms the first place on the leader-board by a large margin (10.29%) while also achieving the best result on RGBD-HuDaAct dataset (96.74%). Both quantitative experiments and qualitative analysis shows the effectiveness of our proposed framework and codes will be released to facilitate future research. version:1
arxiv-1611-06686 | Scalable Approximations for Generalized Linear Problems | http://arxiv.org/abs/1611.06686 | id:1611.06686 author:Murat A. Erdogdu, Mohsen Bayati, Lee H. Dicker category:stat.ML stat.CO  published:2016-11-21 summary:In stochastic optimization, the population risk is generally approximated by the empirical risk. However, in the large-scale setting, minimization of the empirical risk may be computationally restrictive. In this paper, we design an efficient algorithm to approximate the population risk minimizer in generalized linear problems such as binary classification with surrogate losses and generalized linear regression models. We focus on large-scale problems, where the iterative minimization of the empirical risk is computationally intractable, i.e., the number of observations $n$ is much larger than the dimension of the parameter $p$, i.e. $n \gg p \gg 1$. We show that under random sub-Gaussian design, the true minimizer of the population risk is approximately proportional to the corresponding ordinary least squares (OLS) estimator. Using this relation, we design an algorithm that achieves the same accuracy as the empirical risk minimizer through iterations that attain up to a cubic convergence rate, and that are cheaper than any batch optimization algorithm by at least a factor of $\mathcal{O}(p)$. We provide theoretical guarantees for our algorithm, and analyze the convergence behavior in terms of data dimensions. Finally, we demonstrate the performance of our algorithm on well-known classification and regression problems, through extensive numerical studies on large-scale datasets, and show that it achieves the highest performance compared to several other widely used and specialized optimization algorithms. version:1
arxiv-1611-06684 | Probabilistic Duality for Parallel Gibbs Sampling without Graph Coloring | http://arxiv.org/abs/1611.06684 | id:1611.06684 author:Lars Mescheder, Sebastian Nowozin, Andreas Geiger category:cs.LG math.PR stat.ML  published:2016-11-21 summary:We present a new notion of probabilistic duality for random variables involving mixture distributions. Using this notion, we show how to implement a highly-parallelizable Gibbs sampler for weakly coupled discrete pairwise graphical models with strictly positive factors that requires almost no preprocessing and is easy to implement. Moreover, we show how our method can be combined with blocking to improve mixing. Even though our method leads to inferior mixing times compared to a sequential Gibbs sampler, we argue that our method is still very useful for large dynamic networks, where factors are added and removed on a continuous basis, as it is hard to maintain a graph coloring in this setup. Similarly, our method is useful for parallelizing Gibbs sampling in graphical models that do not allow for graph colorings with a small number of colors such as densely connected graphs. version:1
arxiv-1611-06683 | Covariate conscious approach for Gait recognition based upon Zernike moment invariants | http://arxiv.org/abs/1611.06683 | id:1611.06683 author:Himanshu Aggarwal, Dinesh K. Vishwakarma category:cs.CV  published:2016-11-21 summary:Gait recognition i.e. identification of an individual from his/her walking pattern is an emerging field. While existing gait recognition techniques perform satisfactorily in normal walking conditions, there performance tend to suffer drastically with variations in clothing and carrying conditions. In this work, we propose a novel covariate cognizant framework to deal with the presence of such covariates. We describe gait motion by forming a single 2D spatio-temporal template from video sequence, called Average Energy Silhouette image (AESI). Zernike moment invariants (ZMIs) are then computed to screen the parts of AESI infected with covariates. Following this, features are extracted from Spatial Distribution of Oriented Gradients (SDOGs) and novel Mean of Directional Pixels (MDPs) methods. The obtained features are fused together to form the final well-endowed feature set. Experimental evaluation of the proposed framework on three publicly available datasets i.e. CASIA dataset B, OU-ISIR Treadmill dataset B and USF Human-ID challenge dataset with recently published gait recognition approaches, prove its superior performance. version:1
arxiv-1611-06678 | Deep Temporal Linear Encoding Networks | http://arxiv.org/abs/1611.06678 | id:1611.06678 author:Ali Diba, Vivek Sharma, Luc Van Gool category:cs.CV  published:2016-11-21 summary:The CNN-encoding of features from entire videos for the representation of human actions has rarely been addressed. Instead, CNN work has focused on approaches to fuse spatial and temporal networks, but these were typically limited to processing shorter sequences. We present a new video representation, called temporal linear encoding (TLE) and embedded inside of CNNs as a new layer, which captures the appearance and motion throughout entire videos. It encodes this aggregated information into a robust video feature representation, via end-to-end learning. Advantages of TLEs are: (a) they encode the entire video into a compact feature representation, learning the semantics and a discriminative feature space; (b) they are applicable to all kinds of networks like 2D and 3D CNNs for video classification; and (c) they model feature interactions in a more expressive way and without loss of information. We conduct experiments on two challenging human action datasets: HMDB51 and UCF101. The experiments show that TLE outperforms current state-of-the-art methods on both datasets. version:1
arxiv-1611-06674 | Estimation of respiratory pattern from video using selective ensemble aggregation | http://arxiv.org/abs/1611.06674 | id:1611.06674 author:A. P. Prathosh, Pragathi Praveena, Lalit K. Mestha, Sanjay Bharadwaj category:cs.CV  published:2016-11-21 summary:Non-contact estimation of respiratory pattern (RP) and respiration rate (RR) has multiple applications. Existing methods for RP and RR measurement fall into one of the three categories - (i) estimation through nasal air flow measurement, (ii) estimation from video-based remote photoplethysmography, and (iii) estimation by measurement of motion induced by respiration using motion detectors. These methods, however, require specialized sensors, are computationally expensive and/or critically depend on selection of a region of interest (ROI) for processing. In this paper a general framework is described for estimating a periodic signal driving noisy LTI channels connected in parallel with unknown dynamics. The method is then applied to derive a computationally inexpensive method for estimating RP using 2D cameras that does not critically depend on ROI. Specifically, RP is estimated by imaging the changes in the reflected light caused by respiration-induced motion. Each spatial location in the field of view of the camera is modeled as a noise-corrupted linear time-invariant (LTI) measurement channel with unknown system dynamics, driven by a single generating respiratory signal. Estimation of RP is cast as a blind deconvolution problem and is solved through a method comprising subspace projection and statistical aggregation. Experiments are carried out on 31 healthy human subjects by generating multiple RPs and comparing the proposed estimates with simultaneously acquired ground truth from an impedance pneumograph device. The proposed estimator agrees well with the ground truth device in terms of correlation measures, despite variability in clothing pattern, angle of view and ROI. version:1
arxiv-1611-06671 | Ontology Driven Disease Incidence Detection on Twitter | http://arxiv.org/abs/1611.06671 | id:1611.06671 author:Mark Abraham Magumba, Peter Nabende category:cs.CL cs.IR  published:2016-11-21 summary:In this work we address the issue of generic automated disease incidence monitoring on twitter. We employ an ontology of disease related concepts and use it to obtain a conceptual representation of tweets. Unlike previous key word based systems and topic modeling approaches, our ontological approach allows us to apply more stringent criteria for determining which messages are relevant such as spatial and temporal characteristics whilst giving a stronger guarantee that the resulting models will perform well on new data that may be lexically divergent. We achieve this by training learners on concepts rather than individual words. For training we use a dataset containing mentions of influenza and Listeria and use the learned models to classify datasets containing mentions of an arbitrary selection of other diseases. We show that our ontological approach achieves good performance on this task using a variety of Natural Language Processing Techniques. We also show that word vectors can be learned directly from our concepts to achieve even better results. version:1
arxiv-1611-06670 | Error analysis of regularized least-square regression with Fredholm kernel | http://arxiv.org/abs/1611.06670 | id:1611.06670 author:Yanfang Tao, Peipei Yuan, Biqin Song category:math.ST cs.LG stat.TH 68Q25  68T15  published:2016-11-21 summary:Learning with Fredholm kernel has attracted increasing attention recently since it can effectively utilize the data information to improve the prediction performance. Despite rapid progress on theoretical and experimental evaluations, its generalization analysis has not been explored in learning theory literature. In this paper, we establish the generalization bound of least square regularized regression with Fredholm kernel, which implies that the fast learning rate O(l^{-1}) can be reached under mild capacity conditions. Simulated examples show that this Fredholm regression algorithm can achieve the satisfactory prediction performance. version:1
arxiv-1611-06661 | Gland Instance Segmentation Using Deep Multichannel Neural Networks | http://arxiv.org/abs/1611.06661 | id:1611.06661 author:Yan Xu, Yang Li, Yipei Wang, Mingyuan Liu, Yubo Fan, Maode Lai, Eric I-Chao Chang category:cs.CV  published:2016-11-21 summary:We propose a new image instance segmentation method that segments individ- ual glands (instances) in colon histology images. This process is challenging since the glands not only need to be segmented from a complex background, they must also be individually identified. We leverage the idea of image-to-image prediction in recent deep learning by designing an algorithm that automatically exploits and fuses complex multichannel information - regional, location and boundary cues - in gland histology images. Our proposed algorithm, a deep multichannel framework, alleviates heavy feature design due to the use of con- volutional neural networks and is able to meet multifarious requirements by altering channels. Compared to methods reported in the 2015 MICCAI Gland Segmentation Challenge and other currently prevalent instance segmentation methods, we observe state-of-the-art results based on the evaluation metrics. Keywords: Instance segmentation, convolutional neural networks, segmentation, multichannel, histology image. version:1
arxiv-1611-06656 | ResFeats: Residual Network Based Features for Image Classification | http://arxiv.org/abs/1611.06656 | id:1611.06656 author:Ammar Mahmood, Mohammed Bennamoun, Senjian An, Ferdous Sohel category:cs.CV  published:2016-11-21 summary:Deep residual networks have recently emerged as the state-of-the-art architecture in image segmentation and object detection. In this paper, we propose new image features (called ResFeats) extracted from the last convolutional layer of deep residual networks pre-trained on ImageNet. We propose to use ResFeats for diverse image classification tasks namely, object classification, scene classification and coral classification and show that ResFeats consistently perform better than their CNN counterparts on these classification tasks. Since the ResFeats are large feature vectors, we propose to use PCA for dimensionality reduction. Experimental results are provided to show the effectiveness of ResFeats with state-of-the-art classification accuracies on Caltech-101, Caltech-256 and MLC datasets and a significant performance improvement on MIT-67 dataset compared to the widely used CNN features. version:1
arxiv-1611-06652 | Scalable Adaptive Stochastic Optimization Using Random Projections | http://arxiv.org/abs/1611.06652 | id:1611.06652 author:Gabriel Krummenacher, Brian McWilliams, Yannic Kilcher, Joachim M. Buhmann, Nicolai Meinshausen category:stat.ML cs.LG  published:2016-11-21 summary:Adaptive stochastic gradient methods such as AdaGrad have gained popularity in particular for training deep neural networks. The most commonly used and studied variant maintains a diagonal matrix approximation to second order information by accumulating past gradients which are used to tune the step size adaptively. In certain situations the full-matrix variant of AdaGrad is expected to attain better performance, however in high dimensions it is computationally impractical. We present Ada-LR and RadaGrad two computationally efficient approximations to full-matrix AdaGrad based on randomized dimensionality reduction. They are able to capture dependencies between features and achieve similar performance to full-matrix AdaGrad but at a much smaller computational cost. We show that the regret of Ada-LR is close to the regret of full-matrix AdaGrad which can have an up-to exponentially smaller dependence on the dimension than the diagonal variant. Empirically, we show that Ada-LR and RadaGrad perform similarly to full-matrix AdaGrad. On the task of training convolutional neural networks as well as recurrent neural networks, RadaGrad achieves faster convergence than diagonal AdaGrad. version:1
arxiv-1611-06651 | Deep Learning for the Classification of Lung Nodules | http://arxiv.org/abs/1611.06651 | id:1611.06651 author:He Yang, Hengyong Yu, Ge Wang category:q-bio.QM cs.CV cs.LG  published:2016-11-21 summary:Deep learning, as a promising new area of machine learning, has attracted a rapidly increasing attention in the field of medical imaging. Compared to the conventional machine learning methods, deep learning requires no hand-tuned feature extractor, and has shown a superior performance in many visual object recognition applications. In this study, we develop a deep convolutional neural network (CNN) and apply it to thoracic CT images for the classification of lung nodules. We present the CNN architecture and classification accuracy for the original images of lung nodules. In order to understand the features of lung nodules, we further construct new datasets, based on the combination of artificial geometric nodules and some transformations of the original images, as well as a stochastic nodule shape model. It is found that simplistic geometric nodules cannot capture the important features of lung nodules. version:1
arxiv-1611-06646 | Self-Supervised Video Representation Learning With Odd-One-Out Networks | http://arxiv.org/abs/1611.06646 | id:1611.06646 author:Basura Fernando, Hakan Bilen, Efstratios Gavves, Stephen Gould category:cs.CV  published:2016-11-21 summary:We propose a new self-supervised CNN pre-training technique based on a novel auxiliary task called "odd-one-out learning". In this task, the machine is asked to identify the unrelated or odd element from a set of otherwise related elements. We apply this technique to self-supervised video representation learning where we sample subsequences from videos and ask the network to learn to predict the odd video subsequence. The odd video subsequence is sampled such that it has wrong temporal order of frames while the even ones have the correct temporal order. Therefore, to generate a odd-one-out question no manual annotation is required. Our learning machine is implemented as multi-stream convolutional neural network, which is learned end-to-end. Using odd-one-out networks, we learn temporal representations for videos that generalizes to other related tasks such as action recognition. On action classification, our method obtains 60.3\% on the UCF101 dataset using only UCF101 data for training which is approximately 10% better than current state-of-the-art self-supervised learning methods. Similarly, on HMDB51 dataset we outperform self-supervised state-of-the art methods by 12.7% on action classification task. version:1
arxiv-1611-06642 | Cascaded Face Alignment via Intimacy Definition Feature | http://arxiv.org/abs/1611.06642 | id:1611.06642 author:Hailiang Li, Kin-Man Lam, Edmond M. Y. Chiu, Kangheng Wu, Zhibin Lei category:cs.CV  published:2016-11-21 summary:In this paper, we present a fast cascaded regression for face alignment, via a novel local feature. Our proposed local lightweight feature, namely intimacy definition feature (IDF), is more discriminative than landmark shape-indexed feature, more efficient than the handcrafted scale-invariant feature transform (SIFT) feature, and more compact than the local binary feature (LBF). Experimental results show that our approach achieves state-of-the-art performance, when tested on the most challenging benchmarks. Compared with an LBF-based algorithm, our method is able to obtain about two times the speed-up and more than 20% improvement, in terms of alignment error measurement, and able to save an order of magnitude of memory requirement. version:1
arxiv-1611-06641 | Phrase Localization and Visual Relationship Detection with Comprehensive Linguistic Cues | http://arxiv.org/abs/1611.06641 | id:1611.06641 author:Bryan A. Plummer, Arun Mallya, Christopher M. Cervantes, Julia Hockenmaier, Svetlana Lazebnik category:cs.CV  published:2016-11-21 summary:This paper presents a framework for localization or grounding of phrases in images using a large collection of linguistic and visual cues. We model the appearance, size, and position of entity bounding boxes, adjectives that contain attribute information, and spatial relationships between pairs of entities connected by verbs or prepositions. We pay special attention to relationships between people and clothing or body part mentions, as they are useful for distinguishing individuals. We automatically learn weights for combining these cues and at test time, perform joint inference over all phrases in a caption. The resulting system produces a 4% improvement in accuracy over the state of the art on phrase localization on the Flickr30k Entities dataset and a 4-10% improvement for visual relationship detection on the Stanford VRD dataset. version:1
arxiv-1611-06639 | Text Classification Improved by Integrating Bidirectional LSTM with Two-dimensional Max Pooling | http://arxiv.org/abs/1611.06639 | id:1611.06639 author:Peng Zhou, Zhenyu Qi, Suncong Zheng, Jiaming Xu, Hongyun Bao, Bo Xu category:cs.CL  published:2016-11-21 summary:Recurrent Neural Network (RNN) is one of the most popular architectures used in Natural Language Processsing (NLP) tasks because its recurrent structure is very suitable to process variable-length text. RNN can utilize distributed representations of words by first converting the tokens comprising each text into vectors, which form a matrix. And this matrix includes two dimensions: the time-step dimension and the feature vector dimension. Then most existing models usually utilize one-dimensional (1D) max pooling operation or attention-based operation only on the time-step dimension to obtain a fixed-length vector. However, the features on the feature vector dimension are not mutually independent, and simply applying 1D pooling operation over the time-step dimension independently may destroy the structure of the feature representation. On the other hand, applying two-dimensional (2D) pooling operation over the two dimensions may sample more meaningful features for sequence modeling tasks. To integrate the features on both dimensions of the matrix, this paper explores applying 2D max pooling operation to obtain a fixed-length representation of the text. This paper also utilizes 2D convolution to sample more meaningful information of the matrix. Experiments are conducted on six text classification tasks, including sentiment analysis, question classification, subjectivity classification and newsgroup classification. Compared with the state-of-the-art models, the proposed models achieve excellent performance on 4 out of 6 tasks. Specifically, one of the proposed models achieves highest accuracy on Stanford Sentiment Treebank binary classification and fine-grained classification tasks. version:1
arxiv-1611-06638 | Not Afraid of the Dark: NIR-VIS Face Recognition via Cross-spectral Hallucination and Low-rank Embedding | http://arxiv.org/abs/1611.06638 | id:1611.06638 author:Jose Lezama, Qiang Qiu, Guillermo Sapiro category:cs.CV  published:2016-11-21 summary:Surveillance cameras today often capture NIR (near infrared) images in low-light environments. However, most face datasets accessible for training and verification are only collected in the VIS (visible light) spectrum. It remains a challenging problem to match NIR to VIS face images due to the different light spectrum. Recently, breakthroughs have been made for VIS face recognition by applying deep learning on a huge amount of labeled VIS face samples. The same deep learning approach cannot be simply applied to NIR face recognition for two main reasons: First, much limited NIR face images are available for training compared to the VIS spectrum. Second, face galleries to be matched are mostly available only in the VIS spectrum. In this paper, we propose an approach to extend the deep learning breakthrough for VIS face recognition to the NIR spectrum, without retraining the underlying deep models that see only VIS faces. Our approach consists of two core components, cross-spectral hallucination and low-rank embedding, to optimize respectively input and output of a VIS deep model for cross-spectral face recognition. Cross-spectral hallucination produces VIS faces from NIR images through a deep learning approach. Low-rank embedding restores a low-rank structure for faces deep features across both NIR and VIS spectrum. We observe that it is often equally effective to perform hallucination to input NIR images or low-rank embedding to output deep features for a VIS deep model for cross-spectral recognition. When hallucination and low-rank embedding are deployed together, we observe significant further improvement; we obtain state-of-the-art accuracy on the CASIA NIR-VIS v2.0 benchmark, without the need at all to re-train the recognition system. version:1
arxiv-1611-06624 | Temporal Generative Adversarial Nets | http://arxiv.org/abs/1611.06624 | id:1611.06624 author:Masaki Saito, Eiichi Matsumoto category:cs.LG cs.CV  published:2016-11-21 summary:In this paper we propose a generative model, the Temporal Generative Adversarial Network (TGAN), which can learn a semantic representation of unlabelled videos, and is capable of generating consistent videos. Unlike an existing GAN that generates videos with a generator consisting of 3D deconvolutional layers, our model exploits two types of generators: a temporal generator and an image generator. The temporal generator consists of 1D deconvolutional layers and outputs a set of latent variables, each of which corresponds to a frame in the generated video, and the image generator transforms them into a video with 2D deconvolutional layers. This representation allows efficient training of the network parameters. Moreover, it can handle a wider range of applications including the generation of a long sequence, frame interpolation, and the use of pre-trained models. Experimental results demonstrate the effectiveness of our method. version:1
arxiv-1611-06607 | A Hierarchical Approach for Generating Descriptive Image Paragraphs | http://arxiv.org/abs/1611.06607 | id:1611.06607 author:Jonathan Krause, Justin Johnson, Ranjay Krishna, Li Fei-Fei category:cs.CV cs.CL  published:2016-11-20 summary:Recent progress on image captioning has made it possible to generate novel sentences describing images in natural language, but compressing an image into a single sentence can describe visual content in only coarse detail. While one new captioning approach, dense captioning, can potentially describe images in finer levels of detail by captioning many regions within an image, it in turn is unable to produce a coherent story for an image. In this paper we overcome these limitations by generating entire paragraphs for describing images, which can tell detailed, unified stories. We develop a model that decomposes both images and paragraphs into their constituent parts, detecting semantic regions in images and using a hierarchical recurrent neural network to reason about language. Linguistic analysis confirms the complexity of the paragraph generation task, and thorough experiments on a new dataset of image and paragraph pairs demonstrate the effectiveness of our approach. version:1
arxiv-1611-05546 | Zero-Shot Visual Question Answering | http://arxiv.org/abs/1611.05546 | id:1611.05546 author:Damien Teney, Anton van den Hengel category:cs.CV cs.AI cs.CL  published:2016-11-17 summary:Part of the appeal of Visual Question Answering (VQA) is its promise to answer new questions about previously unseen images. Most current methods demand training questions that illustrate every possible concept, and will therefore never achieve this capability, since the volume of required training data would be prohibitive. Answering general questions about images requires methods capable of Zero-Shot VQA, that is, methods able to answer questions beyond the scope of the training questions. We propose a new evaluation protocol for VQA methods which measures their ability to perform Zero-Shot VQA, and in doing so highlights significant practical deficiencies of current approaches, some of which are masked by the biases in current datasets. We propose and evaluate several strategies for achieving Zero-Shot VQA, including methods based on pretrained word embeddings, object classifiers with semantic embeddings, and test-time retrieval of example images. Our extensive experiments are intended to serve as baselines for Zero-Shot VQA, and they also achieve state-of-the-art performance in the standard VQA evaluation setting. version:2
arxiv-1611-06585 | Variational Boosting: Iteratively Refining Posterior Approximations | http://arxiv.org/abs/1611.06585 | id:1611.06585 author:Andrew C. Miller, Nicholas Foti, Ryan P. Adams category:stat.ML cs.LG stat.ME  published:2016-11-20 summary:We propose a black-box variational inference method to approximate intractable distributions with an increasingly rich approximating class. Our method, termed variational boosting, iteratively refines an existing variational approximation by solving a sequence of optimization problems, allowing the practitioner to trade computation time for accuracy. We show how to expand the variational approximating class by incorporating additional covariance structure and by introducing new components to form a mixture. We apply variational boosting to synthetic and real statistical models, and show that resulting posterior inferences compare favorably to existing posterior approximation algorithms in both accuracy and efficiency. version:1
arxiv-1611-06565 | Deep Tensor Convolution on Multicores | http://arxiv.org/abs/1611.06565 | id:1611.06565 author:David Budden, Alexander Matveev, Shibani Santurkar, Shraman Ray Chaudhuri, Nir Shavit category:cs.CV cs.DC cs.NE  published:2016-11-20 summary:Deep convolutional neural networks (ConvNets) have become a de facto standard for image classification and segmentation problems. These networks have also had early success in the video domain, despite failing to capture motion continuity and other rich temporal correlations. Evidence has since emerged that extending ConvNets to 3-dimensions leads to state-of-the-art performance across a broad set of video processing tasks by learning these joint spatiotemporal features. However, these early 3D networks have been restricted to shallower architectures of fewer channels than successful 2D networks due to memory constraints inherent to GPU implementations. In this study we present the first practical CPU implementation of tensor convolution optimized for deep networks of small kernels. Our implementation supports arbitrarily deep ConvNets of $N$-dimensional tensors due to the relaxed memory constraints of CPU systems, which can be further leveraged for an 8-fold reduction in the algorithmic cost of 3D convolution (e.g. C3D kernels). Because most of the optimized ConvNets in previous literature are 2 rather than 3-dimensional, we benchmark our performance against the most popular 2D implementations. Even in this special case, which is theoretically the least beneficial for our fast algorithm, we observe a 5 to 25-fold improvement in throughput compared to previous state-of-the-art. We believe this work is an important step toward practical ConvNets for real-time applications, such as mobile video processing and biomedical image analysis, where high performance 3D networks are a must. version:1
arxiv-1611-06539 | Efficient Stochastic Inference of Bitwise Deep Neural Networks | http://arxiv.org/abs/1611.06539 | id:1611.06539 author:Sebastian Vogel, Christoph Schorn, Andre Guntoro, Gerd Ascheid category:cs.NE cs.LG I.5.1; C.1.3; G.3  published:2016-11-20 summary:Recently published methods enable training of bitwise neural networks which allow reduced representation of down to a single bit per weight. We present a method that exploits ensemble decisions based on multiple stochastically sampled network models to increase performance figures of bitwise neural networks in terms of classification accuracy at inference. Our experiments with the CIFAR-10 and GTSRB datasets show that the performance of such network ensembles surpasses the performance of the high-precision base model. With this technique we achieve 5.81% best classification error on CIFAR-10 test set using bitwise networks. Concerning inference on embedded systems we evaluate these bitwise networks using a hardware efficient stochastic rounding procedure. Our work contributes to efficient embedded bitwise neural networks. version:1
arxiv-1611-06534 | Linear Thompson Sampling Revisited | http://arxiv.org/abs/1611.06534 | id:1611.06534 author:Marc Abeille, Alessandro Lazaric category:stat.ML cs.LG  published:2016-11-20 summary:We derive an alternative proof for the regret of Thompson sampling (\ts) in the stochastic linear bandit setting. While we obtain a regret bound of order $\widetilde{O}(d^{3/2}\sqrt{T})$ as in previous results, the proof sheds new light on the functioning of the \ts. We leverage on the structure of the problem to show how the regret is related to the sensitivity (i.e., the gradient) of the objective function and how selecting optimal arms associated to \textit{optimistic} parameters does control it. Thus we show that \ts can be seen as a generic randomized algorithm where the sampling distribution is designed to have a fixed probability of being optimistic, at the cost of an additional $\sqrt{d}$ regret factor compared to a UCB-like approach. Furthermore, we show that our proof can be readily applied to regularized linear optimization and generalized linear model problems. version:1
arxiv-1611-06530 | Prototypical Recurrent Unit | http://arxiv.org/abs/1611.06530 | id:1611.06530 author:Dingkun Long, Richong Zhang, Yongyi Mao category:cs.LG  published:2016-11-20 summary:The difficulty in analyzing LSTM-like recurrent neural networks lies in the complex structure of the recurrent unit, which induces highly complex nonlinear dynamics. In this paper, we design a new simple recurrent unit, which we call Prototypical Recurrent Unit (PRU). We verify experimentally that PRU performs comparably to LSTM and GRU. This potentially enables PRU to be a prototypical example for analytic study of LSTM-like recurrent networks. Along these experiments, the memorization capability of LSTM-like networks is also studied and some insights are obtained. version:1
arxiv-1611-06495 | Learning Fully Convolutional Networks for Iterative Non-blind Deconvolution | http://arxiv.org/abs/1611.06495 | id:1611.06495 author:Jiawei Zhang, Jinshan Pan, Wei-Sheng Lai, Rynson Lau, Ming-Hsuan Yang category:cs.CV  published:2016-11-20 summary:In this paper, we propose a fully convolutional networks for iterative non-blind deconvolution We decompose the non-blind deconvolution problem into image denoising and image deconvolution. We train a FCNN to remove noises in the gradient domain and use the learned gradients to guide the image deconvolution step. In contrast to the existing deep neural network based methods, we iteratively deconvolve the blurred images in a multi-stage framework. The proposed method is able to learn an adaptive image prior, which keeps both local (details) and global (structures) information. Both quantitative and qualitative evaluations on benchmark datasets demonstrate that the proposed method performs favorably against state-of-the-art algorithms in terms of quality and speed. version:1
arxiv-1611-06492 | Recurrent Memory Addressing for describing videos | http://arxiv.org/abs/1611.06492 | id:1611.06492 author:Kumar Krishna Agrawal, Arnav Kumar Jain, Abhinav Agarwalla, Pabitra Mitra category:cs.CV cs.CL  published:2016-11-20 summary:Deep Neural Network architectures with external memory components allow the model to perform inference and capture long term dependencies, by storing information explicitly. In this paper, we generalize Key-Value Memory Networks to a multimodal setting, introducing a novel key-addressing mechanism to deal with sequence-to-sequence models. The advantages of the framework are demonstrated on the task of video captioning, i.e generating natural language descriptions for videos. Conditioning on the previous time-step attention distributions for the key-value memory slots, we introduce a temporal structure in the memory addressing schema. The proposed model naturally decomposes the problem of video captioning into vision and language segments, dealing with them as key-value pairs. More specifically, we learn a semantic embedding (v) corresponding to each frame (k) in the video, thereby creating (k, v) memory slots. This allows us to exploit the temporal dependencies at multiple hierarchies (in the recurrent key-addressing; and in the language decoder). Exploiting this flexibility of the framework, we additionally capture spatial dependencies while mapping from the visual to semantic embedding. Extensive experiments on the Youtube2Text dataset demonstrate usefulness of recurrent key-addressing, while achieving competitive scores on BLEU@4, METEOR metrics against state-of-the-art models. version:1
arxiv-1611-06478 | Visualizing Linguistic Shift | http://arxiv.org/abs/1611.06478 | id:1611.06478 author:Salman Mahmood, Rami Al-Rfou, Klaus Mueller category:cs.CL cs.HC  published:2016-11-20 summary:Neural network based models are a very powerful tool for creating word embeddings, the objective of these models is to group similar words together. These embeddings have been used as features to improve results in various applications such as document classification, named entity recognition, etc. Neural language models are able to learn word representations which have been used to capture semantic shifts across time and geography. The objective of this paper is to first identify and then visualize how words change meaning in different text corpus. We will train a neural language model on texts from a diverse set of disciplines philosophy, religion, fiction etc. Each text will alter the embeddings of the words to represent the meaning of the word inside that text. We will present a computational technique to detect words that exhibit significant linguistic shift in meaning and usage. We then use enhanced scatterplots and storyline visualization to visualize the linguistic shift. version:1
arxiv-1611-06475 | Dealing with Range Anxiety in Mean Estimation via Statistical Queries | http://arxiv.org/abs/1611.06475 | id:1611.06475 author:Vitaly Feldman category:cs.LG stat.ML  published:2016-11-20 summary:In the statistical query (SQ) model an algorithm has access to an SQ oracle for the input distribution $D$ over $X$ instead of i.i.d.~ samples from $D$. Given a query function $\phi:X \rightarrow [-1,1]$, the oracle returns an estimate of ${\bf E}_{{\bf x}\sim D}[\phi({\bf x})]$ within some tolerance $\tau$. In a variety of natural problems it is necessary to estimate expectations of functions whose standard deviation is much smaller than the range. In this note we describe a nearly optimal algorithm for estimation of such expectations via statistical queries. As applications, we give algorithms for high dimensional mean estimation in the SQ model and in the distributed setting where only a single bit is communicated from each sample. version:1
arxiv-1611-06474 | Nazr-CNN: Object Detection and Fine-Grained Classification in Crowdsourced UAV Images | http://arxiv.org/abs/1611.06474 | id:1611.06474 author:N. Attari, F. Ofli, M. Awad, J. Lucas, S. Chawla category:cs.CV  published:2016-11-20 summary:We propose Nazr-CNN, a deep learning pipeline for object detection and fine-grained classification in images acquired from Unmanned Aerial Vehicles (UAVs). The UAVs were deployed in the Island of Vanuatu to assess damage in the aftermath of cyclone PAM in 2015. The images were labeled by a crowdsourcing effort and the labeling categories consisted of fine-grained levels of damage to built structures. Nazr-CNN consists of two components. The function of the first component is to localize objects (e.g. houses) in an image by carrying out a pixel-level classification. In the second component, a hidden layer of a Convolutional Neural Network (CNN) is used to encode Fisher Vectors (FV) of the segments generated from the first component in order to help discriminate between between different levels of damage. Since our data set is relatively small, a pre-trained network for pixel-level classification and FV encoding was used. Nazr-CNN attains promising results both for object detection and damage assessment suggesting that the integrated pipeline is robust in the face of small data sets and labeling errors by annotators. While the focus of Nazr-CNN is on assessment of UAV images in a post-disaster scenario, our solution is general and can be applied in many diverse settings. version:1
arxiv-1611-06473 | LCNN: Lookup-based Convolutional Neural Network | http://arxiv.org/abs/1611.06473 | id:1611.06473 author:Hessam Bagherinezhad, Mohammad Rastegari, Ali Farhadi category:cs.CV  published:2016-11-20 summary:Porting state of the art deep learning algorithms to resource constrained compute platforms (e.g. VR, AR, wearables) is extremely challenging. We propose a fast, compact, and accurate model for convolutional neural networks that enables efficient learning and inference. We introduce LCNN, a lookup-based convolutional neural network that encodes convolutions by few lookups to a dictionary that is trained to cover the space of weights in CNNs. Training LCNN involves jointly learning a dictionary and a small set of linear combinations. The size of the dictionary naturally traces a spectrum of trade-offs between efficiency and accuracy. Our experimental results on ImageNet challenge show that LCNN can offer 3.2x speedup while achieving 55.1% top-1 accuracy using AlexNet architecture. Our fastest LCNN offers 37.6x speed up over AlexNet while maintaining 44.3% top-1 accuracy. LCNN not only offers dramatic speed ups at inference, but it also enables efficient training. In this paper, we show the benefits of LCNN in few-shot learning and few-iteration learning, two crucial aspects of on-device training of deep learning models. version:1
arxiv-1611-06468 | Generating machine-executable plans from end-user's natural-language instructions | http://arxiv.org/abs/1611.06468 | id:1611.06468 author:Rui Liu, Xiaoli Zhang category:cs.AI cs.CL cs.RO  published:2016-11-20 summary:It is critical for advanced manufacturing machines to autonomously execute a task by following an end-user's natural language (NL) instructions. However, NL instructions are usually ambiguous and abstract so that the machines may misunderstand and incorrectly execute the task. To address this NL-based human-machine communication problem and enable the machines to appropriately execute tasks by following the end-user's NL instructions, we developed a Machine-Executable-Plan-Generation (exePlan) method. The exePlan method conducts task-centered semantic analysis to extract task-related information from ambiguous NL instructions. In addition, the method specifies machine execution parameters to generate a machine-executable plan by interpreting abstract NL instructions. To evaluate the exePlan method, an industrial robot Baxter was instructed by NL to perform three types of industrial tasks {'drill a hole', 'clean a spot', 'install a screw'}. The experiment results proved that the exePlan method was effective in generating machine-executable plans from the end-user's NL instructions. Such a method has the promise to endow a machine with the ability of NL-instructed task execution. version:1
arxiv-1611-06467 | On The Stability of Video Detection and Tracking | http://arxiv.org/abs/1611.06467 | id:1611.06467 author:Hong Zhang, Naiyan Wang category:cs.CV  published:2016-11-20 summary:In this paper, we study an important yet less explored aspect in video detection and multi-object tracking -- stability. Surprisingly, there is no prior work that tried to quantify it. As a consequence, we start our work by proposing a novel evaluation metric for video detection which considers both stability and accuracy. For accuracy, we extend the existing accuracy metric mean Average Precision (mAP). For stability, we decompose it into three terms: fragment error, center position error, scale and ratio error. Each error represents one type of stability. Furthermore, we demonstrate that the stability metric has low correlation with accuracy metric. Thus, it indeed captures a different perspective of quality in object detection. Lastly, based on this metric, we evaluate several existing methods for video detection, and show how they affect accuracy and stability. We believe our work can provide guidance and solid baselines for future researches in related areas. version:1
arxiv-1611-06453 | Fast Video Classification via Adaptive Cascading of Deep Models | http://arxiv.org/abs/1611.06453 | id:1611.06453 author:Haichen Shen, Seungyeop Han, Matthai Philipose, Arvind Krishnamurthy category:cs.CV cs.LG cs.NE  published:2016-11-20 summary:Recent advances have enabled "oracle" classifiers that can classify across many classes and input distributions with high accuracy without retraining. However, these classifiers are relatively heavyweight, so that applying them to classify video is costly. We show that day-to-day video exhibits highly skewed class distributions over the short term, and that these distributions can be classified by much simpler models. We formulate the problem of detecting the short-term skews online and exploiting models based on it as a new sequential decision making problem dubbed the Online Bandit Problem, and present a new algorithm to solve it. When applied to recognizing faces in TV shows and movies, we realize end-to-end classification speedups of 2.5-8.5x/2.8-12.7x (on GPU/CPU) relative to a state-of-the-art convolutional neural network, at competitive accuracy. version:1
arxiv-1611-06440 | Pruning Convolutional Neural Networks for Resource Efficient Transfer Learning | http://arxiv.org/abs/1611.06440 | id:1611.06440 author:Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, Jan Kautz category:cs.LG stat.ML  published:2016-11-19 summary:We propose a new framework for pruning convolutional kernels in neural networks to enable efficient inference, focusing on transfer learning where large and potentially unwieldy pretrained networks are adapted to specialized tasks. We interleave greedy criteria-based pruning with fine-tuning by backpropagation - a computationally efficient procedure that maintains good generalization in the pruned network. We propose a new criterion based on an efficient first-order Taylor expansion to approximate the absolute change in training cost induced by pruning a network component. After normalization, the proposed criterion scales appropriately across all layers of a deep CNN, eliminating the need for per-layer sensitivity analysis. The proposed criterion demonstrates superior performance compared to other criteria, such as the norm of kernel weights or average feature map activation. version:1
arxiv-1611-06439 | A Survey of Credit Card Fraud Detection Techniques: Data and Technique Oriented Perspective | http://arxiv.org/abs/1611.06439 | id:1611.06439 author:SamanehSorournejad, Zahra Zojaji, Reza Ebrahimi Atani, Amir Hassan Monadjemi category:cs.CR cs.AI cs.LG  published:2016-11-19 summary:Credit card plays a very important rule in today's economy. It becomes an unavoidable part of household, business and global activities. Although using credit cards provides enormous benefits when used carefully and responsibly,significant credit and financial damages may be caused by fraudulent activities. Many techniques have been proposed to confront the growth in credit card fraud. However, all of these techniques have the same goal of avoiding the credit card fraud; each one has its own drawbacks, advantages and characteristics. In this paper, after investigating difficulties of credit card fraud detection, we seek to review the state of the art in credit card fraud detection techniques, data sets and evaluation criteria.The advantages and disadvantages of fraud detection methods are enumerated and compared.Furthermore, a classification of mentioned techniques into two main fraud detection approaches, namely, misuses (supervised) and anomaly detection (unsupervised) is presented. Again, a classification of techniques is proposed based on capability to process the numerical and categorical data sets. Different data sets used in literature are then described and grouped into real and synthesized data and the effective and common attributes are extracted for further usage.Moreover, evaluation employed criterions in literature are collected and discussed.Consequently, open issues for credit card fraud detection are explained as guidelines for new researchers. version:1
arxiv-1611-06430 | Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks | http://arxiv.org/abs/1611.06430 | id:1611.06430 author:Emily Denton, Sam Gross, Rob Fergus category:cs.CV  published:2016-11-19 summary:We introduce a simple semi-supervised learning approach for images based on in-painting using an adversarial loss. Images with random patches removed are presented to a generator whose task is to fill in the hole, based on the surrounding pixels. The in-painted images are then presented to a discriminator network that judges if they are real (unaltered training images) or not. This task acts as a regularizer for standard supervised training of the discriminator. Using our approach we are able to directly train large VGG-style networks in a semi-supervised fashion. We evaluate on STL-10 and PASCAL datasets, where our approach obtains performance comparable or superior to existing methods. version:1
arxiv-1611-06426 | Conservative Contextual Linear Bandits | http://arxiv.org/abs/1611.06426 | id:1611.06426 author:Abbas Kazerouni, Mohammad Ghavamzadeh, Benjamin Van Roy category:stat.ML cs.LG  published:2016-11-19 summary:Safety is a desirable property that can immensely increase the applicability of learning algorithms in real-world decision-making problems. It is much easier for a company to deploy an algorithm that is safe, i.e.,~guaranteed to perform at least as well as a baseline. In this paper, we study the issue of safety in contextual linear bandits that have application in many different fields including personalized ad recommendation in online marketing. We formulate a notion of safety for this class of algorithms. We develop a safe contextual linear bandit algorithm, called {\em conservative linear UCB} (CLUCB), that simultaneously minimizes its regret and satisfies the safety constraint, i.e.,~maintains its performance above a fixed percentage of the performance of a baseline strategy, uniformly over time. We prove an upper-bound on the regret of CLUCB and show that it can be decomposed into two terms: {\bf 1)} an upper-bound for the regret of the standard linear UCB algorithm that grows with the time horizon and {\bf 2)} a constant (does not grow with the time horizon) term that accounts for the loss of being conservative in order to satisfy the safety constraint. We empirically show that our algorithm is safe and validate our theoretical analysis. version:1
arxiv-1611-06423 | Incorporating Pass-Phrase Dependent Background Models for Text Dependent Speaker Verification | http://arxiv.org/abs/1611.06423 | id:1611.06423 author:A. K. Sarkar, Zheng-Hua Tan category:cs.CL  published:2016-11-19 summary:In this paper, we propose a pass-phrase dependent background model (PBM) for text dependent (TD) speaker verification (SV) to integrate pass-phrase identification process (without an additional separate identification system) in the conventional TD-SV system, where a PBM is derived from a text-independent background model through adaptation using the utterances of a particular pass-phrase. During training, pass-phrase specific target speaker models are derived from the particular PBM using the training data for the respective target model. While testing, the best PBM is first selected for the test utterance in the maximum likelihood (ML) sense and following the selected PBM is used for the log likelihood ratio (LLR) calculation with respect to the claimant model. The proposed method incorporates the pass-phrase identification step in the LLR calculation, which is not considered in conventional standalone TD-SV based systems. The performance of the proposed method is compared to conventional text-independent background model based TD-SV systems using a Gaussian mixture model (GMM)-universal background model (UBM), Hidden Markov model (HMM)-UBM and i-vector paradigms. In addition, we consider two approaches to build PBMs: one is speaker independent and the other is speaker dependent. We show that the proposed method significantly reduces the error rate of text dependent speaker verification for the non-target types: target-wrong and imposter-wrong while it maintains comparable TD-SV performance when imposters speak a correct utterance with respect to the conventional system. Experiments are conducted on the RedDots challenge and the RSR2015 databases which consist of short utterances. version:1
arxiv-1611-06403 | Deep Outdoor Illumination Estimation | http://arxiv.org/abs/1611.06403 | id:1611.06403 author:Yannick Hold-Geoffroy, Kalyan Sunkavalli, Sunil Hadap, Emiliano Gambaretto, Jean-François Lalonde category:cs.CV  published:2016-11-19 summary:We present a CNN-based technique to estimate high-dynamic range outdoor illumination from a single low dynamic range image. To train the CNN, we leverage a large dataset of outdoor panoramas. We fit a low-dimensional physically-based outdoor illumination model to the skies in these panoramas giving us a compact set of parameters (including sun position, atmospheric conditions, and camera parameters). We extract limited field-of-view images from the panoramas, and train a CNN with this large set of input image--output lighting parameter pairs. Given a test image, this network can be used to infer illumination parameters that can, in turn, be used to reconstruct an outdoor illumination environment map. We demonstrate that our approach allows the recovery of plausible illumination conditions and enables automatic photorealistic virtual object insertion from a single image. An extensive evaluation on both the panorama dataset and captured HDR environment maps shows that our technique significantly outperforms previous solutions to this problem. version:1
arxiv-1611-06395 | Semantic tracking: Single-target tracking with inter-supervised convolutional networks | http://arxiv.org/abs/1611.06395 | id:1611.06395 author:Jingjing Xiao, Qiang Lan, Linbo Qiao, Ales Leonardis category:cs.CV  published:2016-11-19 summary:This article presents a semantic tracker which simultaneously tracks a single target and recognises its category. In general, it is hard to design a tracking model suitable for all object categories, e.g., a rigid tracker for a car is not suitable for a deformable gymnast. Category-based trackers usually achieve superior tracking performance for the objects of that specific category, but have difficulties being generalised. Therefore, we propose a novel unified robust tracking framework which explicitly encodes both generic features and category-based features. The tracker consists of a shared convolutional network (NetS), which feeds into two parallel networks, NetC for classification and NetT for tracking. NetS is pre-trained on ImageNet to serve as a generic feature extractor across the different object categories for NetC and NetT. NetC utilises those features within fully connected layers to classify the object category. NetT has multiple branches, corresponding to multiple categories, to distinguish the tracked object from the background. Since each branch in NetT is trained by the videos of a specific category or groups of similar categories, NetT encodes category-based features for tracking. During online tracking, NetC and NetT jointly determine the target regions with the right category and foreground labels for target estimation. To improve the robustness and precision, NetC and NetT inter-supervise each other and trigger network adaptation when their outputs are ambiguous for the same image regions (i.e., when the category label contradicts the foreground/background classification). We have compared the performance of our tracker to other state-of-the-art trackers on a large-scale tracking benchmark (100 sequences)---the obtained results demonstrate the effectiveness of our proposed tracker as it outperformed other 38 state-of-the-art tracking algorithms. version:1
arxiv-1611-06391 | Deep Residual Learning for Compressed Sensing CT Reconstruction via Persistent Homology Analysis | http://arxiv.org/abs/1611.06391 | id:1611.06391 author:Yoseop Han, Jaejoon Yoo, Jong Chul Ye category:cs.CV  published:2016-11-19 summary:Recently, compressed sensing (CS) computed tomography (CT) using sparse projection views has been extensively investigated to reduce the potential risk of radiation to patient. However, due to the insufficient number of projection views, an analytic reconstruction approach results in severe streaking artifacts and CS-based iterative approach is computationally very expensive. To address this issue, here we propose a novel deep residual learning approach for sparse view CT reconstruction. Specifically, based on a novel persistent homology analysis showing that the manifold of streaking artifacts is topologically simpler than original ones, a deep residual learning architecture that estimates the streaking artifacts is developed. Once a streaking artifact image is estimated, an artifact-free image can be obtained by subtracting the streaking artifacts from the input image. Using extensive experiments with real patient data set, we confirm that the proposed residual learning provides significantly better image reconstruction performance with several orders of magnitude faster computational speed. version:1
arxiv-1611-06362 | Ordinal Constrained Binary Code Learning for Nearest Neighbor Search | http://arxiv.org/abs/1611.06362 | id:1611.06362 author:Hong Liu, Rongrong Ji, Yongjian Wu, Feiyue Huang category:cs.CV I.4.7  H.3.3  published:2016-11-19 summary:Recent years have witnessed extensive attention in binary code learning, a.k.a. hashing, for nearest neighbor search problems. It has been seen that high-dimensional data points can be quantized into binary codes to give an efficient similarity approximation via Hamming distance. Among existing schemes, ranking-based hashing is recent promising that targets at preserving ordinal relations of ranking in the Hamming space to minimize retrieval loss. However, the size of the ranking tuples, which shows the ordinal relations, is quadratic or cubic to the size of training samples. By given a large-scale training data set, it is very expensive to embed such ranking tuples in binary code learning. Besides, it remains a dificulty to build ranking tuples efficiently for most ranking-preserving hashing, which are deployed over an ordinal graph-based setting. To handle these problems, we propose a novel ranking-preserving hashing method, dubbed Ordinal Constraint Hashing (OCH), which efficiently learns the optimal hashing functions with a graph-based approximation to embed the ordinal relations. The core idea is to reduce the size of ordinal graph with ordinal constraint projection, which preserves the ordinal relations through a small data set (such as clusters or random samples). In particular, to learn such hash functions effectively, we further relax the discrete constraints and design a specific stochastic gradient decent algorithm for optimization. Experimental results on three large-scale visual search benchmark datasets, i.e. LabelMe, Tiny100K and GIST1M, show that the proposed OCH method can achieve superior performance over the state-of-the-arts approaches. version:1
arxiv-1611-06355 | Invertible Conditional GANs for image editing | http://arxiv.org/abs/1611.06355 | id:1611.06355 author:Guim Perarnau, Joost van de Weijer, Bogdan Raducanu, Jose M. Álvarez category:cs.CV cs.AI  published:2016-11-19 summary:Generative Adversarial Networks (GANs) have recently demonstrated to successfully approximate complex data distributions. A relevant extension of this model is conditional GANs (cGANs), where the introduction of external information allows to determine specific representations of the generated images. In this work, we evaluate encoders to inverse the mapping of a cGAN, i.e., mapping a real image into a latent space and a conditional representation. This allows, for example, to reconstruct and modify real images of faces conditioning on arbitrary attributes. Additionally, we evaluate the design of cGANs. The combination of an encoder with a cGAN, which we call Invertible cGAN (IcGAN), enables to re-generate real images with deterministic complex modifications. version:1
arxiv-1611-06345 | Beyond Deep Residual Learning for Image Restoration: Persistent Homology-Guided Manifold Simplification | http://arxiv.org/abs/1611.06345 | id:1611.06345 author:Woong Bae, Jaejoon Yoo, Jong Chul Ye category:cs.CV  published:2016-11-19 summary:The latest deep learning approaches perform better than the state-of-the-art signal processing approaches in various image restoration tasks. However, if an image contains many patterns and structures, the performance of these CNNs is still inferior. To address this issue, here we propose a novel wavelet-domain deep residual learning algorithm that outperforms the existing residual learning. The main idea is originated from observation that the performance of a learning algorithm can be improved if the input and/or label manifold can be made topologically simpler. Using persistent homology analysis, we show that the recent residual learning was benefited from such manifold simplification, and wavelet transform provides another way to simplify the data manifold while preserving the edge information. Our extensive experiments demonstrate that the proposed wavelet-domain residual learning outperforms the existing state-of-the art approaches. version:1
arxiv-1611-06342 | Quantized neural network design under weight capacity constraint | http://arxiv.org/abs/1611.06342 | id:1611.06342 author:Sungho Shin, Kyuyeon Hwang, Wonyong Sung category:cs.LG cs.NE  published:2016-11-19 summary:The complexity of deep neural network algorithms for hardware implementation can be lowered either by scaling the number of units or reducing the word-length of weights. Both approaches, however, can accompany the performance degradation although many types of research are conducted to relieve this problem. Thus, it is an important question which one, between the network size scaling and the weight quantization, is more effective for hardware optimization. For this study, the performances of fully-connected deep neural networks (FCDNNs) and convolutional neural networks (CNNs) are evaluated while changing the network complexity and the word-length of weights. Based on these experiments, we present the effective compression ratio (ECR) to guide the trade-off between the network size and the precision of weights when the hardware resource is limited. version:1
arxiv-1611-06322 | Spotting Rumors via Novelty Detection | http://arxiv.org/abs/1611.06322 | id:1611.06322 author:Yumeng Qin, Dominik Wurzer, Victor Lavrenko, Cunchen Tang category:cs.SI cs.CL cs.IR  published:2016-11-19 summary:Rumour detection is hard because the most accurate systems operate retrospectively, only recognizing rumours once they have collected repeated signals. By then the rumours might have already spread and caused harm. We introduce a new category of features based on novelty, tailored to detect rumours early on. To compensate for the absence of repeated signals, we make use of news wire as an additional data source. Unconfirmed (novel) information with respect to the news articles is considered as an indication of rumours. Additionally we introduce pseudo feedback, which assumes that documents that are similar to previous rumours, are more likely to also be a rumour. Comparison with other real-time approaches shows that novelty based features in conjunction with pseudo feedback perform significantly better, when detecting rumours instantly after their publication. version:1
arxiv-1611-06321 | Learning the Number of Neurons in Deep Networks | http://arxiv.org/abs/1611.06321 | id:1611.06321 author:Jose M Alvarez, Mathieu Salzmann category:cs.CV cs.LG cs.NE  published:2016-11-19 summary:Nowadays, the number of layers and of neurons in each layer of a deep network are typically set manually. While very deep and wide networks have proven effective in general, they come at a high memory and computation cost, thus making them impractical for constrained platforms. These networks, however, are known to have many redundant parameters, and could thus, in principle, be replaced by more compact architectures. In this paper, we introduce an approach to automatically determining the number of neurons in each layer of a deep network during learning. To this end, we propose to make use of a group sparsity regularizer on the parameters of the network, where each group is defined to act on a single neuron. Starting from an overcomplete network, we show that our approach can reduce the number of parameters by up to 80\% while retaining or even improving the network accuracy. version:1
arxiv-1611-06320 | Tracking Words in Chinese Poetry of Tang and Song Dynasties with the China Biographical Database | http://arxiv.org/abs/1611.06320 | id:1611.06320 author:Chao-Lin Liu, Kuo-Feng Luo category:cs.CL  published:2016-11-19 summary:Large-scale comparisons between the poetry of Tang and Song dynasties shed light on how words, collocations, and expressions were used and shared among the poets. That some words were used only in the Tang poetry and some only in the Song poetry could lead to interesting research in linguistics. That the most frequent colors are different in the Tang and Song poetry provides a trace of the changing social circumstances in the dynasties. Results of the current work link to research topics of lexicography, semantics, and social transitions. We discuss our findings and present our algorithms for efficient comparisons among the poems, which are crucial for completing billion times of comparisons within acceptable time. version:1
arxiv-1611-06314 | Determining the Veracity of Rumours on Twitter | http://arxiv.org/abs/1611.06314 | id:1611.06314 author:Georgios Giasemidis, Colin Singleton, Ioannis Agrafiotis, Jason R. C. Nurse, Alan Pilgrim, Chris Willis, Danica Vukadinovic Greetham category:cs.SI stat.ML  published:2016-11-19 summary:While social networks can provide an ideal platform for up-to-date information from individuals across the world, it has also proved to be a place where rumours fester and accidental or deliberate misinformation often emerges. In this article, we aim to support the task of making sense from social media data, and specifically, seek to build an autonomous message-classifier that filters relevant and trustworthy information from Twitter. For our work, we collected about 100 million public tweets, including users' past tweets, from which we identified 72 rumours (41 true, 31 false). We considered over 80 trustworthiness measures including the authors' profile and past behaviour, the social network connections (graphs), and the content of tweets themselves. We ran modern machine-learning classifiers over those measures to produce trustworthiness scores at various time windows from the outbreak of the rumour. Such time-windows were key as they allowed useful insight into the progression of the rumours. From our findings, we identified that our model was significantly more accurate than similar studies in the literature. We also identified critical attributes of the data that give rise to the trustworthiness scores assigned. Finally we developed a software demonstration that provides a visual user interface to allow the user to examine the analysis. version:1
arxiv-1611-06310 | Local minima in training of deep networks | http://arxiv.org/abs/1611.06310 | id:1611.06310 author:Grzegorz Swirszcz, Wojciech Marian Czarnecki, Razvan Pascanu category:stat.ML cs.LG cs.NE  published:2016-11-19 summary:There has been a lot of recent interest in trying to characterize the error surface of deep models. This stems from a long standing question. Given that deep networks are highly nonlinear systems optimized by local gradient methods, why do they not seem to be affected by bad local minima? It is widely believed that training of deep models using gradient methods works so well because the error surface either has no local minima, or if they exist they need to be close in value to the global minimum. It is known that such results hold under very strong assumptions which are not satisfied by real models. In this paper we present examples showing that for such theorem to be true additional assumptions on the data, initialization schemes and/or the model classes have to be made. We look at the particular case of finite size datasets. We demonstrate that in this scenario one can construct counter-examples (datasets or initialization schemes) when the network does become susceptible to bad local minima over the weight space. version:1
arxiv-1611-06307 | Multi-Scale Saliency Detection using Dictionary Learning | http://arxiv.org/abs/1611.06307 | id:1611.06307 author:Shubham Pachori, Shanmugananthan Raman category:cs.CV  published:2016-11-19 summary:Saliency detection has drawn a lot of attention of researchers in various fields over the past several years. Saliency is the perceptual quality that makes an object, person to draw the attention of humans at the very sight. Salient object detection in an image has been used centrally in many computational photography and computer vision applications like video compression, object recognition and classification, object segmentation, adaptive content delivery, motion detection, content aware resizing, camouflage images and change blindness images to name a few. We propose a method to detect saliency in the objects using multimodal dictionary learning which has been recently used in classification and image fusion. The multimodal dictionary that we are learning is task driven which gives improved performance over its counterpart (the one which is not task specific). version:1
arxiv-1611-06306 | Cross-model convolutional neural network for multiple modality data representation | http://arxiv.org/abs/1611.06306 | id:1611.06306 author:Yanbin Wu, Li Wang, Fan Cui, Hongbin Zhai, Baoming Dong, Jim Jing-Yan Wang category:cs.LG  published:2016-11-19 summary:A novel data representation method of convolutional neural net- work (CNN) is proposed in this paper to represent data of different modalities. We learn a CNN model for the data of each modality to map the data of differ- ent modalities to a common space, and regularize the new representations in the common space by a cross-model relevance matrix. We further impose that the class label of data points can also be predicted from the CNN representa- tions in the common space. The learning problem is modeled as a minimiza- tion problem, which is solved by an augmented Lagrange method (ALM) with updating rules of Alternating direction method of multipliers (ADMM). The experiments over benchmark of sequence data of multiple modalities show its advantage. version:1
arxiv-1611-06301 | Inferring Restaurant Styles by Mining Crowd Sourced Photos from User-Review Websites | http://arxiv.org/abs/1611.06301 | id:1611.06301 author:Haofu Liao, Yucheng Li, Tianran Hu, Jiebo Luo category:cs.CV  published:2016-11-19 summary:When looking for a restaurant online, user uploaded photos often give people an immediate and tangible impression about a restaurant. Due to their informativeness, such user contributed photos are leveraged by restaurant review websites to provide their users an intuitive and effective search experience. In this paper, we present a novel approach to inferring restaurant types or styles (ambiance, dish styles, suitability for different occasions) from user uploaded photos on user-review websites. To that end, we first collect a novel restaurant photo dataset associating the user contributed photos with the restaurant styles from TripAdvior. We then propose a deep multi-instance multi-label learning (MIML) framework to deal with the unique problem setting of the restaurant style classification task. We employ a two-step bootstrap strategy to train a multi-label convolutional neural network (CNN). The multi-label CNN is then used to compute the confidence scores of restaurant styles for all the images associated with a restaurant. The computed confidence scores are further used to train a final binary classifier for each restaurant style tag. Upon training, the styles of a restaurant can be profiled by analyzing restaurant photos with the trained multi-label CNN and SVM models. Experimental evaluation has demonstrated that our crowd sourcing-based approach can effectively infer the restaurant style when there are a sufficient number of user uploaded photos for a given restaurant. version:1
arxiv-1611-06296 | A Bayesian approach to type-specific conic fitting | http://arxiv.org/abs/1611.06296 | id:1611.06296 author:Matthew Collett category:cs.CV G.1.6; I.4.8  published:2016-11-19 summary:A perturbative approach is used to quantify the effect of noise in data points on fitted parameters in a general homogeneous linear model, and the results applied to the case of conic sections. There is an optimal choice of normalisation that minimises bias, and iteration with the correct reweighting significantly improves statistical reliability. By conditioning on an appropriate prior, an unbiased type-specific fit can be obtained. Error estimates for the conic coefficients may also be used to obtain both bias corrections and confidence intervals for other curve parameters. version:1
arxiv-1611-07819 | dMath: Distributed Linear Algebra for DL | http://arxiv.org/abs/1611.07819 | id:1611.07819 author:Steven Eliuk, Cameron Upright, Hars Vardhan, Stephen Walsh, Trevor Gale category:cs.DC cs.MS cs.NE  published:2016-11-19 summary:The paper presents a parallel math library, dMath, that demonstrates leading scaling when using intranode, internode, and hybrid-parallelism for deep learning (DL). dMath provides easy-to-use distributed primitives and a variety of domain-specific algorithms including matrix multiplication, convolutions, and others allowing for rapid development of scalable applications like deep neural networks (DNNs). Persistent data stored in GPU memory and advanced memory management techniques avoid costly transfers between host and device. dMath delivers performance, portability, and productivity to its specific domain of support. version:1
arxiv-1611-06265 | Deep Clustering and Conventional Networks for Music Separation: Stronger Together | http://arxiv.org/abs/1611.06265 | id:1611.06265 author:Yi Luo, Zhuo Chen, John R. Hershey, Jonathan Le Roux, Nima Mesgarani category:stat.ML cs.LG cs.SD  published:2016-11-18 summary:Deep clustering is the first method to handle general audio separation scenarios with multiple sources of the same type and an arbitrary number of sources, performing impressively in speaker-independent speech separation tasks. However, little is known about its effectiveness in other challenging situations such as music source separation. Contrary to conventional networks that directly estimate the source signals, deep clustering generates an embedding for each time-frequency bin, and separates sources by clustering the bins in the embedding space. We show that deep clustering outperforms conventional networks on a singing voice separation task, in both matched and mismatched conditions, even though conventional networks have the advantage of end-to-end training for best signal approximation, presumably because its more flexible objective engenders better regularization. Since the strengths of deep clustering and conventional network architectures appear complementary, we explore combining them in a single hybrid network trained via an approach akin to multi-task learning. Remarkably, the combination significantly outperforms either of its components. version:1
arxiv-1611-06256 | GA3C: GPU-based A3C for Deep Reinforcement Learning | http://arxiv.org/abs/1611.06256 | id:1611.06256 author:Mohammad Babaeizadeh, Iuri Frosio, Stephen Tyree, Jason Clemons, Jan Kautz category:cs.LG  published:2016-11-18 summary:We introduce and analyze the computational aspects of a hybrid CPU/GPU implementation of the Asynchronous Advantage Actor-Critic (A3C) algorithm, currently the state-of-the-art method in reinforcement learning for various gaming tasks. Our analysis concentrates on the critical aspects to leverage the GPU's computational power, including the introduction of a system of queues and a dynamic scheduling strategy, potentially helpful for other asynchronous algorithms as well. We also show the potential for the use of larger DNN models on a GPU. Our TensorFlow implementation achieves a significant speed up compared to our CPU-only implementation, and it will be made publicly available to other researchers. version:1
arxiv-1611-06245 | Spikes as regularizers | http://arxiv.org/abs/1611.06245 | id:1611.06245 author:Anders Søgaard category:cs.NE cs.LG stat.ML  published:2016-11-18 summary:We present a confidence-based single-layer feed-forward learning algorithm SPIRAL (Spike Regularized Adaptive Learning) relying on an encoding of activation spikes. We adaptively update a weight vector relying on confidence estimates and activation offsets relative to previous activity. We regularize updates proportionally to item-level confidence and weight-specific support, loosely inspired by the observation from neurophysiology that high spike rates are sometimes accompanied by low temporal precision. Our experiments suggest that the new learning algorithm SPIRAL is more robust and less prone to overfitting than both the averaged perceptron and AROW. version:1
arxiv-1611-06241 | Using LSTM recurrent neural networks for detecting anomalous behavior of LHC superconducting magnets | http://arxiv.org/abs/1611.06241 | id:1611.06241 author:Maciej Wielgosz, Andrzej Skoczeń, Matej Mertik category:physics.ins-det cs.LG physics.acc-ph  published:2016-11-18 summary:The superconducting LHC magnets are coupled with an electronic monitoring system which records and analyses voltage time series reflecting their performance. A currently used system is based on a range of preprogrammed triggers which launches protection procedures when a misbehavior of the magnets is detected. All the procedures used in the protection equipment were designed and implemented according to known working scenarios of the system and are updated and monitored by human operators. This paper proposes a novel approach to monitoring and fault protection of the Large Hadron Collider (LHC) superconducting magnets which employs state-of-the-art Deep Learning algorithms. Consequently, the authors of the paper decided to examine the performance of LSTM recurrent neural networks for anomaly detection in voltage time series of the magnets. In order to address this challenging task different network architectures and hyper-parameters were used to achieve the best possible performance of the solution. The regression results were measured in terms of RMSE for different number of future steps and history length taken into account for the prediction. The best result of RMSE=0.00104 was obtained for a network of 128 LSTM cells within the internal layer and 16 steps history buffer. version:1
arxiv-1611-06224 | ModelHub: Towards Unified Data and Lifecycle Management for Deep Learning | http://arxiv.org/abs/1611.06224 | id:1611.06224 author:Hui Miao, Ang Li, Larry S. Davis, Amol Deshpande category:cs.DB cs.CV  published:2016-11-18 summary:Deep learning has improved state-of-the-art results in many important fields, and has been the subject of much research in recent years, leading to the development of several systems for facilitating deep learning. Current systems, however, mainly focus on model building and training phases, while the issues of data management, model sharing, and lifecycle management are largely ignored. Deep learning modeling lifecycle generates a rich set of data artifacts, such as learned parameters and training logs, and comprises of several frequently conducted tasks, e.g., to understand the model behaviors and to try out new models. Dealing with such artifacts and tasks is cumbersome and largely left to the users. This paper describes our vision and implementation of a data and lifecycle management system for deep learning. First, we generalize model exploration and model enumeration queries from commonly conducted tasks by deep learning modelers, and propose a high-level domain specific language (DSL), inspired by SQL, to raise the abstraction level and accelerate the modeling process. To manage the data artifacts, especially the large amount of checkpointed float parameters, we design a novel model versioning system (dlv), and a read-optimized parameter archival storage system (PAS) that minimizes storage footprint and accelerates query workloads without losing accuracy. PAS archives versioned models using deltas in a multi-resolution fashion by separately storing the less significant bits, and features a novel progressive query (inference) evaluation algorithm. Third, we show that archiving versioned models using deltas poses a new dataset versioning problem and we develop efficient algorithms for solving it. We conduct extensive experiments over several real datasets from computer vision domain to show the efficiency of the proposed techniques. version:1
arxiv-1611-06222 | Approximate Near Neighbors for General Symmetric Norms | http://arxiv.org/abs/1611.06222 | id:1611.06222 author:Alexandr Andoni, Aleksandar Nikolov, Ilya Razenshteyn, Erik Waingarten category:cs.DS cs.CG cs.LG math.MG  published:2016-11-18 summary:We show that every symmetric normed space admits an efficient nearest neighbor search data structure with doubly-logarithmic approximation. Specifically, for every $n$, $d = 2^{o\left(\frac{\log n}{\log \log n}\right)}$, and every $d$-dimensional symmetric norm $\ \cdot\ $, there exists a data structure for $\mathrm{poly}(\log \log n)$-approximate nearest neighbor search over $\ \cdot\ $ for $n$-point datasets achieving $n^{o(1)}$ query time and $n^{1+o(1)}$ space. The main technical ingredient of the algorithm is a low-distortion embedding of a symmetric norm into a low-dimensional iterated product of top-$k$ norms. We also show that our techniques cannot be extended to general norms. version:1
arxiv-1611-06221 | Structural Causal Models: Cycles, Marginalizations, Exogenous Reparametrizations and Reductions | http://arxiv.org/abs/1611.06221 | id:1611.06221 author:Stephan Bongers, Jonas Peters, Bernhard Schölkopf, Joris M. Mooij category:stat.ME cs.AI cs.LG  published:2016-11-18 summary:Structural causal models (SCMs), also known as non-parametric structural equation models (NP-SEMs), are widely used for causal modeling purposes. In this paper, we give a rigorous treatment of structural causal models, dealing with measure-theoretic complications that arise in the presence of cyclic relations. The central question studied in this paper is: given a (possibly cyclic) SCM defined on a large system (consisting of observable endogenous and latent exogenous variables), can we "project it down" to an SCM that describes a subsystem (consisting of a subset of the observed endogenous variables and possibly different latent exogenous variables) in order to obtain a more parsimonious but equivalent representation of the subsystem? We define a marginalization operation that effectively removes a subset of the endogenous variables from the model, and a class of mappings, exogenous reparameterizations, that can be used to reduce the space of exogenous variables. We show that both operations preserve the causal semantics of the model and that under mild conditions they can lead to a significant reduction of the model complexity, at least in terms of the number of variables in the model. We argue that for the task of estimating an SCM from data, the existence of "smooth" reductions would be desirable. We provide several conditions under which the existence of such reductions can be shown, but also provide a counterexample that shows that such reductions do not exist in general. The latter result implies that existing approaches to estimate linear or Markovian SCMs from data cannot be extended to general SCMs. version:1
arxiv-1611-06216 | Generative Deep Neural Networks for Dialogue: A Short Review | http://arxiv.org/abs/1611.06216 | id:1611.06216 author:Iulian Vlad Serban, Ryan Lowe, Laurent Charlin, Joelle Pineau category:cs.CL cs.AI cs.NE I.5.1; I.2.7  published:2016-11-18 summary:Researchers have recently started investigating deep neural networks for dialogue applications. In particular, generative sequence-to-sequence (Seq2Seq) models have shown promising results for unstructured tasks, such as word-level dialogue response generation. The hope is that such models will be able to leverage massive amounts of data to learn meaningful natural language representations and response generation strategies, while requiring a minimum amount of domain knowledge and hand-crafting. An important challenge is to develop models that can effectively incorporate dialogue context and generate meaningful and diverse responses. In support of this goal, we review recently proposed models based on generative encoder-decoder neural network architectures, and show that these models have better ability to incorporate long-term dialogue history, to model uncertainty and ambiguity in dialogue, and to generate responses with high-level compositional structure. version:1
arxiv-1611-06213 | GaDei: On Scale-up Training As A Service For Deep Learning | http://arxiv.org/abs/1611.06213 | id:1611.06213 author:Wei Zhang, Minwei Feng, Yunhui Zheng, Yufei Ren, Yandong Wang, Ji Liu, Peng Liu, Bing Xiang, Li Zhang, Bowen Zhou category:stat.ML cs.DC cs.LG  published:2016-11-18 summary:Deep learning (DL) training-as-a-service (TaaS) is an important emerging industrial workload. The unique challenge of TaaS is that it must satisfy a wide range of customers who have no experience and resources to tune DL hyper-parameters, and meticulous tuning for each user's dataset is prohibitively expensive. Therefore, TaaS hyper-parameters must be fixed with values that are applicable to all users. IBM Watson Natural Language Classifier (NLC) service, the most popular IBM cognitive service used by thousands of enterprise-level clients around the globe, is a typical TaaS service. By evaluating the NLC workloads, we show that only the conservative hyper-parameter setup (e.g., small mini-batch size and small learning rate) can guarantee acceptable model accuracy for a wide range of customers. We further justify theoretically why such a setup guarantees better model convergence in general. Unfortunately, the small mini-batch size causes a high volume of communication traffic in a parameter-server based system. We characterize the high communication bandwidth requirement of TaaS using representative industrial deep learning workloads and demonstrate that none of the state-of-the-art scale-up or scale-out solutions can satisfy such a requirement. We then present GaDei, an optimized shared-memory based scale-up parameter server design. We prove that the designed protocol is deadlock-free and it processes each gradient exactly once. Our implementation is evaluated on both commercial benchmarks and public benchmarks to demonstrate that it significantly outperforms the state-of-the-art parameter-server based implementation while maintaining the required accuracy and our implementation reaches near the best possible runtime performance, constrained only by the hardware limitation. Furthermore, to the best of our knowledge, GaDei is the only scale-up DL system that provides fault-tolerance. version:1
arxiv-1611-06211 | NoiseOut: A Simple Way to Prune Neural Networks | http://arxiv.org/abs/1611.06211 | id:1611.06211 author:Mohammad Babaeizadeh, Paris Smaragdis, Roy H. Campbell category:cs.NE cs.CV  published:2016-11-18 summary:Neural networks are usually over-parameterized with significant redundancy in the number of required neurons which results in unnecessary computation and memory usage at inference time. One common approach to address this issue is to prune these big networks by removing extra neurons and parameters while maintaining the accuracy. In this paper, we propose NoiseOut, a fully automated pruning algorithm based on the correlation between activations of neurons in the hidden layers. We prove that adding additional output neurons with entirely random targets results into a higher correlation between neurons which makes pruning by NoiseOut even more efficient. Finally, we test our method on various networks and datasets. These experiments exhibit high pruning rates while maintaining the accuracy of the original network. version:1
arxiv-1611-06204 | Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks | http://arxiv.org/abs/1611.06204 | id:1611.06204 author:Volkan Cirik, Eduard Hovy, Louis-Philippe Morency category:cs.CL cs.LG cs.NE  published:2016-11-18 summary:Curriculum Learning emphasizes the order of training instances in a computational learning setup. The core hypothesis is that simpler instances should be learned early as building blocks to learn more complex ones. Despite its usefulness, it is still unknown how exactly the internal representation of models are affected by curriculum learning. In this paper, we study the effect of curriculum learning on Long Short-Term Memory (LSTM) networks, which have shown strong competency in many Natural Language Processing (NLP) problems. Our experiments on sentiment analysis task and a synthetic task similar to sequence prediction tasks in NLP show that curriculum learning has a positive effect on the LSTM's internal states by biasing the model towards building constructive representations i.e. the internal representation at the previous timesteps are used as building blocks for the final prediction. We also find that smaller models significantly improves when they are trained with curriculum learning. Lastly, we show that curriculum learning helps more when the amount of training data is limited. version:1
arxiv-1611-06203 | Ear Recognition: More Than a Survey | http://arxiv.org/abs/1611.06203 | id:1611.06203 author:Žiga Emeršič, Vitomir Štruc, Peter Peer category:cs.CV  published:2016-11-18 summary:Automatic identity recognition from ear images represents an active field of research within the biometric community. The ability to capture ear images from a distance and in a covert manner makes the technology an appealing choice for surveillance and security applications as well as other application domains. Significant contributions have been made in the field over recent years, but open research problems still remain and hinder a wider (commercial) deployment of the technology. This paper presents an overview of the field of automatic ear recognition (from 2D images) and focuses specifically on the most recent, descriptor-based methods proposed in this area. Open challenges are discussed and potential research directions are outlined with the goal of providing the reader with a point of reference for issues worth examining in the future. In addition to a comprehensive review on ear recognition technology, the paper also introduces a new, fully unconstrained dataset of ear images gathered from the web and a toolbox implementing several state-of-the-art techniques for ear recognition. The dataset and toolbox are meant to address some of the open issues in the field and are made publicly available to the research community. version:1
arxiv-1611-06197 | An Empirical Study of Continuous Connectivity Degree Sequence Equivalents | http://arxiv.org/abs/1611.06197 | id:1611.06197 author:Daniel Moyer, Boris A. Gutman, Joshua Faskowitz, Neda Jahanshad, Paul M. Thompson category:q-bio.NC cs.NE  published:2016-11-18 summary:In the present work we demonstrate the use of a parcellation free connectivity model based on Poisson point processes. This model produces for each subject a continuous bivariate intensity function that represents for every possible pair of points the relative rate at which we observe tracts terminating at those points. We fit this model to explore degree sequence equivalents for spatial continuum graphs, and to investigate the local differences between estimated intensity functions for two different tractography methods. This is a companion paper to Moyer et al. (2016), where the model was originally defined. version:1
arxiv-1611-06194 | Expert Gate: Lifelong Learning with a Network of Experts | http://arxiv.org/abs/1611.06194 | id:1611.06194 author:Rahaf Aljundi, Punarjay Chakravarty, Tinne Tuytelaars category:cs.CV cs.AI stat.ML  published:2016-11-18 summary:In this paper we introduce a model of lifelong learning, based on a Network of Experts. New tasks / experts are learned and added to the model sequentially, building on what was learned before. To ensure scalability of this process, data from previous tasks cannot be stored and hence is not available when learning a new task. A critical issue in such context, not addressed in the literature so far, relates to the decision of which expert to deploy at test time. We introduce a gating autoencoder that learns a representation for the task at hand, and is used at test time to automatically forward the test sample to the relevant expert. This has the added advantage of being memory efficient as only one expert network has to be loaded into memory at any given time. Further, the autoencoders inherently capture the relatedness of one task to another, based on which the most relevant prior model to be used for training a new expert with fine-tuning or learning-without-forgetting can be selected. We evaluate our system on image classification and video prediction problems. version:1
arxiv-1611-06188 | Variable Computation in Recurrent Neural Networks | http://arxiv.org/abs/1611.06188 | id:1611.06188 author:Yacine Jernite, Edouard Grave, Armand Joulin, Tomas Mikolov category:stat.ML cs.AI cs.CL cs.LG  published:2016-11-18 summary:Recurrent neural networks (RNNs) have been used extensively and with increasing success to model various types of sequential data. Much of this progress has been achieved through devising recurrent units and architectures with the flexibility to capture complex statistics in the data, such as long range dependency or localized attention phenomena. However, while many sequential data (such as video, speech or language) can have highly variable information flow, most recurrent models still consume input features at a constant rate and perform a constant number of computations per time step, which can be detrimental to both speed and model capacity. In this paper, we explore a modification to existing recurrent units which allows them to learn to vary the amount of computation they perform at each step, without prior knowledge of the sequence's time structure. We show experimentally that not only is our model more computationally efficient, it also leads to better performance overall on our evaluation tasks. version:1
arxiv-1611-06179 | Exploring LOTS in Deep Neural Networks | http://arxiv.org/abs/1611.06179 | id:1611.06179 author:Andras Rozsa, Manuel Günther, Terrance E. Boult category:cs.CV  published:2016-11-18 summary:Deep neural networks have recently demonstrated excellent performance on various tasks. Despite recent advances, our understanding of these learning models is still incomplete, at least, as their unexpected vulnerability to imperceptibly small, non-random perturbations revealed. The existence of these so-called adversarial examples presents a serious problem of the application of vulnerable machine learning models. In this paper, we introduce the layerwise origin-target synthesis (LOTS) that can serve multiple purposes. First, we can use it as a visualization technique that gives us insights into the function of any intermediate feature layer by showing the notion of a particular input in deep neural networks. Second, our approach can be applied to assess the invariance of the learned features captured at any layer with respect to the class of the particular input. Finally, it can also be utilized as a general way for producing a vast amount of diverse adversarial examples that can be used for training to further improve the robustness of machine learning models and their performance as well. version:1
arxiv-1611-06175 | Learning Interpretability for Visualizations using Adapted Cox Models through a User Experiment | http://arxiv.org/abs/1611.06175 | id:1611.06175 author:Adrien Bibal, Benoit Frénay category:stat.ML cs.AI cs.HC cs.LG  published:2016-11-18 summary:In order to be useful, visualizations need to be interpretable. This paper uses a user-based approach to combine and assess quality measures in order to better model user preferences. Results show that cluster separability measures are outperformed by a neighborhood conservation measure, even though the former are usually considered as intuitively representative of user motives. Moreover, combining measures, as opposed to using a single measure, further improves prediction performances. version:1
arxiv-1611-06172 | Parallelizing Word2Vec in Multi-Core and Many-Core Architectures | http://arxiv.org/abs/1611.06172 | id:1611.06172 author:Shihao Ji, Nadathur Satish, Sheng Li, Pradeep Dubey category:cs.DC stat.ML  published:2016-11-18 summary:Word2vec is a widely used algorithm for extracting low-dimensional vector representations of words. State-of-the-art algorithms including those by Mikolov et al. have been parallelized for multi-core CPU architectures, but are based on vector-vector operations with "Hogwild" updates that are memory-bandwidth intensive and do not efficiently use computational resources. In this paper, we propose "HogBatch" by improving reuse of various data structures in the algorithm through the use of minibatching and negative sample sharing, hence allowing us to express the problem using matrix multiply operations. We also explore different techniques to distribute word2vec computation across nodes in a compute cluster, and demonstrate good strong scalability up to 32 nodes. The new algorithm is particularly suitable for modern multi-core/many-core architectures, especially Intel's latest Knights Landing processors, and allows us to scale up the computation near linearly across cores and nodes, and process hundreds of millions of words per second, which is the fastest word2vec implementation to the best of our knowledge. version:1
arxiv-1611-06159 | End-to-End Subtitle Detection and Recognition for Videos in East Asian Languages via CNN Ensemble with Near-Human-Level Performance | http://arxiv.org/abs/1611.06159 | id:1611.06159 author:Yan Xu, Siyuan Shan, Ziming Qiu, Zhipeng Jia, Zhengyang Shen, Yipei Wang, Mengfei Shi, Eric I-Chao Chang category:cs.CV  published:2016-11-18 summary:In this paper, we propose an innovative end-to-end subtitle detection and recognition system for videos in East Asian languages. Our end-to-end system consists of multiple stages. Subtitles are firstly detected by a novel image operator based on the sequence information of consecutive video frames. Then, an ensemble of Convolutional Neural Networks (CNNs) trained on synthetic data is adopted for detecting and recognizing East Asian characters. Finally, a dynamic programming approach leveraging language models is applied to constitute results of the entire body of text lines. The proposed system achieves average end-to-end accuracies of 98.2% and 98.3% on 40 videos in Simplified Chinese and 40 videos in Traditional Chinese respectively, which is a significant outperformance of other existing methods. The near-perfect accuracy of our system dramatically narrows the gap between human cognitive ability and state-of-the-art algorithms used for such a task. version:1
arxiv-1611-06158 | AFFACT - Alignment Free Facial Attribute Classification Technique | http://arxiv.org/abs/1611.06158 | id:1611.06158 author:Manuel Günther, Andras Rozsa, Terrance E. Boult category:cs.CV  published:2016-11-18 summary:In this paper, we investigate how the latest versions of deep convolutional neural networks perform on the facial attribute classification task. We test two loss functions to train the neural networks: the sigmoid cross-entropy loss usually used in multi-objective classification tasks, and the Euclidean loss normally applied to regression problems, and find that there is little difference between these two loss functions. Rather, more attention should be paid on pre-training the network with external data, the learning rate policy and the evaluation technique. Using an ensemble of three ResNets, we obtain the new state-of-the-art facial attribute classification error of 8.00% on the aligned images of the CelebA dataset. More significantly, we introduce a novel data augmentation technique allowing to train the AFFACT network that classifies facial attributes without requiring alignment, but works solely on detected face bounding boxes. We show that this approach outperforms the CelebA baseline, which did not use any face alignment either, with a relative improvement of 34%. version:1
arxiv-1611-06148 | Compacting Neural Network Classifiers via Dropout Training | http://arxiv.org/abs/1611.06148 | id:1611.06148 author:Yotaro Kubo, George Tucker, Simon Wiesler category:stat.ML cs.LG cs.NE  published:2016-11-18 summary:We introduce dropout compaction, a novel method for training feed-forward neural networks which realizes the performance gains of training a large model with dropout regularization, yet extracts a compact neural network for run-time efficiency. In the proposed method, we introduce a sparsity-inducing prior on the per unit dropout retention probability so that the optimizer can effectively prune hidden units during training. By changing the prior hyperparameters, we can control the size of the resulting network. We performed a systematic comparison of dropout compaction and competing methods on several real-world speech recognition tasks and found that dropout compaction achieved comparable accuracy with fewer than 50% of the hidden units, translating to a 2.5x speedup in run-time. version:1
arxiv-1611-06132 | Faster variational inducing input Gaussian process classification | http://arxiv.org/abs/1611.06132 | id:1611.06132 author:Pavel Izmailov, Dmitry Kropotov category:cs.LG cs.AI stat.ML  published:2016-11-18 summary:Gaussian processes (GP) provide a prior over functions and allow finding complex regularities in data. Gaussian processes are successfully used for classification/regression problems and dimensionality reduction. In this work we consider the classification problem only. The complexity of standard methods for GP-classification scales cubically with the size of the training dataset. This complexity makes them inapplicable to big data problems. Therefore, a variety of methods were introduced to overcome this limitation. In the paper we focus on methods based on so called inducing inputs. This approach is based on variational inference and proposes a particular lower bound for marginal likelihood (evidence). This bound is then maximized w.r.t. parameters of kernel function of the Gaussian process, thus fitting the model to data. The computational complexity of this method is $O(nm^2)$, where $m$ is the number of inducing inputs used by the model and is assumed to be substantially smaller than the size of the dataset $n$. Recently, a new evidence lower bound for GP-classification problem was introduced. It allows using stochastic optimization, which makes it suitable for big data problems. However, the new lower bound depends on $O(m^2)$ variational parameter, which makes optimization challenging in case of big m. In this work we develop a new approach for training inducing input GP models for classification problems. Here we use quadratic approximation of several terms in the aforementioned evidence lower bound, obtaining analytical expressions for optimal values of most of the parameters in the optimization, thus sufficiently reducing the dimension of optimization space. In our experiments we achieve as well or better results, compared to the existing method. Moreover, our method doesn't require the user to manually set the learning rate, making it more practical, than the existing method. version:1
arxiv-1611-06115 | Fast low-level pattern matching algorithm | http://arxiv.org/abs/1611.06115 | id:1611.06115 author:Janja Paliska Soldo, Ana Sovic Krzic, and Damir Sersic category:cs.CV cs.DC q-bio.GN  published:2016-11-18 summary:This paper focuses on pattern matching in the DNA sequence. It was inspired by a previously reported method that proposes encoding both pattern and sequence using prime numbers. Although fast, the method is limited to rather small pattern lengths, due to computing precision problem. Our approach successfully deals with large patterns, due to our implementation that uses modular arithmetic. In order to get the results very fast, the code was adapted for multithreading and parallel implementations. The method is reduced to assembly language level instructions, thus the final result shows significant time and memory savings compared to the reference algorithm. version:1
arxiv-1611-06094 | Generalizing diffuse interface methods on graphs: non-smooth potentials and hypergraphs | http://arxiv.org/abs/1611.06094 | id:1611.06094 author:Jessica Bosch, Steffen Klamt, Martin Stoll category:stat.ML math.NA  published:2016-11-18 summary:Diffuse interface methods have recently been introduced for the task of semi-supervised learning. The underlying model is well-known in materials science but was extended to graphs using a Ginzburg--Landau functional and the graph Laplacian. We here generalize the previously proposed model by a non-smooth potential function. Additionally, we show that the diffuse interface method can be used for the segmentation of data coming from hypergraphs. For this we show that the graph Laplacian in almost all cases is derived from hypergraph information. Additionally, we show that the formerly introduced hypergraph Laplacian coming from a relaxed optimization problem is well suited to be used within the diffuse interface method. We present computational experiments for graph and hypergraph Laplacians. version:1
arxiv-1611-06080 | A Generalized Stochastic Variational Bayesian Hyperparameter Learning Framework for Sparse Spectrum Gaussian Process Regression | http://arxiv.org/abs/1611.06080 | id:1611.06080 author:Quang Minh Hoang, Trong Nghia Hoang, Kian Hsiang Low category:stat.ML cs.LG  published:2016-11-18 summary:While much research effort has been dedicated to scaling up sparse Gaussian process (GP) models based on inducing variables for big data, little attention is afforded to the other less explored class of low-rank GP approximations that exploit the sparse spectral representation of a GP kernel. This paper presents such an effort to advance the state of the art of sparse spectrum GP models to achieve competitive predictive performance for massive datasets. Our generalized framework of stochastic variational Bayesian sparse spectrum GP (sVBSSGP) models addresses their shortcomings by adopting a Bayesian treatment of the spectral frequencies to avoid overfitting, modeling these frequencies jointly in its variational distribution to enable their interaction a posteriori, and exploiting local data for boosting the predictive performance. However, such structural improvements result in a variational lower bound that is intractable to be optimized. To resolve this, we exploit a variational parameterization trick to make it amenable to stochastic optimization. Interestingly, the resulting stochastic gradient has a linearly decomposable structure that can be exploited to refine our stochastic optimization method to incur constant time per iteration while preserving its property of being an unbiased estimator of the exact gradient of the variational lower bound. Empirical evaluation on real-world datasets shows that sVBSSGP outperforms state-of-the-art stochastic implementations of sparse GP models. version:1
arxiv-1611-06069 | DeepVO: A Deep Learning approach for Monocular Visual Odometry | http://arxiv.org/abs/1611.06069 | id:1611.06069 author:Vikram Mohanty, Shubh Agrawal, Shaswat Datta, Arna Ghosh, Vishnu Dutt Sharma, Debashish Chakravarty category:cs.CV  published:2016-11-18 summary:Deep Learning based techniques have been adopted with precision to solve a lot of standard computer vision problems, some of which are image classification, object detection and segmentation. Despite the widespread success of these approaches, they have not yet been exploited largely for solving the standard perception related problems encountered in autonomous navigation such as Visual Odometry (VO), Structure from Motion (SfM) and Simultaneous Localization and Mapping (SLAM). This paper analyzes the problem of Monocular Visual Odometry using a Deep Learning-based framework, instead of the regular 'feature detection and tracking' pipeline approaches. Several experiments were performed to understand the influence of a known/unknown environment, a conventional trackable feature and pre-trained activations tuned for object classification on the network's ability to accurately estimate the motion trajectory of the camera (or the vehicle). Based on these observations, we propose a Convolutional Neural Network architecture, best suited for estimating the object's pose under known environment conditions, and displays promising results when it comes to inferring the actual scale using just a single camera in real-time. version:1
arxiv-1611-06067 | An End-to-End Spatio-Temporal Attention Model for Human Action Recognition from Skeleton Data | http://arxiv.org/abs/1611.06067 | id:1611.06067 author:Sijie Song, Cuiling Lan, Junliang Xing, Wenjun Zeng, Jiaying Liu category:cs.CV  published:2016-11-18 summary:Human action recognition is an important task in computer vision. Extracting discriminative spatial and temporal features to model the spatial and temporal evolutions of different actions plays a key role in accomplishing this task. In this work, we propose an end-to-end spatial and temporal attention model for human action recognition from skeleton data. We build our model on top of the Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM), which learns to selectively focus on discriminative joints of skeleton within each frame of the inputs and pays different levels of attention to the outputs of different frames. Furthermore, to ensure effective training of the network, we propose a regularized cross-entropy loss to drive the model learning process and develop a joint training strategy accordingly. Experimental results demonstrate the effectiveness of the proposed model,both on the small human action recognition data set of SBU and the currently largest NTU dataset. version:1
arxiv-1611-06066 | Deriving reproducible biomarkers from multi-site resting-state data: An Autism-based example | http://arxiv.org/abs/1611.06066 | id:1611.06066 author:Alexandre Abraham, Michael Milham, Adriana Di Martino, R. Cameron Craddock, Dimitris Samaras, Bertrand Thirion, Gaël Varoquaux category:stat.ML q-bio.NC  published:2016-11-18 summary:Resting-state functional Magnetic Resonance Imaging (R-fMRI) holds the promise to reveal functional biomarkers of neuropsychiatric disorders. However, extracting such biomarkers is challenging for complex multi-faceted neuropatholo-gies, such as autism spectrum disorders. Large multi-site datasets increase sample sizes to compensate for this complexity, at the cost of uncontrolled heterogeneity. This heterogeneity raises new challenges, akin to those face in realistic diagnostic applications. Here, we demonstrate the feasibility of inter-site classification of neuropsychiatric status, with an application to the Autism Brain Imaging Data Exchange (ABIDE) database, a large (N=871) multi-site autism dataset. For this purpose, we investigate pipelines that extract the most predictive biomarkers from the data. These R-fMRI pipelines build participant-specific connectomes from functionally-defined brain areas. Connectomes are then compared across participants to learn patterns of connectivity that differentiate typical controls from individuals with autism. We predict this neuropsychiatric status for participants from the same acquisition sites or different, unseen, ones. Good choices of methods for the various steps of the pipeline lead to 67% prediction accuracy on the full ABIDE data, which is significantly better than previously reported results. We perform extensive validation on multiple subsets of the data defined by different inclusion criteria. These enables detailed analysis of the factors contributing to successful connectome-based prediction. First, prediction accuracy improves as we include more subjects, up to the maximum amount of subjects available. Second, the definition of functional brain areas is of paramount importance for biomarker discovery: brain areas extracted from large R-fMRI datasets outperform reference atlases in the classification tasks. version:1
arxiv-1611-06026 | Cross Domain Knowledge Transfer for Person Re-identification | http://arxiv.org/abs/1611.06026 | id:1611.06026 author:Qiqi Xiao, Kelei Cao, Haonan Chen, Fangyue Peng, Chi Zhang category:cs.CV  published:2016-11-18 summary:Person Re-Identification (re-id) is a challenging task in computer vision, especially when there are limited training data from multiple camera views. In this paper, we pro- pose a deep learning based person re-identification method by transferring knowledge of mid-level attribute features and high-level classification features. Building on the idea that identity classification, attribute recognition and re- identification share the same mid-level semantic representations, they can be trained sequentially by fine-tuning one based on another. In our framework, we train identity classification and attribute recognition tasks from deep Convolutional Neural Network (dCNN) to learn person information. The information can be transferred to the person re-id task and improves its accuracy by a large margin. Further- more, a Long Short Term Memory(LSTM) based Recurrent Neural Network (RNN) component is extended by a spacial gate. This component is used in the re-id model to pay attention to certain spacial parts in each recurrent unit. Experimental results show that our method achieves 78.3% of rank-1 recognition accuracy on the CUHK03 benchmark. version:1
arxiv-1611-06013 | Improving training of deep neural networks via Singular Value Bounding | http://arxiv.org/abs/1611.06013 | id:1611.06013 author:Kui Jia category:cs.CV  published:2016-11-18 summary:Deep learning methods achieve great success recently on many computer vision problems, with image classification and object detection as the prominent examples. In spite of these practical successes, optimization of deep networks remains an active topic in deep learning research. In this work, we focus on investigation of the network solution properties that can potentially lead to good performance. Our research is inspired by theoretical and empirical results that use orthogonal matrices to initialize networks, but we are interested in investigating how orthogonal weight matrices perform when network training converges. To this end, we propose to constrain the solutions of weight matrices in the orthogonal feasible set during the whole process of network training, and achieve this by a simple yet effective method called Singular Value Bounding (SVB). In SVB, all singular values of each weight matrix are simply bounded in a narrow band around the value of 1. Based on the same motivation, we also propose Bounded Batch Normalization (BBN), which improves Batch Normalization by removing its potential risk of ill-conditioned layer transform. We present both theoretical and empirical results to justify our proposed methods. Experiments on benchmark image classification datasets show the efficacy of our proposed SVB and BBN. In particular, we reach the level of state-of-the-art results on CIFAR10 and set the new record on CIFAR100, using off-the-shelf network architectures. version:1
arxiv-1611-06011 | Online Visual Multi-Object Tracking via Labeled Random Finite Set Filtering | http://arxiv.org/abs/1611.06011 | id:1611.06011 author:Du Yong Kim, Ba-Ngu Vo, Ba-Tuong Vo category:cs.CV  published:2016-11-18 summary:This paper proposes an online visual multi-object tracking algorithm using a top-down Bayesian formulation that seamlessly integrates state estimation, track management, clutter rejection, occlusion and mis-detection handling into a single recursion. This is achieved by modeling the multi-object state as labeled random finite set and using the Bayes recursion to propagate the multi-object filtering density forward in time. The proposed filter updates tracks with detections but switches to image data when mis-detection occurs, thereby exploiting the efficiency of detection data and the accuracy of image data. Furthermore the labeled random finite set framework enables the incorporation of prior knowledge that mis-detections of long tracks which occur in the middle of the scene are likely to be due to occlusions. Such prior knowledge can be exploited to improve occlusion handling, especially long occlusions that can lead to premature track termination in on-line multi-object tracking. Tracking performance are compared to state-of-the-art algorithms on well-known benchmark video datasets. version:1
arxiv-1611-06009 | Fuzzy Statistical Matrices for Cell Classification | http://arxiv.org/abs/1611.06009 | id:1611.06009 author:Guillaume Thibault, Izhak Shafran category:cs.CV  published:2016-11-18 summary:In this paper, we generalize image (texture) statistical descriptors and propose algorithms that improve their efficacy. Recently, a new method showed how the popular Co-Occurrence Matrix (COM) can be modified into a fuzzy version (FCOM) which is more effective and robust to noise. Here, we introduce new fuzzy versions of two additional higher order statistical matrices: the Run Length Matrix (RLM) and the Size Zone Matrix (SZM). We define the fuzzy zones and propose an efficient algorithm to compute the descriptors. We demonstrate the advantage of the proposed improvements over several state-of-the-art methods on three tasks from quantitative cell biology: analyzing and classifying Human Epithelial type 2 (HEp-2) cells using Indirect Immunofluorescence protocol (IFF). version:1
arxiv-1611-05990 | Monte Carlo Connection Prover | http://arxiv.org/abs/1611.05990 | id:1611.05990 author:Michael Färber, Cezary Kaliszyk, Josef Urban category:cs.LO cs.AI cs.LG  published:2016-11-18 summary:Monte Carlo Tree Search (MCTS) is a technique to guide search in a large decision space by taking random samples and evaluating their outcome. In this work, we study MCTS methods in the context of the connection calculus and implement them on top of the leanCoP prover. This includes proposing useful proof-state evaluation heuristics that are learned from previous proofs, and proposing and automatically improving suitable MCTS strategies in this context. The system is trained and evaluated on a large suite of related problems coming from the Mizar proof assistant, showing that it is capable to find new and different proofs. To our knowledge, this is the first time MCTS has been applied to theorem proving. version:1
arxiv-1611-05977 | Robust and Scalable Column/Row Sampling from Corrupted Big Data | http://arxiv.org/abs/1611.05977 | id:1611.05977 author:Mostafa Rahmani, George Atia category:cs.LG cs.NA stat.AP stat.ML  published:2016-11-18 summary:Conventional sampling techniques fall short of drawing descriptive sketches of the data when the data is grossly corrupted as such corruptions break the low rank structure required for them to perform satisfactorily. In this paper, we present new sampling algorithms which can locate the informative columns in presence of severe data corruptions. In addition, we develop new scalable randomized designs of the proposed algorithms. The proposed approach is simultaneously robust to sparse corruption and outliers and substantially outperforms the state-of-the-art robust sampling algorithms as demonstrated by experiments conducted using both real and synthetic data. version:1
arxiv-1611-05971 | To Find the Symmetry Plane in Any Dimension, Reflect, Register, and Compute a -1 Eigenvector | http://arxiv.org/abs/1611.05971 | id:1611.05971 author:Marcelo Cicconet, David G. C. Hildebrand, Hunter Elliott category:cs.CV  published:2016-11-18 summary:In this paper, we demonstrate that the problem of fitting a plane of reflection symmetry to data in any dimension can be reduced to the problem of registering two datasets, and that the exactness of the solution depends on the accuracy of the registration. The pipeline for symmetry plane detection consists of (1) reflecting the data with respect to an arbitrary plane, (2) registering the original and reflected datasets, and (3) finding the eigenvector of eigenvalue -1 of a matrix given by the reflection and registration mappings. Results are shown for 2D and 3D datasets. We discuss in detail a particular biological application in which we study the 3D symmetry of manual myelinated neuron reconstructions throughout the body of a larval zebrafish that were extracted from serial-section electron micrographs. The data consists of curves that are represented as sequences of points in 3D, and there are two goals: first, find the plane of mirror symmetry given that the neuron reconstructions are nearly symmetric; second, find pairings of symmetric curves. version:1
arxiv-1611-05964 | Reweighted Low-Rank Tensor Completion and its Applications in Video Recovery | http://arxiv.org/abs/1611.05964 | id:1611.05964 author:Baburaj M., Sudhish N. George category:cs.CV  published:2016-11-18 summary:This paper focus on recovering multi-dimensional data called tensor from randomly corrupted incomplete observation. Inspired by reweighted $l_1$ norm minimization for sparsity enhancement, this paper proposes a reweighted singular value enhancement scheme to improve tensor low tubular rank in the tensor completion process. An efficient iterative decomposition scheme based on t-SVD is proposed which improves low-rank signal recovery significantly. The effectiveness of the proposed method is established by applying to video completion problem, and experimental results reveal that the algorithm outperforms its counterparts. version:1
arxiv-1611-05963 | Reweighted Low-Rank Tensor Decomposition and its Applications in Video Denoising | http://arxiv.org/abs/1611.05963 | id:1611.05963 author:Baburaj M., Sudhish N. George category:cs.CV cs.NA  published:2016-11-18 summary:A tensor is decomposed into low-rank and sparse components by simultaneously minimizing tensor nuclear norm and the $l_1$ norm in Tensor Principal Component Pursuit (TPCP). Inspired by reweighted $l_1$ norm minimization for sparsity enhancement, this paper proposes a reweighted singular value enhancement scheme to improve tensor low tubular rank in TPCP. The sparse component of a tensor is also recovered by the reweighted $l_1$ norm which enhances the accuracy of decomposition. An efficient iterative decomposition scheme based on t-SVD is proposed which improves low-rank signal recovery significantly. The effectiveness of the proposed method is established by applying to video denoising problem, and experimental results reveal that the algorithm outperforms its counterparts. version:1
arxiv-1611-05962 | Word and Document Embeddings based on Neural Network Approaches | http://arxiv.org/abs/1611.05962 | id:1611.05962 author:Siwei Lai category:cs.CL  published:2016-11-18 summary:Data representation is a fundamental task in machine learning. The representation of data affects the performance of the whole machine learning system. In a long history, the representation of data is done by feature engineering, and researchers aim at designing better features for specific tasks. Recently, the rapid development of deep learning and representation learning has brought new inspiration to various domains. In natural language processing, the most widely used feature representation is the Bag-of-Words model. This model has the data sparsity problem and cannot keep the word order information. Other features such as part-of-speech tagging or more complex syntax features can only fit for specific tasks in most cases. This thesis focuses on word representation and document representation. We compare the existing systems and present our new model. First, for generating word embeddings, we make comprehensive comparisons among existing word embedding models. In terms of theory, we figure out the relationship between the two most important models, i.e., Skip-gram and GloVe. In our experiments, we analyze three key points in generating word embeddings, including the model construction, the training corpus and parameter design. We evaluate word embeddings with three types of tasks, and we argue that they cover the existing use of word embeddings. Through theory and practical experiments, we present some guidelines for how to generate a good word embedding. Second, in Chinese character or word representation. We introduce the joint training of Chinese character and word. ... Third, for document representation, we analyze the existing document representation models, including recursive NNs, recurrent NNs and convolutional NNs. We point out the drawbacks of these models and present our new model, the recurrent convolutional neural networks. ... version:1
arxiv-1611-05955 | A Characterization of Prediction Errors | http://arxiv.org/abs/1611.05955 | id:1611.05955 author:Christopher Meek category:cs.LG  published:2016-11-18 summary:Understanding prediction errors and determining how to fix them is critical to building effective predictive systems. In this paper, we delineate four types of prediction errors and demonstrate that these four types characterize all prediction errors. In addition, we describe potential remedies and tools that can be used to reduce the uncertainty when trying to determine the source of a prediction error and when trying to take action to remove a prediction errors. version:1
arxiv-1611-06953 | Associative Adversarial Networks | http://arxiv.org/abs/1611.06953 | id:1611.06953 author:Tarik Arici, Asli Celikyilmaz category:cs.LG cs.AI  published:2016-11-18 summary:We propose a higher-level associative memory for learning adversarial networks. Generative adversarial network (GAN) framework has a discriminator and a generator network. The generator (G) maps white noise (z) to data samples while the discriminator (D) maps data samples to a single scalar. To do so, G learns how to map from high-level representation space to data space, and D learns to do the opposite. We argue that higher-level representation spaces need not necessarily follow a uniform probability distribution. In this work, we use Restricted Boltzmann Machines (RBMs) as a higher-level associative memory and learn the probability distribution for the high-level features generated by D. The associative memory samples its underlying probability distribution and G learns how to map these samples to data space. The proposed associative adversarial networks (AANs) are generative models in the higher-levels of the learning, and use adversarial non-stochastic models D and G for learning the mapping between data and higher-level representation spaces. Experiments show the potential of the proposed networks. version:1
arxiv-1611-05950 | Analysis of a Design Pattern for Teaching with Features and Labels | http://arxiv.org/abs/1611.05950 | id:1611.05950 author:Christopher Meek, Patrice Simard, Xiaojin Zhu category:cs.AI cs.LG  published:2016-11-18 summary:We study the task of teaching a machine to classify objects using features and labels. We introduce the Error-Driven-Featuring design pattern for teaching using features and labels in which a teacher prefers to introduce features only if they are needed. We analyze the potential risks and benefits of this teaching pattern through the use of teaching protocols, illustrative examples, and by providing bounds on the effort required for an optimal machine teacher using a linear learning algorithm, the most commonly used type of learners in interactive machine learning systems. Our analysis provides a deeper understanding of potential trade-offs of using different learning algorithms and between the effort required for featuring (creating new features) and labeling (providing labels for objects). version:1
arxiv-1611-05947 | Minimal Problems for the Calibrated Trifocal Variety | http://arxiv.org/abs/1611.05947 | id:1611.05947 author:Joe Kileel category:math.AG cs.CV math.NA  published:2016-11-18 summary:We determine the algebraic degree of minimal problems for the calibrated trifocal variety in computer vision. We rely on numerical algebraic geometry and the homotopy continuation software Bertini. version:1
arxiv-1611-05520 | Deep Action- and Context-Aware Sequence Learning for Activity Recognition and Anticipation | http://arxiv.org/abs/1611.05520 | id:1611.05520 author:Mohammad Sadegh Aliakbarian, Fatemehsadat Saleh, Basura Fernando, Mathieu Salzmann, Lars Petersson, Lars Andersson category:cs.CV  published:2016-11-17 summary:Action recognition and anticipation are key to the success of many computer vision applications. Existing methods can roughly be grouped into those that extract global, context-aware representations of the entire image or sequence, and those that aim at focusing on the regions where the action occurs. While the former may suffer from the fact that context is not always reliable, the latter completely ignore this source of information, which can nonetheless be helpful in many situations. In this paper, we aim at making the best of both worlds by developing an approach that leverages both context-aware and action-aware features. At the core of our method lies a novel multi-stage recurrent architecture that allows us to effectively combine these two sources of information throughout a video. This architecture first exploits the global, context-aware features, and merges the resulting representation with the localized, action-aware ones. Our experiments on standard datasets evidence the benefits of our approach over methods that use each information type separately. We outperform the state-of-the-art methods that, as us, rely only on RGB frames as input for both action recognition and anticipation. version:2
arxiv-1611-05940 | Finding Alternate Features in Lasso | http://arxiv.org/abs/1611.05940 | id:1611.05940 author:Satoshi Hara, Takanori Maehara category:stat.ML  published:2016-11-18 summary:We propose a method for finding alternate features missing in the Lasso optimal solution. In ordinary Lasso problem, one global optimum is obtained and the resulting features are interpreted as task-relevant features. However, this can overlook possibly relevant features not selected by the Lasso. With the proposed method, we can provide not only the Lasso optimal solution but also possible alternate features to the Lasso solution. We show that such alternate features can be computed efficiently by avoiding redundant computations. We also demonstrate how the proposed method works in the 20 newsgroup data, which shows that reasonable features are found as alternate features. version:1
arxiv-1611-05939 | SC-DCNN: Highly-Scalable Deep Convolutional Neural Network using Stochastic Computing | http://arxiv.org/abs/1611.05939 | id:1611.05939 author:Ao Ren, Ji Li, Zhe Li, Caiwen Ding, Xuehai Qian, Qinru Qiu, Bo Yuan, Yanzhi Wang category:cs.CV  published:2016-11-18 summary:With recent advancing of Internet of Things (IoTs), it becomes very attractive to implement the deep convolutional neural networks (DCNNs) onto embedded/portable systems. Presently, executing the software-based DCNNs requires high-performance server clusters in practice, restricting their widespread deployment on the mobile devices. To overcome this issue, considerable research efforts have been conducted in the context of developing highly-parallel and specific DCNN hardware, utilizing GPGPUs, FPGAs, and ASICs. Stochastic Computing (SC), which uses bit-stream to represent a number within [-1, 1] by counting the number of ones in the bit-stream, has a high potential for implementing DCNNs with high scalability and ultra-low hardware footprint. Since multiplications and additions can be calculated using AND gates and multiplexers in SC, significant reductions in power/energy and hardware footprint can be achieved compared to the conventional binary arithmetic implementations. The tremendous savings in power (energy) and hardware resources bring about immense design space for enhancing scalability and robustness for hardware DCNNs. This paper presents the first comprehensive design and optimization framework of SC-based DCNNs (SC-DCNNs). We first present the optimal designs of function blocks that perform the basic operations, i.e., inner product, pooling, and activation function. Then we propose the optimal design of four types of combinations of basic function blocks, named feature extraction blocks, which are in charge of extracting features from input feature maps. Besides, weight storage methods are investigated to reduce the area and power/energy consumption for storing weights. Finally, the whole SC-DCNN implementation is optimized, with feature extraction blocks carefully selected, to minimize area and power/energy consumption while maintaining a high network accuracy level. version:1
arxiv-1611-05934 | Increasing the Interpretability of Recurrent Neural Networks Using Hidden Markov Models | http://arxiv.org/abs/1611.05934 | id:1611.05934 author:Viktoriya Krakovna, Finale Doshi-Velez category:stat.ML cs.LG  published:2016-11-18 summary:As deep neural networks continue to revolutionize various application domains, there is increasing interest in making these powerful models more understandable and interpretable, and narrowing down the causes of good and bad predictions. We focus on recurrent neural networks, state of the art models in speech recognition and translation. Our approach to increasing interpretability is by combining a long short-term memory (LSTM) model with a hidden Markov model (HMM), a simpler and more transparent model. We add the HMM state probabilities to the output layer of the LSTM, and then train the HMM and LSTM either sequentially or jointly. The LSTM can make use of the information from the HMM, and fill in the gaps when the HMM is not performing well. A small hybrid model usually performs better than a standalone LSTM of the same size, especially on smaller data sets. We test the algorithms on text data and medical time series data, and find that the LSTM and HMM learn complementary information about the features in the text. version:1
arxiv-1611-05162 | Net-Trim: A Layer-wise Convex Pruning of Deep Neural Networks | http://arxiv.org/abs/1611.05162 | id:1611.05162 author:Alireza Aghasi, Nam Nguyen, Justin Romberg category:cs.LG stat.ML  published:2016-11-16 summary:Model reduction is a highly desirable process for deep neural networks. While large networks are theoretically capable of learning arbitrarily complex models, overfitting and model redundancy negatively affects the prediction accuracy and model variance. Net-Trim is a layer-wise convex framework to prune (sparsify) deep neural networks. The method is applicable to neural networks operating with the rectified linear unit (ReLU) as the nonlinear activation. The basic idea is to retrain the network layer by layer keeping the layer inputs and outputs close to the originally trained model, while seeking a sparse transform matrix. We present both the parallel and cascade versions of the algorithm. While the former enjoys computational distributability, the latter is capable of achieving simpler models. In both cases, we mathematically show a consistency between the retrained model and the initial trained network. We also derive the general sufficient conditions for the recovery of a sparse transform matrix. In the case of standard Gaussian training samples of dimension $N$ being fed to a layer, and $s$ being the maximum number of nonzero terms across all columns of the transform matrix, we show that $\mathcal{O}(s\log N)$ samples are enough to accurately learn the layer model. version:2
arxiv-1611-05927 | Generalized BackPropagation, Étude De Cas: Orthogonality | http://arxiv.org/abs/1611.05927 | id:1611.05927 author:Mehrtash Harandi, Basura Fernando category:cs.CV  published:2016-11-17 summary:This paper introduces an extension of the backpropagation algorithm that enables us to have layers with constrained weights in a deep network. In particular, we make use of the Riemannian geometry and optimization techniques on matrix manifolds to step outside of normal practice in training deep networks, equipping the network with structures such as orthogonality or positive definiteness. Based on our development, we make another contribution by introducing the Stiefel layer, a layer with orthogonal weights. Among various applications, Stiefel layers can be used to design orthogonal filter banks, perform dimensionality reduction and feature extraction. We demonstrate the benefits of having orthogonality in deep networks through a broad set of experiments, ranging from unsupervised feature learning to fine-grained image classification. version:1
arxiv-1611-05923 | "Influence Sketching": Finding Influential Samples In Large-Scale Regressions | http://arxiv.org/abs/1611.05923 | id:1611.05923 author:Mike Wojnowicz, Ben Cruz, Xuan Zhao, Brian Wallace, Matt Wolff, Jay Luan, Caleb Crable category:stat.ML cs.LG  published:2016-11-17 summary:There is an especially strong need in modern large-scale data analysis to prioritize samples for manual inspection. For example, the inspection could target important mislabeled samples or key vulnerabilities exploitable by an adversarial attack. In order to solve the "needle in the haystack" problem of which samples to inspect, we develop a new scalable version of Cook's distance, a classical statistical technique for identifying samples which unusually strongly impact the fit of a regression model (and its downstream predictions). In order to scale this technique up to very large and high-dimensional datasets, we introduce a new algorithm which we call "influence sketching." Influence sketching embeds random projections within the influence computation; in particular, the influence score is calculated using the randomly projected pseudo-dataset from the post-convergence General Linear Model (GLM). We validate that influence sketching can reliably and successfully discover influential samples by applying the technique to a malware detection dataset of over 2 million executable files, each represented with almost 100,000 features. For example, we find that randomly deleting approximately 10% of training samples reduces predictive accuracy only slightly from 99.47% to 99.45%, whereas deleting the same number of samples with high influence sketch scores reduces predictive accuracy all the way down to 90.24%. Moreover, we find that influential samples are especially likely to be mislabeled. In the case study, we manually inspect the most influential samples, and find that influence sketching pointed us to new, previously unidentified pieces of malware. version:1
arxiv-1611-05915 | Generative One-Class Models for Text-based Person Retrieval in Forensic Applications | http://arxiv.org/abs/1611.05915 | id:1611.05915 author:David Gerónimo, Hedvig Kjellström category:cs.CV  published:2016-11-17 summary:Automatic forensic image analysis assists criminal investigation experts in the search for suspicious persons, abnormal behaviors detection and identity matching in images. In this paper we propose a person retrieval system that uses textual queries (e.g., "black trousers and green shirt") as descriptions and a one-class generative color model with outlier filtering to represent the images both to train the models and to perform the search. The method is evaluated in terms of its efficiency in fulfilling the needs of a forensic retrieval system: limited annotation, robustness, extensibility, adaptability and computational cost. The proposed generative method is compared to a corresponding discriminative approach. Experiments are carried out using a range of queries in three different databases. The experiments show that the two evaluated algorithms provide average retrieval performance and adaptable to new datasets. The proposed generative algorithm has some advantages over the discriminative one, specifically its capability to work with very few training samples and its much lower computational requirements when the number of training examples increases. version:1
arxiv-1611-05896 | Answering Image Riddles using Vision and Reasoning through Probabilistic Soft Logic | http://arxiv.org/abs/1611.05896 | id:1611.05896 author:Somak Aditya, Yezhou Yang, Chitta Baral, Yiannis Aloimonos category:cs.CV cs.AI  published:2016-11-17 summary:In this work, we explore a genre of puzzles ("image riddles") which involves a set of images and a question. Answering these puzzles require both capabilities involving visual detection (including object, activity recognition) and, knowledge-based or commonsense reasoning. We compile a dataset of over 3k riddles where each riddle consists of 4 images and a groundtruth answer. The annotations are validated using crowd-sourced evaluation. We also define an automatic evaluation metric to track future progress. Our task bears similarity with the commonly known IQ tasks such as analogy solving, sequence filling that are often used to test intelligence. We develop a Probabilistic Reasoning-based approach that utilizes probabilistic commonsense knowledge to answer these riddles with a reasonable accuracy. We demonstrate the results of our approach using both automatic and human evaluations. Our approach achieves some promising results for these riddles and provides a strong baseline for future attempts. We make the entire dataset and related materials publicly available to the community in ImageRiddle Website (http://bit.ly/22f9Ala). version:1
arxiv-1611-04488 | Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy | http://arxiv.org/abs/1611.04488 | id:1611.04488 author:Dougal J. Sutherland, Hsiao-Yu Tung, Heiko Strathmann, Soumyajit De, Aaditya Ramdas, Alex Smola, Arthur Gretton category:stat.ML cs.AI cs.LG cs.NE stat.ME  published:2016-11-14 summary:We propose a method to optimize the representation and distinguishability of samples from two probability distributions, by maximizing the estimated power of a statistical test based on the maximum mean discrepancy (MMD). This optimized MMD is applied to the setting of unsupervised learning by generative adversarial networks (GAN), in which a model attempts to generate realistic samples, and a discriminator attempts to tell these apart from data samples. In this context, the MMD may be used in two roles: first, as a discriminator, either directly on the samples, or on features of the samples. Second, the MMD can be used to evaluate the performance of a generative model, by testing the model's samples against a reference data set. In the latter role, the optimized MMD is particularly helpful, as it gives an interpretable indication of how the model and data distributions differ, even in cases where individual model samples are not easily distinguished either by eye or by classifier. version:3
arxiv-1611-05842 | Video Processing from Electro-optical Sensors for Object Detection and Tracking in Maritime Environment: A Survey | http://arxiv.org/abs/1611.05842 | id:1611.05842 author:D. K. Prasad, D. Rajan, L. Rachmawati, E. Rajabaly, C. Quek category:cs.CV  published:2016-11-17 summary:We present a survey on maritime object detection and tracking approaches, which are essential for the development of a navigational system for autonomous ships. The electro-optical (EO) sensor considered here is a video camera that operates in the visible or the infrared spectra, which conventionally complement radar and sonar and have demonstrated effectiveness for situational awareness at sea has demonstrated its effectiveness over the last few years. This paper provides a comprehensive overview of various approaches of video processing for object detection and tracking in the maritime environment. We follow an approach-based taxonomy wherein the advantages and limitations of each approach are compared. The object detection system consists of the following modules: horizon detection, static background subtraction and foreground segmentation. Each of these has been studied extensively in maritime situations and has been shown to be challenging due to the presence of background motion especially due to waves and wakes. The main processes involved in object tracking include video frame registration, dynamic background subtraction, and the object tracking algorithm itself. The challenges for robust tracking arise due to camera motion, dynamic background and low contrast of tracked object, possibly due to environmental degradation. The survey also discusses multisensor approaches and commercial maritime systems that use EO sensors. The survey also highlights methods from computer vision research which hold promise to perform well in maritime EO data processing. Performance of several maritime and computer vision techniques is evaluated on newly proposed Singapore Maritime Dataset. version:1
arxiv-1611-05837 | AutoScaler: Scale-Attention Networks for Visual Correspondence | http://arxiv.org/abs/1611.05837 | id:1611.05837 author:Shenlong Wang, Linjie Luo, Ning Zhang, Jia Li category:cs.CV  published:2016-11-17 summary:Finding visual correspondence between local features is key to many computer vision problems. While defining features with larger contextual scales usually implies greater discriminativeness, it could also lead to less spatial accuracy of the features. We propose AutoScaler, a scale-attention network to explicitly optimize this trade-off in visual correspondence tasks. Our network consists of a weight-sharing feature network to compute multi-scale feature maps and an attention network to combine them optimally in the scale space. This allows our network to have adaptive receptive field sizes over different scales of the input. The entire network is trained end-to-end in a siamese framework for visual correspondence tasks. Our method achieves favorable results compared to state-of-the-art methods on challenging optical flow and semantic matching benchmarks, including Sintel, KITTI and CUB-2011. We also show that our method can generalize to improve hand-crafted descriptors (e.g Daisy) on general visual correspondence tasks. Finally, our attention network can generate visually interpretable scale attention maps. version:1
arxiv-1611-01604 | Dynamic Coattention Networks For Question Answering | http://arxiv.org/abs/1611.01604 | id:1611.01604 author:Caiming Xiong, Victor Zhong, Richard Socher category:cs.CL cs.AI  published:2016-11-05 summary:Several deep learning models have been proposed for question answering. However, due to their single-pass nature, they have no way to recover from local maxima corresponding to incorrect answers. To address this problem, we introduce the Dynamic Coattention Network (DCN) for question answering. The DCN first fuses co-dependent representations of the question and the document in order to focus on relevant parts of both. Then a dynamic pointing decoder iterates over potential answer spans. This iterative procedure enables the model to recover from initial local maxima corresponding to incorrect answers. On the Stanford question answering dataset, a single DCN model improves the previous state of the art from 71.0% F1 to 75.9%, while a DCN ensemble obtains 80.4% F1. version:2
arxiv-1611-05827 | Designing and Training Feedforward Neural Networks: A Smooth Optimisation Perspective | http://arxiv.org/abs/1611.05827 | id:1611.05827 author:Hao Shen category:cs.LG cs.AI cs.NE math.OC  published:2016-11-17 summary:Despite the recent great success of deep neural networks in various applications, designing and training a deep neural network is still among the greatest challenges in the field. In this work, we present a smooth optimisation perspective on designing and training multilayer Feedforward Neural Networks (FNNs) in the supervised learning setting. By characterising the critical point conditions of an FNN based optimisation problem, we identify the conditions to eliminate local optima of the corresponding cost function. Moreover, by studying the Hessian structure of the cost function at the global minima, we develop an approximate Newton FNN algorithm, which is capable of alleviating the vanishing gradient problem. Finally, our results are numerically verified on two classic benchmarks, i.e., the XOR problem and the four region classification problem. version:1
arxiv-1611-05817 | Nothing Else Matters: Model-Agnostic Explanations By Identifying Prediction Invariance | http://arxiv.org/abs/1611.05817 | id:1611.05817 author:Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin category:stat.ML cs.AI cs.LG  published:2016-11-17 summary:At the core of interpretable machine learning is the question of whether humans are able to make accurate predictions about a model's behavior. Assumed in this question are three properties of the interpretable output: coverage, precision, and effort. Coverage refers to how often humans think they can predict the model's behavior, precision to how accurate humans are in those predictions, and effort is either the up-front effort required in interpreting the model, or the effort required to make predictions about a model's behavior. In this work, we propose anchor-LIME (aLIME), a model-agnostic technique that produces high-precision rule-based explanations for which the coverage boundaries are very clear. We compare aLIME to linear LIME with simulated experiments, and demonstrate the flexibility of aLIME with qualitative examples from a variety of domains and tasks. version:1
arxiv-1611-03071 | Fair Learning in Markovian Environments | http://arxiv.org/abs/1611.03071 | id:1611.03071 author:Shahin Jabbari, Matthew Joseph, Michael Kearns, Jamie Morgenstern, Aaron Roth category:cs.LG  published:2016-11-09 summary:We initiate the study of fair learning in Markovian settings, where the actions of a learning algorithm may affect its environment and future rewards. Working in the model of reinforcement learning, we define a fairness constraint requiring that an algorithm never prefers one action over another if the long-term (discounted) reward of choosing the latter action is higher. Our first result is negative: despite the fact that fairness is consistent with the optimal policy, any learning algorithm satisfying fairness must take exponentially many rounds in the number of states to achieve non-trivial approximation to the optimal policy. Our main result is a polynomial time algorithm that is provably fair under an approximate notion of fairness, thus establishing an exponential gap between exact and approximate fairness. version:2
arxiv-1611-05799 | The Freiburg Groceries Dataset | http://arxiv.org/abs/1611.05799 | id:1611.05799 author:Philipp Jund, Nichola Abdo, Andreas Eitel, Wolfram Burgard category:cs.CV  published:2016-11-17 summary:With the increasing performance of machine learning techniques in the last few years, the computer vision and robotics communities have created a large number of datasets for benchmarking object recognition tasks. These datasets cover a large spectrum of natural images and object categories, making them not only useful as a testbed for comparing machine learning approaches, but also a great resource for bootstrapping different domain-specific perception and robotic systems. One such domain is domestic environments, where an autonomous robot has to recognize a large variety of everyday objects such as groceries. This is a challenging task due to the large variety of objects and products, and where there is great need for real-world training data that goes beyond product images available online. In this paper, we address this issue and present a dataset consisting of 5,000 images covering 25 different classes of groceries, with at least 97 images per class. We collected all images from real-world settings at different stores and apartments. In contrast to existing groceries datasets, our dataset includes a large variety of perspectives, lighting conditions, and degrees of clutter. Overall, our images contain thousands of different object instances. It is our hope that machine learning and robotics researchers find this dataset of use for training, testing, and bootstrapping their approaches. As a baseline classifier to facilitate comparison, we re-trained the CaffeNet architecture (an adaptation of the well-known AlexNet) on our dataset and achieved a mean accuracy of 78.9%. We release this trained model along with the code and data splits we used in our experiments. version:1
arxiv-1611-01331 | RenderGAN: Generating Realistic Labeled Data | http://arxiv.org/abs/1611.01331 | id:1611.01331 author:Leon Sixt, Benjamin Wild, Tim Landgraf category:cs.NE cs.CV  published:2016-11-04 summary:Deep Convolutional Neuronal Networks (DCNNs) are showing remarkable performance on many computer vision tasks. Due to their large parameter space, they require many labeled samples when trained in a supervised setting. The costs of annotating data manually can render the usage of DCNNs infeasible. We present a novel framework called RenderGAN that can generate large amounts of realistic, labeled images by combining a 3D model and the Generative Adversarial Network framework. In our approach, image augmentations (e.g. lighting, background, and detail) are learned from unlabeled data such that the generated images are strikingly realistic while preserving the labels known from the 3D model. We apply the RenderGAN framework to generate images of barcode-like markers that are attached to honeybees. A DCNN is trained on this data only. It performs better on a test set of real data than an equal DCNN trained on the limited amounts of real data available. version:3
arxiv-1611-05780 | Gap Safe screening rules for sparsity enforcing penalties | http://arxiv.org/abs/1611.05780 | id:1611.05780 author:Eugene Ndiaye, Olivier Fercoq, Alexandre Gramfort, Joseph Salmon category:stat.ML cs.LG math.OC stat.CO  published:2016-11-17 summary:In high dimensional regression context, sparsity enforcing penalties have proved useful to regularize the data-fitting term. A recently introduced technique called \emph{screening rules}, leverage the expected sparsity of the solutions by ignoring some variables in the optimization, hence leading to solver speed-ups. When the procedure is guaranteed not to discard features wrongly the rules are said to be \emph{safe}. We propose a unifying framework that can cope with generalized linear models regularized with standard sparsity enforcing penalties such as $\ell_1$ or $\ell_1/\ell_2$ norms. Our technique allows to discard safely more variables than previously considered safe rules, particularly for low regularization parameters. Our proposed Gap Safe rules (so called because they rely on duality gap computation) can cope with any iterative solver but is particularly well suited to block coordinate descent for many standard learning tasks: Lasso, Sparse-Group Lasso, multi-task Lasso, binary and multinomial logistic regression, etc. For all such tasks and on all tested datasets, we report significant speed-ups compared to previously proposed safe rules. version:1
arxiv-1611-05778 | Towards the Modeling of Behavioral Trajectories of Users in Online Social Media | http://arxiv.org/abs/1611.05778 | id:1611.05778 author:Alessandro Bessi category:cs.CY cs.SI physics.soc-ph stat.AP stat.ML  published:2016-11-17 summary:In this paper, we introduce a methodology that allows to model behavioral trajectories of users in online social media. First, we illustrate how to leverage the probabilistic framework provided by Hidden Markov Models (HMMs) to represent users by embedding the temporal sequences of actions they performed online. We then derive a model-based distance between trained HMMs, and we use spectral clustering to find homogeneous clusters of users showing similar behavioral trajectories. To provide platform-agnostic results, we apply the proposed approach to two different online social media --- i.e. Facebook and YouTube. We conclude discussing merits and limitations of our approach as well as future and promising research directions. version:1
arxiv-1611-05777 | DeeperBind: Enhancing Prediction of Sequence Specificities of DNA Binding Proteins | http://arxiv.org/abs/1611.05777 | id:1611.05777 author:Hamid Reza Hassanzadeh, May D. Wang category:cs.CV  published:2016-11-17 summary:Transcription factors (TFs) are macromolecules that bind to \textit{cis}-regulatory specific sub-regions of DNA promoters and initiate transcription. Finding the exact location of these binding sites (aka motifs) is important in a variety of domains such as drug design and development. To address this need, several \textit{in vivo} and \textit{in vitro} techniques have been developed so far that try to characterize and predict the binding specificity of a protein to different DNA loci. The major problem with these techniques is that they are not accurate enough in prediction of the binding affinity and characterization of the corresponding motifs. As a result, downstream analysis is required to uncover the locations where proteins of interest bind. Here, we propose DeeperBind, a long short term recurrent convolutional network for prediction of protein binding specificities with respect to DNA probes. DeeperBind can model the positional dynamics of probe sequences and hence reckons with the contributions made by individual sub-regions in DNA sequences, in an effective way. Moreover, it can be trained and tested on datasets containing varying-length sequences. We apply our pipeline to the datasets derived from protein binding microarrays (PBMs), an in-vitro high-throughput technology for quantification of protein-DNA binding preferences, and present promising results. To the best of our knowledge, this is the most accurate pipeline that can predict binding specificities of DNA sequences from the data produced by high-throughput technologies through utilization of the power of deep learning for feature generation and positional dynamics modeling. version:1
arxiv-1611-05774 | What Do Recurrent Neural Network Grammars Learn About Syntax? | http://arxiv.org/abs/1611.05774 | id:1611.05774 author:Adhiguna Kuncoro, Miguel Ballesteros, Lingpeng Kong, Chris Dyer, Graham Neubig, Noah A. Smith category:cs.CL  published:2016-11-17 summary:Recurrent neural network grammars (RNNG) are a recently proposed probabilistic generative modeling family for natural language. They show state-of-the-art language modeling and parsing performance. We investigate what information they learn, from a linguistic perspective, through various ablations to the model and the data, and by augmenting the model with an attention mechanism (GA-RNNG) to enable closer inspection. We find that explicit modeling of composition is crucial for achieving the best performance. Through the attention mechanism, we find that headedness plays a central role in phrasal representation (with the model's latent attention largely agreeing with predictions made by hand-crafted rules, albeit with some important differences). By training grammars without non-terminal labels, we find that phrasal representations depend minimally on non-terminals, providing support for the endocentricity hypothesis. version:1
arxiv-1611-05763 | Learning to reinforcement learn | http://arxiv.org/abs/1611.05763 | id:1611.05763 author:Jane X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel Z Leibo, Remi Munos, Charles Blundell, Dharshan Kumaran, Matt Botvinick category:cs.LG cs.AI stat.ML  published:2016-11-17 summary:In recent years deep reinforcement learning (RL) systems have attained superhuman performance in a number of challenging task domains. However, a major limitation of such applications is their demand for massive amounts of training data. A critical present objective is thus to develop deep RL methods that can adapt rapidly to new tasks. In the present work we introduce a novel approach to this challenge, which we refer to as deep meta-reinforcement learning. Previous work has shown that recurrent networks can support meta-learning in a fully supervised context. We extend this approach to the RL setting. What emerges is a system that is trained using one RL algorithm, but whose recurrent dynamics implement a second, quite separate RL procedure. This second, learned RL algorithm can differ from the original one in arbitrary ways. Importantly, because it is learned, it is configured to exploit structure in the training domain. We unpack these points in a series of seven proof-of-concept experiments, each of which examines a key aspect of deep meta-RL. We consider prospects for extending and scaling up the approach, and also point out some potentially important implications for neuroscience. version:1
arxiv-1611-05760 | Examining the Impact of Blur on Recognition by Convolutional Networks | http://arxiv.org/abs/1611.05760 | id:1611.05760 author:Igor Vasiljevic, Ayan Chakrabarti, Gregory Shakhnarovich category:cs.CV  published:2016-11-17 summary:State-of-the-art algorithms for semantic visual tasks---such as image classification and semantic segmentation---are based on the use of convolutional neural networks. These networks are commonly trained, and evaluated, on large annotated datasets of high-quality images that are free of artifacts. In this paper, we investigate the effect of one such artifact that is quite common in natural capture settings---blur. We show that standard pre-trained network models suffer a significant degradation in performance when applied to blurred images. We investigate the extent to which this degradation is due to the mismatch between training and input image statistics. Specifically, we find that fine-tuning a pre-trained model with blurred images added to the training set allows it to regain much of the lost accuracy. By considering different combinations of sharp and blurred images in the training set, we characterize how much degradation is caused by loss of information, and how much by the uncertainty of not knowing the nature and magnitude of blur. We find that by fine-tuning on a diverse mix of blurred images, convolutional neural networks can in fact learn to generate a blur invariant representation in their hidden layers. Broadly, our results provide practitioners with useful insights for developing vision systems that perform reliably on real world images affected by blur. version:1
arxiv-1611-05755 | Cross-Domain Face Verification: Matching ID Document and Self-Portrait Photographs | http://arxiv.org/abs/1611.05755 | id:1611.05755 author:Guilherme Folego, Marcus A. Angeloni, José Augusto Stuchi, Alan Godoy, Anderson Rocha category:cs.CV  published:2016-11-17 summary:Cross-domain biometrics has been emerging as a new necessity, which poses several additional challenges, including harsh illumination changes, noise, pose variation, among others. In this paper, we explore approaches to cross-domain face verification, comparing self-portrait photographs ("selfies") to ID documents. We approach the problem with proper image photometric adjustment and data standardization techniques, along with deep learning methods to extract the most prominent features from the data, reducing the effects of domain shift in this problem. We validate the methods using a novel dataset comprising 50 individuals. The obtained results are promising and indicate that the adopted path is worth further investigation. version:1
arxiv-1611-05751 | A Multi-Modal Graph-Based Semi-Supervised Pipeline for Predicting Cancer Survival | http://arxiv.org/abs/1611.05751 | id:1611.05751 author:Hamid Reza Hassanzadeh, John H. Phan, May D. Wang category:cs.LG stat.ML  published:2016-11-17 summary:Cancer survival prediction is an active area of research that can help prevent unnecessary therapies and improve patient's quality of life. Gene expression profiling is being widely used in cancer studies to discover informative biomarkers that aid predict different clinical endpoint prediction. We use multiple modalities of data derived from RNA deep-sequencing (RNA-seq) to predict survival of cancer patients. Despite the wealth of information available in expression profiles of cancer tumors, fulfilling the aforementioned objective remains a big challenge, for the most part, due to the paucity of data samples compared to the high dimension of the expression profiles. As such, analysis of transcriptomic data modalities calls for state-of-the-art big-data analytics techniques that can maximally use all the available data to discover the relevant information hidden within a significant amount of noise. In this paper, we propose a pipeline that predicts cancer patients' survival by exploiting the structure of the input (manifold learning) and by leveraging the unlabeled samples using Laplacian support vector machines, a graph-based semi supervised learning (GSSL) paradigm. We show that under certain circumstances, no single modality per se will result in the best accuracy and by fusing different models together via a stacked generalization strategy, we may boost the accuracy synergistically. We apply our approach to two cancer datasets and present promising results. We maintain that a similar pipeline can be used for predictive tasks where labeled samples are expensive to acquire. version:1
arxiv-1611-05744 | Compensating for Large In-Plane Rotations in Natural Images | http://arxiv.org/abs/1611.05744 | id:1611.05744 author:Lokesh Boominathan, Suraj Srinivas, R. Venkatesh Babu category:cs.CV  published:2016-11-17 summary:Rotation invariance has been studied in the computer vision community primarily in the context of small in-plane rotations. This is usually achieved by building invariant image features. However, the problem of achieving invariance for large rotation angles remains largely unexplored. In this work, we tackle this problem by directly compensating for large rotations, as opposed to building invariant features. This is inspired by the neuro-scientific concept of mental rotation, which humans use to compare pairs of rotated objects. Our contributions here are three-fold. First, we train a Convolutional Neural Network (CNN) to detect image rotations. We find that generic CNN architectures are not suitable for this purpose. To this end, we introduce a convolutional template layer, which learns representations for canonical 'unrotated' images. Second, we use Bayesian Optimization to quickly sift through a large number of candidate images to find the canonical 'unrotated' image. Third, we use this method to achieve robustness to large angles in an image retrieval scenario. Our method is task-agnostic, and can be used as a pre-processing step in any computer vision system. version:1
arxiv-1611-05742 | Building Deep Networks on Grassmann Manifolds | http://arxiv.org/abs/1611.05742 | id:1611.05742 author:Zhiwu Huang, Jiqing Wu, Luc Van Gool category:cs.CV  published:2016-11-17 summary:Representing the data on Grassmann manifolds is popular in quite a few image and video recognition tasks. In order to enable deep learning on Grassmann manifolds, this paper proposes a deep network architecture which generalizes the Euclidean network paradigm to Grassmann manifolds. In particular, we design full rank mapping layers to transform input Grassmannian data into more desirable ones, exploit orthogonal re-normalization layers to normalize the resulting matrices, study projection pooling layers to reduce the model complexity in the Grassmannian context, and devise projection mapping layers to turn the resulting Grassmannian data into Euclidean forms for regular output layers. To train the deep network, we exploit a stochastic gradient descent setting on manifolds where the connection weights reside on, and study a matrix generalization of backpropagation to update the structured data. We experimentally evaluate the proposed network for three computer vision tasks, and show that it has clear advantages over existing Grassmann learning methods, and achieves results comparable with state-of-the-art approaches. version:1
arxiv-1611-05725 | PolyNet: A Pursuit of Structural Diversity in Very Deep Networks | http://arxiv.org/abs/1611.05725 | id:1611.05725 author:Xingcheng Zhang, Zhizhong Li, Chen Change Loy, Dahua Lin category:cs.CV  published:2016-11-17 summary:A number of studies have shown that increasing the depth or width of convolutional networks is a rewarding approach to improve the performance of image recognition. In our study, however, we observed difficulties along both directions. On one hand, the pursuit for very deep networks are met with diminishing return and increased training difficulty; on the other hand, widening a network would result in a quadratic growth in both computational cost and memory demand. These difficulties motivate us to explore structural diversity in designing deep networks, a new dimension beyond just depth and width. Specifically, we present a new family of modules, namely the PolyInception, which can be flexibly inserted in isolation or in a composition as replacements of different parts of a network. Choosing PolyInception modules with the guidance of architectural efficiency can improve the expressive power while preserving comparable computational cost. A benchmark on the ILSVRC 2012 validation set demonstrates substantial improvements over the state-of-the-art. Compared to Inception-ResNet-v2, it reduces the top-5 error on single crops from 4.9% to 4.25%, and that on multi-crops from 3.7% to 3.45%. version:1
arxiv-1611-05722 | GENESIM: genetic extraction of a single, interpretable model | http://arxiv.org/abs/1611.05722 | id:1611.05722 author:Gilles Vandewiele, Olivier Janssens, Femke Ongenae, Filip De Turck, Sofie Van Hoecke category:stat.ML cs.LG  published:2016-11-17 summary:Models obtained by decision tree induction techniques excel in being interpretable.However, they can be prone to overfitting, which results in a low predictive performance. Ensemble techniques are able to achieve a higher accuracy. However, this comes at a cost of losing interpretability of the resulting model. This makes ensemble techniques impractical in applications where decision support, instead of decision making, is crucial. To bridge this gap, we present the GENESIM algorithm that transforms an ensemble of decision trees to a single decision tree with an enhanced predictive performance by using a genetic algorithm. We compared GENESIM to prevalent decision tree induction and ensemble techniques using twelve publicly available data sets. The results show that GENESIM achieves a better predictive performance on most of these data sets than decision tree induction techniques and a predictive performance in the same order of magnitude as the ensemble techniques. Moreover, the resulting model of GENESIM has a very low complexity, making it very interpretable, in contrast to ensemble techniques. version:1
arxiv-1611-05720 | Hard-Aware Deeply Cascaded Embedding | http://arxiv.org/abs/1611.05720 | id:1611.05720 author:Yuhui Yuan, Kuiyuan Yang, Chao Zhang category:cs.CV  published:2016-11-17 summary:Riding on the waves of deep neural networks, deep metric learning has also achieved promising results in various tasks using triplet network or Siamese network. Though the basic goal of making images from the same category closer than the ones from different categories is intuitive, it is hard to directly optimize due to the quadratic or cubic sample size. To solve the problem, hard example mining which only focuses on a subset of samples that are considered hard is widely used. However, hard is defined relative to a model, where complex models treat most samples as easy ones and vice versa for simple models, and both are not good for training. Samples are also with different hard levels, it is hard to define a model with the just right complexity and choose hard examples adequately. This motivates us to ensemble a set of models with different complexities in cascaded manner and mine hard examples adaptively, a sample is judged by a series of models with increasing complexities and only updates models that consider the sample as a hard case. We evaluate our method on CARS196, CUB-200-2011, Stanford Online Products, VehicleID and DeepFashion datasets. Our method outperforms state-of-the-art methods by a large margin. version:1
arxiv-1611-05709 | Factorized Bilinear Models for Image Recognition | http://arxiv.org/abs/1611.05709 | id:1611.05709 author:Yanghao Li, Naiyan Wang, Jiaying Liu, Xiaodi Hou category:cs.CV  published:2016-11-17 summary:Although Deep Convolutional Neural Networks (CNNs) have liberated their power in various computer vision tasks, the most important components of CNN, convolutional layers and fully connected layers, are still limited to linear transformations. In this paper, we propose a novel Factorized Bilinear (FB) layer to model the pairwise feature interactions by considering the quadratic terms in the transformations. Compared with existing methods that tried to incorporate complex non-linearity structures into CNNs, the factorized parameterization makes our FB layer only require a linear increase of parameters and affordable computational cost. To further reduce the risk of overfitting of the FB layer, a specific remedy called DropFactor is devised during the training process. We also analyze the connection between FB layer and some existing models, and show FB layer is a generalization to them. Finally, we validate the effectiveness of FB layer on several widely adopted datasets including CIFAR-10, CIFAR-100 and ImageNet, and demonstrate superior results compared with various state-of-the-art deep models. version:1
arxiv-1611-05708 | Fusing 2D Uncertainty and 3D Cues for Monocular Body Pose Estimation | http://arxiv.org/abs/1611.05708 | id:1611.05708 author:Bugra Tekin, Pablo Márquez-Neila, Mathieu Salzmann, Pascal Fua category:cs.CV  published:2016-11-17 summary:Most recent approaches to monocular 3D human pose estimation rely on Deep Learning. They typically involve training a network to regress from an image to either 3D joint coordinates directly, or 2D joint locations from which the 3D coordinates are inferred by a model-fitting procedure. The former takes advantage of 3D cues present in the images but rarely models uncertainty. By contrast, the latter often models 2D uncertainty, for example in the form of joint location heatmaps, but discards all the image information, such as texture, shading and depth cues, in the fitting step. In this paper, we therefore propose to jointly model 2D uncertainty and leverage 3D image cues in a regression framework for monocular 3D human pose estimation. To this end, we introduce a novel two-stream deep architecture. One stream focuses on modeling uncertainty via probability maps of 2D joint locations and the other exploits 3D cues by directly acting on the image. We then study different approaches to fusing their outputs to obtain the final 3D prediction. Our experiments evidence in particular that our late-fusion mechanism improves upon the state-of-the-art by a large margin on standard 3D human pose estimation benchmarks. version:1
arxiv-1611-05705 | DSAC - Differentiable RANSAC for Camera Localization | http://arxiv.org/abs/1611.05705 | id:1611.05705 author:Eric Brachmann, Alexander Krull, Sebastian Nowozin, Jamie Shotton, Frank Michel, Stefan Gumhold, Carsten Rother category:cs.CV  published:2016-11-17 summary:RANSAC is an important algorithm in robust optimization and a central building block for many computer vision applications. In recent years, traditionally hand-crafted pipelines have been replaced by deep learning pipelines, which can be trained in an end-to-end fashion. However, RANSAC has so far not been used as part of such deep learning pipelines, because its hypothesis selection procedure is non-differentiable. In this work, we present two different ways to overcome this limitation. The most promising approach is inspired by reinforcement learning, namely to replace the deterministic hypothesis selection by a probabilistic selection for which we can derive the expected loss w.r.t. to all learnable parameters. We call this approach DSAC, the differentiable counterpart of RANSAC. We apply DSAC to the problem of camera localization, where deep learning has so far failed to improve on traditional approaches. We demonstrate that by directly minimizing the expected loss of the output camera poses, robustly estimated by RANSAC, we achieve an increase in accuracy. In the future, any deep learning pipeline can use DSAC as a robust optimization component. version:1
arxiv-1611-05689 | End-to-end Learning of Cost-Volume Aggregation for Real-time Dense Stereo | http://arxiv.org/abs/1611.05689 | id:1611.05689 author:Andrey Kuzmin, Dmitry Mikushin, Victor Lempitsky category:cs.CV  published:2016-11-17 summary:We present a new deep learning-based approach for dense stereo matching. Compared to previous works, our approach does not use deep learning of pixel appearance descriptors, employing very fast classical matching scores instead. At the same time, our approach uses a deep convolutional network to predict the local parameters of cost volume aggregation process, which in this paper we implement using differentiable domain transform. By treating such transform as a recurrent neural network, we are able to train our whole system that includes cost volume computation, cost-volume aggregation (smoothing), and winner-takes-all disparity selection end-to-end. The resulting method is highly efficient at test time, while achieving good matching accuracy. On the KITTI 2015 benchmark, it achieves a result of 6.34\% error rate while running at 29 frames per second rate on a modern GPU. version:1
arxiv-1611-05198 | One-Shot Video Object Segmentation | http://arxiv.org/abs/1611.05198 | id:1611.05198 author:Sergi Caelles, Kevis-Kokitsi Maninis, Jordi Pont-Tuset, Laura Leal-Taixé, Daniel Cremers, Luc Van Gool category:cs.CV  published:2016-11-16 summary:This paper tackles the task of semi-supervised video object segmentation, i.e., the separation of an object from the background in a video, given the mask of the first frame. We present One-Shot Video Object Segmentation (OSVOS), based on a fully-convolutional neural network architecture that is able to successively transfer generic semantic information, learned on ImageNet, to the task of foreground segmentation, and finally to learning the appearance of a single annotated object of the test sequence (hence one-shot). Although all frames are processed independently, the results are temporally coherent and stable. We perform experiments on three annotated video segmentation databases, which show that OSVOS is fast and improves the state of the art by a significant margin (79.8% vs 68.0%). version:2
arxiv-1611-05675 | Study on Feature Subspace of Archetypal Emotions for Speech Emotion Recognition | http://arxiv.org/abs/1611.05675 | id:1611.05675 author:Xi Ma, Zhiyong Wu, Jia Jia, Mingxing Xu, Helen Meng, Lianhong Cai category:cs.LG cs.AI  published:2016-11-17 summary:Feature subspace selection is an important part in speech emotion recognition. Most of the studies are devoted to finding a feature subspace for representing all emotions. However, some studies have indicated that the features associated with different emotions are not exactly the same. Hence, traditional methods may fail to distinguish some of the emotions with just one global feature subspace. In this work, we propose a new divide and conquer idea to solve the problem. First, the feature subspaces are constructed for all the combinations of every two different emotions (emotion-pair). Bi-classifiers are then trained on these feature subspaces respectively. The final emotion recognition result is derived by the voting and competition method. Experimental results demonstrate that the proposed method can get better results than the traditional multi-classification method. version:1
arxiv-1611-05666 | A Discriminatively Learned CNN Embedding for Person Re-identification | http://arxiv.org/abs/1611.05666 | id:1611.05666 author:Zhedong Zheng, Liang Zheng, Yi Yang category:cs.CV  published:2016-11-17 summary:We revisit two popular convolutional neural networks (CNN) in person re-identification (re-ID), i.e, verification and classification models. The two models have their respective advantages and limitations due to different loss functions. In this paper, we shed light on how to combine the two models to learn more discriminative pedestrian descriptors. Specifically, we propose a new siamese network that simultaneously computes identification loss and verification loss. Given a pair of training images, the network predicts the identities of the two images and whether they belong to the same identity. Our network learns a discriminative embedding and a similarity measurement at the same time, thus making full usage of the annotations. Albeit simple, the learned embedding improves the state-of-the-art performance on two public person re-ID benchmarks. Further, we show our architecture can also be applied in image retrieval. version:1
arxiv-1611-05664 | Learning to detect and localize many objects from few examples | http://arxiv.org/abs/1611.05664 | id:1611.05664 author:Bastien Moysset, Christoper Kermorvant, Christian Wolf category:cs.CV cs.AI  published:2016-11-17 summary:The current trend in object detection and localization is to learn predictions with high capacity deep neural networks trained on a very large amount of annotated data and using a high amount of processing power. In this work, we propose a new neural model which directly predicts bounding box coordinates. The particularity of our contribution lies in the local computations of predictions with a new form of local parameter sharing which keeps the overall amount of trainable parameters low. Key components of the model are spatial 2D-LSTM recurrent layers which convey contextual information between the regions of the image. We show that this model is more powerful than the state of the art in applications where training data is not as abundant as in the classical configuration of natural images and Imagenet/Pascal VOC tasks. We particularly target the detection of text in document images, but our method is not limited to this setting. The proposed model also facilitates the detection of many objects in a single image and can deal with inputs of variable sizes without resizing. version:1
arxiv-1611-05644 | Inverting The Generator Of A Generative Adversarial Network | http://arxiv.org/abs/1611.05644 | id:1611.05644 author:Antonia Creswell, Anil Anthony Bharath category:cs.CV cs.LG  published:2016-11-17 summary:Generative adversarial networks (GANs) learn to synthesise new samples from a high-dimensional distribution by passing samples drawn from a latent space through a generative network. When the high-dimensional distribution describes images of a particular data set, the network should learn to generate visually similar image samples for latent variables that are close to each other in the latent space. For tasks such as image retrieval and image classification, it may be useful to exploit the arrangement of the latent space by projecting images into it, and using this as a representation for discriminative tasks. GANs often consist of multiple layers of non-linear computations, making them very difficult to invert. This paper introduces techniques for projecting image samples into the latent space using any pre-trained GAN, provided that the computational graph is available. We evaluate these techniques on both MNIST digits and Omniglot handwritten characters. In the case of MNIST digits, we show that projections into the latent space maintain information about the style and the identity of the digit. In the case of Omniglot characters, we show that even characters from alphabets that have not been seen during training may be projected well into the latent space; this suggests that this approach may have applications in one-shot learning. version:1
arxiv-1611-05607 | Optical Flow Requires Multiple Strategies (but only one network) | http://arxiv.org/abs/1611.05607 | id:1611.05607 author:Tal Schuster, Lior Wolf, David Gadot category:cs.CV cs.LG  published:2016-11-17 summary:We show that the matching problem that underlies optical flow requires multiple strategies, depending on the amount of image motion and other factors. We then study the implications of this observation on training a deep neural network for representing image patches in the context of descriptor based optical flow. We propose a metric learning method, which selects suitable negative samples based on the nature of the true match. This type of training produces a network that displays multiple strategies depending on the input and leads to state of the art results on the KITTI 2012 and KITTI 2015 optical flow benchmarks. version:1
arxiv-1611-05603 | Weakly-supervised Learning of Mid-level Features for Pedestrian Attribute Recognition and Localization | http://arxiv.org/abs/1611.05603 | id:1611.05603 author:Kai Yu, Biao Leng, Zhang Zhang, Dangwei Li, Kaiqi Huang category:cs.CV  published:2016-11-17 summary:State-of-the-art methods treat pedestrian attribute recognition as a multi-label image classification problem. The location information of person attributes is usually eliminated or simply encoded in the rigid splitting of whole body in previous work. In this paper, we formulate the task in a weakly-supervised attribute localization framework. Based on GoogLeNet, firstly, a set of mid-level attribute features are discovered by novelly designed detection layers, where a max-pooling based weakly-supervised object detection technique is used to train these layers with only image-level labels without the need of bounding box annotations of pedestrian attributes. Secondly, attribute labels are predicted by regression of the detection response magnitudes. Finally, the locations and rough shapes of pedestrian attributes can be inferred by performing clustering on a fusion of activation maps of the detection layers, where the fusion weights are estimated as the correlation strengths between each attribute and its relevant mid-level features. Extensive experiments are performed on the two currently largest pedestrian attribute datasets, i.e. the PETA dataset and the RAP dataset. Results show that the proposed method has achieved competitive performance on attribute recognition, compared to other state-of-the-art methods. Moreover, the results of attribute localization are visualized to understand the characteristics of the proposed method. version:1
arxiv-1611-05594 | SCA-CNN: Spatial and Channel-wise Attention in Convolutional Networks for Image Captioning | http://arxiv.org/abs/1611.05594 | id:1611.05594 author:Long Chen, Hanwang Zhang, Jun Xiao, Liqiang Nie, Jian Shao, Tat-Seng Chua category:cs.CV  published:2016-11-17 summary:Visual attention has been successfully applied in structural prediction tasks such as visual captioning and question answering. Existing visual attention models are generally spatial, i.e., the attention is modeled as spatial probabilities that re-weight the last conv-layer feature map of a CNN which encodes an input image. However, we argue that such spatial attention does not necessarily conform to the attention mechanism --- a dynamic feature extractor that combines contextual fixations over time, as CNN features are naturally spatial, channel-wise and multi-layer. In this paper, we introduce a novel convolutional neural network dubbed SCA-CNN that incorporates Spatial and Channel-wise Attentions in a CNN. In the task of image captioning, SCA-CNN dynamically modulates the sentence generation context in multi-layer feature maps, encoding where (i.e., attentive spatial locations at multiple layers) and what (i.e., attentive channels) the visual attention is. We evaluate the SCA-CNN architecture on three benchmark image captioning datasets: Flickr8K, Flickr30K, and MSCOCO. SCA-CNN achieves significant improvements over state-of-the-art visual attention-based image captioning methods. version:1
arxiv-1611-05592 | Multimodal Memory Modelling for Video Captioning | http://arxiv.org/abs/1611.05592 | id:1611.05592 author:Junbo Wang, Wei Wang, Yan Huang, Liang Wang, Tieniu Tan category:cs.CV  published:2016-11-17 summary:Video captioning which automatically translates video clips into natural language sentences is a very important task in computer vision. By virtue of recent deep learning technologies, e.g., convolutional neural networks (CNNs) and recurrent neural networks (RNNs), video captioning has made great progress. However, learning an effective mapping from visual sequence space to language space is still a challenging problem. In this paper, we propose a Multimodal Memory Model (M3) to describe videos, which builds a visual and textual shared memory to model the long-term visual-textual dependency and further guide global visual attention on described targets. Specifically, the proposed M3 attaches an external memory to store and retrieve both visual and textual contents by interacting with video and sentence with multiple read and write operations. First, text representation in the Long Short-Term Memory (LSTM) based text decoder is written into the memory, and the memory contents will be read out to guide an attention to select related visual targets. Then, the selected visual information is written into the memory, which will be further read out to the text decoder. To evaluate the proposed model, we perform experiments on two publicly benchmark datasets: MSVD and MSR-VTT. The experimental results demonstrate that our method outperforms the state-of-theart methods in terms of BLEU and METEOR. version:1
arxiv-1611-05588 | Instance-aware Image and Sentence Matching with Selective Multimodal LSTM | http://arxiv.org/abs/1611.05588 | id:1611.05588 author:Yan Huang, Wei Wang, Liang Wang category:cs.CV  published:2016-11-17 summary:Effective image and sentence matching depends on how to well measure their global visual-semantic similarity. Based on the observation that such a global similarity arises from a complex aggregation of multiple local similarities between pairwise instances of image (objects) and sentence (words), we propose a selective multimodal Long Short-Term Memory network (sm-LSTM) for instance-aware image and sentence matching. The sm-LSTM includes a multimodal context-modulated attention scheme at each timestep that can selectively attend to a pair of instances of image and sentence, by predicting pairwise instance-aware saliency maps for image and sentence. For selected pairwise instances, their representations are obtained based on the predicted saliency maps, and then compared to measure their local similarity. By similarly measuring multiple local similarities within a few timesteps, the sm-LSTM sequentially aggregates them with hidden states to obtain a final matching score as the desired global similarity. Extensive experiments show that our model can well match image and sentence with complex content, and achieve the state-of-the-art results on two public benchmark datasets. version:1
arxiv-1610-09787 | Edward: A library for probabilistic modeling, inference, and criticism | http://arxiv.org/abs/1610.09787 | id:1610.09787 author:Dustin Tran, Alp Kucukelbir, Adji B. Dieng, Maja Rudolph, Dawen Liang, David M. Blei category:stat.CO cs.AI cs.PL stat.AP stat.ML  published:2016-10-31 summary:Probabilistic modeling is a powerful approach for analyzing empirical information. We describe Edward, a library for probabilistic modeling. Edward's design reflects an iterative process pioneered by George Box: build a model of a phenomenon, make inferences about the model given data, and criticize the model's fit to the data. Edward supports a broad class of probabilistic models, efficient algorithms for inference, and many techniques for model criticism. The library builds on top of TensorFlow to support distributed training and hardware such as GPUs. Edward enables the development of complex probabilistic models and their algorithms at a massive scale. version:2
arxiv-1611-01505 | Improving Stochastic Gradient Descent with Feedback | http://arxiv.org/abs/1611.01505 | id:1611.01505 author:Jayanth Koushik, Hiroaki Hayashi category:cs.LG  published:2016-11-04 summary:In this paper we propose a simple and efficient method for improving stochastic gradient descent methods by using feedback from the objective function. The method tracks the relative changes in the objective function with a running average, and uses it to adaptively tune the learning rate in stochastic gradient descent. We specifically apply this idea to modify Adam, a popular algorithm for training deep neural networks. We conduct experiments to compare the resulting algorithm, which we call Eve, with state of the art methods used for training deep learning models. We train CNNs for image classification, and RNNs for language modeling and question answering. Our experiments show that Eve outperforms all other algorithms on these benchmark tasks. We also analyze the behavior of the feedback mechanism during the training process. version:2
arxiv-1611-05559 | Boosting Variational Inference | http://arxiv.org/abs/1611.05559 | id:1611.05559 author:Fangjian Guo, Xiangyu Wang, Kai Fan, Tamara Broderick, David B. Dunson category:stat.ML cs.LG  published:2016-11-17 summary:Modern Bayesian inference typically requires some form of posterior approximation, and mean-field variational inference (MFVI) is an increasingly popular choice due to its speed. But MFVI can be inaccurate in various aspects, including an inability to capture multimodality in the posterior and underestimation of the posterior covariance. These issues arise since MFVI considers approximations to the posterior only in a family of factorized distributions. We instead consider a much more flexible approximating family consisting of all possible finite mixtures of a parametric base distribution (e.g., Gaussian). In order to efficiently find a high-quality posterior approximation within this family, we borrow ideas from gradient boosting and propose boosting variational inference (BVI). BVI iteratively improves the current approximation by mixing it with a new component from the base distribution family. We develop practical algorithms for BVI and demonstrate their performance on both real and simulated data. version:1
arxiv-1611-05552 | DelugeNets: Deep Networks with Massive and Flexible Cross-layer Information Inflows | http://arxiv.org/abs/1611.05552 | id:1611.05552 author:Jason Kuen, Xiangfei Kong, Gang Wang category:cs.CV cs.LG cs.NE  published:2016-11-17 summary:Human brains are adept at dealing with the deluge of information they continuously receive, by suppressing the non-essential inputs and focusing on the important ones. Inspired by such capability, we propose Deluge Networks (DelugeNets), a novel class of neural networks facilitating massive cross-layer information inflows from preceding layers to succeeding layers. The connections between layers in DelugeNets are efficiently established through cross-layer depthwise convolutional layers with learnable filters, acting as a flexible selection mechanism. By virtue of the massive cross-layer information inflows, DelugeNets can propagate information across many layers with greater flexibility and utilize network parameters more effectively, compared to existing ResNet models. Experiments show the superior performances of DelugeNets in terms of both classification accuracies and parameter efficiencies. Remarkably, a DelugeNet model with just 20.2M parameters achieve state-of-the-art accuracy of 19.02% on CIFAR-100 dataset, outperforming DenseNet model with 27.2M parameters. version:1
arxiv-1611-05365 | Am I a Baller? Basketball Skill Assessment using First-Person Cameras | http://arxiv.org/abs/1611.05365 | id:1611.05365 author:Gedas Bertasius, Stella X. Yu, Hyun Soo Park, Jianbo Shi category:cs.CV  published:2016-11-16 summary:Skill assessment is a fundamental problem in sports like basketball. Nowadays, basketball skill assessment is handled by basketball experts who evaluate a player's skill from unscripted third-person basketball game videos. However, due to a large distance between a camera and the players, a third-person video captures a low-resolution view of the players, which makes it difficult to 1) identify specific players in the video and 2) to recognize what they are doing. To address these issues, we use first-person cameras, which 1) provide a high-resolution view of a player's actions, and 2) also eliminate the need to track each player. Despite this, learning a basketball skill assessment model from the first-person data is still challenging, because 1) a player's actions of interest occur rarely, and 2) the data labeling requires using basketball experts, which is costly. To counter these problems, we introduce a concept of basketball elements, 1) which addresses a limited player's activity data issue, and 2) eliminates the reliance on basketball experts. Basketball elements define simple basketball concepts, making labeling easy even for non-experts. Basketball elements are also prevalent in the first-person data, which allows us to learn, and use them for a player's basketball activity recognition and his basketball skill assessment. Thus, our contributions include (1) a new task of assessing a player's basketball skill from an unscripted first-person basketball game video, (2) a new 10.3 hour long first-person basketball video dataset capturing 48 players and (3) a data-driven model that assesses a player's basketball skill without relying on basketball expert labelers. version:2
arxiv-1611-05545 | Stochastic Gradient Descent in Continuous Time | http://arxiv.org/abs/1611.05545 | id:1611.05545 author:Justin Sirignano, Konstantinos Spiliopoulos category:math.PR math.OC math.ST stat.ML stat.TH  published:2016-11-17 summary:We consider stochastic gradient descent for continuous-time models. Traditional approaches for the statistical estimation of continuous-time models, such as batch optimization, can be impractical for large datasets where observations occur over a long period of time. Stochastic gradient descent provides a computationally efficient method for such statistical estimation problems. The stochastic gradient descent algorithm performs an online parameter update in continuous time, with the parameter updates satisfying a stochastic differential equation. The parameters are proven to converge to a local minimum of a natural objective function for the estimation of the continuous-time dynamics. The convergence proof leverages ergodicity by using an appropriate Poisson equation to help describe the evolution of the parameters for large times. Numerical analysis of the stochastic gradient descent algorithm is presented for several examples, including the Ornstein-Uhlenbeck process, Burger's stochastic partial differential equation, and reinforcement learning. version:1
arxiv-1611-05340 | Approximating Wisdom of Crowds using K-RBMs | http://arxiv.org/abs/1611.05340 | id:1611.05340 author:Abhay Gupta category:cs.LG  published:2016-11-16 summary:An important way to make large training sets is to gather noisy labels from crowds of non experts. We propose a method to aggregate noisy labels collected from a crowd of workers or annotators. Eliciting labels is important in tasks such as judging web search quality and rating products. Our method assumes that labels are generated by a probability distribution over items and labels. We formulate the method by drawing parallels between Gaussian Mixture Models (GMMs) and Restricted Boltzmann Machines (RBMs) and show that the problem of vote aggregation can be viewed as one of clustering. We use K-RBMs to perform clustering. We finally show some empirical evaluations over real datasets. version:2
arxiv-1611-05345 | Weakly Supervised Top-down Salient Object Detection | http://arxiv.org/abs/1611.05345 | id:1611.05345 author:Hisham Cholakkal, Jubin Johnson, Deepu Rajan category:cs.CV  published:2016-11-16 summary:Top-down saliency models produce a probability map that peaks at target locations specified by a task/goal such as object detection. They are usually trained in a fully supervised setting involving pixel-level annotations of objects. We propose a weakly supervised top-down saliency framework using only binary labels that indicate the presence/absence of an object in an image. First, the probabilistic contribution of each image region to the confidence of a CNN-based image classifier is computed through a backtracking strategy to produce top-down saliency. From a set of saliency maps of an image produced by fast bottom-up saliency approaches, we select the best saliency map suitable for the top-down task. The selected bottom-up saliency map is combined with the top-down saliency map. Features having high combined saliency are used to train a linear SVM classifier to estimate feature saliency. This is integrated with combined saliency and further refined through a multi-scale superpixel-averaging of saliency map. We evaluate the performance of the proposed weakly supervised top-down saliency against fully supervised approaches and achieve state-of-the-art performance. Experiments are carried out on seven challenging datasets and quantitative results are compared with 36 closely related approaches across 4 different applications. version:2
arxiv-1611-02344 | A Convolutional Encoder Model for Neural Machine Translation | http://arxiv.org/abs/1611.02344 | id:1611.02344 author:Jonas Gehring, Michael Auli, David Grangier, Yann N. Dauphin category:cs.CL  published:2016-11-07 summary:The prevalent approach to neural machine translation relies on bi-directional LSTMs to encode the source sentence. In this paper we present a faster and simpler architecture based on a succession of convolutional layers. This allows to encode the entire source sentence simultaneously compared to recurrent networks for which computation is constrained by temporal dependencies. On WMT'16 English-Romanian translation we achieve competitive accuracy to the state-of-the-art and we outperform several recently published results on the WMT'15 English-German task. Our models obtain almost the same accuracy as a very deep LSTM setup on WMT'14 English-French translation. Our convolutional encoder speeds up CPU decoding by more than two times at the same or higher accuracy as a strong bi-directional LSTM baseline. version:2
arxiv-1611-05527 | Automatic Node Selection for Deep Neural Networks using Group Lasso Regularization | http://arxiv.org/abs/1611.05527 | id:1611.05527 author:Tsubasa Ochiai, Shigeki Matsuda, Hideyuki Watanabe, Shigeru Katagiri category:cs.CL cs.LG stat.ML  published:2016-11-17 summary:We examine the effect of the Group Lasso (gLasso) regularizer in selecting the salient nodes of Deep Neural Network (DNN) hidden layers by applying a DNN-HMM hybrid speech recognizer to TED Talks speech data. We test two types of gLasso regularization, one for outgoing weight vectors and another for incoming weight vectors, as well as two sizes of DNNs: 2048 hidden layer nodes and 4096 nodes. Furthermore, we compare gLasso and L2 regularizers. Our experiment results demonstrate that our DNN training, in which the gLasso regularizer was embedded, successfully selected the hidden layer nodes that are necessary and sufficient for achieving high classification power. version:1
arxiv-1611-05521 | Robust Hashing for Multi-View Data: Jointly Learning Low-Rank Kernelized Similarity Consensus and Hash Functions | http://arxiv.org/abs/1611.05521 | id:1611.05521 author:Lin Wu, Yang Wang category:cs.LG  published:2016-11-17 summary:Learning hash functions/codes for similarity search over multi-view data is attracting increasing attention, where similar hash codes are assigned to the data objects characterizing consistently neighborhood relationship across views. Traditional methods in this category inherently suffer three limitations: 1) they commonly adopt a two-stage scheme where similarity matrix is first constructed, followed by a subsequent hash function learning; 2) these methods are commonly developed on the assumption that data samples with multiple representations are noise-free,which is not practical in real-life applications; 3) they often incur cumbersome training model caused by the neighborhood graph construction using all $N$ points in the database ($O(N)$). In this paper, we motivate the problem of jointly and efficiently training the robust hash functions over data objects with multi-feature representations which may be noise corrupted. To achieve both the robustness and training efficiency, we propose an approach to effectively and efficiently learning low-rank kernelized \footnote{We use kernelized similarity rather than kernel, as it is not a squared symmetric matrix for data-landmark affinity matrix.} hash functions shared across views. Specifically, we utilize landmark graphs to construct tractable similarity matrices in multi-views to automatically discover neighborhood structure in the data. To learn robust hash functions, a latent low-rank kernel function is used to construct hash functions in order to accommodate linearly inseparable data. In particular, a latent kernelized similarity matrix is recovered by rank minimization on multiple kernel-based similarity matrices. Extensive experiments on real-world multi-view datasets validate the efficacy of our method in the presence of error corruptions. version:1
arxiv-1611-05507 | Deep Feature Interpolation for Image Content Changes | http://arxiv.org/abs/1611.05507 | id:1611.05507 author:Paul Upchurch, Jacob Gardner, Kavita Bala, Robert Pless, Noah Snavely, Kilian Weinberger category:cs.CV  published:2016-11-16 summary:We propose Deep Feature Interpolation (DFI), a new data-driven baseline for automatic high-resolution image transformation. As the name suggests, it relies only on simple linear interpolation of deep convolutional features from pre-trained convnets. We show that despite its simplicity, DFI can perform high-level semantic transformations like "make older/younger", "make bespectacled", "add smile", among others, surprisingly well - sometimes even matching or outperforming the state-of-the-art. This is particularly unexpected as DFI requires no specialized network architecture or even any deep network to be trained for these tasks. DFI therefore can be used as a new baseline to evaluate more complex algorithms and provides a practical answer to the question of which image transformation tasks are still challenging in the rise of deep learning. version:1
arxiv-1611-05503 | On the Exploration of Convolutional Fusion Networks for Visual Recognition | http://arxiv.org/abs/1611.05503 | id:1611.05503 author:Yu Liu, Yanming Guo, Michael S. Lew category:cs.CV  published:2016-11-16 summary:Despite recent advances in multi-scale deep representations, their limitations are attributed to expensive parameters and weak fusion modules. Hence, we propose an efficient approach to fuse multi-scale deep representations, called convolutional fusion networks (CFN). Owing to using 1$\times$1 convolution and global average pooling, CFN can efficiently generate the side branches while adding few parameters. In addition, we present a locally-connected fusion module, which can learn adaptive weights for the side branches and form a discriminatively fused feature. CFN models trained on the CIFAR and ImageNet datasets demonstrate remarkable improvements over the plain CNNs. Furthermore, we generalize CFN to three new tasks, including scene recognition, fine-grained recognition and image retrieval. Our experiments show that it can obtain consistent improvements towards the transferring tasks. version:1
arxiv-1611-05490 | Semantic Regularisation for Recurrent Image Annotation | http://arxiv.org/abs/1611.05490 | id:1611.05490 author:Feng Liu, Tao Xiang, Timothy M. Hospedales, Wankou Yang, Changyin Sun category:cs.CV  published:2016-11-16 summary:The "CNN-RNN" design pattern is increasingly widely applied in a variety of image annotation tasks including multi-label classification and captioning. Existing models use the weakly semantic CNN hidden layer or its transform as the image embedding that provides the interface between the CNN and RNN. This leaves the RNN overstretched with two jobs: predicting the visual concepts and modelling their correlations for generating structured annotation output. Importantly this makes the end-to-end training of the CNN and RNN slow and ineffective due to the difficulty of back propagating gradients through the RNN to train the CNN. We propose a simple modification to the design pattern that makes learning more effective and efficient. Specifically, we propose to use a semantically regularised embedding layer as the interface between the CNN and RNN. Regularising the interface can partially or completely decouple the learning problems, allowing each to be more effectively trained and jointly training much more efficient. Extensive experiments show that state-of-the art performance is achieved on multi-label classification as well as image captioning. version:1
arxiv-1611-05487 | Algebraic multigrid support vector machines | http://arxiv.org/abs/1611.05487 | id:1611.05487 author:Ehsan Sadrfaridpour, Sandeep Jeereddy, Ken Kennedy, Andre Luckow, Talayeh Razzaghi, Ilya Safro category:stat.ML cs.DS cs.LG stat.CO  published:2016-11-16 summary:The support vector machine is a flexible optimization-based technique widely used for classification problems. In practice, its training part becomes computationally expensive on large-scale data sets because of such reasons as the complexity and number of iterations in parameter fitting methods, underlying optimization solvers, and nonlinearity of kernels. We introduce a fast multilevel framework for solving support vector machine models that is inspired by the algebraic multigrid. Significant improvement in the running has been achieved without any loss in the quality. The proposed technique is highly beneficial on imbalanced sets. We demonstrate computational results on publicly available and industrial data sets. version:1
arxiv-1611-05480 | Solving Cold-Start Problem in Large-scale Recommendation Engines: A Deep Learning Approach | http://arxiv.org/abs/1611.05480 | id:1611.05480 author:Jianbo Yuan, Walid Shalaby, Mohammed Korayem, David Lin, Khalifeh AlJadda, Jiebo Luo category:cs.IR cs.LG  published:2016-11-16 summary:Collaborative Filtering (CF) is widely used in large-scale recommendation engines because of its efficiency, accuracy and scalability. However, in practice, the fact that recommendation engines based on CF require interactions between users and items before making recommendations, make it inappropriate for new items which haven't been exposed to the end users to interact with. This is known as the cold-start problem. In this paper we introduce a novel approach which employs deep learning to tackle this problem in any CF based recommendation engine. One of the most important features of the proposed technique is the fact that it can be applied on top of any existing CF based recommendation engine without changing the CF core. We successfully applied this technique to overcome the item cold-start problem in Careerbuilder's CF based recommendation engine. Our experiments show that the proposed technique is very efficient to resolve the cold-start problem while maintaining high accuracy of the CF recommendations. version:1
arxiv-1611-05479 | Probabilistic Fluorescence-Based Synapse Detection | http://arxiv.org/abs/1611.05479 | id:1611.05479 author:Anish K. Simhal, Cecilia Aguerrebere, Forrest Collman, Joshua T. Vogelstein, Kristina D. Micheva, Richard J. Weinberg, Stephen J. Smith, Guillermo Sapiro category:cs.CV q-bio.NC  published:2016-11-16 summary:Brain function results from communication between neurons connected by complex synaptic networks. Synapses are themselves highly complex and diverse signaling machines, containing protein products of hundreds of different genes, some in hundreds of copies, arranged in precise lattice at each individual synapse. Synapses are fundamental not only to synaptic network function but also to network development, adaptation, and memory. In addition, abnormalities of synapse numbers or molecular components are implicated in most mental and neurological disorders. Despite their obvious importance, mammalian synapse populations have so far resisted detailed quantitative study. In human brains and most animal nervous systems, synapses are very small and very densely packed: there are approximately 1 billion synapses per cubic millimeter of human cortex. This volumetric density poses very substantial challenges to proteometric analysis at the critical level of the individual synapse. The present work describes new probabilistic image analysis methods for single-synapse analysis of synapse populations in both animal and human brains. version:1
arxiv-1611-05476 | Self-calibration-based Approach to Critical Motion Sequences of Rolling-shutter Structure from Motion | http://arxiv.org/abs/1611.05476 | id:1611.05476 author:Eisuke Ito, Takayuki Okatani category:cs.CV  published:2016-11-16 summary:In this paper we consider critical motion sequences (CMSs) of rolling-shutter (RS) SfM. Employing an RS camera model with linearized pure rotation, we show that the RS distortion can be approximately expressed by two internal parameters of an "imaginary" camera plus one-parameter nonlinear transformation similar to lens distortion. We then reformulate the problem as self-calibration of the imaginary camera, in which its skew and aspect ratio are unknown and varying in the image sequence. In the formulation, we derive a general representation of CMSs. We also show that our method can explain the CMS that was recently reported in the literature, and then present a new remedy to deal with the degeneracy. Our theoretical results agree well with experimental results; it explains degeneracies observed when we employ naive bundle adjustment, and how they are resolved by our method. version:1
arxiv-1611-05469 | Embedding Projector: Interactive Visualization and Interpretation of Embeddings | http://arxiv.org/abs/1611.05469 | id:1611.05469 author:Daniel Smilkov, Nikhil Thorat, Charles Nicholson, Emily Reif, Fernanda B. Viégas, Martin Wattenberg category:stat.ML cs.HC  published:2016-11-16 summary:Embeddings are ubiquitous in machine learning, appearing in recommender systems, NLP, and many other applications. Researchers and developers often need to explore the properties of a specific embedding, and one way to analyze embeddings is to visualize them. We present the Embedding Projector, a tool for interactive visualization and interpretation of embeddings. version:1
arxiv-1611-05433 | ROS Regression: Integrating Regularization and Optimal Scaling Regression | http://arxiv.org/abs/1611.05433 | id:1611.05433 author:Jacqueline J. Meulman, Anita J. van der Kooij category:stat.ML  published:2016-11-16 summary:In this paper we combine two important extensions of ordinary least squares regression: regularization and optimal scaling. Optimal scaling (sometimes also called optimal scoring) has originally been developed for categorical data, and the process finds quantifications for the categories that are optimal for the regression model in the sense that they maximize the multiple correlation. Although the optimal scaling method was developed initially for variables with a limited number of categories, optimal transformations of continuous variables are a special case. We will consider a variety of transformation types; typically we use step functions for categorical variables, and smooth (spline) functions for continuous variables. Both types of functions can be restricted to be monotonic, preserving the ordinal information in the data. In addition to optimal scaling, three regularization methods will be considered: Ridge regression, the Lasso, and the Elastic Net. The resulting method will be called ROS Regression (Regularized Optimal Scaling Regression. We will show that the basic OS algorithm provides straightforward and efficient estimation of the regularized regression coefficients, automatically gives the Group Lasso and Blockwise Sparse Regression, and extends them with monotonicity properties. We will show that Optimal Scaling linearizes nonlinear relationships between predictors and outcome, and improves upon the condition of the predictor correlation matrix, increasing (on average) the conditional independence of the predictors. Alternative options for regularization of either regression coefficients or category quantifications are mentioned. Extended examples are provided. Keywords: Categorical Data, Optimal Scaling, Conditional Independence, Step Functions, Splines, Monotonic Transformations, Regularization, Lasso, Elastic Net, Group Lasso, Blockwise Sparse Regression. version:1
arxiv-1611-05431 | Aggregated Residual Transformations for Deep Neural Networks | http://arxiv.org/abs/1611.05431 | id:1611.05431 author:Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He category:cs.CV  published:2016-11-16 summary:We present a simple, highly modularized network architecture for image classification. Our network is constructed by repeating a building block that aggregates a set of transformations with the same topology. Our simple design results in a homogeneous, multi-branch architecture that has only a few hyper-parameters to set. This strategy exposes a new dimension, which we call "cardinality" (the size of the set of transformations), as an essential factor in addition to the dimensions of depth and width. On the ImageNet-1K dataset, we empirically show that even under the restricted condition of maintaining complexity, increasing cardinality is able to improve classification accuracy. Moreover, increasing cardinality is more effective than going deeper or wider when we increase the capacity. Our models, codenamed ResNeXt, are the foundations of our entry to the ILSVRC 2016 classification task in which we secured 2nd place. We further investigate ResNeXt on an ImageNet-5K set and the COCO detection set, also showing better results than its ResNet counterpart. version:1
arxiv-1611-05425 | ProjE: Embedding Projection for Knowledge Graph Completion | http://arxiv.org/abs/1611.05425 | id:1611.05425 author:Baoxu Shi, Tim Weninger category:cs.AI stat.ML  published:2016-11-16 summary:With the large volume of new information created every day, determining the validity of information in a knowledge graph and filling in its missing parts are crucial tasks for many researchers and practitioners. To address this challenge, a number of knowledge graph completion methods have been developed using low-dimensional graph embeddings. Although researchers continue to improve these models using an increasingly complex feature space, we show that simple changes in the architecture of the underlying model can outperform state-of-the-art models without the need for complex feature engineering. In this work, we present a shared variable neural network model called ProjE that fills-in missing information in a knowledge graph by learning joint embeddings of the knowledge graph's entities and edges, and through subtle, but important, changes to the standard loss function. In doing so, ProjE has a parameter size that is smaller than 11 out of 15 existing methods while performing $37\%$ better than the current-best method on standard datasets. We also show, via a new fact checking task, that ProjE is capable of accurately determining the veracity of many declarative statements. version:1
arxiv-1611-05424 | Associative Embedding:End-to-End Learning for Joint Detection and Grouping | http://arxiv.org/abs/1611.05424 | id:1611.05424 author:Alejandro Newell, Jia Deng category:cs.CV  published:2016-11-16 summary:We introduce associative embedding, a novel method for supervising convolutional neural networks for the task of detection and grouping. A number of computer vision problems can be framed in this manner including multi-person pose estimation, instance segmentation, and multi-object tracking. Usually the grouping of detections is achieved with multi-stage pipelines, instead we propose an approach that teaches a network to simultaneously output detections and group assignments. This technique can be easily integrated into any state-of-the-art network architecture that produces pixel-wise predictions. We show how to apply this method to both multi-person pose estimation and instance segmentation. We present results for both tasks, and report state-of-the-art performance for multi-person pose. version:1
arxiv-1611-05418 | VisualBackProp: visualizing CNNs for autonomous driving | http://arxiv.org/abs/1611.05418 | id:1611.05418 author:Mariusz Bojarski, Anna Choromanska, Krzysztof Choromanski, Bernhard Firner, Larry Jackel, Urs Muller, Karol Zieba category:cs.CV  published:2016-11-16 summary:This paper proposes a new method, that we call VisualBackProp, for visualizing which sets of pixels of the input image contribute most to the predictions made by the convolutional neural network (CNN). The method heavily hinges on exploring the intuition that the feature maps contain less and less irrelevant information to the prediction decision when moving deeper into the network. The technique we propose was developed as a debugging tool for CNN-based systems for steering self-driving cars and is therefore required to run in real-time, i.e. it was designed to require less computation than a forward propagation. This makes the presented visualization method a valuable debugging tool which can be easily used during both training and inference. We furthermore justify our approach with theoretical arguments and theoretically confirm that the proposed method identifies sets of input pixels, rather than individual pixels, that collaboratively contribute to the prediction. Our theoretical findings stand in agreement with experimental results. The empirical evaluation shows the plausibility of the proposed approach on road data. version:1
arxiv-1611-05416 | Grammar Argumented LSTM Neural Networks with Note-Level Encoding for Music Composition | http://arxiv.org/abs/1611.05416 | id:1611.05416 author:Zheng Sun, Jiaqi Liu, Zewang Zhang, Jingwen Chen, Zhao Huo, Ching Hua Lee, Xiao Zhang category:cs.LG cs.AI cs.SD  published:2016-11-16 summary:Creating any aesthetically pleasing piece of art, like music, has been a long time dream for artificial intelligence research. Based on recent success of long-short term memory (LSTM) on sequence learning, we put forward a novel system to reflect the thinking pattern of a musician. For data representation, we propose a note-level encoding method, which enables our model to simulate how human composes and polishes music phrases. To avoid failure against music theory, we invent a novel method, grammar argumented (GA) method. It can teach machine basic composing principles. In this method, we propose three rules as argumented grammars and three metrics for evaluation of machine-made music. Results show that comparing to basic LSTM, grammar argumented model's compositions have higher contents of diatonic scale notes, short pitch intervals, and chords. version:1
arxiv-1611-05407 | A Semidefinite Program for Structured Blockmodels | http://arxiv.org/abs/1611.05407 | id:1611.05407 author:David Choi category:math.ST stat.ML stat.TH  published:2016-11-16 summary:Semidefinite programs have recently been developed for the problem of community detection, which may be viewed as a special case of the stochastic blockmodel. Here, we develop a semidefinite program that can be tailored to other instances of the blockmodel, such as non-assortative networks and overlapping communities. We establish label recovery in sparse settings, with conditions that are analogous to recent results for community detection. In settings where the data is not generated by a blockmodel, we give an oracle inequality that bounds excess risk relative to the best blockmodel approximation. Simulations are presented for community detection, for overlapping communities, and for latent space models. version:1
arxiv-1611-05402 | ZipML: An End-to-end Bitwise Framework for Dense Generalized Linear Models | http://arxiv.org/abs/1611.05402 | id:1611.05402 author:Hantian Zhang, Kaan Kara, Jerry Li, Dan Alistarh, Ji Liu, Ce Zhang category:cs.LG stat.ML  published:2016-11-16 summary:We present ZipML, the first framework for training dense generalized linear models using end-to-end low-precision representation--in ZipML, all movements of data, including those for input samples, model, and gradients, are represented using as little as two bits per component. Within our framework, we have successfully compressed, separately, the input data by 16x, gradient by 16x, and model by 16x while still getting the same training result. Even for the most challenging datasets, we find that robust convergence can be ensured using only an end-to-end 8-bit representation or a 6-bit representation if only samples are quantized. Our work builds on previous research on using low-precision representations for gradient and model in the context of stochastic gradient descent. Our main technical contribution is a new set of techniques which allow the training samples to be processed with low precision, without affecting the convergence of the algorithm. In turn, this leads to a system where all data items move in a quantized, low precision format. In particular, we first establish that randomized rounding, while sufficient when quantizing the model and the gradients, is biased when quantizing samples, and thus leads to a different training result. We propose two new data representations which converge to the same solution as in the original data representation both in theory and empirically and require as little as 2-bits per component. As a result, if the original data is stored as 32-bit floats, we decrease the bandwidth footprint for each training iteration by up to 16x. Our results hold for models such as linear regression and least squares SVM. ZipML raises interesting theoretical questions related to the robustness of SGD to approximate data, model, and gradient representations. We conclude this working paper by a description of ongoing work extending these preliminary results. version:1
arxiv-1611-00284 | Dictionary Integration using 3D Morphable Face Models for Pose-invariant Collaborative-representation-based Classification | http://arxiv.org/abs/1611.00284 | id:1611.00284 author:Xiaoning Song, Zhen-Hua Feng, Guosheng Hu, Josef Kittler, William Christmas, Xiao-Jun Wu category:cs.CV  published:2016-11-01 summary:The paper presents a dictionary integration algorithm using 3D morphable face models (3DMM) for pose-invariant collaborative-representation-based face classification. To this end, we first fit a 3DMM to the 2D face images of a dictionary to reconstruct the 3D shape and texture of each image. The 3D faces are used to render a number of virtual 2D face images with arbitrary pose variations to augment the training data, by merging the original and rendered virtual samples {\color{black}to create} an extended dictionary. Second, to reduce the information redundancy of the extended dictionary and improve the sparsity of reconstruction coefficient vectors using collaborative-representation-based classification (CRC), we exploit an on-line elimination scheme to optimise the extended dictionary by identifying the most representative training samples for a given query. The final goal is to perform pose-invariant face classification using the proposed dictionary integration method and the on-line pruning strategy under the CRC framework. Experimental results obtained for a set of well-known face datasets demonstrate the merits of the proposed method, especially its robustness to pose variations. version:2
arxiv-1611-05397 | Reinforcement Learning with Unsupervised Auxiliary Tasks | http://arxiv.org/abs/1611.05397 | id:1611.05397 author:Max Jaderberg, Volodymyr Mnih, Wojciech Marian Czarnecki, Tom Schaul, Joel Z Leibo, David Silver, Koray Kavukcuoglu category:cs.LG cs.NE  published:2016-11-16 summary:Deep reinforcement learning agents have achieved state-of-the-art results by directly maximising cumulative reward. However, environments contain a much wider variety of possible training signals. In this paper, we introduce an agent that also maximises many other pseudo-reward functions simultaneously by reinforcement learning. All of these tasks share a common representation that, like unsupervised learning, continues to develop in the absence of extrinsic rewards. We also introduce a novel mechanism for focusing this representation upon extrinsic rewards, so that learning can rapidly adapt to the most relevant aspects of the actual task. Our agent significantly outperforms the previous state-of-the-art on Atari, averaging 880\% expert human performance, and a challenging suite of first-person, three-dimensional \emph{Labyrinth} tasks leading to a mean speedup in learning of 10$\times$ and averaging 87\% expert human performance on Labyrinth. version:1
arxiv-1611-05396 | Dynamic Attention-controlled Cascaded Shape Regression Exploiting Training Data Augmentation and Fuzzy-set Sample Weighting | http://arxiv.org/abs/1611.05396 | id:1611.05396 author:Zhen-Hua Feng, Josef Kittler, William Christmas, Patrik Huber, Xiao-Jun Wu category:cs.CV  published:2016-11-16 summary:We present a new Cascaded Shape Regression (CSR) architecture, namely Dynamic Attention-Controlled CSR (DAC-CSR), for robust facial landmark detection on unconstrained faces. Our DAC-CSR divides facial landmark detection into three cascaded sub-tasks: face bounding box refinement, general CSR and attention-controlled CSR. The first two stages refine initial face bounding boxes and output intermediate facial landmarks. Then, an online dynamic model selection method is used to choose appropriate domain-specific CSRs for further landmark refinement. The key innovation of our DAC-CSR is the fault-tolerant mechanism, using fuzzy set sample weighting for attention-controlled domain-specific model training. Moreover, we advocate data augmentation with a simple but effective 2D profile face generator, and context-aware feature extraction for better facial feature representation. Experimental results obtained on challenging datasets demonstrate the merits of our DAC-CSR over the state-of-the-art. version:1
arxiv-1611-03852 | A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models | http://arxiv.org/abs/1611.03852 | id:1611.03852 author:Chelsea Finn, Paul Christiano, Pieter Abbeel, Sergey Levine category:cs.LG cs.AI  published:2016-11-11 summary:Generative adversarial networks (GANs) are a recently proposed class of generative models in which a generator is trained to optimize a cost function that is being simultaneously learned by a discriminator. While the idea of learning cost functions is relatively new to the field of generative modeling, learning costs has long been studied in control and reinforcement learning (RL) domains, typically for imitation learning from demonstrations. In these fields, learning cost function underlying observed behavior is known as inverse reinforcement learning (IRL) or inverse optimal control. While at first the connection between cost learning in RL and cost learning in generative modeling may appear to be a superficial one, we show in this paper that certain IRL methods are in fact mathematically equivalent to GANs. In particular, we demonstrate an equivalence between a sample-based algorithm for maximum entropy IRL and a GAN in which the generator's density can be evaluated and is provided as an additional input to the discriminator. Interestingly, maximum entropy IRL is a special case of an energy-based model. We discuss the interpretation of GANs as an algorithm for training energy-based models, and relate this interpretation to other recent work that seeks to connect GANs and EBMs. By formally highlighting the connection between GANs, IRL, and EBMs, we hope that researchers in all three communities can better identify and apply transferable ideas from one domain to another, particularly for developing more stable and scalable algorithms: a major challenge in all three domains. version:2
arxiv-1611-05384 | A Long Dependency Aware Deep Architecture for Joint Chinese Word Segmentation and POS Tagging | http://arxiv.org/abs/1611.05384 | id:1611.05384 author:Xinchi Chen, Xipeng Qiu, Xuanjing Huang category:cs.CL  published:2016-11-16 summary:Long-term context is crucial to joint Chinese word segmentation and POS tagging (S&T) task. However, most of machine learning based methods extract features from a window of characters. Due to the limitation of window size, these methods can not exploit the long distance information. In this work, we propose a long dependency aware deep architecture for joint S&T task. Specifically, to simulate the feature templates of traditional discrete feature based models, we use different filters to model the complex compositional features with convolutional and pooling layer, and then utilize long distance dependency information with recurrent layer. Experiment results on five different datasets show the effectiveness of our proposed model. version:1
arxiv-1611-05379 | PCT and Beyond: Towards a Computational Framework for `Intelligent' Communicative Systems | http://arxiv.org/abs/1611.05379 | id:1611.05379 author:Prof. Roger K. Moore category:cs.AI cs.CL cs.HC cs.RO  published:2016-11-16 summary:Recent years have witnessed increasing interest in the potential benefits of `intelligent' autonomous machines such as robots. Honda's Asimo humanoid robot, iRobot's Roomba robot vacuum cleaner and Google's driverless cars have fired the imagination of the general public, and social media buzz with speculation about a utopian world of helpful robot assistants or the coming robot apocalypse! However, there is a long way to go before autonomous systems reach the level of capabilities required for even the simplest of tasks involving human-robot interaction - especially if it involves communicative behaviour such as speech and language. Of course the field of Artificial Intelligence (AI) has made great strides in these areas, and has moved on from abstract high-level rule-based paradigms to embodied architectures whose operations are grounded in real physical environments. What is still missing, however, is an overarching theory of intelligent communicative behaviour that informs system-level design decisions in order to provide a more coherent approach to system integration. This chapter introduces the beginnings of such a framework inspired by the principles of Perceptual Control Theory (PCT). In particular, it is observed that PCT has hitherto tended to view perceptual processes as a relatively straightforward series of transformations from sensation to perception, and has overlooked the potential of powerful generative model-based solutions that have emerged in practical fields such as visual or auditory scene analysis. Starting from first principles, a sequence of arguments is presented which not only shows how these ideas might be integrated into PCT, but which also extend PCT towards a remarkably symmetric architecture for a needs-driven communicative agent. It is concluded that, if behaviour is the control of perception, then perception is the simulation of behaviour. version:1
arxiv-1611-05378 | Spectral Convolution Networks | http://arxiv.org/abs/1611.05378 | id:1611.05378 author:Maria Francesca, Arthur Hughes, David Gregg category:cs.LG stat.ML  published:2016-11-16 summary:Previous research has shown that computation of convolution in the frequency domain provides a significant speedup versus traditional convolution network implementations. However, this performance increase comes at the expense of repeatedly computing the transform and its inverse in order to apply other network operations such as activation, pooling, and dropout. We show, mathematically, how convolution and activation can both be implemented in the frequency domain using either the Fourier or Laplace transformation. The main contributions are a description of spectral activation under the Fourier transform and a further description of an efficient algorithm for computing both convolution and activation under the Laplace transform. By computing both the convolution and activation functions in the frequency domain, we can reduce the number of transforms required, as well as reducing overall complexity. Our description of a spectral activation function, together with existing spectral analogs of other network functions may then be used to compose a fully spectral implementation of a convolution network. version:1
arxiv-1611-05377 | Fully-adaptive Feature Sharing in Multi-Task Networks with Applications in Person Attribute Classification | http://arxiv.org/abs/1611.05377 | id:1611.05377 author:Yongxi Lu, Abhishek Kumar, Shuangfei Zhai, Yu Cheng, Tara Javidi, Rogerio Feris category:cs.CV cs.LG  published:2016-11-16 summary:Multi-task learning aims to improve generalization performance of multiple prediction tasks by appropriately sharing relevant information across them. In the context of deep neural networks, this idea is often realized by hand-designed network architectures with layers that are shared across tasks and branches that encode task-specific features. However, the space of possible multi-task deep architectures is combinatorially large and often the final architecture is arrived at by manual exploration of this space subject to designer's bias, which can be both error-prone and tedious. In this work, we propose a principled approach for designing compact multi-task deep learning architectures. Our approach starts with a thin network and dynamically widens it in a greedy manner during training using a novel criterion that promotes grouping of similar tasks together. Our Extensive evaluation on person attributes classification tasks involving facial and clothing attributes suggests that the models produced by the proposed method are fast, compact and can closely match or exceed the state-of-the-art accuracy from strong baselines by much more expensive models. version:1
arxiv-1610-09756 | Towards Deep Learning in Hindi NER: An approach to tackle the Labelled Data Scarcity | http://arxiv.org/abs/1610.09756 | id:1610.09756 author:Vinayak Athavale, Shreenivas Bharadwaj, Monik Pamecha, Ameya Prabhu, Manish Shrivastava category:cs.CL cs.LG  published:2016-10-31 summary:In this paper we describe an end to end Neural Model for Named Entity Recognition NER) which is based on Bi-Directional RNN-LSTM. Almost all NER systems for Hindi use Language Specific features and handcrafted rules with gazetteers. Our model is language independent and uses no domain specific features or any handcrafted rules. Our models rely on semantic information in the form of word vectors which are learnt by an unsupervised learning algorithm on an unannotated corpus. Our model attained state of the art performance in both English and Hindi without the use of any morphological analysis or without using gazetteers of any sort. version:2
arxiv-1611-05373 | DeepCas: an End-to-end Predictor of Information Cascades | http://arxiv.org/abs/1611.05373 | id:1611.05373 author:Cheng Li, Jiaqi Ma, Xiaoxiao Guo, Qiaozhu Mei category:cs.SI cs.LG  published:2016-11-16 summary:Information cascades, effectively facilitated by most social network platforms, are recognized as a major factor in almost every social success and disaster in these networks. Can cascades be predicted? While many believe that they are inherently unpredictable, recent work has shown that some key properties of information cascades, such as size, growth, and shape, can be predicted by a machine learning algorithm that combines many features. These predictors all depend on a bag of hand-crafting features to represent the cascade network and the global network structure. Such features, always carefully and sometimes mysteriously designed, are not easy to extend or to generalize to a different platform or domain. Inspired by the recent successes of deep learning in multiple data mining tasks, we investigate whether an end-to-end deep learning approach could effectively predict the future size of cascades. Such a method automatically learns the representation of individual cascade graphs in the context of the global network structure, without hand-crafted features and heuristics. We find that node embeddings fall short of predictive power, and it is critical to learn the representation of a cascade graph as a whole. We present algorithms that learn the representation of cascade graphs in an end-to-end manner, which significantly improve the performance of cascade prediction over strong baselines that include feature based methods, node embedding methods, and graph kernel methods. Our results also provide interesting implications for cascade prediction in general. version:1
arxiv-1611-05369 | Fast On-Line Kernel Density Estimation for Active Object Localization | http://arxiv.org/abs/1611.05369 | id:1611.05369 author:Anthony D. Rhodes, Max H. Quinn, Melanie Mitchell category:cs.CV cs.LG  published:2016-11-16 summary:A major goal of computer vision is to enable computers to interpret visual situations---abstract concepts (e.g., "a person walking a dog," "a crowd waiting for a bus," "a picnic") whose image instantiations are linked more by their common spatial and semantic structure than by low-level visual similarity. In this paper, we propose a novel method for prior learning and active object localization for this kind of knowledge-driven search in static images. In our system, prior situation knowledge is captured by a set of flexible, kernel-based density estimations---a situation model---that represent the expected spatial structure of the given situation. These estimations are efficiently updated by information gained as the system searches for relevant objects, allowing the system to use context as it is discovered to narrow the search. More specifically, at any given time in a run on a test image, our system uses image features plus contextual information it has discovered to identify a small subset of training images---an importance cluster---that is deemed most similar to the given test image, given the context. This subset is used to generate an updated situation model in an on-line fashion, using an efficient multipole expansion technique. As a proof of concept, we apply our algorithm to a highly varied and challenging dataset consisting of instances of a "dog-walking" situation. Our results support the hypothesis that dynamically-rendered, context-based probability models can support efficient object localization in visual situations. Moreover, our approach is general enough to be applied to diverse machine learning paradigms requiring interpretable, probabilistic representations generated from partially observed data. version:1
arxiv-1611-05368 | Neural Style Representations and the Large-Scale Classification of Artistic Style | http://arxiv.org/abs/1611.05368 | id:1611.05368 author:Jeremiah Johnson category:cs.CV cs.AI cs.IR stat.AP stat.ML  published:2016-11-16 summary:The artistic style of a painting is a subtle aesthetic judgment used by art historians for grouping and classifying artwork. The recently introduced `neural-style' algorithm substantially succeeds in merging the perceived artistic style of one image or set of images with the perceived content of another. In light of this and other recent developments in image analysis via convolutional neural networks, we investigate the effectiveness of a `neural-style' representation for classifying the artistic style of paintings. version:1
arxiv-1611-05360 | The Life of Lazarillo de Tormes and of His Machine Learning Adversities | http://arxiv.org/abs/1611.05360 | id:1611.05360 author:Javier de la Rosa, Juan-Luis Suárez category:cs.CL  published:2016-11-16 summary:Summit work of the Spanish Golden Age and forefather of the so-called picaresque novel, The Life of Lazarillo de Tormes and of His Fortunes and Adversities still remains an anonymous text. Although distinguished scholars have tried to attribute it to different authors based on a variety of criteria, a consensus has yet to be reached. The list of candidates is long and not all of them enjoy the same support within the scholarly community. Analyzing their works from a data-driven perspective and applying machine learning techniques for style and text fingerprinting, we shed light on the authorship of the Lazarillo. As in a state-of-the-art survey, we discuss the methods used and how they perform in our specific case. According to our methodology, the most likely author seems to be Juan Arce de Ot\'alora, closely followed by Alfonso de Vald\'es. The method states that not certain attribution can be made with the given corpus. version:1
arxiv-1611-05358 | Lip Reading Sentences in the Wild | http://arxiv.org/abs/1611.05358 | id:1611.05358 author:Joon Son Chung, Andrew Senior, Oriol Vinyals, Andrew Zisserman category:cs.CV  published:2016-11-16 summary:The goal of this work is to recognise phrases and sentences being spoken by a talking face, with or without the audio. Unlike previous works that have focussed on recognising a limited number of words or phrases, we tackle lip reading as an open-world problem - unconstrained natural language sentences, and in the wild videos. Our key contributions are: (1) a 'Watch, Listen, Attend and Spell' (WLAS) network that learns to transcribe videos of mouth motion to characters; (2) a curriculum learning strategy to accelerate training and to reduce overfitting; (3) a 'Lip Reading Sentences' (LRS) dataset for visual speech recognition, consisting of over 100,000 natural sentences from British television. The WLAS model trained on the LRS dataset surpasses the performance of all previous work on standard lip reading benchmark datasets, often by a significant margin. This lip reading performance beats a professional lip reader on videos from BBC television, and we also demonstrate that visual information helps to improve speech recognition performance even when the audio is available. version:1
arxiv-1611-05335 | Exploiting Visual-Spatial First-Person Co-Occurrence for Action-Object Detection without Labels | http://arxiv.org/abs/1611.05335 | id:1611.05335 author:Gedas Bertasius, Stella X. Yu, Jianbo Shi category:cs.CV  published:2016-11-16 summary:Many first-person vision tasks such as activity recognition or video summarization requires knowing, which objects the camera wearer is interacting with (i.e. action-objects). The standard way to obtain this information is via a manual annotation, which is costly and time consuming. Also, whereas for the third-person tasks such as object detection, the annotator can be anybody, action-object detection task requires the camera wearer to annotate the data because a third-person may not know what the camera wearer was thinking. Such a constraint makes it even more difficult to obtain first-person annotations. To address this problem, we propose a Visual-Spatial Network (VSN) that detects action-objects without using any first-person labels. We do so (1) by exploiting the visual-spatial co-occurrence in the first-person data and (2) by employing an alternating cross-pathway supervision between the visual and spatial pathways of our VSN. During training, we use a selected action-object prior location to initialize the pseudo action-object ground truth, which is then used to optimize both pathways in an alternating fashion. The predictions from the spatial pathway are used to update the pseudo ground truth for the visual pathway and vice versa, which allows both pathways to improve each other. We show our method's success on two different action-object datasets, where our method achieves similar or better results than the supervised methods. We also show that our method can be successfully used as pretraining for a supervised action-object detection task. version:1
arxiv-1611-05328 | Image Credibility Analysis with Effective Domain Transferred Deep Networks | http://arxiv.org/abs/1611.05328 | id:1611.05328 author:Zhiwei Jin, Juan Cao, Jiebo Luo, Yongdong Zhang category:cs.MM cs.CV  published:2016-11-16 summary:Numerous fake images spread on social media today and can severely jeopardize the credibility of online content to public. In this paper, we employ deep networks to learn distinct fake image related features. In contrast to authentic images, fake images tend to be eye-catching and visually striking. Compared with traditional visual recognition tasks, it is extremely challenging to understand these psychologically triggered visual patterns in fake images. Traditional general image classification datasets, such as ImageNet set, are designed for feature learning at the object level but are not suitable for learning the hyper-features that would be required by image credibility analysis. In order to overcome the scarcity of training samples of fake images, we first construct a large-scale auxiliary dataset indirectly related to this task. This auxiliary dataset contains 0.6 million weakly-labeled fake and real images collected automatically from social media. Through an AdaBoost-like transfer learning algorithm, we train a CNN model with a few instances in the target training set and 0.6 million images in the collected auxiliary set. This learning algorithm is able to leverage knowledge from the auxiliary set and gradually transfer it to the target task. Experiments on a real-world testing set show that our proposed domain transferred CNN model outperforms several competing baselines. It obtains superiror results over transfer learning methods based on the general ImageNet set. Moreover, case studies show that our proposed method reveals some interesting patterns for distinguishing fake and authentic images. version:1
arxiv-1611-05321 | Bootstrap, Review, Decode: Using Out-of-Domain Textual Data to Improve Image Captioning | http://arxiv.org/abs/1611.05321 | id:1611.05321 author:Wenhu Chen, Aurelien Lucchi, Thomas Hofmann category:cs.CV  published:2016-11-16 summary:We propose a novel way of using out-of-domain textual data to enhance the performance of existing image captioning systems. We evaluate this learning approach on a newly designed model that uses - and improves upon - building blocks from state-of-the-art methods. This model starts from detecting visual concepts present in an image which are then fed to a reviewer-decoder architecture with an attention mechanism. Unlike previous approaches that encode visual concepts using word embeddings, we instead suggest using regional image features which capture more intrinsic information. The main benefit of this architecture is that it synthesizes meaningful thought vectors that capture salient image properties and then applies a soft attentive decoder to decode the thought vectors and generate image captions. We evaluate our model on both Microsoft COCO and Flickr30K datasets and demonstrate that this model combined with our bootstrap learning method can largely improve performance and help the model to generate more accurate and diverse captions. version:1
arxiv-1611-05301 | Generalisation and Sharing in Triplet Convnets for Sketch based Visual Search | http://arxiv.org/abs/1611.05301 | id:1611.05301 author:Tu Bui, Leonardo Ribeiro, Moacir Ponti, John Collomosse category:cs.CV  published:2016-11-16 summary:We propose and evaluate several triplet CNN architectures for measuring the similarity between sketches and photographs, within the context of the sketch based image retrieval (SBIR) task. In contrast to recent fine-grained SBIR work, we study the ability of our networks to generalise across diverse object categories from limited training data, and explore in detail strategies for weight sharing, pre-processing, data augmentation and dimensionality reduction. We exceed the performance of pre-existing techniques on both the Flickr15k category level SBIR benchmark by $18\%$, and the TU-Berlin SBIR benchmark by $\sim10 \mathcal{T}_b$, when trained on the 250 category TU-Berlin classification dataset augmented with 25k corresponding photographs harvested from the Internet. version:1
arxiv-1611-05271 | DeMeshNet: Blind Face Inpainting for Deep MeshFace Verification | http://arxiv.org/abs/1611.05271 | id:1611.05271 author:Shu Zhang, Ran He, Tieniu Tan category:cs.CV  published:2016-11-16 summary:MeshFace photos have been widely used in many Chinese business organizations to protect ID face photos from being misused. The occlusions incurred by random meshes severely degenerate the performance of face verification systems, which raises the MeshFace verification problem between MeshFace and daily photos. Previous methods cast this problem as a typical low-level vision problem, i.e. blind inpainting. They recover perceptually pleasing clear ID photos from MeshFaces by enforcing pixel level similarity between the recovered ID images and the ground-truth clear ID images and then perform face verification on them. Essentially, face verification is conducted on a compact feature space rather than the image pixel space. Therefore, this paper argues that pixel level similarity and feature level similarity jointly offer the key to improve the verification performance. Based on this insight, we offer a novel feature oriented blind face inpainting framework. Specifically, we implement this by establishing a novel DeMeshNet, which consists of three parts. The first part addresses blind inpainting of the MeshFaces by implicitly exploiting extra supervision from the occlusion position to enforce pixel level similarity. The second part explicitly enforces a feature level similarity in the compact feature space, which can explore informative supervision from the feature space to produce better inpainting results for verification. The last part copes with face alignment within the net via a customized spatial transformer module when extracting deep facial features. All the three parts are implemented within an end-to-end network that facilitates efficient optimization. Extensive experiments on two MeshFace datasets demonstrate the effectiveness of the proposed DeMeshNet as well as the insight of this paper. version:1
arxiv-1611-05267 | Temporal Convolutional Networks for Action Segmentation and Detection | http://arxiv.org/abs/1611.05267 | id:1611.05267 author:Colin Lea, Michael D. Flynn, Rene Vidal, Austin Reiter, Gregory D. Hager category:cs.CV  published:2016-11-16 summary:The ability to identify and temporally segment fine-grained human actions throughout a video is crucial for robotics, surveillance, education, and beyond. Typical approaches decouple this problem by first extracting local spatiotemporal features from video frames and then feeding them into a temporal classifier that captures high-level temporal patterns. We introduce a new class of temporal models, which we call Temporal Convolutional Networks (TCNs), that use a hierarchy of temporal convolutions to perform fine-grained action segmentation or detection. Our Encoder-Decoder TCN uses pooling and upsampling to efficiently capture long-range temporal patterns whereas our Dilated TCN uses dilated convolutions. We show that TCNs are capable of capturing action compositions, segment durations, and long-range dependencies, and are over a magnitude faster to train than competing LSTM-based Recurrent Neural Networks. We apply these models to three challenging fine-grained datasets and show large improvements over the state of the art. version:1
arxiv-1611-05250 | Real-Time Video Super-Resolution with Spatio-Temporal Networks and Motion Compensation | http://arxiv.org/abs/1611.05250 | id:1611.05250 author:Jose Caballero, Christian Ledig, Andrew Aitken, Alejandro Acosta, Johannes Totz, Zehan Wang, Wenzhe Shi category:cs.CV  published:2016-11-16 summary:Convolutional neural networks have enabled accurate image super-resolution in real-time. However, recent attempts to benefit from temporal correlations in video super-resolution have been limited to naive or inefficient architectures. In this paper, we introduce spatio-temporal sub-pixel convolution networks that effectively exploit temporal redundancies and improve reconstruction accuracy while maintaining real-time speed. Specifically, we discuss the use of early fusion, slow fusion and 3D convolutions for the joint processing of multiple consecutive video frames. We also propose a novel joint motion compensation and video super-resolution algorithm that is orders of magnitude more efficient than competing methods, relying on a fast multi-resolution spatial transformer module that is end-to-end trainable. These contributions provide both higher accuracy and temporally more consistent videos, which we confirm qualitatively and quantitatively. Relative to single-frame models, spatio-temporal networks can either reduce the computational cost by 30% whilst maintaining the same quality or provide a 0.2dB gain for a similar computational cost. Results on publicly available datasets demonstrate that the proposed algorithms surpass current state-of-the-art performance in both accuracy and efficiency. version:1
arxiv-1611-05241 | A Combinatorial Solution to Non-Rigid 3D Shape-to-Image Matching | http://arxiv.org/abs/1611.05241 | id:1611.05241 author:Florian Bernard, Frank R. Schmidt, Johan Thunberg, Daniel Cremers category:cs.CV math.OC  published:2016-11-16 summary:We propose a combinatorial solution for the problem of non-rigidly matching a 3D shape to 3D image data. To this end, we model the shape as a triangular mesh and allow each triangle of this mesh to be rigidly transformed to achieve a suitable matching to the image. By penalising the distance and the relative rotation between neighbouring triangles our matching compromises between the image and the shape information. In this paper, we resolve two major challenges: Firstly, we address the resulting large and NP-hard combinatorial problem with a suitable graph-theoretic approach. Secondly, we propose an efficient discretisation of the unbounded 6-dimensional Lie group SE(3). To our knowledge this is the first combinatorial formulation for non-rigid 3D shape-to-image matching. In contrast to existing local (gradient descent) optimisation methods, we obtain solutions that do not require a good initialisation and that are within a bound of the optimal solution. We evaluate the proposed combinatorial method on the two problems of non-rigid 3D shape-to-shape and non-rigid 3D shape-to-image registration and demonstrate that it provides promising results. version:1
arxiv-1611-05239 | How to do lexical quality estimation of a large OCRed historical Finnish newspaper collection with scarce resources | http://arxiv.org/abs/1611.05239 | id:1611.05239 author:Kimmo Kettunen, Tuula Pääkkönen category:cs.CL  published:2016-11-16 summary:The National Library of Finland has digitized the historical newspapers published in Finland between 1771 and 1910. This collection contains approximately 1.95 million pages in Finnish and Swedish. Finnish part of the collection consists of about 2.40 billion words. The National Library's Digital Collections are offered via the digi.kansalliskirjasto.fi web service, also known as Digi. Part of the newspaper material (from 1771 to 1874) is also available freely downloadable in The Language Bank of Finland provided by the FINCLARIN consortium. The collection can also be accessed through the Korp environment that has been developed by Spr{\aa}kbanken at the University of Gothenburg and extended by FINCLARIN team at the University of Helsinki to provide concordances of text resources. A Cranfield style information retrieval test collection has also been produced out of a small part of the Digi newspaper material at the University of Tampere. Quality of OCRed collections is an important topic in digital humanities, as it affects general usability and searchability of collections. There is no single available method to assess quality of large collections, but different methods can be used to approximate quality. This paper discusses different corpus analysis style methods to approximate overall lexical quality of the Finnish part of the Digi collection. Methods include usage of parallel samples and word error rates, usage of morphological analyzers, frequency analysis of words and comparisons to comparable edited lexical data. Our aim in the quality analysis is twofold: firstly to analyze the present state of the lexical data and secondly, to establish a set of assessment methods that build up a compact procedure for quality assessment after e.g. new OCRing or post correction of the material. In the discussion part of the paper we shall synthesize results of our different analyses. version:1
arxiv-1611-05216 | shuttleNet: A biologically-inspired RNN with loop connection and parameter sharing | http://arxiv.org/abs/1611.05216 | id:1611.05216 author:Yemin Shi, Yonghong Tian, Yaowei Wang, Tiejun Huang category:cs.CV  published:2016-11-16 summary:Despite a lot of research efforts devoted in recent years, how to efficiently learn long-term dependencies from sequences still remains a pretty challenging task. As one of the key models for sequence learning, recurrent neural network (RNN) and its variants such as long short term memory (LSTM) and gated recurrent unit (GRU) are still not powerful enough in practice. One possible reason is that they have only feedforward connections, which is different from biological neural network that is typically composed of both feedforward and feedback connections. To address the problem, this paper proposes a biologically-inspired RNN structure, called shuttleNet, by introducing loop connections in the network and utilizing parameter sharing to prevent overfitting. Unlike the traditional RNNs, the cells of shuttleNet are loop connected to mimic the brain's feedforward and feedback connections. The structure is then stretched in the depth dimension to generate a deeper model with multiple information flow paths, while the parameters are shared so as to prevent shuttleNet from being over-fitting. The attention mechanism is then applied to select the best information path. The extensive experiments are conducted on two datasets for action recognition: UCF101 and HMDB51. We find that our model can outperform LSTMs and GRUs remarkably. Even only replacing the LSTMs with our shuttleNet in a CNN-RNN network, we can still achieve the state-of-the-art performance on both datasets. version:1
arxiv-1611-05215 | Joint Network based Attention for Action Recognition | http://arxiv.org/abs/1611.05215 | id:1611.05215 author:Yemin Shi, Yonghong Tian, Yaowei Wang, Tiejun Huang category:cs.CV  published:2016-11-16 summary:By extracting spatial and temporal characteristics in one network, the two-stream ConvNets can achieve the state-of-the-art performance in action recognition. However, such a framework typically suffers from the separately processing of spatial and temporal information between the two standalone streams and is hard to capture long-term temporal dependence of an action. More importantly, it is incapable of finding the salient portions of an action, say, the frames that are the most discriminative to identify the action. To address these problems, a \textbf{j}oint \textbf{n}etwork based \textbf{a}ttention (JNA) is proposed in this study. We find that the fully-connected fusion, branch selection and spatial attention mechanism are totally infeasible for action recognition. Thus in our joint network, the spatial and temporal branches share some information during the training stage. We also introduce an attention mechanism on the temporal domain to capture the long-term dependence meanwhile finding the salient portions. Extensive experiments are conducted on two benchmark datasets, UCF101 and HMDB51. Experimental results show that our method can improve the action recognition performance significantly and achieves the state-of-the-art results on both datasets. version:1
arxiv-1611-05209 | Deep Variational Inference Without Pixel-Wise Reconstruction | http://arxiv.org/abs/1611.05209 | id:1611.05209 author:Siddharth Agrawal, Ambedkar Dukkipati category:stat.ML cs.CV cs.LG  published:2016-11-16 summary:Variational autoencoders (VAEs), that are built upon deep neural networks have emerged as popular generative models in computer vision. Most of the work towards improving variational autoencoders has focused mainly on making the approximations to the posterior flexible and accurate, leading to tremendous progress. However, there have been limited efforts to replace pixel-wise reconstruction, which have known shortcomings. In this work, we use real-valued non-volume preserving transformations (real NVP) to exactly compute the conditional likelihood of the data given the latent distribution. We show that a simple VAE with this form of reconstruction is competitive with complicated VAE structures, on image modeling tasks. As part of our model, we develop powerful conditional coupling layers that enable real NVP to learn with fewer intermediate layers. version:1
arxiv-1611-05203 | Will People Like Your Image? | http://arxiv.org/abs/1611.05203 | id:1611.05203 author:Katharina Schwarz, Patrick Wieschollek, Hendrik P. A. Lensch category:cs.CV  published:2016-11-16 summary:The wide distribution of digital devices as well as cheap storage allow us to take series of photos making sure not to miss any specific beautiful moment. Thereby, the huge and constantly growing image assembly makes it quite time-consuming to manually pick the best shots afterwards. Even more challenging, finding the most aesthetically pleasing images that might also be worth sharing is a largely subjective task in which general rules rarely apply. Nowadays, online platforms allow users to "like" or favor certain content with a single click. As we aim to predict the aesthetic quality of images, we now make use of such multi-user agreements. More precisely, we assemble a large data set of 380K images with associated meta information and derive a score to rate how visually pleasing a given photo is. predict the aesthetic quality of any arbitrary image or video, we transfer the Our proposed model of aesthetics is validated in a user study. We demonstrate our results on applications for resorting photo collections, capturing the best shot on mobile devices and aesthetic key-frame extraction from videos. version:1
arxiv-1611-05193 | Bayesian optimization of hyper-parameters in reservoir computing | http://arxiv.org/abs/1611.05193 | id:1611.05193 author:Jan Yperman, Thijs Becker category:cs.LG  published:2016-11-16 summary:We describe a method for searching the optimal hyper-parameters in reservoir computing, which consists of a Gaussian process with Bayesian optimization. It provides an alternative to other frequently used optimization methods such as grid, random, or manual search. In addition to a set of optimal hyper-parameters, the method also provides a probability distribution of the cost function as a function of the hyper-parameters. We apply this method to two types of reservoirs: nonlinear delay nodes and echo state networks. It shows excellent performance on all considered benchmarks, either matching or significantly surpassing expert human optimization. We find that some values for hyper-parameters that have become standard in the research community, are in fact suboptimal for most of the problems we considered. In general, the algorithm achieves optimal results in fewer iterations when compared to other optimization methods, and scales well with increasing dimensionality of the hyper-parameter space. Due to its automated nature, this method significantly reduces the need for expert knowledge when optimizing the hyper-parameters in reservoir computing. Existing software libraries for Bayesian optimization make the implementation of the algorithm straightforward. version:1
arxiv-1611-02064 | A Fully Convolutional Neural Network based Structured Prediction Approach Towards the Retinal Vessel Segmentation | http://arxiv.org/abs/1611.02064 | id:1611.02064 author:Avijit Dasgupta, Sonam Singh category:cs.CV  published:2016-11-07 summary:Automatic segmentation of retinal blood vessels from fundus images plays an important role in the computer aided diagnosis of retinal diseases. The task of blood vessel segmentation is challenging due to the extreme variations in morphology of the vessels against noisy background. In this paper, we formulate the segmentation task as a multi-label inference task and utilize the implicit advantages of the combination of convolutional neural networks and structured prediction. Our proposed convolutional neural network based model achieves strong performance and significantly outperforms the state-of-the-art for automatic retinal blood vessel segmentation on DRIVE dataset with 95.33% accuracy and 0.974 AUC score. version:2
arxiv-1611-05181 | Graph Learning from Data under Structural and Laplacian Constraints | http://arxiv.org/abs/1611.05181 | id:1611.05181 author:Hilmi E. Egilmez, Eduardo Pavez, Antonio Ortega category:cs.LG stat.ML  published:2016-11-16 summary:Graphs are fundamental mathematical structures used in various fields to represent data, signals and processes. In this paper, we propose a novel framework for learning/estimating graphs from data. The proposed framework includes (i) formulation of various graph learning problems, (ii) their probabilistic interpretations and (iii) efficient algorithms to solve them. We specifically focus on graph learning problems where the goal is to estimate a graph Laplacian matrix from some observed data under given structural constraints (e.g., graph connectivity and sparsity). Our experimental results demonstrate that the proposed algorithms outperform the current state-of-the-art methods in terms of graph learning performance. version:1
arxiv-1611-05743 | Relational Multi-Manifold Co-Clustering | http://arxiv.org/abs/1611.05743 | id:1611.05743 author:Ping Li, Jiajun Bu, Chun Chen, Zhanying He, Deng Cai category:cs.LG  published:2016-11-16 summary:Co-clustering targets on grouping the samples (e.g., documents, users) and the features (e.g., words, ratings) simultaneously. It employs the dual relation and the bilateral information between the samples and features. In many realworld applications, data usually reside on a submanifold of the ambient Euclidean space, but it is nontrivial to estimate the intrinsic manifold of the data space in a principled way. In this study, we focus on improving the co-clustering performance via manifold ensemble learning, which is able to maximally approximate the intrinsic manifolds of both the sample and feature spaces. To achieve this, we develop a novel co-clustering algorithm called Relational Multi-manifold Co-clustering (RMC) based on symmetric nonnegative matrix tri-factorization, which decomposes the relational data matrix into three submatrices. This method considers the intertype relationship revealed by the relational data matrix, and also the intra-type information reflected by the affinity matrices encoded on the sample and feature data distributions. Specifically, we assume the intrinsic manifold of the sample or feature space lies in a convex hull of some pre-defined candidate manifolds. We want to learn a convex combination of them to maximally approach the desired intrinsic manifold. To optimize the objective function, the multiplicative rules are utilized to update the submatrices alternatively. Besides, both the entropic mirror descent algorithm and the coordinate descent algorithm are exploited to learn the manifold coefficient vector. Extensive experiments on documents, images and gene expression data sets have demonstrated the superiority of the proposed algorithm compared to other well-established methods. version:1
arxiv-1611-05148 | Variational Deep Embedding: A Generative Approach to Clustering | http://arxiv.org/abs/1611.05148 | id:1611.05148 author:Zhuxi jiang, Yin Zheng, Huachun Tan, Bangsheng Tang, Hanning Zhou category:cs.CV  published:2016-11-16 summary:Clustering is among the most fundamental tasks in computer vision and machine learning. In this paper, we propose Variational Deep Embedding (VaDE), a novel unsupervised generative clustering approach within the framework of Variational Auto-Encoder (VAE). Specifically, VaDE models the data generative procedure with a Gaussian Mixture Model (GMM) and a deep neural network (DNN): 1) the GMM picks a cluster; 2) from which a latent embedding is generated; 3) then the DNN decodes the latent embedding into observables. Inference in VaDE is done in a variational way: a different DNN is used to encode observables to latent embeddings, so that the evidence lower bound (ELBO) can be optimized using Stochastic Gradient Variational Bayes (SGVB) estimator and the reparameterization trick. Quantitative comparisons with strong baselines are included in this paper, and experimental results show that VaDE significantly outperforms the state-of-the-art clustering methods on 4 benchmarks from various modalities. Moreover, by VaDE's generative nature, we show its capability of generating highly realistic samples for any specified cluster, without using supervised information during training. Lastly, VaDE is a flexible and extensible framework for unsupervised generative clustering, more general mixture models than GMM can be easily plugged in. version:1
arxiv-1611-05146 | A Semi-Markov Switching Linear Gaussian Model for Censored Physiological Data | http://arxiv.org/abs/1611.05146 | id:1611.05146 author:Ahmed M. Alaa, Jinsung Yoon, Scott Hu, Mihaela van der Schaar category:cs.LG stat.ML  published:2016-11-16 summary:Critically ill patients in regular wards are vulnerable to unanticipated clinical dete- rioration which requires timely transfer to the intensive care unit (ICU). To allow for risk scoring and patient monitoring in such a setting, we develop a novel Semi- Markov Switching Linear Gaussian Model (SSLGM) for the inpatients' physiol- ogy. The model captures the patients' latent clinical states and their corresponding observable lab tests and vital signs. We present an efficient unsupervised learn- ing algorithm that capitalizes on the informatively censored data in the electronic health records (EHR) to learn the parameters of the SSLGM; the learned model is then used to assess the new inpatients' risk for clinical deterioration in an online fashion, allowing for timely ICU admission. Experiments conducted on a het- erogeneous cohort of 6,094 patients admitted to a large academic medical center show that the proposed model significantly outperforms the currently deployed risk scores such as Rothman index, MEWS, SOFA and APACHE. version:1
arxiv-1611-05141 | Training Spiking Deep Networks for Neuromorphic Hardware | http://arxiv.org/abs/1611.05141 | id:1611.05141 author:Eric Hunsberger, Chris Eliasmith category:cs.NE cs.LG  published:2016-11-16 summary:We describe a method to train spiking deep networks that can be run using leaky integrate-and-fire (LIF) neurons, achieving state-of-the-art results for spiking LIF networks on five datasets, including the large ImageNet ILSVRC-2012 benchmark. Our method for transforming deep artificial neural networks into spiking networks is scalable and works with a wide range of neural nonlinearities. We achieve these results by softening the neural response function, such that its derivative remains bounded, and by training the network with noise to provide robustness against the variability introduced by spikes. Our analysis shows that implementations of these networks on neuromorphic hardware will be many times more power-efficient than the equivalent non-spiking networks on traditional hardware. version:1
arxiv-1611-04989 | Recurrent Neural Network based Part-of-Speech Tagger for Code-Mixed Social Media Text | http://arxiv.org/abs/1611.04989 | id:1611.04989 author:Raj Nath Patel, Prakash B. Pimpale, M Sasikumar category:cs.CL  published:2016-11-15 summary:This paper describes Centre for Development of Advanced Computing's (CDACM) submission to the shared task-'Tool Contest on POS tagging for Code-Mixed Indian Social Media (Facebook, Twitter, and Whatsapp) Text', collocated with ICON-2016. The shared task was to predict Part of Speech (POS) tag at word level for a given text. The code-mixed text is generated mostly on social media by multilingual users. The presence of the multilingual words, transliterations, and spelling variations make such content linguistically complex. In this paper, we propose an approach to POS tag code-mixed social media text using Recurrent Neural Network Language Model (RNN-LM) architecture. We submitted the results for Hindi-English (hi-en), Bengali-English (bn-en), and Telugu-English (te-en) code-mixed data. version:2
arxiv-1611-05138 | S3Pool: Pooling with Stochastic Spatial Sampling | http://arxiv.org/abs/1611.05138 | id:1611.05138 author:Shuangfei Zhai, Hui Wu, Abhishek Kumar, Yu Cheng, Yongxi Lu, Zhongfei Zhang, Rogerio Feris category:cs.LG cs.CV  published:2016-11-16 summary:Feature pooling layers (e.g., max pooling) in convolutional neural networks (CNNs) serve the dual purpose of providing increasingly abstract representations as well as yielding computational savings in subsequent convolutional layers. We view the pooling operation in CNNs as a two-step procedure: first, a pooling window (e.g., $2\times 2$) slides over the feature map with stride one which leaves the spatial resolution intact, and second, downsampling is performed by selecting one pixel from each non-overlapping pooling window in an often uniform and deterministic (e.g., top-left) manner. Our starting point in this work is the observation that this regularly spaced downsampling arising from non-overlapping windows, although intuitive from a signal processing perspective (which has the goal of signal reconstruction), is not necessarily optimal for \emph{learning} (where the goal is to generalize). We study this aspect and propose a novel pooling strategy with stochastic spatial sampling (S3Pool), where the regular downsampling is replaced by a more general stochastic version. We observe that this general stochasticity acts as a strong regularizer, and can also be seen as doing implicit data augmentation by introducing distortions in the feature maps. We further introduce a mechanism to control the amount of distortion to suit different datasets and architectures. To demonstrate the effectiveness of the proposed approach, we perform extensive experiments on several popular image classification benchmarks, observing excellent improvements over baseline models. Experimental code is available at https://github.com/Shuangfei/s3pool. version:1
arxiv-1611-05136 | Machine Learning Approach for Skill Evaluation in Robotic-Assisted Surgery | http://arxiv.org/abs/1611.05136 | id:1611.05136 author:Mahtab J. Fard, Sattar Ameri, Ratna B. Chinnam, Abhilash K. Pandya, Michael D. Klein, R. Darin Ellis category:cs.LG stat.ML  published:2016-11-16 summary:Evaluating surgeon skill has predominantly been a subjective task. Development of objective methods for surgical skill assessment are of increased interest. Recently, with technological advances such as robotic-assisted minimally invasive surgery (RMIS), new opportunities for objective and automated assessment frameworks have arisen. In this paper, we applied machine learning methods to automatically evaluate performance of the surgeon in RMIS. Six important movement features were used in the evaluation including completion time, path length, depth perception, speed, smoothness and curvature. Different classification methods applied to discriminate expert and novice surgeons. We test our method on real surgical data for suturing task and compare the classification result with the ground truth data (obtained by manual labeling). The experimental results show that the proposed framework can classify surgical skill level with relatively high accuracy of 85.7%. This study demonstrates the ability of machine learning methods to automatically classify expert and novice surgeons using movement features for different RMIS tasks. Due to the simplicity and generalizability of the introduced classification method, it is easy to implement in existing trainers. version:1
arxiv-1611-05134 | Cost-Sensitive Deep Learning with Layer-Wise Cost Estimation | http://arxiv.org/abs/1611.05134 | id:1611.05134 author:Yu-An Chung, Hsuan-Tien Lin category:cs.CV  published:2016-11-16 summary:While deep neural networks have succeeded in several visual applications, such as object recognition, detection, and localization, by reaching very high classification accuracies, it is important to note that many real-world applications demand vary- ing costs for different types of misclassification errors, thus requiring cost-sensitive classification algorithms. Current models of deep neural networks for cost-sensitive classification are restricted to some specific network structures and limited depth. In this paper, we propose a novel framework that can be applied to deep neural networks with any structure to facilitate their learning of meaningful representations for cost-sensitive classification problems. Furthermore, the framework allows end- to-end training of deeper networks directly. The framework is designed by augmenting auxiliary neurons to the output of each hidden layer for layer-wise cost estimation, and including the total estimation loss within the optimization objective. Experimental results on public benchmark visual data sets with two cost information settings demonstrate that the proposed frame- work outperforms state-of-the-art cost-sensitive deep learning models. version:1
arxiv-1611-05132 | Convergence rate of stochastic k-means | http://arxiv.org/abs/1611.05132 | id:1611.05132 author:Cheng Tang, Claire Monteleoni category:cs.LG  published:2016-11-16 summary:We analyze online \cite{BottouBengio} and mini-batch \cite{Sculley} $k$-means variants. Both scale up the widely used $k$-means algorithm via stochastic approximation, and have become popular for large-scale clustering and unsupervised feature learning. We show, for the first time, that starting with any initial solution, they converge to a "local optimum" at rate $O(\frac{1}{t})$ (in terms of the $k$-means objective) under general conditions. In addition, we show if the dataset is clusterable, when initialized with a simple and scalable seeding algorithm, mini-batch $k$-means converges to an optimal $k$-means solution at rate $O(\frac{1}{t})$ with high probability. The $k$-means objective is non-convex and non-differentiable: we exploit ideas from recent work on stochastic gradient descent for non-convex problems \cite{ge:sgd_tensor, balsubramani13} by providing a novel characterization of the trajectory of $k$-means algorithm on its solution space, and circumvent the non-differentiability problem via geometric insights about $k$-means update. version:1
arxiv-1611-05128 | Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning | http://arxiv.org/abs/1611.05128 | id:1611.05128 author:Tien-Ju Yang, Yu-Hsin Chen, Vivienne Sze category:cs.CV  published:2016-11-16 summary:Deep convolutional neural networks (CNNs) are indispensable to state-of-the-art computer vision algorithms. However, they are still rarely deployed on battery-powered mobile devices, such as smartphones and wearable gadgets, where vision algorithms can enable many revolutionary real-world applications. The key limiting factor is the high energy consumption of CNN processing due to its high computational complexity. While there are many previous efforts that try to reduce the CNN model size or amount of computation, we find that they do not necessarily result in lower energy consumption, and therefore do not serve as a good metric for energy cost estimation. To close the gap between CNN design and energy consumption optimization, we propose an energy-aware pruning algorithm for CNNs that directly uses energy consumption estimation of a CNN to guide the pruning process. The energy estimation methodology uses parameters extrapolated from actual hardware measurements that target realistic battery-powered system setups. The proposed layer-by-layer pruning algorithm also prunes more aggressively than previously proposed pruning methods by minimizing the error in output feature maps instead of filter weights. For each layer, the weights are first pruned and then locally fine-tuned with a closed-form least-square solution to quickly restore the accuracy. After all layers are pruned, the entire network is further globally fine-tuned using back-propagation. With the proposed pruning method, the energy consumption of AlexNet and GoogLeNet are reduced by 3.7x and 1.6x, respectively, with less than 1% top-5 accuracy loss. Finally, we show that pruning the AlexNet with a reduced number of target classes can greatly decrease the number of weights but the energy reduction is limited. version:1
arxiv-1611-05126 | Localized Coulomb Descriptors for the Gaussian Approximation Potential | http://arxiv.org/abs/1611.05126 | id:1611.05126 author:James Barker, Johannes Bulin, Jan Hamaekers, Sonja Mathias category:stat.ML physics.chem-ph 92E10  published:2016-11-16 summary:We introduce a novel class of localized atomic environment representation functions, based upon the global Coulomb matrix, which have dimensionality either quadratic or linear in the number of atoms in the local atomic environment. By combining these functions with the Gaussian approximation potential approach, we present LC-GAP, a new system for generating atomic potentials through machine learning (ML). Tests on the QM7, QM7b and GDB9 biomolecular datasets demonstrate that potentials created with LC-GAP can successfully predict atomization energies for molecules larger than those used for training to chemical accuracy, and can (in the case of QM7b) also be used to predict a range of other atomic properties with accuracy in line with the recent literature. version:1
arxiv-1611-05125 | Learning To Score Olympic Events | http://arxiv.org/abs/1611.05125 | id:1611.05125 author:Paritosh Parmar, Brendan Tran Morris category:cs.CV  published:2016-11-16 summary:While action recognition has been addressed extensively in the field of computer vision, action quality assessment has not been given much attention. Estimating action quality is crucial in areas such as sports and health care, while being useful in other areas like video retrieval. Unlike action recognition, which has millions of examples to learn from, the action quality datasets that are currently available are small -- typically comprised of only a few hundred samples. We develop quality assessment frameworks which use SVR, LSTM and LSTM-SVR on top of spatiotemporal features learned using 3D convolutional neural networks (C3D). We demonstrate an efficient training mechanism for action quality LSTM suitable for limited data scenarios. The proposed systems show significant improvement over existing quality assessment approaches on the task of predicting scores of Olympic events both with short-time length actions (10m platform diving) and long-time length actions (figure skating short program). While SVR based frameworks yields better results, LSTM based frameworks are more intuitive and natural for describing the action, and can be used for improvement feedback. version:1
arxiv-1611-05118 | The Amazing Mysteries of the Gutter: Drawing Inferences Between Panels in Comic Book Narratives | http://arxiv.org/abs/1611.05118 | id:1611.05118 author:Mohit Iyyer, Varun Manjunatha, Anupam Guha, Yogarshi Vyas, Jordan Boyd-Graber, Hal Daumé III, Larry Davis category:cs.CV cs.CL  published:2016-11-16 summary:Visual narrative is often a combination of explicit information and judicious omissions, relying on the viewer to supply missing details. In comics, most movements in time and space are hidden in the "gutters" between panels. To follow the story, readers logically connect panels together by inferring unseen actions through a process called "closure". While computers can now describe the content of natural images, in this paper we examine whether they can understand the closure-driven narratives conveyed by stylized artwork and dialogue in comic book panels. We collect a dataset, COMICS, that consists of over 1.2 million panels (120 GB) paired with automatic textbox transcriptions. An in-depth analysis of COMICS demonstrates that neither text nor image alone can tell a comic book story, so a computer must understand both modalities to keep up with the plot. We introduce three cloze-style tasks that ask models to predict narrative and character-centric aspects of a panel given n preceding panels as context. Various deep neural architectures underperform human baselines on these tasks, suggesting that COMICS contains fundamental challenges for both vision and language. version:1
arxiv-1611-01982 | Chinese/English mixed Character Segmentation as Semantic Segmentation | http://arxiv.org/abs/1611.01982 | id:1611.01982 author:Huabin Zheng, Jingyu Wang, Zhengjie Huang, Yang Yang, Rong Pan category:cs.CV  published:2016-11-07 summary:OCR character segmentation for multilingual printed documents is difficult due to the diversity of different linguistic characters. Previous approaches mainly focus on monolingual texts and are not suitable for multilingual-lingual cases. In this work, we particularly tackle the Chinese/English mixed case by reframing it as a semantic segmentation problem. We take advantage of the successful architecture called fully convolutional networks (FCN) in the field of semantic segmentation. Given a wide enough receptive field, FCN can utilize the necessary context around a horizontal position to determinate whether this is a splitting point or not. As a deep neural architecture, FCN can automatically learn useful features from raw text line images. Although trained on synthesized samples with simulated random disturbance, our FCN model generalizes well to real-world samples. The experimental results show that our model significantly outperforms the previous methods. version:2
arxiv-1611-07917 | Deep Restricted Boltzmann Networks | http://arxiv.org/abs/1611.07917 | id:1611.07917 author:Hengyuan Hu, Lisheng Gao, Quanbin Ma category:cs.LG  published:2016-11-15 summary:Building a good generative model for image has long been an important topic in computer vision and machine learning. Restricted Boltzmann machine (RBM) is one of such models that is simple but powerful. However, its restricted form also has placed heavy constraints on the models representation power and scalability. Many extensions have been invented based on RBM in order to produce deeper architectures with greater power. The most famous ones among them are deep belief network, which stacks multiple layer-wise pretrained RBMs to form a hybrid model, and deep Boltzmann machine, which allows connections between hidden units to form a multi-layer structure. In this paper, we present a new method to compose RBMs to form a multi-layer network style architecture and a training method that trains all layers jointly. We call the resulted structure deep restricted Boltzmann network. We further explore the combination of convolutional RBM with the normal fully connected RBM, which is made trivial under our composition framework. Experiments show that our model can generate descent images and outperform the normal RBM significantly in terms of image quality and feature quality, without losing much efficiency for training. version:1
arxiv-1611-04023 | Sparsey: Event Recognition via Deep Hierarchical Spare Distributed Codes | http://arxiv.org/abs/1611.04023 | id:1611.04023 author:Gerard J. Rinkus category:q-bio.NC cs.CV cs.NE 68  published:2016-11-12 summary:Visual cortex's hierarchical, multi-level organization is captured in many biologically inspired computational vision models, the general idea being that progressively larger scale, more complex spatiotemporal features are represented in progressively higher areas. However, most earlier models use localist representations (codes) in each representational field, which we equate with the cortical macrocolumn (mac), at each level. In localism, each represented feature/event (item) is coded by a single unit. Our model, Sparsey, is also hierarchical but crucially, uses sparse distributed coding (SDC) in every mac in all levels. In SDC, each represented item is coded by a small subset of the mac's units. SDCs of different items can overlap and the size of overlap between items can represent their similarity. The difference between localism and SDC is crucial because SDC allows the two essential operations of associative memory, storing a new item and retrieving the best-matching stored item, to be done in fixed time for the life of the model. Since the model's core algorithm, which does both storage and retrieval (inference), makes a single pass over all macs on each time step, the overall model's storage/retrieval operation is also fixed-time, a criterion we consider essential for scalability to huge datasets. A 2010 paper described a nonhierarchical version of this model in the context of purely spatial pattern processing. Here, we elaborate a fully hierarchical model (arbitrary numbers of levels and macs per level), describing novel model principles like progressive critical periods, dynamic modulation of principal cells' activation functions based on a mac-level familiarity measure, representation of multiple simultaneously active hypotheses, a novel method of time warp invariant recognition, and we report results showing learning/recognition of spatiotemporal patterns. version:1
arxiv-1611-05898 | Associative Memories to Accelerate Approximate Nearest Neighbor Search | http://arxiv.org/abs/1611.05898 | id:1611.05898 author:Vincent Gripon, Matthias Löwe, Franck Vermet category:cs.LG math.PR  published:2016-11-10 summary:Nearest neighbor search is a very active field in machine learning for it appears in many application cases, including classification and object retrieval. In its canonical version, the complexity of the search is linear with both the dimension and the cardinal of the collection of vectors the search is performed in. Recently many works have focused on reducing the dimension of vectors using quantization techniques or hashing, while providing an approximate result. In this paper we focus instead on tackling the cardinal of the collection of vectors. Namely, we introduce a technique that partitions the collection of vectors and stores each part in its own associative memory. When a query vector is given to the system, associative memories are polled to identify which one contain the closest match. Then an exhaustive search is conducted only on the part of vectors stored in the selected associative memory. We study the effectiveness of the system when messages to store are generated from i.i.d. uniform $\pm$1 random variables or 0-1 sparse i.i.d. random variables. We also conduct experiment on both synthetic data and real data and show it is possible to achieve interesting trade-offs between complexity and accuracy. version:1
arxiv-1611-07422 | Deep Learning Approximation for Stochastic Control Problems | http://arxiv.org/abs/1611.07422 | id:1611.07422 author:Jiequn Han, Weinan E category:cs.LG cs.AI cs.NE math.OC stat.ML  published:2016-11-02 summary:Many real world stochastic control problems suffer from the "curse of dimensionality". To overcome this difficulty, we develop a deep learning approach that directly solves high-dimensional stochastic control problems based on Monte-Carlo sampling. We approximate the time-dependent controls as feedforward neural networks and stack these networks together through model dynamics. The objective function for the control problem plays the role of the loss function for the deep neural network. We test this approach using examples from the areas of optimal trading and energy storage. Our results suggest that the algorithm presented here achieves satisfactory accuracy and at the same time, can handle rather high dimensional problems. version:1
