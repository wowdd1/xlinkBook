arxiv-1710-06090 | Face Transfer with Generative Adversarial Network | http://arxiv.org/abs/1710.06090 | id:1710.06090 author:Runze Xu, Zhiming Zhou, Weinan Zhang, Yong Yu category:cs.CV  published:2017-10-17 summary:Face transfer animates the facial performances of the character in the target video by a source actor. Traditional methods are typically based on face modeling. We propose an end-to-end face transfer method based on Generative Adversarial Network. Specifically, we leverage CycleGAN to generate the face image of the target character with the corresponding head pose and facial expression of the source. In order to improve the quality of generated videos, we adopt PatchGAN and explore the effect of different receptive field sizes on generated images. version:1
arxiv-1710-06085 | On the challenges of learning with inference networks on sparse, high-dimensional data | http://arxiv.org/abs/1710.06085 | id:1710.06085 author:Rahul G. Krishnan, Dawen Liang, Matthew Hoffman category:stat.ML cs.LG  published:2017-10-17 summary:We study parameter estimation in Nonlinear Factor Analysis (NFA) where the generative model is parameterized by a deep neural network. Recent work has focused on learning such models using inference (or recognition) networks; we identify a crucial problem when modeling large, sparse, high-dimensional datasets -- underfitting. We study the extent of underfitting, highlighting that its severity increases with the sparsity of the data. We propose methods to tackle it via iterative optimization inspired by stochastic variational inference \citep{hoffman2013stochastic} and improvements in the sparse data representation used for inference. The proposed techniques drastically improve the ability of these powerful models to fit sparse data, achieving state-of-the-art results on a benchmark text-count dataset and excellent results on the task of top-N recommendation. version:1
arxiv-1710-06081 | Discovering Adversarial Examples with Momentum | http://arxiv.org/abs/1710.06081 | id:1710.06081 author:Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Xiaolin Hu, Jun Zhu category:cs.LG stat.ML  published:2017-10-17 summary:Machine learning models, especially Deep Neural Networks, are vulnerable to adversarial examples---malicious inputs crafted by adding small noises to real examples, but fool the models. Adversarial examples transfer from one model to another, enabling black-box attacks to real-world applications. In this paper, we propose a strong attack algorithm named momentum iterative fast gradient sign method (MI-FGSM) to discover adversarial examples. MI-FGSM is an extension of iterative fast gradient sign method (I-FGSM) but improves the transferability significantly. Besides, we study how to attack an ensemble of models efficiently. Experiments demonstrate the effectiveness of the proposed algorithm. We hope that MI-FGSM can serve as a benchmark attack algorithm for evaluating the robustness of various models and defense methods. version:1
arxiv-1710-06078 | Estimate exponential memory decay in Hidden Markov Model and its applications | http://arxiv.org/abs/1710.06078 | id:1710.06078 author:Felix X. -F. Ye, Yi-an Ma, Hong Qian category:stat.ML stat.ME  published:2017-10-17 summary:Inference in hidden Markov model has been challenging in terms of scalability due to dependencies in the observation data. In this paper, we utilize the inherent memory decay in hidden Markov models, such that the forward and backward probabilities can be carried out with subsequences, enabling efficient inference over long sequences of observations. We formulate this forward filtering process in the setting of the random dynamical system and there exist Lyapunov exponents in the i.i.d random matrices production. And the rate of the memory decay is known as $\lambda_2-\lambda_1$, the gap of the top two Lyapunov exponents almost surely. An efficient and accurate algorithm is proposed to numerically estimate the gap after the soft-max parametrization. The length of subsequences $B$ given the controlled error $\epsilon$ is $B=\log(\epsilon)/(\lambda_2-\lambda_1)$. We theoretically prove the validity of the algorithm and demonstrate the effectiveness with numerical examples. The method developed here can be applied to widely used algorithms, such as mini-batch stochastic gradient method. Moreover, the continuity of Lyapunov spectrum ensures the estimated $B$ could be reused for the nearby parameter during the inference. version:1
arxiv-1710-06071 | PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts | http://arxiv.org/abs/1710.06071 | id:1710.06071 author:Franck Dernoncourt, Ji Young Lee category:cs.CL cs.AI stat.ML  published:2017-10-17 summary:We present PubMed 200k RCT, a new dataset based on PubMed for sequential sentence classification. The dataset consists of approximately 200,000 abstracts of randomized controlled trials, totaling 2.3 million sentences. Each sentence of each abstract is labeled with their role in the abstract using one of the following classes: background, objective, method, result, or conclusion. The purpose of releasing this dataset is twofold. First, the majority of datasets for sequential short-text classification (i.e., classification of short texts that appear in sequences) are small: we hope that releasing a new large dataset will help develop more accurate algorithms for this task. Second, from an application perspective, researchers need better tools to efficiently skim through the literature. Automatically classifying each sentence in an abstract would help researchers read abstracts more efficiently, especially in fields where abstracts may be long, such as the medical field. version:1
arxiv-1709-05545 | Relevant Ensemble of Trees | http://arxiv.org/abs/1709.05545 | id:1709.05545 author:Gitesh Dawer, Adrian Barbu category:stat.ML cs.LG  published:2017-09-16 summary:Tree ensembles are flexible predictive models that can capture relevant variables and to some extent their interactions in a compact and interpretable manner. Most algorithms for obtaining tree ensembles are based on versions of boosting or Random Forest. Previous work showed that boosting algorithms exhibit a cyclic behavior of selecting the same tree again and again due to the way the loss is optimized. At the same time, Random Forest is not based on loss optimization and obtains a more complex and less interpretable model. In this paper we present a novel method for obtaining compact tree ensembles by growing a large pool of trees in parallel with many independent boosting threads and then selecting a small subset and updating their leaf weights by loss optimization. We allow for the trees in the initial pool to have different depths which further helps with generalization. Experiments on real datasets show that the obtained model has usually a smaller loss than boosting, which is also reflected in a lower misclassification error on the test set. version:2
arxiv-1706-03686 | Image Crowd Counting Using Convolutional Neural Network and Markov Random Field | http://arxiv.org/abs/1706.03686 | id:1706.03686 author:Kang Han, Wanggen Wan, Haiyan Yao, Li Hou category:cs.CV  published:2017-06-12 summary:In this paper, we propose a method called Convolutional Neural Network-Markov Random Field (CNN-MRF) to estimate the crowd count in a still image. We first divide the dense crowd visible image into overlapping patches and then use a deep convolutional neural network to extract features from each patch image, followed by a fully connected neural network to regress the local patch crowd count. Since the local patches have overlapping portions, the crowd count of the adjacent patches has a high correlation. We use this correlation and the Markov random field to smooth the counting results of the local patches. Experiments show that our approach significantly outperforms the state-of-the-art methods on UCF and Shanghaitech crowd counting datasets. version:3
arxiv-1710-06055 | Evolution in Virtual Worlds | http://arxiv.org/abs/1710.06055 | id:1710.06055 author:Tim Taylor category:cs.NE  published:2017-10-17 summary:This chapter discusses the possibility of instilling a virtual world with mechanisms for evolution and natural selection in order to generate rich ecosystems of complex organisms in a process akin to biological evolution. Some previous work in the area is described, and successes and failures are discussed. The components of a more comprehensive framework for designing such worlds are mapped out, including the design of the individual organisms, the properties and dynamics of the environmental medium in which they are evolving, and the representational relationship between organism and environment. Some of the key issues discussed include how to allow organisms to evolve new structures and functions with few restrictions, and how to create an interconnectedness between organisms in order to generate drives for continuing evolutionary activity. version:1
arxiv-1710-05086 | A deep generative model for single-cell RNA sequencing with application to detecting differentially expressed genes | http://arxiv.org/abs/1710.05086 | id:1710.05086 author:Romain Lopez, Jeffrey Regier, Michael Cole, Michael Jordan, Nir Yosef category:cs.LG q-bio.GN stat.ML  published:2017-10-13 summary:We propose a probabilistic model for interpreting gene expression levels that are observed through single-cell RNA sequencing. In the model, each cell has a low-dimensional latent representation. Additional latent variables account for technical effects that may erroneously set some observations of gene expression levels to zero. Conditional distributions are specified by neural networks, giving the proposed model enough flexibility to fit the data well. We use variational inference and stochastic optimization to approximate the posterior distribution. The inference procedure scales to over one million cells, whereas competing algorithms do not. Even for smaller datasets, for several tasks, the proposed procedure outperforms state-of-the-art methods like ZIFA and ZINB-WaVE. We also extend our framework to take into account batch effects and other confounding factors and propose a natural Bayesian hypothesis framework for differential expression that outperforms tradition DESeq2. version:2
arxiv-1710-05829 | Geometric Learning and Filtering in Finance | http://arxiv.org/abs/1710.05829 | id:1710.05829 author:Anastasis Kratsios, Cody B. Hyndman category:q-fin.MF math.PR q-fin.CP stat.ML  published:2017-10-16 summary:We develop a method for incorporating relevant non-Euclidean geometric information into a broad range of classical filtering and statistical or machine learning algorithms. We apply these techniques to approximate the solution of the non-Euclidean filtering problem to arbitrary precision. We then extend the particle filtering algorithm to compute our asymptotic solution to arbitrary precision. Moreover, we find explicit error bounds measuring the discrepancy between our locally triangulated filter and the true theoretical non-Euclidean filter. Our methods are motivated by certain fundamental problems in mathematical finance. In particular we apply these filtering techniques to incorporate the non-Euclidean geometry present in stochastic volatility models and optimal Markowitz portfolios. We also extend Euclidean statistical or machine learning algorithms to non-Euclidean problems by using the local triangulation technique, which we show improves the accuracy of the original algorithm. We apply the local triangulation method to obtain improvements of the (sparse) principal component analysis and the principal geodesic analysis algorithms and show how these improved algorithms can be used to parsimoniously estimate the evolution of the shape of forward-rate curves. While focused on financial applications, the non-Euclidean geometric techniques presented in this paper can be employed to provide improvements to a range of other statistical or machine learning algorithms and may be useful in other areas of application. version:2
arxiv-1710-05114 | Arbitrage-Free Regularization | http://arxiv.org/abs/1710.05114 | id:1710.05114 author:Anastasis Kratsios, Cody B. Hyndman category:q-fin.MF math.PR q-fin.PR stat.ML  published:2017-10-14 summary:We introduce a path-dependent geometric framework which generalizes the HJM modeling approach to a wide variety of other asset classes. A machine learning regularization framework is developed with the objective of removing arbitrage opportunities from models within this general framework. The regularization method relies on minimal deformations of a model subject to a path-dependent penalty that detects arbitrage opportunities. We prove that the solution of this regularization problem is independent of the arbitrage-penalty chosen, subject to a fixed information loss functional. In addition to the general properties of the minimal deformation, we also consider several explicit examples. This paper is focused on placing machine learning methods in finance on a sound theoretical basis and the techniques developed to achieve this objective may be of interest in other areas of application. version:2
arxiv-1710-06034 | Stochastic Variance Reduction for Policy Gradient Estimation | http://arxiv.org/abs/1710.06034 | id:1710.06034 author:Tianbing Xu, Qiang Liu, Jian Peng category:cs.LG stat.ML  published:2017-10-17 summary:Recent advances in policy gradient methods and deep learning have demonstrated their applicability for complex reinforcement learning problems. However, the variance of the performance gradient estimates obtained from the simulation is often excessive, leading to poor sample efficiency. In this paper, we apply the stochastic variance reduced gradient descent (SVRG) to model-free policy gradient to significantly improve the sample-efficiency. The SVRG estimation is incorporated into a trust-region Newton conjugate gradient framework for the policy optimization. On several Mujoco tasks, our method achieves significantly better performance compared to the state-of-the-art model-free policy gradient methods in robotic continuous control such as trust region policy optimization (TRPO) version:1
arxiv-1710-04783 | Retinal Vasculature Segmentation Using Local Saliency Maps and Generative Adversarial Networks For Image Super Resolution | http://arxiv.org/abs/1710.04783 | id:1710.04783 author:Dwarikanath Mahapatra, Behzad Bozorgtabar category:cs.CV  published:2017-10-13 summary:We propose an image super resolution(ISR) method using generative adversarial networks (GANs) that takes a low resolution input fundus image and generates a high resolution super resolved (SR) image upto scaling factor of $16$. This facilitates more accurate automated image analysis, especially for small or blurred landmarks and pathologies. Local saliency maps, which define each pixel's importance, are used to define a novel saliency loss in the GAN cost function. Experimental results show the resulting SR images have perceptual quality very close to the original images and perform better than competing methods that do not weigh pixels according to their importance. When used for retinal vasculature segmentation, our SR images result in accuracy levels close to those obtained when using the original images. version:2
arxiv-1710-06030 | Linear Regression with Sparsely Permuted Data | http://arxiv.org/abs/1710.06030 | id:1710.06030 author:Martin Slawski, Emanuel Ben-David category:math.ST stat.ME stat.ML stat.TH  published:2017-10-16 summary:In regression analysis of multivariate data, it is tacitly assumed that response and predictor variables in each observed response-predictor pair correspond to the same entity or unit. In this paper, we consider the situation of "permuted data" in which this basic correspondence has been lost. Several recent papers have considered this situation without further assumptions on the underlying permutation. In applications, the latter is often to known to have additional structure that can be leveraged. Specifically, we herein consider the common scenario of "sparsely permuted data" in which only a small fraction of the data is affected by a mismatch between response and predictors. However, an adverse effect already observed for sparsely permuted data is that the least squares estimator as well as other estimators not accounting for such partial mismatch are inconsistent. One approach studied in detail herein is to treat permuted data as outliers which motivates the use of robust regression formulations to estimate the regression parameter. The resulting estimate can subsequently be used to recover the permutation. A notable benefit of the proposed approach is its computational simplicity given the general lack of procedures for the above problem that are both statistically sound and computationally appealing. version:1
arxiv-1710-06012 | VAMPnets: Deep learning of molecular kinetics | http://arxiv.org/abs/1710.06012 | id:1710.06012 author:Andreas Mardt, Luca Pasquali, Hao Wu, Frank Noé category:stat.ML physics.bio-ph physics.chem-ph physics.comp-ph  published:2017-10-16 summary:Here we develop a deep learning framework for molecular kinetics from molecular dynamics (MD) simulation data. There is an increasing demand for computing the relevant structures, equilibria and long-timescale kinetics of complex biomolecular processes, such as protein-drug binding, from high-throughput MD simulations. State-of-the art methods employ a handcrafted data processing pipeline, involving (i) transformation of simulated coordinates into a set of features characterizing the molecular structure, (ii) dimension reduction to collective variables, (iii) clustering the dimension-reduced data, and (iv) estimation of a Markov state model (MSM) or related model of the interconversion rates between molecular structures. This approach demands a substantial amount of modeling expertise, as poor decisions at every step will lead to large modeling errors. Here we employ the recently developed variational approach for Markov processes (VAMP) to develop a deep learning framework for molecular kinetics using neural networks, dubbed VAMPnets. A VAMPnet encodes the entire mapping from molecular coordinates to Markov states and learns optimal feature transformations, nonlinear dimension reduction, cluster discretization and MSM estimation within a single end-to-end learning framework. Our results, ranging from toy models to protein folding, are competitive or outperform state-of-the art Markov modeling methods and readily provide easily interpretable few-state kinetic models. version:1
arxiv-1706-08470 | Efficiency of quantum versus classical annealing in non-convex learning problems | http://arxiv.org/abs/1706.08470 | id:1706.08470 author:Carlo Baldassi, Riccardo Zecchina category:quant-ph cond-mat.dis-nn cs.LG stat.ML  published:2017-06-26 summary:Quantum annealers aim at solving non-convex optimization problems by exploiting cooperative tunneling effects to escape local minima. The underlying idea consists in designing a classical energy function whose ground states are the sought optimal solutions of the original optimization problem and add a controllable quantum transverse field to generate tunneling processes. A key challenge is to identify classes of non-convex optimization problems for which quantum annealing remains efficient while thermal annealing fails. We show that this happens for a wide class of problems which are central to machine learning. Their energy landscapes is dominated by local minima that cause exponential slow down of classical thermal annealers while simulated quantum annealing converges efficiently to rare dense regions of optimal solutions. version:3
arxiv-1709-06265 | Dynamic Oracle for Neural Machine Translation in Decoding Phase | http://arxiv.org/abs/1709.06265 | id:1709.06265 author:Zi-Yi Dou, Hao Zhou, Shu-Jian Huang, Xin-Yu Dai, Jia-Jun Chen category:cs.CL  published:2017-09-19 summary:The past several years have witnessed the rapid progress of end-to-end Neural Machine Translation (NMT). However, there exists discrepancy between training and inference in NMT when decoding, which may lead to serious problems since the model might be in a part of the state space it has never seen during training. To address the issue, Scheduled Sampling has been proposed. However, there are certain limitations in Scheduled Sampling and we propose two dynamic oracle-based methods to improve it. We manage to mitigate the discrepancy by changing the training process towards a less guided scheme and meanwhile aggregating the oracle's demonstrations. Experimental results show that the proposed approaches improve translation quality over standard NMT system. version:2
arxiv-1710-05994 | Volumetric Data Exploration with Machine Learning-Aided Visualization in Neutron Science | http://arxiv.org/abs/1710.05994 | id:1710.05994 author:Yawei Hui, Yaohua Liu category:cs.CV  published:2017-10-16 summary:Recent advancements in neutron and x-ray sources, instrumentation and data collection modes have significantly increased the experimental data size (which could easily contain $10^{8}$-$10^{10}$ points), so that conventional volumetric visualization approaches become inefficient for both still imaging and interactive OpenGL rendition in a 3-D setting. We introduce a new approach based on the unsupervised machine learning algorithm, Density-Based Spatial Clustering of Applications with Noise (DBSCAN), to efficiently analyze and visualize large volumetric datasets. Here we present two examples, including a single crystal diffuse scattering dataset and a neutron tomography dataset. We found that by using the intensity as the weight factor during clustering, the algorithm becomes very effective in de-noising and feature/boundary detection, and thus enables better visualization of the hierarchical internal structures of the scattering data. version:1
arxiv-1710-05989 | Sparse Linear Isotonic Models | http://arxiv.org/abs/1710.05989 | id:1710.05989 author:Sheng Chen, Arindam Banerjee category:stat.ML  published:2017-10-16 summary:In machine learning and data mining, linear models have been widely used to model the response as parametric linear functions of the predictors. To relax such stringent assumptions made by parametric linear models, additive models consider the response to be a summation of unknown transformations applied on the predictors; in particular, additive isotonic models (AIMs) assume the unknown transformations to be monotone. In this paper, we introduce sparse linear isotonic models (SLIMs) for highdimensional problems by hybridizing ideas in parametric sparse linear models and AIMs, which enjoy a few appealing advantages over both. In the high-dimensional setting, a two-step algorithm is proposed for estimating the sparse parameters as well as the monotone functions over predictors. Under mild statistical assumptions, we show that the algorithm can accurately estimate the parameters. Promising preliminary experiments are presented to support the theoretical results. version:1
arxiv-1710-05982 | Pushing the envelope in deep visual recognition for mobile platforms | http://arxiv.org/abs/1710.05982 | id:1710.05982 author:Lorenzo Alvino category:cs.CV cs.LG  published:2017-10-16 summary:Image classification is the task of assigning to an input image a label from a fixed set of categories. One of its most important applicative fields is that of robotics, in particular the needing of a robot to be aware of what's around and the consequent exploitation of that information as a benefit for its tasks. In this work we consider the problem of a robot that enters a new environment and wants to understand visual data coming from its camera, so to extract knowledge from them. As main novelty we want to overcome the needing of a physical robot, as it could be expensive and unhandy, so to hopefully enhance, speed up and ease the research in this field. That's why we propose to develop an application for a mobile platform that wraps several deep visual recognition tasks. First we deal with a simple Image classification, testing a model obtained from an AlexNet trained on the ILSVRC 2012 dataset. Several photo settings are considered to better understand which factors affect most the quality of classification. For the same purpose we are interested to integrate the classification task with an extra module dealing with segmentation of the object inside the image. In particular we propose a technique for extracting the object shape and moving out all the background, so to focus the classification only on the region occupied by the object. Another significant task that is included is that of object discovery. Its purpose is to simulate the situation in which the robot needs a certain object to complete one of its activities. It starts searching for what it needs by looking around and trying to understand the location of the object by scanning the surrounding environment. Finally we provide a tool for dealing with the creation of customized task-specific databases, meant to better suit to one's needing in a particular vision task. version:1
arxiv-1710-05978 | Convolutional Neural Networks for Sentiment Classification on Business Reviews | http://arxiv.org/abs/1710.05978 | id:1710.05978 author:Andreea Salinca category:cs.CL  published:2017-10-16 summary:Recently Convolutional Neural Networks (CNNs) models have proven remarkable results for text classification and sentiment analysis. In this paper, we present our approach on the task of classifying business reviews using word embeddings on a large-scale dataset provided by Yelp: Yelp 2017 challenge dataset. We compare word-based CNN using several pre-trained word embeddings and end-to-end vector representations for text reviews classification. We conduct several experiments to capture the semantic relationship between business reviews and we use deep learning techniques that prove that the obtained results are competitive with traditional methods. version:1
arxiv-1706-04792 | Mapping higher-order network flows in memory and multilayer networks with Infomap | http://arxiv.org/abs/1706.04792 | id:1706.04792 author:Daniel Edler, Ludvig Bohlin, Martin Rosvall category:cs.SI physics.soc-ph stat.ML  published:2017-06-15 summary:Comprehending complex systems by simplifying and highlighting important dynamical patterns requires modeling and mapping higher-order network flows. However, complex systems come in many forms and demand a range of representations, including memory and multilayer networks, which in turn call for versatile community-detection algorithms to reveal important modular regularities in the flows. Here we show that various forms of higher-order network flows can be represented in a unified way with networks that distinguish physical nodes for representing a~complex system's objects from state nodes for describing flows between the objects. Moreover, these so-called sparse memory networks allow the information-theoretic community detection method known as the map equation to identify overlapping and nested flow modules in data from a range of~different higher-order interactions such as multistep, multi-source, and temporal data. We derive the map equation applied to sparse memory networks and describe its search algorithm Infomap, which can exploit the flexibility of sparse memory networks. Together they provide a general solution to reveal overlapping modular patterns in higher-order flows through complex systems. version:2
arxiv-1710-05958 | Gradient-free Policy Architecture Search and Adaptation | http://arxiv.org/abs/1710.05958 | id:1710.05958 author:Sayna Ebrahimi, Anna Rohrbach, Trevor Darrell category:cs.LG cs.AI cs.CV  published:2017-10-16 summary:We develop a method for policy architecture search and adaptation via gradient-free optimization which can learn to perform autonomous driving tasks. By learning from both demonstration and environmental reward we develop a model that can learn with relatively few early catastrophic failures. We first learn an architecture of appropriate complexity to perceive aspects of world state relevant to the expert demonstration, and then mitigate the effect of domain-shift during deployment by adapting a policy demonstrated in a source domain to rewards obtained in a target environment. We show that our approach allows safer learning than baseline methods, offering a reduced cumulative crash metric over the agent's lifetime as it learns to drive in a realistic simulated environment. version:1
arxiv-1710-05956 | HyperDense-Net: A hyper-densely connected CNN for multi-modal image semantic segmentation | http://arxiv.org/abs/1710.05956 | id:1710.05956 author:Jose Dolz, Ismail Ben Ayed, Jing Yuan, Christian Desrosiers category:cs.CV  published:2017-10-16 summary:Neonatal brain segmentation in magnetic resonance (MR) is a challenging problem due to poor image quality and similar levels of intensity between white and gray matter in MR-T1 and T2 images. To tackle this problem, most existing approaches are based on multi-atlas label fusion strategies, which are time-consuming and sensitive to registration errors. As alternative to these methods, we propose a hyper densely connected 3D convolutional neural network that employs MR-T1 and T2 as input, processed independently in two separated paths. A main difference with respect to previous densely connected networks is the use of direct connections between layers from the same and different paths. Adopting such dense connectivity leads to a benefit from a learning perspective thanks to: i) including deep supervision and ii) improving gradient flow. This approach has been evaluated in the MICCAI grand Challenge iSEG and obtains very competitive results among 21 teams, ranking first and second in many metrics, which translates into a promising performance. version:1
arxiv-1710-05941 | Swish: a Self-Gated Activation Function | http://arxiv.org/abs/1710.05941 | id:1710.05941 author:Prajit Ramachandran, Barret Zoph, Quoc V. Le category:cs.NE cs.CV cs.LG  published:2017-10-16 summary:The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose a new activation function, named Swish, which is simply $f(x) = x \cdot \text{sigmoid}(x)$. Our experiments show that Swish tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9% for Mobile NASNet-A and 0.6% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network. version:1
arxiv-1710-05895 | Spectral Algorithms for Computing Fair Support Vector Machines | http://arxiv.org/abs/1710.05895 | id:1710.05895 author:Matt Olfat, Anil Aswani category:cs.LG math.OC stat.ML  published:2017-10-16 summary:Classifiers and rating scores are prone to implicitly codifying biases, which may be present in the training data, against protected classes (i.e., age, gender, or race). So it is important to understand how to design classifiers and scores that prevent discrimination in predictions. This paper develops computationally tractable algorithms for designing accurate but fair support vector machines (SVM's). Our approach imposes a constraint on the covariance matrices conditioned on each protected class, which leads to a nonconvex quadratic constraint in the SVM formulation. We develop iterative algorithms to compute fair linear and kernel SVM's, which solve a sequence of relaxations constructed using a spectral decomposition of the nonconvex constraint. Its effectiveness in achieving high prediction accuracy while ensuring fairness is shown through numerical experiments on several data sets. version:1
arxiv-1710-05888 | Discriminative Learning of Prediction Intervals | http://arxiv.org/abs/1710.05888 | id:1710.05888 author:Nir Rosenfeld, Yishay Mansour, Elad Yom-Tov category:cs.LG  published:2017-10-16 summary:In this work we consider the task of constructing prediction intervals in an inductive batch setting. We present a discriminative learning framework which optimizes the expected error rate under a budget constraint on the interval sizes. Most current methods for constructing prediction intervals offer guarantees for a single new test point. Applying these methods to multiple test points results in a high computational overhead and degraded statistical properties. By focusing on expected errors, our method allows for variability in the per-example conditional error rates. As we demonstrate both analytically and empirically, this flexibility can increase the overall accuracy, or alternatively, reduce the average interval size. While the problem we consider is of a regressive flavor, the loss we use is of a combinatorial nature. This allows us to provide PAC-style, finite-sample guarantees. Computationally, we show that our original objective is NP-hard, and suggest a tractable convex surrogate. We conclude with a series of experimental evaluations. version:1
arxiv-1710-04404 | Sum-Product-Quotient Networks | http://arxiv.org/abs/1710.04404 | id:1710.04404 author:Or Sharir, Amnon Shashua category:cs.LG cs.NE stat.ML  published:2017-10-12 summary:We present a novel tractable generative model that extends Sum-Product Networks (SPNs) and significantly boost their power. We call it Sum-Product-Quotient Networks (SPQNs), whose core concept is to incorporate conditional distributions into the model by direct computation using quotient nodes, e.g. $P(A B){=}\frac{P(A,B)}{P(B)}$. We provide sufficient conditions for the tractability of SPQNs that generalize and relax the decomposable and complete tractability conditions of SPNs. These relaxed conditions give rise to an exponential boost to the expressive efficiency of our model, i.e. we prove that there are distributions which SPQNs can compute efficiently but require SPNs to be of exponential size. Thus, we narrow the gap in expressivity between tractable graphical models and other Neural Network-based generative models. version:2
arxiv-1705-01708 | Semi-Supervised AUC Optimization based on Positive-Unlabeled Learning | http://arxiv.org/abs/1705.01708 | id:1705.01708 author:Tomoya Sakai, Gang Niu, Masashi Sugiyama category:stat.ML cs.LG  published:2017-05-04 summary:Maximizing the area under the receiver operating characteristic curve (AUC) is a standard approach to imbalanced classification. So far, various supervised AUC optimization methods have been developed and they are also extended to semi-supervised scenarios to cope with small sample problems. However, existing semi-supervised AUC optimization methods rely on strong distributional assumptions, which are rarely satisfied in real-world problems. In this paper, we propose a novel semi-supervised AUC optimization method that does not require such restrictive assumptions. We first develop an AUC optimization method based only on positive and unlabeled data (PU-AUC) and then extend it to semi-supervised learning by combining it with a supervised AUC optimization method. We theoretically prove that, without the restrictive distributional assumptions, unlabeled data contribute to improving the generalization performance in PU and semi-supervised AUC optimization methods. Finally, we demonstrate the practical usefulness of the proposed methods through experiments. version:2
arxiv-1710-05778 | A successive difference-of-convex approximation method for a class of nonconvex nonsmooth optimization problems | http://arxiv.org/abs/1710.05778 | id:1710.05778 author:Tianxiang Liu, Ting Kei Pong, Akiko Takeda category:math.OC stat.ML  published:2017-10-16 summary:We consider a class of nonconvex nonsmooth optimization problems whose objective is the sum of a nonnegative smooth function and a bunch of nonnegative proper closed possibly nonsmooth functions (whose proximal mappings are easy to compute), some of which are further composed with linear maps. This kind of problems arises naturally in various applications when different regularizers are introduced for inducing simultaneous structures in the solutions. Solving these problems, however, can be challenging because of the coupled nonsmooth functions: the corresponding proximal mapping can be hard to compute so that standard first-order methods such as the proximal gradient algorithm cannot be applied efficiently. In this paper, we propose a successive difference-of-convex approximation method for solving this kind of problems. In this algorithm, we approximate the nonsmooth functions by their Moreau envelopes in each iteration. Making use of the simple observation that Moreau envelopes of nonnegative proper closed functions are continuous difference-of-convex functions, we can then approximately minimize the approximation function by first-order methods with suitable majorization techniques. These first-order methods can be implemented efficiently thanks to the fact that the proximal mapping of each nonsmooth function is easy to compute. Under suitable assumptions, we prove that the sequence generated by our method is bounded and clusters at a stationary point of the objective. We also discuss how our method can be applied to concrete applications such as nonconvex fused regularized optimization problems and simultaneously structured matrix optimization problems, and illustrate the performance numerically for these two specific applications. version:1
arxiv-1710-05776 | Nonsmooth Frank-Wolfe using Uniform Affine Approximations | http://arxiv.org/abs/1710.05776 | id:1710.05776 author:Edward Cheung, Yuying Li category:stat.ML math.OC  published:2017-10-16 summary:Frank-Wolfe methods (FW) have gained significant interest in the machine learning community due to its ability to efficiently solve large problems that admit a sparse structure (e.g. sparse vectors and low-rank matrices). However the performance of the existing FW method hinges on the quality of the linear approximation. This typically restricts FW to smooth functions for which the approximation quality, indicated by a global curvature measure, is reasonably good. In this paper, we propose a modified FW algorithm amenable to nonsmooth functions by optimizing for approximation quality over all affine approximations given a neighborhood of interest. We analyze theoretical properties of the proposed algorithm and demonstrate that it overcomes many issues associated with existing methods in the context of nonsmooth low-rank matrix estimation. version:1
arxiv-1710-05751 | Time Series Prediction : Predicting Stock Price | http://arxiv.org/abs/1710.05751 | id:1710.05751 author:Aaron Elliot, Cheng Hua Hsu, Jennifer Slodoba category:stat.ML 62-07  published:2017-10-16 summary:Time series forecasting is widely used in a multitude of domains. In this paper, we present four models to predict the stock price using the SNP 500 index as input time series data. The system gives the error of "Bad character(s) in field Abstract" for no reason. Please refer to manuscript for the full abstract version:1
arxiv-1710-05741 | A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning | http://arxiv.org/abs/1710.05741 | id:1710.05741 author:Marco Fraccaro, Simon Kamronn, Ulrich Paquet, Ole Winther category:stat.ML cs.LG  published:2017-10-16 summary:This paper takes a step towards temporal reasoning in a dynamically changing video, not in the pixel space that constitutes its frames, but in a latent space that describes the non-linear dynamics of the objects in its world. We introduce the Kalman variational auto-encoder, a framework for unsupervised learning of sequential data that disentangles two latent representations: an object's representation, coming from a recognition model, and a latent state describing its dynamics. As a result, the evolution of the world can be imagined and missing data imputed, both without the need to generate high dimensional frames at each time step. The model is trained end-to-end on videos of a variety of simulated physical systems, and outperforms competing methods in generative and missing data imputation tasks. version:1
arxiv-1710-05739 | On the Hardness of Inventory Management with Censored Demand Data | http://arxiv.org/abs/1710.05739 | id:1710.05739 author:Gábor Lugosi, Mihalis G. Markakis, Gergely Neu category:cs.LG math.OC stat.ML  published:2017-10-16 summary:We consider a repeated newsvendor problem where the inventory manager has no prior information about the demand, and can access only censored/sales data. In analogy to multi-armed bandit problems, the manager needs to simultaneously "explore" and "exploit" with her inventory decisions, in order to minimize the cumulative cost. We make no probabilistic assumptions---importantly, independence or time stationarity---regarding the mechanism that creates the demand sequence. Our goal is to shed light on the hardness of the problem, and to develop policies that perform well with respect to the regret criterion, that is, the difference between the cumulative cost of a policy and that of the best fixed action/static inventory decision in hindsight, uniformly over all feasible demand sequences. We show that a simple randomized policy, termed the Exponentially Weighted Forecaster, combined with a carefully designed cost estimator, achieves optimal scaling of the expected regret (up to logarithmic factors) with respect to all three key primitives: the number of time periods, the number of inventory decisions available, and the demand support. Through this result, we derive an important insight: the benefit from "information stalking" as well as the cost of censoring are both negligible in this dynamic learning problem, at least with respect to the regret criterion. Furthermore, we modify the proposed policy in order to perform well in terms of the tracking regret, that is, using as benchmark the best sequence of inventory decisions that switches a limited number of times. Numerical experiments suggest that the proposed approach outperforms existing ones (that are tailored to, or facilitated by, time stationarity) on nonstationary demand models. Finally, we extend the proposed approach and its analysis to a "combinatorial" version of the repeated newsvendor problem. version:1
arxiv-1710-05709 | Aligning Script Events with Narrative Texts | http://arxiv.org/abs/1710.05709 | id:1710.05709 author:Simon Ostermann, Michael Roth, Stefan Thater, Manfred Pinkal category:cs.CL  published:2017-10-16 summary:Script knowledge plays a central role in text understanding and is relevant for a variety of downstream tasks. In this paper, we consider two recent datasets which provide a rich and general representation of script events in terms of paraphrase sets. We introduce the task of mapping event mentions in narrative texts to such script event types, and present a model for this task that exploits rich linguistic representations as well as information on temporal ordering. The results of our experiments demonstrate that this complex task is indeed feasible. version:1
arxiv-1710-05918 | Convolutional neural networks for structured omics: OmicsCNN and the OmicsConv layer | http://arxiv.org/abs/1710.05918 | id:1710.05918 author:Giuseppe Jurman, Valerio Maggio, Diego Fioravanti, Ylenia Giarratano, Isotta Landi, Margherita Francescatto, Claudio Agostinelli, Marco Chierici, Manlio De Domenico, Cesare Furlanello category:q-bio.QM stat.ML  published:2017-10-16 summary:Convolutional Neural Networks (CNNs) are a popular deep learning architecture widely applied in different domains, in particular in classifying over images, for which the concept of convolution with a filter comes naturally. Unfortunately, the requirement of a distance (or, at least, of a neighbourhood function) in the input feature space has so far prevented its direct use on data types such as omics data. However, a number of omics data are metrizable, i.e., they can be endowed with a metric structure, enabling to adopt a convolutional based deep learning framework, e.g., for prediction. We propose a generalized solution for CNNs on omics data, implemented through a dedicated Keras layer. In particular, for metagenomics data, a metric can be derived from the patristic distance on the phylogenetic tree. For transcriptomics data, we combine Gene Ontology semantic similarity and gene co-expression to define a distance; the function is defined through a multilayer network where 3 layers are defined by the GO mutual semantic similarity while the fourth one by gene co-expression. As a general tool, feature distance on omics data is enabled by OmicsConv, a novel Keras layer, obtaining OmicsCNN, a dedicated deep learning framework. Here we demonstrate OmicsCNN on gut microbiota sequencing data, for Inflammatory Bowel Disease (IBD) 16S data, first on synthetic data and then a metagenomics collection of gut microbiota of 222 IBD patients. version:1
arxiv-1709-03485 | NiftyNet: a deep-learning platform for medical imaging | http://arxiv.org/abs/1709.03485 | id:1709.03485 author:Eli Gibson, Wenqi Li, Carole Sudre, Lucas Fidon, Dzhoshkun I. Shakir, Guotai Wang, Zach Eaton-Rosen, Robert Gray, Tom Doel, Yipeng Hu, Tom Whyntie, Parashkev Nachev, Marc Modat, Dean C. Barratt, Sébastien Ourselin, M. Jorge Cardoso, Tom Vercauteren category:cs.CV cs.LG cs.NE  published:2017-09-11 summary:Medical image analysis and computer-assisted intervention problems are increasingly being addressed with deep-learning-based solutions. Established deep-learning platforms are flexible but do not provide specific functionality for medical image analysis and adapting them for this application requires substantial implementation effort. Thus, there has been substantial duplication of effort and incompatible infrastructure developed across many research groups. This work presents the open-source NiftyNet platform for deep learning in medical imaging. The ambition of NiftyNet is to accelerate and simplify the development of these solutions, and to provide a common mechanism for disseminating research outputs for the community to use, adapt and build upon. NiftyNet provides a modular deep-learning pipeline for a range of medical imaging applications including segmentation, regression, image generation and representation learning applications. Components of the NiftyNet pipeline including data loading, data augmentation, network architectures, loss functions and evaluation metrics are tailored to, and take advantage of, the idiosyncracies of medical image analysis and computer-assisted intervention. NiftyNet is built on TensorFlow and supports TensorBoard visualization of 2D and 3D images and computational graphs by default. We present 3 illustrative medical image analysis applications built using NiftyNet: (1) segmentation of multiple abdominal organs from computed tomography; (2) image regression to predict computed tomography attenuation maps from brain magnetic resonance images; and (3) generation of simulated ultrasound images for specified anatomical poses. NiftyNet enables researchers to rapidly develop and distribute deep learning solutions for segmentation, regression, image generation and representation learning applications, or extend the platform to new applications. version:2
arxiv-1710-05664 | What is (missing or wrong) in the scene? A Hybrid Deep Boltzmann Machine For Contextualized Scene Modeling | http://arxiv.org/abs/1710.05664 | id:1710.05664 author:İlker Bozcan, Yağmur Oymak, İdil Zeynep Alemdar, Sinan Kalkan category:cs.CV cs.RO  published:2017-10-16 summary:Scene models allow robots to reason about what is in the scene, what else should be in it, and what should not be in it. In this paper, we propose a hybrid Boltzmann Machine (BM) for scene modeling where relations between objects are integrated. To be able to do that, we extend BM to include tri-way edges between visible (object) nodes and make the network to share the relations across different objects. We evaluate our method against several baseline models (Deep Boltzmann Machines, and Restricted Boltzmann Machines) on a scene classification dataset, and show that it performs better in several scene reasoning tasks. version:1
arxiv-1710-05654 | Large Scale Graph Learning from Smooth Signals | http://arxiv.org/abs/1710.05654 | id:1710.05654 author:Vassilis Kalofolias, Nathanaël Perraudin category:stat.ML cs.LG  published:2017-10-16 summary:Graphs are a prevalent tool in data science, as they model the inherent structure of the data. They have been used successfully in unsupervised and semi-supervised learning. Typically they are constructed either by connecting nearest samples, or by learning them from data, solving an optimization problem. While graph learning does achieve a better quality, it also comes with a higher computational cost. In particular, the current state-of-the-art model cost is $\mathcal{O}(n^2)$ for $n$ samples. In this paper, we show how to scale it, obtaining an approximation with leading cost of $\mathcal{O}(n\log(n))$, with quality that approaches the exact graph learning model. Our algorithm uses known approximate nearest neighbor techniques to reduce the number of variables, and automatically selects the correct parameters of the model, requiring a single intuitive input: the desired edge density. version:1
arxiv-1707-09562 | MLBench: How Good Are Machine Learning Clouds for Binary Classification Tasks on Structured Data? | http://arxiv.org/abs/1707.09562 | id:1707.09562 author:Yu Liu, Hantian Zhang, Luyuan Zeng, Wentao Wu, Ce Zhang category:cs.DC cs.LG stat.ML  published:2017-07-29 summary:We conduct an empirical study of machine learning functionalities provided by major cloud service providers, which we call machine learning clouds. Machine learning clouds hold the promise of hiding all the sophistication of running large-scale machine learning: Instead of specifying how to run a machine learning task, users only specify what machine learning task to run and the cloud figures out the rest. Raising the level of abstraction, however, rarely comes free - a performance penalty is possible. How good, then, are current machine learning clouds on real-world machine learning workloads? We study this question with a focus on binary classication problems. We present mlbench, a novel benchmark constructed by harvesting datasets from Kaggle competitions. We then compare the performance of the top winning code available from Kaggle with that of running machine learning clouds from both Azure and Amazon on mlbench. Our comparative study reveals the strength and weakness of existing machine learning clouds and points out potential future directions for improvement. version:3
arxiv-1706-07842 | Image Forgery Localization Based on Multi-Scale Convolutional Neural Networks | http://arxiv.org/abs/1706.07842 | id:1706.07842 author:Yaqi Liu, Qingxiao Guan, Xianfeng Zhao, Yun Cao category:cs.CV cs.MM  published:2017-06-13 summary:In this paper, we propose to utilize Convolutional Neural Networks (CNNs) and the segmentation-based multi-scale analysis to locate tampered areas in digital images. First, to deal with color input sliding windows of different scales, a unified CNN architecture is designed. Then, we elaborately design the training procedures of CNNs on sampled training patches. With a set of robust multi-scale tampering detectors based on CNNs, complementary tampering possibility maps can be generated. Last but not least, a segmentation-based method is proposed to fuse the maps and generate the final decision map. By exploiting the benefits of both the small-scale and large-scale analyses, the segmentation-based multi-scale analysis can lead to a performance leap in forgery localization of CNNs. Numerous experiments are conducted to demonstrate the effectiveness and efficiency of our method. version:3
arxiv-1710-05613 | Learning from Incomplete Ratings using Nonlinear Multi-layer Semi-Nonnegative Matrix Factorization | http://arxiv.org/abs/1710.05613 | id:1710.05613 author:Vaibhav Krishna, Nino Antulov-Fantulin category:cs.LG stat.ML  published:2017-10-16 summary:Recommender systems problems witness a growing interest for finding better learning algorithms for personalized information. Matrix factorization that estimates the user liking for an item by taking an inner product on the latent features of users and item have been widely studied owing to its better accuracy and scalability. However, it is possible that the mapping between the latent features learned from these and the original features contains rather complex nonlinear hierarchical information, that classical linear matrix factorization can not capture. In this paper, we aim to propose a novel multilayer non-linear approach to a variant of nonnegative matrix factorization (NMF) to learn such factors from the incomplete ratings matrix. Firstly, we construct a user-item matrix with explicit ratings, secondly we learn latent factors for representations of users and items from the designed nonlinear multi-layer approach. Further, the architecture is built with different nonlinearities using adaptive gradient optimizer to better learn the latent factors in this space. We show that by doing so, our model is able to learn low-dimensional representations that are better suited for recommender systems on several benchmark datasets. version:1
arxiv-1704-08829 | Deep Feature Learning for Graphs | http://arxiv.org/abs/1704.08829 | id:1704.08829 author:Ryan A. Rossi, Rong Zhou, Nesreen K. Ahmed category:stat.ML cs.LG cs.SI  published:2017-04-28 summary:This paper presents a general graph representation learning framework called DeepGL for learning deep node and edge representations from large (attributed) graphs. In particular, DeepGL begins by deriving a set of base features (e.g., graphlet features) and automatically learns a multi-layered hierarchical graph representation where each successive layer leverages the output from the previous layer to learn features of a higher-order. Contrary to previous work, DeepGL learns relational functions (each representing a feature) that generalize across-networks and therefore useful for graph-based transfer learning tasks. Moreover, DeepGL naturally supports attributed graphs, learns interpretable features, and is space-efficient (by learning sparse feature vectors). In addition, DeepGL is expressive, flexible with many interchangeable components, efficient with a time complexity of $\mathcal{O}( E )$, and scalable for large networks via an efficient parallel implementation. Compared with the state-of-the-art method, DeepGL is (1) effective for across-network transfer learning tasks and attributed graph representation learning, (2) space-efficient requiring up to 6x less memory, (3) fast with up to 182x speedup in runtime performance, and (4) accurate with an average improvement of 20% or more on many learning tasks. version:2
arxiv-1705-04293 | Bayesian Approaches to Distribution Regression | http://arxiv.org/abs/1705.04293 | id:1705.04293 author:Ho Chung Leon Law, Dougal J. Sutherland, Dino Sejdinovic, Seth Flaxman category:stat.ML cs.LG  published:2017-05-11 summary:Distribution regression has recently attracted much interest as a generic solution to the problem of supervised learning where labels are available at the group level, rather than at the individual level. Current approaches, however, do not propagate the uncertainty in observations due to sampling variability in the groups. This effectively assumes that small and large groups are estimated equally well, and should have equal weight in the final regression. We account for this uncertainty with a Bayesian distribution regression formalism, improving the robustness and performance of the model when group sizes vary. We frame our models in a neural network style, allowing for simple MAP inference using backpropagation to learn the parameters, as well as MCMC-based inference which can fully propagate uncertainty. We demonstrate our approach on illustrative toy datasets, as well as on a challenging problem of predicting age from images. version:2
arxiv-1705-00105 | Representation Learning and Pairwise Ranking for Implicit Feedback in Recommendation Systems | http://arxiv.org/abs/1705.00105 | id:1705.00105 author:Sumit Sidana, Mikhail Trofimov, Oleg Horodnitskii, Charlotte Laclau, Yury Maximov, Massih-Reza Amini category:stat.ML cs.CL cs.IR  published:2017-04-29 summary:In this paper, we propose a novel ranking framework for collaborative filtering with the overall aim of learning user preferences over items by minimizing a pairwise ranking loss. We show the minimization problem involves dependent random variables and provide a theoretical analysis by proving the consistency of the empirical risk minimization in the worst case where all users choose a minimal number of positive and negative items. We further derive a Neural-Network model that jointly learns a new representation of users and items in an embedded space as well as the preference relation of users over the pairs of items. The learning objective is based on three scenarios of ranking losses that control the ability of the model to maintain the ordering over the items induced from the users' preferences, as well as, the capacity of the dot-product defined in the learned embedded space to produce the ordering. The proposed model is by nature suitable for implicit feedback and involves the estimation of only very few parameters. Through extensive experiments on several real-world benchmarks on implicit data, we show the interest of learning the preference and the embedding simultaneously when compared to learning those separately. We also demonstrate that our approach is very competitive with the best state-of-the-art collaborative filtering techniques proposed for implicit feedback. version:2
arxiv-1709-05011 | 100-epoch ImageNet Training with AlexNet in 24 Minutes | http://arxiv.org/abs/1709.05011 | id:1709.05011 author:Yang You, Zhao Zhang, Cho-Jui Hsieh, James Demmel, Kurt Keutzer category:cs.CV  published:2017-09-14 summary:Finishing 90-epoch ImageNet-1k training with ResNet-50 on a NVIDIA M40 GPU takes 14 days. This training requires 10^18 single precision operations in total. On the other hand, the world's current fastest supercomputer can finish 2 * 10^17 single precision operations per second (Dongarra et al 2017, https://www.top500.org/lists/2017/06/). If we can make full use of the supercomputer for DNN training, we should be able to finish the 90-epoch ResNet-50 training in five seconds. However, the current bottleneck for fast DNN training is in the algorithm level. Specifically, the current batch size (e.g. 512) is too small to make efficient use of many processors For large-scale DNN training, we focus on using large-batch data-parallelism synchronous SGD without losing accuracy in the fixed epochs. The LARS algorithm (You, Gitman, Ginsburg, 2017, arXiv:1708.03888) enables us to scale the batch size to extremely large case (e.g. 32K). We finish the 100-epoch ImageNet training with AlexNet in 24 minutes. Same as Facebook's result (Goyal et al 2017, arXiv:1706.02677), we finish the 90-epoch ImageNet training with ResNet-50 in one hour. Furthermore, when we increase the batch size to above 10K, our accuracy is much higher than Facebook's on corresponding batch sizes. version:3
arxiv-1710-05578 | Fair Kernel Learning | http://arxiv.org/abs/1710.05578 | id:1710.05578 author:Adrián Pérez-Suay, Valero Laparra, Gonzalo Mateo-García, Jordi Muñoz-Marí, Luis Gómez-Chova, Gustau Camps-Valls category:stat.ML  published:2017-10-16 summary:New social and economic activities massively exploit big data and machine learning algorithms to do inference on people's lives. Applications include automatic curricula evaluation, wage determination, and risk assessment for credits and loans. Recently, many governments and institutions have raised concerns about the lack of fairness, equity and ethics in machine learning to treat these problems. It has been shown that not including sensitive features that bias fairness, such as gender or race, is not enough to mitigate the discrimination when other related features are included. Instead, including fairness in the objective function has been shown to be more efficient. We present novel fair regression and dimensionality reduction methods built on a previously proposed fair classification framework. Both methods rely on using the Hilbert Schmidt independence criterion as the fairness term. Unlike previous approaches, this allows us to simplify the problem and to use multiple sensitive variables simultaneously. Replacing the linear formulation by kernel functions allows the methods to deal with nonlinear problems. For both linear and nonlinear formulations the solution reduces to solving simple matrix inversions or generalized eigenvalue problems. This simplifies the evaluation of the solutions for different trade-off values between the predictive error and fairness terms. We illustrate the usefulness of the proposed methods in toy examples, and evaluate their performance on real world datasets to predict income using gender and/or race discrimination as sensitive variables, and contraceptive method prediction under demographic and socio-economic sensitive descriptors. version:1
arxiv-1710-03285 | Coresets for Dependency Networks | http://arxiv.org/abs/1710.03285 | id:1710.03285 author:Alejandro Molina, Alexander Munteanu, Kristian Kersting category:cs.AI cs.LG stat.ML  published:2017-10-09 summary:Many applications infer the structure of a probabilistic graphical model from data to elucidate the relationships between variables. But how can we train graphical models on a massive data set? In this paper, we show how to construct coresets -compressed data sets which can be used as proxy for the original data and have provably bounded worst case error- for Gaussian dependency networks (DNs), i.e., cyclic directed graphical models over Gaussians, where the parents of each variable are its Markov blanket. Specifically, we prove that Gaussian DNs admit coresets of size independent of the size of the data set. Unfortunately, this does not extend to DNs over members of the exponential family in general. As we will prove, Poisson DNs do not admit small coresets. Despite this worst-case result, we will provide an argument why our coreset construction for DNs can still work well in practice on count data. To corroborate our theoretical results, we empirically evaluated the resulting Core DNs on real data sets. The results version:2
arxiv-1710-03297 | Sum-Product Networks for Hybrid Domains | http://arxiv.org/abs/1710.03297 | id:1710.03297 author:Alejandro Molina, Antonio Vergari, Nicola Di Mauro, Sriraam Natarajan, Floriana Esposito, Kristian Kersting category:cs.LG stat.ML  published:2017-10-09 summary:While all kinds of mixed data -from personal data, over panel and scientific data, to public and commercial data- are collected and stored, building probabilistic graphical models for these hybrid domains becomes more difficult. Users spend significant amounts of time in identifying the parametric form of the random variables (Gaussian, Poisson, Logit, etc.) involved and learning the mixed models. To make this difficult task easier, we propose the first trainable probabilistic deep architecture for hybrid domains that features tractable queries. It is based on Sum-Product Networks (SPNs) with piecewise polynomial leave distributions together with novel nonparametric decomposition and conditioning steps using the Hirschfeld-Gebelein-R\'enyi Maximum Correlation Coefficient. This relieves the user from deciding a-priori the parametric form of the random variables but is still expressive enough to effectively approximate any continuous distribution and permits efficient learning and inference. Our empirical evidence shows that the architecture, called Mixed SPNs, can indeed capture complex distributions across a wide range of hybrid domains. version:2
arxiv-1710-05552 | Fully adaptive algorithm for pure exploration in linear bandits | http://arxiv.org/abs/1710.05552 | id:1710.05552 author:Liyuan Xu, Junya Honda, Masashi Sugiyama category:stat.ML  published:2017-10-16 summary:We propose the first fully-adaptive algorithm for pure exploration in linear bandits---the task to find the arm with the largest expected reward, which depends on an unknown parameter linearly. While existing methods partially or entirely fix sequences of arm selections before observing rewards, our method adaptively changes the arm selection strategy based on past observations at each round. We show our sample complexity matches the achievable lower bound up to a constant factor in an extreme case. Furthermore, we evaluate the performance of the methods by simulations based on both synthetic setting and real-world data, in which our method shows vast improvement over existing methods. version:1
arxiv-1709-01423 | A heterogeneity based iterative clustering approach for obtaining samples with reduced bias | http://arxiv.org/abs/1709.01423 | id:1709.01423 author:Chandrasekaran Anirudh Bhardwaj, Megha Mishra, Kalyani Desikan category:cs.LG  published:2017-09-02 summary:Medical and social sciences demand sampling techniques which are robust, reliable, replicable and give samples with the least bias. Majority of the applications of sampling use randomized sampling, albeit with stratification where applicable to lower the bias. The randomized technique is not consistent, and may provide different samples each time, and the different samples themselves may not be similar to each other. In this paper, we introduce a novel sampling technique called Wobbly Center Algorithm, which relies on iterative clustering based on maximizing heterogeneity to achieve samples which are consistent, and with low bias. The algorithm works on the principle of iteratively building clusters by finding the points with the maximal distance from the cluster center. The algorithm consistently gives a better result in lowering the bias by reducing the standard deviations in the means of each feature in a scaled data. version:2
arxiv-1710-05520 | Entanglement Entropy of Target Functions for Image Classification and Convolutional Neural Network | http://arxiv.org/abs/1710.05520 | id:1710.05520 author:Ya-Hui Zhang category:cs.LG cond-mat.str-el cs.CV  published:2017-10-16 summary:The success of deep convolutional neural network (CNN) in computer vision especially image classification problems requests a new information theory for function of image, instead of image itself. In this article, after establishing a deep mathematical connection between image classification problem and quantum spin model, we propose to use entanglement entropy, a generalization of classical Boltzmann-Shannon entropy, as a powerful tool to characterize the information needed for representation of general function of image. We prove that there is a sub-volume-law bound for entanglement entropy of target functions of reasonable image classification problems. Therefore target functions of image classification only occupy a small subspace of the whole Hilbert space. As a result, a neural network with polynomial number of parameters is efficient for representation of such target functions of image. The concept of entanglement entropy can also be useful to characterize the expressive power of different neural networks. For example, we show that to maintain the same expressive power, number of channels $D$ in a convolutional neural network should scale with the number of convolution layers $n_c$ as $D\sim D_0^{\frac{1}{n_c}}$. Therefore, deeper CNN with large $n_c$ is more efficient than shallow ones. version:1
arxiv-1710-05519 | BKTreebank: Building a Vietnamese Dependency Treebank | http://arxiv.org/abs/1710.05519 | id:1710.05519 author:Kiem-Hieu Nguyen category:cs.CL  published:2017-10-16 summary:Dependency treebank is an important resource in any language. In this paper, we present our work on building BKTreebank, a dependency treebank for Vietnamese. Important points on designing POS tagset, dependency relations, and annotation guidelines are discussed. We describe experiments on POS tagging and dependency parsing on the treebank. Experimental results show that the treebank is a useful resource for Vietnamese language processing. version:1
arxiv-1710-05513 | Robust Maximum Likelihood Estimation of Sparse Vector Error Correction Model | http://arxiv.org/abs/1710.05513 | id:1710.05513 author:Ziping Zhao, Daniel P. Palomar category:stat.ML cs.NA q-fin.ST stat.AP stat.CO  published:2017-10-16 summary:In econometrics and finance, the vector error correction model (VECM) is an important time series model for cointegration analysis, which is used to estimate the long-run equilibrium variable relationships. The traditional analysis and estimation methodologies assume the underlying Gaussian distribution but, in practice, heavy-tailed data and outliers can lead to the inapplicability of these methods. In this paper, we propose a robust model estimation method based on the Cauchy distribution to tackle this issue. In addition, sparse cointegration relations are considered to realize feature selection and dimension reduction. An efficient algorithm based on the majorization-minimization (MM) method is applied to solve the proposed nonconvex problem. The performance of this algorithm is shown through numerical simulations. version:1
arxiv-1710-05512 | The Feeling of Success: Does Touch Sensing Help Predict Grasp Outcomes? | http://arxiv.org/abs/1710.05512 | id:1710.05512 author:Roberto Calandra, Andrew Owens, Manu Upadhyaya, Wenzhen Yuan, Justin Lin, Edward H. Adelson, Sergey Levine category:cs.RO cs.CV cs.LG  published:2017-10-16 summary:A successful grasp requires careful balancing of the contact forces. Deducing whether a particular grasp will be successful from indirect measurements, such as vision, is therefore quite challenging, and direct sensing of contacts through touch sensing provides an appealing avenue toward more successful and consistent robotic grasping. However, in order to fully evaluate the value of touch sensing for grasp outcome prediction, we must understand how touch sensing can influence outcome prediction accuracy when combined with other modalities. Doing so using conventional model-based techniques is exceptionally difficult. In this work, we investigate the question of whether touch sensing aids in predicting grasp outcomes within a multimodal sensing framework that combines vision and touch. To that end, we collected more than 9,000 grasping trials using a two-finger gripper equipped with GelSight high-resolution tactile sensors on each finger, and evaluated visuo-tactile deep neural network models to directly predict grasp outcomes from either modality individually, and from both modalities together. Our experimental results indicate that incorporating tactile readings substantially improve grasping performance. version:1
arxiv-1710-05488 | A Geometric View of Optimal Transportation and Generative Model | http://arxiv.org/abs/1710.05488 | id:1710.05488 author:Na Lei, Kehua Su, Li Cui, Shing-Tung Yau, David Xianfeng Gu category:cs.LG stat.ML  published:2017-10-16 summary:In this work, we show the intrinsic relations between optimal transportation and convex geometry, especially the variational approach to solve Alexandrov problem: constructing a convex polytope with prescribed face normals and volumes. This leads to a geometric interpretation to generative models, and leads to a novel framework for generative models. By using the optimal transportation view of GAN model, we show that the discriminator computes the Kantorovich potential, the generator calculates the transportation map. For a large class of transportation costs, the Kantorovich potential can give the optimal transportation map by a close-form formula. Therefore, it is sufficient to solely optimize the discriminator. This shows the adversarial competition can be avoided, and the computational architecture can be simplified. Preliminary experimental results show the geometric method outperforms WGAN for approximating probability measures with multiple clusters in low dimensional space. version:1
arxiv-1710-05477 | A multi-branch convolutional neural network for detecting double JPEG compression | http://arxiv.org/abs/1710.05477 | id:1710.05477 author:Bin Li, Hu Luo, Haoxin Zhang, Shunquan Tan, Zhongzhou Ji category:cs.CV cs.MM  published:2017-10-16 summary:Detection of double JPEG compression is important to forensics analysis. A few methods were proposed based on convolutional neural networks (CNNs). These methods only accept inputs from pre-processed data, such as histogram features and/or decompressed images. In this paper, we present a CNN solution by using raw DCT (discrete cosine transformation) coefficients from JPEG images as input. Considering the DCT sub-band nature in JPEG, a multiple-branch CNN structure has been designed to reveal whether a JPEG format image has been doubly compressed. Comparing with previous methods, the proposed method provides end-to-end detection capability. Extensive experiments have been carried out to demonstrate the effectiveness of the proposed network. version:1
arxiv-1710-05472 | Safe Learning of Quadrotor Dynamics Using Barrier Certificates | http://arxiv.org/abs/1710.05472 | id:1710.05472 author:Li Wang, Evangelos A. Theodorou, Magnus Egerstedt category:cs.LG cs.SY  published:2017-10-16 summary:To effectively control complex dynamical systems, accurate nonlinear models are typically needed. However, these models are not always known. In this paper, we present a data-driven approach based on Gaussian processes that learns models of quadrotors operating in partially unknown environments. What makes this challenging is that if the learning process is not carefully controlled, the system will go unstable, i.e., the quadcopter will crash. To this end, barrier certificates are employed for safe learning. The barrier certificates establish a non-conservative forward invariant safe region, in which high probability safety guarantees are provided based on the statistics of the Gaussian Process. A learning controller is designed to efficiently explore those uncertain states and expand the barrier certified safe region based on an adaptive sampling scheme. In addition, a recursive Gaussian Process prediction method is developed to learn the complex quadrotor dynamics in real-time. Simulation results are provided to demonstrate the effectiveness of the proposed approach. version:1
arxiv-1710-05468 | Generalization in Deep Learning | http://arxiv.org/abs/1710.05468 | id:1710.05468 author:Kenji Kawaguchi, Leslie Pack Kaelbling, Yoshua Bengio category:stat.ML cs.AI cs.LG cs.NE  published:2017-10-16 summary:This paper explains why deep learning can generalize well, despite large capacity and possible algorithmic instability, nonrobustness, and sharp minima, effectively addressing an open problem in the literature. Based on our theoretical insight, this paper also proposes a family of new regularization methods. Its simplest member was empirically shown to improve base models and achieve state-of-the-art performance on MNIST and CIFAR-10 benchmarks. Moreover, this paper presents both data-dependent and data-independent generalization guarantees with improved convergence rates. Our results suggest several new open areas of research. version:1
arxiv-1708-02288 | Beyond Low-Rank Representations: Orthogonal Clustering Basis Reconstruction with Optimized Graph Structure for Multi-view Spectral Clustering | http://arxiv.org/abs/1708.02288 | id:1708.02288 author:Yang Wang, Lin Wu category:cs.CV  published:2017-08-04 summary:Low-Rank Representation (LRR) is arguably one of the most powerful paradigms for Multi-view spectral clustering, which elegantly encodes the multi-view local graph/manifold structures into an intrinsic low-rank self-expressive data similarity embedded in high-dimensional space, to yield a better graph partition than their single-view counterparts. In this paper we revisit it with a fundamentally different perspective by discovering LRR as essentially a latent clustered orthogonal projection based representation winged with an optimized local graph structure for spectral clustering; each column of the representation is fundamentally a cluster basis orthogonal to others to indicate its members, which intuitively projects the view-specific feature representation to be the one spanned by all orthogonal basis to characterize the cluster structures. Upon this finding, we propose our technique with the followings: (1) We decompose LRR into latent clustered orthogonal representation via low-rank matrix factorization, to encode the more flexible cluster structures than LRR over primal data objects; (2) We convert the problem of LRR into that of simultaneously learning orthogonal clustered representation and optimized local graph structure for each view; (3) The learned orthogonal clustered representations and local graph structures enjoy the same magnitude for multi-view, so that the ideal multi-view consensus can be readily achieved. The experiments over multi-view datasets validate its superiority. version:2
arxiv-1710-05429 | Semi-Supervised Approach to Monitoring Clinical Depressive Symptoms in Social Media | http://arxiv.org/abs/1710.05429 | id:1710.05429 author:Amir Hossein Yazdavar, Hussein S. Al-Olimat, Monireh Ebrahimi, Goonmeet Bajaj, Tanvi Banerjee, Krishnaprasad Thirunarayan, Jyotishman Pathak, Amit Sheth category:cs.CL  published:2017-10-16 summary:With the rise of social media, millions of people are routinely expressing their moods, feelings, and daily struggles with mental health issues on social media platforms like Twitter. Unlike traditional observational cohort studies conducted through questionnaires and self-reported surveys, we explore the reliable detection of clinical depression from tweets obtained unobtrusively. Based on the analysis of tweets crawled from users with self-reported depressive symptoms in their Twitter profiles, we demonstrate the potential for detecting clinical depression symptoms which emulate the PHQ-9 questionnaire clinicians use today. Our study uses a semi-supervised statistical model to evaluate how the duration of these symptoms and their expression on Twitter (in terms of word usage patterns and topical preferences) align with the medical findings reported via the PHQ-9. Our proactive and automatic screening tool is able to identify clinical depressive symptoms with an accuracy of 68% and precision of 72%. version:1
arxiv-1710-05422 | A General Framework for Robust Interactive Learning | http://arxiv.org/abs/1710.05422 | id:1710.05422 author:Ehsan Emamjomeh-Zadeh, David Kempe category:cs.DS cs.LG  published:2017-10-16 summary:We propose a general framework for interactively learning models, such as (binary or non-binary) classifiers, orderings/rankings of items, or clusterings of data points. Our framework is based on a generalization of Angluin's equivalence query model and Littlestone's online learning model: in each iteration, the algorithm proposes a model, and the user either accepts it or reveals a specific mistake in the proposal. The feedback is correct only with probability $p > 1/2$ (and adversarially incorrect with probability $1 - p$), i.e., the algorithm must be able to learn in the presence of arbitrary noise. The algorithm's goal is to learn the ground truth model using few iterations. Our general framework is based on a graph representation of the models and user feedback. To be able to learn efficiently, it is sufficient that there be a graph $G$ whose nodes are the models and (weighted) edges capture the user feedback, with the property that if $s, s^*$ are the proposed and target models, respectively, then any (correct) user feedback $s'$ must lie on a shortest $s$-$s^*$ path in $G$. Under this one assumption, there is a natural algorithm reminiscent of the Multiplicative Weights Update algorithm, which will efficiently learn $s^*$ even in the presence of noise in the user's feedback. From this general result, we rederive with barely any extra effort classic results on learning of classifiers and a recent result on interactive clustering; in addition, we easily obtain new interactive learning algorithms for ordering/ranking. version:1
arxiv-1710-05420 | NeuralPower: Predict and Deploy Energy-Efficient Convolutional Neural Networks | http://arxiv.org/abs/1710.05420 | id:1710.05420 author:Ermao Cai, Da-Cheng Juan, Dimitrios Stamoulis, Diana Marculescu category:cs.LG cs.PF stat.ML  published:2017-10-15 summary:"How much energy is consumed for an inference made by a convolutional neural network (CNN)?" With the increased popularity of CNNs deployed on the wide-spectrum of platforms (from mobile devices to workstations), the answer to this question has drawn significant attention. From lengthening battery life of mobile devices to reducing the energy bill of a datacenter, it is important to understand the energy efficiency of CNNs during serving for making an inference, before actually training the model. In this work, we propose NeuralPower: a layer-wise predictive framework based on sparse polynomial regression, for predicting the serving energy consumption of a CNN deployed on any GPU platform. Given the architecture of a CNN, NeuralPower provides an accurate prediction and breakdown for power and runtime across all layers in the whole network, helping machine learners quickly identify the power, runtime, or energy bottlenecks. We also propose the "energy-precision ratio" (EPR) metric to guide machine learners in selecting an energy-efficient CNN architecture that better trades off the energy consumption and prediction accuracy. The experimental results show that the prediction accuracy of the proposed NeuralPower outperforms the best published model to date, yielding an improvement in accuracy of up to 68.5%. We also assess the accuracy of predictions at the network level, by predicting the runtime, power, and energy of state-of-the-art CNN architectures, achieving an average accuracy of 88.24% in runtime, 88.34% in power, and 97.21% in energy. We comprehensively corroborate the effectiveness of NeuralPower as a powerful framework for machine learners by testing it on different GPU platforms and Deep Learning software tools. version:1
arxiv-1704-06731 | Batch-Expansion Training: An Efficient Optimization Paradigm | http://arxiv.org/abs/1704.06731 | id:1704.06731 author:Michał Dereziński, Dhruv Mahajan, S. Sathiya Keerthi, S. V. N. Vishwanathan, Markus Weimer category:cs.LG  published:2017-04-22 summary:We propose Batch-Expansion Training (BET), a framework for running a batch optimizer on a gradually expanding dataset. As opposed to stochastic approaches, batches do not need to be resampled i.i.d. at every iteration, thus making BET more resource efficient in a distributed setting, and when disk-access is constrained. Moreover, BET can be easily paired with most batch optimizers, does not require any parameter-tuning, and compares favorably to existing stochastic and batch methods. We show that when the batch size grows exponentially with the number of outer iterations, BET achieves optimal $O(1/\epsilon)$ data-access convergence rate for strongly convex objectives. Experiments in parallel and distributed settings show that BET performs better than standard batch and stochastic approaches. version:2
arxiv-1709-05501 | Constrained Bayesian Optimization for Automatic Chemical Design | http://arxiv.org/abs/1709.05501 | id:1709.05501 author:Ryan-Rhys Griffiths, José Miguel Hernández-Lobato category:stat.ML  published:2017-09-16 summary:Automatic Chemical Design leverages recent advances in deep generative modelling to provide a framework for performing continuous optimization of molecular properties. Although the provision of a continuous representation for prospective lead drug candidates has opened the door to hitherto inaccessible tools of mathematical optimization, some challenges remain for the design process. One known pathology is the model's tendency to decode invalid molecular structures. The goal of this thesis is to test the hypothesis that the origin of this pathology is rooted in the current formulation of Bayesian optimization. Recasting the optimization procedure as a constrained Bayesian optimization problem results in novel drug compounds produced by the model consistently ranking in the 100th percentile of the distribution over training set scores. version:3
arxiv-1710-05387 | Manifold Regularization for Kernelized LSTD | http://arxiv.org/abs/1710.05387 | id:1710.05387 author:Xinyan Yan, Krzysztof Choromanski, Byron Boots, Vikas Sindhwani category:cs.LG cs.AI stat.ML  published:2017-10-15 summary:Policy evaluation or value function or Q-function approximation is a key procedure in reinforcement learning (RL). It is a necessary component of policy iteration and can be used for variance reduction in policy gradient methods. Therefore its quality has a significant impact on most RL algorithms. Motivated by manifold regularized learning, we propose a novel kernelized policy evaluation method that takes advantage of the intrinsic geometry of the state space learned from data, in order to achieve better sample efficiency and higher accuracy in Q-function approximation. Applying the proposed method in the Least-Squares Policy Iteration (LSPI) framework, we observe superior performance compared to widely used parametric basis functions on two standard benchmarks in terms of policy quality. version:1
arxiv-1709-03196 | Deep multi-frame face super-resolution | http://arxiv.org/abs/1709.03196 | id:1709.03196 author:E. Ustinova, V. Lempitsky category:cs.CV  published:2017-09-10 summary:Face verification and recognition problems have seen rapid progress in recent years, however recognition from small size images remains a challenging task that is inherently intertwined with the task of face super-resolution. Tackling this problem using multiple frames is an attractive idea, yet requires solving the alignment problem that is also challenging for low-resolution faces. Here we present a holistic system for multi-frame recognition, alignment, and superresolution of faces. Our neural network architecture restores the central frame of each input sequence additionally taking into account a number of adjacent frames and making use of sub-pixel movements. We present our results using the popular dataset for video face recognition (YouTube Faces). We show a notable improvement of identification score compared to several baselines including the one based on single-image super-resolution. version:2
arxiv-1710-05384 | The Scaling Limit of High-Dimensional Online Independent Component Analysis | http://arxiv.org/abs/1710.05384 | id:1710.05384 author:Chuang Wang, Yue M. Lu category:cs.LG cond-mat.dis-nn stat.ML  published:2017-10-15 summary:We analyze the dynamics of an online algorithm for independent component analysis in the high-dimensional scaling limit. As the ambient dimension tends to infinity, and with proper time scaling, we show that the time-varying joint empirical measure of the target feature vector and the estimates provided by the algorithm will converge weakly to a deterministic measured-valued process that can be characterized as the unique solution of a nonlinear PDE. Numerical solutions of this PDE, which involves two spatial variables and one time variable, can be efficiently obtained. These solutions provide detailed information about the performance of the ICA algorithm, as many practical performance metrics are functionals of the joint empirical measures. Numerical simulations show that our asymptotic analysis is accurate even for moderate dimensions. In addition to providing a tool for understanding the performance of the algorithm, our PDE analysis also provides useful insight. In particular, in the high-dimensional limit, the original coupled dynamics associated with the algorithm will be asymptotically "decoupled", with each coordinate independently solving a 1-D effective minimization problem via stochastic gradient descent. Exploiting this insight to design new algorithms for achieving optimal trade-offs between computational and statistical efficiency may prove an interesting line of future research. version:1
arxiv-1710-05381 | A systematic study of the class imbalance problem in convolutional neural networks | http://arxiv.org/abs/1710.05381 | id:1710.05381 author:Mateusz Buda, Atsuto Maki, Maciej A. Mazurowski category:cs.CV cs.AI cs.LG cs.NE stat.ML  published:2017-10-15 summary:In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that totally eliminates the imbalance, whereas undersampling can perform better when the imbalance is only removed to some extent; (iv) as opposed to some classical machine learning models, oversampling does not necessarily cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest. version:1
arxiv-1710-05379 | Towards Automatic Abdominal Multi-Organ Segmentation in Dual Energy CT using Cascaded 3D Fully Convolutional Network | http://arxiv.org/abs/1710.05379 | id:1710.05379 author:Shuqing Chen, Holger Roth, Sabrina Dorn, Matthias May, Alexander Cavallaro, Michael M. Lell, Marc Kachelrieß, Hirohisa Oda, Kensaku Mori, Andreas Maier category:cs.CV  published:2017-10-15 summary:Automatic multi-organ segmentation of the dual energy computed tomography (DECT) data can be beneficial for biomedical research and clinical applications. However, it is a challenging task. Recent advances in deep learning showed the feasibility to use 3-D fully convolutional networks (FCN) for voxel-wise dense predictions in single energy computed tomography (SECT). In this paper, we proposed a 3D FCN based method for automatic multi-organ segmentation in DECT. The work was based on a cascaded FCN and a general model for the major organs trained on a large set of SECT data. We preprocessed the DECT data by using linear weighting and fine-tuned the model for the DECT data. The method was evaluated using 42 torso DECT data acquired with a clinical dual-source CT system. Four abdominal organs (liver, spleen, left and right kidneys) were evaluated. Cross-validation was tested. Effect of the weight on the accuracy was researched. In all the tests, we achieved an average Dice coefficient of 93% for the liver, 90% for the spleen, 91% for the right kidney and 89% for the left kidney, respectively. The results show our method is feasible and promising. version:1
arxiv-1710-05373 | Robust Locally-Linear Controllable Embedding | http://arxiv.org/abs/1710.05373 | id:1710.05373 author:Ershad Banijamali, Rui Shu, Mohammad Ghavamzadeh, Hung Bui, Ali Ghodsi category:cs.LG  published:2017-10-15 summary:Embed-to-control (E2C) is a model for solving high-dimensional optimal control problems by combining variational auto-encoders with locally-optimal controllers. However, the current E2C model suffers from two major drawbacks: 1) its objective function does not correspond to the likelihood of the data sequence and 2) the variational encoder used for embedding typically has large variational approximation error, especially when there is noise in the system dynamics. In this paper, we present a new model for learning robust locally-linear controllable embedding (RCE). Our model directly estimates the predictive conditional density of the future observation given the current one, while introducing the bottleneck between the current and future observations. Although the bottleneck provides a natural embedding candidate for control, our RCE model introduces additional specific structures in the generative graphical model so that the model dynamics can be robustly linearized. We also propose a principled variational approximation of the embedding posterior that takes the future observation into account, and thus, makes the variational approximation more robust against the noise. Experimental results demonstrate that RCE outperforms the existing E2C model, and does so significantly in the regime where the underlying dynamics is noisy. version:1
arxiv-1710-05370 | NoReC: The Norwegian Review Corpus | http://arxiv.org/abs/1710.05370 | id:1710.05370 author:Erik Velldal, Lilja Øvrelid, Eivind Alexander Bergem, Cathrine Stadsnes, Samia Touileb, Fredrik Jørgensen category:cs.CL  published:2017-10-15 summary:This paper presents the Norwegian Review Corpus (NoReC), created for training and evaluating models for document-level sentiment analysis. The full-text reviews have been collected from major Norwegian news sources and cover a range of different domains, including literature, movies, video games, restaurants, music and theater, in addition to product reviews across a range of categories. Each review is labeled with a manually assigned score of 1-6, as provided by the rating of the original author. This first release of the corpus comprises more than 35,000 reviews. It is distributed using the CoNLL-U format, pre-processed using UDPipe, along with a rich set of metadata. The work reported in this paper forms part of the SANT initiative (Sentiment Analysis for Norwegian Text), a project seeking to provide resources and tools for sentiment analysis and opinion mining for Norwegian. As resources for sentiment analysis have so far been unavailable for Norwegian, NoReC represents a highly valuable and sought-after addition to Norwegian language technology. version:1
arxiv-1705-02743 | ChineseFoodNet: A large-scale Image Dataset for Chinese Food Recognition | http://arxiv.org/abs/1705.02743 | id:1705.02743 author:Xin Chen, Yu Zhu, Hua Zhou, Liang Diao, Dongyan Wang category:cs.CV  published:2017-05-08 summary:In this paper, we introduce a new and challenging large-scale food image dataset called "ChineseFoodNet", which aims to automatically recognizing pictured Chinese dishes. Most of the existing food image datasets collected food images either from recipe pictures or selfie. In our dataset, images of each food category of our dataset consists of not only web recipe and menu pictures but photos taken from real dishes, recipe and menu as well. ChineseFoodNet contains over 180,000 food photos of 208 categories, with each category covering a large variations in presentations of same Chinese food. We present our efforts to build this large-scale image dataset, including food category selection, data collection, and data clean and label, in particular how to use machine learning methods to reduce manual labeling work that is an expensive process. We share a detailed benchmark of several state-of-the-art deep convolutional neural networks (CNNs) on ChineseFoodNet. We further propose a novel two-step data fusion approach referred as "TastyNet", which combines prediction results from different CNNs with voting method. Our proposed approach achieves top-1 accuracies of 81.43% on the validation set and 81.55% on the test set, respectively. The latest dataset is public available for research and can be achieved at https://sites.google.com/view/chinesefoodnet. version:3
arxiv-1710-05364 | Clickbait Detection in Tweets Using Self-attentive Network | http://arxiv.org/abs/1710.05364 | id:1710.05364 author:Yiwei Zhou category:cs.CL  published:2017-10-15 summary:Clickbait detection in tweets remains an elusive challenge. In this paper, we describe the solution for the Zingel Clickbait Detector at the Clickbait Challenge 2017, which is capable of evaluating each tweet's level of click baiting. We first reformat the regression problem as a multi-classification problem, based on the annotation scheme. To perform multi-classification, we apply a token-level, self-attentive mechanism on the hidden states of bi-directional Gated Recurrent Units (biGRU), which enables the model to generate tweets' task-specific vector representations by attending to important tokens. The self-attentive neural network can be trained end-to-end, without involving any manual feature engineering. Our detector ranked first in the final evaluation of Clickbait Challenge 2017. version:1
arxiv-1710-05359 | Estimation of Squared-Loss Mutual Information from Positive and Unlabeled Data | http://arxiv.org/abs/1710.05359 | id:1710.05359 author:Tomoya Sakai, Gang Niu, Masashi Sugiyama category:stat.ML cs.LG  published:2017-10-15 summary:Capturing input-output dependency is an important task in statistical data analysis. Mutual information (MI) is a vital tool for this purpose, but it is known to be sensitive to outliers. To cope with this problem, a squared-loss variant of MI (SMI) was proposed, and its supervised estimator has been developed. On the other hand, in real-world classification problems, it is conceivable that only positive and unlabeled (PU) data are available. In this paper, we propose a novel estimator of SMI only from PU data, and prove its optimal convergence to true SMI. Based on the PU-SMI estimator, we further propose a dimension reduction method which can be executed without estimating the class-prior probabilities of unlabeled data. Such PU class-prior estimation is often required in PU classification algorithms, but it is unreliable particularly in high-dimensional problems, yielding a biased classifier. Our dimension reduction method significantly boosts the accuracy of PU class-prior estimation, as demonstrated through experiments. We also develop a method of independent testing based on our PU-SMI estimator and experimentally show its superiority. version:1
arxiv-1709-00751 | Sushi Dish - Object detection and classification from real images | http://arxiv.org/abs/1709.00751 | id:1709.00751 author:Yeongjin Oh, Seunghyun Son, Gyumin Sim category:cs.CV  published:2017-09-03 summary:In conveyor belt sushi restaurants, billing is a burdened job because one has to manually count the number of dishes and identify the color of them to calculate the price. In a busy situation, there can be a mistake that customers are overcharged or under-charged. To deal with this problem, we developed a method that automatically identifies the color of dishes and calculate the total price using real images. Our method consists of ellipse fitting and convol-utional neural network. It achieves ellipse detection precision 85% and recall 96% and classification accuracy 92%. version:2
arxiv-1710-05311 | Vector Quantization using the Improved Differential Evolution Algorithm for Image Compression | http://arxiv.org/abs/1710.05311 | id:1710.05311 author:Sayan Nag category:cs.CV cs.MM cs.NE  published:2017-10-15 summary:Vector Quantization, VQ is a popular image compression technique with a simple decoding architecture and high compression ratio. Codebook designing is the most essential part in Vector Quantization. LindeBuzoGray, LBG is a traditional method of generation of VQ Codebook which results in lower PSNR value. A Codebook affects the quality of image compression, so the choice of an appropriate codebook is a must. Several optimization techniques have been proposed for global codebook generation to enhance the quality of image compression. In this paper, a novel algorithm called IDE-LBG is proposed which uses Improved Differential Evolution Algorithm coupled with LBG for generating optimum VQ Codebooks. The proposed IDE works better than the traditional DE with modifications in the scaling factor and the boundary control mechanism. The IDE generates better solutions by efficient exploration and exploitation of the search space. Then the best optimal solution obtained by the IDE is provided as the initial Codebook for the LBG. This approach produces an efficient Codebook with less computational time and the consequences include excellent PSNR values and superior quality reconstructed images. It is observed that the proposed IDE-LBG find better VQ Codebooks as compared to IPSO-LBG, BA-LBG and FA-LBG. version:1
arxiv-1710-05298 | Text2Action: Generative Adversarial Synthesis from Language to Action | http://arxiv.org/abs/1710.05298 | id:1710.05298 author:Hyemin Ahn, Timothy Ha, Yunho Choi, Hwiyeon Yoo, Songhwai Oh category:cs.LG cs.CL cs.RO  published:2017-10-15 summary:In this paper, we propose a generative model which learns the relationship between language and human action in order to generate a human action sequence given a sentence describing human behavior. The proposed generative model is a generative adversarial network (GAN), which is based on the sequence to sequence (SEQ2SEQ) model. Using the proposed generative network, we can synthesize various actions for a robot or a virtual agent using a text encoder recurrent neural network (RNN) and an action decoder RNN. The proposed generative network is trained from 29,770 pairs of actions and sentence annotations extracted from MSR-Video-to-Text (MSR-VTT), a large-scale video dataset. We demonstrate that the network can generate human-like actions which can be transferred to a Baxter robot, such that the robot performs an action based on a provided sentence. Results show that the proposed generative network correctly models the relationship between language and action and can generate a diverse set of actions from the same sentence. version:1
arxiv-1705-06911 | Beyond similarity assessment: Selecting the optimal model for sequence alignment via the Factorized Asymptotic Bayesian algorithm | http://arxiv.org/abs/1705.06911 | id:1705.06911 author:Taikai Takeda, Michiaki Hamada category:q-bio.QM stat.ML  published:2017-05-19 summary:Pair Hidden Markov Models (PHMMs) are probabilistic models used for pairwise sequence alignment, a quintessential problem in bioinformatics. PHMMs include three types of hidden states: match, insertion and deletion. Most previous studies have used one or two hidden states for each PHMM state type. However, few studies have examined the number of states suitable for representing sequence data or improving alignment accuracy.We developed a novel method to select superior models (including the number of hidden states) for PHMM. Our method selects models with the highest posterior probability using Factorized Information Criteria (FIC), which is widely utilised in model selection for probabilistic models with hidden variables. Our simulations indicated this method has excellent model selection capabilities with slightly improved alignment accuracy. We applied our method to DNA datasets from 5 and 28 species, ultimately selecting more complex models than those used in previous studies. version:2
arxiv-1710-05285 | CNNComparator: Comparative Analytics of Convolutional Neural Networks | http://arxiv.org/abs/1710.05285 | id:1710.05285 author:Haipeng Zeng, Hammad Haleem, Xavier Plantaz, Nan Cao, Huamin Qu category:cs.LG cs.CV H.1.2  published:2017-10-15 summary:Convolutional neural networks (CNNs) are widely used in many image recognition tasks due to their extraordinary performance. However, training a good CNN model can still be a challenging task. In a training process, a CNN model typically learns a large number of parameters over time, which usually results in different performance. Often, it is difficult to explore the relationships between the learned parameters and the model performance due to a large number of parameters and different random initializations. In this paper, we present a visual analytics approach to compare two different snapshots of a trained CNN model taken after different numbers of epochs, so as to provide some insight into the design or the training of a better CNN model. Our system compares snapshots by exploring the differences in operation parameters and the corresponding blob data at different levels. A case study has been conducted to demonstrate the effectiveness of our system. version:1
arxiv-1710-05279 | Facial Keypoints Detection | http://arxiv.org/abs/1710.05279 | id:1710.05279 author:Shenghao Shi category:stat.ML cs.LG  published:2017-10-15 summary:Detect facial keypoints is a critical element in face recognition. However, there is difficulty to catch keypoints on the face due to complex influences from original images, and there is no guidance to suitable algorithms. In this paper, we study different algorithms that can be applied to locate keyponits. Specifically: our framework (1)prepare the data for further investigation (2)Using PCA and LBP to process the data (3) Apply different algorithms to analysis data, including linear regression models, tree based model, neural network and convolutional neural network, etc. Finally we will give our conclusion and further research topic. A comprehensive set of experiments on dataset demonstrates the effectiveness of our framework. version:1
arxiv-1710-05270 | Learning Infinite RBMs with Frank-Wolfe | http://arxiv.org/abs/1710.05270 | id:1710.05270 author:Wei Ping, Qiang Liu, Alexander Ihler category:cs.LG cs.AI stat.ML  published:2017-10-15 summary:In this work, we propose an infinite restricted Boltzmann machine~(RBM), whose maximum likelihood estimation~(MLE) corresponds to a constrained convex optimization. We consider the Frank-Wolfe algorithm to solve the program, which provides a sparse solution that can be interpreted as inserting a hidden unit at each iteration, so that the optimization process takes the form of a sequence of finite models of increasing complexity. As a side benefit, this can be used to easily and efficiently identify an appropriate number of hidden units during the optimization. The resulting model can also be used as an initialization for typical state-of-the-art RBM training algorithms such as contrastive divergence, leading to models with consistently higher test likelihood than random initialization. version:1
arxiv-1710-05268 | Self-Supervised Visual Planning with Temporal Skip Connections | http://arxiv.org/abs/1710.05268 | id:1710.05268 author:Frederik Ebert, Chelsea Finn, Alex X. Lee, Sergey Levine category:cs.RO cs.AI cs.CV cs.LG  published:2017-10-15 summary:In order to autonomously learn wide repertoires of complex skills, robots must be able to learn from their own autonomously collected data, without human supervision. One learning signal that is always available for autonomously collected data is prediction: if a robot can learn to predict the future, it can use this predictive model to take actions to produce desired outcomes, such as moving an object to a particular location. However, in complex open-world scenarios, designing a representation for prediction is difficult. In this work, we instead aim to enable self-supervised robotic learning through direct video prediction: instead of attempting to design a good representation, we directly predict what the robot will see next, and then use this model to achieve desired goals. A key challenge in video prediction for robotic manipulation is handling complex spatial arrangements such as occlusions. To that end, we introduce a video prediction model that can keep track of objects through occlusion by incorporating temporal skip-connections. Together with a novel planning criterion and action space formulation, we demonstrate that this model substantially outperforms prior work on video prediction-based control. Our results show manipulation of objects not seen during training, handling multiple objects, and pushing objects around obstructions. These results represent a significant advance in the range and complexity of skills that can be performed entirely with self-supervised robotic learning. version:1
arxiv-1710-05267 | Deep Learning for Rapid Sparse MR Fingerprinting Reconstruction | http://arxiv.org/abs/1710.05267 | id:1710.05267 author:Ouri Cohen, Bo Zhu, Matthew S. Rosen category:cs.CV  published:2017-10-15 summary:PURPOSE: Demonstrate a novel fast method for reconstruction of multi-dimensional MR Fingerprinting (MRF) data using Deep Learning methods. METHODS: A neural network (NN) is defined using the TensorFlow framework and trained on simulated MRF data computed using the Bloch equations. The accuracy of the NN reconstruction of noisy data is compared to conventional MRF template matching as a function of training data size, and quantified in a both simulated numerical brain phantom data and acquired data from the ISMRM/NIST phantom. The utility of the method is demonstrated in a healthy subject in vivo at 1.5 T. RESULTS: Network training required 10 minutes and once trained, data reconstruction required approximately 10 ms. Reconstruction of simulated brain data using the NN resulted in a root-mean-square error (RMSE) of 3.5 ms for T1 and 7.8 ms for T2. The RMSE for the NN trained on sparse dictionaries was approximately 6 fold lower for T1 and 2 fold lower for T2 than conventional MRF dot-product dictionary matching on the same dictionaries. Phantom measurements yielded good agreement (R2=0.99) between the T1 and T2 estimated by the NN and reference values from the ISMRM/NIST phantom. CONCLUSION: Reconstruction of MRF data with a NN is accurate, 300 fold faster and more robust to noise and undersampling than conventional MRF dictionary matching. version:1
arxiv-1710-05241 | Robust Federated Learning Using ADMM in the Presence of Data Falsifying Byzantines | http://arxiv.org/abs/1710.05241 | id:1710.05241 author:Qunwei Li, Bhavya Kailkhura, Ryan Goldhahn, Priyadip Ray, Pramod K. Varshney category:cs.LG stat.ML  published:2017-10-14 summary:In this paper, we consider the problem of federated (or decentralized) learning using ADMM with multiple agents. We consider a scenario where a certain fraction of agents (referred to as Byzantines) provide falsified data to the system. In this context, we study the convergence behavior of the decentralized ADMM algorithm. We show that ADMM converges linearly to a neighborhood of the solution to the problem under certain conditions. We next provide guidelines for network structure design to achieve faster convergence. Next, we provide necessary conditions on the falsified updates for exact convergence to the true solution. To tackle the data falsification problem, we propose a robust variant of ADMM. We also provide simulation results to validate the analysis and show the resilience of the proposed algorithm to Byzantines. version:1
arxiv-1710-05233 | Learners that Leak Little Information | http://arxiv.org/abs/1710.05233 | id:1710.05233 author:Raef Bassily, Shay Moran, Ido Nachum, Jonathan Shafer, Amir Yehudayoff category:cs.LG cs.AI cs.CR cs.IT math.IT  published:2017-10-14 summary:We study learning algorithms that are restricted to revealing little information about their input sample. Various manifestations of this notion have been recently studied. A central theme in these works, and in ours, is that such algorithms generalize. We study a category of learning algorithms, which we term d-bit information learners}. These are algorithms whose output conveys at most d bits of information on their input. We focus on the learning capacity of such algorithms: we prove generalization bounds with tight dependencies on the confidence and error parameters. We observe connections with well studied notions such as PAC-Bayes and differential privacy. For example, it is known that pure differentially private algorithms leak little information. We complement this fact with a separation between bounded information and pure differential privacy in the setting of proper learning, showing that differential privacy is strictly more restrictive. We also demonstrate limitations by exhibiting simple concept classes for which every (possibly randomized) empirical risk minimizer must leak a lot of information. On the other hand, we show that in the distribution-dependent setting every VC class has empirical risk minimizers that do not leak a lot of information. version:1
arxiv-1709-03239 | On better training the infinite restricted Boltzmann machines | http://arxiv.org/abs/1709.03239 | id:1709.03239 author:Xuan Peng, Xunzhang Gao, Xiang Li category:cs.LG cs.AI stat.ML  published:2017-09-11 summary:The infinite restricted Boltzmann machine (iRBM) is an extension of the classic RBM. It enjoys a good property of automatically deciding the size of the hidden layer according to specific training data. With sufficient training, the iRBM can achieve a competitive performance with that of the classic RBM. However, the convergence of learning the iRBM is slow, due to the fact that the iRBM is sensitive to the ordering of its hidden units, the learned filters change slowly from the left-most hidden unit to right. To break this dependency between neighboring hidden units and speed up the convergence of training, a novel training strategy is proposed. The key idea of the proposed training strategy is randomly regrouping the hidden units before each gradient descent step. Potentially, a mixing of infinite many iRBMs with different permutations of the hidden units can be achieved by this learning method, which has a similar effect of preventing the model from over-fitting as the dropout. The original iRBM is also modified to be capable of carrying out discriminative training. To evaluate the impact of our method on convergence speed of learning and the model's generalization ability, several experiments have been performed on the binarized MNIST and CalTech101 Silhouettes datasets. Experimental results indicate that the proposed training strategy can greatly accelerate learning and enhance generalization ability of iRBMs. version:2
arxiv-1710-05221 | An Adaptive Framework for Missing Depth Inference Using Joint Bilateral Filter | http://arxiv.org/abs/1710.05221 | id:1710.05221 author:Rajer Sindhu, Jayesh Ananya category:cs.CV  published:2017-10-14 summary:Depth imaging has largely focused on sensor and intrinsics properties. However, the accuracy of acquire pixel is largely dependent on the capture. We propose a new depth estimation and approximation algorithm which takes an arbitrary 3D point cloud as input, with potentially complex geometric structures, and generates automatically a bounding box which is used to clamp the 3D distribution into a valid range. We then infer the desired compact geometric network from complex 3D geometries by using a series of adaptive joint bilateral filters. Our approach leverages these input depth in the construction of a compact descriptive adaptive filter framework. The built system that allows a user to control the result of capture depth map to fit the target geometry. In addition, it is desirable to visualize structurally problematic areas of the depth data in a dynamic environment. To provide this feature, we investigate a fast update algorithm for the fragility of each pixel's corresponding 3D point using machine learning. We present a new for of feature vector analysis and demonstrate the effectiveness in the dataset. In our experiment, we demonstrate the practicality and benefits of our proposed method by computing accurate solutions captured depth map from different types of sensors and shows better results than existing methods. version:1
arxiv-1705-05940 | Subregular Complexity and Deep Learning | http://arxiv.org/abs/1705.05940 | id:1705.05940 author:Enes Avcu, Chihiro Shibata, Jeffrey Heinz category:cs.CL  published:2017-05-16 summary:This paper argues that the judicial use of formal language theory and grammatical inference are invaluable tools in understanding how deep neural networks can and cannot represent and learn long-term dependencies in temporal sequences. Learning experiments were conducted with two types of Recurrent Neural Networks (RNNs) on six formal languages drawn from the Strictly Local (SL) and Strictly Piecewise (SP) classes. The networks were Simple RNNs (s-RNNs) and Long Short-Term Memory RNNs (LSTMs) of varying sizes. The SL and SP classes are among the simplest in a mathematically well-understood hierarchy of subregular classes. They encode local and long-term dependencies, respectively. The grammatical inference algorithm Regular Positive and Negative Inference (RPNI) provided a baseline. According to earlier research, the LSTM architecture should be capable of learning long-term dependencies and should outperform s-RNNs. The results of these experiments challenge this narrative. First, the LSTMs' performance was generally worse in the SP experiments than in the SL ones. Second, the s-RNNs out-performed the LSTMs on the most complex SP experiment and performed comparably to them on the others. version:3
arxiv-1710-05219 | Mental Sampling in Multimodal Representations | http://arxiv.org/abs/1710.05219 | id:1710.05219 author:Jian-Qiao Zhu, Adam N. Sanborn, Nick Chater category:cs.LG cs.AI  published:2017-10-14 summary:Both resources in the natural environment and concepts in a semantic space are distributed "patchily", with large gaps in between the patches. To describe people's internal and external foraging behavior, various random walk models have been proposed. In particular, internal foraging has been modeled as sampling: in order to gather relevant information for making a decision, people draw samples from a mental representation using random-walk algorithms such as Markov chain Monte Carlo (MCMC). However, two common empirical observations argue against simple sampling algorithms such as MCMC. First, the spatial structure is often best described by a L\'evy flight distribution: the probability of the distance between two successive locations follows a power-law on the distances. Second, the temporal structure of the sampling that humans and other animals produce have long-range, slowly decaying serial correlations characterized as $1/f$-like fluctuations. We propose that mental sampling is not done by simple MCMC, but is instead adapted to multimodal representations and is implemented by Metropolis-coupled Markov chain Monte Carlo (MC$^3$), one of the first algorithms developed for sampling from multimodal distributions. MC$^3$ involves running multiple Markov chains in parallel but with target distributions of different temperatures, and it swaps the states of the chains whenever a better location is found. Heated chains more readily traverse valleys in the probability landscape to propose moves to far-away peaks, while the colder chains make the local steps that explore the current peak or patch. We show that MC$^3$ generates distances between successive samples that follow a L\'evy flight distribution and $1/f$-like serial correlations, providing a single mechanistic account of these two puzzling empirical phenomena. version:1
arxiv-1710-04176 | On Data-Driven Saak Transform | http://arxiv.org/abs/1710.04176 | id:1710.04176 author:C. -C. Jay Kuo, Yueru Chen category:cs.CV  published:2017-10-11 summary:Being motivated by the multilayer RECOS (REctified-COrrelations on a Sphere) transform, we develop a data-driven Saak (Subspace approximation with augmented kernels) transform in this work. The Saak transform consists of three steps: 1) building the optimal linear subspace approximation with orthonormal bases using the second-order statistics of input vectors, 2) augmenting each transform kernel with its negative, 3) applying the rectified linear unit (ReLU) to the transform output. The Karhunen-Lo\'eve transform (KLT) is used in the first step. The integration of Steps 2 and 3 is powerful since they resolve the sign confusion problem, remove the rectification loss and allow a straightforward implementation of the inverse Saak transform at the same time. Multiple Saak transforms are cascaded to transform images of a larger size. All Saak transform kernels are derived from the second-order statistics of input random vectors in a one-pass feedforward manner. Neither data labels nor backpropagation is used in kernel determination. Multi-stage Saak transforms offer a family of joint spatial-spectral representations between two extremes; namely, the full spatial-domain representation and the full spectral-domain representation. We select Saak coefficients of higher discriminant power to form a feature vector for pattern recognition, and use the MNIST dataset classification problem as an illustrative example. version:2
arxiv-1709-04889 | Control-Oriented Learning on the Fly | http://arxiv.org/abs/1709.04889 | id:1709.04889 author:Melkior Ornik, Arie Israel, Ufuk Topcu category:math.OC cs.LG cs.RO cs.SY 93C41 I.2.8; I.2.6  published:2017-09-14 summary:This paper focuses on developing a strategy for control of systems whose dynamics are almost entirely unknown. This situation arises naturally in a scenario where a system undergoes a critical failure. In that case, it is imperative to retain the ability to satisfy basic control objectives in order to avert an imminent catastrophe. A prime example of such an objective is the reach-avoid problem, where a system needs to move to a certain state in a constrained state space. To deal with limitations on our knowledge of system dynamics, we develop a theory of myopic control. The primary goal of myopic control is to, at any given time, optimize the current direction of the system trajectory, given solely the information obtained about the system until that time. We propose an algorithm that uses small perturbations in the control effort to learn local dynamics while simultaneously ensuring that the system moves in a direction that appears to be nearly optimal, and provide hard bounds for its suboptimality. We additionally verify the usefulness of the algorithm on a simulation of a damaged aircraft seeking to avoid a crash, as well as on an example of a Van der Pol oscillator. version:2
arxiv-1710-05213 | Simultaneous Matrix Diagonalization for Structural Brain Networks Classification | http://arxiv.org/abs/1710.05213 | id:1710.05213 author:Nikita Mokrov, Maxim Panov, Boris A. Gutman, Joshua I. Faskowitz, Neda Jahanshad, Paul M. Thompson category:stat.ML  published:2017-10-14 summary:This paper considers the problem of brain disease classification based on connectome data. A connectome is a network representation of a human brain. The typical connectome classification problem is very challenging because of the small sample size and high dimensionality of the data. We propose to use simultaneous approximate diagonalization of adjacency matrices in order to compute their eigenstructures in more stable way. The obtained approximate eigenvalues are further used as features for classification. The proposed approach is demonstrated to be efficient for detection of Alzheimer's disease, outperforming simple baselines and competing with state-of-the-art approaches to brain disease classification. version:1
arxiv-1710-05209 | Agnostic Distribution Learning via Compression | http://arxiv.org/abs/1710.05209 | id:1710.05209 author:Hassan Ashtiani, Shai Ben-David, Abbas Mehrabian category:cs.LG math.ST stat.TH  published:2017-10-14 summary:We study sample-efficient distribution learning, where a learner is given an iid sample from an unknown target distribution, and aims to approximate that distribution. Assuming the target distribution can be approximated by a member of some predetermined class of distributions, we analyze how large should a sample be, in order to be able to find a distribution that is close to the target in total variation distance. In this work, we introduce a novel method for distribution learning via a form of "compression." Having a large enough sample from a target distribution, can one compress that sample set, by picking only a few instances from it, in a way that allows recovery of (an approximation to) the target distribution from the compressed set? We prove that if this is the case for all members of a class of distributions, then there is a sample-efficient way of distribution learning for this class. As an application of our approach, we provide a sample-efficient method for agnostic distribution learning with respect to the class of mixtures of $k$ axis-aligned Gaussian distributions over $R^n$. This method uses only $\widetilde{O}(kn/\epsilon^2)$ samples (to guarantee with high probability an error of at most $\epsilon$). This is the first sample complexity upper bound that is tight in $k$, $n$, and $\epsilon$, up to logarithmic factors. Along the way, we prove several properties of compression schemes. Namely, we prove that if there is a compression scheme for a base class of distributions, then there is a compression scheme for the class of mixtures, as well as the products of that base class. These closure properties make compression schemes a powerful tool. For example, the problem of learning mixtures of axis-aligned Gaussians reduces to that of "robustly" compressing one-dimensional Gaussians, which we show is possible using a compressed set of constant size. version:1
arxiv-1710-05199 | Community Aware Random Walk for Network Embedding | http://arxiv.org/abs/1710.05199 | id:1710.05199 author:Mohammad Mehdi Keikha, Maseud Rahgozar, Masoud Asadpour category:cs.SI cs.AI cs.LG 68T30 H.3.4  published:2017-10-14 summary:Social network analysis provides meaningful information about behavior of network members that can be used in diverse applications such as classification, link prediction, etc. however, network analysis is computationally expensive because of feature learning for different applications. In recent years, many researches have focused on feature learning methods in social networks. Network embedding represents the network in a lower dimensional representation space with the same properties which presents a compressed representation of the input network. In this paper, we introduce a novel algorithm named "CARE" for network embedding that can be used for different types of networks including weighted, directed and complex. While current methods try to preserve local neighborhood information of nodes, we utilize local neighborhood and community information of network nodes to cover both local and global structure of social networks. CARE builds customized paths, which are consisted of local and global structure of network nodes, as a basis for network embedding and uses skip-gram model to learn representation vector of nodes. Then, stochastic gradient descent is used to optimize our objective function and learn the final representation of nodes. Our method can be scalable when new nodes are appended to network without information loss. Parallelize generation of customized random walks is also used for speeding up CARE. We evaluate the performance of CARE on multi label classification and link prediction tasks. Experimental results on different networks indicate that the proposed method outperforms others in both Micro-f1 and Macro-f1 measures for different size of training data. version:1
arxiv-1707-01212 | ProtoDash: Fast Interpretable Prototype Selection | http://arxiv.org/abs/1707.01212 | id:1707.01212 author:Karthik S. Gurumoorthy, Amit Dhurandhar, Guillermo Cecchi category:stat.ML cs.LG 65K05  68W25  published:2017-07-05 summary:In this paper we propose an efficient algorithm ProtoDash for selecting prototypical examples from complex datasets. Our work builds on top of the learn to criticize (L2C) work by Kim et al. (2016) and generalizes it to not only select prototypes for a given sparsity level $m$ but also to associate non-negative weights with each of them indicative of the importance of each prototype. Unlike in the case of L2C, this extension provides a single coherent framework under which both prototypes and criticisms (i.e. lowest weighted prototypes) can be found. Furthermore, our framework works for any symmetric positive definite kernel thus addressing one of the open questions laid out in Kim et al. (2016). Our additional requirement of learning non-negative weights introduces technical challenges as the objective is no longer submodular as in the previous work. However, we show that the problem is weakly submodular and derive approximation guarantees for our fast ProtoDash algorithm. Moreover, ProtoDash can not only find prototypical examples for a dataset $X$, but it can also find (weighted) prototypical examples from $X^{(2)}$ that best represent another dataset $X^{(1)}$, where $X^{(1)}$ and $X^{(2)}$ belong to the same feature space. We demonstrate the efficacy of our method on diverse domains namely; retail, digit recognition (MNIST) and on the latest publicly available 40 health questionnaires obtained from the Center for Disease Control (CDC) website maintained by the US Dept. of Health. We validate the results quantitatively as well as qualitatively based on expert feedback and recently published scientific studies on public health. version:2
arxiv-1710-05191 | Microaneurysm Detection in Fundus Images Using a Two-step Convolutional Neural Networks | http://arxiv.org/abs/1710.05191 | id:1710.05191 author:Noushin Eftekheri, Hamidreza Pourreza, Ehsan Saeedi category:cs.CV  published:2017-10-14 summary:Diabetic Retinopathy (DR) is the prominent cause of blindness in the world. The early treatment of DR can be conducted from detection of microaneurysms (MA) which is reddish spots in retina images. Automated microaneurysm detection can be a helpful system for ophthalmologists for detection of MA. In this paper, deep learning, in particular convolutional neural network (CNN), is used as a powerful tool to detect MA efficiently. Our method used a new technique utilising of a two-stage training process which has a better efficiency and accuracy compared to previous works, while decreasing computational complexity. To validate our proposed method efficiency, an experiment is conducted using Keras library to implement our proposed CNN on two standard publicly available datasets. Our results show a promising sensitivity value of about 0.8 which is a competitive value with the state-of-the-art approaches. %compared to the best results of previous studies which is 0.5. version:1
arxiv-1710-05189 | A graphical, scalable and intuitive method for the placement and the connection of biological cells | http://arxiv.org/abs/1710.05189 | id:1710.05189 author:Nicolas P. Rougier category:cs.NE cs.GR q-bio.NC  published:2017-10-14 summary:We introduce a graphical method originating from the computer graphics domain that is used for the arbitrary and intuitive placement of cells over a two-dimensional manifold. Using a bitmap image as input, where the color indicates the identity of the different structures and the alpha channel indicates the local cell density, this method guarantees a discrete distribution of cell position respecting the local density function. This method scales to any number of cells, allows to specify several different structures at once with arbitrary shapes and provides a scalable and versatile alternative to the more classical assumption of a uniform non-spatial distribution. Furthermore, several connection schemes can be derived from the paired distances between cells using either an automatic mapping or a user-defined local reference frame, providing new computational properties for the underlying model. The method is illustrated on a discrete homogeneous neural field, on the distribution of cones and rods in the retina and on a coronal view of the basal ganglia. version:1
arxiv-1710-05179 | Regularizing Deep Neural Networks by Noise: Its Interpretation and Optimization | http://arxiv.org/abs/1710.05179 | id:1710.05179 author:Hyeonwoo Noh, Tackgeun You, Jonghwan Mun, Bohyung Han category:cs.LG cs.CV  published:2017-10-14 summary:Overfitting is one of the most critical challenges in deep neural networks, and there are various types of regularization methods to improve generalization performance. Injecting noises to hidden units during training, e.g., dropout, is known as a successful regularizer, but it is still not clear enough why such training techniques work well in practice and how we can maximize their benefit in the presence of two conflicting objectives---optimizing to true data distribution and preventing overfitting by regularization. This paper addresses the above issues by 1) interpreting that the conventional training methods with regularization by noise injection optimize the lower bound of the true objective and 2) proposing a technique to achieve a tighter lower bound using multiple noise samples per training example in a stochastic gradient descent iteration. We demonstrate the effectiveness of our idea in several computer vision applications. version:1
arxiv-1710-05174 | Saliency Detection for Stereoscopic Images Based on Depth Confidence Analysis and Multiple Cues Fusion | http://arxiv.org/abs/1710.05174 | id:1710.05174 author:Runmin Cong, Jianjun Lei, Changqing Zhang, Qingming Huang, Xiaochun Cao, Chunping Hou category:cs.CV  published:2017-10-14 summary:Stereoscopic perception is an important part of human visual system that allows the brain to perceive depth. However, depth information has not been well explored in existing saliency detection models. In this letter, a novel saliency detection method for stereoscopic images is proposed. Firstly, we propose a measure to evaluate the reliability of depth map, and use it to reduce the influence of poor depth map on saliency detection. Then, the input image is represented as a graph, and the depth information is introduced into graph construction. After that, a new definition of compactness using color and depth cues is put forward to compute the compactness saliency map. In order to compensate the detection errors of compactness saliency when the salient regions have similar appearances with background, foreground saliency map is calculated based on depth-refined foreground seeds selection mechanism and multiple cues contrast. Finally, these two saliency maps are integrated into a final saliency map through weighted-sum method according to their importance. Experiments on two publicly available stereo datasets demonstrate that the proposed method performs better than other 10 state-of-the-art approaches. version:1
arxiv-1710-05172 | Co-saliency Detection for RGBD Images Based on Multi-constraint Feature Matching and Cross Label Propagation | http://arxiv.org/abs/1710.05172 | id:1710.05172 author:Runmin Cong, Jianjun Lei, Huazhu Fu, Qingming Huang, Xiaochun Cao, Chunping Hou category:cs.CV  published:2017-10-14 summary:Co-saliency detection aims at extracting the common salient regions from an image group containing two or more relevant images. It is a newly emerging topic in computer vision community. Different from the most existing co-saliency methods focusing on RGB images, this paper proposes a novel co-saliency detection model for RGBD images, which utilizes the depth information to enhance identification of co-saliency. First, the intra saliency map for each image is generated by the single image saliency model, while the inter saliency map is calculated based on the multi-constraint feature matching, which represents the constraint relationship among multiple images. Then, the optimization scheme, namely Cross Label Propagation (CLP), is used to refine the intra and inter saliency maps in a cross way. Finally, all the original and optimized saliency maps are integrated to generate the final co-saliency result. The proposed method introduces the depth information and multi-constraint feature matching to improve the performance of co-saliency detection. Moreover, the proposed method can effectively exploit any existing single image saliency model to work well in co-saliency scenarios. Experiments on two RGBD co-saliency datasets demonstrate the effectiveness of our proposed model. version:1
arxiv-1709-03792 | Sparse Representation Based Augmented Multinomial Logistic Extreme Learning Machine with Weighted Composite Features for Spectral Spatial Hyperspectral Image Classification | http://arxiv.org/abs/1709.03792 | id:1709.03792 author:Faxian Cao, Zhijing Yang, Jinchang Ren, Wing-Kuen Ling category:cs.CV  published:2017-09-12 summary:Although extreme learning machine (ELM) has been successfully applied to a number of pattern recognition problems, it fails to pro-vide sufficient good results in hyperspectral image (HSI) classification due to two main drawbacks. The first is due to the random weights and bias of ELM, which may lead to ill-posed problems. The second is the lack of spatial information for classification. To tackle these two problems, in this paper, we propose a new framework for ELM based spectral-spatial classification of HSI, where probabilistic modelling with sparse representation and weighted composite features (WCF) are employed respectively to derive the op-timized output weights and extract spatial features. First, the ELM is represented as a concave logarithmic likelihood function under statistical modelling using the maximum a posteriori (MAP). Second, the sparse representation is applied to the Laplacian prior to effi-ciently determine a logarithmic posterior with a unique maximum in order to solve the ill-posed problem of ELM. The variable splitting and the augmented Lagrangian are subsequently used to further reduce the computation complexity of the proposed algorithm and it has been proven a more efficient method for speed improvement. Third, the spatial information is extracted using the weighted compo-site features (WCFs) to construct the spectral-spatial classification framework. In addition, the lower bound of the proposed method is derived by a rigorous mathematical proof. Experimental results on two publicly available HSI data sets demonstrate that the proposed methodology outperforms ELM and a number of state-of-the-art approaches. version:2
arxiv-1710-05163 | An Improved Modified Cholesky Decomposition Method for Inverse Covariance Matrix Estimation | http://arxiv.org/abs/1710.05163 | id:1710.05163 author:Xiaoning Kang, Xinwei Deng category:stat.ML  published:2017-10-14 summary:The modified Cholesky decomposition is commonly used for inverse covariance matrix estimation given a specified order of random variables. However, the order of variables is often not available or cannot be pre-determined. Hence, we propose a novel estimator to address the variable order issue in the modified Cholesky decomposition to estimate the sparse inverse covariance matrix. The key idea is to effectively combine a set of estimates obtained from multiple permutations of variable orders, and to efficiently encourage the sparse structure for the resultant estimate by the use of thresholding technique on the combined Cholesky factor matrix. The consistent property of the proposed estimate is established under some weak regularity conditions. Simulation studies show the superior performance of the proposed method in comparison with several existing approaches. We also apply the proposed method into the linear discriminant analysis for analyzing real-data examples for classification. version:1
arxiv-1707-09752 | Anomaly Detection by Robust Statistics | http://arxiv.org/abs/1707.09752 | id:1707.09752 author:Peter J. Rousseeuw, Mia Hubert category:stat.ML  published:2017-07-31 summary:Real data often contain anomalous cases, also known as outliers. These may spoil the resulting analysis but they may also contain valuable information. In either case, the ability to detect such anomalies is essential. A useful tool for this purpose is robust statistics, which aims to detect the outliers by first fitting the majority of the data and then flagging data points that deviate from it. We present an overview of several robust methods and the resulting graphical outlier detection tools. We discuss robust procedures for univariate, low-dimensional, and high-dimensional data, such as estimating location and scatter, linear regression, principal component analysis, classification, clustering, and functional data analysis. Also the challenging new topic of cellwise outliers is introduced. version:2
arxiv-1710-05158 | BrainSegNet : A Segmentation Network for Human Brain Fiber Tractography Data into Anatomically Meaningful Clusters | http://arxiv.org/abs/1710.05158 | id:1710.05158 author:Tushar Gupta, Shreyas Malakarjun Patil, Mukkaram Tailor, Daksh Thapar, Aditya Nigam category:cs.CV  published:2017-10-14 summary:The segregation of brain fiber tractography data into distinct and anatomically meaningful clusters can help to comprehend the complex brain structure and early investigation and management of various neural disorders. We propose a novel stacked bidirectional long short-term memory(LSTM) based segmentation network, (BrainSegNet) for human brain fiber tractography data classification. We perform a two-level hierarchical classification a) White vs Grey matter (Macro) and b) White matter clusters (Micro). BrainSegNet is trained over three brain tractography data having over 250,000 fibers each. Our experimental evaluation shows that our model achieves state-of-the-art results. We have performed inter as well as intra class testing over three patient's brain tractography data and achieved a high classification accuracy for both macro and micro levels both under intra as well as inter brain testing scenario. version:1
arxiv-1710-05152 | GHCLNet: A Generalized Hierarchically tuned Contact Lens detection Network | http://arxiv.org/abs/1710.05152 | id:1710.05152 author:Avantika Singh, Vishesh Mistry, Dhananjay Yadav, Aditya Nigam category:cs.CV  published:2017-10-14 summary:Iris serves as one of the best biometric modality owing to its complex, unique and stable structure. However, it can still be spoofed using fabricated eyeballs and contact lens. Accurate identification of contact lens is must for reliable performance of any biometric authentication system based on this modality. In this paper, we present a novel approach for detecting contact lens using a Generalized Hierarchically tuned Contact Lens detection Network (GHCLNet) . We have proposed hierarchical architecture for three class oculus classification namely: no lens, soft lens and cosmetic lens. Our network architecture is inspired by ResNet-50 model. This network works on raw input iris images without any pre-processing and segmentation requirement and this is one of its prodigious strength. We have performed extensive experimentation on two publicly available data-sets namely: 1)IIIT-D 2)ND and on IIT-K data-set (not publicly available) to ensure the generalizability of our network. The proposed architecture results are quite promising and outperforms the available state-of-the-art lens detection algorithms. version:1
arxiv-1710-05135 | When Point Process Meets RNNs: Predicting Fine-Grained User Interests with Mutual Behavioral Infectivity | http://arxiv.org/abs/1710.05135 | id:1710.05135 author:Tong Chen, Lin Wu, Yang Wang, Jun Zhang, Hongxu Chen, Xue Li category:cs.LG cs.SI stat.ML  published:2017-10-14 summary:Predicting fine-grained interests of users with temporal behavior is important to personalization and information filtering applications. However, existing interest prediction methods are incapable of capturing the subtle degreed user interests towards particular items, and the internal time-varying drifting attention of individuals is not studied yet. Moreover, the prediction process can also be affected by inter-personal influence, known as behavioral mutual infectivity. Inspired by point process in modeling temporal point process, in this paper we present a deep prediction method based on two recurrent neural networks (RNNs) to jointly model each user's continuous browsing history and asynchronous event sequences in the context of inter-user behavioral mutual infectivity. Our model is able to predict the fine-grained interest from a user regarding a particular item and corresponding timestamps when an occurrence of event takes place. The proposed approach is more flexible to capture the dynamic characteristic of event sequences by using the temporal point process to model event data and timely update its intensity function by RNNs. Furthermore, to improve the interpretability of the model, the attention mechanism is introduced to emphasize both intra-personal and inter-personal behavior influence over time. Experiments on real datasets demonstrate that our model outperforms the state-of-the-art methods in fine-grained user interest prediction. version:1
arxiv-1710-05128 | Parametric t-Distributed Stochastic Exemplar-centered Embedding | http://arxiv.org/abs/1710.05128 | id:1710.05128 author:Martin Renqiang Min, Hongyu Guo, Dinghan Shen category:cs.LG  published:2017-10-14 summary:Parametric embedding methods such as parametric t-SNE (pt-SNE) have been widely adopted for data visualization and out-of-sample data embedding without further computationally expensive optimization or approximation. However, the performance of pt-SNE is highly sensitive to the hyper-parameter batch size due to conflicting optimization goals, and often produces dramatically different embeddings with different choices of user-defined perplexities. To effectively solve these issues, we present parametric t-distributed stochastic exemplar-centered embedding methods. Our strategy learns embedding parameters by comparing given data only with precomputed exemplars, resulting in a cost function with linear computational and memory complexity, which is further reduced by noise contrastive samples. Moreover, we propose a shallow embedding network with high-order feature interactions for data visualization, which is much easier to tune but produces comparable performance in contrast to a deep neural network employed by pt-SNE. We empirically demonstrate, using several benchmark datasets, that our proposed methods significantly outperform pt-SNE in terms of robustness, visual effects, and quantitative evaluations. version:1
arxiv-1710-05126 | Hierarchical semantic segmentation using modular convolutional neural networks | http://arxiv.org/abs/1710.05126 | id:1710.05126 author:Sagi Eppel category:cs.CV  published:2017-10-14 summary:Image recognition tasks that involve identifying parts of an object or the contents of a vessel can be viewed as a hierarchical problem, which can be solved by initial recognition of the main object, followed by recognition of its parts or contents. To achieve such modular recognition, it is necessary to use the output of one recognition method (which identifies the general object) as the input for a second method (which identifies the parts or contents). In recent years, convolutional neural networks have emerged as the dominant method for segmentation and classification of images. This work examines a method for serially connecting convolutional neural networks for semantic segmentation of materials inside transparent vessels. It applies one fully convolutional neural net to segment the image into vessel and background, and the vessel region is used as an input for a second net which recognizes the contents of the glass vessel. Transferring the segmentation map generated by the first nets to the second net was performed using the valve filter attention method that involves using different filters on different segments of the image. This modular semantic segmentation method outperforms a single step method in which both the vessel and its contents are identified using a single net. An advantage of the modular neural net is that it allows networks to be built from existing trained modules, as well the transfer and reuse of trained net modules without the need for any retraining of the assembled net. version:1
arxiv-1710-05115 | Benefits from Superposed Hawkes Processes | http://arxiv.org/abs/1710.05115 | id:1710.05115 author:Hongteng Xu, Dixin Luo, Xu Chen, Lawrence Carin category:stat.ML  published:2017-10-14 summary:The superposition of temporal point processes has been studied for many years, although the usefulness of such models for practical applications has not be fully developed. We investigate superposed Hawkes process as an important class of such models, with properties studied in the framework of least squares estimation. The superposition of Hawkes processes is demonstrated to be beneficial for tightening the upper bound of excess risk under certain conditions, and we show the feasibility of the benefit in typical situations. The usefulness of superposed Hawkes processes is verified on synthetic data, and its potential to solve the cold-start problem of recommendation systems is demonstrated on real-world data. version:1
arxiv-1710-05112 | Video Classification With CNNs: Using The Codec As A Spatio-Temporal Activity Sensor | http://arxiv.org/abs/1710.05112 | id:1710.05112 author:Aaron Chadha, Alhabib Abbas, Yiannis Andreopoulos category:cs.CV  published:2017-10-14 summary:We investigate video classification via a two-stream convolutional neural network (CNN) design that directly ingests information extracted from compressed video bitstreams. Our approach begins with the observation that all modern video codecs divide the input frames into macroblocks (MBs). We demonstrate that selective access to MB motion vector (MV) information within compressed video bitstreams can also provide for selective, motion-adaptive, MB pixel decoding (a.k.a., MB texture decoding). This in turn allows for the derivation of spatio-temporal video activity regions at extremely high speed in comparison to conventional full-frame decoding followed by optical flow estimation. In order to evaluate the accuracy of a video classification framework based on such activity data, we independently train two CNN architectures on MB texture and MV correspondences and then fuse their scores to derive the final classification of each test video. Evaluation on two standard datasets shows that the proposed approach is competitive to the best two-stream video classification approaches found in the literature. At the same time: (i) a CPU-based realization of our MV extraction is over 977 times faster than GPU-based optical flow methods; (ii) selective decoding is up to 12 times faster than full-frame decoding; (iii) our proposed spatial and temporal CNNs perform inference at 5 to 49 times lower cloud computing cost than the fastest methods from the literature. version:1
arxiv-1710-05110 | Subsampling for Ridge Regression via Regularized Volume Sampling | http://arxiv.org/abs/1710.05110 | id:1710.05110 author:Michał Dereziński, Manfred K. Warmuth category:cs.LG  published:2017-10-14 summary:Given $n$ vectors $\mathbf{x}_i\in \mathbb{R}^d$, we want to fit a linear regression model for noisy labels $y_i\in\mathbb{R}$. The ridge estimator is a classical solution to this problem. However, when labels are expensive, we are forced to select only a small subset of vectors $\mathbf{x}_i$ for which we obtain the labels $y_i$. We propose a new procedure for selecting the subset of vectors, such that the ridge estimator obtained from that subset offers strong statistical guarantees in terms of the mean squared prediction error over the entire dataset of $n$ labeled vectors. The number of labels needed is proportional to the statistical dimension of the problem which is often much smaller than $d$. Our method is an extension of a joint subsampling procedure called volume sampling. A second major contribution is that we speed up volume sampling so that it is essentially as efficient as leverage scores, which is the main i.i.d. subsampling procedure for this task. Finally, we show theoretically and experimentally that volume sampling has a clear advantage over any i.i.d. sampling in the sparse label case. version:1
arxiv-1710-05106 | CM-GANs: Cross-modal Generative Adversarial Networks for Common Representation Learning | http://arxiv.org/abs/1710.05106 | id:1710.05106 author:Yuxin Peng, Jinwei Qi, Yuxin Yuan category:cs.MM cs.CV cs.LG  published:2017-10-14 summary:It is known that the inconsistent distribution and representation of different modalities, such as image and text, cause the heterogeneity gap that makes it challenging to correlate such heterogeneous data. Generative adversarial networks (GANs) have shown its strong ability of modeling data distribution and learning discriminative representation, existing GANs-based works mainly focus on generative problem to generate new data. We have different goal, aim to correlate heterogeneous data, by utilizing the power of GANs to model cross-modal joint distribution. Thus, we propose Cross-modal GANs to learn discriminative common representation for bridging heterogeneity gap. The main contributions are: (1) Cross-modal GANs architecture is proposed to model joint distribution over data of different modalities. The inter-modality and intra-modality correlation can be explored simultaneously in generative and discriminative models. Both of them beat each other to promote cross-modal correlation learning. (2) Cross-modal convolutional autoencoders with weight-sharing constraint are proposed to form generative model. They can not only exploit cross-modal correlation for learning common representation, but also preserve reconstruction information for capturing semantic consistency within each modality. (3) Cross-modal adversarial mechanism is proposed, which utilizes two kinds of discriminative models to simultaneously conduct intra-modality and inter-modality discrimination. They can mutually boost to make common representation more discriminative by adversarial training process. To the best of our knowledge, our proposed CM-GANs approach is the first to utilize GANs to perform cross-modal common representation learning. Experiments are conducted to verify the performance of our proposed approach on cross-modal retrieval paradigm, compared with 10 methods on 3 cross-modal datasets. version:1
arxiv-1710-05104 | An adaptive thresholding approach for automatic optic disk segmentation | http://arxiv.org/abs/1710.05104 | id:1710.05104 author:Farnoosh Ghadiri, Robert Bergevin, Masoud Shafiee category:cs.CV  published:2017-10-14 summary:Optic disk segmentation is a prerequisite step in automatic retinal screening systems. In this paper, we propose an algorithm for optic disk segmentation based on a local adaptive thresholding method. Location of the optic disk is validated by intensity and average vessel width of retinal images. Then an adaptive thresholding is applied on the temporal and nasal part of the optic disc separately. Adaptive thresholding, makes our algorithm robust to illumination variations and various image acquisition conditions. Moreover, experimental results on the DRIVE and KHATAM databases show promising results compared to the recent literature. In the DRIVE database, the optic disk in all images is correctly located and the mean overlap reached to 43.21%. The optic disk is correctly detected in 98% of the images with the mean overlap of 36.32% in the KHATAM database. version:1
arxiv-1710-05101 | Unsupervised Real-Time Control through Variational Empowerment | http://arxiv.org/abs/1710.05101 | id:1710.05101 author:Maximilian Karl, Maximilian Soelch, Philip Becker-Ehmck, Djalel Benbouzid, Patrick van der Smagt, Justin Bayer category:stat.ML  published:2017-10-13 summary:We introduce a methodology for efficiently computing a lower bound to empowerment, allowing it to be used as an unsupervised cost function for policy learning in real-time control. Empowerment, being the channel capacity between actions and states, maximises the influence of an agent on its near future. It has been shown to be a good model of biological behaviour in the absence of an extrinsic goal. But empowerment is also prohibitively hard to compute, especially in nonlinear continuous spaces. We introduce an efficient, amortised method for learning empowerment-maximising policies. We demonstrate that our algorithm can reliably handle continuous dynamical systems using system dynamics learned from raw data. The resulting policies consistently drive the agents into states where they can use their full potential. version:1
arxiv-1710-05094 | Learning Phrase Embeddings from Paraphrases with GRUs | http://arxiv.org/abs/1710.05094 | id:1710.05094 author:Zhihao Zhou, Lifu Huang, Heng Ji category:cs.CL  published:2017-10-13 summary:Learning phrase representations has been widely explored in many Natural Language Processing (NLP) tasks (e.g., Sentiment Analysis, Machine Translation) and has shown promising improvements. Previous studies either learn non-compositional phrase representations with general word embedding learning techniques or learn compositional phrase representations based on syntactic structures, which either require huge amounts of human annotations or cannot be easily generalized to all phrases. In this work, we propose to take advantage of large-scaled paraphrase database and present a pair-wise gated recurrent units (pairwise-GRU) framework to generate compositional phrase representations. Our framework can be re-used to generate representations for any phrases. Experimental results show that our framework achieves state-of-the-art results on several phrase similarity tasks. version:1
arxiv-1710-05092 | Dropout as a Low-Rank Regularizer for Matrix Factorization | http://arxiv.org/abs/1710.05092 | id:1710.05092 author:Jacopo Cavazza, Pietro Morerio, Benjamin Haeffele, Connor Lane, Vittorio Murino, Rene Vidal category:cs.LG stat.ML  published:2017-10-13 summary:Regularization for matrix factorization (MF) and approximation problems has been carried out in many different ways. Due to its popularity in deep learning, dropout has been applied also for this class of problems. Despite its solid empirical performance, the theoretical properties of dropout as a regularizer remain quite elusive for this class of problems. In this paper, we present a theoretical analysis of dropout for MF, where Bernoulli random variables are used to drop columns of the factors. We demonstrate the equivalence between dropout and a fully deterministic model for MF in which the factors are regularized by the sum of the product of squared Euclidean norms of the columns. Additionally, we inspect the case of a variable sized factorization and we prove that dropout achieves the global minimum of a convex approximation problem with (squared) nuclear norm regularization. As a result, we conclude that dropout can be used as a low-rank regularizer with data dependent singular-value thresholding. version:1
arxiv-1710-05091 | A simple data discretizer | http://arxiv.org/abs/1710.05091 | id:1710.05091 author:Gourab Mitra, Shashidhar Sundareisan, Bikash Kanti Sarkar category:cs.LG cs.DB stat.ML H.2.8  published:2017-10-13 summary:Data discretization is an important step in the process of machine learning, since it is easier for classifiers to deal with discrete attributes rather than continuous attributes. Over the years, several methods of performing discretization such as Boolean Reasoning, Equal Frequency Binning, Entropy have been proposed, explored, and implemented. In this article, a simple supervised discretization approach is introduced. The prime goal of MIL is to maximize classification accuracy of classifier, minimizing loss of information while discretization of continuous attributes. The performance of the suggested approach is compared with the supervised discretization algorithm Minimum Information Loss (MIL), using the state-of-the-art rule inductive algorithms- J48 (Java implementation of C4.5 classifier). The presented approach is, indeed, the modified version of MIL. The empirical results show that the modified approach performs better in several cases in comparison to the original MIL algorithm and Minimum Description Length Principle (MDLP) . version:1
arxiv-1710-05090 | Burn-In Demonstrations for Multi-Modal Imitation Learning | http://arxiv.org/abs/1710.05090 | id:1710.05090 author:Alex Kuefler, Mykel J. Kochenderfer category:cs.LG stat.ML  published:2017-10-13 summary:Recent work on imitation learning has generated policies that reproduce expert behavior from multi-modal data. However, past approaches have focused only on recreating a small number of distinct, expert maneuvers, or have relied on supervised learning techniques that produce unstable policies. This work extends InfoGAIL, an algorithm for multi-modal imitation learning, to reproduce behavior over an extended period of time. Our approach involves reformulating the typical imitation learning setting to include "burn-in demonstrations" upon which policies are conditioned at test time. We demonstrate that our approach outperforms standard InfoGAIL in maximizing the mutual information between predicted and unseen style labels in road scene simulations, and we show that our method leads to policies that imitate expert autonomous driving systems over long time horizons. version:1
arxiv-1709-09346 | Cold-Start Reinforcement Learning with Softmax Policy Gradient | http://arxiv.org/abs/1709.09346 | id:1709.09346 author:Nan Ding, Radu Soricut category:cs.LG  published:2017-09-27 summary:Policy-gradient approaches to reinforcement learning have two common and undesirable overhead procedures, namely warm-start training and sample variance reduction. In this paper, we describe a reinforcement learning method based on a softmax value function that requires neither of these procedures. Our method combines the advantages of policy-gradient methods with the efficiency and simplicity of maximum-likelihood approaches. We apply this new cold-start reinforcement learning method in training sequence generation models for structured output prediction problems. Empirical evidence validates this method on automatic summarization and image captioning tasks. version:2
arxiv-1710-05080 | DSCOVR: Randomized Primal-Dual Block Coordinate Algorithms for Asynchronous Distributed Optimization | http://arxiv.org/abs/1710.05080 | id:1710.05080 author:Lin Xiao, Adams Wei Yu, Qihang Lin, Weizhu Chen category:math.OC stat.ML  published:2017-10-13 summary:Machine learning with big data often involves large optimization models. For distributed optimization over a cluster of machines, frequent communication and synchronization of all model parameters (optimization variables) can be very costly. A promising solution is to use parameter servers to store different subsets of the model parameters, and update them asynchronously at different machines using local datasets. In this paper, we focus on distributed optimization of large linear models with convex loss functions, and propose a family of randomized primal-dual block coordinate algorithms that are especially suitable for asynchronous distributed implementation with parameter servers. In particular, we work with the saddle-point formulation of such problems which allows simultaneous data and model partitioning, and exploit its structure by doubly stochastic coordinate optimization with variance reduction (DSCOVR). Compared with other first-order distributed algorithms, we show that DSCOVR may require less amount of overall computation and communication, and less or no synchronization. We discuss the implementation details of the DSCOVR algorithms, and present numerical experiments on an industrial distributed computing system. version:1
arxiv-1710-05073 | Improving Shadow Suppression for Illumination Robust Face Recognition | http://arxiv.org/abs/1710.05073 | id:1710.05073 author:Wuming Zhang, Xi Zhao, Jean-Marie Morvan, Liming Chen category:cs.CV  published:2017-10-13 summary:2D face analysis techniques, such as face landmarking, face recognition and face verification, are reasonably dependent on illumination conditions which are usually uncontrolled and unpredictable in the real world. An illumination robust preprocessing method thus remains a significant challenge in reliable face analysis. In this paper we propose a novel approach for improving lighting normalization through building the underlying reflectance model which characterizes interactions between skin surface, lighting source and camera sensor, and elaborates the formation of face color appearance. Specifically, the proposed illumination processing pipeline enables the generation of Chromaticity Intrinsic Image (CII) in a log chromaticity space which is robust to illumination variations. Moreover, as an advantage over most prevailing methods, a photo-realistic color face image is subsequently reconstructed which eliminates a wide variety of shadows whilst retaining the color information and identity details. Experimental results under different scenarios and using various face databases show the effectiveness of the proposed approach to deal with lighting variations, including both soft and hard shadows, in face recognition. version:1
arxiv-1710-05053 | Automated Scalable Bayesian Inference via Hilbert Coresets | http://arxiv.org/abs/1710.05053 | id:1710.05053 author:Trevor Campbell, Tamara Broderick category:stat.ML cs.LG stat.CO  published:2017-10-13 summary:The automation of posterior inference in Bayesian data analysis has enabled experts and nonexperts alike to use more sophisticated models, engage in faster exploratory modeling and analysis, and ensure experimental reproducibility. However, standard automated posterior inference algorithms are not tractable at the scale of massive modern datasets, and modifications to make them so are typically model-specific, require expert tuning, and can break theoretical guarantees on inferential quality. Building on the Bayesian coresets framework, this work instead takes advantage of data redundancy to shrink the dataset itself as a preprocessing step, providing fully-automated, scalable Bayesian inference with theoretical guarantees. We begin with an intuitive reformulation of Bayesian coreset construction as sparse vector sum approximation, and demonstrate that its automation and performance-based shortcomings arise from the use of the supremum norm. To address these shortcomings we develop Hilbert coresets, i.e., Bayesian coresets constructed under a norm induced by an inner-product on the log-likelihood function space. We propose two Hilbert coreset construction algorithms---one based on importance sampling, and one based on the Frank-Wolfe algorithm---along with theoretical guarantees on approximation quality as a function of coreset size. Since the exact computation of the proposed inner-products is model-specific, we automate the construction with a random finite-dimensional projection of the log-likelihood functions. The resulting automated coreset construction algorithm is simple to implement, and experiments on a variety of models with real and synthetic datasets show that it provides high-quality posterior approximations and a significant reduction in the computational cost of inference. version:1
arxiv-1710-05050 | Learning Independent Features with Adversarial Nets for Non-linear ICA | http://arxiv.org/abs/1710.05050 | id:1710.05050 author:Philemon Brakel, Yoshua Bengio category:stat.ML  published:2017-10-13 summary:Reliable measures of statistical dependence could be useful tools for learning independent features and performing tasks like source separation using Independent Component Analysis (ICA). Unfortunately, many of such measures, like the mutual information, are hard to estimate and optimize directly. We propose to learn independent features with adversarial objectives which optimize such measures implicitly. These objectives compare samples from the joint distribution and the product of the marginals without the need to compute any probability densities. We also propose two methods for obtaining samples from the product of the marginals using either a simple resampling trick or a separate parametric distribution. Our experiments show that this strategy can easily be applied to different types of model architectures and solve both linear and non-linear ICA problems. version:1
arxiv-1708-05715 | The Stochastic Replica Approach to Machine Learning: Stability and Parameter Optimization | http://arxiv.org/abs/1708.05715 | id:1708.05715 author:Patrick Chao, Tahereh Mazaheri, Bo Sun, Nicholas B. Weingartner, Zohar Nussinov category:stat.ML cond-mat.stat-mech physics.data-an  published:2017-08-18 summary:We introduce a statistical physics inspired supervised machine learning algorithm for classification and regression problems. The method is based on the invariances or stability of predicted results when known data is represented as expansions in terms of various stochastic functions. The algorithm predicts the classification/regression values of new data by combining (via voting) the outputs of these numerous linear expansions in randomly chosen functions. The few parameters (typically only one parameter is used in all studied examples) that this model has may be automatically optimized. The algorithm has been tested on 10 diverse training data sets of various types and feature space dimensions. It has been shown to consistently exhibit high accuracy and readily allow for optimization of parameters, while simultaneously avoiding pitfalls of existing algorithms such as those associated with class imbalance. We very briefly speculate on whether spatial coordinates in physical theories may be viewed as emergent "features" that enable a robust machine learning type description of data with generic low order smooth functions. version:2
arxiv-1710-05012 | Potential Conditional Mutual Information: Estimators, Properties and Applications | http://arxiv.org/abs/1710.05012 | id:1710.05012 author:Arman Rahimzamani, Sreeram Kannan category:cs.IT cs.LG math.IT stat.ML  published:2017-10-13 summary:The conditional mutual information I(X;Y Z) measures the average information that X and Y contain about each other given Z. This is an important primitive in many learning problems including conditional independence testing, graphical model inference, causal strength estimation and time-series problems. In several applications, it is desirable to have a functional purely of the conditional distribution p_{Y X,Z} rather than of the joint distribution p_{X,Y,Z}. We define the potential conditional mutual information as the conditional mutual information calculated with a modified joint distribution p_{Y X,Z} q_{X,Z}, where q_{X,Z} is a potential distribution, fixed airport. We develop K nearest neighbor based estimators for this functional, employing importance sampling, and a coupling trick, and prove the finite k consistency of such an estimator. We demonstrate that the estimator has excellent practical performance and show an application in dynamical system inference. version:1
arxiv-1709-05027 | Learning Intrinsic Sparse Structures within Long Short-term Memory | http://arxiv.org/abs/1709.05027 | id:1709.05027 author:Wei Wen, Yuxiong He, Samyam Rajbhandari, Wenhan Wang, Fang Liu, Bin Hu, Yiran Chen, Hai Li category:cs.LG cs.AI cs.CL cs.NE  published:2017-09-15 summary:Model compression is significant for wide adoption of Recurrent Neural Networks (RNNs) in both user devices possessing limited resources and in business clusters requiring quick responses to large-scale service requests. In this work, we focus on reducing the sizes of basic structures (including input updates, gates, hidden states, cell states and outputs) within Long Short-term Memory (LSTM) units, so as to learn structurally-sparse LSTMs. Independently reducing the sizes of those basic structures can result in unmatched dimensions among them, and consequently, end up with invalid LSTM units. To overcome this, we propose Intrinsic Sparse Structures (ISS) in LSTMs. By reducing one component of ISS, the sizes of those basic structures are simultaneously reduced by one such that the consistency of dimensions is maintained. By learning ISS within LSTM units, the eventual LSTMs are still regular LSTMs but have much smaller sizes of basic structures. Our method achieves 10.59X speedup in state-of-the-art LSTMs, without losing any perplexity of language modeling of Penn TreeBank dataset. It is also successfully evaluated through a compact model with only 2.69M weights for machine Question Answering of SQuAD dataset. Our source code is public available at https://github.com/wenwei202/iss-rnns. version:2
arxiv-1710-05006 | Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC) | http://arxiv.org/abs/1710.05006 | id:1710.05006 author:Noel C. F. Codella, David Gutman, M. Emre Celebi, Brian Helba, Michael A. Marchetti, Stephen W. Dusza, Aadi Kalloo, Konstantinos Liopyris, Nabin Mishra, Harald Kittler, Allan Halpern category:cs.CV  published:2017-10-13 summary:This article describes the design, implementation, and results of the latest installment of the dermoscopic image analysis benchmark challenge. The goal is to support research and development of algorithms for automated diagnosis of melanoma, the most lethal skin cancer. The challenge was divided into 3 tasks: lesion segmentation, feature detection, and disease classification. Participation involved 593 registrations, 81 pre-submissions, 46 finalized submissions (including a 4-page manuscript), and approximately 50 attendees, making this the largest standardized and comparative study in this field to date. While the official challenge duration and ranking of participants has concluded, the dataset snapshots remain available for further research and development. version:1
arxiv-1710-01257 | Deep learning for source camera identification on mobile devices | http://arxiv.org/abs/1710.01257 | id:1710.01257 author:David Freire-Obregón, Fabio Narducci, Silvio Barra, Modesto Castrillón-Santana category:cs.CV  published:2017-09-30 summary:In the present paper, we propose a source camera identification method for mobile devices based on deep learning. Recently, convolutional neural networks (CNNs) have shown a remarkable performance on several tasks such as image recognition, video analysis or natural language processing. A CNN consists on a set of layers where each layer is composed by a set of high pass filters which are applied all over the input image. This convolution process provides the unique ability to extract features automatically from data and to learn from those features. Our proposal describes a CNN architecture which is able to infer the noise pattern of mobile camera sensors (also known as camera fingerprint) with the aim at detecting and identifying not only the mobile device used to capture an image (with a 98\% of accuracy), but also from which embedded camera the image was captured. More specifically, we provide an extensive analysis on the proposed architecture considering different configurations. The experiment has been carried out using the images captured from different mobile devices cameras (MICHE-I Dataset was used) and the obtained results have proved the robustness of the proposed method. version:2
arxiv-1710-04989 | Complex Word Identification: Challenges in Data Annotation and System Performance | http://arxiv.org/abs/1710.04989 | id:1710.04989 author:Marcos Zampieri, Shervin Malmasi, Gustavo Paetzold, Lucia Specia category:cs.CL  published:2017-10-13 summary:This paper revisits the problem of complex word identification (CWI) following up the SemEval CWI shared task. We use ensemble classifiers to investigate how well computational methods can discriminate between complex and non-complex words. Furthermore, we analyze the classification performance to understand what makes lexical complexity challenging. Our findings show that most systems performed poorly on the SemEval CWI dataset, and one of the reasons for that is the way in which human annotation was performed. version:1
arxiv-1710-04981 | A Learning Based Approach to Incremental Context Modeling in Robots | http://arxiv.org/abs/1710.04981 | id:1710.04981 author:Fethiye Irmak Doğan, İlker Bozcan, Sinan Kalkan category:cs.RO cs.LG  published:2017-10-13 summary:There have been several attempts at modeling context in robots. However, either these attempts assume a fixed number of contexts or use a rule-based approach to determine when to increment the number of contexts. In this paper, we propose to pose the task of incrementing as a learning problem, which we solve using a Recurrent Neural Network. We show that the network successfully (with 98% testing accuracy) learns to predict when to increment, and demonstrate, in a scene modeling problem (where the correct number of contexts is not known), that the robot increments the number of contexts in an expected manner (i.e., the entropy of the system is reduced). We also present how the incremental model can be used for various scene reasoning tasks. version:1
arxiv-1710-04975 | A Deep Incremental Boltzmann Machine for Modeling Context in Robots | http://arxiv.org/abs/1710.04975 | id:1710.04975 author:Fethiye Irmak Doğan, Sinan Kalkan category:cs.RO cs.LG  published:2017-10-13 summary:Context is an essential capability for robots that are to be as adaptive as possible in challenging environments. Although there are many context modeling efforts, they assume a fixed structure and number of contexts. In this paper, we propose an incremental deep model that extends Restricted Boltzmann Machines. Our model gets one scene at a time, and gradually extends the contextual model when necessary, either by adding a new context or a new context layer to form a hierarchy. We show on a scene classification benchmark that our method converges to a good estimate of the contexts of the scenes, and performs better or on-par on several tasks compared to other incremental models or non-incremental models. version:1
arxiv-1709-08202 | Performance Characterization of Image Feature Detectors in Relation to the Scene Content Utilizing a Large Image Database | http://arxiv.org/abs/1709.08202 | id:1709.08202 author:Bruno Ferrarini, Shoaib Ehsan, Ales Leonardis, Naveed Ur Rehman, Klaus D. McDonald-Maier category:cs.CV  published:2017-09-24 summary:Selecting the most suitable local invariant feature detector for a particular application has rendered the task of evaluating feature detectors a critical issue in vision research. Although the literature offers a variety of comparison works focusing on performance evaluation of image feature detectors under several types of image transformations, the influence of the scene content on the performance of local feature detectors has received little attention so far. This paper aims to bridge this gap with a new framework for determining the type of scenes which maximize and minimize the performance of detectors in terms of repeatability rate. The results are presented for several state-of-the-art feature detectors that have been obtained using a large image database of 20482 images under JPEG compression, uniform light and blur changes with 539 different scenes captured from real-world scenarios. These results provide new insights into the behavior of feature detectors. version:2
arxiv-1710-05027 | Real time ridge orientation estimation for fingerprint images | http://arxiv.org/abs/1710.05027 | id:1710.05027 author:Eman Alibeigi, Shadrokh Samavi, Shahram Shirani, Zahra Rahmani category:cs.CV cs.AR  published:2017-10-13 summary:Fingerprint verification is an important bio-metric technique for personal identification. Most of the automatic verification systems are based on matching of fingerprint minutiae. Extraction of minutiae is an essential process which requires estimation of orientation of the lines in an image. Most of the existing methods involve intense mathematical computations and hence are performed through software means. In this paper a hardware scheme to perform real time orientation estimation is presented which is based on pipelined architecture. Synthesized circuits proved the functionality and accuracy of the suggested method. version:1
arxiv-1710-04943 | Object Classification in Images of Neoclassical Artifacts Using Deep Learning | http://arxiv.org/abs/1710.04943 | id:1710.04943 author:Bernhard Bermeitinger, Maria Christoforaki, Simon Donig, Siegfried Handschuh category:cs.CV  published:2017-10-13 summary:In this paper, we report on our efforts for using Deep Learning for classifying artifacts and their features in digital visuals as a part of the Neoclassica framework. It was conceived to provide scholars with new methods for analyzing and classifying artifacts and aesthetic forms from the era of Classicism. The framework accommodates both traditional knowledge representation as a formal ontology and data-driven knowledge discovery, where cultural patterns will be identified by means of algorithms in statistical analysis and machine learning. We created a Deep Learning approach trained on photographs to classify the objects inside these photographs. In a next step, we will apply a different Deep Learning approach. It is capable of locating multiple objects inside an image and classifying them with a high accuracy. version:1
arxiv-1710-04934 | RADNET: Radiologist Level Accuracy using Deep Learning for HEMORRHAGE detection in CT Scans | http://arxiv.org/abs/1710.04934 | id:1710.04934 author:Monika Grewal, Muktabh Mayank Srivastava, Pulkit Kumar, Srikrishna Varadarajan category:cs.CV stat.ML  published:2017-10-13 summary:We describe a deep learning approach for automated brain hemorrhage detection from computed tomography (CT) scans. Our model emulates the procedure followed by radiologists to analyse a 3D CT scan in real-world. Similar to radiologists, the model sifts through 2D cross-sectional slices while paying close attention to potential hemorrhagic regions. Further, the model utilizes 3D context from neighboring slices to improve predictions at each slice and subsequently, aggregates the slice-level predictions to provide diagnosis at CT level. We refer to our proposed approach as Recurrent Attention DenseNet (RADnet) as it employs original DenseNet architecture along with adding the components of attention for slice level predictions and recurrent neural network layer for incorporating 3D context. The real-world performance of RADnet has been benchmarked against independent analysis performed by three senior radiologists for 77 brain CTs. RADnet demonstrates 81.82% hemorrhage prediction accuracy at CT level that is comparable to radiologists. Further, RADnet achieves higher recall than two of the three radiologists, which is remarkable. version:1
arxiv-1710-04924 | Two-stage Algorithm for Fairness-aware Machine Learning | http://arxiv.org/abs/1710.04924 | id:1710.04924 author:Junpei Komiyama, Hajime Shimao category:stat.ML cs.AI cs.LG  published:2017-10-13 summary:Algorithmic decision making process now affects many aspects of our lives. Standard tools for machine learning, such as classification and regression, are subject to the bias in data, and thus direct application of such off-the-shelf tools could lead to a specific group being unfairly discriminated. Removing sensitive attributes of data does not solve this problem because a \textit{disparate impact} can arise when non-sensitive attributes and sensitive attributes are correlated. Here, we study a fair machine learning algorithm that avoids such a disparate impact when making a decision. Inspired by the two-stage least squares method that is widely used in the field of economics, we propose a two-stage algorithm that removes bias in the training data. The proposed algorithm is conceptually simple. Unlike most of existing fair algorithms that are designed for classification tasks, the proposed method is able to (i) deal with regression tasks, (ii) combine explanatory attributes to remove reverse discrimination, and (iii) deal with numerical sensitive attributes. The performance and fairness of the proposed algorithm are evaluated in simulations with synthetic and real-world datasets. version:1
arxiv-1710-04881 | User Modelling for Avoiding Overfitting in Interactive Knowledge Elicitation for Prediction | http://arxiv.org/abs/1710.04881 | id:1710.04881 author:Pedram Daee, Tomi Peltola, Aki Vehtari, Samuel Kaski category:cs.HC cs.LG stat.ML H.1.2; I.2.6; H.3.3  published:2017-10-13 summary:In human-in-the-loop machine learning, the user provides information beyond that in the training data. Many algorithms and user interfaces have been designed to optimize and facilitate this human--machine interaction; however, fewer studies have addressed the potential defects the designs can cause. Effective interaction often requires exposing the user to the training data or its statistics. The design of the system is then critical, as this can lead to double use of data and overfitting, if the user reinforces noisy patterns in the data. We propose a user modelling methodology, by assuming simple rational behaviour, to correct the problem. We show, in a user study with 48 participants, that the method improves predictive performance in a sparse linear regression sentiment analysis task, where graded user knowledge on feature relevance is elicited. We believe that the key idea of inferring user knowledge with probabilistic user models has general applicability in guarding against overfitting and improving interactive machine learning. version:1
arxiv-1710-04874 | A Method of Generating Random Weights and Biases in Feedforward Neural Networks with Random Hidden Nodes | http://arxiv.org/abs/1710.04874 | id:1710.04874 author:Grzegorz Dudek category:cs.NE cs.LG stat.ML  published:2017-10-13 summary:Neural networks with random hidden nodes have gained increasing interest from researchers and practical applications. This is due to their unique features such as very fast training and universal approximation property. In these networks the weights and biases of hidden nodes determining the nonlinear feature mapping are set randomly and are not learned. Appropriate selection of the intervals from which weights and biases are selected is extremely important. This topic has not yet been sufficiently explored in the literature. In this work a method of generating random weights and biases is proposed. This method generates the parameters of the hidden nodes in such a way that nonlinear fragments of the activation functions are located in the input space regions with data and can be used to construct the surface approximating a nonlinear target function. The weights and biases are dependent on the input data range and activation function type. The proposed methods allows us to control the generalization degree of the model. These all lead to improvement in approximation performance of the network. Several experiments show very promising results. version:1
arxiv-1710-04872 | Manifold regularization based on Nystr{ö}m type subsampling | http://arxiv.org/abs/1710.04872 | id:1710.04872 author:Abhishake Rastogi, Sivananthan Sampath category:stat.ML cs.LG  published:2017-10-13 summary:In this paper, we study the Nystr{\"o}m type subsampling for large scale kernel methods to reduce the computational complexities of big data. We discuss the multi-penalty regularization scheme based on Nystr{\"o}m type subsampling which is motivated from well-studied manifold regularization schemes. We develop a theoretical analysis of multi-penalty least-square regularization scheme under the general source condition in vector-valued function setting, therefore the results can also be applied to multi-task learning problems. We achieve the optimal minimax convergence rates of multi-penalty regularization using the concept of effective dimension for the appropriate subsampling size. We discuss an aggregation approach based on linear function strategy to combine various Nystr{\"o}m approximants. Finally, we demonstrate the performance of multi-penalty regularization based on Nystr{\"o}m type subsampling on Caltech-101 data set for multi-class image classification and NSL-KDD benchmark data set for intrusion detection problem. version:1
arxiv-1710-05758 | TensorQuant - A Simulation Toolbox for Deep Neural Network Quantization | http://arxiv.org/abs/1710.05758 | id:1710.05758 author:Dominik Marek Loroch, Norbert Wehn, Franz-Josef Pfreundt, Janis Keuper category:cs.CV cs.LG stat.ML  published:2017-10-13 summary:Recent research implies that training and inference of deep neural networks (DNN) can be computed with low precision numerical representations of the training/test data, weights and gradients without a general loss in accuracy. The benefit of such compact representations is twofold: they allow a significant reduction of the communication bottleneck in distributed DNN training and faster neural network implementations on hardware accelerators like FPGAs. Several quantization methods have been proposed to map the original 32-bit floating point problem to low-bit representations. While most related publications validate the proposed approach on a single DNN topology, it appears to be evident, that the optimal choice of the quantization method and number of coding bits is topology dependent. To this end, there is no general theory available, which would allow users to derive the optimal quantization during the design of a DNN topology. In this paper, we present a quantization tool box for the TensorFlow framework. TensorQuant allows a transparent quantization simulation of existing DNN topologies during training and inference. TensorQuant supports generic quantization methods and allows experimental evaluation of the impact of the quantization on single layers as well as on the full topology. In a first series of experiments with TensorQuant, we show an analysis of fix-point quantizations of popular CNN topologies. version:1
arxiv-1710-04843 | Performance Comparison of Intrusion Detection Systems and Application of Machine Learning to Snort System | http://arxiv.org/abs/1710.04843 | id:1710.04843 author:Syed Ali Raza Shah, Biju Issac category:cs.NI cs.CR cs.LG  published:2017-10-13 summary:This study investigates the performance of two open source intrusion detection systems (IDSs) namely Snort and Suricata for accurately detecting the malicious traffic on computer networks. Snort and Suricata were installed on two different but identical computers and the performance was evaluated at 10 Gbps network speed. It was noted that Suricata could process a higher speed of network traffic than Snort with lower packet drop rate but it consumed higher computational resources. Snort had higher detection accuracy and was thus selected for further experiments. It was observed that Snort triggered a high rate of false positive alarms. To solve this problem a Snort adaptive plug-in was developed. To select the best performing algorithm for the Snort adaptive plug-in, an empirical study was carried out with different learning algorithms and Support Vector Machine (SVM) was selected. A hybrid version of SVM and Fuzzy logic produced a better detection accuracy. But the best result was achieved using an optimized SVM with the firefly algorithm with FPR (false positive rate) as 8.6% and FNR (false negative rate) as 2.2%, which is a good result. The novelty of this work is the performance comparison of two IDSs at 10 Gbps and the application of hybrid and optimized machine learning algorithms to Snort. version:1
arxiv-1710-04842 | Dynamic texture recognition using time-causal and time-recursive spatio-temporal receptive fields | http://arxiv.org/abs/1710.04842 | id:1710.04842 author:Ylva Jansson, Tony Lindeberg category:cs.CV  published:2017-10-13 summary:This work presents a first evaluation of using spatio-temporal receptive fields from a recently proposed time-causal spatio-temporal scale-space framework as primitives for video analysis. We propose a new family of video descriptors based on regional statistics of spatio-temporal receptive field responses and evaluate this approach on the problem of dynamic texture recognition. Our approach generalises a previously used method, based on joint histograms of receptive field responses, from the spatial to the spatio-temporal domain and from object recognition to dynamic texture recognition. The time-recursive formulation enables computationally efficient time-causal recognition. The experimental evaluation demonstrates competitive performance compared to state-of-the-art. Especially, it is shown that binary versions of our dynamic texture descriptors achieve improved performance compared to a large range of similar methods using different primitives either handcrafted or learned from data. Further, our qualitative and quantitative investigation into parameter choices and the use of different sets of receptive fields highlights the robustness and flexibility of our approach. Together, these results support the descriptive power of this family of time-causal spatio-temporal receptive fields, validate our approach for dynamic texture recognition and point towards the possibility of designing a range of video analysis methods based on these new time-causal spatio-temporal primitives. version:1
arxiv-1710-04838 | Efficient Computation in Adaptive Artificial Spiking Neural Networks | http://arxiv.org/abs/1710.04838 | id:1710.04838 author:Davide Zambrano, Roeland Nusselder, H. Steven Scholte, Sander Bohte category:cs.NE  published:2017-10-13 summary:Artificial Neural Networks (ANNs) are bio-inspired models of neural computation that have proven highly effective. Still, ANNs lack a natural notion of time, and neural units in ANNs exchange analog values in a frame-based manner, a computationally and energetically inefficient form of communication. This contrasts sharply with biological neurons that communicate sparingly and efficiently using binary spikes. While artificial Spiking Neural Networks (SNNs) can be constructed by replacing the units of an ANN with spiking neurons, the current performance is far from that of deep ANNs on hard benchmarks and these SNNs use much higher firing rates compared to their biological counterparts, limiting their efficiency. Here we show how spiking neurons that employ an efficient form of neural coding can be used to construct SNNs that match high-performance ANNs and exceed state-of-the-art in SNNs on important benchmarks, while requiring much lower average firing rates. For this, we use spike-time coding based on the firing rate limiting adaptation phenomenon observed in biological spiking neurons. This phenomenon can be captured in adapting spiking neuron models, for which we derive the effective transfer function. Neural units in ANNs trained with this transfer function can be substituted directly with adaptive spiking neurons, and the resulting Adaptive SNNs (AdSNNs) can carry out inference in deep neural networks using up to an order of magnitude fewer spikes compared to previous SNNs. Adaptive spike-time coding additionally allows for the dynamic control of neural coding precision: we show how a simple model of arousal in AdSNNs further halves the average required firing rate and this notion naturally extends to other forms of attention. AdSNNs thus hold promise as a novel and efficient model for neural computation that naturally fits to temporally continuous and asynchronous applications. version:1
arxiv-1710-04837 | Recent Advances in Zero-shot Recognition | http://arxiv.org/abs/1710.04837 | id:1710.04837 author:Yanwei Fu, Tao Xiang, Yu-Gang Jiang, Xiangyang Xue, Leonid Sigal, Shaogang Gong category:cs.CV cs.AI cs.LG cs.MM stat.ML  published:2017-10-13 summary:With the recent renaissance of deep convolution neural networks, encouraging breakthroughs have been achieved on the supervised recognition tasks, where each class has sufficient training data and fully annotated training data. However, to scale the recognition to a large number of classes with few or now training samples for each class remains an unsolved problem. One approach to scaling up the recognition is to develop models capable of recognizing unseen categories without any training instances, or zero-shot recognition/ learning. This article provides a comprehensive review of existing zero-shot recognition techniques covering various aspects ranging from representations of models, and from datasets and evaluation settings. We also overview related recognition tasks including one-shot and open set recognition which can be used as natural extensions of zero-shot recognition when limited number of class samples become available or when zero-shot recognition is implemented in a real-world setting. Importantly, we highlight the limitations of existing approaches and point out future research directions in this existing new research area. version:1
arxiv-1706-06266 | Multi-frame image super-resolution with fast upscaling technique | http://arxiv.org/abs/1706.06266 | id:1706.06266 author:Longguang Wang, Zaiping Lin, Xinpu Deng, Wei An category:cs.CV  published:2017-06-20 summary:Multi-frame image super-resolution (MISR) aims to fuse information in low-resolution (LR) image sequence to compose a high-resolution (HR) one, which is applied extensively in many areas recently. Different with single image super-resolution (SISR), sub-pixel transitions between multiple frames introduce additional information, attaching more significance to fusion operator to alleviate the ill-posedness of MISR. For reconstruction-based approaches, the inevitable projection of reconstruction errors from LR space to HR space is commonly tackled by an interpolation operator, however crude interpolation may not fit the natural image and generate annoying blurring artifacts, especially after fusion operator. In this paper, we propose an end-to-end fast upscaling technique to replace the interpolation operator, design upscaling filters in LR space for periodic sub-locations respectively and shuffle the filter results to derive the final reconstruction errors in HR space. The proposed fast upscaling technique not only reduce the computational complexity of the upscaling operation by utilizing shuffling operation to avoid complex operation in HR space, but also realize superior performance with fewer blurring artifacts. Extensive experimental results demonstrate the effectiveness and efficiency of the proposed technique, whilst, combining the proposed technique with bilateral total variation (BTV) regu-larization, the MISR approach outperforms state-of-the-art methods. version:2
arxiv-1710-04835 | Filmy Cloud Removal on Satellite Imagery with Multispectral Conditional Generative Adversarial Nets | http://arxiv.org/abs/1710.04835 | id:1710.04835 author:Kenji Enomoto, Ken Sakurada, Weimin Wang, Hiroshi Fukui, Masashi Matsuoka, Ryosuke Nakamura, Nobuo Kawaguchi category:cs.CV  published:2017-10-13 summary:In this paper, we propose a method for cloud removal from visible light RGB satellite images by extending the conditional Generative Adversarial Networks (cGANs) from RGB images to multispectral images. Satellite images have been widely utilized for various purposes, such as natural environment monitoring (pollution, forest or rivers), transportation improvement and prompt emergency response to disasters. However, the obscurity caused by clouds makes it unstable to monitor the situation on the ground with the visible light camera. Images captured by a longer wavelength are introduced to reduce the effects of clouds. Synthetic Aperture Radar (SAR) is such an example that improves visibility even the clouds exist. On the other hand, the spatial resolution decreases as the wavelength increases. Furthermore, the images captured by long wavelengths differs considerably from those captured by visible light in terms of their appearance. Therefore, we propose a network that can remove clouds and generate visible light images from the multispectral images taken as inputs. This is achieved by extending the input channels of cGANs to be compatible with multispectral images. The networks are trained to output images that are close to the ground truth using the images synthesized with clouds over the ground truth as inputs. In the available dataset, the proportion of images of the forest or the sea is very high, which will introduce bias in the training dataset if uniformly sampled from the original dataset. Thus, we utilize the t-Distributed Stochastic Neighbor Embedding (t-SNE) to improve the problem of bias in the training dataset. Finally, we confirm the feasibility of the proposed network on the dataset of four bands images, which include three visible light bands and one near-infrared (NIR) band. version:1
arxiv-1710-04833 | Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures | http://arxiv.org/abs/1710.04833 | id:1710.04833 author:Ding Liu, Shi-Ju Ran, Peter Wittek, Cheng Peng, Raul Blázquez García, Gang Su, Maciej Lewenstein category:stat.ML cond-mat.str-el physics.comp-ph quant-ph  published:2017-10-13 summary:The resemblance between the methods used in studying quantum-many body physics and in machine learning has drawn considerable attention. In particular, tensor networks (TNs) and deep learning architectures bear striking similarities to the extent that TNs can be used for machine learning. Previous results used one-dimensional TNs in image recognition, showing limited scalability and a high bond dimension. In this work, we train two-dimensional hierarchical TNs to solve image recognition problems, using a training algorithm derived from the multipartite entanglement renormalization ansatz (MERA). This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics, quantum information theory, and machine learning. While keeping the TN unitary in the training phase, TN states can be defined, which optimally encodes each class of the images into a quantum many-body state. We study the quantum features of the TN states, including quantum entanglement and fidelity. We suggest these quantities could be novel properties that characterize the image classes, as well as the machine learning tasks. Our work could be further applied to identifying possible quantum properties of certain artificial intelligence methods. version:1
arxiv-1710-04826 | WeText: Scene Text Detection under Weak Supervision | http://arxiv.org/abs/1710.04826 | id:1710.04826 author:Shangxuan Tian, Shijian Lu, Chongshou Li category:cs.CV  published:2017-10-13 summary:The requiring of large amounts of annotated training data has become a common constraint on various deep learning systems. In this paper, we propose a weakly supervised scene text detection method (WeText) that trains robust and accurate scene text detection models by learning from unannotated or weakly annotated data. With a "light" supervised model trained on a small fully annotated dataset, we explore semi-supervised and weakly supervised learning on a large unannotated dataset and a large weakly annotated dataset, respectively. For the unsupervised learning, the light supervised model is applied to the unannotated dataset to search for more character training samples, which are further combined with the small annotated dataset to retrain a superior character detection model. For the weakly supervised learning, the character searching is guided by high-level annotations of words/text lines that are widely available and also much easier to prepare. In addition, we design an unified scene character detector by adapting regression based deep networks, which greatly relieves the error accumulation issue that widely exists in most traditional approaches. Extensive experiments across different unannotated and weakly annotated datasets show that the scene text detection performance can be clearly boosted under both scenarios, where the weakly supervised learning can achieve the state-of-the-art performance by using only 229 fully annotated scene text images. version:1
arxiv-1709-06293 | Sparse Markov Decision Processes with Causal Sparse Tsallis Entropy Regularization for Reinforcement Learning | http://arxiv.org/abs/1709.06293 | id:1709.06293 author:Kyungjae Lee, Sungjoon Choi, Songhwai Oh category:cs.LG cs.AI stat.ML  published:2017-09-19 summary:In this paper, a sparse Markov decision process (MDP) with novel causal sparse Tsallis entropy regularization is proposed.The proposed policy regularization induces a sparse and multi-modal optimal policy distribution of a sparse MDP. The full mathematical analysis of the proposed sparse MDP is provided.We first analyze the optimality condition of a sparse MDP. Then, we propose a sparse value iteration method which solves a sparse MDP and then prove the convergence and optimality of sparse value iteration using the Banach fixed point theorem. The proposed sparse MDP is compared to soft MDPs which utilize causal entropy regularization. We show that the performance error of a sparse MDP has a constant bound, while the error of a soft MDP increases logarithmically with respect to the number of actions, where this performance error is caused by the introduced regularization term. In experiments, we apply sparse MDPs to reinforcement learning problems. The proposed method outperforms existing methods in terms of the convergence speed and performance. version:3
arxiv-1710-04809 | Deep Regression Bayesian Network and Its Applications | http://arxiv.org/abs/1710.04809 | id:1710.04809 author:Siqi Nie, Meng Zheng, Qiang Ji category:cs.LG  published:2017-10-13 summary:Deep directed generative models have attracted much attention recently due to their generative modeling nature and powerful data representation ability. In this paper, we review different structures of deep directed generative models and the learning and inference algorithms associated with the structures. We focus on a specific structure that consists of layers of Bayesian Networks due to the property of capturing inherent and rich dependencies among latent variables. The major difficulty of learning and inference with deep directed models with many latent variables is the intractable inference due to the dependencies among the latent variables and the exponential number of latent variable configurations. Current solutions use variational methods often through an auxiliary network to approximate the posterior probability inference. In contrast, inference can also be performed directly without using any auxiliary network to maximally preserve the dependencies among the latent variables. Specifically, by exploiting the sparse representation with the latent space, max-max instead of max-sum operation can be used to overcome the exponential number of latent configurations. Furthermore, the max-max operation and augmented coordinate ascent are applied to both supervised and unsupervised learning as well as to various inference. Quantitative evaluations on benchmark datasets of different models are given for both data representation and feature learning tasks. version:1
arxiv-1710-04806 | Deep Learning for Case-based Reasoning through Prototypes: A Neural Network that Explains its Predictions | http://arxiv.org/abs/1710.04806 | id:1710.04806 author:Oscar Li, Hao Liu, Chaofan Chen, Cynthia Rudin category:cs.AI cs.LG stat.ML  published:2017-10-13 summary:Deep neural networks are widely used for classification. These deep models often suffer from a lack of interpretability -- they are particularly difficult to understand because of their non-linear nature. As a result, neural networks are often treated as "black box" models, and in the past, have been trained purely to optimize the accuracy of predictions. In this work, we create a novel network architecture for deep learning that naturally explains its own reasoning for each prediction. This architecture contains an autoencoder and a special prototype layer, where each unit of that layer stores a weight vector that resembles an encoded training input. The encoder of the autoencoder allows us to do comparisons within the latent space, while the decoder allows us to visualize the learned prototypes. The training objective has four terms: an accuracy term, a term that encourages every prototype to be similar to at least one encoded input, a term that encourages every encoded input to be close to at least one prototype, and a term that encourages faithful reconstruction by the autoencoder. The distances computed in the prototype layer are used as part of the classification process. Since the prototypes are learned during training, the learned network naturally comes with explanations for each prediction, and the explanations are loyal to what the network actually computes. version:1
arxiv-1710-04803 | VGR-Net: A View Invariant Gait Recognition Network | http://arxiv.org/abs/1710.04803 | id:1710.04803 author:Daksh Thapar, Divyansh Aggarwal, Punjal Agarwal, Aditya Nigam category:cs.CV  published:2017-10-13 summary:Biometric identification systems have become immensely popular and important because of their high reliability and efficiency. However person identification at a distance, still remains a challenging problem. Gait can be seen as an essential biometric feature for human recognition and identification. It can be easily acquired from a distance and does not require any user cooperation thus making it suitable for surveillance. But the task of recognizing an individual using gait can be adversely affected by varying view points making this task more and more challenging. Our proposed approach tackles this problem by identifying spatio-temporal features and performing extensive experimentation and training mechanism. In this paper, we propose a 3-D Convolution Deep Neural Network for person identification using gait under multiple view. It is a 2-stage network, in which we have a classification network that initially identifies the viewing point angle. After that another set of networks (one for each angle) has been trained to identify the person under a particular viewing angle. We have tested this network over CASIA-B publicly available database and have achieved state-of-the-art results. The proposed system is much more efficient in terms of time and space and performing better for almost all angles. version:1
arxiv-1710-04802 | End-to-end Network for Twitter Geolocation Prediction and Hashing | http://arxiv.org/abs/1710.04802 | id:1710.04802 author:Jey Han Lau, Lianhua Chi, Khoi-Nguyen Tran, Trevor Cohn category:cs.CL  published:2017-10-13 summary:We propose an end-to-end neural network to predict the geolocation of a tweet. The network takes as input a number of raw Twitter metadata such as the tweet message and associated user account information. Our model is language independent, and despite minimal feature engineering, it is interpretable and capable of learning location indicative words and timing patterns. Compared to state-of-the-art systems, our model outperforms them by 2%-6%. Additionally, we propose extensions to the model to compress representation learnt by the network into binary codes. Experiments show that it produces compact codes compared to benchmark hashing algorithms. An implementation of the model is released publicly. version:1
arxiv-1710-04792 | Sparse Weighted Canonical Correlation Analysis | http://arxiv.org/abs/1710.04792 | id:1710.04792 author:Wenwen Min, Juan Liu, Shihua Zhang category:cs.LG stat.ML I.5.1; H.2.8; G.1.6  published:2017-10-13 summary:Given two data matrices $X$ and $Y$, sparse canonical correlation analysis (SCCA) is to seek two sparse canonical vectors $u$ and $v$ to maximize the correlation between $Xu$ and $Yv$. However, classical and sparse CCA models consider the contribution of all the samples of data matrices and thus cannot identify an underlying specific subset of samples. To this end, we propose a novel sparse weighted canonical correlation analysis (SWCCA), where weights are used for regularizing different samples. We solve the $L_0$-regularized SWCCA ($L_0$-SWCCA) using an alternating iterative algorithm. We apply $L_0$-SWCCA to synthetic data and real-world data to demonstrate its effectiveness and superiority compared to related methods. Lastly, we consider also SWCCA with different penalties like LASSO (Least absolute shrinkage and selection operator) and Group LASSO, and extend it for integrating more than three data matrices. version:1
arxiv-1710-04782 | Multimodal and Multiscale Deep Neural Networks for the Early Diagnosis of Alzheimer's Disease using structural MR and FDG-PET images | http://arxiv.org/abs/1710.04782 | id:1710.04782 author:Donghuan Lu, Karteek Popuri, Weiguang Ding, Rakesh Balachandar, Mirza Faisal Beg category:cs.CV  published:2017-10-13 summary:Alzheimer's Disease (AD) is a progressive neurodegenerative disease. Amnestic mild cognitive impairment (MCI) is a common first symptom before the conversion to clinical impairment where the individual becomes unable to perform activities of daily living independently. Although there is currently no treatment available, the earlier a conclusive diagnosis is made, the earlier the potential for interventions to delay or perhaps even prevent progression to full-blown AD. Neuroimaging scans acquired from MRI and metabolism images obtained by FDG-PET provide in-vivo view into the structure and function (glucose metabolism) of the living brain. It is hypothesized that combining different image modalities could better characterize the change of human brain and result in a more accuracy early diagnosis of AD. In this paper, we proposed a novel framework to discriminate normal control(NC) subjects from subjects with AD pathology (AD and NC, MCI subjects convert to AD in future). Our novel approach utilizing a multimodal and multiscale deep neural network was found to deliver a 85.68\% accuracy in the prediction of subjects within 3 years to conversion. Cross validation experiments proved that it has better discrimination ability compared with results in existing published literature. version:1
arxiv-1710-04778 | Retinal Fluid Segmentation and Detection in Optical Coherence Tomography Images using Fully Convolutional Neural Network | http://arxiv.org/abs/1710.04778 | id:1710.04778 author:Donghuan Lu, Morgan Heisler, Sieun Lee, Gavin Ding, Marinko V. Sarunic, Mirza Faisal Beg category:cs.CV  published:2017-10-13 summary:As a non-invasive imaging modality, optical coherence tomography (OCT) can provide micrometer-resolution 3D images of retinal structures. Therefore it is commonly used in the diagnosis of retinal diseases associated with edema in and under the retinal layers. In this paper, a new framework is proposed for the task of fluid segmentation and detection in retinal OCT images. Based on the raw images and layers segmented by a graph-cut algorithm, a fully convolutional neural network was trained to recognize and label the fluid pixels. Random forest classification was performed on the segmented fluid regions to detect and reject the falsely labeled fluid regions. The leave-one-out cross validation experiments on the RETOUCH database show that our method performs well in both segmentation (mean Dice: 0.7317) and detection (mean AUC: 0.985) tasks. version:1
arxiv-1710-04773 | Residual Connections Encourage Iterative Inference | http://arxiv.org/abs/1710.04773 | id:1710.04773 author:Stanisław Jastrzebski, Devansh Arpit, Nicolas Ballas, Vikas Verma, Tong Che, Yoshua Bengio category:cs.CV  published:2017-10-13 summary:Residual networks (Resnets) have become a prominent architecture in deep learning. However, a comprehensive understanding of Resnets is still a topic of ongoing research. A recent view argues that Resnets perform iterative refinement of features. We attempt to further expose properties of this aspect. To this end, we study Resnets both analytically and empirically. We formalize the notion of iterative refinement in Resnets by showing that residual architectures naturally encourage features to move along the negative gradient of loss during the feedforward phase. In addition, our empirical analysis suggests that Resnets are able to perform both representation learning and iterative refinement. In general, a Resnet block tends to concentrate representation learning behavior in the first few layers while higher layers perform iterative refinement of features. Finally we observe that sharing residual layers naively leads to representation explosion and hurts generalization performance, and show that simple existing strategies can help alleviating this problem. version:1
arxiv-1708-09687 | Quantifying Facial Age by Posterior of Age Comparisons | http://arxiv.org/abs/1708.09687 | id:1708.09687 author:Yunxuan Zhang, Li Liu, Cheng Li, Chen change Loy category:cs.CV  published:2017-08-31 summary:We introduce a novel approach for annotating large quantity of in-the-wild facial images with high-quality posterior age distribution as labels. Each posterior provides a probability distribution of estimated ages for a face. Our approach is motivated by observations that it is easier to distinguish who is the older of two people than to determine the person's actual age. Given a reference database with samples of known ages and a dataset to label, we can transfer reliable annotations from the former to the latter via human-in-the-loop comparisons. We show an effective way to transform such comparisons to posterior via fully-connected and SoftMax layers, so as to permit end-to-end training in a deep network. Thanks to the efficient and effective annotation approach, we collect a new large-scale facial age dataset, dubbed `MegaAge', which consists of 41,941 images. Data can be downloaded from our project page mmlab.ie.cuhk.edu.hk/projects/MegaAge and github.com/zyx2012/Age_estimation_BMVC2017. With the dataset, we train a network that jointly performs ordinal hyperplane classification and posterior distribution learning. Our approach achieves state-of-the-art results on popular benchmarks such as MORPH2, Adience, and the newly proposed MegaAge. version:2
arxiv-1710-04759 | Bayesian Hypernetworks | http://arxiv.org/abs/1710.04759 | id:1710.04759 author:David Krueger, Chin-Wei Huang, Riashat Islam, Ryan Turner, Alexandre Lacoste, Aaron Courville category:stat.ML cs.AI cs.LG  published:2017-10-13 summary:We propose Bayesian hypernetworks: a framework for approximate Bayesian inference in neural networks. A Bayesian hypernetwork, $h$, is a neural network which learns to transform a simple noise distribution, $p(\epsilon) = \mathcal{N}(0,I)$, to a distribution $q(\theta) \doteq q(h(\epsilon))$ over the parameters $\theta$ of another neural network (the "primary network"). We train $q$ with variational inference, using an invertible $h$ to enable efficient estimation of the variational lower bound on the posterior $p(\theta \mathcal{D})$ via sampling. In contrast to most methods for Bayesian deep learning, Bayesian hypernets can represent a complex multimodal approximate posterior with correlations between parameters, while enabling cheap i.i.d. sampling of $q(\theta)$. We demonstrate these qualitative advantages of Bayesian hypernets, which also achieve competitive performance on a suite of tasks that demonstrate the advantage of estimating model uncertainty, including active learning and anomaly detection. version:1
arxiv-1710-04071 | Automatic Salient Object Detection for Panoramic Images Using Region Growing and Fixation Prediction Model | http://arxiv.org/abs/1710.04071 | id:1710.04071 author:Chunbiao Zhu, Kan Huang, Ge Li category:cs.CV  published:2017-10-10 summary:Most previous works on saliency detection are dedicated to conventional images, however, it is becoming more and more vital to obtain visual attention for panoramic images with the rapid development of VR or AR technology. In this paper, we propose a novel automatic salient object detection framework for panoramic images using region growing and fixation prediction model. First, we employ a spatial density pattern detection method using region growing for the panoramic image to roughly extract the proposal objects. Meanwhile, the eye fixation model is embedded into the framework to predict the visual attention, which simulates the human vision system. Then, the previous saliency information is combined by the maxima normalization to get the coarse saliency map. Finally, a geodesic refinement is utilized to obtain the final saliency map. To fairly evaluate the performance of the proposed framework, we build a new high-quality dataset of panoramic images for the public. Extensive evaluations performed on the new dataset (SalPan) show the superiority of the proposed framework than other methods. version:3
arxiv-1710-04749 | Explaining Aviation Safety Incidents Using Deep Learned Precursors | http://arxiv.org/abs/1710.04749 | id:1710.04749 author:Vijay Manikandan Janakiraman category:cs.CV cs.AI stat.AP stat.ML  published:2017-10-12 summary:Although aviation accidents are rare, safety incidents occur more frequently and require careful analysis for providing actionable recommendations to improve safety. Automatically analyzing safety incidents using flight data is challenging because of the absence of labels on timestep-wise events in a flight, complexity of multi-dimensional data, and lack of scalable tools to perform analysis over large number of events. In this work, we propose a precursor mining algorithm that identifies correlated patterns in multidimensional time series to explain an adverse event. Precursors are valuable to systems health and safety monitoring in explaining and forecasting anomalies. Current precursor mining methods suffer from poor scalability to high dimensional time series data and in capturing long-term memory. We propose an approach by combining multiple-instance learning (MIL) and deep recurrent neural networks (DRNN) to take advantage of MIL's ability to model weakly-supervised data and DRNN's ability to model long term memory processes, to scale well to high dimensional data and to large volumes of data using GPU parallelism. We apply the proposed method to find precursors and offer explanations to high speed exceedance safety incidents using commercial flight data. version:1
arxiv-1710-04748 | HyperENTM: Evolving Scalable Neural Turing Machines through HyperNEAT | http://arxiv.org/abs/1710.04748 | id:1710.04748 author:Jakob Merrild, Mikkel Angaju Rasmussen, Sebastian Risi category:cs.AI cs.NE  published:2017-10-12 summary:Recent developments within memory-augmented neural networks have solved sequential problems requiring long-term memory, which are intractable for traditional neural networks. However, current approaches still struggle to scale to large memory sizes and sequence lengths. In this paper we show how access to memory can be encoded geometrically through a HyperNEAT-based Neural Turing Machine (HyperENTM). We demonstrate that using the indirect HyperNEAT encoding allows for training on small memory vectors in a bit-vector copy task and then applying the knowledge gained from such training to speed up training on larger size memory vectors. Additionally, we demonstrate that in some instances, networks trained to copy bit-vectors of size 9 can be scaled to sizes of 1,000 without further training. While the task in this paper is simple, these results could open up the problems amendable to networks with external memories to problems with larger memory vectors and theoretically unbounded memory sizes. version:1
arxiv-1709-04071 | Variational Reasoning for Question Answering with Knowledge Graph | http://arxiv.org/abs/1709.04071 | id:1709.04071 author:Yuyu Zhang, Hanjun Dai, Zornitsa Kozareva, Alexander J. Smola, Le Song category:cs.LG cs.AI cs.CL  published:2017-09-12 summary:Knowledge graph (KG) is known to be helpful for the task of question answering (QA), since it provides well-structured relational information between entities, and allows one to further infer indirect facts. However, it is challenging to build QA systems which can learn to reason over knowledge graphs based on question-answer pairs alone. First, when people ask questions, their expressions are noisy (for example, typos in texts, or variations in pronunciations), which is non-trivial for the QA system to match those mentioned entities to the knowledge graph. Second, many questions require multi-hop logic reasoning over the knowledge graph to retrieve the answers. To address these challenges, we propose a novel and unified deep learning architecture, and an end-to-end variational learning algorithm which can handle noise in questions, and learn multi-hop reasoning simultaneously. Our method achieves state-of-the-art performance on a recent benchmark dataset in the literature. We also derive a series of new benchmark datasets, including questions for multi-hop reasoning, questions paraphrased by neural translation model, and questions in human voice. Our method yields very promising results on all these challenging datasets. version:3
arxiv-1710-00477 | HUMOR: A Crowd-Annotated Spanish Corpus for Humor Analysis | http://arxiv.org/abs/1710.00477 | id:1710.00477 author:Santiago Castro, Matías Cubero, Diego Garat, Guillermo Moncecchi category:cs.CL  published:2017-10-02 summary:Computational Humor, as the name implies, studies humor from a computational perspective, and it fosters several tasks, such as humor recognition, humor generation and humor scoring. The area has been little explored, making it attractive to tackle by novel Natural Language Processing and Machine Learning techniques. However, human-curated data is necessary. In this work we present a corpus of almost 40,000 tweets written in Spanish and crowd-annotated by their humor and funniness value with respect to several people on the Internet. It is equally divided between tweets coming from humorous accounts and from non-humorous accounts. There is certain humor value agreement between the raters, with a Krippendorff's alpha value of 0.3654, that allows building a humor classifier upon it. However, it shows an absence of agreement in the funniness value. The dataset is available for general usage and has already been used successfully for humor recognition. Additionally, more aspects of the dataset are analyzed in this paper, such as the distribution by the number of annotations and by categories. version:2
arxiv-1710-04744 | Can the early human visual system compete with Deep Neural Networks? | http://arxiv.org/abs/1710.04744 | id:1710.04744 author:Samuel Dodge, Lina Karam category:cs.CV  published:2017-10-12 summary:We study and compare the human visual system and state-of-the-art deep neural networks on classification of distorted images. Different from previous works, we limit the display time to 100ms to test only the early mechanisms of the human visual system, without allowing time for any eye movements or other higher level processes. Our findings show that the human visual system still outperforms modern deep neural networks under blurry and noisy images. These findings motivate future research into developing more robust deep networks. version:1
arxiv-1710-04735 | On the Runtime-Efficacy Trade-off of Anomaly Detection Techniques for Real-Time Streaming Data | http://arxiv.org/abs/1710.04735 | id:1710.04735 author:Dhruv Choudhary, Arun Kejariwal, Francois Orsini category:stat.ML cs.IR cs.LG eess.SP  published:2017-10-12 summary:Ever growing volume and velocity of data coupled with decreasing attention span of end users underscore the critical need for real-time analytics. In this regard, anomaly detection plays a key role as an application as well as a means to verify data fidelity. Although the subject of anomaly detection has been researched for over 100 years in a multitude of disciplines such as, but not limited to, astronomy, statistics, manufacturing, econometrics, marketing, most of the existing techniques cannot be used as is on real-time data streams. Further, the lack of characterization of performance -- both with respect to real-timeliness and accuracy -- on production data sets makes model selection very challenging. To this end, we present an in-depth analysis, geared towards real-time streaming data, of anomaly detection techniques. Given the requirements with respect to real-timeliness and accuracy, the analysis presented in this paper should serve as a guide for selection of the "best" anomaly detection technique. To the best of our knowledge, this is the first characterization of anomaly detection techniques proposed in very diverse set of fields, using production data sets corresponding to a wide set of application domains. version:1
arxiv-1710-04734 | STDP Based Pruning of Connections and Weight Quantization in Spiking Neural Networks for Energy Efficient Recognition | http://arxiv.org/abs/1710.04734 | id:1710.04734 author:Nitin Rathi, Priyadarshini Panda, Kaushik Roy category:cs.NE  published:2017-10-12 summary:Spiking Neural Networks (SNNs) with a large number of weights and varied weight distribution can be difficult to implement in emerging in-memory computing hardware due to the limitations on crossbar size (implementing dot product), the constrained number of conductance levels in non-CMOS devices and the power budget. We present a sparse SNN topology where non-critical connections are pruned to reduce the network size and the remaining critical synapses are weight quantized to accommodate for limited conductance levels. Pruning is based on the power law weight-dependent Spike Timing Dependent Plasticity (STDP) model; synapses between pre- and post-neuron with high spike correlation are retained, whereas synapses with low correlation or uncorrelated spiking activity are pruned. The weights of the retained connections are quantized to the available number of conductance levels. The process of pruning non-critical connections and quantizing the weights of critical synapses is performed at regular intervals during training. We evaluated our sparse and quantized network on MNIST dataset and on a subset of images from Caltech-101 dataset. The compressed topology achieved a classification accuracy of 90.1% (91.6%) on the MNIST (Caltech-101) dataset with 3.1x (2.2x) and 4x (2.6x) improvement in energy and area, respectively. The compressed topology is energy and area efficient while maintaining the same classification accuracy of a 2-layer fully connected SNN topology. version:1
arxiv-1710-04725 | Hyperparameter Importance Across Datasets | http://arxiv.org/abs/1710.04725 | id:1710.04725 author:J. N. van Rijn, F. Hutter category:stat.ML cs.LG  published:2017-10-12 summary:With the advent of automated machine learning, automated hyperparameter optimization methods are by now routinely used. However, this progress is not yet matched by equal progress on automatic analyses that yield information beyond performance-optimizing hyperparameter settings. In this work, we aim to answer the following two questions: Given an algorithm, what are generally its most important hyperparameters, and what are good priors over their hyperparameters' ranges to draw values from? We present methodology and a framework to answer these questions based on meta-learning across many datasets. We apply this methodology using the experimental meta-data available on OpenML to determine the most important hyperparameters of support vector machines, random forests and Adaboost, and to infer priors for all their hyperparameters. Our results, obtained fully automatically, provide a quantitative basis to focus efforts in both manual algorithm design and in automated hyperparameter optimization. Our experiments confirm that the selected hyperparameters are indeed the most important ones and that our obtained priors also lead to improvements in hyperparameter optimization. version:1
arxiv-1710-05749 | Hardware design for binarization and thinning of fingerprint images | http://arxiv.org/abs/1710.05749 | id:1710.05749 author:Farshad Kheiri, Shadrokh Samavi, Nader Karimi category:cs.CV cs.AR  published:2017-10-12 summary:Two critical steps in fingerprint recognition are binarization and thinning of the image. The need for real time processing motivates us to select local adaptive thresholding approach for the binarization step. We introduce a new hardware for this purpose based on pipeline architecture. We propose a formula for selecting an optimal block size for the thresholding purpose. To decrease minutiae false detection, the binarized image is dilated. We also present in this paper a new pipeline structure for implementing the thinning algorithm version:1
arxiv-1706-03008 | An Ensemble Deep Learning Based Approach for Red Lesion Detection in Fundus Images | http://arxiv.org/abs/1706.03008 | id:1706.03008 author:José Ignacio Orlando, Elena Prokofyeva, Mariana del Fresno, Matthew B. Blaschko category:cs.CV  published:2017-06-09 summary:Diabetic retinopathy is one of the leading causes of preventable blindness in the world. Its earliest sign are red lesions, a general term that groups both microaneurysms and hemorrhages. In daily clinical practice, these lesions are manually detected by physicians using fundus photographs. However, this task is tedious and time consuming, and requires an intensive effort due to the small size of the lesions and their lack of contrast. Computer-assisted diagnosis of DR based on red lesion detection is being actively explored due to its improvement effects both in clinicians consistency and accuracy. Several methods for detecting red lesions have been proposed in the literature, most of them based on characterizing lesion candidates using hand crafted features, and classifying them into true or false positive detections. Deep learning based approaches, by contrast, are scarce in this domain due to the high expense of annotating the lesions manually. In this paper we propose a novel method for red lesion detection based on combining both deep learned and domain knowledge. Features learned by a CNN are augmented by incorporating hand crafted features. Such ensemble vector of descriptors is used afterwards to identify true lesion candidates using a Random Forest classifier. We empirically observed that combining both sources of information significantly improve results with respect to using each approach separately. Furthermore, our method reported the highest performance on a per-lesion basis on DIARETDB1 and e-ophtha, and for screening and need for referral on MESSIDOR compared to a second human expert. Results highlight the fact that integrating manually engineered approaches with deep learned features is relevant to improve results when the networks are trained from lesion-level annotated data. An open source implementation of our system is publicly available online. version:2
arxiv-1710-03740 | Mixed Precision Training | http://arxiv.org/abs/1710.03740 | id:1710.03740 author:Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, Hao Wu category:cs.AI cs.LG stat.ML  published:2017-10-10 summary:Deep neural networks have enabled progress in a wide variety of applications. Growing the size of the neural network typically results in improved accuracy. As model sizes grow, the memory and compute requirements for training these models also increases. We introduce a technique to train deep neural networks using half precision floating point numbers. In our technique, weights, activations and gradients are stored in IEEE half-precision format. Half-precision floating numbers have limited numerical range compared to single-precision numbers. We propose two techniques to handle this loss of information. Firstly, we recommend maintaining a single-precision copy of the weights that accumulates the gradients after each optimizer step. This single-precision copy is rounded to half-precision format during training. Secondly, we propose scaling the loss appropriately to handle the loss of information with half-precision gradients. We demonstrate that this approach works for a wide variety of models including convolution neural networks, recurrent neural networks and generative adversarial networks. This technique works for large scale models with more than 100 million parameters trained on large datasets. Using this approach, we can reduce the memory consumption of deep learning models by nearly 2x. In future processors, we can also expect a significant computation speedup using half-precision hardware units. version:2
arxiv-1710-04689 | Social Attention: Modeling Attention in Human Crowds | http://arxiv.org/abs/1710.04689 | id:1710.04689 author:Anirudh Vemula, Katharina Muelling, Jean Oh category:cs.RO cs.LG  published:2017-10-12 summary:Robots that navigate through human crowds need to be able to plan safe, efficient, and human predictable trajectories. This is a particularly challenging problem as it requires the robot to predict future human trajectories within a crowd where everyone implicitly cooperates with each other to avoid collisions. Previous approaches to human trajectory prediction have modeled the interactions between humans as a function of proximity. However, that is not necessarily true as some people in our immediate vicinity moving in the same direction might not be as important as other people that are further away, but that might collide with us in the future. In this work, we propose Social Attention, a novel trajectory prediction model that captures the relative importance of each person when navigating in the crowd, irrespective of their proximity. We demonstrate the performance of our method against a state-of-the-art approach on two publicly available crowd datasets and analyze the trained attention model to gain a better understanding of which surrounding agents humans attend to, when navigating in a crowd. version:1
arxiv-1710-04681 | Hyperspectral band selection using genetic algorithm and support vector machines for early identification of charcoal rot disease in soybean | http://arxiv.org/abs/1710.04681 | id:1710.04681 author:Koushik Nagasubramanian, Sarah Jones, Soumik Sarkar, Asheesh K. Singh, Arti Singh, Baskar Ganapathysubramanian category:cs.CV  published:2017-10-12 summary:Charcoal rot is a fungal disease that thrives in warm dry conditions and affects the yield of soybeans and other important agronomic crops worldwide. There is a need for robust, automatic and consistent early detection and quantification of disease symptoms which are important in breeding programs for the development of improved cultivars and in crop production for the implementation of disease control measures for yield protection. Current methods of plant disease phenotyping are predominantly visual and hence are slow and prone to human error and variation. There has been increasing interest in hyperspectral imaging applications for early detection of disease symptoms. However, the high dimensionality of hyperspectral data makes it very important to have an efficient analysis pipeline in place for the identification of disease so that effective crop management decisions can be made. The focus of this work is to determine the minimal number of most effective hyperspectral bands that can distinguish between healthy and diseased specimens early in the growing season. Healthy and diseased hyperspectral data cubes were captured at 3, 6, 9, 12, and 15 days after inoculation. We utilized inoculated and control specimens from 4 different genotypes. Each hyperspectral image was captured at 240 different wavelengths in the range of 383 to 1032 nm. We used a combination of genetic algorithm as an optimizer and support vector machines as a classifier for identification of maximally effective band combinations. A binary classification between healthy and infected samples using six selected band combinations obtained a classification accuracy of 97% and a F1 score of 0.97 for the infected class. The results demonstrated that these carefully chosen bands are more informative than RGB images, and could be used in a multispectral camera for remote identification of charcoal rot infection in soybean. version:1
arxiv-1710-04677 | Game-Theoretic Design of Secure and Resilient Distributed Support Vector Machines with Adversaries | http://arxiv.org/abs/1710.04677 | id:1710.04677 author:Rui Zhang, Quanyan Zhu category:stat.ML cs.GT  published:2017-10-12 summary:With a large number of sensors and control units in networked systems, distributed support vector machines (DSVMs) play a fundamental role in scalable and efficient multi-sensor classification and prediction tasks. However, DSVMs are vulnerable to adversaries who can modify and generate data to deceive the system to misclassification and misprediction. This work aims to design defense strategies for DSVM learner against a potential adversary. We establish a game-theoretic framework to capture the conflicting interests between the DSVM learner and the attacker. The Nash equilibrium of the game allows predicting the outcome of learning algorithms in adversarial environments, and enhancing the resilience of the machine learning through dynamic distributed learning algorithms. We show that the DSVM learner is less vulnerable when he uses a balanced network with fewer nodes and higher degree. We also show that adding more training samples is an efficient defense strategy against an attacker. We present secure and resilient DSVM algorithms with verification method and rejection method, and show their resiliency against adversary with numerical experiments. version:1
arxiv-1710-04647 | Progressive Representation Adaptation for Weakly Supervised Object Localization | http://arxiv.org/abs/1710.04647 | id:1710.04647 author:Dong Li, Jia-Bin Huang, Yali Li, Shengjin Wang, Ming-Hsuan Yang category:cs.CV  published:2017-10-12 summary:We address the problem of weakly supervised object localization where only image-level annotations are available for training object detectors. Numerous methods have been proposed to tackle this problem through mining object proposals. However, a substantial amount of noise in object proposals causes ambiguities for learning discriminative object models. Such approaches are sensitive to model initialization and often converge to undesirable local minimum solutions. In this paper, we propose to overcome these drawbacks by progressive representation adaptation with two main steps: 1) classification adaptation and 2) detection adaptation. In classification adaptation, we transfer a pre-trained network to a multi-label classification task for recognizing the presence of a certain object in an image. Through the classification adaptation step, the network learns discriminative representations that are specific to object categories of interest. In detection adaptation, we mine class-specific object proposals by exploiting two scoring strategies based on the adapted classification network. Class-specific proposal mining helps remove substantial noise from the background clutter and potential confusion from similar objects. We further refine these proposals using multiple instance learning and segmentation cues. Using these refined object bounding boxes, we fine-tune all the layer of the classification network and obtain a fully adapted detection network. We present detailed experimental validation on the PASCAL VOC and ILSVRC datasets. Experimental results demonstrate that our progressive representation adaptation algorithm performs favorably against the state-of-the-art methods. version:1
arxiv-1709-06310 | Hybrid, Frame and Event based Visual Inertial Odometry for Robust, Autonomous Navigation of Quadrotors | http://arxiv.org/abs/1709.06310 | id:1709.06310 author:Antoni Rosinol Vidal, Henri Rebecq, Timo Horstschaefer, Davide Scaramuzza category:cs.CV cs.RO  published:2017-09-19 summary:Event cameras are bio-inspired vision sensors that output pixel-level brightness changes instead of standard intensity frames. These cameras do not suffer from motion blur and have a very high dynamic range, which enables them to provide reliable visual information during high speed motions or in scenes characterized by high dynamic range. However, event cameras output only little information when the amount of motion is limited, such as in the case of almost still motion. Conversely, standard cameras provide instant and rich information about the environment most of the time (in low-speed and good lighting scenarios), but they fail severely in case of fast motions, or difficult lighting such as high dynamic range or low light scenes. In this paper, we present the first state estimation pipeline that leverages the complementary advantages of these two sensors by fusing in a tightly-coupled manner events, standard frames, and inertial measurements. We show on the publicly available Event Camera Dataset that our hybrid pipeline leads to an accuracy improvement of 130% over event-only pipelines, and 85% over standard-frames-only visual-inertial systems, while still being computationally tractable. Furthermore, we use our pipeline to demonstrate - to the best of our knowledge - the first autonomous quadrotor flight using an event camera for state estimation, unlocking flight scenarios that were not reachable with traditional visual-inertial odometry, such as low-light environments and high-dynamic range scenes. version:3
arxiv-1710-04623 | Analysis of planar ornament patterns via motif asymmetry assumption and local connections | http://arxiv.org/abs/1710.04623 | id:1710.04623 author:Venera Adanova, Sibel Tari category:cs.CV  published:2017-10-12 summary:Planar ornaments, a.k.a. wallpapers, are regular repetitive patterns which exhibit translational symmetry in two independent directions. There are exactly $17$ distinct planar symmetry groups. We present a fully automatic method for complete analysis of planar ornaments in $13$ of these groups, specifically, the groups called $p6m, \, p6, \, p4g, \,p4m, \,p4, \, p31m, \,p3m, \, p3, \, cmm, \, pgg, \, pg, \, p2$ and $p1$. Given the image of an ornament fragment, we present a method to simultaneously classify the input into one of the $13$ groups and extract the so called fundamental domain (FD), the minimum region that is sufficient to reconstruct the entire ornament. A nice feature of our method is that even when the given ornament image is a small portion such that it does not contain multiple translational units, the symmetry group as well as the fundamental domain can still be defined. This is because, in contrast to common approach, we do not attempt to first identify a global translational repetition lattice. Though the presented constructions work for quite a wide range of ornament patterns, a key assumption we make is that the perceivable motifs (shapes that repeat) alone do not provide clues for the underlying symmetries of the ornament. In this sense, our main target is the planar arrangements of asymmetric interlocking shapes, as in the symmetry art of Escher. version:1
arxiv-1710-04615 | Deep Imitation Learning for Complex Manipulation Tasks from Virtual Reality Teleoperation | http://arxiv.org/abs/1710.04615 | id:1710.04615 author:Tianhao Zhang, Zoe McCarthy, Owen Jow, Dennis Lee, Ken Goldberg, Pieter Abbeel category:cs.LG cs.RO  published:2017-10-12 summary:Imitation learning is a powerful paradigm for robot skill acquisition. However, obtaining demonstrations suitable for learning a policy that maps from raw pixels to actions can be challenging. In this paper we describe how consumer-grade Virtual Reality headsets and hand tracking hardware can be used to naturally teleoperate robots to perform complex tasks. We also describe how imitation learning can learn deep neural network policies (mapping from pixels to actions) that can acquire the demonstrated skills. Our experiments showcase the effectiveness of our approach for learning visuomotor skills. version:1
arxiv-1710-04600 | Auto Analysis of Customer Feedback using CNN and GRU Network | http://arxiv.org/abs/1710.04600 | id:1710.04600 author:Deepak Gupta, Pabitra Lenka, Harsimran Bedi, Asif Ekbal, Pushpak Bhattacharyya category:cs.CL  published:2017-10-12 summary:Analyzing customer feedback is the best way to channelize the data into new marketing strategies that benefit entrepreneurs as well as customers. Therefore an automated system which can analyze the customer behavior is in great demand. Users may write feedbacks in any language, and hence mining appropriate information often becomes intractable. Especially in a traditional feature-based supervised model, it is difficult to build a generic system as one has to understand the concerned language for finding the relevant features. In order to overcome this, we propose deep Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) based approaches that do not require handcrafting of features. We evaluate these techniques for analyzing customer feedback sentences in four languages, namely English, French, Japanese and Spanish. Our empirical analysis shows that our models perform well in all the four languages on the setups of IJCNLP Shared Task on Customer Feedback Analysis. Our model achieved the second rank in French, with an accuracy of 71.75% and third ranks for all the other languages. version:1
arxiv-1710-04584 | Towards Scalable Spectral Clustering via Spectrum-Preserving Sparsification | http://arxiv.org/abs/1710.04584 | id:1710.04584 author:Yongyu Wang, Zhuo Feng category:cs.LG cs.AI stat.ML  published:2017-10-12 summary:The eigendeomposition of nearest-neighbor (NN) graph Laplacian matrices is the main computational bottleneck in spectral clustering. In this work, we introduce a highly-scalable, spectrum-preserving graph sparsification algorithm that enables to build ultra-sparse NN (u-NN) graphs with guaranteed preservation of the original graph spectrums, such as the first few eigenvectors of the original graph Laplacian. Our approach can immediately lead to scalable spectral clustering of large data networks without sacrificing solution quality. The proposed method starts from constructing low-stretch spanning trees (LSSTs) from the original graphs, which is followed by iteratively recovering small portions of "spectrally critical" off-tree edges to the LSSTs by leveraging a spectral off-tree embedding scheme. To determine the suitable amount of off-tree edges to be recovered to the LSSTs, an eigenvalue stability checking scheme is proposed, which enables to robustly preserve the first few Laplacian eigenvectors within the sparsified graph. Additionally, an incremental graph densification scheme is proposed for identifying extra edges that have been missing in the original NN graphs but can still play important roles in spectral clustering tasks. Our experimental results for a variety of well-known data sets show that the proposed method can dramatically reduce the complexity of NN graphs, leading to significant speedups in spectral clustering. version:1
arxiv-1710-04582 | Is Epicurus the father of Reinforcement Learning? | http://arxiv.org/abs/1710.04582 | id:1710.04582 author:Eleni Vasilaki category:cs.LG cs.AI stat.ML  published:2017-10-12 summary:The Epicurean Philosophy is commonly thought as simplistic and hedonistic. Here I discuss how this is a misconception and explore its link to Reinforcement Learning. Based on the letters of Epicurus, I construct an objective function for hedonism which turns out to be equivalent of the Reinforcement Learning objective function when omitting the discount factor. I then discuss how Plato and Aristotle 's views that can be also loosely linked to Reinforcement Learning, as well as their weaknesses in relationship to it. Finally, I emphasise the close affinity of the Epicurean views and the Bellman equation. version:1
arxiv-1710-04580 | Additivity of Information in Multilayer Networks via Additive Gaussian Noise Transforms | http://arxiv.org/abs/1710.04580 | id:1710.04580 author:Galen Reeves category:cs.IT cs.LG math.IT stat.ML  published:2017-10-12 summary:Multilayer (or deep) networks are powerful probabilistic models based on multiple stages of a linear transform followed by a non-linear (possibly random) function. In general, the linear transforms are defined by matrices and the non-linear functions are defined by information channels. These models have gained great popularity due to their ability to characterize complex probabilistic relationships arising in a wide variety of inference problems. The contribution of this paper is a new method for analyzing the fundamental limits of statistical inference in settings where the model is known. The validity of our method can be established in a number of settings and is conjectured to hold more generally. A key assumption made throughout is that the matrices are drawn randomly from orthogonally invariant distributions. Our method yields explicit formulas for 1) the mutual information; 2) the minimum mean-squared error (MMSE); 3) the existence and locations of certain phase-transitions with respect to the problem parameters; and 4) the stationary points for the state evolution of approximate message passing algorithms. When applied to the special case of models with multivariate Gaussian channels our method is rigorous and has close connections to free probability theory for random matrices. When applied to the general case of non-Gaussian channels, our method provides a simple alternative to the replica method from statistical physics. A key observation is that the combined effects of the individual components in the model (namely the matrices and the channels) are additive when viewed in a certain transform domain. version:1
arxiv-1710-04556 | New efficient algorithms for multiple change-point detection with kernels | http://arxiv.org/abs/1710.04556 | id:1710.04556 author:Alain Celisse, Guillemette Marot, Morgane Pierre-Jean, Guillem Rigaill category:math.ST stat.CO stat.ML stat.TH  published:2017-10-12 summary:Several statistical approaches based on reproducing kernels have been proposed to detect abrupt changes arising in the full distribution of the observations and not only in the mean or variance. Some of these approaches enjoy good statistical properties (oracle inequality, \ldots). Nonetheless, they have a high computational cost both in terms of time and memory. This makes their application difficult even for small and medium sample sizes ($n< 10^4$). This computational issue is addressed by first describing a new efficient and exact algorithm for kernel multiple change-point detection with an improved worst-case complexity that is quadratic in time and linear in space. It allows dealing with medium size signals (up to $n \approx 10^5$). Second, a faster but approximation algorithm is described. It is based on a low-rank approximation to the Gram matrix. It is linear in time and space. This approximation algorithm can be applied to large-scale signals ($n \geq 10^6$). These exact and approximation algorithms have been implemented in \texttt{R} and \texttt{C} for various kernels. The computational and statistical performances of these new algorithms have been assessed through empirical experiments. The runtime of the new algorithms is observed to be faster than that of other considered procedures. Finally, simulations confirmed the higher statistical accuracy of kernel-based approaches to detect changes that are not only in the mean. These simulations also illustrate the flexibility of kernel-based approaches to analyze complex biological profiles made of DNA copy number and allele B frequencies. An R package implementing the approach will be made available on github. version:1
arxiv-1710-04540 | Hierarchical Convolutional-Deconvolutional Neural Networks for Automatic Liver and Tumor Segmentation | http://arxiv.org/abs/1710.04540 | id:1710.04540 author:Yading Yuan category:cs.CV  published:2017-10-12 summary:Automatic segmentation of liver and its tumors is an essential step for extracting quantitative imaging biomarkers for accurate tumor detection, diagnosis, prognosis and assessment of tumor response to treatment. MICCAI 2017 Liver Tumor Segmentation Challenge (LiTS) provides a common platform for comparing different automatic algorithms on contrast-enhanced abdominal CT images in tasks including 1) liver segmentation, 2) liver tumor segmentation, and 3) tumor burden estimation. We participate this challenge by developing a hierarchical framework based on deep fully convolutional-deconvolutional neural networks (CDNN). A simple CDNN model is firstly trained to provide a quick but coarse segmentation of the liver on the entire CT volume, then another CDNN is applied to the liver region for fine liver segmentation. At last, the segmented liver region, which is enhanced by histogram equalization, is employed as an additional input to the third CDNN for tumor segmentation. Jaccard distance is used as loss function when training CDNN models to eliminate the need of sample re-weighting. Our framework is trained using the 130 challenge training cases provided by LiTS. The evaluation on the 70 challenge testing cases resulted in a mean Dice Similarity Coefficient (DSC) of 0.963 for liver segmentation, a mean DSC of 0.657 for tumor segmentation, and a root mean square error (RMSE) of 0.017 for tumor burden estimation, which ranked our method in the first, fifth and third place, respectively version:1
arxiv-1710-04521 | Subjectively Interesting Subgroup Discovery on Real-valued Targets | http://arxiv.org/abs/1710.04521 | id:1710.04521 author:Jefrey Lijffijt, Bo Kang, Wouter Duivesteijn, Kai Puolamäki, Emilia Oikarinen, Tijl De Bie category:stat.ML cs.IT math.IT  published:2017-10-12 summary:Deriving insights from high-dimensional data is one of the core problems in data mining. The difficulty mainly stems from the fact that there are exponentially many variable combinations to potentially consider, and there are infinitely many if we consider weighted combinations, even for linear combinations. Hence, an obvious question is whether we can automate the search for interesting patterns and visualizations. In this paper, we consider the setting where a user wants to learn as efficiently as possible about real-valued attributes. For example, to understand the distribution of crime rates in different geographic areas in terms of other (numerical, ordinal and/or categorical) variables that describe the areas. We introduce a method to find subgroups in the data that are maximally informative (in the formal Information Theoretic sense) with respect to a single or set of real-valued target attributes. The subgroup descriptions are in terms of a succinct set of arbitrarily-typed other attributes. The approach is based on the Subjective Interestingness framework FORSIED to enable the use of prior knowledge when finding most informative non-redundant patterns, and hence the method also supports iterative data mining. version:1
arxiv-1710-04515 | Convolutional Attention-based Seq2Seq Neural Network for End-to-End ASR | http://arxiv.org/abs/1710.04515 | id:1710.04515 author:Dan Lim category:cs.CL  published:2017-10-12 summary:This thesis introduces the sequence to sequence model with Luong's attention mechanism for end-to-end ASR. It also describes various neural network algorithms including Batch normalization, Dropout and Residual network which constitute the convolutional attention-based seq2seq neural network. Finally the proposed model proved its effectiveness for speech recognition achieving 15.8% phoneme error rate on TIMIT dataset. version:1
arxiv-1710-04486 | Multimodal Observation and Interpretation of Subjects Engaged in Problem Solving | http://arxiv.org/abs/1710.04486 | id:1710.04486 author:Thomas Guntz, Raffaella Balzarini, Dominique Vaufreydaz, James L. Crowley category:cs.HC cs.CV stat.ML  published:2017-10-12 summary:In this paper we present the first results of a pilot experiment in the capture and interpretation of multimodal signals of human experts engaged in solving challenging chess problems. Our goal is to investigate the extent to which observations of eye-gaze, posture, emotion and other physiological signals can be used to model the cognitive state of subjects, and to explore the integration of multiple sensor modalities to improve the reliability of detection of human displays of awareness and emotion. We observed chess players engaged in problems of increasing difficulty while recording their behavior. Such recordings can be used to estimate a participant's awareness of the current situation and to predict ability to respond effectively to challenging situations. Results show that a multimodal approach is more accurate than a unimodal one. By combining body posture, visual attention and emotion, the multimodal approach can reach up to 93% of accuracy when determining player's chess expertise while unimodal approach reaches 86%. Finally this experiment validates the use of our equipment as a general and reproducible tool for the study of participants engaged in screen-based interaction and/or problem solving. version:1
arxiv-1710-04476 | VOIDD: automatic vessel of intervention dynamic detection in PCI procedures | http://arxiv.org/abs/1710.04476 | id:1710.04476 author:Ketan Bacchuwar, Jean Cousty, Régis Vaillant, Laurent Najman category:cs.CV  published:2017-10-12 summary:In this article, we present the work towards improving the overall workflow of the Percutaneous Coronary Interventions (PCI) procedures by capacitating the imaging instruments to precisely monitor the steps of the procedure. In the long term, such capabilities can be used to optimize the image acquisition to reduce the amount of dose or contrast media employed during the procedure. We present the automatic VOIDD algorithm to detect the vessel of intervention which is going to be treated during the procedure by combining information from the vessel image with contrast agent injection and images acquired during guidewire tip navigation. Due to the robust guidewire tip segmentation method, this algorithm is also able to automatically detect the sequence corresponding to guidewire navigation. We present an evaluation methodology which characterizes the correctness of the guide wire tip detection and correct identification of the vessel navigated during the procedure. On a dataset of 2213 images from 8 sequences of 4 patients, VOIDD identifies vessel-of-intervention with accuracy in the range of 88% or above and absence of tip with accuracy in range of 98% or above depending on the test case. version:1
arxiv-1710-04177 | The Social Bow Tie | http://arxiv.org/abs/1710.04177 | id:1710.04177 author:Heather Mattie, Kenth Engø-Monsen, Rich Ling, Jukka-Pekka Onnela category:cs.SI physics.soc-ph stat.ML  published:2017-10-11 summary:Understanding tie strength in social networks, and the factors that influence it, have received much attention in a myriad of disciplines for decades. Several models incorporating indicators of tie strength have been proposed and used to quantify relationships in social networks, and a standard set of structural network metrics have been applied to predominantly online social media sites to predict tie strength. Here, we introduce the concept of the "social bow tie" framework, a small subgraph of the network that consists of a collection of nodes and ties that surround a tie of interest, forming a topological structure that resembles a bow tie. We also define several intuitive and interpretable metrics that quantify properties of the bow tie. We use random forests and regression models to predict categorical and continuous measures of tie strength from different properties of the bow tie, including nodal attributes. We also investigate what aspects of the bow tie are most predictive of tie strength in two distinct social networks: a collection of 75 rural villages in India and a nationwide call network of European mobile phone users. Our results indicate several of the bow tie metrics are highly predictive of tie strength, and we find the more the social circles of two individuals overlap, the stronger their tie, consistent with previous findings. However, we also find that the more tightly-knit their non-overlapping social circles, the weaker the tie. This new finding complements our current understanding of what drives the strength of ties in social networks. version:2
arxiv-1710-04462 | Effects of Images with Different Levels of Familiarity on EEG | http://arxiv.org/abs/1710.04462 | id:1710.04462 author:Ali Saeedi, Ehsan Arbabi category:stat.ML q-bio.NC  published:2017-10-12 summary:Evaluating human brain potentials during watching different images can be used for memory evaluation, information retrieving, guilty-innocent identification and examining the brain response. In this study, the effects of watching images, with different levels of familiarity, on subjects' Electroencephalogram (EEG) have been studied. Three different groups of images with three familiarity levels of "unfamiliar", "familiar" and "very familiar" have been considered for this study. EEG signals of 21 subjects (14 men) were recorded. After signal acquisition, pre-processing, including noise and artifact removal, were performed on epochs of data. Features, including spatial-statistical, wavelet, frequency and harmonic parameters, and also correlation between recording channels, were extracted from the data. Then, we evaluated the efficiency of the extracted features by using p-value and also an orthogonal feature selection method (combination of Gram-Schmitt method and Fisher discriminant ratio) for feature dimensional reduction. As the final step of feature selection, we used 'add-r take-away l' method for choosing the most discriminative features. For data classification, including all two-class and three-class cases, we applied Support Vector Machine (SVM) on the extracted features. The correct classification rates (CCR) for "unfamiliar-familiar", "unfamiliar-very familiar" and "familiar-very familiar" cases were 85.6%, 92.6%, and 70.6%, respectively. The best results of classifications were obtained in pre-frontal and frontal regions of brain. Also, wavelet, frequency and harmonic features were among the most discriminative features. Finally, in three-class case, the best CCR was 86.8%. version:1
arxiv-1710-04461 | An Improved Naive Bayes Classifier-based Noise Detection Technique for Classifying User Phone Call Behavior | http://arxiv.org/abs/1710.04461 | id:1710.04461 author:Iqbal H. Sarker, Muhammad Ashad Kabir, Alan Colman, Jun Han category:cs.LG cs.SI stat.ML  published:2017-10-12 summary:The presence of noisy instances in mobile phone data is a fundamental issue for classifying user phone call behavior (i.e., accept, reject, missed and outgoing), with many potential negative consequences. The classification accuracy may decrease and the complexity of the classifiers may increase due to the number of redundant training samples. To detect such noisy instances from a training dataset, researchers use naive Bayes classifier (NBC) as it identifies misclassified instances by taking into account independence assumption and conditional probabilities of the attributes. However, some of these misclassified instances might indicate usages behavioral patterns of individual mobile phone users. Existing naive Bayes classifier based noise detection techniques have not considered this issue and, thus, are lacking in classification accuracy. In this paper, we propose an improved noise detection technique based on naive Bayes classifier for effectively classifying users' phone call behaviors. In order to improve the classification accuracy, we effectively identify noisy instances from the training dataset by analyzing the behavioral patterns of individuals. We dynamically determine a noise threshold according to individual's unique behavioral patterns by using both the naive Bayes classifier and Laplace estimator. We use this noise threshold to identify noisy instances. To measure the effectiveness of our technique in classifying user phone call behavior, we employ the most popular classification algorithm (e.g., decision tree). Experimental results on the real phone call log dataset show that our proposed technique more accurately identifies the noisy instances from the training datasets that leads to better classification accuracy. version:1
arxiv-1709-09345 | A Read-Write Memory Network for Movie Story Understanding | http://arxiv.org/abs/1709.09345 | id:1709.09345 author:Seil Na, Sangho Lee, Jisung Kim, Gunhee Kim category:cs.CV cs.CL  published:2017-09-27 summary:We propose a novel memory network model named Read-Write Memory Network (RWMN) to perform question and answering tasks for large-scale, multimodal movie story understanding. The key focus of our RWMN model is to design the read network and the write network that consist of multiple convolutional layers, which enable memory read and write operations to have high capacity and flexibility. While existing memory-augmented network models treat each memory slot as an independent block, our use of multi-layered CNNs allows the model to read and write sequential memory cells as chunks, which is more reasonable to represent a sequential story because adjacent memory blocks often have strong correlations. For evaluation, we apply our model to all the six tasks of the MovieQA benchmark, and achieve the best accuracies on several tasks, especially on the visual QA task. Our model shows a potential to better understand not only the content in the story, but also more abstract information, such as relationships between characters and the reasons for their actions. version:2
arxiv-1710-04450 | Self-Taught Support Vector Machine | http://arxiv.org/abs/1710.04450 | id:1710.04450 author:Parvin Razzaghi category:cs.CV cs.LG stat.ML  published:2017-10-12 summary:In this paper, a new approach for classification of target task using limited labeled target data as well as enormous unlabeled source data is proposed which is called self-taught learning. The target and source data can be drawn from different distributions. In the previous approaches, covariate shift assumption is considered where the marginal distributions p(x) change over domains and the conditional distributions p(y x) remain the same. In our approach, we propose a new objective function which simultaneously learns a common space T(.) where the conditional distributions over domains p(T(x) y) remain the same and learns robust SVM classifiers for target task using both source and target data in the new representation. Hence, in the proposed objective function, the hidden label of the source data is also incorporated. We applied the proposed approach on Caltech-256, MSRC+LMO datasets and compared the performance of our algorithm to the available competing methods. Our method has a superior performance to the successful existing algorithms. version:1
arxiv-1709-04212 | Real Log Canonical Threshold of General Stochastic Matrix Factorization for Markov Chain and Bayesian Network | http://arxiv.org/abs/1709.04212 | id:1709.04212 author:Naoki Hayashi, Sumio Watanabe category:math.ST cs.LG stat.ML stat.TH  published:2017-09-13 summary:Stochastic matrix factorization (SMF) has proposed and it can be understood as a restriction to non-negative matrix factorization (NMF). SMF is useful for inference of topic models, NMF for binary matrices data, and Bayesian Network. However, it needs some strong assumption to reach unique factorization in SMF and also theoretical prediction accuracy has not yet clarified. In this paper, we study the maximum pole of zeta function of SMF and derive an upper bound of the generalization error in Bayesian inference. This results give the foundation of establishing widely applicable and rigorous factorization method for SMF and mean that the generalization error in SMF can become smaller than regular statistical models by Bayesian inference. version:2
arxiv-1710-04437 | Revisiting the Design Issues of Local Models for Japanese Predicate-Argument Structure Analysis | http://arxiv.org/abs/1710.04437 | id:1710.04437 author:Yuichiroh Matsubayashi, Kentaro Inui category:cs.CL  published:2017-10-12 summary:The research trend in Japanese predicate-argument structure (PAS) analysis is shifting from pointwise prediction models with local features to global models designed to search for globally optimal solutions. However, the existing global models tend to employ only relatively simple local features; therefore, the overall performance gains are rather limited. The importance of designing a local model is demonstrated in this study by showing that the performance of a sophisticated local model can be considerably improved with recent feature embedding methods and a feature combination learning based on a neural network, outperforming the state-of-the-art global models in $F_1$ on a common benchmark dataset. version:1
arxiv-1707-09198 | Data-Driven Stochastic Robust Optimization: A General Computational Framework and Algorithm for Optimization under Uncertainty in the Big Data Era | http://arxiv.org/abs/1707.09198 | id:1707.09198 author:Chao Ning, Fengqi You category:cs.LG cs.AI math.OC  published:2017-07-28 summary:A novel data-driven stochastic robust optimization (DDSRO) framework is proposed to systematically and automatically handle labeled multi-class uncertainty data in optimization problems. Uncertainty realizations in large datasets are often collected from various conditions, which are encoded by class labels. A group of Dirichlet process mixture models is employed for uncertainty modeling from the multi-class uncertainty data. The proposed data-driven nonparametric uncertainty model could automatically adjust its complexity based on the data structure and complexity, thus accurately capturing the uncertainty information. A DDSRO framework is further proposed based on the data-driven uncertainty model through a bi-level optimization structure. The outer optimization problem follows a two-stage stochastic programming approach to optimize the expected objective across different classes of data; robust optimization is nested as the inner problem to ensure the robustness of the solution while maintaining computational tractability. A tailored column-and-constraint generation algorithm is further developed to solve the resulting multi-level optimization problem efficiently. Case studies on strategic planning of process networks are presented to demonstrate the applicability of the proposed framework. version:3
arxiv-1710-04423 | Multi-Batch Experience Replay for Fast Convergence of Continuous Action Control | http://arxiv.org/abs/1710.04423 | id:1710.04423 author:Seungyul Han, Youngchul Sung category:cs.LG  published:2017-10-12 summary:Policy gradient methods for direct policy optimization are widely considered to obtain optimal policies in continuous Markov decision process (MDP) environments. However, policy gradient methods require exponentially many samples as the dimension of the action space increases. Thus, off-policy learning with experience replay is proposed to enable the agent to learn by using samples of other policies. Generally, large replay memories are preferred to minimize the sample correlation but large replay memories can yield large bias or variance in importance-sampling-based off-policy learning. In this paper, we propose a multi batch experience replay scheme suitable for off-policy actor-critic-style policy gradient methods such as the proximal policy optimization (PPO) algorithm, which maintains the advantages of experience replay and accelerates learning without causing large bias. To demonstrate the superiority of the proposed method, we apply the proposed experience replay scheme to the PPO algorithm and various continuous control tasks. Numerical results show that our algorithm converges faster and closer to the global optimum than other policy gradient methods. version:1
arxiv-1710-04089 | Quantized Minimum Error Entropy Criterion | http://arxiv.org/abs/1710.04089 | id:1710.04089 author:Badong Chen, Lei Xing, Nanning Zheng, Jose C. Príncipe category:stat.ML cs.LG  published:2017-10-11 summary:Comparing with traditional learning criteria, such as mean square error (MSE), the minimum error entropy (MEE) criterion is superior in nonlinear and non-Gaussian signal processing and machine learning. The argument of the logarithm in Renyis entropy estimator, called information potential (IP), is a popular MEE cost in information theoretic learning (ITL). The computational complexity of IP is however quadratic in terms of sample number due to double summation. This creates computational bottlenecks especially for large-scale datasets. To address this problem, in this work we propose an efficient quantization approach to reduce the computational burden of IP, which decreases the complexity from O(N*N) to O (MN) with M << N. The new learning criterion is called the quantized MEE (QMEE). Some basic properties of QMEE are presented. Illustrative examples are provided to verify the excellent performance of QMEE. version:2
arxiv-1709-02270 | Adaptive Real-Time Removal of Impulse Noise in Medical Images | http://arxiv.org/abs/1709.02270 | id:1709.02270 author:Zohreh HosseinKhani, Mohsen Hajabdollahi, Nader Karimi, Reza Soroushmehr, Shahram Shirani, Kayvan Najarian, Shadrokh Samavi category:cs.CV  published:2017-09-06 summary:Noise is an important factor that degrades the quality of medical images. Impulse noise is a common noise, which is caused by malfunctioning of sensor elements or errors in the transmission of images. In medical images due to presence of white foreground and black background, many pixels have intensities similar to impulse noise and distinction between noisy and regular pixels is difficult. In software techniques, the accuracy of the noise removal is more important than the algorithm's complexity. But for hardware implementation having a low complexity algorithm with an acceptable accuracy is essential. In this paper a low complexity de-noising method is proposed that removes the noise by local analysis of the image blocks. The proposed method distinguishes non-noisy pixels that have noise-like intensities. All steps are designed to have low hardware complexity. Simulation results show that for different magnetic resonance images, the proposed method removes impulse noise with an acceptable accuracy. version:2
arxiv-1710-04394 | Provably Fair Representations | http://arxiv.org/abs/1710.04394 | id:1710.04394 author:Daniel McNamara, Cheng Soon Ong, Robert C. Williamson category:cs.LG  published:2017-10-12 summary:Machine learning systems are increasingly used to make decisions about people's lives, such as whether to give someone a loan or whether to interview someone for a job. This has led to considerable interest in making such machine learning systems fair. One approach is to transform the input data used by the algorithm. This can be achieved by passing each input data point through a representation function prior to its use in training or testing. Techniques for learning such representation functions from data have been successful empirically, but typically lack theoretical fairness guarantees. We show that it is possible to prove that a representation function is fair according to common measures of both group and individual fairness, as well as useful with respect to a target task. These provable properties can be used in a governance model involving a data producer, a data user and a data regulator, where there is a separation of concerns between fairness and target task utility to ensure transparency and prevent perverse incentives. We formally define the 'cost of mistrust' of using this model compared to the setting where there is a single trusted party, and provide bounds on this cost in particular cases. We present a practical approach to learning fair representation functions and apply it to financial and criminal justice datasets. We evaluate the fairness and utility of these representation functions using measures motivated by our theoretical results. version:1
arxiv-1710-03996 | A Simple Yet Efficient Rank One Update for Covariance Matrix Adaptation | http://arxiv.org/abs/1710.03996 | id:1710.03996 author:Zhenhua Li, Qingfu Zhang category:cs.NE  published:2017-10-11 summary:In this paper, we propose an efficient approximated rank one update for covariance matrix adaptation evolution strategy (CMA-ES). It makes use of two evolution paths as simple as that of CMA-ES, while avoiding the computational matrix decomposition. We analyze the algorithms' properties and behaviors. We experimentally study the proposed algorithm's performances. It generally outperforms or performs competitively to the Cholesky CMA-ES. version:2
arxiv-1710-04382 | Marginal sequential Monte Carlo for doubly intractable models | http://arxiv.org/abs/1710.04382 | id:1710.04382 author:Richard G. Everitt, Dennis Prangle, Philip Maybank, Mark Bell category:stat.CO cs.AI physics.data-an stat.ME stat.ML  published:2017-10-12 summary:Bayesian inference for models that have an intractable partition function is known as a doubly intractable problem, where standard Monte Carlo methods are not applicable. The past decade has seen the development of auxiliary variable Monte Carlo techniques (M{\o}ller et al., 2006; Murray et al., 2006) for tackling this problem; these approaches being members of the more general class of pseudo-marginal, or exact-approximate, Monte Carlo algorithms (Andrieu and Roberts, 2009), which make use of unbiased estimates of intractable posteriors. Everitt et al. (2017) investigated the use of exact-approximate importance sampling (IS) and sequential Monte Carlo (SMC) in doubly intractable problems, but focussed only on SMC algorithms that used data-point tempering. This paper describes SMC samplers that may use alternative sequences of distributions, and describes ways in which likelihood estimates may be improved adaptively as the algorithm progresses, building on ideas from Moores et al. (2015). This approach is compared with a number of alternative algorithms for doubly intractable problems, including approximate Bayesian computation (ABC), which we show is closely related to the method of M{\o}ller et al. (2006). version:1
arxiv-1710-04380 | Sign-Constrained Regularized Loss Minimization | http://arxiv.org/abs/1710.04380 | id:1710.04380 author:Tsuyoshi Kato, Misato Kobayashi, Daisuke Sano category:cs.LG cs.AI  published:2017-10-12 summary:In practical analysis, domain knowledge about analysis target has often been accumulated, although, typically, such knowledge has been discarded in the statistical analysis stage, and the statistical tool has been applied as a black box. In this paper, we introduce sign constraints that are a handy and simple representation for non-experts in generic learning problems. We have developed two new optimization algorithms for the sign-constrained regularized loss minimization, called the sign-constrained Pegasos (SC-Pega) and the sign-constrained SDCA (SC-SDCA), by simply inserting the sign correction step into the original Pegasos and SDCA, respectively. We present theoretical analyses that guarantee that insertion of the sign correction step does not degrade the convergence rate for both algorithms. Two applications, where the sign-constrained learning is effective, are presented. The one is exploitation of prior information about correlation between explanatory variables and a target variable. The other is introduction of the sign-constrained to SVM-Pairwise method. Experimental results demonstrate significant improvement of generalization performance by introducing sign constraints in both applications. version:1
arxiv-1710-04374 | Fast, Accurate and Fully Parallelizable Digital Image Correlation | http://arxiv.org/abs/1710.04374 | id:1710.04374 author:Peihan Tu category:cs.CV physics.ins-det  published:2017-10-12 summary:Digital image correlation (DIC) is a widely used optical metrology for surface deformation measurements. DIC relies on nonlinear optimization method. Thus an initial guess is quite important due to its influence on the converge characteristics of the algorithm. In order to obtain a reliable, accurate initial guess, a reliability-guided digital image correlation (RG-DIC) method, which is able to intelligently obtain a reliable initial guess without using time-consuming integer-pixel registration, was proposed. However, the RG-DIC and its improved methods are path-dependent and cannot be fully parallelized. Besides, it is highly possible that RG-DIC fails in the full-field analysis of deformation without manual intervention if the deformation fields contain large areas of discontinuous deformation. Feature-based initial guess is highly robust while it is relatively time-consuming. Recently, path-independent algorithm, fast Fourier transform-based cross correlation (FFT-CC) algorithm, was proposed to estimate the initial guess. Complete parallelizability is the major advantage of the FFT-CC algorithm, while it is sensitive to small deformation. Wu et al proposed an efficient integer-pixel search scheme, but the parameters of this algorithm are set by the users empirically. In this technical note, a fully parallelizable DIC method is proposed. Different from RG-DIC method, the proposed method divides DIC algorithm into two parts: full-field initial guess estimation and sub-pixel registration. The proposed method has the following benefits: 1) providing a pre-knowledge of deformation fields; 2) saving computational time; 3) reducing error propagation; 4) integratability with well-established DIC algorithms; 5) fully parallelizability. version:1
arxiv-1710-04373 | Deep Learning in Multiple Multistep Time Series Prediction | http://arxiv.org/abs/1710.04373 | id:1710.04373 author:Chuanyun Zang category:stat.ML cs.LG  published:2017-10-12 summary:The project aims to research on combining deep learning specifically Long-Short Memory (LSTM) and basic statistics in multiple multistep time series prediction. LSTM can dive into all the pages and learn the general trends of variation in a large scope, while the well selected medians for each page can keep the special seasonality of different pages so that the future trend will not fluctuate too much from the reality. A recent Kaggle competition on 145K Web Traffic Time Series Forecasting [1] is used to thoroughly illustrate and test this idea. version:1
arxiv-1710-04359 | Fast initial guess estimation for digital image correlation | http://arxiv.org/abs/1710.04359 | id:1710.04359 author:Peihan Tu category:cs.CV physics.ins-det physics.optics  published:2017-10-12 summary:Digital image correlation (DIC) is a widely used optical metrology for quantitative deformation measurement due to its non-contact, low-cost, highly precise feature. DIC relies on nonlinear optimization algorithm. Thus it is quite important to efficiently obtain a reliable initial guess. The most widely used method for obtaining initial guess is reliability-guided digital image correlation (RG-DIC) method, which is reliable but path-dependent. This path-dependent method limits the further improvement of computation speed of DIC using parallel computing technology, and error of calculation may be spread out along the calculation path. Therefore, a reliable and path-independent algorithm which is able to provide reliable initial guess is desirable to reach full potential of the ability of parallel computing. In this paper, an algorithm used for initial guess estimation is proposed. Numerical and real experiments show that the proposed algorithm, adaptive incremental dissimilarity approximations algorithm (A-IDA), has the following characteristics: 1) Compared with inverse compositional Gauss-Newton (IC-GN) sub-pixel registration algorithm, the computational time required by A-IDA algorithm is negligible, especially when subset size is relatively large; 2) the efficiency of A-IDA algorithm is less influenced by search range; 3) the efficiency is less influenced by subset size; 4) it is easy to select the threshold for the proposed algorithm. version:1
arxiv-1709-03637 | Capturing Long-range Contextual Dependencies with Memory-enhanced Conditional Random Fields | http://arxiv.org/abs/1709.03637 | id:1709.03637 author:Fei Liu, Timothy Baldwin, Trevor Cohn category:cs.CL  published:2017-09-12 summary:Despite successful applications across a broad range of NLP tasks, conditional random fields ("CRFs"), in particular the linear-chain variant, are only able to model local features. While this has important benefits in terms of inference tractability, it limits the ability of the model to capture long-range dependencies between items. Attempts to extend CRFs to capture long-range dependencies have largely come at the cost of computational complexity and approximate inference. In this work, we propose an extension to CRFs by integrating external memory, taking inspiration from memory networks, thereby allowing CRFs to incorporate information far beyond neighbouring steps. Experiments across two tasks show substantial improvements over strong CRF and LSTM baselines. version:2
arxiv-1710-04200 | Joint Image Filtering with Deep Convolutional Networks | http://arxiv.org/abs/1710.04200 | id:1710.04200 author:Yijun Li, Jia-Bin Huang, Narendra Ahuja, Ming-Hsuan Yang category:cs.CV  published:2017-10-11 summary:Joint image filters leverage the guidance image as a prior and transfer the structural details from the guidance image to the target image for suppressing noise or enhancing spatial resolution. Existing methods either rely on various explicit filter constructions or hand-designed objective functions, thereby making it difficult to understand, improve, and accelerate these filters in a coherent framework. In this paper, we propose a learning-based approach for constructing joint filters based on Convolutional Neural Networks. In contrast to existing methods that consider only the guidance image, the proposed algorithm can selectively transfer salient structures that are consistent with both guidance and target images. We show that the model trained on a certain type of data, e.g., RGB and depth images, generalizes well to other modalities, e.g., flash/non-Flash and RGB/NIR images. We validate the effectiveness of the proposed joint filter through extensive experimental evaluations with state-of-the-art methods. version:2
arxiv-1710-04350 | A Unified Neural Network Approach for Estimating Travel Time and Distance for a Taxi Trip | http://arxiv.org/abs/1710.04350 | id:1710.04350 author:Ishan Jindal, Tony, Qin, Xuewen Chen, Matthew Nokleby, Jieping Ye category:stat.ML cs.LG  published:2017-10-12 summary:In building intelligent transportation systems such as taxi or rideshare services, accurate prediction of travel time and distance is crucial for customer experience and resource management. Using the NYC taxi dataset, which contains taxi trips data collected from GPS-enabled taxis [23], this paper investigates the use of deep neural networks to jointly predict taxi trip time and distance. We propose a model, called ST-NN (Spatio-Temporal Neural Network), which first predicts the travel distance between an origin and a destination GPS coordinate, then combines this prediction with the time of day to predict the travel time. The beauty of ST-NN is that it uses only the raw trips data without requiring further feature engineering and provides a joint estimate of travel time and distance. We compare the performance of ST-NN to that of state-of-the-art travel time estimation methods, and we observe that the proposed approach generalizes better than state-of-the-art methods. We show that ST-NN approach significantly reduces the mean absolute error for both predicted travel time and distance, about 17% for travel time prediction. We also observe that the proposed approach is more robust to outliers present in the dataset by testing the performance of ST-NN on the datasets with and without outliers. version:1
arxiv-1710-04346 | A Finite Element Computational Framework for Active Contours on Graphs | http://arxiv.org/abs/1710.04346 | id:1710.04346 author:Nikolaos Kolotouros, Petros Maragos category:cs.CV  published:2017-10-12 summary:In this paper we present a new framework for the solution of active contour models on graphs. With the use of the Finite Element Method we generalize active contour models on graphs and reduce the problem from a partial differential equation to the solution of a sparse non-linear system. Additionally, we extend the proposed framework to solve models where the curve evolution is locally constrained around its current location. Based on the previous extension, we propose a fast algorithm for the solution of a wide range active contour models. Last, we present a supervised extension of Geodesic Active Contours for image segmentation and provide experimental evidence for the effectiveness of our framework. version:1
arxiv-1710-04344 | Using Context Events in Neural Network Models for Event Temporal Status Identification | http://arxiv.org/abs/1710.04344 | id:1710.04344 author:Zeyu Dai, Wenlin Yao, Ruihong Huang category:cs.CL  published:2017-10-12 summary:Focusing on the task of identifying event temporal status, we find that events directly or indirectly governing the target event in a dependency tree are most important contexts. Therefore, we extract dependency chains containing context events and use them as input in neural network models, which consistently outperform previous models using local context words as input. Visualization verifies that the dependency chain representation can effectively capture the context events which are closely related to the target event and play key roles in predicting event temporal status. version:1
arxiv-1710-04908 | Graph Convolutional Networks for Classification with a Structured Label Space | http://arxiv.org/abs/1710.04908 | id:1710.04908 author:Meihao Chen, Zhuoru Lin, Kyunghyun Cho category:cs.LG stat.ML  published:2017-10-12 summary:It is a usual practice to ignore any structural information underlying classes in multi-class classification. In this paper, we propose a graph convolutional network (GCN) augmented neural network classifier to exploit a known, underlying graph structure of labels. The proposed approach resembles an (approximate) inference procedure in, for instance, a conditional random field (CRF), however without losing any modelling flexibility. The proposed method can easily scale up to thousands of labels. We evaluate the proposed approach on the problems of document classification and object recognition and report both accuracies and graph-theoretic metrics that correspond to the consistency of the model's prediction. The experiment results reveal that the proposed model outperforms a baseline method which ignores the graph structures of a label space. version:1
arxiv-1709-02253 | Linear vs Nonlinear Extreme Learning Machine for Spectral-Spatial Classification of Hyperspectral Image | http://arxiv.org/abs/1709.02253 | id:1709.02253 author:Faxian Cao, Zhijing Yang, Jinchang Ren, Mengying Jiang, Wing-Kuen Ling category:cs.CV cs.LG  published:2017-09-05 summary:As a new machine learning approach, extreme learning machine (ELM) has received wide attentions due to its good performances. However, when directly applied to the hyperspectral image (HSI) classification, the recognition rate is too low. This is because ELM does not use the spatial information which is very important for HSI classification. In view of this, this paper proposes a new framework for spectral-spatial classification of HSI by combining ELM with loopy belief propagation (LBP). The original ELM is linear, and the nonlinear ELMs (or Kernel ELMs) are the improvement of linear ELM (LELM). However, based on lots of experiments and analysis, we found out that the LELM is a better choice than nonlinear ELM for spectral-spatial classification of HSI. Furthermore, we exploit the marginal probability distribution that uses the whole information in the HSI and learn such distribution using the LBP. The proposed method not only maintain the fast speed of ELM, but also greatly improves the accuracy of classification. The experimental results in the well-known HSI data sets, Indian Pines and Pavia University, demonstrate the good performances of the proposed method. version:2
arxiv-1710-04340 | Learning Koopman Invariant Subspaces for Dynamic Mode Decomposition | http://arxiv.org/abs/1710.04340 | id:1710.04340 author:Naoya Takeishi, Yoshinobu Kawahara, Takehisa Yairi category:cs.LG math.DS stat.ML  published:2017-10-12 summary:Spectral decomposition of the Koopman operator is attracting attention as a tool for the analysis of nonlinear dynamical systems. Dynamic mode decomposition is a popular numerical algorithm for Koopman spectral analysis; however, we often need to prepare nonlinear observables manually according to the underlying dynamics, which is not always possible since we may not have any a priori knowledge about them. In this paper, we propose a fully data-driven method for Koopman spectral analysis based on the principle of learning Koopman invariant subspaces from observed data. To this end, we propose minimization of the residual sum of squares of linear least-squares regression to estimate a set of functions that transforms data into a form in which the linear regression fits well. We introduce an implementation with neural networks and evaluate performance empirically using nonlinear dynamical systems and applications. version:1
arxiv-1710-04334 | DisSent: Sentence Representation Learning from Explicit Discourse Relations | http://arxiv.org/abs/1710.04334 | id:1710.04334 author:Allen Nie, Erin D. Bennett, Noah D. Goodman category:cs.CL cs.AI  published:2017-10-12 summary:Sentence vectors represent an appealing approach to meaning: learn an embedding that encompasses the meaning of a sentence in a single vector, that can be used for a variety of semantic tasks. Existing models for learning sentence embeddings either require extensive computational resources to train on large corpora, or are trained on costly, manually curated datasets of sentence relations. We observe that humans naturally annotate the relations between their sentences with discourse markers like "but" and "because". These words are deeply linked to the meanings of the sentences they connect. Using this natural signal, we automatically collect a classification dataset from unannotated text. Training a model to predict these discourse markers yields high quality sentence embeddings. Our model captures complementary information to existing models and achieves comparable generalization performance to state of the art models. version:1
arxiv-1710-04329 | Efficient Data-Driven Geologic Feature Detection from Pre-stack Seismic Measurements using Randomized Machine-Learning Algorithm | http://arxiv.org/abs/1710.04329 | id:1710.04329 author:Youzuo Lin, Shusen Wang, Jayaraman Thiagarajan, George Guthrie, David Coblentz category:cs.LG stat.ML  published:2017-10-11 summary:Conventional seismic techniques for detecting the subsurface geologic features are challenged by limited data coverage, computational inefficiency, and subjective human factors. We developed a novel data-driven geological feature detection approach based on pre-stack seismic measurements. Our detection method employs an efficient and accurate machine-learning detection approach to extract useful subsurface geologic features automatically. Specifically, our method is based on kernel ridge regression model. The conventional kernel ridge regression can be computationally prohibited because of the large volume of seismic measurements. We employ a data reduction technique in combination with the conventional kernel ridge regression method to improve the computational efficiency and reduce memory usage. In particular, we utilize a randomized numerical linear algebra technique, named Nystr\"om method, to effectively reduce the dimensionality of the feature space without compromising the information content required for accurate detection. We provide thorough computational cost analysis to show efficiency of our new geological feature detection methods. We further validate the performance of our new subsurface geologic feature detection method using synthetic surface seismic data for 2D acoustic and elastic velocity models. Our numerical examples demonstrate that our new detection method significantly improves the computational efficiency while maintaining comparable accuracy. Interestingly, we show that our method yields a speed-up ratio on the order of $\sim10^2$ to $\sim 10^3$ in a multi-core computational environment. version:1
arxiv-1710-04328 | What Would a Graph Look Like in This Layout? A Machine Learning Approach to Large Graph Visualization | http://arxiv.org/abs/1710.04328 | id:1710.04328 author:Oh-Hyun Kwon, Tarik Crnovrsanin, Kwan-Liu Ma category:cs.SI cs.CG cs.GR stat.ML  published:2017-10-11 summary:Using different methods for laying out a graph can lead to very different visual appearances, with which the viewer perceives different information. Selecting a "good" layout method is thus important for visualizing a graph. The selection can be highly subjective and dependent on the given task. A common approach to selecting a good layout is to use aesthetic criteria and visual inspection. However, fully calculating various layouts and their associated aesthetic metrics is computationally expensive. In this paper, we present a machine learning approach to large graph visualization based on computing the topological similarity of graphs using graph kernels. For a given graph, our approach can show what the graph would look like in different layouts and estimate their corresponding aesthetic metrics. An important contribution of our work is the development of a new framework to design graph kernels. Our experimental study shows that our estimation calculation is considerably faster than computing the actual layouts and their aesthetic metrics. Also, our graph kernels outperform the state-of-the-art ones in both time and accuracy. In addition, we conducted a user study to demonstrate that the topological similarity computed with our graph kernel matches perceptual similarity assessed by human users. version:1
arxiv-1710-01992 | Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks | http://arxiv.org/abs/1710.01992 | id:1710.01992 author:Wei-Sheng Lai, Jia-Bin Huang, Narendra Ahuja, Ming-Hsuan Yang category:cs.CV  published:2017-10-04 summary:Convolutional neural networks have recently demonstrated high-quality reconstruction for single image super-resolution. However, existing methods often require a large number of network parameters and entail heavy computational loads at runtime for generating high-accuracy super-resolution results. In this paper, we propose the deep Laplacian Pyramid Super-Resolution Network for fast and accurate image super-resolution. The proposed network progressively reconstructs the sub-band residuals of high-resolution images at multiple pyramid levels. In contrast to existing methods that involve the bicubic interpolation for pre-processing (which results in large feature maps), the proposed method directly extracts features from the low-resolution input space and thereby entails low computational loads. We train the proposed network with deep supervision using the robust Charbonnier loss functions and achieve high-quality image reconstruction. Furthermore, we utilize the recursive layers to share parameters across as well as within pyramid levels, and thus drastically reduce the number of parameters. Extensive quantitative and qualitative evaluations on benchmark datasets show that the proposed algorithm performs favorably against the state-of-the-art methods in terms of run-time and image quality. version:2
arxiv-1710-02245 | The Recurrent Temporal Discriminative Restricted Boltzmann Machines | http://arxiv.org/abs/1710.02245 | id:1710.02245 author:Son N. Tran, Srikanth Cherla, Artur Garcez, Tillman Weyde category:cs.LG stat.ML  published:2017-10-06 summary:The recurrent temporal restricted Boltzmann machine (RTRBM) has been successful in modelling very high dimensional sequences. However, there exists an unsolved question of how such model can be useful for discrimination tasks. The key issue of this is that learning is difficult due to the intractable log-likelihood. In this paper we propose the discriminative variant of RTRBM. We show that discriminative learning is easier than its generative counterparts where exact gradient can be computed analytically. In the experiments we evaluate RTDRBM on sequence modelling and sequence labelling which outperforms other baselines, notably the recurrent neural networks, hidden Markov models, and conditional random fields. More interestingly, the model is comparable to recurrent neural networks with complex memory gates while requiring less parameters. version:2
arxiv-1710-04325 | Improved Coresets for Kernel Density Estimates | http://arxiv.org/abs/1710.04325 | id:1710.04325 author:Jeff M. Phillips, Wai Ming Tai category:cs.LG cs.CG stat.ML  published:2017-10-11 summary:We study the construction of coresets for kernel density estimates. That is we show how to approximate the kernel density estimate described by a large point set with another kernel density estimate with a much smaller point set. For characteristic kernels (including Gaussian and Laplace kernels), our approximation preserves the $L_\infty$ error between kernel density estimates within error $\epsilon$, with coreset size $2/\epsilon^2$, but no other aspects of the data, including the dimension, the diameter of the point set, or the bandwidth of the kernel common to other approximations. When the dimension is unrestricted, we show this bound is tight for these kernels as well as a much broader set. This work provides a careful analysis of the iterative Frank-Wolfe algorithm adapted to this context, an algorithm called \emph{kernel herding}. This analysis unites a broad line of work that spans statistics, machine learning, and geometry. When the dimension $d$ is constant, we demonstrate much tighter bounds on the size of the coreset specifically for Gaussian kernels, showing that it is bounded by the size of the coreset for axis-aligned rectangles. Currently the best known constructive bound is $O(\frac{1}{\epsilon} \log^d \frac{1}{\epsilon})$, and non-constructively, this can be improved by $\sqrt{\log \frac{1}{\epsilon}}$. This improves the best constant dimension bounds polynomially for $d \geq 3$. version:1
arxiv-1710-04312 | Measurement Context Extraction from Text: Discovering Opportunities and Gaps in Earth Science | http://arxiv.org/abs/1710.04312 | id:1710.04312 author:Kyle Hundman, Chris A. Mattmann category:cs.IR cs.AI cs.CL  published:2017-10-11 summary:We propose Marve, a system for extracting measurement values, units, and related words from natural language text. Marve uses conditional random fields (CRF) to identify measurement values and units, followed by a rule-based system to find related entities, descriptors and modifiers within a sentence. Sentence tokens are represented by an undirected graphical model, and rules are based on part-of-speech and word dependency patterns connecting values and units to contextual words. Marve is unique in its focus on measurement context and early experimentation demonstrates Marve's ability to generate high-precision extractions with strong recall. We also discuss Marve's role in refining measurement requirements for NASA's proposed HyspIRI mission, a hyperspectral infrared imaging satellite that will study the world's ecosystems. In general, our work with HyspIRI demonstrates the value of semantic measurement extractions in characterizing quantitative discussion contained in large corpuses of natural language text. These extractions accelerate broad, cross-cutting research and expose scientists new algorithmic approaches and experimental nuances. They also facilitate identification of scientific opportunities enabled by HyspIRI leading to more efficient scientific investment and research. version:1
arxiv-1710-01727 | Privacy-Preserving Deep Inference for Rich User Data on The Cloud | http://arxiv.org/abs/1710.01727 | id:1710.01727 author:Seyed Ali Osia, Ali Shahin Shamsabadi, Ali Taheri, Kleomenis Katevas, Hamid R. Rabiee, Nicholas D. Lane, Hamed Haddadi category:cs.CV cs.AI cs.CR  published:2017-10-04 summary:Deep neural networks are increasingly being used in a variety of machine learning applications applied to rich user data on the cloud. However, this approach introduces a number of privacy and efficiency challenges, as the cloud operator can perform secondary inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger, and more complicated models. In this paper, we present a hybrid approach for breaking down large, complex deep models for cooperative, privacy-preserving analytics. We do this by breaking down the popular deep architectures and fine-tune them in a particular way. We then evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also asses the local inference cost of different layers on a modern handset for mobile applications. Our evaluations show that by using certain kind of fine-tuning and embedding techniques and at a small processing costs, we can greatly reduce the level of information available to unintended tasks applied to the data feature on the cloud, and hence achieving the desired tradeoff between privacy and performance. version:3
arxiv-1710-04273 | Stochastic Gradient Descent in Continuous Time: A Central Limit Theorem | http://arxiv.org/abs/1710.04273 | id:1710.04273 author:Justin Sirignano, Konstantinos Spiliopoulos category:math.PR math.ST q-fin.CP stat.ML stat.TH  published:2017-10-11 summary:Stochastic gradient descent in continuous time (SGDCT) provides a computationally efficient method for the statistical learning of continuous-time models, which are widely used in science, engineering, and finance. The SGDCT algorithm follows a (noisy) descent direction along a continuous stream of data. The parameter updates occur in continuous time and satisfy a stochastic differential equation. This paper analyzes the asymptotic convergence rate of the SGDCT algorithm by proving a central limit theorem for strongly convex objective functions and, under slightly stronger conditions, for non-convex objective functions as well. An L$^p$ convergence rate is also proven for the algorithm in the strongly convex case. version:1
arxiv-1710-04265 | Solutions of Quadratic First-Order ODEs applied to Computer Vision Problems | http://arxiv.org/abs/1710.04265 | id:1710.04265 author:David Casillas-Perez, Daniel Pizarro category:cs.NA cs.CV  published:2017-10-11 summary:The article proves the existence of a maximum of two possible solutions to the initial value problem composed by the planar-perspective equation and an initial condition. This initial value problem has a geometric interpretation. Solutions are curves than pass trough the initial condition which is a point of the plane. version:1
arxiv-1710-04248 | Local Convergence of Proximal Splitting Methods for Rank Constrained Problems | http://arxiv.org/abs/1710.04248 | id:1710.04248 author:Christian Grussler, Pontus Giselsson category:math.OC cs.LG stat.ML  published:2017-10-11 summary:We analyze the local convergence of proximal splitting algorithms to solve optimization problems that are convex besides a rank constraint. For this, we show conditions under which the proximal operator of a function involving the rank constraint is locally identical to the proximal operator of its convex envelope, hence implying local convergence. The conditions imply that the non-convex algorithms locally converge to a solution whenever a convex relaxation involving the convex envelope can be expected to solve the non-convex problem. version:1
arxiv-1710-04238 | Regression-aware decompositions | http://arxiv.org/abs/1710.04238 | id:1710.04238 author:Mark Tygert category:stat.ME cs.LG math.NA  published:2017-10-11 summary:Linear least-squares regression models can inform interpolative decompositions, yielding regression-aware interpolative decompositions. As a bonus, this provides an interpretation as regression-aware principal component analysis for a kind of canonical correlation analysis. The regression-aware decompositions effectively enable supervision to inform classical dimensionality reduction, which classically has been unsupervised. version:1
arxiv-1710-04234 | Maximum Margin Interval Trees | http://arxiv.org/abs/1710.04234 | id:1710.04234 author:Alexandre Drouin, Toby Dylan Hocking, François Laviolette category:stat.ML cs.DS cs.LG stat.AP  published:2017-10-11 summary:Learning a regression function using censored or interval-valued output data is an important problem in fields such as genomics and medicine. The goal is to learn a real-valued prediction function, and the training output labels indicate an interval of possible values. Whereas most existing algorithms for this task are linear models, in this paper we investigate learning nonlinear tree models. We propose to learn a tree by minimizing a margin-based discriminative objective function, and we provide a dynamic programming algorithm for computing the optimal solution in log-linear time. We show empirically that this algorithm achieves state-of-the-art speed and prediction accuracy in a benchmark of several data sets. version:1
arxiv-1710-04170 | Concentration of Multilinear Functions of the Ising Model with Applications to Network Data | http://arxiv.org/abs/1710.04170 | id:1710.04170 author:Constantinos Daskalakis, Nishanth Dikkala, Gautam Kamath category:math.PR cs.LG math-ph math.MP math.ST stat.ML stat.TH  published:2017-10-11 summary:We prove near-tight concentration of measure for polynomial functions of the Ising model under high temperature. For any degree $d$, we show that a degree-$d$ polynomial of a $n$-spin Ising model exhibits exponential tails that scale as $\exp(-r^{2/d})$ at radius $r=\tilde{\Omega}_d(n^{d/2})$. Our concentration radius is optimal up to logarithmic factors for constant $d$, improving known results by polynomial factors in the number of spins. We demonstrate the efficacy of polynomial functions as statistics for testing the strength of interactions in social networks in both synthetic and real world data. version:1
arxiv-1710-04162 | Synkhronos: a Multi-GPU Theano Extension for Data Parallelism | http://arxiv.org/abs/1710.04162 | id:1710.04162 author:Adam Stooke, Pieter Abbeel category:cs.DC cs.AI cs.LG  published:2017-10-11 summary:We present Synkhronos, an extension to Theano for multi-GPU computations leveraging data parallelism. Our framework provides automated execution and synchronization across devices, allowing users to continue to write serial programs without risk of race conditions. The NVIDIA Collective Communication Library is used for high-bandwidth inter-GPU communication. Further enhancements to the Theano function interface include input slicing (with aggregation) and input indexing, which perform common data-parallel computation patterns efficiently. One example use case is synchronous SGD, which has recently been shown to scale well for a growing set of deep learning problems. When training ResNet-50, we achieve a near-linear speedup of 7.5x on an NVIDIA DGX-1 using 8 GPUs, relative to Theano-only code running a single GPU in isolation. Yet Synkhronos remains general to any data-parallel computation programmable in Theano. By implementing parallelism at the level of individual Theano functions, our framework uniquely addresses a niche between manual multi-device programming and prescribed multi-GPU training routines. version:1
arxiv-1708-05929 | Explaining Anomalies in Groups with Characterizing Subspace Rules | http://arxiv.org/abs/1708.05929 | id:1708.05929 author:Meghanath Macha, Leman Akoglu category:cs.LG stat.ML  published:2017-08-20 summary:Anomaly detection has numerous applications and has been studied vastly. We consider a complementary problem that has a much sparser literature: anomaly description. Interpretation of anomalies is crucial for practitioners for sense-making, troubleshooting, and planning actions. To this end, we present a new approach called x-PACS (for eXplaining Patterns of Anomalies with Characterizing Subspaces), which "reverse-engineers" the known anomalies by identifying (1) the groups (or patterns) that they form, and (2) the characterizing subspace and feature rules that separate each anomalous pattern from normal instances. Explaining anomalies in groups not only saves analyst time and gives insight into various types of anomalies, but also draws attention to potentially critical, repeating anomalies. In developing x-PACS, we first construct a desiderata for the anomaly description problem. From a descriptive data mining perspective, our method exhibits five desired properties in our desiderata. Namely, it can unearth anomalous patterns (i) of multiple different types, (ii) hidden in arbitrary subspaces of a high dimensional space, (iii) interpretable by the analysts, (iv) different from normal patterns of the data, and finally (v) succinct, providing the shortest data description. Furthermore, x-PACS is highly parallelizable and scales linearly in terms of data size. No existing work on anomaly description satisfies all of these properties simultaneously. While not our primary goal, the anomalous patterns we find serve as interpretable "signatures" and can be used for detection. We show the effectiveness of x-PACS in explanation as well as detection on real-world datasets as compared to state-of-the-art. version:2
arxiv-1708-05125 | Hyperspectral Unmixing: Ground Truth Labeling, Datasets, Benchmark Performances and Survey | http://arxiv.org/abs/1708.05125 | id:1708.05125 author:Feiyun Zhu category:cs.CV  published:2017-08-17 summary:Hyperspectral unmixing (HU) is a very useful and increasingly popular preprocessing step for a wide range of hyperspectral applications. However, the HU research has been constrained a lot by three factors: (a) the number of hyperspectral images (especially the ones with ground truths) are very limited; (b) the ground truths of most hyperspectral images are not shared on the web, which may cause lots of unnecessary troubles for researchers to evaluate their algorithms; (c) the codes of most state-of-the-art methods are not shared, which may also delay the testing of new methods. Accordingly, this paper deals with the above issues from the following three perspectives: (1) as a profound contribution, we provide a general labeling method for the HU. With it, we labeled up to 15 hyperspectral images, providing 18 versions of ground truths. To the best of our knowledge, this is the first paper to summarize and share up to 15 hyperspectral images and their 18 versions of ground truths for the HU. Observing that the hyperspectral classification (HyC) has much more standard datasets (whose ground truths are generally publicly shared) than the HU, we propose an interesting method to transform the HyC datasets for the HU research. (2) To further facilitate the evaluation of HU methods under different conditions, we reviewed and implemented the algorithm to generate a complex synthetic hyperspectral image. By tuning the hyper-parameters in the code, we may verify the HU methods from four perspectives. The code would also be shared on the web. (3) To provide a standard comparison, we reviewed up to 10 state-of-the-art HU algorithms, then selected the 5 most benchmark HU algorithms, and compared them on the 15 real hyperspectral datasets. The experiment results are surely reproducible; the implemented codes would be shared on the web. version:2
arxiv-1708-06724 | VIGAN: Missing View Imputation with Generative Adversarial Networks | http://arxiv.org/abs/1708.06724 | id:1708.06724 author:Chao Shang, Aaron Palmer, Jiangwen Sun, Ko-Shin Chen, Jin Lu, Jinbo Bi category:cs.CV stat.ML  published:2017-08-22 summary:In an era when big data is becoming the norm, there is less concern with the quantity but more with the quality and completeness of the data. In many disciplines, data are collected from heterogeneous sources, resulting in multi-view or multi-modal datasets. The missing data problem has been challenging to address in multi-view data analysis. Especially, when certain samples miss an entire view of data, it creates the missing view problem. Classic multiple imputations or matrix completion methods are hardly effective here when no information can be based on in the specific view to impute data for such samples. The commonly-used simple method of removing samples with the missing view issue can dramatically reduce sample size, thus diminishing the statistical power of an analysis. In this paper, we propose a novel approach for view imputation via generative adversarial networks (GANs), which we name as VIGAN. This approach first treats each view as a separate domain and identifies domain-to-domain mappings through GANs using randomly-sampled data from each view, and then employs a multi-modal denoising autoencoder (DAE) to reconstruct the missing view from the GAN outputs based on paired data from each view. Then, by optimizing the GANs and DAE jointly, our model enables the knowledge integration learned for domain mappings and view correspondences to effectively recover the missing view. Empirical results on benchmark datasets validate the VIGAN approach by comparing against the state of the art, and an evaluation of VIGAN in a genetic study of substance use disorders further proves the effectiveness and usability of this approach in life science. version:4
arxiv-1710-04142 | Bollywood Movie Corpus for Text, Images and Videos | http://arxiv.org/abs/1710.04142 | id:1710.04142 author:Nishtha Madaan, Sameep Mehta, Mayank Saxena, Aditi Aggarwal, Taneea S Agrawaal, Vrinda Malhotra category:cs.CY cs.CL  published:2017-10-11 summary:In past few years, several data-sets have been released for text and images. We present an approach to create the data-set for use in detecting and removing gender bias from text. We also include a set of challenges we have faced while creating this corpora. In this work, we have worked with movie data from Wikipedia plots and movie trailers from YouTube. Our Bollywood Movie corpus contains 4000 movies extracted from Wikipedia and 880 trailers extracted from YouTube which were released from 1970-2017. The corpus contains csv files with the following data about each movie - Wikipedia title of movie, cast, plot text, co-referenced plot text, soundtrack information, link to movie poster, caption of movie poster, number of males in poster, number of females in poster. In addition to that, corresponding to each cast member the following data is available - cast name, cast gender, cast verbs, cast adjectives, cast relations, cast centrality, cast mentions. We present some preliminary results on the task of bias removal which suggest that the data-set is quite useful for performing such tasks. version:1
arxiv-1709-07979 | Multi-task Learning with Gradient Guided Policy Specialization | http://arxiv.org/abs/1709.07979 | id:1709.07979 author:Wenhao Yu, Greg Turk, C. Karen Liu category:cs.RO cs.AI cs.LG  published:2017-09-23 summary:We present a method for efficient learning of control policies for multiple related robotic motor skills. Our approach consists of two stages, joint training and specialization training. During the joint training stage, a neural network policy is trained with minimal information to disambiguate the motor skills. This forces the policy to learn a common representation of the different tasks. Then, during the specialization training stage we selectively split the weights of the policy based on a per-weight metric that measures the disagreement among the multiple tasks. By splitting part of the control policy, it can be further trained to specialize to each task. To update the control policy during learning, we use Trust Region Policy Optimization with Generalized Advantage Function (TRPOGAE). We propose a modification to the gradient update stage of TRPO to better accommodate multi-task learning scenarios. We evaluate our approach on three continuous motor skill learning problems in simulation: 1) a locomotion task where three single legged robots with considerable difference in shape and size are trained to hop forward, 2) a manipulation task where three robot manipulators with different sizes and joint types are trained to reach different locations in 3D space, and 3) locomotion of a two-legged robot, whose range of motion of one leg is constrained in different ways. We compare our training method to three baselines. The first baseline uses only joint training for the policy, the second trains independent policies for each task, and the last randomly selects weights to split. We show that our approach learns more efficiently than each of the baseline methods. version:2
arxiv-1710-04112 | Recognizing Daily Activities from Egocentric Photo-Streams | http://arxiv.org/abs/1710.04112 | id:1710.04112 author:Alejandro Cartas, Juan Marin, Petia Radeva, Mariella Dimiccoli category:cs.CV  published:2017-10-11 summary:Wearable cameras can gather large amounts of image data that provide rich visual information about the daily activities of the wearer. Motivated by the large number of health applications that could be enabled by the automatic recognition of daily activities, such as lifestyle characterization for habit improvement, context-aware personal assistance and tele-rehabilitation services, we propose a system to classify 21 daily activities from photo-streams acquired by a wearable photo-camera. Our approach combines the advantages of a Late Fusion Ensemble strategy relying on convolutional neural networks at image level with the ability of recurrent neural networks to account for the temporal evolution of high level features in photo-streams. The proposed method was tested on a set of 44,902 egocentric images and achieved an overall accuracy of 87.07%, outperforming state of the art end-to-end methodologies. version:1
arxiv-1710-04110 | Discrete Event, Continuous Time RNNs | http://arxiv.org/abs/1710.04110 | id:1710.04110 author:Michael C. Mozer, Denis Kazakov, Robert V. Lindsey category:cs.NE cs.LG I.2.6  published:2017-10-11 summary:We investigate recurrent neural network architectures for event-sequence processing. Event sequences, characterized by discrete observations stamped with continuous-valued times of occurrence, are challenging due to the potentially wide dynamic range of relevant time scales as well as interactions between time scales. We describe four forms of inductive bias that should benefit architectures for event sequences: temporal locality, position and scale homogeneity, and scale interdependence. We extend the popular gated recurrent unit (GRU) architecture to incorporate these biases via intrinsic temporal dynamics, obtaining a continuous-time GRU. The CT-GRU arises by interpreting the gates of a GRU as selecting a time scale of memory, and the CT-GRU generalizes the GRU by incorporating multiple time scales of memory and performing context-dependent selection of time scales for information storage and retrieval. Event time-stamps drive decay dynamics of the CT-GRU, whereas they serve as generic additional inputs to the GRU. Despite the very different manner in which the two models consider time, their performance on eleven data sets we examined is essentially identical. Our surprising results point both to the robustness of GRU and LSTM architectures for handling continuous time, and to the potency of incorporating continuous dynamics into neural architectures. version:1
arxiv-1710-04102 | Combining learned and analytical models for predicting action effects | http://arxiv.org/abs/1710.04102 | id:1710.04102 author:Alina Kloss, Stefan Schaal, Jeannette Bohg category:cs.RO cs.LG  published:2017-10-11 summary:One of the most basic skills a robot should possess is predicting the effect of physical interactions with objects in the environment. This enables optimal action selection to reach a certain goal state. Traditionally, these dynamics are described by physics-based analytical models, which may however be very hard to find for complex problems. More recently, we have seen learning approaches that can predict the effect of more complex physical interactions directly from sensory input. However, it is an open question how far these models generalize beyond their training data. In this work, we analyse how analytical and learned models can be combined to leverage the best of both worlds. As physical interaction task, we use planar pushing, for which there exists a well-known analytical model and a large real-world dataset. We propose to use a neural network to convert the raw sensory data into a suitable representation that can be consumed by the analytical model and compare this approach to using neural networks for both, perception and prediction. Our results show that the combined method outperforms the purely learned version in terms of accuracy and generalization to push actions not seen during training. It also performs comparable to the analytical model applied on ground truth input values, despite using raw sensory data as input. version:1
arxiv-1710-04099 | Wembedder: Wikidata entity embedding web service | http://arxiv.org/abs/1710.04099 | id:1710.04099 author:Finn Årup Nielsen category:stat.ML cs.CL cs.LG I.2.4; H.3.5  published:2017-10-11 summary:I present a web service for querying an embedding of entities in the Wikidata knowledge graph. The embedding is trained on the Wikidata dump using Gensim's Word2Vec implementation and a simple graph walk. A REST API is implemented. Together with the Wikidata API the web service exposes a multilingual resource for over 600'000 Wikidata items and properties. version:1
arxiv-1710-05719 | Lung Cancer Screening Using Adaptive Memory-Augmented Recurrent Networks | http://arxiv.org/abs/1710.05719 | id:1710.05719 author:Aryan Mobiny, Supratik Moulik, Ilker Gurcan, Tanay Shah, Hien Van Nguyen category:cs.CV cs.LG  published:2017-10-11 summary:In this paper, we investigate the effectiveness of deep learning techniques for lung nodule classification in computed tomography scans. Using less than 10,000 training examples, our deep networks perform two times better than a standard radiology software. Visualization of the networks' neurons reveals semantically meaningful features that are consistent with the clinical knowledge and radiologists' perception. Our paper also proposes a novel framework for rapidly adapting deep networks to the radiologists' feedback, or change in the data due to the shift in sensor's resolution or patient population. The classification accuracy of our approach remains above 80% while popular deep networks' accuracy is around chance. Finally, we provide in-depth analysis of our framework by asking a radiologist to examine important networks' features and perform blind re-labeling of networks' mistakes. version:1
arxiv-1710-04097 | Local Radon Descriptors for Image Search | http://arxiv.org/abs/1710.04097 | id:1710.04097 author:Morteza Babaie, H. R. Tizhoosh, Amin Khatami, M. E. Shiri category:cs.CV  published:2017-10-11 summary:Radon transform and its inverse operation are important techniques in medical imaging tasks. Recently, there has been renewed interest in Radon transform for applications such as content-based medical image retrieval. However, all studies so far have used Radon transform as a global or quasi-global image descriptor by extracting projections of the whole image or large sub-images. This paper attempts to show that the dense sampling to generate the histogram of local Radon projections has a much higher discrimination capability than the global one. In this paper, we introduce Local Radon Descriptor (LRD) and apply it to the IRMA dataset, which contains 14,410 x-ray images as well as to the INRIA Holidays dataset with 1,990 images. Our results show significant improvement in retrieval performance by using LRD versus its global version. We also demonstrate that LRD can deliver results comparable to well-established descriptors like LBP and HOG. version:1
arxiv-1710-04484 | Dimensionality Reduction Ensembles | http://arxiv.org/abs/1710.04484 | id:1710.04484 author:Colleen M. Farrelly category:stat.ML stat.AP  published:2017-10-11 summary:Ensemble learning has had many successes in supervised learning, but it has been rare in unsupervised learning and dimensionality reduction. This study explores dimensionality reduction ensembles, using principal component analysis and manifold learning techniques to capture linear, nonlinear, local, and global features in the original dataset. Dimensionality reduction ensembles are tested first on simulation data and then on two real medical datasets using random forest classifiers; results suggest the efficacy of this approach, with accuracies approaching that of the full dataset. Limitations include computational cost of some algorithms with strong performance, which may be ameliorated through distributed computing and the development of more efficient versions of these algorithms. version:1
arxiv-1710-04087 | Word Translation Without Parallel Data | http://arxiv.org/abs/1710.04087 | id:1710.04087 author:Alexis Conneau, Guillaume Lample, Marc'Aurelio Ranzato, Ludovic Denoyer, Hervé Jégou category:cs.CL  published:2017-10-11 summary:State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent works showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally show that our method is a first step towards fully unsupervised machine translation and describe experiments on the English-Esperanto language pair, on which there only exists a limited amount of parallel data. version:1
arxiv-1710-04073 | Stream Graphs and Link Streams for the Modeling of Interactions over Time | http://arxiv.org/abs/1710.04073 | id:1710.04073 author:Matthieu Latapy, Tiphaine Viard, Clémence Magnien category:cs.SI cs.DM cs.DS physics.data-an stat.ML  published:2017-10-11 summary:Graph theory provides a language for studying the structure of relations, and it is often used to study interactions over time too. However, it poorly captures the both temporal and structural nature of interactions, that calls for a dedicated formalism. In this paper, we generalize graph concepts in order to cope with both aspects in a consistent way. We start with elementary concepts like density, clusters, or paths, and derive from them more advanced concepts like cliques, degrees, clustering coefficients, or connected components. We obtain a language to directly deal with interactions over time, similar to the language provided by graphs to deal with relations. This formalism is self-consistent: usual relations between different concepts are preserved. It is also consistent with graph theory: graph concepts are special cases of the ones we introduce. This makes it easy to generalize higher-level objects such as quotient graphs, line graphs, k-cores, and centralities. This paper also considers discrete versus continuous time assumptions, instantaneous links, and extensions to more complex cases. version:1
arxiv-1710-04062 | Decentralized Online Learning with Kernels | http://arxiv.org/abs/1710.04062 | id:1710.04062 author:Alec Koppel, Santiago Paternain, Cedric Richard, Alejandro Ribeiro category:math.OC cs.DC cs.LG cs.MA math.ST stat.ML stat.TH  published:2017-10-11 summary:We consider multi-agent stochastic optimization problems over reproducing kernel Hilbert spaces (RKHS). In this setting, a network of interconnected agents aims to learn decision functions, i.e., nonlinear statistical models, that are optimal in terms of a global convex functional that aggregates data across the network, with only access to locally and sequentially observed samples. We propose solving this problem by allowing each agent to learn a local regression function while enforcing consensus constraints. We use a penalized variant of functional stochastic gradient descent operating simultaneously with low-dimensional subspace projections. These subspaces are constructed greedily by applying orthogonal matching pursuit to the sequence of kernel dictionaries and weights. By tuning the projection-induced bias, we propose an algorithm that allows for each individual agent to learn, based upon its locally observed data stream and message passing with its neighbors only, a regression function that is close to the globally optimal regression function. That is, we establish that with constant step-size selections agents' functions converge to a neighborhood of the globally optimal one while satisfying the consensus constraints as the penalty parameter is increased. Moreover, the complexity of the learned regression functions is guaranteed to remain finite. On both multi-class kernel logistic regression and multi-class kernel support vector classification with data generated from class-dependent Gaussian mixture models, we observe stable function estimation and state of the art performance for distributed online multi-class classification. Experiments on the Brodatz textures further substantiate the empirical validity of this approach. version:1
arxiv-1710-04043 | Interactive Medical Image Segmentation using Deep Learning with Image-specific Fine-tuning | http://arxiv.org/abs/1710.04043 | id:1710.04043 author:Guotai Wang, Wenqi Li, Maria A. Zuluaga, Rosalind Pratt, Premal A. Patel, Michael Aertsen, Tom Doel, Anna L. David, Jan Deprest, Sebastien Ourselin, Tom Vercauteren category:cs.CV  published:2017-10-11 summary:Convolutional neural networks (CNNs) have achieved state-of-the-art performance for automatic medical image segmentation. However, they have not demonstrated sufficiently accurate and robust results for clinical use. In addition, they are limited by the lack of image-specific adaptation and the lack of generalizability to previously unseen object classes. To address these problems, we propose a novel deep learning-based framework for interactive segmentation by incorporating CNNs into a bounding box and scribble-based segmentation pipeline. We propose image-specific fine-tuning to make a CNN model adaptive to a specific test image, which can be either unsupervised (without additional user interactions) or supervised (with additional scribbles). We also propose a weighted loss function considering network and interaction-based uncertainty for the fine-tuning. We applied this framework to two applications: 2D segmentation of multiple organs from fetal MR slices, where only two types of these organs were annotated for training; and 3D segmentation of brain tumor core (excluding edema) and whole brain tumor (including edema) from different MR sequences, where only tumor cores in one MR sequence were annotated for training. Experimental results show that 1) our model is more robust to segment previously unseen objects than state-of-the-art CNNs; 2) image-specific fine-tuning with the proposed weighted loss function significantly improves segmentation accuracy; and 3) our method leads to accurate results with fewer user interactions and less user time than traditional interactive segmentation methods. version:1
arxiv-1710-04036 | Porcellio scaber algorithm (PSA) for solving constrained optimization problems | http://arxiv.org/abs/1710.04036 | id:1710.04036 author:Yinyan Zhang, Shuai Li, Hongliang Guo category:cs.NE  published:2017-10-11 summary:In this paper, we extend a bio-inspired algorithm called the porcellio scaber algorithm (PSA) to solve constrained optimization problems, including a constrained mixed discrete-continuous nonlinear optimization problem. Our extensive experiment results based on benchmark optimization problems show that the PSA has a better performance than many existing methods or algorithms. The results indicate that the PSA is a promising algorithm for constrained optimization. version:1
arxiv-1710-04034 | Image retargeting via Beltrami representation | http://arxiv.org/abs/1710.04034 | id:1710.04034 author:Chun Pong Lau, Chun Pang Yung, Lok Ming Lui category:cs.CV cs.GR  published:2017-10-11 summary:Image retargeting aims to resize an image to one with a prescribed aspect ratio. Simple scaling inevitably introduces unnatural geometric distortions on the important content of the image. In this paper, we propose a simple and yet effective method to resize an image, which preserves the geometry of the important content, using the Beltrami representation. Our algorithm allows users to interactively label content regions as well as line structures. Image resizing can then be achieved by warping the image by an orientation-preserving bijective warping map with controlled distortion. The warping map is represented by its Beltrami representation, which captures the local geometric distortion of the map. By carefully prescribing the values of the Beltrami representation, images with different complexity can be effectively resized. Our method does not require solving any optimization problems and tuning parameters throughout the process. This results in a simple and efficient algorithm to solve the image retargeting problem. Extensive experiments have been carried out, which demonstrate the efficacy of our proposed method. version:1
arxiv-1710-04026 | FFDNet: Toward a Fast and Flexible Solution for CNN based Image Denoising | http://arxiv.org/abs/1710.04026 | id:1710.04026 author:Kai Zhang, Wangmeng Zuo, Lei Zhang category:cs.CV  published:2017-10-11 summary:Due to the fast inference and good performance, discriminative learning methods have been widely studied in image denoising. However, these methods mostly learn a specific model for each noise level, and require multiple models for denoising images with different noise levels. They also lack flexibility to deal with spatially variant noise, limiting their applications in practical denoising. To address these issues, we present a fast and flexible denoising convolutional neural network, namely FFDNet, with a tunable noise level map as the input. The proposed FFDNet works on downsampled sub-images to speed up the inference, and adopts orthogonal regularization to enhance the generalization ability. In contrast to the existing discriminative denoisers, FFDNet enjoys several desirable properties, including (i) the ability to handle a wide range of noise levels (i.e., [0, 75]) effectively with a single network, (ii) the ability to remove spatially variant noise by specifying a non-uniform noise level map, and (iii) faster speed than benchmark BM3D even on CPU without sacrificing denoising performance. Extensive experiments on synthetic and real noisy images are conducted to evaluate FFDNet in comparison with state-of-the-art denoisers. The results show that FFDNet is effective and efficient, making it highly attractive for practical denoising applications. version:1
arxiv-1710-04019 | An introduction to Topological Data Analysis: fundamental and practical aspects for data scientists | http://arxiv.org/abs/1710.04019 | id:1710.04019 author:Frédéric Chazal, Bertrand Michel category:math.ST cs.LG math.AT stat.ML stat.TH  published:2017-10-11 summary:Topological Data Analysis (tda) is a recent and fast growing eld providing a set of new topological and geometric tools to infer relevant features for possibly complex data. This paper is a brief introduction, through a few selected topics, to basic fundamental and practical aspects of tda for non experts. 1 Introduction and motivation Topological Data Analysis (tda) is a recent eld that emerged from various works in applied (algebraic) topology and computational geometry during the rst decade of the century. Although one can trace back geometric approaches for data analysis quite far in the past, tda really started as a eld with the pioneering works of Edelsbrunner et al. (2002) and Zomorodian and Carlsson (2005) in persistent homology and was popularized in a landmark paper in 2009 Carlsson (2009). tda is mainly motivated by the idea that topology and geometry provide a powerful approach to infer robust qualitative, and sometimes quantitative, information about the structure of data-see, e.g. Chazal (2017). tda aims at providing well-founded mathematical, statistical and algorithmic methods to infer, analyze and exploit the complex topological and geometric structures underlying data that are often represented as point clouds in Euclidean or more general metric spaces. During the last few years, a considerable eort has been made to provide robust and ecient data structures and algorithms for tda that are now implemented and available and easy to use through standard libraries such as the Gudhi library (C++ and Python) Maria et al. (2014) and its R software interface Fasy et al. (2014a). Although it is still rapidly evolving, tda now provides a set of mature and ecient tools that can be used in combination or complementary to other data sciences tools. The tdapipeline. tda has recently known developments in various directions and application elds. There now exist a large variety of methods inspired by topological and geometric approaches. Providing a complete overview of all these existing approaches is beyond the scope of this introductory survey. However, most of them rely on the following basic and standard pipeline that will serve as the backbone of this paper: 1. The input is assumed to be a nite set of points coming with a notion of distance-or similarity between them. This distance can be induced by the metric in the ambient space (e.g. the Euclidean metric when the data are embedded in R d) or come as an intrinsic metric dened by a pairwise distance matrix. The denition of the metric on the data is usually given as an input or guided by the application. It is however important to notice that the choice of the metric may be critical to reveal interesting topological and geometric features of the data. version:1
arxiv-1710-04211 | Sequence stacking using dual encoder Seq2Seq recurrent networks | http://arxiv.org/abs/1710.04211 | id:1710.04211 author:Alessandro Bay, Biswa Sengupta category:cs.LG cs.DM cs.NE stat.ML  published:2017-10-11 summary:A widely studied non-polynomial (NP) hard problem lies in finding a route between the two nodes of a graph. Often meta-heuristics algorithms such as $A^{*}$ are employed on graphs with a large number of nodes. Here, we propose a deep recurrent neural network architecture based on the Sequence-2-Sequence model, widely used, for instance in text translation. Particularly, we illustrate that utilising a context vector that has been learned from two different recurrent networks enables increased accuracies in learning the shortest route of a graph. Additionally, we show that one can boost the performance of the Seq2Seq network by smoothing the loss function using a homotopy continuation of the decoder's loss function. version:1
arxiv-1710-04008 | A Dynamic Edge Exchangeable Model for Sparse Temporal Networks | http://arxiv.org/abs/1710.04008 | id:1710.04008 author:Yin Cheng Ng, Ricardo Silva category:stat.ML cs.SI  published:2017-10-11 summary:We propose a dynamic edge exchangeable network model that can capture sparse connections observed in real temporal networks, in contrast to existing models which are dense. The model achieved superior link prediction accuracy on multiple data sets when compared to a dynamic variant of the blockmodel, and is able to extract interpretable time-varying community structures from the data. In addition to sparsity, the model accounts for the effect of social influence on vertices' future behaviours. Compared to the dynamic blockmodels, our model has a smaller latent space. The compact latent space requires a smaller number of parameters to be estimated in variational inference and results in a computationally friendly inference algorithm. version:1
arxiv-1710-03981 | A batching and scheduling optimisation for a cutting work-center: Acta-Mobilier case study | http://arxiv.org/abs/1710.03981 | id:1710.03981 author:Emmanuel Zimmermann, Hind Haouzi, Philippe Thomas, André Thomas, Melanie Noyel category:cs.NE  published:2017-10-11 summary:The purpose of this study is to investigate an approach to group lots in batches and to schedule these batches on Acta-Mobilier cutting work-center while taking into account numerous constraints and objectives. The specific batching method was proposed to handle the Acta-Mobilier problem and a mathematical formalisation and genetic algorithm were proposed to deal with the scheduling problem. The proposed algorithm has been embedded in software to optimise production costs and emphasis the visual management on the production line. The application is currently being used in Acta-Mobilier plant and shows significant results version:1
arxiv-1710-03971 | Adaptive multi-penalty regularization based on a generalized Lasso path | http://arxiv.org/abs/1710.03971 | id:1710.03971 author:Markus Grasmair, Timo Klock, Valeriya Naumova category:stat.ML cs.LG math.NA  published:2017-10-11 summary:For many algorithms, parameter tuning remains a challenging and critical task, which becomes tedious and infeasible in a multi-parameter setting. Multi-penalty regularization, successfully used for solving undetermined sparse regression of problems of unmixing type where signal and noise are additively mixed, is one of such examples. In this paper, we propose a novel algorithmic framework for an adaptive parameter choice in multi-penalty regularization with a focus on the correct support recovery. Building upon the theory of regularization paths and algorithms for single-penalty functionals, we extend these ideas to a multi-penalty framework by providing an efficient procedure for the construction of regions containing structurally similar solutions, i.e., solutions with the same sparsity and sign pattern, over the whole range of parameters. Combining this with a model selection criterion, we can choose regularization parameters in a data-adaptive manner. Another advantage of our algorithm is that it provides an overview on the solution stability over the whole range of parameters. This can be further exploited to obtain additional insights into the problem of interest. We provide a numerical analysis of our method and compare it to the state-of-the-art single-penalty algorithms for compressed sensing problems in order to demonstrate the robustness and power of the proposed algorithm. version:1
arxiv-1710-04207 | Algebraic Image Processing | http://arxiv.org/abs/1710.04207 | id:1710.04207 author:Enrico Celeghini category:eess.IV cs.CV  published:2017-10-11 summary:We propose an approach to image processing related to algebraic operators acting in the space of images. In view of the interest in the applications in optics and computer science, mathematical aspects of the paper have been simplified as much as possible. Underlying theory, related to rigged Hilbert spaces and Lie algebras, is discussed elsewhere version:1
arxiv-1710-03959 | Deep learning in remote sensing: a review | http://arxiv.org/abs/1710.03959 | id:1710.03959 author:Xiao Xiang Zhu, Devis Tuia, Lichao Mou, Gui-Song Xia, Liangpei Zhang, Feng Xu, Friedrich Fraundorfer category:cs.CV eess.IV  published:2017-10-11 summary:Standing at the paradigm shift towards data-intensive science, machine learning techniques are becoming increasingly important. In particular, as a major breakthrough in the field, deep learning has proven as an extremely powerful tool in many fields. Shall we embrace deep learning as the key to all? Or, should we resist a 'black-box' solution? There are controversial opinions in the remote sensing community. In this article, we analyze the challenges of using deep learning for remote sensing data analysis, review the recent advances, and provide resources to make deep learning in remote sensing ridiculously simple to start with. More importantly, we advocate remote sensing scientists to bring their expertise into deep learning, and use it as an implicit general model to tackle unprecedented large-scale influential challenges, such as climate change and urbanization. version:1
arxiv-1710-03958 | Detect to Track and Track to Detect | http://arxiv.org/abs/1710.03958 | id:1710.03958 author:Christoph Feichtenhofer, Axel Pinz, Andrew Zisserman category:cs.CV  published:2017-10-11 summary:Recent approaches for high accuracy detection and tracking of object categories in video consist of complex multistage solutions that become more cumbersome each year. In this paper we propose a ConvNet architecture that jointly performs detection and tracking, solving the task in a simple and effective way. Our contributions are threefold: (i) we set up a ConvNet architecture for simultaneous detection and tracking, using a multi-task objective for frame-based object detection and across-frame track regression; (ii) we introduce correlation features that represent object co-occurrences across time to aid the ConvNet during tracking; and (iii) we link the frame level detections based on our across-frame tracklets to produce high accuracy detections at the video level. Our ConvNet architecture for spatiotemporal object detection is evaluated on the large-scale ImageNet VID dataset where it achieves state-of-the-art results. Our approach provides better single model performance than the winning method of the last ImageNet challenge while being conceptually much simpler. Finally, we show that by increasing the temporal stride we can dramatically increase the tracker speed. version:1
arxiv-1710-03957 | DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset | http://arxiv.org/abs/1710.03957 | id:1710.03957 author:Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, Shuzi Niu category:cs.CL  published:2017-10-11 summary:We develop a high-quality multi-turn dialog dataset, DailyDialog, which is intriguing in several aspects. The language is human-written and less noisy. The dialogues in the dataset reflect our daily communication way and cover various topics about our daily life. We also manually label the developed dataset with communication intention and emotion information. Then, we evaluate existing approaches on DailyDialog dataset and hope it benefit the research field of dialog systems. version:1
arxiv-1710-03501 | A Very Low Resource Language Speech Corpus for Computational Language Documentation Experiments | http://arxiv.org/abs/1710.03501 | id:1710.03501 author:P. Godard, G. Adda, M. Adda-Decker, J. Benjumea, L. Besacier, J. Cooper-Leavitt, G-N. Kouarata, L. Lamel, H. Maynard, M. Mueller, A. Rialland, S. Stueker, F. Yvon, M. Zanon-Boito category:cs.CL  published:2017-10-10 summary:Most speech and language technologies are trained with massive amounts of speech and text information. However, most of the world languages do not have such resources or stable orthography. Systems constructed under these almost zero resource conditions are not only promising for speech technology but also for computational language documentation. The goal of computational language documentation is to help field linguists to (semi-)automatically analyze and annotate audio recordings of endangered and unwritten languages. Example tasks are automatic phoneme discovery or lexicon discovery from the speech signal. This paper presents a speech corpus collected during a realistic language documentation process. It is made up of 5k speech utterances in Mboshi (Bantu C25) aligned to French text translations. Speech transcriptions are also made available: they correspond to a non-standard graphemic form close to the language phonology. We present how the data was collected, cleaned and processed and we illustrate its use through a zero-resource task: spoken term discovery. The dataset is made available to the community for reproducible computational language documentation experiments and their evaluation. version:2
arxiv-1710-03954 | Decision support from financial disclosures with deep neural networks and transfer learning | http://arxiv.org/abs/1710.03954 | id:1710.03954 author:Mathias Kraus, Stefan Feuerriegel category:cs.CL  published:2017-10-11 summary:Company disclosures greatly aid in the process of financial decision-making; therefore, they are consulted by financial investors and automated traders before exercising ownership in stocks. While humans are usually able to correctly interpret the content, the same is rarely true of computerized decision support systems, which struggle with the complexity and ambiguity of natural language. A possible remedy is represented by deep learning, which overcomes several shortcomings of traditional methods of text mining. For instance, recurrent neural networks, such as long short-term memories, employ hierarchical structures, together with a large number of hidden layers, to automatically extract features from ordered sequences of words and capture highly non-linear relationships such as context-dependent meanings. However, deep learning has only recently started to receive traction, possibly because its performance is largely untested. Hence, this paper studies the use of deep neural networks for financial decision support. We additionally experiment with transfer learning, in which we pre-train the network on a different corpus with a length of 139.1 million words. Our results reveal a higher directional accuracy as compared to traditional machine learning when predicting stock price movements in response to financial disclosures. Our work thereby helps to highlight the business value of deep learning and provides recommendations to practitioners and executives. version:1
arxiv-1706-04048 | Indirect Image Registration with Large Diffeomorphic Deformations | http://arxiv.org/abs/1706.04048 | id:1706.04048 author:Chong Chen, Ozan Öktem category:math.NA cs.CV math.DS math.FA math.OC  published:2017-06-13 summary:The paper adapts the large deformation diffeomorphic metric mapping framework for image registration to the indirect setting where a template is registered against a target that is given through indirect noisy observations. The registration uses diffeomorphisms that transform the template through a (group) action. These diffeomorphisms are generated by solving a flow equation that is defined by a velocity field with certain regularity. The theoretical analysis includes a proof that indirect image registration has solutions (existence) that are stable and that converge as the data error tends so zero, so it becomes a well-defined regularization method. The paper concludes with examples of indirect image registration in 2D tomography with very sparse and/or highly noisy data. version:3
arxiv-1710-03942 | When is Network Lasso Accurate: The Vector Case | http://arxiv.org/abs/1710.03942 | id:1710.03942 author:Nguyen Tran, Saeed Basirian, Alexander Jung category:cs.LG  published:2017-10-11 summary:A recently proposed learning algorithm for massive network-structured data sets (big data over networks) is the network Lasso (nLasso), which extends the well- known Lasso estimator from sparse models to network-structured datasets. Efficient implementations of the nLasso have been presented using modern convex optimization methods. In this paper, we provide sufficient conditions on the network structure and available label information such that nLasso accurately learns a vector-valued graph signal (representing label information) from the information provided by the labels of a few data points. version:1
arxiv-1710-03924 | A Note on Community Trees in Networks | http://arxiv.org/abs/1710.03924 | id:1710.03924 author:Ruqian Chen, Yen-Chi Chen, Wei Guo, Ashis G. Banerjee category:stat.ML cs.SI  published:2017-10-11 summary:We introduce the concept of community trees that summarizes topological structures within a network. A community tree is a tree structure representing clique communities from the clique percolation method (CPM). The community tree also generates a persistent diagram. Community trees and persistent diagrams reveal topological structures of the underlying networks and can be used as visualization tools. We study the stability of community trees and derive a quantity called the total star number (TSN) that presents an upper bound on the change of community trees. Our findings provide a topological interpretation for the stability of communities generated by the CPM. version:1
arxiv-1710-03923 | Deep Hyperalignment | http://arxiv.org/abs/1710.03923 | id:1710.03923 author:Muhammad Yousefnezhad, Daoqiang Zhang category:q-bio.NC cs.CV stat.ML  published:2017-10-11 summary:This paper proposes Deep Hyperalignment (DHA) as a regularized, deep extension, scalable Hyperalignment (HA) method, which is well-suited for applying functional alignment to fMRI datasets with nonlinearity, high-dimensionality (broad ROI), and a large number of subjects. Unlink previous methods, DHA is not limited by a restricted fixed kernel function. Further, it uses a parametric approach, rank-$m$ Singular Value Decomposition (SVD), and stochastic gradient descent for optimization. Therefore, DHA has a suitable time complexity for large datasets, and DHA does not require the training data when it computes the functional alignment for a new subject. Experimental studies on multi-subject fMRI analysis confirm that the DHA method achieves superior performance to other state-of-the-art HA algorithms. version:1
arxiv-1706-07001 | Improved Optimization of Finite Sums with Minibatch Stochastic Variance Reduced Proximal Iterations | http://arxiv.org/abs/1706.07001 | id:1706.07001 author:Jialei Wang, Tong Zhang category:math.OC cs.LG stat.ML  published:2017-06-21 summary:We present novel minibatch stochastic optimization methods for empirical risk minimization problems, the methods efficiently leverage variance reduced first-order and sub-sampled higher-order information to accelerate the convergence speed. For quadratic objectives, we prove improved iteration complexity over state-of-the-art under reasonable assumptions. We also provide empirical evidence of the advantages of our method compared to existing approaches in the literature. version:2
arxiv-1710-02971 | Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec | http://arxiv.org/abs/1710.02971 | id:1710.02971 author:Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, Jie Tang category:cs.SI cs.LG stat.ML  published:2017-10-09 summary:Since the invention of word2vec, the skip-gram model has significantly advanced the research of network embedding, such as the recent emergence of DeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of the aforementioned models with negative sampling can be unified into the matrix factorization framework with closed forms. Our analysis and proofs reveal that: (1) DeepWalk empirically produces a low-rank transformation of the normalized Laplacian matrix of a network; (2) LINE, in theory, is a special case of DeepWalk when the size of vertex context is set to one; (3) As an extension to LINE, PTE can be viewed as the joint factorization of multiple Laplacian matrices; (4) node2vec is factorizing a matrix related to the stationary distribution and transition probability tensor of a 2nd-order random walk. We further provide the theoretical connections between skip-gram based network embedding algorithms and the theory of graph Laplacian. Finally, we present the NetMF method as well as its approximation algorithm for computing network embedding. Our method offers significant improvements over DeepWalk and LINE (up to 38% relatively) in several conventional network mining tasks. This work lays the theoretical foundation for skip-gram based network embedding methods, leading to a better understanding of latent network representations. version:2
arxiv-1710-03877 | Fine-Grained Prediction of Syntactic Typology: Discovering Latent Structure with Supervised Learning | http://arxiv.org/abs/1710.03877 | id:1710.03877 author:Dingquan Wang, Jason Eisner category:cs.CL  published:2017-10-11 summary:We show how to predict the basic word-order facts of a novel language given only a corpus of part-of-speech (POS) sequences. We predict how often direct objects follow their verbs, how often adjectives follow their nouns, and in general the directionalities of all dependency relations. Such typological properties could be helpful in grammar induction. While such a problem is usually regarded as unsupervised learning, our innovation is to treat it as supervised learning, using a large collection of realistic synthetic languages as training data. The supervised learner must identify surface features of a language's POS sequence (hand-engineered or neural features) that correlate with the language's deeper structure (latent trees). In the experiment, we show: 1) Given a small set of real languages, it helps to add many synthetic languages to the training data. 2) Our system is robust even when the POS sequences include noise. 3) Our system on this task outperforms a grammar induction baseline by a large margin. version:1
arxiv-1710-03875 | Specification Inference from Demonstrations | http://arxiv.org/abs/1710.03875 | id:1710.03875 author:Marcell Vazquez-Chanlatte, Susmit Jha, Ashish Tiwari, Sanjit A. Seshia category:cs.LG cs.AI cs.LO  published:2017-10-11 summary:Learning from expert demonstrations has received a lot of attention in artificial intelligence and machine learning. The goal is to infer the underlying reward function that an agent is optimizing given a set of observations of the agent's behavior over time in a variety of circumstances, the system state trajectories, and a plant model specifying the evolution of the system state for different agent's actions. The system is often modeled as a Markov decision process, that is, the next state depends only on the current state and agent's action, and the the agent's choice of action depends only on the current state. While the former is a Markovian assumption on the evolution of system state, the later assumes that the target reward function is itself Markovian. In this work, we explore learning a class of non-Markovian reward functions, known in the formal methods literature as specifications. These specifications offer better composition, transferability, and interpretability. We then show that inferring the specification can be done efficiently without unrolling the transition system. We demonstrate on a 2-d grid world example. version:1
arxiv-1710-03863 | On Estimation of $L_{r}$-Norms in Gaussian White Noise Models | http://arxiv.org/abs/1710.03863 | id:1710.03863 author:Yanjun Han, Jiantao Jiao, Rajarshi Mukherjee, Tsachy Weissman category:math.ST cs.LG stat.TH  published:2017-10-11 summary:We provide a complete picture of asymptotically minimax estimation of $L_r$-norms (for any $r\ge 1$) of the mean in Gaussian white noise model over Nikolskii-Besov spaces. In this regard, we complement the work of Lepski, Nemirovski and Spokoiny (1999), who considered the cases of $r=1$ (with poly-logarithmic gap between upper and lower bounds) and $r$ even (with asymptotically sharp upper and lower bounds) over H\"{o}lder spaces. We additionally consider the case of asymptotically adaptive minimax estimation and demonstrate a difference between even and non-even $r$ in terms of an investigator's ability to produce asymptotically adaptive minimax estimators without paying a penalty. version:1
arxiv-1710-05726 | Convolutional Neural Networks for Histopathology Image Classification: Training vs. Using Pre-Trained Networks | http://arxiv.org/abs/1710.05726 | id:1710.05726 author:Brady Kieffer, Morteza Babaie, Shivam Kalra, H. R. Tizhoosh category:cs.CV  published:2017-10-11 summary:We explore the problem of classification within a medical image data-set based on a feature vector extracted from the deepest layer of pre-trained Convolution Neural Networks. We have used feature vectors from several pre-trained structures, including networks with/without transfer learning to evaluate the performance of pre-trained deep features versus CNNs which have been trained by that specific dataset as well as the impact of transfer learning with a small number of samples. All experiments are done on Kimia Path24 dataset which consists of 27,055 histopathology training patches in 24 tissue texture classes along with 1,325 test patches for evaluation. The result shows that pre-trained networks are quite competitive against training from scratch. As well, fine-tuning does not seem to add any tangible improvement for VGG16 to justify additional training while we observed considerable improvement in retrieval and classification accuracy when we fine-tuned the Inception structure. version:1
arxiv-1710-03850 | Using Task Descriptions in Lifelong Machine Learning for Improved Performance and Zero-Shot Transfer | http://arxiv.org/abs/1710.03850 | id:1710.03850 author:David Isele, Mohammad Rostami, Eric Eaton category:cs.LG stat.ML  published:2017-10-10 summary:Knowledge transfer between tasks can improve the performance of learned models, but requires an accurate estimate of the inter-task relationships to identify the relevant knowledge to transfer. These inter-task relationships are typically estimated based on training data for each task, which is inefficient in lifelong learning settings where the goal is to learn each consecutive task rapidly from as little data as possible. To reduce this burden, we develop a lifelong learning method based on coupled dictionary learning that utilizes high-level task descriptions to model the inter-task relationships. We show that using task descriptors improves the performance of the learned task policies, providing both theoretical justification for the benefit and empirical demonstration of the improvement across a variety of learning problems. Given only the descriptor for a new task, the lifelong learner is also able to accurately predict a model for the new task through zero-shot learning using the coupled dictionary, eliminating the need to gather training data before addressing the task. version:1
arxiv-1708-01715 | Training Deep AutoEncoders for Collaborative Filtering | http://arxiv.org/abs/1708.01715 | id:1708.01715 author:Oleksii Kuchaiev, Boris Ginsburg category:stat.ML cs.LG  published:2017-08-05 summary:This paper proposes a novel model for the rating prediction task in recommender systems which significantly outperforms previous state-of-the art models on a time-split Netflix data set. Our model is based on deep autoencoder with 6 layers and is trained end-to-end without any layer-wise pre-training. We empirically demonstrate that: a) deep autoencoder models generalize much better than the shallow ones, b) non-linear activation functions with negative parts are crucial for training deep models, and c) heavy use of regularization techniques such as dropout is necessary to prevent over-fiting. We also propose a new training algorithm based on iterative output re-feeding to overcome natural sparseness of collaborate filtering. The new algorithm significantly speeds up training and improves model performance. Our code is available at https://github.com/NVIDIA/DeepRecommender version:3
arxiv-1709-02554 | Learning to Segment Breast Biopsy Whole Slide Images | http://arxiv.org/abs/1709.02554 | id:1709.02554 author:Sachin Mehta, Ezgi Mercan, Jamen Bartlett, Donald Weaver, Joann Elmore, Linda Shapiro category:cs.CV  published:2017-09-08 summary:We trained and applied an encoder-decoder model to semantically segment breast biopsy images into biologically meaningful tissue labels. Since conventional encoder-decoder networks cannot be applied directly on large biopsy images and the different sized structures in biopsies present novel challenges, we propose four modifications: (1) an input-aware encoding block to compensate for information loss, (2) a new dense connection pattern between encoder and decoder, (3) dense and sparse decoders to combine multi-level features, (4) a multi-resolution network that fuses the results of encoder-decoders run on different resolutions. Our model outperforms a feature-based approach and conventional encoder-decoders from the literature. We use semantic segmentations produced with our model in an automated diagnosis task and obtain higher accuracies than a baseline approach that employs an SVM for feature-based segmentation, both using the same segmentation-based diagnostic features. version:2
arxiv-1710-03839 | Disentangled Representations via Synergy Minimization | http://arxiv.org/abs/1710.03839 | id:1710.03839 author:Greg Ver Steeg, Rob Brekelmans, Hrayr Harutyunyan, Aram Galstyan category:cs.LG cs.IT math.IT  published:2017-10-10 summary:Scientists often seek simplified representations of complex systems to facilitate prediction and understanding. If the factors comprising a representation allow us to make accurate predictions about our system, but obscuring any subset of the factors destroys our ability to make predictions, we say that the representation exhibits informational synergy. We argue that synergy is an undesirable feature in learned representations and that explicitly minimizing synergy can help disentangle the true factors of variation underlying data. We explore different ways of quantifying synergy, deriving new closed-form expressions in some cases, and then show how to modify learning to produce representations that are minimally synergistic. We introduce a benchmark task to disentangle separate characters from images of words. We demonstrate that Minimally Synergistic (MinSyn) representations correctly disentangle characters while methods relying on statistical independence fail. version:1
arxiv-1710-03838 | The Galactic Dependencies Treebanks: Getting More Data by Synthesizing New Languages | http://arxiv.org/abs/1710.03838 | id:1710.03838 author:Dingquan Wang, Jason Eisner category:cs.CL  published:2017-10-10 summary:We release Galactic Dependencies 1.0---a large set of synthetic languages not found on Earth, but annotated in Universal Dependencies format. This new resource aims to provide training and development data for NLP methods that aim to adapt to unfamiliar languages. Each synthetic treebank is produced from a real treebank by stochastically permuting the dependents of nouns and/or verbs to match the word order of other real languages. We discuss the usefulness, realism, parsability, perplexity, and diversity of the synthetic languages. As a simple demonstration of the use of Galactic Dependencies, we consider single-source transfer, which attempts to parse a real target language using a parser trained on a "nearby" source language. We find that including synthetic source languages somewhat increases the diversity of the source pool, which significantly improves results for most target languages. version:1
arxiv-1710-03830 | Inference on Auctions with Weak Assumptions on Information | http://arxiv.org/abs/1710.03830 | id:1710.03830 author:Vasilis Syrgkanis, Elie Tamer, Juba Ziani category:econ.EM cs.GT cs.LG math.ST stat.TH  published:2017-10-10 summary:Given a sample of bids from independent auctions, this paper examines the question of inference on auction fundamentals (e.g. valuation distributions, welfare measures) under weak assumptions on information structure. The question is important as it allows us to learn about the valuation distribution in a robust way, i.e., without assuming that a particular information structure holds across observations. We leverage recent contributions in the robust mechanism design literature that exploit the link between Bayesian Correlated Equilibria and Bayesian Nash Equilibria in incomplete information games to construct an econometrics framework for learning about auction fundamentals using observed data on bids. We showcase our construction of identified sets in private value and common value auctions. Our approach for constructing these sets inherits the computational simplicity of solving for correlated equilibria: checking whether a particular valuation distribution belongs to the identified set is as simple as determining whether a linear program is feasible. A similar linear program can be used to construct the identified set on various welfare measures and counterfactual objects. For inference and to summarize statistical uncertainty, we propose novel finite sample methods using tail inequalities that are used to construct confidence regions on sets. We also highlight methods based on Bayesian bootstrap and subsampling. A set of Monte Carlo experiments show adequate finite sample properties of our inference procedures. We also illustrate our methods using data from OCS auctions. version:1
arxiv-1710-03823 | Application of Deep Learning in Neuroradiology: Automated Detection of Basal Ganglia Hemorrhage using 2D-Convolutional Neural Networks | http://arxiv.org/abs/1710.03823 | id:1710.03823 author:Vishal Desai, Adam E. Flanders, Paras Lakhani category:cs.CV  published:2017-10-10 summary:Background: Deep learning techniques have achieved high accuracy in image classification tasks, and there is interest in applicability to neuroimaging critical findings. This study evaluates the efficacy of 2D deep convolutional neural networks (DCNNs) for detecting basal ganglia (BG) hemorrhage on noncontrast head CT. Materials and Methods: 170 unique de-identified HIPAA-compliant noncontrast head CTs were obtained, those with and without BG hemorrhage. 110 cases were held-out for test, and 60 were split into training (45) and validation (15), consisting of 20 right, 20 left, and 20 no BG hemorrhage. Data augmentation was performed to increase size and variation of the training dataset by 48-fold. Two DCNNs were used to classify the images-AlexNet and GoogLeNet-using untrained networks and those pre-trained on ImageNet. Area under the curves (AUC) for the receiver-operator characteristic (ROC) curves were calculated, using the DeLong method for statistical comparison of ROCs. Results: The best performing model was the pre-trained augmented GoogLeNet, which had an AUC of 1.00 in classification of hemorrhage. Preprocessing augmentation increased accuracy for all networks (p<0.001), and pretrained networks outperformed untrained ones (p<0.001) for the unaugmented models. The best performing GoogLeNet model (AUC 1.00) outperformed the best performing AlexNet model (AUC 0.95)(p=0.01). Conclusion: For this dataset, the best performing DCNN identified BG hemorrhage on noncontrast head CT with an AUC of 1.00. Pretrained networks and data augmentation increased classifier accuracy. Future prospective research would be important to determine if the accuracy can be maintained on a larger cohort of patients and for very small hemorrhages. version:1
arxiv-1709-08166 | Spiking neurons with short-term synaptic plasticity form superior generative networks | http://arxiv.org/abs/1709.08166 | id:1709.08166 author:Luziwei Leng, Roman Martel, Oliver Breitwieser, Ilja Bytschok, Walter Senn, Johannes Schemmel, Karlheinz Meier, Mihai A. Petrovici category:cs.NE physics.bio-ph q-bio.NC  published:2017-09-24 summary:Spiking networks that perform probabilistic inference have been proposed both as models of cortical computation and as candidates for solving problems in machine learning. However, the evidence for spike-based computation being in any way superior to non-spiking alternatives remains scarce. We propose that short-term plasticity can provide spiking networks with distinct computational advantages compared to their classical counterparts. In this work, we use networks of leaky integrate-and-fire neurons that are trained to perform both discriminative and generative tasks in their forward and backward information processing paths, respectively. During training, the energy landscape associated with their dynamics becomes highly diverse, with deep attractor basins separated by high barriers. Classical algorithms solve this problem by employing various tempering techniques, which are both computationally demanding and require global state updates. We demonstrate how similar results can be achieved in spiking networks endowed with local short-term synaptic plasticity. Additionally, we discuss how these networks can even outperform tempering-based approaches when the training data is imbalanced. We thereby show how biologically inspired, local, spike-triggered synaptic dynamics based simply on a limited pool of synaptic resources can allow spiking networks to outperform their non-spiking relatives. version:3
arxiv-1710-03811 | DeepSolarEye: Power Loss Prediction and Weakly Supervised Soiling Localization via Fully Convolutional Networks for Solar Panels | http://arxiv.org/abs/1710.03811 | id:1710.03811 author:Sachin Mehta, Amar P. Azad, Saneem A. Chemmengath, Vikas Raykar, Shivkumar Kalyanraman category:cs.CV  published:2017-10-10 summary:Impact of soiling on solar panels is an important and well-studied problem in renewable energy sector. In this paper, we present a novel approach based on fully convolutional networks which takes an RGB image of solar panel and environmental factors (optional) as inputs to predict power loss, soiling localization, and soiling type. In computer vision, predicting localization is a complex task which typically requires human labeled data such as bounding boxes or segmentation masks. Our proposed approach consists of specialized four stages which completely avoids human labeled localization data and only needs panel images with power loss for training. The region of impact area obtained from the localization masks are then classified into soiling types using the webly supervised learning. For superior localization capabilities of convolutional neural networks (CNNs), we introduce a novel bi-directional input-aware fusion (BiDIAF) block that reinforces the input at different levels of CNN to learn input-specific feature maps. Our empirical study shows that BiDIAF improves the power loss prediction accuracy and the localization Jaccard index of ResNet by about 3% and 4% respectively. Our end-to-end model yields further improvement of about 24% on localization task when learned in a weakly supervised manner. Our approach is generalizable and showed promising results on web crawled solar panel images. Additionally, we collected first of it's kind dataset for solar panel image analysis consisting 45,000+ images. version:1
arxiv-1710-03804 | End-to-End Deep Learning for Steering Autonomous Vehicles Considering Temporal Dependencies | http://arxiv.org/abs/1710.03804 | id:1710.03804 author:Hesham M. Eraqi, Mohamed N. Moustafa, Jens Honer category:cs.LG  published:2017-10-10 summary:Steering a car through traffic is a complex task that is difficult to cast into algorithms. Therefore, researchers turn to training artificial neural networks from front-facing camera data stream along with the associated steering angles. Nevertheless, most existing solutions consider only the visual camera frames as input, thus ignoring the temporal relationship between frames. In this work, we propose a Convolutional Long Short-Term Memory Recurrent Neural Network (C-LSTM), that is end-to-end trainable, to learn both visual and dynamic temporal dependencies of driving. Additionally, We introduce posing the steering angle regression problem as classification while imposing a spatial relationship between the output layer neurons. Such method is based on learning a sinusoidal function that encodes steering angles. To train and validate our proposed methods, we used the publicly available Comma.ai dataset. Our solution improved steering root mean square error by 35% over recent methods, and led to a more stable steering by 87% version:1
arxiv-1710-03144 | Island Loss for Learning Discriminative Features in Facial Expression Recognition | http://arxiv.org/abs/1710.03144 | id:1710.03144 author:Jie Cai, Zibo Meng, Ahmed Shehab Khan, Zhiyuan Li, Yan Tong category:cs.CV  published:2017-10-09 summary:Over the past few years, Convolutional Neural Networks (CNNs) have shown promise on facial expression recognition. However, the performance degrades dramatically under real-world settings due to variations introduced by subtle facial appearance changes, head pose variations, illumination changes, and occlusions. In this paper, a novel island loss is proposed to enhance the discriminative power of the deeply learned features. Specifically, the IL is designed to reduce the intra-class variations while enlarging the inter-class differences simultaneously. Experimental results on four benchmark expression databases have demonstrated that the CNN with the proposed island loss (IL-CNN) outperforms the baseline CNN models with either traditional softmax loss or the center loss and achieves comparable or better performance compared with the state-of-the-art methods for facial expression recognition. version:2
arxiv-1710-05817 | Densely Connected Convolutional Networks and Signal Quality Analysis to Detect Atrial Fibrillation Using Short Single-Lead ECG Recordings | http://arxiv.org/abs/1710.05817 | id:1710.05817 author:Jonathan Rubin, Saman Parvaneh, Asif Rahman, Bryan Conroy, Saeed Babaeizadeh category:eess.SP cs.CV stat.ML  published:2017-10-10 summary:The development of new technology such as wearables that record high-quality single channel ECG, provides an opportunity for ECG screening in a larger population, especially for atrial fibrillation screening. The main goal of this study is to develop an automatic classification algorithm for normal sinus rhythm (NSR), atrial fibrillation (AF), other rhythms (O), and noise from a single channel short ECG segment (9-60 seconds). For this purpose, signal quality index (SQI) along with dense convolutional neural networks was used. Two convolutional neural network (CNN) models (main model that accepts 15 seconds ECG and secondary model that processes 9 seconds shorter ECG) were trained using the training data set. If the recording is determined to be of low quality by SQI, it is immediately classified as noisy. Otherwise, it is transformed to a time-frequency representation and classified with the CNN as NSR, AF, O, or noise. At the final step, a feature-based post-processing algorithm classifies the rhythm as either NSR or O in case the CNN model's discrimination between the two is indeterminate. The best result achieved at the official phase of the PhysioNet/CinC challenge on the blind test set was 0.80 (F1 for NSR, AF, and O were 0.90, 0.80, and 0.70, respectively). version:1
arxiv-1710-03778 | Joint Weakly and Semi-Supervised Deep Learning for Localization and Classification of Masses in Breast Ultrasound Images | http://arxiv.org/abs/1710.03778 | id:1710.03778 author:Seung Yeon Shin, Soochahn Lee, Il Dong Yun, Kyoung Mu Lee category:cs.CV  published:2017-10-10 summary:We propose a framework for localization and classification of masses in breast ultrasound (BUS) images. In particular, we simultaneously use a weakly annotated dataset and a relatively small strongly annotated dataset to train a convolutional neural network detector. We have experimentally found that mass detectors trained with small, strongly annotated datasets are easily overfitted, whereas those trained with large, weakly annotated datasets present a non-trivial problem. To overcome these problems, we jointly use datasets with different characteristics in a hybrid manner. Consequently, a sophisticated weakly and semi-supervised training scenario is introduced with appropriate training loss selection. Experimental results show that the proposed method successfully localizes and classifies masses while requiring less effort in annotation work. The influences of each component in the proposed framework are also validated by conducting an ablative analysis. Although the proposed method is intended for masses in BUS images, it can also be applied as a general framework to train computer-aided detection and diagnosis systems for a wide variety of image modalities, target organs, and diseases. version:1
arxiv-1710-01766 | DeepLesion: Automated Deep Mining, Categorization and Detection of Significant Radiology Image Findings using Large-Scale Clinical Lesion Annotations | http://arxiv.org/abs/1710.01766 | id:1710.01766 author:Ke Yan, Xiaosong Wang, Le Lu, Ronald M. Summers category:cs.CV  published:2017-10-04 summary:Extracting, harvesting and building large-scale annotated radiological image datasets is a greatly important yet challenging problem. It is also the bottleneck to designing more effective data-hungry computing paradigms (e.g., deep learning) for medical image analysis. Yet, vast amounts of clinical annotations (usually associated with disease image findings and marked using arrows, lines, lesion diameters, segmentation, etc.) have been collected over several decades and stored in hospitals' Picture Archiving and Communication Systems. In this paper, we mine and harvest one major type of clinical annotation data - lesion diameters annotated on bookmarked images - to learn an effective multi-class lesion detector via unsupervised and supervised deep Convolutional Neural Networks (CNN). Our dataset is composed of 33,688 bookmarked radiology images from 10,825 studies of 4,477 unique patients. For every bookmarked image, a bounding box is created to cover the target lesion based on its measured diameters. We categorize the collection of lesions using an unsupervised deep mining scheme to generate clustered pseudo lesion labels. Next, we adopt a regional-CNN method to detect lesions of multiple categories, regardless of missing annotations (normally only one lesion is annotated, despite the presence of multiple co-existing findings). Our integrated mining, categorization and detection framework is validated with promising empirical results, as a scalable, universal or multi-purpose CAD paradigm built upon abundant retrospective medical data. Furthermore, we demonstrate that detection accuracy can be significantly improved by incorporating pseudo lesion labels (e.g., Liver lesion/tumor, Lung nodule/tumor, Abdomen lesions, Chest lymph node and others). This dataset will be made publicly available (under the open science initiative). version:2
arxiv-1710-03743 | Confidence through Attention | http://arxiv.org/abs/1710.03743 | id:1710.03743 author:Matīss Rikters, Mark Fishel category:cs.CL  published:2017-10-10 summary:Attention distributions of the generated translations are a useful bi-product of attention-based recurrent neural network translation models and can be treated as soft alignments between the input and output tokens. In this work, we use attention distributions as a confidence metric for output translations. We present two strategies of using the attention distributions: filtering out bad translations from a large back-translated corpus, and selecting the best translation in a hybrid setup of two different translation systems. While manual evaluation indicated only a weak correlation between our confidence score and human judgments, the use-cases showed improvements of up to 2.22 BLEU points for filtering and 0.99 points for hybrid translation, tested on English<->German and English<->Latvian translation. version:1
arxiv-1710-03695 | Underestimate Sequences via Quadratic Averaging | http://arxiv.org/abs/1710.03695 | id:1710.03695 author:Chenxin Ma, Naga Venkata C. Gudapati, Majid Jahani, Rachael Tappenden, Martin Takáč category:math.OC cs.LG  published:2017-10-10 summary:In this work we introduce the concept of an Underestimate Sequence (UES), which is a natural extension of Nesterov's estimate sequence. Our definition of a UES utilizes three sequences, one of which is a lower bound (or under-estimator) of the objective function. The question of how to construct an appropriate sequence of lower bounds is also addressed, and we present lower bounds for strongly convex smooth functions and for strongly convex composite functions, which adhere to the UES framework. Further, we propose several first order methods for minimizing strongly convex functions in both the smooth and composite cases. The algorithms, based on efficiently updating lower bounds on the objective functions, have natural stopping conditions, which provides the user with a certificate of optimality. Convergence of all algorithms is guaranteed through the UES framework, and we show that all presented algorithms converge linearly, with the accelerated variants enjoying the optimal linear rate of convergence. version:1
arxiv-1708-07338 | Gradient-based Camera Exposure Control for Outdoor Mobile Platforms | http://arxiv.org/abs/1708.07338 | id:1708.07338 author:Inwook Shim, Tae-Hyun Oh, Joon-Young Lee, Dong-Geol Choi, Jinwook Choi, In So Kweon category:cs.CV cs.RO  published:2017-08-24 summary:We introduce a novel method to automatically adjust camera exposure for image processing and computer vision applications of mobile robot platforms. Since most image processing algorithms heavily rely on low-level image features, which are largely based on local gradient information, we consider a gradient quantity to determine a proper exposure level, so that a camera is able to capture important image features robust to illumination conditions. We extend it to multi-camera system and present a new control algorithm to achieve both brightness consistency between adjacent cameras and a proper exposure level for each camera. We implement our prototype system with off-the-shelf machine vision cameras and demonstrate the effectiveness of the proposed algorithms on practical applications: pedestrian detection, visual odometry, surround-view imaging, panoramic imaging, and stereo matching. version:2
arxiv-1710-03667 | High-dimensional dynamics of generalization error in neural networks | http://arxiv.org/abs/1710.03667 | id:1710.03667 author:Madhu S. Advani, Andrew M. Saxe category:stat.ML cs.LG physics.data-an q-bio.NC  published:2017-10-10 summary:We perform an average case analysis of the generalization dynamics of large neural networks trained using gradient descent. We study the practically-relevant "high-dimensional" regime where the number of free parameters in the network is on the order of or even larger than the number of examples in the dataset. Using random matrix theory and exact solutions in linear models, we derive the generalization error and training error dynamics of learning and analyze how they depend on the dimensionality of data and signal to noise ratio of the learning problem. We find that the dynamics of gradient descent learning naturally protect against overtraining and overfitting in large networks. Overtraining is worst at intermediate network sizes, when the effective number of free parameters equals the number of samples, and thus can be reduced by making a network smaller or larger. Additionally, in the high-dimensional regime, low generalization error requires starting with small initial weights. We then turn to non-linear neural networks, and show that making networks very large does not harm their generalization performance. On the contrary, it can in fact reduce overtraining, even without early stopping or regularization of any sort. We identify two novel phenomena underlying this behavior in overcomplete models: first, there is a frozen subspace of the weights in which no learning occurs under gradient descent; and second, the statistical properties of the high-dimensional regime yield better-conditioned input correlations which protect against overtraining. We demonstrate that naive application of worst-case theories such as Rademacher complexity are inaccurate in predicting the generalization performance of deep neural networks, and derive an alternative bound which incorporates the frozen subspace and conditioning effects and qualitatively matches the behavior observed in simulation. version:1
arxiv-1706-04119 | Investigating the Parameter Space of Evolutionary Algorithms | http://arxiv.org/abs/1706.04119 | id:1706.04119 author:Moshe Sipper, Weixuan Fu, Karuna Ahuja, Jason H. Moore category:cs.NE  published:2017-06-13 summary:The practice of evolutionary algorithms involves the tuning of many parameters. How big should the population be? How many generations should the algorithm run? What is the (tournament selection) tournament size? What probabilities should one assign to crossover and mutation? Through an extensive series of experiments over multiple evolutionary algorithm implementations and problems we show that parameter space tends to be rife with viable parameters, at least for 25 the problems studied herein. We discuss the implications of this finding in practice. version:3
arxiv-1710-03641 | Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments | http://arxiv.org/abs/1710.03641 | id:1710.03641 author:Maruan Al-Shedivat, Trapit Bansal, Yuri Burda, Ilya Sutskever, Igor Mordatch, Pieter Abbeel category:cs.LG cs.AI  published:2017-10-10 summary:Ability to continuously learn and adapt from limited experience in nonstationary environments is an important milestone on the path towards general intelligence. In this paper, we cast the problem of continuous adaptation into the learning-to-learn framework. We develop a simple gradient-based meta-learning algorithm suitable for adaptation in dynamically changing and adversarial scenarios. Additionally, we design a new multi-agent competitive environment, RoboSumo, and define iterated adaptation games for testing various aspects of continuous adaptation strategies. We demonstrate that meta-learning enables significantly more efficient adaptation than reactive baselines in the few-shot regime. Our experiments with a population of agents that learn and compete suggest that meta-learners are the fittest. version:1
arxiv-1710-03634 | LinXGBoost: Extension of XGBoost to Generalized Local Linear Models | http://arxiv.org/abs/1710.03634 | id:1710.03634 author:Laurent de Vito category:cs.LG stat.ML  published:2017-10-10 summary:XGBoost is often presented as the algorithm that wins every ML competition. Surprisingly, this is true even though predictions are piecewise constant. This might be justified in high dimensional input spaces, but when the number of features is low, a piecewise linear model is likely to perform better. XGBoost was extended into LinXGBoost that stores at each leaf a linear model. This extension, equivalent to piecewise regularized least-squares, is particularly attractive for regression of functions that exhibits jumps or discontinuities. Those functions are notoriously hard to regress. Our extension is compared to the vanilla XGBoost and Random Forest in experiments on both synthetic and real-world data sets. version:1
arxiv-1710-03627 | Multilevel Modeling with Structured Penalties for Classification from Imaging Genetics data | http://arxiv.org/abs/1710.03627 | id:1710.03627 author:Pascal Lu, Olivier Colliot category:stat.ML  published:2017-10-10 summary:In this paper, we propose a framework for automatic classification of patients from multimodal genetic and brain imaging data by optimally combining them. Additive models with unadapted penalties (such as the classical group lasso penalty or $L_1$-multiple kernel learning) treat all modalities in the same manner and can result in undesirable elimination of specific modalities when their contributions are unbalanced. To overcome this limitation, we introduce a multilevel model that combines imaging and genetics and that considers joint effects between these two modalities for diagnosis prediction. Furthermore, we propose a framework allowing to combine several penalties taking into account the structure of the different types of data, such as a group lasso penalty over the genetic modality and a $L_2$-penalty on imaging modalities. Finally , we propose a fast optimization algorithm, based on a proximal gradient method. The model has been evaluated on genetic (single nucleotide polymorphisms-SNP) and imaging (anatomical MRI measures) data from the ADNI database, and compared to additive models. It exhibits good performances in AD diagnosis; and at the same time, reveals relationships between genes, brain regions and the disease status. version:1
arxiv-1710-03753 | Optimizing Long Short-Term Memory Recurrent Neural Networks Using Ant Colony Optimization to Predict Turbine Engine Vibration | http://arxiv.org/abs/1710.03753 | id:1710.03753 author:AbdElRahman ElSaid, Travis Desell, Fatima El Jamiy, James Higgins, Brandon Wild category:cs.NE cs.AI  published:2017-10-10 summary:This article expands on research that has been done to develop a recurrent neural network (RNN) capable of predicting aircraft engine vibrations using long short-term memory (LSTM) neurons. LSTM RNNs can provide a more generalizable and robust method for prediction over analytical calculations of engine vibration, as analytical calculations must be solved iteratively based on specific empirical engine parameters, making this approach ungeneralizable across multiple engines. In initial work, multiple LSTM RNN architectures were proposed, evaluated and compared. This research improves the performance of the most effective LSTM network design proposed in the previous work by using a promising neuroevolution method based on ant colony optimization (ACO) to develop and enhance the LSTM cell structure of the network. A parallelized version of the ACO neuroevolution algorithm has been developed and the evolved LSTM RNNs were compared to the previously used fixed topology. The evolved networks were trained on a large database of flight data records obtained from an airline containing flights that suffered from excessive vibration. Results were obtained using MPI (Message Passing Interface) on a high performance computing (HPC) cluster, evolving 1000 different LSTM cell structures using 168 cores over 4 days. The new evolved LSTM cells showed an improvement of 1.35%, reducing prediction error from 5.51% to 4.17% when predicting excessive engine vibrations 10 seconds in the future, while at the same time dramatically reducing the number of weights from 21,170 to 11,810. version:1
arxiv-1710-03600 | Fast and Strong Convergence of Online Learning Algorithms | http://arxiv.org/abs/1710.03600 | id:1710.03600 author:Zheng-Chu Guo, Lei Shi category:cs.LG stat.ML  published:2017-10-10 summary:In this paper, we study the online learning algorithm without explicit regularization terms. This algorithm is essentially a stochastic gradient descent scheme in a reproducing kernel Hilbert space (RKHS). The polynomially decaying step size in each iteration can play a role of regularization to ensure the generalization ability of online learning algorithm. We develop a novel capacity dependent analysis on the performance of the last iterate of online learning algorithm. The contribution of this paper is two-fold. First, our nice analysis can lead to the convergence rate in the standard mean square distance which is the best so far. Second, we establish, for the first time, the strong convergence of the last iterate with polynomially decaying step sizes in the RKHS norm. We demonstrate that the theoretical analysis established in this paper fully exploits the fine structure of the underlying RKHS, and thus can lead to sharp error estimates of online learning algorithm. version:1
arxiv-1710-03553 | Traffic Sign Timely Visual Recognizability Evaluation Based on 3D Measurable Point Clouds | http://arxiv.org/abs/1710.03553 | id:1710.03553 author:Shanxin Zhang, Cheng Wang, Zhuang Yang, Chenglu Wen, Jonathan Li, Chenhui Yang category:cs.CV  published:2017-10-10 summary:The timely provision of traffic sign information to drivers is essential for the drivers to respond, to ensure safe driving, and to avoid traffic accidents in a timely manner. We proposed a timely visual recognizability quantitative evaluation method for traffic signs in large-scale transportation environments. To achieve this goal, we first address the concept of a visibility field to reflect the visible distribution of three-dimensional (3D) space and construct a traffic sign Visibility Evaluation Model (VEM) to measure the traffic sign visibility for a given viewpoint. Then, based on the VEM, we proposed the concept of the Visual Recognizability Field (VRF) to reflect the visual recognizability distribution in 3D space and established a Visual Recognizability Evaluation Model (VREM) to measure a traffic sign visual recognizability for a given viewpoint. Next, we proposed a Traffic Sign Timely Visual Recognizability Evaluation Model (TSTVREM) by combining VREM, the actual maximum continuous visual recognizable distance, and traffic big data to measure a traffic sign visual recognizability in different lanes. Finally, we presented an automatic algorithm to implement the TSTVREM model through traffic sign and road marking detection and classification, traffic sign environment point cloud segmentation, viewpoints calculation, and TSTVREM model realization. The performance of our method for traffic sign timely visual recognizability evaluation is tested on three road point clouds acquired by a mobile laser scanning system (RIEGL VMX-450) according to Road Traffic Signs and Markings (GB 5768-1999 in China), showing that our method is feasible and efficient. version:1
arxiv-1710-03538 | Contaminated speech training methods for robust DNN-HMM distant speech recognition | http://arxiv.org/abs/1710.03538 | id:1710.03538 author:Mirco Ravanelli, Maurizio Omologo category:eess.AS cs.CL cs.SD  published:2017-10-10 summary:Despite the significant progress made in the last years, state-of-the-art speech recognition technologies provide a satisfactory performance only in the close-talking condition. Robustness of distant speech recognition in adverse acoustic conditions, on the other hand, remains a crucial open issue for future applications of human-machine interaction. To this end, several advances in speech enhancement, acoustic scene analysis as well as acoustic modeling, have recently contributed to improve the state-of-the-art in the field. One of the most effective approaches to derive a robust acoustic modeling is based on using contaminated speech, which proved helpful in reducing the acoustic mismatch between training and testing conditions. In this paper, we revise this classical approach in the context of modern DNN-HMM systems, and propose the adoption of three methods, namely, asymmetric context windowing, close-talk based supervision, and close-talk based pre-training. The experimental results, obtained using both real and simulated data, show a significant advantage in using these three methods, overall providing a 15% error rate reduction compared to the baseline systems. The same trend in performance is confirmed either using a high-quality training set of small size, and a large one. version:1
arxiv-1710-03522 | Underestimated cost of targeted attacks on complex networks | http://arxiv.org/abs/1710.03522 | id:1710.03522 author:Xiao-Long Ren, Niels Gleinig, Dijana Tolic, Nino Antulov-Fantulin category:cs.SI cs.LG physics.soc-ph  published:2017-10-10 summary:The robustness of complex networks under targeted attacks is deeply connected to the resilience of complex systems, i.e., the ability to make appropriate responses to the attacks. In this article, we investigated the state-of-the-art targeted node attack algorithms and demonstrate that they become very inefficient when the cost of the attack is taken into consideration. In this paper, we made explicit assumption that the cost of removing a node is proportional to the number of adjacent links that are removed, i.e., higher degree nodes have higher cost. Finally, for the case when it is possible to attack links, we propose a simple and efficient edge removal strategy named Hierarchical Power Iterative Normalized cut (HPI-Ncut).The results on real and artificial networks show that the HPI-Ncut algorithm outperforms all the node removal and link removal attack algorithms when the cost of the attack is taken into consideration. In addition, we show that on sparse networks, the complexity of this hierarchical power iteration edge removal algorithm is only $O(n\log^{2+\epsilon}(n))$. version:1
arxiv-1710-03488 | Automatic Streaming Segmentation of Stereo Video Using Bilateral Space | http://arxiv.org/abs/1710.03488 | id:1710.03488 author:Wenjing Ke, Yuanjie Zhu, Lei Yu category:cs.CV  published:2017-10-10 summary:In this paper, we take advantage of binocular camera and propose an unsupervised algorithm based on semi-supervised segmentation algorithm and extracting foreground part efficiently. We creatively embed depth information into bilateral grid in the graph cut model and achieve considerable segmenting accuracy in the case of no user input. The experi- ment approves the high precision, time efficiency of our algorithm and its adaptation to complex natural scenario which is significant for practical application. version:1
arxiv-1710-03487 | An Analysis of Dropout for Matrix Factorization | http://arxiv.org/abs/1710.03487 | id:1710.03487 author:Jacopo Cavazza, Connor Lane, Benjamin D. Haeffele, Vittorio Murino, René Vidal category:cs.LG stat.ML  published:2017-10-10 summary:Dropout is a simple yet effective algorithm for regularizing neural networks by randomly dropping out units through Bernoulli multiplicative noise, and for some restricted problem classes, such as linear or logistic regression, several theoretical studies have demonstrated the equivalence between dropout and a fully deterministic optimization problem with data-dependent Tikhonov regularization. This work presents a theoretical analysis of dropout for matrix factorization, where Bernoulli random variables are used to drop a factor, thereby attempting to control the size of the factorization. While recent work has demonstrated the empirical effectiveness of dropout for matrix factorization, a theoretical understanding of the regularization properties of dropout in this context remains elusive. This work demonstrates the equivalence between dropout and a fully deterministic model for matrix factorization in which the factors are regularized by the sum of the product of the norms of the columns. While the resulting regularizer is closely related to a variational form of the nuclear norm, suggesting that dropout may limit the size of the factorization, we show that it is possible to trivially lower the objective value by doubling the size of the factorization. We show that this problem is caused by the use of a fixed dropout rate, which motivates the use of a rate that increases with the size of the factorization. Synthetic experiments validate our theoretical findings. version:1
arxiv-1710-03476 | MoNoise: Modeling Noise Using a Modular Normalization System | http://arxiv.org/abs/1710.03476 | id:1710.03476 author:Rob van der Goot, Gertjan van Noord category:cs.CL  published:2017-10-10 summary:We propose MoNoise: a normalization model focused on generalizability and efficiency, it aims at being easily reusable and adaptable. Normalization is the task of translating texts from a non- canonical domain to a more canonical domain, in our case: from social media data to standard language. Our proposed model is based on a modular candidate generation in which each module is responsible for a different type of normalization action. The most important generation modules are a spelling correction system and a word embeddings module. Depending on the definition of the normalization task, a static lookup list can be crucial for performance. We train a random forest classifier to rank the candidates, which generalizes well to all different types of normaliza- tion actions. Most features for the ranking originate from the generation modules; besides these features, N-gram features prove to be an important source of information. We show that MoNoise beats the state-of-the-art on different normalization benchmarks for English and Dutch, which all define the task of normalization slightly different. version:1
