arxiv-1709-07916 | Characterizing Diabetes, Diet, Exercise, and Obesity Comments on Twitter | http://arxiv.org/abs/1709.07916 | id:1709.07916 author:Amir Karami, Alicia A. Dahl, Gabrielle Turner-McGrievy, Hadi Kharrazi, Jr. George Shaw category:cs.SI cs.CL stat.AP stat.CO stat.ML  published:2017-09-22 summary:Social media provide a platform for users to express their opinions and share information. Understanding public health opinions on social media, such as Twitter, offers a unique approach to characterizing common health issues such as diabetes, diet, exercise, and obesity (DDEO), however, collecting and analyzing a large scale conversational public health data set is a challenging research task. The goal of this research is to analyze the characteristics of the general public's opinions in regard to diabetes, diet, exercise and obesity (DDEO) as expressed on Twitter. A multi-component semantic and linguistic framework was developed to collect Twitter data, discover topics of interest about DDEO, and analyze the topics. From the extracted 4.5 million tweets, 8% of tweets discussed diabetes, 23.7% diet, 16.6% exercise, and 51.7% obesity. The strongest correlation among the topics was determined between exercise and obesity. Other notable correlations were: diabetes and obesity, and diet and obesity DDEO terms were also identified as subtopics of each of the DDEO topics. The frequent subtopics discussed along with Diabetes, excluding the DDEO terms themselves, were blood pressure, heart attack, yoga, and Alzheimer. The non-DDEO subtopics for Diet included vegetarian, pregnancy, celebrities, weight loss, religious, and mental health, while subtopics for Exercise included computer games, brain, fitness, and daily plan. Non-DDEO subtopics for Obesity included Alzheimer, cancer, and children. With 2.67 billion social media users in 2016, publicly available data such as Twitter posts can be utilized to support clinical providers, public health experts, and social scientists in better understanding common public opinions in regard to diabetes, diet, exercise, and obesity. version:1
arxiv-1709-07915 | Computational Content Analysis of Negative Tweets for Obesity, Diet, Diabetes, and Exercise | http://arxiv.org/abs/1709.07915 | id:1709.07915 author:George Shaw Jr., Amir Karami category:cs.SI cs.CL stat.AP stat.CO stat.ML  published:2017-09-22 summary:Social media based digital epidemiology has the potential to support faster response and deeper understanding of public health related threats. This study proposes a new framework to analyze unstructured health related textual data via Twitter users' post (tweets) to characterize the negative health sentiments and non-health related concerns in relations to the corpus of negative sentiments, regarding Diet Diabetes Exercise, and Obesity (DDEO). Through the collection of 6 million Tweets for one month, this study identified the prominent topics of users as it relates to the negative sentiments. Our proposed framework uses two text mining methods, sentiment analysis and topic modeling, to discover negative topics. The negative sentiments of Twitter users support the literature narratives and the many morbidity issues that are associated with DDEO and the linkage between obesity and diabetes. The framework offers a potential method to understand the publics' opinions and sentiments regarding DDEO. More importantly, this research provides new opportunities for computational social scientists, medical experts, and public health professionals to collectively address DDEO-related issues. version:1
arxiv-1709-07914 | Modeling Image Virality with Pairwise Spatial Transformer Networks | http://arxiv.org/abs/1709.07914 | id:1709.07914 author:Abhimanyu Dubey, Sumeet Agarwal category:cs.CV cs.SI  published:2017-09-22 summary:The study of virality and information diffusion online is a topic gaining traction rapidly in the computational social sciences. Computer vision and social network analysis research have also focused on understanding the impact of content and information diffusion in making content viral, with prior approaches not performing significantly well as other traditional classification tasks. In this paper, we present a novel pairwise reformulation of the virality prediction problem as an attribute prediction task and develop a novel algorithm to model image virality on online media using a pairwise neural network. Our model provides significant insights into the features that are responsible for promoting virality and surpasses the existing state-of-the-art by a 12% average improvement in prediction. We also investigate the effect of external category supervision on relative attribute prediction and observe an increase in prediction accuracy for the same across several attribute learning datasets. version:1
arxiv-1709-07902 | Unsupervised Learning of Disentangled and Interpretable Representations from Sequential Data | http://arxiv.org/abs/1709.07902 | id:1709.07902 author:Wei-Ning Hsu, Yu Zhang, James Glass category:cs.LG cs.CL cs.SD eess.AS stat.ML  published:2017-09-22 summary:We present a factorized hierarchical variational autoencoder, which learns disentangled and interpretable representations from sequential data without supervision. Specifically, we exploit the multi-scale nature of information in sequential data by formulating it explicitly within a factorized hierarchical graphical model that imposes sequence-dependent priors and sequence-independent priors to different sets of latent variables. The model is evaluated on two speech corpora to demonstrate, qualitatively, its ability to transform speakers or linguistic content by manipulating different sets of latent variables; and quantitatively, its ability to outperform an i-vector baseline for speaker verification and reduce the word error rate by as much as 35% in mismatched train/test scenarios for automatic speech recognition tasks. version:1
arxiv-1709-07899 | On the Discrimination Power and Effective Utilization of Active Learning Measures in Version Space Search | http://arxiv.org/abs/1709.07899 | id:1709.07899 author:Patrick Rodler category:cs.LG  published:2017-09-22 summary:Active Learning (AL) methods have proven cost-saving against passive supervised methods in many application domains. An active learner, aiming to find some target hypothesis, formulates sequential queries to some oracle. The set of hypotheses consistent with the already answered queries is called version space. Several query selection measures (QSMs) for determining the best query to ask next have been proposed. Assuming binaryoutcome queries, we analyze various QSMs wrt. to the discrimination power of their selected queries within the current version space. As a result, we derive superiority and equivalence relations between these QSMs and introduce improved versions of existing QSMs to overcome identified issues. The obtained picture gives a hint about which QSMs should preferably be used in pool-based AL scenarios. Moreover, we deduce properties optimal queries wrt. QSMs must satisfy. Based on these, we demonstrate how efficient heuristic search methods for optimal queries in query synthesis AL scenarios can be devised. version:1
arxiv-1709-07894 | A Real-time Action Prediction Framework by Encoding Temporal Evolution for Assembly Tasks | http://arxiv.org/abs/1709.07894 | id:1709.07894 author:Fahimeh Rezazadegan, Larry S. Davis, Sareh Shirazi category:cs.CV  published:2017-09-22 summary:Anticipating future actions is a key component of intelligence, specifically when it applies to real-time systems, such as robots or autonomous cars. While recent work has addressed prediction of raw RGB pixel values in future video frames, we focus on predicting further in future by predicting a summary of moving pixels through a sequence of frames which we call dynamic images. More precisely, given a dynamic image, we predict the motion evolution through next unseen video frames. Since this representation consists of a sequence of frames, we can go one second further into the future compared to the previous work in this field. We employed convolutional LSTMs to train our network on the dynamic images in an unsupervised learning process. Since our final goal is predicting the next action of a complex task such as an assembly task, we exploited labelled actions for the recognition process on top of predicted dynamic images. We show the effectiveness of our method on predicting the next human action in the above-mentioned task through the two-step process of predicting the next dynamic image and recognizing the action which it represents. version:1
arxiv-1709-07886 | Machine Learning Models that Remember Too Much | http://arxiv.org/abs/1709.07886 | id:1709.07886 author:Congzheng Song, Thomas Ristenpart, Vitaly Shmatikov category:cs.CR cs.LG  published:2017-09-22 summary:Machine learning (ML) is becoming a commodity. Numerous ML frameworks and services are available to data holders who are not ML experts but want to train predictive models on their data. It is important that ML models trained on sensitive inputs (e.g., personal images or documents) not leak too much information about the training data. We consider a malicious ML provider who supplies model-training code to the data holder, does not observe the training, but then obtains white- or black-box access to the resulting model. In this setting, we design and implement practical algorithms, some of them very similar to standard ML techniques such as regularization and data augmentation, that "memorize" information about the training dataset in the model yet the model is as accurate and predictive as a conventionally trained model. We then explain how the adversary can extract memorized information from the model. We evaluate our techniques on standard ML tasks for image classification (CIFAR10), face recognition (LFW and FaceScrub), and text analysis (20 Newsgroups and IMDB). In all cases, we show how our algorithms create models that have high predictive power yet allow accurate extraction of subsets of their training data. version:1
arxiv-1709-07862 | Mitigating the Impact of Speech Recognition Errors on Chatbot using Sequence-to-sequence Model | http://arxiv.org/abs/1709.07862 | id:1709.07862 author:Pin-Jung Chen, I-Hung Hsu, Yi-Yao Huang, Hung-Yi Lee category:cs.CL  published:2017-09-22 summary:We apply sequence-to-sequence model to mitigate the impact of speech recognition errors on open domain end-to-end dialog generation. We cast the task as a domain adaptation problem where ASR transcriptions and original text are in two different domains. In this paper, our proposed model includes two individual encoders for each domain data and make their hidden states similar to ensure the decoder predict the same dialog text. The method shows that the sequence-to-sequence model can learn the ASR transcriptions and original text pair having the same meaning and eliminate the speech recognition errors. Experimental results on Cornell movie dialog dataset demonstrate that the domain adaption system help the spoken dialog system generate more similar responses with the original text answers. version:1
arxiv-1709-07858 | Bootstrapping incremental dialogue systems from minimal data: the generalisation power of dialogue grammars | http://arxiv.org/abs/1709.07858 | id:1709.07858 author:Arash Eshghi, Igor Shalyminov, Oliver Lemon category:cs.CL I.2.7  published:2017-09-22 summary:We investigate an end-to-end method for automatically inducing task-based dialogue systems from small amounts of unannotated dialogue data. It combines an incremental semantic grammar - Dynamic Syntax and Type Theory with Records (DS-TTR) - with Reinforcement Learning (RL), where language generation and dialogue management are a joint decision problem. The systems thus produced are incremental: dialogues are processed word-by-word, shown previously to be essential in supporting natural, spontaneous dialogue. We hypothesised that the rich linguistic knowledge within the grammar should enable a combinatorially large number of dialogue variations to be processed, even when trained on very few dialogues. Our experiments show that our model can process 74% of the Facebook AI bAbI dataset even when trained on only 0.13% of the data (5 dialogues). It can in addition process 65% of bAbI+, a corpus we created by systematically adding incremental dialogue phenomena such as restarts and self-corrections to bAbI. We compare our model with a state-of-the-art retrieval model, MemN2N. We find that, in terms of semantic accuracy, MemN2N shows very poor robustness to the bAbI+ transformations even when trained on the full bAbI dataset. version:1
arxiv-1709-07840 | Challenging Neural Dialogue Models with Natural Data: Memory Networks Fail on Incremental Phenomena | http://arxiv.org/abs/1709.07840 | id:1709.07840 author:Igor Shalyminov, Arash Eshghi, Oliver Lemon category:cs.CL I.2.7  published:2017-09-22 summary:Natural, spontaneous dialogue proceeds incrementally on a word-by-word basis; and it contains many sorts of disfluency such as mid-utterance/sentence hesitations, interruptions, and self-corrections. But training data for machine learning approaches to dialogue processing is often either cleaned-up or wholly synthetic in order to avoid such phenomena. The question then arises of how well systems trained on such clean data generalise to real spontaneous dialogue, or indeed whether they are trainable at all on naturally occurring dialogue data. To answer this question, we created a new corpus called bAbI+ by systematically adding natural spontaneous incremental dialogue phenomena such as restarts and self-corrections to the Facebook AI Research's bAbI dialogues dataset. We then explore the performance of a state-of-the-art retrieval model, MemN2N, on this more natural dataset. Results show that the semantic accuracy of the MemN2N model drops drastically; and that although it is in principle able to learn to process the constructions in bAbI+, it needs an impractical amount of training data to do so. Finally, we go on to show that an incremental, semantic parser -- DyLan -- shows 100% semantic accuracy on both bAbI and bAbI+, highlighting the generalisation properties of linguistically informed dialogue models. version:1
arxiv-1709-07814 | Attention-based Wav2Text with Feature Transfer Learning | http://arxiv.org/abs/1709.07814 | id:1709.07814 author:Andros Tjandra, Sakriani Sakti, Satoshi Nakamura category:cs.CL cs.LG cs.SD  published:2017-09-22 summary:Conventional automatic speech recognition (ASR) typically performs multi-level pattern recognition tasks that map the acoustic speech waveform into a hierarchy of speech units. But, it is widely known that information loss in the earlier stage can propagate through the later stages. After the resurgence of deep learning, interest has emerged in the possibility of developing a purely end-to-end ASR system from the raw waveform to the transcription without any predefined alignments and hand-engineered models. However, the successful attempts in end-to-end architecture still used spectral-based features, while the successful attempts in using raw waveform were still based on the hybrid deep neural network - Hidden Markov model (DNN-HMM) framework. In this paper, we construct the first end-to-end attention-based encoder-decoder model to process directly from raw speech waveform to the text transcription. We called the model as "Attention-based Wav2Text". To assist the training process of the end-to-end model, we propose to utilize a feature transfer learning. Experimental results also reveal that the proposed Attention-based Wav2Text model directly with raw waveform could achieve a better result in comparison with the attentional encoder-decoder model trained on standard front-end filterbank features. version:1
arxiv-1709-07809 | Neural Machine Translation | http://arxiv.org/abs/1709.07809 | id:1709.07809 author:Philipp Koehn category:cs.CL  published:2017-09-22 summary:Draft of textbook chapter on neural machine translation. a comprehensive treatment of the topic, ranging from introduction to neural networks, computation graphs, description of the currently dominant attentional sequence-to-sequence model, recent refinements, alternative architectures and challenges. Written as chapter for the textbook Statistical Machine Translation. Used in the JHU Fall 2017 class on machine translation. version:1
arxiv-1708-04729 | Deconvolutional Paragraph Representation Learning | http://arxiv.org/abs/1708.04729 | id:1708.04729 author:Yizhe Zhang, Dinghan Shen, Guoyin Wang, Zhe Gan, Ricardo Henao, Lawrence Carin category:cs.CL cs.LG stat.ML  published:2017-08-16 summary:Learning latent representations from long text sequences is an important first step in many natural language processing applications. Recurrent Neural Networks (RNNs) have become a cornerstone for this challenging task. However, the quality of sentences during RNN-based decoding (reconstruction) decreases with the length of the text. We propose a sequence-to-sequence, purely convolutional and deconvolutional autoencoding framework that is free of the above issue, while also being computationally efficient. The proposed method is simple, easy to implement and can be leveraged as a building block for many applications. We show empirically that compared to RNNs, our framework is better at reconstructing and correcting long paragraphs. Quantitative evaluation on semi-supervised text classification and summarization tasks demonstrate the potential for better utilization of long unlabeled text data. version:3
arxiv-1709-07794 | Tropical Land Use Land Cover Mapping in Pará (Brazil) using Discriminative Markov Random Fields and Multi-temporal TerraSAR-X Data | http://arxiv.org/abs/1709.07794 | id:1709.07794 author:Ron Hagensieker, Ribana Roscher, Johannes Rosentreter, Benjamin Jakimow, Björn Waske category:cs.CV  published:2017-09-22 summary:Remote sensing satellite data offer the unique possibility to map land use land cover transformations by providing spatially explicit information. However, detection of short-term processes and land use patterns of high spatial-temporal variability is a challenging task. We present a novel framework using multi-temporal TerraSAR-X data and machine learning techniques, namely Discriminative Markov Random Fields with spatio-temporal priors, and Import Vector Machines, in order to advance the mapping of land cover characterized by short-term changes. Our study region covers a current deforestation frontier in the Brazilian state Par\'{a} with land cover dominated by primary forests, different types of pasture land and secondary vegetation, and land use dominated by short-term processes such as slash-and-burn activities. The data set comprises multi-temporal TerraSAR-X imagery acquired over the course of the 2014 dry season, as well as optical data (RapidEye, Landsat) for reference. Results show that land use land cover is reliably mapped, resulting in spatially adjusted overall accuracies of up to $79\%$ in a five class setting, yet limitations for the differentiation of different pasture types remain. The proposed method is applicable on multi-temporal data sets, and constitutes a feasible approach to map land use land cover in regions that are affected by high-frequent temporal changes. version:1
arxiv-1709-07777 | Sentence Correction Based on Large-scale Language Modelling | http://arxiv.org/abs/1709.07777 | id:1709.07777 author:Ji Wen category:cs.CL  published:2017-09-22 summary:With the further development of informatization, more and more data is stored in the form of text. There are some loss of text during their generation and transmission. The paper aims to establish a language model based on the large-scale corpus to complete the restoration of missing text. In this paper, we introduce a novel measurement to find the missing words, and a way of establishing a comprehensive candidate lexicon to insert the correct choice of words. The paper also introduces some effective optimization methods, which largely improve the efficiency of the text restoration and shorten the time of dealing with 1000 sentences into 3.6 seconds. \keywords{ language model, sentence correction, word imputation, parallel optimization version:1
arxiv-1709-07776 | Computation Error Analysis of Block Floating Point Arithmetic Oriented Convolution Neural Network Accelerator Design | http://arxiv.org/abs/1709.07776 | id:1709.07776 author:Zhourui Song, Zhenyu Liu, Chunlu Wang, Dongsheng Wang category:cs.LG  published:2017-09-22 summary:The heavy burdens of computation and off-chip traffic impede deploying the large scale convolution neural network on embedded platforms. As CNN is attributed to the strong endurance to computation errors, employing block floating point (BFP) arithmetics in CNN accelerators could save the hardware cost and data traffics efficiently, while maintaining the classification accuracy. In this paper, we verify the effects of word width definitions in BFP to the CNN performance without retraining. Several typical CNN models, including VGG16, ResNet-18, ResNet-50 and GoogLeNet, were tested in this paper. Experiments revealed that 8-bit mantissa, including sign bit, in BFP representation merely induced less than 0.3% accuracy loss. In addition, we investigate the computational errors in theory and develop the noise-to-signal ratio (NSR) upper bound, which provides the promising guidance for BFP based CNN engine design. version:1
arxiv-1708-09477 | A Compressive Sensing Approach to Community Detection with Applications | http://arxiv.org/abs/1708.09477 | id:1708.09477 author:Ming-Jun Lai, Daniel Mckenzie category:cs.IT cs.LG math.IT stat.ML  published:2017-08-30 summary:The community detection problem for graphs asks one to partition the n vertices V of a graph G into k communities, or clusters, such that there are many intracluster edges and few intercluster edges. Of course this is equivalent to finding a permutation matrix P such that, if A denotes the adjacency matrix of G, then PAP^T is approximately block diagonal. As there are k^n possible partitions of n vertices into k subsets, directly determining the optimal clustering is clearly infeasible. Instead one seeks to solve a more tractable approximation to the clustering problem. In this paper we reformulate the community detection problem via sparse solution of a linear system associated with the Laplacian of a graph G and then develop a two-stage approach based on a thresholding technique and a compressive sensing algorithm to find a sparse solution which corresponds to the community containing a vertex of interest in G. Crucially, our approach results in an algorithm which is able to find a single cluster of size n_0 in O(nlog(n)n_0) operations and all k clusters in fewer than O(n^2ln(n)) operations. This is a marked improvement over the classic spectral clustering algorithm, which is unable to find a single cluster at a time and takes approximately O(n^3) operations to find all k clusters. Moreover, we are able to provide robust guarantees of success for the case where G is drawn at random from the Stochastic Block Model, a popular model for graphs with clusters. Extensive numerical results are also provided, showing the efficacy of our algorithm on both synthetic and real-world data sets. version:2
arxiv-1709-07758 | Improving Language Modelling with Noise-contrastive estimation | http://arxiv.org/abs/1709.07758 | id:1709.07758 author:Farhana Ferdousi Liza, Marek Grzes category:cs.CL  published:2017-09-22 summary:Neural language models do not scale well when the vocabulary is large. Noise-contrastive estimation (NCE) is a sampling-based method that allows for fast learning with large vocabularies. Although NCE has shown promising performance in neural machine translation, it was considered to be an unsuccessful approach for language modelling. A sufficient investigation of the hyperparameters in the NCE-based neural language models was also missing. In this paper, we showed that NCE can be a successful approach in neural language modelling when the hyperparameters of a neural network are tuned appropriately. We introduced the 'search-then-converge' learning rate schedule for NCE and designed a heuristic that specifies how to use this schedule. The impact of the other important hyperparameters, such as the dropout rate and the weight initialisation range, was also demonstrated. We showed that appropriate tuning of NCE-based neural language models outperforms the state-of-the-art single-model methods on a popular benchmark. version:1
arxiv-1709-07731 | Estimate Exchange over Network is Good for Distributed Hard Thresholding Pursuit | http://arxiv.org/abs/1709.07731 | id:1709.07731 author:Ahmed Zaki, Partha P. Mitra, Lars K. Rasmussen, Saikat Chatterjee category:stat.ML eess.SP  published:2017-09-22 summary:We investigate an existing distributed algorithm for learning sparse signals or data over networks. The algorithm is iterative and exchanges intermediate estimates of a sparse signal over a network. This learning strategy using exchange of intermediate estimates over the network requires a limited communication overhead for information transmission. Our objective in this article is to show that the strategy is good for learning in spite of limited communication. In pursuit of this objective, we first provide a restricted isometry property (RIP)-based theoretical analysis on convergence of the iterative algorithm. Then, using simulations, we show that the algorithm provides competitive performance in learning sparse signals vis-a-vis an existing alternate distributed algorithm. The alternate distributed algorithm exchanges more information including observations and system parameters. version:1
arxiv-1709-07720 | Can We Boost the Power of the Viola-Jones Face Detector Using Pre-processing? An Empirical Study | http://arxiv.org/abs/1709.07720 | id:1709.07720 author:Mahmoud Afifi, Marwa Nasser, Mostafa Korashy, Katherine Rohde, Aly Abdelrahim category:cs.CV  published:2017-09-22 summary:The Viola-Jones face detection algorithm was (and still is) a quite popular face detector. In spite of the numerous face detection techniques that have been recently presented, there are many research works that are still based on the Viola-Jones algorithm because of its simplicity. In this paper, we study the influence of a set of blind pre-processing methods on the face detection rate using the Viola-Jones algorithm. We focus on two aspects of improvement, specifically badly illuminated faces and blurred faces. Many methods for lighting invariant and deblurring are used in order to improve the detection accuracy. We want to avoid using blind pre-processing methods that may obstruct the face detector. To that end, we perform two sets of experiments. The first set is performed to avoid any blind pre-processing method that may hurt the face detector. The second set is performed to study the effect of the selected pre-processing methods on images that suffer from hard conditions. We present two manners of applying the pre-processing method to the image prior to being used by the Viola-Jones face detector. Four different datasets are used to draw a coherent conclusion about the potential improvement caused by using prior enhanced images. The results demonstrate that some of the pre-processing methods may hurt the accuracy of Viola-Jones face detection algorithm. However, other pre-processing methods have an evident positive impact on the accuracy of the face detector. Overall, we recommend three simple and fast blind photometric normalization methods as a pre-processing step in order to improve the accuracy of the pre-trained Viola-Jones face detector. version:1
arxiv-1708-06004 | Boltzmann machines for time-series | http://arxiv.org/abs/1708.06004 | id:1708.06004 author:Takayuki Osogami category:cs.NE  published:2017-08-20 summary:We review Boltzmann machines extended for time-series. These models often have recurrent structure, and back propagration through time (BPTT) is used to learn their parameters. The per-step computational complexity of BPTT in online learning, however, grows linearly with respect to the length of preceding time-series (i.e., learning rule is not local in time), which limits the applicability of BPTT in online learning. We then review dynamic Boltzmann machines (DyBMs), whose learning rule is local in time. DyBM's learning rule relates to spike-timing dependent plasticity (STDP), which has been postulated and experimentally confirmed for biological neural networks. version:2
arxiv-1709-07681 | STAR: Spatio-Temporal Altimeter Waveform Retracking using Sparse Representation and Conditional Random Fields | http://arxiv.org/abs/1709.07681 | id:1709.07681 author:Ribana Roscher, Bernd Uebbing, Jürgen Kusche category:physics.ao-ph cs.CV  published:2017-09-22 summary:Satellite radar altimetry is one of the most powerful techniques for measuring sea surface height variations, with applications ranging from operational oceanography to climate research. Over open oceans, altimeter return waveforms generally correspond to the Brown model, and by inversion, estimated shape parameters provide mean surface height and wind speed. However, in coastal areas or over inland waters, the waveform shape is often distorted by land influence, resulting in peaks or fast decaying trailing edges. As a result, derived sea surface heights are then less accurate and waveforms need to be reprocessed by sophisticated algorithms. To this end, this work suggests a novel Spatio-Temporal Altimetry Retracking (STAR) technique. We show that STAR enables the derivation of sea surface heights over the open ocean as well as over coastal regions of at least the same quality as compared to existing retracking methods, but for a larger number of cycles and thus retaining more useful data. Novel elements of our method are (a) integrating information from spatially and temporally neighboring waveforms through a conditional random field approach, (b) sub-waveform detection, where relevant sub-waveforms are separated from corrupted or non-relevant parts through a sparse representation approach, and (c) identifying the final best set of sea surfaces heights from multiple likely heights using Dijkstra's algorithm. We apply STAR to data from the Jason-1, Jason-2 and Envisat missions for study sites in the Gulf of Trieste, Italy and in the coastal region of the Ganges-Brahmaputra-Meghna estuary, Bangladesh. We compare to several established and recent retracking methods, as well as to tide gauge data. Our experiments suggest that the obtained sea surface heights are significantly less affected by outliers when compared to results obtained by other approaches. version:1
arxiv-1709-07638 | Approximate Bayesian Inference in Linear State Space Models for Intermittent Demand Forecasting at Scale | http://arxiv.org/abs/1709.07638 | id:1709.07638 author:Matthias Seeger, Syama Rangapuram, Yuyang Wang, David Salinas, Jan Gasthaus, Tim Januschowski, Valentin Flunkert category:stat.ML cs.LG  published:2017-09-22 summary:We present a scalable and robust Bayesian inference method for linear state space models. The method is applied to demand forecasting in the context of a large e-commerce platform, paying special attention to intermittent and bursty target statistics. Inference is approximated by the Newton-Raphson algorithm, reduced to linear-time Kalman smoothing, which allows us to operate on several orders of magnitude larger problems than previous related work. In a study on large real-world sales datasets, our method outperforms competing approaches on fast and medium moving items. version:1
arxiv-1709-07634 | EraseReLU: A Simple Way to Ease the Training of Deep Convolution Neural Networks | http://arxiv.org/abs/1709.07634 | id:1709.07634 author:Xuanyi Dong, Guoliang Kang, Kun Zhan, Yi Yang category:cs.CV  published:2017-09-22 summary:For most state-of-the-art architectures, Rectified Linear Unit (ReLU) becomes a standard component accompanied by each layer. Although ReLU can ease the network training to an extent, the character of blocking negative values may suppress the propagation of useful information and leads to the difficulty of optimizing very deep Convolutional Neural Networks (CNNs). Moreover, stacking of layers with nonlinear activations is hard to approximate the intrinsic linear transformations between feature representations. In this paper, we investigate the effect of erasing ReLUs of certain layers and apply it to various representative architectures. We name our approach as "EraseReLU". It can ease the optimization and improve the generalization performance for very deep CNN models. In experiments, this method successfully improves the performance of various representative architectures, and we report the improved results on SVHN, CIFAR-10/100, and ImageNet-1k. By using EraseReLU, we achieve state-of-the-art single-model performance on CIFAR-100 with 83.47% accuracy. Codes will be released soon. version:1
arxiv-1709-07626 | BreathRNNet: Breathing Based Authentication on Resource-Constrained IoT Devices using RNNs | http://arxiv.org/abs/1709.07626 | id:1709.07626 author:Jagmohan Chauhan, Suranga Seneviratne, Yining Hu, Archan Misra, Aruna Seneviratne, Youngki Lee category:cs.CR cs.LG cs.NE  published:2017-09-22 summary:Recurrent neural networks (RNNs) have shown promising results in audio and speech processing applications due to their strong capabilities in modelling sequential data. In many applications, RNNs tend to outperform conventional models based on GMM/UBMs and i-vectors. Increasing popularity of IoT devices makes a strong case for implementing RNN based inferences for applications such as acoustics based authentication, voice commands, and edge analytics for smart homes. Nonetheless, the feasibility and performance of RNN based inferences on resources-constrained IoT devices remain largely unexplored. In this paper, we investigate the feasibility of using RNNs for an end-to-end authentication system based on breathing acoustics. We evaluate the performance of RNN models on three types of devices; smartphone, smartwatch, and Raspberry Pi and show that unlike CNN models, RNN models can be easily ported onto resource-constrained devices without a significant loss in accuracy. version:1
arxiv-1709-07625 | Total stability of kernel methods | http://arxiv.org/abs/1709.07625 | id:1709.07625 author:Andreas Christmann, Daohong Xiang, Ding-Xuan Zhou category:stat.ML cs.LG  published:2017-09-22 summary:Regularized empirical risk minimization using kernels and their corresponding reproducing kernel Hilbert spaces (RKHSs) plays an important role in machine learning. However, the actually used kernel often depends on one or on a few hyperparameters or the kernel is even data dependent in a much more complicated manner. Examples are Gaussian RBF kernels, kernel learning, and hierarchical Gaussian kernels which were recently proposed for deep learning. Therefore, the actually used kernel is often computed by a grid search or in an iterative manner and can often only be considered as an approximation to the "ideal" or "optimal" kernel. The paper gives conditions under which classical kernel based methods based on a convex Lipschitz loss function and on a bounded and smooth kernel are stable, if the probability measure $P$, the regularization parameter $\lambda$, and the kernel $k$ may slightly change in a simultaneous manner. Similar results are also given for pairwise learning. Therefore, the topic of this paper is somewhat more general than in classical robust statistics, where usually only the influence of small perturbations of the probability measure $P$ on the estimated function is considered. version:1
arxiv-1709-07616 | Generalized Bayesian Updating and the Loss-Likelihood Bootstrap | http://arxiv.org/abs/1709.07616 | id:1709.07616 author:Simon Lyddon, Chris Holmes, Stephen Walker category:stat.ME stat.ML  published:2017-09-22 summary:In this paper, we revisit the weighted likelihood bootstrap and show that it is well-motivated for Bayesian inference under misspecified models. We extend the underlying idea to a wider family of inferential problems. This allows us to calibrate an analogue of the likelihood function in situations where little is known about the data-generating mechanism. We demonstrate our method on a number of examples. version:1
arxiv-1706-03475 | Confident Multiple Choice Learning | http://arxiv.org/abs/1706.03475 | id:1706.03475 author:Kimin Lee, Changho Hwang, KyoungSoo Park, Jinwoo Shin category:cs.LG stat.ML  published:2017-06-12 summary:Ensemble methods are arguably the most trustworthy techniques for boosting the performance of machine learning models. Popular independent ensembles (IE) relying on naive averaging/voting scheme have been of typical choice for most applications involving deep neural networks, but they do not consider advanced collaboration among ensemble models. In this paper, we propose new ensemble methods specialized for deep neural networks, called confident multiple choice learning (CMCL): it is a variant of multiple choice learning (MCL) via addressing its overconfidence issue.In particular, the proposed major components of CMCL beyond the original MCL scheme are (i) new loss, i.e., confident oracle loss, (ii) new architecture, i.e., feature sharing and (iii) new training method, i.e., stochastic labeling. We demonstrate the effect of CMCL via experiments on the image classification on CIFAR and SVHN, and the foreground-background segmentation on the iCoseg. In particular, CMCL using 5 residual networks provides 14.05% and 6.60% relative reductions in the top-1 error rates from the corresponding IE scheme for the classification task on CIFAR and SVHN, respectively. version:2
arxiv-1709-07599 | High-Resolution Shape Completion Using Deep Neural Networks for Global Structure and Local Geometry Inference | http://arxiv.org/abs/1709.07599 | id:1709.07599 author:Xiaoguang Han, Zhen Li, Haibin Huang, Evangelos Kalogerakis, Yizhou Yu category:cs.CV cs.CG cs.GR  published:2017-09-22 summary:We propose a data-driven method for recovering miss-ing parts of 3D shapes. Our method is based on a new deep learning architecture consisting of two sub-networks: a global structure inference network and a local geometry refinement network. The global structure inference network incorporates a long short-term memorized context fusion module (LSTM-CF) that infers the global structure of the shape based on multi-view depth information provided as part of the input. It also includes a 3D fully convolutional (3DFCN) module that further enriches the global structure representation according to volumetric information in the input. Under the guidance of the global structure network, the local geometry refinement network takes as input lo-cal 3D patches around missing regions, and progressively produces a high-resolution, complete surface through a volumetric encoder-decoder architecture. Our method jointly trains the global structure inference and local geometry refinement networks in an end-to-end manner. We perform qualitative and quantitative evaluations on six object categories, demonstrating that our method outperforms existing state-of-the-art work on shape completion. version:1
arxiv-1709-07598 | Demography-based Facial Retouching Detection using Subclass Supervised Sparse Autoencoder | http://arxiv.org/abs/1709.07598 | id:1709.07598 author:Aparna Bharati, Mayank Vatsa, Richa Singh, Kevin W. Bowyer, Xin Tong category:cs.CV  published:2017-09-22 summary:Digital retouching of face images is becoming more widespread due to the introduction of software packages that automate the task. Several researchers have introduced algorithms to detect whether a face image is original or retouched. However, previous work on this topic has not considered whether or how accuracy of retouching detection varies with the demography of face images. In this paper, we introduce a new Multi-Demographic Retouched Faces (MDRF) dataset, which contains images belonging to two genders, male and female, and three ethnicities, Indian, Chinese, and Caucasian. Further, retouched images are created using two different retouching software packages. The second major contribution of this research is a novel semi-supervised autoencoder incorporating "subclass" information to improve classification. The proposed approach outperforms existing state-of-the-art detection algorithms for the task of generalized retouching detection. Experiments conducted with multiple combinations of ethnicities show that accuracy of retouching detection can vary greatly based on the demographics of the training and testing images. version:1
arxiv-1709-07592 | Learning to Generate Time-Lapse Videos Using Multi-Stage Dynamic Generative Adversarial Networks | http://arxiv.org/abs/1709.07592 | id:1709.07592 author:Wei Xiong, Wenhan Luo, Lin Ma, Wei Liu, Jiebo Luo category:cs.CV  published:2017-09-22 summary:Taking a photo outside, can we predict the immediate future, like how the cloud would move in the sky? We answer this question by presenting a generative adversarial network (GAN) based two-stage approach to generating realistic time-lapse videos of high resolution. Given the first frame, our model learns to generate long-term future frames. The first stage aims to generate videos of similar content as that in the input frame and of plausible motion dynamics. The second stage refines the generated video from the first stage by enforcing it to be closer to real videos with regard to dynamics. To further encourage realistic motion in the final generated video, Gram matrix is employed to model the motion more precisely. We build a large scale time-lapse dataset, and test our approach on this new dataset. Using our model, we are able to generate up to $128\times 128$ resolution videos for 32 frames in a single forward pass. Quantitative and qualitative experiment results demonstrate the superiority of our method over the state-of-the-art methods. version:1
arxiv-1708-03307 | Cell Detection with Deep Convolutional Neural Network and Compressed Sensing | http://arxiv.org/abs/1708.03307 | id:1708.03307 author:Yao Xue, Nilanjan Ray category:cs.CV  published:2017-08-10 summary:The ability to automatically detect certain types of cells or cellular subunits in microscopy images is of significant interest to a wide range of biomedical research and clinical practices. Cell detection methods have evolved from employing hand-crafted features to deep learning-based techniques to locate target cells. The essential idea of these methods is that their cell classifiers or detectors are trained in the pixel space, where the locations of target cells are labeled. In this paper, we seek a different route and propose a convolutional neural network (CNN)-based cell detection method that uses encoding of the output pixel space. For the cell detection problem, the output space is the sparsely labeled pixel locations indicating cell centers. Consequently, we employ random projections to encode the output space to a compressed vector of fixed dimension. Then, CNN regresses this compressed vector from the input pixels. Using $L_1$-norm optimization, we recover sparse cell locations on the output pixel space from the predicted compressed vector. In the past, output space encoding using compressed sensing (CS) has been used in conjunction with linear and non-linear predictors. To the best of our knowledge, this is the first successful use of CNN with CS-based output space encoding. We experimentally demonstrate that proposed CNN + CS framework (referred to as CNNCS) exceeds the accuracy of the state-of-the-art methods on many benchmark datasets for microscopy cell detection. Additionally, we show that CNNCS can exploit ensemble average by using more than one random encodings of the output space. In the AMIDA13 MICCAI grand competition, we achieve the 3rd highest F1-score in all the 17 participated teams. More ranking details are available at http://amida13.isi.uu.nl/?q=node/62. Implementation of CNNCS is available at https://github.com/yaoxuexa/CNNCS. version:2
arxiv-1709-07584 | Happy Travelers Take Big Pictures: A Psychological Study with Machine Learning and Big Data | http://arxiv.org/abs/1709.07584 | id:1709.07584 author:Xuefeng Liang, Lixin Fan, Yuen Peng Loh, Yang Liu, Song Tong category:cs.CV  published:2017-09-22 summary:In psychology, theory-driven researches are usually conducted with extensive laboratory experiments, yet rarely tested or disproved with big data. In this paper, we make use of 418K travel photos with traveler ratings to test the influential "broaden-and-build" theory, that suggests positive emotions broaden one's visual attention. The core hypothesis examined in this study is that positive emotion is associated with a wider attention, hence highly-rated sites would trigger wide-angle photographs. By analyzing travel photos, we find a strong correlation between a preference for wide-angle photos and the high rating of tourist sites on TripAdvisor. We are able to carry out this analysis through the use of deep learning algorithms to classify the photos into wide and narrow angles, and present this study as an exemplar of how big data and deep learning can be used to test laboratory findings in the wild. version:1
arxiv-1709-07566 | Smart Mirror: Intelligent Makeup Recommendation and Synthesis | http://arxiv.org/abs/1709.07566 | id:1709.07566 author:Tam V. Nguyen, Luoqi Liu category:cs.CV  published:2017-09-22 summary:The female facial image beautification usually requires professional editing softwares, which are relatively difficult for common users. In this demo, we introduce a practical system for automatic and personalized facial makeup recommendation and synthesis. First, a model describing the relations among facial features, facial attributes and makeup attributes is learned as the makeup recommendation model for suggesting the most suitable makeup attributes. Then the recommended makeup attributes are seamlessly synthesized onto the input facial image. version:1
arxiv-1709-07565 | Novel Evaluation Metrics for Seam Carving based Image Retargeting | http://arxiv.org/abs/1709.07565 | id:1709.07565 author:Tam V. Nguyen, Guangyu Gao category:cs.CV  published:2017-09-22 summary:Image retargeting effectively resizes images by preserving the recognizability of important image regions. Most of retargeting methods rely on good importance maps as a cue to retain or remove certain regions in the input image. In addition, the traditional evaluation exhaustively depends on user ratings. There is a legitimate need for a methodological approach for evaluating retargeted results. Therefore, in this paper, we conduct a study and analysis on the prominent method in image retargeting, Seam Carving. First, we introduce two novel evaluation metrics which can be considered as the proxy of user ratings. Second, we exploit salient object dataset as a benchmark for this task. We then investigate different types of importance maps for this particular problem. The experiments show that humans in general agree with the evaluation metrics on the retargeted results and some importance map methods are consistently more favorable than others. version:1
arxiv-1709-07551 | Virtual Blood Vessels in Complex Background using Stereo X-ray Images | http://arxiv.org/abs/1709.07551 | id:1709.07551 author:Qiuyu Chen, Ryoma Bise, Lin Gu, Yinqiang Zheng, Imari Sato, Jenq-Neng Hwang, Nobuaki Imanishi, Sadakazu Aiso category:cs.CV  published:2017-09-22 summary:We propose a fully automatic system to reconstruct and visualize 3D blood vessels in Augmented Reality (AR) system from stereo X-ray images with bones and body fat. Currently, typical 3D imaging technologies are expensive and carrying the risk of irradiation exposure. To reduce the potential harm, we only need to take two X-ray images before visualizing the vessels. Our system can effectively reconstruct and visualize vessels in following steps. We first conduct initial segmentation using Markov Random Field and then refine segmentation in an entropy based post-process. We parse the segmented vessels by extracting their centerlines and generating trees. We propose a coarse-to-fine scheme for stereo matching, including initial matching using affine transform and dense matching using Hungarian algorithm guided by Gaussian regression. Finally, we render and visualize the reconstructed model in a HoloLens based AR system, which can essentially change the way of visualizing medical data. We have evaluated its performance by using synthetic and real stereo X-ray images, and achieved satisfactory quantitative and qualitative results. version:1
arxiv-1709-07545 | Attention-based Mixture Density Recurrent Networks for History-based Recommendation | http://arxiv.org/abs/1709.07545 | id:1709.07545 author:Tian Wang, Kyunghyun Cho category:cs.LG cs.IR  published:2017-09-22 summary:The goal of personalized history-based recommendation is to automatically output a distribution over all the items given a sequence of previous purchases of a user. In this work, we present a novel approach that uses a recurrent network for summarizing the history of purchases, continuous vectors representing items for scalability, and a novel attention-based recurrent mixture density network, which outputs each component in a mixture sequentially, for modelling a multi-modal conditional distribution. We evaluate the proposed approach on two publicly available datasets, MovieLens-20M and RecSys15. The experiments show that the proposed approach, which explicitly models the multi-modal nature of the predictive distribution, is able to improve the performance over various baselines in terms of precision, recall and nDCG. version:1
arxiv-1708-09843 | Predicting Cardiovascular Risk Factors from Retinal Fundus Photographs using Deep Learning | http://arxiv.org/abs/1708.09843 | id:1708.09843 author:Ryan Poplin, Avinash V. Varadarajan, Katy Blumer, Yun Liu, Michael V. McConnell, Greg S. Corrado, Lily Peng, Dale R. Webster category:cs.CV  published:2017-08-31 summary:Traditionally, medical discoveries are made by observing associations and then designing experiments to test these hypotheses. However, observing and quantifying associations in images can be difficult because of the wide variety of features, patterns, colors, values, shapes in real data. In this paper, we use deep learning, a machine learning technique that learns its own features, to discover new knowledge from retinal fundus images. Using models trained on data from 284,335 patients, and validated on two independent datasets of 12,026 and 999 patients, we predict cardiovascular risk factors not previously thought to be present or quantifiable in retinal images, such as such as age (within 3.26 years), gender (0.97 AUC), smoking status (0.71 AUC), HbA1c (within 1.39%), systolic blood pressure (within 11.23mmHg) as well as major adverse cardiac events (0.70 AUC). We further show that our models used distinct aspects of the anatomy to generate each prediction, such as the optic disc or blood vessels, opening avenues of further research. version:2
arxiv-1709-07536 | AutoCon: Regression Testing for Detecting Cache Contention Anomalies Using Autoencoder | http://arxiv.org/abs/1709.07536 | id:1709.07536 author:Mohammad Mejbah ul Alam, Justin Gottschlich, Md. Mostofa Ali Patwary, Saeef Ahmad, Abdullah Muzahid category:cs.SE cs.NE cs.PF  published:2017-09-21 summary:Cache contention is an important type of performance anomaly in this multi-core and many-core era. It can cause a significant slowdown in parallel programs. However, it is hard to detect and often, not visible in the source code. As software changes over time, modifications in code can introduce cache contention anomalies. One way to detect such anomalies, is to use performance regression testing. Prior approaches for cache contention detection are either not suitable for performance regression testing or requires knowledge about specific type of contention behavior. To remedy these shortcomings, we propose AutoCon. It works by finding the modified functions and collecting hardware performance counter profiles for them. It uses an unsupervised learning technique, called Autoencoder, to learn the contention behavior implied by the profiles (collected from the older version of code). Then, it checks the profiles collected from the newer version of code to determine whether the contention pattern (implied by the profiles) is anomalous. If so, AutoCon reports a cache contention anomaly. Finally, it performs root cause analysis to provide detailed debugging information. AutoCon is the first learning based cache contention detector that does not require any positive example of contention anomalies. We evaluated AutoCon with 13 real world cache contention anomalies as well as 7 open source programs. AutoCon detected all types of cache contention anomalies with only 3.7% profiling overhead (on average). Moreover, compared to a state-of-the-art cache contention detector, AutoCon detected more anomalies. version:1
arxiv-1709-07484 | WERd: Using Social Text Spelling Variants for Evaluating Dialectal Speech Recognition | http://arxiv.org/abs/1709.07484 | id:1709.07484 author:Ahmed Ali, Preslav Nakov, Peter Bell, Steve Renals category:cs.CL 68T10 I.2.7  published:2017-09-21 summary:We study the problem of evaluating automatic speech recognition (ASR) systems that target dialectal speech input. A major challenge in this case is that the orthography of dialects is typically not standardized. From an ASR evaluation perspective, this means that there is no clear gold standard for the expected output, and several possible outputs could be considered correct according to different human annotators, which makes standard word error rate (WER) inadequate as an evaluation metric. Such a situation is typical for machine translation (MT), and thus we borrow ideas from an MT evaluation metric, namely TERp, an extension of translation error rate which is closely-related to WER. In particular, in the process of comparing a hypothesis to a reference, we make use of spelling variants for words and phrases, which we mine from Twitter in an unsupervised fashion. Our experiments with evaluating ASR output for Egyptian Arabic, and further manual analysis, show that the resulting WERd (i.e., WER for dialects) metric, a variant of TERp, is more adequate than WER for evaluating dialectal ASR. version:1
arxiv-1707-08273 | MMGAN: Manifold Matching Generative Adversarial Network | http://arxiv.org/abs/1707.08273 | id:1707.08273 author:Noseong Park, Ankesh Anand, Joel Ruben Antony Moniz, Kookjin Lee, Tanmoy Chakraborty, Jaegul Choo, Hongkyu Park, Youngmin Kim category:cs.LG  published:2017-07-26 summary:Generative adversarial networks (GANs) are considered as a totally different type of generative models. However, it is well known that GANs are very hard to train. There have been proposed many different techniques in order to stabilize their training procedures. In this paper, we propose a novel training method called manifold matching and a new GAN model called manifold matching GAN (MMGAN). In MMGAN, vector representations extracted from the last layer of the discriminator are used to train the generator. It finds two manifolds representing vector representations of real and fake images. If these two manifolds are matched, it means that real and fake images are identical in the perspective of the discriminator because the manifolds are constructed from the discriminator's last layer. In general, it is much easier to train the discriminator and it becomes more accurate as epoch goes by. This implies that the manifold matching also becomes very accurate as the discriminator is trained. We also use the kernel trick to find better manifolds. We conduct in-depth experiments with three image datasets and several state-of-the-art GAN models. Our experiments demonstrate the efficacy of the proposed MMGAN model. version:3
arxiv-1709-07470 | Learning Domain-Specific Word Embeddings from Sparse Cybersecurity Texts | http://arxiv.org/abs/1709.07470 | id:1709.07470 author:Arpita Roy, Youngja Park, SHimei Pan category:cs.CL  published:2017-09-21 summary:Word embedding is a Natural Language Processing (NLP) technique that automatically maps words from a vocabulary to vectors of real numbers in an embedding space. It has been widely used in recent years to boost the performance of a vari-ety of NLP tasks such as Named Entity Recognition, Syntac-tic Parsing and Sentiment Analysis. Classic word embedding methods such as Word2Vec and GloVe work well when they are given a large text corpus. When the input texts are sparse as in many specialized domains (e.g., cybersecurity), these methods often fail to produce high-quality vectors. In this pa-per, we describe a novel method to train domain-specificword embeddings from sparse texts. In addition to domain texts, our method also leverages diverse types of domain knowledge such as domain vocabulary and semantic relations. Specifi-cally, we first propose a general framework to encode diverse types of domain knowledge as text annotations. Then we de-velop a novel Word Annotation Embedding (WAE) algorithm to incorporate diverse types of text annotations in word em-bedding. We have evaluated our method on two cybersecurity text corpora: a malware description corpus and a Common Vulnerability and Exposure (CVE) corpus. Our evaluation re-sults have demonstrated the effectiveness of our method in learning domain-specific word embeddings. version:1
arxiv-1709-07434 | Analyzing users' sentiment towards popular consumer industries and brands on Twitter | http://arxiv.org/abs/1709.07434 | id:1709.07434 author:Guoning Hu, Preeti Bhargava, Saul Fuhrmann, Sarah Ellinger, Nemanja Spasojevic category:cs.CL cs.IR cs.SI  published:2017-09-21 summary:Social media serves as a unified platform for users to express their thoughts on subjects ranging from their daily lives to their opinion on consumer brands and products. These users wield an enormous influence in shaping the opinions of other consumers and influence brand perception, brand loyalty and brand advocacy. In this paper, we analyze the opinion of 19M Twitter users towards 62 popular industries, encompassing 12,898 enterprise and consumer brands, as well as associated subject matter topics, via sentiment analysis of 330M tweets over a period spanning a month. We find that users tend to be most positive towards manufacturing and most negative towards service industries. In addition, they tend to be more positive or negative when interacting with brands than generally on Twitter. We also find that sentiment towards brands within an industry varies greatly and we demonstrate this using two industries as use cases. In addition, we discover that there is no strong correlation between topic sentiments of different industries, demonstrating that topic sentiments are highly dependent on the context of the industry that they are mentioned in. We demonstrate the value of such an analysis in order to assess the impact of brands on social media. We hope that this initial study will prove valuable for both researchers and companies in understanding users' perception of industries, brands and associated topics and encourage more research in this field. version:1
arxiv-1709-07433 | Perturbative Black Box Variational Inference | http://arxiv.org/abs/1709.07433 | id:1709.07433 author:Robert Bamler, Cheng Zhang, Manfred Opper, Stephan Mandt category:stat.ML cs.LG  published:2017-09-21 summary:Black box variational inference (BBVI) with reparameterization gradients triggered the exploration of divergence measures other than the Kullback-Leibler (KL) divergence, such as alpha divergences. These divergences can be tuned to be more mass-covering (preventing overfitting in complex models), but are also often harder to optimize using Monte-Carlo gradients. In this paper, we view BBVI with generalized divergences as a form of biased importance sampling. The choice of divergence determines a bias-variance tradeoff between the tightness of the bound (low bias) and the variance of its gradient estimators. Drawing on variational perturbation theory of statistical physics, we use these insights to construct a new variational bound which is tighter than the KL bound and more mass covering. Compared to alpha-divergences, its reparameterization gradients have a lower variance. We show in several experiments on Gaussian Processes and Variational Autoencoders that the resulting posterior covariances are closer to the true posterior and lead to higher likelihoods on held-out data. version:1
arxiv-1709-07432 | Dynamic Evaluation of Neural Sequence Models | http://arxiv.org/abs/1709.07432 | id:1709.07432 author:Ben Krause, Emmanuel Kahembwe, Iain Murray, Steve Renals category:cs.NE cs.CL  published:2017-09-21 summary:We present methodology for using dynamic evaluation to improve neural sequence models. Models are adapted to recent history via a gradient descent based mechanism, allowing them to assign higher probabilities to re-occurring sequential patterns. Dynamic evaluation is demonstrated to compare favourably with existing adaptation approaches for language modelling. We apply dynamic evaluation to improve the state of the art word-level perplexities on the Penn Treebank and WikiText-2 datasets to 51.1 and 44.3 respectively, and the state of the art character-level cross-entropy on the Hutter prize dataset to 1.17 bits/character. version:1
arxiv-1709-07429 | Learned Features are better for Ethnicity Classification | http://arxiv.org/abs/1709.07429 | id:1709.07429 author:Inzamam Anwar, Naeem Ul Islam category:cs.CV  published:2017-09-21 summary:Ethnicity is a key demographic attribute of human beings and it plays a vital role in automatic facial recognition and have extensive real world applications such as Human Computer Interaction (HCI); demographic based classification; biometric based recognition; security and defense to name a few. In this paper we present a novel approach for extracting ethnicity from the facial images. The proposed method makes use of a pre trained Convolutional Neural Network (CNN) to extract the features and then Support Vector Machine (SVM) with linear kernel is used as a classifier. This technique uses translational invariant hierarchical features learned by the network, in contrast to previous works, which use hand crafted features such as Local Binary Pattern (LBP); Gabor etc. Thorough experiments are presented on ten different facial databases which strongly suggest that our approach is robust to different expressions and illuminations conditions. Here we consider ethnicity classification as a three class problem including Asian, African-American and Caucasian. Average classification accuracy over all databases is 98.28%, 99.66% and 99.05% for Asian, African-American and Caucasian respectively. version:1
arxiv-1708-07241 | NNVLP: A Neural Network-Based Vietnamese Language Processing Toolkit | http://arxiv.org/abs/1708.07241 | id:1708.07241 author:Thai-Hoang Pham, Xuan-Khoai Pham, Tuan-Anh Nguyen, Phuong Le-Hong category:cs.CL  published:2017-08-24 summary:This paper demonstrates neural network-based toolkit namely NNVLP for essential Vietnamese language processing tasks including part-of-speech (POS) tagging, chunking, named entity recognition (NER). Our toolkit is a combination of bidirectional Long Short-Term Memory (Bi-LSTM), Convolutional Neural Network (CNN), Conditional Random Field (CRF), using pre-trained word embeddings as input, which achieves state-of-the-art results on these three tasks. We provide both API and web demo for this toolkit. version:4
arxiv-1708-09803 | Transfer Learning across Low-Resource, Related Languages for Neural Machine Translation | http://arxiv.org/abs/1708.09803 | id:1708.09803 author:Toan Q. Nguyen, David Chiang category:cs.CL  published:2017-08-31 summary:We present a simple method to improve neural translation of a low-resource language pair using parallel data from a related, also low-resource, language pair. The method is based on the transfer method of Zoph et al., but whereas their method ignores any source vocabulary overlap, ours exploits it. First, we split words using Byte Pair Encoding (BPE) to increase vocabulary overlap. Then, we train a model on the first language pair and transfer its parameters, including its source word embeddings, to another model and continue training on the second language pair. Our experiments show that transfer learning helps word-based translation only slightly, but when used on top of a much stronger BPE baseline, it yields larger improvements of up to 4.3 BLEU. version:2
arxiv-1709-07409 | Quantum Autoencoders via Quantum Adders with Genetic Algorithms | http://arxiv.org/abs/1709.07409 | id:1709.07409 author:L. Lamata, U. Alvarez-Rodriguez, J. D. Martín-Guerrero, M. Sanz, E. Solano category:quant-ph cs.LG cs.NE  published:2017-09-21 summary:The quantum autoencoder is a recent paradigm in the field of quantum machine learning, which may enable an enhanced use of resources in quantum technologies. To this end, quantum neural networks with less nodes in the inner than in the outer layers were considered. Here, we propose a useful connection between approximate quantum adders and quantum autoencoders. Specifically, this link allows us to employ optimized approximate quantum adders, obtained with genetic algorithms, for the implementation of quantum autoencoders for a variety of initial states. Furthermore, we can also directly optimize the quantum autoencoders via genetic algorithms. Our approach opens a different path for the design of quantum autoencoders in controllable quantum platforms. version:1
arxiv-1709-07403 | Inducing Distant Supervision in Suggestion Mining through Part-of-Speech Embeddings | http://arxiv.org/abs/1709.07403 | id:1709.07403 author:Sapna Negi, Paul Buitelaar category:cs.CL  published:2017-09-21 summary:Mining suggestion expressing sentences from a given text is a less investigated sentence classification task, and therefore lacks hand labeled benchmark datasets. In this work, we propose and evaluate two approaches for distant supervision in suggestion mining. The distant supervision is obtained through a large silver standard dataset, constructed using the text from wikiHow and Wikipedia. Both the approaches use a LSTM based neural network architecture to learn a classification model for suggestion mining, but vary in their method to use the silver standard dataset. The first approach directly trains the classifier using this dataset, while the second approach only learns word embeddings from this dataset. In the second approach, we also learn POS embeddings, which interestingly gives the best classification accuracy. version:1
arxiv-1709-07383 | Urban Land Cover Classification with Missing Data Using Deep Convolutional Neural Networks | http://arxiv.org/abs/1709.07383 | id:1709.07383 author:Michael Kampffmeyer, Arnt-Børre Salberg, Robert Jenssen category:cs.CV  published:2017-09-21 summary:Automatic urban land cover classification is a classical problem in remote sensing and good urban land cover maps build the foundation for many tasks, such as e.g. environmental monitoring. It is a particularly challenging problem, as classes generally have high inter-class and low intra-class variance. A common technique to improve urban land cover classification performance in remote sensing is the fusing of data from different sensors with different data modalities. However, all modalities are rarely available for all test data, and this missing data problem poses severe challenges for multi-modal learning. Inspired by recent successes in deep learning, we propose as a remedy a convolutional neural network (CNN) architecture for urban remote sensing image segmentation trained on data modalities which are not all available at test time. We train our architecture with a cost function particularly suited for imbalanced classes, as this is a frequent problem in remote sensing, especially in urban areas. We demonstrate the method using two benchmark datasets, both consisting of optical and digital surface model (DSM) images. We simulate missing data, by assuming that the DSM images are missing during testing and show that our method outperforms both CNNs trained on optical images as well as an ensemble of two CNNs trained only on optical images. We further evaluate the potential of our method to handle situations where only some DSM images are missing during training and show that we can clearly exploit training time information of the missing modality during testing. version:1
arxiv-1709-07377 | Geometric SMOTE: Effective oversampling for imbalanced learning through a geometric extension of SMOTE | http://arxiv.org/abs/1709.07377 | id:1709.07377 author:Georgios Douzas, Fernando Bacao category:cs.LG  published:2017-09-21 summary:Classification of imbalanced datasets is a challenging task for standard algorithms. Although many methods exist to address this problem in different ways, generating artificial data for the minority class is a more general approach compared to algorithmic modifications. SMOTE algorithm and its variations generate synthetic samples along a line segment that joins minority class instances. In this paper we propose Geometric SMOTE (G-SMOTE) as a generalization of the SMOTE data generation mechanism. G-SMOTE generates synthetic samples in a geometric region of the input space, around each selected minority instance. While in the basic configuration this region is a hyper-sphere, G-SMOTE allows its deformation to a hyper-spheroid and finally to a line segment, emulating, in the last case, the SMOTE mechanism. The performance of G-SMOTE is compared against multiple standard oversampling algorithms. We present empirical results that show a significant improvement in the quality of the generated data when G-SMOTE is used as an oversampling algorithm. version:1
arxiv-1709-04090 | A Constrained, Weighted-L1 Minimization Approach for Joint Discovery of Heterogeneous Neural Connectivity Graphs | http://arxiv.org/abs/1709.04090 | id:1709.04090 author:Chandan Singh, Beilun Wang, Yanjun Qi category:q-bio.NC cs.LG  published:2017-09-13 summary:Determining functional brain connectivity is crucial to understanding the brain and neural differences underlying disorders such as autism. Recent studies have used Gaussian graphical models to learn brain connectivity via statistical dependencies across brain regions from neuroimaging. However, previous studies often fail to properly incorporate priors tailored to neuroscience, such as preferring shorter connections. To remedy this problem, the paper here introduces a novel, weighted-$\ell_1$, multi-task graphical model (W-SIMULE). This model elegantly incorporates a flexible prior, along with a parallelizable formulation. Additionally, W-SIMULE extends the often-used Gaussian assumption, leading to considerable performance increases. Here, applications to fMRI data show that W-SIMULE succeeds in determining functional connectivity in terms of (1) log-likelihood, (2) finding edges that differentiate groups, and (3) classifying different groups based on their connectivity, achieving 58.6\% accuracy on the ABIDE dataset. Having established W-SIMULE's effectiveness, it links four key areas to autism, all of which are consistent with the literature. Due to its elegant domain adaptivity, W-SIMULE can be readily applied to various data types to effectively estimate connectivity. version:2
arxiv-1709-07368 | Multi-label Pixelwise Classification for Reconstruction of Large-scale Urban Areas | http://arxiv.org/abs/1709.07368 | id:1709.07368 author:Yuanlie He, Sudhir Mudur, Charalambos Poullis category:cs.CV  published:2017-09-21 summary:Object classification is one of the many holy grails in computer vision and as such has resulted in a very large number of algorithms being proposed already. Specifically in recent years there has been considerable progress in this area primarily due to the increased efficiency and accessibility of deep learning techniques. In fact, for single-label object classification [i.e. only one object present in the image] the state-of-the-art techniques employ deep neural networks and are reporting very close to human-like performance. There are specialized applications in which single-label object-level classification will not suffice; for example in cases where the image contains multiple intertwined objects of different labels. In this paper, we address the complex problem of multi-label pixelwise classification. We present our distinct solution based on a convolutional neural network (CNN) for performing multi-label pixelwise classification and its application to large-scale urban reconstruction. A supervised learning approach is followed for training a 13-layer CNN using both LiDAR and satellite images. An empirical study has been conducted to determine the hyperparameters which result in the optimal performance of the CNN. Scale invariance is introduced by training the network on five different scales of the input and labeled data. This results in six pixelwise classifications for each different scale. An SVM is then trained to map the six pixelwise classifications into a single-label. Lastly, we refine boundary pixel labels using graph-cuts for maximum a-posteriori (MAP) estimation with Markov Random Field (MRF) priors. The resulting pixelwise classification is then used to accurately extract and reconstruct the buildings in large-scale urban areas. The proposed approach has been extensively tested and the results are reported. version:1
arxiv-1709-07359 | Class-Splitting Generative Adversarial Networks | http://arxiv.org/abs/1709.07359 | id:1709.07359 author:Guillermo L. Grinblat, Lucas C. Uzal, Pablo M. Granitto category:stat.ML cs.CV cs.LG  published:2017-09-21 summary:Generative Adversarial Networks (GANs) produce systematically better quality samples when class label information is provided., i.e. in the conditional GAN setup. This is still observed for the recently proposed Wasserstein GAN formulation which stabilized adversarial training and allows considering high capacity network architectures such as ResNet. In this work we show how to boost conditional GAN by augmenting available class labels. The new classes come from clustering in the representation space learned by the same GAN model. The proposed strategy is also feasible when no class information is available, i.e. in the unsupervised setup. Our generated samples reach state-of-the-art Inception scores for CIFAR-10 and STL-10 datasets in both supervised and unsupervised setup. version:1
arxiv-1709-07357 | Retrofitting Concept Vector Representations of Medical Concepts to Improve Estimates of Semantic Similarity and Relatedness | http://arxiv.org/abs/1709.07357 | id:1709.07357 author:Zhiguo Yu, Byron C. Wallace, Todd Johnson, Trevor Cohen category:cs.CL  published:2017-09-21 summary:Estimation of semantic similarity and relatedness between biomedical concepts has utility for many informatics applications. Automated methods fall into two categories: methods based on distributional statistics drawn from text corpora, and methods using the structure of existing knowledge resources. Methods in the former category disregard taxonomic structure, while those in the latter fail to consider semantically relevant empirical information. In this paper, we present a method that retrofits distributional context vector representations of biomedical concepts using structural information from the UMLS Metathesaurus, such that the similarity between vector representations of linked concepts is augmented. We evaluated it on the UMNSRS benchmark. Our results demonstrate that retrofitting of concept vector representations leads to better correlation with human raters for both similarity and relatedness, surpassing the best results reported to date. They also demonstrate a clear improvement in performance on this reference standard for retrofitted vector representations, as compared to those without retrofitting. version:1
arxiv-1709-05289 | Optimal approximation of piecewise smooth functions using deep ReLU neural networks | http://arxiv.org/abs/1709.05289 | id:1709.05289 author:Philipp Petersen, Felix Voigtlaender category:math.FA cs.LG stat.ML  published:2017-09-15 summary:We study the necessary and sufficient complexity of ReLU neural networks---in terms of depth and number of weights---which is required for approximating classifier functions in an $L^2$-sense. As a model class, we consider the set $\mathcal{E}^\beta (\mathbb R^d)$ of possibly discontinuous piecewise $C^\beta$ functions $f : [-1/2, 1/2]^d \to \mathbb R$, where the different "smooth regions" of $f$ are separated by $C^\beta$ hypersurfaces. For given dimension $d \geq 2$, regularity $\beta > 0$, and accuracy $\varepsilon > 0$, we construct artificial neural networks with ReLU activation function that approximate functions from $\mathcal{E}^\beta(\mathbb R^d)$ up to an $L^2$ error of $\varepsilon$. The constructed networks have a fixed number of layers, depending only on $d$ and $\beta$ and they have $\mathcal{O}(\varepsilon^{-2(d-1)/\beta})$ many non-zero weights, which we prove to be optimal. For the proof of optimality, we establish a lower bound on the description complexity of the class $\mathcal{E}^\beta (\mathbb R^d)$. By showing that a family of approximating neural networks gives rise to an encoder for $\mathcal{E}^\beta (\mathbb R^d)$, we then prove that one cannot approximate a general function $f \in \mathcal{E}^\beta (\mathbb R^d)$ using neural networks that are less complex than those produced by our construction. In addition to the optimality in terms of the number of weights, we show that in order to achieve this optimal approximation rate, one needs ReLU networks of a certain minimal depth. Precisely, for piecewise $C^\beta(\mathbb R^d)$ functions, this minimal depth is given---up to a multiplicative constant---by $\beta/d$. Up to a log factor, our constructed networks match this bound. This partly explains the benefits of depth for ReLU networks by showing that deep networks are necessary to achieve efficient approximation of (piecewise) smooth functions. version:2
arxiv-1709-07337 | Efficient Column Generation for Cell Detection and Segmentation | http://arxiv.org/abs/1709.07337 | id:1709.07337 author:Chong Zhang, Shaofei Wang, Miguel A. Gonzalez-Ballester, Julian Yarkony category:cs.CV stat.ML  published:2017-09-21 summary:We study the problem of instance segmentation in biological images with crowded and compact cells. We formulate this task as an integer program where variables correspond to cells and constraints enforce that cells do not overlap. To solve this integer program, we propose a column generation formulation where the pricing program is solved via exact optimization of very small scale integer programs. Column generation is tightened using odd set inequalities which fit elegantly into pricing problem optimization. Our column generation approach achieves fast stable anytime inference for our instance segmentation problems. We demonstrate on three distinct light microscopy datasets, with several hundred cells each, that our proposed algorithm rapidly achieves or exceeds state of the art accuracy. version:1
arxiv-1709-07330 | H-DenseUNet: Hybrid Densely Connected UNet for Liver and Liver Tumor Segmentation from CT Volumes | http://arxiv.org/abs/1709.07330 | id:1709.07330 author:Xiaomeng Li, Hao Chen, Xiaojuan Qi, Qi Dou, Chi-Wing Fu, Pheng Ann Heng category:cs.CV  published:2017-09-21 summary:Liver and liver tumor segmentation plays an important role in hepatocellular carcinoma diagnosis and treatment planning. Recently, fully convolutional neural networks (FCNs) serve as the back-bone in many volumetric medical image segmentation tasks, including 2D and 3D FCNs. However, 2D convolutions can not fully leverage the spatial information along the $z$-axis direction while 3D convolutions suffer from high computational cost and GPU memory consumption. To address these issues, we propose a novel hybrid densely connected UNet (H-DenseUNet), which consists of a 2D DenseUNet for efficiently extracting intra-slice features and a 3D counterpart for hierarchically aggregating volumetric contexts under the spirit of the auto-context algorithm. In this way, the H-DenseUNet can harness the hybrid deep features effectively for volumetric segmentation. We extensively evaluated our method on the MICCAI 2017 Liver Tumor Segmentation (LiTS) Challenge. Our method outperformed other state-of-the-art methods on the overall score, with dice per case on liver and tumor as 0.961 and 0.686, as well as global dice score on liver and tumor as 0.965 and 0.829, respectively. version:1
arxiv-1709-07322 | Playing for Benchmarks | http://arxiv.org/abs/1709.07322 | id:1709.07322 author:Stephan R. Richter, Zeeshan Hayder, Vladlen Koltun category:cs.CV I.4.8  published:2017-09-21 summary:We present a benchmark suite for visual perception. The benchmark is based on more than 250K high-resolution video frames, all annotated with ground-truth data for both low-level and high-level vision tasks, including optical flow, semantic instance segmentation, object detection and tracking, object-level 3D scene layout, and visual odometry. Ground-truth data for all tasks is available for every frame. The data was collected while driving, riding, and walking a total of 184 kilometers in diverse ambient conditions in a realistic virtual world. To create the benchmark, we have developed a new approach to collecting ground-truth data from simulated worlds without access to their source code or content. We conduct statistical analyses that show that the composition of the scenes in the benchmark closely matches the composition of corresponding physical environments. The realism of the collected data is further validated via perceptual experiments. We analyze the performance of state-of-the-art methods for multiple tasks, providing reference baselines and highlighting challenges for future research. The supplementary video can be viewed at https://youtu.be/T9OybWv923Y version:1
arxiv-1709-05506 | The generalised random dot product graph | http://arxiv.org/abs/1709.05506 | id:1709.05506 author:Patrick Rubin-Delanchy, Carey E. Priebe, Minh Tang category:stat.ML  published:2017-09-16 summary:This paper introduces a latent position network model, called the generalised random dot product graph, comprising as special cases the stochastic blockmodel, mixed membership stochastic blockmodel, and random dot product graph. In this model, nodes are represented as random vectors on $\mathbb{R}^d$, and the probability of an edge between nodes $i$ and $j$ is given by the bilinear form $X_i^T I_{p,q} X_j$, where $I_{p,q} = \mathrm{diag}(1,\ldots, 1, -1, \ldots, -1)$ with $p$ ones and $q$ minus ones, where $p+q=d$. As we show, this provides the only possible representation of nodes in $\mathbb{R}^d$ such that mixed membership is encoded as the corresponding convex combination of latent positions. The positions are identifiable only up to transformation in the indefinite orthogonal group $O(p,q)$, and we discuss some consequences for typical follow-on inference tasks, such as clustering and prediction. version:2
arxiv-1709-07276 | Speech Recognition Challenge in the Wild: Arabic MGB-3 | http://arxiv.org/abs/1709.07276 | id:1709.07276 author:Ahmed Ali, Stephan Vogel, Steve Renals category:cs.CL  published:2017-09-21 summary:This paper describes the Arabic MGB-3 Challenge - Arabic Speech Recognition in the Wild. Unlike last year's Arabic MGB-2 Challenge, for which the recognition task was based on more than 1,200 hours broadcast TV news recordings from Aljazeera Arabic TV programs, MGB-3 emphasises dialectal Arabic using a multi-genre collection of Egyptian YouTube videos. Seven genres were used for the data collection: comedy, cooking, family/kids, fashion, drama, sports, and science (TEDx). A total of 16 hours of videos, split evenly across the different genres, were divided into adaptation, development and evaluation data sets. The Arabic MGB-Challenge comprised two tasks: A) Speech transcription, evaluated on the MGB-3 test set, along with the 10 hour MGB-2 test set to report progress on the MGB-2 evaluation; B) Arabic dialect identification, introduced this year in order to distinguish between four major Arabic dialects - Egyptian, Levantine, North African, Gulf, as well as Modern Standard Arabic. Two hours of audio per dialect were released for development and a further two hours were used for evaluation. For dialect identification, both lexical features and i-vector bottleneck features were shared with participants in addition to the raw audio recordings. Overall, thirteen teams submitted ten systems to the challenge. We outline the approaches adopted in each system, and summarise the evaluation results. version:1
arxiv-1709-07267 | Yet Another ADNI Machine Learning Paper? Paving The Way Towards Fully-reproducible Research on Classification of Alzheimer's Disease | http://arxiv.org/abs/1709.07267 | id:1709.07267 author:Jorge Samper-González, Ninon Burgos, Sabrina Fontanella, Hugo Bertin, Marie-Odile Habert, Stanley Durrleman, Theodoros Evgeniou, Olivier Colliot category:stat.ML cs.CV q-bio.NC q-bio.QM  published:2017-09-21 summary:In recent years, the number of papers on Alzheimer's disease classification has increased dramatically, generating interesting methodological ideas on the use machine learning and feature extraction methods. However, practical impact is much more limited and, eventually, one could not tell which of these approaches are the most efficient. While over 90\% of these works make use of ADNI an objective comparison between approaches is impossible due to variations in the subjects included, image pre-processing, performance metrics and cross-validation procedures. In this paper, we propose a framework for reproducible classification experiments using multimodal MRI and PET data from ADNI. The core components are: 1) code to automatically convert the full ADNI database into BIDS format; 2) a modular architecture based on Nipype in order to easily plug-in different classification and feature extraction tools; 3) feature extraction pipelines for MRI and PET data; 4) baseline classification approaches for unimodal and multimodal features. This provides a flexible framework for benchmarking different feature extraction and classification tools in a reproducible manner. We demonstrate its use on all (1519) baseline T1 MR images and all (1102) baseline FDG PET images from ADNI 1, GO and 2 with SPM-based feature extraction pipelines and three different classification techniques (linear SVM, anatomically regularized SVM and multiple kernel learning SVM). The highest accuracies achieved were: 91% for AD vs CN, 83% for MCIc vs CN, 75% for MCIc vs MCInc, 94% for AD-A$\beta$+ vs CN-A$\beta$- and 72% for MCIc-A$\beta$+ vs MCInc-A$\beta$+. The code is publicly available at https://gitlab.icm-institute.org/aramislab/AD-ML (depends on the Clinica software platform, publicly available at http://www.clinica.run). version:1
arxiv-1709-07244 | Neural network identification of people hidden from view with a single-pixel, single-photon detector | http://arxiv.org/abs/1709.07244 | id:1709.07244 author:Piergiorgio Caramazza, Alessandro Boccolini, Daniel Buschek, Matthias Hullin, Catherine Higham, Robert Henderson, Roderick Murray-Smith, Daniele Faccio category:cs.CV physics.optics  published:2017-09-21 summary:Light scattered from multiple surfaces can be used to retrieve information of hidden environments. However, full three-dimensional retrieval of an object hidden from view by a wall has only been achieved with scanning systems and requires intensive computational processing of the retrieved data. Here we use a non-scanning, single-photon single-pixel detector in combination with an artificial neural network: this allows us to locate the position and to also simultaneously provide the actual identity of a hidden person, chosen from a database of people (N=3). Artificial neural networks applied to specific computational imaging problems can therefore enable novel imaging capabilities with hugely simplified hardware and processing times version:1
arxiv-1709-07220 | Human Pose Estimation using Global and Local Normalization | http://arxiv.org/abs/1709.07220 | id:1709.07220 author:Ke Sun, Cuiling Lan, Junliang Xing, Wenjun Zeng, Dong Liu, Jingdong Wang category:cs.CV  published:2017-09-21 summary:In this paper, we address the problem of estimating the positions of human joints, i.e., articulated pose estimation. Recent state-of-the-art solutions model two key issues, joint detection and spatial configuration refinement, together using convolutional neural networks. Our work mainly focuses on spatial configuration refinement by reducing variations of human poses statistically, which is motivated by the observation that the scattered distribution of the relative locations of joints e.g., the left wrist is distributed nearly uniformly in a circular area around the left shoulder) makes the learning of convolutional spatial models hard. We present a two-stage normalization scheme, human body normalization and limb normalization, to make the distribution of the relative joint locations compact, resulting in easier learning of convolutional spatial models and more accurate pose estimation. In addition, our empirical results show that incorporating multi-scale supervision and multi-scale fusion into the joint detection network is beneficial. Experiment results demonstrate that our method consistently outperforms state-of-the-art methods on the benchmarks. version:1
arxiv-1709-07212 | A First Derivative Potts Model for Segmentation and Denoising Using MILP | http://arxiv.org/abs/1709.07212 | id:1709.07212 author:Ruobing Shen, Gerhard Reinelt, Stéphane Canu category:cs.CV  published:2017-09-21 summary:Unsupervised image segmentation and denoising are two fundamental tasks in image processing. Usually, graph based models such as multicut are used for segmentation and variational models are employed for denoising. Our approach addresses both problems at the same time. We propose a novel MILP formulation of a first derivative Potts model, where binary variables are introduced to directly deal with the $\ell_0$ norm. As a by-product the image is denoised. To the best of our knowledge, it is the first global mathematical programming model for simultaneous segmentation and denoising. Numerical experiments on real-world images are compared with multicut approaches. version:1
arxiv-1709-07200 | Temporal Multimodal Fusion for Video Emotion Classification in the Wild | http://arxiv.org/abs/1709.07200 | id:1709.07200 author:Valentin Vielzeuf, Stéphane Pateux, Frédéric Jurie category:cs.CV cs.LG cs.MM  published:2017-09-21 summary:This paper addresses the question of emotion classification. The task consists in predicting emotion labels (taken among a set of possible labels) best describing the emotions contained in short video clips. Building on a standard framework -- lying in describing videos by audio and visual features used by a supervised classifier to infer the labels -- this paper investigates several novel directions. First of all, improved face descriptors based on 2D and 3D Convo-lutional Neural Networks are proposed. Second, the paper explores several fusion methods, temporal and multimodal, including a novel hierarchical method combining features and scores. In addition, we carefully reviewed the different stages of the pipeline and designed a CNN architecture adapted to the task; this is important as the size of the training set is small compared to the difficulty of the problem, making generalization difficult. The so-obtained model ranked 4th at the 2017 Emotion in the Wild challenge with the accuracy of 58.8 %. version:1
arxiv-1709-07192 | Visual Question Generation as Dual Task of Visual Question Answering | http://arxiv.org/abs/1709.07192 | id:1709.07192 author:Yikang Li, Nan Duan, Bolei Zhou, Xiao Chu, Wanli Ouyang, Xiaogang Wang category:cs.CV  published:2017-09-21 summary:Recently visual question answering (VQA) and visual question generation (VQG) are two trending topics in the computer vision, which have been explored separately. In this work, we propose an end-to-end unified framework, the Invertible Question Answering Network (iQAN), to leverage the complementary relations between questions and answers in images by jointly training the model on VQA and VQG tasks. Corresponding parameter sharing scheme and regular terms are proposed as constraints to explicitly leverage Q,A's dependencies to guide the training process. After training, iQAN can take either question or answer as input, then output the counterpart. Evaluated on the large-scale visual question answering datasets CLEVR and VQA2, our iQAN improves the VQA accuracy over the baselines. We also show the dual learning framework of iQAN can be generalized to other VQA architectures and consistently improve the results over both the VQA and VQG tasks. version:1
arxiv-1709-07175 | Lazy stochastic principal component analysis | http://arxiv.org/abs/1709.07175 | id:1709.07175 author:Michael Wojnowicz, Dinh Nguyen, Li Li, Xuan Zhao category:stat.ML  published:2017-09-21 summary:Stochastic principal component analysis (SPCA) has become a popular dimensionality reduction strategy for large, high-dimensional datasets. We derive a simplified algorithm, called Lazy SPCA, which has reduced computational complexity and is better suited for large-scale distributed computation. We prove that SPCA and Lazy SPCA find the same approximations to the principal subspace, and that the pairwise distances between samples in the lower-dimensional space is invariant to whether SPCA is executed lazily or not. Empirical studies find downstream predictive performance to be identical for both methods, and superior to random projections, across a range of predictive models (linear regression, logistic lasso, and random forests). In our largest experiment with 4.6 million samples, Lazy SPCA reduced 43.7 hours of computation to 9.9 hours. Overall, Lazy SPCA relies exclusively on matrix multiplications, besides an operation on a small square matrix whose size depends only on the target dimensionality. version:1
arxiv-1709-07172 | SpectralFPL: Online Spectral Learning for Single Topic Models | http://arxiv.org/abs/1709.07172 | id:1709.07172 author:Tong Yu, Branislav Kveton, Zheng Wen, Hung Bui, Ole J. Mengshoel category:cs.LG stat.ML  published:2017-09-21 summary:This paper studies how to efficiently learn an optimal latent variable model online from large streaming data. Latent variable models can explain the observed data in terms of unobserved concepts. They are traditionally studied in the unsupervised learning setting, and learned by iterative methods such as the EM. Very few online learning algorithms for latent variable models have been developed, and the most popular one is online EM. Though online EM is computationally efficient, it typically converges to a local optimum. In this work, we motivate and develop SpectralFPL, a novel algorithm to learn latent variable models online from streaming data. SpectralFPL is computationally efficient, and we prove that it quickly learns the global optimum under a bag-of-words model by deriving an $O(\sqrt n)$ regret bound. Experiment results also demonstrate a consistent performance improvement of SpectralFPL over online EM: in both synthetic and real-world experiments, SpectralFPL's performance is similar with or even better than online EM with optimally tuned parameters. version:1
arxiv-1709-07166 | Semi-Automated Nasal PAP Mask Sizing using Facial Photographs | http://arxiv.org/abs/1709.07166 | id:1709.07166 author:Benjamin Johnston, Alistair McEwan, Philip de Chazal category:cs.CV  published:2017-09-21 summary:We present a semi-automated system for sizing nasal Positive Airway Pressure (PAP) masks based upon a neural network model that was trained with facial photographs of both PAP mask users and non-users. It demonstrated an accuracy of 72% in correctly sizing a mask and 96% accuracy sizing to within 1 mask size group. The semi-automated system performed comparably to sizing from manual measurements taken from the same images which produced 89% and 100% accuracy respectively. version:1
arxiv-1709-07124 | Deep Recurrent NMF for Speech Separation by Unfolding Iterative Thresholding | http://arxiv.org/abs/1709.07124 | id:1709.07124 author:Scott Wisdom, Thomas Powers, James Pitton, Les Atlas category:cs.SD cs.LG stat.ML  published:2017-09-21 summary:In this paper, we propose a novel recurrent neural network architecture for speech separation. This architecture is constructed by unfolding the iterations of a sequential iterative soft-thresholding algorithm (ISTA) that solves the optimization problem for sparse nonnegative matrix factorization (NMF) of spectrograms. We name this network architecture deep recurrent NMF (DR-NMF). The proposed DR-NMF network has three distinct advantages. First, DR-NMF provides better interpretability than other deep architectures, since the weights correspond to NMF model parameters, even after training. This interpretability also provides principled initializations that enable faster training and convergence to better solutions compared to conventional random initialization. Second, like many deep networks, DR-NMF is an order of magnitude faster at test time than NMF, since computation of the network output only requires evaluating a few layers at each time step. Third, when a limited amount of training data is available, DR-NMF exhibits stronger generalization and separation performance compared to sparse NMF and state-of-the-art long-short term memory (LSTM) networks. When a large amount of training data is available, DR-NMF achieves lower yet competitive separation performance compared to LSTM networks. version:1
arxiv-1709-07116 | Variational Memory Addressing in Generative Models | http://arxiv.org/abs/1709.07116 | id:1709.07116 author:Jörg Bornschein, Andriy Mnih, Daniel Zoran, Danilo J. Rezende category:cs.LG  published:2017-09-21 summary:Aiming to augment generative models with external memory, we interpret the output of a memory module with stochastic addressing as a conditional mixture distribution, where a read operation corresponds to sampling a discrete memory address and retrieving the corresponding content from memory. This perspective allows us to apply variational inference to memory addressing, which enables effective training of the memory module by using the target information to guide memory lookups. Stochastic addressing is particularly well-suited for generative models as it naturally encourages multimodality which is a prominent aspect of most high-dimensional datasets. Treating the chosen address as a latent variable also allows us to quantify the amount of information gained with a memory lookup and measure the contribution of the memory module to the generative process. To illustrate the advantages of this approach we incorporate it into a variational autoencoder and apply the resulting model to the task of generative few-shot learning. The intuition behind this architecture is that the memory module can pick a relevant template from memory and the continuous part of the model can concentrate on modeling remaining variations. We demonstrate empirically that our model is able to identify and access the relevant memory contents even with hundreds of unseen Omniglot characters in memory version:1
arxiv-1709-06909 | Opposition based Ensemble Micro Differential Evolution | http://arxiv.org/abs/1709.06909 | id:1709.06909 author:Hojjat Salehinejad, Shahryar Rahnamayan, Hamid R. Tizhoosh category:cs.NE  published:2017-09-08 summary:Differential evolution (DE) algorithm with a small population size is called Micro-DE (MDE). A small population size decreases the computational complexity but also reduces the exploration ability of DE by limiting the population diversity. In this paper, we propose the idea of combining ensemble mutation scheme selection and opposition-based learning concepts to enhance the diversity of population in MDE at mutation and selection stages. The proposed algorithm enhances the diversity of population by generating a random mutation scale factor per individual and per dimension, randomly assigning a mutation scheme to each individual in each generation, and diversifying individuals selection using opposition-based learning. This approach is easy to implement and does not require the setting of mutation scheme selection and mutation scale factor. Experimental results are conducted for a variety of objective functions with low and high dimensionality on the CEC Black- Box Optimization Benchmarking 2015 (CEC-BBOB 2015). The results show superior performance of the proposed algorithm compared to the other micro-DE algorithms. version:2
arxiv-1709-07104 | On the Use of Machine Translation-Based Approaches for Vietnamese Diacritic Restoration | http://arxiv.org/abs/1709.07104 | id:1709.07104 author:Thai-Hoang Pham, Xuan-Khoai Pham, Phuong Le-Hong category:cs.CL  published:2017-09-20 summary:This paper presents an empirical study of two machine translation-based approaches for Vietnamese diacritic restoration problem, including phrase-based and neural-based machine translation models. This is the first work that applies neural-based machine translation method to this problem and gives a thorough comparison to the phrase-based machine translation method which is the current state-of-the-art method for this problem. On a large dataset, the phrase-based approach has an accuracy of 97.32% while that of the neural-based approach is 96.15%. While the neural-based method has a slightly lower accuracy, it is about twice faster than the phrase-based method in terms of inference speed. Moreover, neural-based machine translation method has much room for future improvement such as incorporating pre-trained word embeddings and collecting more training data. version:1
arxiv-1709-07100 | Supervised Learning with Indefinite Topological Kernels | http://arxiv.org/abs/1709.07100 | id:1709.07100 author:Tullia Padellini, Pierpaolo Brutti category:stat.ML math.ST stat.TH  published:2017-09-20 summary:Topological Data Analysis (TDA) is a recent and growing branch of statistics devoted to the study of the shape of the data. In this work we investigate the predictive power of TDA in the context of supervised learning. Since topological summaries, most noticeably the Persistence Diagram, are typically defined in complex spaces, we adopt a kernel approach to translate them into more familiar vector spaces. We define a topological exponential kernel, we characterize it, and we show that, despite not being positive semi-definite, it can be successfully used in regression and classification tasks. version:1
arxiv-1709-07097 | Persistence Flamelets: multiscale Persistent Homology for kernel density exploration | http://arxiv.org/abs/1709.07097 | id:1709.07097 author:Tullia Padellini, Pierpaolo Brutti category:stat.ML math.ST stat.TH  published:2017-09-20 summary:In recent years there has been noticeable interest in the study of the "shape of data". Among the many ways a "shape" could be defined, topology is the most general one, as it describes an object in terms of its connectivity structure: connected components (topological features of dimension 0), cycles (features of dimension 1) and so on. There is a growing number of techniques, generally denoted as Topological Data Analysis, aimed at estimating topological invariants of a fixed object; when we allow this object to change, however, little has been done to investigate the evolution in its topology. In this work we define the Persistence Flamelets, a multiscale version of one of the most popular tool in TDA, the Persistence Landscape. We examine its theoretical properties and we show how it could be used to gain insights on KDEs bandwidth parameter. version:1
arxiv-1709-07093 | Near Optimal Sketching of Low-Rank Tensor Regression | http://arxiv.org/abs/1709.07093 | id:1709.07093 author:Jarvis Haupt, Xingguo Li, David P. Woodruff category:cs.LG cs.DS stat.ML  published:2017-09-20 summary:We study the least squares regression problem \begin{align*} \min_{\Theta \in \mathcal{S}_{\odot D,R}} \ A\Theta-b\ _2, \end{align*} where $\mathcal{S}_{\odot D,R}$ is the set of $\Theta$ for which $\Theta = \sum_{r=1}^{R} \theta_1^{(r)} \circ \cdots \circ \theta_D^{(r)}$ for vectors $\theta_d^{(r)} \in \mathbb{R}^{p_d}$ for all $r \in [R]$ and $d \in [D]$, and $\circ$ denotes the outer product of vectors. That is, $\Theta$ is a low-dimensional, low-rank tensor. This is motivated by the fact that the number of parameters in $\Theta$ is only $R \cdot \sum_{d=1}^D p_d$, which is significantly smaller than the $\prod_{d=1}^{D} p_d$ number of parameters in ordinary least squares regression. We consider the above CP decomposition model of tensors $\Theta$, as well as the Tucker decomposition. For both models we show how to apply data dimensionality reduction techniques based on {\it sparse} random projections $\Phi \in \mathbb{R}^{m \times n}$, with $m \ll n$, to reduce the problem to a much smaller problem $\min_{\Theta} \ \Phi A \Theta - \Phi b\ _2$, for which if $\Theta'$ is a near-optimum to the smaller problem, then it is also a near optimum to the original problem. We obtain significantly smaller dimension and sparsity in $\Phi$ than is possible for ordinary least squares regression, and we also provide a number of numerical simulations supporting our theory. version:1
arxiv-1709-07089 | On the Design of LQR Kernels for Efficient Controller Learning | http://arxiv.org/abs/1709.07089 | id:1709.07089 author:Alonso Marco, Philipp Hennig, Stefan Schaal, Sebastian Trimpe category:cs.SY cs.LG stat.ML  published:2017-09-20 summary:Finding optimal feedback controllers for nonlinear dynamic systems from data is hard. Recently, Bayesian optimization (BO) has been proposed as a powerful framework for direct controller tuning from experimental trials. For selecting the next query point and finding the global optimum, BO relies on a probabilistic description of the latent objective function, typically a Gaussian process (GP). As is shown herein, GPs with a common kernel choice can, however, lead to poor learning outcomes on standard quadratic control problems. For a first-order system, we construct two kernels that specifically leverage the structure of the well-known Linear Quadratic Regulator (LQR), yet retain the flexibility of Bayesian nonparametric learning. Simulations of uncertain linear and nonlinear systems demonstrate that the LQR kernels yield superior learning performance. version:1
arxiv-1705-06628 | Robust tracking of respiratory rate in high-dynamic range scenes using mobile thermal imaging | http://arxiv.org/abs/1705.06628 | id:1705.06628 author:Youngjun Cho, Simon J. Julier, Nicolai Marquardt, Nadia Bianchi-Berthouze category:cs.CV physics.med-ph  published:2017-05-08 summary:The ability to monitor respiratory rate is extremely important for medical treatment, healthcare and fitness sectors. In many situations, mobile methods, which allow users to undertake every day activities, are required. However, current monitoring systems can be obtrusive, requiring users to wear respiration belts or nasal probes. Recent advances in thermographic systems have shrunk their size, weight and cost, to the point where it is possible to create smart-phone based respiration rate monitoring devices that are not affected by lighting conditions. However, mobile thermal imaging is challenged in scenes with high thermal dynamic ranges. This challenge is further amplified by general problems such as motion artifacts and low spatial resolution, leading to unreliable breathing signals. In this paper, we propose a novel and robust approach for respiration tracking which compensates for the negative effects of variations in the ambient temperature and motion artifacts and can accurately extract breathing rates in highly dynamic thermal scenes. It has three main contributions. The first is a novel Optimal Quantization technique which adaptively constructs a color mapping of absolute temperature to improve segmentation, classification and tracking. The second is the Thermal Gradient Flow method that computes thermal gradient magnitude maps to enhance accuracy of the nostril region tracking. Finally, we introduce the Thermal Voxel method to increase the reliability of the captured respiration signals compared to the traditional averaging method. We demonstrate the extreme robustness of our system to track the nostril-region and measure the respiratory rate in high dynamic range scenes. version:2
arxiv-1709-07077 | Estimated Depth Map Helps Image Classification | http://arxiv.org/abs/1709.07077 | id:1709.07077 author:Yihui He category:cs.CV cs.LG  published:2017-09-20 summary:We consider image classification with estimated depth. This problem falls into the domain of transfer learning, since we are using a model trained on a set of depth images to generate depth maps (additional features) for use in another classification problem using another disjoint set of images. It's challenging as no direct depth information is provided. Though depth estimation has been well studied, none have attempted to aid image classification with estimated depth. Therefore, we present a way of transferring domain knowledge on depth estimation to a separate image classification task over a disjoint set of train, and test data. We build a RGBD dataset based on RGB dataset and do image classification on it. Then evaluation the performance of neural networks on the RGBD dataset compared to the RGB dataset. From our experiments, the benefit is significant with shallow and deep networks. It improves ResNet-20 by 0.55% and ResNet-56 by 0.53%. Our code and dataset are available publicly. version:1
arxiv-1709-07065 | Multi-camera Multi-Object Tracking | http://arxiv.org/abs/1709.07065 | id:1709.07065 author:Wenqian Liu, Octavia Camps, Mario Sznaier category:cs.CV  published:2017-09-20 summary:In this paper, we propose a pipeline for multi-target visual tracking under multi-camera system. For multi-camera system tracking problem, efficient data association across cameras, and at the same time, across frames becomes more important than single-camera system tracking. However, most of the multi-camera tracking algorithms emphasis on single camera across frame data association. Thus in our work, we model our tracking problem as a global graph, and adopt Generalized Maximum Multi Clique optimization problem as our core algorithm to take both across frame and across camera data correlation into account all together. Furthermore, in order to compute good similarity scores as the input of our graph model, we extract both appearance and dynamic motion similarities. For appearance feature, Local Maximal Occurrence Representation(LOMO) feature extraction algorithm for ReID is conducted. When it comes to capturing the dynamic information, we build Hankel matrix for each tracklet of target and apply rank estimation with Iterative Hankel Total Least Squares(IHTLS) algorithm to it. We evaluate our tracker on the challenging Terrace Sequences from EPFL CVLAB as well as recently published Duke MTMC dataset. version:1
arxiv-1709-04514 | Differentially Private Mixture of Generative Neural Networks | http://arxiv.org/abs/1709.04514 | id:1709.04514 author:Gergely Acs, Luca Melis, Claude Castelluccia, Emiliano De Cristofaro category:cs.LG cs.CR  published:2017-09-13 summary:Generative models are used in an increasing number of applications that rely on large amounts of contextually rich information about individuals. Owing to possible privacy violations of individuals whose data is used to train these models, however, publishing or sharing generative models is not always viable. In this paper, we introduce a novel solution for privately releasing generative models and entire high-dimensional datasets produced by these models. We model the generator distribution of the training data by a mixture of $k$ generative neural networks. These are trained together and collectively learn the generator distribution of a dataset. Data is divided into $k$ clusters, using a novel differentially private kernel $k$-means, then each cluster is given to separate generative neural networks, such as Restricted Boltzmann Machines or Variational Autoencoders, which are trained only on their own cluster using differentially private gradient descent. We evaluate our approach using the MNIST dataset and a large Call Detail Records dataset, showing that it produces realistic synthetic samples, which can also be used to accurately compute arbitrary number of counting queries. version:2
arxiv-1709-07036 | Inter-Subject Analysis: Inferring Sparse Interactions with Dense Intra-Graphs | http://arxiv.org/abs/1709.07036 | id:1709.07036 author:Cong Ma, Junwei Lu, Han Liu category:stat.ME math.ST stat.ML stat.TH  published:2017-09-20 summary:We develop a new modeling framework for Inter-Subject Analysis (ISA). The goal of ISA is to explore the dependency structure between different subjects with the intra-subject dependency as nuisance. It has important applications in neuroscience to explore the functional connectivity between brain regions under natural stimuli. Our framework is based on the Gaussian graphical models, under which ISA can be converted to the problem of estimation and inference of the inter-subject precision matrix. The main statistical challenge is that we do not impose sparsity constraint on the whole precision matrix and we only assume the inter-subject part is sparse. For estimation, we propose to estimate an alternative parameter to get around the non-sparse issue and it can achieve asymptotic consistency even if the intra-subject dependency is dense. For inference, we propose an "untangle and chord" procedure to de-bias our estimator. It is valid without the sparsity assumption on the inverse Hessian of the log-likelihood function. This inferential method is general and can be applied to many other statistical problems, thus it is of independent theoretical interest. Numerical experiments on both simulated and brain imaging data validate our methods and theory. version:1
arxiv-1709-06970 | An Expectation Conditional Maximization approach for Gaussian graphical models | http://arxiv.org/abs/1709.06970 | id:1709.06970 author:Zehang Li, Tyler H. McCormick category:stat.ML  published:2017-09-20 summary:Bayesian graphical models are a useful tool for understanding dependence relationships among many variables, particularly in situations with external prior information. In high-dimensional settings, the space of possible graphs becomes enormous, rendering even state-of-the-art Bayesian stochastic search computationally infeasible. We propose a deterministic alternative to estimate Gaussian and Gaussian copula graphical models using an Expectation Conditional Maximization (ECM) algorithm, extending the EM approach from Bayesian variable selection to graphical model estimation. We show that the ECM approach enables fast posterior exploration under a sequence of mixture priors, and can incorporate multiple sources of information. version:1
arxiv-1709-06950 | Spatial features of synaptic adaptation affecting learning performance | http://arxiv.org/abs/1709.06950 | id:1709.06950 author:Damian L. Berger, Lucilla de Arcangelis, Hans J. Herrmann category:q-bio.NC cond-mat.dis-nn cs.LG cs.NE  published:2017-09-20 summary:Recent studies have proposed that the diffusion of messenger molecules, such as monoamines, can mediate the plastic adaptation of synapses in supervised learning of neural networks. Based on these findings we developed a model for neural learning, where the signal for plastic adaptation is assumed to propagate through the extracellular space. We investigate the conditions allowing learning of Boolean rules in a neural network. Even fully excitatory networks show very good learning performances. Moreover, the investigation of the plastic adaptation features optimizing the performance suggests that learning is very sensitive to the extent of the plastic adaptation and the spatial range of synaptic connections. version:1
arxiv-1709-06922 | Stock-out Prediction in Multi-echelon Networks | http://arxiv.org/abs/1709.06922 | id:1709.06922 author:Afshin Oroojlooyjadid, Lawrence Snyder, Martin Takáč category:cs.LG  published:2017-09-20 summary:In multi-echelon inventory systems the performance of a given node is affected by events that occur at many other nodes and at many other time periods. For example, a supply disruption upstream will have an effect on downstream, customer-facing nodes several periods later as the disruption "cascades" through the system. There is very little research on stock-out prediction in single-echelon systems and (to the best of our knowledge) none on multi-echelon systems. However, in real the world, it is clear that there is significant interest in techniques for this sort of stock-out prediction. Therefore, our research aims to fill this gap by using DNN to predict stock-outs in multi-echelon supply chains. version:1
arxiv-1709-06918 | Constructing a Hierarchical User Interest Structure based on User Profiles | http://arxiv.org/abs/1709.06918 | id:1709.06918 author:Chao Zhao, Min Zhao, Yi Guan category:cs.CL cs.IR  published:2017-09-20 summary:The interests of individual internet users fall into a hierarchical structure which is useful in regards to building personalized searches and recommendations. Most studies on this subject construct the interest hierarchy of a single person from the document perspective. In this study, we constructed the user interest hierarchy via user profiles. We organized 433,397 user interests, referred to here as "attentions", into a user attention network (UAN) from 200 million user profiles; we then applied the Louvain algorithm to detect hierarchical clusters in these attentions. Finally, a 26-level hierarchy with 34,676 clusters was obtained. We found that these attention clusters were aggregated according to certain topics as opposed to the hyponymy-relation based conceptual ontologies. The topics can be entities or concepts, and the relations were not restrained by hyponymy. The concept relativity encapsulated in the user's interest can be captured by labeling the attention clusters with corresponding concepts. version:1
arxiv-1709-06868 | Learning quadrangulated patches for 3D shape parameterization and completion | http://arxiv.org/abs/1709.06868 | id:1709.06868 author:Kripasindhu Sarkar, Kiran Varanasi, Didier Stricker category:cs.CV  published:2017-09-20 summary:We propose a novel 3D shape parameterization by surface patches, that are oriented by 3D mesh quadrangulation of the shape. By encoding 3D surface detail on local patches, we learn a patch dictionary that identifies principal surface features of the shape. Unlike previous methods, we are able to encode surface patches of variable size as determined by the user. We propose novel methods for dictionary learning and patch reconstruction based on the query of a noisy input patch with holes. We evaluate the patch dictionary towards various applications in 3D shape inpainting, denoising and compression. Our method is able to predict missing vertices and inpaint moderately sized holes. We demonstrate a complete pipeline for reconstructing the 3D mesh from the patch encoding. We validate our shape parameterization and reconstruction methods on both synthetic shapes and real world scans. We show that our patch dictionary performs successful shape completion of complicated surface textures. version:1
arxiv-1709-06853 | Bandits with Delayed Anonymous Feedback | http://arxiv.org/abs/1709.06853 | id:1709.06853 author:Ciara Pike-Burke, Shipra Agrawal, Csaba Szepesvari, Steffen Grunewalder category:stat.ML cs.LG  published:2017-09-20 summary:We study the bandits with delayed anonymous feedback problem, a variant of the stochastic $K$-armed bandit problem, in which the reward from each play of an arm is no longer obtained instantaneously but received after some stochastic delay. Furthermore, the learner is not told which arm an observation corresponds to, nor do they observe the delay associated with a play. Instead, at each time step, the learner selects an arm to play and receives a reward which could be from any combination of past plays. This is a very natural problem; however, due to the delay and anonymity of the observations, it is considerably harder than the standard bandit problem. Despite this, we demonstrate it is still possible to achieve logarithmic regret, but with additional lower order terms. In particular, we provide an algorithm with regret $O(\log(T) + \sqrt{g(\tau) \log(T)} + g(\tau))$ where $g(\tau)$ is some function of the delay distribution. This is of the same order as that achieved in Joulani et al. (2013) for the simpler problem where the observations are not anonymous. We support our theoretical observation equating the two orders of regret with experiments. version:1
arxiv-1706-10241 | A selectional auto-encoder approach for document image binarization | http://arxiv.org/abs/1706.10241 | id:1706.10241 author:Jorge Calvo-Zaragoza, Antonio-Javier Gallego category:cs.CV cs.DL  published:2017-06-30 summary:Binarization plays a key role in the automatic information retrieval from document images. This process is usually performed in the first stages of documents analysis systems, and serves as a basis for subsequent steps. Hence it has to be robust in order to allow the full analysis workflow to be successful. Several methods for document image binarization have been proposed so far, most of which are based on hand-crafted image processing strategies. Recently, Convolutional Neural Networks have shown an amazing performance in many disparate duties related to computer vision. In this paper we discuss the use of convolutional auto-encoders devoted to learning an end-to-end map from an input image to its selectional output, in which activations indicate the likelihood of pixels to be either foreground or background. Once trained, documents can therefore be binarized by parsing them through the model and applying a threshold. This approach has proven to outperform existing binarization strategies in a number of document domains. version:2
arxiv-1709-06841 | UnDeepVO: Monocular Visual Odometry through Unsupervised Deep Learning | http://arxiv.org/abs/1709.06841 | id:1709.06841 author:Ruihao Li, Sen Wang, Zhiqiang Long, Dongbing Gu category:cs.CV  published:2017-09-20 summary:We propose a novel monocular visual odometry (VO) system called UnDeepVO in this paper. UnDeepVO is able to estimate the 6-DoF pose of a monocular camera and the depth of its view by using deep neural networks. There are two salient features of the proposed UnDeepVO: one is the unsupervised deep learning scheme, and the other is the absolute scale recovery. Specifically, we train UnDeepVO by using stereo image pairs to recover the scale but test it by using consecutive monocular images. Thus, UnDeepVO is a monocular system. The loss function defined for training the networks is based on spatial and temporal dense information. A system overview is shown in Fig. 1. The experiments on KITTI dataset show our UnDeepVO outperforms other monocular VO methods in terms of pose accuracy. version:1
arxiv-1709-04620 | Random matrix approach for primal-dual portfolio optimization problems | http://arxiv.org/abs/1709.04620 | id:1709.04620 author:Daichi Tada, Hisashi Yamamoto, Takashi Shinzato category:q-fin.PM cond-mat.dis-nn cs.CE cs.LG math.OC  published:2017-09-14 summary:In this paper, we revisit the portfolio optimization problems of the minimization/maximization of investment risk under constraints of budget and investment concentration (primal problem) and the maximization/minimization of investment concentration under constraints of budget and investment risk (dual problem) for the case that the variances of the return rates of the assets are identical. We analyze both optimization problems by using the Lagrange multiplier method and the random matrix approach. Thereafter, we compare the results obtained from our proposed approach with the results obtained in previous work. Moreover, we use numerical experiments to validate the results obtained from the replica approach and the random matrix approach as methods for analyzing both the primal and dual portfolio optimization problems. version:2
arxiv-1709-06818 | Updating the silent speech challenge benchmark with deep learning | http://arxiv.org/abs/1709.06818 | id:1709.06818 author:Yan Ji, Licheng Liu, Hongcui Wang, Zhilei Liu, Zhibin Niu, Bruce Denby category:cs.CL cs.CV cs.HC  published:2017-09-20 summary:The 2010 Silent Speech Challenge benchmark is updated with new results obtained in a Deep Learning strategy, using the same input features and decoding strategy as in the original article. A Word Error Rate of 6.4% is obtained, compared to the published value of 17.4%. Additional results comparing new auto-encoder-based features with the original features at reduced dimensionality, as well as decoding scenarios on two different language models, are also presented. The Silent Speech Challenge archive has been updated to contain both the original and the new auto-encoder features, in addition to the original raw data. version:1
arxiv-1708-01432 | Nonparametric weighted stochastic block models | http://arxiv.org/abs/1708.01432 | id:1708.01432 author:Tiago P. Peixoto category:stat.ML physics.data-an physics.soc-ph  published:2017-08-04 summary:We present a Bayesian formulation of weighted stochastic block models that can be used to infer the large-scale modular structure of weighted networks, including their hierarchical organization. Our method is nonparametric, and thus does not require the prior knowledge of the number of groups or other dimensions of the model, which are instead inferred from data. We give a comprehensive treatment of different kinds of edge weights (i.e. continuous or discrete, signed or unsigned, bounded or unbounded), as well as arbitrary weight transformations, and describe an unsupervised model selection approach to choose the best network description. We illustrate the application of our method to a variety of empirical weighted networks, such as global migrations, voting patterns in congress, and neural connections in the human brain. version:2
arxiv-1709-06770 | Latent Embeddings for Collective Activity Recognition | http://arxiv.org/abs/1709.06770 | id:1709.06770 author:Yongyi Tang, Peizhen Zhang, Jian-Fang Hu, Wei-Shi Zheng category:cs.CV  published:2017-09-20 summary:Rather than simply recognizing the action of a person individually, collective activity recognition aims to find out what a group of people is acting in a collective scene. Previ- ous state-of-the-art methods using hand-crafted potentials in conventional graphical model which can only define a limited range of relations. Thus, the complex structural de- pendencies among individuals involved in a collective sce- nario cannot be fully modeled. In this paper, we overcome these limitations by embedding latent variables into feature space and learning the feature mapping functions in a deep learning framework. The embeddings of latent variables build a global relation containing person-group interac- tions and richer contextual information by jointly modeling broader range of individuals. Besides, we assemble atten- tion mechanism during embedding for achieving more com- pact representations. We evaluate our method on three col- lective activity datasets, where we contribute a much larger dataset in this work. The proposed model has achieved clearly better performance as compared to the state-of-the- art methods in our experiments. version:1
arxiv-1709-06341 | 3D Reconstruction in Canonical Co-ordinate Space from Arbitrarily Oriented 2D Images | http://arxiv.org/abs/1709.06341 | id:1709.06341 author:Benjamin Hou, Bishesh Khanal, Amir Alansary, Steven McDonagh, Alice Davidson, Mary Rutherford, Jo V. Hajnal, Daniel Rueckert, Ben Glocker, Bernhard Kainz category:cs.CV  published:2017-09-19 summary:Limited capture range and the requirement to provide high quality initializations for optimization-based 2D/3D image registration methods can significantly degrade the per- formance of 3D image reconstruction and motion compensation pipelines. Challenging clinical imaging scenarios, that contain sig- nificant subject motion such as fetal in-utero imaging, complicate the 3D image and volume reconstruction process. In this paper we present a learning based image registra- tion method capable of predicting 3D rigid transformations of arbitrarily oriented 2D image slices, with respect to a learned canonical atlas co-ordinate system. Only image slice intensity information is used to perform registration and canonical align- ment, no spatial transform initialization is required. To find image transformations we utilize a Convolutional Neural Network (CNN) architecture to learn the regression function capable of mapping 2D image slices to the 3D canonical atlas space. We extensively evaluate the effectiveness of our approach quantitatively on simulated Magnetic Resonance Imaging (MRI), fetal brain imagery with synthetic motion and further demon- strate qualitative results on real fetal MRI data where our method is integrated into a full reconstruction and motion compensation pipeline. Our learning based registration achieves an average spatial prediction error of 7 mm on simulated data and produces qualitatively improved reconstructions for heavily moving fetuses with gestational ages of approximately 20 weeks. Our model provides a general and computationally efficient solution to the 2D-3D registration initialization problem and is suitable for real- time scenarios. version:2
arxiv-1709-06750 | SegFlow: Joint Learning for Video Object Segmentation and Optical Flow | http://arxiv.org/abs/1709.06750 | id:1709.06750 author:Jingchun Cheng, Yi-Hsuan Tsai, Shengjin Wang, Ming-Hsuan Yang category:cs.CV  published:2017-09-20 summary:This paper proposes an end-to-end trainable network, SegFlow, for simultaneously predicting pixel-wise object segmentation and optical flow in videos. The proposed SegFlow has two branches where useful information of object segmentation and optical flow is propagated bidirectionally in a unified framework. The segmentation branch is based on a fully convolutional network, which has been proved effective in image segmentation task, and the optical flow branch takes advantage of the FlowNet model. The unified framework is trained iteratively offline to learn a generic notion, and fine-tuned online for specific objects. Extensive experiments on both the video object segmentation and optical flow datasets demonstrate that introducing optical flow improves the performance of segmentation and vice versa, against the state-of-the-art algorithms. version:1
arxiv-1709-09518 | Local Directional Relation Pattern for Unconstrained and Robust Face Retrieval | http://arxiv.org/abs/1709.09518 | id:1709.09518 author:Shiv Ram Dubey category:cs.CV  published:2017-09-20 summary:Face recognition is still a very demanding area of research. This problem becomes more challenging in unconstrained environment and in the presence of several variations like pose, illumination, expression, etc. Local descriptors are widely used for this task. The existing local descriptors are not able to utilize the wider local information to make the descriptor more discriminative. The wider local information based descriptors mainly suffer due to the increased dimensionality. In this paper, this problem is solved by encoding the relationship among directional neighbors in an efficient manner. The relationship between the center pixel and the encoded directional neighbors is utilized further to form the proposed local directional relation pattern (LDRP). The descriptor is inherently uniform illumination invariant. The multi-scale mechanism is also adapted to further boost the discriminative ability of the descriptor. The proposed descriptor is evaluated under the image retrieval framework over face databases. Very challenging databases like PaSC, LFW, PubFig, ESSEX, FERET, and AT&T are used to test the discriminative ability and robustness of LDRP descriptor. Results are also compared with the recent state-of-the-art face descriptors such as LBP, LTP, LDP, LDN, LVP, DCP, LDGP and LGHP. Very promising performance is observed using the proposed descriptor over very appealing face databases as compared to the existing face descriptors. version:1
arxiv-1709-06716 | Contrastive Principal Component Analysis | http://arxiv.org/abs/1709.06716 | id:1709.06716 author:Abubakar Abid, Vivek K. Bagaria, Martin J. Zhang, James Zou category:stat.ML cs.LG  published:2017-09-20 summary:We present a new technique called contrastive principal component analysis (cPCA) that is designed to discover low-dimensional structure that is unique to a dataset, or enriched in one dataset relative to other data. The technique is a generalization of standard PCA, for the setting where multiple datasets are available -- e.g. a treatment and a control group, or a mixed versus a homogeneous population -- and the goal is to explore patterns that are specific to one of the datasets. We conduct a wide variety of experiments in which cPCA identifies important dataset-specific patterns that are missed by PCA, demonstrating that it is useful for many applications: subgroup discovery, visualizing trends, feature selection, denoising, and data-dependent standardization. We provide geometrical interpretations of cPCA and show that it satisfies desirable theoretical guarantees. We also extend cPCA to nonlinear settings in the form of kernel cPCA. We have released our code as a python package and documentation is on Github. version:1
arxiv-1709-08698 | Identifying Restaurant Features via Sentiment Analysis on Yelp Reviews | http://arxiv.org/abs/1709.08698 | id:1709.08698 author:Boya Yu, Jiaxu Zhou, Yi Zhang, Yunong Cao category:cs.CL  published:2017-09-20 summary:Many people use Yelp to find a good restaurant. Nonetheless, with only an overall rating for each restaurant, Yelp offers not enough information for independently judging its various aspects such as environment, service or flavor. In this paper, we introduced a machine learning based method to characterize such aspects for particular types of restaurants. The main approach used in this paper is to use a support vector machine (SVM) model to decipher the sentiment tendency of each review from word frequency. Word scores generated from the SVM models are further processed into a polarity index indicating the significance of each word for special types of restaurant. Customers overall tend to express more sentiment regarding service. As for the distinction between different cuisines, results that match the common sense are obtained: Japanese cuisines are usually fresh, some French cuisines are overpriced while Italian Restaurants are often famous for their pizzas. version:1
arxiv-1709-06709 | Online Learning of a Memory for Learning Rates | http://arxiv.org/abs/1709.06709 | id:1709.06709 author:Franziska Meier, Daniel Kappler, Stefan Schaal category:cs.LG  published:2017-09-20 summary:The promise of learning to learn for robotics rests on the hope that by extracting some information about the learning process itself we can speed up subsequent similar learning tasks. Here, we introduce a computationally efficient online meta-learning algorithm that builds and optimizes a memory model of the optimal learning rate landscape from previously observed gradient behaviors. While performing task specific optimization, this memory of learning rates predicts how to scale currently observed gradients. After applying the gradient scaling our meta-learner updates its internal memory based on the observed effect its prediction had. Our meta-learning can be combined with any gradient-based optimizer, learns on the fly and can be transferred to new optimization tasks. In our evaluations we show that our meta-learning algorithm speeds up learning of MNIST classification and a variety of learning control tasks, either in batch or online learning settings. version:1
arxiv-1709-06994 | Structured Probabilistic Pruning for Deep Convolutional Neural Network Acceleration | http://arxiv.org/abs/1709.06994 | id:1709.06994 author:Huan Wang, Qiming Zhang, Yuehai Wang, Roland Hu category:cs.LG stat.ML  published:2017-09-20 summary:Although deep Convolutional Neural Network (CNN) has shown better performance in various machine learning tasks, its application is accompanied by a significant increase in storage and computation. Among CNN simplification techniques, parameter pruning is a promising approach which aims at reducing the number of weights of various layers without intensively reducing the original accuracy. In this paper, we propose a novel progressive parameter pruning method, named Structured Probabilistic Pruning (SPP), which efficiently prunes weights of convolutional layers in a probabilistic manner. Unlike existing deterministic pruning approaches, in which the pruned weights of a well-trained model are permanently eliminated, SPP utilizes the relative importance of weights during training iterations, which makes the pruning procedure more accurate by leveraging the accumulated weight importance. Specifically, we introduce an effective weight competition mechanism to emphasize the important weights and gradually undermine the unimportant ones. Experiments indicate that our proposed method has obtained superior performance on ConvNet and AlexNet compared with existing pruning methods. Our pruned AlexNet achieves 4.0 $\sim$ 8.9x (averagely 5.8x) layer-wise speedup in convolutional layers with only 1.3\% top-5 error increase on the ImageNet-2012 validation dataset. We also prove the effectiveness of our method on transfer learning scenarios using AlexNet. version:1
arxiv-1709-05903 | E$^2$BoWs: An End-to-End Bag-of-Words Model via Deep Convolutional Neural Network | http://arxiv.org/abs/1709.05903 | id:1709.05903 author:Xiaobin Liu, Shiliang Zhang, Tiejun Huang, Qi Tian category:cs.CV  published:2017-09-18 summary:Traditional Bag-of-visual Words (BoWs) model is commonly generated with many steps including local feature extraction, codebook generation, and feature quantization, etc. Those steps are relatively independent with each other and are hard to be jointly optimized. Moreover, the dependency on hand-crafted local feature makes BoWs model not effective in conveying high-level semantics. These issues largely hinder the performance of BoWs model in large-scale image applications. To conquer these issues, we propose an End-to-End BoWs (E$^2$BoWs) model based on Deep Convolutional Neural Network (DCNN). Our model takes an image as input, then identifies and separates the semantic objects in it, and finally outputs the visual words with high semantic discriminative power. Specifically, our model firstly generates Semantic Feature Maps (SFMs) corresponding to different object categories through convolutional layers, then introduces Bag-of-Words Layers (BoWL) to generate visual words for each individual feature map. We also introduce a novel learning algorithm to reinforce the sparsity of the generated E$^2$BoWs model, which further ensures the time and memory efficiency. We evaluate the proposed E$^2$BoWs model on several image search datasets including CIFAR-10, CIFAR-100, MIRFLICKR-25K and NUS-WIDE. Experimental results show that our method achieves promising accuracy and efficiency compared with recent deep learning based retrieval works. version:2
arxiv-1709-06688 | Property Testing in High Dimensional Ising models | http://arxiv.org/abs/1709.06688 | id:1709.06688 author:Matey Neykov, Han Liu category:math.ST stat.ML stat.TH  published:2017-09-20 summary:This paper explores the information-theoretic limitations of graph property testing in zero-field Ising models. Instead of learning the entire graph structure, sometimes testing a basic graph property such as connectivity, cycle presence or maximum clique size is a more relevant and attainable objective. Since property testing is more fundamental than graph recovery, any necessary conditions for property testing imply corresponding conditions for graph recovery, while custom property tests can be statistically and/or computationally more efficient than graph recovery based algorithms. Understanding the statistical complexity of property testing requires the distinction of ferromagnetic (i.e., positive interactions only) and general Ising models. Using combinatorial constructs such as graph packing and strong monotonicity, we characterize how target properties affect the corresponding minimax upper and lower bounds within the realm of ferromagnets. On the other hand, by studying the detection of an antiferromagnetic (i.e., negative interactions only) Curie-Weiss model buried in Rademacher noise, we show that property testing is strictly more challenging over general Ising models. In terms of methodological development, we propose two types of correlation based tests: computationally efficient screening for ferromagnets, and score type tests for general models, including a fast cycle presence test. Our correlation screening tests match the information-theoretic bounds for property testing in ferromagnets. version:1
arxiv-1709-06683 | OptionGAN: Learning Joint Reward-Policy Options using Generative Adversarial Inverse Reinforcement Learning | http://arxiv.org/abs/1709.06683 | id:1709.06683 author:Peter Henderson, Wei-Di Chang, Pierre-Luc Bacon, David Meger, Joelle Pineau, Doina Precup category:cs.LG  published:2017-09-20 summary:Reinforcement learning has shown promise in learning policies that can solve complex problems. However, manually specifying a good reward function can be difficult, especially for intricate tasks. Inverse reinforcement learning offers a useful paradigm to learn the underlying reward function directly from expert demonstrations. Yet in reality, the corpus of demonstrations may contain trajectories arising from a diverse set of underlying reward functions rather than a single one. Thus, in inverse reinforcement learning, it is useful to consider such a decomposition. The options framework in reinforcement learning is specifically designed to decompose policies in a similar light. We therefore extend the options framework and propose a method to simultaneously recover reward options in addition to policy options. We leverage adversarial methods to learn joint reward-policy options using only observed expert states. We show that this approach works well in both simple and complex continuous control tasks and shows significant performance increases in one-shot transfer learning. version:1
arxiv-1709-06680 | Deep Lattice Networks and Partial Monotonic Functions | http://arxiv.org/abs/1709.06680 | id:1709.06680 author:Seungil You, David Ding, Kevin Canini, Jan Pfeifer, Maya Gupta category:stat.ML cs.LG  published:2017-09-19 summary:We propose learning deep models that are monotonic with respect to a user-specified set of inputs by alternating layers of linear embeddings, ensembles of lattices, and calibrators (piecewise linear functions), with appropriate constraints for monotonicity, and jointly training the resulting network. We implement the layers and projections with new computational graph nodes in TensorFlow and use the ADAM optimizer and batched stochastic gradients. Experiments on benchmark and real-world datasets show that six-layer monotonic deep lattice networks achieve state-of-the art performance for classification and regression with monotonicity guarantees. version:1
arxiv-1709-06671 | Think Globally, Embed Locally --- Locally Linear Meta-embedding of Words | http://arxiv.org/abs/1709.06671 | id:1709.06671 author:Danushka Bollegala, Kohei Hayashi, Ken-ichi Kawarabayashi category:cs.CL cs.LG cs.NE  published:2017-09-19 summary:Distributed word embeddings have shown superior performances in numerous Natural Language Processing (NLP) tasks. However, their performances vary significantly across different tasks, implying that the word embeddings learnt by those methods capture complementary aspects of lexical semantics. Therefore, we believe that it is important to combine the existing word embeddings to produce more accurate and complete \emph{meta-embeddings} of words. For this purpose, we propose an unsupervised locally linear meta-embedding learning method that takes pre-trained word embeddings as the input, and produces more accurate meta embeddings. Unlike previously proposed meta-embedding learning methods that learn a global projection over all words in a vocabulary, our proposed method is sensitive to the differences in local neighbourhoods of the individual source word embeddings. Moreover, we show that vector concatenation, a previously proposed highly competitive baseline approach for integrating word embeddings, can be derived as a special case of the proposed method. Experimental results on semantic similarity, word analogy, relation classification, and short-text classification tasks show that our meta-embeddings to significantly outperform prior methods in several benchmark datasets, establishing a new state of the art for meta-embeddings. version:1
arxiv-1709-06669 | A textual transform of multivariate time-series for prognostics | http://arxiv.org/abs/1709.06669 | id:1709.06669 author:Abhay Harpale, Abhishek Srivastav category:stat.ML cs.LG  published:2017-09-19 summary:Prognostics or early detection of incipient faults is an important industrial challenge for condition-based and preventive maintenance. Physics-based approaches to modeling fault progression are infeasible due to multiple interacting components, uncontrolled environmental factors and observability constraints. Moreover, such approaches to prognostics do not generalize to new domains. Consequently, domain-agnostic data-driven machine learning approaches to prognostics are desirable. Damage progression is a path-dependent process and explicitly modeling the temporal patterns is critical for accurate estimation of both the current damage state and its progression leading to total failure. In this paper, we present a novel data-driven approach to prognostics that employs a novel textual representation of multivariate temporal sensor observations for predicting the future health state of the monitored equipment early in its life. This representation enables us to utilize well-understood concepts from text-mining for modeling, prediction and understanding distress patterns in a domain agnostic way. The approach has been deployed and successfully tested on large scale multivariate time-series data from commercial aircraft engines. We report experiments on well-known publicly available benchmark datasets and simulation datasets. The proposed approach is shown to be superior in terms of prediction accuracy, lead time to prediction and interpretability. version:1
arxiv-1709-06664 | Curriculum Learning of Visual Attribute Clusters for Multi-Task Classification | http://arxiv.org/abs/1709.06664 | id:1709.06664 author:Nikolaos Sarafianos, Theodore Giannakopoulos, Christophoros Nikou, Ioannis A. Kakadiaris category:cs.CV  published:2017-09-19 summary:Visual attributes, from simple objects (e.g., backpacks, hats) to soft-biometrics (e.g., gender, height, clothing) have proven to be a powerful representational approach for many applications such as image description and human identification. In this paper, we introduce a novel method to combine the advantages of both multi-task and curriculum learning in a visual attribute classification framework. Individual tasks are grouped after performing hierarchical clustering based on their correlation. The clusters of tasks are learned in a curriculum learning setup by transferring knowledge between clusters. The learning process within each cluster is performed in a multi-task classification setup. By leveraging the acquired knowledge, we speed-up the process and improve performance. We demonstrate the effectiveness of our method via ablation studies and a detailed analysis of the covariates, on a variety of publicly available datasets of humans standing with their full-body visible. Extensive experimentation has proven that the proposed approach boosts the performance by 4% to 10%. version:1
arxiv-1709-06653 | Unique Information via Dependency Constraints | http://arxiv.org/abs/1709.06653 | id:1709.06653 author:Ryan G. James, Jeffrey Emenheiser, James P. Crutchfield category:cond-mat.stat-mech cs.IT cs.LG math.IT math.ST stat.TH  published:2017-09-19 summary:The partial information decomposition is perhaps the leading proposal for resolving shared information in a joint random variable into redundant, synergistic, and unique constituents. Unfortunately, the framework has been hindered by a lack of a generally agreed-upon, multivariate method of quantifying the constituents. Here, we take a step toward rectifying this by developing a decomposition based on a new method that quantifies unique information. The result is the first measure which satisfies the core axioms of the framework while also not treating identical but independent channels as redundant. This marks a key step forward in the practical application of the partial information decomposition. version:1
arxiv-1709-07308 | Predicting Positive and Negative Links with Noisy Queries: Theory & Practice | http://arxiv.org/abs/1709.07308 | id:1709.07308 author:Charalampos E. Tsourakakis, Michael Mitzenmacher, Jarosław Błasiok, Ben Lawson, Preetum Nakkiran, Vasileios Nakos category:cs.DS cs.DM cs.LG cs.SI math.CO  published:2017-09-19 summary:Social networks and interactions in social media involve both positive and negative relationships. Signed graphs capture both types of relationships: positive edges correspond to pairs of "friends", and negative edges to pairs of "foes". The edge sign prediction problem, that aims to predict whether an interaction between a pair of nodes will be positive or negative, is an important graph mining task for which many heuristics have recently been proposed [Leskovec 2010]. We model the edge sign prediction problem as follows: we are allowed to query any pair of nodes whether they belong to the same cluster or not, but the answer to the query is corrupted with some probability $0<q<\frac{1}{2}$. Let $\delta=1-2q$ be the bias. We provide an algorithm that recovers all signs correctly with high probability in the presence of noise for any constant gap $\delta$ with $O(\frac{n\log n}{\delta^4})$ queries. Our algorithm uses breadth first search as its main algorithmic primitive. A byproduct of our proposed learning algorithm is the use of $s-t$ paths as an informative feature to predict the sign of the edge $(s,t)$. As a heuristic, we use edge disjoint $s-t$ paths of short length as a feature for predicting edge signs in real-world signed networks. Our findings suggest that the use of paths improves the classification accuracy, especially for pairs of nodes with no common neighbors. version:1
arxiv-1709-06636 | An Attention-based Collaboration Framework for Multi-View Network Representation Learning | http://arxiv.org/abs/1709.06636 | id:1709.06636 author:Meng Qu, Jian Tang, Jingbo Shang, Xiang Ren, Ming Zhang, Jiawei Han category:cs.SI cs.LG stat.ML  published:2017-09-19 summary:Learning distributed node representations in networks has been attracting increasing attention recently due to its effectiveness in a variety of applications. Existing approaches usually study networks with a single type of proximity between nodes, which defines a single view of a network. However, in reality there usually exists multiple types of proximities between nodes, yielding networks with multiple views. This paper studies learning node representations for networks with multiple views, which aims to infer robust node representations across different views. We propose a multi-view representation learning approach, which promotes the collaboration of different views and lets them vote for the robust representations. During the voting process, an attention mechanism is introduced, which enables each node to focus on the most informative views. Experimental results on real-world networks show that the proposed approach outperforms existing state-of-the-art approaches for network representation learning with a single view and other competitive approaches with multiple views. version:1
arxiv-1705-02047 | Matrix Factorization with Side and Higher Order Information | http://arxiv.org/abs/1705.02047 | id:1705.02047 author:Vatsal Shah, Nikhil Rao, Weicong Ding category:stat.ML cs.LG  published:2017-05-04 summary:The problem of predicting unobserved entries of a partially observed matrix has found wide applicability in several areas, such as recommender systems, computational biology, and computer vision. Many scalable methods with rigorous theoretical guarantees have been developed for algorithms where the matrix is factored into low-rank components, and embeddings are learned for the row and column variables. While there has been recent research on incorporating explicit side information in the low-rank matrix factorization setting, often implicit information can be gleaned from the data, via higher order interactions among variables. In this paper, we design a method to make use of this implicit information, via random walks on graphs. We show that the problem we intend to solve can be cast as factoring a nonlinear transform of the (partially) observed matrix and develop an efficient coordinate descent based algorithm for the same. Experiments on several datasets show that the method we propose outperforms vanilla matrix factorization, and also those methods that use explicitly available side information. version:2
arxiv-1709-04129 | HitFraud: A Broad Learning Approach for Collective Fraud Detection in Heterogeneous Information Networks | http://arxiv.org/abs/1709.04129 | id:1709.04129 author:Bokai Cao, Mia Mao, Siim Viidu, Philip S. Yu category:cs.LG cs.CR  published:2017-09-13 summary:On electronic game platforms, different payment transactions have different levels of risk. Risk is generally higher for digital goods in e-commerce. However, it differs based on product and its popularity, the offer type (packaged game, virtual currency to a game or subscription service), storefront and geography. Existing fraud policies and models make decisions independently for each transaction based on transaction attributes, payment velocities, user characteristics, and other relevant information. However, suspicious transactions may still evade detection and hence we propose a broad learning approach leveraging a graph based perspective to uncover relationships among suspicious transactions, i.e., inter-transaction dependency. Our focus is to detect suspicious transactions by capturing common fraudulent behaviors that would not be considered suspicious when being considered in isolation. In this paper, we present HitFraud that leverages heterogeneous information networks for collective fraud detection by exploring correlated and fast evolving fraudulent behaviors. First, a heterogeneous information network is designed to link entities of interest in the transaction database via different semantics. Then, graph based features are efficiently discovered from the network exploiting the concept of meta-paths, and decisions on frauds are made collectively on test instances. Experiments on real-world payment transaction data from Electronic Arts demonstrate that the prediction performance is effectively boosted by HitFraud with fast convergence where the computation of meta-path based features is largely optimized. Notably, recall can be improved up to 7.93% and F-score 4.62% compared to baselines. version:2
arxiv-1709-06617 | A PAC-Bayesian Analysis of Randomized Learning with Application to Stochastic Gradient Descent | http://arxiv.org/abs/1709.06617 | id:1709.06617 author:Ben London category:cs.LG  published:2017-09-19 summary:We analyze the generalization error of randomized learning algorithms -- focusing on stochastic gradient descent (SGD) -- using a novel combination of PAC-Bayes and algorithmic stability. Importantly, our risk bounds hold for all posterior distributions on the algorithm's random hyperparameters, including distributions that depend on the training data. This inspires an adaptive sampling algorithm for SGD that optimizes the posterior at runtime. We analyze this algorithm in the context of our risk bounds and evaluate it empirically on a benchmark dataset. version:1
arxiv-1709-05554 | Deep Automated Multi-task Learning | http://arxiv.org/abs/1709.05554 | id:1709.05554 author:Davis Liang, Yan Shu category:cs.LG stat.ML  published:2017-09-16 summary:Multi-task learning (MTL) has recently contributed to learning better representations in service of various NLP tasks. MTL aims at improving the performance of a primary task, by jointly training on a secondary task. This paper introduces automated tasks, which exploit the sequential nature of the input data, as secondary tasks in an MTL model. We explore next word prediction, next character prediction, and missing word completion as potential automated tasks. Our results show that training on a primary task in parallel with a secondary automated task improves both the convergence speed and accuracy for the primary task. We suggest two methods for augmenting an existing network with automated tasks and establish better performance in topic prediction, sentiment analysis, and hashtag recommendation. Finally, we show that the MTL models can perform well on datasets that are small and colloquial by nature. version:2
arxiv-1709-06599 | Unsupervised Machine Learning for Networking: Techniques, Applications and Research Challenges | http://arxiv.org/abs/1709.06599 | id:1709.06599 author:Muhammad Usama, Junaid Qadir, Aunn Raza, Hunain Arif, Kok-Lim Alvin Yau, Yehia Elkhatib, Amir Hussain, Ala Al-Fuqaha category:cs.NI cs.LG  published:2017-09-19 summary:While machine learning and artificial intelligence have long been applied in networking research, the bulk of such works has focused on supervised learning. Recently there has been a rising trend of employing unsupervised machine learning using unstructured raw network data to improve network performance and provide services such as traffic engineering, anomaly detection, Internet traffic classification, and quality of service optimization. The interest in applying unsupervised learning techniques in networking emerges from their great success in other fields such as computer vision, natural language processing, speech recognition, and optimal control (e.g., for developing autonomous self-driving cars). Unsupervised learning is interesting since it can unconstrain us from the need of labeled data and manual handcrafted feature engineering thereby facilitating flexible, general, and automated methods of machine learning. The focus of this survey paper is to provide an overview of the applications of unsupervised learning in the domain of networking. We provide a comprehensive survey highlighting the recent advancements in unsupervised learning techniques and describe their applications for various learning tasks in the context of networking. We also provide a discussion on future directions and open research issues, while also identifying potential pitfalls. While a few survey papers focusing on the applications of machine learning in networking have previously been published, a survey of similar scope and breadth is missing in literature. Through this paper, we advance the state of knowledge by carefully synthesizing the insights from these survey papers while also providing contemporary coverage of recent advances. version:1
arxiv-1709-08694 | Methodology and Results for the Competition on Semantic Similarity Evaluation and Entailment Recognition for PROPOR 2016 | http://arxiv.org/abs/1709.08694 | id:1709.08694 author:Luciano Barbosa, Paulo R. Cavalin, Victor Guimaraes, Matthias Kormaksson category:cs.CL cs.LG  published:2017-09-19 summary:In this paper, we present the methodology and the results obtained by our teams, dubbed Blue Man Group, in the ASSIN (from the Portuguese {\it Avalia\c{c}\~ao de Similaridade Sem\^antica e Infer\^encia Textual}) competition, held at PROPOR 2016\footnote{International Conference on the Computational Processing of the Portuguese Language - http://propor2016.di.fc.ul.pt/}. Our team's strategy consisted of evaluating methods based on semantic word vectors, following two distinct directions: 1) to make use of low-dimensional, compact, feature sets, and 2) deep learning-based strategies dealing with high-dimensional feature vectors. Evaluation results demonstrated that the first strategy was more promising, so that the results from the second strategy have been discarded. As a result, by considering the best run of each of the six teams, we have been able to achieve the best accuracy and F1 values in entailment recognition, in the Brazilian Portuguese set, and the best F1 score overall. In the semantic similarity task, our team was ranked second in the Brazilian Portuguese set, and third considering both sets. version:1
arxiv-1709-06548 | Triangle Generative Adversarial Networks | http://arxiv.org/abs/1709.06548 | id:1709.06548 author:Zhe Gan, Liqun Chen, Weiyao Wang, Yunchen Pu, Yizhe Zhang, Hao Liu, Chunyuan Li, Lawrence Carin category:cs.LG stat.ML  published:2017-09-19 summary:A Triangle Generative Adversarial Network ($\Delta$-GAN) is developed for semi-supervised cross-domain joint distribution matching, where the training data consists of samples from each domain, and supervision of domain correspondence is provided by only a few paired samples. $\Delta$-GAN consists of four neural networks, two generators and two discriminators. The generators are designed to learn the two-way conditional distributions between the two domains, while the discriminators implicitly define a ternary discriminative function, which is trained to distinguish real data pairs and two kinds of fake data pairs. The generators and discriminators are trained together using adversarial learning. Under mild assumptions, in theory the joint distributions characterized by the two generators concentrate to the data distribution. In experiments, three different kinds of domain pairs are considered, image-label, image-image and image-attribute pairs. Experiments on semi-supervised image classification, image-to-image translation and attribute-based image generation demonstrate the superiority of the proposed approach. version:1
arxiv-1709-06895 | Optimized Sparse Projections for Compressive Sensing | http://arxiv.org/abs/1709.06895 | id:1709.06895 author:Tao Hong, Xiao Li, Zhihui Zhu, Qiuwei Li category:eess.SP cs.LG  published:2017-09-19 summary:We consider designing a sparse sensing matrix which contains few non-zero entries per row for compressive sensing (CS) systems. By unifying the previous approaches for optimizing sensing matrices based on minimizing the mutual coherence, we propose a general framework for designing a sparse sensing matrix that minimizes the mutual coherence of the equivalent dictionary and is robust to sparse representation error. An alternating minimization-based algorithm is proposed for designing sparse sensing matrices. Experiments with real images show that the obtained sparse sensing matrix (even each row is extremely sparse) significantly outperforms a random dense sensing matrix in terms of the signal recovery accuracy. version:1
arxiv-1709-06532 | When 3D-Aided 2D Face Recognition Meets Deep Learning: An extended UR2D for Pose-Invariant Face Recognition | http://arxiv.org/abs/1709.06532 | id:1709.06532 author:Xiang Xu, Pengfei Dou, Ha A. Le, Ioannis A. Kakadiaris category:cs.CV  published:2017-09-19 summary:Most of the face recognition works focus on specific modules or demonstrate a research idea. This paper presents a pose-invariant 3D-aided 2D face recognition system (UR2D) that is robust to pose variations as large as 90? by leveraging deep learning technology. The architecture and the interface of UR2D are described, and each module is introduced in detail. Extensive experiments are conducted on the UHDB31 and IJB-A, demonstrating that UR2D outperforms existing 2D face recognition systems such as VGG-Face, FaceNet, and a commercial off-the-shelf software (COTS) by at least 9% on the UHDB31 dataset and 3% on the IJB-A dataset on average in face identification tasks. UR2D also achieves state-of-the-art performance of 85% on the IJB-A dataset by comparing the Rank-1 accuracy score from template matching. It fills a gap by providing a 3D-aided 2D face recognition system that has compatible results with 2D face recognition systems using deep learning techniques. version:1
arxiv-1709-06531 | Learning to Detect Violent Videos using Convolutional Long Short-Term Memory | http://arxiv.org/abs/1709.06531 | id:1709.06531 author:Swathikiran Sudhakaran, Oswald Lanz category:cs.CV  published:2017-09-19 summary:Developing a technique for the automatic analysis of surveillance videos in order to identify the presence of violence is of broad interest. In this work, we propose a deep neural network for the purpose of recognizing violent videos. A convolutional neural network is used to extract frame level features from a video. The frame level features are then aggregated using a variant of the long short term memory that uses convolutional gates. The convolutional neural network along with the convolutional long short term memory is capable of capturing localized spatio-temporal features which enables the analysis of local motion taking place in the video. We also propose to use adjacent frame differences as the input to the model thereby forcing it to encode the changes occurring in the video. The performance of the proposed feature extraction pipeline is evaluated on three standard benchmark datasets in terms of recognition accuracy. Comparison of the results obtained with the state of the art techniques revealed the promising capability of the proposed method in recognizing violent videos. version:1
arxiv-1709-06525 | Inference in Graphical Models via Semidefinite Programming Hierarchies | http://arxiv.org/abs/1709.06525 | id:1709.06525 author:Murat A. Erdogdu, Yash Deshpande, Andrea Montanari category:stat.ML cs.DS  published:2017-09-19 summary:Maximum A posteriori Probability (MAP) inference in graphical models amounts to solving a graph-structured combinatorial optimization problem. Popular inference algorithms such as belief propagation (BP) and generalized belief propagation (GBP) are intimately related to linear programming (LP) relaxation within the Sherali-Adams hierarchy. Despite the popularity of these algorithms, it is well understood that the Sum-of-Squares (SOS) hierarchy based on semidefinite programming (SDP) can provide superior guarantees. Unfortunately, SOS relaxations for a graph with $n$ vertices require solving an SDP with $n^{\Theta(d)}$ variables where $d$ is the degree in the hierarchy. In practice, for $d\ge 4$, this approach does not scale beyond a few tens of variables. In this paper, we propose binary SDP relaxations for MAP inference using the SOS hierarchy with two innovations focused on computational efficiency. Firstly, in analogy to BP and its variants, we only introduce decision variables corresponding to contiguous regions in the graphical model. Secondly, we solve the resulting SDP using a non-convex Burer-Monteiro style method, and develop a sequential rounding procedure. We demonstrate that the resulting algorithm can solve problems with tens of thousands of variables within minutes, and outperforms BP and GBP on practical problems such as image denoising and Ising spin glasses. Finally, for specific graph types, we establish a sufficient condition for the tightness of the proposed partial SOS relaxation. version:1
arxiv-1709-06505 | SalNet360: Saliency Maps for omni-directional images with CNN | http://arxiv.org/abs/1709.06505 | id:1709.06505 author:Rafael Monroy, Sebastian Lutz, Tejo Chalasani, Aljosa Smolic category:cs.CV  published:2017-09-19 summary:The prediction of Visual Attention data from any kind of media is of valuable use to content creators and used to efficiently drive encoding algorithms. With the current trend in the Virtual Reality (VR) field, adapting known techniques to this new kind of media is starting to gain momentum. In this paper, we present an architectural extension to any Convolutional Neural Network (CNN) to fine-tune traditional 2D saliency prediction to Omnidirectional Images (ODIs) in an end-to-end manner. We show that each step in the proposed pipeline works towards making the generated saliency map more accurate with respect to ground truth data. version:1
arxiv-1709-06495 | Convolutional Long Short-Term Memory Networks for Recognizing First Person Interactions | http://arxiv.org/abs/1709.06495 | id:1709.06495 author:Swathikiran Sudhakaran, Oswald Lanz category:cs.CV  published:2017-09-19 summary:In this paper, we present a novel deep learning based approach for addressing the problem of interaction recognition from a first person perspective. The proposed approach uses a pair of convolutional neural networks, whose parameters are shared, for extracting frame level features from successive frames of the video. The frame level features are then aggregated using a convolutional long short-term memory. The hidden state of the convolutional long short-term memory, after all the input video frames are processed, is used for classification in to the respective categories. The two branches of the convolutional neural network perform feature encoding on a short time interval whereas the convolutional long short term memory encodes the changes on a longer temporal duration. In our network the spatio-temporal structure of the input is preserved till the very final processing stage. Experimental results show that our method outperforms the state of the art on most recent first person interactions datasets that involve complex ego-motion. In particular, on UTKinect-FirstPerson it competes with methods that use depth image and skeletal joints information along with RGB images, while it surpasses all previous methods that use only RGB images by more than 20% in recognition accuracy. version:1
arxiv-1709-04077 | Setpoint Tracking with Partially Observed Loads | http://arxiv.org/abs/1709.04077 | id:1709.04077 author:Antoine Lesage-Landry, Joshua A. Taylor category:math.OC stat.ML  published:2017-09-12 summary:We use online convex optimization (OCO) for setpoint tracking with uncertain, flexible loads. We consider full feedback from the loads, bandit feedback, and two intermediate types of feedback: partial bandit where a subset of the loads are individually observed and the rest are observed in aggregate, and Bernoulli feedback where in each round the aggregator receives either full or bandit feedback according to a known probability. We give sublinear regret bounds in all cases. We numerically evaluate our algorithms on examples with thermostatically controlled loads and electric vehicles. version:2
arxiv-1709-06489 | Accurate Genomic Prediction Of Human Height | http://arxiv.org/abs/1709.06489 | id:1709.06489 author:Louis Lello, Steven G. Avery, Laurent Tellier, Ana Vazquez, Gustavo de los Campos, Stephen D. H. Hsu category:q-bio.GN cs.LG q-bio.QM stat.ML  published:2017-09-19 summary:We construct genomic predictors for heritable and extremely complex human quantitative traits (height, heel bone density, and educational attainment) using modern methods in high dimensional statistics (i.e., machine learning). Replication tests show that these predictors capture, respectively, $\sim$40, 20, and 9 percent of total variance for the three traits. For example, predicted heights correlate $\sim$0.65 with actual height; actual heights of most individuals in validation samples are within a few cm of the prediction. The variance captured for height is comparable to the estimated SNP heritability from GCTA (GREML) analysis, and seems to be close to its asymptotic value (i.e., as sample size goes to infinity), suggesting that we have captured most of the heritability for the SNPs used. Thus, our results resolve the common SNP portion of the "missing heritability" problem -- i.e., the gap between prediction R-squared and SNP heritability. The $\sim$20k activated SNPs in our height predictor reveal the genetic architecture of human height, at least for common SNPs. Our primary dataset is the UK Biobank cohort, comprised of almost 500k individual genotypes with multiple phenotypes. We also use other datasets and SNPs found in earlier GWAS for out-of-sample validation of our results. version:1
arxiv-1709-06476 | Image operator learning coupled with CNN classification and its application to staff line removal | http://arxiv.org/abs/1709.06476 | id:1709.06476 author:Frank D. Julca-Aguilar, Nina S. T. Hirata category:cs.CV  published:2017-09-19 summary:Many image transformations can be modeled by image operators that are characterized by pixel-wise local functions defined on a finite support window. In image operator learning, these functions are estimated from training data using machine learning techniques. Input size is usually a critical issue when using learning algorithms, and it limits the size of practicable windows. We propose the use of convolutional neural networks (CNNs) to overcome this limitation. The problem of removing staff-lines in music score images is chosen to evaluate the effects of window and convolutional mask sizes on the learned image operator performance. Results show that the CNN based solution outperforms previous ones obtained using conventional learning algorithms or heuristic algorithms, indicating the potential of CNNs as base classifiers in image operator learning. The implementations will be made available on the TRIOSlib project site. version:1
arxiv-1706-07536 | Listen to Your Face: Inferring Facial Action Units from Audio Channel | http://arxiv.org/abs/1706.07536 | id:1706.07536 author:Zibo Meng, Shizhong Han, Yan Tong category:cs.CV  published:2017-06-23 summary:Extensive efforts have been devoted to recognizing facial action units (AUs). However, it is still challenging to recognize AUs from spontaneous facial displays especially when they are accompanied with speech. Different from all prior work that utilized visual observations for facial AU recognition, this paper presents a novel approach that recognizes speech-related AUs exclusively from audio signals based on the fact that facial activities are highly correlated with voice during speech. Specifically, dynamic and physiological relationships between AUs and phonemes are modeled through a continuous time Bayesian network (CTBN); then AU recognition is performed by probabilistic inference via the CTBN model. A pilot audiovisual AU-coded database has been constructed to evaluate the proposed audio-based AU recognition framework. The database consists of a "clean" subset with frontal and neutral faces and a challenging subset collected with large head movements and occlusions. Experimental results on this database show that the proposed CTBN model achieves promising recognition performance for 7 speech-related AUs and outperforms the state-of-the-art visual-based methods especially for those AUs that are activated at low intensities or "hardly visible" in the visual channel. Furthermore, the CTBN model yields more impressive recognition performance on the challenging subset, where the visual-based approaches suffer significantly. version:2
arxiv-1709-06451 | 3D Reconstruction with Low Resolution, Small Baseline and High Radial Distortion Stereo Images | http://arxiv.org/abs/1709.06451 | id:1709.06451 author:Tiago Dias, Helder Araujo, Pedro Miraldo category:cs.CV  published:2017-09-19 summary:In this paper we analyze and compare approaches for 3D reconstruction from low-resolution (250x250), high radial distortion stereo images, which are acquired with small baseline (approximately 1mm). These images are acquired with the system NanEye Stereo manufactured by CMOSIS/AWAIBA. These stereo cameras have also small apertures, which means that high levels of illumination are required. The goal was to develop an approach yielding accurate reconstructions, with a low computational cost, i.e., avoiding non-linear numerical optimization algorithms. In particular we focused on the analysis and comparison of radial distortion models. To perform the analysis and comparison, we defined a baseline method based on available software and methods, such as the Bouguet toolbox [2] or the Computer Vision Toolbox from Matlab. The approaches tested were based on the use of the polynomial model of radial distortion, and on the application of the division model. The issue of the center of distortion was also addressed within the framework of the application of the division model. We concluded that the division model with a single radial distortion parameter has limitations. version:1
arxiv-1709-06447 | Human Activity Recognition Using Robust Adaptive Privileged Probabilistic Learning | http://arxiv.org/abs/1709.06447 | id:1709.06447 author:Michalis Vrigkas, Evangelos Kazakos, Christophoros Nikou, Ioannis A. Kakadiaris category:cs.CV  published:2017-09-19 summary:In this work, a novel method based on the learning using privileged information (LUPI) paradigm for recognizing complex human activities is proposed that handles missing information during testing. We present a supervised probabilistic approach that integrates LUPI into a hidden conditional random field (HCRF) model. The proposed model is called HCRF+ and may be trained using both maximum likelihood and maximum margin approaches. It employs a self-training technique for automatic estimation of the regularization parameters of the objective functions. Moreover, the method provides robustness to outliers (such as noise or missing data) by modeling the conditional distribution of the privileged information by a Student's \textit{t}-density function, which is naturally integrated into the HCRF+ framework. Different forms of privileged information were investigated. The proposed method was evaluated using four challenging publicly available datasets and the experimental results demonstrate its effectiveness with respect to the-state-of-the-art in the LUPI framework using both hand-crafted features and features extracted from a convolutional neural network. version:1
arxiv-1709-06444 | Scalable Support Vector Clustering Using Budget | http://arxiv.org/abs/1709.06444 | id:1709.06444 author:Tung Pham, Trung Le, Hang Dang category:cs.LG  published:2017-09-19 summary:Owing to its application in solving the difficult and diverse clustering or outlier detection problem, support-based clustering has recently drawn plenty of attention. Support-based clustering method always undergoes two phases: finding the domain of novelty and performing clustering assignment. To find the domain of novelty, the training time given by the current solvers is typically over-quadratic in the training size, and hence precluding the usage of support-based clustering method for large-scale datasets. In this paper, we propose applying Stochastic Gradient Descent (SGD) framework to the first phase of support-based clustering for finding the domain of novelty and a new strategy to perform the clustering assignment. However, the direct application of SGD to the first phase of support-based clustering is vulnerable to the curse of kernelization, that is, the model size linearly grows up with the data size accumulated overtime. To address this issue, we invoke the budget approach which allows us to restrict the model size to a small budget. Our new strategy for clustering assignment enables a fast computation by means of reducing the task of clustering assignment on the full training set to the same task on a significantly smaller set. We also provide a rigorous theoretical analysis about the convergence rate for the proposed method. Finally, we validate our proposed method on the well-known datasets for clustering to show that the proposed method offers a comparable clustering quality while simultaneously achieving significant speedup in comparison with the baselines. version:1
arxiv-1709-06438 | A Recorded Debating Dataset | http://arxiv.org/abs/1709.06438 | id:1709.06438 author:Shachar Mirkin, Michal Jacovi, Tamar Lavee, Hong-Kwang Kuo, Samuel Thomas, Leslie Sager, Lili Kotlerman, Elad Venezian, Noam Slonim category:cs.CL  published:2017-09-19 summary:This paper describes an audio and textual dataset of debating speeches, a first-of-a-kind resource for the growing research field of computational argumentation and debating technologies. We detail the process of speech recording by professional debaters, the transcription of the speeches with an Automatic Speech Recognition (ASR) system, their consequent automatic processing to produce a text that is more "NLP-friendly", and in parallel -- the manual transcription of the speeches in order to produce gold-standard "reference" transcripts. We release speeches on various controversial topics, each in 5 formats corresponding to the different stages in the production of the data. The intention is to allow utilizing this resource for multiple research purposes, be it the addition of in-domain training data for a debate-specific ASR system, or applying argumentation mining on either noisy or clean debate transcripts. We intend to make further releases of this data in the future. version:1
arxiv-1709-06437 | Automatic Leaf Extraction from Outdoor Images | http://arxiv.org/abs/1709.06437 | id:1709.06437 author:N. Anantrasirichai, Sion Hannuna, Nishan Canagarajah category:cs.CV  published:2017-09-19 summary:Automatic plant recognition and disease analysis may be streamlined by an image of a complete, isolated leaf as an initial input. Segmenting leaves from natural images is a hard problem. Cluttered and complex backgrounds: often composed of other leaves are commonplace. Furthermore, their appearance is highly dependent upon illumination and viewing perspective. In order to address these issues we propose a methodology which exploits the leaves venous systems in tandem with other low level features. Background and leaf markers are created using colour, intensity and texture. Two approaches are investigated: watershed and graph-cut and results compared. Primary-secondary vein detection and a protrusion-notch removal are applied to refine the extracted leaf. The efficacy of our approach is demonstrated against existing work. version:1
arxiv-1709-06436 | Language Modeling with Highway LSTM | http://arxiv.org/abs/1709.06436 | id:1709.06436 author:Gakuto Kurata, Bhuvana Ramabhadran, George Saon, Abhinav Sethy category:cs.CL  published:2017-09-19 summary:Language models (LMs) based on Long Short Term Memory (LSTM) have shown good gains in many automatic speech recognition tasks. In this paper, we extend an LSTM by adding highway networks inside an LSTM and use the resulting Highway LSTM (HW-LSTM) model for language modeling. The added highway networks increase the depth in the time dimension. Since a typical LSTM has two internal states, a memory cell and a hidden state, we compare various types of HW-LSTM by adding highway networks onto the memory cell and/or the hidden state. Experimental results on English broadcast news and conversational telephone speech recognition show that the proposed HW-LSTM LM improves speech recognition accuracy on top of a strong LSTM LM baseline. We report 5.1% and 9.9% on the Switchboard and CallHome subsets of the Hub5 2000 evaluation, which reaches the best performance numbers reported on these tasks to date. version:1
arxiv-1709-06429 | Neural Networks for Text Correction and Completion in Keyboard Decoding | http://arxiv.org/abs/1709.06429 | id:1709.06429 author:Shaona Ghosh, Per Ola Kristensson category:cs.CL cs.LG  published:2017-09-19 summary:Despite the ubiquity of mobile and wearable text messaging applications, the problem of keyboard text decoding is not tackled sufficiently in the light of the enormous success of the deep learning Recurrent Neural Network (RNN) and Convolutional Neural Networks (CNN) for natural language understanding. In particular, considering that the keyboard decoders should operate on devices with memory and processor resource constraints, makes it challenging to deploy industrial scale deep neural network (DNN) models. This paper proposes a sequence-to-sequence neural attention network system for automatic text correction and completion. Given an erroneous sequence, our model encodes character level hidden representations and then decodes the revised sequence thus enabling auto-correction and completion. We achieve this by a combination of character level CNN and gated recurrent unit (GRU) encoder along with and a word level gated recurrent unit (GRU) attention decoder. Unlike traditional language models that learn from billions of words, our corpus size is only 12 million words; an order of magnitude smaller. The memory footprint of our learnt model for inference and prediction is also an order of magnitude smaller than the conventional language model based text decoders. We report baseline performance for neural keyboard decoders in such limited domain. Our models achieve a word level accuracy of $90\%$ and a character error rate CER of $2.4\%$ over the Twitter typo dataset. We present a novel dataset of noisy to corrected mappings by inducing the noise distribution from the Twitter data over the OpenSubtitles 2009 dataset; on which our model predicts with a word level accuracy of $98\%$ and sequence accuracy of $68.9\%$. In our user study, our model achieved an average CER of $2.6\%$ with the state-of-the-art non-neural touch-screen keyboard decoder at CER of $1.6\%$. version:1
arxiv-1709-06391 | Human Action Forecasting by Learning Task Grammars | http://arxiv.org/abs/1709.06391 | id:1709.06391 author:Tengda Han, Jue Wang, Anoop Cherian, Stephen Gould category:cs.CV  published:2017-09-19 summary:For effective human-robot interaction, it is important that a robotic assistant can forecast the next action a human will consider in a given task. Unfortunately, real-world tasks are often very long, complex, and repetitive; as a result forecasting is not trivial. In this paper, we propose a novel deep recurrent architecture that takes as input features from a two-stream Residual action recognition framework, and learns to estimate the progress of human activities from video sequences -- this surrogate progress estimation task implicitly learns a temporal task grammar with respect to which activities can be localized and forecasted. To learn the task grammar, we propose a stacked LSTM based multi-granularity progress estimation framework that uses a novel cumulative Euclidean loss as objective. To demonstrate the effectiveness of our proposed architecture, we showcase experiments on two challenging robotic assistive tasks, namely (i) assembling an Ikea table from its constituents, and (ii) changing the tires of a car. Our results demonstrate that learning task grammars offers highly discriminative cues improving the forecasting accuracy by more than 9% over the baseline two-stream forecasting model, while also outperforming other competitive schemes. version:1
arxiv-1709-06390 | Analogical-based Bayesian Optimization | http://arxiv.org/abs/1709.06390 | id:1709.06390 author:Trung Le, Khanh Nguyen, Tu Dinh Nguyen, Dinh Phung category:cs.LG stat.ML  published:2017-09-19 summary:Some real-world problems revolve to solve the optimization problem \max_{x\in\mathcal{X}}f\left(x\right) where f\left(.\right) is a black-box function and X might be the set of non-vectorial objects (e.g., distributions) where we can only define a symmetric and non-negative similarity score on it. This setting requires a novel view for the standard framework of Bayesian Optimization that generalizes the core insightful spirit of this framework. With this spirit, in this paper, we propose Analogical-based Bayesian Optimization that can maximize black-box function over a domain where only a similarity score can be defined. Our pathway is as follows: we first base on the geometric view of Gaussian Processes (GP) to define the concept of influence level that allows us to analytically represent predictive means and variances of GP posteriors and base on that view to enable replacing kernel similarity by a more genetic similarity score. Furthermore, we also propose two strategies to find a batch of query points that can efficiently handle high dimensional data. version:1
arxiv-1709-06389 | A General Framework for the Recognition of Online Handwritten Graphics | http://arxiv.org/abs/1709.06389 | id:1709.06389 author:Frank Julca-Aguilar, Harold Mouchère, Christian Viard-Gaudin, Nina S. T. Hirata category:cs.CV  published:2017-09-19 summary:We propose a new framework for the recognition of online handwritten graphics. Three main features of the framework are its ability to treat symbol and structural level information in an integrated way, its flexibility with respect to different families of graphics, and means to control the tradeoff between recognition effectiveness and computational cost. We model a graphic as a labeled graph generated from a graph grammar. Non-terminal vertices represent subcomponents, terminal vertices represent symbols, and edges represent relations between subcomponents or symbols. We then model the recognition problem as a graph parsing problem: given an input stroke set, we search for a parse tree that represents the best interpretation of the input. Our graph parsing algorithm generates multiple interpretations (consistent with the grammar) and then we extract an optimal interpretation according to a cost function that takes into consideration the likelihood scores of symbols and structures. The parsing algorithm consists in recursively partitioning the stroke set according to structures defined in the grammar and it does not impose constraints present in some previous works (e.g. stroke ordering). By avoiding such constraints and thanks to the powerful representativeness of graphs, our approach can be adapted to the recognition of different graphic notations. We show applications to the recognition of mathematical expressions and flowcharts. Experimentation shows that our method obtains state-of-the-art accuracy in both applications. version:1
arxiv-1709-06366 | An Adaptive Algorithm for Precise Pupil Boundary Detection using Entropy of Contour Gradients | http://arxiv.org/abs/1709.06366 | id:1709.06366 author:Cihan Topal, Halil Ibrahim Cakir, Cuneyt Akinlar category:cs.CV  published:2017-09-19 summary:Eye tracking spreads through a vast area of applications from ophthalmology, assistive technologies to gaming and virtual reality. Detection of pupil is the most critical step in many of these tasks hence needs to be performed accurately. Although detection of pupil is a smooth task in clear sight, possible occlusions and odd viewpoints complicate the problem. We present an adaptive pupil boundary detection method that is able to infer whether entire pupil is in clearly visible by a modal heuristic. Thus, a faster detection is performed with the assumption of no occlusions. If the heuristic fails, a deeper search among extracted image features is executed to maintain accuracy. Furthermore, the algorithm can find out if there is no pupil as an aidful information for many applications. We prepare a dataset containing 1509 high resolution eye images collected from five subjects and perform an extensive set of experiments to obtain quantitative results in terms of accuracy, localization and timing. The proposed method outperforms three other state of the art algorithms and can run up to 140 Hz in single-thread on a standard laptop computer. version:1
arxiv-1709-06365 | MetaLDA: a Topic Model that Efficiently Incorporates Meta information | http://arxiv.org/abs/1709.06365 | id:1709.06365 author:He Zhao, Lan Du, Wray Buntine, Gang Liu category:cs.CL stat.AP  published:2017-09-19 summary:Besides the text content, documents and their associated words usually come with rich sets of meta informa- tion, such as categories of documents and semantic/syntactic features of words, like those encoded in word embeddings. Incorporating such meta information directly into the generative process of topic models can improve modelling accuracy and topic quality, especially in the case where the word-occurrence information in the training data is insufficient. In this paper, we present a topic model, called MetaLDA, which is able to leverage either document or word meta information, or both of them jointly. With two data argumentation techniques, we can derive an efficient Gibbs sampling algorithm, which benefits from the fully local conjugacy of the model. Moreover, the algorithm is favoured by the sparsity of the meta information. Extensive experiments on several real world datasets demonstrate that our model achieves comparable or improved performance in terms of both perplexity and topic quality, particularly in handling sparse texts. In addition, compared with other models using meta information, our model runs significantly faster. version:1
arxiv-1709-06328 | Fitting Generalized Essential Matrices from Generic 6x6 Matrices and its Applications | http://arxiv.org/abs/1709.06328 | id:1709.06328 author:João R. Cardoso, Pedro Miraldo category:cs.CV  published:2017-09-19 summary:This paper addresses the problem of finding the closest generalized essential matrix from a given 6x6 matrix, with respect to the Frobenius norm. To the best of our knowledge, this nonlinear constrained optimization problem has not been addressed in the literature yet. Although it can be solved directly, it involves a large amount of 33 constraints, and any optimization method to solve it will require much computational time. Then, we start by converting the original problem into a new one, involving only orthogonal constraints, and propose an efficient algorithm of steepest descent-type to find the goal solution. To test the algorithm, we evaluate with both synthetic and real data. From the results with synthetic data, we conclude that the proposed method is much faster than applying general optimization techniques to the original problem with 33 constraints. To conclude and to further motivate the relevance of our method, we develop an efficient and robust algorithm for estimation of the general relative pose problem, which will be compared with the state-of-the-art techniques. It is shown, in particular, that some existing approaches to solving the relative pose estimation problem can be considerably improved, if combined with our method for estimating the closest generalized essential matrix. Real data to validate the algorithm is used as well. version:1
arxiv-1709-06320 | Nonnegative matrix factorization with side information for time series recovery and prediction | http://arxiv.org/abs/1709.06320 | id:1709.06320 author:Jiali Mei, Yohann De Castro, Yannig Goude, Jean-Marc Azaïs, Georges Hébrail category:stat.ML stat.AP  published:2017-09-19 summary:Motivated by the reconstruction and the prediction of electricity consumption, we extend Nonnegative Matrix Factorization~(NMF) to take into account side information (column or row features). We consider general linear measurement settings, and propose a framework which models non-linear relationships between features and the response variables. We extend previous theoretical results to obtain a sufficient condition on the identifiability of the NMF in this setting. Based the classical Hierarchical Alternating Least Squares~(HALS) algorithm, we propose a new algorithm (HALSX, or Hierarchical Alternating Least Squares with eXogeneous variables) which estimates the factorization model. The algorithm is validated on both simulated and real electricity consumption datasets as well as a recommendation dataset, to show its performance in matrix recovery and prediction for new rows and columns. version:1
arxiv-1709-06317 | Improving Opinion-Target Extraction with Character-Level Word Embeddings | http://arxiv.org/abs/1709.06317 | id:1709.06317 author:Soufian Jebbara, Philipp Cimiano category:cs.CL  published:2017-09-19 summary:Fine-grained sentiment analysis is receiving increasing attention in recent years. Extracting opinion target expressions (OTE) in reviews is often an important step in fine-grained, aspect-based sentiment analysis. Retrieving this information from user-generated text, however, can be difficult. Customer reviews, for instance, are prone to contain misspelled words and are difficult to process due to their domain-specific language. In this work, we investigate whether character-level models can improve the performance for the identification of opinion target expressions. We integrate information about the character structure of a word into a sequence labeling system using character-level word embeddings and show their positive impact on the system's performance. Specifically, we obtain an increase by 3.3 points F1-score with respect to our baseline model. In further experiments, we reveal encoded character patterns of the learned embeddings and give a nuanced view of the performance differences of both models. version:1
arxiv-1709-06311 | Aspect-Based Sentiment Analysis Using a Two-Step Neural Network Architecture | http://arxiv.org/abs/1709.06311 | id:1709.06311 author:Soufian Jebbara, Philipp Cimiano category:cs.CL  published:2017-09-19 summary:The World Wide Web holds a wealth of information in the form of unstructured texts such as customer reviews for products, events and more. By extracting and analyzing the expressed opinions in customer reviews in a fine-grained way, valuable opportunities and insights for customers and businesses can be gained. We propose a neural network based system to address the task of Aspect-Based Sentiment Analysis to compete in Task 2 of the ESWC-2016 Challenge on Semantic Sentiment Analysis. Our proposed architecture divides the task in two subtasks: aspect term extraction and aspect-specific sentiment extraction. This approach is flexible in that it allows to address each subtask independently. As a first step, a recurrent neural network is used to extract aspects from a text by framing the problem as a sequence labeling task. In a second step, a recurrent network processes each extracted aspect with respect to its context and predicts a sentiment label. The system uses pretrained semantic word embedding features which we experimentally enhance with semantic knowledge extracted from WordNet. Further features extracted from SenticNet prove to be beneficial for the extraction of sentiment labels. As the best performing system in its category, our proposed system proves to be an effective approach for the Aspect-Based Sentiment Analysis. version:1
arxiv-1709-06309 | Aspect-Based Relational Sentiment Analysis Using a Stacked Neural Network Architecture | http://arxiv.org/abs/1709.06309 | id:1709.06309 author:Soufian Jebbara, Philipp Cimiano category:cs.CL  published:2017-09-19 summary:Sentiment analysis can be regarded as a relation extraction problem in which the sentiment of some opinion holder towards a certain aspect of a product, theme or event needs to be extracted. We present a novel neural architecture for sentiment analysis as a relation extraction problem that addresses this problem by dividing it into three subtasks: i) identification of aspect and opinion terms, ii) labeling of opinion terms with a sentiment, and iii) extraction of relations between opinion terms and aspect terms. For each subtask, we propose a neural network based component and combine all of them into a complete system for relational sentiment analysis. The component for aspect and opinion term extraction is a hybrid architecture consisting of a recurrent neural network stacked on top of a convolutional neural network. This approach outperforms a standard convolutional deep neural architecture as well as a recurrent network architecture and performs competitively compared to other methods on two datasets of annotated customer reviews. To extract sentiments for individual opinion terms, we propose a recurrent architecture in combination with word distance features and achieve promising results, outperforming a majority baseline by 18% accuracy and providing the first results for the USAGE dataset. Our relation extraction component outperforms the current state-of-the-art in aspect-opinion relation extraction by 15% F-Measure. version:1
arxiv-1709-06308 | Exploring Human-like Attention Supervision in Visual Question Answering | http://arxiv.org/abs/1709.06308 | id:1709.06308 author:Tingting Qiao, Jianfeng Dong, Duanqing Xu category:cs.CV  published:2017-09-19 summary:Attention mechanisms have been widely applied in the Visual Question Answering (VQA) task, as they help to focus on the area-of-interest of both visual and textual information. To answer the questions correctly, the model needs to selectively target different areas of an image, which suggests that an attention-based model may benefit from an explicit attention supervision. In this work, we aim to address the problem of adding attention supervision to VQA models. Since there is a lack of human attention data, we first propose a Human Attention Network (HAN) to generate human-like attention maps, training on a recently released dataset called Human ATtention Dataset (VQA-HAT). Then, we apply the pre-trained HAN on the VQA v2.0 dataset to automatically produce the human-like attention maps for all image-question pairs. The generated human-like attention map dataset for the VQA v2.0 dataset is named as Human-Like ATtention (HLAT) dataset. Finally, we apply human-like attention supervision to an attention-based VQA model. The experiments show that adding human-like supervision yields a more accurate attention together with a better performance, showing a promising future for human-like attention supervision in VQA. version:1
arxiv-1709-06307 | A Fast and Accurate Vietnamese Word Segmenter | http://arxiv.org/abs/1709.06307 | id:1709.06307 author:Dat Quoc Nguyen, Dai Quoc Nguyen, Thanh Vu, Mark Dras, Mark Johnson category:cs.CL  published:2017-09-19 summary:We propose a novel rule-based approach to Vietnamese word segmentation. Our approach is based on the Single Classification Ripple Down Rules methodology (Compton and Jansen, 1990), where rules are stored in an exception structure and new rules are only added to correct segmentation errors given by existing rules. Experimental results on the benchmark Vietnamese treebank show that our approach outperforms previous state-of-the-art approaches JVnSegmenter, vnTokenizer, DongDu and UETsegmenter in terms of both accuracy and performance speed. Our code is open-source and available at: https://github.com/datquocnguyen/RDRsegmenter version:1
arxiv-1709-06304 | Scalable Estimation of Dirichlet Process Mixture Models on Distributed Data | http://arxiv.org/abs/1709.06304 | id:1709.06304 author:Ruohui Wang, Dahua Lin category:stat.ML cs.LG  published:2017-09-19 summary:We consider the estimation of Dirichlet Process Mixture Models (DPMMs) in distributed environments, where data are distributed across multiple computing nodes. A key advantage of Bayesian nonparametric models such as DPMMs is that they allow new components to be introduced on the fly as needed. This, however, posts an important challenge to distributed estimation -- how to handle new components efficiently and consistently. To tackle this problem, we propose a new estimation method, which allows new components to be created locally in individual computing nodes. Components corresponding to the same cluster will be identified and merged via a probabilistic consolidation scheme. In this way, we can maintain the consistency of estimation with very low communication cost. Experiments on large real-world data sets show that the proposed method can achieve high scalability in distributed and asynchronous environments without compromising the mixing performance. version:1
arxiv-1709-06300 | Colour Terms: a Categorisation Model Inspired by Visual Cortex Neurons | http://arxiv.org/abs/1709.06300 | id:1709.06300 author:Arash Akbarinia, C. Alejandro Parraga category:cs.CV  published:2017-09-19 summary:Although it seems counter-intuitive, categorical colours do not exist as external physical entities but are very much the product of our brains. Our cortical machinery segments the world and associate objects to specific colour terms, which is not only convenient for communication but also increases the efficiency of visual processing by reducing the dimensionality of input scenes. Although the neural substrate for this phenomenon is unknown, a recent study of cortical colour processing has discovered a set of neurons that are isoresponsive to stimuli in the shape of 3D-ellipsoidal surfaces in colour-opponent space. We hypothesise that these neurons might help explain the underlying mechanisms of colour naming in the visual cortex. Following this, we propose a biologically-inspired colour naming model where each colour term - e.g. red, green, blue, yellow, etc. - is represented through an ellipsoid in 3D colour-opponent space. This paradigm is also supported by previous psychophysical colour categorisation experiments whose results resemble such shapes. "Belongingness" of each pixel to different colour categories is computed by a non-linear sigmoidal logistic function. The final colour term for a given pixel is calculated by a maximum pooling mechanism. The simplicity of our model allows its parameters to be learnt from a handful of segmented images. It also offers a straightforward extension to include further colour terms. Additionally, ellipsoids of proposed model can adapt to image contents offering a dynamical solution in order to address phenomenon of colour constancy. Our results on the Munsell chart and two datasets of real-world images show an overall improvement comparing to state-of-the-art algorithms. version:1
arxiv-1707-00652 | DeepIGeoS: A Deep Interactive Geodesic Framework for Medical Image Segmentation | http://arxiv.org/abs/1707.00652 | id:1707.00652 author:Guotai Wang, Maria A. Zuluaga, Wenqi Li, Rosalind Pratt, Premal A. Patel, Michael Aertsen, Tom Doel, Anna L. David, Jan Deprest, Sebastien Ourselin, Tom Vercauteren category:cs.CV  published:2017-07-03 summary:Accurate medical image segmentation is essential for diagnosis, surgical planning and many other applications. Convolutional Neural Networks (CNNs) have become the state-of-the-art automatic segmentation methods. However, fully automatic results may still need to be refined to become accurate and robust enough for clinical use. We propose a deep learning-based interactive segmentation method to improve the results obtained by an automatic CNN and to reduce user interactions during refinement for higher accuracy. We use one CNN to obtain an initial automatic segmentation, on which user interactions are added to indicate mis-segmentations. Another CNN takes as input the user interactions with the initial segmentation and gives a refined result. We propose to combine user interactions with CNNs through geodesic distance transforms, and propose a resolution-preserving network that gives a better dense prediction. In addition, we integrate user interactions as hard constraints into a back-propagatable Conditional Random Field. We validated the proposed framework in the context of 2D placenta segmentation from fetal MRI and 3D brain tumor segmentation from FLAIR images. Experimental results show our method achieves a large improvement from automatic CNNs, and obtains comparable and even higher accuracy with fewer user interventions and less time compared with traditional interactive methods. version:3
arxiv-1709-06560 | Deep Reinforcement Learning that Matters | http://arxiv.org/abs/1709.06560 | id:1709.06560 author:Peter Henderson, Riashat Islam, Philip Bachman, Joelle Pineau, Doina Precup, David Meger category:cs.LG stat.ML  published:2017-09-19 summary:In recent years, significant progress has been made in solving challenging problems across various domains using deep reinforcement learning (RL). Reproducing existing work and accurately judging the improvements offered by novel methods is vital to maintaining this rapid progress. Unfortunately, reproducing results for state-of-the-art deep RL methods is seldom straightforward. In particular, non-determinism in standard benchmark environments, combined with variance intrinsic to the methods, can make reported results difficult to interpret. Without significance metrics and tighter standardization of experimental reporting, it is difficult to determine whether improvements over the prior state-of-the-art are meaningful. In this paper, we investigate challenges posed by reproducibility, proper experimental techniques, and reporting procedures. We illustrate the variability in reported metrics and results when comparing against common baselines, and suggest guidelines to make future results in deep RL more reproducible. We aim to spur discussion about how to ensure continued progress in the field, by minimizing wasted effort stemming from results that are non-reproducible and easily misinterpreted. version:1
arxiv-1709-05631 | Unwritten Languages Demand Attention Too! Word Discovery with Encoder-Decoder Models | http://arxiv.org/abs/1709.05631 | id:1709.05631 author:Marcely Zanon Boito, Alexandre Berard, Aline Villavicencio, Laurent Besacier category:cs.CL  published:2017-09-17 summary:Word discovery is the task of extracting words from unsegmented text. In this paper we examine to what extent neural networks can be applied to this task in a realistic unwritten language scenario, where only small corpora and limited annotations are available. We investigate two scenarios: one with no supervision and another with limited supervision with access to the most frequent words. Obtained results show that it is possible to retrieve at least 27% of the gold standard vocabulary by training an encoder-decoder neural machine translation system with only 5,157 sentences. This result is close to those obtained with a task-specific Bayesian nonparametric model. Moreover, our approach has the advantage of generating translation alignments, which could be used to create a bilingual lexicon. As a future perspective, this approach is also well suited to work directly from speech. version:2
arxiv-1709-06257 | Deep-Learnt Classification of Light Curves | http://arxiv.org/abs/1709.06257 | id:1709.06257 author:Ashish Mahabal, Kshiteej Sheth, Fabian Gieseke, Akshay Pai, S. George Djorgovski, Andrew Drake, Matthew Graham, the CSS/CRTS/PTF Collaboration category:astro-ph.IM cs.CV  published:2017-09-19 summary:Astronomy light curves are sparse, gappy, and heteroscedastic. As a result standard time series methods regularly used for financial and similar datasets are of little help and astronomers are usually left to their own instruments and techniques to classify light curves. A common approach is to derive statistical features from the time series and to use machine learning methods, generally supervised, to separate objects into a few of the standard classes. In this work, we transform the time series to two-dimensional light curve representations in order to classify them using modern deep learning techniques. In particular, we show that convolutional neural networks based classifiers work well for broad characterization and classification. We use labeled datasets of periodic variables from CRTS survey and show how this opens doors for a quick classification of diverse classes with several possible exciting extensions. version:1
arxiv-1709-06255 | Finite Sample Guarantees for PCA in Non-Isotropic and Data-Dependent Noise | http://arxiv.org/abs/1709.06255 | id:1709.06255 author:Namrata Vaswani, Praneeth Narayanamurthy category:stat.ML cs.IT math.IT  published:2017-09-19 summary:This work obtains novel finite sample guarantees for Principal Component Analysis (PCA). These hold even when the corrupting noise is non-isotropic, and a part (or all of it) is data-dependent. Because of the latter, in general, the noise and the true data are correlated. The results in this work are a significant improvement over those given in our earlier work where this "correlated-PCA" problem was first studied. In fact, in certain regimes, our results imply that the sample complexity required to achieve subspace recovery error that is a constant fraction of the noise level is near-optimal. Useful corollaries of our result include guarantees for PCA in sparse data-dependent noise and for PCA with missing data. An important application of the former is in proving correctness of the subspace update step of a popular online algorithm for dynamic robust PCA. version:1
arxiv-1709-06248 | Look Wider to Match Image Patches with Convolutional Neural Networks | http://arxiv.org/abs/1709.06248 | id:1709.06248 author:Haesol Park, Kyoung Mu Lee category:cs.CV  published:2017-09-19 summary:When a human matches two images, the viewer has a natural tendency to view the wide area around the target pixel to obtain clues of right correspondence. However, designing a matching cost function that works on a large window in the same way is difficult. The cost function is typically not intelligent enough to discard the information irrelevant to the target pixel, resulting in undesirable artifacts. In this paper, we propose a novel learn a stereo matching cost with a large-sized window. Unlike conventional pooling layers with strides, the proposed per-pixel pyramid-pooling layer can cover a large area without a loss of resolution and detail. Therefore, the learned matching cost function can successfully utilize the information from a large area without introducing the fattening effect. The proposed method is robust despite the presence of weak textures, depth discontinuity, illumination, and exposure difference. The proposed method achieves near-peak performance on the Middlebury benchmark. version:1
arxiv-1709-06247 | Training Better CNNs Requires to Rethink ReLU | http://arxiv.org/abs/1709.06247 | id:1709.06247 author:Gangming Zhao, Zhaoxiang Zhang, Jingdong Wang, He Guan category:cs.CV  published:2017-09-19 summary:With the rapid development of Deep Convolutional Neural Networks (DCNNs), numerous works focus on designing better network architectures (i.e., AlexNet, VGG, Inception, ResNet and DenseNet etc.). Nevertheless, all these networks have the same characteristic: each convolutional layer is followed by an activation layer, a Rectified Linear Unit (ReLU) layer is the most used among them. In this work, we argue that the paired module with 1:1 convolution and ReLU ratio is not the best choice since it may result in poor generalization ability. Thus, we try to investigate the more suitable convolution and ReLU ratio for exploring the better network architectures. Specifically, inspired by Leaky ReLU, we focus on adopting the proportional module with N:M (N$>$M) convolution and ReLU ratio to design the better networks. From the perspective of ensemble learning, Leaky ReLU can be considered as an ensemble of networks with different convolution and ReLU ratio. We find that the proportional module with N:M (N$>$M) convolution and ReLU ratio can help networks acquire the better performance, through the analysis of a simple Leaky ReLU model. By utilizing the proportional module with N:M (N$>$M) convolution and ReLU ratio, many popular networks can form more rich representations in models, since the N:M (N$>$M) proportional module can utilize information more effectively. Furthermore, we apply this module in diverse DCNN models to explore whether is the N:M (N$>$M) convolution and ReLU ratio indeed more effective. From our experimental results, we can find that such a simple yet effective method achieves better performance in different benchmarks with various network architectures and the experimental results verify that the superiority of the proportional module. version:1
arxiv-1709-06229 | CISRDCNN: Super-resolution of compressed images using deep convolutional neural networks | http://arxiv.org/abs/1709.06229 | id:1709.06229 author:Honggang Chen, Xiaohai He, Chao Ren, Linbo Qing, Qizhi Teng category:cs.CV  published:2017-09-19 summary:In recent years, much research has been conducted on image super-resolution (SR). To the best of our knowledge, however, few SR methods were concerned with compressed images. The SR of compressed images is a challenging task due to the complicated compression artifacts, while many images suffer from them in practice. The intuitive solution for this difficult task is to decouple it into two sequential but independent subproblems, i.e., compression artifacts reduction (CAR) and SR. Nevertheless, some useful details may be removed in CAR stage, which is contrary to the goal of SR and makes the SR stage more challenging. In this paper, an end-to-end trainable deep convolutional neural network is designed to perform SR on compressed images (CISRDCNN), which reduces compression artifacts and improves image resolution jointly. Experiments on compressed images produced by JPEG (we take the JPEG as an example in this paper) demonstrate that the proposed CISRDCNN yields state-of-the-art SR performance on commonly used test images and imagesets. The results of CISRDCNN on real low quality web images are also very impressive, with obvious quality enhancement. Further, we explore the application of the proposed SR method in low bit-rate image coding, leading to better rate-distortion performance than JPEG. version:1
arxiv-1710-01218 | Reducing Complexity of HEVC: A Deep Learning Approach | http://arxiv.org/abs/1710.01218 | id:1710.01218 author:Mai Xu, Tianyi Li, Zulin Wang, Xin Deng, Zhenyu Guan category:cs.CV  published:2017-09-19 summary:High Efficiency Video Coding (HEVC) significantly reduces bit-rates over the proceeding H.264 standard but at the expense of extremely high encoding complexity. In HEVC, the quad-tree partition of coding unit (CU) consumes a large proportion of the HEVC encoding complexity, due to the bruteforce search for rate-distortion optimization (RDO). Therefore, this paper proposes a deep learning approach to predict the CU partition for reducing the HEVC complexity at both intraand inter-modes, which is based on convolutional neural network (CNN) and long- and short-term memory (LSTM) network. First, we establish a large-scale database including substantial CU partition data for HEVC intra- and inter-modes. This enables deep learning on the CU partition. Second, we represent the CU partition of an entire coding tree unit (CTU) in the form of a hierarchical CU partition map (HCPM). Then, we propose an early-terminated hierarchical CNN (ETH-CNN) for learning to predict the HCPM. Consequently, the encoding complexity of intra-mode HEVC can be drastically reduced by replacing the brute-force search with ETH-CNN to decide the CU partition. Third, an early-terminated hierarchical LSTM (ETH-LSTM) is proposed to learn the temporal correlation of the CU partition. Then, we combine ETH-LSTM and ETH-CNN to predict the CU partition for reducing the HEVC complexity for intermode. Finally, experimental results show that our approach outperforms other state-of-the-art approaches in reducing the HEVC complexity at both intra- and inter-modes. version:1
arxiv-1709-06212 | Estimating Mutual Information for Discrete-Continuous Mixtures | http://arxiv.org/abs/1709.06212 | id:1709.06212 author:Weihao Gao, Sreeram Kannan, Sewoong Oh, Pramod Viswanath category:cs.IT cs.LG math.IT  published:2017-09-19 summary:Estimating mutual information from observed samples is a basic primitive, useful in several machine learning tasks including correlation mining, information bottleneck clustering, learning a Chow-Liu tree, and conditional independence testing in (causal) graphical models. While mutual information is a well-defined quantity in general probability spaces, existing estimators can only handle two special cases of purely discrete or purely continuous pairs of random variables. The main challenge is that these methods first estimate the (differential) entropies of X, Y and the pair (X;Y) and add them up with appropriate signs to get an estimate of the mutual information. These 3H-estimators cannot be applied in general mixture spaces, where entropy is not well-defined. In this paper, we design a novel estimator for mutual information of discrete-continuous mixtures. We prove that the proposed estimator is consistent. We provide numerical experiments suggesting superiority of the proposed estimator compared to other heuristics of adding small continuous noise to all the samples and applying standard estimators tailored for purely continuous variables, and quantizing the samples and applying standard estimators tailored for purely discrete variables. This significantly widens the applicability of mutual information estimation in real-world applications, where some variables are discrete, some continuous, and others are a mixture between continuous and discrete components. version:1
arxiv-1709-06206 | Algorithm and Hardware Design of Discrete-Time Spiking Neural Networks Based on Back Propagation with Binary Activations | http://arxiv.org/abs/1709.06206 | id:1709.06206 author:Shihui Yin, Shreyas K. Venkataramanaiah, Gregory K. Chen, Ram Krishnamurthy, Yu Cao, Chaitali Chakrabarti, Jae-sun Seo category:cs.NE  published:2017-09-19 summary:We present a new back propagation based training algorithm for discrete-time spiking neural networks (SNN). Inspired by recent deep learning algorithms on binarized neural networks, binary activation with a straight-through gradient estimator is used to model the leaky integrate-fire spiking neuron, overcoming the difficulty in training SNNs using back propagation. Two SNN training algorithms are proposed: (1) SNN with discontinuous integration, which is suitable for rate-coded input spikes, and (2) SNN with continuous integration, which is more general and can handle input spikes with temporal information. Neuromorphic hardware designed in 40nm CMOS exploits the spike sparsity and demonstrates high classification accuracy (>98% on MNIST) and low energy (48.4-773 nJ/image). version:1
arxiv-1709-06204 | Protest Activity Detection and Perceived Violence Estimation from Social Media Images | http://arxiv.org/abs/1709.06204 | id:1709.06204 author:Donghyeon Won, Zachary C. Steinert-Threlkeld, Jungseock Joo category:cs.MM cs.CV cs.SI  published:2017-09-18 summary:We develop a novel visual model which can recognize protesters, describe their activities by visual attributes and estimate the level of perceived violence in an image. Studies of social media and protests use natural language processing to track how individuals use hashtags and links, often with a focus on those items' diffusion. These approaches, however, may not be effective in fully characterizing actual real-world protests (e.g., violent or peaceful) or estimating the demographics of participants (e.g., age, gender, and race) and their emotions. Our system characterizes protests along these dimensions. We have collected geotagged tweets and their images from 2013-2017 and analyzed multiple major protest events in that period. A multi-task convolutional neural network is employed in order to automatically classify the presence of protesters in an image and predict its visual attributes, perceived violence and exhibited emotions. We also release the UCLA Protest Image Dataset, our novel dataset of 40,764 images (11,659 protest images and hard negatives) with various annotations of visual attributes and sentiments. Using this dataset, we train our model and demonstrate its effectiveness. We also present experimental results from various analysis on geotagged image data in several prevalent protest events. Our dataset will be made accessible at https://www.sscnet.ucla.edu/comm/jjoo/mm-protest/. version:1
arxiv-1709-06557 | A Summary Of The Kernel Matrix, And How To Learn It Effectively Using Semidefinite Programming | http://arxiv.org/abs/1709.06557 | id:1709.06557 author:Amir-Hossein Karimi category:stat.ML  published:2017-09-18 summary:Kernel-based learning algorithms are widely used in machine learning for problems that make use of the similarity between object pairs. Such algorithms first embed all data points into an alternative space, where the inner product between object pairs specifies their distance in the embedding space. Applying kernel methods to partially labeled datasets is a classical challenge in this regard, requiring that the distances between unlabeled pairs must somehow be learnt using the labeled data. In this independent study, I will summarize the work of G. Lanckriet et al.'s work on "Learning the Kernel Matrix with Semidefinite Programming" used in support vector machines (SVM) algorithms for the transduction problem. Throughout the report, I have provide alternative explanations / derivations / analysis related to this work which is designed to ease the understanding of the original article. version:1
arxiv-1709-07745 | Measurement of amplitude of the moiré patterns in digital autostereoscopic 3D display | http://arxiv.org/abs/1709.07745 | id:1709.07745 author:Vladimir Saveljev, Sung-Kyu Kim category:eess.IV cs.CV  published:2017-09-18 summary:The article presents the experimental measurements of the amplitude of the moir\'e patterns in a digital autostereoscopic barrier-type 3D display across a wide angular range with a small increment. The period and orientation of the moir\'e patterns were also measured as functions of the angle. Simultaneous branches are observed and analyzed. The theoretical interpretation is also given. The results can help preventing or minimizing the moir\'e effect in displays. version:1
arxiv-1709-06183 | Bias Correction with Jackknife, Bootstrap, and Taylor Series | http://arxiv.org/abs/1709.06183 | id:1709.06183 author:Jiantao Jiao, Yanjun Han, Tsachy Weissman category:math.ST cs.IT cs.LG math.IT stat.TH  published:2017-09-18 summary:We analyze the bias correction methods using jackknife, bootstrap, and Taylor series. We focus on the binomial model, and consider the problem of bias correction for estimating $f(p)$, where $f \in C[0,1]$ is arbitrary. We characterize the supremum norm of the bias of general jackknife and bootstrap estimators for any continuous functions, and demonstrate the in delete-$d$ jackknife, different values of $d$ may lead to drastically different behavior in jackknife. We show that in the binomial model, iterating the bootstrap bias correction infinitely many times may lead to divergence of bias and variance, and demonstrate that the bias properties of the bootstrap bias corrected estimator after $r-1$ rounds is exactly the same as that of the $r$-jackknife estimator if a bounded coefficients condition is satisfied. version:1
arxiv-1709-06182 | A Survey of Machine Learning for Big Code and Naturalness | http://arxiv.org/abs/1709.06182 | id:1709.06182 author:Miltiadis Allamanis, Earl T. Barr, Premkumar Devanbu, Charles Sutton category:cs.SE cs.LG cs.PL  published:2017-09-18 summary:Research at the intersection of machine learning, programming languages, and software engineering has recently taken important steps in proposing learnable probabilistic models of source code that exploit code's abundance of patterns. In this article, we survey this work. We contrast programming languages against natural languages and discuss how these similarities and differences drive the design of probabilistic models. We present a taxonomy based on the underlying design principles of each model and use it to navigate the literature. Then, we review how researchers have adapted these models to application areas and discuss cross-cutting and application-specific challenges and opportunities. version:1
arxiv-1709-06171 | Learning Low-Dimensional Metrics | http://arxiv.org/abs/1709.06171 | id:1709.06171 author:Lalit Jain, Blake Mason, Robert Nowak category:stat.ML  published:2017-09-18 summary:This paper investigates the theoretical foundations of metric learning, focused on three key questions that are not fully addressed in prior work: 1) we consider learning general low-dimensional (low-rank) metrics as well as sparse metrics; 2) we develop upper and lower (minimax)bounds on the generalization error; 3) we quantify the sample complexity of metric learning in terms of the dimension of the feature space and the dimension/rank of the underlying metric;4) we also bound the accuracy of the learned metric relative to the underlying true generative metric. All the results involve novel mathematical approaches to the metric learning problem, and lso shed new light on the special case of ordinal embedding (aka non-metric multidimensional scaling). version:1
arxiv-1709-00668 | SamBaTen: Sampling-based Batch Incremental Tensor Decomposition | http://arxiv.org/abs/1709.00668 | id:1709.00668 author:Ekta Gujral, Ravdeep Pasricha, Evangelos E. Papalexakis category:stat.ML cs.LG  published:2017-09-03 summary:Tensor decompositions are invaluable tools in analyzing multimodal datasets. In many real-world scenarios, such datasets are far from being static, to the contrary they tend to grow over time. For instance, in an online social network setting, as we observe new interactions over time, our dataset gets updated in its "time" mode. How can we maintain a valid and accurate tensor decomposition of such a dynamically evolving multimodal dataset, without having to re-compute the entire decomposition after every single update? In this paper we introduce SaMbaTen, a Sampling-based Batch Incremental Tensor Decomposition algorithm, which incrementally maintains the decomposition given new updates to the tensor dataset. SaMbaTen is able to scale to datasets that the state-of-the-art in incremental tensor decomposition is unable to operate on, due to its ability to effectively summarize the existing tensor and the incoming updates, and perform all computations in the reduced summary space. We extensively evaluate SaMbaTen using synthetic and real datasets. Indicatively, SaMbaTen achieves comparable accuracy to state-of-the-art incremental and non-incremental techniques, while being 25-30 times faster. Furthermore, SaMbaTen scales to very large sparse and dense dynamically evolving tensors of dimensions up to 100K x 100K x 100K where state-of-the-art incremental approaches were not able to operate. version:2
arxiv-1709-06162 | Paraphrasing verbal metonymy through computational methods | http://arxiv.org/abs/1709.06162 | id:1709.06162 author:Alberto Morón Hernández category:cs.CL 68T50 H.3.1; I.2.7  published:2017-09-18 summary:Verbal metonymy has received relatively scarce attention in the field of computational linguistics despite the fact that a model to accurately paraphrase metonymy has applications both in academia and the technology sector. The method described in this paper makes use of data from the British National Corpus in order to create word vectors, find instances of verbal metonymy and generate potential paraphrases. Two different ways of creating word vectors are evaluated in this study: Continuous bag of words and Skip-grams. Skip-grams are found to outperform the Continuous bag of words approach. Furthermore, the Skip-gram model is found to operate with better-than-chance accuracy and there is a strong positive relationship (phi coefficient = 0.61) between the model's classification and human judgement of the ranked paraphrases. This study lends credence to the viability of modelling verbal metonymy through computational methods based on distributional semantics. version:1
arxiv-1709-06161 | PrivyNet: A Flexible Framework for Privacy-Preserving Deep Neural Network Training with A Fine-Grained Privacy Control | http://arxiv.org/abs/1709.06161 | id:1709.06161 author:Meng Li, Liangzhen Lai, Naveen Suda, Vikas Chandra, David Z. Pan category:cs.LG  published:2017-09-18 summary:Massive data exist among user local platforms that usually cannot support deep neural network (DNN) training due to computation and storage resource constraints. Cloud-based training schemes can provide beneficial services, but rely on excessive user data collection, which can lead to potential privacy risks and violations. In this paper, we propose PrivyNet, a flexible framework to enable DNN training on the cloud while protecting the data privacy simultaneously. We propose to split the DNNs into two parts and deploy them separately onto the local platforms and the cloud. The local neural network (NN) is used for feature extraction. To avoid local training, we rely on the idea of transfer learning and derive the local NNs by extracting the initial layers from pre-trained NNs. We identify and compare three factors that determine the topology of the local NN, including the number of layers, the depth of output channels, and the subset of selected channels. We also propose a hierarchical strategy to determine the local NN topology, which is flexible to optimize the accuracy of the target learning task under the constraints on privacy loss, local computation, and storage. To validate PrivyNet, we use the convolutional NN (CNN) based image classification task as an example and characterize the dependency of privacy loss and accuracy on the local NN topology in detail. We also demonstrate that PrivyNet is efficient and can help explore and optimize the trade-off between privacy loss and accuracy. version:1
arxiv-1709-06158 | Matterport3D: Learning from RGB-D Data in Indoor Environments | http://arxiv.org/abs/1709.06158 | id:1709.06158 author:Angel Chang, Angela Dai, Thomas Funkhouser, Maciej Halber, Matthias Nießner, Manolis Savva, Shuran Song, Andy Zeng, Yinda Zhang category:cs.CV  published:2017-09-18 summary:Access to large, diverse RGB-D datasets is critical for training RGB-D scene understanding algorithms. However, existing datasets still cover only a limited number of views or a restricted scale of spaces. In this paper, we introduce Matterport3D, a large-scale RGB-D dataset containing 10,800 panoramic views from 194,400 RGB-D images of 90 building-scale scenes. Annotations are provided with surface reconstructions, camera poses, and 2D and 3D semantic segmentations. The precise global alignment and comprehensive, diverse panoramic set of views over entire buildings enable a variety of supervised and self-supervised computer vision tasks, including keypoint matching, view overlap prediction, normal prediction from color, semantic segmentation, and region classification. version:1
arxiv-1709-06151 | Multi-modal analysis of genetically-related subjects using SIFT descriptors in brain MRI | http://arxiv.org/abs/1709.06151 | id:1709.06151 author:Kuldeep Kumar, Laurent Chauvin, Mathew Toews, Olivier Colliot, Christian Desrosiers category:cs.CV q-bio.NC q-bio.QM  published:2017-09-18 summary:So far, fingerprinting studies have focused on identifying features from single-modality MRI data, which capture individual characteristics in terms of brain structure, function, or white matter microstructure. However, due to the lack of a framework for comparing across multiple modalities, studies based on multi-modal data remain elusive. This paper presents a multi-modal analysis of genetically-related subjects to compare and contrast the information provided by various MRI modalities. The proposed framework represents MRI scans as bags of SIFT features, and uses these features in a nearest-neighbor graph to measure subject similarity. Experiments using the T1/T2-weighted MRI and diffusion MRI data of 861 Human Connectome Project subjects demonstrate strong links between the proposed similarity measure and genetic proximity. version:1
arxiv-1709-06144 | White Matter Fiber Segmentation Using Functional Varifolds | http://arxiv.org/abs/1709.06144 | id:1709.06144 author:Kuldeep Kumar, Pietro Gori, Benjamin Charlier, Stanley Durrleman, Olivier Colliot, Christian Desrosiers category:cs.CV q-bio.NC q-bio.QM  published:2017-09-18 summary:The extraction of fibers from dMRI data typically produces a large number of fibers, it is common to group fibers into bundles. To this end, many specialized distance measures, such as MCP, have been used for fiber similarity. However, these distance based approaches require point-wise correspondence and focus only on the geometry of the fibers. Recent publications have highlighted that using microstructure measures along fibers improves tractography analysis. Also, many neurodegenerative diseases impacting white matter require the study of microstructure measures as well as the white matter geometry. Motivated by these, we propose to use a novel computational model for fibers, called functional varifolds, characterized by a metric that considers both the geometry and microstructure measure (e.g. GFA) along the fiber pathway. We use it to cluster fibers with a dictionary learning and sparse coding-based framework, and present a preliminary analysis using HCP data. version:1
arxiv-1709-06136 | Iterative Policy Learning in End-to-End Trainable Task-Oriented Neural Dialog Models | http://arxiv.org/abs/1709.06136 | id:1709.06136 author:Bing Liu, Ian Lane category:cs.CL  published:2017-09-18 summary:In this paper, we present a deep reinforcement learning (RL) framework for iterative dialog policy optimization in end-to-end task-oriented dialog systems. Popular approaches in learning dialog policy with RL include letting a dialog agent to learn against a user simulator. Building a reliable user simulator, however, is not trivial, often as difficult as building a good dialog agent. We address this challenge by jointly optimizing the dialog agent and the user simulator with deep RL by simulating dialogs between the two agents. We first bootstrap a basic dialog agent and a basic user simulator by learning directly from dialog corpora with supervised training. We then improve them further by letting the two agents to conduct task-oriented dialogs and iteratively optimizing their policies with deep RL. Both the dialog agent and the user simulator are designed with neural network models that can be trained end-to-end. Our experiment results show that the proposed method leads to promising improvements on task success rate and total task reward comparing to supervised training and single-agent RL training baseline models. version:1
arxiv-1709-06126 | How intelligent are convolutional neural networks? | http://arxiv.org/abs/1709.06126 | id:1709.06126 author:Zhennan Yan, Xiang Sean Zhou category:cs.CV  published:2017-09-18 summary:Motivated by the Gestalt pattern theory, and the Winograd Challenge for language understanding, we design synthetic experiments to investigate a deep learning algorithm's ability to infer simple (at least for human) visual concepts, such as symmetry, from examples. A visual concept is represented by randomly generated, positive as well as negative, example images. We then test the ability and speed of algorithms (and humans) to learn the concept from these images. The training and testing are performed progressively in multiple rounds, with each subsequent round deliberately designed to be more complex and confusing than the previous round(s), especially if the concept was not grasped by the learner. However, if the concept was understood, all the deliberate tests would become trivially easy. Our experiments show that humans can often infer a semantic concept quickly after looking at only a very small number of examples (this is often referred to as an "aha moment": a moment of sudden realization), and performs perfectly during all testing rounds (except for careless mistakes). On the contrary, deep convolutional neural networks (DCNN) could approximate some concepts statistically, but only after seeing many (x10^4) more examples. And it will still make obvious mistakes, especially during deliberate testing rounds or on samples outside the training distributions. This signals a lack of true "understanding", or a failure to reach the right "formula" for the semantics. We did find that some concepts are easier for DCNN than others. For example, simple "counting" is more learnable than "symmetry", while "uniformity" or "conformance" are much more difficult for DCNN to learn. To conclude, we propose an "Aha Challenge" for visual perception, calling for focused and quantitative research on Gestalt-style machine intelligence using limited training examples. version:1
arxiv-1709-06123 | A Probabilistic Framework for Nonlinearities in Stochastic Neural Networks | http://arxiv.org/abs/1709.06123 | id:1709.06123 author:Qinliang Su, Xuejun Liao, Lawrence Carin category:stat.ML cs.LG  published:2017-09-18 summary:We present a probabilistic framework for nonlinearities, based on doubly truncated Gaussian distributions. By setting the truncation points appropriately, we are able to generate various types of nonlinearities within a unified framework, including sigmoid, tanh and ReLU, the most commonly used nonlinearities in neural networks. The framework readily integrates into existing stochastic neural networks (with hidden units characterized as random variables), allowing one for the first time to learn the nonlinearities alongside model weights in these networks. Extensive experiments demonstrate the performance improvements brought about by the proposed framework when integrated with the restricted Boltzmann machine (RBM), temporal RBM and the truncated Gaussian graphical model (TGGM). version:1
arxiv-1709-06122 | Fiber-Flux Diffusion Density for White Matter Tracts Analysis: Application to Mild Anomalies Localization in Contact Sports Players | http://arxiv.org/abs/1709.06122 | id:1709.06122 author:Itay Benou, Ronel Veksler, Alon Friedman, Tammy Riklin Raviv category:cs.CV q-bio.QM  published:2017-09-18 summary:We present the concept of fiber-flux density for locally quantifying white matter (WM) fiber bundles. By combining scalar diffusivity measures (e.g., fractional anisotropy) with fiber-flux measurements, we define new local descriptors called Fiber-Flux Diffusion Density (FFDD) vectors. Applying each descriptor throughout fiber bundles allows along-tract coupling of a specific diffusion measure with geometrical properties, such as fiber orientation and coherence. A key step in the proposed framework is the construction of an FFDD dissimilarity measure for sub-voxel alignment of fiber bundles, based on the fast marching method (FMM). The obtained aligned WM tract-profiles enable meaningful inter-subject comparisons and group-wise statistical analysis. We demonstrate our method using two different datasets of contact sports players. Along-tract pairwise comparison as well as group-wise analysis, with respect to non-player healthy controls, reveal significant and spatially-consistent FFDD anomalies. Comparing our method with along-tract FA analysis shows improved sensitivity to subtle structural anomalies in football players over standard FA measurements. version:1
arxiv-1709-06114 | Geometric Semantic Genetic Programming Algorithm and Slump Prediction | http://arxiv.org/abs/1709.06114 | id:1709.06114 author:Juncai Xu, Zhenzhong Shen, Qingwen Ren, Xin Xie, Zhengyu Yang category:cs.NE  published:2017-09-18 summary:Research on the performance of recycled concrete as building material in the current world is an important subject. Given the complex composition of recycled concrete, conventional methods for forecasting slump scarcely obtain satisfactory results. Based on theory of nonlinear prediction method, we propose a recycled concrete slump prediction model based on geometric semantic genetic programming (GSGP) and combined it with recycled concrete features. Tests show that the model can accurately predict the recycled concrete slump by using the established prediction model to calculate the recycled concrete slump with different mixing ratios in practical projects and by comparing the predicted values with the experimental values. By comparing the model with several other nonlinear prediction models, we can conclude that GSGP has higher accuracy and reliability than conventional methods. version:1
arxiv-1709-06109 | A Note on Tight Lower Bound for MNL-Bandit Assortment Selection Models | http://arxiv.org/abs/1709.06109 | id:1709.06109 author:Xi Chen, Yining Wang category:stat.ML cs.LG  published:2017-09-18 summary:In this note we prove a tight lower bound for the MNL-bandit assortment selection model that matches the upper bound given in (Agrawal et al., 2016) for all parameters, up to logarithmic factors. version:1
arxiv-1709-06057 | Rotation Adaptive Visual Object Tracking with Motion Consistency | http://arxiv.org/abs/1709.06057 | id:1709.06057 author:Litu Rout, Sidhartha, Gorthi R. K. S. S. Manyam, Deepak Mishra category:cs.CV  published:2017-09-18 summary:Visual Object tracking research has undergone significant improvement in the past few years. The emergence of tracking by detection approach in tracking paradigm has been quite successful in many ways. Recently, deep convolutional neural networks have been extensively used in most successful trackers. Yet, the standard approach has been based on correlation or feature selection with minimal consideration given to motion consistency. Thus, there is still a need to capture various physical constraints through motion consistency which will improve accuracy, robustness and more importantly rotation adaptiveness. Therefore, one of the major aspects of this paper is to investigate the outcome of rotation adaptiveness in visual object tracking. Among other key contributions, the paper also includes various consistencies that turn out to be extremely effective in numerous challenging sequences than the current state-of-the-art. version:1
arxiv-1709-06054 | Target-adaptive CNN-based pansharpening | http://arxiv.org/abs/1709.06054 | id:1709.06054 author:Giuseppe Scarpa, Sergio Vitale, Davide Cozzolino category:cs.CV  published:2017-09-18 summary:We recently proposed a convolutional neural network for remote sensing image pansharpening obtaining a significant performance gain over the state of the art. In this paper, we explore a number of architectural and training variations to this baseline, achieving further performance gains with a lightweight network which trains very fast. Leveraging on this latter property, we propose a target-adaptive usage modality which ensures a very good performance also in the presence of a mismatch w.r.t. the training set, and even across different sensors. The proposed method, published online as an off-the-shelf software tool, allows users to perform fast and high-quality CNN-based pansharpening of their own target images on general-purpose hardware. version:1
arxiv-1709-06053 | Coupled Ensembles of Neural Networks | http://arxiv.org/abs/1709.06053 | id:1709.06053 author:Anuvabh Dutt, Denis Pellerin, Georges Quénot category:cs.CV stat.ML  published:2017-09-18 summary:We investigate in this paper the architecture of deep convolutional networks. Building on existing state of the art models, we propose a reconfiguration of the model parameters into several parallel branches at the global network level, with each branch being a standalone CNN. We show that this arrangement is an efficient way to significantly reduce the number of parameters without losing performance or to significantly improve the performance with the same level of performance. The use of branches brings an additional form of regularization. In addition to the split into parallel branches, we propose a tighter coupling of these branches by placing the "fuse (averaging) layer" before the Log-Likelihood and SoftMax layers during training. This gives another significant performance improvement, the tighter coupling favouring the learning of better representations, even at the level of the individual branches. We refer to this branched architecture as "coupled ensembles". The approach is very generic and can be applied with almost any DCNN architecture. With coupled ensembles of DenseNet-BC and parameter budget of 25M, we obtain error rates of 2.92%, 15.68% and 1.50% respectively on CIFAR-10, CIFAR-100 and SVHN tasks. For the same budget, DenseNet-BC has error rate of 3.46%, 17.18%, and 1.8% respectively. With ensembles of coupled ensembles, of DenseNet-BC networks, with 50M total parameters, we obtain error rates of 2.72%, 15.13% and 1.42% respectively on these tasks. version:1
arxiv-1709-06035 | Vehicle Tracking in Wide Area Motion Imagery via Stochastic Progressive Association Across Multiple Frames (SPAAM) | http://arxiv.org/abs/1709.06035 | id:1709.06035 author:Ahmed Elliethy, Gaurav Sharma category:cs.CV  published:2017-09-18 summary:Vehicle tracking in Wide Area Motion Imagery (WAMI) relies on associating vehicle detections across multiple WAMI frames to form tracks corresponding to individual vehicles. The temporal window length, i.e., the number $M$ of sequential frames, over which associations are collectively estimated poses a trade-off between accuracy and computational complexity. A larger $M$ improves performance because the increased temporal context enables the use of motion models and allows occlusions and spurious detections to be handled better. The number of total hypotheses tracks, on the other hand, grows exponentially with increasing $M$, making larger values of $M$ computationally challenging to tackle. In this paper, we introduce SPAAM an iterative approach that progressively grows $M$ with each iteration to improve estimated tracks by exploiting the enlarged temporal context while keeping computation manageable through two novel approaches for pruning association hypotheses. First, guided by a road network, accurately co-registered to the WAMI frames, we disregard unlikely associations that do not agree with the road network. Second, as $M$ is progressively enlarged at each iteration, the related increase in association hypotheses is limited by revisiting only the subset of association possibilities rendered open by stochastically determined dis-associations for the previous iteration. The stochastic dis-association at each iteration maintains each estimated association according to an estimated probability for confidence, obtained via a probabilistic model. Associations at each iteration are then estimated globally over the $M$ frames by (approximately) solving a binary integer programming problem for selecting a set of compatible tracks. Vehicle tracking results obtained over test WAMI datasets indicate that our proposed approach provides significant performance improvements over 3 alternatives. version:1
arxiv-1709-06033 | Sequence to Sequence Learning for Event Prediction | http://arxiv.org/abs/1709.06033 | id:1709.06033 author:Dai Quoc Nguyen, Dat Quoc Nguyen, Cuong Xuan Chu, Stefan Thater, Manfred Pinkal category:cs.CL  published:2017-09-18 summary:This paper presents an approach to the task of predicting an event description from a preceding sentence in a text. Our approach explores sequence-to-sequence learning using a bidirectional multi-layer recurrent neural network. Our approach substantially outperforms previous work in terms of the BLEU score on two datasets derived from WikiHow and DeScript respectively. Since the BLEU score is not easy to interpret as a measure of event prediction, we complement our study with a second evaluation that exploits the rich linguistic annotation of gold paraphrase sets of events. version:1
arxiv-1709-06031 | Video Object Segmentation Without Temporal Information | http://arxiv.org/abs/1709.06031 | id:1709.06031 author:Kevis-Kokitsi Maninis, Sergi Caelles, Yuhua Chen, Jordi Pont-Tuset, Laura Leal-Taixé, Daniel Cremers, Luc Van Gool category:cs.CV  published:2017-09-18 summary:Video Object Segmentation, and video processing in general, has been historically dominated by methods that rely on the temporal consistency and redundancy in consecutive video frames. When the temporal smoothness is suddenly broken, such as when an object is occluded, or some frames are missing in a sequence, the result of these methods can deteriorate significantly or they may not even produce any result at all. This paper explores the orthogonal approach of processing each frame independently, i.e disregarding the temporal information. In particular, it tackles the task of semi-supervised video object segmentation: the separation of an object from the background in a video, given its mask in the first frame. We present Semantic One-Shot Video Object Segmentation (OSVOS-S), based on a fully-convolutional neural network architecture that is able to successively transfer generic semantic information, learned on ImageNet, to the task of foreground segmentation, and finally to learning the appearance of a single annotated object of the test sequence (hence one shot). We show that instance level semantic information, when combined effectively, can dramatically improve the results of our previous method, OSVOS. We perform experiments on two recent video segmentation databases, which show that OSVOS-S is both the fastest and most accurate method in the state of the art. version:1
arxiv-1709-06030 | N2N Learning: Network to Network Compression via Policy Gradient Reinforcement Learning | http://arxiv.org/abs/1709.06030 | id:1709.06030 author:Anubhav Ashok, Nicholas Rhinehart, Fares Beainy, Kris M. Kitani category:cs.LG stat.ML  published:2017-09-18 summary:While bigger and deeper neural network architectures continue to advance the state-of-the-art for many computer vision tasks, real-world adoption of these networks is impeded by hardware and speed constraints. Conventional model compression methods attempt to address this problem by modifying the architecture manually or using pre-defined heuristics. Since the space of all reduced architectures is very large, modifying the architecture of a deep neural network in this way is a difficult task. In this paper, we tackle this issue by introducing a principled method for learning reduced network architectures in a data-driven way using reinforcement learning. Our approach takes a larger `teacher' network as input and outputs a compressed `student' network derived from the `teacher' network. In the first stage of our method, a recurrent policy network aggressively removes layers from the large `teacher' model. In the second stage, another recurrent policy network carefully reduces the size of each remaining layer. The resulting network is then evaluated to obtain a reward -- a score based on the accuracy and compression of the network. Our approach uses this reward signal with policy gradients to train the policies to find a locally optimal student network. Our experiments show that we can achieve compression rates of more than 10x for models such as ResNet-34 while maintaining similar performance to the input `teacher' network. We also present a valuable transfer learning result which shows that policies which are pre-trained on smaller `teacher' networks can be used to rapidly speed up training on larger `teacher' networks. version:1
arxiv-1709-06010 | Learning Depth-Three Neural Networks in Polynomial Time | http://arxiv.org/abs/1709.06010 | id:1709.06010 author:Surbhi Goel, Adam Klivans category:cs.DS cs.LG stat.ML  published:2017-09-18 summary:We give a polynomial-time algorithm for learning neural networks with one hidden layer of sigmoids feeding into any smooth, monotone activation function (e.g. Sigmoid or ReLU). We make no assumptions on the structure of the network, and the algorithm succeeds with respect to any distribution on the unit ball in $n$ dimensions (hidden weight vectors also have unit norm). This is the first assumption-free, provably efficient algorithm for learning neural networks with more than one hidden layer. Our algorithm-- Alphatron-- is a simple, iterative update rule that combines isotonic regression with kernel methods. It outputs a hypothesis that yields efficient oracle access to interpretable features. It also suggests a new approach to Boolean function learning via smooth relaxations of hard thesholds, sidestepping traditional hardness results from computational learning theory. As applications, we obtain the first provably correct algorithms for common schemes in multiple-instance learning (in the difficult case where the examples within each bag are not identically distributed) as well the first polynomial-time algorithm for learning intersections of a polynomial number of halfspaces with a margin. version:1
arxiv-1709-06009 | Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents | http://arxiv.org/abs/1709.06009 | id:1709.06009 author:Marlos C. Machado, Marc G. Bellemare, Erik Talvitie, Joel Veness, Matthew Hausknecht, Michael Bowling category:cs.LG  published:2017-09-18 summary:The Arcade Learning Environment (ALE) is an evaluation platform that poses the challenge of building AI agents with general competency across dozens of Atari 2600 games. It supports a variety of different problem settings and it has been receiving increasing attention from the scientific community, leading to some high-profile success stories such as the much publicized Deep Q-Networks (DQN). In this article we take a big picture look at how the ALE is being used by the research community. We show how diverse the evaluation methodologies in the ALE have become with time, and highlight some key concerns when evaluating agents in the ALE. We use this discussion to present some methodological best practices and provide new benchmark results using these best practices. To further the progress in the field, we introduce a new version of the ALE that supports multiple game modes and provides a form of stochasticity we call sticky actions. We conclude this big picture look by revisiting challenges posed when the ALE was introduced, summarizing the state-of-the-art in various problems and highlighting problems that remain open. version:1
arxiv-1709-05982 | Multi-Person Pose Estimation via Column Generation | http://arxiv.org/abs/1709.05982 | id:1709.05982 author:Shaofei Wang, Chong Zhang, Miguel A. Gonzalez-Ballester, Alexander Ihler, Julian Yarkony category:cs.CV  published:2017-09-18 summary:We study the problem of multi-person pose estimation in natural images. A pose estimate describes the spatial position and identity (head, foot, knee, etc.) of every non-occluded body part of a person. Pose estimation is difficult due to issues such as deformation and variation in body configurations and occlusion of parts, while multi-person settings add complications such as an unknown number of people, with unknown appearance and possible interactions in their poses and part locations. We give a novel integer program formulation of the multi-person pose estimation problem, in which variables correspond to assignments of parts in the image to poses in a two-tier, hierarchical way. This enables us to develop an efficient custom optimization procedure based on column generation, where columns are produced by exact optimization of very small scale integer programs. We demonstrate improved accuracy and speed for our method on the MPII multi-person pose estimation benchmark. version:1
arxiv-1709-05965 | Variational Methods for Normal Integration | http://arxiv.org/abs/1709.05965 | id:1709.05965 author:Yvain Quéau, Jean-Denis Durou, Jean-François Aujol category:cs.CV  published:2017-09-18 summary:The need for an efficient method of integration of a dense normal field is inspired by several computer vision tasks, such as shape-from-shading, photometric stereo, deflectometry, etc. Inspired by edge-preserving methods from image processing, we study in this paper several variational approaches for normal integration, with a focus on non-rectangular domains, free boundary and depth discontinuities. We first introduce a new discretization for quadratic integration, which is designed to ensure both fast recovery and the ability to handle non-rectangular domains with a free boundary. Yet, with this solver, discontinuous surfaces can be handled only if the scene is first segmented into pieces without discontinuity. Hence, we then discuss several discontinuity-preserving strategies. Those inspired, respectively, by the Mumford-Shah segmentation method and by anisotropic diffusion, are shown to be the most effective for recovering discontinuities. version:1
arxiv-1709-05964 | Why Pay More When You Can Pay Less: A Joint Learning Framework for Active Feature Acquisition and Classification | http://arxiv.org/abs/1709.05964 | id:1709.05964 author:Hajin Shim, Sung Ju Hwang, Eunho Yang category:cs.LG stat.ML  published:2017-09-18 summary:We consider the problem of active feature acquisition, where we sequentially select the subset of features in order to achieve the maximum prediction performance in the most cost-effective way. In this work, we formulate this active feature acquisition problem as a reinforcement learning problem, and provide a novel framework for jointly learning both the RL agent and the classifier (environment). We also introduce a more systematic way of encoding subsets of features that can properly handle innate challenge with missing entries in active feature acquisition problems, that uses the orderless LSTM-based set encoding mechanism that readily fits in the joint learning framework. We evaluate our model on a carefully designed synthetic dataset for the active feature acquisition as well as several real datasets such as electric health record (EHR) datasets, on which it outperforms all baselines in terms of prediction performance as well feature acquisition cost. version:1
arxiv-1709-05963 | Machine learning approximation algorithms for high-dimensional fully nonlinear partial differential equations and second-order backward stochastic differential equations | http://arxiv.org/abs/1709.05963 | id:1709.05963 author:Christian Beck, Weinan E, Arnulf Jentzen category:math.NA cs.LG cs.NE math.PR stat.ML  published:2017-09-18 summary:High-dimensional partial differential equations (PDE) appear in a number of models from the financial industry, such as in derivative pricing models, credit valuation adjustment (CVA) models, or portfolio optimization models. The PDEs in such applications are high-dimensional as the dimension corresponds to the number of financial assets in a portfolio. Moreover, such PDEs are often fully nonlinear due to the need to incorporate certain nonlinear phenomena in the model such as default risks, transaction costs, volatility uncertainty (Knightian uncertainty), or trading constraints in the model. Such high-dimensional fully nonlinear PDEs are exceedingly difficult to solve as the computational effort for standard approximation methods grows exponentially with the dimension. In this work we propose a new method for solving high-dimensional fully nonlinear second-order PDEs. Our method can in particular be used to sample from high-dimensional nonlinear expectations. The method is based on (i) a connection between fully nonlinear second-order PDEs and second-order backward stochastic differential equations (2BSDEs), (ii) a merged formulation of the PDE and the 2BSDE problem, (iii) a temporal forward discretization of the 2BSDE and a spatial approximation via deep neural nets, and (iv) a stochastic gradient descent-type optimization procedure. Numerical results obtained using ${\rm T{\small ENSOR}F{\small LOW}}$ in ${\rm P{\small YTHON}}$ illustrate the efficiency and the accuracy of the method in the cases of a $100$-dimensional Black-Scholes-Barenblatt equation, a $100$-dimensional Hamilton-Jacobi-Bellman equation, and a nonlinear expectation of a $ 100 $-dimensional $ G $-Brownian motion. version:1
arxiv-1709-05940 | Normal Integration: A Survey | http://arxiv.org/abs/1709.05940 | id:1709.05940 author:Yvain Quéau, Jean-Denis Durou, Jean-François Aujol category:cs.CV  published:2017-09-18 summary:The need for efficient normal integration methods is driven by several computer vision tasks such as shape-from-shading, photometric stereo, deflectometry, etc. In the first part of this survey, we select the most important properties that one may expect from a normal integration method, based on a thorough study of two pioneering works by Horn and Brooks [28] and by Frankot and Chellappa [19]. Apart from accuracy, an integration method should at least be fast and robust to a noisy normal field. In addition, it should be able to handle several types of boundary condition, including the case of a free boundary, and a reconstruction domain of any shape i.e., which is not necessarily rectangular. It is also much appreciated that a minimum number of parameters have to be tuned, or even no parameter at all. Finally, it should preserve the depth discontinuities. In the second part of this survey, we review most of the existing methods in view of this analysis, and conclude that none of them satisfies all of the required properties. This work is complemented by a companion paper entitled Variational Methods for Normal Integration, in which we focus on the problem of normal integration in the presence of depth discontinuities, a problem which occurs as soon as there are occlusions. version:1
arxiv-1709-05932 | Multi-Task Learning for Segmentation of Building Footprints with Deep Neural Networks | http://arxiv.org/abs/1709.05932 | id:1709.05932 author:Benjamin Bischke, Patrick Helber, Joachim Folz, Damian Borth, Andreas Dengel category:cs.CV  published:2017-09-18 summary:The increased availability of high resolution satellite imagery allows to sense very detailed structures on the surface of our planet. Access to such information opens up new directions in the analysis of remote sensing imagery. However, at the same time this raises a set of new challenges for existing pixel-based prediction methods, such as semantic segmentation approaches. While deep neural networks have achieved significant advances in the semantic segmentation of high resolution images in the past, most of the existing approaches tend to produce predictions with poor boundaries. In this paper, we address the problem of preserving semantic segmentation boundaries in high resolution satellite imagery by introducing a new cascaded multi-task loss. We evaluate our approach on Inria Aerial Image Labeling Dataset which contains large-scale and high resolution images. Our results show that we are able to outperform state-of-the-art methods by 8.3\% without any additional post-processing step. version:1
arxiv-1709-05256 | Detecting Faces Using Region-based Fully Convolutional Networks | http://arxiv.org/abs/1709.05256 | id:1709.05256 author:Yitong Wang, Xing Ji, Zheng Zhou, Hao Wang, Zhifeng Li category:cs.CV  published:2017-09-14 summary:Face detection has achieved great success using the region-based methods. In this report, we propose a region-based face detector applying deep networks in a fully convolutional fashion, named Face R-FCN. Based on Region-based Fully Convolutional Networks (R-FCN), our face detector is more accurate and computational efficient compared with the previous R-CNN based face detectors. In our approach, we adopt the fully convolutional Residual Network (ResNet) as the backbone network. Particularly, We exploit several new techniques including position-sensitive average pooling, multi-scale training and testing and on-line hard example mining strategy to improve the detection accuracy. Over two most popular and challenging face detection benchmarks, FDDB and WIDER FACE, Face R-FCN achieves superior performance over state-of-the-arts. version:2
arxiv-1709-05914 | Limitations of Cross-Lingual Learning from Image Search | http://arxiv.org/abs/1709.05914 | id:1709.05914 author:Mareike Hartmann, Anders Soegaard category:cs.CL  published:2017-09-18 summary:Cross-lingual representation learning is an important step in making NLP scale to all the world's languages. Recent work on bilingual lexicon induction suggests that it is possible to learn cross-lingual representations of words based on similarities between images associated with these words. However, that work focused on the translation of selected nouns only. In our work, we investigate whether the meaning of other parts-of-speech, in particular adjectives and verbs, can be learned in the same way. We also experiment with combining the representations learned from visual data with embeddings learned from textual data. Our experiments across five language pairs indicate that previous work does not scale to the problem of learning cross-lingual representations beyond simple nouns. version:1
arxiv-1709-05885 | Variational Gaussian Approximation for Poisson Data | http://arxiv.org/abs/1709.05885 | id:1709.05885 author:Simon Arridge, Kazufumi Ito, Bangti Jin, Chen Zhang category:math.NA stat.CO stat.ML  published:2017-09-18 summary:The Poisson model is frequently employed to describe count data, but in a Bayesian context it leads to an analytically intractable posterior probability distribution. In this work, we analyze a variational Gaussian approximation to the posterior distribution arising from the Poisson model with a Gaussian prior. This is achieved by seeking an optimal Gaussian distribution minimizing the Kullback-Leibler divergence from the posterior distribution to the approximation, or equivalently maximizing the lower bound for the model evidence. We derive an explicit expression for the lower bound, and show the existence and uniqueness of the optimal Gaussian approximation. The lower bound functional can be viewed as a variant of classical Tikhonov regularization that penalizes also the covariance. Then we develop an efficient alternating direction maximization algorithm for solving the optimization problem, and analyze its convergence. We discuss strategies for reducing the computational complexity via low rank structure of the forward operator and the sparsity of the covariance. Further, as an application of the lower bound, we discuss hierarchical Bayesian modeling for selecting the hyperparameter in the prior distribution, and propose a monotonically convergent algorithm for determining the hyperparameter. We present extensive numerical experiments to illustrate the Gaussian approximation and the algorithms. version:1
arxiv-1706-06782 | Object Detection Using Deep CNNs Trained on Synthetic Images | http://arxiv.org/abs/1706.06782 | id:1706.06782 author:Param S. Rajpura, Hristo Bojinov, Ravi S. Hegde category:cs.CV  published:2017-06-21 summary:The need for large annotated image datasets for training Convolutional Neural Networks (CNNs) has been a significant impediment for their adoption in computer vision applications. We show that with transfer learning an effective object detector can be trained almost entirely on synthetically rendered datasets. We apply this strategy for detecting pack- aged food products clustered in refrigerator scenes. Our CNN trained only with 4000 synthetic images achieves mean average precision (mAP) of 24 on a test set with 55 distinct products as objects of interest and 17 distractor objects. A further increase of 12% in the mAP is obtained by adding only 400 real images to these 4000 synthetic images in the training set. A high degree of photorealism in the synthetic images was not essential in achieving this performance. We analyze factors like training data set size and 3D model dictionary size for their influence on detection performance. Additionally, training strategies like fine-tuning with selected layers and early stopping which affect transfer learning from synthetic scenes to real scenes are explored. Training CNNs with synthetic datasets is a novel application of high-performance computing and a promising approach for object detection applications in domains where there is a dearth of large annotated image data. version:2
arxiv-1709-00849 | Dataset Augmentation with Synthetic Images Improves Semantic Segmentation | http://arxiv.org/abs/1709.00849 | id:1709.00849 author:Param Rajpura, Manik Goyal, Hristo Bojinov, Ravi Hegde category:cs.CV  published:2017-09-04 summary:Although Deep Convolutional Neural Networks trained with strong pixel-level annotations have significantly pushed the performance in semantic segmentation, annotation efforts required for the creation of training data remains a roadblock for further improvements. We show that augmentation of the weakly annotated training dataset with synthetic images minimizes both the annotation efforts and also the cost of capturing images with sufficient variety. Evaluation on the PASCAL 2012 validation dataset shows an increase in mean IOU from 52.80% to 55.47% by adding just 100 synthetic images per object class. Our approach is thus a promising solution to the problems of annotation and dataset collection. version:2
arxiv-1709-05867 | Combinational neural network using Gabor filters for the classification of handwritten digits | http://arxiv.org/abs/1709.05867 | id:1709.05867 author:N. Joshi category:cs.CV  published:2017-09-18 summary:A classification algorithm that combines the components of k-nearest neighbours and multilayer neural networks has been designed and tested. With this method the computational time required for training the dataset has been reduced substancially. Gabor filters were used for the feature extraction to ensure a better performance. This algorithm is tested with MNIST dataset and it will be integrated as a module in the object recognition software which is currently under development. version:1
arxiv-1709-05865 | Depression Scale Recognition from Audio, Visual and Text Analysis | http://arxiv.org/abs/1709.05865 | id:1709.05865 author:Shubham Dham, Anirudh Sharma, Abhinav Dhall category:cs.CV cs.LG cs.MM  published:2017-09-18 summary:Depression is a major mental health disorder that is rapidly affecting lives worldwide. Depression not only impacts emotional but also physical and psychological state of the person. Its symptoms include lack of interest in daily activities, feeling low, anxiety, frustration, loss of weight and even feeling of self-hatred. This report describes work done by us for Audio Visual Emotion Challenge (AVEC) 2017 during our second year BTech summer internship. With the increase in demand to detect depression automatically with the help of machine learning algorithms, we present our multimodal feature extraction and decision level fusion approach for the same. Features are extracted by processing on the provided Distress Analysis Interview Corpus-Wizard of Oz (DAIC-WOZ) database. Gaussian Mixture Model (GMM) clustering and Fisher vector approach were applied on the visual data; statistical descriptors on gaze, pose; low level audio features and head pose and text features were also extracted. Classification is done on fused as well as independent features using Support Vector Machine (SVM) and neural networks. The results obtained were able to cross the provided baseline on validation data set by 17% on audio features and 24.5% on video features. version:1
arxiv-1709-05861 | Continuous Multimodal Emotion Recognition Approach for AVEC 2017 | http://arxiv.org/abs/1709.05861 | id:1709.05861 author:Narotam Singh, Nittin Singh, Abhinav Dhall category:cs.CV cs.LG cs.MM  published:2017-09-18 summary:This paper reports the analysis of audio and visual features in predicting the emotion dimensions under the seventh Audio/Visual Emotion Subchallenge (AVEC 2017). For visual features we used the HOG (Histogram of Gradients) features, Fisher encodings of SIFT (Scale-Invariant Feature Transform) features based on Gaussian mixture model (GMM) and some pretrained Convolutional Neural Network layers as features; all these extracted for each video clip. For audio features we used the Bag-of-audio-words (BoAW) representation of the LLDs (low-level descriptors) generated by openXBOW provided by the organisers of the event. Then we trained fully connected neural network regression model on the dataset for all these different modalities. We applied multimodal fusion on the output models to get the Concordance correlation coefficient on Development set as well as Test set. version:1
arxiv-1709-05860 | Microscopy Cell Segmentation via Adversarial Neural Networks | http://arxiv.org/abs/1709.05860 | id:1709.05860 author:Assaf Arbelle, Tammy Riklin Raviv category:cs.CV  published:2017-09-18 summary:We present a novel approach for the segmentation of microscopy images. This method utilizes recent development in the field of Deep Artificial Neural Networks in general and specifically the advances in Generative Adversarial Neural Networks (GAN). We propose a pair of two competitive networks which are trained simultaneously and together define a min-max game resulting in an accurate segmentation of a given image. The system is an expansion of the well know GAN model to conditional probabilities given an input image. This approach has two main strengths as it is weakly supervised, i.e. can be easily trained on a limited amount of data, and does not require a definition of a loss function for the optimization. Promising results are presented. The code is freely available at: https://github.com/arbellea/DeepCellSeg.git version:1
arxiv-1708-08282 | A New Learning Paradigm for Random Vector Functional-Link Network: RVFL+ | http://arxiv.org/abs/1708.08282 | id:1708.08282 author:Peng-Bo Zhang category:stat.ML cs.LG cs.NE  published:2017-08-28 summary:In school, a teacher plays an important role in various classroom teaching patterns. Likewise to this human learning activity, the learning using privileged information (LUPI) paradigm provides additional information generated by the teacher to 'teach' learning algorithms during the training stage. Therefore, this novel learning paradigm is a typical Teacher-Student Interaction mechanism. This paper is the first to present a random vector functional link network based on the LUPI paradigm, called RVFL+. Rather than simply combining two existing approaches, the newly-derived RVFL+ fills the gap between neural networks and the LUPI paradigm, which offers an alternative way to train RVFL networks. Moreover, the proposed RVFL+ can perform in conjunction with the kernel trick for highly complicated nonlinear feature learning, which is termed KRVFL+. Furthermore, the statistical property of the proposed RVFL+ is investigated, and we derive a sharp and high-quality generalization error bound based on the Rademacher complexity. Competitive experimental results on 14 real-world datasets illustrate the great effectiveness and efficiency of the novel RVFL+ and KRVFL+, which can achieve better generalization performance than state-of-the-art algorithms. version:2
arxiv-1709-05849 | Neonatal Seizure Detection using Convolutional Neural Networks | http://arxiv.org/abs/1709.05849 | id:1709.05849 author:Alison O'Shea, Gordon Lightbody, Geraldine Boylan, Andriy Temko category:stat.ML cs.LG  published:2017-09-18 summary:This study presents a novel end-to-end architecture that learns hierarchical representations from raw EEG data using fully convolutional deep neural networks for the task of neonatal seizure detection. The deep neural network acts as both feature extractor and classifier, allowing for end-to-end optimization of the seizure detector. The designed system is evaluated on a large dataset of continuous unedited multi-channel neonatal EEG totaling 835 hours and comprising of 1389 seizures. The proposed deep architecture, with sample-level filters, achieves an accuracy that is comparable to the state-of-the-art SVM-based neonatal seizure detector, which operates on a set of carefully designed hand-crafted features. The fully convolutional architecture allows for the localization of EEG waveforms and patterns that result in high seizure probabilities for further clinical examination. version:1
arxiv-1709-05307 | Top-Down Saliency Detection Driven by Visual Classification | http://arxiv.org/abs/1709.05307 | id:1709.05307 author:Francesca Murabito, Concetto Spampinato, Simone Palazzo, Konstantin Pogorelov, Michael Riegler category:cs.CV  published:2017-09-15 summary:This paper presents an approach for top-down saliency detection guided by visual classification tasks. We first learn how to compute visual saliency when a specific visual task has to be accomplished, as opposed to most state-of-the-art methods which assess saliency merely through bottom-up principles. Afterwards, we investigate if and to what extent visual saliency can support visual classification in nontrivial cases. To achieve this, we propose SalClassNet, a CNN framework consisting of two networks jointly trained: a) the first one computing top-down saliency maps from input images, and b) the second one exploiting the computed saliency maps for visual classification. To test our approach, we collected a dataset of eye-gaze maps, using a Tobii T60 eye tracker, by asking several subjects to look at images from the Stanford Dogs dataset, with the objective of distinguishing dog breeds. Performance analysis on our dataset and other saliency bench-marking datasets, such as POET, showed that SalClassNet out-performs state-of-the-art saliency detectors, such as SalNet and SALICON. Finally, we analyzed the performance of SalClassNet in a fine-grained recognition task and found out that it generalizes better than existing visual classifiers. The achieved results, thus, demonstrate that 1) conditioning saliency detectors with object classes reaches state-of-the-art performance, and 2) providing explicitly top-down saliency maps to visual classifiers enhances classification accuracy. version:2
arxiv-1709-05840 | Autoencoder-Driven Weather Clustering for Source Estimation during Nuclear Events | http://arxiv.org/abs/1709.05840 | id:1709.05840 author:I. A. Klampanos, A. Davvetas, S. Andronopoulos, C. Pappas, A. Ikonomopoulos, V. Karkaletsis category:cs.LG  published:2017-09-18 summary:Emergency response applications for nuclear or radiological events can be significantly improved via deep feature learning due to the hidden complexity of the data and models involved. In this paper we present a novel methodology for rapid source estimation during radiological releases based on deep feature extraction and weather clustering. Atmospheric dispersions are then calculated based on identified predominant weather patterns and are matched against simulated incidents indicated by radiation readings on the ground. We evaluate the accuracy of our methods over multiple years of weather reanalysis data in the European region. We juxtapose these results with deep classification convolution networks and discuss advantages and disadvantages. version:1
arxiv-1709-05833 | Beyond SIFT using Binary features for Loop Closure Detection | http://arxiv.org/abs/1709.05833 | id:1709.05833 author:Lei Han, Guyue Zhou, Lan Xu, Lu Fang category:cs.CV  published:2017-09-18 summary:In this paper a binary feature based Loop Closure Detection (LCD) method is proposed, which for the first time achieves higher precision-recall (PR) performance compared with state-of-the-art SIFT feature based approaches. The proposed system originates from our previous work Multi-Index hashing for Loop closure Detection (MILD), which employs Multi-Index Hashing (MIH)~\cite{greene1994multi} for Approximate Nearest Neighbor (ANN) search of binary features. As the accuracy of MILD is limited by repeating textures and inaccurate image similarity measurement, burstiness handling is introduced to solve this problem and achieves considerable accuracy improvement. Additionally, a comprehensive theoretical analysis on MIH used in MILD is conducted to further explore the potentials of hashing methods for ANN search of binary features from probabilistic perspective. This analysis provides more freedom on best parameter choosing in MIH for different application scenarios. Experiments on popular public datasets show that the proposed approach achieved the highest accuracy compared with state-of-the-art while running at 30Hz for databases containing thousands of images. version:1
arxiv-1704-06228 | Temporal Action Detection with Structured Segment Networks | http://arxiv.org/abs/1704.06228 | id:1704.06228 author:Yue Zhao, Yuanjun Xiong, Limin Wang, Zhirong Wu, Xiaoou Tang, Dahua Lin category:cs.CV  published:2017-04-20 summary:Detecting actions in untrimmed videos is an important yet challenging task. In this paper, we present the structured segment network (SSN), a novel framework which models the temporal structure of each action instance via a structured temporal pyramid. On top of the pyramid, we further introduce a decomposed discriminative model comprising two classifiers, respectively for classifying actions and determining completeness. This allows the framework to effectively distinguish positive proposals from background or incomplete ones, thus leading to both accurate recognition and localization. These components are integrated into a unified network that can be efficiently trained in an end-to-end fashion. Additionally, a simple yet effective temporal action proposal scheme, dubbed temporal actionness grouping (TAG) is devised to generate high quality action proposals. On two challenging benchmarks, THUMOS14 and ActivityNet, our method remarkably outperforms previous state-of-the-art methods, demonstrating superior accuracy and strong adaptivity in handling actions with various temporal structures. version:2
arxiv-1709-05815 | Direct Pose Estimation with a Monocular Camera | http://arxiv.org/abs/1709.05815 | id:1709.05815 author:Darius Burschka, Elmar Mair category:cs.CV  published:2017-09-18 summary:We present a direct method to calculate a 6DoF pose change of a monocular camera for mobile navigation. The calculated pose is estimated up to a constant unknown scale parameter that is kept constant over the entire reconstruction process. This method allows a direct cal- culation of the metric position and rotation without any necessity to fuse the information in a probabilistic approach over longer frame sequence as it is the case in most currently used VSLAM approaches. The algorithm provides two novel aspects to the field of monocular navigation. It allows a direct pose estimation without any a-priori knowledge about the world directly from any two images and it provides a quality measure for the estimated motion parameters that allows to fuse the resulting information in Kalman Filters. We present the mathematical formulation of the approach together with experimental validation on real scene images. version:1
arxiv-1709-05804 | Minimal Effort Back Propagation for Convolutional Neural Networks | http://arxiv.org/abs/1709.05804 | id:1709.05804 author:Bingzhen Wei, Xu Sun, Xuancheng Ren, Jingjing Xu category:cs.LG cs.NE stat.ML  published:2017-09-18 summary:As traditional neural network consumes a significant amount of computing resources during back propagation, \citet{Sun2017mePropSB} propose a simple yet effective technique to alleviate this problem. In this technique, only a small subset of the full gradients are computed to update the model parameters. In this paper we extend this technique into the Convolutional Neural Network(CNN) to reduce calculation in back propagation, and the surprising results verify its validity in CNN: only 5\% of the gradients are passed back but the model still achieves the same effect as the traditional CNN, or even better. We also show that the top-$k$ selection of gradients leads to a sparse calculation in back propagation, which may bring significant computational benefits for high computational complexity of convolution operation in CNN. version:1
arxiv-1709-05788 | StairNet: Top-Down Semantic Aggregation for Accurate One Shot Detection | http://arxiv.org/abs/1709.05788 | id:1709.05788 author:Sanghyun Woo, Soonmin Hwang, In So Kweon category:cs.CV  published:2017-09-18 summary:One-stage object detectors such as SSD or YOLO already have shown promising accuracy with small memory footprint and fast speed. However, it is widely recognized that one-stage detectors have difficulty in detecting small objects while they are competitive with two-stage methods on large objects. In this paper, we investigate how to alleviate this problem starting from the SSD framework. Due to their pyramidal design, the lower layer that is responsible for small objects lacks strong semantics(e.g contextual information). We address this problem by introducing a feature combining module that spreads out the strong semantics in a top-down manner. Our final model StairNet detector unifies the multi-scale representations and semantic distribution effectively. Experiments on PASCAL VOC 2007 and PASCAL VOC 2012 datasets demonstrate that StairNet significantly improves the weakness of SSD and outperforms the other state-of-the-art one-stage detectors. version:1
arxiv-1708-06019 | A Capacity Scaling Law for Artificial Neural Networks | http://arxiv.org/abs/1708.06019 | id:1708.06019 author:Gerald Friedland, Mario Krell category:cs.NE cs.LG  published:2017-08-20 summary:By assuming an ideal neural network with gating functions handling the worst case data, we derive the calculation of two critical numbers predicting the behavior of perceptron networks. First, we derive the calculation of what we call the lossless memory (LM) dimension. The LM dimension is a generalization of the Vapnik-Chervonenkis (VC) dimension that avoids structured data and therefore provides an upper bound for perfectly fitting any training data. Second, we derive what we call the MacKay (MK) dimension. This limit indicates necessary forgetting, that is, the lower limit for most generalization uses of the network. Our derivations are performed by embedding the ideal network into Shannon's communication model which allows to interpret the two points as capacities measured in bits. We validate our upper bounds with repeatable experiments using different network configurations, diverse implementations, varying activation functions, and several learning algorithms. The bottom line is that the two capacity points scale strictly linear with the number of weights. Among other practical applications, our result allows network implementations with gating functions (e.\,g., sigmoid or rectified linear units) to be evaluated against our upper limit independent of a concrete task. version:2
arxiv-1709-05778 | Word Vector Enrichment of Low Frequency Words in the Bag-of-Words Model for Short Text Multi-class Classification Problems | http://arxiv.org/abs/1709.05778 | id:1709.05778 author:Bradford Heap, Michael Bain, Wayne Wobcke, Alfred Krzywicki, Susanne Schmeidl category:cs.CL cs.LG I.2.7; I.2.6  published:2017-09-18 summary:The bag-of-words model is a standard representation of text for many linear classifier learners. In many problem domains, linear classifiers are preferred over more complex models due to their efficiency, robustness and interpretability, and the bag-of-words text representation can capture sufficient information for linear classifiers to make highly accurate predictions. However in settings where there is a large vocabulary, large variance in the frequency of terms in the training corpus, many classes and very short text (e.g., single sentences or document titles) the bag-of-words representation becomes extremely sparse, and this can reduce the accuracy of classifiers. A particular issue in such settings is that short texts tend to contain infrequently occurring or rare terms which lack class-conditional evidence. In this work we introduce a method for enriching the bag-of-words model by complementing such rare term information with related terms from both general and domain-specific Word Vector models. By reducing sparseness in the bag-of-words models, our enrichment approach achieves improved classification over several baseline classifiers in a variety of text classification problems. Our approach is also efficient because it requires no change to the linear classifier before or during training, since bag-of-words enrichment applies only to text being classified. version:1
arxiv-1709-05775 | Social Style Characterization from Egocentric Photo-streams | http://arxiv.org/abs/1709.05775 | id:1709.05775 author:Maedeh Aghaei, Mariella Dimiccoli, Cristian Canton Ferrer, Petia Radeva category:cs.CV  published:2017-09-18 summary:This paper proposes a system for automatic social pattern characterization using a wearable photo-camera. The proposed pipeline consists of three major steps. First, detection of people with whom the camera wearer interacts and, second, categorization of the detected social interactions into formal and informal. These two steps act at event-level where each potential social event is modeled as a multi-dimensional time-series, whose dimensions correspond to a set of relevant features for each task, and a LSTM network is employed for time-series classification. In the last step, recurrences of the same person across the whole set of social interactions are clustered to achieve a comprehensive understanding of the diversity and frequency of the social relations of the user. Experiments over a dataset acquired by a user wearing a photo-camera during a month show promising results on the task of social pattern characterization from egocentric photo-streams. version:1
arxiv-1710-01217 | Wide and deep volumetric residual networks for volumetric image classification | http://arxiv.org/abs/1710.01217 | id:1710.01217 author:Varun Arvind, Anthony Costa, Marcus Badgeley, Samuel Cho, Eric Oermann category:cs.CV  published:2017-09-18 summary:3D shape models that directly classify objects from 3D information have become more widely implementable. Current state of the art models rely on deep convolutional and inception models that are resource intensive. Residual neural networks have been demonstrated to be easier to optimize and do not suffer from vanishing/exploding gradients observed in deep networks. Here we implement a residual neural network for 3D object classification of the 3D Princeton ModelNet dataset. Further, we show that widening network layers dramatically improves accuracy in shallow residual nets, and residual neural networks perform comparable to state-of-the-art 3D shape net models, and we show that widening network layers improves classification accuracy. We provide extensive training and architecture parameters providing a better understanding of available network architectures for use in 3D object classification. version:1
arxiv-1709-05769 | Where to Focus: Deep Attention-based Spatially Recurrent Bilinear Networks for Fine-Grained Visual Recognition | http://arxiv.org/abs/1709.05769 | id:1709.05769 author:Lin Wu, Yang Wang category:cs.CV  published:2017-09-18 summary:Fine-grained visual recognition typically depends on modeling subtle difference from object parts. However, these parts often exhibit dramatic visual variations such as occlusions, viewpoints, and spatial transformations, making it hard to detect. In this paper, we present a novel attention-based model to automatically, selectively and accurately focus on critical object regions with higher importance against appearance variations. Given an image, two different Convolutional Neural Networks (CNNs) are constructed, where the outputs of two CNNs are correlated through bilinear pooling to simultaneously focus on discriminative regions and extract relevant features. To capture spatial distributions among the local regions with visual attention, soft attention based spatial Long-Short Term Memory units (LSTMs) are incorporated to realize spatially recurrent yet visually selective over local input patterns. All the above intuitions equip our network with the following novel model: two-stream CNN layers, bilinear pooling layer, spatial recurrent layer with location attention are jointly trained via an end-to-end fashion to serve as the part detector and feature extractor, whereby relevant features are localized and extracted attentively. We show the significance of our network against two well-known visual recognition tasks: fine-grained image classification and person re-identification. version:1
arxiv-1709-05750 | Adaptive Laplace Mechanism: Differential Privacy Preservation in Deep Learning | http://arxiv.org/abs/1709.05750 | id:1709.05750 author:NhatHai Phan, Xintao Wu, Han Hu, Dejing Dou category:cs.CR cs.LG stat.ML  published:2017-09-18 summary:In this paper, we focus on developing a novel mechanism to preserve differential privacy in deep neural networks, such that: (1) The privacy budget consumption is totally independent of the number of training steps; (2) It has the ability to adaptively inject noise into features based on the contribution of each to the output; and (3) It could be applied in a variety of different deep neural networks. To achieve this, we figure out a way to perturb affine transformations of neurons, and loss functions used in deep neural networks. In addition, our mechanism intentionally adds "more noise" into features which are "less relevant" to the model output, and vice-versa. Our theoretical analysis further derives the sensitivities and error bounds of our mechanism. Rigorous experiments conducted on MNIST and CIFAR-10 datasets show that our mechanism is highly effective and outperforms existing solutions. version:1
arxiv-1709-05745 | Joint Estimation of Camera Pose, Depth, Deblurring, and Super-Resolution from a Blurred Image Sequence | http://arxiv.org/abs/1709.05745 | id:1709.05745 author:Haesol Park, Kyoung Mu Lee category:cs.CV  published:2017-09-18 summary:The conventional methods for estimating camera poses and scene structures from severely blurry or low resolution images often result in failure. The off-the-shelf deblurring or super-resolution methods may show visually pleasing results. However, applying each technique independently before matching is generally unprofitable because this naive series of procedures ignores the consistency between images. In this paper, we propose a pioneering unified framework that solves four problems simultaneously, namely, dense depth reconstruction, camera pose estimation, super-resolution, and deblurring. By reflecting a physical imaging process, we formulate a cost minimization problem and solve it using an alternating optimization technique. The experimental results on both synthetic and real videos show high-quality depth maps derived from severely degraded images that contrast the failures of naive multi-view stereo methods. Our proposed method also produces outstanding deblurred and super-resolved images unlike the independent application or combination of conventional video deblurring, super-resolution methods. version:1
arxiv-1709-05743 | Towards Building a Knowledge Base of Monetary Transactions from a News Collection | http://arxiv.org/abs/1709.05743 | id:1709.05743 author:Jan R. Benetka, Krisztian Balog, Kjetil Nørvåg category:cs.IR cs.CL  published:2017-09-18 summary:We address the problem of extracting structured representations of economic events from a large corpus of news articles, using a combination of natural language processing and machine learning techniques. The developed techniques allow for semi-automatic population of a financial knowledge base, which, in turn, may be used to support a range of data mining and exploration tasks. The key challenge we face in this domain is that the same event is often reported multiple times, with varying correctness of details. We address this challenge by first collecting all information pertinent to a given event from the entire corpus, then considering all possible representations of the event, and finally, using a supervised learning method, to rank these representations by the associated confidence scores. A main innovative element of our approach is that it jointly extracts and stores all attributes of the event as a single representation (quintuple). Using a purpose-built test set we demonstrate that our supervised learning approach can achieve 25% improvement in F1-score over baseline methods that consider the earliest, the latest or the most frequent reporting of the event. version:1
arxiv-1707-03631 | Adversarial Dropout for Supervised and Semi-supervised Learning | http://arxiv.org/abs/1707.03631 | id:1707.03631 author:Sungrae Park, Jun-Keon Park, Su-Jin Shin, Il-Chul Moon category:cs.LG cs.CV  published:2017-07-12 summary:Recently, the training with adversarial examples, which are generated by adding a small but worst-case perturbation on input examples, has been proved to improve generalization performance of neural networks. In contrast to the individually biased inputs to enhance the generality, this paper introduces adversarial dropout, which is a minimal set of dropouts that maximize the divergence between the outputs from the network with the dropouts and the training supervisions. The identified adversarial dropout are used to reconfigure the neural network to train, and we demonstrated that training on the reconfigured sub-network improves the generalization performance of supervised and semi-supervised learning tasks on MNIST and CIFAR-10. We analyzed the trained model to reason the performance improvement, and we found that adversarial dropout increases the sparsity of neural networks more than the standard dropout does. version:2
arxiv-1709-05732 | A Hierarchical Probabilistic Model for Facial Feature Detection | http://arxiv.org/abs/1709.05732 | id:1709.05732 author:Yue Wu, Ziheng Wang, Qiang Ji category:cs.CV  published:2017-09-18 summary:Facial feature detection from facial images has attracted great attention in the field of computer vision. It is a nontrivial task since the appearance and shape of the face tend to change under different conditions. In this paper, we propose a hierarchical probabilistic model that could infer the true locations of facial features given the image measurements even if the face is with significant facial expression and pose. The hierarchical model implicitly captures the lower level shape variations of facial components using the mixture model. Furthermore, in the higher level, it also learns the joint relationship among facial components, the facial expression, and the pose information through automatic structure learning and parameter estimation of the probabilistic model. Experimental results on benchmark databases demonstrate the effectiveness of the proposed hierarchical probabilistic model. version:1
arxiv-1709-05731 | Facial Feature Tracking under Varying Facial Expressions and Face Poses based on Restricted Boltzmann Machines | http://arxiv.org/abs/1709.05731 | id:1709.05731 author:Yue Wu, Zuoguan Wang, Qiang Ji category:cs.CV  published:2017-09-18 summary:Facial feature tracking is an active area in computer vision due to its relevance to many applications. It is a nontrivial task, since faces may have varying facial expressions, poses or occlusions. In this paper, we address this problem by proposing a face shape prior model that is constructed based on the Restricted Boltzmann Machines (RBM) and their variants. Specifically, we first construct a model based on Deep Belief Networks to capture the face shape variations due to varying facial expressions for near-frontal view. To handle pose variations, the frontal face shape prior model is incorporated into a 3-way RBM model that could capture the relationship between frontal face shapes and non-frontal face shapes. Finally, we introduce methods to systematically combine the face shape prior models with image measurements of facial feature points. Experiments on benchmark databases show that with the proposed method, facial feature points can be tracked robustly and accurately even if faces have significant facial expressions and poses. version:1
arxiv-1709-05729 | Flexible Computing Services for Comparisons and Analyses of Classical Chinese Poetry | http://arxiv.org/abs/1709.05729 | id:1709.05729 author:Chao-Lin Liu category:cs.CL cs.DL  published:2017-09-18 summary:We collect nine corpora of representative Chinese poetry for the time span of 1046 BCE and 1644 CE for studying the history of Chinese words, collocations, and patterns. By flexibly integrating our own tools, we are able to provide new perspectives for approaching our goals. We illustrate the ideas with two examples. The first example show a new way to compare word preferences of poets, and the second example demonstrates how we can utilize our corpora in historical studies of the Chinese words. We show the viability of the tools for academic research, and we wish to make it helpful for enriching existing Chinese dictionary as well. version:1
arxiv-1709-05725 | FlashProfile: Interactive Synthesis of Syntactic Profiles | http://arxiv.org/abs/1709.05725 | id:1709.05725 author:Saswat Padhi, Prateek Jain, Daniel Perelman, Oleksandr Polozov, Sumit Gulwani, Todd Millstein category:cs.LG  published:2017-09-17 summary:We address the problem of learning comprehensive syntactic profiles for a set of strings. Real-world datasets, typically curated from multiple sources, often contain data in various formats. Thus any data processing task is preceded by the critical step of data format identification. However, manual inspection of data to identify various formats is infeasible in standard big-data scenarios. We present a technique for generating comprehensive syntactic profiles in terms of user-defined patterns that also allows for interactive refinement. We define a syntactic profile as a set of succinct patterns that describe the entire dataset. Our approach efficiently learns such profiles, and allows refinement by exposing a desired number of patterns. Our implementation, FlashProfile, shows a median profiling time of 0.7s over 142 tasks on 74 real datasets. We also show that access to the generated data profiles allow for more accurate synthesis of programs, using fewer examples in programming-by-example workflows. version:1
arxiv-1709-05707 | Nonparametric Shape-restricted Regression | http://arxiv.org/abs/1709.05707 | id:1709.05707 author:Adityanand Guntuboyina, Bodhisattva Sen category:math.ST stat.ML stat.TH  published:2017-09-17 summary:We consider the problem of nonparametric regression under shape constraints. The main examples include isotonic regression (with respect to any partial order), unimodal/convex regression, additive shape-restricted regression, and constrained single index model. We review some of the theoretical properties of the least squares estimator (LSE) in these problems, emphasizing on the adaptive nature of the LSE. In particular, we study the risk behavior of the LSE, and its pointwise limiting distribution theory, with special emphasis to isotonic regression. We survey various methods for constructing pointwise confidence intervals around these shape-restricted functions. We also briefly discuss the computation of the LSE and indicate some open research problems and future directions. version:1
arxiv-1710-01216 | Group Affect Prediction Using Emotion Heatmaps and Scene Information | http://arxiv.org/abs/1710.01216 | id:1710.01216 author:Saqib Shamsi, Bhanu Pratap Singh Rawat, Manya Wadhwa category:cs.CV  published:2017-09-17 summary:In this paper, we describe our work on emotion detection for a group of people in an image. We use an ensemble of a Convolutional Neutral Network (CNN) trained on the emotion heatmaps and a fine-tuned CNN which had been trained on ImageNet data. This work was done for Emotion Recognition in in the Wild (EmotiW) challenge, 2017. Our best submission achieved a test accuracy of 70.64% which was 17.02% above the baseline accuracy provided by the organizers. version:1
arxiv-1709-05700 | MERF: Morphology-based Entity and Relational Entity Extraction Framework for Arabic | http://arxiv.org/abs/1709.05700 | id:1709.05700 author:Amin A. Jaber, Fadi A. Zaraket category:cs.IR cs.CL  published:2017-09-17 summary:Rule-based techniques and tools to extract entities and relational entities from documents allow users to specify desired entities using natural language questions, finite state automata, regular expressions, structured query language statements, or proprietary scripts. These techniques and tools require expertise in linguistics and programming and lack support of Arabic morphological analysis which is key to process Arabic text. In this work, we present MERF; a morphology-based entity and relational entity extraction framework for Arabic text. MERF provides a user-friendly interface where the user, with basic knowledge of linguistic features and regular expressions, defines tag types and interactively associates them with regular expressions defined over Boolean formulae. Boolean formulae range over matches of Arabic morphological features, and synonymity features. Users define user defined relations with tuples of subexpression matches and can associate code actions with subexpressions. MERF computes feature matches, regular expression matches, and constructs entities and relational entities from user defined relations. We evaluated our work with several case studies and compared with existing application-specific techniques. The results show that MERF requires shorter development time and effort compared to existing techniques and produces reasonably accurate results within a reasonable overhead in run time. version:1
arxiv-1709-05675 | Organizing Multimedia Data in Video Surveillance Systems Based on Face Verification with Convolutional Neural Networks | http://arxiv.org/abs/1709.05675 | id:1709.05675 author:Anastasiia D. Sokolova, Angelina S. Kharchevnikova, Andrey V. Savchenko category:cs.CV 68T10  68T45 I.4.8; I.5.4  published:2017-09-17 summary:In this paper we propose the two-stage approach of organizing information in video surveillance systems. At first, the faces are detected in each frame and a video stream is split into sequences of frames with face region of one person. Secondly, these sequences (tracks) that contain identical faces are grouped using face verification algorithms and hierarchical agglomerative clustering. Gender and age are estimated for each cluster (person) in order to facilitate the usage of the organized video collection. The particular attention is focused on the aggregation of features extracted from each frame with the deep convolutional neural networks. The experimental results of the proposed approach using YTF and IJB-A datasets demonstrated that the most accurate and fast solution is achieved for matching of normalized average of feature vectors of all frames in a track. version:1
arxiv-1709-05673 | Semi-supervised learning | http://arxiv.org/abs/1709.05673 | id:1709.05673 author:Alejandro Cholaquidis, Ricardo Fraiman, Mariela Sued category:math.ST stat.ML stat.TH  published:2017-09-17 summary:Semi-supervised learning deals with the problem of how, if possible, to take advantage of a huge amount of not classified data, to perform classification, in situations when, typically, the labelled data are few. Even though this is not always possible (it depends on how useful is to know the distribution of the unlabelled data in the inference of the labels), several algorithm have been proposed recently. A new algorithm is proposed, that under almost neccesary conditions, attains asymptotically the performance of the best theoretical rule, when the size of unlabeled data tends to infinity. The set of necessary assumptions, although reasonables, show that semi-parametric classification only works for very well conditioned problems. version:1
arxiv-1709-05672 | Neural Affine Grayscale Image Denoising | http://arxiv.org/abs/1709.05672 | id:1709.05672 author:Sungmin Cha, Taesup Moon category:cs.CV cs.LG  published:2017-09-17 summary:We propose a new grayscale image denoiser, dubbed as Neural Affine Image Denoiser (Neural AIDE), which utilizes neural network in a novel way. Unlike other neural network based image denoising methods, which typically apply simple supervised learning to learn a mapping from a noisy patch to a clean patch, we formulate to train a neural network to learn an \emph{affine} mapping that gets applied to a noisy pixel, based on its context. Our formulation enables both supervised training of the network from the labeled training dataset and adaptive fine-tuning of the network parameters using the given noisy image subject to denoising. The key tool for devising Neural AIDE is to devise an estimated loss function of the MSE of the affine mapping, solely based on the noisy data. As a result, our algorithm can outperform most of the recent state-of-the-art methods in the standard benchmark datasets. Moreover, our fine-tuning method can nicely overcome one of the drawbacks of the patch-level supervised learning methods in image denoising; namely, a supervised trained model with a mismatched noise variance can be mostly corrected as long as we have the matched noise variance during the fine-tuning step. version:1
arxiv-1709-05669 | An Improved Fatigue Detection System Based on Behavioral Characteristics of Driver | http://arxiv.org/abs/1709.05669 | id:1709.05669 author:Rajat Gupta, Kanishk Aman, Nalin Shiva, Yadvendra Singh category:cs.CV  published:2017-09-17 summary:In recent years, road accidents have increased significantly. One of the major reasons for these accidents, as reported is driver fatigue. Due to continuous and longtime driving, the driver gets exhausted and drowsy which may lead to an accident. Therefore, there is a need for a system to measure the fatigue level of driver and alert him when he/she feels drowsy to avoid accidents. Thus, we propose a system which comprises of a camera installed on the car dashboard. The camera detect the driver's face and observe the alteration in its facial features and uses these features to observe the fatigue level. Facial features include eyes and mouth. Principle Component Analysis is thus implemented to reduce the features while minimizing the amount of information lost. The parameters thus obtained are processed through Support Vector Classifier for classifying the fatigue level. After that classifier output is sent to the alert unit. version:1
arxiv-1709-05667 | Bayesian nonparametric Principal Component Analysis | http://arxiv.org/abs/1709.05667 | id:1709.05667 author:Clément Elvira, Pierre Chainais, Nicolas Dobigeon category:stat.ML  published:2017-09-17 summary:Principal component analysis (PCA) is very popular to perform dimension reduction. The selection of the number of significant components is essential but often based on some practical heuristics depending on the application. Only few works have proposed a probabilistic approach able to infer the number of significant components. To this purpose, this paper introduces a Bayesian nonparametric principal component analysis (BNP-PCA). The proposed model projects observations onto a random orthogonal basis which is assigned a prior distribution defined on the Stiefel manifold. The prior on factor scores involves an Indian buffet process to model the uncertainty related to the number of components. The parameters of interest as well as the nuisance parameters are finally inferred within a fully Bayesian framework via Monte Carlo sampling. A study of the (in-)consistence of the marginal maximum a posteriori estimator of the latent dimension is carried out. A new estimator of the subspace dimension is proposed. Moreover, for sake of statistical significance, a Kolmogorov-Smirnov test based on the posterior distribution of the principal components is used to refine this estimate. The behaviour of the algorithm is first studied on various synthetic examples. Finally, the proposed BNP dimension reduction approach is shown to be easily yet efficiently coupled with clustering or latent factor models within a unique framework. version:1
arxiv-1709-05665 | Automatic Tool Landmark Detection for Stereo Vision in Robot-Assisted Retinal Surgery | http://arxiv.org/abs/1709.05665 | id:1709.05665 author:Thomas Probst, Kevis-Kokitsi Maninis, Ajad Chhatkuli, Mouloud Ourak, Emmanuel Vander Poorten, Luc Van Gool category:cs.CV  published:2017-09-17 summary:Computer vision and robotics are being increasingly applied in medical interventions. Especially in interventions where extreme precision is required they could make a difference. One such application is robot-assisted retinal microsurgery. In recent works, such interventions are conducted under a stereo-microscope, and with a robot-controlled surgical tool. The complementarity of computer vision and robotics has however not yet been fully exploited. In order to improve the robot control we are interested in 3D reconstruction of the anatomy and in automatic tool localization using a stereo microscope. In this paper, we solve this problem for the first time using a single pipeline, starting from uncalibrated cameras to reach metric 3D reconstruction and registration, in retinal microsurgery. The key ingredients of our method are: (a) surgical tool landmark detection, and (b) 3D reconstruction with the stereo microscope, using the detected landmarks. To address the former, we propose a novel deep learning method that detects and recognizes keypoints in high definition images at higher than real-time speed. We use the detected 2D keypoints along with their corresponding 3D coordinates obtained from the robot sensors to calibrate the stereo microscope using an affine projection model. We design an online 3D reconstruction pipeline that makes use of smoothness constraints and performs robot-to-camera registration. The entire pipeline is extensively validated on open-sky porcine eye sequences. Quantitative and qualitative results are presented for all steps. version:1
arxiv-1709-01688 | Group-level Emotion Recognition using Transfer Learning from Face Identification | http://arxiv.org/abs/1709.01688 | id:1709.01688 author:Alexandr G. Rassadin, Alexey S. Gruzdev, Andrey V. Savchenko category:cs.CV 68T10  68T45 I.4.8; I.5.4  published:2017-09-06 summary:In this paper, we describe our algorithmic approach, which was used for submissions in the fifth Emotion Recognition in the Wild (EmotiW 2017) group-level emotion recognition sub-challenge. We extracted feature vectors of detected faces using the Convolutional Neural Network trained for face identification task, rather than traditional pre-training on emotion recognition problems. In the final pipeline an ensemble of Random Forest classifiers was learned to predict emotion score using available training set. In case when the faces have not been detected, one member of our ensemble extracts features from the whole image. During our experimental study, the proposed approach showed the lowest error rate when compared to other explored techniques. In particular, we achieved 75.4% accuracy on the validation data, which is 20% higher than the handcrafted feature-based baseline. The source code using Keras framework is to be made publicly available. version:2
arxiv-1709-04518 | Saliency Transformation Network: Incorporating Multi-stage Visual Cues for Pancreas Segmentation | http://arxiv.org/abs/1709.04518 | id:1709.04518 author:Qihang Yu, Lingxi Xie, Yan Wang, Yuyin Zhou, Elliot K. Fishman, Alan L. Yuille category:cs.CV  published:2017-09-13 summary:We aim at segmenting small organs (e.g., the pancreas) from abdominal CT scans. As the target often occupies a relatively small region in the input image, deep neural networks can be easily confused by the complex and variable background. To alleviate this, researchers proposed a coarse-to-fine approach (Zhou et al. 2016), which used prediction from the coarse stage to shrink the input region provided to the fine stage. Although this strategy achieves high accuracy, we note that the coarse-scaled and fine-scaled networks were trained and tested individually, which limited the use of multi-stage visual cues for segmentation. This paper presents a Saliency Transformation Network, which contains a trainable saliency transformation module. This module computes spatial weights from the coarse-scaled segmentation score map, and applies them to the fine-scaled input image. In training, the coarse-scaled and fine-scaled segmentation networks are optimized in a joint manner, so that both networks become more powerful when they are evaluated individually. In testing, this strategy makes full use of the segmentation results at the coarse stage, so that we can deliver complementary information to the fine stage rather than merely providing a bounding box. We perform experiments on the NIH pancreas segmentation dataset with 82 CT volumes. Following the same testing process which involves a coarse-to-fine iteration, our approach outperforms the state-of-the-art approach (trained in a stage-wise manner) by an average of over 2%. In addition, our approach enjoys better convergence properties, making it more reliable in practice. version:2
arxiv-1710-01215 | The Cafe Wall Illusion: Local and Global Perception from multiple scale to multiscale | http://arxiv.org/abs/1710.01215 | id:1710.01215 author:Nasim Nematzadeh, David M. W. Powers category:cs.CV  published:2017-09-17 summary:Geometrical illusions are a subclass of optical illusions in which the geometrical characteristics of patterns such as orientations and angles are distorted and misperceived as the result of low- to high-level retinal/cortical processing. Modelling the detection of tilt in these illusions and their strengths as they are perceived is a challenging task computationally and leads to development of techniques that match with human performance. In this study, we present a predictive and quantitative approach for modeling foveal and peripheral vision in the induced tilt in Caf\'e Wall illusion in which parallel mortar lines between shifted rows of black and white tiles appear to converge and diverge. A bioderived filtering model for the responses of retinal/cortical simple cells to the stimulus using Difference of Gaussians is utilized with an analytic processing pipeline introduced in our previous studies to quantify the angle of tilt in the model. Here we have considered visual characteristics of foveal and peripheral vision in the perceived tilt in the pattern to predict different degrees of tilt in different areas of the fovea and periphery as the eye saccades to different parts of the image. The tilt analysis results from several sampling sizes and aspect ratios, modelling variant foveal views are used from our previous investigations on the local tilt, and we specifically investigate in this work, different configurations of the whole pattern modelling variant Gestalt views across multiple scales in order to provide confidence intervals around the predicted tilts. The foveal sample sets are verified and quantified using two different sampling methods. We present here a precise and quantified comparison contrasting local tilt detection in the foveal sets with a global average across all of the Caf\'e Wall configurations tested in this work. version:1
arxiv-1709-05612 | Multi-Entity Dependence Learning with Rich Context via Conditional Variational Auto-encoder | http://arxiv.org/abs/1709.05612 | id:1709.05612 author:Luming Tang, Yexiang Xue, Di Chen, Carla P. Gomes category:cs.LG stat.ML  published:2017-09-17 summary:Multi-Entity Dependence Learning (MEDL) explores conditional correlations among multiple entities. The availability of rich contextual information requires a nimble learning scheme that tightly integrates with deep neural networks and has the ability to capture correlation structures among exponentially many outcomes. We propose MEDL_CVAE, which encodes a conditional multivariate distribution as a generating process. As a result, the variational lower bound of the joint likelihood can be optimized via a conditional variational auto-encoder and trained end-to-end on GPUs. Our MEDL_CVAE was motivated by two real-world applications in computational sustainability: one studies the spatial correlation among multiple bird species using the eBird data and the other models multi-dimensional landscape composition and human footprint in the Amazon rainforest with satellite images. We show that MEDL_CVAE captures rich dependency structures, scales better than previous methods, and further improves on the joint likelihood taking advantage of very large datasets that are beyond the capacity of previous methods. version:1
arxiv-1707-00409 | Deep Ranking Model by Large Adaptive Margin Learning for Person Re-identification | http://arxiv.org/abs/1707.00409 | id:1707.00409 author:Jiayun Wang, Sanping Zhou, Jinjun Wang, Qiqi Hou category:cs.CV  published:2017-07-03 summary:Person re-identification aims to match images of the same person across disjoint camera views, which is a challenging problem in video surveillance. The major challenge of this task lies in how to preserve the similarity of the same person against large variations caused by complex backgrounds, mutual occlusions and different illuminations, while discriminating the different individuals. In this paper, we present a novel deep ranking model with feature learning and fusion by learning a large adaptive margin between the intra-class distance and inter-class distance to solve the person re-identification problem. Specifically, we organize the training images into a batch of pairwise samples. Treating these pairwise samples as inputs, we build a novel part-based deep convolutional neural network (CNN) to learn the layered feature representations by preserving a large adaptive margin. As a result, the final learned model can effectively find out the matched target to the anchor image among a number of candidates in the gallery image set by learning discriminative and stable feature representations. Overcoming the weaknesses of conventional fixed-margin loss functions, our adaptive margin loss function is more appropriate for the dynamic feature space. On four benchmark datasets, PRID2011, Market1501, CUHK01 and 3DPeS, we extensively conduct comparative evaluations to demonstrate the advantages of the proposed method over the state-of-the-art approaches in person re-identification. version:2
arxiv-1709-05602 | Learning Mixtures of Multi-Output Regression Models by Correlation Clustering for Multi-View Data | http://arxiv.org/abs/1709.05602 | id:1709.05602 author:Eric Lei, Kyle Miller, Artur Dubrawski category:stat.ML cs.LG  published:2017-09-17 summary:In many datasets, different parts of the data may have their own patterns of correlation, a structure that can be modeled as a mixture of local linear correlation models. The task of finding these mixtures is known as correlation clustering. In this work, we propose a linear correlation clustering method for datasets whose features are pre-divided into two views. The method, called Canonical Least Squares (CLS) clustering, is inspired by multi-output regression and Canonical Correlation Analysis. CLS clusters can be interpreted as variations in the regression relationship between the two views. The method is useful for data mining and data interpretation. Its utility is demonstrated on a synthetic dataset and stock market dataset. version:1
arxiv-1709-05599 | Hierarchical Gated Recurrent Neural Tensor Network for Answer Triggering | http://arxiv.org/abs/1709.05599 | id:1709.05599 author:Wei Li, Yunfang Wu category:cs.CL  published:2017-09-17 summary:In this paper, we focus on the problem of answer triggering ad-dressed by Yang et al. (2015), which is a critical component for a real-world question answering system. We employ a hierarchical gated recurrent neural tensor (HGRNT) model to capture both the context information and the deep in-teractions between the candidate answers and the question. Our result on F val-ue achieves 42.6%, which surpasses the baseline by over 10 %. version:1
arxiv-1704-00253 | Building a Neural Machine Translation System Using Only Synthetic Parallel Data | http://arxiv.org/abs/1704.00253 | id:1704.00253 author:Jaehong Park, Jongyoon Song, Sungroh Yoon category:cs.CL  published:2017-04-02 summary:Recent works have shown that synthetic parallel data automatically generated by translation models can be effective for various neural machine translation (NMT) issues. In this study, we build NMT systems using only synthetic parallel data. As an efficient alternative to real parallel data, we also present a new type of synthetic parallel corpus. The proposed pseudo parallel data are distinct from previous works in that ground truth and synthetic examples are mixed on both sides of sentence pairs. Experiments on Czech-German and French-German translations demonstrate the efficacy of the proposed pseudo parallel corpus, which shows not only enhanced results for bidirectional translation tasks but also substantial improvement with the aid of a ground truth real parallel corpus. version:4
arxiv-1709-05587 | Character Distributions of Classical Chinese Literary Texts: Zipf's Law, Genres, and Epochs | http://arxiv.org/abs/1709.05587 | id:1709.05587 author:Chao-Lin Liu, Shuhua Zhang, Yuanli Geng, Huei-ling Lai, Hongsu Wang category:cs.CL cs.DL  published:2017-09-17 summary:We collect 14 representative corpora for major periods in Chinese history in this study. These corpora include poetic works produced in several dynasties, novels of the Ming and Qing dynasties, and essays and news reports written in modern Chinese. The time span of these corpora ranges between 1046 BCE and 2007 CE. We analyze their character and word distributions from the viewpoint of the Zipf's law, and look for factors that affect the deviations and similarities between their Zipfian curves. Genres and epochs demonstrated their influences in our analyses. Specifically, the character distributions for poetic works of between 618 CE and 1644 CE exhibit striking similarity. In addition, although texts of the same dynasty may tend to use the same set of characters, their character distributions still deviate from each other. version:1
arxiv-1709-05583 | Mitigating Evasion Attacks to Deep Neural Networks via Region-based Classification | http://arxiv.org/abs/1709.05583 | id:1709.05583 author:Xiaoyu Cao, Neil Zhenqiang Gong category:cs.CR cs.LG stat.ML  published:2017-09-17 summary:Deep neural networks (DNNs) have transformed several artificial intelligence research areas including computer vision, speech recognition, and natural language processing. However, recent studies demonstrated that DNNs are vulnerable to adversarial manipulations at testing time. Specifically, suppose we have a testing example, whose label can be correctly predicted by a DNN classifier. An attacker can add a small carefully crafted noise to the testing example such that the DNN classifier predicts an incorrect label, where the crafted testing example is called adversarial example. Such attacks are called evasion attacks. Evasion attacks are one of the biggest challenges for deploying DNNs in safety and security critical applications such as self-driving cars. In this work, we develop new DNNs that are robust to state-of-the-art evasion attacks. Our key observation is that adversarial examples are close to the classification boundary. Therefore, we propose region-based classification to be robust to adversarial examples. Specifically, for a benign/adversarial testing example, we ensemble information in a hypercube centered at the example to predict its label. In contrast, traditional classifiers are point-based classification, i.e., given a testing example, the classifier predicts its label based on the testing example alone. Our evaluation results on MNIST and CIFAR-10 datasets demonstrate that our region-based classification can significantly mitigate evasion attacks without sacrificing classification accuracy on benign examples. Specifically, our region-based classification achieves the same classification accuracy on testing benign examples as point-based classification, but our region-based classification is significantly more robust than point-based classification to state-of-the-art evasion attacks. version:1
arxiv-1709-05563 | Data Innovation for International Development: An overview of natural language processing for qualitative data analysis | http://arxiv.org/abs/1709.05563 | id:1709.05563 author:Philipp Broniecki, Anna Hanchar, Slava J. Mikhaylov category:cs.CL  published:2017-09-16 summary:Availability, collection and access to quantitative data, as well as its limitations, often make qualitative data the resource upon which development programs heavily rely. Both traditional interview data and social media analysis can provide rich contextual information and are essential for research, appraisal, monitoring and evaluation. These data may be difficult to process and analyze both systematically and at scale. This, in turn, limits the ability of timely data driven decision-making which is essential in fast evolving complex social systems. In this paper, we discuss the potential of using natural language processing to systematize analysis of qualitative data, and to inform quick decision-making in the development context. We illustrate this with interview data generated in a format of micro-narratives for the UNDP Fragments of Impact project. version:1
arxiv-1709-05559 | Nonnegative HMM for Babble Noise Derived from Speech HMM: Application to Speech Enhancement | http://arxiv.org/abs/1709.05559 | id:1709.05559 author:Nasser Mohammadiha, Arne Leijon category:cs.SD cs.LG  published:2017-09-16 summary:Deriving a good model for multitalker babble noise can facilitate different speech processing algorithms, e.g. noise reduction, to reduce the so-called cocktail party difficulty. In the available systems, the fact that the babble waveform is generated as a sum of N different speech waveforms is not exploited explicitly. In this paper, first we develop a gamma hidden Markov model for power spectra of the speech signal, and then formulate it as a sparse nonnegative matrix factorization (NMF). Second, the sparse NMF is extended by relaxing the sparsity constraint, and a novel model for babble noise (gamma nonnegative HMM) is proposed in which the babble basis matrix is the same as the speech basis matrix, and only the activation factors (weights) of the basis vectors are different for the two signals over time. Finally, a noise reduction algorithm is proposed using the derived speech and babble models. All of the stationary model parameters are estimated using the expectation-maximization (EM) algorithm, whereas the time-varying parameters, i.e. the gain parameters of speech and babble signals, are estimated using a recursive EM algorithm. The objective and subjective listening evaluations show that the proposed babble model and the final noise reduction algorithm significantly outperform the conventional methods. version:1
arxiv-1709-05557 | Speech Dereverberation Using Nonnegative Convolutive Transfer Function and Spectro temporal Modeling | http://arxiv.org/abs/1709.05557 | id:1709.05557 author:Nasser Mohammadiha, Simon Doclo category:cs.SD cs.LG  published:2017-09-16 summary:This paper presents two single channel speech dereverberation methods to enhance the quality of speech signals that have been recorded in an enclosed space. For both methods, the room acoustics are modeled using a nonnegative approximation of the convolutive transfer function (NCTF), and to additionally exploit the spectral properties of the speech signal, such as the low rank nature of the speech spectrogram, the speech spectrogram is modeled using nonnegative matrix factorization (NMF). Two methods are described to combine the NCTF and NMF models. In the first method, referred to as the integrated method, a cost function is constructed by directly integrating the speech NMF model into the NCTF model, while in the second method, referred to as the weighted method, the NCTF and NMF based cost functions are weighted and summed. Efficient update rules are derived to solve both optimization problems. In addition, an extension of the integrated method is presented, which exploits the temporal dependencies of the speech signal. Several experiments are performed on reverberant speech signals with and without background noise, where the integrated method yields a considerably higher speech quality than the baseline NCTF method and a state of the art spectral enhancement method. Moreover, the experimental results indicate that the weighted method can even lead to a better performance in terms of instrumental quality measures, but that the optimal weighting parameter depends on the room acoustics and the utilized NMF model. Modeling the temporal dependencies in the integrated method was found to be useful only for highly reverberant conditions. version:1
arxiv-1709-05552 | Multivariate Gaussian Network Structure Learning | http://arxiv.org/abs/1709.05552 | id:1709.05552 author:Xingqi Du, Subhashis Ghosal category:stat.ML  published:2017-09-16 summary:We consider a graphical model where a multivariate normal vector is associated with each node of the underlying graph and estimate the graphical structure. We minimize a loss function obtained by regressing the vector at each node on those at the remaining ones under a group penalty. We show that the proposed estimator can be computed by a fast convex optimization algorithm. We show that as the sample size increases, the estimated regression coefficients and the correct graphical structure are correctly estimated with probability tending to one. By extensive simulations, we show the superiority of the proposed method over comparable procedures. We apply the technique on two real datasets. The first one is to identify gene and protein networks showing up in cancer cell lines, and the second one is to reveal the connections among different industries in the US. version:1
arxiv-1709-05548 | Forecasting of commercial sales with large scale Gaussian Processes | http://arxiv.org/abs/1709.05548 | id:1709.05548 author:Rodrigo Rivera, Evgeny Burnaev category:stat.AP stat.ML  published:2017-09-16 summary:This paper argues that there has not been enough discussion in the field of applications of Gaussian Process for the fast moving consumer goods industry. Yet, this technique can be important as it e.g., can provide automatic feature relevance determination and the posterior mean can unlock insights on the data. Significant challenges are the large size and high dimensionality of commercial data at a point of sale. The study reviews approaches in the Gaussian Processes modeling for large data sets, evaluates their performance on commercial sales and shows value of this type of models as a decision-making tool for management. version:1
arxiv-1709-05538 | DeepLung: 3D Deep Convolutional Nets for Automated Pulmonary Nodule Detection and Classification | http://arxiv.org/abs/1709.05538 | id:1709.05538 author:Wentao Zhu, Chaochun Liu, Wei Fan, Xiaohui Xie category:cs.CV cs.LG cs.NE  published:2017-09-16 summary:In this work, we present a fully automated lung CT cancer diagnosis system, DeepLung. DeepLung contains two parts, nodule detection and classification. Considering the 3D nature of lung CT data, two 3D networks are designed for the nodule detection and classification respectively. Specifically, a 3D Faster R-CNN is designed for nodule detection with a U-net-like encoder-decoder structure to effectively learn nodule features. For nodule classification, gradient boosting machine (GBM) with 3D dual path network (DPN) features is proposed. The nodule classification subnetwork is validated on a public dataset from LIDC-IDRI, on which it achieves better performance than state-of-the-art approaches, and surpasses the average performance of four experienced doctors. For the DeepLung system, candidate nodules are detected first by the nodule detection subnetwork, and nodule diagnosis is conducted by the classification subnetwork. Extensive experimental results demonstrate the DeepLung is comparable to the experienced doctors both for the nodule-level and patient-level diagnosis on the LIDC-IDRI dataset. version:1
arxiv-1709-05522 | AISHELL-1: An Open-Source Mandarin Speech Corpus and A Speech Recognition Baseline | http://arxiv.org/abs/1709.05522 | id:1709.05522 author:Hui Bu, Jiayu Du, Xingyu Na, Bengu Wu, Hao Zheng category:cs.CL  published:2017-09-16 summary:An open-source Mandarin speech corpus called AISHELL-1 is released. It is by far the largest corpus which is suitable for conducting the speech recognition research and building speech recognition systems for Mandarin. The recording procedure, including audio capturing devices and environments are presented in details. The preparation of the related resources, including transcriptions and lexicon are described. The corpus is released with a Kaldi recipe. Experimental results implies that the quality of audio recordings and transcriptions are promising. version:1
arxiv-1709-05515 | Some variations on Random Survival Forest with application to Cancer Research | http://arxiv.org/abs/1709.05515 | id:1709.05515 author:Arabin Kumar Dey, Anshul Juneja category:stat.ME stat.AP stat.CO stat.ML  published:2017-09-16 summary:Random survival forest can be extremely time consuming for large data set. In this paper we propose few computationally efficient algorithms in prediction of survival function. We explore the behavior of the algorithms for different cancer data sets. Our construction includes right censoring data too. We have also applied the same for competing risk survival function. version:1
arxiv-1709-05510 | The Geometric Block Model | http://arxiv.org/abs/1709.05510 | id:1709.05510 author:Sainyam Galhotra, Arya Mazumdar, Soumyabrata Pal, Barna Saha category:cs.SI cs.DS stat.ML E.1  published:2017-09-16 summary:To capture the inherent geometric features of many community detection problems, we propose to use a new random graph model of communities that we call a Geometric Block Model. The geometric block model generalizes the random geometric graphs in the same way that the well-studied stochastic block model generalizes the Erdos-Renyi random graphs. It is also a natural extension of random community models inspired by the recent theoretical and practical advancement in community detection. While being a topic of fundamental theoretical interest, our main contribution is to show that many practical community structures are better explained by the geometric block model. We also show that a simple triangle-counting algorithm to detect communities in the geometric block model is near-optimal. Indeed, even in the regime where the average degree of the graph grows only logarithmically with the number of vertices (sparse-graph), we show that this algorithm performs extremely well, both theoretically and practically. In contrast, the triangle-counting algorithm is far from being optimum for the stochastic block model. We simulate our results on both real and synthetic datasets to show superior performance of both the new model as well as our algorithm. version:1
arxiv-1709-05495 | The Multiscale Bowler-Hat Transform for Blood Vessel Enhancement in Retinal Images | http://arxiv.org/abs/1709.05495 | id:1709.05495 author:Çiğdem Sazak, Carl J. Nelson, Boguslaw Obara category:cs.CV  published:2017-09-16 summary:Enhancement, followed by segmentation, quantification and modelling, of blood vessels in retinal images plays an essential role in computer-aid retinopathy diagnosis. In this paper, we introduce a new vessel enhancement method which is the bowler-hat transform based on mathematical morphology. The proposed method combines different structuring elements to detect innate features of vessel-like structures. We evaluate the proposed method qualitatively and quantitatively, and compare it with the existing, state-of-the-art methods using both synthetic and real datasets. Our results show that the proposed method achieves high-quality vessel-like structure enhancement in both synthetic examples and in clinically relevant retinal images, and is shown to be able to detect fine vessels while remaining robust at junctions. version:1
arxiv-1709-06079 | Orthogonal Weight Normalization: Solution to Optimization over Multiple Dependent Stiefel Manifolds in Deep Neural Networks | http://arxiv.org/abs/1709.06079 | id:1709.06079 author:Lei Huang, Xianglong Liu, Bo Lang, Adams Wei Yu, Bo Li category:cs.LG  published:2017-09-16 summary:Orthogonal matrix has shown advantages in training Recurrent Neural Networks (RNNs), but such matrix is limited to be square for the hidden-to-hidden transformation in RNNs. In this paper, we generalize such square orthogonal matrix to orthogonal rectangular matrix and formulating this problem in feed-forward Neural Networks (FNNs) as Optimization over Multiple Dependent Stiefel Manifolds (OMDSM). We show that the rectangular orthogonal matrix can stabilize the distribution of network activations and regularize FNNs. We also propose a novel orthogonal weight normalization method to solve OMDSM. Particularly, it constructs orthogonal transformation over proxy parameters to ensure the weight matrix is orthogonal and back-propagates gradient information through the transformation during training. To guarantee stability, we minimize the distortions between proxy parameters and canonical weights over all tractable orthogonal transformations. In addition, we design an orthogonal linear module (OLM) to learn orthogonal filter banks in practice, which can be used as an alternative to standard linear module. Extensive experiments demonstrate that by simply substituting OLM for standard linear module without revising any experimental protocols, our method largely improves the performance of the state-of-the-art networks, including Inception and residual networks on CIFAR and ImageNet datasets. In particular, we have reduced the test error of wide residual network on CIFAR-100 from 20.04% to 18.61% with such simple substitution. Our code is available online for result reproduction. version:1
arxiv-1709-05487 | Role of Morphology Injection in Statistical Machine Translation | http://arxiv.org/abs/1709.05487 | id:1709.05487 author:Sreelekha S, Pushpak Bhattacharyya category:cs.CL  published:2017-09-16 summary:Phrase-based Statistical models are more commonly used as they perform optimally in terms of both, translation quality and complexity of the system. Hindi and in general all Indian languages are morphologically richer than English. Hence, even though Phrase-based systems perform very well for the less divergent language pairs, for English to Indian language translation, we need more linguistic information (such as morphology, parse tree, parts of speech tags, etc.) on the source side. Factored models seem to be useful in this case, as Factored models consider word as a vector of factors. These factors can contain any information about the surface word and use it while translating. Hence, the objective of this work is to handle morphological inflections in Hindi and Marathi using Factored translation models while translating from English. SMT approaches face the problem of data sparsity while translating into a morphologically rich language. It is very unlikely for a parallel corpus to contain all morphological forms of words. We propose a solution to generate these unseen morphological forms and inject them into original training corpora. In this paper, we study factored models and the problem of sparseness in context of translation to morphologically rich languages. We propose a simple and effective solution which is based on enriching the input with various morphological forms of words. We observe that morphology injection improves the quality of translation in terms of both adequacy and fluency. We verify this with the experiments on two morphologically rich languages: Hindi and Marathi, while translating from English. version:1
arxiv-1709-05480 | Subset Labeled LDA for Large-Scale Multi-Label Classification | http://arxiv.org/abs/1709.05480 | id:1709.05480 author:Yannis Papanikolaou, Grigorios Tsoumakas category:stat.ML cs.LG  published:2017-09-16 summary:Labeled Latent Dirichlet Allocation (LLDA) is an extension of the standard unsupervised Latent Dirichlet Allocation (LDA) algorithm, to address multi-label learning tasks. Previous work has shown it to perform in par with other state-of-the-art multi-label methods. Nonetheless, with increasing label sets sizes LLDA encounters scalability issues. In this work, we introduce Subset LLDA, a simple variant of the standard LLDA algorithm, that not only can effectively scale up to problems with hundreds of thousands of labels but also improves over the LLDA state-of-the-art. We conduct extensive experiments on eight data sets, with label sets sizes ranging from hundreds to hundreds of thousands, comparing our proposed algorithm with the previously proposed LLDA algorithms (Prior--LDA, Dep--LDA), as well as the state of the art in extreme multi-label classification. The results show a steady advantage of our method over the other LLDA algorithms and competitive results compared to the extreme multi-label classification algorithms. version:1
arxiv-1709-05475 | Order-Preserving Abstractive Summarization for Spoken Content Based on Connectionist Temporal Classification | http://arxiv.org/abs/1709.05475 | id:1709.05475 author:Bo-Ru Lu, Frank Shyu, Yun-Nung Chen, Hung-Yi Lee, Lin-shan Lee category:cs.CL  published:2017-09-16 summary:Connectionist temporal classification (CTC) is a powerful approach for sequence-to-sequence learning, and has been popularly used in speech recognition. The central ideas of CTC include adding a label "blank" during training. With this mechanism, CTC eliminates the need of segment alignment, and hence has been applied to various sequence-to-sequence learning problems. In this work, we applied CTC to abstractive summarization for spoken content. The "blank" in this case implies the corresponding input data are less important or noisy; thus it can be ignored. This approach was shown to outperform the existing methods in term of ROUGE scores over Chinese Gigaword and MATBN corpora. This approach also has the nice property that the ordering of words or characters in the input documents can be better preserved in the generated summaries. version:1
arxiv-1709-02898 | Learning a Dilated Residual Network for SAR Image Despeckling | http://arxiv.org/abs/1709.02898 | id:1709.02898 author:Qiang Zhang, Zhen Yang, Qiangqiang Yuan, Jie Li, Xiaoshuang Ma, Huanfeng Shen, Liangpei Zhang category:cs.CV  published:2017-09-09 summary:In this letter, to break the limit of the traditional linear models for SAR image despeckling, we propose a novel deep learning approach by learning a non-linear end-to-end mapping between the noisy and clean SAR images with a dilated residual network (SAR-DRN). SAR-DRN is based on dilated convolutions, which can both enlarge the receptive field and maintain the filter size and layer depth with a lightweight structure. In addition, skip connections are added to the despeckling model to reduce the vanishing gradient problem. Compared with the traditional despeckling methods, the proposed method shows superior performance over the state-of-the-art methods on both quantitative and visual assessments, especially for strong speckle noise. version:2
arxiv-1709-05470 | Long-Term Ensemble Learning of Visual Place Classifiers | http://arxiv.org/abs/1709.05470 | id:1709.05470 author:Xiaoxiao Fei, Kanji Tanaka, Yichu Fang, Akitaka Takayama category:cs.CV  published:2017-09-16 summary:This paper addresses the problem of cross-season visual place classification (VPC) from a novel perspective of long-term map learning. Our goal is to enable transfer learning efficiently from one season to the next, at a small constant cost, and without wasting the robot's available long-term-memory by memorizing very large amounts of training data. To realize a good tradeoff between generalization and specialization abilities, we employ an ensemble of convolutional neural network (DCN) classifiers and consider the task of scheduling (when and which classifiers to retrain), given a previous season's DCN classifiers as the sole prior knowledge. We present a unified framework for retraining scheduling and discuss practical implementation strategies. Furthermore, we address the task of partitioning a robot's workspace into places to define place classes in an unsupervised manner, rather than using uniform partitioning, so as to maximize VPC performance. Experiments using the publicly available NCLT dataset revealed that retraining scheduling of a DCN classifier ensemble is crucial and performance is significantly increased by using planned scheduling. version:1
arxiv-1709-06508 | Face Retrieval using Frequency Decoded Local Descriptor | http://arxiv.org/abs/1709.06508 | id:1709.06508 author:Shiv Ram Dubey category:cs.CV  published:2017-09-16 summary:The local descriptors have been the backbone of most of the computer vision problems. Most of the existing local descriptors are generated over the raw input images. In order to increase the discriminative power of the local descriptors, some researchers converted the raw image into multiple images with the help some high and low pass frequency filters, then the local descriptors are computed over each filtered image and finally concatenated into a single descriptor. By doing so, these approaches do not utilize the inter frequency relationship which causes the less improvement in the discriminative power of the descriptor that could be achieved. In this paper, this problem is solved by utilizing the decoder concept of multi-channel decoded local binary pattern over the multi-frequency patterns. A frequency decoded local binary pattern (FDLBP) is proposed with two decoders. Each decoder works with one low frequency pattern and two high frequency pattern. Finally, the descriptors from both decoders are concatenated to form the single descriptor. The face retrieval experiments are conducted over four benchmarks and challenging databases such as PaSC, LFW, PubFig, and ESSEX. The experimental results confirm the superiority of the FDLBP descriptor as compared to the state-of-the-art descriptors such as LBP, SOBEL_LBP, BoF_LBP, SVD_S_LBP, mdLBP, etc. version:1
arxiv-1709-05467 | Acquiring Background Knowledge to Improve Moral Value Prediction | http://arxiv.org/abs/1709.05467 | id:1709.05467 author:Ying Lin, Joe Hoover, Morteza Dehghani, Marlon Mooijman, Heng Ji category:cs.CL cs.CY  published:2017-09-16 summary:In this paper, we address the problem of detecting expressions of moral values in tweets using content analysis. This is a particularly challenging problem because moral values are often only implicitly signaled in language, and tweets contain little contextual information due to length constraints. To address these obstacles, we present a novel approach to automatically acquire background knowledge from an external knowledge base to enrich input texts and thus improve moral value prediction. By combining basic text features with background knowledge, our overall context-aware framework achieves performance comparable to a single human annotator. To the best of our knowledge, this is the first attempt to incorporate background knowledge for the prediction of implicit psychological variables in the area of computational social science. version:1
arxiv-1709-05454 | Statistical inference on random dot product graphs: a survey | http://arxiv.org/abs/1709.05454 | id:1709.05454 author:Avanti Athreya, Donniell E. Fishkind, Keith Levin, Vince Lyzinski, Youngser Park, Yichen Qin, Daniel L. Sussman, Minh Tang, Joshua T. Vogelstein, Carey E. Priebe category:stat.ME math.ST stat.ML stat.TH  published:2017-09-16 summary:The random dot product graph (RDPG) is an independent-edge random graph that is analytically tractable and, simultaneously, either encompasses or can successfully approximate a wide range of random graphs, from relatively simple stochastic block models to complex latent position graphs. In this survey paper, we describe a comprehensive paradigm for statistical inference on random dot product graphs, a paradigm centered on spectral embeddings of adjacency and Laplacian matrices. We examine the analogues, in graph inference, of several canonical tenets of classical Euclidean inference: in particular, we summarize a body of existing results on the consistency and asymptotic normality of the adjacency and Laplacian spectral embeddings, and the role these spectral embeddings can play in the construction of single- and multi-sample hypothesis tests for graph data. We investigate several real-world applications, including community detection and classification in large social networks and the determination of functional and biologically relevant network properties from an exploratory data analysis of the Drosophila connectome. We outline requisite background and current open problems in spectral graph inference. version:1
arxiv-1705-00464 | Speech-Based Visual Question Answering | http://arxiv.org/abs/1705.00464 | id:1705.00464 author:Ted Zhang, Dengxin Dai, Tinne Tuytelaars, Marie-Francine Moens, Luc Van Gool category:cs.CL cs.CV  published:2017-05-01 summary:This paper introduces speech-based visual question answering (VQA), the task of generating an answer given an image and a spoken question. Two methods are studied: an end-to-end, deep neural network that directly uses audio waveforms as input versus a pipelined approach that performs ASR (Automatic Speech Recognition) on the question, followed by text-based visual question answering. Furthermore, we investigate the robustness of both methods by injecting various levels of noise into the spoken question and find both methods to be tolerate noise at similar levels. version:2
arxiv-1709-03741 | Learning Graph-Level Representation for Drug Discovery | http://arxiv.org/abs/1709.03741 | id:1709.03741 author:Junying Li, Deng Cai, Xiaofei He category:cs.LG stat.ML  published:2017-09-12 summary:Predicating macroscopic influences of drugs on human body, like efficacy and toxicity, is a central problem of small-molecule based drug discovery. Molecules can be represented as an undirected graph, and we can utilize graph convolution networks to predication molecular properties. However, graph convolutional networks and other graph neural networks all focus on learning node-level representation rather than graph-level representation. Previous works simply sum all feature vectors for all nodes in the graph to obtain the graph feature vector for drug predication. In this paper, we introduce a dummy super node that is connected with all nodes in the graph by a directed edge as the representation of the graph and modify the graph operation to help the dummy super node learn graph-level feature. Thus, we can handle graph-level classification and regression in the same way as node-level classification and regression. In addition, we apply focal loss to address class imbalance in drug datasets. The experiments on MoleculeNet show that our method can effectively improve the performance of molecular properties predication. version:2
arxiv-1709-06509 | A LBP Based Correspondence Identification Scheme for Multi-view Sensing Network | http://arxiv.org/abs/1709.06509 | id:1709.06509 author:Raghavendra Kandukuri category:cs.CV  published:2017-09-16 summary:In this paper, we describes a correspondence identification method between two-views of regular RGB camera that can be run in real-time. The basic idea is first applying normalized cross correlation to retrieve a sparse set of matching pairs from image pair. Then loopy belief propagation scheme is applied to the the set of possible candidates to densely identify correspondences from different views. The experiment results demonstrate superb accuracy and precision that outperform the state-of-the-art in the computer vision field. Meanwhile, the implementation is simple enough that can be optimized for real-time performance. We have given the detailed comparison of existing approaches and show that this method can enable various practical applications from 3D reconstruction to image search. version:1
arxiv-1709-05433 | Grade Prediction with Temporal Course-wise Influence | http://arxiv.org/abs/1709.05433 | id:1709.05433 author:Zhiyun Ren, Xia Ning, Huzefa Rangwala category:cs.LG  published:2017-09-15 summary:There is a critical need to develop new educational technology applications that analyze the data collected by universities to ensure that students graduate in a timely fashion (4 to 6 years); and they are well prepared for jobs in their respective fields of study. In this paper, we present a novel approach for analyzing historical educational records from a large, public university to perform next-term grade prediction; i.e., to estimate the grades that a student will get in a course that he/she will enroll in the next term. Accurate next-term grade prediction holds the promise for better student degree planning, personalized advising and automated interventions to ensure that students stay on track in their chosen degree program and graduate on time. We present a factorization-based approach called Matrix Factorization with Temporal Course-wise Influence that incorporates course-wise influence effects and temporal effects for grade prediction. In this model, students and courses are represented in a latent "knowledge" space. The grade of a student on a course is modeled as the similarity of their latent representation in the "knowledge" space. Course-wise influence is considered as an additional factor in the grade prediction. Our experimental results show that the proposed method outperforms several baseline approaches and infer meaningful patterns between pairs of courses within academic programs. version:1
arxiv-1709-05424 | NIMA: Neural Image Assessment | http://arxiv.org/abs/1709.05424 | id:1709.05424 author:Hossein Talebi, Peyman Milanfar category:cs.CV  published:2017-09-15 summary:Automatically learned quality assessment for images has recently become a hot topic due to its usefulness in a wide variety of applications such as evaluating image capture pipelines, storage techniques and sharing media. Despite the subjective nature of this problem, most existing methods only predict the mean opinion score provided by datasets such as AVA [1] and TID2013 [2]. Our approach differs from others in that we predict the distribution of human opinion scores using a convolutional neural network. Our architecture also has the advantage of being significantly simpler than other methods with comparable performance. Our proposed approach relies on the success (and retraining) of proven, state-of-the-art deep object recognition networks. Our resulting network can be used to not only score images reliably and with high correlation to human perception, but also to assist with adaptation and optimization of photo editing/enhancement algorithms in a photographic pipeline. All this is done without need of a "golden" reference image, consequently allowing for single-image, semantic- and perceptually-aware, no-reference quality assessment. version:1
arxiv-1709-05418 | Deep Scattering: Rendering Atmospheric Clouds with Radiance-Predicting Neural Networks | http://arxiv.org/abs/1709.05418 | id:1709.05418 author:Simon Kallweit, Thomas Müller, Brian McWilliams, Markus Gross, Jan Novák category:cs.LG cs.GR stat.ML  published:2017-09-15 summary:We present a technique for efficiently synthesizing images of atmospheric clouds using a combination of Monte Carlo integration and neural networks. The intricacies of Lorenz-Mie scattering and the high albedo of cloud-forming aerosols make rendering of clouds---e.g. the characteristic silverlining and the "whiteness" of the inner body---challenging for methods based solely on Monte Carlo integration or diffusion theory. We approach the problem differently. Instead of simulating all light transport during rendering, we pre-learn the spatial and directional distribution of radiant flux from tens of cloud exemplars. To render a new scene, we sample visible points of the cloud and, for each, extract a hierarchical 3D descriptor of the cloud geometry with respect to the shading location and the light source. The descriptor is input to a deep neural network that predicts the radiance function for each shading configuration. We make the key observation that progressively feeding the hierarchical descriptor into the network enhances the network's ability to learn faster and predict with high accuracy while using few coefficients. We also employ a block design with residual connections to further improve performance. A GPU implementation of our method synthesizes images of clouds that are nearly indistinguishable from the reference solution within seconds interactively. Our method thus represents a viable solution for applications such as cloud design and, thanks to its temporal stability, also for high-quality production of animated content. version:1
arxiv-1708-07747 | Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms | http://arxiv.org/abs/1708.07747 | id:1708.07747 author:Han Xiao, Kashif Rasul, Roland Vollgraf category:cs.LG cs.CV stat.ML  published:2017-08-25 summary:We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist version:2
arxiv-1709-05413 | "How May I Help You?": Modeling Twitter Customer Service Conversations Using Fine-Grained Dialogue Acts | http://arxiv.org/abs/1709.05413 | id:1709.05413 author:Shereen Oraby, Pritam Gundecha, Jalal Mahmud, Mansurul Bhuiyan, Rama Akkiraju category:cs.CL  published:2017-09-15 summary:Given the increasing popularity of customer service dialogue on Twitter, analysis of conversation data is essential to understand trends in customer and agent behavior for the purpose of automating customer service interactions. In this work, we develop a novel taxonomy of fine-grained "dialogue acts" frequently observed in customer service, showcasing acts that are more suited to the domain than the more generic existing taxonomies. Using a sequential SVM-HMM model, we model conversation flow, predicting the dialogue act of a given turn in real-time. We characterize differences between customer and agent behavior in Twitter customer service conversations, and investigate the effect of testing our system on different customer service industries. Finally, we use a data-driven approach to predict important conversation outcomes: customer satisfaction, customer frustration, and overall problem resolution. We show that the type and location of certain dialogue acts in a conversation have a significant effect on the probability of desirable and undesirable outcomes, and present actionable rules based on our findings. The patterns and rules we derive can be used as guidelines for outcome-driven automated customer service platforms. version:1
arxiv-1709-05412 | Multi-Agent Distributed Lifelong Learning for Collective Knowledge Acquisition | http://arxiv.org/abs/1709.05412 | id:1709.05412 author:Mohammad Rostami, Soheil Kolouri, Kyungnam Kim, Eric Eaton category:cs.LG  published:2017-09-15 summary:Lifelong machine learning methods acquire knowledge over a series of consecutive tasks, continually building upon their experience. Current lifelong learning algorithms rely upon a single learning agent that has centralized access to all data. In this paper, we extend the idea of lifelong learning from a single agent to a network of multiple agents that collectively learn a series of tasks. Each agent faces some (potentially unique) set of tasks; the key idea is that knowledge learned from these tasks may benefit other agents trying to learn different (but related) tasks. Our Collective Lifelong Learning Algorithm (CoLLA) provides an efficient way for a network of agents to share their learned knowledge in a distributed and decentralized manner, while preserving the privacy of the locally observed data. We provide theoretical guarantees for robust performance of the algorithm and empirically demonstrate that CoLLA outperforms existing approaches for distributed multi-task learning on a variety of data sets. version:1
arxiv-1709-05411 | Combining Search with Structured Data to Create a More Engaging User Experience in Open Domain Dialogue | http://arxiv.org/abs/1709.05411 | id:1709.05411 author:Kevin K. Bowden, Shereen Oraby, Jiaqi Wu, Amita Misra, Marilyn Walker category:cs.CL  published:2017-09-15 summary:The greatest challenges in building sophisticated open-domain conversational agents arise directly from the potential for ongoing mixed-initiative multi-turn dialogues, which do not follow a particular plan or pursue a particular fixed information need. In order to make coherent conversational contributions in this context, a conversational agent must be able to track the types and attributes of the entities under discussion in the conversation and know how they are related. In some cases, the agent can rely on structured information sources to help identify the relevant semantic relations and produce a turn, but in other cases, the only content available comes from search, and it may be unclear which semantic relations hold between the search results and the discourse context. A further constraint is that the system must produce its contribution to the ongoing conversation in real-time. This paper describes our experience building SlugBot for the 2017 Alexa Prize, and discusses how we leveraged search and structured data from different sources to help SlugBot produce dialogic turns and carry on conversations whose length over the semi-finals user evaluation period averaged 8:17 minutes. version:1
arxiv-1709-05409 | Gaussian Process Latent Force Models for Learning and Stochastic Control of Physical Systems | http://arxiv.org/abs/1709.05409 | id:1709.05409 author:Simo Särkkä, Mauricio A. Álvarez, Neil D. Lawrence category:cs.SY math.DS stat.ME stat.ML  published:2017-09-15 summary:This paper is concerned with estimation and stochastic control in physical systems which contain unknown input signals or forces. These unknown signals are modeled as Gaussian processes (GP) in the sense that GP models are used in machine learning. The resulting latent force models (LFMs) can be seen as hybrid models that contain a first-principles physical model part and a non-parametric GP model part. The aim of this paper is to collect and extend the statistical inference and learning methods for this kind of models, provide new theoretical results for the models, and to extend the methodology and theory to stochastic control of LFMs. version:1
arxiv-1709-05404 | Creating and Characterizing a Diverse Corpus of Sarcasm in Dialogue | http://arxiv.org/abs/1709.05404 | id:1709.05404 author:Shereen Oraby, Vrindavan Harrison, Lena Reed, Ernesto Hernandez, Ellen Riloff, Marilyn Walker category:cs.CL  published:2017-09-15 summary:The use of irony and sarcasm in social media allows us to study them at scale for the first time. However, their diversity has made it difficult to construct a high-quality corpus of sarcasm in dialogue. Here, we describe the process of creating a large- scale, highly-diverse corpus of online debate forums dialogue, and our novel methods for operationalizing classes of sarcasm in the form of rhetorical questions and hyperbole. We show that we can use lexico-syntactic cues to reliably retrieve sarcastic utterances with high accuracy. To demonstrate the properties and quality of our corpus, we conduct supervised learning experiments with simple features, and show that we achieve both higher precision and F than previous work on sarcasm in debate forums dialogue. We apply a weakly-supervised linguistic pattern learner and qualitatively analyze the linguistic differences in each class. version:1
arxiv-1709-05397 | Zero-Shot Learning to Manage a Large Number of Place-Specific Compressive Change Classifiers | http://arxiv.org/abs/1709.05397 | id:1709.05397 author:Tanaka Kanji category:cs.CV  published:2017-09-15 summary:With recent progress in large-scale map maintenance and long-term map learning, the task of change detection on a large-scale map from a visual image captured by a mobile robot has become a problem of increasing criticality. Previous approaches for change detection are typically based on image differencing and require the memorization of a prohibitively large number of mapped images in the above context. In contrast, this study follows the recent, efficient paradigm of change-classifier-learning and specifically employs a collection of place-specific change classifiers. Our change-classifier-learning algorithm is based on zero-shot learning (ZSL) and represents a place-specific change classifier by its training examples mined from an external knowledge base (EKB). The proposed algorithm exhibits several advantages. First, we are required to memorize only training examples (rather than the classifier itself), which can be further compressed in the form of bag-of-words (BoW). Secondly, we can incorporate the most recent map into the classifiers by straightforwardly adding or deleting a few training examples that correspond to these classifiers. Thirdly, we can share the BoW vocabulary with other related task scenarios (e.g., BoW-based self-localization), wherein the vocabulary is generally designed as a rich, continuously growing, and domain-adaptive knowledge base. In our contribution, the proposed algorithm is applied and evaluated on a practical long-term cross-season change detection system that consists of a large number of place-specific object-level change classifiers. version:1
arxiv-1709-05394 | $ε$-Lexicase selection: a probabilistic and multi-objective analysis of lexicase selection in continuous domains | http://arxiv.org/abs/1709.05394 | id:1709.05394 author:William La Cava, Thomas Helmuth, Lee Spector, Jason H. Moore category:cs.NE  published:2017-09-15 summary:Lexicase selection is a parent selection method that considers training cases individually, rather than in aggregate, when performing parent selection. Whereas previous work has demonstrated the ability of lexicase selection to solve difficult problems, the central goal of this paper is to develop the theoretical underpinnings that explain its performance. To this end, we derive an analytical formula that gives the expected probabilities of selection under lexicase selection, given a population and its behavior. In addition, we expand upon the relation of lexicase selection to many-objective optimization methods to describe the behavior of lexicase, which is to select individuals on the boundaries of Pareto fronts in high-dimensional space. We show analytically why lexicase selection performs more poorly for certain sizes of population and training cases, and show why it has been shown to perform more poorly in continuous error spaces. To address this last concern, we introduce $\epsilon$-lexicase selection, which modifies the pass condition in lexicase selection to allow near-elite individuals to pass cases, thereby improving selection performance with continuous errors. We show that $\epsilon$-lexicase outperforms several diversity-maintenance strategies on a number of real-world and synthetic regression problems. version:1
arxiv-1709-05379 | Road Friction Estimation for Connected Vehicles using Supervised Machine Learning | http://arxiv.org/abs/1709.05379 | id:1709.05379 author:Ghazaleh Panahandeh, Erik Ek, Nasser Mohammadiha category:cs.LG stat.ML  published:2017-09-15 summary:In this paper, the problem of road friction prediction from a fleet of connected vehicles is investigated. A framework is proposed to predict the road friction level using both historical friction data from the connected cars and data from weather stations, and comparative results from different methods are presented. The problem is formulated as a classification task where the available data is used to train three machine learning models including logistic regression, support vector machine, and neural networks to predict the friction class (slippery or non-slippery) in the future for specific road segments. In addition to the friction values, which are measured by moving vehicles, additional parameters such as humidity, temperature, and rainfall are used to obtain a set of descriptive feature vectors as input to the classification methods. The proposed prediction models are evaluated for different prediction horizons (0 to 120 minutes in the future) where the evaluation shows that the neural networks method leads to more stable results in different conditions. version:1
arxiv-1709-05374 | General Phase Regularized Reconstruction using Phase Cycling | http://arxiv.org/abs/1709.05374 | id:1709.05374 author:Frank Ong, Joseph Cheng, Michael Lustig category:cs.CV physics.med-ph  published:2017-09-15 summary:Purpose: To develop a general phase regularized image reconstruction method, with applications to partial Fourier imaging, water-fat imaging and flow imaging. Theory and Methods: The problem of enforcing phase constraints in reconstruction was studied under a regularized inverse problem framework. A general phase regularized reconstruction algorithm was proposed to enable various joint reconstruction of partial Fourier imaging, water-fat imaging and flow imaging, along with parallel imaging (PI) and compressed sensing (CS). Since phase regularized reconstruction is inherently non-convex and sensitive to phase wraps in the initial solution, a reconstruction technique, named phase cycling, was proposed to render the overall algorithm invariant to phase wraps. The proposed method was applied to retrospectively under-sampled in vivo datasets and compared with state of the art reconstruction methods. Results: Phase cycling reconstructions showed reduction of artifacts compared to reconstructions with- out phase cycling and achieved similar performances as state of the art results in partial Fourier, water-fat and divergence-free regularized flow reconstruction. Joint reconstruction of partial Fourier + water-fat imaging + PI + CS, and partial Fourier + divergence-free regularized flow imaging + PI + CS were demonstrated. Conclusion: The proposed phase cycling reconstruction provides an alternative way to perform phase regularized reconstruction, without the need to perform phase unwrapping. It is robust to the choice of initial solutions and encourages the joint reconstruction of phase imaging applications. version:1
arxiv-1709-05362 | Supervised and Unsupervised Speech Enhancement Using Nonnegative Matrix Factorization | http://arxiv.org/abs/1709.05362 | id:1709.05362 author:Nasser Mohammadiha, Paris Smaragdis, Arne Leijon category:cs.SD cs.LG  published:2017-09-15 summary:Reducing the interference noise in a monaural noisy speech signal has been a challenging task for many years. Compared to traditional unsupervised speech enhancement methods, e.g., Wiener filtering, supervised approaches, such as algorithms based on hidden Markov models (HMM), lead to higher-quality enhanced speech signals. However, the main practical difficulty of these approaches is that for each noise type a model is required to be trained a priori. In this paper, we investigate a new class of supervised speech denoising algorithms using nonnegative matrix factorization (NMF). We propose a novel speech enhancement method that is based on a Bayesian formulation of NMF (BNMF). To circumvent the mismatch problem between the training and testing stages, we propose two solutions. First, we use an HMM in combination with BNMF (BNMF-HMM) to derive a minimum mean square error (MMSE) estimator for the speech signal with no information about the underlying noise type. Second, we suggest a scheme to learn the required noise BNMF model online, which is then used to develop an unsupervised speech enhancement system. Extensive experiments are carried out to investigate the performance of the proposed methods under different conditions. Moreover, we compare the performance of the developed algorithms with state-of-the-art speech enhancement schemes using various objective measures. Our simulations show that the proposed BNMF-based methods outperform the competing algorithms substantially. version:1
arxiv-1709-05328 | Granger Mediation Analysis of Multiple Time Series with an Application to fMRI | http://arxiv.org/abs/1709.05328 | id:1709.05328 author:Yi Zhao, Xi Luo category:stat.ME stat.AP stat.ML 62J99  62H12  published:2017-09-15 summary:It becomes increasingly popular to perform mediation analysis for complex data from sophisticated experimental studies. In this paper, we present Granger Mediation Analysis (GMA), a new framework for causal mediation analysis of multiple time series. This framework is motivated by a functional magnetic resonance imaging (fMRI) experiment where we are interested in estimating the mediation effects between a randomized stimulus time series and brain activity time series from two brain regions. The stable unit treatment assumption for causal mediation analysis is thus unrealistic for this type of time series data. To address this challenge, our framework integrates two types of models: causal mediation analysis across the variables and vector autoregressive models across the temporal observations. We further extend this framework to handle multilevel data to address individual variability and correlated errors between the mediator and the outcome variables. These models not only provide valid causal mediation for time series data but also model the causal dynamics across time. We show that the modeling parameters in our models are identifiable, and we develop computationally efficient methods to maximize the likelihood-based optimization criteria. Simulation studies show that our method reduces the estimation bias and improve statistical power, compared to existing approaches. On a real fMRI data set, our approach not only infers the causal effects of brain pathways but accurately captures the feedback effect of the outcome region on the mediator region. version:1
arxiv-1709-05324 | Cystoid macular edema segmentation of Optical Coherence Tomography images using fully convolutional neural networks and fully connected CRFs | http://arxiv.org/abs/1709.05324 | id:1709.05324 author:Fangliang Bai, Manuel J. Marques, Stuart J. Gibson category:cs.CV  published:2017-09-15 summary:In this paper we present a new method for cystoid macular edema (CME) segmentation in retinal Optical Coherence Tomography (OCT) images, using a fully convolutional neural network (FCN) and a fully connected conditional random fields (dense CRFs). As a first step, the framework trains the FCN model to extract features from retinal layers in OCT images, which exhibit CME, and then segments CME regions using the trained model. Thereafter, dense CRFs are used to refine the segmentation according to the edema appearance. We have trained and tested the framework with OCT images from 10 patients with diabetic macular edema (DME). Our experimental results show that fluid and concrete macular edema areas were segmented with good adherence to boundaries. A segmentation accuracy of $0.61\pm 0.21$ (Dice coefficient) was achieved, with respect to the ground truth, which compares favourably with the previous state-of-the-art that used a kernel regression based method ($0.51\pm 0.34$). Our approach is versatile and we believe it can be easily adapted to detect other macular defects. version:1
arxiv-1709-05311 | Video Synopsis Generation Using Spatio-Temporal Groups | http://arxiv.org/abs/1709.05311 | id:1709.05311 author:A. Ahmed, D. P. Dogra, S. Kar, R. Patnaik, S. Lee, H. Choi, I. Kim category:cs.CV  published:2017-09-15 summary:Millions of surveillance cameras operate at 24x7 generating huge amount of visual data for processing. However, retrieval of important activities from such a large data can be time consuming. Thus, researchers are working on finding solutions to present hours of visual data in a compressed, but meaningful way. Video synopsis is one of the ways to represent activities using relatively shorter duration clips. So far, two main approaches have been used by researchers to address this problem, namely synopsis by tracking moving objects and synopsis by clustering moving objects. Synopses outputs, mainly depend on tracking, segmenting, and shifting of moving objects temporally as well as spatially. In many situations, tracking fails, thus produces multiple trajectories of the same object. Due to this, the object may appear and disappear multiple times within the same synopsis output, which is misleading. This also leads to discontinuity and often can be confusing to the viewer of the synopsis. In this paper, we present a new approach for generating compressed video synopsis by grouping tracklets of moving objects. Grouping helps to generate a synopsis where chronologically related objects appear together with meaningful spatio-temporal relation. Our proposed method produces continuous, but a less confusing synopses when tested on publicly available dataset videos as well as in-house dataset videos. version:1
arxiv-1709-05308 | Harvesting Creative Templates for Generating Stylistically Varied Restaurant Reviews | http://arxiv.org/abs/1709.05308 | id:1709.05308 author:Shereen Oraby, Sheideh Homayon, Marilyn Walker category:cs.CL  published:2017-09-15 summary:Many of the creative and figurative elements that make language exciting are lost in translation in current natural language generation engines. In this paper, we explore a method to harvest templates from positive and negative reviews in the restaurant domain, with the goal of vastly expanding the types of stylistic variation available to the natural language generator. We learn hyperbolic adjective patterns that are representative of the strongly-valenced expressive language commonly used in either positive or negative reviews. We then identify and delexicalize entities, and use heuristics to extract generation templates from review sentences. We evaluate the learned templates against more traditional review templates, using subjective measures of "convincingness", "interestingness", and "naturalness". Our results show that the learned templates score highly on these measures. Finally, we analyze the linguistic categories that characterize the learned positive and negative templates. We plan to use the learned templates to improve the conversational style of dialogue systems in the restaurant domain. version:1
arxiv-1709-05306 | Recursive Binary Neural Network Learning Model with 2.28b/Weight Storage Requirement | http://arxiv.org/abs/1709.05306 | id:1709.05306 author:Tianchan Guan, Xiaoyang Zeng, Mingoo Seok category:cs.NE  published:2017-09-15 summary:This paper presents a storage-efficient learning model titled Recursive Binary Neural Networks for sensing devices having a limited amount of on-chip data storage such as < 100's kilo-Bytes. The main idea of the proposed model is to recursively recycle data storage of synaptic weights (parameters) during training. This enables a device with a given storage constraint to train and instantiate a neural network classifier with a larger number of weights on a chip and with a less number of off-chip storage accesses. This enables higher classification accuracy, shorter training time, less energy dissipation, and less on-chip storage requirement. We verified the training model with deep neural network classifiers and the permutation-invariant MNIST benchmark. Our model uses only 2.28 bits/weight while for the same data storage constraint achieving ~1% lower classification error as compared to the conventional binary-weight learning model which yet has to use 8 to 16 bit storage per weight. To achieve the similar classification error, the conventional binary model requires ~4x more data storage for weights than the proposed model. version:1
arxiv-1709-05305 | Are you serious?: Rhetorical Questions and Sarcasm in Social Media Dialog | http://arxiv.org/abs/1709.05305 | id:1709.05305 author:Shereen Oraby, Vrindavan Harrison, Amita Misra, Ellen Riloff, Marilyn Walker category:cs.CL  published:2017-09-15 summary:Effective models of social dialog must understand a broad range of rhetorical and figurative devices. Rhetorical questions (RQs) are a type of figurative language whose aim is to achieve a pragmatic goal, such as structuring an argument, being persuasive, emphasizing a point, or being ironic. While there are computational models for other forms of figurative language, rhetorical questions have received little attention to date. We expand a small dataset from previous work, presenting a corpus of 10,270 RQs from debate forums and Twitter that represent different discourse functions. We show that we can clearly distinguish between RQs and sincere questions (0.76 F1). We then show that RQs can be used both sarcastically and non-sarcastically, observing that non-sarcastic (other) uses of RQs are frequently argumentative in forums, and persuasive in tweets. We present experiments to distinguish between these uses of RQs using SVM and LSTM models that represent linguistic features and post-level context, achieving results as high as 0.76 F1 for "sarcastic" and 0.77 F1 for "other" in forums, and 0.83 F1 for both "sarcastic" and "other" in tweets. We supplement our quantitative experiments with an in-depth characterization of the linguistic variation in RQs. version:1
arxiv-1709-05295 | And That's A Fact: Distinguishing Factual and Emotional Argumentation in Online Dialogue | http://arxiv.org/abs/1709.05295 | id:1709.05295 author:Shereen Oraby, Lena Reed, Ryan Compton, Ellen Riloff, Marilyn Walker, Steve Whittaker category:cs.CL  published:2017-09-15 summary:We investigate the characteristics of factual and emotional argumentation styles observed in online debates. Using an annotated set of "factual" and "feeling" debate forum posts, we extract patterns that are highly correlated with factual and emotional arguments, and then apply a bootstrapping methodology to find new patterns in a larger pool of unannotated forum posts. This process automatically produces a large set of patterns representing linguistic expressions that are highly correlated with factual and emotional language. Finally, we analyze the most discriminating patterns to better understand the defining characteristics of factual and emotional arguments. version:1
arxiv-1708-02337 | Unconstrained Face Detection and Open-Set Face Recognition Challenge | http://arxiv.org/abs/1708.02337 | id:1708.02337 author:Manuel Günther, Peiyun Hu, Christian Herrmann, Chi Ho Chan, Min Jiang, Shufan Yang, Akshay Raj Dhamija, Deva Ramanan, Jürgen Beyerer, Josef Kittler, Mohamad Al Jazaery, Mohammad Iqbal Nouyed, Guodong Guo, Cezary Stankiewicz, Terrance E. Boult category:cs.CV  published:2017-08-08 summary:Face detection and recognition benchmarks have shifted toward more difficult environments. The challenge presented in this paper addresses the next step in the direction of automatic detection and identification of people from outdoor surveillance cameras. While face detection has shown remarkable success in images collected from the web, surveillance cameras include more diverse occlusions, poses, weather conditions and image blur. Although face verification or closed-set face identification have surpassed human capabilities on some datasets, open-set identification is much more complex as it needs to reject both unknown identities and false accepts from the face detector. We show that unconstrained face detection can approach high detection rates albeit with moderate false accept rates. By contrast, open-set face recognition is currently weak and requires much more attention. version:2
arxiv-1709-05276 | Mixtures and products in two graphical models | http://arxiv.org/abs/1709.05276 | id:1709.05276 author:Anna Seigal, Guido Montufar category:stat.ML  published:2017-09-15 summary:We compare two statistical models of three binary random variables. One is a mixture model and the other is a product of mixtures model called a restricted Boltzmann machine. Although the two models we study look different from their parametrizations, we show that they represent the same set of distributions on the interior of the probability simplex, and are equal up to closure. We give a semi-algebraic description of the model in terms of six binomial inequalities and obtain closed form expressions for the maximum likelihood estimates. We briefly discuss extensions to larger models. version:1
arxiv-1709-05254 | Detection of Anomalies in Large Scale Accounting Data using Deep Autoencoder Networks | http://arxiv.org/abs/1709.05254 | id:1709.05254 author:Marco Schreyer, Timur Sattarov, Damian Borth, Andreas Dengel, Bernd Reimer category:cs.LG cs.CE  published:2017-09-15 summary:Learning to detect fraud in large-scale accounting data is one of the long-standing challenges in financial statement audits or forensic investigations. Nowadays, the majority of applied techniques refer to handcrafted rules derived from known fraud scenarios. While fairly successful, these rules exhibit the drawback that fraudsters gradually adapt and find ways to circumvent them. In addition, these rigid rules often fail to generalize beyond known fraud scenarios. To overcome this challenge we propose a novel method of detecting anomalous journal entries using deep autoencoder networks. We demonstrate that the trained networks' reconstruction error regularized by the individual attribute probabilities of a journal entry can be interpreted as a highly adaptive anomaly assessment. Our empirical study, based on two datasets of real-world journal entries, demonstrates the effectiveness of the approach and outperforms several baseline anomaly detection methods. Resulting in a fraction of less than 0.15% (0.7%) of detected anomalous entries while achieving a high detection precision of 19.71% (9.26%). Initial feedback received by accountants underpinned the quality of our approach capturing highly relevant anomalies in the data. We envision this method as an important supplement to the forensic examiners' toolbox. version:1
arxiv-1709-05227 | Transcribing Against Time | http://arxiv.org/abs/1709.05227 | id:1709.05227 author:Matthias Sperber, Graham Neubig, Jan Niehues, Satoshi Nakamura, Alex Waibel category:cs.CL  published:2017-09-15 summary:We investigate the problem of manually correcting errors from an automatic speech transcript in a cost-sensitive fashion. This is done by specifying a fixed time budget, and then automatically choosing location and size of segments for correction such that the number of corrected errors is maximized. The core components, as suggested by previous research [1], are a utility model that estimates the number of errors in a particular segment, and a cost model that estimates annotation effort for the segment. In this work we propose a dynamic updating framework that allows for the training of cost models during the ongoing transcription process. This removes the need for transcriber enrollment prior to the actual transcription, and improves correction efficiency by allowing highly transcriber-adaptive cost modeling. We first confirm and analyze the improvements afforded by this method in a simulated study. We then conduct a realistic user study, observing efficiency improvements of 15% relative on average, and 42% for the participants who deviated most strongly from our initial, transcriber-agnostic cost model. Moreover, we find that our updating framework can capture dynamically changing factors, such as transcriber fatigue and topic familiarity, which we observe to have a large influence on the transcriber's working behavior. version:1
arxiv-1708-02840 | Speaker Diarization using Deep Recurrent Convolutional Neural Networks for Speaker Embeddings | http://arxiv.org/abs/1708.02840 | id:1708.02840 author:Pawel Cyrta, Tomasz Trzciński, Wojciech Stokowiec category:cs.SD cs.MM cs.NE  published:2017-08-09 summary:In this paper we propose a new method of speaker diarization that employs a deep learning architecture to learn speaker embeddings. In contrast to the traditional approaches that build their speaker embeddings using manually hand-crafted spectral features, we propose to train for this purpose a recurrent convolutional neural network applied directly on magnitude spectrograms. To compare our approach with the state of the art, we collect and release for the public an additional dataset of over 6 hours of fully annotated broadcast material. The results of our evaluation on the new dataset and three other benchmark datasets show that our proposed method significantly outperforms the competitors and reduces diarization error rate by a large margin of over 30% with respect to the baseline. version:2
arxiv-1709-05165 | Multi-scale Deep Learning Architectures for Person Re-identification | http://arxiv.org/abs/1709.05165 | id:1709.05165 author:Xuelin Qian, Yanwei Fu, Yu-Gang Jiang, Tao Xiang, Xiangyang Xue category:cs.CV  published:2017-09-15 summary:Person Re-identification (re-id) aims to match people across non-overlapping camera views in a public space. It is a challenging problem because many people captured in surveillance videos wear similar clothes. Consequently, the differences in their appearance are often subtle and only detectable at the right location and scales. Existing re-id models, particularly the recently proposed deep learning based ones match people at a single scale. In contrast, in this paper, a novel multi-scale deep learning model is proposed. Our model is able to learn deep discriminative feature representations at different scales and automatically determine the most suitable scales for matching. The importance of different spatial locations for extracting discriminative features is also learned explicitly. Experiments are carried out to demonstrate that the proposed model outperforms the state-of-the art on a number of benchmarks version:1
arxiv-1709-05156 | Trend Detection based Regret Minimization for Bandit Problems | http://arxiv.org/abs/1709.05156 | id:1709.05156 author:Paresh Nakhe, Rebecca Reiffenhäuser category:cs.LG  published:2017-09-15 summary:We study a variation of the classical multi-armed bandits problem. In this problem, the learner has to make a sequence of decisions, picking from a fixed set of choices. In each round, she receives as feedback only the loss incurred from the chosen action. Conventionally, this problem has been studied when losses of the actions are drawn from an unknown distribution or when they are adversarial. In this paper, we study this problem when the losses of the actions also satisfy certain structural properties, and especially, do show a trend structure. When this is true, we show that using \textit{trend detection}, we can achieve regret of order $\tilde{O} (N \sqrt{TK})$ with respect to a switching strategy for the version of the problem where a single action is chosen in each round and $\tilde{O} (Nm \sqrt{TK})$ when $m$ actions are chosen each round. This guarantee is a significant improvement over the conventional benchmark. Our approach can, as a framework, be applied in combination with various well-known bandit algorithms, like Exp3. For both versions of the problem, we give regret guarantees also for the \textit{anytime} setting, i.e. when the length of the choice-sequence is not known in advance. Finally, we pinpoint the advantages of our method by comparing it to some well-known other strategies. version:1
arxiv-1707-00896 | Multilingual Hierarchical Attention Networks for Document Classification | http://arxiv.org/abs/1707.00896 | id:1707.00896 author:Nikolaos Pappas, Andrei Popescu-Belis category:cs.CL  published:2017-07-04 summary:Hierarchical attention networks have recently achieved remarkable performance for document classification in a given language. However, when multilingual document collections are considered, training such models separately for each language entails linear parameter growth and lack of cross-language transfer. Learning a single multilingual model with fewer parameters is therefore a challenging but potentially beneficial objective. To this end, we propose multilingual hierarchical attention networks for learning document structures, with shared encoders and/or shared attention mechanisms across languages, using multi-task learning and an aligned semantic space as input. We evaluate the proposed models on multilingual document classification with disjoint label sets, on a large dataset which we provide, with 600k news documents in 8 languages, and 5k labels. The multilingual models outperform monolingual ones in low-resource as well as full-resource settings, and use fewer parameters, thus confirming their computational efficiency and the utility of cross-language transfer. version:4
arxiv-1704-06645 | Feed-forward approximations to dynamic recurrent network architectures | http://arxiv.org/abs/1704.06645 | id:1704.06645 author:Dylan Richard Muir category:cs.NE q-bio.NC  published:2017-04-21 summary:Recurrent neural network architectures can have useful computational properties, with complex temporal dynamics and input-sensitive attractor states. However, evaluation of recurrent dynamic architectures requires solution of systems of differential equations, and the number of evaluations required to determine their response to a given input can vary with the input, or can be indeterminate altogether in the case of oscillations or instability. In feed-forward networks, by contrast, only a single pass through the network is needed to determine the response to a given input. Modern machine-learning systems are designed to operate efficiently on feed-forward architectures. We hypothesised that two-layer feedforward architectures with simple, deterministic dynamics could approximate the responses of single-layer recurrent network architectures. By identifying the fixed-point responses of a given recurrent network, we trained two-layer networks to directly approximate the fixed-point response to a given input. These feed-forward networks then embodied useful computations, including competitive interactions, information transformations and noise rejection. Our approach was able to find useful approximations to recurrent networks, which can then be evaluated in linear and deterministic time complexity. version:2
arxiv-1709-05119 | Dependence Modeling in Ultra High Dimensions with Vine Copulas and the Graphical Lasso | http://arxiv.org/abs/1709.05119 | id:1709.05119 author:Dominik Müller, Claudia Czado category:stat.ML  published:2017-09-15 summary:To model high dimensional data, Gaussian methods are widely used since they remain tractable and yield parsimonious models by imposing strong assumptions on the data. Vine copulas are more flexible by combining arbitrary marginal distributions and (conditional) bivariate copulas. Yet, this adaptability is accompanied by sharply increasing computational effort as the dimension increases. The approach proposed in this paper overcomes this burden and makes the first step into ultra high dimensional non-Gaussian dependence modeling by using a divide-and-conquer approach. First, we apply Gaussian methods to split datasets into feasibly small subsets and second, apply parsimonious and flexible vine copulas thereon. Finally, we reconcile them into one joint model. We provide numerical results demonstrating the feasibility of our approach in moderate dimensions and showcase its ability to estimate ultra high dimensional non-Gaussian dependence models in thousands of dimensions. version:1
arxiv-1709-05094 | Unsupervised Aspect Term Extraction with B-LSTM & CRF using Automatically Labelled Datasets | http://arxiv.org/abs/1709.05094 | id:1709.05094 author:Athanasios Giannakopoulos, Claudiu Musat, Andreea Hossmann, Michael Baeriswyl category:cs.CL  published:2017-09-15 summary:Aspect Term Extraction (ATE) identifies opinionated aspect terms in texts and is one of the tasks in the SemEval Aspect Based Sentiment Analysis (ABSA) contest. The small amount of available datasets for supervised ATE and the costly human annotation for aspect term labelling give rise to the need for unsupervised ATE. In this paper, we introduce an architecture that achieves top-ranking performance for supervised ATE. Moreover, it can be used efficiently as feature extractor and classifier for unsupervised ATE. Our second contribution is a method to automatically construct datasets for ATE. We train a classifier on our automatically labelled datasets and evaluate it on the human annotated SemEval ABSA test sets. Compared to a strong rule-based baseline, we obtain a dramatically higher F-score and attain precision values above 80%. Our unsupervised method beats the supervised ABSA baseline from SemEval, while preserving high precision scores. version:1
arxiv-1709-05087 | Viewpoint Invariant Action Recognition using RGB-D Videos | http://arxiv.org/abs/1709.05087 | id:1709.05087 author:Jian Liu, Naveed Akhtar, Ajmal Mian category:cs.CV  published:2017-09-15 summary:In video-based action recognition, viewpoint variations often pose major challenges because the same actions can appear different from different views. We use the complementary RGB and Depth information from the RGB-D cameras to address this problem. The proposed technique capitalizes on the spatio-temporal information available in the two data streams to the extract action features that are largely insensitive to the viewpoint variations. We use the RGB data to compute dense trajectories that are translated to viewpoint insensitive deep features under a non-linear knowledge transfer model. Similarly, the Depth stream is used to extract CNN-based view invariant features on which Fourier Temporal Pyramid is computed to incorporate the temporal information. The heterogeneous features from the two streams are combined and used as a dictionary to predict the label of the test samples. To that end, we propose a sparse-dense collaborative representation classification scheme that strikes a balance between the discriminative abilities of the dense and the sparse representations of the samples over the extracted heterogeneous dictionary. version:1
