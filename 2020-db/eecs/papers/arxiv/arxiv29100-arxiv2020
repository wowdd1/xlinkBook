arxiv-1707-05574 | One-shot Face Recognition by Promoting Underrepresented Classes | http://arxiv.org/abs/1707.05574 | id:1707.05574 author:Yandong Guo, Lei Zhang category:cs.CV  published:2017-07-18 summary:We study in this paper the problem of one-shot face recognition, with the goal to build a large-scale face recognizer capable of recognizing a substantial number of persons. Given that for face recognition one can leverage a large-scale dataset to learn good face representation, our study shows that the poor generalization ability of the one-shot classes is mainly caused by the data imbalance problem, which cannot be effectively addressed by multinomial logistic regression that is widely used as the final classification layer in convolutional neural networks. To solve this problem, we propose a novel supervision signal called underrepresented-classes promotion (UP) loss term, which aligns the norms of the weight vectors of the one-shot classes (a.k.a. underrepresented-classes) to those of the normal classes. In addition to the original cross entropy loss, this new loss term effectively promotes the underrepresented classes in the learned model and leads to a remarkable improvement in face recognition performance. The experimental results on a benchmark dataset of $21,000$ persons show that the new loss term significantly helps improve the recognition coverage rate from $25.65\%$ to $77.48\%$ at the precision of $99\%$ for underrepresented classes, while still keeps an overall top-1 accuracy of $99.8\%$ for normal classes. version:1
arxiv-1707-05572 | Fast Feature Fool: A data independent approach to universal adversarial perturbations | http://arxiv.org/abs/1707.05572 | id:1707.05572 author:Konda Reddy Mopuri, Utsav Garg, R. Venkatesh Babu category:cs.CV  published:2017-07-18 summary:State-of-the-art object recognition Convolutional Neural Networks (CNNs) are shown to be fooled by image agnostic perturbations, called universal adversarial perturbations. It is also observed that these perturbations generalize across multiple networks trained on the same target data. However, these algorithms require training data on which the CNNs were trained and compute adversarial perturbations via complex optimization. The fooling performance of these approaches is directly proportional to the amount of available training data. This makes them unsuitable for practical attacks since its unreasonable for an attacker to have access to the training data. In this paper, for the first time, we propose a novel data independent approach to generate image agnostic perturbations for a range of CNNs trained for object recognition. We further show that these perturbations are transferable across multiple network architectures trained either on same or different data. In the absence of data, our method generates universal adversarial perturbations efficiently via fooling the features learned at multiple layers thereby causing CNNs to misclassify. Experiments demonstrate impressive fooling rates and surprising transferability for the proposed universal perturbations generated without any training data. version:1
arxiv-1707-05564 | Batch based Monocular SLAM for Egocentric Videos | http://arxiv.org/abs/1707.05564 | id:1707.05564 author:Suvam Patra, Kartikeya Gupta, Faran Ahmad, Chetan Arora, Subhashis Banerjee category:cs.CV  published:2017-07-18 summary:Simultaneous Localization and Mapping (SLAM) from a monocular camera has been a well researched area. However, estimating camera pose and 3d geometry reliably for egocentric videos still remain a challenge. Some of the common causes of failures are dominant 3D rotations and low parallax between successive frames, resulting in unreliable pose and 3d estimates. For forward moving cameras, with no opportunities for loop closures, the drift leads to eventual failures for traditional feature based and direct SLAM techniques. We propose a novel batch mode structure from motion based technique for robust SLAM in such scenarios. In contrast to most of the existing techniques, we process frames in short batches, wherein we exploit short loop closures arising out of to-and-fro motion of wearer's head, and stabilize the egomotion estimates by 2D batch mode techniques such as motion averaging on pairwise epipolar results. Once pose estimates are obtained reliably over a batch, we refine the 3d estimate by triangulation and batch mode Bundle Adjustment (BA). Finally, we merge the batches using 3D correspondences and carry out a BA refinement post merging. We present both qualitative and quantitative comparison of our method on various public first and third person video datasets, to establish the robustness and accuracy of our algorithm over the state of the art. version:1
arxiv-1707-05562 | One-Shot Learning in Discriminative Neural Networks | http://arxiv.org/abs/1707.05562 | id:1707.05562 author:Jordan Burgess, James Robert Lloyd, Zoubin Ghahramani category:stat.ML cs.LG  published:2017-07-18 summary:We consider the task of one-shot learning of visual categories. In this paper we explore a Bayesian procedure for updating a pretrained convnet to classify a novel image category for which data is limited. We decompose this convnet into a fixed feature extractor and softmax classifier. We assume that the target weights for the new task come from the same distribution as the pretrained softmax weights, which we model as a multivariate Gaussian. By using this as a prior for the new weights, we demonstrate competitive performance with state-of-the-art methods whilst also being consistent with 'normal' methods for training deep networks on large data. version:1
arxiv-1707-05553 | Spectral Filter Tracking | http://arxiv.org/abs/1707.05553 | id:1707.05553 author:Zhen Cui, You yi Cai, Wen ming Zheng, Jian Yang category:cs.CV  published:2017-07-18 summary:Visual object tracking is a challenging computer vision task with numerous real-world applications. Here we propose a simple but efficient Spectral Filter Tracking (SFT)method. To characterize rotational and translation invariance of tracking targets, the candidate image region is models as a pixelwise grid graph. Instead of the conventional graph matching, we convert the tracking into a plain least square regression problem to estimate the best center coordinate of the target. But different from the holistic regression of correlation filter based methods, SFT can operate on localized surrounding regions of each pixel (i.e.,vertex) by using spectral graph filters, which thus is more robust to resist local variations and cluttered background.To bypass the eigenvalue decomposition problem of the graph Laplacian matrix L, we parameterize spectral graph filters as the polynomial of L by spectral graph theory, in which L k exactly encodes a k-hop local neighborhood of each vertex. Finally, the filter parameters (i.e., polynomial coefficients) as well as feature projecting functions are jointly integrated into the regression model. version:1
arxiv-1707-07539 | Exploring Outliers in Crowdsourced Ranking for QoE | http://arxiv.org/abs/1707.07539 | id:1707.07539 author:Qianqian Xu, Ming Yan, Chendi Huang, Jiechao Xiong, Qingming Huang, Yuan Yao category:stat.ML cs.LG  published:2017-07-18 summary:Outlier detection is a crucial part of robust evaluation for crowdsourceable assessment of Quality of Experience (QoE) and has attracted much attention in recent years. In this paper, we propose some simple and fast algorithms for outlier detection and robust QoE evaluation based on the nonconvex optimization principle. Several iterative procedures are designed with or without knowing the number of outliers in samples. Theoretical analysis is given to show that such procedures can reach statistically good estimates under mild conditions. Finally, experimental results with simulated and real-world crowdsourcing datasets show that the proposed algorithms could produce similar performance to Huber-LASSO approach in robust ranking, yet with nearly 8 or 90 times speed-up, without or with a prior knowledge on the sparsity size of outliers, respectively. Therefore the proposed methodology provides us a set of helpful tools for robust QoE evaluation with crowdsourcing data. version:1
arxiv-1612-07025 | Boolean kernels for collaborative filtering in top-N item recommendation | http://arxiv.org/abs/1612.07025 | id:1612.07025 author:Mirko Polato, Fabio Aiolli category:cs.IR cs.AI  published:2016-12-21 summary:In many personalized recommendation problems available data consists only of positive interactions (implicit feedback) between users and items. This problem is also known as One-Class Collaborative Filtering (OC-CF). Linear models usually achieve state-of-the-art performances on OC-CF problems and many efforts have been devoted to build more expressive and complex representations able to improve the recommendations. Recent analysis show that collaborative filtering (CF) datasets have peculiar characteristics such as high sparsity and a long tailed distribution of the ratings. In this paper we propose a boolean kernel, called Disjunctive kernel, which is less expressive than the linear one but it is able to alleviate the sparsity issue in CF contexts. The embedding of this kernel is composed by all the combinations of a certain arity d of the input variables, and these combined features are semantically interpreted as disjunctions of the input variables. Experiments on several CF datasets show the effectiveness and the efficiency of the proposed kernel. version:2
arxiv-1707-05537 | Beyond Forward Shortcuts: Fully Convolutional Master-Slave Networks (MSNets) with Backward Skip Connections for Semantic Segmentation | http://arxiv.org/abs/1707.05537 | id:1707.05537 author:Abrar H. Abdulnabi, Stefan Winkler, Gang Wang category:cs.CV  published:2017-07-18 summary:Recent deep CNNs contain forward shortcut connections; i.e. skip connections from low to high layers. Reusing features from lower layers that have higher resolution (location information) benefit higher layers to recover lost details and mitigate information degradation. However, during inference the lower layers do not know about high layer features, although they contain contextual high semantics that benefit low layers to adaptively extract informative features for later layers. In this paper, we study the influence of backward skip connections which are in the opposite direction to forward shortcuts, i.e. paths from high layers to low layers. To achieve this -- which indeed runs counter to the nature of feed-forward networks -- we propose a new fully convolutional model that consists of a pair of networks. A `Slave' network is dedicated to provide the backward connections from its top layers to the `Master' network's bottom layers. The Master network is used to produce the final label predictions. In our experiments we validate the proposed FCN model on ADE20K (ImageNet scene parsing), PASCAL-Context, and PASCAL VOC 2011 datasets. version:1
arxiv-1707-05534 | Latent Gaussian Process Regression | http://arxiv.org/abs/1707.05534 | id:1707.05534 author:Erik Bodin, Neill D. F. Campbell, Carl Henrik Ek category:stat.ML cs.LG  published:2017-07-18 summary:We introduce Latent Gaussian Process Regression which is a latent variable extension allowing modelling of non-stationary processes using stationary GP priors. The approach is built on extending the input space of a regression problem with a latent variable that is used to modulate the covariance function over the input space. We show how our approach can be used to model non-stationary processes but also how multi-modal or non-functional processes can be described where the input signal cannot fully disambiguate the output. We exemplify the approach on a set of synthetic data and provide results on real data from geostatistics. version:1
arxiv-1707-05533 | Global optimization for low-dimensional switching linear regression and bounded-error estimation | http://arxiv.org/abs/1707.05533 | id:1707.05533 author:Fabien Lauer category:cs.LG stat.ML  published:2017-07-18 summary:The paper provides global optimization algorithms for two particularly difficult nonconvex problems raised by hybrid system identification: switching linear regression and bounded-error estimation. While most works focus on local optimization heuristics without global optimality guarantees or with guarantees valid only under restrictive conditions, the proposed approach yields a solution with a certificate of global optimality. This approach relies on a branch-and-bound strategy for which we devise lower bounds that can be efficiently computed. In order to obtain scalable algorithms with respect to the number of data, we directly optimize the model parameters in a continuous optimization setting without involving integer variables. Numerical experiments show that the proposed algorithms offer a higher accuracy than convex relaxations with a reasonable computational burden for hybrid system identification. In addition, we discuss how bounded-error estimation is related to robust estimation in the presence of outliers and exact recovery under sparse noise, for which we also obtain promising numerical results. version:1
arxiv-1707-05532 | Bayesian Nonlinear Support Vector Machines for Big Data | http://arxiv.org/abs/1707.05532 | id:1707.05532 author:Florian Wenzel, Theo Galy-Fajou, Matthaeus Deutsch, Marius Kloft category:stat.ML  published:2017-07-18 summary:We propose a fast inference method for Bayesian nonlinear support vector machines that leverages stochastic variational inference and inducing points. Our experiments show that the proposed method is faster than competing Bayesian approaches and scales easily to millions of data points. It provides additional features over frequentist competitors such as accurate predictive uncertainty estimates and automatic hyperparameter search. version:1
arxiv-1707-05167 | Cosmological model discrimination with Deep Learning | http://arxiv.org/abs/1707.05167 | id:1707.05167 author:Jorit Schmelzle, Aurelien Lucchi, Tomasz Kacprzak, Adam Amara, Raphael Sgier, Alexandre Réfrégier, Thomas Hofmann category:astro-ph.CO stat.ML  published:2017-07-17 summary:We demonstrate the potential of Deep Learning methods for measurements of cosmological parameters from density fields, focusing on the extraction of non-Gaussian information. We consider weak lensing mass maps as our dataset. We aim for our method to be able to distinguish between five models, which were chosen to lie along the $\sigma_8$ - $\Omega_m$ degeneracy, and have nearly the same two-point statistics. We design and implement a Deep Convolutional Neural Network (DCNN) which learns the relation between five cosmological models and the mass maps they generate. We develop a new training strategy which ensures the good performance of the network for high levels of noise. We compare the performance of this approach to commonly used non-Gaussian statistics, namely the skewness and kurtosis of the convergence maps. We find that our implementation of DCNN outperforms the skewness and kurtosis statistics, especially for high noise levels. The network maintains the mean discrimination efficiency greater than $85\%$ even for noise levels corresponding to ground based lensing observations, while the other statistics perform worse in this setting, achieving efficiency less than $70\%$. This demonstrates the ability of CNN-based methods to efficiently break the $\sigma_8$ - $\Omega_m$ degeneracy with weak lensing mass maps alone. We discuss the potential of this method to be applied to the analysis of real weak lensing data and other datasets. version:2
arxiv-1703-10847 | MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation | http://arxiv.org/abs/1703.10847 | id:1703.10847 author:Li-Chia Yang, Szu-Yu Chou, Yi-Hsuan Yang category:cs.SD cs.AI  published:2017-03-31 summary:Most existing neural network models for music generation use recurrent neural networks. However, the recent WaveNet model proposed by DeepMind shows that convolutional neural networks (CNNs) can also generate realistic musical waveforms in the audio domain. Following this light, we investigate using CNNs for generating melody (a series of MIDI notes) one bar after another in the symbolic domain. In addition to the generator, we use a discriminator to learn the distributions of melodies, making it a generative adversarial network (GAN). Moreover, we propose a novel conditional mechanism to exploit available prior knowledge, so that the model can generate melodies either from scratch, by following a chord sequence, or by conditioning on the melody of previous bars (e.g. a priming melody), among other possibilities. The resulting model, named MidiNet, can be expanded to generate music with multiple MIDI channels (i.e. tracks). We conduct a user study to compare the melody of eight-bar long generated by MidiNet and by Google's MelodyRNN models, each time using the same priming melody. Result shows that MidiNet performs comparably with MelodyRNN models in being realistic and pleasant to listen to, yet MidiNet's melodies are reported to be much more interesting. version:2
arxiv-1707-02725 | Interleaved Group Convolutions for Deep Neural Networks | http://arxiv.org/abs/1707.02725 | id:1707.02725 author:Ting Zhang, Guo-Jun Qi, Bin Xiao, Jingdong Wang category:cs.CV  published:2017-07-10 summary:In this paper, we present a simple and modularized neural network architecture, named interleaved group convolutional neural networks (IGCNets). The main point lies in a novel building block, a pair of two successive interleaved group convolutions: primary group convolution and secondary group convolution. The two group convolutions are complementary: (i) the convolution on each partition in primary group convolution is a spatial convolution, while on each partition in secondary group convolution, the convolution is a point-wise convolution; (ii) the channels in the same secondary partition come from different primary partitions. We discuss one representative advantage: Wider than a regular convolution with the number of parameters and the computation complexity preserved. We also show that regular convolutions, group convolution with summation fusion, and the Xception block are special cases of interleaved group convolutions. Empirical results over standard benchmarks, CIFAR-$10$, CIFAR-$100$, SVHN and ImageNet demonstrate that our networks are more efficient in using parameters and computation complexity with similar or higher accuracy. version:2
arxiv-1705-05415 | Robotic Wireless Sensor Networks | http://arxiv.org/abs/1705.05415 | id:1705.05415 author:Pradipta Ghosh, Andrea Gasparri, Jiong Jin, Bhaskar Krishnamachari category:cs.RO cs.SY  published:2017-05-15 summary:In this chapter, we present a literature survey of an emerging, cutting-edge, and multi-disciplinary field of research at the intersection of Robotics and Wireless Sensor Networks (WSN) which we refer to as Robotic Wireless Sensor Networks (RWSN). We define a Robotic Wireless Sensor Network as an autonomous networked multi-robot system that aims to achieve certain sensing goals while meeting and maintaining certain communication performance requirements, through cooperative control, learning and adaptation. While both of the component areas, i.e., Robotics and WSN, are very well-known and well-explored, there exist a whole set of new opportunities and research directions at the intersection of these two fields which are relatively or even completely unexplored. One such example would be the use of a set of robotic routers to set up a temporary communication path between a sender and a receiver that uses the controlled mobility to the advantage of packet routing. We find that there exist only a limited number of articles to be directly categorized as RWSN related works whereas there exist a range of articles in the robotics and the WSN literature that are also relevant to this new field of research. To connect the dots, we first identify the core problems and research trends related to RWSN such as connectivity, localization, routing, and robust flow of information. Next, we classify the existing research on RWSN as well as the relevant state-of-the-arts from robotics and WSN community according to the problems and trends identified in the first step. Lastly, we analyze what is missing in the existing literature, and identify topics that require more research attention in the future. version:2
arxiv-1707-05501 | Story Generation from Sequence of Independent Short Descriptions | http://arxiv.org/abs/1707.05501 | id:1707.05501 author:Parag Jain, Priyanka Agrawal, Abhijit Mishra, Mohak Sukhwani, Anirban Laha, Karthik Sankaranarayanan category:cs.CL  published:2017-07-18 summary:Existing Natural Language Generation (NLG) systems are weak AI systems and exhibit limited capabilities when language generation tasks demand higher levels of creativity, originality and brevity. Effective solutions or, at least evaluations of modern NLG paradigms for such creative tasks have been elusive, unfortunately. This paper introduces and addresses the task of coherent story generation from independent descriptions, describing a scene or an event. Towards this, we explore along two popular text-generation paradigms -- (1) Statistical Machine Translation (SMT), posing story generation as a translation problem and (2) Deep Learning, posing story generation as a sequence to sequence learning problem. In SMT, we chose two popular methods such as phrase based SMT (PB-SMT) and syntax based SMT (SYNTAX-SMT) to `translate' the incoherent input text into stories. We then implement a deep recurrent neural network (RNN) architecture that encodes sequence of variable length input descriptions to corresponding latent representations and decodes them to produce well formed comprehensive story like summaries. The efficacy of the suggested approaches is demonstrated on a publicly available dataset with the help of popular machine translation and summarization evaluation metrics. version:1
arxiv-1707-05031 | Residual Features and Unified Prediction Network for Single Stage Detection | http://arxiv.org/abs/1707.05031 | id:1707.05031 author:Kyoungmin Lee, Jaeseok Choi, Jisoo Jeong, Nojun Kwak category:cs.CV  published:2017-07-17 summary:Recently, a lot of single stage detectors using multi-scale features have been actively proposed. They are much faster than two stage detectors using region proposal networks (RPN) without much degradation in the detection performances. However, the feature maps in the lower layers close to the input which are used to detect small objects in a single stage detector have a problem of insufficient representation power because they are too shallow. There is also a structural contradiction that the feature maps have to deliver low-level information to next layers as well as contain high-level abstraction for prediction. In this paper, we propose a method to enrich the representation power of feature maps using ResBlock and deconvolutional layers. In addition, a unified prediction module is applied to generalize output results. The proposed method enabled more precise prediction and scored 77.0% mAP on PASCAL VOC 2012 test set, which is 1.5% higher than that of SSD300. In addition, it takes 15.6 milliseconds for Titan X Pascal GPU, which indicates that it maintains the advantage of fast computation of a single stage detector. version:2
arxiv-1707-05499 | A Machine Learning Approach for Evaluating Creative Artifacts | http://arxiv.org/abs/1707.05499 | id:1707.05499 author:Disha Shrivastava, Saneem Ahmed CG, Anirban Laha, Karthik Sankaranarayanan category:cs.LG cs.AI stat.ML  published:2017-07-18 summary:Much work has been done in understanding human creativity and defining measures to evaluate creativity. This is necessary mainly for the reason of having an objective and automatic way of quantifying creative artifacts. In this work, we propose a regression-based learning framework which takes into account quantitatively the essential criteria for creativity like novelty, influence, value and unexpectedness. As it is often the case with most creative domains, there is no clear ground truth available for creativity. Our proposed learning framework is applicable to all creative domains; yet we evaluate it on a dataset of movies created from IMDb and Rotten Tomatoes due to availability of audience and critic scores, which can be used as proxy ground truth labels for creativity. We report promising results and observations from our experiments in the following ways : 1) Correlation of creative criteria with critic scores, 2) Improvement in movie rating prediction with inclusion of various creative criteria, and 3) Identification of creative movies. version:1
arxiv-1707-05497 | Differentially Private Identity and Closeness Testing of Discrete Distributions | http://arxiv.org/abs/1707.05497 | id:1707.05497 author:Maryam Aliakbarpour, Ilias Diakonikolas, Ronitt Rubinfeld category:cs.LG cs.DS cs.IT math.IT stat.ML  published:2017-07-18 summary:We investigate the problems of identity and closeness testing over a discrete population from random samples. Our goal is to develop efficient testers while guaranteeing Differential Privacy to the individuals of the population. We describe an approach that yields sample-efficient differentially private testers for these problems. Our theoretical results show that there exist private identity and closeness testers that are nearly as sample-efficient as their non-private counterparts. We perform an experimental evaluation of our algorithms on synthetic data. Our experiments illustrate that our private testers achieve small type I and type II errors with sample size sublinear in the domain size of the underlying distributions. version:1
arxiv-1707-05495 | Order-Free RNN with Visual Attention for Multi-Label Classification | http://arxiv.org/abs/1707.05495 | id:1707.05495 author:Shang-Fu Chen, Yi-Chen Chen, Chih-Kuan Yeh, Yu-Chiang Frank Wang category:cs.CV  published:2017-07-18 summary:In this paper, we propose the joint learning attention and recurrent neural network (RNN) models for multi-label classification. While approaches based on the use of either model exist (e.g., for the task of image captioning), training such existing network architectures typically require pre-defined label sequences. For multi-label classification, it would be desirable to have a robust inference process, so that the prediction error would not propagate and thus affect the performance. Our proposed model uniquely integrates attention and Long Short Term Memory (LSTM) models, which not only addresses the above problem but also allows one to identify visual objects of interests with varying sizes without the prior knowledge of particular label ordering. More importantly, label co-occurrence information can be jointly exploited by our LSTM model. Finally, by advancing the technique of beam search, prediction of multiple labels can be efficiently achieved by our proposed network model. version:1
arxiv-1707-05493 | ARREST: A RSSI Based Approach for Mobile Sensing and Tracking of a Moving Object | http://arxiv.org/abs/1707.05493 | id:1707.05493 author:Pradipta Ghosh, Jason A. Tran, Bhaskar Krishnamachari category:cs.RO cs.AI cs.NI  published:2017-07-18 summary:We present Autonomous Rssi based RElative poSitioning and Tracking (ARREST), a new robotic sensing system for tracking and following a moving, RF-emitting object, which we refer to as the Leader, solely based on signal strength information. This kind of system can expand the horizon of autonomous mobile tracking and distributed robotics into many scenarios with limited visibility such as nighttime, dense forests, and cluttered environments. Our proposed tracking agent, which we refer to as the TrackBot, uses a single rotating, off-the-shelf, directional antenna, novel angle and relative speed estimation algorithms, and Kalman filtering to continually estimate the relative position of the Leader with decimeter level accuracy (which is comparable to a state-of-the-art multiple access point based RF-localization system) and the relative speed of the Leader with accuracy on the order of 1 m/s. The TrackBot feeds the relative position and speed estimates into a Linear Quadratic Gaussian (LQG) controller to generate a set of control outputs to control the orientation and the movement of the TrackBot. We perform an extensive set of real world experiments with a full-fledged prototype to demonstrate that the TrackBot is able to stay within 5m of the Leader with: (1) more than $99\%$ probability in line of sight scenarios, and (2) more than $70\%$ probability in no line of sight scenarios, when it moves 1.8X faster than the Leader. For ground truth estimation in real world experiments, we also developed an integrated TDoA based distance and angle estimation system with centimeter level localization accuracy in line of sight scenarios. While providing a first proof of concept, our work opens the door to future research aimed at further improvements of autonomous RF-based tracking. version:1
arxiv-1707-05489 | Vision-based Real Estate Price Estimation | http://arxiv.org/abs/1707.05489 | id:1707.05489 author:Omid Poursaeed, Tomas Matera, Serge Belongie category:cs.CV cs.LG  published:2017-07-18 summary:Since the advent of online real estate database companies like Zillow, Trulia and Redfin, the problem of automatic estimation of market values for houses has received considerable attention. Several real estate websites provide such estimates using a proprietary formula. Although these estimates are often close to the actual sale prices, in some cases they are highly inaccurate. One of the key factors that affects the value of a house is its interior and exterior appearance, which is not considered in calculating automatic value estimates. In this paper, we evaluate the impact of visual characteristics of a house on its market value. Using deep convolutional neural networks on a large dataset of photos of home interiors and exteriors, we develop a method for estimating the luxury level of real estate photos. We also develop a novel framework for automated value assessment using the above photos in addition to home characteristics including size, offered price and number of bedrooms. Finally, by applying our proposed method for price estimation to a new dataset of real estate photos and metadata, we show that it outperforms Zillow's estimates. version:1
arxiv-1707-05481 | A Linguistic Model of Classifying and Clustering Community Pages in a Social Network Based on User Interests | http://arxiv.org/abs/1707.05481 | id:1707.05481 author:Elena Mikhalkova, Yuri Karyakin, Natalia Drozhashchikh, Natalia Rogacheva category:cs.CL cs.IR cs.SI  published:2017-07-18 summary:Social networks provide people with an opportunity to form social clusters that share interests not only sporadically, but on a regular basis (circles of fans of different music, books, kinds of sports, etc.). Every circle communicates these interests creating lots of linguistic data to attract new followers and support interests of the existing ones. In the present article, we suggest a linguistic model of classifying VKontakte pages by interests of their followers and test its effectiveness with such classifiers as Naive Bayes, SVM and some other. The task of cross-classification within three particular groups sharing a specific interest (football, vegetarianism, historical reenactment) is solved with F1-score reaching 0.99 for some classes. We also suggest a clustering procedure to retrieve texts of these groups from a collection of up to 1,000 random texts. When we enrich linguistic data with the help of DBpedia Spotlight, clustering becomes more effective. version:1
arxiv-1707-09866 | Guided Co-training for Large-Scale Multi-View Spectral Clustering | http://arxiv.org/abs/1707.09866 | id:1707.09866 author:Tyng-Luh Liu category:cs.CV  published:2017-07-18 summary:In many real-world applications, we have access to multiple views of the data, each of which characterizes the data from a distinct aspect. Several previous algorithms have demonstrated that one can achieve better clustering accuracy by integrating information from all views appropriately than using only an individual view. Owing to the effectiveness of spectral clustering, many multi-view clustering methods are based on it. Unfortunately, they have limited applicability to large-scale data due to the high computational complexity of spectral clustering. In this work, we propose a novel multi-view spectral clustering method for large-scale data. Our approach is structured under the guided co-training scheme to fuse distinct views, and uses the sampling technique to accelerate spectral clustering. More specifically, we first select $p$ ($\ll n$) landmark points and then approximate the eigen-decomposition accordingly. The augmented view, which is essential to guided co-training process, can then be quickly determined by our method. The proposed algorithm scales linearly with the number of given data. Extensive experiments have been performed and the results support the advantage of our method for handling the large-scale multi-view situation. version:1
arxiv-1707-05479 | PunFields at SemEval-2017 Task 7: Employing Roget's Thesaurus in Automatic Pun Recognition and Interpretation | http://arxiv.org/abs/1707.05479 | id:1707.05479 author:Elena Mikhalkova, Yuri Karyakin category:cs.CL  published:2017-07-18 summary:The article describes a model of automatic interpretation of English puns, based on Roget's Thesaurus, and its implementation, PunFields. In a pun, the algorithm discovers two groups of words that belong to two main semantic fields. The fields become a semantic vector based on which an SVM classifier learns to recognize puns. A rule-based model is then applied for recognition of intentionally ambiguous (target) words and their definitions. In SemEval Task 7 PunFields shows a considerably good result in pun classification, but requires improvement in searching for the target word and its definition. version:1
arxiv-1705-05065 | AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles | http://arxiv.org/abs/1705.05065 | id:1705.05065 author:Shital Shah, Debadeepta Dey, Chris Lovett, Ashish Kapoor category:cs.RO cs.AI cs.CV cs.SY  published:2017-05-15 summary:Developing and testing algorithms for autonomous vehicles in real world is an expensive and time consuming process. Also, in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments. We present a new simulator built on Unreal Engine that offers physically and visually realistic simulations for both of these goals. Our simulator includes a physics engine that can operate at a high frequency for real-time hardware-in-the-loop (HITL) simulations with support for popular protocols (e.g. MavLink). The simulator is designed from the ground up to be extensible to accommodate new types of vehicles, hardware platforms and software protocols. In addition, the modular design enables various components to be easily usable independently in other projects. We demonstrate the simulator by first implementing a quadrotor as an autonomous vehicle and then experimentally comparing the software components with real-world flights. version:2
arxiv-1707-05474 | AE-GAN: adversarial eliminating with GAN | http://arxiv.org/abs/1707.05474 | id:1707.05474 author:Shiwei Shen, Guoqing Jin, Ke Gao, Yongdong Zhang category:cs.CV  published:2017-07-18 summary:Although Neural networks could achieve state-of-the-art performance while recongnizing images, they often suffer a tremendous defeat from adversarial examples--inputs generated by utilizing imperceptible but intentional perturbations to samples from the datasets. How to defense against adversarial examples is an important problem which is well worth to research. So far, only two well-known methods adversarial training and defensive distillation have provided a significant defense. In contrast to existing methods mainly based on model itself, we address the problem purely based on the adversarial examples itself. In this paper, a novel idea and the first framework based Generative Adversarial Nets named AE-GAN capable of resisting adversarial examples are proposed. Extensive experiments on benchmark datasets indicate that AE-GAN is able to defense against adversarial examples effectively. version:1
arxiv-1707-05471 | DCTM: Discrete-Continuous Transformation Matching for Semantic Flow | http://arxiv.org/abs/1707.05471 | id:1707.05471 author:Seungryong Kim, Dongbo Min, Stephen Lin, Kwanghoon Sohn category:cs.CV  published:2017-07-18 summary:Techniques for dense semantic correspondence have provided limited ability to deal with the geometric variations that commonly exist between semantically similar images. While variations due to scale and rotation have been examined, there lack practical solutions for more complex deformations such as affine transformations because of the tremendous size of the associated solution space. To address this problem, we present a discrete-continuous transformation matching (DCTM) framework where dense affine transformation fields are inferred through a discrete label optimization in which the labels are iteratively updated via continuous regularization. In this way, our approach draws solutions from the continuous space of affine transformations in a manner that can be computed efficiently through constant-time edge-aware filtering and a proposed affine-varying CNN-based descriptor. Experimental results show that this model outperforms the state-of-the-art methods for dense semantic correspondence on various benchmarks. version:1
arxiv-1512-06257 | Up in the Air: When Homes Meet the Web of Things | http://arxiv.org/abs/1512.06257 | id:1512.06257 author:Lina Yao, Quan Z. Sheng, Boualem Benatallah, Schahram Dustdar, Xianzhi Wang, Ali Shemshadi, Anne H. H. Ngu category:cs.CY cs.DC  published:2015-12-19 summary:The emerging Internet of Things (IoT) will comprise billions of Web-enabled objects (or "things") where such objects can sense, communicate, compute and potentially actuate. WoT is essentially the embodiment of the evolution from systems linking digital documents to systems relating digital information to real-world physical items. It is widely understood that significant technical challenges exist in developing applications in the WoT environment. In this paper, we report our practical experience in the design and development of a smart home system in a WoT environment. Our system provides a layered framework for managing and sharing the information produced by physical things as well as the residents. We particularly focus on a research prototype named WITS, that helps the elderly live independently and safely in their own homes, with minimal support from the decreasing number of individuals in the working-age population. WITS enables an unobtrusive monitoring of elderly people in a real-world, inhabituated home environment, by leveraging WoT technologies in building context-aware, personalized services. version:3
arxiv-1707-05470 | DeepProbe: Information Directed Sequence Understanding and Chatbot Design via Recurrent Neural Networks | http://arxiv.org/abs/1707.05470 | id:1707.05470 author:Zi Yin, Keng-hao Chang, Ruofei Zhang category:stat.ML cs.LG  published:2017-07-18 summary:Information extraction and user intention identification are central topics in modern query understanding and recommendation systems. In this paper, we propose DeepProbe, a generic information-directed interaction framework which is built around an attention-based sequence to sequence (seq2seq) recurrent neural network. DeepProbe can rephrase, evaluate, and even actively ask questions, leveraging the generative ability and likelihood estimation made possible by seq2seq models. DeepProbe makes decisions based on a derived uncertainty (entropy) measure conditioned on user inputs, possibly with multiple rounds of interactions. Three applications, namely a rewritter, a relevance scorer and a chatbot for ad recommendation, were built around DeepProbe, with the first two serving as precursory building blocks for the third. We first use the seq2seq model in DeepProbe to rewrite a user query into one of standard query form, which is submitted to an ordinary recommendation system. Secondly, we evaluate DeepProbe's seq2seq model-based relevance scoring. Finally, we build a chatbot prototype capable of making active user interactions, which can ask questions that maximize information gain, allowing for a more efficient user intention idenfication process. We evaluate first two applications by 1) comparing with baselines by BLEU and AUC, and 2) human judge evaluation. Both demonstrate significant improvements compared with current state-of-the-art systems, proving their values as useful tools on their own, and at the same time laying a good foundation for the ongoing chatbot application. version:1
arxiv-1707-05468 | Detecting Intentional Lexical Ambiguity in English Puns | http://arxiv.org/abs/1707.05468 | id:1707.05468 author:Elena Mikhalkova, Yuri Karyakin category:cs.CL  published:2017-07-18 summary:The article describes a model of automatic analysis of puns, where a word is intentionally used in two meanings at the same time (the target word). We employ Roget's Thesaurus to discover two groups of words which, in a pun, form around two abstract bits of meaning (semes). They become a semantic vector, based on which an SVM classifier learns to recognize puns, reaching a score 0.73 for F-measure. We apply several rule-based methods to locate intentionally ambiguous (target) words, based on structural and semantic criteria. It appears that the structural criterion is more effective, although it possibly characterizes only the tested dataset. The results we get correlate with the results of other teams at SemEval-2017 competition (Task 7 Detection and Interpretation of English Puns) considering effects of using supervised learning models and word statistics. version:1
arxiv-1707-05466 | Coresets for Triangulation | http://arxiv.org/abs/1707.05466 | id:1707.05466 author:Qianggong Zhang, Tat-Jun Chin category:cs.CG cs.CV  published:2017-07-18 summary:Multiple-view triangulation by $\ell_{\infty}$ minimisation has become established in computer vision. State-of-the-art $\ell_{\infty}$ triangulation algorithms exploit the quasiconvexity of the cost function to derive iterative update rules that deliver the global minimum. Such algorithms, however, can be computationally costly for large problem instances that contain many image measurements, e.g., from web-based photo sharing sites or long-term video recordings. In this paper, we prove that $\ell_{\infty}$ triangulation admits a coreset approximation scheme, which seeks small representative subsets of the input data called coresets. A coreset possesses the special property that the error of the $\ell_{\infty}$ solution on the coreset is within known bounds from the global minimum. We establish the necessary mathematical underpinnings of the coreset algorithm, specifically, by enacting the stopping criterion of the algorithm and proving that the resulting coreset gives the desired approximation accuracy. On large-scale triangulation problems, our method provides theoretically sound approximate solutions. Iterated until convergence, our coreset algorithm is also guaranteed to reach the true optimum. On practical datasets, we show that our technique can in fact attain the global minimiser much faster than current methods version:1
arxiv-1707-05458 | Stabilization Control of the Differential Mobile Robot Using Lyapunov Function and Extended Kalman Filter | http://arxiv.org/abs/1707.05458 | id:1707.05458 author:T. T. Hoang, P. M. Duong, N. T. T. Van, T. Q. Vinh category:cs.RO cs.SY  published:2017-07-18 summary:This paper presents the design of a control model to navigate the differential mobile robot to reach the desired destination from an arbitrary initial pose. The designed model is divided into two stages: the state estimation and the stabilization control. In the state estimation, an extended Kalman filter is employed to optimally combine the information from the system dynamics and measurements. Two Lyapunov functions are constructed that allow a hybrid feedback control law to execute the robot movements. The asymptotical stability and robustness of the closed loop system are assured. Simulations and experiments are carried out to validate the effectiveness and applicability of the proposed approach. version:1
arxiv-1707-05456 | Control of an Internet-based Robot System Using the Real-time Transport Protocol | http://arxiv.org/abs/1707.05456 | id:1707.05456 author:P. M. Duong, T. T. Hoang, T. Q. Vinh category:cs.RO cs.NI cs.SY  published:2017-07-18 summary:In this paper, we introduce a novel approach in controlling robot systems over the Internet. The Real-time Transport Protocol (RTP) is used as the communication protocol instead of traditionally using TCP and UDP. The theoretic analyses, the simulation studies and the experimental implementation have been performed to evaluate the feasibility and effectiveness of the proposed approach for practical uses. version:1
arxiv-1707-05455 | Pruning Convolutional Neural Networks for Image Instance Retrieval | http://arxiv.org/abs/1707.05455 | id:1707.05455 author:Gaurav Manek, Jie Lin, Vijay Chandrasekhar, Lingyu Duan, Sateesh Giduthuri, Xiaoli Li, Tomaso Poggio category:cs.CV  published:2017-07-18 summary:In this work, we focus on the problem of image instance retrieval with deep descriptors extracted from pruned Convolutional Neural Networks (CNN). The objective is to heavily prune convolutional edges while maintaining retrieval performance. To this end, we introduce both data-independent and data-dependent heuristics to prune convolutional edges, and evaluate their performance across various compression rates with different deep descriptors over several benchmark datasets. Further, we present an end-to-end framework to fine-tune the pruned network, with a triplet loss function specially designed for the retrieval task. We show that the combination of heuristic pruning and fine-tuning offers 5x compression rate without considerable loss in retrieval performance. version:1
arxiv-1512-08493 | Unveiling Contextual Similarity of Things via Mining Human-Thing Interactions in the Internet of Things | http://arxiv.org/abs/1512.08493 | id:1512.08493 author:Lina Yao, Quan Z. Sheng, Anne H. H. Ngu, Xue Li, Boualem Benatallah category:cs.CY cs.DB cs.DC  published:2015-12-24 summary:With recent advances in radio-frequency identification (RFID), wireless sensor networks, and Web services, physical things are becoming an integral part of the emerging ubiquitous Web. Finding correlations of ubiquitous things is a crucial prerequisite for many important applications such as things search, discovery, classification, recommendation, and composition. This article presents DisCor-T, a novel graph-based method for discovering underlying connections of things via mining the rich content embodied in human-thing interactions in terms of user, temporal and spatial information. We model these various information using two graphs, namely spatio-temporal graph and social graph. Then, random walk with restart (RWR) is applied to find proximities among things, and a relational graph of things (RGT) indicating implicit correlations of things is learned. The correlation analysis lays a solid foundation contributing to improved effectiveness in things management. To demonstrate the utility, we develop a flexible feature-based classification framework on top of RGT and perform a systematic case study. Our evaluation exhibits the strength and feasibility of the proposed approach. version:3
arxiv-1707-05446 | Discriminative Transformation Learning for Fuzzy Sparse Subspace Clustering | http://arxiv.org/abs/1707.05446 | id:1707.05446 author:Zaidao Wen, Biao Hou, Qian Wu, Licheng Jiao category:cs.CV  published:2017-07-18 summary:This paper develops a novel iterative framework for subspace clustering in a learned discriminative feature domain. This framework consists of two modules of fuzzy sparse subspace clustering and discriminative transformation learning. In the first module, fuzzy latent labels containing discriminative information and latent representations capturing the subspace structure will be simultaneously evaluated in a feature domain. Then the linear transforming operator with respect to the feature domain will be successively updated in the second module with the advantages of more discrimination, subspace structure preservation and robustness to outliers. These two modules will be alternatively carried out and both theoretical analysis and empirical evaluations will demonstrate its effectiveness and superiorities. In particular, experimental results on three benchmark databases for subspace clustering clearly illustrate that the proposed framework can achieve significant improvements than other state-of-the-art approaches in terms of clustering accuracy. version:1
arxiv-1707-05438 | Top-Rank Enhanced Listwise Optimization for Statistical Machine Translation | http://arxiv.org/abs/1707.05438 | id:1707.05438 author:Huadong Chen, Shujian Huang, David Chiang, Xinyu Dai, Jiajun Chen category:cs.CL  published:2017-07-18 summary:Pairwise ranking methods are the basis of many widely used discriminative training approaches for structure prediction problems in natural language processing(NLP). Decomposing the problem of ranking hypotheses into pairwise comparisons enables simple and efficient solutions. However, neglecting the global ordering of the hypothesis list may hinder learning. We propose a listwise learning framework for structure prediction problems such as machine translation. Our framework directly models the entire translation list's ordering to learn parameters which may better fit the given listwise samples. Furthermore, we propose top-rank enhanced loss functions, which are more sensitive to ranking errors at higher positions. Experiments on a large-scale Chinese-English translation task show that both our listwise learning framework and top-rank enhanced listwise losses lead to significant improvements in translation quality. version:1
arxiv-1707-05436 | Improved Neural Machine Translation with a Syntax-Aware Encoder and Decoder | http://arxiv.org/abs/1707.05436 | id:1707.05436 author:Huadong Chen, Shujian Huang, David Chiang, Jiajun Chen category:cs.CL  published:2017-07-18 summary:Most neural machine translation (NMT) models are based on the sequential encoder-decoder framework, which makes no use of syntactic information. In this paper, we improve this model by explicitly incorporating source-side syntactic trees. More specifically, we propose (1) a bidirectional tree encoder which learns both sequential and tree structured representations; (2) a tree-coverage model that lets the attention depend on the source-side syntax. Experiments on Chinese-English translation demonstrate that our proposed models outperform the sequential attentional model as well as a stronger baseline with a bottom-up tree encoder and word coverage. version:1
arxiv-1707-04912 | Improving Deep Pancreas Segmentation in CT and MRI Images via Recurrent Neural Contextual Learning and Direct Loss Function | http://arxiv.org/abs/1707.04912 | id:1707.04912 author:Jinzheng Cai, Le Lu, Yuanpu Xie, Fuyong Xing, Lin Yang category:cs.CV  published:2017-07-16 summary:Deep neural networks have demonstrated very promising performance on accurate segmentation of challenging organs (e.g., pancreas) in abdominal CT and MRI scans. The current deep learning approaches conduct pancreas segmentation by processing sequences of 2D image slices independently through deep, dense per-pixel masking for each image, without explicitly enforcing spatial consistency constraint on segmentation of successive slices. We propose a new convolutional/recurrent neural network architecture to address the contextual learning and segmentation consistency problem. A deep convolutional sub-network is first designed and pre-trained from scratch. The output layer of this network module is then connected to recurrent layers and can be fine-tuned for contextual learning, in an end-to-end manner. Our recurrent sub-network is a type of Long short-term memory (LSTM) network that performs segmentation on an image by integrating its neighboring slice segmentation predictions, in the form of a dependent sequence processing. Additionally, a novel segmentation-direct loss function (named Jaccard Loss) is proposed and deep networks are trained to optimize Jaccard Index (JI) directly. Extensive experiments are conducted to validate our proposed deep models, on quantitative pancreas segmentation using both CT and MRI scans. Our method outperforms the state-of-the-art work on CT [11] and MRI pancreas segmentation [1], respectively. version:2
arxiv-1707-05427 | Visually Aligned Word Embeddings for Improving Zero-shot Learning | http://arxiv.org/abs/1707.05427 | id:1707.05427 author:Ruizhi Qiao, Lingqiao Liu, Chunhua Shen, Anton van den Hengel category:cs.CV  published:2017-07-18 summary:Zero-shot learning (ZSL) highly depends on a good semantic embedding to connect the seen and unseen classes. Recently, distributed word embeddings (DWE) pre-trained from large text corpus have become a popular choice to draw such a connection. Compared with human defined attributes, DWEs are more scalable and easier to obtain. However, they are designed to reflect semantic similarity rather than visual similarity and thus using them in ZSL often leads to inferior performance. To overcome this visual-semantic discrepancy, this work proposes an objective function to re-align the distributed word embeddings with visual information by learning a neural network to map it into a new representation called visually aligned word embedding (VAWE). Thus the neighbourhood structure of VAWEs becomes similar to that in the visual domain. Note that in this work we do not design a ZSL method that projects the visual features and semantic embeddings onto a shared space but just impose a requirement on the structure of the mapped word embeddings. This strategy allows the learned VAWE to generalize to various ZSL methods and visual features. As evaluated via four state-of-the-art ZSL methods on four benchmark datasets, the VAWE exhibit consistent performance improvement. version:1
arxiv-1707-05425 | Fast and Accurate Image Super Resolution by Deep CNN with Skip Connection and Network in Network | http://arxiv.org/abs/1707.05425 | id:1707.05425 author:Jin Yamanaka, Shigesumi Kuwashima, Takio Kurita category:cs.CV  published:2017-07-18 summary:We propose a highly efficient and faster Single Image Super-Resolution (SISR) model with Deep Convolutional neural networks (Deep CNN). Deep CNN have recently shown that they have a significant reconstruction performance on single-image super-resolution. Current trend is using deeper CNN layers to improve performance. However, deep models demand larger computation resources and is not suitable for network edge devices like mobile, tablet and IoT devices. Our model achieves state of the art reconstruction performance with at least 10 times lower calculation cost by Deep CNN with Residual Net, Skip Connection and Network in Network (DCSCN). A combination of Deep CNNs and Skip connection layers is used as a feature extractor for image features on both local and global area. Parallelized 1x1 CNNs, like the one called Network in Network, is also used for image reconstruction. That structure reduces the dimensions of the previous layer's output for faster computation with less information loss, and make it possible to process original images directly. Also we optimize the number of layers and filters of each CNN to significantly reduce the calculation cost. Thus, the proposed algorithm not only achieves the state of the art performance but also achieves faster and efficient computation. Code is available at https://github.com/jiny2001/dcscn-super-resolution. version:1
arxiv-1707-05422 | Don't relax: early stopping for convex regularization | http://arxiv.org/abs/1707.05422 | id:1707.05422 author:Simon Matet, Lorenzo Rosasco, Silvia Villa, Bang Long Vu category:math.OC cs.LG  published:2017-07-18 summary:We consider the problem of designing efficient regularization algorithms when regularization is encoded by a (strongly) convex functional. Unlike classical penalization methods based on a relaxation approach, we propose an iterative method where regularization is achieved via early stopping. Our results show that the proposed procedure achieves the same recovery accuracy as penalization methods, while naturally integrating computational considerations. An empirical analysis on a number of problems provides promising results with respect to the state of the art. version:1
arxiv-1707-05420 | Cooperative Hierarchical Dirichlet Processes: Superposition vs. Maximization | http://arxiv.org/abs/1707.05420 | id:1707.05420 author:Junyu Xuan, Jie Lu, Guangquan Zhang, Richard Yi Da Xu category:cs.LG stat.ML  published:2017-07-18 summary:The cooperative hierarchical structure is a common and significant data structure observed in, or adopted by, many research areas, such as: text mining (author-paper-word) and multi-label classification (label-instance-feature). Renowned Bayesian approaches for cooperative hierarchical structure modeling are mostly based on topic models. However, these approaches suffer from a serious issue in that the number of hidden topics/factors needs to be fixed in advance and an inappropriate number may lead to overfitting or underfitting. One elegant way to resolve this issue is Bayesian nonparametric learning, but existing work in this area still cannot be applied to cooperative hierarchical structure modeling. In this paper, we propose a cooperative hierarchical Dirichlet process (CHDP) to fill this gap. Each node in a cooperative hierarchical structure is assigned a Dirichlet process to model its weights on the infinite hidden factors/topics. Together with measure inheritance from hierarchical Dirichlet process, two kinds of measure cooperation, i.e., superposition and maximization, are defined to capture the many-to-many relationships in the cooperative hierarchical structure. Furthermore, two constructive representations for CHDP, i.e., stick-breaking and international restaurant process, are designed to facilitate the model inference. Experiments on synthetic and real-world data with cooperative hierarchical structures demonstrate the properties and the ability of CHDP for cooperative hierarchical structure modeling and its potential for practical application scenarios. version:1
arxiv-1707-04820 | Development of Direct Kinematics and Workspace Representation for Smokie Robot Manipulator & the Barret WAM | http://arxiv.org/abs/1707.04820 | id:1707.04820 author:Reza Yazdanpanah Abdolmalaki category:cs.RO  published:2017-07-16 summary:This paper discusses modelling two 6 DOF arm robots. The first step of modelling a robot is establishing its Denavit-Hartenberg parameters. It requires assigning proper coordinates for each link and finding their exact dimensions. In this project we will develop the direct kinematics and workspace representations for two manipulators: the Smokie Robot and the Barrett WAM. After finding the D-H parameters and creating Transformation Matrices,MATLAB programming is used to represent their workspaces. version:2
arxiv-1707-04821 | Geometric Jacobians Derivation and Kinematic Singularity Analysis for Smokie Robot Manipulator & the Barrett WAM | http://arxiv.org/abs/1707.04821 | id:1707.04821 author:Reza Yazdanpanah Abdolmalaki category:cs.RO  published:2017-07-16 summary:This paper discusses deriving geometric jacobians and identifying and analyzing the kinematic singularities for two 6 DOF arm robots. First we show the direct kinematics and D-H parameters derived for these two arms. The Geometric jacobian is computed for Barrett WAM and Smokie OUR. By analyzing the jacobian matrices we find the configurations at which J is rank deficient and derive the kinematic singularities through jacobian's determinent. Schematic are provided to show the singular configurations of both robots. Finally a survey is done on redundant kinematic allocation schemesfor 7 DoF Barrett WAM. version:2
arxiv-1707-04084 | An Earthworm-Inspired Soft Crawling Robot Controlled by Friction | http://arxiv.org/abs/1707.04084 | id:1707.04084 author:Joey Z. Ge, Ariel A. Calderón, Néstor O. Pérez-Arancibia category:cs.RO  published:2017-07-12 summary:We present the modeling, design, fabrication and feedback control of an earthworm-inspired soft robot capable of crawling on surfaces by actively manipulating the frictional force between its body and the surface. Earthworms are segmented worms composed of repeating units known as metameres. The muscle and setae structure embedded in each individual metamere makes possible its peristaltic locomotion both under and above ground. Here, we propose a pneumatically-driven soft robotic system made of parts analogous to the muscle and setae structure and can replicate the crawling motion of a single earthworm metamere. A model is also introduced to describe the crawling dynamics of the proposed robotic system and proven be controllable. Robust crawling locomotion is then experimentally verified. version:2
arxiv-1707-05414 | Wide Inference Network for Image Denoising | http://arxiv.org/abs/1707.05414 | id:1707.05414 author:Peng Liu, Ruogu Fang category:cs.CV  published:2017-07-17 summary:"Deeper is better" has been recently considered as a principal design criterion for building convolutional neural networks due to its favorable performance in both high-level and low-level computer vision tasks. In this paper, inspired by the importance of image priors in low-level vision tasks, we introduce Wide InferenceNetwork (WIN) with increased filter number and size for low-level vision tasks such as natural image denoising. The key to our approach is the observation that mapping from noisy to clean images primarily relies on the priors learned from feature distributions in the training stage, instead of reasoning through stacked nonlinear layers. We evaluate WIN on additive white Gaussian noise (AWGN) and demonstrate that by learning the prior distribution in natural images, WIN-based network consistently achieves significantly better performance than current state-of-the-art deep CNN-based methods in both quantitative and visual evaluations. version:1
arxiv-1703-08922 | On Automating the Doctrine of Double Effect | http://arxiv.org/abs/1703.08922 | id:1703.08922 author:Naveen Sundar Govindarajulu, Selmer Bringsjord category:cs.AI cs.LO cs.RO  published:2017-03-27 summary:The doctrine of double effect ($\mathcal{DDE}$) is a long-studied ethical principle that governs when actions that have both positive and negative effects are to be allowed. The goal in this paper is to automate $\mathcal{DDE}$. We briefly present $\mathcal{DDE}$, and use a first-order modal logic, the deontic cognitive event calculus, as our framework to formalize the doctrine. We present formalizations of increasingly stronger versions of the principle, including what is known as the doctrine of triple effect. We then use our framework to simulate successfully scenarios that have been used to test for the presence of the principle in human subjects. Our framework can be used in two different modes: One can use it to build $\mathcal{DDE}$-compliant autonomous systems from scratch, or one can use it to verify that a given AI system is $\mathcal{DDE}$-compliant, by applying a $\mathcal{DDE}$ layer on an existing system or model. For the latter mode, the underlying AI system can be built using any architecture (planners, deep neural networks, bayesian networks, knowledge-representation systems, or a hybrid); as long as the system exposes a few parameters in its model, such verification is possible. The role of the $\mathcal{DDE}$ layer here is akin to a (dynamic or static) software verifier that examines existing software modules. Finally, we end by presenting initial work on how one can apply our $\mathcal{DDE}$ layer to the STRIPS-style planning model, and to a modified POMDP model.This is preliminary work to illustrate the feasibility of the second mode, and we hope that our initial sketches can be useful for other researchers in incorporating DDE in their own frameworks. version:5
arxiv-1707-04476 | Big Data vs. complex physical models: a scalable inference algorithm | http://arxiv.org/abs/1707.04476 | id:1707.04476 author:J. Buchner category:stat.CO astro-ph.IM physics.data-an stat.ML  published:2017-07-14 summary:The data torrent unleashed by current and upcoming instruments requires scalable analysis methods. Machine Learning approaches scale well. However, separating the instrument measurement from the physical effects of interest, dealing with variable errors, and deriving parameter uncertainties is usually an after-thought. Classic forward-folding analyses with Markov Chain Monte Carlo or Nested Sampling enable parameter estimation and model comparison, even for complex and slow-to-evaluate physical models. However, these approaches require independent runs for each data set, implying an unfeasible number of model evaluations in the Big Data regime. Here we present a new algorithm based on nested sampling, deriving parameter probability distributions for each observation. Importantly, in our method the number of physical model evaluations scales sub-linearly with the number of data sets, and we make no assumptions about homogeneous errors, Gaussianity, the form of the model or heterogeneity/completeness of the observations. Our method has immediate application in speeding up analyses of large surveys, integral-field-unit observations, and Monte Carlo simulations. version:2
arxiv-1707-05399 | Performance Implications of NoCs on 3D-Stacked Memories: Insights from the Hybrid Memory Cube | http://arxiv.org/abs/1707.05399 | id:1707.05399 author:Ramyad Hadidi, Bahar Asgari, Jeffrey Young, Burhan Ahmad Mudassar, Kartikay Garg, Tushar Krishna, Hyesoon Kim category:cs.AR cs.ET  published:2017-07-17 summary:Memories that exploit three-dimensional (3D)-stacking technology, which integrate memory and logic dies in a single stack, are becoming popular. These memories, such as Hybrid Memory Cube (HMC), utilize a network-on-chip (NoC) design for connecting their internal structural organizations. This novel usage of NoC, in addition to aiding processing-in-memory capabilities, enables numerous benefits such as high bandwidth and memory-level parallelism. However, the implications of NoCs on the characteristics of 3D-stacked memories in terms of memory access latency and bandwidth have not been fully explored. This paper addresses this knowledge gap by (i) characterizing an HMC prototype on the AC-510 accelerator board and revealing its access latency behaviors, and (ii) by investigating the implications of such behaviors on system and software designs. version:1
arxiv-1707-05397 | Slanted Stixels: Representing San Francisco's Steepest Streets | http://arxiv.org/abs/1707.05397 | id:1707.05397 author:Daniel Hernandez-Juarez, Lukas Schneider, Antonio Espinosa, David Vázquez, Antonio M. López, Uwe Franke, Marc Pollefeys, Juan C. Moure category:cs.CV  published:2017-07-17 summary:In this work we present a novel compact scene representation based on Stixels that infers geometric and semantic information. Our approach overcomes the previous rather restrictive geometric assumptions for Stixels by introducing a novel depth model to account for non-flat roads and slanted objects. Both semantic and depth cues are used jointly to infer the scene representation in a sound global energy minimization formulation. Furthermore, a novel approximation scheme is introduced that uses an extremely efficient over-segmentation. In doing so, the computational complexity of the Stixel inference algorithm is reduced significantly, achieving real-time computation capabilities with only a slight drop in accuracy. We evaluate the proposed approach in terms of semantic and geometric accuracy as well as run-time on four publicly available benchmark datasets. Our approach maintains accuracy on flat road scene datasets while improving substantially on a novel non-flat road dataset. version:1
arxiv-1706-06243 | The Complexity of Campaigning | http://arxiv.org/abs/1706.06243 | id:1706.06243 author:Cory Siler, Luke Harold Miles, Judy Goldsmith category:cs.AI cs.LO  published:2017-06-20 summary:In "The Logic of Campaigning", Dean and Parikh consider a candidate making campaign statements to appeal to the voters. They model these statements as Boolean formulas over variables that represent stances on the issues, and study optimal candidate strategies under three proposed models of voter preferences based on the assignments that satisfy these formulas. We prove that voter utility evaluation is computationally hard under these preference models (in one case, #P-hard), along with certain problems related to candidate strategic reasoning. Our results raise questions about the desirable characteristics of a voter preference model and to what extent a polynomial-time-evaluable function can capture them. version:2
arxiv-1707-05395 | Incremental Boosting Convolutional Neural Network for Facial Action Unit Recognition | http://arxiv.org/abs/1707.05395 | id:1707.05395 author:Shizhong Han, Zibo Meng, Ahmed Shehab Khan, Yan Tong category:cs.CV  published:2017-07-17 summary:Recognizing facial action units (AUs) from spontaneous facial expressions is still a challenging problem. Most recently, CNNs have shown promise on facial AU recognition. However, the learned CNNs are often overfitted and do not generalize well to unseen subjects due to limited AU-coded training images. We proposed a novel Incremental Boosting CNN (IB-CNN) to integrate boosting into the CNN via an incremental boosting layer that selects discriminative neurons from the lower layer and is incrementally updated on successive mini-batches. In addition, a novel loss function that accounts for errors from both the incremental boosted classifier and individual weak classifiers was proposed to fine-tune the IB-CNN. Experimental results on four benchmark AU databases have demonstrated that the IB-CNN yields significant improvement over the traditional CNN and the boosting CNN without incremental learning, as well as outperforming the state-of-the-art CNN-based methods in AU recognition. The improvement is more impressive for the AUs that have the lowest frequencies in the databases. version:1
arxiv-1707-05392 | Freehand Ultrasound Image Simulation with Spatially-Conditioned Generative Adversarial Networks | http://arxiv.org/abs/1707.05392 | id:1707.05392 author:Yipeng Hu, Eli Gibson, Li-Lin Lee, Weidi Xie, Dean C. Barratt, Tom Vercauteren, J. Alison Noble category:cs.LG cs.CV  published:2017-07-17 summary:Sonography synthesis has a wide range of applications, including medical procedure simulation, clinical training and multimodality image registration. In this paper, we propose a machine learning approach to simulate ultrasound images at given 3D spatial locations (relative to the patient anatomy), based on conditional generative adversarial networks (GANs). In particular, we introduce a novel neural network architecture that can sample anatomically accurate images conditionally on spatial position of the (real or mock) freehand ultrasound probe. To ensure an effective and efficient spatial information assimilation, the proposed spatially-conditioned GANs take calibrated pixel coordinates in global physical space as conditioning input, and utilise residual network units and shortcuts of conditioning data in the GANs' discriminator and generator, respectively. Using optically tracked B-mode ultrasound images, acquired by an experienced sonographer on a fetus phantom, we demonstrate the feasibility of the proposed method by two sets of quantitative results: distances were calculated between corresponding anatomical landmarks identified in the held-out ultrasound images and the simulated data at the same locations unseen to the networks; a usability study was carried out to distinguish the simulated data from the real images. In summary, we present what we believe are state-of-the-art visually realistic ultrasound images, simulated by the proposed GAN architecture that is stable to train and capable of generating plausibly diverse image samples. version:1
arxiv-1707-05390 | TensorLog: Deep Learning Meets Probabilistic DBs | http://arxiv.org/abs/1707.05390 | id:1707.05390 author:William W. Cohen, Fan Yang, Kathryn Rivard Mazaitis category:cs.AI cs.LG I.2.4; I.2.6  published:2017-07-17 summary:We present an implementation of a probabilistic first-order logic called TensorLog, in which classes of logical queries are compiled into differentiable functions in a neural-network infrastructure such as Tensorflow or Theano. This leads to a close integration of probabilistic logical reasoning with deep-learning infrastructure: in particular, it enables high-performance deep learning frameworks to be used for tuning the parameters of a probabilistic logic. Experimental results show that TensorLog scales to problems involving hundreds of thousands of knowledge-base triples and tens of thousands of examples. version:1
arxiv-1707-05388 | Benchmarking and Error Diagnosis in Multi-Instance Pose Estimation | http://arxiv.org/abs/1707.05388 | id:1707.05388 author:Matteo Ruggero Ronchi, Pietro Perona category:cs.CV  published:2017-07-17 summary:We propose a new method to analyze the impact of errors in algorithms for multi-instance pose estimation and a principled benchmark that can be used to compare them. We define and characterize three main classes of errors - localization, scoring, and background - study how they are influenced by instance attributes and their impact on an algorithm's performance. Our technique is applied to compare the two leading methods for human pose estimation on the COCO Dataset, measure the sensitivity of pose estimation with respect to instance size, type and number of visible keypoints, clutter due to multiple instances, and the relative score of instances. The performance of algorithms, and the types of error they make, are highly dependent on all these variables, but mostly on the number of keypoints and the clutter. The analysis and software tools we propose offer a novel and insightful approach for understanding the behavior of pose estimation algorithms and an effective method for measuring their strengths and weaknesses. version:1
arxiv-1707-05385 | Make Your Bone Great Again : A study on Osteoporosis Classification | http://arxiv.org/abs/1707.05385 | id:1707.05385 author:Rahul Paul, Saeed Alahamri, Sulav Malla, Ghulam Jilani Quadri category:cs.CV  published:2017-07-17 summary:Osteoporosis can be identified by looking at 2D x-ray images of the bone. The high degree of similarity between images of a healthy bone and a diseased one makes classification a challenge. A good bone texture characterization technique is essential for identifying osteoporosis cases. Standard texture feature extraction techniques like Local Binary Pattern (LBP), Gray Level Co-occurrence Matrix (GLCM) have been used for this purpose. In this paper, we draw a comparison between deep features extracted from convolution neural network against these traditional features. Our results show that deep features have more discriminative power as classifiers trained on them always outperform the ones trained on traditional features. version:1
arxiv-1707-05373 | Houdini: Fooling Deep Structured Prediction Models | http://arxiv.org/abs/1707.05373 | id:1707.05373 author:Moustapha Cisse, Yossi Adi, Natalia Neverova, Joseph Keshet category:stat.ML cs.AI cs.CR cs.CV cs.LG  published:2017-07-17 summary:Generating adversarial examples is a critical step for evaluating and improving the robustness of learning machines. So far, most existing methods only work for classification and are not designed to alter the true performance measure of the problem at hand. We introduce a novel flexible approach named Houdini for generating adversarial examples specifically tailored for the final performance measure of the task considered, be it combinatorial and non-decomposable. We successfully apply Houdini to a range of applications such as speech recognition, pose estimation and semantic segmentation. In all cases, the attacks based on Houdini achieve higher success rate than those based on the traditional surrogates used to train the models while using a less perceptible adversarial perturbation. version:1
arxiv-1707-09865 | Remote sensing of forests using discrete return airborne LiDAR | http://arxiv.org/abs/1707.09865 | id:1707.09865 author:Hamid Hamraz, Marco A. Contreras category:cs.CV cs.CE cs.DC  published:2017-07-17 summary:Airborne discrete return light detection and ranging (LiDAR) point clouds covering forested areas can be processed to segment individual trees and retrieve their morphological attributes. Segmenting individual trees in natural deciduous forests however remained a challenge because of the complex and multi-layered canopy. In this chapter, we present (i) a robust segmentation method that avoids a priori assumptions about the canopy structure, (ii) a vertical canopy stratification procedure that improves segmentation of understory trees, (iii) an occlusion model for estimating the point density of each canopy stratum, and (iv) a distributed computing approach for efficient processing at the forest level. When applied to the University of Kentucky Robinson Forest, the segmentation method detected about 90% of overstory and 47% of understory trees with over-segmentation rates of 14% and 2%. Stratifying the canopy improved the detection rate of understory trees to 68% at the cost of increasing their over-segmentations to 16%. According to our occlusion model, a point density of ~170 pt/m-sqr is needed to segment understory trees as accurately as overstory trees. Lastly, using the distributed approach, we segmented about two million trees in the 7,440-ha forest in 2.5 hours using 192 processors, which is 167 times faster than using a single processor. Keywords: individual tree segmentation, multi-layered stand, vertical canopy stratification, segmentation evaluation, point density, canopy occlusion effect, big data, distributed computing. version:1
arxiv-1707-05368 | A robotic vision system to measure tree traits | http://arxiv.org/abs/1707.05368 | id:1707.05368 author:Amy Tabb, Henry Medeiros category:cs.RO  published:2017-07-17 summary:The autonomous measurement of tree traits, such as branching structure, branch diameters, branch lengths, and branch angles, is required for tasks such as robotic pruning of trees as well as structural phenotyping. We propose a robotic vision system called the Robotic System for Tree Shape Estimation (RoTSE) to determine tree traits in field settings. The process is composed of the following stages: image acquisition with a mobile robot unit, segmentation, reconstruction, curve skeletonization, conversion to a graph representation, and then computation of traits. Quantitative and qualitative results on apple trees are shown in terms of accuracy, computation time, and robustness. Compared to ground truth measurements, the RoTSE produced the following estimates: branch diameter (mean-squared error $0.99$ mm), branch length (mean-squared error $45.64$ mm), and branch angle (mean-squared error $10.36$ degrees). The average run time was 8.47 minutes when the voxel resolution was $3$ mm$^3$. version:1
arxiv-1707-05365 | An Information Theoretic Measure for Robot Expressivity | http://arxiv.org/abs/1707.05365 | id:1707.05365 author:A. LaViers category:cs.RO  published:2017-07-17 summary:This paper presents a principled way to think about articulated movement for artificial agents and a measurement of platforms that produce such movement. In particular, in human-facing scenarios, the shape evolution of robotic platforms will become essential in creating systems that integrate and communicate with human counterparts. This paper provides a tool to measure the expressive capacity or expressivity of articulated platforms. To do this, it points to the synergistic relationship between computation and mechanization. Importantly, this way of thinking gives an information theoretic basis for measuring and comparing robots of increasing complexity and capability. The paper will provide concrete examples of this measure in application to current robotic platforms. It will also provide a comparison between the computational and mechanical capabilities of robotic platforms and analyze order-of-magnitude trends over the last 15 years. Implications for future work made by the paper are to provide a method by which to quantify movement imitation, outline a way of thinking about designing expressive robotic systems, and contextualize the capabilities of current robotic systems. version:1
arxiv-1707-05354 | GPU LSM: A Dynamic Dictionary Data Structure for the GPU | http://arxiv.org/abs/1707.05354 | id:1707.05354 author:Saman Ashkiani, Shengren Li, Martin Farach-Colton, Nina Amenta, John D. Owens category:cs.DC  published:2017-07-17 summary:We develop and implement a concurrent dictionary data structure based on the Log Structured Merge tree (LSM), suitable for current massively parallel GPU architectures. Our GPU LSM is dynamic (mutable) in that it provides fast updates (insertions and deletions). For example, on an NVIDIA K40c GPU we can get an average update rate of 225 M elements/s (13.5x faster than merging with a sorted array). GPU LSM also supports lookup, count, and range query operations with an average rate of 75 M, 32 M and 23 M queries/s respectively. For lookups, we are 7.5x (and 1.75x) slower than a hash table (and a sorted array). However, none of these other data structures are considered mutable, and hash tables cannot even support count and range queries. We believe that our GPU LSM is the first dynamic general-purpose GPU data structure. version:1
arxiv-1707-05342 | An optimal unrestricted learning procedure | http://arxiv.org/abs/1707.05342 | id:1707.05342 author:Shahar Mendelson category:stat.ML  published:2017-07-17 summary:We study learning problems in the general setup, for arbitrary classes of functions $F$, distributions $X$ and targets $Y$. Because proper learning procedures, i.e., procedures that are only allowed to select functions in $F$, tend to perform poorly unless the problem satisfies some additional structural property (e.g., that $F$ is convex), we consider unrestricted learning procedures, that is, procedures that are free to choose functions outside the given class $F$. We present a new unrestricted procedure that is optimal in a very strong sense: it attains the best possible accuracy/confidence tradeoff for (almost) any triplet $(F,X,Y)$, including in heavy-tailed problems. Moreover, the tradeoff the procedure attains coincides with what one would expect if $F$ were convex, even when $F$ is not; and when $F$ happens to be convex, the procedure is proper; thus, the unrestricted procedure is actually optimal in both realms, for convex classes as a proper procedure and for arbitrary classes as an unrestricted procedure. The notion of optimality we consider is problem specific: our procedure performs with the best accuracy/confidence tradeoff one can hope to achieve for each individual problem. As such, it is a significantly stronger property than the standard `worst-case' notion, in which one considers optimality as the best uniform estimate that holds for a relatively large family of problems. Thanks to the sharp and problem-specific estimates we obtain, classical, worst-case bounds are immediate outcomes of our main result. version:1
arxiv-1707-05303 | Aggressive Deep Driving: Model Predictive Control with a CNN Cost Model | http://arxiv.org/abs/1707.05303 | id:1707.05303 author:Paul Drews, Grady Williams, Brian Goldfain, Evangelos A. Theodorou, James M. Rehg category:cs.RO 68T40  published:2017-07-17 summary:We present a framework for vision-based model predictive control (MPC) for the task of aggressive, high-speed autonomous driving. Our approach uses deep convolutional neural networks to predict cost functions from input video which are directly suitable for online trajectory optimization with MPC. We demonstrate the method in a high speed autonomous driving scenario, where we use a single monocular camera and a deep convolutional neural network to predict a cost map of the track in front of the vehicle. Results are demonstrated on a 1:5 scale autonomous vehicle given the task of high speed, aggressive driving. version:1
arxiv-1707-05300 | Reverse Curriculum Generation for Reinforcement Learning | http://arxiv.org/abs/1707.05300 | id:1707.05300 author:Carlos Florensa, David Held, Markus Wulfmeier, Pieter Abbeel category:cs.AI  published:2017-07-17 summary:Many relevant tasks require an agent to reach a certain state, or to manipulate objects into a desired configuration. For example, we might want a robot to align and assemble a gear onto an axle or insert and turn a key in a lock. These tasks present considerable difficulties for reinforcement learning approaches, since the natural reward function for such goal-oriented tasks is sparse and prohibitive amounts of exploration are required to reach the goal and receive a learning signal. Past approaches tackle these problems by manually designing a task-specific reward shaping function to help guide the learning. Instead, we propose a method to learn these tasks without requiring any prior task knowledge other than obtaining a single state in which the task is achieved. The robot is trained in "reverse", gradually learning to reach the goal from a set of starting positions increasingly far from the goal. Our method automatically generates a curriculum of starting positions that adapts to the agent's performance, leading to efficient training on such tasks. We demonstrate our approach on difficult simulated fine-grained manipulation problems, not solvable by state-of-the-art reinforcement learning methods. version:1
arxiv-1707-05288 | MAG: A Multilingual, Knowledge-based Agnostic and Deterministic Entity Linking Approach | http://arxiv.org/abs/1707.05288 | id:1707.05288 author:Diego Moussallem, Ricardo Usbeck, Michael R öder, Axel-Cyrille Ngonga Ngomo category:cs.CL  published:2017-07-17 summary:Entity linking has recently been the subject of a significant body of research. Currently, the best performing approaches rely on trained mono-lingual models. Porting these approaches to other languages is consequently a difficult endeavor as it requires corresponding training data and retraining of the models. We address this drawback by presenting a novel multilingual, knowledge-based agnostic and deterministic approach to entity linking, dubbed MAG. MAG is based on a combination of context-based retrieval on structured knowledge bases and graph algorithms. We evaluate MAG on 23 data sets and in 7 languages. Our results show that the best approach trained on English datasets (PBOH) achieves a micro F-measure that is up to 4 times worse on datasets in other languages. MAG, on the other hand, achieves state-of-the-art performance on English datasets and reaches a micro F-measure that is up to 0.6 higher than that of PBOH on non-English languages. version:1
arxiv-1707-05266 | A Simple Language Model based on PMI Matrix Approximations | http://arxiv.org/abs/1707.05266 | id:1707.05266 author:Oren Melamud, Ido Dagan, Jacob Goldberger category:cs.CL  published:2017-07-17 summary:In this study, we introduce a new approach for learning language models by training them to estimate word-context pointwise mutual information (PMI), and then deriving the desired conditional probabilities from PMI at test time. Specifically, we show that with minor modifications to word2vec's algorithm, we get principled language models that are closely related to the well-established Noise Contrastive Estimation (NCE) based language models. A compelling aspect of our approach is that our models are trained with the same simple negative sampling objective function that is commonly used in word2vec to learn word embeddings. version:1
arxiv-1707-05261 | Exploring text datasets by visualizing relevant words | http://arxiv.org/abs/1707.05261 | id:1707.05261 author:Franziska Horn, Leila Arras, Grégoire Montavon, Klaus-Robert Müller, Wojciech Samek category:cs.CL  published:2017-07-17 summary:When working with a new dataset, it is important to first explore and familiarize oneself with it, before applying any advanced machine learning algorithms. However, to the best of our knowledge, no tools exist that quickly and reliably give insight into the contents of a selection of documents with respect to what distinguishes them from other documents belonging to different categories. In this paper we propose to extract `relevant words' from a collection of texts, which summarize the contents of documents belonging to a certain class (or discovered cluster in the case of unlabeled datasets), and visualize them in word clouds to allow for a survey of salient features at a glance. We compare three methods for extracting relevant words and demonstrate the usefulness of the resulting word clouds by providing an overview of the classes contained in a dataset of scientific publications as well as by discovering trending topics from recent New York Times article snippets. version:1
arxiv-1707-05260 | Deterministic Memory Abstraction and Supporting Cache Architecture for Real-Time Systems | http://arxiv.org/abs/1707.05260 | id:1707.05260 author:Farzad Farshchi, Prathap Kumar Valsan, Renato Mancuso, Heechul Yun category:cs.AR cs.OS cs.PF  published:2017-07-17 summary:Achieving strong real-time guarantees in multi-core platforms is challenging due to the extensive hardware resource sharing in the memory hierarchy. Modern platforms and OS's, however, provide no means to appropriately handle memory regions that are crucial for real-time performance. In this paper, we propose a new OS-level abstraction, namely Deterministic Memory, to define memory regions that are specially handled by the OS and the hardware to exhibit strong real-time guarantees. We show that the deterministic memory abstraction can be introduced in the OS at the granularity of single memory pages by exploiting existing hardware support. When deterministic memory pages are accessed, the attribute is propagated through all the levels of the memory hierarchy. Clearly, the hardware needs to be designed to ensure real-time handling of deterministic memory requests. To illustrate the potentialities of the new abstraction, we also propose a novel design for a shared cache controller that takes advantage of deterministic memory. Minimum cache space is guaranteed for deterministic memory, while unused cache space is left available to non-real-time applications. We implemented OS support for deterministic memory in the Linux kernel; and we evaluated the proposed hardware modifications in a cycle-accurate full-system simulator. We study the effectiveness of our approach on a set of synthetic and real benchmarks. Results show that it is possible to achieve (i) temporal determinism as strong as with traditional way-based cache partitioning; and (ii) giving 50% of the private partition space, on average, to the non-real-time applications. version:1
arxiv-1707-05251 | Aesthetic-Driven Image Enhancement by Adversarial Learning | http://arxiv.org/abs/1707.05251 | id:1707.05251 author:Yubin Deng, Chen Change Loy, Xiaoou Tang category:cs.CV  published:2017-07-17 summary:We introduce EnhanceGAN, an adversarial learning based model that performs automatic image enhancement. Traditional image enhancement frameworks involve training separate models for automatic cropping or color enhancement in a fully-supervised manner, which requires expensive annotations in the form of image pairs. In contrast to these approaches, our proposed EnhanceGAN only requires weak supervision (binary labels on image aesthetic quality) and is able to learn enhancement parameters for tasks including image cropping and color enhancement. The full differentiability of our image enhancement modules enables training the proposed EnhanceGAN in an end-to-end manner. A novel stage-wise learning scheme is further proposed to stabilize the training of each enhancement task and facilitate the extensibility for other image enhancement techniques. Our weakly-supervised EnhanceGAN reports competitive quantitative results against supervised models in automatic image cropping using standard benchmarking datasets, and a user study confirms that the images enhancement results are on par with or even preferred over professional enhancement. version:1
arxiv-1707-05246 | Learning to select data for transfer learning with Bayesian Optimization | http://arxiv.org/abs/1707.05246 | id:1707.05246 author:Sebastian Ruder, Barbara Plank category:cs.CL cs.LG  published:2017-07-17 summary:Domain similarity measures can be used to gauge adaptability and select suitable data for transfer learning, but existing approaches define ad hoc measures that are deemed suitable for respective tasks. Inspired by work on curriculum learning, we propose to \emph{learn} data selection measures using Bayesian Optimization and evaluate them across models, domains and tasks. Our learned measures outperform existing domain similarity measures significantly on three tasks: sentiment analysis, part-of-speech tagging, and parsing. We show the importance of complementing similarity with diversity, and that learned measures are -- to some degree -- transferable across models, domains, and even tasks. version:1
arxiv-1707-05236 | Artificial Error Generation with Machine Translation and Syntactic Patterns | http://arxiv.org/abs/1707.05236 | id:1707.05236 author:Marek Rei, Mariano Felice, Zheng Yuan, Ted Briscoe category:cs.CL cs.LG I.2.7; I.2.6; I.5.1  published:2017-07-17 summary:Shortage of available training data is holding back progress in the area of automated error detection. This paper investigates two alternative methods for artificially generating writing errors, in order to create additional resources. We propose treating error generation as a machine translation task, where grammatically correct text is translated to contain errors. In addition, we explore a system for extracting textual patterns from an annotated corpus, which can then be used to insert errors into grammatically correct sentences. Our experiments show that the inclusion of artificially generated errors significantly improves error detection accuracy on both FCE and CoNLL 2014 datasets. version:1
arxiv-1707-05233 | Detecting Off-topic Responses to Visual Prompts | http://arxiv.org/abs/1707.05233 | id:1707.05233 author:Marek Rei category:cs.CL cs.LG cs.NE I.2.7; I.2.6; I.5.1  published:2017-07-17 summary:Automated methods for essay scoring have made great progress in recent years, achieving accuracies very close to human annotators. However, a known weakness of such automated scorers is not taking into account the semantic relevance of the submitted text. While there is existing work on detecting answer relevance given a textual prompt, very little previous research has been done to incorporate visual writing prompts. We propose a neural architecture and several extensions for detecting off-topic responses to visual prompts and evaluate it on a dataset of texts written by language learners. version:1
arxiv-1707-05227 | Auxiliary Objectives for Neural Error Detection Models | http://arxiv.org/abs/1707.05227 | id:1707.05227 author:Marek Rei, Helen Yannakoudakis category:cs.CL cs.LG cs.NE I.2.7; I.2.6; I.5.1  published:2017-07-17 summary:We investigate the utility of different auxiliary objectives and training strategies within a neural sequence labeling approach to error detection in learner writing. Auxiliary costs provide the model with additional linguistic information, allowing it to learn general-purpose compositional features that can then be exploited for other objectives. Our experiments show that a joint learning approach trained with parallel labels on in-domain data improves performance over the previous best error detection system. While the resulting model has the same number of parameters, the additional objectives allow it to be optimised more efficiently and achieve better performance. version:1
arxiv-1607-08525 | Walking of the iCub humanoid robot in different scenarios: implementation and performance analysis | http://arxiv.org/abs/1607.08525 | id:1607.08525 author:Yue Hu, Jorhabib Eljaik, Kevin Stein, Francesco Nori, Katja Mombaur category:cs.RO  published:2016-07-28 summary:The humanoid robot iCub is a research platform of the Fondazione Istituto Italiano di Tecnologia (IIT), spread among different institutes around the world. In the most recent version of iCub, the robot is equipped with stronger legs and bigger feet, allowing it to perform balancing and walking motions that were not possible with the first generations. Despite the new legs hardware, walking has been rarely performed on the iCub robot. In this work the objective is to implement walking motions on the robot, from which we want to analyze its walking capabilities. We developed software modules based on extensions of classic techniques such as the ZMP based pattern generator and position control to identify which are the characteristics as well as limitations of the robot against different walking tasks in order to give the users a reference of the performance of the robot. Most of the experiments have been performed with HeiCub, a reduced version of iCub without arms and head. version:2
arxiv-1707-00117 | SAM: Semantic Attribute Modulated Language Modeling | http://arxiv.org/abs/1707.00117 | id:1707.00117 author:Wenbo Hu, Lifeng Hua, Lei Li, Tian Wang, Jun Zhu, Hang Su, Bo Zhang category:cs.CL cs.LG stat.ML  published:2017-07-01 summary:As a fundamental task in the natural language processing field, language modeling aims to estimate the distribution of the word sequences. However, the most existing algorithms have focused on the main texts while often ignoring the vastly-accessible semantic attributes of the documents, e.g., titles, authors, sentiments and tags. To address this issue, we propose Semantic Attribute Modulated (SAM) language modeling, a novel language modeling framework that incorporates the various semantic attributes. Attributes are selected automatically with an attribute attention mechanism. We build three text datasets with a diversity of semantic attributes. On the three text datasets, we empirically examine the language model perplexities of several typical corpora, and then demonstrate the superiority of our model with the different combinations of the attributes. Extensive qualitative results, including word semantic analysis, attention values and an interesting lyric generation, further demonstrate the effectiveness of our SAM method. version:2
arxiv-1706-03757 | Semantic Entity Retrieval Toolkit | http://arxiv.org/abs/1706.03757 | id:1706.03757 author:Christophe Van Gysel, Maarten de Rijke, Evangelos Kanoulas category:cs.CL cs.AI cs.IR  published:2017-06-12 summary:Unsupervised learning of low-dimensional, semantic representations of words and entities has recently gained attention. In this paper we describe the Semantic Entity Retrieval Toolkit (SERT) that provides implementations of our previously published entity representation models. The toolkit provides a unified interface to different representation learning algorithms, fine-grained parsing configuration and can be used transparently with GPUs. In addition, users can easily modify existing models or implement their own models in the framework. After model training, SERT can be used to rank entities according to a textual query and extract the learned entity/word representation for use in downstream algorithms, such as clustering or recommendation. version:2
arxiv-1707-05176 | Translational Recommender Networks | http://arxiv.org/abs/1707.05176 | id:1707.05176 author:Yi Tay, Anh Tuan Luu, Siu Cheung Hui category:cs.AI cs.IR  published:2017-07-17 summary:Representing relationships as translations in vector space lives at the heart of many neural embedding models such as word embeddings and knowledge graph embeddings. In this work, we study the connections of this translational principle with collaborative filtering algorithms. We propose Translational Recommender Networks (\textsc{TransRec}), a new attentive neural architecture that utilizes the translational principle to model the relationships between user and item pairs. Our model employs a neural attention mechanism over a \emph{Latent Relational Attentive Memory} (LRAM) module to learn the latent relations between user-item pairs that best explains the interaction. By exploiting adaptive user-item specific translations in vector space, our model also alleviates the geometric inflexibility problem of other metric learning algorithms while enabling greater modeling capability and fine-grained fitting of users and items in vector space. The proposed architecture not only demonstrates the state-of-the-art performance across multiple recommendation benchmarks but also boasts of improved interpretability. Qualitative studies over the LRAM module shows evidence that our proposed model is able to infer and encode explicit sentiment, temporal and attribute information despite being only trained on implicit feedback. As such, this ascertains the ability of \textsc{TransRec} to uncover hidden relational structure within implicit datasets. version:1
arxiv-1707-05173 | Trial without Error: Towards Safe Reinforcement Learning via Human Intervention | http://arxiv.org/abs/1707.05173 | id:1707.05173 author:William Saunders, Girish Sastry, Andreas Stuhlmueller, Owain Evans category:cs.AI cs.LG cs.NE  published:2017-07-17 summary:AI systems are increasingly applied to complex tasks that involve interaction with humans. During training, such systems are potentially dangerous, as they haven't yet learned to avoid actions that could cause serious harm. How can an AI system explore and learn without making a single mistake that harms humans or otherwise causes serious damage? For model-free reinforcement learning, having a human "in the loop" and ready to intervene is currently the only way to prevent all catastrophes. We formalize human intervention for RL and show how to reduce the human labor required by training a supervised learner to imitate the human's intervention decisions. We evaluate this scheme on Atari games, with a Deep RL agent being overseen by a human for four hours. When the class of catastrophes is simple, we are able to prevent all catastrophes without affecting the agent's learning (whereas an RL baseline fails due to catastrophic forgetting). However, this scheme is less successful when catastrophes are more complex: it reduces but does not eliminate catastrophes and the supervised learner fails on adversarial examples found by the agent. Extrapolating to more challenging environments, we show that our implementation would not scale (due to the infeasible amount of human labor required). We outline extensions of the scheme that are necessary if we are to train model-free agents without a single catastrophe. version:1
arxiv-1706-08334 | A Meta-Learning Approach to One-Step Active Learning | http://arxiv.org/abs/1706.08334 | id:1706.08334 author:Gabriella Contardo, Ludovic Denoyer, Thierry Artieres category:cs.LG  published:2017-06-26 summary:We consider the problem of learning when obtaining the training labels is costly, which is usually tackled in the literature using active-learning techniques. These approaches provide strategies to choose the examples to label before or during training. These strategies are usually based on heuristics or even theoretical measures, but are not learned as they are directly used during training. We design a model which aims at \textit{learning active-learning strategies} using a meta-learning setting. More specifically, we consider a pool-based setting, where the system observes all the examples of the dataset of a problem and has to choose the subset of examples to label in a single shot. Experiments show encouraging results. version:2
arxiv-1707-04092 | Disentangling Motion, Foreground and Background Features in Videos | http://arxiv.org/abs/1707.04092 | id:1707.04092 author:Xunyu Lin, Victor Campos, Xavier Giro-i-Nieto, Jordi Torres, Cristian Canton Ferrer category:cs.CV cs.AI cs.MM  published:2017-07-13 summary:This paper introduces an unsupervised framework to extract semantically rich features for video representation. Inspired by how the human visual system groups objects based on motion cues, we propose a deep convolutional neural network that disentangles motion, foreground and background information. The proposed architecture consists of a 3D convolutional feature encoder for blocks of 16 frames, which is trained for reconstruction tasks over the first and last frames of the sequence. A preliminary supervised experiment was conducted to verify the feasibility of proposed method by training the model with a fraction of videos from the UCF-101 dataset taking as ground truth the bounding boxes around the activity regions. Qualitative results indicate that the network can successfully segment foreground and background in videos as well as update the foreground appearance based on disentangled motion features. The benefits of these learned features are shown in a discriminative classification task, where initializing the network with the proposed pretraining method outperforms both random initialization and autoencoder pretraining. Our model and source code are publicly available at https://imatge-upc.github.io/unsupervised-2017-cvprw/ . version:2
arxiv-1707-05152 | When You Must Forget: beyond strong persistence when forgetting in answer set programming | http://arxiv.org/abs/1707.05152 | id:1707.05152 author:Ricardo Gonçalves, Matthias Knorr, João Leite, Stefan Woltran category:cs.AI I.2.4  published:2017-07-17 summary:Among the myriad of desirable properties discussed in the context of forgetting in Answer Set Programming (ASP), strong persistence naturally captures its essence. Recently, it has been shown that it is not always possible to forget a set of atoms from a program while obeying this property, and a precise criterion regarding what can be forgotten has been presented, accompanied by a class of forgetting operators that return the correct result when forgetting is possible. However, it is an open question what to do when we have to forget a set of atoms, but cannot without violating this property. In this paper, we address this issue and investigate three natural alternatives to forget when forgetting without violating strong persistence is not possible, which turn out to correspond to the different possible relaxations of the characterization of strong persistence. Additionally, we discuss their preferable usage, shed light on the relation between forgetting and notions of relativized equivalence established earlier in the context of ASP, and present a detailed study on their computational complexity. version:1
arxiv-1705-08174 | Distributed Testing of Conductance | http://arxiv.org/abs/1705.08174 | id:1705.08174 author:Hendrik Fichtenberger, Yadu Vasudev category:cs.DC cs.DS  published:2017-05-23 summary:We study the problem of testing conductance in the distributed computing model and give a two-sided tester that takes $\mathcal{O}(\log n)$ rounds to decide if a graph has conductance at least $\Phi$ or is $\epsilon$-far from having conductance at least $\Theta(\Phi^2)$ in the distributed CONGEST model. We also show that $\Omega(\log n)$ rounds are necessary for testing conductance even in the LOCAL model. In the case of a connected graph, we show that we can perform the test even when the number of vertices in the graph is not known a priori. This is the first two-sided tester in the distributed model we are aware of. The key idea in our algorithm is a way to perform a polynomial number of random walks from a set of vertices, avoiding the congestion on the edges. version:2
arxiv-1707-05137 | Fully Automatic and Real-Time Catheter Segmentation in X-Ray Fluoroscopy | http://arxiv.org/abs/1707.05137 | id:1707.05137 author:Pierre Ambrosini, Daniel Ruijters, Wiro J. Niessen, Adriaan Moelker, Theo van Walsum category:cs.CV  published:2017-07-17 summary:Augmenting X-ray imaging with 3D roadmap to improve guidance is a common strategy. Such approaches benefit from automated analysis of the X-ray images, such as the automatic detection and tracking of instruments. In this paper, we propose a real-time method to segment the catheter and guidewire in 2D X-ray fluoroscopic sequences. The method is based on deep convolutional neural networks. The network takes as input the current image and the three previous ones, and segments the catheter and guidewire in the current image. Subsequently, a centerline model of the catheter is constructed from the segmented image. A small set of annotated data combined with data augmentation is used to train the network. We trained the method on images from 182 X-ray sequences from 23 different interventions. On a testing set with images of 55 X-ray sequences from 5 other interventions, a median centerline distance error of 0.2 mm and a median tip distance error of 0.9 mm was obtained. The segmentation of the instruments in 2D X-ray sequences is performed in a real-time fully-automatic manner. version:1
arxiv-1707-05316 | Current-mode Memristor Crossbars for Neuromemristive Systems | http://arxiv.org/abs/1707.05316 | id:1707.05316 author:Cory Merkel category:stat.ML cs.ET  published:2017-07-17 summary:Motivated by advantages of current-mode design, this brief contribution explores the implementation of weight matrices in neuromemristive systems via current-mode memristor crossbar circuits. After deriving theoretical results for the range and distribution of weights in the current-mode design, it is shown that any weight matrix based on voltage-mode crossbars can be mapped to a current-mode crossbar if the voltage-mode weights are carefully bounded. Then, a modified gradient descent rule is derived for the current-mode design that can be used to perform backpropagation training. Behavioral simulations on the MNIST dataset indicate that both voltage and current-mode designs are able to achieve similar accuracy and have similar defect tolerance. However, analysis of trained weight distributions reveals that current-mode and voltage-mode designs may use different feature representations. version:1
arxiv-1706-06210 | Sub-domain Modelling for Dialogue Management with Hierarchical Reinforcement Learning | http://arxiv.org/abs/1706.06210 | id:1706.06210 author:Paweł Budzianowski, Stefan Ultes, Pei-Hao Su, Nikola Mrkšić, Tsung-Hsien Wen, Iñigo Casanueva, Lina Rojas-Barahona, Milica Gašić category:cs.CL cs.AI  published:2017-06-19 summary:Human conversation is inherently complex, often spanning many different topics/domains. This makes policy learning for dialogue systems very challenging. Standard flat reinforcement learning methods do not provide an efficient framework for modelling such dialogues. In this paper, we focus on the under-explored problem of multi-domain dialogue management. First, we propose a new method for hierarchical reinforcement learning using the option framework. Next, we show that the proposed architecture learns faster and arrives at a better policy than the existing flat ones do. Moreover, we show how pretrained policies can be adapted to more complex systems with an additional set of new actions. In doing that, we show that our approach has the potential to facilitate policy optimisation for more sophisticated multi-domain dialogue systems. version:2
arxiv-1707-05128 | Differentially Private Testing of Identity and Closeness of Discrete Distributions | http://arxiv.org/abs/1707.05128 | id:1707.05128 author:Jayadev Acharya, Ziteng Sun, Huanyu Zhang category:cs.LG cs.DS cs.IT math.IT  published:2017-07-17 summary:We study the fundamental problems of identity testing (goodness of fit), and closeness testing (two sample test) of distributions over $k$ elements, under differential privacy. While the problems have a long history in statistics, finite sample bounds for these problems have only been established recently. In this work, we derive upper and lower bounds on the sample complexity of both the problems under $\varepsilon$-differential privacy. Our results improve over the best known algorithms for identity testing, and are the first results for differentially private closeness testing. Our bounds are tight up to a constant factor whenever the number of samples is $O(k)$, a regime which has garnered much attention over the last decade since it allows property testing even when only a fraction of the domain is observed. Our upper bounds are obtained by converting (and sometimes combining) the known non-private testing algorithms into differentially private algorithms. We propose a simple, yet general procedure based on coupling of distributions, to establish sample complexity lower bounds for differentially private algorithms. version:1
arxiv-1707-05127 | Neural Reranking for Named Entity Recognition | http://arxiv.org/abs/1707.05127 | id:1707.05127 author:Jie Yang, Yue Zhang, Fei Dong category:cs.CL  published:2017-07-17 summary:We propose a neural reranking system for named entity recognition (NER). The basic idea is to leverage recurrent neural network models to learn sentence-level patterns that involve named entity mentions. In particular, given an output sentence produced by a baseline NER model, we replace all entity mentions, such as \textit{Barack Obama}, into their entity types, such as \textit{PER}. The resulting sentence patterns contain direct output information, yet is less sparse without specific named entities. For example, "PER was born in LOC" can be such a pattern. LSTM and CNN structures are utilised for learning deep representations of such sentences for reranking. Results show that our system can significantly improve the NER accuracies over two different baselines, giving the best reported results on a standard benchmark. version:1
arxiv-1707-05118 | LIG-CRIStAL System for the WMT17 Automatic Post-Editing Task | http://arxiv.org/abs/1707.05118 | id:1707.05118 author:Alexandre Berard, Olivier Pietquin, Laurent Besacier category:cs.CL  published:2017-07-17 summary:This paper presents the LIG-CRIStAL submission to the shared Automatic Post- Editing task of WMT 2017. We propose two neural post-editing models: a monosource model with a task-specific attention mechanism, which performs particularly well in a low-resource scenario; and a chained architecture which makes use of the source sentence to provide extra context. This latter architecture manages to slightly improve our results when more training data is available. We present and discuss our results on two datasets (en-de and de-en) that are made available for the task. version:1
arxiv-1707-05116 | To Normalize, or Not to Normalize: The Impact of Normalization on Part-of-Speech Tagging | http://arxiv.org/abs/1707.05116 | id:1707.05116 author:Rob van der Goot, Barbara Plank, Malvina Nissim category:cs.CL  published:2017-07-17 summary:Does normalization help Part-of-Speech (POS) tagging accuracy on noisy, non-canonical data? To the best of our knowledge, little is known on the actual impact of normalization in a real-world scenario, where gold error detection is not available. We investigate the effect of automatic normalization on POS tagging of tweets. We also compare normalization to strategies that leverage large amounts of unlabeled data kept in its raw form. Our results show that normalization helps, but does not add consistently beyond just word embedding layer initialization. The latter approach yields a tagging model that is competitive with a Twitter state-of-the-art tagger. version:1
arxiv-1707-05115 | The Power of Constraint Grammars Revisited | http://arxiv.org/abs/1707.05115 | id:1707.05115 author:Anssi Yli-Jyrä category:cs.FL cs.AI cs.CL  published:2017-07-17 summary:Sequential Constraint Grammar (SCG) (Karlsson, 1990) and its extensions have lacked clear connections to formal language theory. The purpose of this article is to lay a foundation for these connections by simplifying the definition of strings processed by the grammar and by showing that Nonmonotonic SCG is undecidable and that derivations similar to the Generative Phonology exist. The current investigations propose resource bounds that restrict the generative power of SCG to a subset of context sensitive languages and present a strong finite-state condition for grammars as wholes. We show that a grammar is equivalent to a finite-state transducer if it is implemented with a Turing machine that runs in o(n log n) time. This condition opens new finite-state hypotheses and avenues for deeper analysis of SCG instances in the way inspired by Finite-State Phonology. version:1
arxiv-1707-05114 | Towards Bidirectional Hierarchical Representations for Attention-Based Neural Machine Translation | http://arxiv.org/abs/1707.05114 | id:1707.05114 author:Baosong Yang, Derek F. Wong, Tong Xiao, Lidia S. Chao, Jingbo Zhu category:cs.CL  published:2017-07-17 summary:This paper proposes a hierarchical attentional neural translation model which focuses on enhancing source-side hierarchical representations by covering both local and global semantic information using a bidirectional tree-based encoder. To maximize the predictive likelihood of target words, a weighted variant of an attention mechanism is used to balance the attentive information between lexical and phrase vectors. Using a tree-based rare word encoding, the proposed model is extended to sub-word level to alleviate the out-of-vocabulary (OOV) problem. Empirical results reveal that the proposed model significantly outperforms sequence-to-sequence attention-based and tree-based neural translation models in English-Chinese translation tasks. version:1
arxiv-1707-05110 | Control of a Quadrotor with Reinforcement Learning | http://arxiv.org/abs/1707.05110 | id:1707.05110 author:Jemin Hwangbo, Inkyu Sa, Roland Siegwart, Marco Hutter category:cs.RO  published:2017-07-17 summary:In this paper, we present a method to control a quadrotor with a neural network trained using reinforcement learning techniques. With reinforcement learning, a common network can be trained to directly map state to actuator command making any predefined control structure obsolete for training. Moreover, we present a new learning algorithm which differs from the existing ones in certain aspects. Our algorithm is conservative but stable for complicated tasks. We found that it is more applicable to controlling a quadrotor than existing algorithms. We demonstrate the performance of the trained policy both in simulation and with a real quadrotor. Experiments show that our policy network can react to step response relatively accurately. With the same policy, we also demonstrate that we can stabilize the quadrotor in the air even under very harsh initialization (manually throwing it upside-down in the air with an initial velocity of 5 m/s). Computation time of evaluating the policy is only 7 {\mu}s per time step which is two orders of magnitude less than common trajectory optimization algorithms with an approximated model. version:1
arxiv-1707-05712 | PAC-Bayes and Domain Adaptation | http://arxiv.org/abs/1707.05712 | id:1707.05712 author:Pascal Germain, Amaury Habrard, François Laviolette, Emilie Morvant category:stat.ML  published:2017-07-17 summary:We provide two main contributions in PAC-Bayesian theory for domain adaptation where the objective is to learn, from a source distribution, a well-performing majority vote on a different, but related, target distribution. Firstly, we propose an improvement of the previous approach we proposed in Germain et al. (2013), which relies on a novel distribution pseudodistance based on a disagreement averaging, allowing us to derive a new tighter domain adaptation bound for the target risk. While this bound stands in the spirit of common domain adaptation works, we derive a second bound (recently introduced in Germain et al., 2016) that brings a new perspective on domain adaptation by deriving an upper bound on the target risk where the distributions' divergence-expressed as a ratio-controls the trade-off between a source error measure and the target voters' disagreement. We discuss and compare both results, from which we obtain PAC-Bayesian generalization bounds. Furthermore, from the PAC-Bayesian specialization to linear classifiers, we infer two learning algorithms, and we evaluate them on real data. version:1
arxiv-1707-05101 | On consistency of optimal pricing algorithms in repeated posted-price auctions with strategic buyer | http://arxiv.org/abs/1707.05101 | id:1707.05101 author:Alexey Drutsa category:cs.GT cs.AI cs.LG stat.ML I.2.6; F.2.2  published:2017-07-17 summary:We study revenue optimization learning algorithms for repeated posted-price auctions where a seller interacts with a single strategic buyer that holds a fixed private valuation for a good and seeks to maximize his cumulative discounted surplus. For this setting, first, we propose a novel algorithm that never decreases offered prices and has a tight strategic regret bound in $\Theta(\log\log T)$ under some mild assumptions on the buyer surplus discounting. This result closes the open research question on the existence of a no-regret horizon-independent weakly consistent pricing. The proposed algorithm is inspired by our observation that a double decrease of offered prices in a weakly consistent algorithm is enough to cause a linear regret. This motivates us to construct a novel transformation that maps a right-consistent algorithm to a weakly consistent one that never decreases offered prices. Second, we outperform the previously known strategic regret upper bound of the algorithm PRRFES, where the improvement is achieved by means of a finer constant factor $C$ of the principal term $C\log\log T$ in this upper bound. Finally, we generalize results on strategic regret previously known for geometric discounting of the buyer's surplus to discounting of other types, namely: the optimality of the pricing PRRFES to the case of geometrically concave decreasing discounting; and linear lower bound on the strategic regret of a wide range of horizon-independent weakly consistent algorithms to the case of arbitrary discounts. version:1
arxiv-1707-05077 | Lower Bounds for Searching Robots, some Faulty | http://arxiv.org/abs/1707.05077 | id:1707.05077 author:Andrey Kupavskii, Emo Welzl category:cs.RO cs.DC  published:2017-07-17 summary:Suppose we are sending out $k$ robots from $0$ to search the real line at constant speed (with turns) to find a target at an unknown location; $f$ of the robots are faulty, meaning that they fail to report the target although visiting its location (called crash type). The goal is to find the target in time at most $\lambda d $, if the target is located at $d$, $ d \ge 1$, for $\lambda$ as small as possible. We show that it cannot be achieved for $\lambda < 2\frac{(1+\rho)^{1+\rho}}{\rho^\rho}+1$, $\rho := 2\frac{f+1}{k} -1$, which is tight due to earlier work. This also gives some better than previously known lower bounds for so-called Byzantine-type faulty robots (that may actually wrongly report a target). version:1
arxiv-1611-03947 | An Efficient Algorithm for Maintaining Acyclicity in Concurrent Graph Objects | http://arxiv.org/abs/1611.03947 | id:1611.03947 author:Sathya Peri, Muktikanta Sa, Nandini Singhal category:cs.DC  published:2016-11-12 summary:In this paper, we propose an algorithm for maintaining a concurrent directed graph (for shared memory architecture) that is concurrently being updated by threads adding/deleting vertices and edges. The update methods of the algorithm are deadlock-free while the contains methods are wait-free. To the the best of our knowledge, this is the first work to propose a concurrent data structure for an adjacency list representation of the graphs. We extend the lazy list implementation of concurrent set for achieving this. We believe that there are many applications that can benefit from this concurrent graph structure. An important application that inspired us is SGT in databases and Transactional Memory. Motivated by this application, on this concurrent graph data-structure, we pose the constraint that the graph should always be acyclic. We ensure this by checking for graph acyclicity whenever we add an edge. To detect the cycle efficiently we have proposed a Wait-free reachability algorithm. We have compared the performance of the proposed concurrent data structure with coarse-grained locking implementation which has been traditionally used in implementing SGT. We show that our algorithm achieves on an average 8x improvement in throughput as compared to coarse-grained and sequential implementations. version:5
arxiv-1707-05315 | Unsupervised Iterative Deep Learning of Speech Features and Acoustic Tokens with Applications to Spoken Term Detection | http://arxiv.org/abs/1707.05315 | id:1707.05315 author:Cheng-Tao Chung, Cheng-Yu Tsai, Chia-Hsiang Liu, Lin-Shan Lee category:cs.CL  published:2017-07-17 summary:In this paper we aim to automatically discover high quality frame-level speech features and acoustic tokens directly from unlabeled speech data. A Multi-granular Acoustic Tokenizer (MAT) was proposed for automatic discovery of multiple sets of acoustic tokens from the given corpus. Each acoustic token set is specified by a set of hyperparameters describing the model configuration. These different sets of acoustic tokens carry different characteristics for the given corpus and the language behind, thus can be mutually reinforced. The multiple sets of token labels are then used as the targets of a Multi-target Deep Neural Network (MDNN) trained on frame-level acoustic features. Bottleneck features extracted from the MDNN are then used as the feedback input to the MAT and the MDNN itself in the next iteration. The multi-granular acoustic token sets and the frame-level speech features can be iteratively optimized in the iterative deep learning framework. We call this framework the Multi-granular Acoustic Tokenizing Deep Neural Network (MATDNN). The results were evaluated using the metrics and corpora defined in the Zero Resource Speech Challenge organized at Interspeech 2015, and improved performance was obtained with a set of experiments of query-by-example spoken term detection on the same corpora. Visualization for the discovered tokens against the English phonemes was also shown. version:1
arxiv-1707-05063 | Optimal Storage under Unsynchrononized Mobile Byzantine Faults | http://arxiv.org/abs/1707.05063 | id:1707.05063 author:Silvia Bonomi, Antonella Del Pozzo, Maria Potop-Butucaru, Sébastien Tixeuil category:cs.DC  published:2017-07-17 summary:In this paper we prove lower and matching upper bounds for the number of servers required to implement a regular shared register that tolerates unsynchronized Mobile Byzantine failures. We consider the strongest model of Mobile Byzantine failures to date: agents are moved arbitrarily by an omniscient adversary from a server to another in order to deviate their computation in an unforeseen manner. When a server is infected by an Byzantine agent, it behaves arbitrarily until the adversary decides to move the agent to another server. Previous approaches considered asynchronous servers with synchronous mobile Byzantine agents (yielding impossibility results), and synchronous servers with synchronous mobile Byzantine agents (yielding optimal solutions for regular register implementation, even in the case where servers and agents periods are decoupled). We consider the remaining open case of synchronous servers with unsynchronized agents, that can move at their own pace, and change their pace during the execution of the protocol. Most of our findings relate to lower bounds, and characterizing the model parameters that make the problem solvable. It turns out that unsynchronized mobile Byzantine agent movements requires completely new proof arguments, that can be of independent interest when studying other problems in this model. Additionally, we propose a generic server-based algorithm that emulates a regular register in this model, that is tight with respect to the number of mobile Byzantine agents that can be tolerated. Our emulation spans two awareness models: servers with and without self-diagnose mechanisms. In the first case servers are aware that the mobile Byzantine agent has left and hence they can stop running the protocol until they recover a correct state while in the second case, servers are not aware of their faulty state and continue to run the protocol using an incorrect local state. version:1
arxiv-1707-05062 | Speeding up the K{ö}hler's method of contrast thresholding | http://arxiv.org/abs/1707.05062 | id:1707.05062 author:Guillaume Noyel category:cs.CV cs.CC cs.DC  published:2017-07-17 summary:K{\"o}hler's method is a useful multi-thresholding technique based on boundary contrast. However, the direct algorithm has a too high complexity-O(N 2) i.e. quadratic with the pixel numbers N-to process images at a sufficient speed for practical applications. In this paper, a new algorithm to speed up K{\"o}hler's method is introduced with a complexity in O(N M), M is the number of grey levels. The proposed algorithm is designed for parallelisation and vector processing , which are available in current processors, using OpenMP (Open Multi-Processing) and SIMD instructions (Single Instruction on Multiple Data). A fast implementation allows a gain factor of 405 in an image of 18 million pixels and a video processing in real time (gain factor of 96). version:1
arxiv-1707-05654 | Eigenlogic: Interpretable Quantum Observables with applications to Fuzzy Behavior of Vehicular Robots | http://arxiv.org/abs/1707.05654 | id:1707.05654 author:Zeno Toffano, François Dubois category:cs.AI  published:2017-07-17 summary:This work proposes a formulation of propositional logic, named Eigenlogic, using quantum observables as propositions. The eigenvalues of these operators are the truth-values and the associated eigenvectors the interpretations of the propositional system. Fuzzy logic arises naturally when considering vectors outside the eigensystem, the fuzzy membership function is obtained by the Born rule of the logical observable.This approach is then applied in the context of quantum robots using simple behavioral agents represented by Braitenberg vehicles. Processing with non-classical logic such as multivalued logic, fuzzy logic and the quantum Eigenlogic permits to enlarge the behavior possibilities and the associated decisions of these simple agents. version:1
arxiv-1707-05055 | Designing Effective Inter-Pixel Information Flow for Natural Image Matting | http://arxiv.org/abs/1707.05055 | id:1707.05055 author:Yağız Aksoy, Tunç Ozan Aydın, Marc Pollefeys category:cs.CV I.4.6  published:2017-07-17 summary:We present a novel, purely affinity-based natural image matting algorithm. Our method relies on carefully defined pixel-to-pixel connections that enable effective use of information available in the image. We control the information flow from the known-opacity regions into the unknown region, as well as within the unknown region itself, by utilizing multiple definitions of pixel affinities. Among other forms of information flow, we introduce color-mixture flow, which builds upon local linear embedding and effectively encapsulates the relation between different pixel opacities. Our resulting novel linear system formulation can be solved in closed-form and is robust against several fundamental challenges of natural matting such as holes and remote intricate structures. Our evaluation using the alpha matting benchmark suggests a significant performance improvement over the current methods. While our method is primarily designed as a standalone matting tool, we show that it can also be used for regularizing mattes obtained by sampling-based methods. We extend our formulation to layer color estimation and show that the use of multiple channels of flow increases the layer color quality. We also demonstrate our performance in green-screen keying and further analyze the characteristics of the affinities used in our method. version:1
arxiv-1706-05692 | Dimensionality Reduction using Similarity-induced Embeddings | http://arxiv.org/abs/1706.05692 | id:1706.05692 author:Nikolaos Passalis, Anastasios Tefas category:cs.CV  published:2017-06-18 summary:The vast majority of Dimensionality Reduction (DR) techniques rely on second-order statistics to define their optimization objective. Even though this provides adequate results in most cases, it comes with several shortcomings. The methods require carefully designed regularizers and they are usually prone to outliers. In this work, a new DR framework, that can directly model the target distribution using the notion of similarity instead of distance, is introduced. The proposed framework, called Similarity Embedding Framework, can overcome the aforementioned limitations and provides a conceptually simpler way to express optimization targets similar to existing DR techniques. Deriving a new DR technique using the Similarity Embedding Framework becomes simply a matter of choosing an appropriate target similarity matrix. A variety of classical tasks, such as performing supervised dimensionality reduction and providing out-of-of-sample extensions, as well as, new novel techniques, such as providing fast linear embeddings for complex techniques, are demonstrated in this paper using the proposed framework. Six datasets from a diverse range of domains are used to evaluate the proposed method and it is demonstrated that it can outperform many existing DR techniques. version:2
arxiv-1707-05041 | Line-Recovery by Programmable Particles | http://arxiv.org/abs/1707.05041 | id:1707.05041 author:Giuseppe Di Luna, Paola Flocchini, Giuseppe Prencipe, Nicola Santoro, Giovanni Viglietta category:cs.DC  published:2017-07-17 summary:Shape formation has been recently studied in distributed systems of programmable particles. In this paper we consider the shape recovery problem of restoring the shape when $f$ of the $n$ particles have crashed. We focus on the basic line shape, used as a tool for the construction of more complex configurations. We present a solution to the line recovery problem by the non-faulty anonymous particles; the solution works regardless of the initial distribution and number $f<n-4$ of faults, of the local orientations of the non-faulty entities, and of the number of non-faulty entities activated in each round (i.e., semi-synchronous adversarial scheduler). version:1
arxiv-1707-05023 | Optimization by gradient boosting | http://arxiv.org/abs/1707.05023 | id:1707.05023 author:Gérard Biau, Benoît Cadre category:math.ST cs.LG stat.TH  published:2017-07-17 summary:Gradient boosting is a state-of-the-art prediction technique that sequentially produces a model in the form of linear combinations of simple predictors---typically decision trees---by solving an infinite-dimensional convex optimization problem. We provide in the present paper a thorough analysis of two widespread versions of gradient boosting, and introduce a general framework for studying these algorithms from the point of view of functional optimization. We prove their convergence as the number of iterations tends to infinity and highlight the importance of having a strongly convex risk functional to minimize. We also present a reasonable statistical context ensuring consistency properties of the boosting predictors as the sample size grows. In our approach, the optimization procedures are run forever (that is, without resorting to an early stopping strategy), and statistical regularization is basically achieved via an appropriate $L^2$ penalization of the loss and strong convexity arguments. version:1
arxiv-1707-01932 | End-to-End Learning of Semantic Grasping | http://arxiv.org/abs/1707.01932 | id:1707.01932 author:Eric Jang, Sudheendra Vijaynarasimhan, Peter Pastor, Julian Ibarz, Sergey Levine category:cs.RO cs.LG stat.ML  published:2017-07-06 summary:We consider the task of semantic robotic grasping, in which a robot picks up an object of a user-specified class using only monocular images. Inspired by the two-stream hypothesis of visual reasoning, we present a semantic grasping framework that learns object detection, classification, and grasp planning in an end-to-end fashion. A "ventral stream" recognizes object class while a "dorsal stream" simultaneously interprets the geometric relationships necessary to execute successful grasps. We leverage the autonomous data collection capabilities of robots to obtain a large self-supervised dataset for training the dorsal stream, and use semi-supervised label propagation to train the ventral stream with only a modest amount of human supervision. We experimentally show that our approach improves upon grasping systems whose components are not learned end-to-end, including a baseline method that uses bounding box detection. Furthermore, we show that jointly training our model with auxiliary data consisting of non-semantic grasping data, as well as semantically labeled images without grasp actions, has the potential to substantially improve semantic grasping performance. version:2
arxiv-1705-00744 | A Strategy for an Uncompromising Incremental Learner | http://arxiv.org/abs/1705.00744 | id:1705.00744 author:Ragav Venkatesan, Hemanth Venkateswara, Sethuraman Panchanathan, Baoxin Li category:cs.CV cs.LG  published:2017-05-02 summary:Multi-class supervised learning systems require the knowledge of the entire range of labels they predict. Often when learnt incrementally, they suffer from catastrophic forgetting. To avoid this, generous leeways have to be made to the philosophy of incremental learning that either forces a part of the machine to not learn, or to retrain the machine again with a selection of the historic data. While these hacks work to various degrees, they do not adhere to the spirit of incremental learning. In this article, we redefine incremental learning with stringent conditions that do not allow for any undesirable relaxations and assumptions. We design a strategy involving generative models and the distillation of dark knowledge as a means of hallucinating data along with appropriate targets from past distributions. We call this technique, phantom sampling.We show that phantom sampling helps avoid catastrophic forgetting during incremental learning. Using an implementation based on deep neural networks, we demonstrate that phantom sampling dramatically avoids catastrophic forgetting. We apply these strategies to competitive multi-class incremental learning of deep neural networks. Using various benchmark datasets and through our strategy, we demonstrate that strict incremental learning could be achieved. We further put our strategy to test on challenging cases, including cross-domain increments and incrementing on a novel label space. We also propose a trivial extension to unbounded-continual learning and identify potential for future development. version:2
arxiv-1707-05015 | Iris: A Conversational Agent for Complex Tasks | http://arxiv.org/abs/1707.05015 | id:1707.05015 author:Ethan Fast, Binbin Chen, Julia Mendelsohn, Jonathan Bassen, Michael Bernstein category:cs.HC cs.CL  published:2017-07-17 summary:Today's conversational agents are restricted to simple standalone commands. In this paper, we present Iris, an agent that draws on human conversational strategies to combine commands, allowing it to perform more complex tasks that it has not been explicitly designed to support: for example, composing one command to "plot a histogram" with another to first "log-transform the data". To enable this complexity, we introduce a domain specific language that transforms commands into automata that Iris can compose, sequence, and execute dynamically by interacting with a user through natural language, as well as a conversational type system that manages what kinds of commands can be combined. We have designed Iris to help users with data science tasks, a domain that requires support for command combination. In evaluation, we find that data scientists complete a predictive modeling task significantly faster (2.6 times speedup) with Iris than a modern non-conversational programming environment. Iris supports the same kinds of commands as today's agents, but empowers users to weave together these commands to accomplish complex goals. version:1
arxiv-1707-05014 | A Real-time Image Reconstruction System for Particle Treatment Planning Using Proton Computed Tomography (pCT) | http://arxiv.org/abs/1707.05014 | id:1707.05014 author:Caesar E. Ordoñez, Nicholas Karonis, Kirk Duffin, George Coutrakon, Reinhard Schulte, Robert Johnson, Mark Pankuch category:physics.med-ph cs.DC  published:2017-07-17 summary:Proton computed tomography (pCT) is a novel medical imaging modality for mapping the distribution of proton relative stopping power (RSP) in medical objects of interest. Compared to conventional X-ray computed tomography, where range uncertainty margins are around 3.5%, pCT has the potential to provide more accurate measurements to within 1%. This improved efficiency will be beneficial to proton-therapy planning and pre-treatment verification. A prototype pCT imaging device has recently been developed capable of rapidly acquiring low-dose proton radiographs of head-sized objects. We have also developed an advanced, fast image reconstruction software based on distributed computing that utilizes parallel processors and graphical processing units. The combination of fast data acquisition and fast image reconstruction will enable the availability of RSP images within minutes for use in clinical settings. The performance of our image reconstruction software has been evaluated using data collected by the prototype pCT scanner from several phantoms. version:1
arxiv-1707-05010 | Deep Learning to Attend to Risk in ICU | http://arxiv.org/abs/1707.05010 | id:1707.05010 author:Phuoc Nguyen, Truyen Tran, Svetha Venkatesh category:cs.LG stat.ML  published:2017-07-17 summary:Modeling physiological time-series in ICU is of high clinical importance. However, data collected within ICU are irregular in time and often contain missing measurements. Since absence of a measure would signify its lack of importance, the missingness is indeed informative and might reflect the decision making by the clinician. Here we propose a deep learning architecture that can effectively handle these challenges for predicting ICU mortality outcomes. The model is based on Long Short-Term Memory, and has layered attention mechanisms. At the sensing layer, the model decides whether to observe and incorporate parts of the current measurements. At the reasoning layer, evidences across time steps are weighted and combined. The model is evaluated on the PhysioNet 2012 dataset showing competitive and interpretable results. version:1
arxiv-1707-05009 | "Maximizing rigidity" revisited: a convex programming approach for generic 3D shape reconstruction from multiple perspective views | http://arxiv.org/abs/1707.05009 | id:1707.05009 author:Pan Ji, Hongdong Li, Yuchao Dai, Ian Reid category:cs.CV  published:2017-07-17 summary:Rigid structure-from-motion (RSfM) and non-rigid structure-from-motion (NRSfM) have long been treated in the literature as separate (different) problems. Inspired by a previous work which solved directly for 3D scene structure by factoring the relative camera poses out, we revisit the principle of "maximizing rigidity" in structure-from-motion literature, and develop a unified theory which is applicable to both rigid and non-rigid structure reconstruction in a rigidity-agnostic way. We formulate these problems as a convex semi-definite program, imposing constraints that seek to apply the principle of minimizing non-rigidity. Our results demonstrate the efficacy of the approach, with state-of-the-art accuracy on various 3D reconstruction problems. version:1
arxiv-1707-05005 | graph2vec: Learning Distributed Representations of Graphs | http://arxiv.org/abs/1707.05005 | id:1707.05005 author:Annamalai Narayanan, Mahinthan Chandramohan, Rajasekar Venkatesan, Lihui Chen, Yang Liu, Shantanu Jaiswal category:cs.AI cs.CL cs.CR cs.NE cs.SE  published:2017-07-17 summary:Recent works on representation learning for graph structured data predominantly focus on learning distributed representations of graph substructures such as nodes and subgraphs. However, many graph analytics tasks such as graph classification and clustering require representing entire graphs as fixed length feature vectors. While the aforementioned approaches are naturally unequipped to learn such representations, graph kernels remain as the most effective way of obtaining them. However, these graph kernels use handcrafted features (e.g., shortest paths, graphlets, etc.) and hence are hampered by problems such as poor generalization. To address this limitation, in this work, we propose a neural embedding framework named graph2vec to learn data-driven distributed representations of arbitrary sized graphs. graph2vec's embeddings are learnt in an unsupervised manner and are task agnostic. Hence, they could be used for any downstream task such as graph classification, clustering and even seeding supervised representation learning approaches. Our experiments on several benchmark and large real-world datasets show that graph2vec achieves significant improvements in classification and clustering accuracies over substructure representation learning approaches and are competitive with state-of-the-art graph kernels. version:1
arxiv-1707-05001 | Coalition formation for Multi-agent Pursuit based on Neural Network and AGRMF Model | http://arxiv.org/abs/1707.05001 | id:1707.05001 author:Zhaoyi Pei, Songhao Piao, Mohammed Ei Souidi category:cs.AI  published:2017-07-17 summary:An approach for coalition formation of multi-agent pursuit based on neural network and AGRMF model is proposed.This paper constructs a novel neural work called AGRMF-ANN which consists of feature extraction part and group generation part. On one hand,The convolutional layers of feature extraction part can abstract the features of agent group role membership function(AGRMF) for all of the groups,on the other hand,those features will be fed to the group generation part based on self-organizing map(SOM) layer which is used to group the pursuers with similar features in the same group. Besides, we also come up the group attractiveness function(GAF) to evaluate the quality of groups and the pursuers contribution in order to adjust the main ability indicators of AGRMF and other weight of all neural network. The simulation experiment showed that this proposal can improve the effectiveness of coalition formation for multi-agent pursuit and ability to adopt pursuit-evasion problem with the scale of pursuer team growing. version:1
arxiv-1707-05000 | In-Order Transition-based Constituent Parsing | http://arxiv.org/abs/1707.05000 | id:1707.05000 author:Jiangming Liu, Yue Zhang category:cs.CL  published:2017-07-17 summary:Both bottom-up and top-down strategies have been used for neural transition-based constituent parsing. The parsing strategies differ in terms of the order in which they recognize productions in the derivation tree, where bottom-up strategies and top-down strategies take post-order and pre-order traversal over trees, respectively. Bottom-up parsers benefit from rich features from readily built partial parses, but lack lookahead guidance in the parsing process; top-down parsers benefit from non-local guidance for local decisions, but rely on a strong encoder over the input to predict a constituent hierarchy before its construction.To mitigate both issues, we propose a novel parsing system based on in-order traversal over syntactic trees, designing a set of transition actions to find a compromise between bottom-up constituent information and top-down lookahead information. Based on stack-LSTM, our psycholinguistically motivated constituent parsing system achieves 91.8 F1 on WSJ benchmark. Furthermore, the system achieves 93.6 F1 with supervised reranking and 94.2 F1 with semi-supervised reranking, which are the best results on the WSJ benchmark. version:1
arxiv-1707-04993 | MoCoGAN: Decomposing Motion and Content for Video Generation | http://arxiv.org/abs/1707.04993 | id:1707.04993 author:Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, Jan Kautz category:cs.CV  published:2017-07-17 summary:Visual information in a natural video can be decomposed into two major components: content and motion. While content encodes the objects present in the video, motion encodes the object dynamics. Based on this prior, we propose the Motion and Content decomposed Generative Adversarial Network (MoCoGAN) framework for video generation. The proposed framework generates a video clip by sequentially mapping random noise vectors to video frames. We divide a random noise vector into content and motion parts. The content part, modeled by a Gaussian, is kept fixed when generating individual frames in a short video clip, since the content in a short clip remains largely the same. On the other hand, the motion part, modeled by a recurrent neural network, aims at representing the dynamics in a video. Despite the lack of supervision signals on the motion - content decomposition in natural videos, we show that the MoCoGAN framework can learn to decompose these two factors through a novel adversarial training scheme. Experimental results on action, facial expression, and on a Tai Chi dataset along with comparison to the state-of-the-art verify the effectiveness of the proposed framework. We further show that, by fixing the content noise while changing the motion noise, MoCoGAN learns to generate videos of different dynamics of the same object, and, by fixing the motion noise while changing the content noise, MoCoGAN learns to generate videos of the same motion from different objects. More information is available in our project page (https://github.com/sergeytulyakov/mocogan). version:1
arxiv-1707-04991 | Tracking as Online Decision-Making: Learning a Policy from Streaming Videos with Reinforcement Learning | http://arxiv.org/abs/1707.04991 | id:1707.04991 author:James Steven Supancic III, Deva Ramanan category:cs.CV  published:2017-07-17 summary:We formulate tracking as an online decision-making process, where a tracking agent must follow an object despite ambiguous image frames and a limited computational budget. Crucially, the agent must decide where to look in the upcoming frames, when to reinitialize because it believes the target has been lost, and when to update its appearance model for the tracked object. Such decisions are typically made heuristically. Instead, we propose to learn an optimal decision-making policy by formulating tracking as a partially observable decision-making process (POMDP). We learn policies with deep reinforcement learning algorithms that need supervision (a reward signal) only when the track has gone awry. We demonstrate that sparse rewards allow us to quickly train on massive datasets, several orders of magnitude more than past work. Interestingly, by treating the data source of Internet videos as unlimited streams, we both learn and evaluate our trackers in a single, unified computational stream. version:1
arxiv-1706-08249 | Few-shot Object Detection | http://arxiv.org/abs/1706.08249 | id:1706.08249 author:Xuanyi Dong, Liang Zheng, Fan Ma, Yi Yang, Deyu Meng category:cs.CV  published:2017-06-26 summary:In this paper, we study object detection using a large pool of unlabeled images and only a few labeled images per category, named "few-shot object detection". The key challenge consists in generating trustworthy training samples as many as possible from the pool. Using few training examples as seeds, our method iterates between model training and high-confidence sample selection. In training, easy samples are generated first and, then the poorly initialized model undergoes improvement. As the model becomes more discriminative, challenging but reliable samples are selected. After that, another round of model improvement takes place. To further improve the precision and recall of the generated training samples, we embed multiple detection models in our framework, which has proven to outperform the single model baseline and the model ensemble method. Experiments on PASCAL VOC'07 indicate that by using as few as three or four samples selected for each category, our method produces very competitive results when compared to the state-of-the-art weakly-supervised approaches using a large number of image-level labels. version:2
arxiv-1707-04987 | Online Multi-Armed Bandit | http://arxiv.org/abs/1707.04987 | id:1707.04987 author:Uma Roy, Ashwath Thirmulai, Joe Zurier category:cs.AI cs.GT  published:2017-07-17 summary:We introduce a novel variant of the multi-armed bandit problem, in which bandits are streamed one at a time to the player, and at each point, the player can either choose to pull the current bandit or move on to the next bandit. Once a player has moved on from a bandit, they may never visit it again, which is a crucial difference between our problem and classic multi-armed bandit problems. In this online context, we study Bernoulli bandits (bandits with payout Ber($p_i$) for some underlying mean $p_i$) with underlying means drawn i.i.d. from various distributions, including the uniform distribution, and in general, all distributions that have a CDF satisfying certain differentiability conditions near zero. In all cases, we suggest several strategies and investigate their expected performance. Furthermore, we bound the performance of any optimal strategy and show that the strategies we have suggested are indeed optimal up to a constant factor. We also investigate the case where the distribution from which the underlying means are drawn is not known ahead of time. We again, are able to suggest algorithms that are optimal up to a constant factor for this case, given certain mild conditions on the universe of distributions. version:1
arxiv-1707-04974 | Low-Rank Kernel Subspace Clustering | http://arxiv.org/abs/1707.04974 | id:1707.04974 author:Pan Ji, Ian Reid, Ravi Garg, Hongdong Li, Mathieu Salzmann category:cs.CV  published:2017-07-17 summary:Most state-of-the-art subspace clustering methods only work with linear (or affine) subspaces. In this paper, we present a kernel subspace clustering method that can handle non-linear models. While an arbitrary kernel can non-linearly map data into high-dimensional Hilbert feature space, the data in the resulting feature space are very unlikely to have the desired subspace structures. By contrast, we propose to learn a low-rank kernel mapping, with which the mapped data in feature space are not only low-rank but also self-expressive, such that the low-dimensional subspace structures are present and manifested in the high-dimensional feature space. We have evaluated the proposed method extensively on both motion segmentation and image clustering benchmarks, and obtained superior results, outperforming the kernel subspace clustering method that uses standard kernels~\cite{patel2014kernel} and other state-of-the-art linear subspace clustering methods. version:1
arxiv-1707-04968 | Visual Question Answering with Memory-Augmented Networks | http://arxiv.org/abs/1707.04968 | id:1707.04968 author:Chao Ma, Chunhua Shen, Anthony Dick, Anton van den Hengel category:cs.CV cs.CL  published:2017-07-17 summary:This paper exploits a memory-augmented neural network to predict accurate answers to visual questions, even when those answers occur rarely in the training set. The memory network incorporates both internal and external memory blocks and selectively pays attention to each training exemplar. We show that memory-augmented neural networks are able to maintain a relatively long-term memory of scarce training exemplars, which is important for visual question answering due to the heavy-tailed distribution of answers in a general VQA setting. Experimental results on two large scale benchmark datasets show the favorable performance of the proposed algorithm with a comparison to state of the art. version:1
arxiv-1707-04960 | Query-Focused Video Summarization: Dataset, Evaluation, and A Memory Network Based Approach | http://arxiv.org/abs/1707.04960 | id:1707.04960 author:Aidean Sharghi, Jacob S. Laurel, Boqing Gong category:cs.CV  published:2017-07-16 summary:Recent years have witnessed a resurgence of interest in video summarization. However, one of the main obstacles to the research on video summarization is the user subjectivity - users have various preferences over the summaries. The subjectiveness causes at least two problems. First, no single video summarizer fits all users unless it interacts with and adapts to the individual users. Second, it is very challenging to evaluate the performance of a video summarizer. To tackle the first problem, we explore the recently proposed query-focused video summarization which introduces user preferences in the form of text queries about the video into the summarization process. We propose a memory network parameterized sequential determinantal point process in order to attend the user query onto different video frames and shots. To address the second challenge, we contend that a good evaluation metric for video summarization should focus on the semantic information that humans can perceive rather than the visual features or temporal overlaps. To this end, we collect dense per-video-shot concept annotations, compile a new dataset, and suggest an efficient evaluation method defined upon the concept annotations. We conduct extensive experiments contrasting our video summarizer to existing ones and present detailed analyses about the dataset and the new evaluation method. version:1
arxiv-1706-05446 | Adversarial Variational Inference for Tweedie Compound Poisson Models | http://arxiv.org/abs/1706.05446 | id:1706.05446 author:Yaodong Yang, Sergey Demyanov, Yunayuan Liu, Jun Wang category:stat.ML stat.AP  published:2017-06-16 summary:Tweedie Compound Poisson models are heavily used for modelling non-negative continuous data with a discrete probability spike at zero. An important practice is the modelling of the aggregate claim loss for insurance policies in actuarial science. However, the intractable density function and the unknown variance function have presented considerable challenges for Tweedie regression models. Previous studies are focused on numerical approximations to the density function. In this study, we tackle the Bayesian Tweedie regression problem via a Variational approach. In particular, we empower the posterior approximation by an implicit model trained in the adversarial setting, introduce the hyper prior by making the parameters of the prior distribution trainable, and integrate out one local latent variable in Tweedie model to reduce the variance. Our method is evaluated on the application of predicting the losses for auto insurance policies. Results show that the proposed method enjoys a state-of-the-art performance among traditional inference methods, while having a richer estimation of the variance function. version:3
arxiv-1707-04958 | An Ensemble Boosting Model for Predicting Transfer to the Pediatric Intensive Care Unit | http://arxiv.org/abs/1707.04958 | id:1707.04958 author:Jonathan Rubin, Cristhian Potes, Minnan Xu-Wilson, Junzi Dong, Asif Rahman, Hiep Nguyen, David Moromisato category:cs.LG stat.AP stat.ML  published:2017-07-16 summary:Our work focuses on the problem of predicting the transfer of pediatric patients from the general ward of a hospital to the pediatric intensive care unit. Using data collected over 5.5 years from the electronic health records of two medical facilities, we develop classifiers based on adaptive boosting and gradient tree boosting. We further combine these learned classifiers into an ensemble model and compare its performance to a modified pediatric early warning score (PEWS) baseline that relies on expert defined guidelines. To gauge model generalizability, we perform an inter-facility evaluation where we train our algorithm on data from one facility and perform evaluation on a hidden test dataset from a separate facility. We show that improvements are witnessed over the PEWS baseline in accuracy (0.77 vs. 0.69), sensitivity (0.80 vs. 0.68), specificity (0.74 vs. 0.70) and AUROC (0.85 vs. 0.73). version:1
arxiv-1707-04957 | Improving Adherence to Heart Failure Management Guidelines via Abductive Reasoning | http://arxiv.org/abs/1707.04957 | id:1707.04957 author:Zhuo Chen, Elmer Salazar, Kyle Marple, Gopal Gupta, Lakshman Tamil, Sandeep Das, Alpesh Amin category:cs.AI  published:2017-07-16 summary:Management of chronic diseases such as heart failure (HF) is a major public health problem. A standard approach to managing chronic diseases by medical community is to have a committee of experts develop guidelines that all physicians should follow. Due to their complexity, these guidelines are difficult to implement and are adopted slowly by the medical community at large. We have developed a physician advisory system that codes the entire set of clinical practice guidelines for managing HF using answer set programming(ASP). In this paper we show how abductive reasoning can be deployed to find missing symptoms and conditions that the patient must exhibit in order for a treatment prescribed by a physician to work effectively. Thus, if a physician does not make an appropriate recommendation or makes a non-adherent recommendation, our system will advise the physician about symptoms and conditions that must be in effect for that recommendation to apply. It is under consideration for acceptance in TPLP. version:1
arxiv-1705-03556 | Relevance-based Word Embedding | http://arxiv.org/abs/1705.03556 | id:1705.03556 author:Hamed Zamani, W. Bruce Croft category:cs.IR cs.CL cs.LG cs.NE  published:2017-05-09 summary:Learning a high-dimensional dense representation for vocabulary terms, also known as a word embedding, has recently attracted much attention in natural language processing and information retrieval tasks. The embedding vectors are typically learned based on term proximity in a large corpus. This means that the objective in well-known word embedding algorithms, e.g., word2vec, is to accurately predict adjacent word(s) for a given word or context. However, this objective is not necessarily equivalent to the goal of many information retrieval (IR) tasks. The primary objective in various IR tasks is to capture relevance instead of term proximity, syntactic, or even semantic similarity. This is the motivation for developing unsupervised relevance-based word embedding models that learn word representations based on query-document relevance information. In this paper, we propose two learning models with different objective functions; one learns a relevance distribution over the vocabulary set for each query, and the other classifies each term as belonging to the relevant or non-relevant class for each query. To train our models, we used over six million unique queries and the top ranked documents retrieved in response to each query, which are assumed to be relevant to the query. We extrinsically evaluate our learned word representation models using two IR tasks: query expansion and query classification. Both query expansion experiments on four TREC collections and query classification experiments on the KDD Cup 2005 dataset suggest that the relevance-based word embedding models significantly outperform state-of-the-art proximity-based embedding models, such as word2vec and GloVe. version:2
arxiv-1707-04943 | Improving Naive Bayes for Regression with Optimised Artificial Surrogate Data | http://arxiv.org/abs/1707.04943 | id:1707.04943 author:Michael Mayo, Eibe Frank category:cs.AI  published:2017-07-16 summary:Can we evolve better training data for machine learning algorithms? We show that we can enhance the generalisation performance of naive Bayes for regression models by generating artificial surrogate training data using population-based optimisation. These results are important because (i) naive Bayes models are simple and interpretable, but frequently underperform compared to more complex "black box" models -- therefore new methods of enhancing accuracy are called for; and (ii) the idea of using real training data only indirectly to construct artificial training data that is subsequently used to train a model is a novel twist on the machine learning paradigm. version:1
arxiv-1707-04940 | Comparative Performance Analysis of Neural Networks Architectures on H2O Platform for Various Activation Functions | http://arxiv.org/abs/1707.04940 | id:1707.04940 author:Yuriy Kochura, Sergii Stirenko, Yuri Gordienko category:cs.LG cs.CV cs.PF  published:2017-07-16 summary:Deep learning (deep structured learning, hierarchi- cal learning or deep machine learning) is a branch of machine learning based on a set of algorithms that attempt to model high- level abstractions in data by using multiple processing layers with complex structures or otherwise composed of multiple non-linear transformations. In this paper, we present the results of testing neural networks architectures on H2O platform for various activation functions, stopping metrics, and other parameters of machine learning algorithm. It was demonstrated for the use case of MNIST database of handwritten digits in single-threaded mode that blind selection of these parameters can hugely increase (by 2-3 orders) the runtime without the significant increase of precision. This result can have crucial influence for opitmization of available and new machine learning methods, especially for image recognition problems. version:1
arxiv-1707-04939 | Performance Evaluation of Distributed Computing Environments with Hadoop and Spark Frameworks | http://arxiv.org/abs/1707.04939 | id:1707.04939 author:Vladyslav Taran, Oleg Alienin, Sergii Stirenko, A. Rojbi, Yuri Gordienko category:cs.DC cs.PF  published:2017-07-16 summary:Recently, due to rapid development of information and communication technologies, the data are created and consumed in the avalanche way. Distributed computing create preconditions for analyzing and processing such Big Data by distributing the computations among a number of compute nodes. In this work, performance of distributed computing environments on the basis of Hadoop and Spark frameworks is estimated for real and virtual versions of clusters. As a test task, we chose the classic use case of word counting in texts of various sizes. It was found that the running times grow very fast with the dataset size and faster than a power function even. As to the real and virtual versions of cluster implementations, this tendency is the similar for both Hadoop and Spark frameworks. Moreover, speedup values decrease significantly with the growth of dataset size, especially for virtual version of cluster configuration. The problem of growing data generated by IoT and multimodal (visual, sound, tactile, neuro and brain-computing, muscle and eye tracking, etc.) interaction channels is presented. In the context of this problem, the current observations as to the running times and speedup on Hadoop and Spark frameworks in real and virtual cluster configurations can be very useful for the proper scaling-up and efficient job management, especially for machine learning and Deep Learning applications, where Big Data are widely present. version:1
arxiv-1707-04935 | Automatized Generation of Alphabets of Symbols | http://arxiv.org/abs/1707.04935 | id:1707.04935 author:Serhii Hamotskyi, Anis Rojbi, Sergii Stirenko, Yuri Gordienko category:cs.HC cs.CL cs.CY  published:2017-07-16 summary:In this paper, we discuss the generation of symbols (and alphabets) based on specific user requirements (medium, priorities, type of information that needs to be conveyed). A framework for the generation of alphabets is proposed, and its use for the generation of a shorthand writing system is explored. We discuss the possible use of machine learning and genetic algorithms to gather inputs for generation of such alphabets and for optimization of already generated ones. The alphabets generated using such methods may be used in very different fields, from the creation of synthetic languages and constructed scripts to the creation of sensible commands for multimodal interaction through Human-Computer Interfaces, such as mouse gestures, touchpads, body gestures, eye-tracking cameras, and brain-computing Interfaces, especially in applications for elderly care and people with disabilities. version:1
arxiv-1707-04931 | Pathological OCT Retinal Layer Segmentation using Branch Residual U-shape Networks | http://arxiv.org/abs/1707.04931 | id:1707.04931 author:Stefanos Apostolopoulos, Sandro De Zanet, Carlos Ciller, Sebastian Wolf, Raphael Sznitman category:cs.CV  published:2017-07-16 summary:The automatic segmentation of retinal layer structures enables clinically-relevant quantification and monitoring of eye disorders over time in OCT imaging. Eyes with late-stage diseases are particularly challenging to segment, as their shape is highly warped due to pathological biomarkers. In this context, we propose a novel fully Convolutional Neural Network (CNN) architecture which combines dilated residual blocks in an asymmetric U-shape configuration, and can segment multiple layers of highly pathological eyes in one shot. We validate our approach on a dataset of late-stage AMD patients and demonstrate lower computational costs and higher performance compared to other state-of-the-art methods. version:1
arxiv-1707-04926 | Theoretical insights into the optimization landscape of over-parameterized shallow neural networks | http://arxiv.org/abs/1707.04926 | id:1707.04926 author:Mahdi Soltanolkotabi, Adel Javanmard, Jason D. Lee category:cs.LG cs.IT math.IT math.OC stat.ML  published:2017-07-16 summary:In this paper we study the problem of learning a shallow artificial neural network that best fits a training data set. We study this problem in the over-parameterized regime where the number of observations are fewer than the number of parameters in the model. We show that with quadratic activations the optimization landscape of training such shallow neural networks has certain favorable characteristics that allow globally optimal models to be found efficiently using a variety of local search heuristics. This result holds for an arbitrary training data of input/output pairs. For differentiable activation functions we also show that gradient descent, when suitably initialized, converges at a linear rate to a globally optimal model. This result focuses on a realizable model where the inputs are chosen i.i.d. from a Gaussian distribution and the labels are generated according to planted weight coefficients. version:1
arxiv-1707-04913 | End-to-End Information Extraction without Token-Level Supervision | http://arxiv.org/abs/1707.04913 | id:1707.04913 author:Rasmus Berg Palm, Dirk Hovy, Florian Laws, Ole Winther category:cs.CL  published:2017-07-16 summary:Most state-of-the-art information extraction approaches rely on token-level labels to find the areas of interest in text. Unfortunately, these labels are time-consuming and costly to create, and consequently, not available for many real-life IE tasks. To make matters worse, token-level labels are usually not the desired output, but just an intermediary step. End-to-end (E2E) models, which take raw text as input and produce the desired output directly, need not depend on token-level labels. We propose an E2E model based on pointer networks, which can be trained directly on pairs of raw input and output text. We evaluate our model on the ATIS data set, MIT restaurant corpus and the MIT movie corpus and compare to neural baselines that do use token-level labels. We achieve competitive results, within a few percentage points of the baselines, showing the feasibility of E2E information extraction without the need for token-level labels. This opens up new possibilities, as for many tasks currently addressed by human extractors, raw input and output data are available, but not token-level labels. version:1
arxiv-1704-07828 | Friendships, Rivalries, and Trysts: Characterizing Relations between Ideas in Texts | http://arxiv.org/abs/1704.07828 | id:1704.07828 author:Chenhao Tan, Dallas Card, Noah A. Smith category:cs.SI cs.CL physics.soc-ph  published:2017-04-25 summary:Understanding how ideas relate to each other is a fundamental question in many domains, ranging from intellectual history to public communication. Because ideas are naturally embedded in texts, we propose the first framework to systematically characterize the relations between ideas based on their occurrence in a corpus of documents, independent of how these ideas are represented. Combining two statistics --- cooccurrence within documents and prevalence correlation over time --- our approach reveals a number of different ways in which ideas can cooperate and compete. For instance, two ideas can closely track each other's prevalence over time, and yet rarely cooccur, almost like a "cold war" scenario. We observe that pairwise cooccurrence and prevalence correlation exhibit different distributions. We further demonstrate that our approach is able to uncover intriguing relations between ideas through in-depth case studies on news articles and research papers. version:2
arxiv-1707-04905 | Expected exponential loss for gaze-based video and volume ground truth annotation | http://arxiv.org/abs/1707.04905 | id:1707.04905 author:Laurent Lejeune, Mario Christoudias, Raphael Sznitman category:cs.CV  published:2017-07-16 summary:Many recent machine learning approaches used in medical imaging are highly reliant on large amounts of image and ground truth data. In the context of object segmentation, pixel-wise annotations are extremely expensive to collect, especially in video and 3D volumes. To reduce this annotation burden, we propose a novel framework to allow annotators to simply observe the object to segment and record where they have looked at with a \$200 eye gaze tracker. Our method then estimates pixel-wise probabilities for the presence of the object throughout the sequence from which we train a classifier in semi-supervised setting using a novel Expected Exponential loss function. We show that our framework provides superior performances on a wide range of medical image settings compared to existing strategies and that our method can be combined with current crowd-sourcing paradigms as well. version:1
arxiv-1707-04904 | Chinese Typography Transfer | http://arxiv.org/abs/1707.04904 | id:1707.04904 author:Jie Chang, Yujun Gu category:cs.CV  published:2017-07-16 summary:In this paper, we propose a new network architecture for Chinese typography transformation based on deep learning. The architecture consists of two sub-networks: (1)a fully convolutional network(FCN) aiming at transferring specified typography style to another in condition of preserving structure information; (2)an adversarial network aiming at generating more realistic strokes in some details. Unlike models proposed before 2012 relying on the complex segmentation of Chinese components or strokes, our model treats every Chinese character as an inseparable image, so pre-processing or post-preprocessing are abandoned. Besides, our model adopts end-to-end training without pre-trained used in other deep models. The experiments demonstrates that our model can synthesize realistic-looking target typography from any source typography both on printed style and handwriting style. version:1
arxiv-1707-04903 | Tunnel Effects in Cognition: A new Mechanism for Scientific Discovery and Education | http://arxiv.org/abs/1707.04903 | id:1707.04903 author:Antoine Cornuéjols, Andrée Tiberghien, Gérard Collet category:cs.AI  published:2017-07-16 summary:It is quite exceptional, if it ever happens, that a new conceptual domain be built from scratch. Usually, it is developed and mastered in interaction, both positive and negative, with other more operational existing domains. Few reasoning mechanisms have been proposed to account for the interplay of different conceptual domains and the transfer of information from one to another. Analogical reasoning is one, blending is another. This paper presents a new mechanism, called 'tunnel effect', that may explain, in part, how scientists and students reason while constructing a new conceptual domain. One experimental study with high school students and analyses from the history of science, particularly about the birth of classical thermodynamics, provide evidence and illustrate this mechanism. The knowledge organization, processes and conditions for its appearance are detailed and put into the perspective of a computational model. Specifically, we put forward the hypothesis that two levels of knowledge, notional and conceptual, cooperate in the scientific discovery process when a new conceptual domain is being built. The type of conceptual learning that can be associated with tunnel effect is discussed and a thorough comparison is made with analogical reasoning in order to underline the main features of the new proposed mechanism. version:1
arxiv-1707-04881 | Generative Adversarial Network based on Resnet for Conditional Image Restoration | http://arxiv.org/abs/1707.04881 | id:1707.04881 author:Meng Wang, Huafeng Li, Fang Li category:cs.CV  published:2017-07-16 summary:The GANs promote an adversarive game to approximate complex and jointed example probability. The networks driven by noise generate fake examples to approximate realistic data distributions. Later the conditional GAN merges prior-conditions as input in order to transfer attribute vectors to the corresponding data. However, the CGAN is not designed to deal with the high dimension conditions since indirect guide of the learning is inefficiency. In this paper, we proposed a network ResGAN to generate fine images in terms of extremely degenerated images. The coarse images aligned to attributes are embedded as the generator inputs and classifier labels. In generative network, a straight path similar to the Resnet is cohered to directly transfer the coarse images to the higher layers. And adversarial training is circularly implemented to prevent degeneration of the generated images. Experimental results of applying the ResGAN to datasets MNIST, CIFAR10/100 and CELEBA show its higher accuracy to the state-of-art GANs. version:1
arxiv-1707-04879 | Listening while Speaking: Speech Chain by Deep Learning | http://arxiv.org/abs/1707.04879 | id:1707.04879 author:Andros Tjandra, Sakriani Sakti, Satoshi Nakamura category:cs.CL cs.LG cs.SD  published:2017-07-16 summary:Despite the close relationship between speech perception and production, research in automatic speech recognition (ASR) and text-to-speech synthesis (TTS) has progressed more or less independently without exerting much mutual influence on each other. In human communication, on the other hand, a closed-loop speech chain mechanism with auditory feedback from the speaker's mouth to her ear is crucial. In this paper, we take a step further and develop a closed-loop speech chain model based on deep learning. The sequence-to-sequence model in close-loop architecture allows us to train our model on the concatenation of both labeled and unlabeled data. While ASR transcribes the unlabeled speech features, TTS attempts to reconstruct the original speech waveform based on the text from ASR. In the opposite direction, ASR also attempts to reconstruct the original text transcription given the synthesized speech. To the best of our knowledge, this is the first deep learning model that integrates human speech perception and production behaviors. Our experimental results show that the proposed approach significantly improved the performance more than separate systems that were only trained with labeled data. version:1
arxiv-1707-04877 | Optical Music Recognition with Convolutional Sequence-to-Sequence Models | http://arxiv.org/abs/1707.04877 | id:1707.04877 author:Eelco van der Wel, Karen Ullrich category:cs.CV cs.IR cs.SD  published:2017-07-16 summary:Optical Music Recognition (OMR) is an important technology within Music Information Retrieval. Deep learning models show promising results on OMR tasks, but symbol-level annotated data sets of sufficient size to train such models are not available and difficult to develop. We present a deep learning architecture called a Convolutional Sequence-to-Sequence model to both move towards an end-to-end trainable OMR pipeline, and apply a learning process that trains on full sentences of sheet music instead of individually labeled symbols. The model is trained and evaluated on a human generated data set, with various image augmentations based on real-world scenarios. This data set is the first publicly available set in OMR research with sufficient size to train and evaluate deep learning models. With the introduced augmentations a pitch recognition accuracy of 81% and a duration accuracy of 94% is achieved, resulting in a note level accuracy of 80%. Finally, the model is compared to commercially available methods, showing a large improvements over these applications. version:1
arxiv-1707-04873 | Reinforcement Learning for Architecture Search by Network Transformation | http://arxiv.org/abs/1707.04873 | id:1707.04873 author:Han Cai, Tianyao Chen, Weinan Zhang, Yong Yu, Jun Wang category:cs.LG cs.AI  published:2017-07-16 summary:Deep neural networks have shown effectiveness in many challenging tasks and proved their strong capability in automatically learning good feature representation from raw input. Nonetheless, designing their architectures still requires much human effort. Techniques for automatically designing neural network architectures such as reinforcement learning based approaches recently show promising results in benchmarks. However, these methods still train each network from scratch during exploring the architecture space, which results in extremely high computational cost. In this paper, we propose a novel reinforcement learning framework for automatic architecture designing, where the action is to grow the network depth or layer width based on the current network architecture with function preserved. As such, the previously validated networks can be reused for further exploration, thus saves a large amount of computational cost. The experiments on image benchmark datasets have demonstrated the efficiency and effectiveness of our proposed solution compared to existing automatic architecture designing methods. version:1
arxiv-1707-04860 | Automated Detection of Non-Relevant Posts on the Russian Imageboard "2ch": Importance of the Choice of Word Representations | http://arxiv.org/abs/1707.04860 | id:1707.04860 author:Amir Bakarov, Olga Gureenkova category:cs.CL  published:2017-07-16 summary:This study considers the problem of automated detection of non-relevant posts on Web forums and discusses the approach of resolving this problem by approximation it with the task of detection of semantic relatedness between the given post and the opening post of the forum discussion thread. The approximated task could be resolved through learning the supervised classifier with a composed word embeddings of two posts. Considering that the success in this task could be quite sensitive to the choice of word representations, we propose a comparison of the performance of different word embedding models. We train 7 models (Word2Vec, Glove, Word2Vec-f, Wang2Vec, AdaGram, FastText, Swivel), evaluate embeddings produced by them on dataset of human judgements and compare their performance on the task of non-relevant posts detection. To make the comparison, we propose a dataset of semantic relatedness with posts from one of the most popular Russian Web forums, imageboard "2ch", which has challenging lexical and grammatical features. version:1
arxiv-1706-10059 | A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem | http://arxiv.org/abs/1706.10059 | id:1706.10059 author:Zhengyao Jiang, Dixing Xu, Jinjun Liang category:q-fin.CP cs.AI q-fin.PM  published:2017-06-30 summary:Financial portfolio management is the process of constant redistribution of a fund into different financial products. This paper presents a financial-model-free Reinforcement Learning framework to provide a deep machine learning solution to the portfolio management problem. The framework consists of the Ensemble of Identical Independent Evaluators (EIIE) topology, a Portfolio-Vector Memory (PVM), an Online Stochastic Batch Learning (OSBL) scheme, and a fully exploiting and explicit reward function. This framework is realized in three instants in this work with a Convolutional Neural Network (CNN), a basic Recurrent Neural Network (RNN), and a Long Short-Term Memory (LSTM). They are, along with a number of recently reviewed or published portfolio-selection strategies, examined in three back-test experiments with a trading period of 30 minutes in a cryptocurrency market. Cryptocurrencies are electronic and decentralized alternatives to government-issued money, with Bitcoin as the best-known example of a cryptocurrency. All three instances of the framework monopolize the top three positions in all experiments, outdistancing other compared trading algorithms. Although with a high commission rate of 0.25% in the backtests, the framework is able to achieve at least 4-fold returns in 50 days. version:2
arxiv-1603-04178 | Stability Analysis and Design of Momentum-based Controllers for Humanoid Robots | http://arxiv.org/abs/1603.04178 | id:1603.04178 author:Gabriele Nava, Francesco Romano, Francesco Nori, Daniele Pucci category:math.OC cs.RO  published:2016-03-14 summary:Envisioned applications for humanoid robots call for the design of balancing and walking controllers. While promising results have been recently achieved, robust and reliable controllers are still a challenge for the control community dealing with humanoid robotics. Momentum-based strategies have proven their effectiveness for controlling humanoids balancing, but the stability analysis of these controllers is still missing. The contribution of this paper is twofold. First, we numerically show that the application of state-of-the-art momentum-based control strategies may lead to unstable zero dynamics. Secondly, we propose simple modifications to the control architecture that avoid instabilities at the zero-dynamics level. Asymptotic stability of the closed loop system is shown by means of a Lyapunov analysis on the linearized system's joint space. The theoretical results are validated with both simulations and experiments on the iCub humanoid robot. version:4
arxiv-1707-04849 | Minimax deviation strategies for machine learning and recognition with short learning samples | http://arxiv.org/abs/1707.04849 | id:1707.04849 author:Michail Schlesinger, Evgeniy Vodolazskiy category:cs.LG  published:2017-07-16 summary:The article is devoted to the problem of small learning samples in machine learning. The flaws of maximum likelihood learning and minimax learning are looked into and the concept of minimax deviation learning is introduced that is free of those flaws. version:1
arxiv-1707-04848 | Do Neural Nets Learn Statistical Laws behind Natural Language? | http://arxiv.org/abs/1707.04848 | id:1707.04848 author:Shuntaro Takahashi, Kumiko Tanaka-Ishii category:cs.CL  published:2017-07-16 summary:The performance of deep learning in natural language processing has been spectacular, but the reason for this success remains unclear because of the inherent complexity of deep learning. This paper provides empirical evidence of its effectiveness and of a limitation of neural networks for language engineering. Precisely, we demonstrate that a Long Short-Term Memory (LSTM)-based neural language model effectively reproduces Zipf's law and Heaps' law, two representative statistical properties underlying natural language. We discuss the quality of the reproducibility and the emergence of Zipf's law and Heaps' law as training progresses. We also point out that the neural language model has a limitation in reproducing long-range correlation, another statistical law of natural language. This understanding could provide a direction of improvement of architectures of neural networks. version:1
arxiv-1707-04835 | Process Migration over CCNx | http://arxiv.org/abs/1707.04835 | id:1707.04835 author:Marc Mosko category:cs.NI cs.DC  published:2017-07-16 summary:Process migration involves moving the running state of a process from one physical system to another, as is commonly done for virtual machines. In this paper, we describe how Content Centric Networking (CCNx) facilitates process migration through an intuitive naming ontology and version checkpointing. version:1
arxiv-1707-04828 | FML-based Dynamic Assessment Agent for Human-Machine Cooperative System on Game of Go | http://arxiv.org/abs/1707.04828 | id:1707.04828 author:Chang-Shing Lee, Mei-Hui Wang, Sheng-Chi Yang, Pi-Hsia Hung, Su-Wei Lin, Nan Shuo, Naoyuki Kubota, Chun-Hsun Chou, Ping-Chiang Chou, Chia-Hsiu Kao category:cs.AI  published:2017-07-16 summary:In this paper, we demonstrate the application of Fuzzy Markup Language (FML) to construct an FML-based Dynamic Assessment Agent (FDAA), and we present an FML-based Human-Machine Cooperative System (FHMCS) for the game of Go. The proposed FDAA comprises an intelligent decision-making and learning mechanism, an intelligent game bot, a proximal development agent, and an intelligent agent. The intelligent game bot is based on the open-source code of Facebook Darkforest, and it features a representational state transfer application programming interface mechanism. The proximal development agent contains a dynamic assessment mechanism, a GoSocket mechanism, and an FML engine with a fuzzy knowledge base and rule base. The intelligent agent contains a GoSocket engine and a summarization agent that is based on the estimated win rate, real-time simulation number, and matching degree of predicted moves. Additionally, the FML for player performance evaluation and linguistic descriptions for game results commentary are presented. We experimentally verify and validate the performance of the FDAA and variants of the FHMCS by testing five games in 2016 and 60 games of Google Master Go, a new version of the AlphaGo program, in January 2017. The experimental results demonstrate that the proposed FDAA can work effectively for Go applications. version:1
arxiv-1707-04822 | Normalized Gradient with Adaptive Stepsize Method for Deep Neural Network Training | http://arxiv.org/abs/1707.04822 | id:1707.04822 author:Adams Wei Yu, Qihang Lin, Ruslan Salakhutdinov, Jaime Carbonell category:cs.LG cs.AI  published:2017-07-16 summary:In this paper, we propose a generic and simple algorithmic framework for first order optimization. The framework essentially contains two consecutive steps in each iteration: 1) computing and normalizing the mini-batch stochastic gradient; 2) selecting adaptive step size to update the decision variable (parameter) towards the negative of the normalized gradient. We show that the proposed approach, when customized to the popular adaptive stepsize methods, such as AdaGrad, can enjoy a sublinear convergence rate, if the objective is convex. We also conduct extensive empirical studies on various non-convex neural network optimization problems, including multi layer perceptron, convolution neural networks and recurrent neural networks. The results indicate the normalized gradient with adaptive step size can help accelerate the training of neural networks. In particular, significant speedup can be observed if the networks are deep or the dependencies are long. version:1
arxiv-1707-04818 | RED: Reinforced Encoder-Decoder Networks for Action Anticipation | http://arxiv.org/abs/1707.04818 | id:1707.04818 author:Jiyang Gao, Zhenheng Yang, Ram Nevatia category:cs.CV  published:2017-07-16 summary:Action anticipation aims to detect an action before it happens. Many real world applications in robotics and surveillance are related to this predictive capability. Current methods address this problem by first anticipating visual representations of future frames and then categorizing the anticipated representations to actions. However, anticipation is based on a single past frame's representation, which ignores the history trend. Besides, it can only anticipate a fixed future time. We propose a Reinforced Encoder-Decoder (RED) network for action anticipation. RED takes multiple history representations as input and learns to anticipate a sequence of future representations. One salient aspect of RED is that a reinforcement module is adopted to provide sequence-level supervision; the reward function is designed to encourage the system to make correct predictions as early as possible. We test RED on TVSeries, THUMOS-14 and TV-Human-Interaction datasets for action anticipation and achieve state-of-the-art performance on all datasets. version:1
arxiv-1707-04817 | Open-Set Language Identification | http://arxiv.org/abs/1707.04817 | id:1707.04817 author:Shervin Malmasi category:cs.CL  published:2017-07-16 summary:We present the first open-set language identification experiments using one-class classification. We first highlight the shortcomings of traditional feature extraction methods and propose a hashing-based feature vectorization approach as a solution. Using a dataset of 10 languages from different writing systems, we train a One- Class Support Vector Machine using only a monolingual corpus for each language. Each model is evaluated against a test set of data from all 10 languages and we achieve an average F-score of 0.99, highlighting the effectiveness of this approach for open-set language identification. version:1
arxiv-1707-04173 | Review: Modeling and Classical Controller Of Quad-rotor | http://arxiv.org/abs/1707.04173 | id:1707.04173 author:Tarek N. Dief, Shigeo Yoshida category:cs.RO  published:2017-07-13 summary:This paper presents an overview of the most effective ideas for the Quad-rotor project. The concept of modeling using different methods is presented. The modeling part presented the nonlinear model, and the concept of linearization using small disturbance theory. Parameter identifications part explained the most important parameters that affect the system stability and tried to get suitable solutions for these problems and identify some parameters experimentally. Data filtration, Kalman filter, Structure design, motor distribution, aerodynamic effect, analysis of shroud and its effect on the resultant thrust were explained. The control part incorporates different classical schemes such as PD and PID controllers to stabilize the Quad-rotor. Also, different ideas are presented to stabilize the quad rotor using PID controllers with some modification to get high maneuverability and better performance. version:2
arxiv-1707-04791 | Non-Asymptotic Analysis of Robust Control from Coarse-Grained Identification | http://arxiv.org/abs/1707.04791 | id:1707.04791 author:Stephen Tu, Ross Boczar, Andrew Packard, Benjamin Recht category:math.OC cs.LG  published:2017-07-15 summary:This work explores the trade-off between the number of samples required to accurately build models of dynamical systems and the degradation of performance in various control objectives due to a coarse approximation. In particular, we show that simple models can be easily fit from input/output data and are sufficient for achieving various control objectives. We derive bounds on the number of noisy input/output samples from a stable linear time-invariant system that are sufficient to guarantee that the corresponding finite impulse response approximation is close to the true system in the $\mathcal{H}_\infty$-norm. We demonstrate that these demands are lower than those derived in prior art which aimed to accurately identify dynamical models. We also explore how different physical input constraints, such as power constraints, affect the sample complexity. Finally, we show how our analysis cleanly fits within the established framework of robust control, demonstrating how a controller designed for an approximate system provably meets performance objectives on the true system. version:1
arxiv-1707-04788 | MPIgnite: An MPI-Like Language and Prototype Implementation for Apache Spark | http://arxiv.org/abs/1707.04788 | id:1707.04788 author:Brandon L. Morris, Anthony Skjellum category:cs.DC  published:2017-07-15 summary:Scale-out parallel processing based on MPI is a 25-year-old standard with at least another decade of preceding history of enabling technologies in the High Performance Computing community. Newer frameworks such as MapReduce, Hadoop, and Spark represent industrial scalable computing solutions that have received broad adoption because of their comparative simplicity of use, applicability to relevant problems, and ability to harness scalable, distributed resources. While MPI provides performance and portability, it lacks in productivity and fault tolerance. Likewise, Spark is a specific example of a current-generation MapReduce and data-parallel computing infrastructure that addresses those goals but in turn lacks peer communication support to allow featherweight, highly scalable peer-to-peer data-parallel code sections. The key contribution of this paper is to demonstrate how to introduce the collective and point-to-point peer communication concepts of MPI into a Spark environment. This is done in order to produce performance-portable, peer-oriented and group-oriented communication services while retaining the essential, desirable properties of Spark. Additional concepts of fault tolerance and productivity are considered. This approach is offered in contrast to adding MapReduce framework as upper-middleware based on a traditional MPI implementation as baseline infrastructure. version:1
arxiv-1707-04781 | Modified Alpha-Rooting Color Image Enhancement Method On The Two-Side 2-D Quaternion Discrete Fourier Transform And The 2-D Discrete Fourier Transform | http://arxiv.org/abs/1707.04781 | id:1707.04781 author:Artyom M. Grigoryan, Aparna John, Sos S. Agaian category:cs.CV  published:2017-07-15 summary:Color in an image is resolved into 3 or 4 color components and 2-Dimages of these components are stored in separate channels. Most of the color image enhancement algorithms are applied channel-by-channel on each image. But such a system of color image processing is not processing the original color. When a color image is represented as a quaternion image, processing is done in original colors. This paper proposes an implementation of the quaternion approach of enhancement algorithm for enhancing color images and is referred as the modified alpha-rooting by the two-dimensional quaternion discrete Fourier transform (2-D QDFT). Enhancement results of this proposed method are compared with the channel-by-channel image enhancement by the 2-D DFT. Enhancements in color images are quantitatively measured by the color enhancement measure estimation (CEME), which allows for selecting optimum parameters for processing by the genetic algorithm. Enhancement of color images by the quaternion based method allows for obtaining images which are closer to the genuine representation of the real original color. version:1
arxiv-1707-04780 | Evolutionary Training of Sparse Artificial Neural Networks: A Network Science Perspective | http://arxiv.org/abs/1707.04780 | id:1707.04780 author:Decebal Constantin Mocanu, Elena Mocanu, Peter Stone, Phuong H. Nguyen, Madeleine Gibescu, Antonio Liotta category:cs.NE cs.AI cs.LG  published:2017-07-15 summary:Through the success of deep learning, Artificial Neural Networks (ANNs) are among the most used artificial intelligence methods nowadays. ANNs have led to major breakthroughs in various domains, such as particle physics, reinforcement learning, speech recognition, computer vision, and so on. Taking inspiration from the network properties of biological neural networks (e.g. sparsity, scale-freeness), we argue that (contrary to general practice) Artificial Neural Networks (ANN), too, should not have fully-connected layers. We show how ANNs perform perfectly well with sparsely-connected layers. Following a Darwinian evolutionary approach, we propose a novel algorithm which evolves an initial random sparse topology (i.e. an Erd\H{o}s-R\'enyi random graph) of two consecutive layers of neurons into a scale-free topology, during the ANN training process. The resulting sparse layers can safely replace the corresponding fully-connected layers. Our method allows to quadratically reduce the number of parameters in the fully conencted layers of ANNs, yielding quadratically faster computational times in both phases (i.e. training and inference), at no decrease in accuracy. We demonstrate our claims on two popular ANN types (restricted Boltzmann machine and multi-layer perceptron), on two types of tasks (supervised and unsupervised learning), and on 14 benchmark datasets. We anticipate that our approach will enable ANNs having billions of neurons and evolved topologies to be capable of handling complex real-world tasks that are intractable using state-of-the-art methods. version:1
arxiv-1707-01596 | Topology Estimation in Bulk Power Grids: Guarantees on Exact Recovery | http://arxiv.org/abs/1707.01596 | id:1707.01596 author:Deepjyoti Deka, Saurav Talukdar, Michael Chertkov, Murti Salapaka category:math.OC cs.SY stat.ML  published:2017-07-05 summary:The topology of a power grid affects its dynamic operation and settlement in the electricity market. Real-time topology identification can enable faster control action following an emergency scenario like failure of a line. This article discusses a graphical model framework for topology estimation in bulk power grids (both loopy transmission and radial distribution) using measurements of voltage collected from the grid nodes. The graphical model for the probability distribution of nodal voltages in linear power flow models is shown to include additional edges along with the operational edges in the true grid. Our proposed estimation algorithms first learn the graphical model and subsequently extract the operational edges using either thresholding or a neighborhood counting scheme. For grid topologies containing no three-node cycles (two buses do not share a common neighbor), we prove that an exact extraction of the operational topology is theoretically guaranteed. This includes a majority of distribution grids that have radial topologies. For grids that include cycles of length three, we provide sufficient conditions that ensure existence of algorithms for exact reconstruction. In particular, for grids with constant impedance per unit length and uniform injection covariances, this observation leads to conditions on geographical placement of the buses. The performance of algorithms is demonstrated in test case simulations. version:2
arxiv-1707-04775 | AI Challenges in Human-Robot Cognitive Teaming | http://arxiv.org/abs/1707.04775 | id:1707.04775 author:Tathagata Chakraborti, Subbarao Kambhampati, Matthias Scheutz, Yu Zhang category:cs.AI  published:2017-07-15 summary:Among the many anticipated roles for robots in future is that of being a human teammate. Aside from all the technological hurdles that have to be overcome on the hardware and control sides to make robots fit for work with humans, the added complication here is that humans have many conscious and subconscious expectations of their teammates -- indeed, teaming is mostly a cognitive rather than physical coordination activity. This focus on cognitive coordination, however, introduces new challenges for the robotics community that require fundamental changes to the traditional view of autonomous agents. In this paper, we provide an analysis of the differences between traditional autonomous robots and robots that team with humans, identifying the necessary teaming capabilities that are largely missing from current robotic systems. We then focus on the important challenges that are unique and of particular importance to human-robot teaming, especially from the point of view of the deliberative process of the autonomous agent, and sketch potential ways to address them. version:1
arxiv-1703-06905 | Learning to Navigate Cloth using Haptics | http://arxiv.org/abs/1703.06905 | id:1703.06905 author:Alexander Clegg, Wenhao Yu, Zackory Erickson, Jie Tan, C. Karen Liu, Greg Turk category:cs.RO  published:2017-03-20 summary:We present a controller that allows an arm-like manipulator to navigate deformable cloth garments in simulation through the use of haptic information. The main challenge of such a controller is to avoid getting tangled in, tearing or punching through the deforming cloth. Our controller aggregates force information from a number of haptic-sensing spheres all along the manipulator for guidance. Based on haptic forces, each individual sphere updates its target location, and the conflicts that arise between this set of desired positions is resolved by solving an inverse kinematic problem with constraints. Reinforcement learning is used to train the controller for a single haptic-sensing sphere, where a training run is terminated (and thus penalized) when large forces are detected due to contact between the sphere and a simplified model of the cloth. In simulation, we demonstrate successful navigation of a robotic arm through a variety of garments, including an isolated sleeve, a jacket, a shirt, and shorts. Our controller out-performs two baseline controllers: one without haptics and another that was trained based on large forces between the sphere and cloth, but without early termination. version:3
arxiv-1707-04771 | Original Loop-closure Detection Algorithm for Monocular vSLAM | http://arxiv.org/abs/1707.04771 | id:1707.04771 author:Andrey Bokovoy, Konstantin Yakovlev category:cs.CV  published:2017-07-15 summary:Vision-based simultaneous localization and mapping (vSLAM) is a well-established problem in mobile robotics and monocular vSLAM is one of the most challenging variations of that problem nowadays. In this work we study one of the core post-processing optimization mechanisms in vSLAM, e.g. loop-closure detection. We analyze the existing methods and propose original algorithm for loop-closure detection, which is suitable for dense, semi-dense and feature-based vSLAM methods. We evaluate the algorithm experimentally and show that it contribute to more accurate mapping while speeding up the monocular vSLAM pipeline to the extent the latter can be used in real-time for controlling small multi-rotor vehicle (drone). version:1
arxiv-1704-08966 | Not All Dialogues are Created Equal: Instance Weighting for Neural Conversational Models | http://arxiv.org/abs/1704.08966 | id:1704.08966 author:Pierre Lison, Serge Bibauw category:cs.CL cs.AI I.2.7; I.2.6  published:2017-04-28 summary:Neural conversational models require substantial amounts of dialogue data for their parameter estimation and are therefore usually learned on large corpora such as chat forums or movie subtitles. These corpora are, however, often challenging to work with, notably due to their frequent lack of turn segmentation and the presence of multiple references external to the dialogue itself. This paper shows that these challenges can be mitigated by adding a weighting model into the architecture. The weighting model, which is itself estimated from dialogue data, associates each training example to a numerical weight that reflects its intrinsic quality for dialogue modelling. At training time, these sample weights are included into the empirical loss to be minimised. Evaluation results on retrieval-based models trained on movie and TV subtitles demonstrate that the inclusion of such a weighting model improves the model performance on unsupervised metrics. version:2
arxiv-1706-09059 | The k-means-u* algorithm: non-local jumps and greedy retries improve k-means++ clustering | http://arxiv.org/abs/1706.09059 | id:1706.09059 author:Bernd Fritzke category:cs.LG I.5.3  published:2017-06-27 summary:We present a new clustering algorithm called k-means-u* which in many cases is able to significantly improve the clusterings found by k-means++, the current de-facto standard for clustering in Euclidean spaces. First we introduce the k-means-u algorithm which starts from a result of k-means++ and attempts to improve it with a sequence of non-local "jumps" alternated by runs of standard k-means. Each jump transfers the "least useful" center towards the center with the largest local error, offset by a small random vector. This is continued as long as the error decreases and often leads to an improved solution. Occasionally k-means-u terminates despite obvious remaining optimization possibilities. By allowing a limited number of retries for the last jump it is frequently possible to reach better local minima. The resulting algorithm is called k-means-u* and dominates k-means++ wrt. solution quality which is demonstrated empirically using various data sets. By construction the logarithmic quality bound established for k-means++ holds for k-means-u* as well. version:2
arxiv-1707-05660 | Quantum Computation via Sparse Distributed Representation | http://arxiv.org/abs/1707.05660 | id:1707.05660 author:Gerard J. Rinkus category:cs.NE  published:2017-07-15 summary:Quantum superposition says that any physical system simultaneously exists in all of its possible states, the number of which is exponential in the number of entities composing the system. The strength of presence of each possible state in the superposition, i.e., its probability of being observed, is represented by its probability amplitude coefficient. The assumption that these coefficients must be represented physically disjointly from each other, i.e., localistically, is nearly universal in the quantum theory/computing literature. Alternatively, these coefficients can be represented using sparse distributed representations (SDR), wherein each coefficient is represented by small subset of an overall population of units, and the subsets can overlap. Specifically, I consider an SDR model in which the overall population consists of Q WTA clusters, each with K binary units. Each coefficient is represented by a set of Q units, one per cluster. Thus, K^Q coefficients can be represented with KQ units. Thus, the particular world state, X, whose coefficient's representation, R(X), is the set of Q units active at time t has the max probability and the probability of every other state, Y_i, at time t, is measured by R(Y_i)'s intersection with R(X). Thus, R(X) simultaneously represents both the particular state, X, and the probability distribution over all states. Thus, set intersection may be used to classically implement quantum superposition. If algorithms exist for which the time it takes to store (learn) new representations and to find the closest-matching stored representation (probabilistic inference) remains constant as additional representations are stored, this meets the criterion of quantum computing. Such an algorithm has already been described: it achieves this "quantum speed-up" without esoteric hardware, and in fact, on a single-processor, classical (Von Neumann) computer. version:1
arxiv-1706-05083 | Ensembling Factored Neural Machine Translation Models for Automatic Post-Editing and Quality Estimation | http://arxiv.org/abs/1706.05083 | id:1706.05083 author:Chris Hokamp category:cs.CL  published:2017-06-15 summary:This work presents a novel approach to Automatic Post-Editing (APE) and Word-Level Quality Estimation (QE) using ensembles of specialized Neural Machine Translation (NMT) systems. Word-level features that have proven effective for QE are included as input factors, expanding the representation of the original source and the machine translation hypothesis, which are used to generate an automatically post-edited hypothesis. We train a suite of NMT models that use different input representations, but share the same output space. These models are then ensembled together, and tuned for both the APE and the QE task. We thus attempt to connect the state-of-the-art approaches to APE and QE within a single framework. Our models achieve state-of-the-art results in both tasks, with the only difference in the tuning step which learns weights for each component of the ensemble. version:2
arxiv-1707-04724 | Memoisation: Purely, Left-recursively, and with (Continuation Passing) Style | http://arxiv.org/abs/1707.04724 | id:1707.04724 author:Samer Abdallah category:cs.LO cs.CL cs.PL  published:2017-07-15 summary:Memoisation, or tabling, is a well-known technique that yields large improvements in the performance of some recursive computations. Tabled resolution in Prologs such as XSB and B-Prolog can transform so called left-recursive predicates from non-terminating computations into finite and well-behaved ones. In the functional programming literature, memoisation has usually been implemented in a way that does not handle left-recursion, requiring supplementary mechanisms to prevent non-termination. A notable exception is Johnson's (1995) continuation passing approach in Scheme. This, however, relies on mutation of a memo table data structure and coding in explicit continuation passing style. We show how Johnson's approach can be implemented purely functionally in a modern, strongly typed functional language (OCaml), presented via a monadic interface that hides the implementation details, yet providing a way to return a compact represention of the memo tables at the end of the computation. version:1
arxiv-1702-05412 | Cover Time in Edge-Uniform Stochastically-Evolving Graphs | http://arxiv.org/abs/1702.05412 | id:1702.05412 author:Ioannis Lamprou, Russell Martin, Paul Spirakis category:cs.DC cs.DM  published:2017-02-17 summary:We define a new general model of stochastically evolving graphs, namely the \emph{Edge-Uniform Stochastically-Evolving Graphs}. In this model, each possible edge of an underlying general static graph evolves independently being either alive or dead at each discrete time step of evolution following a (Markovian) stochastic rule. The stochastic rule is identical for each possible edge and may depend on the previous $k \ge 0$ observations of the edge's state. We examine two kinds of random walks for a single agent taking place in such a dynamic graph: (i) The \emph{Random Walk with a Delay} (\emph{RWD}), where at each step the agent chooses (uniformly at random) an incident possible edge (i.e. an incident edge in the underlying static graph) and then it waits till the edge becomes alive to traverse it. (ii) The more natural \emph{Random Walk on what is Available} (\emph{RWA}) where the agent only looks at alive incident edges at each time step and traverses one of them uniformly at random. Our study is on bounding the \emph{cover time}, i.e. the expected time until each node is visited at least once by the agent. For \emph{RWD}, we provide the first upper bounds for the cases $k = 0, 1$ by correlating \emph{RWD} with a simple random walk on a static graph. Moreover, we present a modified electrical network theory capturing the $k = 0$ case and a mixing-time argument toward an upper bound for the case $k = 1$. For \emph{RWA}, we derive the first upper bounds for the cases $k = 0, 1$, too, by reducing \emph{RWA} to an \emph{RWD}-equivalent walk with a modified delay. Finally, for the case $k = 1$, we prove that when the underlying graph is complete, then the cover time is $\mathcal{O}(n\log n)$ (i.e. it matches the cover time on the static complete graph) under only a mild condition on the edge-existence probabilities determined by the stochastic rule. version:3
arxiv-1707-04693 | Binarized Convolutional Neural Networks with Separable Filters for Efficient Hardware Acceleration | http://arxiv.org/abs/1707.04693 | id:1707.04693 author:Jeng-Hau Lin, Tianwei Xing, Ritchie Zhao, Zhiru Zhang, Mani Srivastava, Zhuowen Tu, Rajesh K. Gupta category:cs.CV  published:2017-07-15 summary:State-of-the-art convolutional neural networks are enormously costly in both compute and memory, demanding massively parallel GPUs for execution. Such networks strain the computational capabilities and energy available to embedded and mobile processing platforms, restricting their use in many important applications. In this paper, we push the boundaries of hardware-effective CNN design by proposing BCNN with Separable Filters (BCNNw/SF), which applies Singular Value Decomposition (SVD) on BCNN kernels to further reduce computational and storage complexity. To enable its implementation, we provide a closed form of the gradient over SVD to calculate the exact gradient with respect to every binarized weight in backward propagation. We verify BCNNw/SF on the MNIST, CIFAR-10, and SVHN datasets, and implement an accelerator for CIFAR-10 on FPGA hardware. Our BCNNw/SF accelerator realizes memory savings of 17% and execution time reduction of 31.3% compared to BCNN with only minor accuracy sacrifices. version:1
arxiv-1707-04692 | On the Performance of Forecasting Models in the Presence of Input Uncertainty | http://arxiv.org/abs/1707.04692 | id:1707.04692 author:Hossein Sangrody, Morteza Sarailoo, Ning Zhou, Ahmad Shokrollahi, Elham Foruzan category:stat.ML  published:2017-07-15 summary:Nowadays, with the unprecedented penetration of renewable distributed energy resources (DERs), the necessity of an efficient energy forecasting model is more demanding than before. Generally, forecasting models are trained using observed weather data while the trained models are applied for energy forecasting using forecasted weather data. In this study, the performance of several commonly used forecasting methods in the presence of weather predictors with uncertainty is assessed and compared. Accordingly, both observed and forecasted weather data are collected, then the influential predictors for solar PV generation forecasting model are selected using several measures. Using observed and forecasted weather data, an analysis on the uncertainty of weather variables is represented by MAE and bootstrapping. The energy forecasting model is trained using observed weather data, and finally, the performance of several commonly used forecasting methods in solar energy forecasting is simulated and compared for a real case study. version:1
arxiv-1707-05309 | Dominant Sets for "Constrained" Image Segmentation | http://arxiv.org/abs/1707.05309 | id:1707.05309 author:Eyasu Zemene, Leulseged Tesfaye Alemu, Marcello Pelillo category:cs.CV  published:2017-07-15 summary:Image segmentation has come a long way since the early days of computer vision, and still remains a challenging task. Modern variations of the classical (purely bottom-up) approach, involve, e.g., some form of user assistance (interactive segmentation) or ask for the simultaneous segmentation of two or more images (co-segmentation). At an abstract level, all these variants can be thought of as "constrained" versions of the original formulation, whereby the segmentation process is guided by some external source of information. In this paper, we propose a new approach to tackle this kind of problems in a unified way. Our work is based on some properties of a family of quadratic optimization problems related to dominant sets, a well-known graph-theoretic notion of a cluster which generalizes the concept of a maximal clique to edge-weighted graphs. In particular, we show that by properly controlling a regularization parameter which determines the structure and the scale of the underlying problem, we are in a position to extract groups of dominant-set clusters that are constrained to contain predefined elements. In particular, we shall focus on interactive segmentation and co-segmentation (in both the unsupervised and the interactive versions). The proposed algorithm can deal naturally with several type of constraints and input modality, including scribbles, sloppy contours, and bounding boxes, and is able to robustly handle noisy annotations on the part of the user. Experiments on standard benchmark datasets show the effectiveness of our approach as compared to state-of-the-art algorithms on a variety of natural images under several input conditions and constraints. version:1
arxiv-1707-04679 | Ternary Residual Networks | http://arxiv.org/abs/1707.04679 | id:1707.04679 author:Abhisek Kundu, Kunal Banerjee, Naveen Mellempudi, Dheevatsa Mudigere, Dipankar Das, Bharat Kaul, Pradeep Dubey category:cs.IT cs.AI math.IT  published:2017-07-15 summary:Sub-8-bit representation of DNNs incur some noticeable loss of accuracy despite rigorous (re)training at low-precision. Such loss of accuracy essentially makes them equivalent to a much shallower counterpart, diminishing the power of being deep networks. To address this problem of accuracy drop we introduce the notion of \textit{residual networks} where we add more low-precision edges to sensitive branches of the sub-8-bit network to compensate for the lost accuracy. Further, we present a perturbation theory to identify such sensitive edges. Aided by such an elegant trade-off between accuracy and model size, the 8-2 architecture (8-bit activations, ternary weights), enhanced by residual ternary edges, turns out to be sophisticated enough to achieve similar accuracy as 8-8 representation ($\sim 1\%$ drop from our FP-32 baseline), despite $\sim 1.6\times$ reduction in model size, $\sim 26\times$ reduction in number of multiplications , and potentially $\sim 2\times$ inference speed up comparing to 8-8 representation, on the state-of-the-art deep network ResNet-101 pre-trained on ImageNet dataset. Moreover, depending on the varying accuracy requirements in a dynamic environment, the deployed low-precision model can be upgraded/downgraded on-the-fly by partially enabling/disabling residual connections. For example, disabling the least important residual connections in the above enhanced network, the accuracy drop is $\sim 2\%$ (from our FP-32 baseline), despite $\sim 1.9\times$ reduction in model size, $\sim 32\times$ reduction in number of multiplications, and potentially $\sim 2.3\times$ inference speed up comparing to 8-8 representation. Finally, all the ternary connections are sparse in nature, and the residual ternary conversion can be done in a resource-constraint setting without any low-precision (re)training and without accessing the data. version:1
arxiv-1707-04678 | Lyrics-Based Music Genre Classification Using a Hierarchical Attention Network | http://arxiv.org/abs/1707.04678 | id:1707.04678 author:Alexandros Tsaptsinos category:cs.IR cs.CL cs.NE  published:2017-07-15 summary:Music genre classification, especially using lyrics alone, remains a challenging topic in Music Information Retrieval. In this study we apply recurrent neural network models to classify a large dataset of intact song lyrics. As lyrics exhibit a hierarchical layer structure - in which words combine to form lines, lines form segments, and segments form a complete song - we adapt a hierarchical attention network (HAN) to exploit these layers and in addition learn the importance of the words, lines, and segments. We test the model over a 117-genre dataset and a reduced 20-genre dataset. Experimental results show that the HAN outperforms both non-neural models and simpler neural models, whilst also classifying over a higher number of genres than previous research. Through the learning process we can also visualise which words or lines in a song the model believes are important to classifying the genre. As a result the HAN provides insights, from a computational perspective, into lyrical structure and language features that differentiate musical genres. version:1
arxiv-1707-04677 | Knowledge-Guided Recurrent Neural Network Learning for Task-Oriented Action Prediction | http://arxiv.org/abs/1707.04677 | id:1707.04677 author:Liang Lin, Lili Huang, Tianshui Chen, Yukang Gan, Hui Cheng category:cs.CV  published:2017-07-15 summary:This paper aims at task-oriented action prediction, i.e., predicting a sequence of actions towards accomplishing a specific task under a certain scene, which is a new problem in computer vision research. The main challenges lie in how to model task-specific knowledge and integrate it in the learning procedure. In this work, we propose to train a recurrent long-short term memory (LSTM) network for handling this problem, i.e., taking a scene image (including pre-located objects) and the specified task as input and recurrently predicting action sequences. However, training such a network usually requires large amounts of annotated samples for covering the semantic space (e.g., diverse action decomposition and ordering). To alleviate this issue, we introduce a temporal And-Or graph (AOG) for task description, which hierarchically represents a task into atomic actions. With this AOG representation, we can produce many valid samples (i.e., action sequences according with common sense) by training another auxiliary LSTM network with a small set of annotated samples. And these generated samples (i.e., task-oriented action sequences) effectively facilitate training the model for task-oriented action prediction. In the experiments, we create a new dataset containing diverse daily tasks and extensively evaluate the effectiveness of our approach. version:1
arxiv-1707-04674 | ADAPT: Zero-Shot Adaptive Policy Transfer for Stochastic Dynamical Systems | http://arxiv.org/abs/1707.04674 | id:1707.04674 author:James Harrison, Animesh Garg, Boris Ivanovic, Yuke Zhu, Silvio Savarese, Li Fei-Fei, Marco Pavone category:cs.RO  published:2017-07-15 summary:Model-free policy learning has enabled robust performance of complex tasks with relatively simple algorithms. However, this simplicity comes at the cost of requiring an Oracle and arguably very poor sample complexity. This renders such methods unsuitable for physical systems. Variants of model-based methods address this problem through the use of simulators, however, this gives rise to the problem of policy transfer from simulated to the physical system. Model mismatch due to systematic parameter shift and unmodelled dynamics error may cause sub-optimal or unsafe behavior upon direct transfer. We introduce the Adaptive Policy Transfer for Stochastic Dynamics (ADAPT) algorithm that achieves provably safe and robust, dynamically-feasible zero-shot transfer of RL-policies to new domains with dynamics error. ADAPT combines the strengths of offline policy learning in a black-box source simulator with online tube-based MPC to attenuate bounded model mismatch between the source and target dynamics. ADAPT allows online transfer of policy, trained solely in a simulation offline, to a family of unknown targets without fine-tuning. We also formally show that (i) ADAPT guarantees state and control safety through state-action tubes under the assumption of Lipschitz continuity of the divergence in dynamics and, (ii) ADAPT results in a bounded loss of reward accumu- lation in case of direct transfer with ADAPT as compared to a policy trained only on target. We evaluate ADAPT on 2 continuous, non-holonomic simulated dynamical systems with 4 different disturbance models, and find that ADAPT performs between 50%-300% better on mean reward accrual than direct policy transfer. version:1
arxiv-1707-04673 | Learning linear structural equation models in polynomial time and sample complexity | http://arxiv.org/abs/1707.04673 | id:1707.04673 author:Asish Ghoshal, Jean Honorio category:cs.LG stat.ML  published:2017-07-15 summary:The problem of learning structural equation models (SEMs) from data is a fundamental problem in causal inference. We develop a new algorithm --- which is computationally and statistically efficient and works in the high-dimensional regime --- for learning linear SEMs from purely observational data with arbitrary noise distribution. We consider three aspects of the problem: identifiability, computational efficiency, and statistical efficiency. We show that when data is generated from a linear SEM over $p$ nodes and maximum degree $d$, our algorithm recovers the directed acyclic graph (DAG) structure of the SEM under an identifiability condition that is more general than those considered in the literature, and without faithfulness assumptions. In the population setting, our algorithm recovers the DAG structure in $\mathcal{O}(p(d^2 + \log p))$ operations. In the finite sample setting, if the estimated precision matrix is sparse, our algorithm has a smoothed complexity of $\widetilde{\mathcal{O}}(p^3 + pd^7)$, while if the estimated precision matrix is dense, our algorithm has a smoothed complexity of $\widetilde{\mathcal{O}}(p^5)$. For sub-Gaussian noise, we show that our algorithm has a sample complexity of $\mathcal{O}(\frac{d^8}{\varepsilon^2} \log (\frac{p}{\sqrt{\delta}}))$ to achieve $\varepsilon$ element-wise additive error with respect to the true autoregression matrix with probability at most $1 - \delta$, while for noise with bounded $(4m)$-th moment, with $m$ being a positive integer, our algorithm has a sample complexity of $\mathcal{O}(\frac{d^8}{\varepsilon^2} (\frac{p^2}{\delta})^{1/m})$. version:1
arxiv-1707-04662 | Rotations and Interpretability of Word Embeddings: the Case of the Russian Language | http://arxiv.org/abs/1707.04662 | id:1707.04662 author:Alexey Zobnin category:cs.CL  published:2017-07-14 summary:Consider a continuous word embedding model. Usually, the cosines between word vectors are used as a measure of similarity of words. These cosines do not change under orthogonal transformations of the embedding space. We demonstrate that, using some canonical orthogonal transformations from SVD, it is possible both to increase the meaning of some components and to make the components more stable under re-learning. We study the interpretability of components for publicly available models for the Russian language (RusVectores, fastText, RDT). version:1
arxiv-1707-04659 | Variational approach for learning Markov processes from time series data | http://arxiv.org/abs/1707.04659 | id:1707.04659 author:Hao Wu, Frank Noé category:stat.ML math.DS  published:2017-07-14 summary:Inference, prediction and control of complex dynamical systems from time series is important in many areas, including financial markets, power grid management, climate and weather modeling, or molecular dynamics. The analysis of such highly nonlinear dynamical systems is facilitated by the fact that we can often find a (generally nonlinear) transformation of the system coordinates to features in which the dynamics can be excellently approximated by a linear Markovian model. Moreover, the large number of system variables often change collectively on large time- and length-scales, facilitating a low-dimensional analysis in feature space. In this paper, we introduce a variational approach for Markov processes (VAMP) that allows us to find optimal feature mappings and optimal Markovian models of the dynamics from given time series data. The key insight is that the best linear model can be obtained from the top singular components of the Koopman operator. This leads to the definition of a family of score functions called VAMP-r which can be calculated from data, and can be employed to optimize a Markovian model. In addition, based on the relationship between the variational scores and approximation errors of Koopman operators, we propose a new VAMP-E score, which can be applied to cross-validation for hyper-parameter optimization and model selection in VAMP. VAMP is valid for both reversible and nonreversible processes and for stationary and non-stationary processes or realizations. version:1
arxiv-1707-04657 | Variable Instruction Fetch Rate to Reduce Control Dependent Penalties | http://arxiv.org/abs/1707.04657 | id:1707.04657 author:Aswin Ramachandran, Louis Johnson category:cs.AR cs.CY  published:2017-07-14 summary:In order to overcome the branch execution penalties of hard-to-predict instruction branches, two new instruction fetch micro-architectural methods are proposed in this paper. In addition, to compare performance of the two proposed methods, different instruction fetch policy schemes of existing multi-branch path architectures are evaluated. An improvement in Instructions Per Cycle (IPC) of 29.4% on average over single-thread execution with gshare branch predictor on SPEC 2000/2006 benchmark is shown. In this paper, wide pipeline machines are simulated for evaluation purposes. The methods discussed in this paper can be extended to High Performance Scientific Computing needs, if the demands of IPC improvement are far more critical than $cost. version:1
arxiv-1707-04653 | A Semantics-Based Measure of Emoji Similarity | http://arxiv.org/abs/1707.04653 | id:1707.04653 author:Sanjaya Wijeratne, Lakshika Balasuriya, Amit Sheth, Derek Doran category:cs.CL cs.SI  published:2017-07-14 summary:Emoji have grown to become one of the most important forms of communication on the web. With its widespread use, measuring the similarity of emoji has become an important problem for contemporary text processing since it lies at the heart of sentiment analysis, search, and interface design tasks. This paper presents a comprehensive analysis of the semantic similarity of emoji through embedding models that are learned over machine-readable emoji meanings in the EmojiNet knowledge base. Using emoji descriptions, emoji sense labels and emoji sense definitions, and with different training corpora obtained from Twitter and Google News, we develop and test multiple embedding models to measure emoji similarity. To evaluate our work, we create a new dataset called EmoSim508, which assigns human-annotated semantic similarity scores to a set of 508 carefully selected emoji pairs. After validation with EmoSim508, we present a real-world use-case of our emoji embedding models using a sentiment analysis task and show that our models outperform the previous best-performing emoji embedding model on this task. The EmoSim508 dataset and our emoji embedding models are publicly released with this paper and can be downloaded from http://emojinet.knoesis.org/. version:1
arxiv-1707-04652 | EmojiNet: An Open Service and API for Emoji Sense Discovery | http://arxiv.org/abs/1707.04652 | id:1707.04652 author:Sanjaya Wijeratne, Lakshika Balasuriya, Amit Sheth, Derek Doran category:cs.CL cs.SI  published:2017-07-14 summary:This paper presents the release of EmojiNet, the largest machine-readable emoji sense inventory that links Unicode emoji representations to their English meanings extracted from the Web. EmojiNet is a dataset consisting of: (i) 12,904 sense labels over 2,389 emoji, which were extracted from the web and linked to machine-readable sense definitions seen in BabelNet, (ii) context words associated with each emoji sense, which are inferred through word embedding models trained over Google News corpus and a Twitter message corpus for each emoji sense definition, and (iii) recognizing discrepancies in the presentation of emoji on different platforms, specification of the most likely platform-based emoji sense for a selected set of emoji. The dataset is hosted as an open service with a REST API and is available at http://emojinet.knoesis.org/. The development of this dataset, evaluation of its quality, and its applications including emoji sense disambiguation and emoji sense similarity are discussed. version:1
arxiv-1707-04642 | Recognizing Abnormal Heart Sounds Using Deep Learning | http://arxiv.org/abs/1707.04642 | id:1707.04642 author:Jonathan Rubin, Rui Abreu, Anurag Ganguli, Saigopal Nelaturi, Ion Matei, Kumar Sricharan category:cs.SD cs.CV  published:2017-07-14 summary:The work presented here applies deep learning to the task of automated cardiac auscultation, i.e. recognizing abnormalities in heart sounds. We describe an automated heart sound classification algorithm that combines the use of time-frequency heat map representations with a deep convolutional neural network (CNN). Given the cost-sensitive nature of misclassification, our CNN architecture is trained using a modified loss function that directly optimizes the trade-off between sensitivity and specificity. We evaluated our algorithm at the 2016 PhysioNet Computing in Cardiology challenge where the objective was to accurately classify normal and abnormal heart sounds from single, short, potentially noisy recordings. Our entry to the challenge achieved a final specificity of 0.95, sensitivity of 0.73 and overall score of 0.84. We achieved the greatest specificity score out of all challenge entries and, using just a single CNN, our algorithm differed in overall score by only 0.02 compared to the top place finisher, which used an ensemble approach. version:1
arxiv-1707-04639 | Assessing Retail Employee Risk Through Unsupervised Learning Techniques | http://arxiv.org/abs/1707.04639 | id:1707.04639 author:Richard R. Yang, Mike Borowczak category:cs.LG  published:2017-07-14 summary:The retail industry is a data-rich environment, especially in the case of risk management. However, much of this risk management data is not used to its full potential and there exists a need for more automated analytic tools. Supervised learning solutions are not enticing due to the difficulty of providing meaningful labels for these types of dataset. In this project, we explore the utility of three unsupervised learning techniques: Principal Component Analysis (PCA), t-Distributed Stochastic Neighbor Embedding (t-SNE), and Self-Organizing Feature Maps (SOFM) on an unlabeled real world dataset. Specifically, we use these techniques to identify features that correlate to the amount of risk a retail cashier poses to the store. We show that while PCA and t-SNE allow clustering and visualization of cashier data, they are not sufficient for detailed risk management analysis. Also, we expand the reach of the SOFM algorithm in real world applications by showing that it provides better visualization than PCA and t-SNE, and allows for detailed analysis of this dataset. version:1
arxiv-1707-04638 | Predicting multicellular function through multi-layer tissue networks | http://arxiv.org/abs/1707.04638 | id:1707.04638 author:Marinka Zitnik, Jure Leskovec category:cs.LG cs.SI q-bio.MN stat.ML  published:2017-07-14 summary:Motivation: Understanding functions of proteins in specific human tissues is essential for insights into disease diagnostics and therapeutics, yet prediction of tissue-specific cellular function remains a critical challenge for biomedicine. Results: Here we present OhmNet, a hierarchy-aware unsupervised node feature learning approach for multi-layer networks. We build a multi-layer network, where each layer represents molecular interactions in a different human tissue. OhmNet then automatically learns a mapping of proteins, represented as nodes, to a neural embedding based low-dimensional space of features. OhmNet encourages sharing of similar features among proteins with similar network neighborhoods and among proteins activated in similar tissues. The algorithm generalizes prior work, which generally ignores relationships between tissues, by modeling tissue organization with a rich multiscale tissue hierarchy. We use OhmNet to study multicellular function in a multi-layer protein interaction network of 107 human tissues. In 48 tissues with known tissue-specific cellular functions, OhmNet provides more accurate predictions of cellular function than alternative approaches, and also generates more accurate hypotheses about tissue-specific protein actions. We show that taking into account the tissue hierarchy leads to improved predictive power. Remarkably, we also demonstrate that it is possible to leverage the tissue hierarchy in order to effectively transfer cellular functions to a functionally uncharacterized tissue. Overall, OhmNet moves from flat networks to multiscale models able to predict a range of phenotypes spanning cellular subsystems version:1
arxiv-1707-04629 | Compliant Movement Primitives in a Bimanual Setting | http://arxiv.org/abs/1707.04629 | id:1707.04629 author:Aleksandar Batinica, Bojan Nemec, Aleš Ude, Mirko Raković, Andrej Gams category:cs.RO  published:2017-07-14 summary:Simultaneously achieving low trajectory errors and compliant control \emph{without} explicit models of the task was effectively addressed with Compliant Movement Primitives (CMP). For a single-robot task, this means that it is accurately following its trajectory, but also exhibits compliant behavior in case of perturbations. In this paper we extend this kind of behavior without explicit models to bimanual tasks. In the presence of an external perturbation on any of the robots, they will both move in synchrony in order to maintain their relative posture, and thus not exert force on the object they are carrying. Thus, they will act compliantly in their absolute task, but remain stiff in their relative task. To achieve compliant absolute behavior and stiff relative behavior, we combine joint-space CMPs with the well known symmetric control approach. To reduce the necessary feedback reaction of symmetric control, we further augment it with copying of a virtual force vector at the end-effector, calculated through the measured external joint torques. Real-world results on two Kuka LWR-4 robots in a bimanual setting confirm the applicability of the approach. version:1
arxiv-1707-04626 | Simplified Long Short-term Memory Recurrent Neural Networks: part III | http://arxiv.org/abs/1707.04626 | id:1707.04626 author:Atra Akandeh, Fathi M. Salem category:cs.NE cs.LG  published:2017-07-14 summary:This is part III of three-part work. In parts I and II, we have presented eight variants for simplified Long Short Term Memory (LSTM) recurrent neural networks (RNNs). It is noted that fast computation, specially in constrained computing resources, are an important factor in processing big time-sequence data. In this part III paper, we present and evaluate two new LSTM model variants which dramatically reduce the computational load while retaining comparable performance to the base (standard) LSTM RNNs. In these new variants, we impose (Hadamard) pointwise state multiplications in the cell-memory network in addition to the gating signal networks. version:1
arxiv-1707-04623 | Simplified Long Short-term Memory Recurrent Neural Networks: part II | http://arxiv.org/abs/1707.04623 | id:1707.04623 author:Atra Akandeh, Fathi M. Salem category:cs.NE cs.LG  published:2017-07-14 summary:This is part II of three-part work. Here, we present a second set of inter-related five variants of simplified Long Short-term Memory (LSTM) recurrent neural networks by further reducing adaptive parameters. Two of these models have been introduced in part I of this work. We evaluate and verify our model variants on the benchmark MNIST dataset and assert that these models are comparable to the base LSTM model while use progressively less number of parameters. Moreover, we observe that in case of using the ReLU activation, the test accuracy performance of the standard LSTM will drop after a number of epochs when learning parameter become larger. However all of the new model variants sustain their performance. version:1
arxiv-1707-04619 | Simplified Long Short-term Memory Recurrent Neural Networks: part I | http://arxiv.org/abs/1707.04619 | id:1707.04619 author:Atra Akandeh, Fathi M. Salem category:cs.NE cs.LG  published:2017-07-14 summary:We present five variants of the standard Long Short-term Memory (LSTM) recurrent neural networks by uniformly reducing blocks of adaptive parameters in the gating mechanisms. For simplicity, we refer to these models as LSTM1, LSTM2, LSTM3, LSTM4, and LSTM5, respectively. Such parameter-reduced variants enable speeding up data training computations and would be more suitable for implementations onto constrained embedded platforms. We comparatively evaluate and verify our five variant models on the classical MNIST dataset and demonstrate that these variant models are comparable to a standard implementation of the LSTM model while using less number of parameters. Moreover, we observe that in some cases the standard LSTM's accuracy performance will drop after a number of epochs when using the ReLU nonlinearity; in contrast, however, LSTM3, LSTM4 and LSTM5 will retain their performance. version:1
arxiv-1707-04618 | Communication Lower Bounds of Bilinear Algorithms for Symmetric Tensor Contractions | http://arxiv.org/abs/1707.04618 | id:1707.04618 author:Edgar Solomonik, James Demmel, Torsten Hoefler category:cs.DC cs.NA  published:2017-07-14 summary:Accurate numerical calculations of electronic structure are often dominated in cost by tensor contractions. These tensors are typically symmetric under interchange of modes, enabling reduced-size representations as well as a reduced computation cost. Direct evaluation algorithms for such contractions use matrix and vector unfoldings of the tensors, computing and accumulating products of input elements. Symmetry preserving algorithms reduce the number of products by multiplying linear combinations of input elements. The two schemes can be encoded via sparse matrices as bilinear algorithms. We formulate a general notion of expansion for bilinear algorithms in terms of the rank of submatrices of the sparse matrix encoding. This expansion bounds the number of products that can be computed provided a bounded amount of data. Consequently, we derive communication lower bounds for any sequential or parallel schedule of a bilinear algorithm with a given expansion. After deriving such expansion bounds for the tensor contraction algorithms, we obtain new results that demonstrate asymptotic communication overheads associated with exploiting symmetries. Computing a nonsymmetric tensor contraction requires less communication than either method for symmetric contractions when either (1) computing a symmetrized tensor-product of tensors of different orders or (2) the tensor unfolding of the contraction corresponds to a matrix-vector product with a nonsquare matrix. Further, when the unfolding is a product of two non-square matrices, asymptotically more communication is needed by the symmetry preserving algorithm than the traditional algorithm, despite its lower computation cost. version:1
arxiv-1707-04617 | A Real-Time Solver For Time-Optimal Control Of Omnidirectional Robots with Bounded Acceleration | http://arxiv.org/abs/1707.04617 | id:1707.04617 author:David Balaban, Joydeep Biswas category:cs.RO  published:2017-07-14 summary:We are interested in the problem of time-optimal control of omnidirectional robots with bounded acceleration (TOC-ORBA). While there exist approximate solutions for such robots, and exact solutions with unbounded acceleration, exact solvers to the TOC-ORBA problem have remained elusive until now. In this paper, we present a real-time solver for true time-optimal control of omnidirectional robots with bounded acceleration. We first derive the general parameterized form of the solution to the TOC-ORBA problem by application of Pontryagin's maximum principle. Next, we derive bounds for the parameters for the optimal control solution, thus defining a closed trust region over the parameter space. We then frame the boundary value problem of TOC-ORBA as an optimization problem over the parametrized control space. To overcome local minima and poor initial guesses to the optimization problem, we introduce a two-stage optimal control solver (TSOCS) that first solves an approximation of the problem to satisfy the location and direction constraints of the TOC-ORBA problem, followed by a second stage where the solution to the approximate problem is used as an initial seed to solve the complete TOC-ORBA problem. We present extensive experimental results over the space of TOC-ORBA problems demonstrating the accuracy, robustness, and successful convergence properties of TSOCS. We further demonstrate the numerical stability, and convergence properties of TSOCS under closed-loop control, even in the presence of noisy actuation. Finally, by comparing our exact solver to existing approximate solvers, we empirically demonstrate the extent of improvement in the quality of solutions, even under noisy actuation. version:1
arxiv-1707-04615 | On the Complexity of Learning Neural Networks | http://arxiv.org/abs/1707.04615 | id:1707.04615 author:Le Song, Santosh Vempala, John Wilmes, Bo Xie category:cs.LG cs.CC  published:2017-07-14 summary:The stunning empirical successes of neural networks currently lack rigorous theoretical explanation. What form would such an explanation take, in the face of existing complexity-theoretic lower bounds? A first step might be to show that data generated by neural networks with a single hidden layer, smooth activation functions and benign input distributions can be learned efficiently. We demonstrate here a comprehensive lower bound ruling out this possibility: for a wide class of activation functions (including all currently used), and inputs drawn from any logconcave distribution, there is a family of one-hidden-layer functions whose output is a sum gate, that are hard to learn in a precise sense: any statistical query algorithm (which includes all known variants of stochastic gradient descent with any loss function) needs an exponential number of queries even using tolerance inversely proportional to the input dimensionality. Moreover, this hard family of functions is realizable with a small (sublinear in dimension) number of activation units in the single hidden layer. The lower bound is also robust to small perturbations of the true weights. Systematic experiments illustrate a phase transition in the training error as predicted by the analysis. version:1
arxiv-1707-05308 | Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples | http://arxiv.org/abs/1707.05308 | id:1707.05308 author:Amit Sheth, Sujan Perera, Sanjaya Wijeratne, Krishnaprasad Thirunarayan category:cs.AI  published:2017-07-14 summary:Machine Learning has been a big success story during the AI resurgence. One particular stand out success relates to learning from a massive amount of data. In spite of early assertions of the unreasonable effectiveness of data, there is increasing recognition for utilizing knowledge whenever it is available or can be created purposefully. In this paper, we discuss the indispensable role of knowledge for deeper understanding of content where (i) large amounts of training data are unavailable, (ii) the objects to be recognized are complex, (e.g., implicit entities and highly subjective content), and (iii) applications need to use complementary or related data in multiple modalities/media. What brings us to the cusp of rapid progress is our ability to (a) create relevant and reliable knowledge and (b) carefully exploit knowledge to enhance ML/NLP techniques. Using diverse examples, we seek to foretell unprecedented progress in our ability for deeper understanding and exploitation of multimodal data and continued incorporation of knowledge in learning techniques. version:1
arxiv-1707-00243 | Deep GrabCut for Object Selection | http://arxiv.org/abs/1707.00243 | id:1707.00243 author:Ning Xu, Brian Price, Scott Cohen, Jimei Yang, Thomas Huang category:cs.CV  published:2017-07-02 summary:Most previous bounding-box-based segmentation methods assume the bounding box tightly covers the object of interest. However it is common that a rectangle input could be too large or too small. In this paper, we propose a novel segmentation approach that uses a rectangle as a soft constraint by transforming it into an Euclidean distance map. A convolutional encoder-decoder network is trained end-to-end by concatenating images with these distance maps as inputs and predicting the object masks as outputs. Our approach gets accurate segmentation results given sloppy rectangles while being general for both interactive segmentation and instance segmentation. We show our network extends to curve-based input without retraining. We further apply our network to instance-level semantic segmentation and resolve any overlap using a conditional random field. Experiments on benchmark datasets demonstrate the effectiveness of the proposed approaches. version:2
arxiv-1707-04596 | DocTag2Vec: An Embedding Based Multi-label Learning Approach for Document Tagging | http://arxiv.org/abs/1707.04596 | id:1707.04596 author:Sheng Chen, Akshay Soni, Aasish Pappu, Yashar Mehdad category:cs.CL cs.IR  published:2017-07-14 summary:Tagging news articles or blog posts with relevant tags from a collection of predefined ones is coined as document tagging in this work. Accurate tagging of articles can benefit several downstream applications such as recommendation and search. In this work, we propose a novel yet simple approach called DocTag2Vec to accomplish this task. We substantially extend Word2Vec and Doc2Vec---two popular models for learning distributed representation of words and documents. In DocTag2Vec, we simultaneously learn the representation of words, documents, and tags in a joint vector space during training, and employ the simple $k$-nearest neighbor search to predict tags for unseen documents. In contrast to previous multi-label learning methods, DocTag2Vec directly deals with raw text instead of provided feature vector, and in addition, enjoys advantages like the learning of tag representation, and the ability of handling newly created tags. To demonstrate the effectiveness of our approach, we conduct experiments on several datasets and show promising results against state-of-the-art methods. version:1
arxiv-1707-04578 | An Efficient Approach to Communication-aware Path Planning for Long-range Surveillance Missions undertaken by UAVs | http://arxiv.org/abs/1707.04578 | id:1707.04578 author:Hrishikesh Sharma, Tom Sebastian category:cs.RO  published:2017-07-14 summary:While using drones for remote surveillance missions, it is mandatory to do path planning of the vehicle since these are pilot-less vehicles. Path planning, whether offline or online, entails setting up the path as a sequence of locations in the 3D Euclidean space, whose coordinates happen to be latitude, longitude and altitude. For the specific application of remote surveillance of long linear infrastructures in non-urban terrain, the continuous 3D-ESP problem practically entails two important scalar costs. The first scalar cost is the distance traveled along the planned path. Since drones are battery operated, hence it is needed that the path length between fixed start and goal locations of a mission should be minimal at all costs. The other scalar cost is the cost of transmitting the acquired video during the mission of remote surveillance, via a camera mounted in the drone's belly. Because of the length of surveillance target which is long linear infrastructure, the amount of video generated is very high and cannot be generally stored in its entirety, on board. If the connectivity is poor along certain segments of a naive path, to boost video transmission rate, the transmission power of the signal is kept high, which in turn dissipates more battery energy. Hence a path is desired that simultaneously also betters what is known as communication cost. These two costs trade-off, and hence Pareto optimization is needed for this 3D bi-objective Euclidean shortest path problem. In this report, we study the mono-objective offline path planning problem, based on the distance cost, while posing the communication cost as an upper-bounded constraint. The bi-objective path planning solution is sketched out towards the end. version:1
arxiv-1707-03237 | Generalised Dice overlap as a deep learning loss function for highly unbalanced segmentations | http://arxiv.org/abs/1707.03237 | id:1707.03237 author:Carole H Sudre, Wenqi Li, Tom Vercauteren, Sébastien Ourselin, M. Jorge Cardoso category:cs.CV  published:2017-07-11 summary:Deep-learning has proved in recent years to be a powerful tool for image analysis and is now widely used to segment both 2D and 3D medical images. Deep-learning segmentation frameworks rely not only on the choice of network architecture but also on the choice of loss function. When the segmentation process targets rare observations, a severe class imbalance is likely to occur between candidate labels, thus resulting in sub-optimal performance. In order to mitigate this issue, strategies such as the weighted cross-entropy function, the sensitivity function or the Dice loss function, have been proposed. In this work, we investigate the behavior of these loss functions and their sensitivity to learning rate tuning in the presence of different rates of label imbalance across 2D and 3D segmentation tasks. We also propose to use the class re-balancing properties of the Generalized Dice overlap, a known metric for segmentation assessment, as a robust and accurate deep-learning loss function for unbalanced tasks. version:3
arxiv-1706-04148 | Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks | http://arxiv.org/abs/1706.04148 | id:1706.04148 author:Massimo Quadrana, Alexandros Karatzoglou, Balázs Hidasi, Paolo Cremonesi category:cs.LG cs.HC cs.IR  published:2017-06-13 summary:Session-based recommendations are highly relevant in many modern on-line services (e.g. e-commerce, video streaming) and recommendation settings. Recently, Recurrent Neural Networks have been shown to perform very well in session-based settings. While in many session-based recommendation domains user identifiers are hard to come by, there are also domains in which user profiles are readily available. We propose a seamless way to personalize RNN models with cross-session information transfer and devise a Hierarchical RNN model that relays end evolves latent hidden states of the RNNs across user sessions. Results on two industry datasets show large improvements over the session-only RNNs. version:4
arxiv-1707-01747 | Verifying Strong Eventual Consistency in Distributed Systems | http://arxiv.org/abs/1707.01747 | id:1707.01747 author:Victor B. F. Gomes, Martin Kleppmann, Dominic P. Mulligan, Alastair R. Beresford category:cs.DC  published:2017-07-06 summary:Data replication is used in distributed systems to maintain up-to-date copies of shared data across multiple computers in a network. However, despite decades of research, algorithms for achieving consistency in replicated systems are still poorly understood. Indeed, many published algorithms have later been shown to be incorrect, even some that were accompanied by supposed mechanised proofs of correctness. In this work, we focus on the correctness of Conflict-free Replicated Data Types (CRDTs), a class of algorithm that provides strong eventual consistency guarantees for replicated data. We develop a modular and reusable framework in the Isabelle/HOL interactive proof assistant for verifying the correctness of CRDT algorithms. We avoid correctness issues that have dogged previous mechanised proofs in this area by including a network model in our formalisation, and proving that our theorems hold in all possible network behaviours. Our axiomatic network model is a standard abstraction that accurately reflects the behaviour of real-world computer networks. Moreover, we identify an abstract convergence theorem, a property of order relations, which provides a formal definition of strong eventual consistency. We then obtain the first machine-checked correctness theorems for three concrete CRDTs: the Replicated Growable Array, the Observed-Remove Set, and an Increment-Decrement Counter. We find that our framework is highly reusable, developing proofs of correctness for the latter two CRDTs in a few hours and with relatively little CRDT-specific code. version:2
arxiv-1707-04555 | Temporal Modeling Approaches for Large-scale Youtube-8M Video Understanding | http://arxiv.org/abs/1707.04555 | id:1707.04555 author:Fu Li, Chuang Gan, Xiao Liu, Yunlong Bian, Xiang Long, Yandong Li, Zhichao Li, Jie Zhou, Shilei Wen category:cs.CV  published:2017-07-14 summary:This paper describes our solution for the video recognition task of the Google Cloud and YouTube-8M Video Understanding Challenge that ranked the 3rd place. Because the challenge provides pre-extracted visual and audio features instead of the raw videos, we mainly investigate various temporal modeling approaches to aggregate the frame-level features for multi-label video recognition. Our system contains three major components: two-stream sequence model, fast-forward sequence model and temporal residual neural networks. Experiment results on the challenging Youtube-8M dataset demonstrate that our proposed temporal modeling approaches can significantly improve existing temporal modeling approaches in the large-scale video recognition tasks. To be noted, our fast-forward LSTM with a depth of 7 layers achieves 82.75% in term of GAP@20 on the Kaggle Public test set. version:1
arxiv-1707-04550 | CUNI System for the WMT17 Multimodal Translation Task | http://arxiv.org/abs/1707.04550 | id:1707.04550 author:Jindřich Helcl, Jindřich Libovický category:cs.CL cs.NE I.2.7  published:2017-07-14 summary:In this paper, we describe our submissions to the WMT17 Multimodal Translation Task. For Task 1 (multimodal translation), our best scoring system is a purely textual neural translation of the source image caption to the target language. The main feature of the system is the use of additional data that was acquired by selecting similar sentences from parallel corpora and by data synthesis with back-translation. For Task 2 (cross-lingual image captioning), our best submitted system generates an English caption which is then translated by the best system used in Task 1. We also present negative results, which are based on ideas that we believe have potential of making improvements, but did not prove to be useful in our particular setup. version:1
arxiv-1705-09970 | Probabilistic Program Abstractions | http://arxiv.org/abs/1705.09970 | id:1705.09970 author:Steven Holtzen, Todd Millstein, Guy Van den Broeck category:cs.AI  published:2017-05-28 summary:Abstraction is a fundamental tool for reasoning about complex systems. Program abstraction has been utilized to great effect for analyzing deterministic programs. At the heart of program abstraction is the relationship between a concrete program, which is difficult to analyze, and an abstract program, which is more tractable. Program abstractions, however, are typically not probabilistic. We generalize non-deterministic program abstractions to probabilistic program abstractions by explicitly quantifying the non-deterministic choices. Our framework upgrades key definitions and properties of abstractions to the probabilistic context. We also discuss preliminary ideas for performing inference on probabilistic abstractions and general probabilistic programs. version:2
arxiv-1707-04546 | Linguistic Markers of Influence in Informal Interactions | http://arxiv.org/abs/1707.04546 | id:1707.04546 author:Shrimai Prabhumoye, Samridhi Choudhary, Evangelia Spiliopoulou, Christopher Bogart, Carolyn Penstein Rose, Alan W Black category:cs.CL cs.SI  published:2017-07-14 summary:There has been a long standing interest in understanding `Social Influence' both in Social Sciences and in Computational Linguistics. In this paper, we present a novel approach to study and measure interpersonal influence in daily interactions. Motivated by the basic principles of influence, we attempt to identify indicative linguistic features of the posts in an online knitting community. We present the scheme used to operationalize and label the posts with indicator features. Experiments with the identified features show an improvement in the classification accuracy of influence by 3.15%. Our results illustrate the important correlation between the characteristics of the language and its potential to influence others. version:1
arxiv-1707-04540 | Autonomous Racing with AutoRally Vehicles and Differential Games | http://arxiv.org/abs/1707.04540 | id:1707.04540 author:Grady Williams, Brian Goldfain, Paul Drews, James M. Rehg, Evangelos A. Theodorou category:cs.RO  published:2017-07-14 summary:Safe autonomous vehicles must be able to predict and react to the drivers around them. Previous control methods rely heavily on pre-computation and are unable to react to dynamic events as they unfold in real-time. In this paper, we extend Model Predictive Path Integral Control (MPPI) using differential game theory and introduce Best-Response MPPI (BR-MPPI) for real-time multi-vehicle interactions. Experimental results are presented using two AutoRally platforms in a racing format with BR-MPPI competing against a skilled human driver at the Georgia Tech Autonomous Racing Facility. version:1
arxiv-1707-04538 | Cross-genre Document Retrieval: Matching between Conversational and Formal Writings | http://arxiv.org/abs/1707.04538 | id:1707.04538 author:Tomasz Jurczyk, Jinho D. Choi category:cs.CL  published:2017-07-14 summary:This paper challenges a cross-genre document retrieval task, where the queries are in formal writing and the target documents are in conversational writing. In this task, a query, is a sentence extracted from either a summary or a plot of an episode in a TV show, and the target document consists of transcripts from the corresponding episode. To establish a strong baseline, we employ the current state-of-the-art search engine to perform document retrieval on the dataset collected for this work. We then introduce a structure reranking approach to improve the initial ranking by utilizing syntactic and semantic structures generated by NLP tools. Our evaluation shows an improvement of more than 4% when the structure reranking is applied, which is very promising. version:1
arxiv-1706-09308 | A New Urban Objects Detection Framework Using Weakly Annotated Sets | http://arxiv.org/abs/1706.09308 | id:1706.09308 author:Eric Keiji, Gabriel Ferreira, Claudio Silva, Roberto M. Cesar Jr category:cs.CV  published:2017-06-28 summary:Urban informatics explore data science methods to address different urban issues intensively based on data. The large variety and quantity of data available should be explored but this brings important challenges. For instance, although there are powerful computer vision methods that may be explored, they may require large annotated datasets. In this work we propose a novel approach to automatically creating an object recognition system with minimal manual annotation. The basic idea behind the method is to use large input datasets using available online cameras on large cities. A off-the-shelf weak classifier is used to detect an initial set of urban elements of interest (e.g. cars, pedestrians, bikes, etc.). Such initial dataset undergoes a quality control procedure and it is subsequently used to fine tune a strong classifier. Quality control and comparative performance assessment are used as part of the pipeline. We evaluate the method for detecting cars based on monitoring cameras. Experimental results using real data show that despite losing generality, the final detector provides better detection rates tailored to the selected cameras. The programmed robot gathered 770 video hours from 24 online city cameras (\~300GB), which has been fed to the proposed system. Our approach has shown that the method nearly doubled the recall (93\%) with respect to state-of-the-art methods using off-the-shelf algorithms. version:2
arxiv-1705-06173 | Self-stabilising Byzantine Clock Synchronisation is Almost as Easy as Consensus | http://arxiv.org/abs/1705.06173 | id:1705.06173 author:Christoph Lenzen, Joel Rybicki category:cs.DC  published:2017-05-17 summary:We give fault-tolerant algorithms for establishing synchrony in distributed systems in which each of the $n$ nodes has its own clock. Our algorithms operate in a very strong fault model: we require self-stabilisation, i.e., the initial state of the system may be arbitrary, and there can be up to $f<n/3$ ongoing Byzantine faults, i.e., nodes that deviate from the protocol in an arbitrary manner. Furthermore, we assume that the local clocks of the nodes may progress at different speeds (clock drift) and communication has bounded delay. In this model, we study the pulse synchronisation problem, where the task is to guarantee that eventually all correct nodes generate well-separated local pulse events (i.e., unlabelled logical clock ticks) in a synchronised manner. Compared to prior work, we achieve exponential improvements in stabilisation time and the number of communicated bits, and give the first sublinear-time algorithm for the problem: - In the deterministic setting, the state-of-the-art solutions stabilise in time $\Theta(f)$ and have each node broadcast $\Theta(f \log f)$ bits per time unit. We exponentially reduce the number of bits broadcasted per time unit to $\Theta(\log f)$ while retaining the same stabilisation time. - In the randomised setting, the state-of-the-art solutions stabilise in time $\Theta(f)$ and have each node broadcast $O(1)$ bits per time unit. We exponentially reduce the stabilisation time to $\log^{O(1)} f$ while each node broadcasts $\log^{O(1)} f$ bits per time unit. These results are obtained by means of a recursive approach reducing the above task of self-stabilising pulse synchronisation in the bounded-delay model to non-self-stabilising binary consensus in the synchronous model. In general, our approach introduces at most logarithmic overheads in terms of stabilisation time and broadcasted bits over the underlying consensus routine. version:2
arxiv-1707-04499 | LIUM Machine Translation Systems for WMT17 News Translation Task | http://arxiv.org/abs/1707.04499 | id:1707.04499 author:Mercedes García-Martínez, Ozan Caglayan, Walid Aransa, Adrien Bardet, Fethi Bougares, Loïc Barrault category:cs.CL  published:2017-07-14 summary:This paper describes LIUM submissions to WMT17 News Translation Task for English-German, English-Turkish, English-Czech and English-Latvian language pairs. We train BPE-based attentive Neural Machine Translation systems with and without factored outputs using the open source nmtpy framework. Competitive scores were obtained by ensembling various systems and exploiting the availability of target monolingual corpora for back-translation. The impact of back-translation quantity and quality is also analyzed for English-Turkish where our post-deadline submission surpassed the best entry by +1.6 BLEU. version:1
arxiv-1707-04489 | Freeway Merging in Congested Traffic based on Multipolicy Decision Making with Passive Actor Critic | http://arxiv.org/abs/1707.04489 | id:1707.04489 author:Tomoki Nishi, Prashant Doshi, Danil Prokhorov category:cs.AI cs.RO  published:2017-07-14 summary:Freeway merging in congested traffic is a significant challenge toward fully automated driving. Merging vehicles need to decide not only how to merge into a spot, but also where to merge. We present a method for the freeway merging based on multi-policy decision making with a reinforcement learning method called {\em passive actor-critic} (pAC), which learns with less knowledge of the system and without active exploration. The method selects a merging spot candidate by using the state value learned with pAC. We evaluate our method using real traffic data. Our experiments show that pAC achieves 92\% success rate to merge into a freeway, which is comparable to human decision making. version:1
arxiv-1707-04487 | Guiding InfoGAN with Semi-Supervision | http://arxiv.org/abs/1707.04487 | id:1707.04487 author:Adrian Spurr, Emre Aksan, Otmar Hilliges category:cs.CV cs.LG  published:2017-07-14 summary:In this paper we propose a new semi-supervised GAN architecture (ss-InfoGAN) for image synthesis that leverages information from few labels (as little as 0.22%, max. 10% of the dataset) to learn semantically meaningful and controllable data representations where latent variables correspond to label categories. The architecture builds on Information Maximizing Generative Adversarial Networks (InfoGAN) and is shown to learn both continuous and categorical codes and achieves higher quality of synthetic samples compared to fully unsupervised settings. Furthermore, we show that using small amounts of labeled data speeds-up training convergence. The architecture maintains the ability to disentangle latent variables for which no labels are available. Finally, we contribute an information-theoretic reasoning on how introducing semi-supervision increases mutual information between synthetic and real data. version:1
arxiv-1707-04481 | LIUM-CVC Submissions for WMT17 Multimodal Translation Task | http://arxiv.org/abs/1707.04481 | id:1707.04481 author:Ozan Caglayan, Walid Aransa, Adrien Bardet, Mercedes García-Martínez, Fethi Bougares, Loïc Barrault, Marc Masana, Luis Herranz, Joost van de Weijer category:cs.CL  published:2017-07-14 summary:This paper describes the monomodal and multimodal Neural Machine Translation systems developed by LIUM and CVC for WMT17 Shared Task on Multimodal Translation. We mainly explored two multimodal architectures where either global visual features or convolutional feature maps are integrated in order to benefit from visual context. Our final systems ranked first for both En-De and En-Fr language pairs according to the automatic evaluation metrics METEOR and BLEU. version:1
arxiv-1707-04588 | GLSR-VAE: Geodesic Latent Space Regularization for Variational AutoEncoder Architectures | http://arxiv.org/abs/1707.04588 | id:1707.04588 author:Gaëtan Hadjeres, Frank Nielsen, François Pachet category:cs.LG cs.AI stat.ML  published:2017-07-14 summary:VAEs (Variational AutoEncoders) have proved to be powerful in the context of density modeling and have been used in a variety of contexts for creative purposes. In many settings, the data we model possesses continuous attributes that we would like to take into account at generation time. We propose in this paper GLSR-VAE, a Geodesic Latent Space Regularization for the Variational AutoEncoder architecture and its generalizations which allows a fine control on the embedding of the data into the latent space. When augmenting the VAE loss with this regularization, changes in the learned latent space reflects changes of the attributes of the data. This deeper understanding of the VAE latent space structure offers the possibility to modulate the attributes of the generated data in a continuous way. We demonstrate its efficiency on a monophonic music generation task where we manage to generate variations of discrete sequences in an intended and playful way. version:1
arxiv-1707-03903 | Negative Sampling Improves Hypernymy Extraction Based on Projection Learning | http://arxiv.org/abs/1707.03903 | id:1707.03903 author:Dmitry Ustalov, Nikolay Arefyev, Chris Biemann, Alexander Panchenko category:cs.CL I.2.6; I.5.3; I.2.4  published:2017-07-12 summary:We present a new approach to extraction of hypernyms based on projection learning and word embeddings. In contrast to classification-based approaches, projection-based methods require no candidate hyponym-hypernym pairs. While it is natural to use both positive and negative training examples in supervised relation extraction, the impact of negative examples on hypernym prediction was not studied so far. In this paper, we show that explicit negative examples used for regularization of the model significantly improve performance compared to the state-of-the-art approach of Fu et al. (2014) on three datasets from different languages. version:2
arxiv-1707-04449 | Optimal Asynchronous Rendezvous for Mobile Robots with Lights | http://arxiv.org/abs/1707.04449 | id:1707.04449 author:Takashi Okumura, Koichi Wada, Yoshiaki Katayama category:cs.DC  published:2017-07-14 summary:We study a Rendezvous problem for 2 autonomous mobile robots in asynchronous settings with persistent memory called light. It is well known that Rendezvous is impossible when robots have no lights in basic common models, even if the system is semi-synchronous. On the other hand, Rendezvous is possible if robots have lights with a constant number of colors in several types lights. In asynchronous settings, Rendezvous can be solved by robots with 4 colors of lights in non-rigid movement, if robots can use not only own light but also other robot's light (full-light), where non-rigid movement means robots may be stopped before reaching the computed destination but can move a minimum distance \delta > 0 and rigid movement means robots can reach the computed destination. In semi-synchronous settings, Rendezvous can be solved with 2 colors of full-lights in non-rigid movement. In this paper, we show that in asynchronous settings, Rendezvous can be solved with 2 colors of full-lights in rigid movement and in non-rigid movement if robots know the value of the minimum distance \delta. We also show that Rendezvous can be solved with 2 colors of full-lights in general non-rigid movement if we consider some reasonable restricted class of asynchronous settings. version:1
arxiv-1707-09864 | Generalizing the Convolution Operator in Convolutional Neural Networks | http://arxiv.org/abs/1707.09864 | id:1707.09864 author:Kamaledin Ghiasi-Shirazi category:cs.CV  published:2017-07-14 summary:Convolutional neural networks have become a main tool for solving many machine vision and machine learning problems. A major element of these networks is the convolution operator which essentially computes the inner product between a weight vector and the vectorized image patches extracted by sliding a window in the image planes of the previous layer. In this paper, we propose two classes of surrogate functions for the inner product operation inherent in the convolution operator and so attain two generalizations of the convolution operator. The first one is the class of positive definite kernel functions where their application is justified by the kernel trick. The second one is the class of similarity measures defined based on a distance function. We justify this by tracing back to the basic idea behind the neocognitron which is the ancestor of CNNs. Both methods are then further generalized by allowing a monotonically increasing function to be applied subsequently. Like any trainable parameter in a neural network, the template pattern and the parameters of the kernel/distance function are trained with the back-propagation algorithm. As an aside, we use the proposed framework to justify the use of sine activation function in CNNs. Our experiments on the MNIST dataset show that the performance of ordinary CNNs can be achieved by generalized CNNs based on weighted L1/L2 distances, proving the applicability of the proposed generalization of the convolutional neural networks. version:1
arxiv-1707-02747 | Robust Imitation of Diverse Behaviors | http://arxiv.org/abs/1707.02747 | id:1707.02747 author:Ziyu Wang, Josh Merel, Scott Reed, Greg Wayne, Nando de Freitas, Nicolas Heess category:cs.LG  published:2017-07-10 summary:Deep generative models have recently shown great promise in imitation learning for motor control. Given enough data, even supervised approaches can do one-shot imitation learning; however, they are vulnerable to cascading failures when the agent trajectory diverges from the demonstrations. Compared to purely supervised methods, Generative Adversarial Imitation Learning (GAIL) can learn more robust controllers from fewer demonstrations, but is inherently mode-seeking and more difficult to train. In this paper, we show how to combine the favourable aspects of these two approaches. The base of our model is a new type of variational autoencoder on demonstration trajectories that learns semantic policy embeddings. We show that these embeddings can be learned on a 9 DoF Jaco robot arm in reaching tasks, and then smoothly interpolated with a resulting smooth interpolation of reaching behavior. Leveraging these policy representations, we develop a new version of GAIL that (1) is much more robust than the purely-supervised controller, especially with few demonstrations, and (2) avoids mode collapse, capturing many diverse behaviors when GAIL on its own does not. We demonstrate our approach on learning diverse gaits from demonstration on a 2D biped and a 62 DoF 3D humanoid in the MuJoCo physics environment. version:2
arxiv-1707-05165 | A General-Purpose Implementation of Conceptual Spaces | http://arxiv.org/abs/1707.05165 | id:1707.05165 author:Lucas Bechberger, Kai-Uwe Kühnberger category:cs.AI  published:2017-07-14 summary:The highly influential framework of conceptual spaces provides a geometric way of representing knowledge. Instances are represented by points and concepts are represented by regions in a high-dimensional space. Based on our recent formalization, we present a general-purpose implementation of the conceptual spaces framework that is not only capable of representing concepts with inter-domain correlations, but that also offers a variety of operations on these concepts. version:1
arxiv-1707-09858 | Spatially variant PSF modeling in confocal macroscopy | http://arxiv.org/abs/1707.09858 | id:1707.09858 author:Anna Jezierska, Hugues Talbot, Jean-Christophe Pesquet, Gilbert Engler category:cs.CV  published:2017-07-14 summary:Point spread function (PSF) plays an essential role in image reconstruction. In the context of confocal microscopy, optical performance degrades towards the edge of the field of view as astigmatism, coma and vignetting. Thus, one should expect the related artifacts to be even stronger in macroscopy, where the field of view is much larger. The field aberrations in macroscopy fluorescence imaging system was observed to be symmetrical and to increase with the distance from the center of the field of view. In this paper we propose an experiment and an optimization method for assessing the center of the field of view. The obtained results constitute a step towards reducing the number of parameters in macroscopy PSF model. version:1
arxiv-1707-09862 | Iterative Manifold Embedding Layer Learned by Incomplete Data for Large-scale Image Retrieval | http://arxiv.org/abs/1707.09862 | id:1707.09862 author:Jian Xu, Chunheng Wang, Chengzuo Qi, Cunzhao Shi, Baihua Xiao category:cs.CV  published:2017-07-14 summary:Existing manifold learning methods are not appropriate for image retrieval task, because most of them are unable to process query image and they have much additional computational cost especially for large scale database. Therefore, we propose the iterative manifold embedding (IME) layer, of which the weights are learned off-line by unsupervised strategy, to explore the intrinsic manifolds by incomplete data. On the large scale database that contains 27000 images, IME layer is more than 120 times faster than other manifold learning methods to embed the original representations at query time. We embed the original descriptors of database images which lie on manifold in a high dimensional space into manifold-based representations iteratively to generate the IME representations in off-line learning stage. According to the original descriptors and the IME representations of database images, we estimate the weights of IME layer by ridge regression. In on-line retrieval stage, we employ the IME layer to map the original representation of query image with ignorable time cost (2 milliseconds). We experiment on five public standard datasets for image retrieval. The proposed IME layer significantly outperforms related dimension reduction methods and manifold learning methods. Without post-processing, Our IME layer achieves a boost in performance of state-of-the-art image retrieval methods with post-processing on most datasets, and needs less computational cost. version:1
arxiv-1707-04412 | Evaluating Semantic Parsing against a Simple Web-based Question Answering Model | http://arxiv.org/abs/1707.04412 | id:1707.04412 author:Alon Talmor, Mor Geva, Jonathan Berant category:cs.CL  published:2017-07-14 summary:Semantic parsing shines at analyzing complex natural language that involves composition and computation over multiple pieces of evidence. However, datasets for semantic parsing contain many factoid questions that can be answered from a single web document. In this paper, we propose to evaluate semantic parsing-based question answering models by comparing them to a question answering baseline that queries the web and extracts the answer only from web snippets, without access to the target knowledge-base. We investigate this approach on COMPLEXQUESTIONS, a dataset designed to focus on compositional language, and find that our model obtains reasonable performance (35 F1 compared to 41 F1 of state-of-the-art). We find in our analysis that our model performs well on complex questions involving conjunctions, but struggles on questions that involve relation composition and superlatives. version:1
arxiv-1707-04408 | Developing a concept-level knowledge base for sentiment analysis in Singlish | http://arxiv.org/abs/1707.04408 | id:1707.04408 author:Rajiv Bajpai, Soujanya Poria, Danyun Ho, Erik Cambria category:cs.CL  published:2017-07-14 summary:In this paper, we present Singlish sentiment lexicon, a concept-level knowledge base for sentiment analysis that associates multiword expressions to a set of emotion labels and a polarity value. Unlike many other sentiment analysis resources, this lexicon is not built by manually labeling pieces of knowledge coming from general NLP resources such as WordNet or DBPedia. Instead, it is automatically constructed by applying graph-mining and multi-dimensional scaling techniques on the affective common-sense knowledge collected from three different sources. This knowledge is represented redundantly at three levels: semantic network, matrix, and vector space. Subsequently, the concepts are labeled by emotions and polarity through the ensemble application of spreading activation, neural networks and an emotion categorization model. version:1
arxiv-1705-11046 | Implicit Consensus: Blockchain with Unbounded Throughput | http://arxiv.org/abs/1705.11046 | id:1705.11046 author:Zhijie Ren, Kelong Cong, Johan Pouwelse, Zekeriya Erkin category:cs.DC C.2.4  published:2017-05-31 summary:Recently, the blockchain technique was put in the spotlight as it introduced a systematic approach for multiple parties to reach consensus without needing trust. However, the application of this technique in practice is severely restricted due to its limitations in throughput. In this paper, we propose a novel consensus model, namely the implicit consensus, with a distinctive blockchain-based distributed ledger in which each node holds its individual blockchain. In our system, the consensus is not on the transactions, but on a special type of blocks called Check Points that are used to validate individual transactions. Our system exploits the ideas of self-interest and spontaneous sharding and achieves unbounded throughput with the transaction reliability that equivalent to traditional Byzantine fault tolerance schemes. version:3
arxiv-1707-04406 | Inner-Scene Similarities as a Contextual Cue for Object Detection | http://arxiv.org/abs/1707.04406 | id:1707.04406 author:Noa Arbel, Tamar Avraham, Michael Lindenbaum category:cs.CV  published:2017-07-14 summary:Using image context is an effective approach for improving object detection. Previously proposed methods used contextual cues that rely on semantic or spatial information. In this work, we explore a different kind of contextual information: inner-scene similarity. We present the CISS (Context by Inner Scene Similarity) algorithm, which is based on the observation that two visually similar sub-image patches are likely to share semantic identities, especially when both appear in the same image. CISS uses base-scores provided by a base detector and performs as a post-detection stage. For each candidate sub-image (denoted anchor), the CISS algorithm finds a few similar sub-images (denoted supporters), and, using them, calculates a new enhanced score for the anchor. This is done by utilizing the base-scores of the supporters and a pre-trained dependency model. The new scores are modeled as a linear function of the base scores of the anchor and the supporters and is estimated using a minimum mean square error optimization. This approach results in: (a) improved detection of partly occluded objects (when there are similar non-occluded objects in the scene), and (b) fewer false alarms (when the base detector mistakenly classifies a background patch as an object). This work relates to Duncan and Humphreys' "similarity theory," a psychophysical study. which suggested that the human visual system perceptually groups similar image regions and that the classification of one region is affected by the estimated identity of the other. Experimental results demonstrate the enhancement of a base detector's scores on the PASCAL VOC dataset. version:1
arxiv-1707-04402 | Lenient Multi-Agent Deep Reinforcement Learning | http://arxiv.org/abs/1707.04402 | id:1707.04402 author:Gregory Palmer, Karl Tuyls, Daan Bloembergen, Rahul Savani category:cs.MA cs.AI cs.LG  published:2017-07-14 summary:A significant amount of research in recent years has been dedicated towards single agent deep reinforcement learning. Much of the success of deep reinforcement learning can be attributed towards the use of experience replay memories within which state transitions are stored. Function approximation methods such as convolutional neural networks (referred to as deep Q-Networks, or DQNs, in this context) can subsequently be trained through sampling the stored transitions. However, considerations are required when using experience replay memories within multi-agent systems, as stored transitions can become outdated due to agents updating their respective policies in parallel [1]. In this work we apply leniency [2] to multi-agent deep reinforcement learning (MA-DRL), acting as a control mechanism to determine which state-transitions sampled are allowed to update the DQN. Our resulting Lenient-DQN (LDQN) is evaluated using variations of the Coordinated Multi-Agent Object Transportation Problem (CMOTP) outlined by Busoniu et al. [3]. The LDQN significantly outperforms the existing hysteretic DQN (HDQN) [4] within environments that yield stochastic rewards. Based on results from experiments conducted using vanilla and double Q-learning versions of the lenient and hysteretic algorithms, we advocate a hybrid approach where learners initially use vanilla Q-learning before transitioning to double Q-learners upon converging on a cooperative joint policy. version:1
arxiv-1707-03073 | TAPAS: Two-pass Approximate Adaptive Sampling for Softmax | http://arxiv.org/abs/1707.03073 | id:1707.03073 author:Yu Bai, Sally Goldman, Li Zhang category:cs.LG  published:2017-07-10 summary:TAPAS is a novel adaptive sampling method for the softmax model. It uses a two pass sampling strategy where the examples used to approximate the gradient of the partition function are first sampled according to a squashed population distribution and then resampled adaptively using the context and current model. We describe an efficient distributed implementation of TAPAS. We show, on both synthetic data and a large real dataset, that TAPAS has low computational overhead and works well for minimizing the rank loss for multi-class classification problems with a very large label space. version:2
arxiv-1701-05294 | Non-Iterative SLAM | http://arxiv.org/abs/1701.05294 | id:1701.05294 author:Chen Wang, Junsong Yuan, Lihua Xie category:cs.RO  published:2017-01-19 summary:The goal of this paper is to create a new framework for dense SLAM that is light enough for micro-robot systems based on depth camera and inertial sensor. Feature-based and direct methods are two mainstreams in visual SLAM. Both methods minimize photometric or reprojection error by iterative solutions, which are computationally expensive. To overcome this problem, we propose a non-iterative framework to reduce computational requirement. First, the attitude and heading reference system (AHRS) and axonometric projection are utilized to decouple the 6 Degree-of-Freedom (DoF) data, so that point clouds can be matched in independent spaces respectively. Second, based on single key-frame training, the matching process is carried out in frequency domain by Fourier transformation, which provides a closed-form non-iterative solution. In this manner, the time complexity is reduced to $\mathcal{O}(n \log{n})$, where $n$ is the number of matched points in each frame. To the best of our knowledge, this method is the first non-iterative and online trainable approach for data association in visual SLAM. Compared with the state-of-the-arts, it runs at a faster speed and obtains 3-D maps with higher resolution yet still with comparable accuracy. version:2
arxiv-1705-04924 | Gland Segmentation in Histopathology Images Using Random Forest Guided Boundary Construction | http://arxiv.org/abs/1705.04924 | id:1705.04924 author:Rohith AP, Salman S. Khan, Kumar Anubhav, Angshuman Paul category:cs.CV  published:2017-05-14 summary:Grading of cancer is important to know the extent of its spread. Prior to grading, segmentation of glandular structures is important. Manual segmentation is a time consuming process and is subject to observer bias. Hence, an automated process is required to segment the gland structures. These glands show a large variation in shape size and texture. This makes the task challenging as the glands cannot be segmented using mere morphological operations and conventional segmentation mechanisms. In this project we propose a method which detects the boundary epithelial cells of glands and then a novel approach is used to construct the complete gland boundary. The region enclosed within the boundary can then be obtained to get the segmented gland regions. version:2
arxiv-1707-04385 | f-GANs in an Information Geometric Nutshell | http://arxiv.org/abs/1707.04385 | id:1707.04385 author:Richard Nock, Zac Cranko, Aditya Krishna Menon, Lizhen Qu, Robert C. Williamson category:cs.LG stat.ML I.2.6; I.5.1  published:2017-07-14 summary:Nowozin \textit{et al} showed last year how to extend the GAN \textit{principle} to all $f$-divergences. The approach is elegant but falls short of a full description of the supervised game, and says little about the key player, the generator: for example, what does the generator actually converge to if solving the GAN game means convergence in some space of parameters? How does that provide hints on the generator's design and compare to the flourishing but almost exclusively experimental literature on the subject? In this paper, we unveil a broad class of distributions for which such convergence happens --- namely, deformed exponential families, a wide superset of exponential families --- and show tight connections with the three other key GAN parameters: loss, game and architecture. In particular, we show that current deep architectures are able to factorize a very large number of such densities using an especially compact design, hence displaying the power of deep architectures and their concinnity in the $f$-GAN game. This result holds given a sufficient condition on \textit{activation functions} --- which turns out to be satisfied by popular choices. The key to our results is a variational generalization of an old theorem that relates the KL divergence between regular exponential families and divergences between their natural parameters. We complete this picture with additional results and experimental insights on how these results may be used to ground further improvements of GAN architectures, via (i) a principled design of the activation functions in the generator and (ii) an explicit integration of proper composite losses' link function in the discriminator. version:1
arxiv-1707-03095 | Look Who's Talking: Bipartite Networks as Representations of a Topic Model of New Zealand Parliamentary Speeches | http://arxiv.org/abs/1707.03095 | id:1707.03095 author:Ben Curran, Kyle Higham, Elisenda Ortiz, Demival Vasques Filho category:cs.CL cs.DL cs.SI physics.soc-ph  published:2017-07-11 summary:Quantitative methods to measure the participation to parliamentary debate and discourse of elected Members of Parliament (MPs) and the parties they belong to are lacking. This is an exploratory study in which we propose the development of a new approach for a quantitative analysis of such participation. We utilize the New Zealand government's digital Hansard database to construct a topic model of parliamentary speeches consisting of nearly 40 million words in the period 2003-2016. A Latent Dirichlet Allocation topic model is implemented in order to reveal the thematic structure of our set of documents. This generative statistical model enables the detection of major themes or topics that are publicly discussed in the New Zealand parliament, as well as permitting their classification by MP. Information on topic proportions is subsequently analyzed using a combination of statistical methods. We observe patterns arising from time-series analysis of topic frequencies which can be related to specific social, economic and legislative events. We then construct a bipartite network representation, linking MPs to topics, for each of four parliamentary terms in this time frame. We build projected networks (onto the set of nodes represented by MPs) and proceed to the study of the dynamical changes of their topology, including community structure. By performing this longitudinal network analysis, we can observe the evolution of the New Zealand parliamentary topic network and its main parties in the period studied. version:3
arxiv-1707-04585 | The Reversible Residual Network: Backpropagation Without Storing Activations | http://arxiv.org/abs/1707.04585 | id:1707.04585 author:Aidan N. Gomez, Mengye Ren, Raquel Urtasun, Roger B. Grosse category:cs.CV cs.LG  published:2017-07-14 summary:Deep residual networks (ResNets) have significantly pushed forward the state-of-the-art on image classification, increasing in performance as networks grow both deeper and wider. However, memory consumption becomes a bottleneck, as one needs to store the activations in order to calculate gradients using backpropagation. We present the Reversible Residual Network (RevNet), a variant of ResNets where each layer's activations can be reconstructed exactly from the next layer's. Therefore, the activations for most layers need not be stored in memory during backpropagation. We demonstrate the effectiveness of RevNets on CIFAR-10, CIFAR-100, and ImageNet, establishing nearly identical classification accuracy to equally-sized ResNets, even though the activation storage requirements are independent of depth. version:1
arxiv-1707-00381 | Joint Pose and Principal Curvature Refinement Using Quadrics | http://arxiv.org/abs/1707.00381 | id:1707.00381 author:Andrew Spek, Tom Drummond category:cs.CV  published:2017-07-03 summary:In this paper we present a novel joint approach for optimising surface curvature and pose alignment. We present two implementations of this joint optimisation strategy, including a fast implementation that uses two frames and an offline multi-frame approach. We demonstrate an order of magnitude improvement in simulation over state of the art dense relative point-to-plane Iterative Closest Point (ICP) pose alignment using our dense joint frame-to-frame approach and show comparable pose drift to dense point-to-plane ICP bundle adjustment using low-cost depth sensors. Additionally our improved joint quadric based approach can be used to more accurately estimate surface curvature on noisy point clouds than previous approaches. version:2
arxiv-1707-04373 | Comparison of Multiple Features and Modeling Methods for Text-dependent Speaker Verification | http://arxiv.org/abs/1707.04373 | id:1707.04373 author:Yi Liu, Liang He, Yao Tian, Zhuzi Chen, Jia Liu, Michael T. Johnson category:cs.SD cs.AI  published:2017-07-14 summary:Text-dependent speaker verification is becoming popular in the speaker recognition society. However, the conventional i-vector framework which has been successful for speaker identification and other similar tasks works relatively poorly in this task. Researchers have proposed several new methods to improve performance, but it is still unclear that which model is the best choice, especially when the pass-phrases are prompted during enrollment and test. In this paper, we introduce four modeling methods and compare their performance on the newly published RedDots dataset. To further explore the influence of different frame alignments, Viterbi and forward-backward algorithms are both used in the HMM-based models. Several bottleneck features are also investigated. Our experiments show that, by explicitly modeling the lexical content, the HMM-based modeling achieves good results in the fixed-phrase condition. In the prompted-phrase condition, GMM-HMM and i-vector/HMM are not as successful. In both conditions, the forward-backward algorithm brings more benefits to the i-vector/HMM system. Additionally, we also find that even though bottleneck features perform well for text-independent speaker verification, they do not outperform MFCCs on the most challenging Imposter-Correct trials on RedDots. version:1
arxiv-1707-00385 | A Fast Method For Computing Principal Curvatures From Range Images | http://arxiv.org/abs/1707.00385 | id:1707.00385 author:Andrew Spek, Wai Ho Li, Tom Drummond category:cs.CV  published:2017-07-03 summary:Estimation of surface curvature from range data is important for a range of tasks in computer vision and robotics, object segmentation, object recognition and robotic grasping estimation. This work presents a fast method of robustly computing accurate metric principal curvature values from noisy point clouds which was implemented on GPU. In contrast to existing readily available solutions which first differentiate the surface to estimate surface normals and then differentiate these to obtain curvature, amplifying noise, our method iteratively fits parabolic quadric surface patches to the data. Additionally previous methods with a similar formulation use less robust techniques less applicable to a high noise sensor. We demonstrate that our method is fast and provides better curvature estimates than existing techniques. In particular we compare our method to several alternatives to demonstrate the improvement. version:2
arxiv-1707-04368 | Kernel Method for Detecting Higher Order Interactions in multi-view Data: An Application to Imaging, Genetics, and Epigenetics | http://arxiv.org/abs/1707.04368 | id:1707.04368 author:Md. Ashad Alam, Hui-Yi Lin, Vince Calhoun, Yu-Ping Wang category:stat.ML  published:2017-07-14 summary:In this study, we tested the interaction effect of multimodal datasets using a novel method called the kernel method for detecting higher order interactions among biologically relevant mulit-view data. Using a semiparametric method on a reproducing kernel Hilbert space (RKHS), we used a standard mixed-effects linear model and derived a score-based variance component statistic that tests for higher order interactions between multi-view data. The proposed method offers an intangible framework for the identification of higher order interaction effects (e.g., three way interaction) between genetics, brain imaging, and epigenetic data. Extensive numerical simulation studies were first conducted to evaluate the performance of this method. Finally, this method was evaluated using data from the Mind Clinical Imaging Consortium (MCIC) including single nucleotide polymorphism (SNP) data, functional magnetic resonance imaging (fMRI) scans, and deoxyribonucleic acid (DNA) methylation data, respectfully, in schizophrenia patients and healthy controls. We treated each gene-derived SNPs, region of interest (ROI) and gene-derived DNA methylation as a single testing unit, which are combined into triplets for evaluation. In addition, cardiovascular disease risk factors such as age, gender, and body mass index were assessed as covariates on hippocampal volume and compared between triplets. Our method identified $13$-triplets ($p$-values $\leq 0.001$) that included $6$ gene-derived SNPs, $10$ ROIs, and $6$ gene-derived DNA methylations that correlated with changes in hippocampal volume, suggesting that these triplets may be important in explaining schizophrenia-related neurodegeneration. With strong evidence ($p$-values $\leq 0.000001$), the triplet ({\bf MAGI2, CRBLCrus1.L, FBXO28}) has the potential to distinguish schizophrenia patients from the healthy control variations. version:1
arxiv-1705-05414 | Key-Value Retrieval Networks for Task-Oriented Dialogue | http://arxiv.org/abs/1705.05414 | id:1705.05414 author:Mihail Eric, Christopher D. Manning category:cs.CL  published:2017-05-15 summary:Neural task-oriented dialogue systems often struggle to smoothly interface with a knowledge base. In this work, we seek to address this problem by proposing a new neural dialogue agent that is able to effectively sustain grounded, multi-domain discourse through a novel key-value retrieval mechanism. The model is end-to-end differentiable and does not need to explicitly model dialogue state or belief trackers. We also release a new dataset of 3,031 dialogues that are grounded through underlying knowledge bases and span three distinct tasks in the in-car personal assistant space: calendar scheduling, weather information retrieval, and point-of-interest navigation. Our architecture is simultaneously trained on data from all domains and significantly outperforms a competitive rule-based system and other existing neural dialogue architectures on the provided domains according to both automatic and human evaluation metrics. version:2
arxiv-1707-04352 | Advances in Artificial Intelligence Require Progress Across all of Computer Science | http://arxiv.org/abs/1707.04352 | id:1707.04352 author:Gregory D. Hager, Randal Bryant, Eric Horvitz, Maja Mataric, Vasant Honavar category:cs.AI  published:2017-07-13 summary:Advances in Artificial Intelligence require progress across all of computer science. version:1
arxiv-1707-04347 | Weakly Submodular Maximization Beyond Cardinality Constraints: Does Randomization Help Greedy? | http://arxiv.org/abs/1707.04347 | id:1707.04347 author:Lin Chen, Moran Feldman, Amin Karbasi category:cs.DM cs.AI cs.DS cs.LG stat.ML  published:2017-07-13 summary:Submodular functions are a broad class of set functions, which naturally arise in diverse areas. Many algorithms have been suggested for the maximization of these functions. Unfortunately, once the function deviates from submodularity, the known algorithms may perform arbitrarily poorly. Amending this issue, by obtaining approximation results for set functions generalizing submodular functions, has been the focus of recent works. One such class, known as weakly submodular functions, has received a lot of attention. A key result proved by Das and Kempe (2011) showed that the approximation ratio of the greedy algorithm for weakly submodular maximization subject to a cardinality constraint degrades smoothly with the distance from submodularity. However, no results have been obtained for maximization subject to constraints beyond cardinality. In particular, it is not known whether the greedy algorithm achieves any non-trivial approximation ratio for such constraints. In this paper, we prove that a randomized version of the greedy algorithm (previously used by Buchbinder et al. (2014) for a different problem) achieves an approximation ratio of $(1 + 1/\gamma)^{-2}$ for the maximization of a weakly submodular function subject to a general matroid constraint, where $\gamma$ is a parameter measuring the distance of the function from submodularity. Moreover, we also experimentally compare the performance of this version of the greedy algorithm on real world problems against natural benchmarks, and show that the algorithm we study performs well also in practice. To the best of our knowledge, this is the first algorithm with a non-trivial approximation guarantee for maximizing a weakly submodular function subject to a constraint other than the simple cardinality constraint. In particular, it is the first algorithm with such a guarantee for the important and broad class of matroid constraints. version:1
arxiv-1707-04338 | Privacy-preserving Decentralized Optimization Based on ADMM | http://arxiv.org/abs/1707.04338 | id:1707.04338 author:Chunlei Zhang, Yongqiang Wang category:math.OC cs.DC  published:2017-07-13 summary:In this paper, we address the problem of privacy-preservation in decentralized optimization, where $N$ agents cooperatively minimize an objective function that is the sum of $N$ strongly convex functions private to these individual agents. In most existing decentralized optimization approaches, participating agents exchange and disclose estimates explicitly, which may not be desirable when the estimates contain sensitive information of individual agents. The problem is more acute when adversaries exist which try to steal information from other participating agents. To address this issue, we propose a privacy-preserving decentralized optimization approach based on ADMM and partially homomorphic cryptography. In contrast to differential privacy based approaches which use noise to cover sensitive information and are subject to a trade-off between privacy and accuracy, our approach can provide privacy without compromising the optimality of the solution. To our knowledge, this is the first time that cryptographic techniques are incorporated in a fully decentralized setting to enable privacy preservation in decentralized optimization in the absence of any third party or aggegator. To facilitate the incorporation of encryption in a fully decentralized manner, we also introduce a new ADMM which allows time-varying penalty matrices and rigorously prove its convergence. Numerical simulations confirm the effectiveness and low computational complexity of the proposed approach. version:1
arxiv-1704-04947 | Space-Optimal Majority in Population Protocols | http://arxiv.org/abs/1704.04947 | id:1704.04947 author:Dan Alistarh, James Aspnes, Rati Gelashvili category:cs.DC cs.DS  published:2017-04-17 summary:Population protocols are a model of distributed computing, in which $n$ agents with limited local state interact randomly, and cooperate to collectively compute global predicates. An extensive series of papers, across different communities, has examined the computability and complexity characteristics of this model. Majority, or consensus, is a central task, in which agents need to collectively reach a decision as to which one of two states $A$ or $B$ had a higher initial count. Two complexity metrics are important: the time that a protocol requires to stabilize to an output decision, and the state space size that each agent requires. It is known that majority requires $\Omega(\log \log n)$ states per agent to allow for poly-logarithmic time stabilization, and that $O(\log^2 n)$ states are sufficient. Thus, there is an exponential gap between the upper and lower bounds. We address this question. We provide a new lower bound of $\Omega(\log n)$ states for any protocol which stabilizes in $O( n^{1-c} )$ time, for any $c > 0$ constant. This result is conditional on basic monotonicity and output assumptions, satisfied by all known protocols. Technically, it represents a significant departure from previous lower bounds. Instead of relying on dense configurations, we introduce a new surgery technique to construct executions which contradict the correctness of algorithms that stabilize too fast. Subsequently, our lower bound applies to general initial configurations. We give an algorithm for majority which uses $O(\log n)$ states, and stabilizes in $O(\log^2 n)$ time. Central to the algorithm is a new leaderless phase clock, which allows nodes to synchronize in phases of $\Theta(n \log{n})$ consecutive interactions using $O(\log n)$ states per node. We also employ our phase clock to build a leader election algorithm with $O(\log n )$ states, which stabilizes in $O(\log^2 n)$ time. version:5
arxiv-1707-04327 | Human-Level Intelligence or Animal-Like Abilities? | http://arxiv.org/abs/1707.04327 | id:1707.04327 author:Adnan Darwiche category:cs.AI cs.CY cs.LG stat.ML  published:2017-07-13 summary:The vision systems of the eagle and the snake outperform everything that we can make in the laboratory, but snakes and eagles cannot build an eyeglass or a telescope or a microscope. (Judea Pearl) version:1
arxiv-1707-04324 | Tensor-Based Backpropagation in Neural Networks with Non-Sequential Input | http://arxiv.org/abs/1707.04324 | id:1707.04324 author:Hirsh R. Agarwal, Andrew Huang category:cs.LG 68T05 I.2.6  published:2017-07-13 summary:Neural networks have been able to achieve groundbreaking accuracy at tasks conventionally considered only doable by humans. Using stochastic gradient descent, optimization in many dimensions is made possible, albeit at a relatively high computational cost. By splitting training data into batches, networks can be distributed and trained vastly more efficiently and with minimal accuracy loss. We have explored the mathematics behind efficiently implementing tensor-based batch backpropagation algorithms. A common approach to batch training is iterating over batch items individually. Explicitly using tensor operations to backpropagate allows training to be performed non-linearly, increasing computational efficiency. version:1
arxiv-1707-04319 | Model compression as constrained optimization, with application to neural nets. Part II: quantization | http://arxiv.org/abs/1707.04319 | id:1707.04319 author:Miguel Á. Carreira-Perpiñán, Yerlan Idelbayev category:cs.LG cs.NE math.OC stat.ML  published:2017-07-13 summary:We consider the problem of deep neural net compression by quantization: given a large, reference net, we want to quantize its real-valued weights using a codebook with $K$ entries so that the training loss of the quantized net is minimal. The codebook can be optimally learned jointly with the net, or fixed, as for binarization or ternarization approaches. Previous work has quantized the weights of the reference net, or incorporated rounding operations in the backpropagation algorithm, but this has no guarantee of converging to a loss-optimal, quantized net. We describe a new approach based on the recently proposed framework of model compression as constrained optimization \citep{Carreir17a}. This results in a simple iterative "learning-compression" algorithm, which alternates a step that learns a net of continuous weights with a step that quantizes (or binarizes/ternarizes) the weights, and is guaranteed to converge to local optimum of the loss for quantized nets. We develop algorithms for an adaptive codebook or a (partially) fixed codebook. The latter includes binarization, ternarization, powers-of-two and other important particular cases. We show experimentally that we can achieve much higher compression rates than previous quantization work (even using just 1 bit per weight) with negligible loss degradation. version:1
arxiv-1707-04318 | Discriminative Optimization: Theory and Applications to Computer Vision Problems | http://arxiv.org/abs/1707.04318 | id:1707.04318 author:Jayakorn Vongkulbhisal, Fernando De la Torre, João P. Costeira category:cs.CV  published:2017-07-13 summary:Many computer vision problems are formulated as the optimization of a cost function. This approach faces two main challenges: (i) designing a cost function with a local optimum at an acceptable solution, and (ii) developing an efficient numerical method to search for one (or multiple) of these local optima. While designing such functions is feasible in the noiseless case, the stability and location of local optima are mostly unknown under noise, occlusion, or missing data. In practice, this can result in undesirable local optima or not having a local optimum in the expected place. On the other hand, numerical optimization algorithms in high-dimensional spaces are typically local and often rely on expensive first or second order information to guide the search. To overcome these limitations, this paper proposes Discriminative Optimization (DO), a method that learns search directions from data without the need of a cost function. Specifically, DO explicitly learns a sequence of updates in the search space that leads to stationary points that correspond to desired solutions. We provide a formal analysis of DO and illustrate its benefits in the problem of 3D point cloud registration, camera pose estimation, and image denoising. We show that DO performed comparably or outperformed state-of-the-art algorithms in terms of accuracy, robustness to perturbations, and computational efficiency. version:1
arxiv-1707-04314 | Bayesian Optimization for Probabilistic Programs | http://arxiv.org/abs/1707.04314 | id:1707.04314 author:Tom Rainforth, Tuan Anh Le, Jan-Willem van de Meent, Michael A. Osborne, Frank Wood category:stat.ML cs.AI cs.PL stat.CO  published:2017-07-13 summary:We present the first general purpose framework for marginal maximum a posteriori estimation of probabilistic program variables. By using a series of code transformations, the evidence of any probabilistic program, and therefore of any graphical model, can be optimized with respect to an arbitrary subset of its sampled variables. To carry out this optimization, we develop the first Bayesian optimization package to directly exploit the source code of its target, leading to innovations in problem-independent hyperpriors, unbounded optimization, and implicit constraint satisfaction; delivering significant performance improvements over prominent existing packages. We present applications of our method to a number of tasks including engineering design and parameter optimization. version:1
arxiv-1707-04300 | Coalescent-based species tree estimation: a stochastic Farris transform | http://arxiv.org/abs/1707.04300 | id:1707.04300 author:Gautam Dasarathy, Elchanan Mossel, Robert Nowak, Sebastien Roch category:cs.LG math.PR math.ST q-bio.PE stat.TH  published:2017-07-13 summary:The reconstruction of a species phylogeny from genomic data faces two significant hurdles: 1) the trees describing the evolution of each individual gene--i.e., the gene trees--may differ from the species phylogeny and 2) the molecular sequences corresponding to each gene often provide limited information about the gene trees themselves. In this paper we consider an approach to species tree reconstruction that addresses both these hurdles. Specifically, we propose an algorithm for phylogeny reconstruction under the multispecies coalescent model with a standard model of site substitution. The multispecies coalescent is commonly used to model gene tree discordance due to incomplete lineage sorting, a well-studied population-genetic effect. In previous work, an information-theoretic trade-off was derived in this context between the number of loci, $m$, needed for an accurate reconstruction and the length of the locus sequences, $k$. It was shown that to reconstruct an internal branch of length $f$, one needs $m$ to be of the order of $1/[f^{2} \sqrt{k}]$. That previous result was obtained under the molecular clock assumption, i.e., under the assumption that mutation rates (as well as population sizes) are constant across the species phylogeny. Here we generalize this result beyond the restrictive molecular clock assumption, and obtain a new reconstruction algorithm that has the same data requirement (up to log factors). Our main contribution is a novel reduction to the molecular clock case under the multispecies coalescent. As a corollary, we also obtain a new identifiability result of independent interest: for any species tree with $n \geq 3$ species, the rooted species tree can be identified from the distribution of its unrooted weighted gene trees even in the absence of a molecular clock. version:1
arxiv-1706-03741 | Deep reinforcement learning from human preferences | http://arxiv.org/abs/1706.03741 | id:1706.03741 author:Paul Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, Dario Amodei category:stat.ML  published:2017-06-12 summary:For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on less than one percent of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any that have been previously learned from human feedback. version:3
arxiv-1707-04298 | Strategic Coalitions with Perfect Recall | http://arxiv.org/abs/1707.04298 | id:1707.04298 author:Pavel Naumov, Jia Tao category:cs.AI cs.LO  published:2017-07-13 summary:The paper proposes a bimodal logic that describes an interplay between distributed knowledge modality and coalition know-how modality. Unlike other similar systems, the one proposed here assumes perfect recall by all agents. Perfect recall is captured in the system by a single axiom. The main technical results are the soundness and the completeness theorems for the proposed logical system. version:1
arxiv-1707-04291 | Predicting Abandonment in Online Coding Tutorials | http://arxiv.org/abs/1707.04291 | id:1707.04291 author:An Yan, Michael J. Lee, Andrew J. Ko category:cs.LG cs.AI cs.HC  published:2017-07-13 summary:Learners regularly abandon online coding tutorials when they get bored or frustrated, but there are few techniques for anticipating this abandonment to intervene. In this paper, we examine the feasibility of predicting abandonment with machine-learned classifiers. Using interaction logs from an online programming game, we extracted a collection of features that are potentially related to learner abandonment and engagement, then developed classifiers for each level. Across the first five levels of the game, our classifiers successfully predicted 61% to 76% of learners who did not complete the next level, achieving an average AUC of 0.68. In these classifiers, features negatively associated with abandonment included account activation and help-seeking behaviors, whereas features positively associated with abandonment included features indicating difficulty and disengagement. These findings highlight the feasibility of providing timely intervention to learners likely to quit. version:1
arxiv-1707-04282 | Polynomial Counting in Anonymous Dynamic Networks with Applications to Anonymous Dynamic Algebraic Computations | http://arxiv.org/abs/1707.04282 | id:1707.04282 author:Dariusz R. Kowalski, Miguel A. Mosteiro category:cs.DC cs.DS cs.NI 68W15  68W40  published:2017-07-13 summary:Starting with Michail, Chatzigiannakis, and Spirakis work, the problem of Counting the number of nodes in Anonymous Dynamic Networks has attracted a lot of attention. The problem is challenging because nodes are indistinguishable (they lack identifiers and execute the same program) and the topology may change arbitrarily from round to round of communication, as long as the network is connected in each round. The problem is central in distributed computing as the number of participants is frequently needed to make important decisions, such as termination, agreement, synchronization, and many others. A variety of algorithms built on top of mass-distribution techniques have been presented, analyzed, and also experimentally evaluated; some of them assumed additional knowledge of network characteristics, such as bounded degree or given upper bound on the network size. However, the question of whether Counting can be solved deterministically in sub-exponential time remained open. In this work, we answer this question positively by presenting Methodical Counting, which runs in polynomial time and requires no knowledge of network characteristics. Moreover, we also show how to extend Methodical Counting to compute the sum of input values and more complex functions without extra cost. Our analysis leverages previous work on random walks in evolving graphs, combined with carefully chosen alarms in the algorithm that control the process and its parameters. To the best of our knowledge, our Counting algorithm and its extensions to other algebraic and Boolean functions are the first that can be implemented in practice with worst-case guarantees. version:1
arxiv-1707-04277 | On (Anti)Conditional Independence in Dempster-Shafer Theory | http://arxiv.org/abs/1707.04277 | id:1707.04277 author:Mieczysław A. Kłopotek category:cs.AI  published:2017-07-13 summary:This paper verifies a result of {Shenoy:94} concerning graphoidal structure of Shenoy's notion of independence for Dempster-Shafer theory of belief functions. Shenoy proved that his notion of independence has graphoidal properties for positive normal valuations. The requirement of strict positive normal valuations as prerequisite for application of graphoidal properties excludes a wide class of DS belief functions. It excludes especially so-called probabilistic belief functions. It is demonstrated that the requirement of positiveness of valuation may be weakened in that it may be required that commonality function is non-zero for singleton sets instead, and the graphoidal properties for independence of belief function variables are then preserved. This means especially that probabilistic belief functions with all singleton sets as focal points possess graphoidal properties for independence. version:1
arxiv-1707-05147 | Comparative Study of Inference Methods for Bayesian Nonnegative Matrix Factorisation | http://arxiv.org/abs/1707.05147 | id:1707.05147 author:Thomas Brouwer, Jes Frellsen, Pietro Lió category:stat.ML cs.LG  published:2017-07-13 summary:In this paper, we study the trade-offs of different inference approaches for Bayesian matrix factorisation methods, which are commonly used for predicting missing values, and for finding patterns in the data. In particular, we consider Bayesian nonnegative variants of matrix factorisation and tri-factorisation, and compare non-probabilistic inference, Gibbs sampling, variational Bayesian inference, and a maximum-a-posteriori approach. The variational approach is new for the Bayesian nonnegative models. We compare their convergence, and robustness to noise and sparsity of the data, on both synthetic and real-world datasets. Furthermore, we extend the models with the Bayesian automatic relevance determination prior, allowing the models to perform automatic model selection, and demonstrate its efficiency. version:1
arxiv-1707-09839 | Superposition de calques monochromes d'opacités variables | http://arxiv.org/abs/1707.09839 | id:1707.09839 author:Alexandre Bali category:cs.GR cs.CV  published:2017-07-13 summary:For a monochrome layer $x$ of opacity $0\le o_x\le1 $ placed on another monochrome layer of opacity 1, the result given by the standard formula is $$\small\Pi\left({\bf C}_\varphi\right)=1+\sum_{n=1}^2\left(2-n-(-1)^no_{\chi(\varphi+1)}\right)\left(\chi(n+\varphi-1)-o_{\chi(n+\varphi-1)}\right),$$ the formula being of course explained in detail in this paper. We will eventually deduce a very simple theorem, generalize it and then see its validity with alternative formulas to this standard containing the same main properties here exposed. version:1
arxiv-1707-04584 | Fast Restricted Causal Inference | http://arxiv.org/abs/1707.04584 | id:1707.04584 author:Mieczysław A. Kłopotek category:cs.AI  published:2017-07-13 summary:Hidden variables are well known sources of disturbance when recovering belief networks from data based only on measurable variables. Hence models assuming existence of hidden variables are under development. This paper presents a new algorithm "accelerating" the known CI algorithm of Spirtes, Glymour and Scheines {Spirtes:93}. We prove that this algorithm does not produces (conditional) independencies not present in the data if statistical independence test is reliable. This result is to be considered as non-trivial since e.g. the same claim fails to be true for FCI algorithm, another "accelerator" of CI, developed in {Spirtes:93}. version:1
arxiv-1707-04272 | Cultivating DNN Diversity for Large Scale Video Labelling | http://arxiv.org/abs/1707.04272 | id:1707.04272 author:Mikel Bober-Irizar, Sameed Husain, Eng-Jon Ong, Miroslaw Bober category:cs.CV  published:2017-07-13 summary:We investigate factors controlling DNN diversity in the context of the Google Cloud and YouTube-8M Video Understanding Challenge. While it is well-known that ensemble methods improve prediction performance, and that combining accurate but diverse predictors helps, there is little knowledge on how to best promote & measure DNN diversity. We show that diversity can be cultivated by some unexpected means, such as model over-fitting or dropout variations. We also present details of our solution to the video understanding problem, which ranked #7 in the Kaggle competition (competing as the Yeti team). version:1
arxiv-1706-09789 | Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension | http://arxiv.org/abs/1706.09789 | id:1706.09789 author:David Golub, Po-Sen Huang, Xiaodong He, Li Deng category:cs.CL  published:2017-06-29 summary:We develop a technique for transfer learning in machine comprehension (MC) using a novel two-stage synthesis network (SynNet). Given a high-performing MC model in one domain, our technique aims to answer questions about documents in another domain, where we use no labeled data of question-answer pairs. Using the proposed SynNet with a pretrained model on the SQuAD dataset, we achieve an F1 measure of 46.6% on the challenging NewsQA dataset, approaching performance of in-domain models (F1 measure of 50.0%) and outperforming the out-of-domain baseline by 7.6%, without use of provided annotations. version:2
arxiv-1707-04244 | Lithium NLP: A System for Rich Information Extraction from Noisy User Generated Text on Social Media | http://arxiv.org/abs/1707.04244 | id:1707.04244 author:Preeti Bhargava, Nemanja Spasojevic, Guoning Hu category:cs.AI cs.CL cs.IR  published:2017-07-13 summary:In this paper, we describe the Lithium Natural Language Processing (NLP) system - a resource-constrained, high- throughput and language-agnostic system for information extraction from noisy user generated text on social media. Lithium NLP extracts a rich set of information including entities, topics, hashtags and sentiment from text. We discuss several real world applications of the system currently incorporated in Lithium products. We also compare our system with existing commercial and academic NLP systems in terms of performance, information extracted and languages supported. We show that Lithium NLP is at par with and in some cases, outperforms state- of-the-art commercial NLP systems. version:1
arxiv-1707-04242 | Neural Networks for Information Retrieval | http://arxiv.org/abs/1707.04242 | id:1707.04242 author:Tom Kenter, Alexey Borisov, Christophe Van Gysel, Mostafa Dehghani, Maarten de Rijke, Bhaskar Mitra category:cs.IR cs.AI cs.CL  published:2017-07-13 summary:Machine learning plays a role in many aspects of modern IR systems, and deep learning is applied in all of them. The fast pace of modern-day research has given rise to many different approaches for many different IR problems. The amount of information available can be overwhelming both for junior students and for experienced researchers looking for new research topics and directions. Additionally, it is interesting to see what key insights into IR problems the new technologies are able to give us. The aim of this full-day tutorial is to give a clear overview of current tried-and-trusted neural methods in IR and how they benefit IR research. It covers key architectures, as well as the most promising future directions. version:1
arxiv-1707-04236 | Improving Sparsity in Kernel Adaptive Filters Using a Unit-Norm Dictionary | http://arxiv.org/abs/1707.04236 | id:1707.04236 author:Felipe Tobar category:stat.ML cs.LG  published:2017-07-13 summary:Kernel adaptive filters, a class of adaptive nonlinear time-series models, are known by their ability to learn expressive autoregressive patterns from sequential data. However, for trivial monotonic signals, they struggle to perform accurate predictions and at the same time keep computational complexity within desired boundaries. This is because new observations are incorporated to the dictionary when they are far from what the algorithm has seen in the past. We propose a novel approach to kernel adaptive filtering that compares new observations against dictionary samples in terms of their unit-norm (normalised) versions, meaning that new observations that look like previous samples but have a different magnitude are not added to the dictionary. We achieve this by proposing the unit-norm Gaussian kernel and define a sparsification criterion for this novel kernel. This new methodology is validated on two real-world datasets against standard KAF in terms of the normalised mean square error and the dictionary size. version:1
arxiv-1704-07335 | Development of a Swarm UAV Simulator Integrating Realistic Motion Control Models For Disaster Operations | http://arxiv.org/abs/1704.07335 | id:1704.07335 author:Kazi Tanvir Ahmed Siddiqui, David Feil-Seifer, Tianyi Jiang, Sonu Jose, Siming Liu, Sushil Louis category:cs.RO  published:2017-04-24 summary:Simulation environments for Unmanned Aerial Vehicles (UAVs) can be very useful for prototyping user interfaces and training personnel that will operate UAVs in the real world. The realistic operation of such simulations will only enhance the value of such training. In this paper, we present the integration of a model-based waypoint navigation controller into the Reno Rescue Simulator for the purposes of providing a more realistic user interface in simulated environments. We also present potential uses for such simulations, even for real-world operation of UAVs. version:2
arxiv-1707-04227 | Automatic Speech Recognition with Very Large Conversational Finnish and Estonian Vocabularies | http://arxiv.org/abs/1707.04227 | id:1707.04227 author:Seppo Enarvi, Peter Smit, Sami Virpioja, Mikko Kurimo category:cs.CL cs.SD  published:2017-07-13 summary:Previously, very large vocabularies have been efficiently modeled in conventional n-gram language models either by splitting words into subword units or by clustering words into classes. While the vocabulary size is not anymore as critical in modern speech recognition systems, training time and memory consumption become an issue when state-of-the-art neural network language models are used. In this paper we investigate techniques that address the vocabulary size issue by reducing the effective vocabulary size and by processing large vocabularies more efficiently. The experimental results in conversational Finnish and Estonian speech recognition indicate that properly defined word classes improve recognition accuracy. Subword n-gram models are not better on evaluation data than word n-gram models constructed from a vocabulary that includes all the words in the training corpus. However, when recurrent neural network (RNN) language models are used, their ability to utilize long contexts gives a larger gain to subword-based modeling. Our best results are from RNN language models that are based on statistical morphs. We show that the suitable size for a subword vocabulary depends on the language. Using time delay neural network (TDNN) acoustic models, we were able to achieve new state of the art in Finnish and Estonian conversational speech recognition, 27.1 % word error rate in the Finnish task and 21.9 % in the Estonian task. version:1
arxiv-1706-08457 | Iterative Random Forests to detect predictive and stable high-order interactions | http://arxiv.org/abs/1706.08457 | id:1706.08457 author:Sumanta Basu, Karl Kumbier, James B. Brown, Bin Yu category:stat.ML q-bio.GN  published:2017-06-26 summary:Genomics has revolutionized biology, enabling the interrogation of whole transcriptomes, genome-wide binding sites for proteins, and many other molecular processes. However, individual genomic assays measure elements that operate in vivo as components of larger molecular machines that regulate gene expression. Understanding these processes and the high-order interactions that govern them presents a substantial statistical challenge. Building on Random Forests (RF), Random Intersection Trees (RIT), and through extensive, biologically inspired simulations, we developed iterative Random Forests (iRF). iRF leverages the Principle of Stability to train an interpretable ensemble of decisions trees and detect stable, high-order interactions with same order of computational cost as RF. We demonstrate the utility of iRF for high-order interaction discovery in two prediction problems: enhancer activity for the early Drosophila embryo and alternative splicing of primary transcripts in human derived cell lines. In Drosophila, iRF re-discovered the essential role of zelda (zld) in early zygotic enhancer activation, and novel third-order interactions, e.g. between zld, giant (gt), and twist (twi). In human-derived cells, iRF re-discovered that H3K36me3 plays a central role in chromatin-mediated splicing regulation, and identified novel 5th and 6th order interactions, indicative of multi-valent nucleosomes with specific roles in splicing regulation. By decoupling the order of interactions from the computational cost of identification, iRF opens new avenues of inquiry in genome biology, automating hypothesis generation for the discovery of new molecular mechanisms from high-throughput, genome-wide datasets. version:2
arxiv-1707-03815 | Deep Gaussian Embedding of Attributed Graphs: Unsupervised Inductive Learning via Ranking | http://arxiv.org/abs/1707.03815 | id:1707.03815 author:Aleksandar Bojchevski, Stephan Günnemann category:stat.ML cs.LG cs.SI  published:2017-07-12 summary:Methods that learn representations of graph nodes play a critical role in network analysis since they enable many downstream learning tasks. We propose Graph2Gauss - an approach that can efficiently learn versatile node embeddings on large scale (attributed) graphs that show strong performance on tasks such as link prediction and node classification. Unlike most approaches that represent nodes as (point) vectors in a lower-dimensional continuous space, we embed each node as a Gaussian distribution, allowing us to capture uncertainty about the representation. Furthermore, in contrast to previous approaches we propose a completely unsupervised method that is also able to handle inductive learning scenarios and is applicable to different types of graphs (plain, attributed, directed, undirected). By leveraging both the topological network structure and the associated node attributes, we are able to generalize to unseen nodes without additional training. To learn the embeddings we adopt a personalized ranking formulation w.r.t. the node distances that exploits the natural ordering between the nodes imposed by the network structure. Experiments on real world networks demonstrate the high performance of our approach, outperforming state-of-the-art network embedding methods on several different tasks. version:2
arxiv-1707-04221 | Parsing with Traces: An $O(n^4)$ Algorithm and a Structural Representation | http://arxiv.org/abs/1707.04221 | id:1707.04221 author:Jonathan K. Kummerfeld, Dan Klein category:cs.CL cs.DM I.2.7; F.2.2; G.2.2  published:2017-07-13 summary:General treebank analyses are graph structured, but parsers are typically restricted to tree structures for efficiency and modeling reasons. We propose a new representation and algorithm for a class of graph structures that is flexible enough to cover almost all treebank structures, while still admitting efficient learning and inference. In particular, we consider directed, acyclic, one-endpoint-crossing graph structures, which cover most long-distance dislocation, shared argumentation, and similar tree-violating linguistic phenomena. We describe how to convert phrase structure parses, including traces, to our new representation in a reversible manner. Our dynamic program uniquely decomposes structures, is sound and complete, and covers 97.3% of the Penn English Treebank. We also implement a proof-of-concept parser that recovers a range of null elements and trace types. version:1
arxiv-1707-04218 | Learning Features from Co-occurrences: A Theoretical Analysis | http://arxiv.org/abs/1707.04218 | id:1707.04218 author:Yanpeng Li category:cs.CL cs.LG math.ST stat.ML stat.TH  published:2017-07-13 summary:Representing a word by its co-occurrences with other words in context is an effective way to capture the meaning of the word. However, the theory behind remains a challenge. In this work, taking the example of a word classification task, we give a theoretical analysis of the approaches that represent a word X by a function f(P(C X)), where C is a context feature, P(C X) is the conditional probability estimated from a text corpus, and the function f maps the co-occurrence measure to a prediction score. We investigate the impact of context feature C and the function f. We also explain the reasons why using the co-occurrences with multiple context features may be better than just using a single one. In addition, some of the results shed light on the theory of feature learning and machine learning in general. version:1
arxiv-1707-04199 | Be Careful What You Backpropagate: A Case For Linear Output Activations & Gradient Boosting | http://arxiv.org/abs/1707.04199 | id:1707.04199 author:Anders Oland, Aayush Bansal, Roger B. Dannenberg, Bhiksha Raj category:cs.LG cs.CV  published:2017-07-13 summary:In this work, we show that saturating output activation functions, such as the softmax, impede learning on a number of standard classification tasks. Moreover, we present results showing that the utility of softmax does not stem from the normalization, as some have speculated. In fact, the normalization makes things worse. Rather, the advantage is in the exponentiation of error gradients. This exponential gradient boosting is shown to speed up convergence and improve generalization. To this end, we demonstrate faster convergence and better performance on diverse classification tasks: image classification using CIFAR-10 and ImageNet, and semantic segmentation using PASCAL VOC 2012. In the latter case, using the state-of-the-art neural network architecture, the model converged 33% faster with our method (roughly two days of training less) than with the standard softmax activation, and with a slightly better performance to boot. version:1
arxiv-1707-04191 | Distributionally Robust Optimization Techniques in Batch Bayesian Optimization | http://arxiv.org/abs/1707.04191 | id:1707.04191 author:Nikitas Rontsis, Michael A. Osborne, Paul J. Goulart category:stat.ML  published:2017-07-13 summary:We propose a novel, theoretically-grounded, acquisition function for batch Bayesian optimisation informed by insights from distributionally robust optimization. Our acquisition function is a lower bound on the well-known Expected Improvement function - which requires a multi-dimensional Gaussian Expectation over a piecewise affine function - and is computed by evaluating instead the best-case expectation over all probability distributions consistent with the same mean and variance as the original Gaussian distribution. We show that, unlike alternative approaches including Expected Improvement, our proposed acquisition function avoids multi-dimensional integrations entirely, and can be calculated exactly as the solution of a convex optimization problem in the form of a tractable semidefinite program (SDP). Moreover, we prove that the solution of this SDP also yields exact numerical derivatives, which enable efficient optimisation of the acquisition function. Numerical results suggest that our acquisition function performs very similar to the computationally intractable exact Expected Improvement and considerably better than other heuristics. version:1
arxiv-1706-09865 | Generalising Random Forest Parameter Optimisation to Include Stability and Cost | http://arxiv.org/abs/1706.09865 | id:1706.09865 author:C. H. Bryan Liu, Benjamin Paul Chamberlain, Duncan A. Little, Angelo Cardoso category:stat.ML cs.CY cs.LG  published:2017-06-29 summary:Random forests are among the most popular classification and regression methods used in industrial applications. To be effective, the parameters of random forests must be carefully tuned. This is usually done by choosing values that minimize the prediction error on a held out dataset. We argue that error reduction is only one of several metrics that must be considered when optimizing random forest parameters for commercial applications. We propose a novel metric that captures the stability of random forests predictions, which we argue is key for scenarios that require successive predictions. We motivate the need for multi-criteria optimization by showing that in practical applications, simply choosing the parameters that lead to the lowest error can introduce unnecessary costs and produce predictions that are not stable across independent runs. To optimize this multi-criteria trade-off, we present a new framework that efficiently finds a principled balance between these three considerations using Bayesian optimisation. The pitfalls of optimising forest parameters purely for error reduction are demonstrated using two publicly available real world datasets. We show that our framework leads to parameter settings that are markedly different from the values discovered by error reduction metrics. version:2
arxiv-1707-00780 | Discriminatory Transfer | http://arxiv.org/abs/1707.00780 | id:1707.00780 author:Chao Lan, Jun Huan category:cs.CY cs.LG stat.ML  published:2017-07-03 summary:We observe standard transfer learning can improve prediction accuracies of target tasks at the cost of lowering their prediction fairness -- a phenomenon we named discriminatory transfer. We examine prediction fairness of a standard hypothesis transfer algorithm and a standard multi-task learning algorithm, and show they both suffer discriminatory transfer on the real-world Communities and Crime data set. The presented case study introduces an interaction between fairness and transfer learning, as an extension of existing fairness studies that focus on single task learning. version:3
arxiv-1707-04175 | Distral: Robust Multitask Reinforcement Learning | http://arxiv.org/abs/1707.04175 | id:1707.04175 author:Yee Whye Teh, Victor Bapst, Wojciech Marian Czarnecki, John Quan, James Kirkpatrick, Raia Hadsell, Nicolas Heess, Razvan Pascanu category:cs.LG stat.ML  published:2017-07-13 summary:Most deep reinforcement learning algorithms are data inefficient in complex and rich environments, limiting their applicability to many scenarios. One direction for improving data efficiency is multitask learning with shared neural network parameters, where efficiency may be improved through transfer across related tasks. In practice, however, this is not usually observed, because gradients from different tasks can interfere negatively, making learning unstable and sometimes even less data efficient. Another issue is the different reward schemes between tasks, which can easily lead to one task dominating the learning of a shared model. We propose a new approach for joint training of multiple tasks, which we refer to as Distral (Distill & transfer learning). Instead of sharing parameters between the different workers, we propose to share a "distilled" policy that captures common behaviour across tasks. Each worker is trained to solve its own task while constrained to stay close to the shared policy, while the shared policy is trained by distillation to be the centroid of all task policies. Both aspects of the learning process are derived by optimizing a joint objective function. We show that our approach supports efficient transfer on complex 3D environments, outperforming several related methods. Moreover, the proposed learning process is more robust and more stable---attributes that are critical in deep reinforcement learning. version:1
arxiv-1705-02042 | Exponential scaling of neural algorithms - a future beyond Moore's Law? | http://arxiv.org/abs/1705.02042 | id:1705.02042 author:James B. Aimone category:cs.NE q-bio.NC  published:2017-05-04 summary:Although the brain has long been considered a potential inspiration for future computing, Moore's Law - the scaling property that has seen revolutions in technologies ranging from supercomputers to smart phones - has largely been driven by advances in materials science. As the ability to miniaturize transistors is coming to an end, there is increasing attention on new approaches to computation, including renewed enthusiasm around the potential of neural computation. This paper describes how recent advances in neurotechnologies, many of which have been aided by computing's rapid progression over recent decades, are now reigniting this opportunity to bring neural computation insights into broader computing applications. As we understand more about the brain, our ability to motivate new computing paradigms with continue to progress. These new approaches to computing, which we are already seeing in techniques such as deep learning and neuromorphic hardware, will themselves improve our ability to learn about the brain and accordingly can be projected to give rise to even further insights. This paper will describe how this positive feedback has the potential to change the complexion of how computing sciences and neurosciences interact, and suggests that the next form of exponential scaling in computing may emerge from our progressive understanding of the brain. version:2
arxiv-1706-06827 | Structure Learning in Motor Control:A Deep Reinforcement Learning Model | http://arxiv.org/abs/1706.06827 | id:1706.06827 author:Ari Weinstein, Matthew M. Botvinick category:cs.AI  published:2017-06-21 summary:Motor adaptation displays a structure-learning effect: adaptation to a new perturbation occurs more quickly when the subject has prior exposure to perturbations with related structure. Although this `learning-to-learn' effect is well documented, its underlying computational mechanisms are poorly understood. We present a new model of motor structure learning, approaching it from the point of view of deep reinforcement learning. Previous work outside of motor control has shown how recurrent neural networks can account for learning-to-learn effects. We leverage this insight to address motor learning, by importing it into the setting of model-based reinforcement learning. We apply the resulting processing architecture to empirical findings from a landmark study of structure learning in target-directed reaching (Braun et al., 2009), and discuss its implications for a wider range of learning-to-learn phenomena. version:2
arxiv-1707-04143 | UTS submission to Google YouTube-8M Challenge 2017 | http://arxiv.org/abs/1707.04143 | id:1707.04143 author:Linchao Zhu, Yanbin Liu, Yi Yang category:cs.CV  published:2017-07-13 summary:In this paper, we present our solution to Google YouTube-8M Video Classification Challenge 2017. We leveraged both video-level and frame-level features in the submission. For video-level classification, we simply used a 200-mixture Mixture of Experts (MoE) layer, which achieves GAP 0.802 on the validation set with a single model. For frame-level classification, we utilized several variants of recurrent neural networks, sequence aggregation with attention mechanism and 1D convolutional models. We achieved GAP 0.8408 on the private testing set with the ensemble model. The source code of our models can be found in \url{https://github.com/ffmpbgrnn/yt8m}. version:1
arxiv-1707-04131 | Foolbox v0.8.0: A Python toolbox to benchmark the robustness of machine learning models | http://arxiv.org/abs/1707.04131 | id:1707.04131 author:Jonas Rauber, Wieland Brendel, Matthias Bethge category:cs.LG cs.CR cs.CV stat.ML  published:2017-07-13 summary:Even todays most advanced machine learning models are easily fooled by almost imperceptible perturbations of their inputs. Foolbox is a new Python package to generate such adversarial perturbations and to quantify and compare the robustness of machine learning models. It is build around the idea that the most comparable robustness measure is the minimum perturbation needed to craft an adversarial example. To this end, Foolbox provides reference implementations of most published adversarial attack methods alongside some new ones, all of which perform internal hyperparameter tuning to find the minimum adversarial perturbation. Additionally, Foolbox interfaces with most popular deep learning frameworks such as PyTorch, Keras, TensorFlow, Theano and MXNet, provides a straight forward way to add support for other frameworks and allows different adversarial criteria such as targeted misclassification and top-k misclassification as well as different distance measures. The code is licensed under the MIT license and is openly available at https://github.com/bethgelab/foolbox version:1
arxiv-1705-10480 | Preliminary results on Ontology-based Open Data Publishing | http://arxiv.org/abs/1705.10480 | id:1705.10480 author:Gianluca Cima category:cs.DB cs.AI  published:2017-05-30 summary:Despite the current interest in Open Data publishing, a formal and comprehensive methodology supporting an organization in deciding which data to publish and carrying out precise procedures for publishing high-quality data, is still missing. In this paper we argue that the Ontology-based Data Management paradigm can provide a formal basis for a principled approach to publish high quality, semantically annotated Open Data. We describe two main approaches to using an ontology for this endeavor, and then we present some technical results on one of the approaches, called bottom-up, where the specification of the data to be published is given in terms of the sources, and specific techniques allow deriving suitable annotations for interpreting the published data under the light of the ontology. version:2
arxiv-1707-04114 | Inferring the parameters of a Markov process from snapshots of the steady state | http://arxiv.org/abs/1707.04114 | id:1707.04114 author:Simon Lee Dettmer, Johannes Berg category:cond-mat.stat-mech cond-mat.dis-nn math.PR physics.data-an stat.ML  published:2017-07-13 summary:We seek to infer the parameters of an ergodic Markov process from samples taken independently from the steady state. Our focus is on non-equilibrium processes, where the steady state is not described by the Boltzmann measure, but is generally unknown and hard to compute. To this end, we propose a quantity we call propagator likelihood, which takes on the role of the likelihood in equilibrium processes. This propagator likelihood is based on fictitious transitions between those configurations of the system which occur in the samples. The propagator likelihood can be derived by minimising the relative entropy between the empirical distribution and a distribution generated by propagating the empirical distribution forward in time. Maximising this propagator likelihood leads to an efficient reconstruction of the parameters of the underlying model in different systems, both with discrete configurations and with continuous configurations. We apply the method to different non-equilibrium models from statistical physics and theoretical biology, including the asymmetric simple exclusion process (ASEP), the kinetic Ising model, and replicator dynamics. version:1
arxiv-1707-04108 | Do Convolutional Networks need to be Deep for Text Classification ? | http://arxiv.org/abs/1707.04108 | id:1707.04108 author:Hoa T. Le, Christophe Cerisara, Alexandre Denis category:cs.CL  published:2017-07-13 summary:We study in this work the importance of depth in convolutional models for text classification, either when character or word inputs are considered. We show on 5 standard text classification and sentiment analysis tasks that deep models indeed give better performances than shallow networks when the text input is represented as a sequence of characters. However, a simple shallow-and-wide network outperforms deep models such as DenseNet with word inputs. Our shallow word model further establishes new state-of-the-art performances on two datasets: Yelp Binary (95.9\%) and Yelp Full (64.9\%). version:1
arxiv-1707-04106 | Armstrong's Axioms and Navigation Strategies | http://arxiv.org/abs/1707.04106 | id:1707.04106 author:Kaya Deuser, Pavel Naumov category:cs.AI cs.LO  published:2017-07-13 summary:The paper investigates navigability with imperfect information. It shows that the properties of navigability with perfect recall are exactly those captured by Armstrong's axioms from the database theory. If the assumption of perfect recall is omitted, then Armstrong's transitivity axiom is not valid, but it can be replaced by two new weaker principles. The main technical results are soundness and completeness theorems for the logical systems describing properties of navigability with and without perfect recall. version:1
arxiv-1707-04095 | Is writing style predictive of scientific fraud? | http://arxiv.org/abs/1707.04095 | id:1707.04095 author:Chloé Braud, Anders Søgaard category:cs.CL  published:2017-07-13 summary:The problem of detecting scientific fraud using machine learning was recently introduced, with initial, positive results from a model taking into account various general indicators. The results seem to suggest that writing style is predictive of scientific fraud. We revisit these initial experiments, and show that the leave-one-out testing procedure they used likely leads to a slight over-estimate of the predictability, but also that simple models can outperform their proposed model by some margin. We go on to explore more abstract linguistic features, such as linguistic complexity and discourse structure, only to obtain negative results. Upon analyzing our models, we do see some interesting patterns, though: Scientific fraud, for examples, contains less comparison, as well as different types of hedging and ways of presenting logical reasoning. version:1
arxiv-1707-03377 | Learning like humans with Deep Symbolic Networks | http://arxiv.org/abs/1707.03377 | id:1707.03377 author:Qunzhi Zhang, Didier Sornette category:cs.AI cond-mat.dis-nn cs.LG  published:2017-07-11 summary:We introduce the Deep Symbolic Network (DSN) model, which aims at becoming the white-box version of Deep Neural Networks (DNN). The DSN model provides a simple, universal yet powerful structure, similar to DNN, to represent any knowledge of the world, which is transparent to humans. The conjecture behind the DSN model is that any type of real world objects sharing enough common features are mapped into human brains as a symbol. Those symbols are connected by links, representing the composition, correlation, causality, or other relationships between them, forming a deep, hierarchical symbolic network structure. Powered by such a structure, the DSN model is expected to learn like humans, because of its unique characteristics. First, it is universal, using the same structure to store any knowledge. Second, it can learn symbols from the world and construct the deep symbolic networks automatically, by utilizing the fact that real world objects have been naturally separated by singularities. Third, it is symbolic, with the capacity of performing causal deduction and generalization. Fourth, the symbols and the links between them are transparent to us, and thus we will know what it has learned or not - which is the key for the security of an AI system. Fifth, its transparency enables it to learn with relatively small data. Sixth, its knowledge can be accumulated. Last but not least, it is more friendly to unsupervised learning than DNN. We present the details of the model, the algorithm powering its automatic learning ability, and describe its usefulness in different use cases. The purpose of this paper is to generate broad interest to develop it within an open source project centered on the Deep Symbolic Network (DSN) model towards the development of general AI. version:2
arxiv-1707-09842 | Deep Domain Adaptation by Geodesic Distance Minimization | http://arxiv.org/abs/1707.09842 | id:1707.09842 author:Yifei Wang, Wen Li, Dengxin Dai, Luc Van Gool category:cs.CV  published:2017-07-13 summary:Recently, a method called deep CORAL was proposed for deep domain adaptation problem. It represents each domain by its second order statistic information (i.e. the covariance matrix), and minimizes the Euclidean distance between the covariance matrices of the source domain (training domain) and the target domain (test domain). However, Euclidean distance may not be a proper choice for measuring the difference between covariance matrices, since the convaraice matrix is a PSD matrix that represents the second-order statistical information. In this work, we propose a new method for deep unsupervised domain adaptation. By observing the covariance matrix lies on a Riemannian manifold, we propose to minimize the geodesic distance between the source and target covariance matrices. We build up our method on the deep CORAL approach, and use the Log-Euclidean distance to replace the naive Euclidean distance. In particular, we use the pre-trained Alexnet model as the base model, and add a new LogEig layer after fc8 layer, which calculate Riemannain distance of two covariance matrices from source and target domains. We simultaneously optimize the classification loss on the source domain labeled samples and the Log-Euclidean distance between two domains. We conduct experiments on the benchmark Office dataset. The results show that Deep LogCORAL gives higher accuracy in four out of the six domains and raise 0.7% of the average accuracy. Also, the experiment gives another interesting observation that Euclidean distance and Riemannain distance have only weak correlation, which shows a potential direction in domain adaptation to optimize Euclidean distance and Riemannian distance at the same time. version:1
arxiv-1707-04067 | Automation of Feature Engineering for IoT Analytics | http://arxiv.org/abs/1707.04067 | id:1707.04067 author:Snehasis Banerjee, Tanushyam Chattopadhyay, Arpan Pal, Utpal Garain category:stat.ML  published:2017-07-13 summary:This paper presents an approach for automation of interpretable feature selection for Internet Of Things Analytics (IoTA) using machine learning (ML) techniques. Authors have conducted a survey over different people involved in different IoTA based application development tasks. The survey reveals that feature selection is the most time consuming and niche skill demanding part of the entire workflow. This paper shows how feature selection is successfully automated without sacrificing the decision making accuracy and thereby reducing the project completion time and cost of hiring expensive resources. Several pattern recognition principles and state of art (SoA) ML techniques are followed to design the overall approach for the proposed automation. Three data sets are considered to establish the proof-of-concept. Experimental results show that the proposed automation is able to reduce the time for feature selection to $2$ days instead of $4-6$ months which would have been required in absence of the automation. This reduction in time is achieved without any sacrifice in the accuracy of the decision making process. Proposed method is also compared against Multi Layer Perceptron (MLP) model as most of the state of the art works on IoTA uses MLP based Deep Learning. Moreover the feature selection method is compared against SoA feature reduction technique namely Principal Component Analysis (PCA) and its variants. The results obtained show that the proposed method is effective. version:1
arxiv-1707-04061 | Automatic Recognition of Deceptive Facial Expressions of Emotion | http://arxiv.org/abs/1707.04061 | id:1707.04061 author:Ikechukwu Ofodile, Kaustubh Kulkarni, Ciprian Adrian Corneanu, Sergio Escalera, Xavier Baro, Sylwia Hyniewska, Juri Allik, Gholamreza Anbarjafari category:cs.CV  published:2017-07-13 summary:Humans modify facial expressions in order to mislead observers regarding their true emotional states. Being able to recognize the authenticity of emotional displays is notoriously difficult for human observers. Evidence in experimental psychology shows that discriminative facial responses are short and subtle. This suggests that such behavior would be easier to distinguish when captured in high resolution at an increased frame rate. We are proposing SASE-FE, the first dataset of genuine and deceptive facial expressions of emotions for automatic recognition. We show that overall the problem of recognizing deceptive facial expressions can be successfully addressed by learning spatio-temporal representations of the data. For this purpose, we propose a method that aggregates features along fiducial trajectories in a deeply learnt feature space. Interesting additional results show that on average it is easier to distinguish among genuine expressions than deceptive ones and that certain emotion pairs are more difficult to distinguish than others. version:1
arxiv-1707-04053 | Clingo goes Linear Constraints over Reals and Integers | http://arxiv.org/abs/1707.04053 | id:1707.04053 author:Tomi Janhunen, Roland Kaminski, Max Ostrowski, Torsten Schaub, Sebastian Schellhorn, Philipp Wanko category:cs.AI  published:2017-07-13 summary:The recent series 5 of the ASP system clingo provides generic means to enhance basic Answer Set Programming (ASP) with theory reasoning capabilities. We instantiate this framework with different forms of linear constraints, discuss the respective implementations, and present techniques of how to use these constraints in a reactive context. More precisely, we introduce extensions to clingo with difference and linear constraints over integers and reals, respectively, and realize them in complementary ways. Finally, we empirically evaluate the resulting clingo derivatives clingo[dl] and clingo[lp] on common fragments and contrast them to related ASP systems. This paper is under consideration for acceptance in TPLP. version:1
arxiv-1707-04047 | Discrete Multi-modal Hashing with Canonical Views for Robust Mobile Landmark Search | http://arxiv.org/abs/1707.04047 | id:1707.04047 author:Lei Zhu, Zi Huang, Xiaobai Liu, Xiangnan He, Jingkuan Song, Xiaofang Zhou category:cs.CV  published:2017-07-13 summary:Mobile landmark search (MLS) recently receives increasing attention for its great practical values. However, it still remains unsolved due to two important challenges. One is high bandwidth consumption of query transmission, and the other is the huge visual variations of query images sent from mobile devices. In this paper, we propose a novel hashing scheme, named as canonical view based discrete multi-modal hashing (CV-DMH), to handle these problems via a novel three-stage learning procedure. First, a submodular function is designed to measure visual representativeness and redundancy of a view set. With it, canonical views, which capture key visual appearances of landmark with limited redundancy, are efficiently discovered with an iterative mining strategy. Second, multi-modal sparse coding is applied to transform visual features from multiple modalities into an intermediate representation. It can robustly and adaptively characterize visual contents of varied landmark images with certain canonical views. Finally, compact binary codes are learned on intermediate representation within a tailored discrete binary embedding model which preserves visual relations of images measured with canonical views and removes the involved noises. In this part, we develop a new augmented Lagrangian multiplier (ALM) based optimization method to directly solve the discrete binary codes. We can not only explicitly deal with the discrete constraint, but also consider the bit-uncorrelated constraint and balance constraint together. Experiments on real world landmark datasets demonstrate the superior performance of CV-DMH over several state-of-the-art methods. version:1
arxiv-1707-04046 | Stable Distribution Alignment Using the Dual of the Adversarial Distance | http://arxiv.org/abs/1707.04046 | id:1707.04046 author:Ben Usman, Kate Saenko, Brian Kulis category:cs.LG cs.AI cs.CV  published:2017-07-13 summary:Learning to align distributions by minimizing an adversarial distance between them has recently achieved impressive results. However, such models are difficult to optimize with gradient descent and they often do not converge without very careful parameter tuning and initialization. We investigate whether turning the adversarial min-max problem into an optimization problem by replacing the maximization part with its dual improves the quality of the resulting alignment. Our empirical results suggest that using the dual formulation for linear and kernelized discriminators results in a more stable convergence to a desirable solution. We test our hypothesis on the problem of aligning two synthetic point clouds on a plane and on a real-image domain adaptation problem using a subset of MNIST and USPS. In both cases, the dual formulation yields an iterative procedure that gives more stable and monotonic improvement over time. version:1
arxiv-1707-04045 | Large-scale Video Classification guided by Batch Normalized LSTM Translator | http://arxiv.org/abs/1707.04045 | id:1707.04045 author:Jae Hyeon Yoo category:cs.CV  published:2017-07-13 summary:Youtube-8M dataset enhances the development of large-scale video recognition technology as ImageNet dataset has encouraged image classification, recognition and detection of artificial intelligence fields. For this large video dataset, it is a challenging task to classify a huge amount of multi-labels. By change of perspective, we propose a novel method by regarding labels as words. In details, we describe online learning approaches to multi-label video classification that are guided by deep recurrent neural networks for video to sentence translator. We designed the translator based on LSTMs and found out that a stochastic gating before the input of each LSTM cell can help us to design the structural details. In addition, we adopted batch normalizations into our models to improve our LSTM models. Since our models are feature extractors, they can be used with other classifiers. Finally we report improved validation results of our models on large-scale Youtube-8M datasets and discussions for the further improvement. version:1
arxiv-1707-04041 | Deep Learning with Topological Signatures | http://arxiv.org/abs/1707.04041 | id:1707.04041 author:Christoph Hofer, Roland Kwitt, Marc Niethammer, Andreas Uhl category:cs.CV cs.LG math.AT  published:2017-07-13 summary:Inferring topological and geometrical information from data can offer an alternative perspective on machine learning problems. Methods from topological data analysis, e.g., persistent homology, enable us to obtain such information, typically in the form of summary representations of topological features. However, such topological signatures often come with an unusual structure (e.g., multisets of intervals) that is highly impractical for most machine learning techniques. While many strategies have been proposed to map these topological signatures into machine learning compatible representations, they suffer from being agnostic to the target learning task. In contrast, we propose a technique that enables us to input topological signatures to deep neural networks and learn a task-optimal representation during training. Our approach is realized as a novel input layer with favorable theoretical properties. Classification experiments on 2D object shapes and social network graphs demonstrate the versatility of the approach and, in case of the latter, we even outperform the state-of-the-art by a large margin. version:1
arxiv-1707-04035 | Kafnets: kernel-based non-parametric activation functions for neural networks | http://arxiv.org/abs/1707.04035 | id:1707.04035 author:Simone Scardapane, Steven Van Vaerenbergh, Aurelio Uncini category:stat.ML cs.AI cs.LG cs.NE  published:2017-07-13 summary:Neural networks are generally built by interleaving (adaptable) linear layers with (fixed) nonlinear activation functions. To increase their flexibility, several authors have proposed methods for adapting the activation functions themselves, endowing them with varying degrees of flexibility. None of these approaches, however, have gained wide acceptance in practice, and research in this topic remains open. In this paper, we introduce a novel family of flexible activation functions that are based on an inexpensive kernel expansion at every neuron. Leveraging over several properties of kernel-based models, we propose multiple variations for designing and initializing these kernel activation functions (KAFs), including a multidimensional scheme allowing to nonlinearly combine information from different paths in the network. The resulting KAFs can approximate any mapping defined over a subset of the real line, either convex or nonconvex. Furthermore, they are smooth over their entire domain, linear in their parameters, and they can be regularized using any known scheme, including the use of $\ell_1$ penalties to enforce sparseness. To the best of our knowledge, no other known model satisfies all these properties simultaneously. In addition, we provide a relatively complete overview on alternative techniques for adapting the activation functions, which is currently lacking in the literature. A large set of experiments validates our proposal. version:1
arxiv-1706-08500 | GANs Trained by a Two Time-Scale Update Rule Converge to a Nash Equilibrium | http://arxiv.org/abs/1706.08500 | id:1706.08500 author:Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Günter Klambauer, Sepp Hochreiter category:cs.LG stat.ML  published:2017-06-26 summary:Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent that has an individual learning rate for both the discriminator and the generator. We prove that the TTUR converges under mild assumptions to a stationary Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the "Fr\'echet Inception Distance" (FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments, TTUR improves learning for DCGANs, improved Wasserstein GANs, and BEGANs, outperforming conventional GAN training on CelebA, One Billion Word Benchmark, and LSUN bedrooms. version:4
arxiv-1707-04027 | Constraints, Lazy Constraints, or Propagators in ASP Solving: An Empirical Analysis | http://arxiv.org/abs/1707.04027 | id:1707.04027 author:Bernardo Cuteri, Carmine Dodaro, Francesco Ricca, Peter Schüller category:cs.AI  published:2017-07-13 summary:Answer Set Programming (ASP) is a well-established declarative paradigm. One of the successes of ASP is the availability of efficient systems. State-of-the-art systems are based on the ground+solve approach. In some applications this approach is infeasible because the grounding of one or few constraints is expensive. In this paper, we systematically compare alternative strategies to avoid the instantiation of problematic constraints, that are based on custom extensions of the solver. Results on real and synthetic benchmarks highlight some strengths and weaknesses of the different strategies. (Under consideration for acceptance in TPLP, ICLP 2017 Special Issue.) version:1
arxiv-1707-04025 | On Measuring and Quantifying Performance: Error Rates, Surrogate Loss, and an Example in SSL | http://arxiv.org/abs/1707.04025 | id:1707.04025 author:Marco Loog, Jesse H. Krijthe, Are C. Jensen category:cs.LG cs.CV stat.ML  published:2017-07-13 summary:In various approaches to learning, notably in domain adaptation, active learning, learning under covariate shift, semi-supervised learning, learning with concept drift, and the like, one often wants to compare a baseline classifier to one or more advanced (or at least different) strategies. In this chapter, we basically argue that if such classifiers, in their respective training phases, optimize a so-called surrogate loss that it may also be valuable to compare the behavior of this loss on the test set, next to the regular classification error rate. It can provide us with an additional view on the classifiers' relative performances that error rates cannot capture. As an example, limited but convincing empirical results demonstrates that we may be able to find semi-supervised learning strategies that can guarantee performance improvements with increasing numbers of unlabeled data in terms of log-likelihood. In contrast, the latter may be impossible to guarantee for the classification error rate. version:1
arxiv-1707-04021 | Query-Aware Sparse Coding for Multi-Video Summarization | http://arxiv.org/abs/1707.04021 | id:1707.04021 author:Zhong Ji, Yaru Ma, Yanwei Pang, Xuelong Li category:cs.CV  published:2017-07-13 summary:Given the explosive growth of online videos, it is becoming increasingly important to relieve the tedious work of browsing and managing the video content of interest. Video summarization aims at providing such a technique by transforming one or multiple videos into a compact one. However, conventional multi-video summarization methods often fail to produce satisfying results as they ignore the user's search intent. To this end, this paper proposes a novel query-aware approach by formulating the multi-video summarization in a sparse coding framework, where the web images searched by the query are taken as the important preference information to reveal the query intent. To provide a user-friendly summarization, this paper also develops an event-keyframe presentation structure to present keyframes in groups of specific events related to the query by using an unsupervised multi-graph fusion method. We release a new public dataset named MVS1K, which contains about 1, 000 videos from 10 queries and their video tags, manual annotations, and associated web images. Extensive experiments on MVS1K dataset validate our approaches produce superior objective and subjective results against several recently proposed approaches. version:1
arxiv-1707-04016 | Dependency Injection for Programming by Optimization | http://arxiv.org/abs/1707.04016 | id:1707.04016 author:Zoltan A. Kocsis, Jerry Swan category:cs.AI D.1.2; I.2.2  published:2017-07-13 summary:Programming by Optimization tools perform automatic software configuration according to the specification supplied by a software developer. Developers specify design spaces for program components, and the onerous task of determining which configuration best suits a given use case is determined using automated analysis tools and optimization heuristics. However, in current approaches to Programming by Optimization, design space specification and exploration relies on external configuration algorithms, executable wrappers and fragile, preprocessed programming language extensions. Here we show that the architectural pattern of Dependency Injection provides a superior alternative to the traditional Programming by Optimization pipeline. We demonstrate that configuration tools based on Dependency Injection fit naturally into the software development process, while requiring less overhead than current wrapper-based mechanisms. Furthermore, the structural correspondence between Dependency Injection and context-free grammars yields a new class of evolutionary metaheuristics for automated algorithm configuration. We found that the new heuristics significantly outperform existing configuration algorithms on many problems of interest (in one case by two orders of magnitude). We anticipate that these developments will make Programming by Optimization immediately applicable to a large number of enterprise software projects. version:1
arxiv-1707-03997 | A Web-Based Tool for Analysing Normative Documents in English | http://arxiv.org/abs/1707.03997 | id:1707.03997 author:John J. Camilleri, Mohammad Reza Haghshenas, Gerardo Schneider category:cs.CL cs.CY  published:2017-07-13 summary:Our goal is to use formal methods to analyse normative documents written in English, such as privacy policies and service-level agreements. This requires the combination of a number of different elements, including information extraction from natural language, formal languages for model representation, and an interface for property specification and verification. We have worked on a collection of components for this task: a natural language extraction tool, a suitable formalism for representing such documents, an interface for building models in this formalism, and methods for answering queries asked of a given model. In this work, each of these concerns is brought together in a web-based tool, providing a single interface for analysing normative texts in English. Through the use of a running example, we describe each component and demonstrate the workflow established by our tool. version:1
arxiv-1707-03993 | Leveraging the Path Signature for Skeleton-based Human Action Recognition | http://arxiv.org/abs/1707.03993 | id:1707.03993 author:Weixin Yang, Terry Lyons, Hao Ni, Cordelia Schmid, Lianwen Jin, Jiawei Chang category:cs.CV  published:2017-07-13 summary:Human action recognition in videos is one of the most challenging tasks in computer vision. One important issue is how to design discriminative features for representing spatial context and temporal dynamics. Here, we introduce a path signature feature to encode information from intra-frame and inter-frame contexts. A key step towards leveraging this feature is to construct the proper trajectories (paths) for the data steam. In each frame, the correlated constraints of human joints are treated as small paths, then the spatial path signature features are extracted from them. In video data, the evolution of these spatial features over time can also be regarded as paths from which the temporal path signature features are extracted. Eventually, all these features are concatenated to constitute the input vector of a fully connected neural network for action classification. Experimental results on four standard benchmark action datasets, J-HMDB, SBU Dataset, Berkeley MHAD, and NTURGB+D demonstrate that the proposed approach achieves state-of-the-art accuracy even in comparison with recent deep learning based models. version:1
arxiv-1707-03986 | Merge or Not? Learning to Group Faces via Imitation Learning | http://arxiv.org/abs/1707.03986 | id:1707.03986 author:Yue He, Kaidi Cao, Cheng Li, Chen Change Loy category:cs.CV cs.LG  published:2017-07-13 summary:Given a large number of unlabeled face images, face grouping aims at clustering the images into individual identities present in the data. This task remains a challenging problem despite the remarkable capability of deep learning approaches in learning face representation. In particular, grouping results can still be egregious given profile faces and a large number of uninteresting faces and noisy detections. Often, a user needs to correct the erroneous grouping manually. In this study, we formulate a novel face grouping framework that learns clustering strategy from ground-truth simulated behavior. This is achieved through imitation learning (a.k.a apprenticeship learning or learning by watching) via inverse reinforcement learning (IRL). In contrast to existing clustering approaches that group instances by similarity, our framework makes sequential decision to dynamically decide when to merge two face instances/groups driven by short- and long-term rewards. Extensive experiments on three benchmark datasets show that our framework outperforms unsupervised and supervised baselines. version:1
arxiv-1707-03985 | Towards End-to-end Text Spotting with Convolutional Recurrent Neural Networks | http://arxiv.org/abs/1707.03985 | id:1707.03985 author:Hui Li, Peng Wang, Chunhua Shen category:cs.CV  published:2017-07-13 summary:In this work, we jointly address the problem of text detection and recognition in natural scene images based on convolutional recurrent neural networks. We propose a unified network that simultaneously localizes and recognizes text with a single forward pass, avoiding intermediate processes like image cropping and feature re-calculation, word separation, or character grouping. In contrast to existing approaches that consider text detection and recognition as two distinct tasks and tackle them one by one, the proposed framework settles these two tasks concurrently. The whole framework can be trained end-to-end, requiring only images, the ground-truth bounding boxes and text labels. Through end-to-end training, the learned features can be more informative, which improves the overall performance. The convolutional features are calculated only once and shared by both detection and recognition, which saves processing time. Our proposed method has achieved competitive performance on several benchmark datasets. version:1
arxiv-1706-09274 | The YouTube-8M Kaggle Competition: Challenges and Methods | http://arxiv.org/abs/1706.09274 | id:1706.09274 author:Haosheng Zou, Kun Xu, Jialian Li, Jun Zhu category:cs.CV  published:2017-06-28 summary:We took part in the YouTube-8M Video Understanding Challenge hosted on Kaggle, and achieved the 10th place within less than one month's time. In this paper, we present an extensive analysis and solution to the underlying machine-learning problem based on frame-level data, where major challenges are identified and corresponding preliminary methods are proposed. It's noteworthy that, with merely the proposed strategies and uniformly-averaging multi-crop ensemble was it sufficient for us to reach our ranking. We also report the methods we believe to be promising but didn't have enough time to train to convergence. We hope this paper could serve, to some extent, as a review and guideline of the YouTube-8M multi-label video classification benchmark, inspiring future attempts and research. version:2
arxiv-1707-03981 | Learning Photography Aesthetics with Deep CNNs | http://arxiv.org/abs/1707.03981 | id:1707.03981 author:Gautam Malu, Raju S. Bapi, Bipin Indurkhya category:cs.CV cs.AI cs.MM 68T45  published:2017-07-13 summary:Automatic photo aesthetic assessment is a challenging artificial intelligence task. Existing computational approaches have focused on modeling a single aesthetic score or a class (good or bad), however these do not provide any details on why the photograph is good or bad, or which attributes contribute to the quality of the photograph. To obtain both accuracy and human interpretation of the score, we advocate learning the aesthetic attributes along with the prediction of the overall score. For this purpose, we propose a novel multitask deep convolution neural network, which jointly learns eight aesthetic attributes along with the overall aesthetic score. We report near human performance in the prediction of the overall aesthetic score. To understand the internal representation of these attributes in the learned model, we also develop the visualization technique using back propagation of gradients. These visualizations highlight the important image regions for the corresponding attributes, thus providing insights about model's representation of these attributes. We showcase the diversity and complexity associated with different attributes through a qualitative analysis of the activation maps. version:1
arxiv-1707-03979 | A Brief Study of In-Domain Transfer and Learning from Fewer Samples using A Few Simple Priors | http://arxiv.org/abs/1707.03979 | id:1707.03979 author:Marc Pickett, Ayush Sekhari, James Davidson category:cs.AI cs.LG  published:2017-07-13 summary:Domain knowledge can often be encoded in the structure of a network, such as convolutional layers for vision, which has been shown to increase generalization and decrease sample complexity, or the number of samples required for successful learning. In this study, we ask whether sample complexity can be reduced for systems where the structure of the domain is unknown beforehand, and the structure and parameters must both be learned from the data. We show that sample complexity reduction through learning structure is possible for at least two simple cases. In studying these cases, we also gain insight into how this might be done for more complex domains. version:1
arxiv-1707-03976 | Asymptotic Optimality of Rapidly Exploring Random Tree | http://arxiv.org/abs/1707.03976 | id:1707.03976 author:Titas Bera, Debasish Ghose, Sundaram Suresh category:cs.RO  published:2017-07-13 summary:In this paper we investigate the asymptotic optimality property of a randomized sampling based motion planner, namely RRT. We prove that a RRT planner is not an asymptotically optimal motion planner. Our result, while being consistent with similar results which exist in the literature, however, brings out an important characteristics of a RRT planner. We show that the degree distribution of the tree vertices follows a power law in an asymptotic sense. A simulation result is presented to support the theoretical claim. Based on these results we also try to establish a simple necessary condition for sampling based motion planners to be asymptotically optimal. version:1
arxiv-1707-03968 | Predicting Causes of Reformulation in Intelligent Assistants | http://arxiv.org/abs/1707.03968 | id:1707.03968 author:Shumpei Sano, Nobuhiro Kaji, Manabu Sassano category:cs.CL  published:2017-07-13 summary:Intelligent assistants (IAs) such as Siri and Cortana conversationally interact with users and execute a wide range of actions (e.g., searching the Web, setting alarms, and chatting). IAs can support these actions through the combination of various components such as automatic speech recognition, natural language understanding, and language generation. However, the complexity of these components hinders developers from determining which component causes an error. To remove this hindrance, we focus on reformulation, which is a useful signal of user dissatisfaction, and propose a method to predict the reformulation causes. We evaluate the method using the user logs of a commercial IA. The experimental results have demonstrated that features designed to detect the error of a specific component improve the performance of reformulation cause detection. version:1
arxiv-1604-04359 | Complexity of Manipulation with Partial Information in Voting | http://arxiv.org/abs/1604.04359 | id:1604.04359 author:Palash Dey, Neeldhara Misra, Y. Narahari category:cs.MA cs.AI cs.CC cs.CY cs.DS  published:2016-04-15 summary:The Coalitional Manipulation problem has been studied extensively in the literature for many voting rules. However, most studies have focused on the complete information setting, wherein the manipulators know the votes of the non-manipulators. While this assumption is reasonable for purposes of showing intractability, it is unrealistic for algorithmic considerations. In most real-world scenarios, it is impractical for the manipulators to have accurate knowledge of all the other votes. In this paper, we investigate manipulation with incomplete information. In our framework, the manipulators know a partial order for each voter that is consistent with the true preference of that voter. In this setting, we formulate three natural computational notions of manipulation, namely weak, opportunistic, and strong manipulation. We say that an extension of a partial order is if there exists a manipulative vote for that extension. 1. Weak Manipulation (WM): the manipulators seek to vote in a way that makes their preferred candidate win in at least one extension of the partial votes of the non-manipulators. 2. Opportunistic Manipulation (OM): the manipulators seek to vote in a way that makes their preferred candidate win in every viable extension of the partial votes of the non-manipulators. 3. Strong Manipulation (SM): the manipulators seek to vote in a way that makes their preferred candidate win in every extension of the partial votes of the non-manipulators. We consider several scenarios for which the traditional manipulation problems are easy (for instance, Borda with a single manipulator). For many of them, the corresponding manipulative questions that we propose turn out to be computationally intractable. Our hardness results often hold even when very little information is missing, or in other words, even when the instances are quite close to the complete information setting. version:2
