arxiv-1705-10826 | Minimizing the Cost of Team Exploration | http://arxiv.org/abs/1705.10826 | id:1705.10826 author:Dorota Urbańska-Osula category:cs.DM cs.DC math.CO  published:2017-05-30 summary:A group of mobile entities is given a task to explore an edge-weighted tree $T$, i.e. every vertex of $T$ has to be visited by at least one agent. There is no centralized unit to coordinate their actions, but they can freely communicate with each other and they know the structure of $T$ in advance. The goal is to construct a deterministic strategy which allows robots to complete their task optimally. In this paper we are interested in a cost-optimal strategy, where the cost is understood as the sum of the total distance traversed by agents and the cost of invoking them. We present an algorithm that finds an optimal solution for a given $n$-node tree in $O(n)$ time. version:1
arxiv-1705-10742 | Generating Steganographic Text with LSTMs | http://arxiv.org/abs/1705.10742 | id:1705.10742 author:Tina Fang, Martin Jaggi, Katerina Argyraki category:cs.AI cs.CR cs.MM E.3; I.2.7  published:2017-05-30 summary:Motivated by concerns for user privacy, we design a steganographic system ("stegosystem") that enables two users to exchange encrypted messages without an adversary detecting that such an exchange is taking place. We propose a new linguistic stegosystem based on a Long Short-Term Memory (LSTM) neural network. We demonstrate our approach on the Twitter and Enron email datasets and show that it yields high-quality steganographic text while significantly improving capacity (encrypted bits per word) relative to the state-of-the-art. version:1
arxiv-1705-10726 | Strength Factors: An Uncertainty System for a Quantified Modal Logic | http://arxiv.org/abs/1705.10726 | id:1705.10726 author:Naveen Sundar Govindarajulu, Selmer Bringsjord category:cs.AI  published:2017-05-30 summary:We present a new system S for handling uncertainty in a quantified modal logic (first-order modal logic). The system is based on both probability theory and proof theory. The system is derived from Chisholm's epistemology. We concretize Chisholm's system by grounding his undefined and primitive (i.e. foundational) concept of reasonablenes in probability and proof theory. S can be useful in systems that have to interact with humans and provide justifications for their uncertainty. As a demonstration of the system, we apply the system to provide a solution to the lottery paradox. Another advantage of the system is that it can be used to provide uncertainty values for counterfactual statements. Counterfactuals are statements that an agent knows for sure are false. Among other cases, counterfactuals are useful when systems have to explain their actions to users. Uncertainties for counterfactuals fall out naturally from our system. Efficient reasoning in just simple first-order logic is a hard problem. Resolution-based first-order reasoning systems have made significant progress over the last several decades in building systems that have solved non-trivial tasks (even unsolved conjectures in mathematics). We present a sketch of a novel algorithm for reasoning that extends first-order resolution. Finally, while there have been many systems of uncertainty for propositional logics, first-order logics and propositional modal logics, there has been very little work in building systems of uncertainty for first-order modal logics. The work described below is in progress; and once finished will address this lack. version:1
arxiv-1705-10720 | Low Impact Artificial Intelligences | http://arxiv.org/abs/1705.10720 | id:1705.10720 author:Stuart Armstrong, Benjamin Levinstein category:cs.AI  published:2017-05-30 summary:There are many goals for an AI that could become dangerous if the AI becomes superintelligent or otherwise powerful. Much work on the AI control problem has been focused on constructing AI goals that are safe even for such AIs. This paper looks at an alternative approach: defining a general concept of `low impact'. The aim is to ensure that a powerful AI which implements low impact will not modify the world extensively, even if it is given a simple or dangerous goal. The paper proposes various ways of defining and grounding low impact, and discusses methods for ensuring that the AI can still be allowed to have a (desired) impact despite the restriction. The end of the paper addresses known issues with this approach and avenues for future research. version:1
arxiv-1705-10664 | A Fast Stochastic Contact Model for Planar Pushing and Grasping: Theory and Experimental Validation | http://arxiv.org/abs/1705.10664 | id:1705.10664 author:Jiaji Zhou, J. Andrew Bagnell, Matthew T. Mason category:cs.RO  published:2017-05-30 summary:Based on the convex force-motion polynomial model for quasi-static sliding, we derive the kinematic contact model to determine the contact modes and instantaneous object motion on a supporting surface given a position controlled manipulator. The inherently stochastic object-to-surface friction distribution is modelled by sampling physically consistent parameters from appropriate distributions, with only one parameter to control the amount of noise. Thanks to the high fidelity and smoothness of convex polynomial models, the mechanics of patch contact is captured while being computationally efficient without mode selection at support points. The motion equations for both single and multiple frictional contacts are given. Simulation based on the model is validated with robotic pushing and grasping experiments. version:1
arxiv-1606-06570 | Metastability-Containing Circuits | http://arxiv.org/abs/1606.06570 | id:1606.06570 author:Stephan Friedrichs, Matthias Függer, Christoph Lenzen category:cs.DC  published:2016-06-21 summary:In digital circuits, metastability can cause deteriorated signals that neither are logical 0 or logical 1, breaking the abstraction of Boolean logic. Unfortunately, any way of reading a signal from an unsynchronized clock domain or performing an analog-to-digital conversion incurs the risk of a metastable upset; no digital circuit can deterministically avoid, resolve, or detect metastability (Marino, 1981). Synchronizers, the only traditional countermeasure, exponentially decrease the odds of maintained metastability over time. Trading synchronization delay for an increased probability to resolve metastability to logical 0 or 1, they do not guarantee success. We propose a fundamentally different approach: It is possible to contain metastability by fine-grained logical masking so that it cannot infect the entire circuit. This technique guarantees a limited degree of metastability in---and uncertainty about---the output. At the heart of our approach lies a time- and value-discrete model for metastability in synchronous clocked digital circuits. Metastability is propagated in a worst-case fashion, allowing to derive deterministic guarantees, without and unlike synchronizers. The proposed model permits positive results and passes the test of reproducing Marino's impossibility results. We fully classify which functions can be computed by circuits with standard registers. Regarding masking registers, we show that they become computationally strictly more powerful with each clock cycle, resulting in a non-trivial hierarchy of computable functions. version:7
arxiv-1705-10638 | A Receding Horizon Push Recovery Strategy for Balancing the iCub Humanoid Robot | http://arxiv.org/abs/1705.10638 | id:1705.10638 author:Stefano Dafarra, Francesco Romano, Francesco Nori category:cs.RO  published:2017-05-30 summary:Balancing and reacting to strong and unexpected pushes is a critical requirement for humanoid robots. We recently designed a capture point based approach which interfaces with a momentum-based torque controller and we implemented and validated it on the iCub humanoid robot. In this work we implement a Receding Horizon control, also known as Model Predictive Control, to add the possibility to predict the future evolution of the robot, especially the constraints switching given by the hybrid nature of the system. We prove that the proposed MPC extension makes the step-recovery controller more robust and reliable when executing the recovery strategy. Experiments in simulation show the results of the proposed approach. version:1
arxiv-1705-10579 | Torque-Controlled Stepping-Strategy Push Recovery: Design and Implementation on the iCub Humanoid Robot | http://arxiv.org/abs/1705.10579 | id:1705.10579 author:Stefano Dafarra, Francesco Romano, Francesco Nori category:cs.RO  published:2017-05-30 summary:One of the challenges for the robotics community is to deploy robots which can reliably operate in real world scenarios together with humans. A crucial requirement for legged robots is the capability to properly balance on their feet, rejecting external disturbances. iCub is a state-of-the-art humanoid robot which has only recently started to balance on its feet. While the current balancing controller has proved successful in various scenarios, it still misses the capability to properly react to strong pushes by taking steps. This paper goes in this direction. It proposes and implements a control strategy based on the Capture Point concept [1]. Instead of relying on position control, like most of Capture Point related approaches, the proposed strategy generates references for the momentum-based torque controller already implemented on the iCub, thus extending its capabilities to react to external disturbances, while retaining the advantages of torque control when interacting with the environment. Experiments in the Gazebo simulator and on the iCub humanoid robot validate the proposed strategy. version:1
arxiv-1705-10557 | Universal Reinforcement Learning Algorithms: Survey and Experiments | http://arxiv.org/abs/1705.10557 | id:1705.10557 author:John Aslanides, Jan Leike, Marcus Hutter category:cs.AI  published:2017-05-30 summary:Many state-of-the-art reinforcement learning (RL) algorithms typically assume that the environment is an ergodic Markov Decision Process (MDP). In contrast, the field of universal reinforcement learning (URL) is concerned with algorithms that make as few assumptions as possible about the environment. The universal Bayesian agent AIXI and a family of related URL algorithms have been developed in this setting. While numerous theoretical optimality results have been proven for these agents, there has been no empirical investigation of their behavior to date. We present a short and accessible survey of these URL algorithms under a unified notation and framework, along with results of some experiments that qualitatively illustrate some properties of the resulting policies, and their relative performance on partially-observable gridworld environments. We also present an open-source reference implementation of the algorithms which we hope will facilitate further understanding of, and experimentation with, these ideas. version:1
arxiv-1609-02584 | Towards Better Response Times and Higher-Quality Queries in Interactive Knowledge Base Debugging | http://arxiv.org/abs/1609.02584 | id:1609.02584 author:Patrick Rodler category:cs.AI  published:2016-09-08 summary:Many AI applications rely on knowledge encoded in a locigal knowledge base (KB). The most essential benefit of such logical KBs is the opportunity to perform automatic reasoning which however requires a KB to meet some minimal quality criteria such as consistency. Without adequate tool assistance, the task of resolving such violated quality criteria in a KB can be extremely hard, especially when the problematic KB is large and complex. To this end, interactive KB debuggers have been introduced which ask a user queries whether certain statements must or must not hold in the intended domain. The given answers help to gradually restrict the search space for KB repairs. Existing interactive debuggers often rely on a pool-based strategy for query computation. A pool of query candidates is precomputed, from which the best candidate according to some query quality criterion is selected to be shown to the user. This often leads to the generation of many unnecessary query candidates and thus to a high number of expensive calls to logical reasoning services. We tackle this issue by an in-depth mathematical analysis of diverse real-valued active learning query selection measures in order to determine qualitative criteria that make a query favorable. These criteria are the key to devising efficient heuristic query search methods. The proposed methods enable for the first time a completely reasoner-free query generation for interactive KB debugging while at the same time guaranteeing optimality conditions, e.g. minimal cardinality or best understandability for the user, of the generated query that existing methods cannot realize. Further, we study different relations between active learning measures. The obtained picture gives a hint about which measures are more favorable in which situation or which measures always lead to the same outcomes, based on given types of queries. version:2
arxiv-1705-10464 | Polynomial Codes: an Optimal Design for High-Dimensional Coded Matrix Multiplication | http://arxiv.org/abs/1705.10464 | id:1705.10464 author:Qian Yu, Mohammad Ali Maddah-Ali, A. Salman Avestimehr category:cs.IT cs.DC math.IT  published:2017-05-30 summary:We consider a large-scale matrix multiplication problem where the computation is carried out using a distributed system with a master node and multiple worker nodes, where each worker can store parts of the input matrices. We propose a computation strategy that leverages ideas from coding theory to design intermediate computations at the worker nodes, in order to efficiently deal with straggling workers. The proposed strategy, named as \emph{polynomial codes}, achieves the optimum recovery threshold, defined as the minimum number of workers that the master needs to wait for in order to compute the output. Furthermore, by leveraging the algebraic structure of polynomial codes, we can map the reconstruction problem of the final output to a polynomial interpolation problem, which can be solved efficiently. Polynomial codes provide order-wise improvement over the state of the art in terms of recovery threshold, and are also optimal in terms of several other metrics. Furthermore, we extend this code to distributed convolution and show its order-wise optimality. version:1
arxiv-1705-10443 | MOBA: a New Arena for Game AI | http://arxiv.org/abs/1705.10443 | id:1705.10443 author:Victor do Nascimento Silva, Luiz Chaimowicz category:cs.AI  published:2017-05-30 summary:Games have always been popular testbeds for Artificial Intelligence (AI). In the last decade, we have seen the rise of the Multiple Online Battle Arena (MOBA) games, which are the most played games nowadays. In spite of this, there are few works that explore MOBA as a testbed for AI Research. In this paper we present and discuss the main features and opportunities offered by MOBA games to Game AI Research. We describe the various challenges faced along the game and also propose a discrete model that can be used to better understand and explore the game. With this, we aim to encourage the use of MOBA as a novel research platform for Game AI. version:1
arxiv-1705-10432 | Fine-grained acceleration control for autonomous intersection management using deep reinforcement learning | http://arxiv.org/abs/1705.10432 | id:1705.10432 author:Hamid Mirzaei, Tony Givargis category:cs.AI cs.RO cs.SY  published:2017-05-30 summary:Recent advances in combining deep learning and Reinforcement Learning have shown a promising path for designing new control agents that can learn optimal policies for challenging control tasks. These new methods address the main limitations of conventional Reinforcement Learning methods such as customized feature engineering and small action/state space dimension requirements. In this paper, we leverage one of the state-of-the-art Reinforcement Learning methods, known as Trust Region Policy Optimization, to tackle intersection management for autonomous vehicles. We show that using this method, we can perform fine-grained acceleration control of autonomous vehicles in a grid street plan to achieve a global design objective. version:1
arxiv-1705-10387 | Good Things Come in LogLog(n)-Sized Packages: Robustness with Small Quorums | http://arxiv.org/abs/1705.10387 | id:1705.10387 author:Mercy O. Jaiyeola, Kyle Patron, Jared Saia, Maxwell Young, Qian M. Zhou category:cs.DS cs.DC  published:2017-05-29 summary:A popular technique for tolerating Byzantine faults in open distributed systems is to group machines into sets called quorums, each of which has an honest majority. These quorums are then used as basic building blocks to design systems that are robust to adversarial faults. Despite over a decade of active research, all current algorithms require quorum sizes of $\Omega(\log n)$, where $n$ is the number of machines in the network. This size is important since communication cost scales polynomially in the size of the quorum. Given the stubbornness of this $\Omega(\log n)$ barrier, a natural question is whether better bounds are possible. In this paper, we demonstrate that it is possible to reduce quorums sizes to $O(\log\log n)$, despite an adversary that controls a constant fraction of the computational resources in the network. In particular, we show that even with such small quorums, we can ensure that all but an $o(1)$-fraction of the machines can communicate with all but an $o(1)$-fraction of the machines in the network. version:1
arxiv-1705-10308 | Learning Belief Network Structure From Data under Causal Insufficiency | http://arxiv.org/abs/1705.10308 | id:1705.10308 author:Mieczysław Kłopotek category:cs.AI  published:2017-05-29 summary:Though a belief network (a representation of the joint probability distribution, see [3]) and a causal network (a representation of causal relationships [14]) are intended to mean different things, they are closely related. Both assume an underlying dag (directed acyclic graph) structure of relations among variables and if Markov condition and faithfulness condition [15] are met, then a causal network is in fact a belief network. The difference comes to appearance when we recover belief network and causal network structure from data. A causal network structure may be impossible to recover completely from data as not all directions of causal links may be uniquely determined [15]. Fortunately, if we deal with causally sufficient sets of variables (that is whenever significant influence variables are not omitted from observation), then there exists the possibility to identify the family of belief networks a causal network belongs to [16]. Regrettably, to our knowledge, a similar result is not directly known for causally insufficient sets of variables. Spirtes, Glymour and Scheines developed a CI algorithm to handle this situation, but it leaves some important questions open. The big open question is whether or not the bidirectional edges (that is indications of a common cause) are the only ones necessary to develop a belief network out of the product of CI, or must there be some other hidden variables added (e.g. by guessing). This paper is devoted to settling this question. version:1
arxiv-1705-10292 | Understanding Reduced-Voltage Operation in Modern DRAM Chips: Characterization, Analysis, and Mechanisms | http://arxiv.org/abs/1705.10292 | id:1705.10292 author:Kevin K. Chang, Abdullah Giray Yağlıkçı, Saugata Ghose, Aditya Agrawal, Niladrish Chatterjee, Abhijith Kashyap, Donghyuk Lee, Mike O'Connor, Hasan Hassan, Onur Mutlu category:cs.AR  published:2017-05-29 summary:The energy consumption of DRAM is a critical concern in modern computing systems. Improvements in manufacturing process technology have allowed DRAM vendors to lower the DRAM supply voltage conservatively, which reduces some of the DRAM energy consumption. We would like to reduce the DRAM supply voltage more aggressively, to further reduce energy. Aggressive supply voltage reduction requires a thorough understanding of the effect voltage scaling has on DRAM access latency and DRAM reliability. In this paper, we take a comprehensive approach to understanding and exploiting the latency and reliability characteristics of modern DRAM when the supply voltage is lowered below the nominal voltage level specified by DRAM standards. Using an FPGA-based testing platform, we perform an experimental study of 124 real DDR3L (low-voltage) DRAM chips manufactured recently by three major DRAM vendors. We find that reducing the supply voltage below a certain point introduces bit errors in the data, and we comprehensively characterize the behavior of these errors. We discover that these errors can be avoided by increasing the latency of three major DRAM operations (activation, restoration, and precharge). We perform detailed DRAM circuit simulations to validate and explain our experimental findings. We also characterize the various relationships between reduced supply voltage and error locations, stored data patterns, DRAM temperature, and data retention. Based on our observations, we propose a new DRAM energy reduction mechanism, called Voltron. The key idea of Voltron is to use a performance model to determine by how much we can reduce the supply voltage without introducing errors and without exceeding a user-specified threshold for performance loss. Voltron reduces the average system energy by 7.3% while limiting the average system performance loss to only 1.8%, for a variety of workloads. version:1
arxiv-1705-10259 | Distributed Communication-aware Motion Planning for Multi-agent Systems from STL and SpaTeL Specifications | http://arxiv.org/abs/1705.10259 | id:1705.10259 author:Zhiyu Liu, Bo Wu, Jin Dai, Hai Lin category:cs.MA cs.LO cs.RO cs.SY  published:2017-05-29 summary:In future intelligent transportation systems, networked vehicles coordinate with each other to achieve safe operations based on an assumption that communications among vehicles and infrastructure are reliable. Traditional methods usually deal with the design of control systems and communication networks in a separated manner. However, control and communication systems are tightly coupled as the motions of vehicles will affect the overall communication quality. Hence, we are motivated to study the co-design of both control and communication systems. In particular, we propose a control theoretical framework for distributed motion planning for multi-agent systems which satisfies complex and high-level spatial and temporal specifications while accounting for communication quality at the same time. Towards this end, desired motion specifications and communication performances are formulated as signal temporal logic (STL) and spatial-temporal logic (SpaTeL) formulas, respectively. The specifications are encoded as constraints on system and environment state variables of mixed integer linear programs (MILP), and upon which control strategies satisfying both STL and SpaTeL specifications are generated for each agent by employing a distributed model predictive control (MPC) framework. Effectiveness of the proposed framework is validated by a simulation of distributed communication-aware motion planning for multi-agent systems. version:1
arxiv-1705-10219 | Automatic White-Box Testing of First-Order Logic Ontologies | http://arxiv.org/abs/1705.10219 | id:1705.10219 author:Javier Álvez, Montserrat Hermo, Paqui Lucio, German Rigau category:cs.AI 68T30 I.2.4  published:2017-05-29 summary:A long-standing dream of Artificial Intelligence (AI) has pursued to encode commonsense knowledge into computer programs enabling machines to reason about our world and problems. This work offers a new practical insight towards the automatic testing of first-order logic (FOL) ontologies. We introduce a novel fully automatic white-box testing framework for first-order logic (FOL) ontologies. The application of the proposed testing method is fully automatic since a) the automated generation of tests is only guided by the syntax of axioms and b) the evaluation of tests is performed by automated theorem provers. Our proposal enables the detection of defective axioms and, additionally, it also serves to demonstrate the suitability for reasoning purposes of those formulas included into FOL ontologies. We validate our proposal by its practical application to different FOL ontologies. In particular, DOLCE ---consisting of around 200 axioms---, FPK (formal proof of the Kepler conjecture) ---which has been derived from the Flyspeck project for its use in the CADE ATP System Competition CASC-J8---, and Adimen-SUMO ---which is an ontology with more than 7,000 axioms derived from SUMO---. As result, we have detected several non-trivial defects that were hidden in those ontologies. Further, we have obtained an improved version of Adimen-SUMO (v2.6) by correcting all the defects detected during the practical application of our white-box testing method. version:1
arxiv-1705-10218 | Increasing the Efficiency of Sparse Matrix-Matrix Multiplication with a 2.5D Algorithm and One-Sided MPI | http://arxiv.org/abs/1705.10218 | id:1705.10218 author:Alfio Lazzaro, Joost VandeVondele, Juerg Hutter, Ole Schuett category:cs.DC cs.MS  published:2017-05-29 summary:Matrix-matrix multiplication is a basic operation in linear algebra and an essential building block for a wide range of algorithms in various scientific fields. Theory and implementation for the dense, square matrix case are well-developed. If matrices are sparse, with application-specific sparsity patterns, the optimal implementation remains an open question. Here, we explore the performance of communication reducing 2.5D algorithms and one-sided MPI communication in the context of linear scaling electronic structure theory. In particular, we extend the DBCSR sparse matrix library, which is the basic building block for linear scaling electronic structure theory and low scaling correlated methods in CP2K. The library is specifically designed to efficiently perform block-sparse matrix-matrix multiplication of matrices with a relatively large occupation. Here, we compare the performance of the original implementation based on Cannon's algorithm and MPI point-to-point communication, with an implementation based on MPI one-sided communications (RMA), in both a 2D and a 2.5D approach. The 2.5D approach trades memory and auxiliary operations for reduced communication, which can lead to a speedup if communication is dominant. The 2.5D algorithm is somewhat easier to implement with one-sided communications. A detailed description of the implementation is provided, also for non ideal processor topologies, since this is important for actual applications. Given the importance of the precise sparsity pattern, and even the actual matrix data, which decides the effective fill-in upon multiplication, the tests are performed within the CP2K package with application benchmarks. Results show a substantial boost in performance for the RMA based 2.5D algorithm, up to 1.80x, which is observed to increase with the number of involved processes in the parallelization. version:1
arxiv-1705-10217 | Black-box Testing of First-Order Logic Ontologies Using WordNet | http://arxiv.org/abs/1705.10217 | id:1705.10217 author:Javier Álvez, Paqui Lucio, German Rigau category:cs.AI 68T30 I.2.4  published:2017-05-29 summary:A long-standing dream of Artificial Intelligence (AI) has pursued to enrich computer programs with commonsense knowledge enabling machines to reason about our world. This paper offers a new practical insight towards the automation of commonsense reasoning with first-order logic (FOL) ontologies. We propose a new black-box testing methodology of FOL SUMO-based ontologies by exploiting WordNet and its mapping into SUMO. Our proposal includes a method for the (semi-)automatic creation of a very large set of tests and a procedure for its automated evaluation by using automated theorem provers (ATPs). Applying our testing proposal, we are able to successfully evaluate a) the competency of several translations of SUMO into FOL and b) the performance of various automated ATPs. In addition, we are also able to evaluate the resulting set of tests according to different quality criteria. version:1
arxiv-1609-04745 | A Portable, 3D-Printing Enabled Multi-Vehicle Platform for Robotics Research and Education | http://arxiv.org/abs/1609.04745 | id:1609.04745 author:Jingjin Yu, Shuai D Han, Wei N Tang, Daniela Rus category:cs.RO  published:2016-09-15 summary:microMVP is an affordable, portable, and open source micro-scale mobile robot platform designed for robotics research and education. As a complete and unique multi-vehicle platform enabled by 3D printing and the maker culture, microMVP can be easily reproduced and requires little maintenance: a set of six micro vehicles, each measuring $8\times 5\times 6$ cubic centimeters and weighing under $100$ grams, and the accompanying tracking platform can be fully assembled in under two hours, all from readily available components. In this paper, we describe microMVP's hardware and software architecture, and the design thoughts that go into the making of the platform. The capabilities of microMVP APIs are then demonstrated with several single- and multi-robot path and motion planning algorithms. microMVP supports all common operation systems. version:2
arxiv-1705-08245 | Enhanced Experience Replay Generation for Efficient Reinforcement Learning | http://arxiv.org/abs/1705.08245 | id:1705.08245 author:Vincent Huang, Tobias Ley, Martha Vlachou-Konchylaki, Wenfeng Hu category:cs.AI  published:2017-05-23 summary:Applying deep reinforcement learning (RL) on real systems suffers from slow data sampling. We propose an enhanced generative adversarial network (EGAN) to initialize an RL agent in order to achieve faster learning. The EGAN utilizes the relation between states and actions to enhance the quality of data samples generated by a GAN. Pre-training the agent with the EGAN shows a steeper learning curve with a 20% improvement of training time in the beginning of learning, compared to no pre-training, and an improvement compared to training with GAN by about 5% with smaller variations. For real time systems with sparse and slow data sampling the EGAN could be used to speed up the early phases of the training process. version:2
arxiv-1705-10208 | Dependency-Aware Rollback and Checkpoint-Restart for Distributed Task-Based Runtimes | http://arxiv.org/abs/1705.10208 | id:1705.10208 author:Kiril Dichev, Herbert Jordan, Konstantinos Tovletoglou, Thomas Heller, Dimitrios S. Nikolopoulos, Georgios Karakonstantis, Charles Gillan category:cs.DC  published:2017-05-29 summary:With the increase in compute nodes in large compute platforms, a proportional increase in node failures will follow. Many application-based checkpoint/restart (C/R) techniques have been proposed for MPI applications to target the reduced mean time between failures. However, rollback as part of the recovery remains a dominant cost even in highly optimised MPI applications employing C/R techniques. Continuing execution past a checkpoint (that is, reducing rollback) is possible in message-passing runtimes, but extremely complex to design and implement. Our work focuses on task-based runtimes, where task dependencies are explicit and message passing is implicit. We see an opportunity for reducing rollback for such runtimes: we explore task dependencies in the rollback, which we call dependency-aware rollback. We also design a new C/R technique, which is influenced by recursive decomposition of tasks, and combine it with dependency-aware rollback. We expect the dependency-aware rollback to cancel and recompute less tasks in the presence of node failures. We describe, implement and validate the proposed protocol in a simulator, which confirms these expectations. In addition, we consistently observe faster overall execution time for dependency-aware rollback in the presence of faults, despite the fact that reduced task cancellation does not guarantee reduced overall execution time. version:1
arxiv-1705-10201 | Machine Learned Learning Machines | http://arxiv.org/abs/1705.10201 | id:1705.10201 author:Leigh Sheneman, Arend Hintze category:cs.AI  published:2017-05-29 summary:There are two common approaches for optimizing the performance of a machine: genetic algorithms and machine learning. A genetic algorithm is applied over many generations whereas machine learning works by applying feedback until the system meets a performance threshold. Though these are methods that typically operate separately, we combine evolutionary adaptation and machine learning into one approach. Our focus is on machines that can learn during their lifetime, but instead of equipping them with a machine learning algorithm we aim to let them evolve their ability to learn by themselves. We use evolvable networks of probabilistic and deterministic logic gates, known as Markov Brains, as our computational model organism. The ability of Markov Brains to learn is augmented by a novel adaptive component that can change its computational behavior based on feedback. We show that Markov Brains can indeed evolve to incorporate these feedback gates to improve their adaptability to variable environments. By combining these two methods, we now also implemented a computational model that can be used to study the evolution of learning. version:1
arxiv-1705-10195 | Deterministic subgraph detection in broadcast CONGEST | http://arxiv.org/abs/1705.10195 | id:1705.10195 author:Janne H. Korhonen, Joel Rybicki category:cs.DC cs.DS  published:2017-05-29 summary:We present simple deterministic algorithms for subgraph finding and enumeration in the broadcast CONGEST model of distributed computation: -- For any constant $k$, detecting $k$-paths and trees on $k$ nodes can be done in constantly many rounds, and $k$-cycles in $O(n)$ rounds. -- On $d$-degenerate graphs, cliques and $4$-cycles can be enumerated in $O(d + \log n)$ rounds, and $5$-cycles in $O(d^2 + \log n)$ rounds. In many cases, these bounds are tight up to logarithmic factors. Moreover, we show that the algorithms for $d$-degenerate graphs can be improved to optimal complexity $O(d/\log n)$ and $O(d^2/\log n)$, respectively, in the supported CONGEST model, which can be seen as an intermediate model between CONGEST and the congested clique. version:1
arxiv-1705-10146 | Human-Robot Collaboration: From Psychology to Social Robotics | http://arxiv.org/abs/1705.10146 | id:1705.10146 author:Judith Bütepage, Danica Kragic category:cs.RO  published:2017-05-29 summary:With the advances in robotic technology, research in human-robot collaboration (HRC) has gained in importance. For robots to interact with humans autonomously they need active decision making that takes human partners into account. However, state-of-the-art research in HRC does often assume a leader-follower division, in which one agent leads the interaction. We believe that this is caused by the lack of a reliable representation of the human and the environment to allow autonomous decision making. This problem can be overcome by an embodied approach to HRC which is inspired by psychological studies of human-human interaction (HHI). In this survey, we review neuroscientific and psychological findings of the sensorimotor patterns that govern HHI and view them in a robotics context. Additionally, we study the advances made by the robotic community into the direction of embodied HRC. We focus on the mechanisms that are required for active, physical human-robot collaboration. Finally, we discuss the similarities and differences in the two fields of study which pinpoint directions of future research. version:1
arxiv-1705-10143 | Simplification of multibody models by parameter reduction | http://arxiv.org/abs/1705.10143 | id:1705.10143 author:Javier Ros, Xabier Iriarte, Aitor Plaza, Vicente Mata category:cs.RO  published:2017-05-29 summary:Model selection methods are used in different scientific contexts to represent a characteristic data set in terms of a reduced number of parameters. Apparently, these methods have not found their way into the literature on multibody systems dynamics. Multibody models can be considered parametric models in terms of their dynamic parameters, and model selection techniques can then be used to express these models in terms of a reduced number of parameters. These parameter-reduced models are expected to have a smaller computational complexity than the original one and still preserve the desired level of accuracy. They are also known to be good candidates for parameter estimation purposes. In this work, simulations of the actual model are used to define a data set that is representative of the system's standard working conditions. A parameter-reduced model is chosen and its parameter values estimated so that they minimize the prediction error on these data. To that end, model selection heuristics and normalized error measures are proposed. Using this methodology, two multibody systems with very different characteristic mobility are analyzed. Highly considerable reductions in the number of parameters and computational cost are obtained without compromising the accuracy of the reduced model too much. As an additional result, a generalization of the base parameter concept to the context of parameter-reduced models is proposed. version:1
arxiv-1609-06508 | Global Versus Local Computations: Fast Computing with Identifiers | http://arxiv.org/abs/1609.06508 | id:1609.06508 author:Rabie Mikaël category:cs.CC cs.DC  published:2016-09-21 summary:This paper studies what can be computed by using probabilistic local interactions with agents with a very restricted power in polylogarithmic parallel time. It is known that if agents are only finite state (corresponding to the Population Protocol model by Angluin et al.), then only semilinear predicates over the global input can be computed. In fact, if the population starts with a unique leader, these predicates can even be computed in a polylogarithmic parallel time. If identifiers are added (corresponding to the Community Protocol model by Guerraoui and Ruppert), then more global predicates over the input multiset can be computed. Local predicates over the input sorted according to the identifiers can also be computed, as long as the identifiers are ordered. The time of some of those predicates might require exponential parallel time. In this paper, we consider what can be computed with Community Protocol in a polylogarithmic number of parallel interactions. We introduce the class CPPL corresponding to protocols that use $O(n\log^k n)$, for some k, expected interactions to compute their predicates, or equivalently a polylogarithmic number of parallel expected interactions. We provide some computable protocols, some boundaries of the class, using the fact that the population can compute its size. We also prove two impossibility results providing some arguments showing that local computations are no longer easy: the population does not have the time to compare a linear number of consecutive identifiers. The Linearly Local languages, such that the rational language $(ab)^*$, are not computable. version:2
arxiv-1705-10092 | Role Playing Learning for Socially Concomitant Mobile Robot Navigation | http://arxiv.org/abs/1705.10092 | id:1705.10092 author:Mingming Li, Rui Jiang, Shuzhi Sam Ge, Tong Heng Lee category:cs.RO cs.AI  published:2017-05-29 summary:In this paper, we present the Role Playing Learning (RPL) scheme for a mobile robot to navigate socially with its human companion in populated environments. Neural networks (NN) are constructed to parameterize a stochastic policy that directly maps sensory data collected by the robot to its velocity outputs, while respecting a set of social norms. An efficient simulative learning environment is built with maps and pedestrians trajectories collected from a number of real-world crowd data sets. In each learning iteration, a robot equipped with the NN policy is created virtually in the learning environment to play itself as a companied pedestrian and navigate towards a goal in a socially concomitant manner. Thus, we call this process Role Playing Learning, which is formulated under a reinforcement learning (RL) framework. The NN policy is optimized end-to-end using Trust Region Policy Optimization (TRPO), with consideration of the imperfectness of robot's sensor measurements. Simulative and experimental results are provided to demonstrate the efficacy and superiority of our method. version:1
arxiv-1705-10633 | Distributed Matrix Factorization using Asynchrounous Communication | http://arxiv.org/abs/1705.10633 | id:1705.10633 author:Tom Vander Aa, Imen Chakroun, Tom Haber category:cs.DC  published:2017-05-29 summary:Using the matrix factorization technique in machine learning is very common mainly in areas like recommender systems. Despite its high prediction accuracy and its ability to avoid over-fitting of the data, the Bayesian Probabilistic Matrix Factorization algorithm (BPMF) has not been widely used on large scale data because of the prohibitive cost. In this paper, we propose a distributed high-performance parallel implementation of the BPMF using Gibbs sampling on shared and distributed architectures. We show by using efficient load balancing using work stealing on a single node, and by using asynchronous communication in the distributed version we beat state of the art implementations. version:1
arxiv-1610-01495 | The Static Center of Pressure Sensitivity: a further Criterion to assess Contact Stability and Balancing Controllers | http://arxiv.org/abs/1610.01495 | id:1610.01495 author:Francesco Romano, Daniele Pucci, Silvio Traversaro, Francesco Nori category:cs.RO math.OC  published:2016-10-05 summary:Legged locomotion has received increasing attention from the robotics community. In this respect, contact stability plays a critical role in ensuring that robots maintain balance, and it is a key element for balancing and walking controllers. The Center of Pressure is a contact stability criterion that defines a point that must be kept strictly inside the support polygon in order to ensure postural stability. In this paper, we introduce the concept of the sensitivity of the static center of pressure: roughly speaking, the rate of change of the center of pressure with respect to the system equilibrium configurations. This new concept can be used as an additional criterion to assess the robustness of the contact stability. We show how the sensitivity of the center of pressure can also be used as a metric to assess balancing controllers by considering two state-of-the-art control strategies. The analytical analysis is performed on a simplified model, and validated during balancing tasks on the iCub humanoid robot. version:2
arxiv-1705-09990 | Should Robots be Obedient? | http://arxiv.org/abs/1705.09990 | id:1705.09990 author:Smitha Milli, Dylan Hadfield-Menell, Anca Dragan, Stuart Russell category:cs.AI  published:2017-05-28 summary:Intuitively, obedience -- following the order that a human gives -- seems like a good property for a robot to have. But, we humans are not perfect and we may give orders that are not best aligned to our preferences. We show that when a human is not perfectly rational then a robot that tries to infer and act according to the human's underlying preferences can always perform better than a robot that simply follows the human's literal order. Thus, there is a tradeoff between the obedience of a robot and the value it can attain for its owner. We investigate how this tradeoff is impacted by the way the robot infers the human's preferences, showing that some methods err more on the side of obedience than others. We then analyze how performance degrades when the robot has a misspecified model of the features that the human cares about or the level of rationality of the human. Finally, we study how robots can start detecting such model misspecification. Overall, our work suggests that there might be a middle ground in which robots intelligently decide when to obey human orders, but err on the side of obedience. version:1
arxiv-1705-09937 | Sparse Matrix Multiplication on CAM Based Accelerator | http://arxiv.org/abs/1705.09937 | id:1705.09937 author:Leonid Yavits, Ran Ginosar category:cs.AR  published:2017-05-28 summary:Sparse matrix multiplication is an important component of linear algebra computations. In this paper, an architecture based on Content Addressable Memory (CAM) and Resistive Content Addressable Memory (ReCAM) is proposed for accelerating sparse matrix by sparse vector and matrix multiplication in CSR format. Using functional simulation, we show that the proposed ReCAM-based accelerator exhibits two orders of magnitude higher power efficiency as compared to existing sparse matrix-vector multiplication implementations. version:1
arxiv-1705-09927 | Fully distributed PageRank computation with exponential convergence | http://arxiv.org/abs/1705.09927 | id:1705.09927 author:Liang Dai, Nikolaos M. Freris category:cs.DC cs.SY  published:2017-05-28 summary:This work studies a fully distributed algorithm for computing the PageRank vector, which is inspired by the Matching Pursuit and features: 1) fully distributed 2) expected converges with exponential rate 3) low storage requirement (two scalar values per page). Illustrative experiments are conducted to verify the findings. version:1
arxiv-1703-01908 | A proposal for ethically traceable artificial intelligence | http://arxiv.org/abs/1703.01908 | id:1703.01908 author:Christopher A. Tucker category:cs.AI  published:2017-03-06 summary:Although the problem of a critique of robotic behavior in near-unanimous agreement to human norms seems intractable, a starting point of such an ambition is a framework of the collection of knowledge a priori and experience a posteriori categorized as a set of synthetical judgments available to the intelligence, translated into computer code. If such a proposal were successful, an algorithm with ethically traceable behavior and cogent equivalence to human cognition is established. This paper will propose the application of Kant's critique of reason to current programming constructs of an autonomous intelligent system. version:2
arxiv-1705-09905 | A Unified Optimization Approach for Sparse Tensor Operations on GPUs | http://arxiv.org/abs/1705.09905 | id:1705.09905 author:Bangtian Liu, Chengyao Wen, Anand D. Sarwate, Maryam Mehri Dehnavi category:cs.MS cs.DC  published:2017-05-28 summary:Sparse tensors appear in many large-scale applications with multidimensional and sparse data. While multidimensional sparse data often need to be processed on manycore processors, attempts to develop highly-optimized GPU-based implementations of sparse tensor operations are rare. The irregular computation patterns and sparsity structures as well as the large memory footprints of sparse tensor operations make such implementations challenging. We leverage the fact that sparse tensor operations share similar computation patterns to propose a unified tensor representation called F-COO. Combined with GPU-specific optimizations, F-COO provides highly-optimized implementations of sparse tensor computations on GPUs. The performance of the proposed unified approach is demonstrated for tensor-based kernels such as the Sparse Matricized Tensor- Times-Khatri-Rao Product (SpMTTKRP) and the Sparse Tensor- Times-Matrix Multiply (SpTTM) and is used in tensor decomposition algorithms. Compared to state-of-the-art work we improve the performance of SpTTM and SpMTTKRP up to 3.7 and 30.6 times respectively on NVIDIA Titan-X GPUs. We implement a CANDECOMP/PARAFAC (CP) decomposition and achieve up to 14.9 times speedup using the unified method over state-of-the-art libraries on NVIDIA Titan-X GPUs. version:1
arxiv-1705-09890 | Minimally Actuated Serial Robot | http://arxiv.org/abs/1705.09890 | id:1705.09890 author:Moshe P. Mann, Lior Damti, David Zarrouk category:cs.RO  published:2017-05-28 summary:In this paper, we propose a novel type of serial robot with minimal actuation. The robot is a serial rigid structure consisting of multiple links connected by passive joints and of movable actuators. The novelty of this robot is that the actuators travel over the links to a given joint and adjust the relative angle between the two adjacent links. The joints passively preserve their angles until one of the actuators moves them again. This actuation can be applied to any serial robot with two or more links. This unique configuration enables the robot to undergo the same wide range of motions typically associated with hyper-redundant robots but with much fewer actuators. The robot is modular and its size and geometry can be easily changed. We describe the robot's mechanical design and kinematics in detail and demonstrate its capabilities for obstacle avoidance with some simulated examples. In addition, we show how an experimental robot fitted with a single mobile actuator can maneuver through a confined space to reach its target. version:1
arxiv-1611-09490 | Generalized Shared Control versus Classical Shared Control: Illustrative Examples | http://arxiv.org/abs/1611.09490 | id:1611.09490 author:Pete Trautman category:cs.RO  published:2016-11-29 summary:Shared control fuses operator inputs and autonomy inputs into a single command. However, if environmental or operator predictions are multimodal, state of the art approaches are suboptimal with respect to safety, efficiency, and operator-autonomy agreement: even under mildly challenging conditions, existing approaches can fuse two safe inputs into an unsafe shared control [13]. Multi-modal conditions are common to many real world applications, such as search and rescue robots navigating disaster zones, teleoperated robots facing communication degradation, and assistive driving technologies. In [11, 13], we introduced a novel approach called generalized shared control (GSC) that simultaneously optimizes autonomy objectives (e.g., safety and efficiency) and operator-autonomy agreement under multimodal conditions; this optimality prevents such unsafe shared control. In this paper, we describe those results in more user friendly language by using illustrations and text. version:2
arxiv-1701-00287 | STRIPS Planning in Infinite Domains | http://arxiv.org/abs/1701.00287 | id:1701.00287 author:Caelan Reed Garrett, Tomás Lozano-Pérez, Leslie Pack Kaelbling category:cs.AI  published:2017-01-01 summary:Many robotic planning applications involve continuous actions with highly non-linear constraints, which cannot be modeled using modern planners that construct a propositional representation. We introduce STRIPStream: an extension of the STRIPS language which can model these domains by supporting the specification of blackbox generators to handle complex constraints. The outputs of these generators interact with actions through possibly infinite streams of objects and static predicates. We provide two algorithms which both reduce STRIPStream problems to a sequence of finite-domain planning problems. The representation and algorithms are entirely domain independent. We demonstrate our framework on simple illustrative domains, and then on a high-dimensional, continuous robotic task and motion planning domain. version:2
arxiv-1705-09879 | Inexpensive Cost-Optimized Measurement Proposal for Sequential Model-Based Diagnosis | http://arxiv.org/abs/1705.09879 | id:1705.09879 author:Patrick Rodler, Wolfgang Schmid, Konstantin Schekotihin category:cs.AI  published:2017-05-28 summary:In this work we present strategies for (optimal) measurement selection in model-based sequential diagnosis. In particular, assuming a set of leading diagnoses being given, we show how queries (sets of measurements) can be computed and optimized along two dimensions: expected number of queries and cost per query. By means of a suitable decoupling of two optimizations and a clever search space reduction the computations are done without any inference engine calls. For the full search space, we give a method requiring only a polynomial number of inferences and guaranteeing query properties existing methods cannot provide. Evaluation results using real-world problems indicate that the new method computes (virtually) optimal queries instantly independently of the size and complexity of the considered diagnosis problems. version:1
arxiv-1705-09844 | Quadratic Unconstrained Binary Optimization Problem Preprocessing: Theory and Empirical Analysis | http://arxiv.org/abs/1705.09844 | id:1705.09844 author:Mark Lewis, Fred Glover category:cs.AI  published:2017-05-27 summary:The Quadratic Unconstrained Binary Optimization problem (QUBO) has become a unifying model for representing a wide range of combinatorial optimization problems, and for linking a variety of disciplines that face these problems. A new class of quantum annealing computer that maps QUBO onto a physical qubit network structure with specific size and edge density restrictions is generating a growing interest in ways to transform the underlying QUBO structure into an equivalent graph having fewer nodes and edges. In this paper we present rules for reducing the size of the QUBO matrix by identifying variables whose value at optimality can be predetermined. We verify that the reductions improve both solution quality and time to solution and, in the case of metaheuristic methods where optimal solutions cannot be guaranteed, the quality of solutions obtained within reasonable time limits. We discuss the general QUBO structural characteristics that can take advantage of these reduction techniques and perform careful experimental design and analysis to identify and quantify the specific characteristics most affecting reduction. The rules make it possible to dramatically improve solution times on a new set of problems using both the exact Cplex solver and a tabu search metaheuristic. version:1
arxiv-1705-10313 | Fast Trajectory Optimization for Legged Robots using Vertex-based ZMP Constraints | http://arxiv.org/abs/1705.10313 | id:1705.10313 author:Alexander W Winkler, Farbod Farshidian, Diego Pardo, Michael Neunert, Jonas Buchli category:cs.RO math.OC  published:2017-05-27 summary:This paper combines the fast Zero-Moment-Point (ZMP) approaches that work well in practice with the broader range of capabilities of a Trajectory Optimization formulation, by optimizing over body motion, footholds and Center of Pressure simultaneously. We introduce a vertex-based representation of the support-area constraint, which can treat arbitrarily oriented point-, line-, and area-contacts uniformly. This generalization allows us to create motions such quadrupedal walking, trotting, bounding, pacing, combinations and transitions between these, limping, bipedal walking and push-recovery all with the same approach. This formulation constitutes a minimal representation of the physical laws (unilateral contact forces) and kinematic restrictions (range of motion) in legged locomotion, which allows us to generate various motion in less than a second. We demonstrate the feasibility of the generated motions on a real quadruped robot. version:1
arxiv-1705-09811 | Multi-shot ASP solving with clingo | http://arxiv.org/abs/1705.09811 | id:1705.09811 author:Martin Gebser, Roland Kaminski, Benjamin Kaufmann, Torsten Schaub category:cs.AI D.1.6  published:2017-05-27 summary:We introduce a new flexible paradigm of grounding and solving in Answer Set Programming (ASP), which we refer to as multi-shot ASP solving, and present its implementation in the ASP system clingo. Multi-shot ASP solving features grounding and solving processes that deal with continuously changing logic programs. In doing so, they remain operative and accommodate changes in a seamless way. For instance, such processes allow for advanced forms of search, as in optimization or theory solving, or interaction with an environment, as in robotics or query-answering. Common to them is that the problem specification evolves during the reasoning process, either because data or constraints are added, deleted, or replaced. This evolutionary aspect adds another dimension to ASP since it brings about state changing operations. We address this issue by providing an operational semantics that characterizes grounding and solving processes in multi-shot ASP solving. This characterization provides a semantic account of grounder and solver states along with the operations manipulating them. The operative nature of multi-shot solving avoids redundancies in relaunching grounder and solver programs and benefits from the solver's learning capacities. clingo accomplishes this by complementing ASP's declarative input language with control capacities. On the declarative side, a new directive allows for structuring logic programs into named and parameterizable subprograms. The grounding and integration of these subprograms into the solving process is completely modular and fully controllable from the procedural side. To this end, clingo offers a new application programming interface that is conveniently accessible via scripting languages. version:1
arxiv-1705-09798 | Spreading a Confirmed Rumor: A Case for Oscillatory Dynamics | http://arxiv.org/abs/1705.09798 | id:1705.09798 author:Bartlomiej Dudek, Adrian Kosowski category:cs.DS cs.DC math.DS  published:2017-05-27 summary:We consider an information spreading problem in which a population of $n$ agents is to determine, through random pairwise interactions, whether an authoritative rumor source $X$ is present in the population or not. The studied problem is a generalization of the rumor spreading problem, in which we additionally impose that the rumor should disappear when the rumor source no longer exists. It is also a generalization of the self-stabilizing broadcasting problem and has direct application to amplifying trace concentrations in chemical reaction networks.We show that there exists a protocol such that, starting from any possible initial state configuration, in the absence of a rumor source all agents reach a designated "uninformed" state after $O(\log^2 n)$ rounds w.h.p., whereas in the presence of the rumor source, at any time after at least $O(\log n)$ rounds from the moment $X$ appears, at least $(1 -\varepsilon)n$ agents are in an "informed" state with probability $1 - O(1/n)$, where $\varepsilon>0$ may be arbitrarily fixed. The protocol uses a constant number of states and its operation relies on an underlying oscillatory dynamics with a closed limit orbit. On the negative side, we show that any system which has such an ability to "suppress false rumors" in sub-polynomial time must either exhibit significant and perpetual variations of opinion over time in the presence of the rumor source, or use a super-constant number of states. version:1
arxiv-1705-02955 | Safe and Nested Subgame Solving for Imperfect-Information Games | http://arxiv.org/abs/1705.02955 | id:1705.02955 author:Noam Brown, Tuomas Sandholm category:cs.AI cs.GT  published:2017-05-08 summary:Unlike perfect-information games, imperfect-information games cannot be solved by decomposing the game into subgames that are solved independently. Instead, all decisions must consider the strategy of the game as a whole. While it is not possible to solve an imperfect-information game exactly through decomposition, it is possible to approximate solutions, or improve existing strategies, by solving disjoint subgames. This process is referred to as subgame solving. We introduce subgame solving techniques that outperform prior methods both in theory and practice. We also show how to adapt them, and past subgame solving techniques, to respond to opponent actions that are outside the original action abstraction; this significantly outperforms the prior state-of-the-art approach, action translation. Finally, we show that subgame solving can be repeated as the game progresses down the tree, leading to lower exploitability. Subgame solving is a key component of Libratus, the first AI to defeat top humans in heads-up no-limit Texas hold'em poker. version:2
arxiv-1706-02621 | Design and Implementation of Modified Fuzzy based CPU Scheduling Algorithm | http://arxiv.org/abs/1706.02621 | id:1706.02621 author:Rajani Kumari, Vivek Kumar Sharma, Sandeep Kumar category:cs.OS cs.AI  published:2017-05-26 summary:CPU Scheduling is the base of multiprogramming. Scheduling is a process which decides order of task from a set of multiple tasks that are ready to execute. There are number of CPU scheduling algorithms available, but it is very difficult task to decide which one is better. This paper discusses the design and implementation of modified fuzzy based CPU scheduling algorithm. This paper present a new set of fuzzy rules. It demonstrates that scheduling done with new priority improves average waiting time and average turnaround time. version:1
arxiv-1705-09609 | Gossip in a Smartphone Peer-to-Peer Network | http://arxiv.org/abs/1705.09609 | id:1705.09609 author:Calvin Newport category:cs.DS cs.DC  published:2017-05-26 summary:In this paper, we study the fundamental problem of gossip in the mobile telephone model: a recently introduced variation of the classical telephone model modified to better describe the local peer-to-peer communication services implemented in many popular smartphone operating systems. In more detail, the mobile telephone model differs from the classical telephone model in three ways: (1) each device can participate in at most one connection per round; (2) the network topology can undergo a parameterized rate of change; and (3) devices can advertise a parameterized number of bits about their state to their neighbors in each round before connection attempts are initiated. We begin by describing and analyzing new randomized gossip algorithms in this model under the harsh assumption of a network topology that can change completely in every round. We prove a significant time complexity gap between the case where nodes can advertise $0$ bits to their neighbors in each round, and the case where nodes can advertise $1$ bit. For the latter assumption, we present two solutions: the first depends on a shared randomness source, while the second eliminates this assumption using a pseudorandomness generator we prove to exist with a novel generalization of a classical result from the study of two-party communication complexity. We then turn our attention to the easier case where the topology graph is stable, and describe and analyze a new gossip algorithm that provides a substantial performance improvement for many parameters. We conclude by studying a relaxed version of gossip in which it is only necessary for nodes to each learn a specified fraction of the messages in the system. version:1
arxiv-1607-01341 | Algorand | http://arxiv.org/abs/1607.01341 | id:1607.01341 author:Jing Chen, Silvio Micali category:cs.CR cs.DC  published:2016-07-05 summary:A public ledger is a tamperproof sequence of data that can be read and augmented by everyone. Public ledgers have innumerable and compelling uses. They can secure, in plain sight, all kinds of transactions ---such as titles, sales, and payments--- in the exact order in which they occur. Public ledgers not only curb corruption, but also enable very sophisticated applications ---such as cryptocurrencies and smart contracts. They stand to revolutionize the way a democratic society operates. As currently implemented, however, they scale poorly and cannot achieve their potential. Algorand is a truly democratic and efficient way to implement a public ledger. Unlike prior implementations based on proof of work, it requires a negligible amount of computation, and generates a transaction history that will not "fork" with overwhelmingly high probability. Algorand is based on (a novel and super fast) message-passing Byzantine agreement. For concreteness, we shall describe Algorand only as a money platform. version:9
arxiv-1705-09566 | Rational Fair Consensus in the GOSSIP Model | http://arxiv.org/abs/1705.09566 | id:1705.09566 author:Andrea Clementi, Luciano Gualà, Guido Proietti, Giacomo Scornavacca category:cs.GT cs.DC 68W15  91A06 F.2  published:2017-05-26 summary:The \emph{rational fair consensus problem} can be informally defined as follows. Consider a network of $n$ (selfish) \emph{rational agents}, each of them initially supporting a \emph{color} chosen from a finite set $ \Sigma$. The goal is to design a protocol that leads the network to a stable monochromatic configuration (i.e. a consensus) such that the probability that the winning color is $c$ is equal to the fraction of the agents that initially support $c$, for any $c \in \Sigma$. Furthermore, this fairness property must be guaranteed (with high probability) even in presence of any fixed \emph{coalition} of rational agents that may deviate from the protocol in order to increase the winning probability of their supported colors. A protocol having this property, in presence of coalitions of size at most $t$, is said to be a \emph{whp\,-$t$-strong equilibrium}. We investigate, for the first time, the rational fair consensus problem in the GOSSIP communication model where, at every round, every agent can actively contact at most one neighbor via a \emph{push$/$pull} operation. We provide a randomized GOSSIP protocol that, starting from any initial color configuration of the complete graph, achieves rational fair consensus within $O(\log n)$ rounds using messages of $O(\log^2n)$ size, w.h.p. More in details, we prove that our protocol is a whp\,-$t$-strong equilibrium for any $t = o(n/\log n)$ and, moreover, it tolerates worst-case permanent faults provided that the number of non-faulty agents is $\Omega(n)$. As far as we know, our protocol is the first solution which avoids any all-to-all communication, thus resulting in $o(n^2)$ message complexity. version:1
arxiv-1705-09545 | Logical and Inequality Implications for Reducing the Size and Complexity of Quadratic Unconstrained Binary Optimization Problems | http://arxiv.org/abs/1705.09545 | id:1705.09545 author:Fred Glover, Mark Lewis, Gary Kochenberger category:cs.AI  published:2017-05-26 summary:The quadratic unconstrained binary optimization (QUBO) problem arises in diverse optimization applications ranging from Ising spin problems to classical problems in graph theory and binary discrete optimization. The use of preprocessing to transform the graph representing the QUBO problem into a smaller equivalent graph is important for improving solution quality and time for both exact and metaheuristic algorithms and is a step towards mapping large scale QUBO to hardware graphs used in quantum annealing computers. In an earlier paper (Lewis and Glover, 2016) a set of rules was introduced that achieved significant QUBO reductions as verified through computational testing. Here this work is extended with additional rules that provide further reductions that succeed in exactly solving 10% of the benchmark QUBO problems. An algorithm and associated data structures to efficiently implement the entire set of rules is detailed and computational experiments are reported that demonstrate their efficacy. version:1
arxiv-1604-04180 | Job Selection in a Network of Autonomous UAVs for Delivery of Goods | http://arxiv.org/abs/1604.04180 | id:1604.04180 author:Pasquale Grippa, Doris A. Behrens, Christian Bettstetter, Friederike Wall category:cs.MA cs.RO  published:2016-04-14 summary:This article analyzes two classes of job selection policies that control how a network of autonomous aerial vehicles delivers goods from depots to customers. Customer requests (jobs) occur according to a spatio-temporal stochastic process not known by the system. If job selection uses a policy in which the first job (FJ) is served first, the system may collapse to instability by removing just one vehicle. Policies that serve the nearest job (NJ) first show such threshold behavior only in some settings and can be implemented in a distributed manner. The timing of job selection has significant impact on delivery time and stability for NJ while it has no impact for FJ. Based on these findings we introduce a methodological approach for decision-making support to set up and operate such a system, taking into account the trade-off between monetary cost and service quality. In particular, we compute a lower bound for the infrastructure expenditure required to achieve a certain expected delivery time. The approach includes three time horizons: long-term decisions on the number of depots to deploy in the service area, mid-term decisions on the number of vehicles to use, and short-term decisions on the policy to operate the vehicles. version:2
arxiv-1705-09400 | Regrasp Planning using 10,000s of Grasps | http://arxiv.org/abs/1705.09400 | id:1705.09400 author:Weiwei Wan, Kensuke Harada category:cs.RO  published:2017-05-26 summary:This paper develops intelligent algorithms for robots to reorient objects. Given the initial and goal poses of an object, the proposed algorithms plan a sequence of robot poses and grasp configurations that reorient the object from its initial pose to the goal. While the topic has been studied extensively in previous work, this paper makes important improvements in grasp planning by using over-segmented meshes, in data storage by using relational database, and in regrasp planning by mixing real-world roadmaps. The improvements enable robots to do robust regrasp planning using 10,000s of grasps and their relationships in interactive time. The proposed algorithms are validated using various objects and robots. version:1
arxiv-1705-09382 | Distributed Robust Subspace Recovery | http://arxiv.org/abs/1705.09382 | id:1705.09382 author:Vahan Huroyan, Gilad Lerman category:math.NA cs.AI cs.DC cs.NA  published:2017-05-25 summary:We study Robust Subspace Recovery (RSR) in distributed settings. We consider a huge data set in an ad hoc network without a central processor, where each node has access only to one chunk of the data set. We assume that part of the whole data set lies around a low-dimensional subspace and the other part is composed of outliers that lie away from that subspace. The goal is to recover the underlying subspace for the whole data set, without transferring the data itself between the nodes. We apply the Consensus Based Gradient method for the Geometric Median Subspace algorithm for RSR. We propose an iterative solution for the local dual minimization problem and establish its $r$-linear convergence. We show that this mathematical framework also extends to two simpler problems: Principal Component Analysis and the geometric median. We also explain how to distributedly implement the Reaper and Fast Median Subspace algorithms for RSR. We demonstrate the competitive performance of our algorithms for both synthetic and real data. version:1
arxiv-1611-05973 | NCBO Ontology Recommender 2.0: An Enhanced Approach for Biomedical Ontology Recommendation | http://arxiv.org/abs/1611.05973 | id:1611.05973 author:Marcos Martinez-Romero, Clement Jonquet, Martin J. O'Connor, John Graybeal, Alejandro Pazos, Mark A. Musen category:cs.AI cs.IR I.2.4  published:2016-11-18 summary:Biomedical researchers use ontologies to annotate their data with ontology terms, enabling better data integration and interoperability. However, the number, variety and complexity of current biomedical ontologies make it cumbersome for researchers to determine which ones to reuse for their specific needs. To overcome this problem, in 2010 the National Center for Biomedical Ontology (NCBO) released the Ontology Recommender, which is a service that receives a biomedical text corpus or a list of keywords and suggests ontologies appropriate for referencing the indicated terms. We developed a new version of the NCBO Ontology Recommender. Called Ontology Recommender 2.0, it uses a new recommendation approach that evaluates the relevance of an ontology to biomedical text data according to four criteria: (1) the extent to which the ontology covers the input data; (2) the acceptance of the ontology in the biomedical community; (3) the level of detail of the ontology classes that cover the input data; and (4) the specialization of the ontology to the domain of the input data. Our evaluation shows that the enhanced recommender provides higher quality suggestions than the original approach, providing better coverage of the input data, more detailed information about their concepts, increased specialization for the domain of the input data, and greater acceptance and use in the community. In addition, it provides users with more explanatory information, along with suggestions of not only individual ontologies but also groups of ontologies. It also can be customized to fit the needs of different scenarios. Ontology Recommender 2.0 combines the strengths of its predecessor with a range of adjustments and new features that improve its reliability and usefulness. Ontology Recommender 2.0 recommends over 500 biomedical ontologies from the NCBO BioPortal platform, where it is openly available. version:2
arxiv-1705-09366 | Parallel Space-Time Kernel Density Estimation | http://arxiv.org/abs/1705.09366 | id:1705.09366 author:Erik Saule, Dinesh Panchananam, Alexander Hohl, Wenwu Tang, Eric Delmelle category:cs.DC  published:2017-05-25 summary:The exponential growth of available data has increased the need for interactive exploratory analysis. Dataset can no longer be understood through manual crawling and simple statistics. In Geographical Information Systems (GIS), the dataset is often composed of events localized in space and time; and visualizing such a dataset involves building a map of where the events occurred. We focus in this paper on events that are localized among three dimensions (latitude, longitude, and time), and on computing the first step of the visualization pipeline, space-time kernel density estimation (STKDE), which is most computationally expensive. Starting from a gold standard implementation, we show how algorithm design and engineering, parallel decomposition, and scheduling can be applied to bring near real-time computing to space-time kernel density estimation. We validate our techniques on real world datasets extracted from infectious disease, social media, and ornithology. version:1
arxiv-1705-09358 | Shared Memory Parallel Subgraph Enumeration | http://arxiv.org/abs/1705.09358 | id:1705.09358 author:Raphael Kimmig, Henning Meyerhenke, Darren Strash category:cs.DC cs.DS F.2.2; G.2.2  published:2017-05-25 summary:The subgraph enumeration problem asks us to find all subgraphs of a target graph that are isomorphic to a given pattern graph. Determining whether even one such isomorphic subgraph exists is NP-complete---and therefore finding all such subgraphs (if they exist) is a time-consuming task. Subgraph enumeration has applications in many fields, including biochemistry and social networks, and interestingly the fastest algorithms for solving the problem for biochemical inputs are sequential. Since they depend on depth-first tree traversal, an efficient parallelization is far from trivial. Nevertheless, since important applications produce data sets with increasing difficulty, parallelism seems beneficial. We thus present here a shared-memory parallelization of the state-of-the-art subgraph enumeration algorithms RI and RI-DS (a variant of RI for dense graphs) by Bonnici et al. [BMC Bioinformatics, 2013]. Our strategy uses work stealing and our implementation demonstrates a significant speedup on real-world biochemical data---despite a highly irregular data access pattern. We also improve RI-DS by pruning the search space better; this further improves the empirical running times compared to the already highly tuned RI-DS. version:1
arxiv-1705-09328 | Operation Frames and Clubs in Kidney Exchange | http://arxiv.org/abs/1705.09328 | id:1705.09328 author:Gabriele Farina, John P. Dickerson, Tuomas Sandholm category:cs.GT cs.AI  published:2017-05-25 summary:A kidney exchange is a centrally-administered barter market where patients swap their willing yet incompatible donors. Modern kidney exchanges use 2-cycles, 3-cycles, and chains initiated by non-directed donors (altruists who are willing to give a kidney to anyone) as the means for swapping. We propose significant generalizations to kidney exchange. We allow more than one donor to donate in exchange for their desired patient receiving a kidney. We also allow for the possibility of a donor willing to donate if any of a number of patients receive kidneys. Furthermore, we combine these notions and generalize them. The generalization is to exchange among organ clubs, where a club is willing to donate organs outside the club if and only if the club receives organs from outside the club according to given specifications. We prove that unlike in the standard model, the uncapped clearing problem is NP-complete. We also present the notion of operation frames that can be used to sequence the operations across batches, and present integer programming formulations for the market clearing problems for these new types of organ exchanges. Experiments show that in the single-donation setting, operation frames improve planning by 34%--51%. Allowing up to two donors to donate in exchange for one kidney donated to their designated patient yields a further increase in social welfare. version:1
arxiv-1705-09617 | Distributed Dominating Set Approximations beyond Planar Graphs | http://arxiv.org/abs/1705.09617 | id:1705.09617 author:Saeed Akhoondian Amiri, Stefan Schmid, Sebastian Siebertz category:cs.DC cs.DM cs.DS math.CO  published:2017-05-25 summary:The Minimum Dominating Set (MDS) problem is one of the most fundamental and challenging problems in distributed computing. While it is well-known that minimum dominating sets cannot be approximated locally on general graphs, over the last years, there has been much progress on computing local approximations on sparse graphs, and in particular planar graphs. In this paper we study distributed and deterministic MDS approximation algorithms for graph classes beyond planar graphs. In particular, we show that existing approximation bounds for planar graphs can be lifted to bounded genus graphs, and present (1) a local constant-time, constant-factor MDS approximation algorithm and (2) a local $\mathcal{O}(\log^*{n})$-time approximation scheme. Our main technical contribution is a new analysis of a slightly modified variant of an existing algorithm by Lenzen et al. Interestingly, unlike existing proofs for planar graphs, our analysis does not rely on direct topological arguments. version:1
arxiv-1608-08517 | Empirically Grounded Agent-Based Models of Innovation Diffusion: A Critical Review | http://arxiv.org/abs/1608.08517 | id:1608.08517 author:Haifeng Zhang, Yevgeniy Vorobeychik category:cs.SI cs.AI physics.soc-ph  published:2016-08-30 summary:Innovation diffusion has been studied extensively in a variety of disciplines, including sociology, economics, marketing, ecology, and computer science. Traditional literature on innovation diffusion has been dominated by models of aggregate behavior and trends. However, the agent-based modeling (ABM) paradigm is gaining popularity as it captures agent heterogeneity and enables fine-grained modeling of interactions mediated by social and geographic networks. While most ABM work on innovation diffusion is theoretical, empirically grounded models are increasingly important, particularly in guiding policy decisions. We present a critical review of empirically grounded agent-based models of innovation diffusion, developing a categorization of this research based on types of agent models as well as applications. By connecting the modeling methodologies in the fields of information and innovation diffusion, we suggest that the maximum likelihood estimation framework widely used in the former is a promising paradigm for calibration of agent-based models for innovation diffusion. Although many advances have been made to standardize ABM methodology, we identify four major issues in model calibration and validation, and suggest potential solutions. version:4
arxiv-1705-08661 | Robot Introspection with Bayesian Nonparametric Vector Autoregressive Hidden Markov Models | http://arxiv.org/abs/1705.08661 | id:1705.08661 author:Hongmin Wu, Juan Rojas, Hongbin Lin, Kensuke Harada category:cs.RO  published:2017-05-24 summary:Robot introspection, as opposed to anomaly detection typical in process monitoring, helps a robot understand what it is doing at all times. A robot should be able to identify its actions not only when failure or novelty occurs, but also as it executes any number of sub-tasks. As robots continue their quest of functioning in unstructured environments, it is imperative they understand what is it that they are actually doing to render them more robust. This work investigates the modeling ability of Bayesian nonparametric techniques on Markov Switching Process to learn complex dynamics typical in robot contact tasks. We study whether the Markov switching process, together with Bayesian priors can outperform the modeling ability of its counterparts: an HMM with Bayesian priors and without. The work was tested in a snap assembly task characterized by high elastic forces. The task consists of an insertion subtask with very complex dynamics. Our approach showed a stronger ability to generalize and was able to better model the subtask with complex dynamics in a computationally efficient way. The modeling technique is also used to learn a growing library of robot skills, one that when integrated with low-level control allows for robot online decision making. version:2
arxiv-1705-09073 | Load Balancing for Skewed Streams on Heterogeneous Cluster | http://arxiv.org/abs/1705.09073 | id:1705.09073 author:Muhammad Anis Uddin Nasir, Hiroshi Horii, Marco Serafini, Nicolas Kourtellis, Rudy Raymond, Sarunas Girdzijauskas, Takayuki Osogami category:cs.DC  published:2017-05-25 summary:Primitive partitioning strategies for streaming applications operate efficiently under two very strict assumptions: the resources are homogeneous and the messages are drawn from a uniform key distribution. These assumptions are often not true for the real-world use cases. Dealing with heterogeneity and non-uniform workload requires inferring the resource capacities and input distribution at run time. However, gathering these statistics and finding an optimal placement often become a challenge when microsecond latency is desired. In this paper, we address the load balancing problem for streaming engines running on a heterogeneous cluster and processing skewed workload. In doing so, we propose a novel partitioning strategy called Consistent Grouping (CG) that is inspired by traditional consistent hashing. CG is a lightweight distributed strategy that enables each processing element instance (PEIs) to process the workload according to its capacity. The main idea behind CG is the notion of equal-sized virtual workers at the sources, which are assigned to workers based on their capacities. We provide a theoretical analysis of the proposed algorithm and show via extensive empirical evaluation that the proposed scheme outperforms the state-of-the-art approaches. In particular, CG achieves 3.44x superior performance in terms of latency compared to key grouping, which is the state-of-the-art grouping strategy for stateful streaming applications. version:1
arxiv-1705-09061 | Triangle Finding and Listing in CONGEST Networks | http://arxiv.org/abs/1705.09061 | id:1705.09061 author:Taisuke Izumi, François Le Gall category:cs.DC cs.DS  published:2017-05-25 summary:Triangle-free graphs play a central role in graph theory, and triangle detection (or triangle finding) as well as triangle enumeration (triangle listing) play central roles in the field of graph algorithms. In distributed computing, algorithms with sublinear round complexity for triangle finding and listing have recently been developed in the powerful CONGEST clique model, where communication is allowed between any two nodes of the network. In this paper we present the first algorithms with sublinear complexity for triangle finding and triangle listing in the standard CONGEST model, where the communication topology is the same as the topology of the network. More precisely, we give randomized algorithms for triangle finding and listing with round complexity $O(n^{2/3}(\log n)^{2/3})$ and $O(n^{3/4}\log n)$, respectively, where $n$ denotes the number of nodes of the network. We also show a lower bound $\Omega(n^{1/3}/\log n)$ on the round complexity of triangle listing, which also holds for the CONGEST clique model. version:1
arxiv-1705-09058 | An Empirical Analysis of Approximation Algorithms for the Euclidean Traveling Salesman Problem | http://arxiv.org/abs/1705.09058 | id:1705.09058 author:Yihui He, Ming Xiang category:cs.AI  published:2017-05-25 summary:With applications to many disciplines, the traveling salesman problem (TSP) is a classical computer science optimization problem with applications to industrial engineering, theoretical computer science, bioinformatics, and several other disciplines. In recent years, there have been a plethora of novel approaches for approximate solutions ranging from simplistic greedy to cooperative distributed algorithms derived from artificial intelligence. In this paper, we perform an evaluation and analysis of cornerstone algorithms for the Euclidean TSP. We evaluate greedy, 2-opt, and genetic algorithms. We use several datasets as input for the algorithms including a small dataset, a mediumsized dataset representing cities in the United States, and a synthetic dataset consisting of 200 cities to test algorithm scalability. We discover that the greedy and 2-opt algorithms efficiently calculate solutions for smaller datasets. Genetic algorithm has the best performance for optimality for medium to large datasets, but generally have longer runtime. Our implementations is public available. version:1
arxiv-1705-08996 | An Experimental Platform for Multi-spacecraft Phase-Array Communications | http://arxiv.org/abs/1705.08996 | id:1705.08996 author:Aaditya Ravindran, Ravi Teja Nallapu, Andrew Warren, Alessandra Babuscia, Jose Vazco, Jekan Thangavelautham category:cs.RO  published:2017-05-24 summary:The emergence of small satellites and CubeSats for interplanetary exploration will mean hundreds if not thousands of spacecraft exploring every corner of the solar-system. Current methods for communication and tracking of deep space probes use ground based systems such as the Deep Space Network (DSN). However, the increased communication demand will require radically new methods to ease communication congestion. Networks of communication relay satellites located at strategic locations such as geostationary orbit and Lagrange points are potential solutions. Instead of one large communication relay satellite, we could have scores of small satellites that utilize phase arrays to effectively operate as one large satellite. Excess payload capacity on rockets can be used to warehouse more small satellites in the communication network. The advantage of this network is that even if one or a few of the satellites are damaged or destroyed, the network still operates but with degraded performance. The satellite network would operate in a distributed architecture and some satellites maybe dynamically repurposed to split and communicate with multiple targets at once. The potential for this alternate communication architecture is significant, but this requires development of satellite formation flying and networking technologies. Our research has found neural-network control approaches such as the Artificial Neural Tissue can be effectively used to control multirobot/multi-spacecraft systems and can produce human competitive controllers. We have been developing a laboratory experiment platform called Athena to develop critical spacecraft control algorithms and cognitive communication methods. We briefly report on the development of the platform and our plans to gain insight into communication phase arrays for space. version:1
arxiv-1705-09555 | Concurrent self-adjusting distributed tree networks | http://arxiv.org/abs/1705.09555 | id:1705.09555 author:Bruna Peres category:cs.DC  published:2017-05-24 summary:SplayNets are a distributed generalization of the classic splay tree data structures. Given a set of communication requests and a network comprised of n nodes, such that any pair of nodes is capable of establishing a direct connection, the goal is to dynamically find a (locally routable) binary tree topology, which connects all nodes and optimizes the routing cost for that communication pattern, making local topology transformations (rotations) before each request is served. In this work we present a distributed and concurrent implementation of SplayNets. Analytical results show that our proposed algorithm prevents loops and deadlocks from occurring between concurrent rotations. We compute the total amortized average cost of a splay request in number of rounds and number of time-slots and as a function of the empirical entropies of source and destination nodes of the splay requests. version:1
arxiv-1705-08968 | Logic Tensor Networks for Semantic Image Interpretation | http://arxiv.org/abs/1705.08968 | id:1705.08968 author:Ivan Donadello, Luciano Serafini, Artur d'Avila Garcez category:cs.AI  published:2017-05-24 summary:Semantic Image Interpretation (SII) is the task of extracting structured semantic descriptions from images. It is widely agreed that the combined use of visual data and background knowledge is of great importance for SII. Recently, Statistical Relational Learning (SRL) approaches have been developed for reasoning under uncertainty and learning in the presence of data and rich knowledge. Logic Tensor Networks (LTNs) are an SRL framework which integrates neural networks with first-order fuzzy logic to allow (i) efficient learning from noisy data in the presence of logical constraints, and (ii) reasoning with logical formulas describing general properties of the data. In this paper, we develop and apply LTNs to two of the main tasks of SII, namely, the classification of an image's bounding boxes and the detection of the relevant part-of relations between objects. To the best of our knowledge, this is the first successful application of SRL to such SII tasks. The proposed approach is evaluated on a standard image processing benchmark. Experiments show that the use of background knowledge in the form of logical constraints can improve the performance of purely data-driven approaches, including the state-of-the-art Fast Region-based Convolutional Neural Networks (Fast R-CNN). Moreover, we show that the use of logical background knowledge adds robustness to the learning system when errors are present in the labels of the training data. version:1
arxiv-1705-08961 | Efficient, Safe, and Probably Approximately Complete Learning of Action Models | http://arxiv.org/abs/1705.08961 | id:1705.08961 author:Roni Stern, Brendan Juba category:cs.AI  published:2017-05-24 summary:In this paper we explore the theoretical boundaries of planning in a setting where no model of the agent's actions is given. Instead of an action model, a set of successfully executed plans are given and the task is to generate a plan that is safe, i.e., guaranteed to achieve the goal without failing. To this end, we show how to learn a conservative model of the world in which actions are guaranteed to be applicable. This conservative model is then given to an off-the-shelf classical planner, resulting in a plan that is guaranteed to achieve the goal. However, this reduction from a model-free planning to a model-based planning is not complete: in some cases a plan will not be found even when such exists. We analyze the relation between the number of observed plans and the likelihood that our conservative approach will indeed fail to solve a solvable problem. Our analysis show that the number of trajectories needed scales gracefully. version:1
arxiv-1705-08927 | Compiling Quantum Circuits to Realistic Hardware Architectures using Temporal Planners | http://arxiv.org/abs/1705.08927 | id:1705.08927 author:Davide Venturelli, Minh Do, Eleanor Rieffel, Jeremy Frank category:quant-ph cs.AI cs.ET cs.SY  published:2017-05-24 summary:To run quantum algorithms on emerging gate-model quantum hardware, quantum circuits must be compiled to take into account constraints on the hardware. For near-term hardware, with only limited means to mitigate decoherence, it is critical to minimize the duration of the circuit. We investigate the application of temporal planners to the problem of compiling quantum circuits to newly emerging quantum hardware. While our approach is general, we focus on compiling to superconducting hardware architectures with nearest neighbor constraints. Our initial experiments focus on compiling Quantum Approximate Optimization Algorithm (QAOA) circuits whose high number of commuting gates allow great flexibility in the order in which the gates can be applied. That freedom makes it more challenging to find optimal compilations but also means there is a greater potential win from more optimized compilation than for less flexible circuits. We map this quantum circuit compilation problem to a temporal planning problem, and generated a test suite of compilation problems for QAOA circuits of various sizes to a realistic hardware architecture. We report compilation results from several state-of-the-art temporal planners on this test set. compile circuits of various sizes to a realistic hardware. This early empirical evaluation demonstrates that temporal planning is a viable approach to quantum circuit compilation. version:1
arxiv-1705-08926 | Counterfactual Multi-Agent Policy Gradients | http://arxiv.org/abs/1705.08926 | id:1705.08926 author:Jakob Foerster, Gregory Farquhar, Triantafyllos Afouras, Nantas Nardelli, Shimon Whiteson category:cs.AI cs.MA  published:2017-05-24 summary:Cooperative multi-agent systems can be naturally used to model many real world problems, such as network packet routing and the coordination of autonomous vehicles. There is a great need for new reinforcement learning methods that can efficiently learn decentralised policies for such systems. To this end, we propose a new multi-agent actor-critic method called counterfactual multi-agent (COMA) policy gradients. COMA uses a centralised critic to estimate the Q-function and decentralised actors to optimise the agents' policies. In addition, to address the challenges of multi-agent credit assignment, it uses a counterfactual baseline that marginalises out a single agent's action, while keeping the other agents' actions fixed. COMA also uses a critic representation that allows the counterfactual baseline to be computed efficiently in a single forward pass. We evaluate COMA in the testbed of StarCraft unit micromanagement, using a decentralised variant with significant partial observability. COMA significantly improves average performance over other multi-agent actor-critic methods in this setting, and the best performing agents are competitive with state-of-the-art centralised controllers that get access to the full state. version:1
arxiv-1705-08885 | Linearizable Iterators for Concurrent Data Structures | http://arxiv.org/abs/1705.08885 | id:1705.08885 author:Archita Agarwal, Zhiyu Liu, Eli Rosenthal, Vikram Saraph category:cs.DS cs.DC  published:2017-05-24 summary:In this work, we provide a general framework for adding a linearizable iterator to data structures with set operations. We propose a condition on these set operations, called locality, so that any data structure implemented from local atomic operations can be augmented with a linearizable iterator as described by our framework. We then apply the iterator framework to various data structures, prove locality of their operations, and demonstrate that the iterator framework does not significantly affect the performance of concurrent operations. version:1
arxiv-1705-08781 | Dynamic Occupancy Grid Prediction for Urban Autonomous Driving: A Deep Learning Approach with Fully Automatic Labeling | http://arxiv.org/abs/1705.08781 | id:1705.08781 author:Stefan Hoermann, Martin Bach, Klaus Dietmayer category:cs.RO  published:2017-05-24 summary:Long-term situation prediction plays a crucial role in the development of intelligent vehicles. A major challenge still to overcome is the prediction of complex downtown scenarios with mutiple road users interacting with each other. This contribution tackles this challenge by combining a Bayesian filtering technique for environment representation and machine learning as long-term predictor. Therefore, a dynamic occupancy grid map representing the static and dynamic environment around the ego-vehicle is utilized as input to a deep convolutional neural network. This yields the advantage of using data from a single timestamp for prediction, rather than an entire time series, alleviating common problems dealing with input time series. Furthermore, convolutional neural networks have the inherent characteristic of using context information, enabling the implicit modeling of road user interaction. Considering the extremely unbalanced data of dynamic and static grid cells, a pixel-wise balancing loss function for the training of the neural network is introduced. One of the major advantages is the unsupervised learning character due to fully automatic label generation. The presented algorithm is trained and evaluated on multiple hours of recorded sensor data. The recorded scenario is comprised of a shared space containing multiple road users, e.g., pedestrians, bikes and vehicles. version:1
arxiv-1705-08775 | A Control Performance Index for Multicopters Under Off-nominal Conditions | http://arxiv.org/abs/1705.08775 | id:1705.08775 author:Guang-Xun Du, Quan Quan, Zhiyu Xi, Yang Liu, Kai-Yuan Cai category:cs.RO  published:2017-05-24 summary:In order to prevent loss of control (LOC) accidents, the real-time control performance monitoring (CPM) problem is studied for multicopters. Different from the existing literature, this paper does not try to monitor the performance of the controllers directly. Conversely, the unknown disturbances of the multicopter under off-nominal conditions are modeled and assessed. The monitoring results will tell the user whether a multicopter will be LOC or not. Firstly, a new degree of controllability (DoC) will be proposed for multicopters subject to control constrains and off-nominal conditions. Then a control performance index (CPI) will be defined based on the new DoC to reflect the control performance of the multicopters. Besides, the proposed CPI is applied to a new switching control framework to guide the control decision of multicopter under off-nominal conditions. Finally, simulation and experimental results will show the effectiveness of the CPI and the switching control framework proposed in this paper. version:1
arxiv-1702-05456 | LCL problems on grids | http://arxiv.org/abs/1702.05456 | id:1702.05456 author:Sebastian Brandt, Juho Hirvonen, Janne H. Korhonen, Tuomo Lempiäinen, Patric R. J. Östergård, Christopher Purcell, Joel Rybicki, Jukka Suomela, Przemysław Uznański category:cs.DC cs.CC cs.DS  published:2017-02-17 summary:LCLs or locally checkable labelling problems (e.g. maximal independent set, maximal matching, and vertex colouring) in the LOCAL model of computation are very well-understood in cycles (toroidal 1-dimensional grids): every problem has a complexity of $O(1)$, $\Theta(\log^* n)$, or $\Theta(n)$, and the design of optimal algorithms can be fully automated. This work develops the complexity theory of LCL problems for toroidal 2-dimensional grids. The complexity classes are the same as in the 1-dimensional case: $O(1)$, $\Theta(\log^* n)$, and $\Theta(n)$. However, given an LCL problem it is undecidable whether its complexity is $\Theta(\log^* n)$ or $\Theta(n)$ in 2-dimensional grids. Nevertheless, if we correctly guess that the complexity of a problem is $\Theta(\log^* n)$, we can completely automate the design of optimal algorithms. For any problem we can find an algorithm that is of a normal form $A' \circ S_k$, where $A'$ is a finite function, $S_k$ is an algorithm for finding a maximal independent set in $k$th power of the grid, and $k$ is a constant. Finally, partially with the help of automated design tools, we classify the complexity of several concrete LCL problems related to colourings and orientations. version:2
arxiv-1707-05228 | Object Tracking based on Quantum Particle Swarm Optimization | http://arxiv.org/abs/1707.05228 | id:1707.05228 author:Rajesh Misra, Kumar S. Ray category:cs.CV cs.AI  published:2017-05-24 summary:In Computer Vision domain, moving Object Tracking considered as one of the toughest problem.As there so many factors associated like illumination of light, noise, occlusion, sudden start and stop of moving object, shading which makes tracking even harder problem not only for dynamic background but also for static background.In this paper we present a new object tracking algorithm based on Dominant points on tracked object using Quantum particle swarm optimization (QPSO) which is a new different version of PSO based on Quantum theory. The novelty in our approach is that it can be successfully applicable in variable background as well as static background and application of quantum PSO makes the algorithm runs lot faster where other basic PSO algorithm failed to do so due to heavy computation.In our approach firstly dominants points of tracked objects detected, then a group of particles form a swarm are initialized randomly over the image search space and then start searching the curvature connected between two consecutive dominant points until they satisfy fitness criteria. Obviously it is a Multi-Swarm approach as there are multiple dominant points, as they moves, the curvature moves and the curvature movement is tracked by the swarm throughout the video and eventually when the swarm reaches optimal solution , a bounding box drawn based on particles final position.Experimental results demonstrate this proposed QPSO based method work efficiently and effectively in visual object tracking in both dynamic and static environments and run time shows that it runs closely 90% faster than basic PSO.in our approach we also apply parallelism using MatLab Parfor command to show how very less number of iteration and swarm size will enable us to successfully track object. version:1
arxiv-1705-05098 | Quantifying Aspect Bias in Ordinal Ratings using a Bayesian Approach | http://arxiv.org/abs/1705.05098 | id:1705.05098 author:Lahari Poddar, Wynne Hsu, Mong Li Lee category:cs.AI  published:2017-05-15 summary:User opinions expressed in the form of ratings can influence an individual's view of an item. However, the true quality of an item is often obfuscated by user biases, and it is not obvious from the observed ratings the importance different users place on different aspects of an item. We propose a probabilistic modeling of the observed aspect ratings to infer (i) each user's aspect bias and (ii) latent intrinsic quality of an item. We model multi-aspect ratings as ordered discrete data and encode the dependency between different aspects by using a latent Gaussian structure. We handle the Gaussian-Categorical non-conjugacy using a stick-breaking formulation coupled with P\'{o}lya-Gamma auxiliary variable augmentation for a simple, fully Bayesian inference. On two real world datasets, we demonstrate the predictive ability of our model and its effectiveness in learning explainable user biases to provide insights towards a more reliable product quality estimation. version:2
arxiv-1705-09218 | Finding Robust Solutions to Stable Marriage | http://arxiv.org/abs/1705.09218 | id:1705.09218 author:Begum Genc, Mohamed Siala, Barry O'Sullivan, Gilles Simonin category:cs.AI  published:2017-05-24 summary:We study the notion of robustness in stable matching problems. We first define robustness by introducing (a,b)-supermatches. An $(a,b)$-supermatch is a stable matching in which if $a$ pairs break up it is possible to find another stable matching by changing the partners of those $a$ pairs and at most $b$ other pairs. In this context, we define the most robust stable matching as a $(1,b)$-supermatch where b is minimum. We show that checking whether a given stable matching is a $(1,b)$-supermatch can be done in polynomial time. Next, we use this procedure to design a constraint programming model, a local search approach, and a genetic algorithm to find the most robust stable matching. Our empirical evaluation on large instances show that local search outperforms the other approaches. version:1
arxiv-1705-08627 | On Using Time Without Clocks via Zigzag Causality | http://arxiv.org/abs/1705.08627 | id:1705.08627 author:Asa Dan, Rajit Manohar, Yoram Moses category:cs.DC  published:2017-05-24 summary:Even in the absence of clocks, time bounds on the duration of actions enable the use of time for distributed coordination. This paper initiates an investigation of coordination in such a setting. A new communication structure called a zigzag pattern is introduced, and shown to guarantee bounds on the relative timing of events in this clockless model. Indeed, zigzag patterns are shown to be necessary and sufficient for establishing that events occur in a manner that satisfies prescribed bounds. We capture when a process can know that an appropriate zigzag pattern exists, and use this to provide necessary and sufficient conditions for timed coordination of events using a full-information protocol in the clockless model. version:1
arxiv-1705-08218 | XOR-Sampling for Network Design with Correlated Stochastic Events | http://arxiv.org/abs/1705.08218 | id:1705.08218 author:Xiaojian Wu, Yexiang Xue, Bart Selman, Carla P. Gomes category:cs.AI  published:2017-05-23 summary:Many network optimization problems can be formulated as stochastic network design problems in which edges are present or absent stochastically. Furthermore, protective actions can guarantee that edges will remain present. We consider the problem of finding the optimal protection strategy under a budget limit in order to maximize some connectivity measurements of the network. Previous approaches rely on the assumption that edges are independent. In this paper, we consider a more realistic setting where multiple edges are not independent due to natural disasters or regional events that make the states of multiple edges stochastically correlated. We use Markov Random Fields to model the correlation and define a new stochastic network design framework. We provide a novel algorithm based on Sample Average Approximation (SAA) coupled with a Gibbs or XOR sampler. The experimental results on real road network data show that the policies produced by SAA with the XOR sampler have higher quality and lower variance compared to SAA with Gibbs sampler. version:2
arxiv-1705-08566 | A Near-Optimal Separation Principle for Nonlinear Stochastic Systems Arising in Robotic Path Planning and Control | http://arxiv.org/abs/1705.08566 | id:1705.08566 author:Mohammadhussein Rafieisakhaei, Suman Chakravorty, P. R. Kumar category:cs.RO cs.SY  published:2017-05-24 summary:We consider nonlinear stochastic systems that arise in path planning and control of mobile robots. As is typical of almost all nonlinear stochastic systems, the optimally solving problem is intractable. We provide a design approach which yields a tractable design that is quantifiably near-optimal. We exhibit a "separation" principle under a small noise assumption consisting of the optimal open-loop design of nominal trajectory followed by an optimal feedback law to track this trajectory, which is different from the usual effort of separating estimation from control. As a corollary, we obtain a trajectory-optimized linear quadratic regulator design for stochastic nonlinear systems with Gaussian noise. version:1
arxiv-1606-06183 | Asymptotically Optimal Approximation Algorithms for Coflow Scheduling | http://arxiv.org/abs/1606.06183 | id:1606.06183 author:Hamidreza Jahanjou, Erez Kantor, Rajmohan Rajaraman category:cs.DC cs.DS  published:2016-06-20 summary:Many modern datacenter applications involve large-scale computations composed of multiple data flows that need to be completed over a shared set of distributed resources. Such a computation completes when all of its flows complete. A useful abstraction for modeling such scenarios is a {\em coflow}, which is a collection of flows (e.g., tasks, packets, data transmissions) that all share the same performance goal. In this paper, we present the first approximation algorithms for scheduling coflows over general network topologies with the objective of minimizing total weighted completion time. We consider two different models for coflows based on the nature of individual flows: circuits, and packets. We design constant-factor polynomial-time approximation algorithms for scheduling packet-based coflows with or without given flow paths, and circuit-based coflows with given flow paths. Furthermore, we give an $O(\log n/\log \log n)$-approximation polynomial time algorithm for scheduling circuit-based coflows where flow paths are not given (here $n$ is the number of network edges). We obtain our results by developing a general framework for coflow schedules, based on interval-indexed linear programs, which may extend to other coflow models and objective functions and may also yield improved approximation bounds for specific network scenarios. We also present an experimental evaluation of our approach for circuit-based coflows that show a performance improvement of at least 22% on average over competing heuristics. version:3
arxiv-1705-03158 | Manifold Relevance Determination: Learning the Latent Space of Robotics | http://arxiv.org/abs/1705.03158 | id:1705.03158 author:Pete Trautman category:cs.RO  published:2017-05-09 summary:In this article we present the basics of manifold relevance determination (MRD) as introduced in \cite{mrd}, and some applications where the technology might be of particular use. Section 1 acts as a short tutorial of the ideas developed in \cite{mrd}, while Section 2 presents possible applications in sensor fusion, multi-agent SLAM, and "human-appropriate" robot movement (e.g. legibility and predictability~\cite{dragan-hri-2013}). In particular, we show how MRD can be used to construct the underlying models in a data driven manner, rather than directly leveraging first principles theories (e.g., physics, psychology) as is commonly the case for sensor fusion, SLAM, and human robot interaction. We note that [Bekiroglu et al., 2016] leveraged MRD for correcting unstable robot grasps to stable robot grasps. version:2
arxiv-1705-08509 | Predictive Analytics for Enhancing Travel Time Estimation in Navigation Apps of Apple, Google, and Microsoft | http://arxiv.org/abs/1705.08509 | id:1705.08509 author:Pouria Amirian, Anahid Basiri, Jeremy Morley category:cs.AI  published:2017-05-23 summary:The explosive growth of the location-enabled devices coupled with the increasing use of Internet services has led to an increasing awareness of the importance and usage of geospatial information in many applications. The navigation apps (often called Maps), use a variety of available data sources to calculate and predict the travel time as well as several options for routing in public transportation, car or pedestrian modes. This paper evaluates the pedestrian mode of Maps apps in three major smartphone operating systems (Android, iOS and Windows Phone). In the paper, we will show that the Maps apps on iOS, Android and Windows Phone in pedestrian mode, predict travel time without learning from the individual's movement profile. In addition, we will exemplify that those apps suffer from a specific data quality issue which relates to the absence of information about location and type of pedestrian crossings. Finally, we will illustrate learning from movement profile of individuals using various predictive analytics models to improve the accuracy of travel time estimation. version:1
arxiv-1705-08492 | Uplift Modeling with Multiple Treatments and General Response Types | http://arxiv.org/abs/1705.08492 | id:1705.08492 author:Yan Zhao, Xiao Fang, David Simchi-Levi category:cs.AI  published:2017-05-23 summary:Randomized experiments have been used to assist decision-making in many areas. They help people select the optimal treatment for the test population with certain statistical guarantee. However, subjects can show significant heterogeneity in response to treatments. The problem of customizing treatment assignment based on subject characteristics is known as uplift modeling, differential response analysis, or personalized treatment learning in literature. A key feature for uplift modeling is that the data is unlabeled. It is impossible to know whether the chosen treatment is optimal for an individual subject because response under alternative treatments is unobserved. This presents a challenge to both the training and the evaluation of uplift models. In this paper we describe how to obtain an unbiased estimate of the key performance metric of an uplift model, the expected response. We present a new uplift algorithm which creates a forest of randomized trees. The trees are built with a splitting criterion designed to directly optimize their uplift performance based on the proposed evaluation method. Both the evaluation method and the algorithm apply to arbitrary number of treatments and general response types. Experimental results on synthetic data and industry-provided data show that our algorithm leads to significant performance improvement over other applicable methods. version:1
arxiv-1607-06667 | Audio inpainting with similarity graphs | http://arxiv.org/abs/1607.06667 | id:1607.06667 author:Nathanael Perraudin, Nicki Holighaus, Piotr Majdak, Peter Balazs category:cs.SD cs.AI cs.MM cs.SE  published:2016-07-22 summary:We present a novel method for the compensation of long duration data gaps in audio signals, in particular music. The concealment of such signal defects is based on a graph that encodes signal structure in terms of time-persistent spectral similarity. A suitable candidate segment for the substitution of the lost content is proposed by an intuitive optimization scheme and smoothly inserted into the gap. Extensive listening tests show that the proposed algorithm provides highly promising results when applied to a variety of real-world music signals. version:2
arxiv-1609-04056 | Decoupled limbs yield differentiable trajectory outcomes through intermittent contact in locomotion and manipulation | http://arxiv.org/abs/1609.04056 | id:1609.04056 author:Andrew Pace, Samuel A. Burden category:cs.RO  published:2016-09-13 summary:When limbs are decoupled, we find that trajectory outcomes in mechanical systems subject to unilateral constraints vary differentiably with respect to initial conditions, even as the contact mode sequence varies. version:2
arxiv-1705-08440 | Knowledge Acquisition, Representation \& Manipulation in Decision Support Systems | http://arxiv.org/abs/1705.08440 | id:1705.08440 author:M. Michalewicz, S. T. Wierzchoń, M. A. Kłopotek category:cs.AI  published:2017-05-23 summary:In this paper we present a methodology and discuss some implementation issues for a project on statistical/expert approach to data analysis and knowledge acquisition. We discuss some general assumptions underlying the project. Further, the requirements for a user-friendly computer assistant are specified along with the nature of tools aiding the researcher. Next we show some aspects of belief network approach and Dempster-Shafer (DST) methodology introduced in practice to system SEAD. Specifically we present the application of DS methodology to belief revision problem. Further a concept of an interface to probabilistic and DS belief networks enabling a user to understand the communication with a belief network based reasoning system is presented version:1
arxiv-1705-08439 | Thinking Fast and Slow with Deep Learning and Tree Search | http://arxiv.org/abs/1705.08439 | id:1705.08439 author:Thomas Anthony, Zheng Tian, David Barber category:cs.AI  published:2017-05-23 summary:Solving sequential decision making problems, such as text parsing, robotic control, and game playing, requires a combination of planning policies and generalisation of those plans. In this paper, we present Expert Iteration, a novel algorithm which decomposes the problem into separate planning and generalisation tasks. Planning new policies is performed by tree search, while a deep neural network generalises those plans. In contrast, standard Deep Reinforcement Learning algorithms rely on a neural network not only to generalise plans, but to discover them too. We show that our method substantially outperforms Policy Gradients in the board game Hex, winning 84.4% of games against it when trained for equal time. version:1
arxiv-1703-03868 | Front-to-End Bidirectional Heuristic Search with Near-Optimal Node Expansions | http://arxiv.org/abs/1703.03868 | id:1703.03868 author:Jingwei Chen, Robert C. Holte, Sandra Zilles, Nathan R. Sturtevant category:cs.AI  published:2017-03-10 summary:It is well-known that any admissible unidirectional heuristic search algorithm must expand all states whose $f$-value is smaller than the optimal solution cost when using a consistent heuristic. Such states are called "surely expanded" (s.e.). A recent study characterized s.e. pairs of states for bidirectional search with consistent heuristics: if a pair of states is s.e. then at least one of the two states must be expanded. This paper derives a lower bound, VC, on the minimum number of expansions required to cover all s.e. pairs, and present a new admissible front-to-end bidirectional heuristic search algorithm, Near-Optimal Bidirectional Search (NBS), that is guaranteed to do no more than 2VC expansions. We further prove that no admissible front-to-end algorithm has a worst case better than 2VC. Experimental results show that NBS competes with or outperforms existing bidirectional search algorithms, and often outperforms A* as well. version:2
arxiv-1705-08426 | Symbolic LTLf Synthesis | http://arxiv.org/abs/1705.08426 | id:1705.08426 author:Shufang Zhu, Lucas M. Tabajara, Jianwen Li, Geguang Pu, Moshe Y. Vardi category:cs.LO cs.AI  published:2017-05-23 summary:LTLf synthesis is the process of finding a strategy that satisfies a linear temporal specification over finite traces. An existing solution to this problem relies on a reduction to a DFA game. In this paper, we propose a symbolic framework for LTLf synthesis based on this technique, by performing the computation over a representation of the DFA as a boolean formula rather than as an explicit graph. This approach enables strategy generation by utilizing the mechanism of boolean synthesis. We implement this symbolic synthesis method in a tool called Syft, and demonstrate by experiments on scalable benchmarks that the symbolic approach scales better than the explicit one. version:1
arxiv-1705-05983 | AI, Native Supercomputing and The Revival of Moore's Law | http://arxiv.org/abs/1705.05983 | id:1705.05983 author:Chien-Ping Lu category:cs.AI  published:2017-05-17 summary:Based on Alan Turing's proposition on AI and computing machinery, which shaped Computing as we know it today, the new AI computing machinery should comprise a universal computer and a universal learning machine. The later should understand linear algebra natively to overcome the slowdown of Moore's law. In such a universal learnig machine, a computing unit does not need to keep the legacy of a universal computing core. The data can be distributed to the computing units, and the results can be collected from them through Collective Streaming, reminiscent of Collective Communication in Supercomputing. It is not necessary to use a GPU-like deep memory hierarchy, nor a TPU-like fine-grain mesh. version:2
arxiv-1705-08449 | Developing an edge analytics platform for analyzing real-time transit data streams | http://arxiv.org/abs/1705.08449 | id:1705.08449 author:Hung Cao, Monica Wachowicz, Sangwhan Cha category:cs.CY cs.DC cs.NI  published:2017-05-23 summary:The Internet of Mobile Things encompasses stream data being generated by sensors, network communications that pull and push these data streams, as well as running processing and analytics that can effectively leverage actionable information for planning, management, and business advantage. Edge computing emerges as a new paradigm that decentralizes the communication, computation, control and storage resources from the cloud to the edge of the Internet. This paper proposes an edge computing platform where mobile fog nodes are physical devices where descriptive analytics is deployed to analyze real-time transit data streams. An application experiment is used to evaluate the advantages and disadvantages of our proposed platform to run descriptive analytics at the mobile fog node and support transit managers with actionable information. version:1
arxiv-1705-08350 | Bounding Cache Miss Costs of Multithreaded Computations Under General Schedulers | http://arxiv.org/abs/1705.08350 | id:1705.08350 author:Richard Cole, Vijaya Ramachandran category:cs.DC cs.DS  published:2017-05-23 summary:We analyze the caching overhead incurred by a class of multithreaded algorithms when scheduled by an arbitrary scheduler. We obtain bounds that match or improve upon the well-known $O(Q+S \cdot (M/B))$ caching cost for the randomized work stealing (RWS) scheduler, where $S$ is the number of steals, $Q$ is the sequential caching cost, and $M$ and $B$ are the cache size and block (or cache line) size respectively. version:1
arxiv-1705-08320 | Explaining Transition Systems through Program Induction | http://arxiv.org/abs/1705.08320 | id:1705.08320 author:Svetlin Penkov, Subramanian Ramamoorthy category:cs.AI  published:2017-05-23 summary:Explaining and reasoning about processes which underlie observed black-box phenomena enables the discovery of causal mechanisms, derivation of suitable abstract representations and the formulation of more robust predictions. We propose to learn high level functional programs in order to represent abstract models which capture the invariant structure in the observed data. We introduce the $\pi$-machine (program-induction machine) -- an architecture able to induce interpretable LISP-like programs from observed data traces. We propose an optimisation procedure for program learning based on backpropagation, gradient descent and A* search. We apply the proposed method to three problems: system identification of dynamical systems, explaining the behaviour of a DQN agent and learning by demonstration in a human-robot interaction scenario. Our experimental results show that the $\pi$-machine can efficiently induce interpretable programs from individual data traces. version:1
arxiv-1705-08242 | Randomized Composable Coresets for Matching and Vertex Cover | http://arxiv.org/abs/1705.08242 | id:1705.08242 author:Sepehr Assadi, Sanjeev Khanna category:cs.DS cs.DC  published:2017-05-23 summary:A common approach for designing scalable algorithms for massive data sets is to distribute the computation across, say $k$, machines and process the data using limited communication between them. A particularly appealing framework here is the simultaneous communication model whereby each machine constructs a small representative summary of its own data and one obtains an approximate/exact solution from the union of the representative summaries. If the representative summaries needed for a problem are small, then this results in a communication-efficient and round-optimal protocol. While many fundamental graph problems admit efficient solutions in this model, two prominent problems are notably absent from the list of successes, namely, the maximum matching problem and the minimum vertex cover problem. Indeed, it was shown recently that for both these problems, even achieving a polylog$(n)$ approximation requires essentially sending the entire input graph from each machine. The main insight of our work is that the intractability of matching and vertex cover in the simultaneous communication model is inherently connected to an adversarial partitioning of the underlying graph across machines. We show that when the underlying graph is randomly partitioned across machines, both these problems admit randomized composable coresets of size $\widetilde{O}(n)$ that yield an $\widetilde{O}(1)$-approximate solution. This results in an $\widetilde{O}(1)$-approximation simultaneous protocol for these problems with $\widetilde{O}(nk)$ total communication when the input is randomly partitioned across $k$ machines. We further prove the optimality of our results. Finally, by a standard application of composable coresets, our results also imply MapReduce algorithms with the same approximation guarantee in one or two rounds of communication version:1
arxiv-1705-08213 | Parallel Accelerated Custom Correlation Coefficient Calculations for Genomics Applications | http://arxiv.org/abs/1705.08213 | id:1705.08213 author:Wayne Joubert, James Nance, Sharlee Climer, Deborah Weighill, Daniel Jacobson category:cs.DC cs.DS cs.PF  published:2017-05-23 summary:The massive quantities of genomic data being made available through gene sequencing techniques are enabling breakthroughs in genomic science in many areas such as medical advances in the diagnosis and treatment of diseases. Analyzing this data, however, is a computational challenge insofar as the computational costs of the relevant algorithms can grow with quadratic, cubic or higher complexity--leading to the need for leadership scale computing. In this paper we describe a new approach to calculations of the Custom Correlation Coefficient (CCC) between Single Nucleotide Polymorphisms (SNPs) across a population, suitable for parallel systems equipped with graphics processing units (GPUs) or Intel Xeon Phi processors. We describe the mapping of the algorithms to accelerated processors, techniques used for eliminating redundant calculations due to symmetries, and strategies for efficient mapping of the calculations to many-node parallel systems. Results are presented demonstrating high per-node performance and near-ideal parallel scalability with rates of more than four quadrillion elementwise comparisons achieved per second on the ORNL Titan system. In a companion paper we describe corresponding techniques applied to calculations of the Proportional Similarity metric for comparative genomics applications. version:1
arxiv-1705-08210 | Parallel Accelerated Vector Similarity Calculations for Genomics Applications | http://arxiv.org/abs/1705.08210 | id:1705.08210 author:Wayne Joubert, James Nance, Deborah Weighill, Daniel Jacobson category:cs.DC cs.DS cs.PF  published:2017-05-23 summary:The surge in availability of genomic data holds promise for enabling determination of genetic causes of observed individual traits, with applications to problems such as discovery of the genetic roots of phenotypes, be they molecular phenotypes such as gene expression or metabolite concentrations, or complex phenotypes such as diseases. However, the growing sizes of these datasets and the quadratic, cubic or higher scaling characteristics of the relevant algorithms pose a serious computational challenge necessitating use of leadership scale computing. In this paper we describe a new approach to performing vector similarity metrics calculations, suitable for parallel systems equipped with graphics processing units (GPUs) or Intel Xeon Phi processors. Our primary focus is the Proportional Similarity metric applied to Genome Wide Association Studies (GWAS) and Phenome Wide Association Studies (PheWAS). We describe the implementation of the algorithms on accelerated processors, methods used for eliminating redundant calculations due to symmetries, and techniques for efficient mapping of the calculations to many-node parallel systems. Results are presented demonstrating high per-node performance and parallel scalability with rates of more than five quadrillion elementwise comparisons achieved per second on the ORNL Titan system. In a companion paper we describe corresponding techniques applied to calculations of the Custom Correlation Coefficient for comparative genomics applications. version:1
arxiv-1705-08200 | Logical Learning Through a Hybrid Neural Network with Auxiliary Inputs | http://arxiv.org/abs/1705.08200 | id:1705.08200 author:Fang Wan, Chaoyang Song category:cs.AI  published:2017-05-23 summary:The human reasoning process is seldom a one-way process from an input leading to an output. Instead, it often involves a systematic deduction by ruling out other possible outcomes as a self-checking mechanism. In this paper, we describe the design of a hybrid neural network for logical learning that is similar to the human reasoning through the introduction of an auxiliary input, namely the indicators, that act as the hints to suggest logical outcomes. We generate these indicators by digging into the hidden information buried underneath the original training data for direct or indirect suggestions. We used the MNIST data to demonstrate the design and use of these indicators in a convolutional neural network. We trained a series of such hybrid neural networks with variations of the indicators. Our results show that these hybrid neural networks are very robust in generating logical outcomes with inherently higher prediction accuracy than the direct use of the original input and output in apparent models. Such improved predictability with reassured logical confidence is obtained through the exhaustion of all possible indicators to rule out all illogical outcomes, which is not available in the apparent models. Our logical learning process can effectively cope with the unknown unknowns using a full exploitation of all existing knowledge available for learning. The design and implementation of the hints, namely the indicators, become an essential part of artificial intelligence for logical learning. We also introduce an ongoing application setup for this hybrid neural network in an autonomous grasping robot, namely as_DeepClaw, aiming at learning an optimized grasping pose through logical learning. version:1
arxiv-1705-08169 | Transformation of Python Applications into Function-as-a-Service Deployments | http://arxiv.org/abs/1705.08169 | id:1705.08169 author:Josef Spillner category:cs.DC cs.SE D.2.1; I.2.2; C.2.4  published:2017-05-23 summary:New cloud programming and deployment models pose challenges to software application engineers who are looking, often in vain, for tools to automate any necessary code adaptation and transformation. Function-as-a-Service interfaces are particular non-trivial targets when considering that most cloud applications are implemented in non-functional languages. Among the most widely used of these languages is Python. This starting position calls for an automated approach to transform monolithic Python code into modular FaaS units by partially automated decomposition. Hence, this paper introduces and evaluates Lambada, a Python module to dynamically decompose, convert and deploy unmodified Python code into AWS Lambda functions. Beyond the tooling in the form of a measured open source prototype implementation, the paper contributes a description of the algorithms and code rewriting rules as blueprints for transformations of other scripting languages. version:1
arxiv-1705-08135 | Kinetostatic Analysis and Solution Classification of a Planar Tensegrity Mechanism | http://arxiv.org/abs/1705.08135 | id:1705.08135 author:P Wenger, Damien Chablat category:cs.RO  published:2017-05-23 summary:Tensegrity mechanisms have several interesting properties that make them suitable for a number of applications. Their analysis is generally challenging because the static equilibrium conditions often result in complex equations. A class of planar one-degree-of-freedom (dof) tensegrity mechanisms with three linear springs is analyzed in detail in this paper. The kinetostatic equations are derived and solved under several loading and geometric conditions. It is shown that these mechanisms exhibit up to six equilibrium configurations, of which one or two are stable. Discriminant varieties and cylindrical algebraic decomposition combined with Groebner base elimination are used to classify solutions as function of the input parameters. version:1
arxiv-1705-09144 | Modeling and Simulation of the Dynamics of the Quick Return Mechanism: A Bond Graph Approach | http://arxiv.org/abs/1705.09144 | id:1705.09144 author:Anand Vaz, Thommen G K category:cs.RO  published:2017-05-22 summary:This paper applies the multibond graph approach for rigid multibody systems to model the dynamics of general spatial mechanisms. The commonly used quick return mechanism which comprises of revolute as well as prismatic joints has been chosen as a representative example to demonstrate the application of this technique and its resulting advantages. In this work, the links of the quick return mechanism are modeled as rigid bodies. The rigid links are then coupled at the joints based on the nature of constraint. This alternative method of formulation of system dynamics, using Bond Graphs, offers a rich set of features that include pictorial representation of the dynamics of translation and rotation for each link of the mechanism in the inertial frame, representation and handling of constraints at the joints, depiction of causality, obtaining dynamic reaction forces and moments at various locations in the mechanism and so on. Yet another advantage of this approach is that the coding for simulation can be carried out directly from the Bond Graph in an algorithmic manner, without deriving system equations. In this work, the program code for simulation is written in MATLAB. The vector and tensor operations are conveniently represented in MATLAB, resulting in a compact and optimized code. The simulation results are plotted and discussed in detail. version:1
arxiv-1705-08010 | Dynamic Motion Planning for Aerial Surveillance on a Fixed-Wing UAV | http://arxiv.org/abs/1705.08010 | id:1705.08010 author:Vaibhav Darbari, Saksham Gupta, Om Prakash Verma category:cs.RO  published:2017-05-22 summary:We present an efficient path planning algorithm for an Unmanned Aerial Vehicle surveying a cluttered urban landscape. A special emphasis is on maximizing area surveyed while adhering to constraints of the UAV and partially known and updating environment. A Voronoi bias is introduced in the probabilistic roadmap building phase to identify certain critical milestones for maximal surveillance of the search space. A kinematically feasible but coarse tour connecting these milestones is generated by the global path planner. A local path planner then generates smooth motion primitives between consecutive nodes of the global path based on UAV as a Dubins vehicle and taking into account any impending obstacles. A Markov Decision Process (MDP) models the control policy for the UAV and determines the optimal action to be undertaken for evading the obstacles in the vicinity with minimal deviation from current path. The efficacy of the proposed algorithm is evaluated in an updating simulation environment with dynamic and static obstacles. version:1
arxiv-1705-08009 | A Low-Power Accelerator for Deep Neural Networks with Enlarged Near-Zero Sparsity | http://arxiv.org/abs/1705.08009 | id:1705.08009 author:Yuxiang Huan, Yifan Qin, Yantian You, Lirong Zheng, Zhuo Zou category:cs.AR  published:2017-05-22 summary:It remains a challenge to run Deep Learning in devices with stringent power budget in the Internet-of-Things. This paper presents a low-power accelerator for processing Deep Neural Networks in the embedded devices. The power reduction is realized by avoiding multiplications of near-zero valued data. The near-zero approximation and a dedicated Near-Zero Approximation Unit (NZAU) are proposed to predict and skip the near-zero multiplications under certain thresholds. Compared with skipping zero-valued computations, our design achieves 1.92X and 1.51X further reduction of the total multiplications in LeNet-5 and Alexnet respectively, with negligible lose of accuracy. In the proposed accelerator, 256 multipliers are grouped into 16 independent Processing Lanes (PL) to support up to 16 neuron activations simultaneously. With the help of data pre-processing and buffering in each PL, multipliers can be clock-gated in most of the time even the data is excessively streaming in. Designed and simulated in UMC 65 nm process, the accelerator operating at 500 MHz is $>$ 4X faster than the mobile GPU Tegra K1 in processing the fully-connected layer FC8 of Alexnet, while consuming 717X less energy. version:1
arxiv-1705-07996 | Living Together: Mind and Machine Intelligence | http://arxiv.org/abs/1705.07996 | id:1705.07996 author:Neil D. Lawrence category:cs.AI  published:2017-05-22 summary:In this paper we consider the nature of the machine intelligences we have created in the context of our human intelligence. We suggest that the fundamental difference between human and machine intelligence comes down to \emph{embodiment factors}. We define embodiment factors as the ratio between an entity's ability to communicate information vs compute information. We speculate on the role of embodiment factors in driving our own intelligence and consciousness. We briefly review dual process models of cognition and cast machine intelligence within that framework, characterising it as a dominant System Zero, which can drive behaviour through interfacing with us subconsciously. Driven by concerns about the consequence of such a system we suggest prophylactic courses of action that could be considered. Our main conclusion is that it is \emph{not} sentient intelligence we should fear but \emph{non-sentient} intelligence. version:1
arxiv-1705-07983 | Liquid Cloud Storage | http://arxiv.org/abs/1705.07983 | id:1705.07983 author:Michael G. Luby, Roberto Padovani, Thomas J. Richardson, Lorenz Minder, Pooja Aggarwal category:cs.DC cs.PF cs.SY  published:2017-05-22 summary:A liquid system provides durable object storage based on spreading redundantly generated data across a network of hundreds to thousands of potentially unreliable storage nodes. A liquid system uses a combination of a large code, lazy repair, and a flow storage organization. We show that a liquid system can be operated to enable flexible and essentially optimal combinations of storage durability, storage overhead, repair bandwidth usage, and access performance. version:1
arxiv-1705-07961 | Compatible extensions and consistent closures: a fuzzy approach | http://arxiv.org/abs/1705.07961 | id:1705.07961 author:Irina Georgescu category:cs.AI  published:2017-05-22 summary:In this paper $\ast$--compatible extensions of fuzzy relations are studied, generalizing some results obtained by Duggan in case of crisp relations. From this general result are obtained as particular cases fuzzy versions of some important extension theorems for crisp relations (Szpilrajn, Hansson, Suzumura). Two notions of consistent closure of a fuzzy relation are introduced. version:1
arxiv-1705-07861 | Symmetry Breaking in the Congest Model: Time- and Message-Efficient Algorithms for Ruling Sets | http://arxiv.org/abs/1705.07861 | id:1705.07861 author:Shreyas Pai, Gopal Pandurangan, Sriram V. Pemmaraju, Talal Riaz, Peter Robinson category:cs.DC cs.DS  published:2017-05-22 summary:We study local symmetry breaking problems in the CONGEST model, focusing on ruling set problems, which generalize the fundamental Maximal Independent Set (MIS) problem. A $\beta$-ruling set is an independent set such that every node in the graph is at most $\beta$ hops from a node in the independent set. Our work is motivated by the following central question: can we break the $\Theta(\log n)$ time complexity barrier and the $\Theta(m)$ message complexity barrier in the CONGEST model for MIS or closely-related symmetry breaking problems? We present the following results: - Time Complexity: We show that we can break the $O(\log n)$ "barrier" for 2- and 3-ruling sets. We compute 3-ruling sets in $O\left(\frac{\log n}{\log \log n}\right)$ rounds with high probability (whp). More generally we show that 2-ruling sets can be computed in $O\left(\log \Delta \cdot (\log n)^{1/2 + \varepsilon} + \frac{\log n}{\log\log n}\right)$ rounds for any $\varepsilon > 0$, which is $o(\log n)$ for a wide range of $\Delta$ values (e.g., $\Delta = 2^{(\log n)^{1/2-\varepsilon}}$). These are the first 2- and 3-ruling set algorithms to improve over the $O(\log n)$-round complexity of Luby's algorithm in the CONGEST model. - Message Complexity: We show an $\Omega(n^2)$ lower bound on the message complexity of computing an MIS (i.e., 1-ruling set) which holds also for randomized algorithms and present a contrast to this by showing a randomized algorithm for 2-ruling sets that, whp, uses only $O(n \log^2 n)$ messages and runs in $O(\Delta \log n)$ rounds. This is the first message-efficient algorithm known for ruling sets, which has message complexity nearly linear in $n$ (which is optimal up to a polylogarithmic factor). version:1
arxiv-1705-07834 | Adaptive Information Gathering via Imitation Learning | http://arxiv.org/abs/1705.07834 | id:1705.07834 author:Sanjiban Choudhury, Ashish Kapoor, Gireeja Ranade, Sebastian Scherer, Debadeepta Dey category:cs.RO  published:2017-05-22 summary:In the adaptive information gathering problem, a policy is required to select an informative sensing location using the history of measurements acquired thus far. While there is an extensive amount of prior work investigating effective practical approximations using variants of Shannon's entropy, the efficacy of such policies heavily depends on the geometric distribution of objects in the world. On the other hand, the principled approach of employing online POMDP solvers is rendered impractical by the need to explicitly sample online from a posterior distribution of world maps. We present a novel data-driven imitation learning framework to efficiently train information gathering policies. The policy imitates a clairvoyant oracle - an oracle that at train time has full knowledge about the world map and can compute maximally informative sensing locations. We analyze the learnt policy by showing that offline imitation of a clairvoyant oracle is implicitly equivalent to online oracle execution in conjunction with posterior sampling. This observation allows us to obtain powerful near-optimality guarantees for information gathering problems possessing an adaptive sub-modularity property. As demonstrated on a spectrum of 2D and 3D exploration problems, the trained policies enjoy the best of both worlds - they adapt to different world map distributions while being computationally inexpensive to evaluate. version:1
arxiv-1705-08230 | Towards Blockchain-based Auditable Storage and Sharing of IoT Data | http://arxiv.org/abs/1705.08230 | id:1705.08230 author:Hossein Shafagh, Anwar Hithnawi, Simon Duquennoy category:cs.DC  published:2017-05-22 summary:Today the cloud plays a central role in storing, processing, and distributing data. Despite contributing to the rapid development of various applications, including the IoT, the current centralized storage architecture has led into a myriad of isolated data silos and is preventing the full potential of holistic data-driven analytics for IoT data. In this abstract, we advocate a data-centric design for IoT with focus on resilience, sharing, and auditable protection of information. We introduce the initial design of our blockchain-based end-to-end encrypted data storage system. We enable a secure and persistent data management, by utilizing the blockchain as an auditable access control layer to a decentralized storage layer. version:1
arxiv-1704-04058 | Solving ill-posed inverse problems using iterative deep neural networks | http://arxiv.org/abs/1704.04058 | id:1704.04058 author:Jonas Adler, Ozan Öktem category:math.OC cs.AI math.FA math.NA  published:2017-04-13 summary:We propose a partially learned approach for the solution of ill posed inverse problems with not necessarily linear forward operators. The method builds on ideas from classical regularization theory and recent advances in deep learning to perform learning while making use of prior information about the inverse problem encoded in the forward operator, noise model and a regularizing functional. The method results in a gradient-like iterative scheme, where the "gradient" component is learned using a convolutional network that includes the gradients of the data discrepancy and regularizer as input in each iteration. We present results of such a partially learned gradient scheme on a non-linear tomographic inversion problem with simulated data from both the Sheep-Logan phantom as well as a head CT. The outcome is compared against FBP and TV reconstruction and the proposed method provides a 5.4 dB PSNR improvement over the TV reconstruction while being significantly faster, giving reconstructions of 512 x 512 volumes in about 0.4 seconds using a single GPU. version:2
arxiv-1705-07637 | Kinodynamic Planning on Constraint Manifolds | http://arxiv.org/abs/1705.07637 | id:1705.07637 author:Ricard Bordalba, Lluís Ros, Josep M. Porta category:cs.RO  published:2017-05-22 summary:This paper presents a motion planner for systems subject to kinematic and dynamic constraints. The former appear when kinematic loops are present in the system, such as in parallel manipulators, in robots that cooperate to achieve a given task, or in situations involving contacts with the environment. The latter are necessary to obtain realistic trajectories, taking into account the forces acting on the system. The kinematic constraints make the state space become an implicitly-defined manifold, which complicates the application of common motion planning techniques. To address this issue, the planner constructs an atlas of the state space manifold incrementally, and uses this atlas both to generate random states and to dynamically simulate the steering of the system towards such states. The resulting tools are then exploited to construct a rapidly-exploring random tree (RRT) over the state space. To the best of our knowledge, this is the first randomized kinodynamic planner for implicitly-defined state spaces. The test cases presented in this paper validate the approach in significantly-complex systems. version:1
arxiv-1705-07615 | AIXIjs: A Software Demo for General Reinforcement Learning | http://arxiv.org/abs/1705.07615 | id:1705.07615 author:John Aslanides category:cs.AI  published:2017-05-22 summary:Reinforcement learning is a general and powerful framework with which to study and implement artificial intelligence. Recent advances in deep learning have enabled RL algorithms to achieve impressive performance in restricted domains such as playing Atari video games (Mnih et al., 2015) and, recently, the board game Go (Silver et al., 2016). However, we are still far from constructing a generally intelligent agent. Many of the obstacles and open questions are conceptual: What does it mean to be intelligent? How does one explore and learn optimally in general, unknown environments? What, in fact, does it mean to be optimal in the general sense? The universal Bayesian agent AIXI (Hutter, 2005) is a model of a maximally intelligent agent, and plays a central role in the sub-field of general reinforcement learning (GRL). Recently, AIXI has been shown to be flawed in important ways; it doesn't explore enough to be asymptotically optimal (Orseau, 2010), and it can perform poorly with certain priors (Leike and Hutter, 2015). Several variants of AIXI have been proposed to attempt to address these shortfalls: among them are entropy-seeking agents (Orseau, 2011), knowledge-seeking agents (Orseau et al., 2013), Bayes with bursts of exploration (Lattimore, 2013), MDL agents (Leike, 2016a), Thompson sampling (Leike et al., 2016), and optimism (Sunehag and Hutter, 2015). We present AIXIjs, a JavaScript implementation of these GRL agents. This implementation is accompanied by a framework for running experiments against various environments, similar to OpenAI Gym (Brockman et al., 2016), and a suite of interactive demos that explore different properties of the agents, similar to REINFORCEjs (Karpathy, 2015). We use AIXIjs to present numerous experiments illustrating fundamental properties of, and differences between, these agents. version:1
arxiv-1705-07558 | Note on Evolution and Forecasting of Requirements: Communications Example | http://arxiv.org/abs/1705.07558 | id:1705.07558 author:Mark Sh. Levin category:cs.NI cs.AI  published:2017-05-22 summary:Combinatorial evolution and forecasting of system requirements is examined. The morphological model is used for a hierarchical requirements system (i.e., system parts, design alternatives for the system parts, ordinal estimates for the alternatives). A set of system changes involves changes of the system structure, component alternatives and their estimates. The composition process of the forecast is based on combinatorial synthesis (knapsack problem, multiple choice problem, hierarchical morphological design). An illustrative numerical example for four-phase evolution and forecasting of requirements to communications is described. version:1
arxiv-1605-00495 | Coalition Formability Semantics with Conflict-Eliminable Sets of Arguments | http://arxiv.org/abs/1605.00495 | id:1605.00495 author:Ryuta Arisaka, Ken Satoh category:cs.AI  published:2016-05-02 summary:We consider abstract-argumentation-theoretic coalition formability in this work. Taking a model from political alliance among political parties, we will contemplate profitability, and then formability, of a coalition. As is commonly understood, a group forms a coalition with another group for a greater good, the goodness measured against some criteria. As is also commonly understood, however, a coalition may deliver benefits to a group X at the sacrifice of something that X was able to do before coalition formation, which X may be no longer able to do under the coalition. Use of the typical conflict-free sets of arguments is not very fitting for accommodating this aspect of coalition, which prompts us to turn to a weaker notion, conflict-eliminability, as a property that a set of arguments should primarily satisfy. We require numerical quantification of attack strengths as well as of argument strengths for its characterisation. We will first analyse semantics of profitability of a given conflict-eliminable set forming a coalition with another conflict-eliminable set, and will then provide four coalition formability semantics, each of which formalises certain utility postulate(s) taking the coalition profitability into account. version:2
arxiv-1705-07478 | Report of the HPC Correctness Summit, Jan 25--26, 2017, Washington, DC | http://arxiv.org/abs/1705.07478 | id:1705.07478 author:Ganesh Gopalakrishnan, Paul D. Hovland, Costin Iancu, Sriram Krishnamoorthy, Ignacio Laguna, Richard A. Lethin, Koushik Sen, Stephen F. Siegel, Armando Solar-Lezama category:cs.DC  published:2017-05-21 summary:Maintaining leadership in HPC requires the ability to support simulations at large scales and fidelity. In this study, we detail one of the most significant productivity challenges in achieving this goal, namely the increasing proclivity to bugs, especially in the face of growing hardware and software heterogeneity and sheer system scale. We identify key areas where timely new research must be proactively begun to address these challenges, and create new correctness tools that must ideally play a significant role even while ramping up toward exacale. We close with the proposal for a two-day workshop in which the problems identified in this report can be more broadly discussed, and specific plans to launch these new research thrusts identified. version:1
arxiv-1705-07465 | Some Schemes for Implementation of Arithmetic Operations with Complex Numbers Using Squaring Units | http://arxiv.org/abs/1705.07465 | id:1705.07465 author:Aleksandr Cariow, Galina Cariowa category:cs.AR 15A23  65Y20  65F30 F.2.1  G.1.0  I.1.2  published:2017-05-21 summary:In this paper, new schemes for a squarer, multiplier and divider of complex numbers are proposed. Traditional structural solutions for each of these operations require the presence some number of general-purpose binary multipliers. The advantage of our solutions is a removing of multiplications through replacing them by less costly squarers. We use Logan's trick and quarter square technique, which propose to replace the calculation of the product of two real numbers by summing the squares. Replacing usual multipliers on digital squares implies reducing power consumption as well as decreases hardware circuit complexity. The squarer requiring less area and power as compared to general-purpose multiplier, it is interesting to assess the use of squarers to implementation of complex arithmetic. version:1
arxiv-1701-08084 | Erasure Coding for Small Objects in In-Memory KV Storage | http://arxiv.org/abs/1701.08084 | id:1701.08084 author:Matt M. T. Yiu, Helen H. W. Chan, Patrick P. C. Lee category:cs.DB cs.DC  published:2017-01-27 summary:We present MemEC, an erasure-coding-based in-memory key-value (KV) store that achieves high availability and fast recovery while keeping low data redundancy across storage servers. MemEC is specifically designed for workloads dominated by small objects. By encoding objects in entirety, MemEC is shown to incur 60% less storage redundancy for small objects than existing replication- and erasure-coding-based approaches. It also supports graceful transitions between decentralized requests in normal mode (i.e., no failures) and coordinated requests in degraded mode (i.e., with failures). We evaluate our MemEC prototype via testbed experiments under read-heavy and update-heavy YCSB workloads. We show that MemEC achieves high throughput and low latency in both normal and degraded modes, and supports fast transitions between the two modes. version:2
arxiv-1705-07460 | Experience enrichment based task independent reward model | http://arxiv.org/abs/1705.07460 | id:1705.07460 author:Min Xu category:cs.AI  published:2017-05-21 summary:For most reinforcement learning approaches, the learning is performed by maximizing an accumulative reward that is expectedly and manually defined for specific tasks. However, in real world, rewards are emergent phenomena from the complex interactions between agents and environments. In this paper, we propose an implicit generic reward model for reinforcement learning. Unlike those rewards that are manually defined for specific tasks, such implicit reward is task independent. It only comes from the deviation from the agents' previous experiences. version:1
arxiv-1507-01384 | The method of artificial systems | http://arxiv.org/abs/1507.01384 | id:1507.01384 author:Christopher A. Tucker category:cs.AI  published:2015-07-06 summary:This document is written with the intention to describe in detail a method and means by which a computer program can reason about the world and in so doing, increase its analogue to a living system. As the literature is rife and it is apparent we, as scientists and engineers, have not found the solution, this document will attempt the solution by grounding its intellectual arguments within tenets of human cognition in Western philosophy. The result will be a characteristic description of a method to describe an artificial system analogous to that performed for a human. The approach was the substance of my Master's thesis, explored more deeply during the course of my postdoc research. It focuses primarily on context awareness and choice set within a boundary of available epistemology, which serves to describe it. Expanded upon, such a description strives to discover agreement with Kant's critique of reason to understand how it could be applied to define the architecture of its design. The intention has never been to mimic human or biological systems, rather, to understand the profoundly fundamental rules, when leveraged correctly, results in an artificial consciousness as noumenon while in keeping with the perception of it as phenomenon. version:2
arxiv-1704-02855 | A Decision Tree Based Approach Towards Adaptive Profiling of Distributed Applications | http://arxiv.org/abs/1704.02855 | id:1704.02855 author:Ioannis Giannakopoulos, Dimitrios Tsoumakos, Nectarios Koziris category:cs.DC cs.DB cs.PF  published:2017-04-10 summary:The adoption of the distributed paradigm has allowed applications to increase their scalability, robustness and fault tolerance, but it has also complicated their structure, leading to an exponential growth of the applications' configuration space and increased difficulty in predicting their performance. In this work, we describe a novel, automated profiling methodology that makes no assumptions on application structure. Our approach utilizes oblique Decision Trees in order to recursively partition an application's configuration space in disjoint regions, choose a set of representative samples from each subregion according to a defined policy and return a model for the entire space as a composition of linear models over each subregion. An extensive evaluation over real-life applications and synthetic performance functions showcases that our scheme outperforms other state-of-the-art profiling methodologies. It particularly excels at reflecting abnormalities and discontinuities of the performance function, allowing the user to influence the sampling policy based on the modeling accuracy and the space coverage. version:2
arxiv-1705-07429 | Sketched Answer Set Programming | http://arxiv.org/abs/1705.07429 | id:1705.07429 author:Sergey Paramonov, Christian Bessiere, Anton Dries, Luc De Raedt category:cs.AI  published:2017-05-21 summary:Answer Set Programming (ASP) is a powerful modeling formalism for combinatorial problems. However, writing ASP models is not trivial. We propose a novel method, called Sketched Answer Set Programming (SkASP), aiming at supporting the user in resolving this issue. The user writes an ASP program while marking uncertain parts open with question marks. In addition, the user provides a number of positive and negative examples of the desired program behaviour. The sketched model is rewritten into another ASP program, which is solved by traditional methods. As a result, the user obtains a functional and reusable ASP program modelling her problem. We evaluate our approach on 21 well known puzzles and combinatorial problems inspired by Karp's 21 NP-complete problems and demonstrate a use-case for a database application based on ASP. version:1
arxiv-1705-07400 | MITHRIL: Mining Sporadic Associations for Cache Prefetching | http://arxiv.org/abs/1705.07400 | id:1705.07400 author:Juncheng Yang, Reza Karimi, Trausti Sæmundsson, Avani Wildani, Ymir Vigfusson category:cs.PF cs.DC cs.OS  published:2017-05-21 summary:The growing pressure on cloud application scalability has accentuated storage performance as a critical bottle- neck. Although cache replacement algorithms have been extensively studied, cache prefetching - reducing latency by retrieving items before they are actually requested remains an underexplored area. Existing approaches to history-based prefetching, in particular, provide too few benefits for real systems for the resources they cost. We propose MITHRIL, a prefetching layer that efficiently exploits historical patterns in cache request associations. MITHRIL is inspired by sporadic association rule mining and only relies on the timestamps of requests. Through evaluation of 135 block-storage traces, we show that MITHRIL is effective, giving an average of a 55% hit ratio increase over LRU and PROBABILITY GRAPH, a 36% hit ratio gain over AMP at reasonable cost. We further show that MITHRIL can supplement any cache replacement algorithm and be readily integrated into existing systems. Furthermore, we demonstrate the improvement comes from MITHRIL being able to capture mid-frequency blocks. version:1
arxiv-1705-07369 | Broadcasting in Noisy Radio Networks | http://arxiv.org/abs/1705.07369 | id:1705.07369 author:Keren Censor-Hillel, Bernhard Haeupler, D. Ellis Hershkowitz, Goran Zuzic category:cs.DC cs.DS  published:2017-05-21 summary:The widely-studied radio network model [Chlamtac and Kutten, 1985] is a graph-based description that captures the inherent impact of collisions in wireless communication. In this model, the strong assumption is made that node $v$ receives a message from a neighbor if and only if exactly one of its neighbors broadcasts. We relax this assumption by introducing a new noisy radio network model in which random faults occur at senders or receivers. Specifically, for a constant noise parameter $p \in [0,1)$, either every sender has probability $p$ of transmitting noise or every receiver of a single transmission in its neighborhood has probability $p$ of receiving noise. We first study single-message broadcast algorithms in noisy radio networks and show that the Decay algorithm [Bar-Yehuda et al., 1992] remains robust in the noisy model while the diameter-linear algorithm of Gasieniec et al., 2007 does not. We give a modified version of the algorithm of Gasieniec et al., 2007 that is robust to sender and receiver faults, and extend both this modified algorithm and the Decay algorithm to robust multi-message broadcast algorithms. We next investigate the extent to which (network) coding improves throughput in noisy radio networks. We address the previously perplexing result of Alon et al. 2014 that worst case coding throughput is no better than worst case routing throughput up to constants: we show that the worst case throughput performance of coding is, in fact, superior to that of routing -- by a $\Theta(\log(n))$ gap -- provided receiver faults are introduced. However, we show that any coding or routing scheme for the noiseless setting can be transformed to be robust to sender faults with only a constant throughput overhead. These transformations imply that the results of Alon et al., 2014 carry over to noisy radio networks with sender faults. version:1
arxiv-1705-07343 | Why You Should Charge Your Friends for Borrowing Your Stuff | http://arxiv.org/abs/1705.07343 | id:1705.07343 author:Kijung Shin, Euiwoong Lee, Dhivya Eswaran, Ariel D. Procaccia category:cs.AI cs.GT cs.MA cs.SI  published:2017-05-20 summary:We consider goods that can be shared with k-hop neighbors (i.e., the set of nodes within k hops from an owner) on a social network. We examine incentives to buy such a good by devising game-theoretic models where each node decides whether to buy the good or free ride. First, we find that social inefficiency, specifically excessive purchase of the good, occurs in Nash equilibria. Second, the social inefficiency decreases as k increases and thus a good can be shared with more nodes. Third, and most importantly, the social inefficiency can also be significantly reduced by charging free riders an access cost and paying it to owners, leading to the conclusion that organizations and system designers should impose such a cost. These findings are supported by our theoretical analysis in terms of the price of anarchy and the price of stability; and by simulations based on synthetic and real social networks. version:1
arxiv-1705-07339 | Combining tabu search and graph reduction to solve the maximum balanced biclique problem | http://arxiv.org/abs/1705.07339 | id:1705.07339 author:Yi Zhou, Jin-Kao Hao category:cs.AI  published:2017-05-20 summary:The Maximum Balanced Biclique Problem is a well-known graph model with relevant applications in diverse domains. This paper introduces a novel algorithm, which combines an effective constraint-based tabu search procedure and two dedicated graph reduction techniques. We verify the effectiveness of the algorithm on 30 classical random benchmark graphs and 25 very large real-life sparse graphs from the popular Koblenz Network Collection (KONECT). The results show that the algorithm improves the best-known results (new lower bounds) for 10 classical benchmarks and obtains the optimal solutions for 14 KONECT instances. version:1
arxiv-1705-07327 | Dynamic Analysis of the Arrow Distributed Directory Protocol in General Networks | http://arxiv.org/abs/1705.07327 | id:1705.07327 author:Abdolhamid Ghodselahi, Fabian Kuhn category:cs.DS cs.DC F.1.2; F.2.2; G.2.2  published:2017-05-20 summary:The Arrow protocol is a simple and elegant protocol to coordinate exclusive access to a shared object in a network. The protocol solves the underlying distributed queueing problem by using path reversal on a pre-computed spanning tree (or any other tree topology simulated on top of the given network). It is known that the Arrow protocol solves the problem with a competitive ratio of O(log D) on trees of diameter D. This implies a distributed queueing algorithm with competitive ratio O(s*log D) for general networks with a spanning tree of diameter D and stretch s. In this work we show that when running the Arrow protocol on top of the well-known probabilistic tree embedding of Fakcharoenphol, Rao, and Talwar [STOC 03], we obtain a randomized distributed queueing algorithm with a competitive ratio of O(log n) even on general network topologies. The result holds even if the queueing requests occur in an arbitrarily dynamic and concurrent fashion and even if communication is asynchronous. From a technical point of view, the main of the paper shows that the competitive ratio of the Arrow protocol is constant on a special family of tree topologies, known as hierarchically well separated trees. version:1
arxiv-1705-07281 | Cache Hierarchy Optimization | http://arxiv.org/abs/1705.07281 | id:1705.07281 author:Leonid Yavits, Amir Morad, Ran Ginosar category:cs.AR  published:2017-05-20 summary:Power consumption, off-chip memory bandwidth, chip area and Network on Chip (NoC) capacity are among main chip resources limiting the scalability of Chip Multiprocessors (CMP). A closed form analytical solution for optimizing the CMP cache hierarchy and optimally allocating area among hierarchy levels under such constrained resources is developed. The optimization framework is extended by incorporating the impact of data sharing on cache miss rate. An analytical model for cache access time as a function of cache size is proposed and verified using CACTI simulation. version:1
arxiv-1705-07280 | The Effect of Temperature on Amdahl Law in 3D Multicore Era | http://arxiv.org/abs/1705.07280 | id:1705.07280 author:Leonid Yavits, Amir Morad, Ran Ginosar category:cs.AR  published:2017-05-20 summary:This work studies the influence of temperature on performance and scalability of 3D Chip Multiprocessors (CMP) from Amdahl law perspective. We find that 3D CMP may reach its thermal limit before reaching its maximum power. We show that a high level of parallelism may lead to high peak temperatures even in small scale 3D CMPs, thus limiting 3D CMP scalability and calling for different, in-memory computing architectures. version:1
arxiv-1705-07269 | Learning to Factor Policies and Action-Value Functions: Factored Action Space Representations for Deep Reinforcement learning | http://arxiv.org/abs/1705.07269 | id:1705.07269 author:Sahil Sharma, Aravind Suresh, Rahul Ramesh, Balaraman Ravindran category:cs.LG cs.AI  published:2017-05-20 summary:Deep Reinforcement Learning (DRL) methods have performed well in an increasing numbering of high-dimensional visual decision making domains. Among all such visual decision making problems, those with discrete action spaces often tend to have underlying compositional structure in the said action space. Such action spaces often contain actions such as go left, go up as well as go diagonally up and left (which is a composition of the former two actions). The representations of control policies in such domains have traditionally been modeled without exploiting this inherent compositional structure in the action spaces. We propose a new learning paradigm, Factored Action space Representations (FAR) wherein we decompose a control policy learned using a Deep Reinforcement Learning Algorithm into independent components, analogous to decomposing a vector in terms of some orthogonal basis vectors. This architectural modification of the control policy representation allows the agent to learn about multiple actions simultaneously, while executing only one of them. We demonstrate that FAR yields considerable improvements on top of two DRL algorithms in Atari 2600: FARA3C outperforms A3C (Asynchronous Advantage Actor Critic) in 9 out of 14 tasks and FARAQL outperforms AQL (Asynchronous n-step Q-Learning) in 9 out of 13 tasks. version:1
arxiv-1705-07267 | Search Engine Guided Non-Parametric Neural Machine Translation | http://arxiv.org/abs/1705.07267 | id:1705.07267 author:Jiatao Gu, Yong Wang, Kyunghyun Cho, Victor O. K. Li category:cs.CL cs.AI cs.LG  published:2017-05-20 summary:In this paper, we extend an attention-based neural machine translation (NMT) model by allowing it to access an entire training set of parallel sentence pairs even after training. The proposed approach consists of two stages. In the first stage--retrieval stage--, an off-the-shelf, black-box search engine is used to retrieve a small subset of sentence pairs from a training set given a source sentence. These pairs are further filtered based on a fuzzy matching score based on edit distance. In the second stage--translation stage--, a novel translation model, called translation memory enhanced NMT (TM-NMT), seamlessly uses both the source sentence and a set of retrieved sentence pairs to perform the translation. Empirical evaluation on three language pairs (En-Fr, En-De, and En-Es) shows that the proposed approach significantly outperforms the baseline approach and the improvement is more significant when more relevant sentence pairs were retrieved. version:1
arxiv-1705-07254 | BRPL: Backpressure RPL for High-throughput and Mobile IoTs | http://arxiv.org/abs/1705.07254 | id:1705.07254 author:Yad Tahir, Shusen Yang, Julie McCann category:cs.NI cs.DC  published:2017-05-20 summary:RPL, an IPv6 routing protocol for Low power Lossy Networks (LLNs), is considered to be the de facto routing standard for the Internet of Things (IoT). However, more and more experimental results demonstrate that RPL performs poorly when it comes to throughput and adaptability to network dynamics. This significantly limits the application of RPL in many practical IoT scenarios, such as an LLN with high-speed sensor data streams and mobile sensing devices. To address this issue, we develop BRPL, an extension of RPL, providing a practical approach that allows users to smoothly combine any RPL Object Function (OF) with backpressure routing. BRPL uses two novel algorithms, QuickTheta and QuickBeta, to support time-varying data traffic loads and node mobility respectively. We implement BRPL on Contiki OS, an open-source operating system for the Internet of Things. We conduct an extensive evaluation using both real-world experiments based on the FIT IoT-LAB testbed and large-scale simulations using Cooja over 18 virtual servers on the Cloud. The evaluation results demonstrate that BRPL not only is fully backward compatible with RPL (i.e. devices running RPL and BRPL can work together seamlessly), but also significantly improves network throughput and adaptability to changes in network topologies and data traffic loads. The observed packet loss reduction in mobile networks is, at a minimum, 60% and up to 1000% can be seen in extreme cases. version:1
arxiv-1705-07231 | Adapting Low-Cost Platforms for Robotics Research | http://arxiv.org/abs/1705.07231 | id:1705.07231 author:Thommen George Karimpanal, Mohammadreza Chamanbaz, Wenzheng Li, Timothy Jeruzalski, Abhishek Gupta, Erik Wilhelm category:cs.RO  published:2017-05-20 summary:Validation of robotics theory on real-world hardware platforms is important to prove the practical feasibility of algorithms. This paper discusses some of the lessons learned while adapting the EvoBot, a low-cost robotics platform that we designed and prototyped, for research in diverse areas in robotics. The EvoBot platform was designed to be a low cost, open source, general purpose robotics platform intended to enable testing and validation of algorithms from a wide variety of sub-fields of robotics. Throughout the paper, we outline and discuss some common failures, practical limitations and inconsistencies between theory and practice that one may encounter while adapting such low-cost platforms for robotics research. We demonstrate these aspects through four representative common robotics tasks- localization, real-time control, swarm consensus and path planning applications, performed using the EvoBots. We also propose some potential solutions to the encountered problems and try to generalize them. version:1
arxiv-1705-07226 | RankPL: A Qualitative Probabilistic Programming Language | http://arxiv.org/abs/1705.07226 | id:1705.07226 author:Tjitze Rienstra category:cs.AI cs.PL  published:2017-05-19 summary:In this paper we introduce RankPL, a modeling language that can be thought of as a qualitative variant of a probabilistic programming language with a semantics based on Spohn's ranking theory. Broadly speaking, RankPL can be used to represent and reason about processes that exhibit uncertainty expressible by distinguishing "normal" from" surprising" events. RankPL allows (iterated) revision of rankings over alternative program states and supports various types of reasoning, including abduction and causal inference. We present the language, its denotational semantics, and a number of practical examples. We also discuss an implementation of RankPL that is available for download. version:1
arxiv-1705-07224 | AIDE: An algorithm for measuring the accuracy of probabilistic inference algorithms | http://arxiv.org/abs/1705.07224 | id:1705.07224 author:Marco F. Cusumano-Towner, Vikash K. Mansinghka category:stat.ML cs.AI cs.LG  published:2017-05-19 summary:Approximate probabilistic inference algorithms are central to many fields. Examples include sequential Monte Carlo inference in robotics, variational inference in machine learning, and Markov chain Monte Carlo inference in statistics. A key problem faced by practitioners is measuring the accuracy of an approximate inference algorithm on a specific dataset. This paper introduces the auxiliary inference divergence estimator (AIDE), an algorithm for measuring the accuracy of approximate inference algorithms. AIDE is based on the observation that inference algorithms can be treated as probabilistic models and the random variables used within the inference algorithm can be viewed as auxiliary variables. This view leads to a new estimator for the symmetric KL divergence between the output distributions of two inference algorithms. The paper illustrates application of AIDE to algorithms for inference in regression, hidden Markov, and Dirichlet process mixture models. The experiments show that AIDE captures the qualitative behavior of a broad class of inference algorithms and can detect failure modes of inference algorithms that are missed by standard heuristics. version:1
arxiv-1705-07212 | Space Complexity of Fault Tolerant Register Emulations | http://arxiv.org/abs/1705.07212 | id:1705.07212 author:Gregory Chockler, Alexander Spiegelman category:cs.DC C.2.4; D.4.7  published:2017-05-19 summary:Driven by the rising popularity of cloud storage, the costs associated with implementing reliable storage services from a collection of fault-prone servers have recently become an actively studied question. The well-known ABD result shows that an f-tolerant register can be emulated using a collection of 2f + 1 fault-prone servers each storing a single read-modify-write object type, which is known to be optimal. In this paper we generalize this bound: we investigate the inherent space complexity of emulating reliable multi-writer registers as a fucntion of the type of the base objects exposed by the underlying servers, the number of writers to the emulated register, the number of available servers, and the failure threshold. We establish a sharp separation between registers, and both max-registers (the base object types assumed by ABD) and CAS in terms of the resources (i.e., the number of base objects of the respective types) required to support the emulation; we show that no such separation exists between max-registers and CAS. Our main technical contribution is lower and upper bounds on the resources required in case the underlying base objects are fault-prone read/write registers. We show that the number of required registers is directly proportional to the number of writers and inversely proportional to the number of servers. version:1
arxiv-1705-07177 | Model-Based Planning in Discrete Action Spaces | http://arxiv.org/abs/1705.07177 | id:1705.07177 author:Mikael Henaff, William F. Whitney, Yann LeCun category:cs.AI  published:2017-05-19 summary:Planning actions using learned and differentiable forward models of the world is a general approach which has a number of desirable properties, including improved sample complexity over model-free RL methods, reuse of learned models across different tasks, and the ability to perform efficient gradient-based optimization in continuous action spaces. However, this approach does not apply straightforwardly when the action space is discrete, which may have limited its adoption. In this work, we introduce two discrete planning tasks inspired by existing question-answering datasets and show that it is in fact possible to effectively perform planning via backprop in discrete action spaces using two simple yet principled modifications. Our experiments show that this approach can significantly outperform model-free RL based methods and supervised imitation learners. version:1
arxiv-1705-07175 | Espresso: Efficient Forward Propagation for BCNNs | http://arxiv.org/abs/1705.07175 | id:1705.07175 author:Fabrizio Pedersoli, George Tzanetakis, Andrea Tagliasacchi category:cs.DC cs.CV cs.LG cs.NE 62M45 I.2.6  published:2017-05-19 summary:There are many applications scenarios for which the computational performance and memory footprint of the prediction phase of Deep Neural Networks (DNNs) needs to be optimized. Binary Neural Networks (BDNNs) have been shown to be an effective way of achieving this objective. In this paper, we show how Convolutional Neural Networks (CNNs) can be implemented using binary representations. Espresso is a compact, yet powerful library written in C/CUDA that features all the functionalities required for the forward propagation of CNNs, in a binary file less than 400KB, without any external dependencies. Although it is mainly designed to take advantage of massive GPU parallelism, Espresso also provides an equivalent CPU implementation for CNNs. Espresso provides special convolutional and dense layers for BCNNs, leveraging bit-packing and bit-wise computations for efficient execution. These techniques provide a speed-up of matrix-multiplication routines, and at the same time, reduce memory usage when storing parameters and activations. We experimentally show that Espresso is significantly faster than existing implementations of optimized binary neural networks ($\approx$ 2 orders of magnitude). Espresso is released under the Apache 2.0 license and is available at http://github.com/fpeder/espresso. version:1
arxiv-1705-07114 | A Comparison of Reinforcement Learning Techniques for Fuzzy Cloud Auto-Scaling | http://arxiv.org/abs/1705.07114 | id:1705.07114 author:Hamid Arabnejad, Claus Pahl, Pooyan Jamshidi, Giovani Estrada category:cs.DC cs.AI  published:2017-05-19 summary:A goal of cloud service management is to design self-adaptable auto-scaler to react to workload fluctuations and changing the resources assigned. The key problem is how and when to add/remove resources in order to meet agreed service-level agreements. Reducing application cost and guaranteeing service-level agreements (SLAs) are two critical factors of dynamic controller design. In this paper, we compare two dynamic learning strategies based on a fuzzy logic system, which learns and modifies fuzzy scaling rules at runtime. A self-adaptive fuzzy logic controller is combined with two reinforcement learning (RL) approaches: (i) Fuzzy SARSA learning (FSL) and (ii) Fuzzy Q-learning (FQL). As an off-policy approach, Q-learning learns independent of the policy currently followed, whereas SARSA as an on-policy always incorporates the actual agent's behavior and leads to faster learning. Both approaches are implemented and compared in their advantages and disadvantages, here in the OpenStack cloud platform. We demonstrate that both auto-scaling approaches can handle various load traffic situations, sudden and periodic, and delivering resources on demand while reducing operating costs and preventing SLA violations. The experimental results demonstrate that FSL and FQL have acceptable performance in terms of adjusted number of virtual machine targeted to optimize SLA compliance and response time. version:1
arxiv-1705-07105 | The Bag Semantics of Ontology-Based Data Access | http://arxiv.org/abs/1705.07105 | id:1705.07105 author:Charalampos Nikolaou, Egor V. Kostylev, George Konstantinidis, Mark Kaminski, Bernardo Cuenca Grau, Ian Horrocks category:cs.AI  published:2017-05-19 summary:Ontology-based data access (OBDA) is a popular approach for integrating and querying multiple data sources by means of a shared ontology. The ontology is linked to the sources using mappings, which assign views over the data to ontology predicates. Motivated by the need for OBDA systems supporting database-style aggregate queries, we propose a bag semantics for OBDA, where duplicate tuples in the views defined by the mappings are retained, as is the case in standard databases. We show that bag semantics makes conjunctive query answering in OBDA coNP-hard in data complexity. To regain tractability, we consider a rather general class of queries and show its rewritability to a generalisation of the relational calculus to bags. version:1
arxiv-1705-07095 | Induction of Interpretable Possibilistic Logic Theories from Relational Data | http://arxiv.org/abs/1705.07095 | id:1705.07095 author:Ondrej Kuzelka, Jesse Davis, Steven Schockaert category:cs.AI  published:2017-05-19 summary:The field of Statistical Relational Learning (SRL) is concerned with learning probabilistic models from relational data. Learned SRL models are typically represented using some kind of weighted logical formulas, which make them considerably more interpretable than those obtained by e.g. neural networks. In practice, however, these models are often still difficult to interpret correctly, as they can contain many formulas that interact in non-trivial ways and weights do not always have an intuitive meaning. To address this, we propose a new SRL method which uses possibilistic logic to encode relational models. Learned models are then essentially stratified classical theories, which explicitly encode what can be derived with a given level of certainty. Compared to Markov Logic Networks (MLNs), our method is faster and produces considerably more interpretable models. version:1
arxiv-1705-07086 | Estimating Accuracy from Unlabeled Data: A Probabilistic Logic Approach | http://arxiv.org/abs/1705.07086 | id:1705.07086 author:Emmanouil A. Platanios, Hoifung Poon, Tom M. Mitchell, Eric Horvitz category:cs.LG cs.AI stat.ML  published:2017-05-19 summary:We propose an efficient method to estimate the accuracy of classifiers using only unlabeled data. We consider a setting with multiple classification problems where the target classes may be tied together through logical constraints. For example, a set of classes may be mutually exclusive, meaning that a data instance can belong to at most one of them. The proposed method is based on the intuition that: (i) when classifiers agree, they are more likely to be correct, and (ii) when the classifiers make a prediction that violates the constraints, at least one classifier must be making an error. Experiments on four real-world data sets produce accuracy estimates within a few percent of the true accuracy, using solely unlabeled data. Our models also outperform existing state-of-the-art solutions in both estimating accuracies, and combining multiple classifier outputs. The results emphasize the utility of logical constraints in estimating accuracy, thus validating our intuition. version:1
arxiv-1705-07069 | CacheShuffle: An Oblivious Shuffle Algorithm Using Caches | http://arxiv.org/abs/1705.07069 | id:1705.07069 author:Sarvar Patel, Giuseppe Persiano, Kevin Yeo category:cs.CR cs.DC cs.DS  published:2017-05-19 summary:In this work, we present CacheShuffle, an algorithm for obliviously shuffling data on an untrusted server. Our methods improve the previously best known results by reducing the number of block accesses to (4 + \epsilon)N which is close to the lower bound of 2N. Experimentation shows that for practical sizes of N, there is a 4x improvement over the previous best result. Also our result only requires 2 roundtrips compared to 5 roundtrips needed by the previous result. The novelty in our algorithm involves introducing a persistent client cache. Additionally, we show a recursive version of our algorithm which allows oblivious shuffling with smaller client memory. version:1
arxiv-1601-07815 | Convex Optimization of Real Time SoC | http://arxiv.org/abs/1601.07815 | id:1601.07815 author:L. Yavits, A. Morad, R. Ginosar, U. Weiser category:cs.DC cs.PF  published:2016-01-28 summary:Convex optimization methods are employed to optimize a real-time (RT) system-on-chip (SoC) under a variety of physical resource-driven constraints, demonstrated on an industry MPEG2 encoder SoC. The power optimization is compared to conventional performance-optimization framework, showing a factor of two and a half saving in power. Convex optimization is shown to be very efficient in a high-level early stage design exploration, guiding computer architects as to the choice of area, voltage, and frequency of the individual components of the Chip Multiprocessor (CMP). version:2
arxiv-1611-01137 | A Memory Bandwidth-Efficient Hybrid Radix Sort on GPUs | http://arxiv.org/abs/1611.01137 | id:1611.01137 author:Elias Stehle, Hans-Arno Jacobsen category:cs.DB cs.DC cs.DS  published:2016-11-03 summary:Sorting is at the core of many database operations, such as index creation, sort-merge joins, and user-requested output sorting. As GPUs are emerging as a promising platform to accelerate various operations, sorting on GPUs becomes a viable endeavour. Over the past few years, several improvements have been proposed for sorting on GPUs, leading to the first radix sort implementations that achieve a sorting rate of over one billion 32-bit keys per second. Yet, state-of-the-art approaches are heavily memory bandwidth-bound, as they require substantially more memory transfers than their CPU-based counterparts. Our work proposes a novel approach that almost halves the amount of memory transfers and, therefore, considerably lifts the memory bandwidth limitation. Being able to sort two gigabytes of eight-byte records in as little as 50 milliseconds, our approach achieves a 2.32-fold improvement over the state-of-the-art GPU-based radix sort for uniform distributions, sustaining a minimum speed-up of no less than a factor of 1.66 for skewed distributions. To address inputs that either do not reside on the GPU or exceed the available device memory, we build on our efficient GPU sorting approach with a pipelined heterogeneous sorting algorithm that mitigates the overhead associated with PCIe data transfers. Comparing the end-to-end sorting performance to the state-of-the-art CPU-based radix sort running 16 threads, our heterogeneous approach achieves a 2.06-fold and a 1.53-fold improvement for sorting 64 GB key-value pairs with a skewed and a uniform distribution, respectively. version:2
arxiv-1601-02781 | BAMCloud: A Cloud Based Mobile Biometric Authentication Framework | http://arxiv.org/abs/1601.02781 | id:1601.02781 author:Farhana Javed Zareen, Kashish Ara Shakil, Mansaf Alam, Suraiya Jabin category:cs.DC cs.CR  published:2016-01-12 summary:With an exponential increase in number of users switching to mobile banking, various countries are adopting biometric solutions as security measures. The main reason for biometric technologies becoming more common in the everyday lives of consumers is because of the facility to easily capture biometric data in real time, using their mobile phones. Biometric technologies are providing the potential security framework to make banking more convenient and secure than it has ever been. At the same time, the exponential growth of enrollment in the biometric system produces massive amount of high dimensionality data that leads to degradation in the performance of the mobile banking systems. Therefore, in order to overcome the performance issues arising due to this data deluge, this paper aims to propose a distributed mobile biometric system based on a high performance cluster Cloud. High availability, better time efficiency and scalability are some of the added advantages of using the proposed system. In this paper a Cloud based mobile biometric authentication framework (BAMCloud) is proposed that uses dynamic signatures and performs authentication. It includes the steps involving data capture using any handheld mobile device, then storage, preprocessing and training the system in a distributed manner over Cloud. For this purpose we have implemented it using MapReduce on Hadoop platform and for training Levenberg-Marquardt backpropagation neural network has been used. Moreover, the methodology adopted is very novel as it achieves a speedup of 8.5x and a performance of 96.23%. Furthermore, the cost benefit analysis of the implemented system shows that the cost of implementation and execution of the system is lesser than the existing ones. The experiments demonstrate that the better performance is achieved by proposed framework as compared to the other methods used in the recent literature. version:2
arxiv-1705-06936 | Atari games and Intel processors | http://arxiv.org/abs/1705.06936 | id:1705.06936 author:Robert Adamski, Tomasz Grel, Maciej Klimek, Henryk Michalewski category:cs.DC cs.AI cs.LG  published:2017-05-19 summary:The asynchronous nature of the state-of-the-art reinforcement learning algorithms such as the Asynchronous Advantage Actor-Critic algorithm, makes them exceptionally suitable for CPU computations. However, given the fact that deep reinforcement learning often deals with interpreting visual information, a large part of the train and inference time is spent performing convolutions. In this work we present our results on learning strategies in Atari games using a Convolutional Neural Network, the Math Kernel Library and TensorFlow 0.11rc0 machine learning framework. We also analyze effects of asynchronous computations on the convergence of reinforcement learning algorithms. version:1
arxiv-1705-07121 | BAMHealthCloud: A Biometric Authentication and Data Management System for Healthcare Data in Cloud | http://arxiv.org/abs/1705.07121 | id:1705.07121 author:Kashish A. Shakil, Farhana J. Zareen, Mansaf Alam, Suraiya Jabin category:cs.CR cs.CY cs.DC  published:2017-05-19 summary:Advancements in healthcare industry with new technology and population growth has given rise to security threat to our most personal data. The healthcare data management system consists of records in different formats such as text, numeric, pictures and videos leading to data which is big and unstructured. Also, hospitals have several branches at different locations throughout a country and overseas. In view of these requirements a cloud based healthcare management system can be an effective solution for efficient health care data management. One of the major concerns of a cloud based healthcare system is the security aspect. It includes theft to identity, tax fraudulence, insurance frauds, medical frauds and defamation of high profile patients. Hence, a secure data access and retrieval is needed in order to provide security of critical medical records in health care management system. Biometric authentication mechanism is suitable in this scenario since it overcomes the limitations of token theft and forgetting passwords in conventional token id-password mechanism used for providing security. It also has high accuracy rate for secure data access and retrieval. In this paper we propose BAMHealthCloud which is a cloud based system for management of healthcare data, it ensures security of data through biometric authentication. It has been developed after performing a detailed case study on healthcare sector in a developing country. Training of the signature samples for authentication purpose has been performed in parallel on hadoop MapReduce framework using Resilient Backpropagation neural network. From rigorous experiments it can be concluded that it achieves a speedup of 9x, Equal error rate (EER) of 0.12, sensitivity of 0.98 and specificity of 0.95 as compared to other approaches existing in literature. version:1
arxiv-1705-06927 | Foundations of Declarative Data Analysis Using Limit Datalog Programs | http://arxiv.org/abs/1705.06927 | id:1705.06927 author:Mark Kaminski, Bernardo Cuenca Grau, Egor V. Kostylev, Boris Motik, Ian Horrocks category:cs.AI cs.LO  published:2017-05-19 summary:Motivated by applications in declarative data analysis, we study $\mathit{Datalog}_{\mathbb{Z}}$---an extension of positive Datalog with arithmetic functions over integers. This language is known to be undecidable, so we propose two fragments. In $\mathit{limit}~\mathit{Datalog}_{\mathbb{Z}}$ predicates are axiomatised to keep minimal/maximal numeric values, allowing us to show that fact entailment is coNExpTime-complete in combined, and coNP-complete in data complexity. Moreover, an additional $\mathit{stability}$ requirement causes the complexity to drop to ExpTime and PTime, respectively. Finally, we show that stable $\mathit{Datalog}_{\mathbb{Z}}$ can express many useful data analysis tasks, and so our results provide a sound foundation for the development of advanced information systems. version:1
arxiv-1705-06923 | MultiAmdahl: Optimal Resource Allocation in Heterogeneous Architectures | http://arxiv.org/abs/1705.06923 | id:1705.06923 author:Leonid Yavits, Amir Morad, Uri Weiser, Ran Ginosar category:cs.AR  published:2017-05-19 summary:Future multiprocessor chips will integrate many different units, each tailored to a specific computation. When designing such a system, the chip architect must decide how to distribute limited system resources such as area, power, and energy among the computational units. We extend MultiAmdahl, an analytical optimization technique for resource allocation in heterogeneous architectures, for energy optimality under a variety of constant system power scenarios. We conclude that reduction in constant system power should be met by reallocating resources from general-purpose computing to heterogeneous accelerator-dominated computing, to keep the overall energy consumption at a minimum. We extend this conclusion to offer an intuition regarding energy-optimal resource allocation in data center computing. version:1
arxiv-1705-06521 | Plane Formation by Synchronous Mobile Robots without Chirality | http://arxiv.org/abs/1705.06521 | id:1705.06521 author:Yusaku Tomita, Yukiko Yamauchi, Shuji Kijima, Masafumi Yamashita category:cs.DC  published:2017-05-18 summary:We consider a distributed system consisting of autonomous mobile computing entities, called robots, moving in a specified space. The robots are anonymous, oblivious, and have neither any access to the global coordinate system nor any explicit communication medium. Each robot observes the positions of other robots and moves in terms of its local coordinate system. To investigate the self-organization power of robot systems, formation problems in the two dimensional space (2D-space) have been extensively studied. Yamauchi et al. (DISC 2015) introduced robot systems in the three dimensional space (3D-space). While existing results for 3D-space assume that the robots agree on the handedness of their local coordinate systems, we remove the assumption and consider the robots without chirality. One of the most fundamental agreement problems in 3D-space is the plane formation problem that requires the robots to land on a common plane, that is not predefined. It has been shown that the solvability of the plane formation problem by robots with chirality is determined by the rotation symmetry of their initial local coordinate systems because the robots cannot break it. We show that when the robots lack chirality, the combination of rotation symmetry and reflection symmetry determines the solvability of the plane formation problem because a set of symmetric local coordinate systems without chirality is obtained by rotations and reflections. This richer symmetry results in the increase of unsolvable instances compared with robots with chirality and a flaw of existing plane formation algorithm. In this paper, we give a characterization of initial configurations from which the robots without chirality can form a plane and a new plane formation algorithm for solvable instances. version:2
arxiv-1702-01135 | Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks | http://arxiv.org/abs/1702.01135 | id:1702.01135 author:Guy Katz, Clark Barrett, David Dill, Kyle Julian, Mykel Kochenderfer category:cs.AI cs.LO  published:2017-02-03 summary:Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can successfully prove properties of networks that are an order of magnitude larger than the largest networks verified using existing methods. version:2
arxiv-1202-6456 | A Resource-Competitive Jamming Defense | http://arxiv.org/abs/1202.6456 | id:1202.6456 author:Valerie King, Seth Pettie, Jared Saia, Maxwell Young category:cs.DC  published:2012-02-29 summary:Consider a scenario where Alice wishes to send a message $m$ to Bob in a time-slotted wireless network. However, there exists an adversary, Carol, who aims to prevent the transmission of $m$ by jamming the communication channel. There is a per-slot cost of $1$ to send, receive or jam $m$ on the channel, and we are interested in how much Alice and Bob need to spend relative to Carol in order to guarantee communication. Our approach is to design an algorithm in the framework of resource-competitive analysis where the cost to correct network devices (i.e., Alice and Bob) is parameterized by the cost to faulty devices (i.e., Carol). We present an algorithm that guarantees the successful transmission of $m$ and has the following property: if Carol incurs a cost of $T$ to jam, then both Alice and Bob have a cost of $O(T^{\varphi - 1} + 1)=O(T^{.62}+1)$ in expectation, where $\varphi = (1+ \sqrt{5})/2$ is the golden ratio. In other words, it possible for Alice and Bob to communicate while incurring asymptotically less cost than Carol. We generalize to the case where Alice wishes to send $m$ to $n$ receivers, and we achieve a similar result. Our findings hold even if (1) $T$ is unknown to either party; (2) Carol knows the algorithms of both parties, but not their random bits; (3) Carol can jam using knowledge of past actions of both parties; and (4) Carol can jam reactively, so long as there is sufficient network traffic in addition to $m$. version:2
arxiv-1705-06840 | The Conference Paper Assignment Problem: Using Order Weighted Averages to Assign Indivisible Goods | http://arxiv.org/abs/1705.06840 | id:1705.06840 author:Jing Wu Lian, Nicholas Mattei, Renee Noble, Toby Walsh category:cs.AI cs.GT cs.MA 91A80  91B74 J.4; I.2; G.1.6  published:2017-05-19 summary:Motivated by the common academic problem of allocating papers to referees for conference reviewing we propose a novel mechanism for solving the assignment problem when we have a two sided matching problem with preferences from one side (the agents/reviewers) over the other side (the objects/papers) and both sides have capacity constraints. The assignment problem is a fundamental problem in both computer science and economics with application in many areas including task and resource allocation. We draw inspiration from multi-criteria decision making and voting and use order weighted averages (OWAs) to propose a novel and flexible class of algorithms for the assignment problem. We show an algorithm for finding a $\Sigma$-OWA assignment in polynomial time, in contrast to the NP-hardness of finding an egalitarian assignment. Inspired by this setting we observe an interesting connection between our model and the classic proportional multi-winner election problem in social choice. version:1
arxiv-1701-01189 | GPU Multisplit: an extended study of a parallel algorithm | http://arxiv.org/abs/1701.01189 | id:1701.01189 author:Saman Ashkiani, Andrew Davidson, Ulrich Meyer, John D. Owens category:cs.DC  published:2017-01-05 summary:Multisplit is a broadly useful parallel primitive that permutes its input data into contiguous buckets or bins, where the function that categorizes an element into a bucket is provided by the programmer. Due to the lack of an efficient multisplit on GPUs, programmers often choose to implement multisplit with a sort. One way is to first generate an auxiliary array of bucket IDs and then sort input data based on it. In case smaller indexed buckets possess smaller valued keys, another way for multisplit is to directly sort input data. Both methods are inefficient and require more work than necessary: the former requires more expensive data movements while the latter spends unnecessary effort in sorting elements within each bucket. In this work, we provide a parallel model and multiple implementations for the multisplit problem. Our principal focus is multisplit for a small (up to 256) number of buckets. We use warp-synchronous programming models and emphasize warp-wide communications to avoid branch divergence and reduce memory usage. We also hierarchically reorder input elements to achieve better coalescing of global memory accesses. On a GeForce GTX 1080 GPU, we can reach a peak throughput of 18.93 Gkeys/s (or 11.68 Gpairs/s) for a key-only (or key-value) multisplit. Finally, we demonstrate how multisplit can be used as a building block for radix sort. In our multisplit-based sort implementation, we achieve comparable performance to the fastest GPU sort routines, sorting 32-bit keys (and key-value pairs) with a throughput of 3.0 G keys/s (and 2.1 Gpair/s). version:2
arxiv-1604-06414 | FlashR: R-Programmed Parallel and Scalable Machine Learning using SSDs | http://arxiv.org/abs/1604.06414 | id:1604.06414 author:Da Zheng, Disa Mhembere, Joshua T. Vogelstein, Carey E. Priebe, Randal Burns category:cs.DC  published:2016-04-21 summary:R is one of the most popular programming languages for statistics and machine learning, but the R framework is relatively slow and unable to scale to large datasets. The general approach for speeding up an implementation in R is to implement the algorithms in C or FORTRAN and provide an R wrapper. FlashR takes a different approach: it executes R code in parallel and scales the code beyond memory capacity by utilizing solid-state drives (SSDs) automatically. It provides a small number of generalized operations (GenOps) upon which we reimplement a large number of matrix functions in the R base package. As such, FlashR parallelizes and scales existing R code with little/no modification. To reduce data movement between CPU and SSDs, FlashR evaluates matrix operations lazily, fuses operations at runtime, and uses cache-aware, two-level matrix partitioning. We evaluate FlashR on a variety of machine learning and statistics algorithms on inputs of up to four billion data points. FlashR out-of-core tracks closely the performance of FlashR in-memory. The R code for machine learning algorithms executed in FlashR outperforms the in-memory execution of H2O and Spark MLlib by a factor of 2-10 and outperforms Revolution R Open by more than an order of magnitude. version:4
arxiv-1704-04697 | A Comprehensive Review of Smart Wheelchairs: Past, Present and Future | http://arxiv.org/abs/1704.04697 | id:1704.04697 author:Jesse Leaman, Hung M. La category:cs.RO  published:2017-04-15 summary:A smart wheelchair (SW) is a power wheelchair (PW) to which computers, sensors, and assistive technology are attached. In the past decade, there has been little effort to provide a systematic review of SW research. This paper aims to provide a complete state-of-the-art overview of SW research trends. We expect that the information gathered in this study will enhance awareness of the status of contemporary PW as well as SW technology, and increase the functional mobility of people who use PWs. We systematically present the international SW research effort, starting with an introduction to power wheelchairs and the communities they serve. Then we discuss in detail the SW and associated technological innovations with an emphasis on the most researched areas, generating the most interest for future research and development. We conclude with our vision for the future of SW research and how to best serve people with all types of disabilities. version:2
arxiv-1703-01281 | An Extended Consideration of Joint Exploration and Tracking: JET | http://arxiv.org/abs/1703.01281 | id:1703.01281 author:Alexander Ivanov, Mark Campbell category:cs.RO  published:2017-03-03 summary:Autonomous exploration and multi-object tracking by a team of agents have traditionally been considered as two separate, yet related, problems which are usually solved in two phases: an exploration phase then a tracking phase. The exploration problem is usually viewed through an information theoretic framework where a robotic agent attempts to gather as much information about the environment or an Object of Interest (OI). Conversely, the tracking problem attempts to maintain precise location information about an OI over time. This work proposes a single framework which enables the multi-robot multi-object problem to be solved simultaneously. A hierarchical architecture is used to coordinate robotic agents in the tracking of multiple OIs while simultaneously allowing the task to remain computationally efficient. The primary contributions of this work are a probabilistic constraint on the tracked OIs' covariances guarantees tracking performance throughout the entire mission. The automatic discovery of new OIs, a seamless transition to guaranteed tracking of discovered OIs, and the automatic balancing of exploration with the requirements of tracking. version:2
arxiv-1705-05427 | Repeated Inverse Reinforcement Learning | http://arxiv.org/abs/1705.05427 | id:1705.05427 author:Kareem Amin, Nan Jiang, Satinder Singh category:cs.AI cs.LG  published:2017-05-15 summary:How detailed should we make the goals we prescribe to AI agents acting on our behalf in complex environments? Detailed and low-level specification of goals can be tedious and expensive to create, and abstract and high-level goals could lead to negative surprises as the agent may find behaviors that we would not want it to do, i.e., lead to unsafe AI. One approach to addressing this dilemma is for the agent to infer human goals by observing human behavior. This is the Inverse Reinforcement Learning (IRL) problem. However, IRL is generally ill-posed for there are typically many reward functions for which the observed behavior is optimal. While the use of heuristics to select from among the set of feasible reward functions has led to successful applications of IRL to learning from demonstration, such heuristics do not address AI safety. In this paper we introduce a novel repeated IRL problem that captures an aspect of AI safety as follows. The agent has to act on behalf of a human in a sequence of tasks and wishes to minimize the number of tasks that it surprises the human. Each time the human is surprised the agent is provided a demonstration of the desired behavior by the human. We formalize this problem, including how the sequence of tasks is chosen, in a few different ways and provide some foundational results. version:2
arxiv-1705-06769 | Feature Control as Intrinsic Motivation for Hierarchical Reinforcement Learning | http://arxiv.org/abs/1705.06769 | id:1705.06769 author:Nat Dilokthanakul, Christos Kaplanis, Nick Pawlowski, Murray Shanahan category:cs.LG cs.AI  published:2017-05-18 summary:The problem of sparse rewards is one of the hardest challenges in contemporary reinforcement learning. Hierarchical reinforcement learning (HRL) tackles this problem by using a set of temporally-extended actions, or options, each of which has its own subgoal. These subgoals are normally handcrafted for specific tasks. Here, though, we introduce a generic class of subgoals with broad applicability in the visual domain. Underlying our approach (in common with work using "auxiliary tasks") is the hypothesis that the ability to control aspects of the environment is an inherently useful skill to have. We incorporate such subgoals in an end-to-end hierarchical reinforcement learning system and test two variants of our algorithm on a number of games from the Atari suite. We highlight the advantage of our approach in one of the hardest games -- Montezuma's revenge -- for which the ability to handle sparse rewards is key. Our agent learns several times faster than the current state-of-the-art HRL agent in this game, reaching a similar level of performance. version:1
arxiv-1705-06715 | Continuous Implicit Authentication for Mobile Devices based on Adaptive Neuro-Fuzzy Inference System | http://arxiv.org/abs/1705.06715 | id:1705.06715 author:Feng Yao, Suleiman Y. Yerima, BooJoong Kang, Sakir Sezer category:cs.CR cs.AI  published:2017-05-18 summary:As mobile devices have become indispensable in modern life, mobile security is becoming much more important. Traditional password or PIN-like point-of-entry security measures score low on usability and are vulnerable to brute force and other types of attacks. In order to improve mobile security, an adaptive neuro-fuzzy inference system(ANFIS)-based implicit authentication system is proposed in this paper to provide authentication in a continuous and transparent manner.To illustrate the applicability and capability of ANFIS in our implicit authentication system, experiments were conducted on behavioural data collected for up to 12 weeks from different Android users. The ability of the ANFIS-based system to detect an adversary is also tested with scenarios involving an attacker with varying levels of knowledge. The results demonstrate that ANFIS is a feasible and efficient approach for implicit authentication with an average of 95% user recognition rate. Moreover, the use of ANFIS-based system for implicit authentication significantly reduces manual tuning and configuration tasks due to its selflearning capability. version:1
arxiv-1705-06709 | Learning Spatiotemporal Features for Infrared Action Recognition with 3D Convolutional Neural Networks | http://arxiv.org/abs/1705.06709 | id:1705.06709 author:Zhuolin Jiang, Viktor Rozgic, Sancar Adali category:cs.CV cs.AI cs.LG cs.MM  published:2017-05-18 summary:Infrared (IR) imaging has the potential to enable more robust action recognition systems compared to visible spectrum cameras due to lower sensitivity to lighting conditions and appearance variability. While the action recognition task on videos collected from visible spectrum imaging has received much attention, action recognition in IR videos is significantly less explored. Our objective is to exploit imaging data in this modality for the action recognition task. In this work, we propose a novel two-stream 3D convolutional neural network (CNN) architecture by introducing the discriminative code layer and the corresponding discriminative code loss function. The proposed network processes IR image and the IR-based optical flow field sequences. We pretrain the 3D CNN model on the visible spectrum Sports-1M action dataset and finetune it on the Infrared Action Recognition (InfAR) dataset. To our best knowledge, this is the first application of the 3D CNN to action recognition in the IR domain. We conduct an elaborate analysis of different fusion schemes (weighted average, single and double-layer neural nets) applied to different 3D CNN outputs. Experimental results demonstrate that our approach can achieve state-of-the-art average precision (AP) performances on the InfAR dataset: (1) the proposed two-stream 3D CNN achieves the best reported 77.5% AP, and (2) our 3D CNN model applied to the optical flow fields achieves the best reported single stream 75.42% AP. version:1
arxiv-1705-06694 | I Probe, Therefore I Am: Designing a Virtual Journalist with Human Emotions | http://arxiv.org/abs/1705.06694 | id:1705.06694 author:Kevin K. Bowden, Tommy Nilsson, Christine P. Spencer, Kubra Cengiz, Alexandru Ghitulescu, Jelte B. van Waterschoot category:cs.HC cs.AI cs.MM 68T42  published:2017-05-18 summary:By utilizing different communication channels, such as verbal language, gestures or facial expressions, virtually embodied interactive humans hold a unique potential to bridge the gap between human-computer interaction and actual interhuman communication. The use of virtual humans is consequently becoming increasingly popular in a wide range of areas where such a natural communication might be beneficial, including entertainment, education, mental health research and beyond. Behind this development lies a series of technological advances in a multitude of disciplines, most notably natural language processing, computer vision, and speech synthesis. In this paper we discuss a Virtual Human Journalist, a project employing a number of novel solutions from these disciplines with the goal to demonstrate their viability by producing a humanoid conversational agent capable of naturally eliciting and reacting to information from a human user. A set of qualitative and quantitative evaluation sessions demonstrated the technical feasibility of the system whilst uncovering a number of deficits in its capacity to engage users in a way that would be perceived as natural and emotionally engaging. We argue that naturalness should not always be seen as a desirable goal and suggest that deliberately suppressing the naturalness of virtual human interactions, such as by altering its personality cues, might in some cases yield more desirable results. version:1
arxiv-1508-02535 | Efficient counting with optimal resilience | http://arxiv.org/abs/1508.02535 | id:1508.02535 author:Christoph Lenzen, Joel Rybicki, Jukka Suomela category:cs.DC  published:2015-08-11 summary:Consider a complete communication network of $n$ nodes, where the nodes receive a common clock pulse. We study the synchronous $c$-counting problem: given any starting state and up to $f$ faulty nodes with arbitrary behaviour, the task is to eventually have all correct nodes labeling the pulses with increasing values modulo $c$ in agreement. Thus, we are considering algorithms that are self-stabilising despite Byzantine failures. In this work, we give new algorithms for the synchronous counting problem that (1) are deterministic, (2) have optimal resilience, (3) have a linear stabilisation time in $f$ (asymptotically optimal), (4) use a small number of states, and consequently, (5) communicate a small number of bits per round. Prior algorithms either resort to randomisation, use a large number of states and need high communication bandwidth, or have suboptimal resilience. In particular, we achieve an exponential improvement in both state complexity and message size for deterministic algorithms. Moreover, we present two complementary approaches for reducing the number of bits communicated during and after stabilisation. version:3
arxiv-1705-06573 | Online learnability of Statistical Relational Learning in anomaly detection | http://arxiv.org/abs/1705.06573 | id:1705.06573 author:Magnus Jändel, Pontus Svenson, Niclas Wadströmer category:cs.LG cs.AI I.2.6  published:2017-05-18 summary:Statistical Relational Learning (SRL) methods for anomaly detection are introduced via a security-related application. Operational requirements for online learning stability are outlined and compared to mathematical definitions as applied to the learning process of a representative SRL method - Bayesian Logic Programs (BLP). Since a formal proof of online stability appears to be impossible, tentative common sense requirements are formulated and tested by theoretical and experimental analysis of a simple and analytically tractable BLP model. It is found that learning algorithms in initial stages of online learning can lock on unstable false predictors that nevertheless comply with our tentative stability requirements and thus masquerade as bona fide solutions. The very expressiveness of SRL seems to cause significant stability issues in settings with many variables and scarce data. We conclude that reliable anomaly detection with SRL-methods requires monitoring by an overarching framework that may involve a comprehensive context knowledge base or human supervision. version:1
arxiv-1705-06564 | Stepwise Debugging of Answer-Set Programs | http://arxiv.org/abs/1705.06564 | id:1705.06564 author:Johannes Oetsch, Jörg Pührer, Hans Tompits category:cs.AI cs.LO cs.PL 68N17  68T27 D.1.6; D.2.5  published:2017-05-18 summary:We introduce a stepping methodology for answer-set programming (ASP) that allows for debugging answer-set programs and is based on the stepwise application of rules. Similar to debugging in imperative languages, where the behaviour of a program is observed during a step-by-step execution, stepping for ASP allows for observing the effects that rule applications have in the computation of an answer set. While the approach is inspired from debugging in imperative programming, it is conceptually different to stepping in other paradigms due to non-determinism and declarativity that are inherent to ASP. In particular, unlike statements in an imperative program that are executed following a strict control flow, there is no predetermined order in which to consider rules in ASP during a computation. In our approach, the user is free to decide which rule to consider active in the next step following his or her intuition. This way, one can focus on interesting parts of the debugging search space. Bugs are detected during stepping by revealing differences between the actual semantics of the program and the expectations of the user. As a solid formal basis for stepping, we develop a framework of computations for answer-set programs. For fully supporting different solver languages, we build our framework on an abstract ASP language that is sufficiently general to capture different solver languages. To this end, we make use of abstract constraints as an established abstraction for popular language constructs such as aggregates. Stepping has been implemented in SeaLion, an integrated development environment for ASP. We illustrate stepping using an example scenario and discuss the stepping plugin of SeaLion. Moreover, we elaborate on methodological aspects and the embedding of stepping in the ASP development process. version:1
arxiv-1704-07649 | Fast Space Optimal Leader Election in Population Protocols | http://arxiv.org/abs/1704.07649 | id:1704.07649 author:Leszek Gasieniec, Grzegorz Stachowiak category:cs.DC  published:2017-04-25 summary:The model of population protocols refers to the growing in popularity theoretical framework suitable for studying pairwise interactions within a large collection of simple indistinguishable entities, frequently called agents. In this paper the emphasis is on the space complexity in fast leader election via population protocols governed by the random scheduler, which uniformly at random selects pairwise interactions within the population of n agents. The main result of this paper is a new fast and space optimal leader election protocol. The new protocol utilises O(log^2 n) parallel time (which is equivalent to O(n log^2 n) sequential pairwise interactions), and each agent operates on O(log log n) states. This double logarithmic space usage matches asymptotically the lower bound 1/2 log log n on the minimal number of states required by agents in any leader election algorithm with the running time o(n/polylog n). Our solution takes an advantage of the concept of phase clocks, a fundamental synchronisation and coordination tool in distributed computing. We propose a new fast and robust population protocol for initialisation of phase clocks to be run simultaneously in multiple modes and intertwined with the leader election process. We also provide the reader with the relevant formal argumentation indicating that our solution is always correct, and fast with high probability. version:2
arxiv-1705-06453 | Elastic and Secure Energy Forecasting in Cloud Environments | http://arxiv.org/abs/1705.06453 | id:1705.06453 author:André Martin, Andrey Britoy, Christof Fetzer category:cs.DC  published:2017-05-18 summary:Although cloud computing offers many advantages with regards to adaption of resources, we witness either a strong resistance or a very slow adoption to those new offerings. One reason for the resistance is that (i) many technologies such as stream processing systems still lack of appropriate mechanisms for elasticity in order to fully harness the power of the cloud, and (ii) do not provide mechanisms for secure processing of privacy sensitive data such as when analyzing energy consumption data provided through smart plugs in the context of smart grids. In this white paper, we present our vision and approach for elastic and secure processing of streaming data. Our approach is based on StreamMine3G, an elastic event stream processing system and Intel's SGX technology that provides secure processing using enclaves. We highlight the key aspects of our approach and research challenges when using Intel's SGX technology. version:1
arxiv-1705-01320 | Formal Verification of Piece-Wise Linear Feed-Forward Neural Networks | http://arxiv.org/abs/1705.01320 | id:1705.01320 author:Ruediger Ehlers category:cs.LO cs.AI cs.LG D.2.4; I.2.6  published:2017-05-03 summary:We present an approach for the verification of feed-forward neural networks in which all nodes have a piece-wise linear activation function. Such networks are often used in deep learning and have been shown to be hard to verify for modern satisfiability modulo theory (SMT) and integer linear programming (ILP) solvers. The starting point of our approach is the addition of a global linear approximation of the overall network behavior to the verification problem that helps with SMT-like reasoning over the network behavior. We present a specialized verification algorithm that employs this approximation in a search process in which it infers additional node phases for the non-linear nodes in the network from partial node phase assignments, similar to unit propagation in classical SAT solving. We also show how to infer additional conflict clauses and safe node fixtures from the results of the analysis steps performed during the search. The resulting approach is evaluated on collision avoidance and handwritten digit recognition case studies. version:2
arxiv-1705-06431 | Vehicle Routing with Drones | http://arxiv.org/abs/1705.06431 | id:1705.06431 author:Rami Daknama, Elisabeth Kraus category:math.OC cs.AI math.CO  published:2017-05-18 summary:We introduce a package service model where trucks as well as drones can deliver packages. Drones can travel on trucks or fly; but while flying, drones can only carry one package at a time and have to return to a truck to charge after each delivery. We present a heuristic algorithm to solve the problem of finding a good schedule for all drones and trucks. The algorithm is based on two nested local searches, thus the definition of suitable neighbourhoods of solutions is crucial for the algorithm. Empirical tests show that our algorithm performs significantly better than a natural Greedy algorithm. Moreover, the savings compared to solutions without drones turn out to be substantial, suggesting that delivery systems might considerably benefit from using drones in addition to trucks. version:1
arxiv-1705-06419 | SimpleSSD: Modeling Solid State Drives for Holistic System Simulation | http://arxiv.org/abs/1705.06419 | id:1705.06419 author:Myoungsoo Jung, Jie Zhang, Ahmed Abulila, Miryeong Kwon, Narges Shahidi, John Shalf, Nam Sung Kim, Mahmut Kandemir category:cs.AR  published:2017-05-18 summary:Existing solid state drive (SSD) simulators unfortunately lack hardware and/or software architecture models. Consequently, they are far from capturing the critical features of contemporary SSD devices. More importantly, while the performance of modern systems that adopt SSDs can vary based on their numerous internal design parameters and storage-level configurations, a full system simulation with traditional SSD models often requires unreasonably long runtimes and excessive computational resources. In this work, we propose SimpleSSD, a highfidelity simulator that models all detailed characteristics of hardware and software, while simplifying the nondescript features of storage internals. In contrast to existing SSD simulators, SimpleSSD can easily be integrated into publicly-available full system simulators. In addition, it can accommodate a complete storage stack and evaluate the performance of SSDs along with diverse memory technologies and microarchitectures. Thus, it facilitates simulations that explore the full design space at different levels of system abstraction. version:1
arxiv-1705-06401 | Towards Robotically Supported Decommissioning of Nuclear Sites | http://arxiv.org/abs/1705.06401 | id:1705.06401 author:Frank Mascarich, Taylor Wilson, Tung Dang, Shehryar Khattak, Christos Papachristos, Kostas Alexis category:cs.RO  published:2017-05-18 summary:This paper overviews certain radiation detection, perception, and planning challenges for nuclearized robotics that aim to support the waste management and decommissioning mission. To enable the autonomous monitoring, inspection and multi-modal characterization of nuclear sites, we discuss important problems relevant to the tasks of navigation in degraded visual environments, localizability-aware exploration and mapping without any prior knowledge of the environment, as well as robotic radiation detection. Future contributions will focus on each of the relevant problems, will aim to deliver a comprehensive multi-modal mapping result, and will emphasize on extensive field evaluation and system verification. version:1
arxiv-1705-06400 | Learning a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks | http://arxiv.org/abs/1705.06400 | id:1705.06400 author:Matthias Plappert, Christian Mandery, Tamim Asfour category:cs.LG cs.CL cs.RO stat.ML  published:2017-05-18 summary:Linking human whole-body motion and natural language is of great interest for the generation of semantic representations of observed human behaviors as well as for the generation of robot behaviors based on natural language input. While there has been a large body of research in this area, most approaches that exist today require a symbolic representation of motions (e.g. in the form of motion primitives), which have to be defined a-priori or require complex segmentation algorithms. In contrast, recent advances in the field of neural networks and especially deep learning have demonstrated that sub-symbolic representations that can be learned end-to-end usually outperform more traditional approaches, for applications such as machine translation. In this paper we propose a generative model that learns a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks (RNNs) and sequence-to-sequence learning. Our approach does not require any segmentation or manual feature engineering and learns a distributed representation, which is shared for all motions and descriptions. We evaluate our approach on 2,846 human whole-body motions and 6,187 natural language descriptions thereof from the KIT Motion-Language Dataset. Our results clearly demonstrate the effectiveness of the proposed model: We show that our model generates a wide variety of realistic motions only from descriptions thereof in form of a single sentence. Conversely, our model is also capable of generating correct and detailed natural language descriptions from human motions. version:1
arxiv-1705-06391 | Asynchronous parallel primal-dual block update methods | http://arxiv.org/abs/1705.06391 | id:1705.06391 author:Yangyang Xu category:math.OC cs.DC math.NA stat.ML  published:2017-05-18 summary:Recent several years have witnessed the surge of asynchronous (async-) parallel computing methods due to the extremely big data involved in many modern applications and also the advancement of multi-core machines and computer clusters. In optimization, most works about async-parallel methods are on unconstrained problems or those with block separable constraints. In this paper, we propose an async-parallel method based on block coordinate update (BCU) for solving convex problems with nonseparable linear constraint. Running on a single node, the method becomes a novel randomized primal-dual BCU with adaptive stepsize for multi-block affinely constrained problems. For these problems, Gauss-Seidel cyclic primal-dual BCU needs strong convexity to have convergence. On the contrary, merely assuming convexity, we show that the objective value sequence generated by the proposed algorithm converges in probability to the optimal value and also the constraint residual to zero. In addition, we establish an ergodic $O(1/k)$ convergence result, where $k$ is the number of iterations. Numerical experiments are performed to demonstrate the efficiency of the proposed method and significantly better speed-up performance than its sync-parallel counterpart. version:1
arxiv-1705-06390 | Scalable Exact Parent Sets Identification in Bayesian Networks Learning with Apache Spark | http://arxiv.org/abs/1705.06390 | id:1705.06390 author:Subhadeep Karan, Jaroslaw Zola category:cs.AI  published:2017-05-18 summary:In Machine Learning, the parent set identification problem is to find a set of random variables that best explain selected variable given the data and some predefined scoring function. This problem is a critical component to structure learning of Bayesian networks and Markov blankets discovery, and thus has many practical applications ranging from fraud detection to clinical decision support. In this paper, we introduce a new distributed memory approach to the exact parent sets assignment problem. To achieve scalability, we derive theoretical bounds to constraint the search space when MDL scoring function is used, and we reorganize the underlying dynamic programming such that the computational density is increased and fine-grain synchronization is eliminated. We then design efficient realization of our approach in the Apache Spark platform. Through experimental results, we demonstrate that the method maintains strong scalability on a 500-core standalone Spark cluster, and it can be used to efficiently process data sets with 70 variables, far beyond the reach of the currently available solutions. version:1
arxiv-1610-04028 | A fuzzy expert system for earthquake prediction, case study: the Zagros range | http://arxiv.org/abs/1610.04028 | id:1610.04028 author:Arash Andalib, Mehdi Zare, Farid Atry category:cs.AI  published:2016-10-13 summary:A methodology for the development of a fuzzy expert system (FES) with application to earthquake prediction is presented. The idea is to reproduce the performance of a human expert in earthquake prediction. To do this, at the first step, rules provided by the human expert are used to generate a fuzzy rule base. These rules are then fed into an inference engine to produce a fuzzy inference system (FIS) and to infer the results. In this paper, we have used a Sugeno type fuzzy inference system to build the FES. At the next step, the adaptive network-based fuzzy inference system (ANFIS) is used to refine the FES parameters and improve its performance. The proposed framework is then employed to attain the performance of a human expert used to predict earthquakes in the Zagros area based on the idea of coupled earthquakes. While the prediction results are promising in parts of the testing set, the general performance indicates that prediction methodology based on coupled earthquakes needs more investigation and more complicated reasoning procedure to yield satisfactory predictions. version:2
arxiv-1705-06342 | Identification and Off-Policy Learning of Multiple Objectives Using Adaptive Clustering | http://arxiv.org/abs/1705.06342 | id:1705.06342 author:Thommen George Karimpanal, Erik Wilhelm category:cs.AI  published:2017-05-17 summary:In this work, we present a methodology that enables an agent to make efficient use of its exploratory actions by autonomously identifying possible objectives in its environment and learning them in parallel. The identification of objectives is achieved using an online and unsupervised adaptive clustering algorithm. The identified objectives are learned (at least partially) in parallel using Q-learning. Using a simulated agent and environment, it is shown that the converged or partially converged value function weights resulting from off-policy learning can be used to accumulate knowledge about multiple objectives without any additional exploration. We claim that the proposed approach could be useful in scenarios where the objectives are initially unknown or in real world scenarios where exploration is typically a time and energy intensive process. The implications and possible extensions of this work are also briefly discussed. version:1
arxiv-1705-06338 | Distributed Vector Representation Of Shopping Items, The Customer And Shopping Cart To Build A Three Fold Recommendation System | http://arxiv.org/abs/1705.06338 | id:1705.06338 author:Bibek Behera, Manoj Joshi, Abhilash KK, Mohammad Ansari Ismail category:cs.IR cs.AI  published:2017-05-17 summary:The main idea of this paper is to represent shopping items through vectors because these vectors act as the base for building em- beddings for customers and shopping carts. Also, these vectors are input to the mathematical models that act as either a recommendation engine or help in targeting potential customers. We have used exponential family embeddings as the tool to construct two basic vectors - product embeddings and context vectors. Using the basic vectors, we build combined embeddings, trip embeddings and customer embeddings. Combined embeddings mix linguistic properties of product names with their shopping patterns. The customer embeddings establish an understand- ing of the buying pattern of customers in a group and help in building customer profile. For example a customer profile can represent customers frequently buying pet-food. Identifying such profiles can help us bring out offers and discounts. Similarly, trip embeddings are used to build trip profiles. People happen to buy similar set of products in a trip and hence their trip embeddings can be used to predict the next product they would like to buy. This is a novel technique and the first of its kind to make recommendation using product, trip and customer embeddings. version:1
arxiv-1705-06273 | Transfer Learning for Named-Entity Recognition with Neural Networks | http://arxiv.org/abs/1705.06273 | id:1705.06273 author:Ji Young Lee, Franck Dernoncourt, Peter Szolovits category:cs.CL cs.AI cs.NE stat.ML  published:2017-05-17 summary:Recent approaches based on artificial neural networks (ANNs) have shown promising results for named-entity recognition (NER). In order to achieve high performances, ANNs need to be trained on a large labeled dataset. However, labels might be difficult to obtain for the dataset on which the user wants to perform NER: label scarcity is particularly pronounced for patient note de-identification, which is an instance of NER. In this work, we analyze to what extent transfer learning may address this issue. In particular, we demonstrate that transferring an ANN model trained on a large labeled dataset to another dataset with a limited number of labels improves upon the state-of-the-art results on two different datasets for patient note de-identification. version:1
arxiv-1705-06271 | Fast Snapshottable Concurrent Braun Heaps | http://arxiv.org/abs/1705.06271 | id:1705.06271 author:Thomas D. Dickerson category:cs.DS cs.DC E.1  published:2017-05-17 summary:This paper proposes a new concurrent heap algorithm, based on a stateless shape property, which efficiently maintains balance during insert and removeMin operations implemented with hand-over-hand locking. It also provides a O(1) linearizable snapshot operation based on lazy copy-on-write semantics. Such snapshots can be used to provide consistent views of the heap during iteration, as well as to make speculative updates (which can later be dropped). The simplicity of the algorithm allows it to be easily proven correct, and the choice of shape property provides priority queue performance which is competitive with highly optimized skiplist implementations (and has stronger bounds on worst-case time complexity). A Scala reference implementation is provided. version:1
arxiv-1705-06266 | A Parallel Solver for Graph Laplacians | http://arxiv.org/abs/1705.06266 | id:1705.06266 author:Tristan Konolige, Jed Brown category:cs.DC  published:2017-05-17 summary:Problems from graph drawing, spectral clustering, network flow and graph parti- tioning all can be expressed as Laplacian matrices. Theoretically fast approaches to solving these problems exist, but in practice these techniques are slow. Three practical approaches have been proposed and work well in serial. However, as problem sizes increase and single core speeds stagnate, parallelism is essential to solve problems quickly. We present an unsmoothed aggregation Multigrid method for solving graph Laplacians in distributed memory setting. Our solver scales up to 64 compute nodes and achieves speedups of up to 83x over the existing serial solutions. version:1
arxiv-1705-06243 | Learning to Represent Haptic Feedback for Partially-Observable Tasks | http://arxiv.org/abs/1705.06243 | id:1705.06243 author:Jaeyong Sung, J. Kenneth Salisbury, Ashutosh Saxena category:cs.RO cs.AI cs.LG  published:2017-05-17 summary:The sense of touch, being the earliest sensory system to develop in a human body [1], plays a critical part of our daily interaction with the environment. In order to successfully complete a task, many manipulation interactions require incorporating haptic feedback. However, manually designing a feedback mechanism can be extremely challenging. In this work, we consider manipulation tasks that need to incorporate tactile sensor feedback in order to modify a provided nominal plan. To incorporate partial observation, we present a new framework that models the task as a partially observable Markov decision process (POMDP) and learns an appropriate representation of haptic feedback which can serve as the state for a POMDP model. The model, that is parametrized by deep recurrent neural networks, utilizes variational Bayes methods to optimize the approximate posterior. Finally, we build on deep Q-learning to be able to select the optimal action in each state without access to a simulator. We test our model on a PR2 robot for multiple tasks of turning a knob until it clicks. version:1
arxiv-1705-06215 | Mixing MACs: An Introduction to Hybrid Radio Wireless Virtualization | http://arxiv.org/abs/1705.06215 | id:1705.06215 author:Gautam Bhanage category:cs.NI cs.DC  published:2017-05-17 summary:This study presents the design of the hybrid wireless virtualization HWV controller based network architecture. Using a HWV controller, an unified approach can be taken for provisioning and management of virtualized heterogeneous radios, irrespective of their MAC and PHY layer mechanisms. It is shown that the airtime occupancy by transmissions from different slices or groups can be used as a single metric for tying these virtualized platforms. The HWV controller can account and dynamically reprovision slice quotas, which can be used for maximizing the revenue of the network operator or aggregate system throughput performance. Results from simulations show that an HWV controller based infrastructure is able to improve the revenue generated from a single virtualized basestation and an AP by up to 40 percent under tested conditions. version:1
arxiv-1705-06202 | Data Access for LIGO on the OSG | http://arxiv.org/abs/1705.06202 | id:1705.06202 author:Derek Weitzel, Brian Bockelman, Duncan A. Brown, Peter Couvares, Frank Würthwein, Edgar Fajardo Hernandez category:cs.DC astro-ph.IM  published:2017-05-17 summary:During 2015 and 2016, the Laser Interferometer Gravitational-Wave Observatory (LIGO) conducted a three-month observing campaign. These observations delivered the first direct detection of gravitational waves from binary black hole mergers. To search for these signals, the LIGO Scientific Collaboration uses the PyCBC search pipeline. To deliver science results in a timely manner, LIGO collaborated with the Open Science Grid (OSG) to distribute the required computation across a series of dedicated, opportunistic, and allocated resources. To deliver the petabytes necessary for such a large-scale computation, our team deployed a distributed data access infrastructure based on the XRootD server suite and the CernVM File System (CVMFS). This data access strategy grew from simply accessing remote storage to a POSIX-based interface underpinned by distributed, secure caches across the OSG. version:1
arxiv-1705-06201 | Modeling Cooperative Navigation in Dense Human Crowds | http://arxiv.org/abs/1705.06201 | id:1705.06201 author:Anirudh Vemula, Katharina Muelling, Jean Oh category:cs.RO  published:2017-05-17 summary:For robots to be a part of our daily life, they need to be able to navigate among crowds not only safely but also in a socially compliant fashion. This is a challenging problem because humans tend to navigate by implicitly cooperating with one another to avoid collisions, while heading toward their respective destinations. Previous approaches have used hand-crafted functions based on proximity to model human-human and human-robot interactions. However, these approaches can only model simple interactions and fail to generalize for complex crowded settings. In this paper, we develop an approach that models the joint distribution over future trajectories of all interacting agents in the crowd, through a local interaction model that we train using real human trajectory data. The interaction model infers the velocity of each agent based on the spatial orientation of other agents in his vicinity. During prediction, our approach infers the goal of the agent from its past trajectory and uses the learned model to predict its future trajectory. We demonstrate the performance of our method against a state-of-the-art approach on a public dataset and show that our model outperforms when predicting future trajectories for longer horizons. version:1
arxiv-1705-08260 | Self-Supervised Siamese Learning on Stereo Image Pairs for Depth Estimation in Robotic Surgery | http://arxiv.org/abs/1705.08260 | id:1705.08260 author:Menglong Ye, Edward Johns, Ankur Handa, Lin Zhang, Philip Pratt, Guang-Zhong Yang category:cs.CV cs.RO  published:2017-05-17 summary:Robotic surgery has become a powerful tool for performing minimally invasive procedures, providing advantages in dexterity, precision, and 3D vision, over traditional surgery. One popular robotic system is the da Vinci surgical platform, which allows preoperative information to be incorporated into live procedures using Augmented Reality (AR). Scene depth estimation is a prerequisite for AR, as accurate registration requires 3D correspondences between preoperative and intraoperative organ models. In the past decade, there has been much progress on depth estimation for surgical scenes, such as using monocular or binocular laparoscopes [1,2]. More recently, advances in deep learning have enabled depth estimation via Convolutional Neural Networks (CNNs) [3], but training requires a large image dataset with ground truth depths. Inspired by [4], we propose a deep learning framework for surgical scene depth estimation using self-supervision for scalable data acquisition. Our framework consists of an autoencoder for depth prediction, and a differentiable spatial transformer for training the autoencoder on stereo image pairs without ground truth depths. Validation was conducted on stereo videos collected in robotic partial nephrectomy. version:1
arxiv-1705-06058 | Pitfalls and Best Practices in Algorithm Configuration | http://arxiv.org/abs/1705.06058 | id:1705.06058 author:Katharina Eggensperger, Marius Lindauer, Frank Hutter category:cs.AI cs.SE  published:2017-05-17 summary:Good parameter settings are crucial to achieve high performance in many areas of artificial intelligence (AI), such as satisfiability solving, AI planning, scheduling, and machine learning (in particular deep learning). Automated algorithm configuration methods have recently received much attention in the AI community since they replace tedious, irreproducible and error-prone manual parameter tuning and can lead to new state-of-the-art performance. However, practical applications of algorithm configuration are prone to several (often subtle) pitfalls in the experimental design that can render the procedure ineffective. We identify several common issues and propose best practices for avoiding them, including a tool called GenericWrapper4AC for preventing the many possible problems in measuring the performance of the algorithm being optimized by executing it in a standardized, controlled manner. version:1
arxiv-1605-06645 | Full-Pose Tracking Control for Aerial Robotic Systems with Laterally-Bounded Input Force | http://arxiv.org/abs/1605.06645 | id:1605.06645 author:Antonio Franchi, Ruggero Carli, Davide Bicego, Markus Ryll category:math.OC cs.RO cs.SY math.DS  published:2016-05-21 summary:In this paper, we define a general class of abstract aerial robotic systems named Laterally Bounded Force (LBF) vehicles, in which most of the control authority is expressed along a principal thrust direction, while in the lateral directions a (smaller and possibly null) force may be exploited to achieve full-pose tracking. This class approximates well platforms endowed with non-coplanar/non-collinear rotors that can use the tilted propellers to slightly change the orientation of the total thrust w.r.t. the body frame. For this broad class of systems, we introduce a new geometric control strategy in SE(3) to achieve, whenever made possible by the force constraints, the independent tracking of position-plus-orientation trajectories. The exponential tracking of a feasible full-pose reference trajectory is proven using a Lyapunov technique in SE(3). The method can deal seamlessly with both under- and fully-actuated LBF platforms. The controller guarantees the tracking of at least the positional part in the case that an unfeasible full-pose reference trajectory is provided. The paper provides several experimental tests clearly showing the practicability of the approach and the sharp improvement with respect to state of-the-art approaches. version:2
arxiv-1705-06024 | Demand-Aware Network Designs of Bounded Degree | http://arxiv.org/abs/1705.06024 | id:1705.06024 author:Chen Avin, Kaushik Mondal, Stefan Schmid category:cs.DC  published:2017-05-17 summary:Traditionally, networks such as datacenter interconnects are designed to optimize worst-case performance under arbitrary traffic patterns. Such network designs can however be far from optimal when considering the actual workloads and traffic patterns which they serve. This insight led to the development of demand-aware datacenter interconnects which can be reconfigured depending on the workload. Motivated by these trends, this paper initiates the algorithmic study of demand-aware networks (DANs) designs, and in particular the design of bounded-degree networks. The inputs to the network design problem are a discrete communication request distribution, D, defined over communicating pairs from the node set V , and a bound, d, on the maximum degree. In turn, our objective is to design an (undirected) demand-aware network N = (V,E) of bounded-degree d, which provides short routing paths between frequently communicating nodes distributed across N. In particular, the designed network should minimize the expected path length on N (with respect to D), which is a basic measure of the efficiency of the network. We show that this fundamental network design problem exhibits interesting connections to several classic combinatorial problems and to information theory. We derive a general lower bound based on the entropy of the communication pattern D, and present asymptotically optimal network-aware design algorithms for important distribution families, such as sparse distributions and distributions of locally bounded doubling dimensions. version:1
arxiv-1705-06020 | Sparse Gaussian Processes for Continuous-Time Trajectory Estimation on Matrix Lie Groups | http://arxiv.org/abs/1705.06020 | id:1705.06020 author:Jing Dong, Byron Boots, Frank Dellaert category:cs.RO  published:2017-05-17 summary:Continuous-time trajectory representations are a powerful tool that can be used to address several issues in many practical simultaneous localization and mapping (SLAM) scenarios, like continuously collected measurements distorted by robot motion, or during with asynchronous sensor measurements. Sparse Gaussian processes (GP) allow for a probabilistic non-parametric trajectory representation that enables fast trajectory estimation by sparse GP regression. However, previous approaches are limited to dealing with vector space representations of state only. In this technical report we extend the work by Barfoot et al. [1] to general matrix Lie groups, by applying constant-velocity prior, and defining locally linear GP. This enables using sparse GP approach in a large space of practical SLAM settings. In this report we give the theory and leave the experimental evaluation in future publications. version:1
arxiv-1705-05987 | Stochastic Functional Gradient Path Planning in Occupancy Maps | http://arxiv.org/abs/1705.05987 | id:1705.05987 author:Gilad Francis, Lionel Ott, Fabio Ramos category:cs.RO  published:2017-05-17 summary:Planning safe paths is a major building block in robot autonomy. It has been an active field of research for several decades, with a plethora of planning methods. Planners can be generally categorised as either trajectory optimisers or sampling-based planners. The latter is the predominant planning paradigm for occupancy maps. Trajectory optimisation entails major algorithmic changes to tackle contextual information gaps caused by incomplete sensor coverage of the map. However, the benefits are substantial, as trajectory optimisers can reason on the trade-off between path safety and efficiency. In this work, we improve our previous work on stochastic functional gradient planners. We introduce a novel expressive path representation based on kernel approximation, that allows cost effective model updates based on stochastic samples. The main drawback of the previous stochastic functional gradient planner was the cubic cost, stemming from its non-parametric path representation. Our novel approximate kernel based model, on the other hand, has a fixed linear cost that depends solely on the number of features used to represent the path. We show that the stochasticity of the samples is crucial for the planner and present comparisons to other state-of-the-art planning methods in both simulation and with real occupancy data. The experiments demonstrate the advantages of the stochastic approximate kernel method for path planning in occupancy maps. version:1
arxiv-1705-05986 | REMIX: Automated Exploration for Interactive Outlier Detection | http://arxiv.org/abs/1705.05986 | id:1705.05986 author:Yanjie Fu, Charu Aggarwal, Srinivasan Parthasarathy, Deepak S. Turaga, Hui Xiong category:cs.AI  published:2017-05-17 summary:Outlier detection is the identification of points in a dataset that do not conform to the norm. Outlier detection is highly sensitive to the choice of the detection algorithm and the feature subspace used by the algorithm. Extracting domain-relevant insights from outliers needs systematic exploration of these choices since diverse outlier sets could lead to complementary insights. This challenge is especially acute in an interactive setting, where the choices must be explored in a time-constrained manner. In this work, we present REMIX, the first system to address the problem of outlier detection in an interactive setting. REMIX uses a novel mixed integer programming (MIP) formulation for automatically selecting and executing a diverse set of outlier detectors within a time limit. This formulation incorporates multiple aspects such as (i) an upper limit on the total execution time of detectors (ii) diversity in the space of algorithms and features, and (iii) meta-learning for evaluating the cost and utility of detectors. REMIX provides two distinct ways for the analyst to consume its results: (i) a partitioning of the detectors explored by REMIX into perspectives through low-rank non-negative matrix factorization; each perspective can be easily visualized as an intuitive heatmap of experiments versus outliers, and (ii) an ensembled set of outliers which combines outlier scores from all detectors. We demonstrate the benefits of REMIX through extensive empirical validation on real-world data. version:1
arxiv-1704-02003 | A Comparison of Parallel Graph Processing Implementations | http://arxiv.org/abs/1704.02003 | id:1704.02003 author:Samuel Pollard, Boyana Norris category:cs.PF cs.DC  published:2017-04-06 summary:The rapidly growing number of large network analysis problems has led to the emergence of many parallel and distributed graph processing systems---one survey in 2014 identified over 80. Since then, the landscape has evolved; some packages have become inactive while more are being developed. Determining the best approach for a given problem is infeasible for most developers. To enable easy, rigorous, and repeatable comparison of the capabilities of such systems, we present an approach and associated software for analyzing the performance and scalability of parallel, open-source graph libraries. We demonstrate our approach on five graph processing packages: GraphMat, the Graph500, the Graph Algorithm Platform Benchmark Suite, GraphBIG, and PowerGraph using synthetic and real-world datasets. We examine previously overlooked aspects of parallel graph processing performance such as phases of execution and energy usage for three algorithms: breadth first search, single source shortest paths, and PageRank and compare our results to Graphalytics. version:2
arxiv-1705-05935 | Rise of the humanbot | http://arxiv.org/abs/1705.05935 | id:1705.05935 author:Ricard Sole category:q-bio.NC cs.AI  published:2017-05-16 summary:The accelerated path of technological development, particularly at the interface between hardware and biology has been suggested as evidence for future major technological breakthroughs associated to our potential to overcome biological constraints. This includes the potential of becoming immortal, having expanded cognitive capacities thanks to hardware implants or the creation of intelligent machines. Here I argue that several relevant evolutionary and structural constraints might prevent achieving most (if not all) these innovations. Instead, the coming future will bring novelties that will challenge many other aspects of our life and that can be seen as other feasible singularities. One particularly important one has to do with the evolving interactions between humans and non-intelligent robots capable of learning and communication. Here I argue that a long term interaction can lead to a new class of "agent" (the humanbot). The way shared memories get tangled over time will inevitably have important consequences for both sides of the pair, whose identity as separated entities might become blurred and ultimately vanish. Understanding such hybrid systems requires a second-order neuroscience approach while posing serious conceptual challenges, including the definition of consciousness. version:1
arxiv-1706-03021 | Ethical Artificial Intelligence - An Open Question | http://arxiv.org/abs/1706.03021 | id:1706.03021 author:Alice Pavaloiu, Utku Kose category:cs.AI cs.CY  published:2017-05-16 summary:Artificial Intelligence (AI) is an effective science which employs strong enough approaches, methods, and techniques to solve unsolvable real world based problems. Because of its unstoppable rise towards the future, there are also some discussions about its ethics and safety. Shaping an AI friendly environment for people and a people friendly environment for AI can be a possible answer for finding a shared context of values for both humans and robots. In this context, objective of this paper is to address the ethical issues of AI and explore the moral dilemmas that arise from ethical algorithms, from pre set or acquired values. In addition, the paper will also focus on the subject of AI safety. As general, the paper will briefly analyze the concerns and potential solutions to solving the ethical issues presented and increase readers awareness on AI safety as another related research interest. version:1
arxiv-1705-05904 | Motion-Compensated Autonomous Scanning for Tumour Localisation using Intraoperative Ultrasound | http://arxiv.org/abs/1705.05904 | id:1705.05904 author:Lin Zhang, Menglong Ye, Stamatia Giannarou, Philip Pratt, Guang-Zhong Yang category:cs.RO  published:2017-05-16 summary:Intraoperative ultrasound facilitates localisation of tumour boundaries during minimally invasive procedures. Autonomous ultrasound scanning systems have been recently proposed to improve scanning accuracy and reduce surgeons' cognitive load. However, current methods mainly consider static scanning environments typically with the probe pressing against the tissue surface. In this work, a motion-compensated autonomous ultrasound scanning system using the da Vinci Research Kit (dVRK) is proposed. An optimal scanning trajectory is generated considering both the tissue surface shape and the ultrasound transducer dimensions. A robust vision-based approach is proposed to learn the underlying tissue motion characteristics. The learned motion model is then incorporated into the visual servoing framework. The proposed system has been validated with both phantom and ex vivo experiments using the ground truth motion data for comparison. version:1
arxiv-1705-05884 | Static Gesture Recognition using Leap Motion | http://arxiv.org/abs/1705.05884 | id:1705.05884 author:Babak Toghiani-Rizi, Christofer Lind, Maria Svensson, Marcus Windmark category:stat.ML cs.AI cs.CV cs.HC  published:2017-05-16 summary:In this report, an automated bartender system was developed for making orders in a bar using hand gestures. The gesture recognition of the system was developed using Machine Learning techniques, where the model was trained to classify gestures using collected data. The final model used in the system reached an average accuracy of 95%. The system raised ethical concerns both in terms of user interaction and having such a system in a real world scenario, but it could initially work as a complement to a real bartender. version:1
arxiv-1508-03619 | The GAP Benchmark Suite | http://arxiv.org/abs/1508.03619 | id:1508.03619 author:Scott Beamer, Krste Asanović, David Patterson category:cs.DC cs.DS  published:2015-08-14 summary:We present a graph processing benchmark suite with the goal of helping to standardize graph processing evaluations. Fewer differences between graph processing evaluations will make it easier to compare different research efforts and quantify improvements. The benchmark not only specifies graph kernels, input graphs, and evaluation methodologies, but it also provides optimized baseline implementations. These baseline implementations are representative of state-of-the-art performance, and thus new contributions should outperform them to demonstrate an improvement. The input graphs are sized appropriately for shared memory platforms, but any implementation on any platform that conforms to the benchmark's specifications could be compared. This benchmark suite can be used in a variety of settings. Graph framework developers can demonstrate the generality of their programming model by implementing all of the benchmark's kernels and delivering competitive performance on all of the benchmark's graphs. Algorithm designers can use the input graphs and the baseline implementations to demonstrate their contribution. Platform designers and performance analysts can use the suite as a workload representative of graph processing. version:4
arxiv-1707-00629 | Practical Approach to Distributed Systems' Design | http://arxiv.org/abs/1707.00629 | id:1707.00629 author:Jerzy Mieścicki, Wiktor B. Daszczuk, Waldemar Grabski, Artur Krystosik category:cs.DC 68M14 C.1.4  published:2017-05-16 summary:The paper, based on authors' experience from several distributed systems integration projects, summarizes briefly practical designer's view on methodological requirements and overall system organization, including clues as to the organization of the application layer, use of operating system and preferred communication protocols. version:1
arxiv-1705-03303 | The Imprecisions of Precision Measures in Process Mining | http://arxiv.org/abs/1705.03303 | id:1705.03303 author:Niek Tax, Xixi Lu, Natalia Sidorova, Dirk Fahland, Wil M. P. van der Aalst category:cs.DB cs.AI cs.LO cs.SE  published:2017-05-03 summary:In process mining, precision measures are used to quantify how much a process model overapproximates the behavior seen in an event log. Although several measures have been proposed throughout the years, no research has been done to validate whether these measures achieve the intended aim of quantifying over-approximation in a consistent way for all models and logs. This paper fills this gap by postulating a number of axioms for quantifying precision consistently for any log and any model. Further, we show through counter-examples that none of the existing measures consistently quantifies precision. version:2
arxiv-1705-05824 | Minimizing Communication Overhead in Window-Based Parallel Complex Event Processing | http://arxiv.org/abs/1705.05824 | id:1705.05824 author:Ruben Mayer, Muhammad Adnan Tariq, Kurt Rothermel category:cs.DC  published:2017-05-16 summary:Distributed Complex Event Processing has emerged as a well-established paradigm to detect situations of interest from basic sensor streams, building an operator graph between sensors and applications. In order to detect event patterns that correspond to situations of interest, each operator correlates events on its incoming streams according to a sliding window mechanism. To increase the throughput of an operator, different windows can be assigned to different operator instances---i.e., identical operator copies---which process them in parallel. This implies that events that are part of multiple overlapping windows are replicated to different operator instances. The communication overhead of replicating the events can be reduced by assigning overlapping windows to the same operator instance. However, this imposes a higher processing load on the single operator instance, possibly overloading it. In this paper, we address the trade-off between processing load and communication overhead when assigning overlapping windows to a single operator instance. Controlling the trade-off is challenging and cannot be solved with traditional reactive methods. To this end, we propose a model-based batch scheduling controller building on prediction. Evaluations show that our approach is able to significantly save bandwidth, while keeping a user-defined latency bound in the operator instances. version:1
arxiv-1705-05785 | Demystifying Relational Latent Representations | http://arxiv.org/abs/1705.05785 | id:1705.05785 author:Sebastijan Dumančić, Hendrik Blockeel category:cs.AI cs.LG stat.ML  published:2017-05-16 summary:Latent features learned by deep learning approaches have proven to be a powerful tool for machine learning. They serve as a data abstraction that makes learning easier by capturing regularities in data explicitly. Their benefits motivated their adaptation to relational learning context. In our previous work, we introduce an approach that learns relational latent features by means of clustering instances and their relations. The major drawback of latent representations is that they are often black-box and difficult to interpret. This work addresses these issues and shows that (1) latent features created by clustering are interpretable and capture interesting properties of data; (2) they identify local regions of instances that match well with the label, which partially explains their benefit; and (3) although the number of latent features generated by this approach is large, often many of them are highly redundant and can be removed without hurting performance much. version:1
arxiv-1705-05769 | Multiobjective Programming for Type-2 Hierarchical Fuzzy Inference Trees | http://arxiv.org/abs/1705.05769 | id:1705.05769 author:Varun Kumar Ojha, Vaclav Snasel, Ajith Abraham category:cs.AI  published:2017-05-16 summary:This paper proposes a design of hierarchical fuzzy inference tree (HFIT). An HFIT produces an optimum treelike structure, i.e., a natural hierarchical structure that accommodates simplicity by combining several low-dimensional fuzzy inference systems (FISs). Such a natural hierarchical structure provides a high degree of approximation accuracy. The construction of HFIT takes place in two phases. Firstly, a nondominated sorting based multiobjective genetic programming (MOGP) is applied to obtain a simple tree structure (a low complexity model) with a high accuracy. Secondly, the differential evolution algorithm is applied to optimize the obtained tree's parameters. In the derived tree, each node acquires a different input's combination, where the evolutionary process governs the input's combination. Hence, HFIT nodes are heterogeneous in nature, which leads to a high diversity among the rules generated by the HFIT. Additionally, the HFIT provides an automatic feature selection because it uses MOGP for the tree's structural optimization that accepts inputs only relevant to the knowledge contained in data. The HFIT was studied in the context of both type-1 and type-2 FISs, and its performance was evaluated through six application problems. Moreover, the proposed multiobjective HFIT was compared both theoretically and empirically with recently proposed FISs methods from the literature, such as McIT2FIS, TSCIT2FNN, SIT2FNN, RIT2FNS-WB, eT2FIS, MRIT2NFS, IT2FNN-SVR, etc. From the obtained results, it was found that the HFIT provided less complex and highly accurate models compared to the models produced by the most of other methods. Hence, the proposed HFIT is an efficient and competitive alternative to the other FISs for function approximation and feature selection. version:1
arxiv-1705-05765 | Online Article Ranking as a Constrained, Dynamic, Multi-Objective Optimization Problem | http://arxiv.org/abs/1705.05765 | id:1705.05765 author:Jeya Balaji Balasubramanian, Akshay Soni, Yashar Mehdad, Nikolay Laptev category:cs.AI cs.IR  published:2017-05-16 summary:The content ranking problem in a social news website, is typically a function that maximizes a scalar metric of interest like dwell-time. However, like in most real-world applications we are interested in more than one metric---for instance simultaneously maximizing click-through rate, monetization metrics, dwell-time---and also satisfy the traffic requirements promised to different publishers. All this needs to be done on online data and under the settings where the objective function and the constraints can dynamically change; this could happen if for instance new publishers are added, some contracts are adjusted, or if some contracts are over. In this paper, we formulate this problem as a constrained, dynamic, multi-objective optimization problem. We propose a novel framework that extends a successful genetic optimization algorithm, NSGA-II, to solve this online, data-driven problem. We design the modules of NSGA-II to suit our problem. We evaluate optimization performance using Hypervolume and introduce a confidence interval metric for assessing the practicality of a solution. We demonstrate the application of this framework on a real-world Article Ranking problem. We observe that we make considerable improvements in both time and performance over a brute-force baseline technique that is currently in production. version:1
arxiv-1705-05756 | All-relevant feature selection using multidimensional filters with exhaustive search | http://arxiv.org/abs/1705.05756 | id:1705.05756 author:Krzysztof Mnich, Witold R. Rudnicki category:cs.AI  published:2017-05-16 summary:This paper describes a method for identification of the informative variables in the information system with discrete decision variables. It is targeted specifically towards discovery of the variables that are non-informative when considered alone, but are informative when the synergistic interactions between multiple variables are considered. To this end, the mutual entropy of all possible k-tuples of variables with decision variable is computed. Then, for each variable the maximal information gain due to interactions with other variables is obtained. For non-informative variables this quantity conforms to the well known statistical distributions. This allows for discerning truly informative variables from non-informative ones. For demonstration of the approach, the method is applied to several synthetic datasets that involve complex multidimensional interactions between variables. It is capable of identifying most important informative variables, even in the case when the dimensionality of the analysis is smaller than the true dimensionality of the problem. What is more, the high sensitivity of the algorithm allows for detection of the influence of nuisance variables on the response variable. version:1
arxiv-1705-05735 | Comparison-Based Choices | http://arxiv.org/abs/1705.05735 | id:1705.05735 author:Jon Kleinberg, Sendhil Mullainathan, Johan Ugander category:cs.DS cs.AI  published:2017-05-16 summary:A broad range of on-line behaviors are mediated by interfaces in which people make choices among sets of options. A rich and growing line of work in the behavioral sciences indicate that human choices follow not only from the utility of alternatives, but also from the choice set in which alternatives are presented. In this work we study comparison-based choice functions, a simple but surprisingly rich class of functions capable of exhibiting so-called choice-set effects. Motivated by the challenge of predicting complex choices, we study the query complexity of these functions in a variety of settings. We consider settings that allow for active queries or passive observation of a stream of queries, and give analyses both at the granularity of individuals or populations that might exhibit heterogeneous choice behavior. Our main result is that any comparison-based choice function in one dimension can be inferred as efficiently as a basic maximum or minimum choice function across many query contexts, suggesting that choice-set effects need not entail any fundamental algorithmic barriers to inference. We also introduce a class of choice functions we call distance-comparison-based functions, and briefly discuss the analysis of such functions. The framework we outline provides intriguing connections between human choice behavior and a range of questions in the theory of sorting. version:1
arxiv-1705-05720 | Subjective Knowledge Acquisition and Enrichment Powered By Crowdsourcing | http://arxiv.org/abs/1705.05720 | id:1705.05720 author:Rui Meng, Hao Xin, Lei Chen, Yangqiu Song category:cs.DB cs.AI cs.HC  published:2017-05-16 summary:Knowledge bases (KBs) have attracted increasing attention due to its great success in various areas, such as Web and mobile search.Existing KBs are restricted to objective factual knowledge, such as city population or fruit shape, whereas,subjective knowledge, such as big city, which is commonly mentioned in Web and mobile queries, has been neglected. Subjective knowledge differs from objective knowledge in that it has no documented or observed ground truth. Instead, the truth relies on people's dominant opinion. Thus, we can use the crowdsourcing technique to get opinion from the crowd. In our work, we propose a system, called crowdsourced subjective knowledge acquisition (CoSKA),for subjective knowledge acquisition powered by crowdsourcing and existing KBs. The acquired knowledge can be used to enrich existing KBs in the subjective dimension which bridges the gap between existing objective knowledge and subjective queries.The main challenge of CoSKA is the conflict between large scale knowledge facts and limited crowdsourcing resource. To address this challenge, in this work, we define knowledge inference rules and then select the seed knowledge judiciously for crowdsourcing to maximize the inference power under the resource constraint. Our experimental results on real knowledge base and crowdsourcing platform verify the effectiveness of CoSKA system. version:1
arxiv-1705-05704 | Parallel Search with no Coordination | http://arxiv.org/abs/1705.05704 | id:1705.05704 author:Amos Korman, Yoav Rodeh category:cs.DC  published:2017-05-16 summary:We consider a parallel version of a classical Bayesian search problem. $k$ agents are looking for a treasure that is placed in one of the boxes indexed by $\mathbb{N}^+$ according to a known distribution $p$. The aim is to minimize the expected time until the first agent finds it. Searchers run in parallel where at each time step each searcher can "peek" into a box. A basic family of algorithms which are inherently robust is \emph{non-coordinating} algorithms. Such algorithms act independently at each searcher, differing only by their probabilistic choices. We are interested in the price incurred by employing such algorithms when compared with the case of full coordination. We first show that there exists a non-coordination algorithm, that knowing only the relative likelihood of boxes according to $p$, has expected running time of at most $10+4(1+\frac{1}{k})^2 T$, where $T$ is the expected running time of the best fully coordinated algorithm. This result is obtained by applying a refined version of the main algorithm suggested by Fraigniaud, Korman and Rodeh in STOC'16, which was designed for the context of linear parallel search.We then describe an optimal non-coordinating algorithm for the case where the distribution $p$ is known. The running time of this algorithm is difficult to analyse in general, but we calculate it for several examples. In the case where $p$ is uniform over a finite set of boxes, then the algorithm just checks boxes uniformly at random among all non-checked boxes and is essentially $2$ times worse than the coordinating algorithm.We also show simple algorithms for Pareto distributions over $M$ boxes. That is, in the case where $p(x) \sim 1/x^b$ for $0< b < 1$, we suggest the following algorithm: at step $t$ choose uniformly from the boxes unchecked in ${1, . . . ,min(M, \lfloor t/\sigma\rfloor)}$, where $\sigma = b/(b + k - 1)$. It turns out this algorithm is asymptotically optimal, and runs about $2+b$ times worse than the case of full coordination. version:1
arxiv-1705-05691 | Cloudroid: A Cloud Framework for Transparent and QoS-aware Robotic Computation Outsourcing | http://arxiv.org/abs/1705.05691 | id:1705.05691 author:Ben Hu, Huaimin Wang, Pengfei Zhang, Bo Ding, Huimin Che category:cs.DC cs.RO  published:2017-05-16 summary:Many robotic tasks require heavy computation, which can easily exceed the robot's onboard computer capability. A promising solution to address this challenge is outsourcing the computation to the cloud. However, exploiting the potential of cloud resources in robotic software is difficult, because it involves complex code modification and extensive (re)configuration procedures. Moreover, quality of service (QoS) such as timeliness, which is critical to robot's behavior, have to be considered. In this paper, we propose a transparent and QoS-aware software framework called Cloudroid for cloud robotic applications. This framework supports direct deployment of existing robotic software packages to the cloud, transparently transforming them into Internet-accessible cloud services. And with the automatically generated service stubs, robotic applications can outsource their computation to the cloud without any code modification. Furthermore, the robot and the cloud can cooperate to maintain the specific QoS property such as request response time, even in a highly dynamic and resource-competitive environment. We evaluated Cloudroid based on a group of typical robotic scenarios and a set of software packages widely adopted in real-world robot practices. Results show that robot's capability can be enhanced significantly without code modification and specific QoS objectives can be guaranteed. In certain tasks, the "cloud + robot" setup shows improved performance in orders of magnitude compared with the robot native setup. version:1
arxiv-1705-05684 | A lightweight MapReduce framework for secure processing with SGX | http://arxiv.org/abs/1705.05684 | id:1705.05684 author:Rafael Pires, Daniel Gavril, Pascal Felber, Emanuel Onica, Marcelo Pasin category:cs.DC cs.CR  published:2017-05-16 summary:MapReduce is a programming model used extensively for parallel data processing in distributed environments. A wide range of algorithms were implemented using MapReduce, from simple tasks like sorting and searching up to complex clustering and machine learning operations. Many of these implementations are part of services externalized to cloud infrastructures. Over the past years, however, many concerns have been raised regarding the security guarantees offered in such environments. Some solutions relying on cryptography were proposed for countering threats but these typically imply a high computational overhead. Intel, the largest manufacturer of commodity CPUs, recently introduced SGX (software guard extensions), a set of hardware instructions that support execution of code in an isolated secure environment. In this paper, we explore the use of Intel SGX for providing privacy guarantees for MapReduce operations, and based on our evaluation we conclude that it represents a viable alternative to a cryptographic mechanism. We present results based on the widely used k-means clustering algorithm, but our implementation can be generalized to other applications that can be expressed using MapReduce model. version:1
arxiv-1705-05681 | Optimal Warping Paths are unique for almost every pair of Time Series | http://arxiv.org/abs/1705.05681 | id:1705.05681 author:Brijnesh J. Jain, David Schultz category:cs.LG cs.AI stat.ML  published:2017-05-16 summary:An optimal warping path between two time series is generally not unique. The size and form of the set of pairs of time series with non-unique optimal warping path is unknown. This article shows that optimal warping paths are unique for almost every pair of time series in a measure-theoretic sense. All pairs of time series with non-unique optimal warping path form a negligible set and are geometrically the union of zero sets of quadratic forms. The result is useful for analyzing and understanding adaptive learning methods in dynamic time warping spaces. version:1
arxiv-1503-04333 | Dynamic Move Tables and Long Branches with Backtracking in Computer Chess | http://arxiv.org/abs/1503.04333 | id:1503.04333 author:Kieran Greer category:cs.AI  published:2015-03-14 summary:The idea of dynamic move chains has been described in a preceding paper [10]. Re-using an earlier piece of search allows the tree to be forward-pruned, which is known to be dangerous, because it can potentially remove new information that would only be realised through a more exhaustive search process. The justification is the integrity in the position and small changes between positions make it more likely that an earlier result still applies. Larger problems where exhaustive search is not possible would also like a method that can guess accurately. This paper has added to the forward-pruning technique by using 'move tables' that can act in the same way as Transposition Tables, but for moves not positions. They use an efficient memory structure and have put the design into the context of short or long-term memories. The long-term memory includes simply rote-learning of other players' games. The forward-pruning technique can also be fortified to help to remove some potential errors. Another idea is 'long branches'. This plays a short move sequence, before returning to a full search at the resulting leaf nodes. Therefore, with some configuration the dynamic tables can be reliably used and relatively independently of the position. This has advanced some of the future work theory of the earlier paper, and made more explicit where logical plans and more knowledge-based approaches might be applied. The author would argue that the process is a very human approach to searching for chess moves. version:3
arxiv-1411-0440 | Modelling serendipity in a computational context | http://arxiv.org/abs/1411.0440 | id:1411.0440 author:Joseph Corneli, Anna Jordanous, Christian Guckelsberger, Alison Pease, Simon Colton category:cs.AI I.2.11; D.2.2  published:2014-11-03 summary:Building on a survey of previous theories of serendipity and creativity, we advance a sequential model of serendipitous occurrences. We distinguish between serendipity as a service and serendipity in the system itself, clarify the role of invention and discovery, and provide a measure for the serendipity potential of a system. While a system can arguably not be guaranteed to be serendipitous, it can have a high potential for serendipity. Practitioners can use these theoretical tools to evaluate a computational system's potential for unexpected behaviour that may have a beneficial outcome. In addition to a qualitative features of serendipity potential, the model also includes quantitative ratings that can guide development work. We show how the model is used in three case studies of existing and hypothetical systems, in the context of evolutionary computing, automated programming, and (next-generation) recommender systems. From this analysis, we extract recommendations for practitioners working with computational serendipity, and outline future directions for research. version:5
arxiv-1705-05646 | Quadratic and Near-Quadratic Lower Bounds for the CONGEST Model | http://arxiv.org/abs/1705.05646 | id:1705.05646 author:Keren Censor-Hillel, Seri Khoury, Ami Paz category:cs.DC cs.DS  published:2017-05-16 summary:We present the first super-linear lower bounds for natural graph problems in the CONGEST model, answering a long-standing open question. Specifically, we show that any exact computation of a minimum vertex cover or a maximum independent set requires $\Omega(n^2/\log^2{n})$ rounds in the worst case in the CONGEST model, as well as any algorithm for $\chi$-coloring a graph, where $\chi$ is the chromatic number of the graph. We further show that such strong lower bounds are not limited to NP-hard problems, by showing two simple graph problems in P which require a quadratic and near-quadratic number of rounds. Finally, we address the problem of computing an exact solution to weighted all-pairs-shortest-paths (APSP), which arguably may be considered as a candidate for having a super-linear lower bound. We show a simple $\Omega(n)$ lower bound for this problem, which implies a separation between the weighted and unweighted cases, since the latter is known to have a complexity of $\Theta(n/\log{n})$. We also formally prove that the standard Alice-Bob framework is incapable of providing a super-linear lower bound for exact weighted APSP, whose complexity remains an intriguing open question. version:1
arxiv-1705-05637 | Text-based Adventures of the Golovin AI Agent | http://arxiv.org/abs/1705.05637 | id:1705.05637 author:Bartosz Kostka, Jaroslaw Kwiecien, Jakub Kowalski, Pawel Rychlikowski category:cs.AI  published:2017-05-16 summary:The domain of text-based adventure games has been recently established as a new challenge of creating the agent that is both able to understand natural language, and acts intelligently in text-described environments. In this paper, we present our approach to tackle the problem. Our agent, named Golovin, takes advantage of the limited game domain. We use genre-related corpora (including fantasy books and decompiled games) to create language models suitable to this domain. Moreover, we embed mechanisms that allow us to specify, and separately handle, important tasks as fighting opponents, managing inventory, and navigating on the game map. We validated usefulness of these mechanisms, measuring agent's performance on the set of 50 interactive fiction games. Finally, we show that our agent plays on a level comparable to the winner of the last year Text-Based Adventure AI Competition. version:1
arxiv-1707-00561 | Identifying hazardousness of sewer pipeline gas mixture using classification methods: a comparative study | http://arxiv.org/abs/1707.00561 | id:1707.00561 author:Varun Kumar Ojha, Paramartha Dutta, Atal Chaudhuri category:cs.NE cs.AI  published:2017-05-16 summary:In this work, we formulated a real-world problem related to sewer pipeline gas detection using the classification-based approaches. The primary goal of this work was to identify the hazardousness of sewer pipeline to offer safe and non-hazardous access to sewer pipeline workers so that the human fatalities, which occurs due to the toxic exposure of sewer gas components, can be avoided. The dataset acquired through laboratory tests, experiments, and various literature sources was organized to design a predictive model that was able to identify/classify hazardous and non-hazardous situation of sewer pipeline. To design such prediction model, several classification algorithms were used and their performances were evaluated and compared, both empirically and statistically, over the collected dataset. In addition, the performances of several ensemble methods were analyzed to understand the extent of improvement offered by these methods. The result of this comprehensive study showed that the instance-based learning algorithm performed better than many other algorithms such as multilayer perceptron, radial basis function network, support vector machine, reduced pruning tree. Similarly, it was observed that multi-scheme ensemble approach enhanced the performance of base predictors. version:1
arxiv-1705-05583 | Tight Analysis for the 3-Majority Consensus Dynamics | http://arxiv.org/abs/1705.05583 | id:1705.05583 author:Mohsen Ghaffari, Johannes Lengler category:cs.DC cs.DM  published:2017-05-16 summary:We present a tight analysis for the well-studied randomized 3-majority dynamics of stabilizing consensus, hence answering the main open question of Becchetti et al. [SODA'16]. Consider a distributed system of n nodes, each initially holding an opinion in {1, 2, ..., k}. The system should converge to a setting where all (non-corrupted) nodes hold the same opinion. This consensus opinion should be \emph{valid}, meaning that it should be among the initially supported opinions, and the (fast) convergence should happen even in the presence of a malicious adversary who can corrupt a bounded number of nodes per round and in particular modify their opinions. A well-studied distributed algorithm for this problem is the 3-majority dynamics, which works as follows: per round, each node gathers three opinions --- say by taking its own and two of other nodes sampled at random --- and then it sets its opinion equal to the majority of this set; ties are broken arbitrarily, e.g., towards the node's own opinion. Becchetti et al. [SODA'16] showed that the 3-majority dynamics converges to consensus in O((k^2\sqrt{\log n} + k\log n)(k+\log n)) rounds, even in the presence of a limited adversary. We prove that, even with a stronger adversary, the convergence happens within O(k\log n) rounds. This bound is known to be optimal. version:1
arxiv-1706-09724 | Kinematics and workspace analysis of a 3ppps parallel robot with u-shaped base | http://arxiv.org/abs/1706.09724 | id:1706.09724 author:Damien Chablat, Luc Baron, Ranjan Jha category:cs.RO  published:2017-05-16 summary:This paper presents the kinematic analysis of the 3-PPPS parallel robot with an equilateral mobile platform and a U-shape base. The proposed design and appropriate selection of parameters allow to formulate simpler direct and inverse kinematics for the manipulator under study. The parallel singularities associated with the manipulator depend only on the orientation of the end-effector, and thus depend only on the orientation of the end effector. The quaternion parameters are used to represent the aspects, i.e. the singularity free regions of the workspace. A cylindrical algebraic decomposition is used to characterize the workspace and joint space with a low number of cells. The dis-criminant variety is obtained to describe the boundaries of each cell. With these simplifications, the 3-PPPS parallel robot with proposed design can be claimed as the simplest 6 DOF robot, which further makes it useful for the industrial applications. version:1
arxiv-1705-05563 | Kinematics, workspace and singularity analysis of a multi-mode parallel robot | http://arxiv.org/abs/1705.05563 | id:1705.05563 author:Damien Chablat, Xianwen Kong, Chengwei Zhang category:cs.RO  published:2017-05-16 summary:A family of reconfigurable parallel robots can change motion modes by passing through constraint singularities by locking and releasing some passive joints of the robot. This paper is about the kinematics, the workspace and singularity analysis of a 3-PRPiR parallel robot involving lockable Pi and R (revolute) joints. Here a Pi joint may act as a 1-DOF planar parallelogram if its lock-able P (prismatic) joint is locked or a 2-DOF RR serial chain if its lockable P joint is released. The operation modes of the robot include a 3T operation modes to three 2T1R operation modes with two different directions of the rotation axis of the moving platform. The inverse kinematics and forward kinematics of the robot in each operation modes are dealt with in detail. The workspace analysis of the robot allow us to know the regions of the workspace that the robot can reach in each operation mode. A prototype built at Heriot-Watt University is used to illustrate the results of this work. version:1
arxiv-1703-03543 | Communications that Emerge through Reinforcement Learning Using a (Recurrent) Neural Network | http://arxiv.org/abs/1703.03543 | id:1703.03543 author:Katsunari Shibata category:cs.AI  published:2017-03-10 summary:Communication is not only an action of choosing a signal, but needs to consider the context and sensor signals. It also needs to decide what information is communicated and how it is represented in or understood from signals. Therefore, communication should be realized comprehensively together with its purpose and other functions. The recent successful results in end-to-end reinforcement learning (RL) show the importance of comprehensive learning and the usefulness of end-to-end RL. Although little is known, we have shown that a variety of communications emerge through RL using a (recurrent) neural network (NN). Here, three of them are introduced. In the 1st one, negotiation to avoid conflicts among 4 randomly-picked agents was learned. Each agent generates a binary signal from the output of its recurrent NN (RNN), and receives 4 signals from the agents three times. After learning, each agent made an appropriate final decision after negotiation for any combination of 4 agents. Differentiation of individuality among the agents also could be seen. The 2nd one focused on discretization of communication signal. A sender agent perceives the receiver's location and generates a continuous signal twice by its RNN. A receiver agent receives them sequentially, and moves according to its RNN's output to reach the sender's location. When noises were added to the signal, it was binarized through learning and 2-bit communication was established. The 3rd one focused on end-to-end comprehensive communication. A sender receives 1,785-pixel real camera image on which a real robot can be seen, and sends two sounds whose frequencies are computed by its NN. A receiver receives them, and two motion commands for the robot are generated by its NN. After learning, though some preliminary learning was necessary for the sender, the robot could reach the goal from any initial location. version:2
arxiv-1703-02239 | Functions that Emerge through End-to-End Reinforcement Learning - The Direction for Artificial General Intelligence - | http://arxiv.org/abs/1703.02239 | id:1703.02239 author:Katsunari Shibata category:cs.AI  published:2017-03-07 summary:Recently, triggered by the impressive results in TV-games or game of Go by Google DeepMind, end-to-end reinforcement learning (RL) is collecting attentions. Although little is known, the author's group has propounded this framework for around 20 years and already has shown various functions that emerge in a neural network (NN) through RL. In this paper, they are introduced again at this timing. "Function Modularization" approach is deeply penetrated subconsciously. The inputs and outputs for a learning system can be raw sensor signals and motor commands. "State space" or "action space" generally used in RL show the existence of functional modules. That has limited reinforcement learning to learning only for the action-planning module. In order to extend reinforcement learning to learning of the entire function on a huge degree of freedom of a massively parallel learning system and to explain or develop human-like intelligence, the author has believed that end-to-end RL from sensors to motors using a recurrent NN (RNN) becomes an essential key. Especially in the higher functions, this approach is very effective by being free from the need to decide their inputs and outputs. The functions that emerge, we have confirmed, through RL using a NN cover a broad range from real robot learning with raw camera pixel inputs to acquisition of dynamic functions in a RNN. Those are (1)image recognition, (2)color constancy (optical illusion), (3)sensor motion (active recognition), (4)hand-eye coordination and hand reaching movement, (5)explanation of brain activities, (6)communication, (7)knowledge transfer, (8)memory, (9)selective attention, (10)prediction, (11)exploration. The end-to-end RL enables the emergence of very flexible comprehensive functions that consider many things in parallel although it is difficult to give the boundary of each function clearly. version:2
arxiv-1705-05551 | New Reinforcement Learning Using a Chaotic Neural Network for Emergence of "Thinking" - "Exploration" Grows into "Thinking" through Learning - | http://arxiv.org/abs/1705.05551 | id:1705.05551 author:Katsunari Shibata, Yuki Goto category:cs.AI  published:2017-05-16 summary:Expectation for the emergence of higher functions is getting larger in the framework of end-to-end reinforcement learning using a recurrent neural network. However, the emergence of "thinking" that is a typical higher function is difficult to realize because "thinking" needs non fixed-point, flow-type attractors with both convergence and transition dynamics. Furthermore, in order to introduce "inspiration" or "discovery" in "thinking", not completely random but unexpected transition should be also required. By analogy to "chaotic itinerancy", we have hypothesized that "exploration" grows into "thinking" through learning by forming flow-type attractors on chaotic random-like dynamics. It is expected that if rational dynamics are learned in a chaotic neural network (ChNN), coexistence of rational state transition, inspiration-like state transition and also random-like exploration for unknown situation can be realized. Based on the above idea, we have proposed new reinforcement learning using a ChNN as an actor. The positioning of exploration is completely different from the conventional one. The chaotic dynamics inside the ChNN produces exploration factors by itself. Since external random numbers for stochastic action selection are not used, exploration factors cannot be isolated from the output. Therefore, the learning method is also completely different from the conventional one. At each non-feedback connection, one variable named causality trace takes in and maintains the input through the connection according to the change in its output. Using the trace and TD error, the weight is updated. In this paper, as the result of a recent simple task to see whether the new learning works or not, it is shown that a robot with two wheels and two visual sensors reaches a target while avoiding an obstacle after learning though there are still many rooms for improvement. version:1
arxiv-1705-05541 | Algorithm-Directed Crash Consistence in Non-Volatile Memory for HPC | http://arxiv.org/abs/1705.05541 | id:1705.05541 author:Shuo Yang, Kai Wu, Yifan Qiao, Dong Li, Jidong Zhai category:cs.DC  published:2017-05-16 summary:Fault tolerance is one of the major design goals for HPC. The emergence of non-volatile memories (NVM) provides a solution to build fault tolerant HPC. Data in NVM-based main memory are not lost when the system crashes because of the non-volatility nature of NVM. However, because of volatile caches, data must be logged and explicitly flushed from caches into NVM to ensure consistence and correctness before crashes, which can cause large runtime overhead. In this paper, we introduce an algorithm-based method to establish crash consistence in NVM for HPC applications. We slightly extend application data structures or sparsely flush cache blocks, which introduce ignorable runtime overhead. Such extension or cache flushing allows us to use algorithm knowledge to \textit{reason} data consistence or correct inconsistent data when the application crashes. We demonstrate the effectiveness of our method for three algorithms, including an iterative solver, dense matrix multiplication, and Monte-Carlo simulation. Based on comprehensive performance evaluation on a variety of test environments, we demonstrate that our approach has very small runtime overhead (at most 8.2\% and less than 3\% in most cases), much smaller than that of traditional checkpoint, while having the same or less recomputation cost. version:1
arxiv-1705-05524 | Learning Hard Alignments with Variational Inference | http://arxiv.org/abs/1705.05524 | id:1705.05524 author:Dieterich Lawson, George Tucker, Chung-Cheng Chiu, Colin Raffel, Kevin Swersky, Navdeep Jaitly category:cs.AI cs.LG stat.ML  published:2017-05-16 summary:There has recently been significant interest in hard attention models for tasks such as object recognition, visual captioning and speech recognition. Hard attention can offer benefits over soft attention such as decreased computational cost, but training hard attention models can be difficult because of the discrete latent variables they introduce. Previous work has used REINFORCE and Q-learning to approach these issues, but those methods can provide high-variance gradient estimates and be slow to train. In this paper, we tackle the problem of learning hard attention for a 1-d temporal task using variational inference methods, specifically the recently introduced VIMCO and NVIL. Furthermore, we propose novel baselines that adapt VIMCO to this setting. We demonstrate our method on a phoneme recognition task in clean and noisy environments and show that our method outperforms REINFORCE with the difference being greater for a more complicated task. version:1
arxiv-1705-05515 | A Method for Determining Weights of Criterias and Alternative of Fuzzy Group Decision Making Problem | http://arxiv.org/abs/1705.05515 | id:1705.05515 author:Jon JaeGyong, Mun JongHui, Ryang GyongIl category:cs.AI  published:2017-05-16 summary:In this paper, we constructed a model to determine weights of criterias and presented a solution for determining the optimal alternative by using the constructed model and relationship analysis between criterias in fuzzy group decision-making problem with different forms of preference information of decision makers on criterias. version:1
arxiv-1705-05491 | Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent | http://arxiv.org/abs/1705.05491 | id:1705.05491 author:Yudong Chen, Lili Su, Jiaming Xu category:cs.DC cs.CR cs.LG stat.ML  published:2017-05-16 summary:We consider the problem of distributed statistical machine learning in adversarial settings, where some unknown and time-varying subset of working machines may be compromised and behave arbitrarily to prevent an accurate model from being learned. This setting captures the potential adversarial attacks faced by Federated Learning -- a modern machine learning paradigm that is proposed by Google researchers and has been intensively studied for ensuring user privacy. Formally, we focus on a distributed system consisting of a parameter server and $m$ working machines. Each working machine keeps $N/m$ data samples, where $N$ is the total number of samples. The goal is to collectively learn the underlying true model parameter of dimension $d$. In classical batch gradient descent methods, the gradients reported to the server by the working machines are aggregated via simple averaging, which is vulnerable to a single Byzantine failure. In this paper, we propose a Byzantine gradient descent method based on the geometric median of means of the gradients. We show that our method can tolerate $q \le (m-1)/2$ Byzantine failures, and the parameter estimate converges in $O(\log N)$ rounds with an estimation error of $\sqrt{d(2q+1)/N}$, hence approaching the optimal error rate $\sqrt{d/N}$ in the centralized and failure-free setting. The total computational complexity of our algorithm is of $O((Nd/m) \log N)$ at each working machine and $O(md + kd \log^3 N)$ at the central server, and the total communication cost is of $O(m d \log N)$. We further provide an application of our general results to the linear regression problem. A key challenge arises in the above problem is that Byzantine failures create arbitrary and unspecified dependency among the iterations and the aggregated gradients. We prove that the aggregated gradient converges uniformly to the true gradient function. version:1
arxiv-1702-04047 | Constraint Answer Set Solver EZCSP and Why Integration Schemas Matter | http://arxiv.org/abs/1702.04047 | id:1702.04047 author:Marcello Balduccini, Yuliya Lierler category:cs.AI  published:2017-02-14 summary:Researchers in answer set programming and constraint programming have spent significant efforts in the development of hybrid languages and solving algorithms combining the strengths of these traditionally separate fields. These efforts resulted in a new research area: constraint answer set programming. Constraint answer set programming languages and systems proved to be successful at providing declarative, yet efficient solutions to problems involving hybrid reasoning tasks. One of the main contributions of this paper is the first comprehensive account of the constraint answer set language and solver EZCSP, a mainstream representative of this research area that has been used in various successful applications. We also develop an extension of the transition systems proposed by Nieuwenhuis et al. in 2006 to capture Boolean satisfiability solvers. We use this extension to describe the EZCSP algorithm and prove formal claims about it. The design and algorithmic details behind EZCSP clearly demonstrate that the development of the hybrid systems of this kind is challenging. Many questions arise when one faces various design choices in an attempt to maximize system's benefits. One of the key decisions that a developer of a hybrid solver makes is settling on a particular integration schema within its implementation. Thus, another important contribution of this paper is a thorough case study based on EZCSP, focused on the various integration schemas that it provides. Under consideration in Theory and Practice of Logic Programming (TPLP). version:2
arxiv-1705-05472 | A Biomimetic Vocalisation System for MiRo | http://arxiv.org/abs/1705.05472 | id:1705.05472 author:Roger K. Moore, Ben Mitchinson category:cs.SD cs.RO  published:2017-05-15 summary:There is increasing interest in the use of animal-like robots in applications such as companionship and pet therapy. However, in the majority of cases it is only the robot's physical appearance that mimics a given animal. In contrast, MiRo is the first commercial biomimetic robot to be based on a hardware and software architecture that is modelled on the biological brain. This paper describes how MiRo's vocalisation system was designed, not using pre-recorded animal sounds, but based on the implementation of a real-time parametric general-purpose mammalian vocal synthesiser tailored to the specific physical characteristics of the robot. The novel outcome has been the creation of an 'appropriate' voice for MiRo that is perfectly aligned to the physical and behavioural affordances of the robot, thereby avoiding the 'uncanny valley' effect and contributing strongly to the effectiveness of MiRo as an interactive device. version:1
arxiv-1705-05464 | Diseña, Fabrica y Programa Tu Propio Robot | http://arxiv.org/abs/1705.05464 | id:1705.05464 author:Leopoldo Armesto category:cs.RO  published:2017-05-15 summary:In this document we present DYOR, an educational robot that you can make at home or at class. The robot has been created by students at the Universitat Polit\'ecnica de Val\`encia and me through their projects and masther thesis and it has been used in my subjects at the University so my students dessign, make and program their own robot with low-cost materials. version:1
arxiv-1705-02745 | Pricing of Tiered cloud storage via two-stage, latency-aware bidding | http://arxiv.org/abs/1705.02745 | id:1705.02745 author:Yang Zhang, Arnob Ghosh, Vaneet Aggarwal, Tian Lan, Yu Xiang, Yih-Farn Robin Chen category:cs.NI cs.DC cs.GT  published:2017-05-08 summary:In this paper, we address a major challenge confronting the Cloud Service Providers (CSPs) utilizing a tiered storage architecture - how to maximize their overall profit over a variety of storage tiers that offer distinct characteristics, as well as file placement and access request scheduling policies. version:2
arxiv-1610-09604 | Understanding and Exploiting Design-Induced Latency Variation in Modern DRAM Chips | http://arxiv.org/abs/1610.09604 | id:1610.09604 author:Donghyuk Lee, Samira Khan, Lavanya Subramanian, Saugata Ghose, Rachata Ausavarungnirun, Gennady Pekhimenko, Vivek Seshadri, Onur Mutlu category:cs.AR  published:2016-10-30 summary:Variation has been shown to exist across the cells within a modern DRAM chip. We empirically demonstrate a new form of variation that exists within a real DRAM chip, induced by the design and placement of different components in the DRAM chip. Our goals are to understand design-induced variation that exists in real, state-of-the-art DRAM chips, exploit it to develop low-cost mechanisms that can dynamically find and use the lowest latency at which to operate a DRAM chip reliably, and, thus, improve overall system performance while ensuring reliable system operation. To this end, we first experimentally demonstrate and analyze designed-induced variation in modern DRAM devices by testing and characterizing 96 DIMMs (768 DRAM chips). Our characterization identifies DRAM regions that are vulnerable to errors, if operated at lower latency, and finds consistency in their locations across a given DRAM chip generation, due to design-induced variation. Based on our extensive experimental analysis, we develop two mechanisms that reliably reduce DRAM latency. First, DIVA Profiling uses runtime profiling to dynamically identify the lowest DRAM latency that does not introduce failures. DIVA Profiling exploits design-induced variation and periodically profiles only the vulnerable regions to determine the lowest DRAM latency at low cost. Our second mechanism, DIVA Shuffling, shuffles data such that values stored in vulnerable regions are mapped to multiple error-correcting code (ECC) codewords. Combined together, our two mechanisms reduce read/write latency by 40.0%/60.5%, which translates to an overall system performance improvement of 14.7%/13.7%/13.8% (in 2-/4-/8-core systems) across a variety of workloads, while ensuring reliable operation. version:2
arxiv-1705-05396 | Learning Probabilistic Programs Using Backpropagation | http://arxiv.org/abs/1705.05396 | id:1705.05396 author:Avi Pfeffer category:cs.LG cs.AI stat.ML  published:2017-05-15 summary:Probabilistic modeling enables combining domain knowledge with learning from data, thereby supporting learning from fewer training instances than purely data-driven methods. However, learning probabilistic models is difficult and has not achieved the level of performance of methods such as deep neural networks on many tasks. In this paper, we attempt to address this issue by presenting a method for learning the parameters of a probabilistic program using backpropagation. Our approach opens the possibility to building deep probabilistic programming models that are trained in a similar way to neural networks. version:1
arxiv-1705-05394 | Probabilistically Safe Policy Transfer | http://arxiv.org/abs/1705.05394 | id:1705.05394 author:David Held, Zoe McCarthy, Michael Zhang, Fred Shentu, Pieter Abbeel category:cs.RO cs.AI cs.LG  published:2017-05-15 summary:Although learning-based methods have great potential for robotics, one concern is that a robot that updates its parameters might cause large amounts of damage before it learns the optimal policy. We formalize the idea of safe learning in a probabilistic sense by defining an optimization problem: we desire to maximize the expected return while keeping the expected damage below a given safety limit. We study this optimization for the case of a robot manipulator with safety-based torque limits. We would like to ensure that the damage constraint is maintained at every step of the optimization and not just at convergence. To achieve this aim, we introduce a novel method which predicts how modifying the torque limit, as well as how updating the policy parameters, might affect the robot's safety. We show through a number of experiments that our approach allows the robot to improve its performance while ensuring that the expected damage constraint is not violated during the learning process. version:1
arxiv-1705-05363 | Curiosity-driven Exploration by Self-supervised Prediction | http://arxiv.org/abs/1705.05363 | id:1705.05363 author:Deepak Pathak, Pulkit Agrawal, Alexei A. Efros, Trevor Darrell category:cs.LG cs.AI cs.CV cs.RO stat.ML  published:2017-05-15 summary:In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent's ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (e.g. new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch. Demo video and code available at https://pathak22.github.io/noreward-rl/ version:1
arxiv-1705-05344 | GP-ILQG: Data-driven Robust Optimal Control for Uncertain Nonlinear Dynamical Systems | http://arxiv.org/abs/1705.05344 | id:1705.05344 author:Gilwoo Lee, Siddhartha S. Srinivasa, Matthew T. Mason category:cs.RO cs.SY  published:2017-05-15 summary:As we aim to control complex systems, use of a simulator in model-based reinforcement learning is becoming more common. However, it has been challenging to overcome the Reality Gap, which comes from nonlinear model bias and susceptibility to disturbance. To address these problems, we propose a novel algorithm that combines data-driven system identification approach (Gaussian Process) with a Differential-Dynamic-Programming-based robust optimal control method (Iterative Linear Quadratic Control). Our algorithm uses the simulator's model as the mean function for a Gaussian Process and learns only the difference between the simulator's prediction and actual observations, making it a natural hybrid of simulation and real-world observation. We show that our approach quickly corrects incorrect models, comes up with robust optimal controllers, and transfers its acquired model knowledge to new tasks efficiently. version:1
arxiv-1705-05326 | Constrained Bayesian Networks: Theory, Optimization, and Applications | http://arxiv.org/abs/1705.05326 | id:1705.05326 author:Paul Beaumont, Michael Huth category:cs.AI  published:2017-05-15 summary:We develop the theory and practice of an approach to modelling and probabilistic inference in causal networks that is suitable when application-specific or analysis-specific constraints should inform such inference or when little or no data for the learning of causal network structure or probability values at nodes are available. Constrained Bayesian Networks generalize a Bayesian Network such that probabilities can be symbolic, arithmetic expressions and where the meaning of the network is constrained by finitely many formulas from the theory of the reals. A formal semantics for constrained Bayesian Networks over first-order logic of the reals is given, which enables non-linear and non-convex optimisation algorithms that rely on decision procedures for this logic, and supports the composition of several constrained Bayesian Networks. A non-trivial case study in arms control, where few or no data are available to assess the effectiveness of an arms inspection process, evaluates our approach. An open-access prototype implementation of these foundations and their algorithms uses the SMT solver Z3 as decision procedure, leverages an open-source package for Bayesian inference to symbolic computation, and is evaluated experimentally. version:1
arxiv-1705-05316 | Exploiting the Pruning Power of Strong Local Consistencies Through Parallelization | http://arxiv.org/abs/1705.05316 | id:1705.05316 author:Minas Dasygenis, Kostas Stergiou category:cs.AI I.2.8; F.0; D.1.3  published:2017-05-15 summary:Local consistencies stronger than arc consistency have received a lot of attention since the early days of CSP research. %because of the strong pruning they can achieve. However, they have not been widely adopted by CSP solvers. This is because applying such consistencies can sometimes result in considerably smaller search tree sizes and therefore in important speed-ups, but in other cases the search space reduction may be small, causing severe run time penalties. Taking advantage of recent advances in parallelization, we propose a novel approach for the application of strong local consistencies (SLCs) that can improve their performance by largely preserving the speed-ups they offer in cases where they are successful, and eliminating the run time penalties in cases where they are unsuccessful. This approach is presented in the form of two search algorithms. Both algorithms consist of a master search process, which is a typical CSP solver, and a number of slave processes, with each one implementing a SLC method. The first algorithm runs the different SLCs synchronously at each node of the search tree explored in the master process, while the second one can run them asynchronously at different nodes of the search tree. Experimental results demonstrate the benefits of the proposed method. version:1
arxiv-1701-09107 | Rational Parametrization of Linear Pentapod's Singularity Variety and the Distance to it | http://arxiv.org/abs/1701.09107 | id:1701.09107 author:Arvin Rasoulzadeh, Georg Nawratil category:cs.RO  published:2017-01-31 summary:A linear pentapod is a parallel manipulator with five collinear anchor points on the motion platform (end-effector), which are connected via extendible legs to the base. This manipulator has five controllable degrees-of-freedom and the remaining one is a free rotation around the motion platform axis (which in fact is an axial spindle). In this paper we present a rational parametrization of the singularity variety of the linear pentapod. Moreover we compute the shortest distance to this rational variety with respect to a suitable metric. Kinematically this distance can be interpreted as the radius of the maximal singularity free-sphere. version:2
arxiv-1705-05254 | Strategically knowing how | http://arxiv.org/abs/1705.05254 | id:1705.05254 author:Raul Fervari, Andreas Herzig, Yanjun Li, Yanjing Wang category:cs.AI cs.LO  published:2017-05-15 summary:In this paper, we propose a single-agent logic of goal-directed knowing how extending the standard epistemic logic of knowing that with a new knowing how operator. The semantics of the new operator is based on the idea that knowing how to achieve $\phi$ means that there exists a (uniform) strategy such that the agent knows that it can make sure $\phi$. We give an intuitive axiomatization of our logic and prove the soundness, completeness, and decidability of the logic. The crucial axioms relating knowing that and knowing how illustrate our understanding of knowing how in this setting. This logic can be used in representing both knowledge-that and knowledge-how. version:1
arxiv-1705-05206 | ResumeVis: A Visual Analytics System to Discover Semantic Information in Semi-structured Resume Data | http://arxiv.org/abs/1705.05206 | id:1705.05206 author:Chen Zhang, Hao Wang, Yingcai Wu category:cs.HC cs.AI  published:2017-05-15 summary:Massive public resume data emerging on the WWW indicates individual-related characteristics in terms of profile and career experiences. Resume Analysis (RA) provides opportunities for many applications, such as talent seeking and evaluation. Existing RA studies based on statistical analyzing have primarily focused on talent recruitment by identifying explicit attributes. However, they failed to discover the implicit semantic information, i.e., individual career progress patterns and social-relations, which are vital to comprehensive understanding of career development. Besides, how to visualize them for better human cognition is also challenging. To tackle these issues, we propose a visual analytics system ResumeVis to mine and visualize resume data. Firstly, a text-mining based approach is presented to extract semantic information. Then, a set of visualizations are devised to represent the semantic information in multiple perspectives. By interactive exploration on ResumeVis performed by domain experts, the following tasks can be accomplished: to trace individual career evolving trajectory; to mine latent social-relations among individuals; and to hold the full picture of massive resumes' collective mobility. Case studies with over 2500 online officer resumes demonstrate the effectiveness of our system. We provide a demonstration video. version:1
arxiv-1705-05172 | Emotion in Reinforcement Learning Agents and Robots: A Survey | http://arxiv.org/abs/1705.05172 | id:1705.05172 author:Thomas M. Moerland, Joost Broekens, Catholijn M. Jonker category:cs.LG cs.AI cs.HC cs.RO stat.ML  published:2017-05-15 summary:This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on agent/robot emotions, and mostly ignores human user emotions. Emotions are recognized as functional in decision-making by influencing motivation and action selection. Therefore, computational emotion models are usually grounded in the agent's decision making architecture, of which RL is an important subclass. Studying emotions in RL-based agents is useful for three research fields. For machine learning (ML) researchers, emotion models may improve learning efficiency. For the interactive ML and human-robot interaction (HRI) community, emotions can communicate state and enhance user investment. Lastly, it allows affective modelling (AM) researchers to investigate their emotion theories in a successful AI agent class. This survey provides background on emotion theory and RL. It systematically addresses 1) from what underlying dimensions (e.g., homeostasis, appraisal) emotions can be derived and how these can be modelled in RL-agents, 2) what types of emotions have been derived from these dimensions, and 3) how these emotions may either influence the learning efficiency of the agent or be useful as social signals. We also systematically compare evaluation criteria, and draw connections to important RL sub-domains like (intrinsic) motivation and model-based RL. In short, this survey provides both a practical overview for engineers wanting to implement emotions in their RL agents, and identifies challenges and directions for future emotion-RL research. version:1
arxiv-1705-05142 | Adapting a General Purpose Robot for Paediatric Rehabilitation: In-situ Design of a Socially Assistive Robot | http://arxiv.org/abs/1705.05142 | id:1705.05142 author:Felip Martí, Jo Butchart, Sarah Knight, Adam Scheinberg, Lisa Wise, Leon Sterling, Chris McCarthy category:cs.HC cs.RO  published:2017-05-15 summary:Socially Assistive Robots (SARs) offer great promise for improving outcomes in paediatric rehabilitation. However, the design of software and interactive capabilities for SARs must be carefully considered in the context of their intended clinical use. While previous work has explored specific roles and functionalities to support paediatric rehabilitation, few have considered the design of such capabilities in the context of ongoing clinical deployment. In this paper we present a two-phase In-situ Design process for SARs in health care, emphasising stakeholder engagement and on-site development. We explore this in the context of developing the humanoid social robot NAO as a socially assistive rehabilitation aid for children with cerebral palsy. We present and evaluate our design process, outcomes achieved, and preliminary results from ongoing clinical testing with 9 patients and 5 therapists over 14 sessions. We argue that our in-situ Design methodology has been central to the rapid and successful deployment of our system. version:1
arxiv-1705-05116 | Tuning Modular Networks with Weighted Losses for Hand-Eye Coordination | http://arxiv.org/abs/1705.05116 | id:1705.05116 author:Fangyi Zhang, Jürgen Leitner, Michael Milford, Peter I. Corke category:cs.RO cs.AI cs.CV cs.LG cs.SY  published:2017-05-15 summary:This paper introduces an end-to-end fine-tuning method to improve hand-eye coordination in modular deep visuo-motor policies (modular networks) where each module is trained independently. Benefiting from weighted losses, the fine-tuning method significantly improves the performance of the policies for a robotic planar reaching task. version:1
arxiv-1705-05088 | Simulated Penetration Testing and Mitigation Analysis | http://arxiv.org/abs/1705.05088 | id:1705.05088 author:Michael Backes, Jörg Hoffmann, Robert Künnemann, Patrick Speicher, Marcel Steinmetz category:cs.CR cs.AI  published:2017-05-15 summary:Penetration testing is a well-established practical concept for the identification of potentially exploitable security weaknesses and an important component of a security audit. Providing a holistic security assessment for networks consisting of several hundreds hosts is hardly feasible though without some sort of mechanization. Mitigation, prioritizing counter- measures subject to a given budget, currently lacks a solid theoretical understanding and is hence more art than science. In this work, we propose the first approach for conduct- ing comprehensive what-if analyses in order to reason about mitigation in a conceptually well-founded manner. To evaluate and compare mitigation strategies, we use simulated penetration testing, i.e., automated attack-finding, based on a network model to which a subset of a given set of mitigation actions, e.g., changes to the network topology, system updates, configuration changes etc. is applied. We determine optimal combinations that minimize the maximal attacker success (similar to a Stackelberg game), and thus provide a well-founded basis for a holistic mitigation strategy. We show that these what-if analysis models can largely be derived from network scan, public vulnerability databases and manual inspection with various degrees of automation and detail, and we simulate mitigation analysis on networks of different size and vulnerability. version:1
arxiv-1705-05035 | Discrete Sequential Prediction of Continuous Actions for Deep RL | http://arxiv.org/abs/1705.05035 | id:1705.05035 author:Luke Metz, Julian Ibarz, Navdeep Jaitly, James Davidson category:cs.LG cs.AI stat.ML  published:2017-05-14 summary:It has long been assumed that high dimensional continuous control problems cannot be solved effectively by discretizing individual dimensions of the action space due to the exponentially large number of bins over which policies would have to be learned. In this paper, we draw inspiration from the recent success of sequence-to-sequence models for structured prediction problems to develop policies over discretized spaces. Central to this method is the realization that complex functions over high dimensional spaces can be modeled by neural networks that use next step prediction. Specifically, we show how Q-values and policies over continuous spaces can be modeled using a next step prediction model over discretized dimensions. With this parameterization, it is possible to both leverage the compositional structure of action spaces during learning, as well as compute maxima over action spaces (approximately). On a simple example task we demonstrate empirically that our method can perform global search, which effectively gets around the local optimization issues that plague DDPG and NAF. We apply the technique to off-policy (Q-learning) methods and show that our method can achieve the state-of-the-art for off-policy methods on several continuous control tasks. version:1
arxiv-1705-04995 | Design-Phase Buffer Allocation for Post-Silicon Clock Binning by Iterative Learning | http://arxiv.org/abs/1705.04995 | id:1705.04995 author:Li Zhang, Bing Li, Jinglan Liu, Yiyu Shi, Ulf Schlichtmann category:cs.AR  published:2017-05-14 summary:At submicron manufacturing technology nodes, pro- cess variations affect circuit performance significantly. To counter these variations, engineers are reserving more timing margin to maintain yield, leading to an unaffordable overdesign. Most of these margins, however, are wasted after manufacturing, because process variations cause only some chips to be really slow, while other chips can easily meet given timing specifications. To reduce this pessimism, we can reserve less timing margin and tune failed chips after manufacturing with clock buffers to make them meet timing specifications. With this post-silicon clock tuning, critical paths can be balanced with neighboring paths in each chip specifically to counter the effect of process variations. Consequently, chips with timing failures can be rescued and the yield can thus be improved. This is specially useful in high- performance designs, e.g., high-end CPUs, where clock binning makes chips with higher performance much more profitable. In this paper, we propose a method to determine where to insert post-silicon tuning buffers during the design phase to improve the overall profit with clock binning. This method learns the buffer locations with a Sobol sequence iteratively and reduces the buffer ranges afterwards with tuning concentration and buffer grouping. Experimental results demonstrate that the proposed method can achieve a profit improvement of about 14% on average and up to 26%, with only a small number of tuning buffers inserted into the circuit. version:1
arxiv-1705-04993 | PieceTimer: A Holistic Timing Analysis Framework Considering Setup/Hold Time Interdependency Using A Piecewise Model | http://arxiv.org/abs/1705.04993 | id:1705.04993 author:Grace Li Zhang, Bing Li, Ulf Schlichtmann category:cs.AR  published:2017-05-14 summary:In static timing analysis, clock-to-q delays of flip-flops are considered as constants. Setup times and hold times are characterized separately and also used as constants. The characterized delays, setup times and hold times, are ap- plied in timing analysis independently to verify the perfor- mance of circuits. In reality, however, clock-to-q delays of flip-flops depend on both setup and hold times. Instead of being constants, these delays change with respect to different setup/hold time combinations. Consequently, the simple ab- straction of setup/hold times and constant clock-to-q delays introduces inaccuracy in timing analysis. In this paper, we propose a holistic method to consider the relation between clock-to-q delays and setup/hold time combinations with a piecewise linear model. The result is more accurate than that of traditional timing analysis, and the incorporation of the interdependency between clock-to-q delays, setup times and hold times may also improve circuit performance. version:1
arxiv-1705-04992 | EffiTest: Efficient Delay Test and Statistical Prediction for Configuring Post-silicon Tunable Buffers | http://arxiv.org/abs/1705.04992 | id:1705.04992 author:Grace Li Zhang, Bing Li, Ulf Schlichtmann category:cs.AR  published:2017-05-14 summary:At nanometer manufacturing technology nodes, process variations significantly affect circuit performance. To combat them, post- silicon clock tuning buffers can be deployed to balance timing bud- gets of critical paths for each individual chip after manufacturing. The challenge of this method is that path delays should be mea- sured for each chip to configure the tuning buffers properly. Current methods for this delay measurement rely on path-wise frequency stepping. This strategy, however, requires too much time from ex- pensive testers. In this paper, we propose an efficient delay test framework (EffiTest) to solve the post-silicon testing problem by aligning path delays using the already-existing tuning buffers in the circuit. In addition, we only test representative paths and the delays of other paths are estimated by statistical delay prediction. Exper- imental results demonstrate that the proposed method can reduce the number of frequency stepping iterations by more than 94% with only a slight yield loss. version:1
arxiv-1705-04990 | Sampling-based Buffer Insertion for Post-Silicon Yield Improvement under Process Variability | http://arxiv.org/abs/1705.04990 | id:1705.04990 author:Grace Li Zhang, Bing Li, Ulf Schlichtmann category:cs.AR  published:2017-05-14 summary:At submicron manufacturing technology nodes process variations affect circuit performance significantly. This trend leads to a large timing margin and thus overdesign to maintain yield. To combat this pessimism, post-silicon clock tuning buffers can be inserted into circuits to balance timing budgets of critical paths with their neighbors. After manufacturing, these clock buffers can be configured for each chip individually so that chips with timing failures may be rescued to improve yield. In this paper, we propose a sampling-based method to determine the proper locations of these buffers. The goal of this buffer insertion is to reduce the number of buffers and their ranges, while still maintaining a good yield improvement. Experimental results demonstrate that our algorithm can achieve a significant yield improvement (up to 35%) with only a small number of buffers. version:1
arxiv-1705-04986 | Statistical Timing Analysis and Criticality Computation for Circuits with Post-Silicon Clock Tuning Elements | http://arxiv.org/abs/1705.04986 | id:1705.04986 author:Bing Li, Ulf Schlichtmann category:cs.AR  published:2017-05-14 summary:Post-silicon clock tuning elements are widely used in high-performance designs to mitigate the effects of process variations and aging. Located on clock paths to flip-flops, these tuning elements can be configured through the scan chain so that clock skews to these flip-flops can be adjusted after man- ufacturing. Owing to the delay compensation across consecutive register stages enabled by the clock tuning elements, higher yield and enhanced robustness can be achieved. These benefits are, nonetheless, attained by increasing die area due to the inserted clock tuning elements. For balancing performance improvement and area cost, an efficient timing analysis algorithm is needed to evaluate the performance of such a circuit. So far this evaluation is only possible by Monte Carlo simulation which is very timing- consuming. In this paper, we propose an alternative method using graph transformation, which computes a parametric minimum clock period and is more than 10 4 times faster than Monte Carlo simulation while maintaining a good accuracy. This method also identifies the gates that are critical to circuit performance, so that a fast analysis-optimization flow becomes possible. version:1
arxiv-1705-04984 | ILP-based Alleviation of Dense Meander Segments with Prioritized Shifting and Progressive Fixing in PCB Routing | http://arxiv.org/abs/1705.04984 | id:1705.04984 author:Tsun-Ming Tseng, Bing Li, Tsung-Yi Ho, Ulf Schlichtmann category:cs.AR  published:2017-05-14 summary:Length-matching is an important technique to bal- ance delays of bus signals in high-performance PCB routing. Existing routers, however, may generate very dense meander segments. Signals propagating along these meander segments exhibit a speedup effect due to crosstalk between the segments of the same wire, thus leading to mismatch of arrival times even under the same physical wire length. In this paper, we present a post-processing method to enlarge the width and the distance of meander segments and hence distribute them more evenly on the board so that crosstalk can be reduced. In the proposed framework, we model the sharing of available routing areas after removing dense meander segments from the initial routing, as well as the generation of relaxed meander segments and their groups for wire length compensation. This model is transformed into an ILP problem and solved for a balanced distribution of wire patterns. In addition, we adjust the locations of long wire segments according to wire priorities to swap free spaces toward critical wires that need much length compensation. To reduce the problem space of the ILP model, we also introduce a progressive fixing technique so that wire patterns are grown gradually from the edge of the routing toward the center area. Experimental results show that the proposed method can expand meander segments significantly even under very tight area constraints, so that the speedup effect can be alleviated effectively in high- performance PCB designs. version:1
arxiv-1705-04983 | Post-Route Alleviation of Dense Meander Segments in High-Performance Printed Circuit Boards | http://arxiv.org/abs/1705.04983 | id:1705.04983 author:Tsun-Ming Tseng, Bing Li, Tsung-Yi Ho, Ulf Schlichtmann category:cs.AR  published:2017-05-14 summary:Length-matching is an important technique to balance delays of bus signals in high-performance PCB routing. Existing routers, however, may generate dense meander segments with small distance. Signals propagating across these meander segments exhibit a speedup effect due to crosstalks between the segments of the same wire, thus leading to mismatch of arrival times even with the same physical wire length. In this paper, we propose a post-processing method to enlarge the width and the distance of meander segments and distribute them more evenly on the board so that the crosstalks can be reduced. In the proposed framework, we model the sharing combinations of available routing areas after removing dense meander segments from the initial routing, as well as the generation of relaxed meander segments and their groups in subareas. Thereafter, this model is transformed into an ILP problem and solved efficiently. Experimental results show that the proposed method can extend the width and the distance of meander segments about two times even under very tight area constraints, so that the crosstalks and thus the speedup effect can be alleviated effectively in high-performance PCB designs. version:1
arxiv-1705-04982 | Post-Route Refinement for High-Frequency PCBs Considering Meander Segment Alleviation | http://arxiv.org/abs/1705.04982 | id:1705.04982 author:Tsun-Ming, Tseng Bing Li, Tsung-Yi Ho, Ulf Schlichtmann category:cs.AR  published:2017-05-14 summary:In this paper, we propose a post-processing framework which iteratively refines the routing results from an existing PCB router by removing dense meander segments. By swapping and detouring dense meander segments the proposed method can effectively alleviate accumulating crosstalk noise, while respecting pre-defined area constraints. Experimental results show more than 85% reduction of the meander segments and hence the noise cost. version:1
arxiv-1705-04981 | On Timing Model Extraction and Hierarchical Statistical Timing Analysis | http://arxiv.org/abs/1705.04981 | id:1705.04981 author:Bing Li, Ning Chen, Yang Xu, Ulf Schlichtmann category:cs.AR  published:2017-05-14 summary:In this paper, we investigate the challenges to apply Statistical Static Timing Analysis (SSTA) in hierarchical design flow, where modules supplied by IP vendors are used to hide design details for IP protection and to reduce the complexity of design and verification. For the three basic circuit types, combinational, flip-flop-based and latch-controlled, we propose methods to extract timing models which contain interfacing as well as compressed internal constraints. Using these compact timing models the runtime of full-chip timing analysis can be reduced, while circuit details from IP vendors are not exposed. We also propose a method to reconstruct the correlation between modules during full-chip timing analysis. This correlation can not be incorporated into timing models because it depends on the layout of the corresponding modules in the chip. In addition, we investigate how to apply the extracted timing models with the reconstructed correlation to evaluate the performance of the complete design. Experiments demonstrate that using the extracted timing models and reconstructed correlation full-chip timing analysis can be several times faster than applying the flattened circuit directly, while the accuracy of statistical timing analysis is still well maintained. version:1
arxiv-1705-04979 | Fast Statistical Timing Analysis for Circuits with Post-Silicon Tunable Clock Buffers | http://arxiv.org/abs/1705.04979 | id:1705.04979 author:Bing Li, Ning Chen, Ulf Schlichtmann category:cs.AR  published:2017-05-14 summary:Post-Silicon Tunable (PST) clock buffers are widely used in high performance designs to counter process variations. By allowing delay compensation between consecutive register stages, PST buffers can effectively improve the yield of digital circuits. To date, the evaluation of manufacturing yield in the presence of PST buffers is only possible using Monte Carlo simulation. In this paper, we propose an alternative method based on graph transformations, which is much faster, more than 1000 times, and computes a parametric minimum clock period. It also identifies the gates which are most critical to the circuit performance, therefore enabling a fast analysis-optimization flow. version:1
arxiv-1705-04976 | Timing Model Extraction for Sequential Circuits Considering Process Variations | http://arxiv.org/abs/1705.04976 | id:1705.04976 author:Bing Li, Ning Chen, Ulf Schlichtmann category:cs.AR  published:2017-05-14 summary:As semiconductor devices continue to scale down, process vari- ations become more relevant for circuit design. Facing such variations, statistical static timing analysis is introduced to model variations more accurately so that the pessimism in tra- ditional worst case timing analysis is reduced. Because all de- lays are modeled using correlated random variables, most statis- tical timing methods are much slower than corner based timing analysis. To speed up statistical timing analysis, we propose a method to extract timing models for flip-flop and latch based sequential circuits respectively. When such a circuit is used as a module in a hierarchical design, the timing model instead of the original circuit is used for timing analysis. The extracted timing models are much smaller than the original circuits. Ex- periments show that using extracted timing models accelerates timing verification by orders of magnitude compared to previ- ous approaches using flat netlists directly. Accuracy is main- tained, however, with the mean and standard deviation of the clock period both showing usually less than 1% error compared to Monte Carlo simulation on a number of benchmark circuits. version:1
arxiv-1705-04975 | On Hierarchical Statistical Static Timing Analysis | http://arxiv.org/abs/1705.04975 | id:1705.04975 author:Bing Li, Ning Chen, Manuel Schmidt, Walter Schneider, Ulf Schlichtmann category:cs.AR  published:2017-05-14 summary:Statistical static timing analysis deals with the increasing variations in manufacturing processes to reduce the pessimism in the worst case timing analysis. Because of the correlation between delays of circuit components, timing model generation and hierarchical timing analysis face more challenges than in static timing analysis. In this paper, a novel method to generate timing models for combinational circuits considering variations is proposed. The resulting timing models have accurate input-output delays and are about 80% smaller than the original circuits. Additionally, an accurate hierarchical timing analysis method at design level using pre-characterized timing models is proposed. This method incorporates the correlation between modules by replacing independent random variables to improve timing accuracy. Experimental results show that the correlation between modules strongly affects the delay distribution of the hierarchical design and the proposed method has good accuracy compared with Monte Carlo simulation, but is faster by three orders of magnitude. version:1
arxiv-1705-04970 | Relaxation heuristics for the set multicover problem with generalized upper bound constraints | http://arxiv.org/abs/1705.04970 | id:1705.04970 author:Shunji Umetani, Masanao Arakawa, Mutsunori Yagiura category:cs.DS cs.AI math.OC  published:2017-05-14 summary:We consider an extension of the set covering problem (SCP) introducing (i) multicover and (ii) generalized upper bound (GUB) constraints. For the conventional SCP, the pricing method has been introduced to reduce the size of instances, and several efficient heuristic algorithms based on such reduction techniques have been developed to solve large-scale instances. However, GUB constraints often make the pricing method less effective, because they often prevent solutions from containing highly evaluated variables together. To overcome this, we develop heuristic algorithms to reduce the size of instances, in which new evaluation schemes of variables are introduced taking account of GUB constraints. We also develop an efficient implementation of a 2-flip neighborhood local search algorithm that reduces the number of candidates in the neighborhood without sacrificing the solution quality. According to computational comparison on benchmark instances with the recent solvers, the proposed algorithm performs quite effectively for instances having large gaps between lower and upper bounds. version:1
arxiv-1705-04898 | Faster and Simpler Distributed Algorithms for Testing and Correcting Graph Properties in the CONGEST-Model | http://arxiv.org/abs/1705.04898 | id:1705.04898 author:Guy Even, Reut Levi, Moti Medina category:cs.DC cs.DS  published:2017-05-13 summary:In this paper we present distributed testing algorithms of graph properties in the CONGEST-model [Censor-Hillel et al. 2016]. We present one-sided error testing algorithms in the general graph model. We first describe a general procedure for converting $\epsilon$-testers with a number of rounds $f(D)$, where $D$ denotes the diameter of the graph, to $O((\log n)/\epsilon)+f((\log n)/\epsilon)$ rounds, where $n$ is the number of processors of the network. We then apply this procedure to obtain an optimal tester, in terms of $n$, for testing bipartiteness, whose round complexity is $O(\epsilon^{-1}\log n)$, which improves over the $poly(\epsilon^{-1} \log n)$-round algorithm by Censor-Hillel et al. (DISC 2016). Moreover, for cycle-freeness, we obtain a \emph{corrector} of the graph that locally corrects the graph so that the corrected graph is acyclic. Note that, unlike a tester, a corrector needs to mend the graph in many places in the case that the graph is far from having the property. In the second part of the paper we design algorithms for testing whether the network is $H$-free for any connected $H$ of size up to four with round complexity of $O(\epsilon^{-1})$. This improves over the $O(\epsilon^{-2})$-round algorithms for testing triangle freeness by Censor-Hillel et al. (DISC 2016) and for testing excluded graphs of size $4$ by Fraigniaud et al. (DISC 2016). In the last part we generalize the global tester by Iwama and Yoshida (ITCS 2014) of testing $k$-path freeness to testing the exclusion of any tree of order $k$. We then show how to simulate this algorithm in the CONGEST-model in $O(k^{k^2+1}\cdot\epsilon^{-k})$ rounds. version:1
arxiv-1705-04888 | Automated Robotic Monitoring and Inspection of Steel Structures and Bridges | http://arxiv.org/abs/1705.04888 | id:1705.04888 author:Hung M. La category:cs.RO  published:2017-05-13 summary:This paper presents visual and 3D structure inspection for steel structures and bridges using a developed climbing robot. The robot can move freely on a steel surface, carry sensors, collect data and then send to the ground station in real time for monitoring as well as further processing. Steel surface image stitching and 3D map building are conducted to provide a current condition of the structure. Also, a computer vision-based method is implemented to detect surface defects on stitched images. The effectiveness of the climbing robot's inspection is tested in multiple circumstances to ensure strong steel adhesion and successful data collection. The detection method was also successfully evaluated on various test images, where steel cracks could be automatically identified, without the requirement of some heuristic reasoning. version:1
arxiv-1705-04885 | Awareness improves problem-solving performance | http://arxiv.org/abs/1705.04885 | id:1705.04885 author:José F. Fontanari category:cs.AI  published:2017-05-13 summary:The brain's self-monitoring of activities, including internal activities -- a functionality that we refer to as awareness -- has been suggested as a key element of consciousness. Here we investigate whether the presence of an inner-eye-like process (monitor) that supervises the activities of a number of subsystems (operative agents) engaged in the solution of a problem can improve the problem-solving efficiency of the system. The problem is to find the global maximum of a NK fitness landscape and the performance is measured by the time required to find that maximum. The operative agents explore blindly the fitness landscape and the monitor provides them with feedback on the quality (fitness) of the proposed solutions. This feedback is then used by the operative agents to bias their searches towards the fittest regions of the landscape. We find that a weak feedback between the monitor and the operative agents improves the performance of the system, regardless of the difficulty of the problem, which is gauged by the number of local maxima in the landscape. For easy problems (i.e., landscapes without local maxima), the performance improves monotonically as the feedback strength increases, but for difficult problems, there is an optimal value of the feedback strength beyond which the system performance degrades very rapidly. version:1
arxiv-1705-04874 | Fast GPU-Based Seismogram Simulation from Microseismic Events in Marine Environments Using Heterogeneous Velocity Models | http://arxiv.org/abs/1705.04874 | id:1705.04874 author:Saptarshi Das, Xi Chen, Michael P. Hobson category:physics.geo-ph cs.DC physics.comp-ph  published:2017-05-13 summary:A novel approach is presented for fast generation of synthetic seismograms due to microseismic events, using heterogeneous marine velocity models. The partial differential equations (PDEs) for the 3D elastic wave equation have been numerically solved using the Fourier domain pseudo-spectral method which is parallelizable on the graphics processing unit (GPU) cards, thus making it faster compared to traditional CPU based computing platforms. Due to computationally expensive forward simulation of large geological models, several combinations of individual synthetic seismic traces are used for specified microseismic event locations, in order to simulate the effect of realistic microseismic activity patterns in the subsurface. We here explore the patterns generated by few hundreds of microseismic events with different source mechanisms using various combinations, both in event amplitudes and origin times, using the simulated pressure and three component particle velocity fields via 1D, 2D and 3D seismic visualizations. version:1
arxiv-1705-05727 | A General Scheme Implicit Force Control for a Flexible-Link Manipulator | http://arxiv.org/abs/1705.05727 | id:1705.05727 author:Cecilia Murrugarra, Osberth De Castro, Juan Carlos Grieco, Gerardo Fernandez category:cs.RO cs.SY nlin.CD  published:2017-05-13 summary:In this paper we propose an implicit force control scheme for a one-link flexible manipulator that interact with a compliant environment. The controller was based in the mathematical model of the manipulator, considering the dynamics of the beam flexible and the gravitational force. With this method, the controller parameters are obtained from the structural parameters of the beam (link) of the manipulator. This controller ensure the stability based in the Lyapunov Theory. The controller proposed has two closed loops: the inner loop is a tracking control with gravitational force and vibration frequencies compensation and the outer loop is a implicit force control. To evaluate the performance of the controller, we have considered to three different manipulators (the length, the diameter were modified) and three environments with compliance modified. The results obtained from simulations verify the asymptotic tracking and regulated in position and force respectively and the vibrations suppression of the beam in a finite time. version:1
arxiv-1704-08483 | No, This is not a Circle | http://arxiv.org/abs/1704.08483 | id:1704.08483 author:Zoltán Kovács category:math.HO cs.AI  published:2017-04-27 summary:A popular curve shown in introductory maths textbooks, seems like a circle. But it is actually a different curve. This paper discusses some elementary approaches to identify the geometric object, including novel technological means by using GeoGebra. We demonstrate two ways to refute the false impression, two suggestions to find a correct conjecture, and four ways to confirm the result by proving it rigorously. All of the discussed approaches can be introduced in classrooms at various levels from middle school to high school. version:3
arxiv-1705-04835 | Which Broadcast Abstraction Captures $k$-Set Agreement? | http://arxiv.org/abs/1705.04835 | id:1705.04835 author:Damien Imbs, Achour Mostéfaoui, Matthieu Perrin, Michel Raynal category:cs.DC  published:2017-05-13 summary:It is well-known that consensus (one-set agreement) and total order broadcast are equivalent in asynchronous systems prone to process crash failures. Considering wait-free systems, this article addresses and answers the following question: which is the communication abstraction that "captures" $k$-set agreement? To this end, it introduces a new broadcast communication abstraction, called $k$-BO-Broadcast, which restricts the disagreement on the local deliveries of the messages that have been broadcast ($1$-BO-Broadcast boils down to total order broadcast). Hence, in this context, $k=1$ is not a special number, but only the first integer in an increasing integer sequence. This establishes a new "correspondence" between distributed agreement problems and communication abstractions, which enriches our understanding of the relations linking fundamental issues of fault-tolerant distributed computing. version:1
arxiv-1705-03392 | Asynchronous Announcements | http://arxiv.org/abs/1705.03392 | id:1705.03392 author:Hans van Ditmarsch category:cs.AI cs.DC cs.LO  published:2017-05-08 summary:We propose a logic of asynchronous announcements, where truthful announcements are publicly sent but individually received by agents. Additional to epistemic modalities, the logic therefore contains two types of dynamic modalities, for sending messages and for receiving messages. The semantics defines truth relative to the current state of reception of messages for all agents. This means that knowledge need not be truthful, because some messages may not have been received by the knowing agent. Messages that are announcements may also result in partial synchronization, namely when an agent learns from receiving an announcement that other announcements must already have been received by other agents. We give detailed examples of the semantics, and prove several semantic results, including that: after an announcement an agent knows that a proposition is true, if and only if on condition of the truth of that announcement, the agent knows that after that announcement and after any number of other agents also receiving it, the proposition is true. We show that on multi-agent epistemic models, each formula in asynchronous announcement logic is equivalent to a formula in epistemic logic. version:2
arxiv-1705-02884 | Proving Correctness of Concurrent Objects by Validating Linearization Points | http://arxiv.org/abs/1705.02884 | id:1705.02884 author:Sathya Peri, Muktikanta Sa, Nandini Singhal category:cs.DC  published:2017-05-08 summary:In the recent years, several concurrent data-structures/objects have been proposed. These data-structures allow multiple threads/process to operate on them concurrently while maintaining consistency. By allowing multiple threads to operate on them simultaneously, these structures strive to increase parallelism. These structures typically involve the operating threads applying different fine-grained synchronization mechanisms. While these concurrent structures with fine-grained synchronization mechanisms certainly improve parallelism, proving their correctness has turned out to be a challenging task. The well accepted criterion for proving correctness of these concurrent objects is Linearizability. Showing that these concurrent structures are linearizable is non-trivial in many cases. The standard technique to show correctness adopted by several researchers and practitioners in this case is to use Linearization Points (LPs) - an atomic event within each method between the invocation and response events where the effect of the entire method seems to have taken place. In many of these cases, the LPs intuitively prove the correctness of the object. Without a formal proof, it is not clear if these LPs and hence the concurrent structure are indeed correct. In this paper, we present a hand-written technique for verifying the correctness of Linearization Points of a class of commonly used concurrent data-structures. Although the technique is hand-written, we believe that it is applicable to wide variety of concurrent data-structures. We demonstrate the efficacy of this technique by showing the correctness of two commonly used variants of set data-structure based on linked-lists: Hand-over-Hand locking and Lazy List. Further, we hope to extend this technique for automatic verification in future. version:2
arxiv-1705-04789 | Scalable and Efficient Construction of Suffix Array with MapReduce and In-Memory Data Store System | http://arxiv.org/abs/1705.04789 | id:1705.04789 author:Hsiang-Huang Wu, Chien-Min Wang, Hsuan-Chi Kuo, Wei-Chun Chung, Jan-Ming Ho category:cs.DC  published:2017-05-13 summary:Suffix Array (SA) is a cardinal data structure in many pattern matching applications, including data compression, plagiarism detection and sequence alignment. However, as the volumes of data increase abruptly, the construction of SA is not amenable to the current large-scale data processing frameworks anymore due to its intrinsic proliferation of suffixes during the construction. That is, ameliorating the performance by just adding the resources to the frameworks becomes less cost- effective, even having the severe diminishing returns. At issue now is whether we can permit SA construction to be more scalable and efficient for the everlasting accretion of data by creating a radical shift in perspective. Regarding TeraSort [1] as our baseline, we first demonstrate the fragile scalability of TeraSort and investigate what causes it through the experiments on the sequence alignment of a grouper (i.e., the SA construc- tion used in bioinformatics). As such, we propose a scheme that amalgamates the distributed key-value store system into MapReduce to leverage the in-memory queries about suffixes. Rather than handling the communication of suffixes, MapReduce is in charge of the communication of their indexes, which means better capacity for more data. It significantly abates the required disk space for constructing SA and better utilizes the memory, which in turn improves the scalability radically. We also examine the efficiency of our scheme in terms of memory and show it outperforms TeraSort. At last, our scheme can complete the pair- end sequencing and alignment with two input files without any degradation on scalability, and can accommodate the suffixes of nearly 6.7 TB in a small cluster composed of 16 nodes and Gigabit Ethernet without any compression. version:1
arxiv-1705-04769 | Advancing Consumer Adoption of Blockchain Applications | http://arxiv.org/abs/1705.04769 | id:1705.04769 author:Zane Witherspoon category:cs.CY cs.DC cs.GT  published:2017-05-12 summary:Blockchain technology as a whole is experiencing a dramatic rise in adoption, in no small part due to the developer-friendly Ethereum network. While the number of smart-contract powered distributed applications (Dapps) continues to rise, they face many of the same challenges all new technologies face as they are introduced to a market. By modeling the consumer adoption of blockchain technology and analyzing scholarly literature on supply-side factors affecting the diffusion of technology, we seek to prove the growth of a Dapp can be accelerated using abstraction, whole product planning, and complementaries. version:1
arxiv-1705-04763 | High-Precision Trajectory Tracking in Changing Environments Through $\mathcal{L}_1$ Adaptive Feedback and Iterative Learning | http://arxiv.org/abs/1705.04763 | id:1705.04763 author:Karime Pereida, Rikky R. P. R. Duivenvoorden, Angela P. Schoellig category:cs.RO cs.SY  published:2017-05-12 summary:As robots and other automated systems are introduced to unknown and dynamic environments, robust and adaptive control strategies are required to cope with disturbances, unmodeled dynamics and parametric uncertainties. In this paper, we propose and provide theoretical proofs of a combined $\mathcal{L}_1$ adaptive feedback and iterative learning control (ILC) framework to improve trajectory tracking of a system subject to unknown and changing disturbances. The $\mathcal{L}_1$ adaptive controller forces the system to behave in a repeatable, predefined way, even in the presence of unknown and changing disturbances; however, this does not imply that perfect trajectory tracking is achieved. ILC improves the tracking performance based on experience from previous executions. The performance of ILC is limited by the robustness and repeatability of the underlying system, which, in this approach, is handled by the $\mathcal{L}_1$ adaptive controller. In particular, we are able to generalize learned trajectories across different system configurations because the $\mathcal{L}_1$ adaptive controller handles the underlying changes in the system. We demonstrate the improved trajectory tracking performance and generalization capabilities of the combined method compared to pure ILC in experiments with a quadrotor subject to unknown, dynamic disturbances. This is the first work to show $\mathcal{L}_1$ adaptive control combined with ILC in experiment. version:1
arxiv-1609-01257 | cf4ocl: a C framework for OpenCL | http://arxiv.org/abs/1609.01257 | id:1609.01257 author:Nuno Fachada, Vitor V. Lopes, Rui C. Martins, Agostinho C. Rosa category:cs.DC D.1.3; D.2.2  published:2016-09-05 summary:OpenCL is an open standard for parallel programming of heterogeneous compute devices, such as GPUs, CPUs, DSPs or FPGAs. However, the verbosity of its C host API can hinder application development. In this paper we present cf4ocl, a software library for rapid development of OpenCL programs in pure C. It aims to reduce the verbosity of the OpenCL API, offering straightforward memory management, integrated profiling of events (e.g., kernel execution and data transfers), simple but extensible device selection mechanism and user-friendly error management. We compare two versions of a conceptual application example, one based on cf4ocl, the other developed directly with the OpenCL host API. Results show that the former is simpler to implement and offers more features, at the cost of an effectively negligible computational overhead. Additionally, the tools provided with cf4ocl allowed for a quick analysis on how to optimize the application. version:3
arxiv-1705-04721 | The Generalized Label Correcting Method for Optimal Kinodynamic Motion Planning | http://arxiv.org/abs/1705.04721 | id:1705.04721 author:Brian Paden category:cs.RO  published:2017-05-12 summary:Nearly all autonomous robotic systems use some form of motion planning to compute reference motions through their environment. An increasing use of autonomous robots in a broad range of applications creates a need for efficient, general purpose motion planning algorithms that are applicable in any of these new application domains. This thesis presents a resolution complete optimal kinodynamic motion planning algorithm based on a direct forward search of the set of admissible input signals to a dynamical model. The advantage of this generalized label correcting method is that it does not require a local planning subroutine as in the case of related methods. Preliminary material focuses on new topological properties of the canonical problem formulation that are used to show continuity of the performance objective. These observations are used to derive a generalization of Bellman's principle of optimality in the context of kinodynamic motion planning. A generalized label correcting algorithm is then proposed which leverages these results to prune candidate input signals from the search when their cost is greater than related signals. The second part of this thesis addresses admissible heuristics for kinodynamic motion planning. An admissibility condition is derived that can be used to verify the admissibility of candidate heuristics for a particular problem. This condition also characterizes a convex set of admissible heuristics. A linear program is formulated to obtain a heuristic which is as close to the optimal cost-to-go as possible while remaining admissible. This optimization is justified by showing its solution coincides with the solution to the Hamilton-Jacobi-Bellman equation. Lastly, a sum-of-squares relaxation of this infinite-dimensional linear program is proposed for obtaining provably admissible approximate solutions. version:1
arxiv-1705-04719 | On the Complexity of Semantic Integration of OWL Ontologies | http://arxiv.org/abs/1705.04719 | id:1705.04719 author:Yevgeny Kazakov, Denis Ponomaryov category:cs.AI  published:2017-05-12 summary:We propose a new mechanism for integration of OWL ontologies using semantic import relations. In contrast to the standard OWL importing, we do not require all axioms of the imported ontologies to be taken into account for reasoning tasks, but only their logical implications over a chosen signature. This property comes natural in many ontology integration scenarios, especially when the number of ontologies is large. In this paper, we study the complexity of reasoning over ontologies with semantic import relations and establish a range of tight complexity bounds for various fragments of OWL. version:1
arxiv-1705-04712 | Progression of Decomposed Local-Effect Action Theories | http://arxiv.org/abs/1705.04712 | id:1705.04712 author:Denis Ponomaryov, Mikhail Soutchanski category:cs.AI  published:2017-05-12 summary:In many tasks related to reasoning about consequences of a logical theory, it is desirable to decompose the theory into a number of weakly-related or independent components. However, a theory may represent knowledge that is subject to change, as a result of executing actions that have effects on some of the initial properties mentioned in the theory. Having once computed a decomposition of a theory, it is advantageous to know whether a decomposition has to be computed again in the newly-changed theory (obtained from taking into account changes resulting from execution of an action). In the paper, we address this problem in the scope of the situation calculus, where a change of an initial theory is related to the notion of progression. Progression provides a form of forward reasoning; it relies on forgetting values of those properties, which are subject to change, and computing new values for them. We consider decomposability and inseparability, two component properties known from the literature, and contribute by 1) studying the conditions when these properties are preserved and 2) when they are lost wrt progression and the related operation of forgetting. To show the latter, we demonstrate the boundaries using a number of negative examples. To show the former, we identify cases when these properties are preserved under forgetting and progression of initial theories in local-effect basic action theories of the situation calculus. Our paper contributes to bridging two different communities in Knowledge Representation, namely research on modularity and research on reasoning about actions. version:1
arxiv-1705-04665 | A Formal Characterization of the Local Search Topology of the Gap Heuristic | http://arxiv.org/abs/1705.04665 | id:1705.04665 author:Richard Anthony Valenzano, Danniel Sihui Yang category:cs.AI  published:2017-05-12 summary:The pancake puzzle is a classic optimization problem that has become a standard benchmark for heuristic search algorithms. In this paper, we provide full proofs regarding the local search topology of the gap heuristic for the pancake puzzle. First, we show that in any non-goal state in which there is no move that will decrease the number of gaps, there is a move that will keep the number of gaps constant. We then classify any state in which the number of gaps cannot be decreased in a single action into two groups: those requiring 2 actions to decrease the number of gaps, and those which require 3 actions to decrease the number of gaps. version:1
arxiv-1705-04662 | Monaural Audio Speaker Separation with Source Contrastive Estimation | http://arxiv.org/abs/1705.04662 | id:1705.04662 author:Cory Stephenson, Patrick Callier, Abhinav Ganesh, Karl Ni category:cs.SD cs.AI cs.LG stat.ML  published:2017-05-12 summary:We propose an algorithm to separate simultaneously speaking persons from each other, the "cocktail party problem", using a single microphone. Our approach involves a deep recurrent neural networks regression to a vector space that is descriptive of independent speakers. Such a vector space can embed empirically determined speaker characteristics and is optimized by distinguishing between speaker masks. We call this technique source-contrastive estimation. The methodology is inspired by negative sampling, which has seen success in natural language processing, where an embedding is learned by correlating and de-correlating a given input vector with output weights. Although the matrix determined by the output weights is dependent on a set of known speakers, we only use the input vectors during inference. Doing so will ensure that source separation is explicitly speaker-independent. Our approach is similar to recent deep neural network clustering and permutation-invariant training research; we use weighted spectral features and masks to augment individual speaker frequencies while filtering out other speakers. We avoid, however, the severe computational burden of other approaches with our technique. Furthermore, by training a vector space rather than combinations of different speakers or differences thereof, we avoid the so-called permutation problem during training. Our algorithm offers an intuitive, computationally efficient response to the cocktail party problem, and most importantly boasts better empirical performance than other current techniques. version:1
arxiv-1705-05249 | CLBlast: A Tuned OpenCL BLAS Library | http://arxiv.org/abs/1705.05249 | id:1705.05249 author:Cedric Nugteren category:cs.MS cs.AI cs.DC  published:2017-05-12 summary:This work demonstrates how to accelerate dense linear algebra computations using CLBlast, an open-source OpenCL BLAS library providing optimized routines for a wide variety of devices. It is targeted at machine learning and HPC applications and thus provides a fast matrix-multiplication routine (GEMM) to accelerate the core of many applications (e.g. deep learning, iterative solvers, astrophysics, computational fluid dynamics, quantum chemistry). CLBlast has four main advantages over other BLAS libraries: 1) it is optimized for and tested on a large variety of OpenCL devices including less commonly used devices such as embedded and low-power GPUs, 2) it can be explicitly tuned for specific problem-sizes on specific hardware platforms, 3) it can perform operations in half-precision floating-point FP16 saving precious bandwidth, time and energy, 4) and it can combine multiple operations in a single batched routine, accelerating smaller problems significantly. This paper describes the library and demonstrates the advantages of CLBlast experimentally for different use-cases on a wide variety of OpenCL hardware. version:1
arxiv-1705-04658 | Inverse, forward and other dynamic computations computationally optimized with sparse matrix factorizations | http://arxiv.org/abs/1705.04658 | id:1705.04658 author:Francesco Nori category:cs.RO  published:2017-05-12 summary:We propose an algorithm to compute the dynamics of articulated rigid-bodies with different sensor distributions. Prior to the on-line computations, the proposed algorithm performs an off-line optimisation step to simplify the computational complexity of the underlying solution. This optimisation step consists in formulating the dynamic computations as a system of linear equations. The computational complexity of computing the associated solution is reduced by performing a permuted LU-factorisation with off-line optimised permutations. We apply our algorithm to solve classical dynamic problems: inverse and forward dynamics. The computational complexity of the proposed solution is compared to `gold standard' algorithms: recursive Newton-Euler and articulated body algorithm. It is shown that our algorithm reduces the number of floating point operations with respect to previous approaches. We also evaluate the numerical complexity of our algorithm by performing tests on dynamic computations for which no gold standard is available. version:1
arxiv-1705-04185 | A First Empirical Study of Emphatic Temporal Difference Learning | http://arxiv.org/abs/1705.04185 | id:1705.04185 author:Sina Ghiassian, Banafsheh Rafiee, Richard S. Sutton category:cs.AI cs.LG  published:2017-05-11 summary:In this paper we present the first empirical study of the emphatic temporal-difference learning algorithm (ETD), comparing it with conventional temporal-difference learning, in particular, with linear TD(0), on on-policy and off-policy variations of the Mountain Car problem. The initial motivation for developing ETD was that it has good convergence properties under off-policy training (Sutton, Mahmood and White 2016), but it is also a new algorithm for the on-policy case. In both our on-policy and off-policy experiments, we found that each method converged to a characteristic asymptotic level of error, with ETD better than TD(0). TD(0) achieved a still lower error level temporarily before falling back to its higher asymptote, whereas ETD never showed this kind of "bounce". In the off-policy case (in which TD(0) is not guaranteed to converge), ETD was significantly slower. version:2
arxiv-1705-05247 | Compressed Sensing for Scalable Robotic Tactile Skins | http://arxiv.org/abs/1705.05247 | id:1705.05247 author:Brayden Hollis, Stacy Patterson, Jeff Trinkle category:cs.RO  published:2017-05-12 summary:The potential of large tactile arrays to improve robot perception for safe operation in human-dominated environments and of high-resolution tactile arrays to enable human-level dexterous manipulation is well accepted. However, the increase in the number of tactile sensing elements introduces challenges including wiring complexity, data acquisition, and data processing. To help address these challenges, we develop a tactile sensing technique based on compressed sensing. Compressed sensing simultaneously performs data sampling and compression with recovery guarantees and has been successfully applied in computer vision. We use compressed sensing techniques for tactile data acquisition to reduce hardware complexity and data transmission, while allowing fast, accurate reconstruction of the full-resolution signal. For our simulated test array of 4096 taxels, we achieve reconstruction quality equivalent to measuring all taxel signals independently (the full signal) from just 1024 measurements (the compressed signal) at a rate over 100Hz. We then apply tactile compressed sensing to the problem of object classification. Specifically, we perform object classification on the compressed tactile data based on a method called compressed learning. We obtain up to 98% classification accuracy, even with a compression ratio of 64:1. version:1
arxiv-1604-08448 | Exploiting variable associations to configure efficient local search algorithms in large-scale binary integer programs | http://arxiv.org/abs/1604.08448 | id:1604.08448 author:Shunji Umetani category:cs.DS cs.AI math.OC  published:2016-04-28 summary:We present a data mining approach for reducing the search space of local search algorithms in a class of binary integer programs including the set covering and partitioning problems. The quality of locally optimal solutions typically improves if a larger neighborhood is used, while the computation time of searching the neighborhood increases exponentially. To overcome this, we extract variable associations from the instance to be solved in order to identify promising pairs of flipping variables in the neighborhood search. Based on this, we develop a 4-flip neighborhood local search algorithm that incorporates an efficient incremental evaluation of solutions and an adaptive control of penalty weights. Computational results show that the proposed method improves the performance of the local search algorithm for large-scale set covering and partitioning problems. version:2
arxiv-1705-04627 | Sprinkler: Maximizing Resource Utilization in Many-Chip Solid State Disks | http://arxiv.org/abs/1705.04627 | id:1705.04627 author:Myoungsoo Jung, Mahmut T. Kandemir category:cs.AR  published:2017-05-12 summary:Resource utilization is one of the emerging problems in many-chip SSDs. In this paper, we propose Sprinkler, a novel device-level SSD controller, which targets maximizing resource utilization and achieving high performance without additional NAND flash chips. Specifically, Sprinkler relaxes parallelism dependency by scheduling I/O requests based on internal resource layout rather than the order imposed by the device-level queue. In addition, Sprinkler improves flash-level parallelism and reduces the number of transactions (i.e., improves transactional-locality) by over-committing flash memory requests to specific resources. Our extensive experimental evaluation using a cycle-accurate large-scale SSD simulation framework shows that a many-chip SSD equipped with our Sprinkler provides at least 56.6% shorter latency and 1.8 ~ 2.2 times better throughput than the state-of-the-art SSD controllers. Further, it improves overall resource utilization by 68.8% under different I/O request patterns and provides, on average, 80.2% more flash-level parallelism by reducing half of the flash memory requests at runtime. version:1
arxiv-1705-04569 | Clingcon: The Next Generation | http://arxiv.org/abs/1705.04569 | id:1705.04569 author:Mutsunori Banbara, Benjamin Kaufmann, Max Ostrowski, Torsten Schaub category:cs.AI  published:2017-05-12 summary:We present the third generation of the constraint answer set system clingcon, combining Answer Set Programming (ASP) with finite domain constraint processing (CP). While its predecessors rely on a black-box approach to hybrid solving by integrating the CP solver gecode, the new clingcon system pursues a lazy approach using dedicated constraint propagators to extend propagation in the underlying ASP solver clasp. No extension is needed for parsing and grounding clingcon's hybrid modeling language since both can be accommodated by the new generic theory handling capabilities of the ASP grounder gringo. As a whole, clingcon 3 is thus an extension of the ASP system clingo 5, which itself relies on the grounder gringo and the solver clasp. The new approach of clingcon offers a seamless integration of CP propagation into ASP solving that benefits from the whole spectrum of clasp's reasoning modes, including for instance multi-shot solving and advanced optimization techniques. This is accomplished by a lazy approach that unfolds the representation of constraints and adds it to that of the logic program only when needed. Although the unfolding is usually dictated by the constraint propagators during solving, it can already be partially (or even totally) done during preprocessing. Moreover, clingcon's constraint preprocessing and propagation incorporate several well established CP techniques that greatly improve its performance. We demonstrate this via an extensive empirical evaluation contrasting, first, the various techniques in the context of CSP solving and, second, the new clingcon system with other hybrid ASP systems. Under consideration in Theory and Practice of Logic Programming (TPLP) version:1
arxiv-1705-04513 | GRID Storage Optimization in Transparent and User-Friendly Way for LHCb Datasets | http://arxiv.org/abs/1705.04513 | id:1705.04513 author:Mikhail Hushchyn, Andrey Ustyuzhanin, Philippe Charpentier, Christophe Haen category:cs.DC  published:2017-05-12 summary:The LHCb collaboration is one of the four major experiments at the Large Hadron Collider at CERN. Many petabytes of data are produced by the detectors and Monte-Carlo simulations. The LHCb Grid interware LHCbDIRAC is used to make data available to all collaboration members around the world. The data is replicated to the Grid sites in different locations. However the Grid disk storage is limited and does not allow keeping replicas of each file at all sites. Thus it is essential to optimize number of replicas to achieve a better Grid performance. In this study, we present a new approach of data replication and distribution strategy based on data popularity prediction. The popularity is performed based on the data access history and metadata, and uses machine learning techniques and time series analysis methods. version:1
arxiv-1603-02580 | On the limitations of analysing worst-case dynamic energy of processing | http://arxiv.org/abs/1603.02580 | id:1603.02580 author:Jeremy Morse, Steve Kerrison, Kerstin Eder category:cs.CC cs.AR cs.DC  published:2016-03-07 summary:This paper examines dynamic energy consumption caused by data during software execution on deeply embedded microprocessors, which can be significant on some devices. In worst-case energy consumption analysis, energy models are used to find the most costly execution path. Taking each instruction's worst case energy produces a safe but overly pessimistic upper bound. Algorithms for safe and tight bounds would be desirable. We show that finding exact worst-case energy is NP-hard, and that tight bounds cannot be approximated with guaranteed safety. We conclude that any energy model targeting tightness must either sacrifice safety or accept overapproximation proportional to data-dependent energy. version:3
arxiv-1705-04480 | Distributed Protocols at the Rescue for Trustworthy Online Voting | http://arxiv.org/abs/1705.04480 | id:1705.04480 author:Robert Riemann, Stéphane Grumbach category:cs.CR cs.DC  published:2017-05-12 summary:While online services emerge in all areas of life, the voting procedure in many democracies remains paper-based as the security of current online voting technology is highly disputed. We address the issue of trustworthy online voting protocols and recall therefore their security concepts with its trust assumptions. Inspired by the Bitcoin protocol, the prospects of distributed online voting protocols are analysed. No trusted authority is assumed to ensure ballot secrecy. Further, the integrity of the voting is enforced by all voters themselves and without a weakest link, the protocol becomes more robust. We introduce a taxonomy of notions of distribution in online voting protocols that we apply on selected online voting protocols. Accordingly, blockchain-based protocols seem to be promising for online voting due to their similarity with paper-based protocols. version:1
arxiv-1609-05616 | Preorder-Based Triangle: A Modified Version of Bilattice-Based Triangle for Belief Revision in Nonmonotonic Reasoning | http://arxiv.org/abs/1609.05616 | id:1609.05616 author:Kumar Sankar Ray, Sandip Paul, Diganta Saha category:cs.AI  published:2016-09-19 summary:Bilattice-based triangle provides an elegant algebraic structure for reasoning with vague and uncertain information. But the truth and knowledge ordering of intervals in bilattice-based triangle can not handle repetitive belief revisions which is an essential characteristic of nonmonotonic reasoning. Moreover the ordering induced over the intervals by the bilattice-based triangle is not sometimes intuitive. In this work, we construct an alternative algebraic structure, namely preorder-based triangle and we formulate proper logical connectives for this. It is an enhancement of the bilattice-based triangle to handle belief revision in nonmonotonic reasoning. version:3
arxiv-1705-04399 | Motion Rectification for an Homeostasis-Enabling Wheel | http://arxiv.org/abs/1705.04399 | id:1705.04399 author:Juan-Pablo Afman, Mark Mote, Eric Feron category:cs.RO  published:2017-05-11 summary:A wheel that is capable of producing thrust and maintaining vehicle internal integrity is presented. The wheel can be seen as an organic extension to the central unit (eg the vehicle) it is attached to, that is, the system and the wheel can be completely surrounded by the same tegument while enabling continuous wheel rotation without tearing the tegument. Furthermore, a skeleton linking the central unit of the system to the wheel's center can be made through the use of joints and linear links, while allowing the apparatus to rotate continuously in the same direction with bounded twisting and no tegument tear. For that reason, artificial muscles can also be used to actuate the entire system. The underlying enabling mechanism is the rectification of a small number of oscillatory inputs. Another contribution of the proposed setup is to offer a plausible, yet untested, evolutionary path from today's living animals towards animals capable of wheeled locomotion. version:1
arxiv-1705-04351 | A rational analysis of curiosity | http://arxiv.org/abs/1705.04351 | id:1705.04351 author:Rachit Dubey, Thomas L. Griffiths category:cs.AI  published:2017-05-11 summary:We present a rational analysis of curiosity, proposing that people's curiosity is driven by seeking stimuli that maximize their ability to make appropriate responses in the future. This perspective offers a way to unify previous theories of curiosity into a single framework. Experimental results confirm our model's predictions, showing how the relationship between curiosity and confidence can change significantly depending on the nature of the environment. version:1
arxiv-1704-00725 | Reprogramming Matter, Life, and Purpose | http://arxiv.org/abs/1704.00725 | id:1704.00725 author:Hector Zenil category:cs.CY cs.AI  published:2017-04-02 summary:Reprogramming matter may sound far-fetched, but we have been doing it with increasing power and staggering efficiency for at least 60 years, and for centuries we have been paving the way toward the ultimate reprogrammed fate of the universe, the vessel of all programs. How will we be doing it in 60 years' time and how will it impact life and the purpose both of machines and of humans? version:3
arxiv-1705-04263 | Improving Resilience of Autonomous Moving Platforms by Real Time Analysis of Their Cooperation | http://arxiv.org/abs/1705.04263 | id:1705.04263 author:Bogdan Czejdo, Sambit Bhattacharya, Mikołaj Baszun, Wiktor B. Daszczuk category:cs.SE cs.DC 68U07 D.2.4  published:2017-05-11 summary:Environmental changes, failures, collisions or even terrorist attacks can cause serious malfunctions of the delivery systems. We have presented a novel approach improving resilience of Autonomous Moving Platforms AMPs. The approach is based on multi-level state diagrams describing environmental trigger specifications, movement actions and synchronization primitives. The upper level diagrams allowed us to model advanced interactions between autonomous AMPs and detect irregularities such as deadlocks live-locks etc. The techniques were presented to verify and analyze combined AMPs' behaviors using model checking technique. The described system, Dedan verifier, is still under development. In the near future, a graphical form of verified system representation is planned. version:1
arxiv-1704-04722 | Bounded Distributed Flocking Control of Nonholonomic Mobile Robots | http://arxiv.org/abs/1704.04722 | id:1704.04722 author:Thang Nguyen, Hung La, Vahid Azimi, Thanh-Trung Han category:cs.RO cs.SY  published:2017-04-16 summary:There have been numerous studies on the problem of flocking control for multiagent systems whose simplified models are presented in terms of point-mass elements. Meanwhile, full dynamic models pose some challenging problems in addressing the flocking control problem of mobile robots due to their nonholonomic dynamic properties. Taking practical constraints into consideration, we propose a novel approach to distributed flocking control of nonholonomic mobile robots by bounded feedback. The flocking control objectives consist of velocity consensus, collision avoidance, and cohesion maintenance among mobile robots. A flocking control protocol which is based on the information of neighbor mobile robots is constructed. The theoretical analysis is conducted with the help of a Lyapunov-like function and graph theory. Simulation results are shown to demonstrate the efficacy of the proposed distributed flocking control scheme. version:2
arxiv-1705-04159 | Distributed Bayesian Probabilistic Matrix Factorization | http://arxiv.org/abs/1705.04159 | id:1705.04159 author:Tom Vander Aa, Imen Chakroun, Tom Haber category:cs.DC  published:2017-05-11 summary:Matrix factorization is a common machine learning technique for recommender systems. Despite its high prediction accuracy, the Bayesian Probabilistic Matrix Factorization algorithm (BPMF) has not been widely used on large scale data because of its high computational cost. In this paper we propose a distributed high-performance parallel implementation of BPMF on shared memory and distributed architectures. We show by using efficient load balancing using work stealing on a single node, and by using asynchronous communication in the distributed version we beat state of the art implementations. version:1
arxiv-1705-04146 | Program Induction by Rationale Generation:Learning to Solve and Explain Algebraic Word Problems | http://arxiv.org/abs/1705.04146 | id:1705.04146 author:Wang Ling, Dani Yogatama, Chris Dyer, Phil Blunsom category:cs.AI cs.CL cs.LG  published:2017-05-11 summary:Solving algebraic word problems requires executing a series of arithmetic operations---a program---to obtain a final answer. However, since programs can be arbitrarily complicated, inducing them directly from question-answer pairs is a formidable challenge. To make this task more feasible, we solve these problems by generating answer rationales, sequences of natural language and human-readable mathematical expressions that derive the final answer through a series of small steps. Although rationales do not explicitly specify programs, they provide a scaffolding for their structure via intermediate milestones. To evaluate our approach, we have created a new 100,000-sample dataset of questions, answers and rationales. Experimental results show that indirect supervision of program learning via answer rationales is a promising strategy for inducing arithmetic programs. version:1
arxiv-1705-04144 | Error-Sensitive Proof-Labeling Schemes | http://arxiv.org/abs/1705.04144 | id:1705.04144 author:Laurent Feuilloley, Pierre Fraigniaud category:cs.DC  published:2017-05-11 summary:Proof-labeling schemes are known mechanisms providing nodes of networks with certificates that can be verified locally by distributed algorithms. Given a boolean predicate on network states, such schemes enable to check whether the predicate is satisfied by the actual state of the network, by having nodes interacting with their neighbors only. Proof-labeling schemes are typically designed for enforcing fault-tolerance, by making sure that if the current state of the network is illegal with respect to some given predicate, then at least one node will detect it. Such a node can raise an alarm, or launch a recovery procedure enabling the system to return to a legal state. In this paper, we introduce error-sensitive proof-labeling schemes. These are proof-labeling schemes which guarantee that the number of nodes detecting illegal states is linearly proportional to the edit-distance between the current state and the set of legal states. By using error-sensitive proof-labeling schemes, states which are far from satisfying the predicate will be detected by many nodes, enabling fast return to legality. We provide a structural characterization of the set of boolean predicates on network states for which there exist error-sensitive proof-labeling schemes. This characterization allows us to show that classical predicates such as, e.g., acyclicity, and leader admit error-sensitive proof-labeling schemes, while others like regular subgraphs don't. We also focus on compact error-sensitive proof-labeling schemes. In particular, we show that the known proof-labeling schemes for spanning tree and minimum spanning tree, using certificates on $O(\log n)$ bits, and on $O\left(\log^2n\right)$ bits, respectively, are error-sensitive, as long as the trees are locally represented by adjacency lists, and not just by parent pointers. version:1
arxiv-1705-04119 | Memetic search for identifying critical nodes in sparse graphs | http://arxiv.org/abs/1705.04119 | id:1705.04119 author:Yangming Zhou, Jin-Kao Hao, Fred Glover category:cs.AI  published:2017-05-11 summary:Critical node problems involve identifying a subset of critical nodes from an undirected graph whose removal results in optimizing a pre-defined measure over the residual graph. As useful models for a variety of practical applications, these problems are computational challenging. In this paper, we study the classic critical node problem (CNP) and introduce an effective memetic algorithm for solving CNP. The proposed algorithm combines a double backbone-based crossover operator (to generate promising offspring solutions), a component-based neighborhood search procedure (to find high-quality local optima) and a rank-based pool updating strategy (to guarantee a healthy population). Specially, the component-based neighborhood search integrates two key techniques, i.e., two-phase node exchange strategy and node weighting scheme. The double backbone-based crossover extends the idea of general backbone-based crossovers. Extensive evaluations on 42 synthetic and real-world benchmark instances show that the proposed algorithm discovers 21 new upper bounds and matches 18 previous best-known upper bounds. We also demonstrate the relevance of our algorithm for effectively solving a variant of the classic CNP, called the cardinality-constrained critical node problem. Finally, we investigate the usefulness of each key algorithmic component. version:1
arxiv-1705-04069 | Survey on Data-Centric based Routing Protocols for Wireless Sensor Networks | http://arxiv.org/abs/1705.04069 | id:1705.04069 author:Khalid Al Rasbi, Hothefa Shaker, Zeyad Sharef category:cs.NI cs.DC  published:2017-05-11 summary:The great concern for energy that grew with the technological advances in the field of networks and especially in sensor network has triggered various approaches and protocols that relate to sensor networks. In this context, the routing protocols were of great interest. The aim of the present paper is to discuss routing protocols for sensor networks. This paper will focus mainly on the discussion of the data-centric approach (COUGAR, rumor, SPIN, flooding and Gossiping), while shedding light on the other approaches occasionally. The functions of the nodes will be discussed as well. The methodology selected for this paper is based on a close description and discussion of the protocol. As a conclusion, open research questions and limitations are proposed to the reader at the end of this paper. version:1
arxiv-1705-04042 | Robust Routing Made Easy | http://arxiv.org/abs/1705.04042 | id:1705.04042 author:Christoph Lenzen, Moti Medina category:cs.DC  published:2017-05-11 summary:Designing routing schemes is a multidimensional and complex task that depends on the objective function, the computational model (centralized vs. distributed), and the amount of uncertainty (online vs. offline). Nevertheless, there are quite a few well-studied general techniques, for a large variety of network problems. In contrast, in our view, practical techniques for designing robust routing schemes are scarce; while fault-tolerance has been studied from a number of angles, existing approaches are concerned with dealing with faults after the fact by rerouting, self-healing, or similar techniques. We argue that this comes at a high burden for the designer, as in such a system any algorithm must account for the effects of faults on communication. With the goal of initiating efforts towards addressing this issue, we showcase simple and generic transformations that can be used as a blackbox to increase resilience against (independently distributed) faults. Given a network and a routing scheme, we determine a reinforced network and corresponding routing scheme that faithfully preserves the specification and behavior of the original scheme. We show that reasonably small constant overheads in terms of size of the new network compared to the old are sufficient for substantially relaxing the reliability requirements on individual components. The main message in this paper is that the task of designing a robust routing scheme can be decoupled into (i) designing a routing scheme that meets the specification in a fault-free environment, (ii) ensuring that nodes correspond to fault-containment regions, i.e., fail (approximately) independently, and (iii) applying our transformation to obtain a reinforced network and a robust routing scheme that is fault-tolerant. version:1
arxiv-1705-03865 | Survey of Visual Question Answering: Datasets and Techniques | http://arxiv.org/abs/1705.03865 | id:1705.03865 author:Akshay Kumar Gupta category:cs.CL cs.AI cs.CV  published:2017-05-10 summary:Visual question answering (or VQA) is a new and exciting problem that combines natural language processing and computer vision techniques. We present a survey of the various datasets and models that have been used to tackle this task. The first part of the survey details the various datasets for VQA and compares them along some common factors. The second part of this survey details the different approaches for VQA, classified into four types: non-deep learning models, deep learning models without attention, deep learning models with attention, and other models which do not fit into the first three. Finally, we compare the performances of these approaches and provide some directions for future work. version:2
arxiv-1705-04010 | Swarm-Enabling Technology for Multi-Robot Systems | http://arxiv.org/abs/1705.04010 | id:1705.04010 author:Mohammadreza Chamanbaz, David Mateo, Brandon M. Zoss, Grgur Tokić, Erik Wilhelm, Roland Bouffanais, and Dick K. P. Yue category:cs.RO  published:2017-05-11 summary:Swarm robotics has experienced a rapid expansion in recent years, primarily fueled by specialized multi-robot systems developed to achieve dedicated collective actions. These specialized platforms are in general designed with swarming considerations at the front and center. Key hardware and software elements required for swarming are often deeply embedded and integrated with the particular system. However, given the noticeable increase in the number of low-cost mobile robots readily available, practitioners and hobbyists may start considering to assemble full-fledged swarms by minimally retrofitting such mobile platforms with a swarm-enabling technology. Here, we report one possible embodiment of such a technology designed to enable the assembly and the study of swarming in a range of general-purpose robotic systems. This is achieved by combining a modular and transferable software toolbox with a hardware suite composed of a collection of low-cost and off-the-shelf components. The developed technology can be ported to a relatively vast range of robotic platforms with minimal changes and high levels of scalability. This swarm-enabling technology has successfully been implemented on two distinct distributed multi-robot systems, a swarm of mobile marine buoys and a team of commercial terrestrial robots. We have tested the effectiveness of both of these distributed robotic systems in performing collective exploration and search scenarios, as well as other classical cooperative behaviors. Experimental results on different swarm behaviors are reported for the two platforms in uncontrolled environments and without any supporting infrastructure. The design of the associated software library allows for a seamless switch to other cooperative behaviors, and also offers the possibility to simulate newly designed collective behaviors prior to their implementation onto the platforms. version:1
arxiv-1705-03501 | Socially Trusted Collaborative Edge Computing in Ultra Dense Networks | http://arxiv.org/abs/1705.03501 | id:1705.03501 author:Lixing Chen, Jie Xu category:cs.GT cs.DC  published:2017-05-09 summary:Small cell base stations (SBSs) endowed with cloud-like computing capabilities are considered as a key enabler of edge computing (EC), which provides ultra-low latency and location-awareness for a variety of emerging mobile applications and the Internet of Things. However, due to the limited computation resources of an individual SBS, providing computation services of high quality to its users faces significant challenges when it is overloaded with an excessive amount of computation workload. In this paper, we propose collaborative edge computing among SBSs by forming SBS coalitions to share computation resources with each other, thereby accommodating more computation workload in the edge system and reducing reliance on the remote cloud. A novel SBS coalition formation algorithm is developed based on the coalitional game theory to cope with various new challenges in small-cell-based edge systems, including the co-provisioning of radio access and computing services, cooperation incentives, and potential security risks. To address these challenges, the proposed method (1) allows collaboration at both the user-SBS association stage and the SBS peer offloading stage by exploiting the ultra dense deployment of SBSs, (2) develops a payment-based incentive mechanism that implements proportionally fair utility division to form stable SBS coalitions, and (3) builds a social trust network for managing security risks among SBSs due to collaboration. Systematic simulations in practical scenarios are carried out to evaluate the efficacy and performance of the proposed method, which shows that tremendous edge computing performance improvement can be achieved. version:2
arxiv-1602-06347 | Distributed Constraint Optimization Problems and Applications: A Survey | http://arxiv.org/abs/1602.06347 | id:1602.06347 author:Ferdinando Fioretto, Enrico Pontelli, William Yeoh category:cs.AI cs.MA  published:2016-02-20 summary:The field of Multi-Agent System (MAS) is an active area of research within Artificial Intelligence, with an increasingly important impact in industrial and other real-world applications. Within a MAS, autonomous agents interact to pursue personal interests and/or to achieve common objectives. Distributed Constraint Optimization Problems (DCOPs) have emerged as one of the prominent agent architectures to govern the agents' autonomous behavior, where both algorithms and communication models are driven by the structure of the specific problem. During the last decade, several extensions to the DCOP model have enabled them to support MAS in complex, real-time, and uncertain environments. This survey aims at providing an overview of the DCOP model, giving a classification of its multiple extensions and addressing both resolution methods and applications that find a natural mapping within each class of DCOPs. The proposed classification suggests several future perspectives for DCOP extensions, and identifies challenges in the design of efficient resolution algorithms, possibly through the adaptation of strategies from different areas. version:3
