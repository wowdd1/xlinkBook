arxiv-1709-05083 | Robust Kernelized Multi-View Self-Representations for Clustering by Tensor Multi-Rank Minimization | http://arxiv.org/abs/1709.05083 | id:1709.05083 author:Yanyun Qu, Jinyan Liu, Yuan Xie, Wensheng Zhang category:cs.CV  published:2017-09-15 summary:Most recently, tensor-SVD is implemented on multi-view self-representation clustering and has achieved the promising results in many real-world applications such as face clustering, scene clustering and generic object clustering. However, tensor-SVD based multi-view self-representation clustering is proposed originally to solve the clustering problem in the multiple linear subspaces, leading to unsatisfactory results when dealing with the case of non-linear subspaces. To handle data clustering from the non-linear subspaces, a kernelization method is designed by mapping the data from the original input space to a new feature space in which the transformed data can be clustered by a multiple linear clustering method. In this paper, we make an optimization model for the kernelized multi-view self-representation clustering problem. We also develop a new efficient algorithm based on the alternation direction method and infer a closed-form solution. Since all the subproblems can be solved exactly, the proposed optimization algorithm is guaranteed to obtain the optimal solution. In particular, the original tensor-based multi-view self-representation clustering problem is a special case of our approach and can be solved by our algorithm. Experimental results on several popular real-world clustering datasets demonstrate that our approach achieves the state-of-the-art performance. version:1
arxiv-1709-04893 | Convolutional Networks for Spherical Signals | http://arxiv.org/abs/1709.04893 | id:1709.04893 author:Taco Cohen, Mario Geiger, Jonas Köhler, Max Welling category:cs.LG  published:2017-09-14 summary:The success of convolutional networks in learning problems involving planar signals such as images is due to their ability to exploit the translation symmetry of the data distribution through weight sharing. Many areas of science and egineering deal with signals with other symmetries, such as rotation invariant data on the sphere. Examples include climate and weather science, astrophysics, and chemistry. In this paper we present spherical convolutional networks. These networks use convolutions on the sphere and rotation group, which results in rotational weight sharing and rotation equivariance. Using a synthetic spherical MNIST dataset, we show that spherical convolutional networks are very effective at dealing with rotationally invariant classification problems. version:2
arxiv-1709-05074 | A Deep Generative Framework for Paraphrase Generation | http://arxiv.org/abs/1709.05074 | id:1709.05074 author:Ankush Gupta, Arvind Agarwal, Prawaan Singh, Piyush Rai category:cs.CL  published:2017-09-15 summary:Paraphrase generation is an important problem in NLP, especially in question answering, information retrieval, information extraction, conversation systems, to name a few. In this paper, we address the problem of generating paraphrases automatically. Our proposed method is based on a combination of deep generative models (VAE) with sequence-to-sequence models (LSTM) to generate paraphrases, given an input sentence. Traditional VAEs when combined with recurrent neural networks can generate free text but they are not suitable for paraphrase generation for a given sentence. We address this problem by conditioning the both, encoder and decoder sides of VAE, on the original sentence, so that it can generate the given sentence's paraphrases. Unlike most existing models, our model is simple, modular and can generate multiple paraphrases, for a given sentence. Quantitative evaluation of the proposed method on a benchmark paraphrase dataset demonstrates its efficacy, and its performance improvement over the state-of-the-art methods by a significant margin, whereas qualitative human evaluation indicate that the generated paraphrases are well-formed, grammatically correct, and are relevant to the input sentence. Furthermore, we evaluate our method on a newly released question paraphrase dataset, and establish a new baseline for future research. version:1
arxiv-1709-04109 | Empower Sequence Labeling with Task-Aware Neural Language Model | http://arxiv.org/abs/1709.04109 | id:1709.04109 author:Liyuan Liu, Jingbo Shang, Frank F. Xu, Xiang Ren, Huan Gui, Jian Peng, Jiawei Han category:cs.CL cs.LG  published:2017-09-13 summary:Linguistic sequence labeling is a general modeling approach that encompasses a variety of problems, such as part-of-speech tagging and named entity recognition. Recent advances in neural networks (NNs) make it possible to build reliable models without handcrafted features. However, in many cases, it is hard to obtain sufficient annotations to train these models. In this study, we develop a novel neural framework to extract abundant knowledge hidden in raw texts to empower the sequence labeling task. Besides word-level knowledge contained in pre-trained word embeddings, character-aware neural language models are incorporated to extract character-level knowledge. Transfer learning techniques are further adopted to mediate different components and guide the language model towards the key knowledge. Comparing to previous methods, these task-specific knowledge allows us to adopt a more concise model and conduct more efficient training. Different from most transfer learning methods, the proposed framework does not rely on any additional supervision. It extracts knowledge from self-contained order information of training sequences. Extensive experiments on benchmark datasets demonstrate the effectiveness of leveraging character-level knowledge and the efficiency of co-training. For example, on the CoNLL03 NER task, model training completes in about 6 hours on a single GPU, reaching F1 score of 91.71$\pm$0.10 without using any extra annotation. version:3
arxiv-1709-05072 | Joint Hierarchical Category Structure Learning and Large-Scale Image Classification | http://arxiv.org/abs/1709.05072 | id:1709.05072 author:Yanyun Qu, Li Lin, Fumin Shen, Chang Lu, Yang Wu, Yuan Xie, Dacheng Tao category:cs.CV  published:2017-09-15 summary:We investigate the scalable image classification problem with a large number of categories. Hierarchical visual data structures are helpful for improving the efficiency and performance of large-scale multi-class classification. We propose a novel image classification method based on learning hierarchical inter-class structures. Specifically, we first design a fast algorithm to compute the similarity metric between categories, based on which a visual tree is constructed by hierarchical spectral clustering. Using the learned visual tree, a test sample label is efficiently predicted by searching for the best path over the entire tree. The proposed method is extensively evaluated on the ILSVRC2010 and Caltech 256 benchmark datasets. Experimental results show that our method obtains significantly better category hierarchies than other state-of-the-art visual tree-based methods and, therefore, much more accurate classification. version:1
arxiv-1709-05069 | Accelerating SGD for Distributed Deep-Learning Using Approximated Hessian Matrix | http://arxiv.org/abs/1709.05069 | id:1709.05069 author:Sébastien M. R. Arnold, Chunming Wang category:cs.LG  published:2017-09-15 summary:We introduce a novel method to compute a rank $m$ approximation of the inverse of the Hessian matrix in the distributed regime. By leveraging the differences in gradients and parameters of multiple Workers, we are able to efficiently implement a distributed approximation of the Newton-Raphson method. We also present preliminary results which underline advantages and challenges of second-order methods for large stochastic optimization problems. In particular, our work suggests that novel strategies for combining gradients provide further information on the loss surface. version:1
arxiv-1709-05065 | Asian Stamps Identification and Classification System | http://arxiv.org/abs/1709.05065 | id:1709.05065 author:Behzad Mahaseni, Nabhan D. Salih category:cs.CV  published:2017-09-15 summary:In this paper, we address the problem of stamp recognition. The goal is to classify a given stamp to a certain country and also identify the year it is published. We propose a new approach for stamp recognition based on describing a given stamp image using color information and texture information. For color information we use color histogram for the entire image and for texture we use two features. SIFT which is based on local feature descriptors and HOG which is a dens texture descriptor. As a result on total we have three different types of features. Our initial evaluation shows that give these information we are able to classify the images with a reasonable accuracy. version:1
arxiv-1707-09700 | Scene Graph Generation from Objects, Phrases and Region Captions | http://arxiv.org/abs/1707.09700 | id:1707.09700 author:Yikang Li, Wanli Ouyang, Bolei Zhou, Kun Wang, Xiaogang Wang category:cs.CV  published:2017-07-31 summary:Object detection, scene graph generation and region captioning, which are three scene understanding tasks at different semantic levels, are tied together: scene graphs are generated on top of objects detected in an image with their pairwise relationship predicted, while region captioning gives a language description of the objects, their attributes, relations, and other context information. In this work, to leverage the mutual connections across semantic levels, we propose a novel neural network model, termed as Multi-level Scene Description Network (denoted as MSDN), to solve the three vision tasks jointly in an end-to-end manner. Objects, phrases, and caption regions are first aligned with a dynamic graph based on their spatial and semantic connections. Then a feature refining structure is used to pass messages across the three levels of semantic tasks through the graph. We benchmark the learned model on three tasks, and show the joint learning across three tasks with our proposed method can bring mutual improvements over previous models. Particularly, on the scene graph generation task, our proposed method outperforms the state-of-art method with more than 3% margin. version:2
arxiv-1709-04666 | Learning Multi-frame Visual Representation for Joint Detection and Tracking of Small Objects | http://arxiv.org/abs/1709.04666 | id:1709.04666 author:Ryota Yoshihashi, Tu Tuan Trinh, Rei Kawakami, Shaodi You, Makoto Iida, Takeshi Naemura category:cs.CV  published:2017-09-14 summary:Deep convolutional and recurrent neural networks have delivered significant advancements in object detection and tracking. However, current models handle detection and tracking through separate networks, and deep-learning-based joint detection and tracking has not yet been explored despite its potential benefits to both tasks. In this study, we present an integrated neural model called the Recurrent Correlational Network for joint detection and tracking, where the two tasks are performed over multi-frame representation learned through a single, trainable, and end-to-end network. Detection is benefited by the tracker because of the stabilized trajectories and tracking is aided by the enhanced representation afforded by the training of the detector. We show that recently developed convolutional long short-term memory networks can learn multi-frame, multi-task representation, which is useful for both tasks. In experiments, we tackled the detection of small flying objects, such as birds and unmanned aerial vehicles, that can be challenging for single-frame-based detectors. We found that there was consistent improvement in detection performance by the proposed model in comparison with deep single-frame detectors and currently used motion-based detectors. version:2
arxiv-1709-05056 | Learning Compact Geometric Features | http://arxiv.org/abs/1709.05056 | id:1709.05056 author:Marc Khoury, Qian-Yi Zhou, Vladlen Koltun category:cs.CV cs.GR cs.LG  published:2017-09-15 summary:We present an approach to learning features that represent the local geometry around a point in an unstructured point cloud. Such features play a central role in geometric registration, which supports diverse applications in robotics and 3D vision. Current state-of-the-art local features for unstructured point clouds have been manually crafted and none combines the desirable properties of precision, compactness, and robustness. We show that features with these properties can be learned from data, by optimizing deep networks that map high-dimensional histograms into low-dimensional Euclidean spaces. The presented approach yields a family of features, parameterized by dimension, that are both more compact and more accurate than existing descriptors. version:1
arxiv-1709-05038 | Self-Guiding Multimodal LSTM - when we do not have a perfect training dataset for image captioning | http://arxiv.org/abs/1709.05038 | id:1709.05038 author:Yang Xian, Yingli Tian category:cs.CV cs.CL cs.LG  published:2017-09-15 summary:In this paper, a self-guiding multimodal LSTM (sg-LSTM) image captioning model is proposed to handle uncontrolled imbalanced real-world image-sentence dataset. We collect FlickrNYC dataset from Flickr as our testbed with 306,165 images and the original text descriptions uploaded by the users are utilized as the ground truth for training. Descriptions in FlickrNYC dataset vary dramatically ranging from short term-descriptions to long paragraph-descriptions and can describe any visual aspects, or even refer to objects that are not depicted. To deal with the imbalanced and noisy situation and to fully explore the dataset itself, we propose a novel guiding textual feature extracted utilizing a multimodal LSTM (m-LSTM) model. Training of m-LSTM is based on the portion of data in which the image content and the corresponding descriptions are strongly bonded. Afterwards, during the training of sg-LSTM on the rest training data, this guiding information serves as additional input to the network along with the image representations and the ground-truth descriptions. By integrating these input components into a multimodal block, we aim to form a training scheme with the textual information tightly coupled with the image content. The experimental results demonstrate that the proposed sg-LSTM model outperforms the traditional state-of-the-art multimodal RNN captioning framework in successfully describing the key components of the input images. version:1
arxiv-1709-05961 | Adaptive compressed 3D imaging based on wavelet trees and Hadamard multiplexing with a single photon counting detector | http://arxiv.org/abs/1709.05961 | id:1709.05961 author:Huidong Dai, Weiji He, Guohua Gu, Ling Ye, Tianyi Mao, Qian Chen category:cs.CV  published:2017-09-15 summary:Photon counting 3D imaging allows to obtain 3D images with single-photon sensitivity and sub-ns temporal resolution. However, it is challenging to scale to high spatial resolution. In this work, we demonstrate a photon counting 3D imaging technique with short-pulsed structured illumination and a single-pixel photon counting detector. The proposed multi-resolution photon counting 3D imaging technique acquires a high-resolution 3D image from a coarse image and edges at successfully finer resolution sampled by Hadamard multiplexing along the wavelet trees. The detected power is significantly increased thanks to the Hadamard multiplexing. Both the required measurements and the reconstruction time can be significantly reduced by performing wavelet-tree-based regions of edges predication and Hadamard demultiplexing, which makes the proposed technique suitable for scenes with high spatial resolution. The experimental results indicate that a 3D image at resolution up to 512*512 pixels can be acquired and retrieved with practical time as low as 17 seconds. version:1
arxiv-1705-04886 | Learning task structure via sparsity grouped multitask learning | http://arxiv.org/abs/1705.04886 | id:1705.04886 author:Meghana Kshirsagar, Eunho Yang, Aurélie C. Lozano category:stat.ML  published:2017-05-13 summary:Sparse mapping has been a key methodology in many high-dimensional scientific problems. When multiple tasks share the set of relevant features, learning them jointly in a group drastically improves the quality of relevant feature selection. However, in practice this technique is used limitedly since such grouping information is usually hidden. In this paper, our goal is to recover the group structure on the sparsity patterns and leverage that information in the sparse learning. Toward this, we formulate a joint optimization problem in the task parameter and the group membership, by constructing an appropriate regularizer to encourage sparse learning as well as correct recovery of task groups. We further demonstrate that our proposed method recovers groups and the sparsity patterns in the task parameters accurately by extensive experiments. version:2
arxiv-1709-05340 | Dynamic Capacity Estimation in Hopfield Networks | http://arxiv.org/abs/1709.05340 | id:1709.05340 author:Saarthak Sarup, Mingoo Seok category:cs.NE cs.LG  published:2017-09-15 summary:Understanding the memory capacity of neural networks remains a challenging problem in implementing artificial intelligence systems. In this paper, we address the notion of capacity with respect to Hopfield networks and propose a dynamic approach to monitoring a network's capacity. We define our understanding of capacity as the maximum number of stored patterns which can be retrieved when probed by the stored patterns. Prior work in this area has presented static expressions dependent on neuron count $N$, forcing network designers to assume worst-case input characteristics for bias and correlation when setting the capacity of the network. Instead, our model operates simultaneously with the learning Hopfield network and concludes on a capacity estimate based on the patterns which were stored. By continuously updating the crosstalk associated with the stored patterns, our model guards the network from overwriting its memory traces and exceeding its capacity. We simulate our model using artificially generated random patterns, which can be set to a desired bias and correlation, and observe capacity estimates between 93% and 97% accurate. As a result, our model doubles the memory efficiency of Hopfield networks in comparison to the static and worst-case capacity estimate while minimizing the risk of lost patterns. version:1
arxiv-1709-04989 | On Coordinate Minimization of Convex Piecewise-Affine Functions | http://arxiv.org/abs/1709.04989 | id:1709.04989 author:Tomas Werner category:math.OC cs.CV  published:2017-09-14 summary:A popular class of algorithms to optimize the dual LP relaxation of the discrete energy minimization problem (a.k.a.\ MAP inference in graphical models or valued constraint satisfaction) are convergent message-passing algorithms, such as max-sum diffusion, TRW-S, MPLP and SRMP. These algorithms are successful in practice, despite the fact that they are a version of coordinate minimization applied to a convex piecewise-affine function, which is not guaranteed to converge to a global minimizer. These algorithms converge only to a local minimizer, characterized by local consistency known from constraint programming. We generalize max-sum diffusion to a version of coordinate minimization applicable to an arbitrary convex piecewise-affine function, which converges to a local consistency condition. This condition can be seen as the sign relaxation of the global optimality condition. version:1
arxiv-1709-05956 | Deep Learning for Automatic Stereotypical Motor Movement Detection using Wearable Sensors in Autism Spectrum Disorders | http://arxiv.org/abs/1709.05956 | id:1709.05956 author:Nastaran Mohammadian Rad, Seyed Mostafa Kia, Calogero Zarbo, Twan van Laarhoven, Giuseppe Jurman, Paola Venuti, Elena Marchiori, Cesare Furlanello category:cs.CV cs.NE  published:2017-09-14 summary:Autism Spectrum Disorders are associated with atypical movements, of which stereotypical motor movements (SMMs) interfere with learning and social interaction. The automatic SMM detection using inertial measurement units (IMU) remains complex due to the strong intra and inter-subject variability, especially when handcrafted features are extracted from the signal. We propose a new application of the deep learning to facilitate automatic SMM detection using multi-axis IMUs. We use a convolutional neural network (CNN) to learn a discriminative feature space from raw data. We show how the CNN can be used for parameter transfer learning to enhance the detection rate on longitudinal data. We also combine the long short-term memory (LSTM) with CNN to model the temporal patterns in a sequence of multi-axis signals. Further, we employ ensemble learning to combine multiple LSTM learners into a more robust SMM detector. Our results show that: 1) feature learning outperforms handcrafted features; 2) parameter transfer learning is beneficial in longitudinal settings; 3) using LSTM to learn the temporal dynamic of signals enhances the detection rate especially for skewed training data; 4) an ensemble of LSTMs provides more accurate and stable detectors. These findings provide a significant step toward accurate SMM detection in real-time scenarios. version:1
arxiv-1709-04969 | Cross-Platform Emoji Interpretation: Analysis, a Solution, and Applications | http://arxiv.org/abs/1709.04969 | id:1709.04969 author:Fred Morstatter, Kai Shu, Suhang Wang, Huan Liu category:cs.CL  published:2017-09-14 summary:Most social media platforms are largely based on text, and users often write posts to describe where they are, what they are seeing, and how they are feeling. Because written text lacks the emotional cues of spoken and face-to-face dialogue, ambiguities are common in written language. This problem is exacerbated in the short, informal nature of many social media posts. To bypass this issue, a suite of special characters called "emojis," which are small pictograms, are embedded within the text. Many emojis are small depictions of facial expressions designed to help disambiguate the emotional meaning of the text. However, a new ambiguity arises in the way that emojis are rendered. Every platform (Windows, Mac, and Android, to name a few) renders emojis according to their own style. In fact, it has been shown that some emojis can be rendered so differently that they look "happy" on some platforms, and "sad" on others. In this work, we use real-world data to verify the existence of this problem. We verify that the usage of the same emoji can be significantly different across platforms, with some emojis exhibiting different sentiment polarities on different platforms. We propose a solution to identify the intended emoji based on the platform-specific nature of the emoji used by the author of a social media post. We apply our solution to sentiment analysis, a task that can benefit from the emoji calibration technique we use in this work. We conduct experiments to evaluate the effectiveness of the mapping in this task. version:1
arxiv-1709-04960 | Dynamic Pricing in Competitive Markets | http://arxiv.org/abs/1709.04960 | id:1709.04960 author:Paresh Nakhe category:cs.LG cs.GT  published:2017-09-14 summary:Dynamic pricing of goods in a competitive environment to maximize revenue is a natural objective and has been a subject of research over the years. In this paper, we focus on a class of markets exhibiting the substitutes property with sellers having divisible and replenishable goods. Depending on the prices chosen, each seller observes a certain demand which is satisfied subject to the supply constraint. The goal of the seller is to price her good dynamically so as to maximize her revenue. For the static market case, when the consumer utility satisfies the Constant Elasticity of Substitution (CES) property, we give a $O(\sqrt{T})$ regret bound on the maximum loss in revenue of a seller using a modified version of the celebrated Online Gradient Descent Algorithm by Zinkevich. For a more specialized set of consumer utilities satisfying the iso-elasticity condition, we show that when each seller uses a regret-minimizing algorithm satisfying a certain technical property, the regret with respect to $(1-\alpha)$ times optimal revenue is bounded as $O(T^{1/4} / \sqrt{\alpha})$. We extend this result to markets with dynamic supplies and prove a corresponding dynamic regret bound, whose guarantee deteriorates smoothly with the inherent instability of the market. As a side-result, we also extend the previously known convergence results of these algorithms in a general game to the dynamic setting. version:1
arxiv-1709-00268 | Algorithmically probable mutations reproduce aspects of evolution such as convergence rate, genetic memory, modularity, diversity explosions, and mass extinction | http://arxiv.org/abs/1709.00268 | id:1709.00268 author:Santiago Hernández-Orozco, Hector Zenil, Narsis A. Kiani category:cs.NE cs.IT math.IT q-bio.PE  published:2017-09-01 summary:We show that if evolution is algorithmic in any form and can thus be considered a program in software space, the emergence of a natural algorithmic probability distribution has the potential to become an accelerating mechanism. We simulate the application of algorithmic mutations to binary matrices based on numerical approximations to algorithmic probability, comparing the evolutionary speed to the alternative hypothesis of uniformly distributed mutations for a series of matrices of varying complexity. When the algorithmic mutation produces unfit organisms---because mutations may lead to, for example, syntactically useless evolutionary programs---massive extinctions may occur. We show that modularity provides an evolutionary advantage also evolving a genetic memory. We demonstrate that such regular structures are preserved and carried on when they first occur and can also lead to an accelerated production of diversity and extinction, possibly explaining natural phenomena such as periods of accelerated growth of the number of species (e.g. the Cambrian explosion) and the occurrence of massive extinctions (e.g. the End Triassic) whose causes are a matter of considerable debate. The approach introduced here appears to be a better approximation to actual biological evolution than models based upon the application of mutation from uniform probability distributions, and because evolution by algorithmic probability converges faster to regular structures (both artificial and natural, as tested on a small biological network), it also approaches a formal version of open-ended evolution based on previous results. The results validate the motivations and results of Chaitin's Metabiology programme. We also show that the procedure has the potential to significantly accelerate solving optimization problems in the context of artificial evolutionary algorithms. version:4
arxiv-1709-01972 | A Quasi-isometric Embedding Algorithm | http://arxiv.org/abs/1709.01972 | id:1709.01972 author:David W. Dreisigmeyer category:stat.ML cs.CG cs.LG  published:2017-09-06 summary:The Whitney embedding theorem gives an upper bound on the smallest embedding dimension of a manifold. If a data set lies on a manifold, a random projection into this reduced dimension will retain the manifold structure. Here we present an algorithm to find a projection that distorts the data as little as possible. version:2
arxiv-1709-04864 | Food Recognition using Fusion of Classifiers based on CNNs | http://arxiv.org/abs/1709.04864 | id:1709.04864 author:Eduardo Aguilar, Marc Bolaños, Petia Radeva category:cs.CV  published:2017-09-14 summary:With the arrival of convolutional neural networks, the complex problem of food recognition has experienced an important improvement in recent years. The best results have been obtained using methods based on very deep convolutional neural networks, which show that the deeper the model,the better the classification accuracy will be obtain. However, very deep neural networks may suffer from the overfitting problem. In this paper, we propose a combination of multiple classifiers based on different convolutional models that complement each other and thus, achieve an improvement in performance. The evaluation of our approach is done on two public datasets: Food-101 as a dataset with a wide variety of fine-grained dishes, and Food-11 as a dataset of high-level food categories, where our approach outperforms the independent CNN models. version:1
arxiv-1709-04862 | Random Forests of Interaction Trees for Estimating Individualized Treatment Effects in Randomized Trials | http://arxiv.org/abs/1709.04862 | id:1709.04862 author:Xiaogang Su, Annette T. Peña, Lei Liu, Richard A. Levine category:stat.ML 62G08 G.3  published:2017-09-14 summary:Assessing heterogeneous treatment effects has become a growing interest in advancing precision medicine. Individualized treatment effects (ITE) play a critical role in such an endeavor. Concerning experimental data collected from randomized trials, we put forward a method, termed random forests of interaction trees (RFIT), for estimating ITE on the basis of interaction trees (Su et al., 2009). To this end, we first propose a smooth sigmoid surrogate (SSS) method, as an alternative to greedy search, to speed up tree construction. RFIT outperforms the traditional `separate regression' approach in estimating ITE. Furthermore, standard errors for the estimated ITE via RFIT can be obtained with the infinitesimal jackknife method. We assess and illustrate the use of RFIT via both simulation and the analysis of data from an acupuncture headache trial. version:1
arxiv-1709-04836 | Informed Non-convex Robust Principal Component Analysis with Features | http://arxiv.org/abs/1709.04836 | id:1709.04836 author:Niannan Xue, Jiankang Deng, Yannis Panagakis, Stefanos Zafeiriou category:stat.ML cs.CV cs.LG  published:2017-09-14 summary:We revisit the problem of robust principal component analysis with features acting as prior side information. To this aim, a novel, elegant, non-convex optimization approach is proposed to decompose a given observation matrix into a low-rank core and the corresponding sparse residual. Rigorous theoretical analysis of the proposed algorithm results in exact recovery guarantees with low computational complexity. Aptly designed synthetic experiments demonstrate that our method is the first to wholly harness the power of non-convexity over convexity in terms of both recoverability and speed. That is, the proposed non-convex approach is more accurate and faster compared to the best available algorithms for the problem under study. Two real-world applications, namely image classification and face denoising further exemplify the practical superiority of the proposed method. version:1
arxiv-1709-04821 | MODNet: Moving Object Detection Network with Motion and Appearance for Autonomous Driving | http://arxiv.org/abs/1709.04821 | id:1709.04821 author:Mennatullah Siam, Heba Mahgoub, Mohamed Zahran, Senthil Yogamani, Martin Jagersand, Ahmad El-Sallab category:cs.CV  published:2017-09-14 summary:We propose a novel multi-task learning system that combines appearance and motion cues for a better semantic reasoning of the environment. A unified architecture for joint vehicle detection and motion segmentation is introduced. In this architecture, a two-stream encoder is shared among both tasks. In order to evaluate our method in autonomous driving setting, KITTI annotated sequences with detection and odometry ground truth are used to automatically generate static/dynamic annotations on the vehicles. This dataset is called KITTI Moving Object Detection dataset (KITTI MOD). The dataset will be made publicly available to act as a benchmark for the motion detection task. Our experiments show that the proposed method outperforms state of the art methods that utilize motion cue only with 21.5% in mAP on KITTI MOD. Our method performs on par with the state of the art unsupervised methods on DAVIS benchmark for generic object segmentation. One of our interesting conclusions is that joint training of motion segmentation and vehicle detection benefits motion segmentation. Motion segmentation has relatively fewer data, unlike the detection task. However, the shared fusion encoder benefits from joint training to learn a generalized representation. The proposed method runs in 120 ms per frame, which beats the state of the art motion detection/segmentation in computational efficiency. version:1
arxiv-1709-04820 | Synapse at CAp 2017 NER challenge: Fasttext CRF | http://arxiv.org/abs/1709.04820 | id:1709.04820 author:Damien Sileo, Camille Pradel, Philippe Muller, Tim Van de Cruys category:cs.CL  published:2017-09-14 summary:We present our system for the CAp 2017 NER challenge which is about named entity recognition on French tweets. Our system leverages unsupervised learning on a larger dataset of French tweets to learn features feeding a CRF model. It was ranked first without using any gazetteer or structured external data, with an F-measure of 58.89\%. To the best of our knowledge, it is the first system to use fasttext embeddings (which include subword representations) and an embedding-based sentence representation for NER. version:1
arxiv-1709-04808 | On Multi-Relational Link Prediction with Bilinear Models | http://arxiv.org/abs/1709.04808 | id:1709.04808 author:Yanjie Wang, Rainer Gemulla, Hui Li category:cs.LG  published:2017-09-14 summary:We study bilinear embedding models for the task of multi-relational link prediction and knowledge graph completion. Bilinear models belong to the most basic models for this task, they are comparably efficient to train and use, and they can provide good prediction performance. The main goal of this paper is to explore the expressiveness of and the connections between various bilinear models proposed in the literature. In particular, a substantial number of models can be represented as bilinear models with certain additional constraints enforced on the embeddings. We explore whether or not these constraints lead to universal models, which can in principle represent every set of relations, and whether or not there are subsumption relationships between various models. We report results of an independent experimental study that evaluates recent bilinear models in a common experimental setup. Finally, we provide evidence that relation-level ensembles of multiple bilinear models can achieve state-of-the art prediction performance. version:1
arxiv-1709-04800 | Exploring Food Detection using CNNs | http://arxiv.org/abs/1709.04800 | id:1709.04800 author:Eduardo Aguilar, Marc Bolaños, Petia Radeva category:cs.CV  published:2017-09-14 summary:One of the most common critical factors directly related to the cause of a chronic disease is unhealthy diet consumption. In this sense, building an automatic system for food analysis could allow a better understanding of the nutritional information with respect to the food eaten and thus it could help in taking corrective actions in order to consume a better diet. The Computer Vision community has focused its efforts on several areas involved in the visual food analysis such as: food detection, food recognition, food localization, portion estimation, among others. For food detection, the best results evidenced in the state of the art were obtained using Convolutional Neural Network. However, the results of all these different approaches were gotten on different datasets and therefore are not directly comparable. This article proposes an overview of the last advances on food detection and an optimal model based on GoogLeNet Convolutional Neural Network method, principal component analysis, and a support vector machine that outperforms the state of the art on two public food/non-food datasets. version:1
arxiv-1709-04250 | Dialogue Act Sequence Labeling using Hierarchical encoder with CRF | http://arxiv.org/abs/1709.04250 | id:1709.04250 author:Harshit Kumar, Arvind Agarwal, Riddhiman Dasgupta, Sachindra Joshi, Arun Kumar category:cs.CL  published:2017-09-13 summary:Dialogue Act recognition associate dialogue acts (i.e., semantic labels) to utterances in a conversation. The problem of associating semantic labels to utterances can be treated as a sequence labeling problem. In this work, we build a hierarchical recurrent neural network using bidirectional LSTM as a base unit and the conditional random field (CRF) as the top layer to classify each utterance into its corresponding dialogue act. The hierarchical network learns representations at multiple levels, i.e., word level, utterance level, and conversation level. The conversation level representations are input to the CRF layer, which takes into account not only all previous utterances but also their dialogue acts, thus modeling the dependency among both, labels and utterances, an important consideration of natural dialogue. We validate our approach on two different benchmark data sets, Switchboard and Meeting Recorder Dialogue Act, and show performance improvement over the state-of-the-art methods by $2.2\%$ and $4.1\%$ absolute points, respectively. It is worth noting that the inter-annotator agreement on Switchboard data set is $84\%$, and our method is able to achieve the accuracy of about $79\%$ despite being trained on the noisy data. version:2
arxiv-1708-05286 | Simple Open Stance Classification for Rumour Analysis | http://arxiv.org/abs/1708.05286 | id:1708.05286 author:Ahmet Aker, Leon Derczynski, Kalina Bontcheva category:cs.CL  published:2017-08-17 summary:Stance classification determines the attitude, or stance, in a (typically short) text. The task has powerful applications, such as the detection of fake news or the automatic extraction of attitudes toward entities or events in the media. This paper describes a surprisingly simple and efficient classification approach to open stance classification in Twitter, for rumour and veracity classification. The approach profits from a novel set of automatically identifiable problem-specific features, which significantly boost classifier accuracy and achieve above state-of-the-art results on recent benchmark datasets. This calls into question the value of using complex sophisticated models for stance classification without first doing informed feature extraction. version:2
arxiv-1709-04764 | Interpretable Graph-Based Semi-Supervised Learning via Flows | http://arxiv.org/abs/1709.04764 | id:1709.04764 author:Raif M. Rustamov, James T. Klosowski category:stat.ML cs.LG  published:2017-09-14 summary:In this paper, we consider the interpretability of the foundational Laplacian-based semi-supervised learning approaches on graphs. We introduce a novel flow-based learning framework that subsumes the foundational approaches and additionally provides a detailed, transparent, and easily understood expression of the learning process in terms of graph flows. As a result, one can visualize and interactively explore the precise subgraph along which the information from labeled nodes flows to an unlabeled node of interest. Surprisingly, the proposed framework avoids trading accuracy for interpretability, but in fact leads to improved prediction accuracy, which is supported both by theoretical considerations and empirical results. The flow-based framework guarantees the maximum principle by construction and can handle directed graphs in an out-of-the-box manner. version:1
arxiv-1709-04744 | Subspace Clustering using Ensembles of $K$-Subspaces | http://arxiv.org/abs/1709.04744 | id:1709.04744 author:John Lipor, David Hong, Dejiao Zhang, Laura Balzano category:cs.CV cs.LG stat.ML  published:2017-09-14 summary:We present a novel approach to the subspace clustering problem that leverages ensembles of the $K$-subspaces (KSS) algorithm via the evidence accumulation clustering framework. Our algorithm forms a co-association matrix whose $(i,j)$th entry is the number of times points $i$ and $j$ are clustered together by several runs of KSS with random initializations. We analyze the entries of this co-association matrix and show that a naive version of our algorithm can recover subspaces for points drawn from the same conditions as the Thresholded Subspace Clustering algorithm. We show on synthetic data that our method performs well under subspaces with large intersection, subspaces with small principal angles, and noisy data. Finally, we provide a variant of our algorithm that achieves state-of-the-art performance across several benchmark datasets, including a resulting error for the COIL-20 database that is less than half that achieved by existing algorithms. version:1
arxiv-1709-02764 | An Adaptive Sampling Scheme to Efficiently Train Fully Convolutional Networks for Semantic Segmentation | http://arxiv.org/abs/1709.02764 | id:1709.02764 author:Lorenz Berger, Eoin Hyde, M. Jorge Cardoso, Sebastien Ourselin category:cs.CV  published:2017-09-08 summary:Deep convolutional neural networks (CNNs) have shown excellent performance in object recognition tasks and dense classification problems such as semantic segmentation. However, training deep neural networks on large and sparse datasets is still challenging and can require large amounts of computation and memory. In this work, we address the task of performing semantic segmentation on large data sets, such as three-dimensional medical images. We propose an adaptive sampling scheme that uses a-posterior error maps, generated throughout training, to focus sampling on difficult regions, resulting in improved learning. Our contribution is threefold: 1) We give a detailed description of the proposed sampling algorithm to speed up and improve learning performance on large images. We propose a deep dual path CNN that captures information at fine and coarse scales, resulting in a network with a large field of view and high resolution outputs. We show that our method is able to attain new state-of-the-art results on the VISCERAL Anatomy benchmark. version:3
arxiv-1709-02641 | Completion of High Order Tensor Data with Missing Entries via Tensor-train Decomposition | http://arxiv.org/abs/1709.02641 | id:1709.02641 author:Longhao Yuan, Qibin Zhao, Jianting Cao category:cs.NA cs.CV  published:2017-09-08 summary:In this paper, we aim at the completion problem of high order tensor data with missing entries. The existing tensor factorization and completion methods suffer from the curse of dimensionality when the order of tensor N>>3. To overcome this problem, we propose an efficient algorithm called TT-WOPT (Tensor-train Weighted OPTimization) to find the latent core tensors of tensor data and recover the missing entries. Tensor-train decomposition, which has the powerful representation ability with linear scalability to tensor order, is employed in our algorithm. The experimental results on synthetic data and natural image completion demonstrate that our method significantly outperforms the other related methods. Especially when the missing rate of data is very high, e.g., 85% to 99%, our algorithm can achieve much better performance than other state-of-the-art algorithms. version:2
arxiv-1709-04731 | Binary-decomposed DCNN for accelerating computation and compressing model without retraining | http://arxiv.org/abs/1709.04731 | id:1709.04731 author:Ryuji Kamiya, Takayoshi Yamashita, Mitsuru Ambai, Ikuro Sato, Yuji Yamauchi, Hironobu Fujiyoshi category:cs.CV  published:2017-09-14 summary:Recent trends show recognition accuracy increasing even more profoundly. Inference process of Deep Convolutional Neural Networks (DCNN) has a large number of parameters, requires a large amount of computation, and can be very slow. The large number of parameters also require large amounts of memory. This is resulting in increasingly long computation times and large model sizes. To implement mobile and other low performance devices incorporating DCNN, model sizes must be compressed and computation must be accelerated. To that end, this paper proposes Binary-decomposed DCNN, which resolves these issues without the need for retraining. Our method replaces real-valued inner-product computations with binary inner-product computations in existing network models to accelerate computation of inference and decrease model size without the need for retraining. Binary computations can be done at high speed using logical operators such as XOR and AND, together with bit counting. In tests using AlexNet with the ImageNet classification task, speed increased by a factor of 1.79, models were compressed by approximately 80%, and increase in error rate was limited to 1.20%. With VGG-16, speed increased by a factor of 2.07, model sizes decreased by 81%, and error increased by only 2.16%. version:1
arxiv-1707-09855 | Convolution with Logarithmic Filter Groups for Efficient Shallow CNN | http://arxiv.org/abs/1707.09855 | id:1707.09855 author:Tae Kwan Lee, Wissam J. Baddar, Seong Tae Kim, Yong Man Ro category:cs.CV  published:2017-07-31 summary:In convolutional neural networks (CNNs), the filter grouping in convolution layers is known to be useful to reduce the network parameter size. In this paper, we propose a new logarithmic filter grouping which can capture the nonlinearity of filter distribution in CNNs. The proposed logarithmic filter grouping is installed in shallow CNNs applicable in a mobile application. Experiments were performed with the shallow CNNs for classification tasks. Our classification results on Multi-PIE dataset for facial expression recognition and CIFAR-10 dataset for object classification reveal that the compact CNN with the proposed logarithmic filter grouping scheme outperforms the same network with the uniform filter grouping in terms of accuracy and parameter efficiency. Our results indicate that the efficiency of shallow CNNs can be improved by the proposed logarithmic filter grouping. version:2
arxiv-1709-04725 | Unsupervised deep object discovery for instance recognition | http://arxiv.org/abs/1709.04725 | id:1709.04725 author:Oriane Siméoni, Ahmet Iscen, Giorgos Tolias, Yannis Avrithis, Ondrej Chum category:cs.CV  published:2017-09-14 summary:Severe background clutter is challenging in many computer vision tasks, including large-scale image retrieval. Global descriptors, that are popular due to their memory and search efficiency, are especially prone to corruption by such clutter. Eliminating the impact of the clutter on the image descriptor increases the chance of retrieving relevant images as well as preventing topic drift by actually retrieving the clutter in the case of query expansion. In this work, we propose a novel salient region detection method. It captures, in an unsupervised manner, patterns that are both discriminative and common in the dataset. The descriptors derived on the salient regions improve particular object retrieval, most noticeably in a large collections containing small objects. version:1
arxiv-1709-04718 | The Impact of Local Geometry and Batch Size on the Convergence and Divergence of Stochastic Gradient Descent | http://arxiv.org/abs/1709.04718 | id:1709.04718 author:Vivak Patel category:math.OC stat.CO stat.ML 90C15  90C30  published:2017-09-14 summary:Stochastic small-batch (SB) methods, such as mini-batch Stochastic Gradient Descent (SGD), have been extremely successful in training neural networks with strong generalization properties. In the work of Keskar et. al (2017), an SB method's success in training neural networks was attributed to the fact it converges to flat minima---those minima whose Hessian has only small eigenvalues---while a large-batch (LB) method converges to sharp minima---those minima whose Hessian has a few large eigenvalues. Commonly, this difference is attributed to the noisier gradients in SB methods that allow SB iterates to escape from sharp minima. While this explanation is intuitive, in this work we offer an alternative mechanism. In this work, we argue that SGD escapes from or converges to minima based on a deterministic relationship between the learning rate, the batch size, and the local geometry of the minimizer. We derive the exact relationships by a rigorous mathematical analysis of the canonical quadratic sums problem. Then, we numerically study how these relationships extend to nonconvex, stochastic optimization problems. As a consequence of this work, we offer a more complete explanation of why SB methods prefer flat minima and LB methods seem agnostic, which can be leveraged to design SB and LB training methods that have tailored optimization properties. version:1
arxiv-1709-04710 | Embedded-Graph Theory | http://arxiv.org/abs/1709.04710 | id:1709.04710 author:Atsushi Yokoyama category:cs.DM cs.CL 05C90  68R10  97K30 G.2.2  published:2017-09-14 summary:In this paper, we propose a new type of graph, denoted as "embedded-graph", and its theory, which employs a distributed representation to describe the relations on the graph edges. Embedded-graphs can express linguistic and complicated relations, which cannot be expressed by the existing edge-graphs or weighted-graphs. We introduce the mathematical definition of embedded-graph, translation, edge distance, and graph similarity. We can transform an embedded-graph into a weighted-graph and a weighted-graph into an edge-graph by the translation method and by threshold calculation, respectively. The edge distance of an embedded-graph is a distance based on the components of a target vector, and it is calculated through cosine similarity with the target vector. The graph similarity is obtained considering the relations with linguistic complexity. In addition, we provide some examples and data structures for embedded-graphs in this paper. version:1
arxiv-1709-05952 | Towards a Crowd Analytic Framework For Crowd Management in Majid-al-Haram | http://arxiv.org/abs/1709.05952 | id:1709.05952 author:Sultan Daud Khan, Muhammad Tayyab, Muhammad Khurram Amin, Akram Nour, Anas Basalamah, Saleh Basalamah, Sohaib Ahmad Khan category:cs.CV  published:2017-09-14 summary:The scared cities of Makkah Al Mukarramah and Madina Al Munawarah host millions of pilgrims every year. During Hajj, the movement of large number of people has a unique spatial and temporal constraints, which makes Hajj one of toughest challenges for crowd management. In this paper, we propose a computer vision based framework that automatically analyses video sequence and computes important measurements which include estimation of crowd density, identification of dominant patterns, detection and localization of congestion. In addition, we analyze helpful statistics of the crowd like speed, and direction, that could provide support to crowd management personnel. The framework presented in this paper indicate that new advances in computer vision and machine learning can be leveraged effectively for challenging and high density crowd management applications. However, significant customization of existing approaches is required to apply them to the challenging crowd management situations in Masjid Al Haram. Our results paint a promising picture for deployment of computer vision technologies to assist in quantitative measurement of crowd size, density and congestion. version:1
arxiv-1709-04685 | Machine-Translation History and Evolution: Survey for Arabic-English Translations | http://arxiv.org/abs/1709.04685 | id:1709.04685 author:Nabeel T. Alsohybe, Neama Abdulaziz Dahan, Fadl Mutaher Ba-Alwi category:cs.CL  published:2017-09-14 summary:As a result of the rapid changes in information and communication technology (ICT), the world has become a small village where people from all over the world connect with each other in dialogue and communication via the Internet. Also, communications have become a daily routine activity due to the new globalization where companies and even universities become global residing cross countries borders. As a result, translation becomes a needed activity in this connected world. ICT made it possible to have a student in one country take a course or even a degree from a different country anytime anywhere easily. The resulted communication still needs a language as a means that helps the receiver understands the contents of the sent message. People need an automated translation application because human translators are hard to find all the times, and the human translations are very expensive comparing to the translations automated process. Several types of research describe the electronic process of the Machine-Translation. In this paper, the authors are going to study some of these previous researches, and they will explore some of the needed tools for the Machine-Translation. This research is going to contribute to the Machine-Translation area by helping future researchers to have a summary for the Machine-Translation groups of research and to let lights on the importance of the translation mechanism. version:1
arxiv-1709-04682 | Towards an Arabic-English Machine-Translation Based on Semantic Web | http://arxiv.org/abs/1709.04682 | id:1709.04682 author:Neama Abdulaziz Dahan, Fadl Mutaher Ba-Alwi, Ibrahim Ahmed Al-Baltah, Ghaleb H. Al-gapheri category:cs.CL  published:2017-09-14 summary:Communication tools make the world like a small village and as a consequence people can contact with others who are from different societies or who speak different languages. This communication cannot happen effectively without Machine Translation because they can be found anytime and everywhere. There are a number of studies that have developed Machine Translation for the English language with so many other languages except the Arabic it has not been considered yet. Therefore we aim to highlight a roadmap for our proposed translation machine to provide an enhanced Arabic English translation based on Semantic. version:1
arxiv-1707-01058 | Skeleton-aided Articulated Motion Generation | http://arxiv.org/abs/1707.01058 | id:1707.01058 author:Yichao Yan, Jingwei Xu, Bingbing Ni, Xiaokang Yang category:cs.CV  published:2017-07-04 summary:This work make the first attempt to generate articulated human motion sequence from a single image. On the one hand, we utilize paired inputs including human skeleton information as motion embedding and a single human image as appearance reference, to generate novel motion frames, based on the conditional GAN infrastructure. On the other hand, a triplet loss is employed to pursue appearance-smoothness between consecutive frames. As the proposed framework is capable of jointly exploiting the image appearance space and articulated/kinematic motion space, it generates realistic articulated motion sequence, in contrast to most previous video generation methods which yield blurred motion effects. We test our model on two human action datasets including KTH and Human3.6M, and the proposed framework generates very promising results on both datasets. version:2
arxiv-1709-04673 | Conditions for Stability and Convergence of Set-Valued Stochastic Approximations: Applications to Approximate Value and Fixed point Iterations with Noise | http://arxiv.org/abs/1709.04673 | id:1709.04673 author:Arunselvan Ramaswamy, Shalabh Bhatnagar category:cs.SY math.DS stat.ML  published:2017-09-14 summary:The study of stochastic approximation algorithms (SAAs) with set-valued mean-fields has been popular during recent times due to their applications to many large scale model-free problems arising in stochastic optimization and control. The analysis of such algorithms requires the almost sure boundedness of the iterates, which can be hard to verify. In this paper we extend the ideas of Abounadi, Bertsekas and Borkar involving regular SAAs (with point-to-point maps), to develop easily verifiable sufficient conditions, based on Lyapunov functions, for both stability and convergence of SAAs with set-valued mean-fields. As an important application of our results, we analyze the stochastic approximation counterpart of approximate value iteration (AVI), an important dynamic programming method designed to tackle Bellman's curse of dimensionality. Our framework significantly relaxes the assumptions involved in the analysis of AVI methods. Further, our analysis covers both stochastic shortest path and infinite horizon discounted cost problems. Generalizing further, we present an SAA, together with an analysis of it's stability and convergence for finding fixed points of contractive set-valued maps. To the best of our knowledge ours is the first SAA for finding fixed points of set-valued maps. version:1
arxiv-1709-04647 | Detection of Unauthorized IoT Devices Using Machine Learning Techniques | http://arxiv.org/abs/1709.04647 | id:1709.04647 author:Yair Meidan, Michael Bohadana, Asaf Shabtai, Martin Ochoa, Nils Ole Tippenhauer, Juan Davis Guarnizo, Yuval Elovici category:cs.CR cs.CV H.2.8; C.2.5; K.6.5  published:2017-09-14 summary:Security experts have demonstrated numerous risks imposed by Internet of Things (IoT) devices on organizations. Due to the widespread adoption of such devices, their diversity, standardization obstacles, and inherent mobility, organizations require an intelligent mechanism capable of automatically detecting suspicious IoT devices connected to their networks. In particular, devices not included in a white list of trustworthy IoT device types (allowed to be used within the organizational premises) should be detected. In this research, Random Forest, a supervised machine learning algorithm, was applied to features extracted from network traffic data with the aim of accurately identifying IoT device types from the white list. To train and evaluate multi-class classifiers, we collected and manually labeled network traffic data from 17 distinct IoT devices, representing nine types of IoT devices. Based on the classification of 20 consecutive sessions and the use of majority rule, IoT device types that are not on the white list were correctly detected as unknown in 96% of test cases (on average), and white listed device types were correctly classified by their actual types in 99% of cases. Some IoT device types were identified quicker than others (e.g., sockets and thermostats were successfully detected within five TCP sessions of connecting to the network). Perfect detection of unauthorized IoT device types was achieved upon analyzing 110 consecutive sessions; perfect classification of white listed types required 346 consecutive sessions, 110 of which resulted in 99.49% accuracy. Further experiments demonstrated the successful applicability of classifiers trained in one location and tested on another. In addition, a discussion is provided regarding the resilience of our machine learning-based IoT white listing method to adversarial attacks. version:1
arxiv-1709-04625 | Robustness Analysis of Visual QA Models by Basic Questions | http://arxiv.org/abs/1709.04625 | id:1709.04625 author:Jia-Hong Huang, Modar Alfadly, Bernard Ghanem category:cs.CV cs.CL  published:2017-09-14 summary:Visual Question Answering (VQA) models should have both high robustness and accuracy. Unfortunately, most of the current VQA research only focuses on accuracy because there is a lack of proper methods to measure the robustness of VQA models. There are two main modules in our algorithm. Given a natural language question about an image, the first module takes the question as input and then outputs the ranked basic questions, with similarity scores, of the main given question. The second module takes the main question, image and these basic questions as input and then outputs the text-based answer of the main question about the given image. We claim that a robust VQA model is one, whose performance is not changed much when related basic questions as also made available to it as input. We formulate the basic questions generation problem as a LASSO optimization, and also propose a large scale Basic Question Dataset (BQD) and Rscore (novel robustness measure), for analyzing the robustness of VQA models. We hope our BQD will be used as a benchmark for to evaluate the robustness of VQA models, so as to help the community build more robust and accurate VQA models. version:1
arxiv-1709-04609 | Learning to Segment Instances in Videos with Spatial Propagation Network | http://arxiv.org/abs/1709.04609 | id:1709.04609 author:Jingchun Cheng, Sifei Liu, Yi-Hsuan Tsai, Wei-Chih Hung, Shalini De Mello, Jinwei Gu, Jan Kautz, Shengjin Wang, Ming-Hsuan Yang category:cs.CV  published:2017-09-14 summary:We propose a deep learning-based framework for instance-level object segmentation. Our method mainly consists of three steps. First, We train a generic model based on ResNet-101 for foreground/background segmentations. Second, based on this generic model, we fine-tune it to learn instance-level models and segment individual objects by using augmented object annotations in first frames of test videos. To distinguish different instances in the same video, we compute a pixel-level score map for each object from these instance-level models. Each score map indicates the objectness likelihood and is only computed within the foreground mask obtained in the first step. To further refine this per frame score map, we learn a spatial propagation network. This network aims to learn how to propagate a coarse segmentation mask spatially based on the pairwise similarities in each frame. In addition, we apply a filter on the refined score map that aims to recognize the best connected region using spatial and temporal consistencies in the video. Finally, we decide the instance-level object segmentation in each video by comparing score maps of different instances. version:1
arxiv-1709-04595 | A2-RL: Aesthetics Aware Reinforcement Learning for Automatic Image Cropping | http://arxiv.org/abs/1709.04595 | id:1709.04595 author:Debang Li, Huikai Wu, Junge Zhang, Kaiqi Huang category:cs.CV  published:2017-09-14 summary:Image cropping aims at improving the aesthetic quality of images by adjusting their composition. Most previous methods rely on the sliding window mechanism. The sliding window mechanism requires fixed aspect ratios and limits the cropping region with arbitrary size. Moreover, the sliding window method usually produces tens of thousands of windows which is very time-consuming. Motivated by these challenges and also inspired by the human's cropping process, we firstly formulate the aesthetic image cropping as a sequential decision-making process and propose an Aesthetics Aware Reinforcement Learning (A2-RL) framework to address this problem. Particularly, the proposed method develops an aesthetics aware reward function which especially benefits image cropping. Similar to human's decision making and to better utilize the historical experience, we use a LSTM based state representation including both the current and historical experience. We train the agent using the actor-critic architecture in an end-to-end manner. The agent is evaluated on several popular unseen cropping databases. Experiment results show that our method achieves the state-of-the-art performance with much fewer candidate windows and much less time compared with previous methods. version:1
arxiv-1709-04583 | Accelerate Histogram-Based Contrast Enhancement by Selective Downsampling | http://arxiv.org/abs/1709.04583 | id:1709.04583 author:Gang Cao, Huawei Tian, Lifang Yu, Xianglin Huang, Yongbin Wang category:cs.MM cs.CV  published:2017-09-14 summary:In this paper, we propose a general framework to accelerate the universal histogram-based image contrast enhancement (CE) algorithms. Both spatial and gray-level selective down- sampling of digital images are adopted to decrease computational cost, while the visual quality of enhanced images is still preserved and without apparent degradation. Mapping function calibration is novelly proposed to reconstruct the pixel mapping on the gray levels missed by downsampling. As two case studies, accelerations of histogram equalization (HE) and the state-of-the-art global CE algorithm, i.e., spatial mutual information and PageRank (SMIRANK), are presented detailedly. Both quantitative and qualitative assessment results have verified the effectiveness of our proposed CE acceleration framework. In typical tests, computational efficiencies of HE and SMIRANK have been speeded up by about 3.9 and 13.5 times, respectively. version:1
arxiv-1709-04577 | DeepVoting: An Explainable Framework for Semantic Part Detection under Partial Occlusion | http://arxiv.org/abs/1709.04577 | id:1709.04577 author:Zhishuai Zhang, Cihang Xie, Jianyu Wang, Lingxi Xie, Alan L. Yuille category:cs.CV  published:2017-09-14 summary:In this paper, we study the task of detecting semantic parts of an object. This is very important in computer vision, as it provides the possibility to parse an object as human do, and helps us better understand object detection algorithms. Also, detecting semantic parts is very challenging especially when the parts are partially or fully occluded. In this scenario, the popular proposal-based methods like Faster-RCNN often produce unsatisfactory results, because both the proposal extraction and classification stages may be confused by the irrelevant occluders. To this end, we propose a novel detection framework, named DeepVoting, which accumulates local visual cues, called visual concepts (VC), to locate the semantic parts. Our approach involves adding two layers after the intermediate outputs of a deep neural network. The first layer is used to extract VC responses, and the second layer performs a voting mechanism to capture the spatial relationship between VC's and semantic parts. The benefit is that each semantic part is supported by multiple VC's. Even if some of the supporting VC's are missing due to occlusion, we can still infer the presence of the target semantic part using the remaining ones. To avoid generating an exponentially large training set to cover all occlusion cases, we train our model without seeing occlusion and transfer the learned knowledge to deal with occlusions. This setting favors learning the models which are naturally robust and adaptive to occlusions instead of over-fitting the occlusion patterns in the training data. In experiments, DeepVoting shows significantly better performance on semantic part detection in occlusion scenarios, compared with Faster-RCNN, with one order of magnitude fewer parameters and 2.5x testing speed. In addition, DeepVoting is explainable as the detection result can be diagnosed via looking up the voted VC's. version:1
arxiv-1709-04576 | Catalyst design using actively learned machine with non-ab initio input features towards CO2 reduction reactions | http://arxiv.org/abs/1709.04576 | id:1709.04576 author:Juhwan Noh, Jaehoon Kim, Seoin Back, Yousung Jung category:cond-mat.mtrl-sci physics.chem-ph stat.ML  published:2017-09-14 summary:In conventional chemisorption model, the d-band center theory (augmented sometimes with the upper edge of d-band for imporved accuarcy) plays a central role in predicting adsorption energies and catalytic activity as a function of d-band center of the solid surfaces, but it requires density functional calculations that can be quite costly for large scale screening purposes of materials. In this work, we propose to use the d-band width of the muffin-tin orbital theory (to account for local coordination environment) plus electronegativity (to account for adsorbate renormalization) as a simple set of alternative descriptors for chemisorption, which do not demand the ab initio calculations. This pair of descriptors are then combined with machine learning methods, namely, artificial neural network (ANN) and kernel ridge regression (KRR), to allow large scale materials screenings. We show, for a toy set of 263 alloy systems, that the CO adsorption energy can be predicted with a remarkably small mean absolute deviation error of 0.05 eV, a significantly improved result as compared to 0.13 eV obtained with descriptors including costly d-band center calculations in literature. We achieved this high accuracy by utilizing an active learning algorithm, without which the accuracy was 0.18 eV otherwise. As a practical application of this machine, we identified Cu3Y@Cu as a highly active and cost-effective electrochemical CO2 reduction catalyst to produce CO with the overpotential 0.37 V lower than Au catalyst. version:1
arxiv-1709-04570 | Learning Unknown Markov Decision Processes: A Thompson Sampling Approach | http://arxiv.org/abs/1709.04570 | id:1709.04570 author:Yi Ouyang, Mukul Gagrani, Ashutosh Nayyar, Rahul Jain category:cs.LG  published:2017-09-14 summary:We consider the problem of learning an unknown Markov Decision Process (MDP) that is weakly communicating in the infinite horizon setting. We propose a Thompson Sampling-based reinforcement learning algorithm with dynamic episodes (TSDE). At the beginning of each episode, the algorithm generates a sample from the posterior distribution over the unknown model parameters. It then follows the optimal stationary policy for the sampled model for the rest of the episode. The duration of each episode is dynamically determined by two stopping criteria. The first stopping criterion controls the growth rate of episode length. The second stopping criterion happens when the number of visits to any state-action pair is doubled. We establish $\tilde O(HS\sqrt{AT})$ bounds on expected regret under a Bayesian setting, where $S$ and $A$ are the sizes of the state and action spaces, $T$ is time, and $H$ is the bound of the span. This regret bound matches the best available bound for weakly communicating MDPs. Numerical results show it to perform better than existing algorithms for infinite horizon MDPs. version:1
arxiv-1708-03888 | Large Batch Training of Convolutional Networks | http://arxiv.org/abs/1708.03888 | id:1708.03888 author:Yang You, Igor Gitman, Boris Ginsburg category:cs.CV  published:2017-08-13 summary:A common way to speed up training of large convolutional networks is to add computational units. Training is then performed using data-parallel synchronous Stochastic Gradient Descent (SGD) with mini-batch divided between computational units. With an increase in the number of nodes, the batch size grows. But training with large batch size often results in the lower model accuracy. We argue that the current recipe for large batch training (linear learning rate scaling with warm-up) is not general enough and training may diverge. To overcome this optimization difficulties we propose a new training algorithm based on Layer-wise Adaptive Rate Scaling (LARS). Using LARS, we scaled Alexnet up to a batch size of 8K, and Resnet-50 to a batch size of 32K without loss in accuracy. version:3
arxiv-1709-04553 | MOLTE: a Modular Optimal Learning Testing Environment | http://arxiv.org/abs/1709.04553 | id:1709.04553 author:Yingfei Wang, Warren Powell category:cs.LG  published:2017-09-13 summary:We address the relative paucity of empirical testing of learning algorithms (of any type) by introducing a new public-domain, Modular, Optimal Learning Testing Environment (MOLTE) for Bayesian ranking and selection problem, stochastic bandits or sequential experimental design problems. The Matlab-based simulator allows the comparison of a number of learning policies (represented as a series of .m modules) in the context of a wide range of problems (each represented in its own .m module) which makes it easy to add new algorithms and new test problems. State-of-the-art policies and various problem classes are provided in the package. The choice of problems and policies is guided through a spreadsheet-based interface. Different graphical metrics are included. MOLTE is designed to be compatible with parallel computing to scale up from local desktop to clusters and clouds. We offer MOLTE as an easy-to-use tool for the research community that will make it possible to perform much more comprehensive testing, spanning a broader selection of algorithms and test problems. We demonstrate the capabilities of MOLTE through a series of comparisons of policies on a starter library of test problems. We also address the problem of tuning and constructing priors that have been largely overlooked in optimal learning literature. We envision MOLTE as a modest spur to provide researchers an easy environment to study interesting questions involved in optimal learning. version:1
arxiv-1709-05216 | Optimal Learning for Sequential Decision Making for Expensive Cost Functions with Stochastic Binary Feedbacks | http://arxiv.org/abs/1709.05216 | id:1709.05216 author:Yingfei Wang, Chu Wang, Warren Powell category:stat.ML  published:2017-09-13 summary:We consider the problem of sequentially making decisions that are rewarded by "successes" and "failures" which can be predicted through an unknown relationship that depends on a partially controllable vector of attributes for each instance. The learner takes an active role in selecting samples from the instance pool. The goal is to maximize the probability of success in either offline (training) or online (testing) phases. Our problem is motivated by real-world applications where observations are time-consuming and/or expensive. We develop a knowledge gradient policy using an online Bayesian linear classifier to guide the experiment by maximizing the expected value of information of labeling each alternative. We provide a finite-time analysis of the estimated error and show that the maximum likelihood estimator based produced by the KG policy is consistent and asymptotically normal. We also show that the knowledge gradient policy is asymptotically optimal in an offline setting. This work further extends the knowledge gradient to the setting of contextual bandits. We report the results of a series of experiments that demonstrate its efficiency. version:1
arxiv-1709-04550 | A Computational Model of Afterimages based on Simultaneous and Successive Contrasts | http://arxiv.org/abs/1709.04550 | id:1709.04550 author:Jinhui Yu, Kailin Wu, Kang Zhang, Xianjun Sam Zheng category:cs.CV q-bio.NC  published:2017-09-13 summary:Negative afterimage appears in our vision when we shift our gaze from an over stimulated original image to a new area with a uniform color. The colors of negative afterimages differ from the old stimulating colors in the original image when the color in the new area is either neutral or chromatic. The interaction between stimulating colors in the test and inducing field in the original image changes our color perception due to simultaneous contrast, and the interaction between changed colors perceived in the previously-viewed field and the color in the currently-viewed field also affects our perception of colors in negative afterimages due to successive contrast. Based on these observations we propose a computational model to estimate colors of negative afterimages in more general cases where the original stimulating color in the test field is chromatic, and the original stimulating color in the inducing field and the new stimulating color can be either neutral or chromatic. We validate our model with human experiments. version:1
arxiv-1709-04549 | Ignoring Distractors in the Absence of Labels: Optimal Linear Projection to Remove False Positives During Anomaly Detection | http://arxiv.org/abs/1709.04549 | id:1709.04549 author:Allison Del Giorno, J. Andrew Bagnell, Martial Hebert category:cs.LG  published:2017-09-13 summary:In the anomaly detection setting, the native feature embedding can be a crucial source of bias. We present a technique, Feature Omission using Context in Unsupervised Settings (FOCUS) to learn a feature mapping that is invariant to changes exemplified in training sets while retaining as much descriptive power as possible. While this method could apply to many unsupervised settings, we focus on applications in anomaly detection, where little task-labeled data is available. Our algorithm requires only non-anomalous sets of data, and does not require that the contexts in the training sets match the context of the test set. By maximizing within-set variance and minimizing between-set variance, we are able to identify and remove distracting features while retaining fidelity to the descriptiveness needed at test time. In the linear case, our formulation reduces to a generalized eigenvalue problem that can be solved quickly and applied to test sets outside the context of the training sets. This technique allows us to align technical definitions of anomaly detection with human definitions through appropriate mappings of the feature space. We demonstrate that this method is able to remove uninformative parts of the feature space for the anomaly detection setting. version:1
arxiv-1709-04546 | Normalized Direction-preserving Adam | http://arxiv.org/abs/1709.04546 | id:1709.04546 author:Zijun Zhang, Lin Ma, Zongpeng Li, Chuan Wu category:cs.LG stat.ML  published:2017-09-13 summary:Optimization algorithms for training deep models not only affects the convergence rate and stability of the training process, but are also highly related to the generalization performance of the models. While adaptive algorithms, such as Adam and RMSprop, have shown better optimization performance than stochastic gradient descent (SGD) in many scenarios, they often lead to worse generalization performance than SGD, when used for training deep neural networks (DNNs). In this work, we identify two problems of Adam that may degrade the generalization performance. As a solution, we propose the normalized direction-preserving Adam (ND-Adam) algorithm, which combines the best of both worlds, i.e., the good optimization performance of Adam, and the good generalization performance of SGD. In addition, we further improve the generalization performance in classification tasks, by using batch-normalized softmax. This study suggests the need for more precise control over the training process of DNNs. version:1
arxiv-1708-02973 | Learning Policies for Adaptive Tracking with Deep Feature Cascades | http://arxiv.org/abs/1708.02973 | id:1708.02973 author:Chen Huang, Simon Lucey, Deva Ramanan category:cs.CV  published:2017-08-09 summary:Visual object tracking is a fundamental and time-critical vision task. Recent years have seen many shallow tracking methods based on real-time pixel-based correlation filters, as well as deep methods that have top performance but need a high-end GPU. In this paper, we learn to improve the speed of deep trackers without losing accuracy. Our fundamental insight is to take an adaptive approach, where easy frames are processed with cheap features (such as pixel values), while challenging frames are processed with invariant but expensive deep features. We formulate the adaptive tracking problem as a decision-making process, and learn an agent to decide whether to locate objects with high confidence on an early layer, or continue processing subsequent layers of a network. This significantly reduces the feed-forward cost for easy frames with distinct or slow-moving objects. We train the agent offline in a reinforcement learning fashion, and further demonstrate that learning all deep layers (so as to provide good features for adaptive tracking) can lead to near real-time average tracking speed of 23 fps on a single CPU while achieving state-of-the-art performance. Perhaps most tellingly, our approach provides a 100X speedup for almost 50% of the time, indicating the power of an adaptive approach. version:2
arxiv-1708-00260 | Deep Asymmetric Multi-task Feature Learning | http://arxiv.org/abs/1708.00260 | id:1708.00260 author:Hae Beom Lee, Eunho Yang, Sung Ju Hwang category:cs.LG stat.ML  published:2017-08-01 summary:We propose Deep Asymmetric Multitask Feature Learning (Deep-AMTFL) which can learn deep representations shared across multiple tasks while effectively preventing negative transfer that may happen in the feature sharing process. Specifically, we introduce an asymmetric autoencoder term that allows reliable predictors for the easy tasks to have high contribution to the feature learning while suppressing the influences of unreliable predictors for more difficult tasks. This allows the learning of less noisy representations, and enables unreliable predictors to exploit knowledge from the reliable predictors via the shared latent features. Such asymmetric knowledge transfer through shared features is also more scalable and efficient than inter-task asymmetric transfer. We validate our Deep-AMTFL model on multiple benchmark datasets for multitask learning and image classification, on which it significantly outperforms existing symmetric and asymmetric multitask learning models, by effectively preventing negative transfer in deep feature learning. version:2
arxiv-1709-03199 | 3D Densely Convolutional Networks for Volumetric Segmentation | http://arxiv.org/abs/1709.03199 | id:1709.03199 author:Toan Duc Bui, Jitae Shin, Taesup Moon category:cs.CV  published:2017-09-11 summary:In the isointense stage, the accurate volumetric image segmentation is a challenging task due to the low contrast between tissues. In this paper, we propose a novel very deep network architecture based on a densely convolutional network for volumetric brain segmentation. The proposed network architecture provides a dense connection between layers that aims to improve the information flow in the network. By concatenating features map of fine and coarse dense blocks, it allows capturing multi-scale contextual information. Experimental results demonstrate significant advantages of the proposed method over existing methods, in terms of both segmentation accuracy and parameter efficiency in MICCAI grand challenge on 6-month infant brain MRI segmentation. version:2
arxiv-1709-04491 | Method for Aspect-Based Sentiment Annotation Using Rhetorical Analysis | http://arxiv.org/abs/1709.04491 | id:1709.04491 author:Łukasz Augustyniak, Krzysztof Rajda, Tomasz Kajdanowicz category:cs.CL 68T50 I.2.7  published:2017-09-13 summary:This paper fills a gap in aspect-based sentiment analysis and aims to present a new method for preparing and analysing texts concerning opinion and generating user-friendly descriptive reports in natural language. We present a comprehensive set of techniques derived from Rhetorical Structure Theory and sentiment analysis to extract aspects from textual opinions and then build an abstractive summary of a set of opinions. Moreover, we propose aspect-aspect graphs to evaluate the importance of aspects and to filter out unimportant ones from the summary. Additionally, the paper presents a prototype solution of data flow with interesting and valuable results. The proposed method's results proved the high accuracy of aspect detection when applied to the gold standard dataset. version:1
arxiv-1709-04482 | Analyzing Hidden Representations in End-to-End Automatic Speech Recognition Systems | http://arxiv.org/abs/1709.04482 | id:1709.04482 author:Yonatan Belinkov, James Glass category:cs.CL cs.NE cs.SD I.2.7  published:2017-09-13 summary:Neural models have become ubiquitous in automatic speech recognition systems. While neural networks are typically used as acoustic models in more complex systems, recent studies have explored end-to-end speech recognition systems based on neural networks, which can be trained to directly predict text from input acoustic features. Although such systems are conceptually elegant and simpler than traditional systems, it is less obvious how to interpret the trained models. In this work, we analyze the speech representations learned by a deep end-to-end model that is based on convolutional and recurrent layers, and trained with a connectionist temporal classification (CTC) loss. We use a pre-trained model to generate frame-level features which are given to a classifier that is trained on frame classification into phones. We evaluate representations from different layers of the deep model and compare their quality for predicting phone labels. Our experiments shed light on important aspects of the end-to-end model such as layer depth, model complexity, and other design choices. version:1
arxiv-1709-03545 | Learning Graph Topological Features via GAN | http://arxiv.org/abs/1709.03545 | id:1709.03545 author:Weiyi Liu, Hal Cooper, Min Hwan Oh, Sailung Yeung, Pin-Yu Chen, Toyotaro Suzumura, Lingli Chen category:cs.SI cs.LG  published:2017-09-11 summary:Inspired by the generation power of generative adversarial networks (GANs) in image domains, we introduce a novel hierarchical architecture for learning characteristic topological features from a single arbitrary input graph via GANs. The hierarchical architecture consisting of multiple GANs preserves both local and global topological features and automatically partitions the input graph into representative stages for feature learning. The stages facilitate reconstruction and can be used as indicators of the importance of the associated topological structures. Experiments show that our method produces subgraphs retaining a wide range of topological features, even in early reconstruction stages (unlike a single GAN, which cannot easily identify such features, let alone reconstruct the original graph). This paper is firstline research on combining the use of GANs and graph topological analysis. version:2
arxiv-1709-04481 | Network Classification and Categorization | http://arxiv.org/abs/1709.04481 | id:1709.04481 author:James P. Canning, Emma E. Ingram, Sammantha Nowak-Wolff, Adriana M. Ortiz, Nesreen K. Ahmed, Ryan A. Rossi, Karl R. B. Schmitt, Sucheta Soundarajan category:cs.SI cs.DL stat.ML  published:2017-09-13 summary:To the best of our knowledge, this paper presents the first large-scale study that tests whether network categories (e.g., social networks vs. web graphs) are distinguishable from one another (using both categories of real-world networks and synthetic graphs). A classification accuracy of $94.2\%$ was achieved using a random forest classifier with both real and synthetic networks. This work makes two important findings. First, real-world networks from various domains have distinct structural properties that allow us to predict with high accuracy the category of an arbitrary network. Second, classifying synthetic networks is trivial as our models can easily distinguish between synthetic graphs and the real-world networks they are supposed to model. version:1
arxiv-1709-02848 | Improving Heterogeneous Face Recognition with Conditional Adversarial Networks | http://arxiv.org/abs/1709.02848 | id:1709.02848 author:Wuming Zhang, Zhixin Shu, Dimitris Samaras, Liming Chen category:cs.CV  published:2017-09-08 summary:Heterogeneous face recognition between color image and depth image is a much desired capacity for real world applications where shape information is looked upon as merely involved in gallery. In this paper, we propose a cross-modal deep learning method as an effective and efficient workaround for this challenge. Specifically, we begin with learning two convolutional neural networks (CNNs) to extract 2D and 2.5D face features individually. Once trained, they can serve as pre-trained models for another two-way CNN which explores the correlated part between color and depth for heterogeneous matching. Compared with most conventional cross-modal approaches, our method additionally conducts accurate depth image reconstruction from single color image with Conditional Generative Adversarial Nets (cGAN), and further enhances the recognition performance by fusing multi-modal matching results. Through both qualitative and quantitative experiments on benchmark FRGC 2D/3D face database, we demonstrate that the proposed pipeline outperforms state-of-the-art performance on heterogeneous face recognition and ensures a drastically efficient on-line stage. version:2
arxiv-1709-04451 | Alternating minimization and alternating descent over nonconvex sets | http://arxiv.org/abs/1709.04451 | id:1709.04451 author:Wooseok Ha, Rina Foygel Barber category:math.OC stat.ML  published:2017-09-13 summary:Many optimization problems in high-dimensional statistics and signal processing involve more than one decision variable to be minimized, where the variables often reflect different structures or components within the signals being considered. Alternating minimization is a widely used method for solving such optimization problems, but the general properties of alternating minimization has not yet been understood well in some settings. In this work, we study and analyze the performance of alternating minimization under the setting where the loss function is optimized over two variables and each variable is restricted to its own constraint set - in particular, we allow these constraints to be potentially nonconvex. Our analysis depends strongly on the notion of local concavity coefficients, which have been recently proposed in Barber and Ha [2017] to measure and quantify the concavity of a general nonconvex set. Our results further reveal important distinctions between alternating and non-alternating methods. Since computing the alternating minimization steps may not be tractable for some problems, we also consider an inexact version of the algorithm and provide a set of sufficient conditions to ensure fast convergence of the inexact algorithms. We demonstrate our framework on two important examples of this type of problem, low rank + sparse decomposition and multitask regression, and provide numerical experiments to validate our theoretical results. version:1
arxiv-1709-04427 | Contrast Enhancement of Brightness-Distorted Images by Improved Adaptive Gamma Correction | http://arxiv.org/abs/1709.04427 | id:1709.04427 author:Gang Cao, Lihui Huang, Huawei Tian, Xianglin Huang, Yongbin Wang, Ruicong Zhi category:cs.MM cs.CV  published:2017-09-13 summary:As an efficient image contrast enhancement (CE) tool, adaptive gamma correction (AGC) was previously proposed by relating gamma parameter with cumulative distribution function (CDF) of the pixel gray levels within an image. ACG deals well with most dimmed images, but fails for globally bright images and the dimmed images with local bright regions. Such two categories of brightness-distorted images are universal in real scenarios, such as improper exposure and white object regions. In order to attenuate such deficiencies, here we propose an improved AGC algorithm. The novel strategy of negative images is used to realize CE of the bright images, and the gamma correction modulated by truncated CDF is employed to enhance the dimmed ones. As such, local over-enhancement and structure distortion can be alleviated. Both qualitative and quantitative experimental results show that our proposed method yields consistently good CE results. version:1
arxiv-1709-04412 | Merge and Select: Visualization of a likelihood based k-sample adaptive fusing and model selection | http://arxiv.org/abs/1709.04412 | id:1709.04412 author:Agnieszka Sitko, Przemyslaw Biecek category:stat.ML cs.HC stat.ME  published:2017-09-13 summary:In this article we introduce Merge and Select - a methodology - and factorMerger - an R package - for exploration and visualization of k-group comparisons. Comparison of k-groups is one of the most important issues in exploratory analyses and it has zillions of applications. The classical solution is to test a null hypothesis that observations from all groups come from the same distribution. If the global null hypothesis is rejected a more detailed analysis of differences among pairs of groups is performed. The traditional approach is to use pairwise post hoc tests in order to verify which groups differ significantly. However, this approach fails with large number of groups in both interpretation and visualization layer. The Merge and Select methodology solves this problem by using easy to understand description of LRT based similarity among groups. version:1
arxiv-1709-04411 | Exploiting skeletal structure in computer vision annotation with Benders decomposition | http://arxiv.org/abs/1709.04411 | id:1709.04411 author:Shaofei Wang, Konrad Kording, Julian Yarkony category:cs.CV  published:2017-09-13 summary:Many annotation problems in computer vision can be phrased as integer linear programs (ILPs). The use of standard industrial solvers does not to exploit the underlying structure of such problems eg, the skeleton in pose estimation. The leveraging of the underlying structure in conjunction with industrial solvers promises increases in both speed and accuracy. Such structure can be exploited using Bender's decomposition, a technique from operations research, that solves complex ILPs or mixed integer linear programs by decomposing them into sub-problems that communicate via a master problem. The intuition is that conditioned on a small subset of the variables the solution to the remaining variables can be computed easily by taking advantage of properties of the ILP constraint matrix such as block structure. In this paper we apply Benders decomposition to a typical problem in computer vision where we have many sub-ILPs (eg, partitioning of detections, body-parts) coupled to a master ILP (eg, constructing skeletons). Dividing inference problems into a master problem and sub-problems motivates the development of a plethora of novel models, and inference approaches for the field of computer vision. version:1
arxiv-1709-04409 | A Review of Evaluation Techniques for Social Dialogue Systems | http://arxiv.org/abs/1709.04409 | id:1709.04409 author:Amanda Cercas Curry, Helen Hastie, Verena Rieser category:cs.CL 68T50  published:2017-09-13 summary:In contrast with goal-oriented dialogue, social dialogue has no clear measure of task success. Consequently, evaluation of these systems is notoriously hard. In this paper, we review current evaluation methods, focusing on automatic metrics. We conclude that turn-based metrics often ignore the context and do not account for the fact that several replies are valid, while end-of-dialogue rewards are mainly hand-crafted. Both lack grounding in human perceptions. version:1
arxiv-1709-04402 | On Early-stage Debunking Rumors on Twitter: Leveraging the Wisdom of Weak Learners | http://arxiv.org/abs/1709.04402 | id:1709.04402 author:Tu Ngoc Nguyen, Cheng Li, Claudia Niederée category:cs.SI cs.LG  published:2017-09-13 summary:Recently a lot of progress has been made in rumor modeling and rumor detection for micro-blogging streams. However, existing automated methods do not perform very well for early rumor detection, which is crucial in many settings, e.g., in crisis situations. One reason for this is that aggregated rumor features such as propagation features, which work well on the long run, are - due to their accumulating characteristic - not very helpful in the early phase of a rumor. In this work, we present an approach for early rumor detection, which leverages Convolutional Neural Networks for learning the hidden representations of individual rumor-related tweets to gain insights on the credibility of each tweets. We then aggregate the predictions from the very beginning of a rumor to obtain the overall event credits (so-called wisdom), and finally combine it with a time series based rumor classification model. Our extensive experiments show a clearly improved classification performance within the critical very first hours of a rumor. For a better understanding, we also conduct an extensive feature evaluation that emphasized on the early stage and shows that the low-level credibility has best predictability at all phases of the rumor lifetime. version:1
arxiv-1709-04396 | A Tutorial on Deep Learning for Music Information Retrieval | http://arxiv.org/abs/1709.04396 | id:1709.04396 author:Keunwoo Choi, György Fazekas, Kyunghyun Cho, Mark Sandler category:cs.CV cs.SD  published:2017-09-13 summary:Following their success in Computer Vision and other areas, deep learning techniques have recently become widely adopted in Music Information Retrieval (MIR) research. However, the majority of works aim to adopt and assess methods that have been shown to be effective in other domains, while there is still a great need for more original research focusing on music primarily and utilising musical knowledge and insight. The goal of this paper is to boost the interest of beginners by providing a comprehensive tutorial and reducing the barriers to entry into deep learning for MIR. We lay out the basic principles and review prominent works in this hard to navigate field. We then outline the network structures that have been successful in MIR problems and facilitate the selection of building blocks for the problems at hand. Finally, guidelines for new tasks and some advanced topics in deep learning are discussed to stimulate new research in this fascinating field. version:1
arxiv-1709-04395 | Tight Semi-Nonnegative Matrix Factorization | http://arxiv.org/abs/1709.04395 | id:1709.04395 author:David W Dreisigmeyer category:stat.ML cs.LG  published:2017-09-13 summary:The nonnegative matrix factorization is a widely used, flexible matrix decomposition, finding applications in biology, image and signal processing and information retrieval, among other areas. Here we present a related matrix factorization. A multi-objective optimization problem finds conical combinations of templates that approximate a given data matrix. The templates are chosen so that as far as possible only the initial data set can be represented this way. However, the templates are not required to be nonnegative nor convex combinations of the original data. version:1
arxiv-1709-04393 | An Efficient Evolutionary Based Method For Image Segmentation | http://arxiv.org/abs/1709.04393 | id:1709.04393 author:Kazem Qazanfari, Reza Aslanzadeh, Mohammad Rahmati category:cs.CV  published:2017-09-13 summary:The goal of this paper is to present a new efficient image segmentation method based on evolutionary computation which is a model inspired from human behavior. Based on this model, a four layer process for image segmentation is proposed using the split/merge approach. In the first layer, an image is split into numerous regions using the watershed algorithm. In the second layer, a co-evolutionary process is applied to form centers of finals segments by merging similar primary regions. In the third layer, a meta-heuristic process uses two operators to connect the residual regions to their corresponding determined centers. In the final layer, an evolutionary algorithm is used to combine the resulted similar and neighbor regions. Different layers of the algorithm are totally independent, therefore for certain applications a specific layer can be changed without constraint of changing other layers. Some properties of this algorithm like the flexibility of its method, the ability to use different feature vectors for segmentation (grayscale, color, texture, etc), the ability to control uniformity and the number of final segments using free parameters and also maintaining small regions, makes it possible to apply the algorithm to different applications. Moreover, the independence of each region from other regions in the second layer, and the independence of centers in the third layer, makes parallel implementation possible. As a result the algorithm speed will increase. The presented algorithm was tested on a standard dataset (BSDS 300) of images, and the region boundaries were compared with different people segmentation contours. Results show the efficiency of the algorithm and its improvement to similar methods. As an instance, in 70% of tested images, results are better than ACT algorithm, besides in 100% of tested images, we had better results in comparison with VSP algorithm. version:1
arxiv-1709-08470 | An efficient clustering algorithm from the measure of local Gaussian distribution | http://arxiv.org/abs/1709.08470 | id:1709.08470 author:Yuan-Yen Tai category:cs.DB cs.LG  published:2017-09-13 summary:In this paper, I will introduce a fast and novel clustering algorithm based on Gaussian distribution and it can guarantee the separation of each cluster centroid as a given parameter, $d_s$. The worst run time complexity of this algorithm is approximately $\sim$O$(T\times N \times \log(N))$ where $T$ is the iteration steps and $N$ is the number of features. version:1
arxiv-1709-04384 | Similarity Embedding Network for Unsupervised Sequential Pattern Learning by Playing Music Puzzle Games | http://arxiv.org/abs/1709.04384 | id:1709.04384 author:Yu-Siang Huang, Szu-Yu Chou, Yi-Hsuan Yang category:stat.ML cs.LG cs.SD  published:2017-09-13 summary:Real-world time series data are rich in sequential and structural patterns. Music, for example, often have a multi-level organization of musical events, with higher-level building blocks made up of smaller recurrent patterns. For computers to understand and process such time series data, we need a mechanism to uncover the underlying structure. Toward this goal, we propose and formulate a number of music puzzle games to test the ability of contemporary neural network models to mine sequential patterns. In essence, these games require a model to correctly sort a few multisecond, nonoverlapping music fragments, either from the same song or not. In the training stage, we learn the model by sampling multiple fragment pairs from the same songs and seeking to predict whether a given pair is consecutive and is in correct chronological order. As no manual labels are needed, it is an unsupervised (more specifically, self-supervised) learning problem. On the basis of state-of-the-art Siamese convolutional network, we propose an improved architecture that learns to embed frame-level similarity scores computed from the input fragment pairs into a common space, where fragment pairs of different types can be more easily distinguished. Our experiments show that the resulting model, dubbed as the similarity embedding network (SEN), performs better than competing models across different games, including music jigsaw puzzle, music sequencing, and music medley. version:1
arxiv-1709-01599 | Deep Ordinal Ranking for Multi-Category Diagnosis of Alzheimer's Disease using Hippocampal MRI data | http://arxiv.org/abs/1709.01599 | id:1709.01599 author:Hongming Li, Mohamad Habes, Yong Fan category:cs.CV  published:2017-09-05 summary:Increasing effort in brain image analysis has been dedicated to early diagnosis of Alzheimer's disease (AD) based on neuroimaging data. Most existing studies have been focusing on binary classification problems, e.g., distinguishing AD patients from normal control (NC) elderly or mild cognitive impairment (MCI) individuals from NC elderly. However, identifying individuals with AD and MCI, especially MCI individuals who will convert to AD (progressive MCI, pMCI), in a single setting, is needed to achieve the goal of early diagnosis of AD. In this paper, we propose a deep ordinal ranking model for distinguishing NC, stable MCI (sMCI), pMCI, and AD at an individual subject level, taking into account the inherent ordinal severity of brain degeneration caused by normal aging, MCI, and AD, rather than formulating the classification as a multi-category classification problem. The proposed deep ordinal ranking model focuses on the hippocampal morphology of individuals and learns informative and discriminative features automatically. Experiment results based on a large cohort of individuals from the Alzheimer's Disease Neuroimaging Initiative (ADNI) indicate that the proposed method can achieve better performance than traditional multi-category classification techniques using shape and radiomics features from structural magnetic resonance imaging (MRI) data. version:2
arxiv-1709-04359 | Linguistic Features of Genre and Method Variation in Translation: A Computational Perspective | http://arxiv.org/abs/1709.04359 | id:1709.04359 author:Ekaterina Lapshninova-Koltunski, Marcos Zampieri category:cs.CL  published:2017-09-13 summary:In this paper we describe the use of text classification methods to investigate genre and method variation in an English - German translation corpus. For this purpose we use linguistically motivated features representing texts using a combination of part-of-speech tags arranged in bigrams, trigrams, and 4-grams. The classification method used in this paper is a Bayesian classifier with Laplace smoothing. We use the output of the classifiers to carry out an extensive feature analysis on the main difference between genres and methods of translation. version:1
arxiv-1709-04348 | Natural Language Inference over Interaction Space | http://arxiv.org/abs/1709.04348 | id:1709.04348 author:Yichen Gong, Heng Luo, Jian Zhang category:cs.CL  published:2017-09-13 summary:Natural Language Inference (NLI) task requires an agent to determine the logical relationship between a natural language premise and a natural language hypothesis. We introduce Interactive Inference Network (IIN), a novel class of neural network architectures that is able to achieve high-level understanding of the sentence pair by hierarchically extracting semantic features from interaction space. We show that an interaction tensor (attention weight) contains semantic information to solve natural language inference, and a denser interaction tensor contains richer semantic information. One instance of such architecture, Densely Interactive Inference Network (DIIN), demonstrates the state-of-the-art performance on large scale NLI copora and large-scale NLI alike corpus. It's noteworthy that DIIN achieve a greater than 20% error reduction on the challenging Multi-Genre NLI (MultiNLI) dataset with respect to the strongest published system. version:1
arxiv-1709-04347 | Zoom Out-and-In Network with Map Attention Decision for Region Proposal and Object Detection | http://arxiv.org/abs/1709.04347 | id:1709.04347 author:Hongyang Li, Yu Liu, Wanli Ouyang, Xiaogang Wang category:cs.CV  published:2017-09-13 summary:In this paper, we propose a zoom-out-and-in network for generating object proposals. A key observation is that it is difficult to classify anchors of different sizes with the same set of features. Anchors of different sizes should be placed accordingly based on different depth within a network: smaller boxes on high-resolution layers with a smaller stride while larger boxes on low-resolution counterparts with a larger stride. Inspired by the conv/deconv structure, we fully leverage the low-level local details and high-level regional semantics from two feature map streams, which are complimentary to each other, to identify the objectness in an image. A map attention decision (MAD) unit is further proposed to aggressively search for neuron activations among two streams and attend the most contributive ones on the feature learning of the final loss. The unit serves as a decision maker to adaptively activate maps along certain channels with the solely purpose of optimizing the overall training loss. One advantage of MAD is that the learned weights enforced on each feature channel is predicted on-the-fly based on the input context, which is more suitable than the fixed enforcement of a convolutional kernel. Experimental results on three datasets demonstrate the effectiveness of our proposed algorithm over other state-of-the-arts, in terms of average recall for region proposal and average precision for object detection. version:1
arxiv-1709-04344 | Flexible Network Binarization with Layer-wise Priority | http://arxiv.org/abs/1709.04344 | id:1709.04344 author:Lixue Zhuang, Yi Xu, Bingbing Ni, Hongteng Xu category:cs.CV  published:2017-09-13 summary:How to effectively approximate real-valued parameters with binary codes plays a central role in neural network binarization. In this work, we reveal an important fact that binarizing different layers has a widely-varied effect on the compression ratio of network and the loss of performance. Based on this fact, we propose a novel and flexible neural network binarization method by introducing the concept of layer-wise priority which binarizes parameters in inverse order of their layer depth. In each training step, our method selects a specific network layer, minimizes the discrepancy between the original real-valued weights and its binary approximations, and fine-tunes the whole network accordingly. During the iteration of the above process, it is significant that we can flexibly decide whether to binarize the remaining floating layers or not and explore a trade-off between the loss of performance and the compression ratio of model. The resulting binary network is applied for efficient pedestrian detection. Extensive experimental results on several benchmarks show that under the same compression ratio, our method achieves much lower miss rate and faster detection speed than the state-of-the-art neural network binarization method. version:1
arxiv-1709-04329 | GLAD: Global-Local-Alignment Descriptor for Pedestrian Retrieval | http://arxiv.org/abs/1709.04329 | id:1709.04329 author:Longhui Wei, Shiliang Zhang, Hantao Yao, Wen Gao, Qi Tian category:cs.CV  published:2017-09-13 summary:The huge variance of human pose and the misalignment of detected human images significantly increase the difficulty of person Re-Identification (Re-ID). Moreover, efficient Re-ID systems are required to cope with the massive visual data being produced by video surveillance systems. Targeting to solve these problems, this work proposes a Global-Local-Alignment Descriptor (GLAD) and an efficient indexing and retrieval framework, respectively. GLAD explicitly leverages the local and global cues in human body to generate a discriminative and robust representation. It consists of part extraction and descriptor learning modules, where several part regions are first detected and then deep neural networks are designed for representation learning on both the local and global regions. A hierarchical indexing and retrieval framework is designed to eliminate the huge redundancy in the gallery set, and accelerate the online Re-ID procedure. Extensive experimental results show GLAD achieves competitive accuracy compared to the state-of-the-art methods. Our retrieval framework significantly accelerates the online Re-ID procedure without loss of accuracy. Therefore, this work has potential to work better on person Re-ID tasks in real scenarios. version:1
arxiv-1709-03842 | ExprGAN: Facial Expression Editing with Controllable Expression Intensity | http://arxiv.org/abs/1709.03842 | id:1709.03842 author:Hui Ding, Kumar Sricharan, Rama Chellappa category:cs.CV  published:2017-09-12 summary:Facial expression editing is a challenging task as it needs a high-level semantic understanding of the input face image. In conventional methods, either paired training data is required or the synthetic face resolution is low. Moreover, only the categories of facial expression can be changed. To address these limitations, we propose an Expression Generative Adversarial Network (ExprGAN) for photo-realistic facial expression editing with controllable expression intensity. An expression controller module is specially designed to learn an expressive and compact expression code in addition to the encoder-decoder network. This novel architecture enables the expression intensity to be continuously adjusted from low to high. We further show that our ExprGAN can be applied for other tasks, such as expression transfer, image retrieval, and data augmentation for training improved face expression recognition models. To tackle the small size of the training database, an effective incremental learning scheme is proposed. Quantitative and qualitative evaluations on the widely used Oulu-CASIA dataset demonstrate the effectiveness of ExprGAN. version:2
arxiv-1709-03851 | A Deep Cascade Network for Unaligned Face Attribute Classification | http://arxiv.org/abs/1709.03851 | id:1709.03851 author:Hui Ding, Hao Zhou, Shaohua Kevin Zhou, Rama Chellappa category:cs.CV  published:2017-09-12 summary:Humans focus attention on different face regions when recognizing face attributes. Most existing face attribute classification methods use the whole image as input. Moreover, some of these methods rely on fiducial landmarks to provide defined face parts. In this paper, we propose a cascade network that simultaneously learns to localize face regions specific to attributes and performs attribute classification without alignment. First, a weakly-supervised face region localization network is designed to automatically detect regions (or parts) specific to attributes. Then multiple part-based networks and a whole-image-based network are separately constructed and combined together by the region switch layer and attribute relation layer for final attribute classification. A multi-net learning method and hint-based model compression is further proposed to get an effective localization model and a compact classification model, respectively. Our approach achieves significantly better performance than state-of-the-art methods on unaligned CelebA dataset, reducing the classification error by 30.9%. version:2
arxiv-1709-04303 | Reading Scene Text with Attention Convolutional Sequence Modeling | http://arxiv.org/abs/1709.04303 | id:1709.04303 author:Yunze Gao, Yingying Chen, Jinqiao Wang, Hanqing Lu category:cs.CV  published:2017-09-13 summary:Reading text in the wild is a challenging task in the field of computer vision. Existing approaches mainly adopted Connectionist Temporal Classification (CTC) or Attention models based on Recurrent Neural Network (RNN), which is computationally expensive and hard to train. In this paper, we present an end-to-end Attention Convolutional Network for scene text recognition. Firstly, instead of RNN, we adopt the stacked convolutional layers to effectively capture the contextual dependencies of the input sequence, which is characterized by lower computational complexity and easier parallel computation. Compared to the chain structure of recurrent networks, the Convolutional Neural Network (CNN) provides a natural way to capture long-term dependencies between elements, which is 9 times faster than Bidirectional Long Short-Term Memory (BLSTM). Furthermore, in order to enhance the representation of foreground text and suppress the background noise, we incorporate the residual attention modules into a small densely connected network to improve the discriminability of CNN features. We validate the performance of our approach on the standard benchmarks, including the Street View Text, IIIT5K and ICDAR datasets. As a result, state-of-the-art or highly-competitive performance and efficiency show the superiority of the proposed approach. version:1
arxiv-1709-04299 | A Survey of Calibration Methods for Optical See-Through Head-Mounted Displays | http://arxiv.org/abs/1709.04299 | id:1709.04299 author:Jens Grubert, Yuta Itoh, Kenneth Moser, J. Edward Swan II category:cs.HC cs.CV  published:2017-09-13 summary:Optical see-through head-mounted displays (OST HMDs) are a major output medium for Augmented Reality, which have seen significant growth in popularity and usage among the general public due to the growing release of consumer-oriented models, such as the Microsoft Hololens. Unlike Virtual Reality headsets, OST HMDs inherently support the addition of computer-generated graphics directly into the light path between a user's eyes and their view of the physical world. As with most Augmented and Virtual Reality systems, the physical position of an OST HMD is typically determined by an external or embedded 6-Degree-of-Freedom tracking system. However, in order to properly render virtual objects, which are perceived as spatially aligned with the physical environment, it is also necessary to accurately measure the position of the user's eyes within the tracking system's coordinate frame. For over 20 years, researchers have proposed various calibration methods to determine this needed eye position. However, to date, there has not been a comprehensive overview of these procedures and their requirements. Hence, this paper surveys the field of calibration methods for OST HMDs. Specifically, it provides insights into the fundamentals of calibration techniques, and presents an overview of both manual and automatic approaches, as well as evaluation methods and metrics. Finally, it also identifies opportunities for future research. % relative to the tracking coordinate system, and, hence, its position in 3D space. version:1
arxiv-1709-04295 | Densely tracking sequences of 3D face scans | http://arxiv.org/abs/1709.04295 | id:1709.04295 author:Huaxiong Ding, Liming Chen category:cs.CV  published:2017-09-13 summary:3D face dense tracking aims to find dense inter-frame correspondences in a sequence of 3D face scans and constitutes a powerful tool for many face analysis tasks, e.g., 3D dynamic facial expression analysis. The majority of the existing methods just fit a 3D face surface or model to a 3D target surface without considering temporal information between frames. In this paper, we propose a novel method for densely tracking sequences of 3D face scans, which ex- tends the non-rigid ICP algorithm by adding a novel specific criterion for temporal information. A novel fitting framework is presented for automatically tracking a full sequence of 3D face scans. The results of experiments carried out on the BU4D-FE database are promising, showing that the proposed algorithm outperforms state-of-the-art algorithms for 3D face dense tracking. version:1
arxiv-1709-04264 | Flexible End-to-End Dialogue System for Knowledge Grounded Conversation | http://arxiv.org/abs/1709.04264 | id:1709.04264 author:Wenya Zhu, Kaixiang Mo, Yu Zhang, Zhangbin Zhu, Xuezheng Peng, Qiang Yang category:cs.CL  published:2017-09-13 summary:In knowledge grounded conversation, domain knowledge plays an important role in a special domain such as Music. The response of knowledge grounded conversation might contain multiple answer entities or no entity at all. Although existing generative question answering (QA) systems can be applied to knowledge grounded conversation, they either have at most one entity in a response or cannot deal with out-of-vocabulary entities. We propose a fully data-driven generative dialogue system GenDS that is capable of generating responses based on input message and related knowledge base (KB). To generate arbitrary number of answer entities even when these entities never appear in the training set, we design a dynamic knowledge enquirer which selects different answer entities at different positions in a single response, according to different local context. It does not rely on the representations of entities, enabling our model deal with out-of-vocabulary entities. We collect a human-human conversation data (ConversMusic) with knowledge annotations. The proposed method is evaluated on CoversMusic and a public question answering dataset. Our proposed GenDS system outperforms baseline methods significantly in terms of the BLEU, entity accuracy, entity recall and human evaluation. Moreover,the experiments also demonstrate that GenDS works better even on small datasets. version:1
arxiv-1709-09528 | A New Multifocus Image Fusion Method Using Contourlet Transform | http://arxiv.org/abs/1709.09528 | id:1709.09528 author:Fatemeh Vakili Moghadam, Hamid Reza Shahdoosti category:cs.CV  published:2017-09-13 summary:A new multifocus image fusion approach is presented in this paper. First the contourlet transform is used to decompose the source images into different components. Then, some salient features are extracted from components. In order to extract salient features, spatial frequency is used. Subsequently, the best coefficients from the components are selected by the maximum selection rule. Finally, the inverse contourlet transform is applied to the selected coefficients. Experiments show the superiority of the proposed method. version:1
arxiv-1704-07203 | What is the Essence of a Claim? Cross-Domain Claim Identification | http://arxiv.org/abs/1704.07203 | id:1704.07203 author:Johannes Daxenberger, Steffen Eger, Ivan Habernal, Christian Stab, Iryna Gurevych category:cs.CL  published:2017-04-24 summary:Argument mining has become a popular research area in NLP. It typically includes the identification of argumentative components, e.g. claims, as the central component of an argument. We perform a qualitative analysis across six different datasets and show that these appear to conceptualize claims quite differently. To learn about the consequences of such different conceptualizations of claim for practical applications, we carried out extensive experiments using state-of-the-art feature-rich and deep learning systems, to identify claims in a cross-domain fashion. While the divergent perception of claims in different datasets is indeed harmful to cross-domain classification, we show that there are shared properties on the lexical level as well as system configurations that can help to overcome these gaps. version:3
arxiv-1709-03655 | Learning Gating ConvNet for Two-Stream based Methods in Action Recognition | http://arxiv.org/abs/1709.03655 | id:1709.03655 author:Jiagang Zhu, Wei Zou, Zheng Zhu category:cs.CV  published:2017-09-12 summary:For the two-stream style methods in action recognition, fusing the two streams' predictions is always by the weighted averaging scheme. This fusion method with fixed weights lacks of pertinence to different action videos and always needs trial and error on the validation set. In order to enhance the adaptability of two-stream ConvNets and improve its performance, an end-to-end trainable gated fusion method, namely gating ConvNet, for the two-stream ConvNets is proposed in this paper based on the MoE (Mixture of Experts) theory. The gating ConvNet takes the combination of feature maps from the same layer of the spatial and the temporal nets as input and adopts ReLU (Rectified Linear Unit) as the gating output activation function. To reduce the over-fitting of gating ConvNet caused by the redundancy of parameters, a new multi-task learning method is designed, which jointly learns the gating fusion weights for the two streams and learns the gating ConvNet for action classification. With our gated fusion method and multi-task learning approach, a high accuracy of 94.5% is achieved on the dataset UCF101. version:2
arxiv-1709-02926 | Joint Calibration of Panoramic Camera and Lidar Based on Supervised Learning | http://arxiv.org/abs/1709.02926 | id:1709.02926 author:Mingwei Cao, Ming Yang, Chunxiang Wang, Yeqiang Qian, Bing Wang category:cs.CV  published:2017-09-09 summary:In view of contemporary panoramic camera-laser scanner system, the traditional calibration method is not suitable for panoramic cameras whose imaging model is extremely nonlinear. The method based on statistical optimization has the disadvantage that the requirement of the number of laser scanner's channels is relatively high. Calibration equipments with extreme accuracy for panoramic camera-laser scanner system are costly. Facing all these in the calibration of panoramic camera-laser scanner system, a method based on supervised learning is proposed. Firstly, corresponding feature points of panoramic images and point clouds are gained to generate the training dataset by designing a round calibration object. Furthermore, the traditional calibration problem is transformed into a multiple nonlinear regression optimization problem by designing a supervised learning network with preprocessing of the panoramic imaging model. Back propagation algorithm is utilized to regress the rotation and translation matrix with high accuracy. Experimental results show that this method can quickly regress the calibration parameters and the accuracy is better than the traditional calibration method and the method based on statistical optimization. The calibration accuracy of this method is really high, and it is more highly-automated. version:2
arxiv-1704-07554 | A relevance-scalability-interpretability tradeoff with temporally evolving user personas | http://arxiv.org/abs/1704.07554 | id:1704.07554 author:Snigdha Panigrahi, Nadia Fawaz category:stat.ML  published:2017-04-25 summary:The current work characterizes the users of a VoD streaming space through user-personas based on a tenure timeline and temporal behavioral features in the absence of explicit user profiles. A combination of tenure timeline and temporal characteristics caters to business needs of understanding the evolution and phases of user behavior as their accounts age. The personas constructed in this work successfully represent both dominant and niche characterizations while providing insightful maturation of user behavior in the system. The two major highlights of our personas are demonstration of stability along tenure timelines on a population level, while exhibiting interesting migrations between labels on an individual granularity and clear interpretability of user labels. Finally, we show a trade-off between an indispensable trio of guarantees, relevance-scalability-interpretability by using summary information from personas in a CTR (Click through rate) predictive model. The proposed method of uncovering latent personas, consequent insights from these and application of information from personas to predictive models are broadly applicable to other streaming based products. version:2
arxiv-1709-01233 | Linear Optimal Low Rank Projection for High-Dimensional Multi-Class Data | http://arxiv.org/abs/1709.01233 | id:1709.01233 author:Joshua T. Vogelstein, Minh Tang, Da Zheng, Randal Burns, Mauro Maggioni category:stat.ML  published:2017-09-05 summary:Classification of individual samples into one or more categories is critical to modern scientific inquiry. Most modern datasets, such as those used in genetic analysis or imaging, include numerous features, such as genes or pixels. Principal Components Analysis (PCA) is now generally used to find low-dimensional representations of such features for further analysis. However, PCA ignores class label information, thereby discarding data that could substantially improve downstream classification performance. We here describe an approach called "Linear Optimal Low-rank"' projection (LOL), which extends PCA by incorporating the class labels. Using theory and synthetic data, we show that LOL leads to a better representation of the data for subsequent classification than PCA while adding negligible computational cost. Experimentally we demonstrate that LOL substantially outperforms PCA in differentiating cancer patients from healthy controls using genetic data and in differentiating gender from magnetic resonance imaging data incorporating >500 million features and 400 gigabytes of data. LOL allows the solution of previous intractable problems yet requires only a few minutes to run on a single desktop computer. version:4
arxiv-1704-07961 | Nonlinear Unsupervised Clustering of Hyperspectral Images with Applications to Anomaly Detection and Active Learning | http://arxiv.org/abs/1704.07961 | id:1704.07961 author:James M. Murphy, Mauro Maggioni category:cs.CV  published:2017-04-26 summary:The problem of unsupervised learning and segmentation of hyperspectral images is a significant challenge in remote sensing. The high dimensionality of hyperspectral data, presence of substantial noise, and overlap of classes all contribute to the difficulty of automatically clustering and segmenting hyperspectral images. In this article, we propose an unsupervised learning technique that combines a geometric estimation of class modes with a diffusion-inspired labeling that incorporates both spatial and spectral information. The mode estimation incorporates the geometry of the hyperspectral data by using diffusion distance to promote learning a unique mode from each class. These class modes are then used to label all points by a joint spatial-spectral nonlinear diffusion process. The proposed method, called spatial-spectral diffusion learning (DLSS), is shown to perform competitively against benchmark and state-of-the-art hyperspectral clustering methods on a variety of synthetic and real datasets. The proposed methods are shown to enjoy low computational complexity and fast empirical runtime. Two variations of the proposed method are also discussed. The first variation combines the proposed method of mode estimation with partial least squares regression (PLSR) to efficiently segment chemical plumes in hyperspectral images for anomaly detection. The second variation incorporates active learning to allow the user to request labels for a very small number of pixels, which can dramatically improve overall clustering results. Extensive experimental analysis demonstrate the efficacy of the proposed methods, and their robustness to choices of parameters. version:3
arxiv-1709-04136 | Recursive Exponential Weighting for Online Non-convex Optimization | http://arxiv.org/abs/1709.04136 | id:1709.04136 author:Lin Yang, Cheng Tan, Wing Shing Wong category:cs.LG  published:2017-09-13 summary:In this paper, we investigate the online non-convex optimization problem which generalizes the classic {online convex optimization problem by relaxing the convexity assumption on the cost function. For this type of problem, the classic exponential weighting online algorithm has recently been shown to attain a sub-linear regret of $O(\sqrt{T\log T})$. In this paper, we introduce a novel recursive structure to the online algorithm to define a recursive exponential weighting algorithm that attains a regret of $O(\sqrt{T})$, matching the well-known regret lower bound. To the best of our knowledge, this is the first online algorithm with provable $O(\sqrt{T})$ regret for the online non-convex optimization problem. version:1
arxiv-1709-04135 | Weighted Orthogonal Components Regression Analysis | http://arxiv.org/abs/1709.04135 | id:1709.04135 author:Xiaogang Su, Yaa Wonkye, Pei Wang, Xiangrong Yin category:stat.ML 62J07  published:2017-09-13 summary:In the multiple linear regression setting, we propose a general framework, termed weighted orthogonal components regression (WOCR), which encompasses many known methods as special cases, including ridge regression and principal components regression. WOCR makes use of the monotonicity inherent in orthogonal components to parameterize the weight function. The formulation allows for efficient determination of tuning parameters and hence is computationally advantageous. Moreover, WOCR offers insights for deriving new better variants. Specifically, we advocate weighting components based on their correlations with the response, which leads to enhanced predictive performance. Both simulated studies and real data examples are provided to assess and illustrate the advantages of the proposed methods. version:1
arxiv-1707-08945 | Robust Physical-World Attacks on Deep Learning Models | http://arxiv.org/abs/1707.08945 | id:1707.08945 author:Ivan Evtimov, Kevin Eykholt, Earlence Fernandes, Tadayoshi Kohno, Bo Li, Atul Prakash, Amir Rahmati, Dawn Song category:cs.CR cs.LG  published:2017-07-27 summary:Although deep neural networks (DNNs) perform well in a variety of applications, they are vulnerable to adversarial examples resulting from small-magnitude perturbations added to the input data. Inputs modified in this way can be mislabeled as a target class in targeted attacks or as a random class different from the ground truth in untargeted attacks. However, recent studies have demonstrated that such adversarial examples have limited effectiveness in the physical world due to changing physical conditions--they either completely fail to cause misclassification or only work in restricted cases where a relatively complex image is perturbed and printed on paper. In this paper, we propose a general attack algorithm--Robust Physical Perturbations (RP2)-- that takes into account the numerous physical conditions and produces robust adversarial perturbations. Using a real-world example of road sign recognition, we show that adversarial examples generated using RP2 achieve high attack success rates in the physical world under a variety of conditions, including different viewpoints. Furthermore, to the best of our knowledge, there is currently no standardized way to evaluate physical adversarial perturbations. Therefore, we propose a two-stage evaluation methodology and tailor it to the road sign recognition use case. Our methodology captures a range of diverse physical conditions, including those encountered when images are captured from moving vehicles. We evaluate our physical attacks using this methodology and effectively fool two road sign classifiers. Using a perturbation in the shape of black and white stickers, we attack a real Stop sign, causing targeted misclassification in 100% of the images obtained in controlled lab settings and above 84% of the captured video frames obtained on a moving vehicle for one of the classifiers we attack. version:4
arxiv-1709-04121 | Sketch-pix2seq: a Model to Generate Sketches of Multiple Categories | http://arxiv.org/abs/1709.04121 | id:1709.04121 author:Yajing Chen, Shikui Tu, Yuqi Yi, Lei Xu category:cs.CV  published:2017-09-13 summary:Sketch is an important media for human to communicate ideas, which reflects the superiority of human intelligence. Studies on sketch can be roughly summarized into recognition and generation. Existing models on image recognition failed to obtain satisfying performance on sketch classification. But for sketch generation, a recent study proposed a sequence-to-sequence variational-auto-encoder (VAE) model called sketch-rnn which was able to generate sketches based on human inputs. The model achieved amazing results when asked to learn one category of object, such as an animal or a vehicle. However, the performance dropped when multiple categories were fed into the model. Here, we proposed a model called sketch-pix2seq which could learn and draw multiple categories of sketches. Two modifications were made to improve the sketch-rnn model: one is to replace the bidirectional recurrent neural network (BRNN) encoder with a convolutional neural network(CNN); the other is to remove the Kullback-Leibler divergence from the objective function of VAE. Experimental results showed that models with CNN encoders outperformed those with RNN encoders in generating human-style sketches. Visualization of the latent space illustrated that the removal of KL-divergence made the encoder learn a posterior of latent space that reflected the features of different categories. Moreover, the combination of CNN encoder and removal of KL-divergence, i.e., the sketch-pix2seq model, had better performance in learning and generating sketches of multiple categories and showed promising results in creativity tasks. version:1
arxiv-1709-04114 | EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples | http://arxiv.org/abs/1709.04114 | id:1709.04114 author:Pin-Yu Chen, Yash Sharma, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh category:stat.ML cs.CR cs.LG  published:2017-09-13 summary:Recent studies have highlighted the vulnerability of deep neural networks (DNNs) to adversarial examples - a visually indistinguishable adversarial image can easily be crafted to cause a well-trained model to misclassify. Existing methods for crafting adversarial examples are based on $L_2$ and $L_\infty$ distortion metrics. However, despite the fact that $L_1$ distortion accounts for the total variation and encourages sparsity in the perturbation, little has been developed for crafting $L_1$-based adversarial examples. In this paper, we formulate the process of attacking DNNs via adversarial examples as an elastic-net regularized optimization problem. Our Elastic-net Attacks to DNNs (EAD) feature $L_1$-oriented adversarial examples and include the state-of-the-art $L_2$ attack as a special case. Experimental results on MNIST, CIFAR10 and ImageNet show that EAD can yield a distinct set of adversarial examples and attains similar attack performance to the state-of-the-art methods in different attack scenarios. More importantly, EAD leads to improved attack transferability and complements adversarial training for DNNs, suggesting novel insights on leveraging $L_1$ distortion in adversarial learning and security implications for DNNs. version:1
arxiv-1709-04111 | Meta Networks for Neural Style Transfer | http://arxiv.org/abs/1709.04111 | id:1709.04111 author:Falong Shen, Shuicheng Yan, Gang Zeng category:cs.CV  published:2017-09-13 summary:In this paper we propose a new method to get the specified network parameters through one time feed-forward propagation of the meta networks and explore the application to neural style transfer. Recent works on style transfer typically need to train image transformation networks for every new style, and the style is encoded in the network parameters by enormous iterations of stochastic gradient descent. To tackle these issues, we build a meta network which takes in the style image and produces a corresponding image transformations network directly. Compared with optimization-based methods for every style, our meta networks can handle an arbitrary new style within $19ms$ seconds on one modern GPU card. The fast image transformation network generated by our meta network is only 449KB, which is capable of real-time executing on a mobile device. We also investigate the manifold of the style transfer networks by operating the hidden features from meta networks. Experiments have well validated the effectiveness of our method. Code and trained models has been released https://github.com/FalongShen/styletransfer. version:1
arxiv-1709-04108 | Co-training for Demographic Classification Using Deep Learning from Label Proportions | http://arxiv.org/abs/1709.04108 | id:1709.04108 author:Ehsan Mohammady Ardehaly, Aron Culotta category:cs.CV cs.LG stat.ML  published:2017-09-13 summary:Deep learning algorithms have recently produced state-of-the-art accuracy in many classification tasks, but this success is typically dependent on access to many annotated training examples. For domains without such data, an attractive alternative is to train models with light, or distant supervision. In this paper, we introduce a deep neural network for the Learning from Label Proportion (LLP) setting, in which the training data consist of bags of unlabeled instances with associated label distributions for each bag. We introduce a new regularization layer, Batch Averager, that can be appended to the last layer of any deep neural network to convert it from supervised learning to LLP. This layer can be implemented readily with existing deep learning packages. To further support domains in which the data consist of two conditionally independent feature views (e.g. image and text), we propose a co-training algorithm that iteratively generates pseudo bags and refits the deep LLP model to improve classification accuracy. We demonstrate our models on demographic attribute classification (gender and race/ethnicity), which has many applications in social media analysis, public health, and marketing. We conduct experiments to predict demographics of Twitter users based on their tweets and profile image, without requiring any user-level annotations for training. We find that the deep LLP approach outperforms baselines for both text and image features separately. Additionally, we find that co-training algorithm improves image and text classification by 4% and 8% absolute F1, respectively. Finally, an ensemble of text and image classifiers further improves the absolute F1 measure by 4% on average. version:1
arxiv-1709-05939 | AJILE Movement Prediction: Multimodal Deep Learning for Natural Human Neural Recordings and Video | http://arxiv.org/abs/1709.05939 | id:1709.05939 author:Xin Ru Nancy Wang, Ali Farhadi, Rajesh Rao, Bingni Brunton category:cs.CV q-bio.NC  published:2017-09-13 summary:Developing useful interfaces between brains and machines is a grand challenge of neuroengineering. An effective interface has the capacity to not only interpret neural signals, but predict the intentions of the human to perform an action in the near future; prediction is made even more challenging outside well-controlled laboratory experiments. This paper describes our approach to detect and to predict natural human arm movements in the future, a key challenge in brain computer interfacing that has never before been attempted. We introduce the novel Annotated Joints in Long-term ECoG (AJILE) dataset; AJILE includes automatically annotated poses of 7 upper body joints for four human subjects over 670 total hours (more than 72 million frames), along with the corresponding simultaneously acquired intracranial neural recordings. The size and scope of AJILE greatly exceeds all previous datasets with movements and electrocorticography (ECoG), making it possible to take a deep learning approach to movement prediction. We propose a multimodal model that combines deep convolutional neural networks (CNN) with long short-term memory (LSTM) blocks, leveraging both ECoG and video modalities. We demonstrate that our models are able to detect movements and predict future movements up to 800 msec before movement initiation. Further, our multimodal movement prediction models exhibit resilience to simulated ablation of input neural signals. We believe a multimodal approach to natural neural decoding that takes context into account is critical in advancing bioelectronic technologies and human neuroscience. version:1
arxiv-1709-04093 | Joint Learning of Set Cardinality and State Distribution | http://arxiv.org/abs/1709.04093 | id:1709.04093 author:S. Hamid Rezatofighi, Anton Milan, Qinfeng Shi, Anthony Dick, Ian Reid category:cs.CV  published:2017-09-13 summary:We present a novel approach for learning to predict sets using deep learning. In recent years, deep neural networks have shown remarkable results in computer vision, natural language processing and other related problems. Despite their success, traditional architectures suffer from a serious limitation in that they are built to deal with structured input and output data, i.e. vectors or matrices. Many real-world problems, however, are naturally described as sets, rather than vectors. Existing techniques that allow for sequential data, such as recurrent neural networks, typically heavily depend on the input and output order and do not guarantee a valid solution. Here, we derive in a principled way, a mathematical formulation for set prediction which is permutation invariant. In particular, our approach jointly learns both the cardinality and the state distribution of the target set. We demonstrate the validity of our method on the task of multi-label image classification and achieve a new state of the art on the PASCAL VOC and MS COCO datasets. version:1
arxiv-1708-09254 | Interpretation of Mammogram and Chest X-Ray Reports Using Deep Neural Networks - Preliminary Results | http://arxiv.org/abs/1708.09254 | id:1708.09254 author:Hojjat Salehinejad, Shahrokh Valaee, Aren Mnatzakanian, Tim Dowdell, Joseph Barfett, Errol Colak category:cs.CV  published:2017-08-24 summary:Radiology reports are an important means of communication between radiologists and other physicians. These reports express a radiologist's interpretation of a medical imaging examination and are critical in establishing a diagnosis and formulating a treatment plan. In this paper, we propose a Bi-directional convolutional neural network (Bi-CNN) model for the interpretation and classification of mammograms based on breast density and chest radiographic radiology reports based on the basis of chest pathology. The proposed approach helps to organize databases of radiology reports, retrieve them expeditiously, and evaluate the radiology report that could be used in an auditing system to decrease incorrect diagnoses. Our study revealed that the proposed Bi-CNN outperforms the random forest and the support vector machine methods. version:3
arxiv-1709-04073 | Linear Stochastic Approximation: Constant Step-Size and Iterate Averaging | http://arxiv.org/abs/1709.04073 | id:1709.04073 author:Chandrashekar Lakshminarayanan, Csaba Szepesvári category:cs.LG cs.SY stat.ML  published:2017-09-12 summary:We consider $d$-dimensional linear stochastic approximation algorithms (LSAs) with a constant step-size and the so called Polyak-Ruppert (PR) averaging of iterates. LSAs are widely applied in machine learning and reinforcement learning (RL), where the aim is to compute an appropriate $\theta_{*} \in \mathbb{R}^d$ (that is an optimum or a fixed point) using noisy data and $O(d)$ updates per iteration. In this paper, we are motivated by the problem (in RL) of policy evaluation from experience replay using the \emph{temporal difference} (TD) class of learning algorithms that are also LSAs. For LSAs with a constant step-size, and PR averaging, we provide bounds for the mean squared error (MSE) after $t$ iterations. We assume that data is \iid with finite variance (underlying distribution being $P$) and that the expected dynamics is Hurwitz. For a given LSA with PR averaging, and data distribution $P$ satisfying the said assumptions, we show that there exists a range of constant step-sizes such that its MSE decays as $O(\frac{1}{t})$. We examine the conditions under which a constant step-size can be chosen uniformly for a class of data distributions $\mathcal{P}$, and show that not all data distributions `admit' such a uniform constant step-size. We also suggest a heuristic step-size tuning algorithm to choose a constant step-size of a given LSA for a given data distribution $P$. We compare our results with related work and also discuss the implication of our results in the context of TD algorithms that are LSAs. version:1
arxiv-1709-04072 | A convergence frame for inexact nonconvex and nonsmooth algorithms and its applications to several iterations | http://arxiv.org/abs/1709.04072 | id:1709.04072 author:Tao Sun, Hao Jiang, Lizhi Cheng, Wei Zhu category:math.OC math.NA stat.ML  published:2017-09-12 summary:In this paper, we consider the convergence of an abstract inexact nonconvex and nonsmooth algorithm. We promise a pseudo sufficient descent condition and a pseudo relative error condition, which both are related to an auxiliary sequence, for the algorithm; and a continuity condition is assumed to hold. In fact, a wide of classical inexact nonconvex and nonsmooth algorithms allow these three conditions. Under the finite energy assumption on the auxiliary sequence, we prove the sequence generated by the general algorithm converges to a critical point of the objective function if being assumed Kurdyka- Lojasiewicz property. The core of the proofs lies on building a new Lyapunov function, whose successive difference provides a bound for the successive difference of the points generated by the algorithm. And then, we apply our findings to several classical nonconvex iterative algorithms and derive corresponding convergence results. version:1
arxiv-1709-04060 | Streamlined Deployment for Quantized Neural Networks | http://arxiv.org/abs/1709.04060 | id:1709.04060 author:Yaman Umuroglu, Magnus Jahre category:cs.CV  published:2017-09-12 summary:Running Deep Neural Network (DNN) models on devices with limited computational capability is a challenge due to large compute and memory requirements. Quantized Neural Networks (QNNs) have emerged as a potential solution to this problem, promising to offer most of the DNN accuracy benefits with much lower computational cost. However, harvesting these benefits on existing mobile CPUs is a challenge since operations on highly quantized datatypes are not natively supported in most instruction set architectures (ISAs). In this work, we first describe a streamlining flow to convert all QNN inference operations to integer ones. Afterwards, we provide techniques based on processing one bit position at a time (bit-serial) to show how QNNs can be efficiently deployed using common bitwise operations. We demonstrate the potential of QNNs on mobile CPUs with microbenchmarks and on a quantized AlexNet, which is 3.5x faster than an optimized 8-bit baseline. version:1
arxiv-1709-06165 | MUFold-SS: Protein Secondary Structure Prediction Using Deep Inception-Inside-Inception Networks | http://arxiv.org/abs/1709.06165 | id:1709.06165 author:Chao Fang, Yi Shang, Dong Xu category:q-bio.QM cs.CV cs.NE  published:2017-09-12 summary:Motivation: Protein secondary structure prediction can provide important information for protein 3D structure prediction and protein functions. Deep learning, which has been successfully applied to various research fields such as image classification and voice recognition, provides a new opportunity to significantly improve the secondary structure prediction accuracy. Although several deep-learning methods have been developed for secondary structure prediction, there is room for improvement. MUFold-SS was developed to address these issues. Results: Here, a very deep neural network, the deep inception-inside-inception networks (Deep3I), is proposed for protein secondary structure prediction and a software tool was implemented using this network. This network takes two inputs: a protein sequence and a profile generated by PSI-BLAST. The output is the predicted eight states (Q8) or three states (Q3) of secondary structures. The proposed Deep3I not only achieves the state-of-the-art performance but also runs faster than other tools. Deep3I achieves Q3 82.8% and Q8 71.1% accuracies on the CB513 benchmark. version:1
arxiv-1706-08917 | Rotational Rectification Network: Enabling Pedestrian Detection for Mobile Vision | http://arxiv.org/abs/1706.08917 | id:1706.08917 author:Xinshuo Weng, Shangxuan Wu, Fares Beainy, Kris Kitani category:cs.CV  published:2017-06-19 summary:Across a majority of pedestrian detection datasets, it is typically assumed that pedestrians will be standing upright with respect to the image coordinate system. This assumption, however, is not always valid for many vision-equipped mobile platforms such as mobile phones, UAVs or construction vehicles on rugged terrain. In these situations, the motion of the camera can cause images of pedestrians to be captured at extreme angles. This can lead to very poor pedestrian detection performance when using standard pedestrian detectors. To address this issue, we propose a Rotational Rectification Network (R2N) that can be inserted into any CNN-based pedestrian (or object) detector to adapt it to significant changes in camera rotation. The rotational rectification network uses a 2D rotation estimation module that passes rotational information to a spatial transformer network to undistort image features. To enable robust rotation estimation, we propose a Global Polar Pooling (GP-Pooling) operator to capture rotational shifts in convolutional features. Through our experiments, we show how our rotational rectification network can be used to improve the performance of the state-of-the-art pedestrian detector under heavy image rotation by up to 45% version:3
arxiv-1709-04056 | Multi-scale Forest Species Recognition Systems for Reduced Cost | http://arxiv.org/abs/1709.04056 | id:1709.04056 author:Paulo R. Cavalin, Marcelo N. Kapp, Luiz S. Oliveira category:cs.CV  published:2017-09-12 summary:This work focuses on cost reduction methods for forest species recognition systems. Current state-of-the-art shows that the accuracy of these systems have increased considerably in the past years, but the cost in time to perform the recognition of input samples has also increased proportionally. For this reason, in this work we focus on investigating methods for cost reduction locally (at either feature extraction or classification level individually) and globally (at both levels combined), and evaluate two main aspects: 1) the impact in cost reduction, given the proposed measures for it; and 2) the impact in recognition accuracy. The experimental evaluation conducted on two forest species datasets demonstrated that, with global cost reduction, the cost of the system can be reduced to less than 1/20 and recognition rates that are better than those of the original system can be achieved. version:1
arxiv-1709-04054 | Shifting Mean Activation Towards Zero with Bipolar Activation Functions | http://arxiv.org/abs/1709.04054 | id:1709.04054 author:Lars Eidnes, Arild Nøkland category:stat.ML cs.LG cs.NE  published:2017-09-12 summary:We propose a simple extension to the ReLU-family of activation functions that allows them to shift the mean activation across a layer towards zero. Combined with proper weight initialization, this alleviates the need for normalization layers. We explore the training of deep vanilla recurrent neural networks (RNNs) with up to 144 layers, and show that bipolar activation functions help learning in this setting. On the Penn Treebank and Text8 language modeling tasks we obtain competitive results, improving on the best reported results for non-gated networks. version:1
arxiv-1709-02755 | Training RNNs as Fast as CNNs | http://arxiv.org/abs/1709.02755 | id:1709.02755 author:Tao Lei, Yu Zhang category:cs.CL cs.NE  published:2017-09-08 summary:Recurrent neural networks scale poorly due to the intrinsic difficulty in parallelizing their state computations. For instance, the forward pass computation of $h_t$ is blocked until the entire computation of $h_{t-1}$ finishes, which is a major bottleneck for parallel computing. In this work, we propose an alternative RNN implementation by deliberately simplifying the state computation and exposing more parallelism. The proposed recurrent unit operates as fast as a convolutional layer and 5-10x faster than cuDNN-optimized LSTM. We demonstrate the unit's effectiveness across a wide range of applications including classification, question answering, language modeling, translation and speech recognition. We open source our implementation in PyTorch and CNTK. version:2
arxiv-1709-04005 | Addressee and Response Selection in Multi-Party Conversations with Speaker Interaction RNNs | http://arxiv.org/abs/1709.04005 | id:1709.04005 author:Rui Zhang, Honglak Lee, Lazaros Polymenakos, Dragomir Radev category:cs.CL  published:2017-09-12 summary:In this paper, we study the problem of addressee and response selection in multi-party conversations. Understanding multi-party conversations is challenging because of complex speaker interactions: multiple speakers exchange messages with each other, playing different roles (sender, addressee, observer), and these roles vary across turns. To tackle this challenge, we propose the Speaker Interaction Recurrent Neural Network (SI-RNN). Whereas the previous state-of-the-art system updated speaker embeddings only for the sender, SI-RNN uses a novel dialog encoder to update speaker embeddings in a role-sensitive way. Additionally, unlike the previous work that selected the addressee and response separately, SI-RNN selects them jointly by viewing the task as a sequence prediction problem. Experimental results show that SI-RNN significantly improves the accuracy of addressee and response selection, particularly in complex conversations with many speakers and responses to distant messages many turns in the past. version:1
arxiv-1709-04004 | Adaptive Exploration-Exploitation Tradeoff for Opportunistic Bandits | http://arxiv.org/abs/1709.04004 | id:1709.04004 author:Huasen Wu, Xueying Guo, Xin Liu category:cs.LG stat.ML  published:2017-09-12 summary:In this paper, we propose and study opportunistic bandits - a new variant of bandits where the regret of pulling a suboptimal arm varies under different environmental conditions, such as network load or produce price. When the load/price is low, so is the cost/regret of pulling a suboptimal arm (e.g., trying a suboptimal network configuration). Therefore, intuitively, we could explore more when the load is low and exploit more when the load is high. Inspired by this intuition, we propose an Adaptive Upper-Confidence-Bound (AdaUCB) algorithm to adaptively balance the exploration-exploitation tradeoff for opportunistic bandits. We prove that AdaUCB achieves $O(\log T)$ regret with a smaller coefficient than the traditional UCB algorithm. Furthermore, AdaUCB achieves $O(1)$ regret when the exploration cost is zero if the load level is below a certain threshold. Last, based on both synthetic data and real-world traces, experimental results show that AdaUCB significantly outperforms other bandit algorithms, such as UCB and TS (Thompson Sampling), under large load fluctuations. version:1
arxiv-1709-03966 | Unsupervised Deep Homography: A Fast and Robust Homography Estimation Model | http://arxiv.org/abs/1709.03966 | id:1709.03966 author:Ty Nguyen, Steven W. Chen, Shreyas S. Shivakumar, Camillo J. Taylor, Vijay Kumar category:cs.CV  published:2017-09-12 summary:This paper develops an unsupervised learning algorithm that trains a Deep Convolutional Neural Network to estimate planar homographies. The traditional feature-based approaches to estimating can fail when good features cannot be identified, and can be slow during the feature identification and matching process. We demonstrate that our unsupervised algorithm outperforms these traditional approaches in accuracy, speed, and robustness to noise on both synthetic images and real-world images captured from a UAV. In addition, we demonstrate that our unsupervised method has superior performance compared to the corresponding supervised method of training the network architecture using ground truth homography labels. Our approach is a general motion estimation framework that can be extended beyond estimating planar homographies to more general motions such as optical flow. version:1
arxiv-1709-03942 | Deep Reinforcement Learning with Surrogate Agent-Environment Interface | http://arxiv.org/abs/1709.03942 | id:1709.03942 author:Song Wang, Yu Jing category:cs.LG  published:2017-09-12 summary:In this paper we propose surrogate agent-environment interface (SAEI) in reinforcement learning. We also state that learning based on probability surrogate agent-environment interface gives optimal policy of task agent-environment interface. We introduce surrogate probability action and develope the probability surrogate action deterministic policy gradient (PSADPG) algorithm based on SAEI. This algorithm enables continuous control of discrete action. The experiments show PSADPG achieves the performance of DQN in the long run for selected tasks. version:1
arxiv-1709-03933 | Hash Embeddings for Efficient Word Representations | http://arxiv.org/abs/1709.03933 | id:1709.03933 author:Dan Svenstrup, Jonas Meinertz Hansen, Ole Winther category:cs.CL  published:2017-09-12 summary:We present hash embeddings, an efficient method for representing words in a continuous vector form. A hash embedding may be seen as an interpolation between a standard word embedding and a word embedding created using a random hash function (the hashing trick). In hash embeddings each token is represented by $k$ $d$-dimensional embeddings vectors and one $k$ dimensional weight vector. The final $d$ dimensional representation of the token is the product of the two. Rather than fitting the embedding vectors for each token these are selected by the hashing trick from a shared pool of $B$ embedding vectors. Our experiments show that hash embeddings can easily deal with huge vocabularies consisting of millions of tokens. When using a hash embedding there is no need to create a dictionary before training nor to perform any kind of vocabulary pruning after training. We show that models trained using hash embeddings exhibit at least the same level of performance as models trained using regular embeddings across a wide range of tasks. Furthermore, the number of parameters needed by such an embedding is only a fraction of what is required by a regular embedding. Since standard embeddings and embeddings constructed using the hashing trick are actually just special cases of a hash embedding, hash embeddings can be considered an extension and improvement over the existing regular embedding types. version:1
arxiv-1709-03925 | Human Associations Help to Detect Conventionalized Multiword Expressions | http://arxiv.org/abs/1709.03925 | id:1709.03925 author:Natalia Loukachevitch, Anastasia Gerasimova category:cs.CL  published:2017-09-12 summary:In this paper we show that if we want to obtain human evidence about conventionalization of some phrases, we should ask native speakers about associations they have to a given phrase and its component words. We have shown that if component words of a phrase have each other as frequent associations, then this phrase can be considered as conventionalized. Another type of conventionalized phrases can be revealed using two factors: low entropy of phrase associations and low intersection of component word and phrase associations. The association experiments were performed for the Russian language. version:1
arxiv-1709-02373 | Adaptive PCA for Time-Varying Data | http://arxiv.org/abs/1709.02373 | id:1709.02373 author:Salaheddin Alakkari, John Dingliana category:stat.ML cs.CV cs.LG  published:2017-09-07 summary:In this paper, we present an online adaptive PCA algorithm that is able to compute the full dimensional eigenspace per new time-step of sequential data. The algorithm is based on a one-step update rule that considers all second order correlations between previous samples and the new time-step. Our algorithm has O(n) complexity per new time-step in its deterministic mode and O(1) complexity per new time-step in its stochastic mode. We test our algorithm on a number of time-varying datasets of different physical phenomena. Explained variance curves indicate that our technique provides an excellent approximation to the original eigenspace computed using standard PCA in batch mode. In addition, our experiments show that the stochastic mode, despite its much lower computational complexity, converges to the same eigenspace computed using the deterministic mode. version:2
arxiv-1709-03917 | Image Matching Benchmark | http://arxiv.org/abs/1709.03917 | id:1709.03917 author:JiaWang Bian, Le Zhang, Yun Liu, Wen-Yan Lin, Ming-Ming Cheng, Ian D. Reid category:cs.CV  published:2017-09-12 summary:Image matching has been one of the most fundamental and active research areas in computer vision community. In this field, existing evaluation protocols overemphasize feature design and ignore the performance of image level matching. However, the latter is critical for many high-level vision and robotics tasks. To address this, we present the first application-oriented image matching benchmark to facilitate the analysis of matching algorithms in application level. In addition, we construct a large-scale dataset of real-world images that cover a wide range of scene types, on which state-of-the-art matchers (local features with correspondence selection methods) are exhaustively evaluated and analyzed. Moreover, we demonstrate the effectiveness of a simple technique which is readily pluggable into any matching system to improve performance. The results and analysis will provide researchers with a practical guide to utilizing and improving image matching. Finally, we will release our evaluation code on the GitHub. version:1
arxiv-1709-04343 | End-to-End Audiovisual Fusion with LSTMs | http://arxiv.org/abs/1709.04343 | id:1709.04343 author:Stavros Petridis, Yujiang Wang, Zuwei Li, Maja Pantic category:cs.CV  published:2017-09-12 summary:Several end-to-end deep learning approaches have been recently presented which simultaneously extract visual features from the input images and perform visual speech classification. However, research on jointly extracting audio and visual features and performing classification is very limited. In this work, we present an end-to-end audiovisual model based on Bidirectional Long Short-Term Memory (BLSTM) networks. To the best of our knowledge, this is the first audiovisual fusion model which simultaneously learns to extract features directly from the pixels and spectrograms and perform classification of speech and nonlinguistic vocalisations. The model consists of multiple identical streams, one for each modality, which extract features directly from mouth regions and spectrograms. The temporal dynamics in each stream/modality are modeled by a BLSTM and the fusion of multiple streams/modalities takes place via another BLSTM. An absolute improvement of 1.9% in the mean F1 of 4 nonlingusitic vocalisations over audio-only classification is reported on the AVIC database. At the same time, the proposed end-to-end audiovisual fusion system improves the state-of-the-art performance on the AVIC database leading to a 9.7% absolute increase in the mean F1 measure. We also perform audiovisual speech recognition experiments on the OuluVS2 database using different views of the mouth, frontal to profile. The proposed audiovisual system significantly outperforms the audio-only model for all views when the acoustic noise is high. version:1
arxiv-1704-08231 | Estimating the coefficients of a mixture of two linear regressions by expectation maximization | http://arxiv.org/abs/1704.08231 | id:1704.08231 author:Jason M. Klusowski, Dana Yang, W. D. Brinda category:stat.ML 62F10  68W40  published:2017-04-26 summary:We give convergence guarantees for estimating the coefficients of a symmetric mixture of two linear regressions by expectation maximization (EM). In particular, we show that convergence of the empirical iterates is guaranteed provided the algorithm is initialized in an unbounded cone. That is, if the initializer has a large cosine angle with the population coefficient vector and the signal to noise ratio (SNR) is large, a sample-splitting version of the EM algorithm converges to the true coefficient vector with high probability. Here "large" means that each quantity is required to be at least a universal constant. Finally, we show that the population EM operator is not globally contractive by characterizing a region where it fails. We give empirical evidence that suggests that the sample based EM performs poorly when intitializers are drawn from this set. Interestingly, our analysis borrows from tools used in the problem of estimating the centers of a symmetric mixture of two Gaussians by EM. version:2
arxiv-1709-03907 | Weighted Message Passing and Minimum Energy Flow for Heterogeneous Stochastic Block Models with Side Information | http://arxiv.org/abs/1709.03907 | id:1709.03907 author:T. Tony Cai, Tengyuan Liang, Alexander Rakhlin category:math.ST stat.ML stat.TH  published:2017-09-12 summary:We study the misclassification error for community detection in general heterogeneous stochastic block models (SBM) with noisy or partial label information. We establish a connection between the misclassification rate and the notion of minimum energy on the local neighborhood of the SBM. We develop an optimally weighted message passing algorithm to reconstruct labels for SBM based on the minimum energy flow and the eigenvectors of a certain Markov transition matrix. The general SBM considered in this paper allows for unequal-size communities, degree heterogeneity, and different connection probabilities among blocks. We focus on how to optimally weigh the message passing to improve misclassification. version:1
arxiv-1709-05936 | Kernel Cross-Correlator | http://arxiv.org/abs/1709.05936 | id:1709.05936 author:Chen Wang, Le Zhang, Lihua Xie, Junsong Yuan category:cs.CV  published:2017-09-12 summary:Cross-correlator plays a significant role in many visual perception tasks, such as object detection and tracking. Beyond the linear cross-correlator, this paper proposes a kernel cross-correlator (KCC) that breaks traditional limitations. First, by introducing the kernel trick, the KCC extends the linear cross-correlation to non-linear space, which is more robust to signal noises and distortions. Second, the connection to the existing works shows that KCC provides a unified solution for correlation filters. Third, KCC is applicable to any kernel function and is not limited to circulant structure on training data, thus it is able to predict affine transformations with customized properties. Last, by leveraging the fast Fourier transform (FFT), KCC eliminates direct calculation of kernel vectors, thus achieves better performance yet still with a reasonable computational cost. Comprehensive experiments on visual tracking and human activity recognition using wearable devices demonstrate its robustness, flexibility, and efficiency. version:1
arxiv-1706-04606 | Nudged elastic band calculations accelerated with Gaussian process regression | http://arxiv.org/abs/1706.04606 | id:1706.04606 author:Olli-Pekka Koistinen, Freyja B. Dagbjartsdóttir, Vilhjálmur Ásgeirsson, Aki Vehtari, Hannes Jónsson category:physics.chem-ph physics.atm-clus physics.comp-ph stat.CO stat.ML  published:2017-06-14 summary:Minimum energy paths for transitions such as atomic and/or spin rearrangements in thermalized systems are the transition paths of largest statistical weight. Such paths are frequently calculated using the nudged elastic band method, where an initial path is iteratively shifted to the nearest minimum energy path. The computational effort can be large, especially when ab initio or electron density functional calculations are used to evaluate the energy and atomic forces. Here, we show how the number of such evaluations can be reduced by an order of magnitude using a Gaussian process regression approach where an approximate energy surface is generated and refined in each iteration. When the goal is to evaluate the transition rate within harmonic transition state theory, the evaluation of the Hessian matrix at the initial and final state minima can be carried out beforehand and used as input in the minimum energy path calculation, thereby improving stability and reducing the number of iterations needed for convergence. A Gaussian process model also provides an uncertainty estimate for the approximate energy surface, and this can be used to focus the calculations on the lesser-known part of the path, thereby reducing the number of needed energy and force evaluations to a half in the present calculations. The methodology is illustrated using the two-dimensional M\"uller-Brown potential surface and performance assessed on an established benchmark involving 13 rearrangement transitions of a heptamer island on a solid surface. version:2
arxiv-1709-03891 | High-Dimensional Dependency Structure Learning for Physical Processes | http://arxiv.org/abs/1709.03891 | id:1709.03891 author:Jamal Golmohammadi, Imme Ebert-Uphoff, Sijie He, Yi Deng, Arindam Banerjee category:cs.LG stat.ML  published:2017-09-12 summary:In this paper, we consider the use of structure learning methods for probabilistic graphical models to identify statistical dependencies in high-dimensional physical processes. Such processes are often synthetically characterized using PDEs (partial differential equations) and are observed in a variety of natural phenomena, including geoscience data capturing atmospheric and hydrological phenomena. Classical structure learning approaches such as the PC algorithm and variants are challenging to apply due to their high computational and sample requirements. Modern approaches, often based on sparse regression and variants, do come with finite sample guarantees, but are usually highly sensitive to the choice of hyper-parameters, e.g., parameter $\lambda$ for sparsity inducing constraint or regularization. In this paper, we present ACLIME-ADMM, an efficient two-step algorithm for adaptive structure learning, which estimates an edge specific parameter $\lambda_{ij}$ in the first step, and uses these parameters to learn the structure in the second step. Both steps of our algorithm use (inexact) ADMM to solve suitable linear programs, and all iterations can be done in closed form in an efficient block parallel manner. We compare ACLIME-ADMM with baselines on both synthetic data simulated by partial differential equations (PDEs) that model advection-diffusion processes, and real data (50 years) of daily global geopotential heights to study information flow in the atmosphere. ACLIME-ADMM is shown to be efficient, stable, and competitive, usually better than the baselines especially on difficult problems. On real data, ACLIME-ADMM recovers the underlying structure of global atmospheric circulation, including switches in wind directions at the equator and tropics entirely from the data. version:1
arxiv-1709-03871 | Learning by Refuting | http://arxiv.org/abs/1709.03871 | id:1709.03871 author:Pravesh K. Kothari, Roi Livni category:cs.LG  published:2017-09-12 summary:The sample complexity of learning a Boolean-valued function class is precisely characterized by its Rademacher complexity. This has little bearing, however, on the sample complexity of \emph{efficient} agnostic learning. We introduce \emph{refutation complexity}, a natural computational analog of Rademacher complexity of a Boolean concept class and show that it exactly characterizes the sample complexity of \emph{efficient} agnostic learning. Informally, refutation complexity of a class $\mathcal{C}$ is the minimum number of example-label pairs required to efficiently distinguish between the case that the labels correlate with the evaluation of some member of $\mathcal{C}$ (\emph{structure}) and the case where the labels are i.i.d. Rademacher random variables (\emph{noise}). The easy direction of this relationship was implicitly used in the recent framework for improper PAC learning lower bounds of Daniely and co-authors via connections to the hardness of refuting random constraint satisfaction problems. Our work can be seen as making the relationship between agnostic learning and refutation implicit in their work into an explicit equivalence. In a recent, independent work, Salil Vadhan discovered a similar relationship between refutation and PAC-learning in the realizable (i.e. noiseless) case. version:1
arxiv-1709-01572 | Sequence Prediction with Neural Segmental Models | http://arxiv.org/abs/1709.01572 | id:1709.01572 author:Hao Tang category:cs.CL cs.LG cs.SD  published:2017-09-05 summary:Segments that span contiguous parts of inputs, such as phonemes in speech, named entities in sentences, actions in videos, occur frequently in sequence prediction problems. Segmental models, a class of models that explicitly hypothesizes segments, have allowed the exploration of rich segment features for sequence prediction. However, segmental models suffer from slow decoding, hampering the use of computationally expensive features. In this thesis, we introduce discriminative segmental cascades, a multi-pass inference framework that allows us to improve accuracy by adding higher-order features and neural segmental features while maintaining efficiency. We also show that instead of including more features to obtain better accuracy, segmental cascades can be used to speed up training and decoding. Segmental models, similarly to conventional speech recognizers, are typically trained in multiple stages. In the first stage, a frame classifier is trained with manual alignments, and then in the second stage, segmental models are trained with manual alignments and the out- puts of the frame classifier. However, obtaining manual alignments are time-consuming and expensive. We explore end-to-end training for segmental models with various loss functions, and show how end-to-end training with marginal log loss can eliminate the need for detailed manual alignments. We draw the connections between the marginal log loss and a popular end-to-end training approach called connectionist temporal classification. We present a unifying framework for various end-to-end graph search-based models, such as hidden Markov models, connectionist temporal classification, and segmental models. Finally, we discuss possible extensions of segmental models to large-vocabulary sequence prediction tasks. version:2
arxiv-1708-02214 | LitStoryTeller: An Interactive System for Visual Exploration of Scientific Papers Leveraging Named entities and Comparative Sentences | http://arxiv.org/abs/1708.02214 | id:1708.02214 author:Qing Ping, Chaomei Chen category:cs.HC cs.CL cs.DL  published:2017-08-07 summary:The present study proposes LitStoryTeller, an interactive system for visually exploring the semantic structure of a scientific article. We demonstrate how LitStoryTeller could be used to answer some of the most fundamental research questions, such as how a new method was built on top of existing methods, based on what theoretical proof and experimental evidences. More importantly, LitStoryTeller can assist users to understand the full and interesting story a scientific paper, with a concise outline and important details. The proposed system borrows a metaphor from screen play, and visualizes the storyline of a scientific paper by arranging its characters (scientific concepts or terminologies) and scenes (paragraphs/sentences) into a progressive and interactive storyline. Such storylines help to preserve the semantic structure and logical thinking process of a scientific paper. Semantic structures, such as scientific concepts and comparative sentences, are extracted using existing named entity recognition APIs and supervised classifiers, from a scientific paper automatically. Two supplementary views, ranked entity frequency view and entity co-occurrence network view, are provided to help users identify the "main plot" of such scientific storylines. When collective documents are ready, LitStoryTeller also provides a temporal entity evolution view and entity community view for collection digestion. version:3
arxiv-1709-03853 | Imitation Learning for Vision-based Lane Keeping Assistance | http://arxiv.org/abs/1709.03853 | id:1709.03853 author:Christopher Innocenti, Henrik Lindén, Ghazaleh Panahandeh, Lennart Svensson, Nasser Mohammadiha category:cs.LG  published:2017-09-12 summary:This paper aims to investigate direct imitation learning from human drivers for the task of lane keeping assistance in highway and country roads using grayscale images from a single front view camera. The employed method utilizes convolutional neural networks (CNN) to act as a policy that is driving a vehicle. The policy is successfully learned via imitation learning using real-world data collected from human drivers and is evaluated in closed-loop simulated environments, demonstrating good driving behaviour and a robustness for domain changes. Evaluation is based on two proposed performance metrics measuring how well the vehicle is positioned in a lane and the smoothness of the driven trajectory. version:1
arxiv-1709-03849 | Spatio-temporal Learning with Arrays of Analog Nanosynapses | http://arxiv.org/abs/1709.03849 | id:1709.03849 author:Christopher H. Bennett, Damien Querlioz, Jacques-Olivier Klein category:cs.NE  published:2017-09-12 summary:Emerging nanodevices such as resistive memories are being considered for hardware realizations of a variety of artificial neural networks (ANNs), including highly promising online variants of the learning approaches known as reservoir computing (RC) and the extreme learning machine (ELM). We propose an RC/ELM inspired learning system built with nanosynapses that performs both on-chip projection and regression operations. To address time-dynamic tasks, the hidden neurons of our system perform spatio-temporal integration and can be further enhanced with variable sampling or multiple activation windows. We detail the system and show its use in conjunction with a highly analog nanosynapse device on a standard task with intrinsic timing dynamics- the TI-46 battery of spoken digits. The system achieves nearly perfect (99%) accuracy at sufficient hidden layer size, which compares favorably with software results. In addition, the model is extended to a larger dataset, the MNIST database of handwritten digits. By translating the database into the time domain and using variable integration windows, up to 95% classification accuracy is achieved. In addition to an intrinsically low-power programming style, the proposed architecture learns very quickly and can easily be converted into a spiking system with negligible loss in performance- all features that confer significant energy efficiency. version:1
arxiv-1709-03831 | Dual Discriminator Generative Adversarial Nets | http://arxiv.org/abs/1709.03831 | id:1709.03831 author:Tu Dinh Nguyen, Trung Le, Hung Vu, Dinh Phung category:cs.LG stat.ML  published:2017-09-12 summary:We propose in this paper a novel approach to tackle the problem of mode collapse encountered in generative adversarial network (GAN). Our idea is intuitive but proven to be very effective, especially in addressing some key limitations of GAN. In essence, it combines the Kullback-Leibler (KL) and reverse KL divergences into a unified objective function, thus it exploits the complementary statistical properties from these divergences to effectively diversify the estimated density in capturing multi-modes. We term our method dual discriminator generative adversarial nets (D2GAN) which, unlike GAN, has two discriminators; and together with a generator, it also has the analogy of a minimax game, wherein a discriminator rewards high scores for samples from data distribution whilst another discriminator, conversely, favoring data from the generator, and the generator produces data to fool both two discriminators. We develop theoretical analysis to show that, given the maximal discriminators, optimizing the generator of D2GAN reduces to minimizing both KL and reverse KL divergences between data distribution and the distribution induced from the data generated by the generator, hence effectively avoiding the mode collapsing problem. We conduct extensive experiments on synthetic and real-world large-scale datasets (MNIST, CIFAR-10, STL-10, ImageNet), where we have made our best effort to compare our D2GAN with the latest state-of-the-art GAN's variants in comprehensive qualitative and quantitative evaluations. The experimental results demonstrate the competitive and superior performance of our approach in generating good quality and diverse samples over baselines, and the capability of our method to scale up to ImageNet database. version:1
arxiv-1709-05937 | Une véritable approche $\ell_0$ pour l'apprentissage de dictionnaire | http://arxiv.org/abs/1709.05937 | id:1709.05937 author:Yuan Liu, Stéphane Canu, Paul Honeine, Su Ruan category:cs.CV eess.IV  published:2017-09-12 summary:Sparse representation learning has recently gained a great success in signal and image processing, thanks to recent advances in dictionary learning. To this end, the $\ell_0$-norm is often used to control the sparsity level. Nevertheless, optimization problems based on the $\ell_0$-norm are non-convex and NP-hard. For these reasons, relaxation techniques have been attracting much attention of researchers, by priorly targeting approximation solutions (e.g. $\ell_1$-norm, pursuit strategies). On the contrary, this paper considers the exact $\ell_0$-norm optimization problem and proves that it can be solved effectively, despite of its complexity. The proposed method reformulates the problem as a Mixed-Integer Quadratic Program (MIQP) and gets the global optimal solution by applying existing optimization software. Because the main difficulty of this approach is its computational time, two techniques are introduced that improve the computational speed. Finally, our method is applied to image denoising which shows its feasibility and relevance compared to the state-of-the-art. version:1
arxiv-1709-03820 | Emotion Recognition in the Wild using Deep Neural Networks and Bayesian Classifiers | http://arxiv.org/abs/1709.03820 | id:1709.03820 author:Luca Surace, Massimiliano Patacchiola, Elena Battini Sönmez, William Spataro, Angelo Cangelosi category:cs.CV  published:2017-09-12 summary:Group emotion recognition in the wild is a challenging problem, due to the unstructured environments in which everyday life pictures are taken. Some of the obstacles for an effective classification are occlusions, variable lighting conditions, and image quality. In this work we present a solution based on a novel combination of deep neural networks and Bayesian classifiers. The neural network works on a bottom-up approach, analyzing emotions expressed by isolated faces. The Bayesian classifier estimates a global emotion integrating top-down features obtained through a scene descriptor. In order to validate the system we tested the framework on the dataset released for the Emotion Recognition in the Wild Challenge 2017. Our method achieved an accuracy of 64.68% on the test set, significantly outperforming the 53.62% competition baseline. version:1
arxiv-1709-03815 | OpenNMT: Open-source Toolkit for Neural Machine Translation | http://arxiv.org/abs/1709.03815 | id:1709.03815 author:Guillaume Klein, Yoon Kim, Yuntian Deng, Josep Crego, Jean Senellart, Alexander M. Rush category:cs.CL  published:2017-09-12 summary:We introduce an open-source toolkit for neural machine translation (NMT) to support research into model architectures, feature representations, and source modalities, while maintaining competitive performance, modularity and reasonable training requirements. version:1
arxiv-1709-03814 | SYSTRAN Purely Neural MT Engines for WMT2017 | http://arxiv.org/abs/1709.03814 | id:1709.03814 author:Yongchao Deng, Jungi Kim, Guillaume Klein, Catherine Kobus, Natalia Segal, Christophe Servan, Bo Wang, Dakun Zhang, Josep Crego, Jean Senellart category:cs.CL  published:2017-09-12 summary:This paper describes SYSTRAN's systems submitted to the WMT 2017 shared news translation task for English-German, in both translation directions. Our systems are built using OpenNMT, an open-source neural machine translation system, implementing sequence-to-sequence models with LSTM encoder/decoders and attention. We experimented using monolingual data automatically back-translated. Our resulting models are further hyper-specialised with an adaptation technique that finely tunes models according to the evaluation test sentences. version:1
arxiv-1709-03806 | Can Deep Neural Networks Match the Related Objects?: A Survey on ImageNet-trained Classification Models | http://arxiv.org/abs/1709.03806 | id:1709.03806 author:Han S. Lee, Heechul Jung, Alex A. Agarwal, Junmo Kim category:cs.CV  published:2017-09-12 summary:Deep neural networks (DNNs) have shown the state-of-the-art level of performances in wide range of complicated tasks. In recent years, the studies have been actively conducted to analyze the black box characteristics of DNNs and to grasp the learning behaviours, tendency, and limitations of DNNs. In this paper, we investigate the limitation of DNNs in image classification task and verify it with the method inspired by cognitive psychology. Through analyzing the failure cases of ImageNet classification task, we hypothesize that the DNNs do not sufficiently learn to associate related classes of objects. To verify how DNNs understand the relatedness between object classes, we conducted experiments on the image database provided in cognitive psychology. We applied the ImageNet-trained DNNs to the database consisting of pairs of related and unrelated object images to compare the feature similarities and determine whether the pairs match each other. In the experiments, we observed that the DNNs show limited performance in determining relatedness between object classes. In addition, the DNNs present somewhat improved performance in discovering relatedness based on similarity, but they perform weaker in discovering relatedness based on association. Through these experiments, a novel analysis of learning behaviour of DNNs is provided and the limitation which needs to be overcome is suggested. version:1
arxiv-1709-03793 | Opportunistic Self Organizing Migrating Algorithm for Real-Time Dynamic Traveling Salesman Problem | http://arxiv.org/abs/1709.03793 | id:1709.03793 author:Shubham Dokania, Sunyam Bagga, Rohit Sharma category:cs.NE  published:2017-09-12 summary:Self Organizing Migrating Algorithm (SOMA) is a meta-heuristic algorithm based on the self-organizing behavior of individuals in a simulated social environment. SOMA performs iterative computations on a population of potential solutions in the given search space to obtain an optimal solution. In this paper, an Opportunistic Self Organizing Migrating Algorithm (OSOMA) has been proposed that introduces a novel strategy to generate perturbations effectively. This strategy allows the individual to span across more possible solutions and thus, is able to produce better solutions. A comprehensive analysis of OSOMA on multi-dimensional unconstrained benchmark test functions is performed. OSOMA is then applied to solve real-time Dynamic Traveling Salesman Problem (DTSP). The problem of real-time DTSP has been stipulated and simulated using real-time data from Google Maps with a varying cost-metric between any two cities. Although DTSP is a very common and intuitive model in the real world, its presence in literature is still very limited. OSOMA performs exceptionally well on the problems mentioned above. To substantiate this claim, the performance of OSOMA is compared with SOMA, Differential Evolution and Particle Swarm Optimization. version:1
arxiv-1708-00598 | Controllable Generative Adversarial Network | http://arxiv.org/abs/1708.00598 | id:1708.00598 author:Minhyeok Lee, Junhee Seok category:cs.LG cs.CV stat.ML  published:2017-08-02 summary:Although it is recently introduced, in last few years, generative adversarial network (GAN) has been shown many promising results to generate realistic samples. However, it is hardly able to control generated samples since input variables for a generator are from a random distribution. Some attempts have been made to control generated samples from GAN, but they have not shown good performances with difficult problems. Furthermore, it is hardly possible to control the generator to concentrate on reality or distinctness. For example, with existing models, a generator for face image generation cannot be set to concentrate on one of the two objectives, i.e. generating realistic face and generating difference face according to input labels. Here, we propose controllable GAN (CGAN) in this paper. CGAN shows powerful performance to control generated samples; in addition, it can control the generator to concentrate on reality or distinctness. In this paper, CGAN is evaluated with CelebA datasets. We believe that CGAN can contribute to the research in generative neural network models. version:2
arxiv-1709-02939 | Urban morphology meets deep learning: Exploring urban forms in one million cities, town and villages across the planet | http://arxiv.org/abs/1709.02939 | id:1709.02939 author:Vahid Moosavi category:cs.CV cs.CY  published:2017-09-09 summary:Study of urban form is an important area of research in urban planning/design that contributes to our understanding of how cities function and evolve. However, classical approaches are based on very limited observations and inconsistent methods. As an alternative, availability of massive urban data collections such as Open Street Map from the one hand and the recent advancements in machine learning methods such as deep learning techniques on the other have opened up new possibilities to automatically investigate urban forms at the global scale. In this work for the first time, by collecting a large data set of street networks in more than one million cities, towns and villages all over the world, we trained a deep convolutional auto-encoder, that automatically learns the hierarchical structures of urban forms and represents them via dense and comparable vectors. We showed how the learned urban vectors could be used for different investigations. Using the learned urban vectors, one is able to easily find and compare similar urban forms all over the world, considering their overall spatial structure and other factors such as orientation, graphical structure, and density and partial deformations. Further cluster analysis reveals the distribution of the main patterns of urban forms all over the planet. version:2
arxiv-1709-03376 | Stack-Captioning: Coarse-to-Fine Learning for Image Captioning | http://arxiv.org/abs/1709.03376 | id:1709.03376 author:Jiuxiang Gu, Jianfei Cai, Gang Wang, Tsuhan Chen category:cs.CV  published:2017-09-11 summary:The existing image captioning approaches typically train a one-stage sentence decoder, which is difficult to generate rich fine-grained descriptions. On the other hand, multi-stage image caption model is hard to train due to the vanishing gradient problem. In this paper, we propose a coarse-to-fine multi-stage prediction framework for image captioning, composed of multiple decoders each of which operates on the output of the previous stage, producing increasingly refined image descriptions. Our proposed learning approach addresses the difficulty of vanishing gradients during training by providing a learning objective function that enforces intermediate supervisions. Particularly, we optimize our model with a reinforcement learning approach which utilizes the output of each intermediate decoder's test-time inference algorithm as well as the output of its preceding decoder to normalize the rewards, which simultaneously solves the well-known exposure bias problem and the loss-evaluation mismatch problem. We extensively evaluate the proposed approach on MSCOCO and show that our approach can achieve the state-of-the-art performance. version:2
arxiv-1709-03768 | Learning with Bounded Instance- and Label-dependent Label Noise | http://arxiv.org/abs/1709.03768 | id:1709.03768 author:Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamohanarao, Dacheng Tao category:stat.ML cs.LG  published:2017-09-12 summary:Instance- and label-dependent label noise (ILN) is widely existed in real-world datasets but has been rarely studied. In this paper, we focus on a particular case of ILN where the label noise rates, representing the probabilities that the true labels of examples flip into the corrupted labels, have upper bounds. We propose to handle this bounded instance- and label-dependent label noise under two different conditions. First, theoretically, we prove that when the marginal distributions $P(X Y=+1)$ and $P(X Y=-1)$ have non-overlapping supports, we can recover every noisy example's true label and perform supervised learning directly on the cleansed examples. Second, for the overlapping situation, we propose a novel approach to learn a well-performing classifier which needs only a few noisy examples to be labeled manually. Experimental results demonstrate that our method works well on both synthetic and real-world datasets. version:1
arxiv-1709-03763 | Efficient Online Surface Correction for Real-time Large-Scale 3D Reconstruction | http://arxiv.org/abs/1709.03763 | id:1709.03763 author:Robert Maier, Raphael Schaller, Daniel Cremers category:cs.CV  published:2017-09-12 summary:State-of-the-art methods for large-scale 3D reconstruction from RGB-D sensors usually reduce drift in camera tracking by globally optimizing the estimated camera poses in real-time without simultaneously updating the reconstructed surface on pose changes. We propose an efficient on-the-fly surface correction method for globally consistent dense 3D reconstruction of large-scale scenes. Our approach uses a dense Visual RGB-D SLAM system that estimates the camera motion in real-time on a CPU and refines it in a global pose graph optimization. Consecutive RGB-D frames are locally fused into keyframes, which are incorporated into a sparse voxel hashed Signed Distance Field (SDF) on the GPU. On pose graph updates, the SDF volume is corrected on-the-fly using a novel keyframe re-integration strategy with reduced GPU-host streaming. We demonstrate in an extensive quantitative evaluation that our method is up to 93% more runtime efficient compared to the state-of-the-art and requires significantly less memory, with only negligible loss of surface quality. Overall, our system requires only a single GPU and allows for real-time surface correction of large environments. version:1
arxiv-1709-03759 | Language Models of Spoken Dutch | http://arxiv.org/abs/1709.03759 | id:1709.03759 author:Lyan Verwimp, Joris Pelemans, Marieke Lycke, Hugo Van hamme, Patrick Wambacq category:cs.CL  published:2017-09-12 summary:In Flanders, all TV shows are subtitled. However, the process of subtitling is a very time-consuming one and can be sped up by providing the output of a speech recognizer run on the audio of the TV show, prior to the subtitling. Naturally, this speech recognition will perform much better if the employed language model is adapted to the register and the topic of the program. We present several language models trained on subtitles of television shows provided by the Flemish public-service broadcaster VRT. This data was gathered in the context of the project STON which has as purpose to facilitate the process of subtitling TV shows. One model is trained on all available data (46M word tokens), but we also trained models on a specific type of TV show or domain/topic. Language models of spoken language are quite rare due to the lack of training data. The size of this corpus is relatively large for a corpus of spoken language (compare with e.g. CGN which has 9M words), but still rather small for a language model. Thus, in practice it is advised to interpolate these models with a large background language model trained on written language. The models can be freely downloaded on http://www.esat.kuleuven.be/psi/spraak/downloads/. version:1
arxiv-1709-03756 | Cross-lingual Word Segmentation and Morpheme Segmentation as Sequence Labelling | http://arxiv.org/abs/1709.03756 | id:1709.03756 author:Yan Shao category:cs.CL  published:2017-09-12 summary:This paper presents our segmentation system developed for the MLP 2017 shared tasks on cross-lingual word segmentation and morpheme segmentation. We model both word and morpheme segmentation as character-level sequence labelling tasks. The prevalent bidirectional recurrent neural network with conditional random fields as the output interface is adapted as the baseline system, which is further improved via ensemble decoding. Our universal system is applied to and extensively evaluated on all the official data sets without any language-specific adjustment. The official evaluation results indicate that the proposed model achieves outstanding accuracies both for word and morpheme segmentation on all the languages in various types when compared to the other participating systems. version:1
arxiv-1709-03754 | Transform Invariant Auto-encoder | http://arxiv.org/abs/1709.03754 | id:1709.03754 author:Tadashi Matsuo, Hiroya Fukuhara, Nobutaka Shimada category:cs.CV  published:2017-09-12 summary:The auto-encoder method is a type of dimensionality reduction method. A mapping from a vector to a descriptor that represents essential information can be automatically generated from a set of vectors without any supervising information. However, an image and its spatially shifted version are encoded into different descriptors by an existing ordinary auto-encoder because each descriptor includes a spatial subpattern and its position. To generate a descriptor representing a spatial subpattern in an image, we need to normalize its spatial position in the images prior to training an ordinary auto-encoder; however, such a normalization is generally difficult for images without obvious standard positions. We propose a transform invariant auto-encoder and an inference model of transform parameters. By the proposed method, we can separate an input into a transform invariant descriptor and transform parameters. The proposed method can be applied to various auto-encoders without requiring any special modules or labeled training samples. By applying it to shift transforms, we can achieve a shift invariant auto-encoder that can extract a typical spatial subpattern independent of its relative position in a window. In addition, we can achieve a model that can infer shift parameters required to restore the input from the typical subpattern. As an example of the proposed method, we demonstrate that a descriptor generated by a shift invariant auto-encoder can represent a typical spatial subpattern. In addition, we demonstrate the imitation of a human hand by a robot hand as an example of a regression based on spatial subpatterns. version:1
arxiv-1708-04692 | GANs for Biological Image Synthesis | http://arxiv.org/abs/1708.04692 | id:1708.04692 author:Anton Osokin, Anatole Chessel, Rafael E. Carazo Salas, Federico Vaggi category:cs.CV cs.LG stat.ML  published:2017-08-15 summary:In this paper, we propose a novel application of Generative Adversarial Networks (GAN) to the synthesis of cells imaged by fluorescence microscopy. Compared to natural images, cells tend to have a simpler and more geometric global structure that facilitates image generation. However, the correlation between the spatial pattern of different fluorescent proteins reflects important biological functions, and synthesized images have to capture these relationships to be relevant for biological applications. We adapt GANs to the task at hand and propose new models with casual dependencies between image channels that can generate multi-channel images, which would be impossible to obtain experimentally. We evaluate our approach using two independent techniques and compare it against sensible baselines. Finally, we demonstrate that by interpolating across the latent space we can mimic the known changes in protein localization that occur through time during the cell cycle, allowing us to predict temporal evolution from static images. version:2
arxiv-1709-03742 | Dependencies: Formalising Semantic Catenae for Information Retrieval | http://arxiv.org/abs/1709.03742 | id:1709.03742 author:Christina Lioma category:cs.IR cs.CL  published:2017-09-12 summary:Building machines that can understand text like humans is an AI-complete problem. A great deal of research has already gone into this, with astounding results, allowing everyday people to discuss with their telephones, or have their reading materials analysed and classified by computers. A prerequisite for processing text semantics, common to the above examples, is having some computational representation of text as an abstract object. Operations on this representation practically correspond to making semantic inferences, and by extension simulating understanding text. The complexity and granularity of semantic processing that can be realised is constrained by the mathematical and computational robustness, expressiveness, and rigour of the tools used. This dissertation contributes a series of such tools, diverse in their mathematical formulation, but common in their application to model semantic inferences when machines process text. These tools are principally expressed in nine distinct models that capture aspects of semantic dependence in highly interpretable and non-complex ways. This dissertation further reflects on present and future problems with the current research paradigm in this area, and makes recommendations on how to overcome them. The amalgamation of the body of work presented in this dissertation advances the complexity and granularity of semantic inferences that can be made automatically by machines. version:1
arxiv-1709-03739 | Construction of Latent Descriptor Space and Inference Model of Hand-Object Interactions | http://arxiv.org/abs/1709.03739 | id:1709.03739 author:Tadashi Matsuo, Nobutaka Shimada category:cs.CV  published:2017-09-12 summary:Appearance-based generic object recognition is a challenging problem because all possible appearances of objects cannot be registered, especially as new objects are produced every day. Function of objects, however, has a comparatively small number of prototypes. Therefore, function-based classification of new objects could be a valuable tool for generic object recognition. Object functions are closely related to hand-object interactions during handling of a functional object; i.e., how the hand approaches the object, which parts of the object and contact the hand, and the shape of the hand during interaction. Hand-object interactions are helpful for modeling object functions. However, it is difficult to assign discrete labels to interactions because an object shape and grasping hand-postures intrinsically have continuous variations. To describe these interactions, we propose the interaction descriptor space which is acquired from unlabeled appearances of human hand-object interactions. By using interaction descriptors, we can numerically describe the relation between an object's appearance and its possible interaction with the hand. The model infers the quantitative state of the interaction from the object image alone. It also identifies the parts of objects designed for hand interactions such as grips and handles. We demonstrate that the proposed method can unsupervisedly generate interaction descriptors that make clusters corresponding to interaction types. And also we demonstrate that the model can infer possible hand-object interactions. version:1
arxiv-1709-03272 | Fused Text Segmentation Networks for Multi-oriented Scene Text Detection | http://arxiv.org/abs/1709.03272 | id:1709.03272 author:Yuchen Dai, Zheng Huang, Yuting Gao, Kai Chen category:cs.CV  published:2017-09-11 summary:In this paper, we introduce a novel end-end framework for multi-oriented scene text detection from an instance-aware segmentation perspective. We present Fused Text Segmentation Networks, which combine multi-level features during the feature extracting as text instance may rely on finer feature expression compared to general objects. It detects and segments the text instance jointly and simultaneously, leveraging merits from both semantic segmentation task and region proposal based object detection task. Not involving any extra pipelines, our approach surpasses the current state of the art on multi-oriented scene text detection benchmarks: ICDAR2015 Incidental Scene Text and MSRA-TD500 reaching Hmean 84.1% and Hmean 82.0% respectively which suggests effectiveness of the proposed approach. version:2
arxiv-1709-03730 | Interpreting Shared Deep Learning Models via Explicable Boundary Trees | http://arxiv.org/abs/1709.03730 | id:1709.03730 author:Huijun Wu, Chen Wang, Jie Yin, Kai Lu, Liming Zhu category:cs.LG cs.HC  published:2017-09-12 summary:Despite outperforming the human in many tasks, deep neural network models are also criticized for the lack of transparency and interpretability in decision making. The opaqueness results in uncertainty and low confidence when deploying such a model in model sharing scenarios, when the model is developed by a third party. For a supervised machine learning model, sharing training process including training data provides an effective way to gain trust and to better understand model predictions. However, it is not always possible to share all training data due to privacy and policy constraints. In this paper, we propose a method to disclose a small set of training data that is just sufficient for users to get the insight of a complicated model. The method constructs a boundary tree using selected training data and the tree is able to approximate the complicated model with high fidelity. We show that traversing data points in the tree gives users significantly better understanding of the model and paves the way for trustworthy model sharing. version:1
arxiv-1709-03726 | Adaptive Graph Signal Processing: Algorithms and Optimal Sampling Strategies | http://arxiv.org/abs/1709.03726 | id:1709.03726 author:Paolo Di Lorenzo, Paolo Banelli, Elvin Isufi, Sergio Barbarossa, Geert Leus category:cs.LG cs.SY  published:2017-09-12 summary:The goal of this paper is to propose novel strategies for adaptive learning of signals defined over graphs, which are observed over a (randomly time-varying) subset of vertices. We recast two classical adaptive algorithms in the graph signal processing framework, namely, the least mean squares (LMS) and the recursive least squares (RLS) adaptive estimation strategies. For both methods, a detailed mean-square analysis illustrates the effect of random sampling on the adaptive reconstruction capability and the steady-state performance. Then, several probabilistic sampling strategies are proposed to design the sampling probability at each node in the graph, with the aim of optimizing the tradeoff between steady-state performance, graph sampling rate, and convergence rate of the adaptive algorithms. Finally, a distributed RLS strategy is derived and is shown to be convergent to its centralized counterpart. Numerical simulations carried out over both synthetic and real data illustrate the good performance of the proposed sampling and reconstruction strategies for (possibly distributed) adaptive learning of signals defined over graphs. version:1
arxiv-1709-07943 | Cascaded Contextual Region-based Convolutional Neural Network for Event Detection from Time Series Signals: A Seismic Application | http://arxiv.org/abs/1709.07943 | id:1709.07943 author:Yue Wu, Youzuo Lin, Zheng Zhou, David Chas Bolton, Ji Liu, Paul Johnson category:cs.LG cs.CV  published:2017-09-12 summary:Many existing event detection models are point-wised, meaning they classify data points at each timestamp. In this paper, inspired by object detection in 2D imagery, we propose a CNN-based model to give two coordinates for each event denoting the beginning and end. To capture events with dramatically various lengths, we develop a cascaded model which consists of more downsampling layers and we directly use receptive fields as anchors. The take into account the temporal correlation of proposals, we build a contextual block inspired by atrous convolutions. Label dependent loss is used to mitigate the impact caused by omitted positive events. version:1
arxiv-1709-03717 | A low cost non-wearable gaze detection system based on infrared image processing | http://arxiv.org/abs/1709.03717 | id:1709.03717 author:Ehsan Arbabi, Mohammad Shabani, Ali Yarigholi category:cs.HC cs.CV  published:2017-09-12 summary:Human eye gaze detection plays an important role in various fields, including human-computer interaction, virtual reality and cognitive science. Although different relatively accurate systems of eye tracking and gaze detection exist, they are usually either too expensive to be bought for low cost applications or too complex to be implemented easily. In this article, we propose a non-wearable system for eye tracking and gaze detection with low complexity and cost. The proposed system provides a medium accuracy which makes it suitable for general applications in which low cost and easy implementation is more important than achieving very precise gaze detection. The proposed method includes pupil and marker detection using infrared image processing, and gaze evaluation using an interpolation-based strategy. The interpolation-based strategy exploits the positions of the detected pupils and markers in a target captured image and also in some previously captured training images for estimating the position of a point that the user is gazing at. The proposed system has been evaluated by three users in two different lighting conditions. The experimental results show that the accuracy of this low cost system can be between 90% and 100% for finding major gazing directions. version:1
arxiv-1709-03252 | Evaluation of Classical Features and Classifiers in Brain-Computer Interface Tasks | http://arxiv.org/abs/1709.03252 | id:1709.03252 author:Ehsan Arbabi, Mohammad Bagher Shamsollahi category:cs.HC stat.ML  published:2017-09-11 summary:Brain-Computer Interface (BCI) uses brain signals in order to provide a new method for communication between human and outside world. Feature extraction, selection and classification are among the main matters of concerns in signal processing stage of BCI. In this article, we present our findings about the most effective features and classifiers in some brain tasks. Six different groups of classical features and twelve classifiers have been examined in nine datasets of brain signal. The results indicate that energy of brain signals in {\alpha} and \b{eta} frequency bands, together with some statistical parameters are more effective, comparing to the other types of extracted features. In addition, Bayesian classifier with Gaussian distribution assumption and also Support Vector Machine (SVM) show to classify different BCI datasets more accurately than the other classifiers. We believe that the results can give an insight about a strategy for blind classification of brain signals in brain-computer interface. version:2
arxiv-1709-03708 | PQk-means: Billion-scale Clustering for Product-quantized Codes | http://arxiv.org/abs/1709.03708 | id:1709.03708 author:Yusuke Matsui, Keisuke Ogaki, Toshihiko Yamasaki, Kiyoharu Aizawa category:cs.CV cs.MM  published:2017-09-12 summary:Data clustering is a fundamental operation in data analysis. For handling large-scale data, the standard k-means clustering method is not only slow, but also memory-inefficient. We propose an efficient clustering method for billion-scale feature vectors, called PQk-means. By first compressing input vectors into short product-quantized (PQ) codes, PQk-means achieves fast and memory-efficient clustering, even for high-dimensional vectors. Similar to k-means, PQk-means repeats the assignment and update steps, both of which can be performed in the PQ-code domain. Experimental results show that even short-length (32 bit) PQ-codes can produce competitive results compared with k-means. This result is of practical importance for clustering in memory-restricted environments. Using the proposed PQk-means scheme, the clustering of one billion 128D SIFT features with K = 10^5 is achieved within 14 hours, using just 32 GB of memory consumption on a single computer. version:1
arxiv-1709-03698 | Reversible Architectures for Arbitrarily Deep Residual Neural Networks | http://arxiv.org/abs/1709.03698 | id:1709.03698 author:Bo Chang, Lili Meng, Eldad Haber, Lars Ruthotto, David Begert, Elliot Holtham category:cs.CV stat.ML  published:2017-09-12 summary:Recently, deep residual networks have been successfully applied in many computer vision and natural language processing tasks, pushing the state-of-the-art performance with deeper and wider architectures. In this work, we interpret deep residual networks as ordinary differential equations (ODEs), which have long been studied in mathematics and physics with rich theoretical and empirical success. From this interpretation, we develop a theoretical framework on stability and reversibility of deep neural networks, and derive three reversible neural network architectures that can go arbitrarily deep in theory. The reversibility property allows a memory-efficient implementation, which does not need to store the activations for most hidden layers. Together with the stability of our architectures, this enables training deeper networks using only modest computational resources. We provide both theoretical analyses and empirical results. Experimental results demonstrate the efficacy of our architectures against several strong baselines on CIFAR-10, CIFAR-100 and STL-10 with superior or on-par state-of-the-art performance. Furthermore, we show our architectures yield superior results when trained using fewer training data. version:1
arxiv-1709-03697 | Automatic Ground Truths: Projected Image Annotations for Omnidirectional Vision | http://arxiv.org/abs/1709.03697 | id:1709.03697 author:Victor Stamatescu, Peter Barsznica, Manjung Kim, Kin K. Liu, Mark McKenzie, Will Meakin, Gwilyn Saunders, Sebastien C. Wong, Russell S. A. Brinkworth category:cs.CV  published:2017-09-12 summary:We present a novel data set made up of omnidirectional video of multiple objects whose centroid positions are annotated automatically. Omnidirectional vision is an active field of research focused on the use of spherical imagery in video analysis and scene understanding, involving tasks such as object detection, tracking and recognition. Our goal is to provide a large and consistently annotated video data set that can be used to train and evaluate new algorithms for these tasks. Here we describe the experimental setup and software environment used to capture and map the 3D ground truth positions of multiple objects into the image. Furthermore, we estimate the expected systematic error on the mapped positions. In addition to final data products, we release publicly the software tools and raw data necessary to re-calibrate the camera and/or redo this mapping. The software also provides a simple framework for comparing the results of standard image annotation tools or visual tracking systems against our mapped ground truth annotations. version:1
arxiv-1709-03979 | Analysis of the Group Sparsity based on the Rank Minimization Methods | http://arxiv.org/abs/1709.03979 | id:1709.03979 author:Zhiyuan Zha, Xinggan Zhang, Qiong Wang, Lan Tang, Xin Liu category:cs.CV  published:2017-09-12 summary:Sparse coding has achieved a great success in various image processing studies. However, there is not any benchmark to measure the sparsity of image patch/group because the sparse discriminant conditions cannot keep unchanged. This paper analyzes the sparsity of group based on the strategy of the rank minimization. Firstly, an adaptive dictionary is designed for each group. Then, we prove that group-based sparse coding is equivalent to the rank minimization problem, and thus the sparse coefficients of each group can be measured by estimating the singular values of each group. Based on that conclusion, four nuclear norm minimization methods including the standard nuclear norm minimization (NNM), the weighted nuclear norm minimization (WNNM), Schatten p-norm minimization (SNM) and the weighted Schatten p-norm minimization (WSNM) are used to analyze the sparsity of each group and WSNM is found to be the closest solution to the real singular values of each group. Therefore, WSNM can be equivalently turned into a non-convex weighted Lp-norm minimization problem in group-based sparse coding. To make the proposed scheme tractable and robust, the alternating direction method of multipliers (ADMM) is developed to solve the non-convex optimization problem. Experimental results on two low-level vision tasks: image inpainting and image compressive sensing (CS) recovery, show that the proposed scheme is feasible and outperforms existing state-of-the-art reconstruction methods both quantitatively and qualitatively. version:1
arxiv-1707-00783 | A simple efficient density estimator that enables fast systematic search | http://arxiv.org/abs/1707.00783 | id:1707.00783 author:Jonathan R. Wells, Kai Ming Ting category:cs.LG stat.ML  published:2017-07-03 summary:This paper introduces a simple and efficient density estimator that enables fast systematic search. To show its advantage over commonly used kernel density estimator, we apply it to outlying aspects mining. Outlying aspects mining discovers feature subsets (or subspaces) that describe how a query stand out from a given dataset. The task demands a systematic search of subspaces. We identify that existing outlying aspects miners are restricted to datasets with small data size and dimensions because they employ kernel density estimator, which is computationally expensive, for subspace assessments. We show that a recent outlying aspects miner can run orders of magnitude faster by simply replacing its density estimator with the proposed density estimator, enabling it to deal with large datasets with thousands of dimensions that would otherwise be impossible. version:2
arxiv-1709-03688 | Joint Dictionaries for Zero-Shot Learning | http://arxiv.org/abs/1709.03688 | id:1709.03688 author:Soheil Kolouri, Mohammad Rostami, Yuri Owechko, Kyungnam Kim category:cs.CV  published:2017-09-12 summary:A classic approach toward zero-shot learning (ZSL) is to map the input domain to a set of semantically meaningful attributes that could be used later on to classify unseen classes of data (e.g. visual data). In this paper, we propose to learn a visual feature dictionary that has semantically meaningful atoms. Such dictionary is learned via joint dictionary learning for the visual domain and the attribute domain, while enforcing the same sparse coding for both dictionaries. Our novel attribute aware formulation provides an algorithmic solution to the domain shift/hubness problem in ZSL. Upon learning the joint dictionaries, images from unseen classes can be mapped into the attribute space by finding the attribute aware joint sparse representation using solely the visual data. We demonstrate that our approach provides superior or comparable performance to that of the state of the art on benchmark datasets. version:1
arxiv-1709-01672 | Throughput Optimal Decentralized Scheduling of Multi-Hop Networks with End-to-End Deadline Constraints: II Wireless Networks with Interference | http://arxiv.org/abs/1709.01672 | id:1709.01672 author:Rahul Singh, P. R. Kumar, Eytan Modiano category:cs.NI cs.LG cs.NE cs.SY  published:2017-09-06 summary:Consider a multihop wireless network serving multiple flows in which wireless link interference constraints are described by a link interference graph. For such a network, we design routing-scheduling policies that maximize the end-to-end timely throughput of the network. Timely throughput of a flow $f$ is defined as the average rate at which packets of flow $f$ reach their destination node $d_f$ within their deadline. Our policy has several surprising characteristics. Firstly, we show that the optimal routing-scheduling decision for an individual packet that is present at a wireless node $i\in V$ is solely a function of its location, and "age". Thus, a wireless node $i$ does not require the knowledge of the "global" network state in order to maximize the timely throughput. We notice that in comparison, under the backpressure routing policy, a node $i$ requires only the knowledge of its neighbours queue lengths in order to guarantee maximal stability, and hence is decentralized. The key difference arises due to the fact that in our set-up the packets loose their utility once their "age" has crossed their deadline, thus making the task of optimizing timely throughput much more challenging than that of ensuring network stability. Of course, due to this key difference, the decision process involved in maximizing the timely throughput is also much more complex than that involved in ensuring network-wide queue stabilization. In view of this, our results are somewhat surprising. version:2
arxiv-1709-03675 | Adversarial Discriminative Heterogeneous Face Recognition | http://arxiv.org/abs/1709.03675 | id:1709.03675 author:Lingxiao Song, Man Zhang, Xiang Wu, Ran He category:cs.CV  published:2017-09-12 summary:The gap between sensing patterns of different face modalities remains a challenging problem in heterogeneous face recognition (HFR). This paper proposes an adversarial discriminative feature learning framework to close the sensing gap via adversarial learning on both raw-pixel space and compact feature space. This framework integrates cross-spectral face hallucination and discriminative feature learning into an end-to-end adversarial network. In the pixel space, we make use of generative adversarial networks to perform cross-spectral face hallucination. An elaborate two-path model is introduced to alleviate the lack of paired images, which gives consideration to both global structures and local textures. In the feature space, an adversarial loss and a high-order variance discrepancy loss are employed to measure the global and local discrepancy between two heterogeneous distributions respectively. These two losses enhance domain-invariant feature learning and modality independent noise removing. Experimental results on three NIR-VIS databases show that our proposed approach outperforms state-of-the-art HFR methods, without requiring of complex network or large-scale training dataset. version:1
arxiv-1709-03671 | Rapid Near-Neighbor Interaction of High-dimensional Data via Hierarchical Clustering | http://arxiv.org/abs/1709.03671 | id:1709.03671 author:Nikos Pitsianis, Dimitris Floros, Alexandros-Stavros Iliopoulos, Kostas Mylonakis, Nikos Sismanis, Xiaobai Sun category:cs.LG  published:2017-09-12 summary:Calculation of near-neighbor interactions among high dimensional, irregularly distributed data points is a fundamental task to many graph-based or kernel-based machine learning algorithms and applications. Such calculations, involving large, sparse interaction matrices, expose the limitation of conventional data-and-computation reordering techniques for improving space and time locality on modern computer memory hierarchies. We introduce a novel method for obtaining a matrix permutation that renders a desirable sparsity profile. The method is distinguished by the guiding principle to obtain a profile that is block-sparse with dense blocks. Our profile model and measure capture the essential properties affecting space and time locality, and permit variation in sparsity profile without imposing a restriction to a fixed pattern. The second distinction lies in an efficient algorithm for obtaining a desirable profile, via exploring and exploiting multi-scale cluster structure hidden in but intrinsic to the data. The algorithm accomplishes its task with key components for lower-dimensional embedding with data-specific principal feature axes, hierarchical data clustering, multi-level matrix compression storage, and multi-level interaction computations. We provide experimental results from case studies with two important data analysis algorithms. The resulting performance is remarkably comparable to the BLAS performance for the best-case interaction governed by a regularly banded matrix with the same sparsity. version:1
arxiv-1709-03670 | Community Recovery in Hypergraphs | http://arxiv.org/abs/1709.03670 | id:1709.03670 author:Kwangjun Ahn, Kangwook Lee, Changho Suh category:cs.IT cs.LG math.IT stat.ML  published:2017-09-12 summary:Community recovery is a central problem that arises in a wide variety of applications such as network clustering, motion segmentation, face clustering and protein complex detection. The objective of the problem is to cluster data points into distinct communities based on a set of measurements, each of which is associated with the values of a certain number of data points. While most of the prior works focus on a setting in which the number of data points involved in a measurement is two, this work explores a generalized setting in which the number can be more than two. Motivated by applications particularly in machine learning and channel coding, we consider two types of measurements: (1) homogeneity measurement which indicates whether or not the associated data points belong to the same community; (2) parity measurement which denotes the modulo-2 sum of the values of the data points. Such measurements are possibly corrupted by Bernoulli noise. We characterize the fundamental limits on the number of measurements required to reconstruct the communities for the considered models. version:1
arxiv-1709-03665 | Small-footprint Keyword Spotting Using Deep Neural Network and Connectionist Temporal Classifier | http://arxiv.org/abs/1709.03665 | id:1709.03665 author:Zhiming Wang, Xiaolong Li, Jun Zhou category:cs.CL  published:2017-09-12 summary:Mainly for the sake of solving the lack of keyword-specific data, we propose one Keyword Spotting (KWS) system using Deep Neural Network (DNN) and Connectionist Temporal Classifier (CTC) on power-constrained small-footprint mobile devices, taking full advantage of general corpus from continuous speech recognition which is of great amount. DNN is to directly predict the posterior of phoneme units of any personally customized key-phrase, and CTC to produce a confidence score of the given phoneme sequence as responsive decision-making mechanism. The CTC-KWS has competitive performance in comparison with purely DNN based keyword specific KWS, but not increasing any computational complexity. version:1
arxiv-1709-03659 | Multi-view Graph Embedding with Hub Detection for Brain Network Analysis | http://arxiv.org/abs/1709.03659 | id:1709.03659 author:Guixiang Ma, Chun-Ta Lu, Lifang He, Philip S. Yu, Ann B. Ragin category:cs.LG  published:2017-09-12 summary:Multi-view graph embedding has become a widely studied problem in the area of graph learning. Most of the existing works on multi-view graph embedding aim to find a shared common node embedding across all the views of the graph by combining the different views in a specific way. Hub detection, as another essential topic in graph mining has also drawn extensive attentions in recent years, especially in the context of brain network analysis. Both the graph embedding and hub detection relate to the node clustering structure of graphs. The multi-view graph embedding usually implies the node clustering structure of the graph based on the multiple views, while the hubs are the boundary-spanning nodes across different node clusters in the graph and thus may potentially influence the clustering structure of the graph. However, none of the existing works in multi-view graph embedding considered the hubs when learning the multi-view embeddings. In this paper, we propose to incorporate the hub detection task into the multi-view graph embedding framework so that the two tasks could benefit each other. Specifically, we propose an auto-weighted framework of Multi-view Graph Embedding with Hub Detection (MVGE-HD) for brain network analysis. The MVGE-HD framework learns a unified graph embedding across all the views while reducing the potential influence of the hubs on blurring the boundaries between node clusters in the graph, thus leading to a clear and discriminative node clustering structure for the graph. We apply MVGE-HD on two real multi-view brain network datasets (i.e., HIV and Bipolar). The experimental results demonstrate the superior performance of the proposed framework in brain network analysis for clinical investigation and application. version:1
arxiv-1709-03658 | End-to-End Waveform Utterance Enhancement for Direct Evaluation Metrics Optimization by Fully Convolutional Neural Networks | http://arxiv.org/abs/1709.03658 | id:1709.03658 author:Szu-Wei Fu, Yu Tsao, Xugang Lu, Hisashi Kawai category:stat.ML cs.LG cs.SD  published:2017-09-12 summary:Speech enhancement model is used to map a noisy speech to a clean speech. In the training stage, an objective function is often adopted to optimize the model parameters. However, in most studies, there is an inconsistency between the model optimization criterion and the evaluation criterion on the enhanced speech. For example, in measuring speech intelligibility, most of the evaluation metric is based on a short-time objective intelligibility (STOI) measure, while the frame based minimum mean square error (MMSE) between estimated and clean speech is widely used in optimizing the model. Due to the inconsistency, there is no guarantee that the trained model can provide optimal performance in applications. In this study, we propose an end-to-end utterance-based speech enhancement framework using fully convolutional neural networks (FCN) to reduce the gap between the model optimization and evaluation criterion (true targets). Because of the utterance-based optimization, temporal correlation information of long speech segments, or even at the entire utterance level, can be considered when perception-based objective functions are used for the direct optimization. As an example, we implement the proposed FCN enhancement framework to optimize the STOI measure. Experimental results show that the STOI of test speech is better than conventional MMSE-optimized speech due to the consistency between the training and evaluation target. Moreover, by integrating the STOI in model optimization, the performance of the automatic speech recognition (ASR) system on the enhanced speech is also substantially improved compared to those generated by the MMSE criterion. version:1
arxiv-1709-03657 | Uniform Concentration of the Loss Estimator for Neural DUDE | http://arxiv.org/abs/1709.03657 | id:1709.03657 author:Taesup Moon category:cs.LG cs.IT math.IT  published:2017-09-12 summary:We give a theoretical justification of the concentration property observed for the recently developed neural network-based sliding window discrete denoiser, Neural DUDE. Namely, we rigorously prove that the estimated loss devised for Neural DUDE, computed solely from the noisy data, concentrates on the true denoising loss, which can only be evaluated with the underlying clean data. The concentration is shown to hold in a strong sense, i.e., it uniformly holds over \emph{all} the bounded network parameters including the parameters of Neural DUDE and over \emph{all} possible underlying clean data, with high probability. Moreover, we characterize the sufficient condition for the concentration, in terms of the sliding window size $k$ and the data size $n$, as $k=o(\sqrt{n})$, which is a much weaker condition than that of DUDE, the predecessor of Neural DUDE. For the proof, we make a novel application of the tools of the learning theory, e.g., Rademacher complexity. We conclude with experimental results that highlight the theoretical results and advocate the hyperparamter selection method of Neural DUDE. version:1
arxiv-1709-03656 | Joint Adaptive Neighbours and Metric Learning for Multi-view Subspace Clustering | http://arxiv.org/abs/1709.03656 | id:1709.03656 author:Nan Xu, Yanqing Guo, Jiujun Wang, Xiangyang Luo, Ran He category:cs.CV  published:2017-09-12 summary:Due to the existence of various views or representations in many real-world data, multi-view learning has drawn much attention recently. Multi-view spectral clustering methods based on similarity matrixes or graphs are pretty popular. Generally, these algorithms learn informative graphs by directly utilizing original data. However, in the real-world applications, original data often contain noises and outliers that lead to unreliable graphs. In addition, different views may have different contributions to data clustering. In this paper, a novel Multiview Subspace Clustering method unifying Adaptive neighbours and Metric learning (MSCAM), is proposed to address the above problems. In this method, we use the subspace representations of different views to adaptively learn a consensus similarity matrix, uncovering the subspace structure and avoiding noisy nature of original data. For all views, we also learn different Mahalanobis matrixes that parameterize the squared distances and consider the contributions of different views. Further, we constrain the graph constructed by the similarity matrix to have exact c (c is the number of clusters) connected components. An iterative algorithm is developed to solve this optimization problem. Moreover, experiments on a synthetic dataset and different real-world datasets demonstrate the effectiveness of MSCAM. version:1
arxiv-1709-03654 | Anti-Makeup: Learning A Bi-Level Adversarial Network for Makeup-Invariant Face Verification | http://arxiv.org/abs/1709.03654 | id:1709.03654 author:Yi Li, Lingxiao Song, Xiang Wu, Ran He, Tieniu Tan category:cs.CV  published:2017-09-12 summary:Makeup is widely used to improve facial attractiveness and is well accepted by the public. However, different makeup styles will result in significant facial appearance changes. It remains a challenging problem to match makeup and non-makeup face images. This paper proposes a learning from generation approach for makeup-invariant face verification by introducing a bi-level adversarial network (BLAN). To alleviate the negative effects from makeup, we first generate non-makeup images from makeup ones, and then use the synthesized non-makeup images for further verification. Two adversarial networks in BLAN are integrated in an end-to-end deep network, with the one on pixel level for reconstructing appealing facial images and the other on feature level for preserving identity information. These two networks jointly reduce the sensing gap between makeup and non-makeup images. Moreover, we make the generator well constrained by incorporating multiple perceptual losses. Experimental results on three benchmark makeup face datasets demonstrate that our method achieves state-of-the-art verification accuracy across makeup status and can produce photo-realistic non-makeup face images. version:1
arxiv-1709-03645 | Identifying Genetic Risk Factors via Sparse Group Lasso with Group Graph Structure | http://arxiv.org/abs/1709.03645 | id:1709.03645 author:Tao Yang, Paul Thompson, Sihai Zhao, Jieping Ye category:stat.ML cs.LG q-bio.GN  published:2017-09-12 summary:Genome-wide association studies (GWA studies or GWAS) investigate the relationships between genetic variants such as single-nucleotide polymorphisms (SNPs) and individual traits. Recently, incorporating biological priors together with machine learning methods in GWA studies has attracted increasing attention. However, in real-world, nucleotide-level bio-priors have not been well-studied to date. Alternatively, studies at gene-level, for example, protein--protein interactions and pathways, are more rigorous and legitimate, and it is potentially beneficial to utilize such gene-level priors in GWAS. In this paper, we proposed a novel two-level structured sparse model, called Sparse Group Lasso with Group-level Graph structure (SGLGG), for GWAS. It can be considered as a sparse group Lasso along with a group-level graph Lasso. Essentially, SGLGG penalizes the nucleotide-level sparsity as well as takes advantages of gene-level priors (both gene groups and networks), to identifying phenotype-associated risk SNPs. We employ the alternating direction method of multipliers algorithm to optimize the proposed model. Our experiments on the Alzheimer's Disease Neuroimaging Initiative whole genome sequence data and neuroimage data demonstrate the effectiveness of SGLGG. As a regression model, it is competitive to the state-of-the-arts sparse models; as a variable selection method, SGLGG is promising for identifying Alzheimer's disease-related risk SNPs. version:1
arxiv-1705-06808 | Analysis of Thompson Sampling for Gaussian Process Optimization in the Bandit Setting | http://arxiv.org/abs/1705.06808 | id:1705.06808 author:Kinjal Basu, Souvik Ghosh category:stat.ML stat.ME  published:2017-05-18 summary:We consider the global optimization of a function over a continuous domain. At every evaluation attempt, we can observe the function at a chosen point in the domain and we reap the reward of the value observed. We assume that drawing these observations are expensive and noisy. We frame it as a continuum-armed bandit problem with a Gaussian Process prior on the function. In this regime, most algorithms have been developed to minimize some form of regret. Contrary to this popular norm, in this paper, we study the convergence of the sequential point $x^t$ to the global optimizer $x^*$ for the Thompson Sampling approach. Under some very mild assumptions, we show that the point sequence convergences to the true optimal. version:2
arxiv-1709-03629 | What were you expecting? Using Expectancy Features to Predict Expressive Performances of Classical Piano Music | http://arxiv.org/abs/1709.03629 | id:1709.03629 author:Carlos Cancino-Chacón, Maarten Grachten, David R. W. Sears, Gerhard Widmer category:cs.SD cs.IT cs.LG math.IT  published:2017-09-11 summary:In this paper we present preliminary work examining the relationship between the formation of expectations and the realization of musical performances, paying particular attention to expressive tempo and dynamics. To compute features that reflect what a listener is expecting to hear, we employ a computational model of auditory expectation called the Information Dynamics of Music model (IDyOM). We then explore how well these expectancy features -- when combined with score descriptors using the Basis-Function modeling approach -- can predict expressive tempo and dynamics in a dataset of Mozart piano sonata performances. Our results suggest that using expectancy features significantly improves the predictions for tempo. version:1
arxiv-1709-03615 | Manifold Learning Using Kernel Density Estimation and Local Principal Components Analysis | http://arxiv.org/abs/1709.03615 | id:1709.03615 author:Kitty Mohammed, Hariharan Narayanan category:math.ST stat.ML stat.TH  published:2017-09-11 summary:We consider the problem of recovering a $d-$dimensional manifold $\mathcal{M} \subset \mathbb{R}^n$ when provided with noiseless samples from $\mathcal{M}$. There are many algorithms (e.g., Isomap) that are used in practice to fit manifolds and thus reduce the dimensionality of a given data set. Ideally, the estimate $\mathcal{M}_\mathrm{put}$ of $\mathcal{M}$ should be an actual manifold of a certain smoothness; furthermore, $\mathcal{M}_\mathrm{put}$ should be arbitrarily close to $\mathcal{M}$ in Hausdorff distance given a large enough sample. Generally speaking, existing manifold learning algorithms do not meet these criteria. Fefferman, Mitter, and Narayanan (2016) have developed an algorithm whose output is provably a manifold. The key idea is to define an approximate squared-distance function (asdf) to $\mathcal{M}$. Then, $\mathcal{M}_\mathrm{put}$ is given by the set of points where the gradient of the asdf is orthogonal to the subspace spanned by the largest $n - d$ eigenvectors of the Hessian of the asdf. As long as the asdf meets certain regularity conditions, $\mathcal{M}_\mathrm{put}$ is a manifold that is arbitrarily close in Hausdorff distance to $\mathcal{M}$. In this paper, we define two asdfs that can be calculated from the data and show that they meet the required regularity conditions. The first asdf is based on kernel density estimation, and the second is based on estimation of tangent spaces using local principal components analysis. version:1
arxiv-1704-05526 | Learning to Reason: End-to-End Module Networks for Visual Question Answering | http://arxiv.org/abs/1704.05526 | id:1704.05526 author:Ronghang Hu, Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Kate Saenko category:cs.CV  published:2017-04-18 summary:Natural language questions are inherently compositional, and many are most easily answered by reasoning about their decomposition into modular sub-problems. For example, to answer "is there an equal number of balls and boxes?" we can look for balls, look for boxes, count them, and compare the results. The recently proposed Neural Module Network (NMN) architecture implements this approach to question answering by parsing questions into linguistic substructures and assembling question-specific deep networks from smaller modules that each solve one subtask. However, existing NMN implementations rely on brittle off-the-shelf parsers, and are restricted to the module configurations proposed by these parsers rather than learning them from data. In this paper, we propose End-to-End Module Networks (N2NMNs), which learn to reason by directly predicting instance-specific network layouts without the aid of a parser. Our model learns to generate network structures (by imitating expert demonstrations) while simultaneously learning network parameters (using the downstream task loss). Experimental results on the new CLEVR dataset targeted at compositional question answering show that N2NMNs achieve an error reduction of nearly 50% relative to state-of-the-art attentional approaches, while discovering interpretable network architectures specialized for each question. version:3
arxiv-1709-03612 | Holistic, Instance-Level Human Parsing | http://arxiv.org/abs/1709.03612 | id:1709.03612 author:Qizhu Li, Anurag Arnab, Philip H. S. Torr category:cs.CV  published:2017-09-11 summary:Object parsing -- the task of decomposing an object into its semantic parts -- has traditionally been formulated as a category-level segmentation problem. Consequently, when there are multiple objects in an image, current methods cannot count the number of objects in the scene, nor can they determine which part belongs to which object. We address this problem by segmenting the parts of objects at an instance-level, such that each pixel in the image is assigned a part label, as well as the identity of the object it belongs to. Moreover, we show how this approach benefits us in obtaining segmentations at coarser granularities as well. Our proposed network is trained end-to-end given detections, and begins with a category-level segmentation module. Thereafter, a differentiable Conditional Random Field, defined over a variable number of instances for every input image, reasons about the identity of each part by associating it with a human detection. In contrast to other approaches, our method can handle the varying number of people in each image and our holistic network produces state-of-the-art results in instance-level part and human segmentation, together with competitive results in category-level part segmentation, all achieved by a single forward-pass through our neural network. version:1
arxiv-1709-03588 | On the definition of Shape Parts: a Dominant Sets Approach | http://arxiv.org/abs/1709.03588 | id:1709.03588 author:Foteini Fotopoulou, George Economou category:cs.CV  published:2017-09-11 summary:In the present paper a novel graph-based approach to the shape decomposition problem is addressed. The shape is appropriately transformed into a visibility graph enriched with local neighborhood information. A two-step diffusion process is then applied to the visibility graph that efficiently enhances the information provided, thus leading to a more robust and meaningful graph construction. Inspired by the notion of a clique as a strict cluster definition, the dominant sets algorithm is invoked, slightly modified to comport with the specific problem of defining shape parts. The cluster cohesiveness and a node participation vector are two important outputs of the proposed graph partitioning method. Opposed to most of the existing techniques, the final number of the clusters is determined automatically, by estimating the cluster cohesiveness on a random network generation process. Experimental results on several shape databases show the effectiveness of our framework for graph based shape decomposition. version:1
arxiv-1709-03573 | Anomaly Detection in Hierarchical Data Streams under Unknown Models | http://arxiv.org/abs/1709.03573 | id:1709.03573 author:Sattar Vakili, Qing Zhao, Chang Liu, Chen-Nee Chuah category:cs.LG  published:2017-09-11 summary:We consider the problem of detecting a few targets among a large number of hierarchical data streams. The data streams are modeled as random processes with unknown and potentially heavy-tailed distributions. The objective is an active inference strategy that determines, sequentially, which data stream to collect samples from in order to minimize the sample complexity under a reliability constraint. We propose an active inference strategy that induces a biased random walk on the tree-structured hierarchy based on confidence bounds of sample statistics. We then establish its order optimality in terms of both the size of the search space (i.e., the number of data streams) and the reliability requirement. The results find applications in hierarchical heavy hitter detection, noisy group testing, and adaptive sampling for active learning, classification, and stochastic root finding. version:1
arxiv-1709-03562 | False arrhythmia alarm reduction in the intensive care unit | http://arxiv.org/abs/1709.03562 | id:1709.03562 author:Andrea S. Li, Alistair E. W. Johnson, Roger G. Mark category:cs.LG I.5.4  published:2017-09-11 summary:Research has shown that false alarms constitute more than 80% of the alarms triggered in the intensive care unit (ICU). The high false arrhythmia alarm rate has severe implications such as disruption of patient care, caregiver alarm fatigue, and desensitization from clinical staff to real life-threatening alarms. A method to reduce the false alarm rate would therefore greatly benefit patients as well as nurses in their ability to provide care. We here develop and describe a robust false arrhythmia alarm reduction system for use in the ICU. Building off of work previously described in the literature, we make use of signal processing and machine learning techniques to identify true and false alarms for five arrhythmia types. This baseline algorithm alone is able to perform remarkably well, with a sensitivity of 0.908, a specificity of 0.838, and a PhysioNet/CinC challenge score of 0.756. We additionally explore dynamic time warping techniques on both the entire alarm signal as well as on a beat-by-beat basis in an effort to improve performance of ventricular tachycardia, which has in the literature been one of the hardest arrhythmias to classify. Such an algorithm with strong performance and efficiency could potentially be translated for use in the ICU to promote overall patient care and recovery. version:1
arxiv-1709-03553 | Extracting Traffic Primitives Directly from Naturalistically Logged Data for Self-Driving Applications | http://arxiv.org/abs/1709.03553 | id:1709.03553 author:Wenshuo Wang, Ding Zhao category:cs.CV  published:2017-09-11 summary:Developing an automated vehicle, that can handle the complicated driving scenarios and appropriately interact with other road users, requires the ability to semantically learn and understand the driving environment, oftentimes, based on the analysis of massive amount of naturalistic driving data. An important paradigm that allows automated vehicles to both learn from human drivers and develop deeper insights is understanding traffic primitives, representing principal compositions of the entire traffic. However, the exploding driving data growth presents a great challenge in extracting primitives from a long-term multidimensional time-series traffic scenario data with multiscale varieties of road users get involved. Therefore, automatic primitive extraction is becoming one of the cost-efficient ways to help autonomous vehicles understand and predict the complex traffic scenarios. In addition, the extracted primitives from raw data should 1) be appropriate for automated driving applications and also 2) be easily combined to generate new driving scenarios. Existing literature does not provide a method to automatically learn these primitives from large-scale traffic data. The contribution of this paper has two manifolds. One is that we proposed a new framework to generate new traffic scenarios from a handful of limited traffic data. The other one is that we introduce a nonparametric Bayesian learning method -- a sticky hierarchical Dirichlet process hidden Markov model -- that can automatically extract primitives from multidimensional driving data without prior knowledge of the primitive settings. The developed method is validated using one day of naturalistic driving data. Experiment results show that the nonparametric Bayesian learning method extracts primitives from traffic scenarios where both the binary and continuous events coexist. version:1
arxiv-1709-03548 | Exploring Geometric Property Thresholds For Filtering Non-Text Regions In A Connected Component Based Text Detection Application | http://arxiv.org/abs/1709.03548 | id:1709.03548 author:Teresa Nicole Brooks category:cs.CV  published:2017-09-11 summary:Automated text detection is a difficult computer vision task. In order to accurately detect and identity text in an image or video, two major problems must be addressed. The primary problem is implementing a robust and reliable method for distinguishing text vs non-text regions in images and videos. Part of the difficulty stems from the almost unlimited combinations of fonts, lighting conditions, distortions, and other variations that can be found in images and videos. This paper explores key properties of two popular and proven methods for implementing text detection; maximum stable external regions (MSER) and stroke width variation. version:1
arxiv-1708-08557 | A parameterized activation function for learning fuzzy logic operations in deep neural networks | http://arxiv.org/abs/1708.08557 | id:1708.08557 author:Luke B. Godfrey, Michael S. Gashler category:cs.NE  published:2017-08-28 summary:We present a deep learning architecture for learning fuzzy logic expressions. Our model uses an innovative, parameterized, differentiable activation function that can learn a number of logical operations by gradient descent. This activation function allows a neural network to determine the relationships between its input variables and provides insight into the logical significance of learned network parameters. We provide a theoretical basis for this parameterization and demonstrate its effectiveness and utility by successfully applying our model to five classification problems from the UCI Machine Learning Repository. version:2
arxiv-1709-03544 | KnowNER: Incremental Multilingual Knowledge in Named Entity Recognition | http://arxiv.org/abs/1709.03544 | id:1709.03544 author:Dominic Seyler, Tatiana Dembelova, Luciano Del Corro, Johannes Hoffart, Gerhard Weikum category:cs.CL  published:2017-09-11 summary:KnowNER is a multilingual Named Entity Recognition (NER) system that leverages different degrees of external knowledge. A novel modular framework divides the knowledge into four categories according to the depth of knowledge they convey. Each category consists of a set of features automatically generated from different information sources (such as a knowledge-base, a list of names or document-specific semantic annotations) and is used to train a conditional random field (CRF). Since those information sources are usually multilingual, KnowNER can be easily trained for a wide range of languages. In this paper, we show that the incorporation of deeper knowledge systematically boosts accuracy and compare KnowNER with state-of-the-art NER approaches across three languages (i.e., English, German and Spanish) performing amongst state-of-the art systems in all of them. version:1
arxiv-1709-03524 | Recovering Homography from Camera Captured Documents using Convolutional Neural Networks | http://arxiv.org/abs/1709.03524 | id:1709.03524 author:Syed Ammar Abbas, Sibt ul Hussain category:cs.CV  published:2017-09-11 summary:Removing perspective distortion from hand held camera captured document images is one of the primitive tasks in document analysis, but unfortunately, no such method exists that can reliably remove the perspective distortion from document images automatically. In this paper, we propose a convolutional neural network based method for recovering homography from hand-held camera captured documents. Our proposed method works independent of document's underlying content and is trained end-to-end in a fully automatic way. Specifically, this paper makes following three contributions: Firstly, we introduce a large scale synthetic dataset for recovering homography from documents images captured under different geometric and photometric transformations; secondly, we show that a generic convolutional neural network based architecture can be successfully used for regressing the corners positions of documents captured under wild settings; thirdly, we show that L1 loss can be reliably used for corners regression. Our proposed method gives state-of-the-art performance on the tested datasets, and has potential to become an integral part of document analysis pipeline. version:1
arxiv-1709-03481 | Deep Generative Filter for Motion Deblurring | http://arxiv.org/abs/1709.03481 | id:1709.03481 author:Sainandan Ramakrishnan, Shubham Pachori. Aal, Shanmuganathan Raman category:cs.CV  published:2017-09-11 summary:Removing blur caused by camera shake in images has always been a challenging problem in computer vision literature due to its ill-posed nature. Motion blur caused due to the relative motion between the camera and the object in 3D space induces a spatially varying blurring effect over the entire image. In this paper, we propose a novel deep filter based on Generative Adversarial Network (GAN) architecture integrated with global skip connection and dense architecture in order to tackle this problem. Our model, while bypassing the process of blur kernel estimation, significantly reduces the test time which is necessary for practical applications. The experiments on the benchmark datasets prove the effectiveness of the proposed method which outperforms the state-of-the-art blind deblurring algorithms both quantitatively and qualitatively. version:1
arxiv-1706-05374 | Expected Policy Gradients | http://arxiv.org/abs/1706.05374 | id:1706.05374 author:Kamil Ciosek, Shimon Whiteson category:stat.ML cs.LG 90C40 I.2.8; G.3  published:2017-06-15 summary:We propose expected policy gradients (EPG), which unify stochastic policy gradients (SPG) and deterministic policy gradients (DPG) for reinforcement learning. Inspired by expected sarsa, EPG integrates across the action when estimating the gradient, instead of relying only on the action in the sampled trajectory. We establish a new general policy gradient theorem, of which the stochastic and deterministic policy gradient theorems are special cases. We also prove that EPG reduces the variance of the gradient estimates without requiring deterministic policies and, for the Gaussian case, with no computational overhead. Finally, we show that it is optimal in a certain sense to explore with a Gaussian policy such that the covariance is proportional to the exponential of the scaled Hessian of the critic with respect to the actions. We present empirical results confirming that this new form of exploration substantially outperforms DPG with the Ornstein-Uhlenbeck heuristic in four challenging MuJoCo domains. version:2
arxiv-1709-00944 | Audio-Visual Speech Enhancement based on Multimodal Deep Convolutional Neural Network | http://arxiv.org/abs/1709.00944 | id:1709.00944 author:Jen-Cheng Hou, Syu-Siang Wang, Ying-Hui Lai, Yu Tsao, Hsiu-Wen Chang, Hsin-Min Wang category:cs.SD cs.MM stat.ML  published:2017-09-01 summary:Speech enhancement (SE) aims to reduce noise in speech signals. Most SE techniques focus on addressing audio information only. In this work, inspired by multimodal learning, which utilizes data from different modalities, and the recent success of convolutional neural networks (CNNs) in SE, we propose an audio-visual deep CNN (AVDCNN) SE model, which incorporates audio and visual streams into a unified network model. In the proposed AVDCNN SE model, audio and visual data are first processed using individual CNNs, and then, fused into a joint network to generate enhanced speech at the output layer. The AVDCNN model is trained in an end-to-end manner, and parameters are jointly learned through back-propagation. We evaluate enhanced speech using five objective criteria. Results show that the AVDCNN yields notably better performance, compared with an audio-only CNN-based SE model and two conventional SE approaches, confirming the effectiveness of integrating visual information into the SE process. version:2
arxiv-1709-03441 | The Diverse Cohort Selection Problem: Multi-Armed Bandits with Varied Pulls | http://arxiv.org/abs/1709.03441 | id:1709.03441 author:Candice Schumann, Samsara N. Counts, Jeffrey S. Foster, John P. Dickerson category:cs.LG  published:2017-09-11 summary:How should a firm allocate its limited interviewing resources to select the optimal cohort of new employees from a large set of job applicants? How should that firm allocate cheap but noisy resume screenings and expensive but in-depth in-person interviews? We view this problem through the lens of combinatorial pure exploration (CPE) in the multi-armed bandit setting, where a central learning agent performs costly exploration of a set of arms before selecting a final subset with some combinatorial structure. We generalize a recent CPE algorithm to the setting where arm pulls can have different cost, but return different levels of information, and prove theoretical upper bounds for a general class of arm-pulling strategies in this new setting. We then apply our general algorithm to a real-world problem with combinatorial structure: incorporating diversity into university admissions. We take real data from admissions at one of the largest US-based computer science graduate programs and show that a simulation of our algorithm produced more diverse student cohorts at low cost to individual student quality, and does so by spending comparable budget to the current admissions process at that university. version:1
arxiv-1709-03439 | Why Do Deep Neural Networks Still Not Recognize These Images?: A Qualitative Analysis on Failure Cases of ImageNet Classification | http://arxiv.org/abs/1709.03439 | id:1709.03439 author:Han S. Lee, Alex A. Agarwal, Junmo Kim category:cs.CV  published:2017-09-11 summary:In a recent decade, ImageNet has become the most notable and powerful benchmark database in computer vision and machine learning community. As ImageNet has emerged as a representative benchmark for evaluating the performance of novel deep learning models, its evaluation tends to include only quantitative measures such as error rate, rather than qualitative analysis. Thus, there are few studies that analyze the failure cases of deep learning models in ImageNet, though there are numerous works analyzing the networks themselves and visualizing them. In this abstract, we qualitatively analyze the failure cases of ImageNet classification results from recent deep learning model, and categorize these cases according to the certain image patterns. Through this failure analysis, we believe that it can be discovered what the final challenges are in ImageNet database, which the current deep learning model is still vulnerable to. version:1
arxiv-1709-02418 | How Does Knowledge of the AUC Constrain the Set of Possible Ground-truth Labelings? | http://arxiv.org/abs/1709.02418 | id:1709.02418 author:Jacob Whitehill category:cs.LG  published:2017-09-07 summary:Recent work on privacy-preserving machine learning has considered how data-mining competitions such as Kaggle could potentially be "hacked", either intentionally or inadvertently, by using information from an oracle that reports a classifier's accuracy on the test set. For binary classification tasks in particular, one of the most common accuracy metrics is the Area Under the ROC Curve (AUC), and in this paper we explore the mathematical structure of how the AUC is computed from an n-vector of real-valued "guesses" with respect to the ground-truth labels. We show how knowledge of a classifier's AUC on the test set can constrain the set of possible ground-truth labelings, and we derive an algorithm both to compute the exact number of such labelings and to enumerate efficiently over them. Finally, we provide empirical evidence that, surprisingly, the number of compatible labelings can actually decrease as n grows, until a test set-dependent threshold is reached. version:2
arxiv-1709-03423 | Ensemble Methods as a Defense to Adversarial Perturbations Against Deep Neural Networks | http://arxiv.org/abs/1709.03423 | id:1709.03423 author:Thilo Strauss, Markus Hanselmann, Andrej Junginger, Holger Ulmer category:stat.ML cs.LG  published:2017-09-11 summary:Deep learning has become the state of the art approach in many machine learning problems such as classification. It has recently been shown that deep learning is highly vulnerable to adversarial perturbations. Taking the camera systems of self-driving cars as an example, small adversarial perturbations can cause the system to make errors in important tasks, such as classifying traffic signs or detecting pedestrians. Hence, in order to use deep learning without safety concerns a proper defense strategy is required. We propose to use ensemble methods as a defense strategy against adversarial perturbations. We find that an attack leading one model to misclassify does not imply the same for other networks performing the same task. This makes ensemble methods an attractive defense strategy against adversarial attacks. We empirically show for the MNIST and the CIFAR-10 data sets that ensemble methods not only improve the accuracy of neural networks on test data but also increase their robustness against adversarial perturbations. version:1
arxiv-1709-00401 | Statistical Inference for Machine Learning Inverse Probability Weighting with Survival Outcomes | http://arxiv.org/abs/1709.00401 | id:1709.00401 author:Iván Díaz category:stat.ML  published:2017-09-01 summary:We present an inverse probability weighted estimator for survival analysis under informative right censoring. Our estimator has the novel property that it converges to a normal variable at $n^{1/2}$ rate for a large class of censoring probability estimators, including many data-adaptive (e.g., machine learning) prediction methods. We present the formula of the asymptotic variance of the estimator, which allows the computation of asymptotically correct confidence intervals and p-values under data-adaptive estimation of the censoring and treatment probabilities. We demonstrate the asymptotic properties of the estimator in simulation studies, and illustrate its use in a phase III clinical trial for estimating the effect of a novel therapy for the treatment of breast cancer. version:2
arxiv-1709-03410 | One-Shot Learning for Semantic Segmentation | http://arxiv.org/abs/1709.03410 | id:1709.03410 author:Amirreza Shaban, Shray Bansal, Zhen Liu, Irfan Essa, Byron Boots category:cs.CV  published:2017-09-11 summary:Low-shot learning methods for image classification support learning from sparse data. We extend these techniques to support dense semantic image segmentation. Specifically, we train a network that, given a small set of annotated images, produces parameters for a Fully Convolutional Network (FCN). We use this FCN to perform dense pixel-level prediction on a test image for the new semantic class. Our architecture shows a 25% relative meanIoU improvement compared to the best baseline methods for one-shot segmentation on unseen classes in the PASCAL VOC 2012 dataset and is at least 3 times faster. version:1
arxiv-1709-03409 | Generic Sketch-Based Retrieval Learned without Drawing a Single Sketch | http://arxiv.org/abs/1709.03409 | id:1709.03409 author:Filip Radenović, Giorgos Tolias, Ondřej Chum category:cs.CV  published:2017-09-11 summary:We cast the sketch-based retrieval as edge-map matching. A shared convolutional network is trained to extract descriptors from edge maps and sketches, which are treated as a special case of edge maps. The network is fine-tuned solely from edge maps of landmark images. The training images are acquired in a fully unsupervised manner from 3D landmark models obtained by an automated structure-from-motion pipeline. The proposed method achieves the state-of-the-art results on a standard benchmark. On two other fine-grained sketch-based retrieval benchmarks, it performs on par with or comes just after the method specifically designed for the dataset. version:1
arxiv-1709-03406 | Social Media Text Processing and Semantic Analysis for Smart Cities | http://arxiv.org/abs/1709.03406 | id:1709.03406 author:João Filipe Figueiredo Pereira category:cs.SI cs.CL cs.CY  published:2017-09-11 summary:With the rise of Social Media, people obtain and share information almost instantly on a 24/7 basis. Many research areas have tried to gain valuable insights from these large volumes of freely available user generated content. With the goal of extracting knowledge from social media streams that might be useful in the context of intelligent transportation systems and smart cities, we designed and developed a framework that provides functionalities for parallel collection of geo-located tweets from multiple pre-defined bounding boxes (cities or regions), including filtering of non-complying tweets, text pre-processing for Portuguese and English language, topic modeling, and transportation-specific text classifiers, as well as, aggregation and data visualization. We performed an exploratory data analysis of geo-located tweets in 5 different cities: Rio de Janeiro, S\~ao Paulo, New York City, London and Melbourne, comprising a total of more than 43 million tweets in a period of 3 months. Furthermore, we performed a large scale topic modelling comparison between Rio de Janeiro and S\~ao Paulo. Interestingly, most of the topics are shared between both cities which despite being in the same country are considered very different regarding population, economy and lifestyle. We take advantage of recent developments in word embeddings and train such representations from the collections of geo-located tweets. We then use a combination of bag-of-embeddings and traditional bag-of-words to train travel-related classifiers in both Portuguese and English to filter travel-related content from non-related. We created specific gold-standard data to perform empirical evaluation of the resulting classifiers. Results are in line with research work in other application areas by showing the robustness of using word embeddings to learn word similarities that bag-of-words is not able to capture. version:1
arxiv-1709-03399 | Automated Identification of Trampoline Skills Using Computer Vision Extracted Pose Estimation | http://arxiv.org/abs/1709.03399 | id:1709.03399 author:Paul W. Connolly, Guenole C. Silvestre, Chris J. Bleakley category:cs.CV  published:2017-09-11 summary:A novel method to identify trampoline skills using a single video camera is proposed herein. Conventional computer vision techniques are used for identification, estimation, and tracking of the gymnast's body in a video recording of the routine. For each frame, an open source convolutional neural network is used to estimate the pose of the athlete's body. Body orientation and joint angle estimates are extracted from these pose estimates. The trajectories of these angle estimates over time are compared with those of labelled reference skills. A nearest neighbour classifier utilising a mean squared error distance metric is used to identify the skill performed. A dataset containing 714 skill examples with 20 distinct skills performed by adult male and female gymnasts was recorded and used for evaluation of the system. The system was found to achieve a skill identification accuracy of 80.7% for the dataset. version:1
arxiv-1709-01412 | Deep learning: Technical introduction | http://arxiv.org/abs/1709.01412 | id:1709.01412 author:Thomas Epelbaum category:stat.ML cs.LG  published:2017-09-05 summary:This note presents in a technical though hopefully pedagogical way the three most common forms of neural network architectures: Feedforward, Convolutional and Recurrent. For each network, their fundamental building blocks are detailed. The forward pass and the update rules for the backpropagation algorithm are then derived in full. version:2
arxiv-1708-00980 | 3DFaceNet: Real-time Dense Face Reconstruction via Synthesizing Photo-realistic Face Images | http://arxiv.org/abs/1708.00980 | id:1708.00980 author:Yudong Guo, Juyong Zhang, Jianfei Cai, Boyi Jiang, Jianmin Zheng category:cs.CV  published:2017-08-03 summary:With the powerfulness of convolution neural networks (CNN), CNN based face reconstruction has recently shown promising performance in reconstructing detailed face shape from 2D face images. The success of CNN-based methods relies on a large number of labeled data. The state-of-the-art synthesizes such data using a coarse morphable face model, which however has difficulty to generate detailed photo-realistic images of faces (with wrinkles). This paper presents a novel face data generation method. Specifically, we render a large number of photo-realistic face images with different attributes based on inverse rendering. Furthermore, we construct a fine-detailed face image dataset by transferring different scales of details from one image to another. We also construct a large number of video-type adjacent frame pairs by simulating the distribution of real video data. With these nicely constructed datasets, we propose a coarse-to-fine learning framework consisting of three convolutional networks. The networks are trained for real-time detailed 3D face reconstruction from monocular video as well as from a single image. Extensive experimental results demonstrate that our framework can produce high-quality reconstruction but with much less computation time compared to the state-of-the-art. Moreover, our method is robust to pose, expression and lighting due to the diversity of data. version:2
arxiv-1708-03280 | Exploring Temporal Preservation Networks for Precise Temporal Action Localization | http://arxiv.org/abs/1708.03280 | id:1708.03280 author:Ke Yang, Peng Qiao, Dongsheng Li, Shaohe Lv, Yong Dou category:cs.CV  published:2017-08-10 summary:Temporal action localization is an important task of computer vision. Though a variety of methods have been proposed, it still remains an open question how to predict the temporal boundaries of action segments precisely. Most works use segment-level classifiers to select video segments pre-determined by action proposal or dense sliding windows. However, in order to achieve more precise action boundaries, a temporal localization system should make dense predictions at a fine granularity. A newly proposed work exploits Convolutional-Deconvolutional-Convolutional (CDC) filters to upsample the predictions of 3D ConvNets, making it possible to perform per-frame action predictions and achieving promising performance in terms of temporal action localization. However, CDC network loses temporal information partially due to the temporal downsampling operation. In this paper, we propose an elegant and powerful Temporal Preservation Convolutional (TPC) Network that equips 3D ConvNets with TPC filters. TPC network can fully preserve temporal resolution and downsample the spatial resolution simultaneously, enabling frame-level granularity action localization. TPC network can be trained in an end-to-end manner. Experiment results on public datasets show that TPC network achieves significant improvement on per-frame action prediction and competing results on segment-level temporal action localization. version:2
arxiv-1708-07722 | A dependency look at the reality of constituency | http://arxiv.org/abs/1708.07722 | id:1708.07722 author:Xinying Chen, Carlos Gómez-Rodríguez, Ramon Ferrer-i-Cancho category:cs.CL cs.SI physics.soc-ph  published:2017-08-24 summary:A comment on "Neurophysiological dynamics of phrase-structure building during sentence processing" by Nelson et al (2017), Proceedings of the National Academy of Sciences USA 114(18), E3669-E3678. version:2
arxiv-1709-02565 | Segmentation and Classification of Cine-MR Images Using Fully Convolutional Networks and Handcrafted Features | http://arxiv.org/abs/1709.02565 | id:1709.02565 author:M. Hossein Eybposh, Mohammad Haghir Ebrahim-Abadi, Mohammad Jalilpour-Monesi, Seyed Saman Saboksayr category:cs.CV  published:2017-09-08 summary:Three-dimensional cine-MRI is of crucial importance for assessing the cardiac function. Features that describe the anatomy and function of cardiac structures (e.g. Left Ventricle (LV), Right Ventricle (RV), and Myocardium(MC)) are known to have significant diagnostic value and can be computed from 3D cine-MR images. However, these features require precise segmentation of cardiac structures. Among the fully automated segmentation methods, Fully Convolutional Networks (FCN) with Skip Connections have shown robustness in medical segmentation problems. In this study, we develop a complete pipeline for classification of subjects with cardiac conditions based on 3D cine-MRI. For the segmentation task, we develop a 2D FCN and introduce Parallel Paths (PP) as a way to exploit the 3D information of the cine-MR image. For the classification task, 125 features were extracted from the segmented structures, describing their anatomy and function. Next, a two-stage pipeline for feature selection using the LASSO method is developed. A subset of 20 features is selected for classification. Each subject is classified using an ensemble of Logistic Regression, Multi-Layer Perceptron, and Support Vector Machine classifiers through majority voting. The Dice Coefficient for segmentation was 0.95+-0.03, 0.89+-0.13, and 0.90+-0.03 for LV, RV, and MC respectively. The 8-fold cross validation accuracy for the classification task was 95.05% and 92.77% based on ground truth and the proposed methods segmentations respectively. The results show that the PPs increase the segmentation accuracy, by exploiting the spatial relations. Moreover, the classification algorithm and the features showed discriminability while keeping the sensitivity to segmentation error as low as possible. version:2
arxiv-1709-03943 | Support Spinor Machine | http://arxiv.org/abs/1709.03943 | id:1709.03943 author:Kabin Kanjamapornkul, Richard Pinčák, Sanphet Chunithpaisan, Erik Bartoš category:cs.LG eess.SP q-fin.ST stat.ML  published:2017-09-11 summary:We generalize a support vector machine to a support spinor machine by using the mathematical structure of wedge product over vector machine in order to extend field from vector field to spinor field. The separated hyperplane is extended to Kolmogorov space in time series data which allow us to extend a structure of support vector machine to a support tensor machine and a support tensor machine moduli space. Our performance test on support spinor machine is done over one class classification of end point in physiology state of time series data after empirical mode analysis and compared with support vector machine test. We implement algorithm of support spinor machine by using Holo-Hilbert amplitude modulation for fully nonlinear and nonstationary time series data analysis. version:1
arxiv-1709-03247 | Evolution of Convolutional Highway Networks | http://arxiv.org/abs/1709.03247 | id:1709.03247 author:Oliver Kramer category:cs.NE  published:2017-09-11 summary:Convolutional highways are deep networks based on multiple stacked convolutional layers for feature preprocessing. We introduce an evolutionary algorithm (EA) for optimization of the structure and hyperparameters of convolutional highways and demonstrate the potential of this optimization setting on the well-known MNIST data set. The (1+1)-EA employs Rechenberg's mutation rate control and a niching mechanism to overcome local optima adapts the optimization approach. An experimental study shows that the EA is capable of improving the state-of-the-art network contribution and of evolving highway networks from scratch. version:1
arxiv-1709-02753 | Privacy Loss in Apple's Implementation of Differential Privacy on MacOS 10.12 | http://arxiv.org/abs/1709.02753 | id:1709.02753 author:Jun Tang, Aleksandra Korolova, Xiaolong Bai, Xueqiang Wang, Xiaofeng Wang category:cs.CR cs.CY cs.LG  published:2017-09-08 summary:In June 2016, Apple announced that it will deploy differential privacy for some user data collection in order to ensure privacy of user data, even from Apple. The details of Apple's approach remained sparse. Although several patents have since appeared hinting at the algorithms that may be used to achieve differential privacy, they did not include a precise explanation of the approach taken to privacy parameter choice. Such choice and the overall approach to privacy budget use and management are key questions for understanding the privacy protections provided by any deployment of differential privacy. In this work, through a combination of experiments, static and dynamic code analysis of macOS Sierra (Version 10.12) implementation, we shed light on the choices Apple made for privacy budget management. We discover and describe Apple's set-up for differentially private data processing, including the overall data pipeline, the parameters used for differentially private perturbation of each piece of data, and the frequency with which such data is sent to Apple's servers. We find that although Apple's deployment ensures that the (differential) privacy loss per each datum submitted to its servers is $1$ or $2$, the overall privacy loss permitted by the system is significantly higher, as high as $16$ per day for the four initially announced applications of Emojis, New words, Deeplinks and Lookup Hints. Furthermore, Apple renews the privacy budget available every day, which leads to a possible privacy loss of 16 times the number of days since user opt-in to differentially private data collection for those four applications. We advocate that in order to claim the full benefits of differentially private data collection, Apple must give full transparency of its implementation, enable user choice in areas related to privacy loss, and set meaningful defaults on the privacy loss permitted. version:2
arxiv-1707-09482 | Deep Feature Consistent Deep Image Transformations: Downscaling, Decolorization and HDR Tone Mapping | http://arxiv.org/abs/1707.09482 | id:1707.09482 author:Xianxu Hou, Jiang Duan, Guoping Qiu category:cs.CV  published:2017-07-29 summary:Building on crucial insights into the determining factors of the visual integrity of an image and the property of deep convolutional neural network (CNN), we have developed the Deep Feature Consistent Deep Image Transformation (DFC-DIT) framework which unifies challenging one-to-many mapping image processing problems such as image downscaling, decolorization (colour to grayscale conversion) and high dynamic range (HDR) image tone mapping. We train one CNN as a non-linear mapper to transform an input image to an output image following what we term the deep feature consistency principle which is enforced through another pretrained and fixed deep CNN. This is the first work that uses deep learning to solve and unify these three common image processing tasks. We present experimental results to demonstrate the effectiveness of the DFC-DIT technique and its state of the art performances. version:2
arxiv-1709-03209 | Recurrent neural networks based Indic word-wise script identification using character-wise training | http://arxiv.org/abs/1709.03209 | id:1709.03209 author:Rohun Tripathi, Riccha Tripati category:cs.CV  published:2017-09-11 summary:This paper presents a novel methodology of Indic handwritten script recognition using Recurrent Neural Networks and addresses the problem of script recognition in poor data scenarios, such as when only character level online data is available. It is based on the hypothesis that curves of online character data comprise sufficient information for prediction at the word level. Online character data is used to train RNNs using BLSTM architecture which are then used to make predictions of online word level data. These prediction results on the test set are at par with prediction results of models trained with online word data, while the training of the character level model is much less data intensive and takes much less time. Performance for binary-script models and then 5 Indic script models are reported, along with comparison with HMM models.The system is extended for offline data prediction. Raw offline data lacks the temporal information available in online data and required for prediction using models trained with online data. To overcome this, stroke recovery is implemented and the strokes are utilized for predicting using the online character level models. The performance on character and word level offline data is reported. version:1
arxiv-1709-03202 | Semi-Supervised Active Clustering with Weak Oracles | http://arxiv.org/abs/1709.03202 | id:1709.03202 author:Taewan Kim, Joydeep Ghosh category:stat.ML cs.LG  published:2017-09-11 summary:Semi-supervised active clustering (SSAC) utilizes the knowledge of a domain expert to cluster data points by interactively making pairwise "same-cluster" queries. However, it is impractical to ask human oracles to answer every pairwise query. In this paper, we study the influence of allowing "not-sure" answers from a weak oracle and propose algorithms to efficiently handle uncertainties. Different types of model assumptions are analyzed to cover realistic scenarios of oracle abstraction. In the first model, random-weak oracle, an oracle randomly abstains with a certain probability. We also proposed two distance-weak oracle models which simulate the case of getting confused based on the distance between two points in a pairwise query. For each weak oracle model, we show that a small query complexity is adequate for the effective $k$ means clustering with high probability. Sufficient conditions for the guarantee include a $\gamma$-margin property of the data, and an existence of a point close to each cluster center. Furthermore, we provide a sample complexity with a reduced effect of the cluster's margin and only a logarithmic dependency on the data dimension. Our results allow significantly less number of same-cluster queries if the margin of the clusters is tight, i.e. $\gamma \approx 1$. Experimental results on synthetic data show the effective performance of our approach in overcoming uncertainties. version:1
arxiv-1709-02576 | Deep learning for undersampled MRI reconstruction | http://arxiv.org/abs/1709.02576 | id:1709.02576 author:Chang Min Hyun, Hwa Pyung Kim, Sung Min Lee, Sungchul Lee, Jin Keun Seo category:stat.ML cs.LG physics.med-ph  published:2017-09-08 summary:This paper presents a deep learning method for faster magnetic resonance imaging (MRI) by reducing k-space data with sub-Nyquist sampling strategies and provides a rationale for why the proposed approach works well. Uniform subsampling is used in the time-consuming phase-encoding direction to capture high-resolution image information, while permitting the image-folding problem dictated by the Poisson summation formula. To deal with the localization uncertainty due to image folding, very few low-frequency k-space data are added. Training the deep learning net involves input and output images that are pairs of Fourier transforms of the subsampled and fully sampled k-space data. Numerous experiments show the remarkable performance of the proposed method; only 29% of k-space data can generate images of high quality as effectively as standard MRI reconstruction with fully sampled data. version:2
arxiv-1709-03190 | Data-Driven Dialogue Systems for Social Agents | http://arxiv.org/abs/1709.03190 | id:1709.03190 author:Kevin K. Bowden, Shereen Oraby, Amita Misra, Jiaqi Wu, Stephanie Lukin category:cs.CL  published:2017-09-10 summary:In order to build dialogue systems to tackle the ambitious task of holding social conversations, we argue that we need a data driven approach that includes insight into human conversational chit chat, and which incorporates different natural language processing modules. Our strategy is to analyze and index large corpora of social media data, including Twitter conversations, online debates, dialogues between friends, and blog posts, and then to couple this data retrieval with modules that perform tasks such as sentiment and style analysis, topic modeling, and summarization. We aim for personal assistants that can learn more nuanced human language, and to grow from task-oriented agents to more personable social bots. version:1
arxiv-1709-03187 | Applying ACO To Large Scale TSP Instances | http://arxiv.org/abs/1709.03187 | id:1709.03187 author:Darren M. Chitty category:cs.NE  published:2017-09-10 summary:Ant Colony Optimisation (ACO) is a well known metaheuristic that has proven successful at solving Travelling Salesman Problems (TSP). However, ACO suffers from two issues; the first is that the technique has significant memory requirements for storing pheromone levels on edges between cities and second, the iterative probabilistic nature of choosing which city to visit next at every step is computationally expensive. This restricts ACO from solving larger TSP instances. This paper will present a methodology for deploying ACO on larger TSP instances by removing the high memory requirements, exploiting parallel CPU hardware and introducing a significant efficiency saving measure. The approach results in greater accuracy and speed. This enables the proposed ACO approach to tackle TSP instances of up to 200K cities within reasonable timescales using a single CPU. Speedups of as much as 1200 fold are achieved by the technique. version:1
arxiv-1709-03183 | Rates of Convergence of Spectral Methods for Graphon Estimation | http://arxiv.org/abs/1709.03183 | id:1709.03183 author:Jiaming Xu category:stat.ML cs.LG cs.SI math.ST stat.TH  published:2017-09-10 summary:This paper studies the problem of estimating the grahpon model - the underlying generating mechanism of a network. Graphon estimation arises in many applications such as predicting missing links in networks and learning user preferences in recommender systems. The graphon model deals with a random graph of $n$ vertices such that each pair of two vertices $i$ and $j$ are connected independently with probability $\rho \times f(x_i,x_j)$, where $x_i$ is the unknown $d$-dimensional label of vertex $i$, $f$ is an unknown symmetric function, and $\rho$ is a scaling parameter characterizing the graph sparsity. Recent studies have identified the minimax error rate of estimating the graphon from a single realization of the random graph. However, there exists a wide gap between the known error rates of computationally efficient estimation procedures and the minimax optimal error rate. Here we analyze a spectral method, namely universal singular value thresholding (USVT) algorithm, in the relatively sparse regime with the average vertex degree $n\rho=\Omega(\log n)$. When $f$ belongs to H\"{o}lder or Sobolev space with smoothness index $\alpha$, we show the error rate of USVT is at most $(n\rho)^{ -2 \alpha / (2\alpha+d)}$, approaching the minimax optimal error rate $\log (n\rho)/(n\rho)$ for $d=1$ as $\alpha$ increases. Furthermore, when $f$ is analytic, we show the error rate of USVT is at most $\log^d (n\rho)/(n\rho)$. In the special case of stochastic block model with $k$ blocks, the error rate of USVT is at most $k/(n\rho)$, which is larger than the minimax optimal error rate by at most a multiplicative factor $k/\log k$. This coincides with the computational gap observed for community detection. A key step of our analysis is to derive the eigenvalue decaying rate of the edge probability matrix using piecewise polynomial approximations of the graphon function $f$. version:1
arxiv-1709-03170 | An Iterative Regression Approach for Face Pose Estimation from RGB Images | http://arxiv.org/abs/1709.03170 | id:1709.03170 author:Wenye He category:cs.CV  published:2017-09-10 summary:This paper presents a iterative optimization method, explicit shape regression, for face pose detection and localization. The regression function is learnt to find out the entire facial shape and minimize the alignment errors. A cascaded learning framework is employed to enhance shape constraint during detection. A combination of a two-level boosted regression, shape indexed features and a correlation-based feature selection method is used to improve the performance. In this paper, we have explain the advantage of ESR for deformable object like face pose estimation and reveal its generic applications of the method. In the experiment, we compare the results with different work and demonstrate the accuracy and robustness in different scenarios. version:1
arxiv-1709-03167 | Debbie, the Debate Bot of the Future | http://arxiv.org/abs/1709.03167 | id:1709.03167 author:Geetanjali Rakshit, Kevin K. Bowden, Lena Reed, Amita Misra, Marilyn Walker category:cs.CL  published:2017-09-10 summary:Chatbots are a rapidly expanding application of dialogue systems with companies switching to bot services for customer support, and new applications for users interested in casual conversation. One style of casual conversation is argument, many people love nothing more than a good argument. Moreover, there are a number of existing corpora of argumentative dialogues, annotated for agreement and disagreement, stance, sarcasm and argument quality. This paper introduces Debbie, a novel arguing bot, that selects arguments from conversational corpora, and aims to use them appropriately in context. We present an initial working prototype of Debbie, with some preliminary evaluation and describe future work. version:1
arxiv-1709-03163 | Variational inference for the multi-armed contextual bandit | http://arxiv.org/abs/1709.03163 | id:1709.03163 author:Iñigo Urteaga, Chris H. Wiggins category:stat.ML cs.LG stat.CO I.2.6  published:2017-09-10 summary:In many biomedical, science, and engineering problems, one must sequentially decide which action to take next so as to maximize rewards. Reinforcement learning is an area of machine learning that studies how this maximization balances exploration and exploitation, optimizing interactions with the world while simultaneously learning how the world operates. One general class of algorithms for this type of learning is the multi-armed bandit setting and, in particular, the contextual bandit case, in which observed rewards are dependent on each action as well as on given information or 'context' available at each interaction with the world. The Thompson sampling algorithm has recently been shown to perform well in real-world settings and to enjoy provable optimality properties for this set of problems. It facilitates generative and interpretable modeling of the problem at hand, though complexity of the model limits its application, since one must both sample from the distributions modeled and calculate their expected rewards. We here show how these limitations can be overcome using variational approximations, applying to the reinforcement learning case advances developed for the inference case in the machine learning community over the past two decades. We consider bandit applications where the true reward distribution is unknown and approximate it with a mixture model, whose parameters are inferred via variational inference. version:1
arxiv-1709-03162 | Bayesian bandits: balancing the exploration-exploitation tradeoff via double sampling | http://arxiv.org/abs/1709.03162 | id:1709.03162 author:Iñigo Urteaga, Chris H. Wiggins category:stat.ML cs.LG stat.CO I.2.6  published:2017-09-10 summary:Reinforcement learning studies how to balance exploration and exploitation in real-world systems, optimizing interactions with the world while simultaneously learning how the world works. One general class of algorithms for such learning is the multi-armed bandit setting (in which sequential interactions are independent and identically distributed) and the related contextual bandit case, in which the distribution depends on different information or 'context' presented with each interaction. Thompson sampling, though introduced in the 1930s, has recently been shown to perform well and to enjoy provable optimality properties, while at the same time permitting generative, interpretable modeling. In a Bayesian setting, prior knowledge is incorporated and the computed posteriors naturally capture the full state of knowledge. In several application domains, for example in health and medicine, each interaction with the world can be expensive and invasive, whereas drawing samples from the model is relatively inexpensive. Exploiting this viewpoint, we develop a double-sampling technique driven by the uncertainty in the learning process. The proposed algorithm does not make any distributional assumption and it is applicable to complex reward distributions, as long as Bayesian posterior updates are computable. We empirically show that it out-performs (in the sense of regret) Thompson sampling in two classical illustrative cases, i.e., the multi-armed bandit problem with and without context. version:1
arxiv-1709-03159 | R2N2: Residual Recurrent Neural Networks for Multivariate Time Series Forecasting | http://arxiv.org/abs/1709.03159 | id:1709.03159 author:Hardik Goel, Igor Melnyk, Arindam Banerjee category:cs.LG stat.ML  published:2017-09-10 summary:Multivariate time-series modeling and forecasting is an important problem with numerous applications. Traditional approaches such as VAR (vector auto-regressive) models and more recent approaches such as RNNs (recurrent neural networks) are indispensable tools in modeling time-series data. In many multivariate time series modeling problems, there is usually a significant linear dependency component, for which VARs are suitable, and a nonlinear component, for which RNNs are suitable. Modeling such times series with only VAR or only RNNs can lead to poor predictive performance or complex models with large training times. In this work, we propose a hybrid model called R2N2 (Residual RNN), which first models the time series with a simple linear model (like VAR) and then models its residual errors using RNNs. R2N2s can be trained using existing algorithms for VARs and RNNs. Through an extensive empirical evaluation on two real world datasets (aviation and climate domains), we show that R2N2 is competitive, usually better than VAR or RNN, used alone. We also show that R2N2 is faster to train as compared to an RNN, while requiring less number of hidden units. version:1
arxiv-1709-03139 | Fully Convolutional Neural Networks for Dynamic Object Detection in Grid Maps | http://arxiv.org/abs/1709.03139 | id:1709.03139 author:Florian Piewak, Timo Rehfeld, Michael Weber, J. Marius Zöllner category:cs.CV  published:2017-09-10 summary:Grid maps are widely used in robotics to represent obstacles in the environment and differentiating dynamic objects from static infrastructure is essential for many practical applications. In this work, we present a methods that uses a deep convolutional neural network (CNN) to infer whether grid cells are covering a moving object or not. Compared to tracking approaches, that use e.g. a particle filter to estimate grid cell velocities and then make a decision for individual grid cells based on this estimate, our approach uses the entire grid map as input image for a CNN that inspects a larger area around each cell and thus takes the structural appearance in the grid map into account to make a decision. Compared to our reference method, our concept yields a performance increase from 83.9% to 97.2%. A runtime optimized version of our approach yields similar improvements with an execution time of just 10 milliseconds. version:1
arxiv-1709-03138 | Fully Convolutional Neural Networks for Dynamic Object Detection in Grid Maps (Masters Thesis) | http://arxiv.org/abs/1709.03138 | id:1709.03138 author:Florian Piewak category:cs.CV  published:2017-09-10 summary:One of the most important parts of environment perception is the detection of obstacles in the surrounding of the vehicle. To achieve that, several sensors like radars, LiDARs and cameras are installed in autonomous vehicles. The produced sensor data is fused to a general representation of the surrounding. In this thesis the dynamic occupancy grid map approach of Nuss et al. is used while three goals are achieved. First, the approach of Nuss et al. to distinguish between moving and non-moving obstacles is improved by using Fully Convolutional Neural Networks to create a class prediction for each grid cell. For this purpose, the network is initialized with public pre-trained network models and the training is executed with a semi-automatic generated dataset. The second goal is to provide orientation information for each detected moving obstacle. This could improve tracking algorithms, which are based on the dynamic occupancy grid map. The orientation extraction based on the Convolutional Neural Network shows a better performance in comparison to an orientation extraction directly over the velocity information of the dynamic occupancy grid map. A general problem of developing machine learning approaches like Neural Networks is the number of labeled data, which can always be increased. For this reason, the last goal is to evaluate a semi-supervised learning algorithm, to generate automatically more labeled data. The result of this evaluation shows that the automated labeled data does not improve the performance of the Convolutional Neural Network. All in all, the best results are combined to compare the detection against the approach of Nuss et al. [36] and a relative improvement of 34.8% is reached. version:1
arxiv-1709-03128 | DPC-Net: Deep Pose Correction for Visual Localization | http://arxiv.org/abs/1709.03128 | id:1709.03128 author:Valentin Peretroukhin, Jonathan Kelly category:cs.CV  published:2017-09-10 summary:We present a novel method to fuse the power of deep networks with the computational efficiency of geometric and probabilistic localization algorithms. In contrast to other methods that completely replace a classical visual estimator with a deep network, we propose an approach that uses a convolutional neural network to learn difficult-to-model corrections to the estimator from ground-truth training data. To this end, we derive a novel loss function for learning SE(3) corrections based on a matrix Lie groups approach, with a natural formulation for balancing translation and rotation errors. We use this loss to train a Deep Pose Correction network (DPC-Net) that predicts corrections for a particular estimator, sensor and environment. Using the KITTI odometry dataset, we demonstrate significant improvements to the accuracy of a computationally-efficient sparse stereo visual odometry pipeline, that render it as accurate as a modern computationally-intensive dense estimator. Further, we show how DPC-Net can be used to mitigate the effect of poorly calibrated lens distortion parameters. version:1
arxiv-1709-05929 | Institutionally Distributed Deep Learning Networks | http://arxiv.org/abs/1709.05929 | id:1709.05929 author:Ken Chang, Niranjan Balachandar, Carson K Lam, Darvin Yi, James M Brown, Andrew Beers, Bruce R Rosen, Daniel L Rubin, Jayashree Kalpathy-Cramer category:cs.CV cs.LG physics.med-ph  published:2017-09-10 summary:Deep learning has become a promising approach for automated medical diagnoses. When medical data samples are limited, collaboration among multiple institutions is necessary to achieve high algorithm performance. However, sharing patient data often has limitations due to technical, legal, or ethical concerns. In such cases, sharing a deep learning model is a more attractive alternative. The best method of performing such a task is unclear, however. In this study, we simulate the dissemination of learning deep learning network models across four institutions using various heuristics and compare the results with a deep learning model trained on centrally hosted patient data. The heuristics investigated include ensembling single institution models, single weight transfer, and cyclical weight transfer. We evaluated these approaches for image classification in three independent image collections (retinal fundus photos, mammography, and ImageNet). We find that cyclical weight transfer resulted in a performance (testing accuracy = 77.3%) that was closest to that of centrally hosted patient data (testing accuracy = 78.7%). We also found that there is an improvement in the performance of cyclical weight transfer heuristic with high frequency of weight transfer. version:1
arxiv-1709-04857 | A New Semantic Theory of Natural Language | http://arxiv.org/abs/1709.04857 | id:1709.04857 author:Kun Xing category:cs.CL cs.LO  published:2017-09-10 summary:Formal Semantics and Distributional Semantics are two important semantic frameworks in Natural Language Processing (NLP). Cognitive Semantics belongs to the movement of Cognitive Linguistics, which is based on contemporary cognitive science. Each framework could deal with some meaning phenomena, but none of them fulfills all requirements proposed by applications. A unified semantic theory characterizing all important language phenomena has both theoretical and practical significance; however, although many attempts have been made in recent years, no existing theory has achieved this goal yet. This article introduces a new semantic theory that has the potential to characterize most of the important meaning phenomena of natural language and to fulfill most of the necessary requirements for philosophical analysis and for NLP applications. The theory is based on a unified representation of information, and constructs a kind of mathematical model called cognitive model to interpret natural language expressions in a compositional manner. It accepts the empirical assumption of Cognitive Semantics, and overcomes most shortcomings of Formal Semantics and of Distributional Semantics. The theory, however, is not a simple combination of existing theories, but an extensive generalization of classic logic and Formal Semantics. It inherits nearly all advantages of Formal Semantics, and also provides descriptive contents for objects and events as fine-gram as possible, descriptive contents which represent the results of human cognition. version:1
arxiv-1709-03093 | Efficient Online Linear Optimization with Approximation Algorithms | http://arxiv.org/abs/1709.03093 | id:1709.03093 author:Dan Garber category:cs.LG math.OC  published:2017-09-10 summary:We revisit the problem of \textit{online linear optimization} in case the set of feasible actions is accessible through an approximated linear optimization oracle with a factor $\alpha$ multiplicative approximation guarantee. This setting is in particular interesting since it captures natural online extensions of well-studied \textit{offline} linear optimization problems which are NP-hard, yet admit efficient approximation algorithms. The goal here is to minimize the $\alpha$\textit{-regret} which is the natural extension of the standard \textit{regret} in \textit{online learning} to this setting. We present new algorithms with significantly improved oracle complexity for both the full information and bandit variants of the problem. Mainly, for both variants, we present $\alpha$-regret bounds of $O(T^{-1/3})$, were $T$ is the number of prediction rounds, using only $O(\log{T})$ calls to the approximation oracle per iteration, on average. These are the first results to obtain both average oracle complexity of $O(\log{T})$ (or even poly-logarithmic in $T$) and $\alpha$-regret bound $O(T^{-c})$ for a constant $c>0$, for both variants. version:1
arxiv-1709-03086 | A Product Shape Congruity Measure via Entropy in Shape Scale Space | http://arxiv.org/abs/1709.03086 | id:1709.03086 author:Asli Genctav, Sibel Tari category:cs.CV  published:2017-09-10 summary:Product shape is one of the factors that trigger preference decisions of customers. Congruity of shape elements and deformation of shape from the prototype are two factors that are found to influence aesthetic response, hence preference. We propose a measure to indirectly quantify congruity of different parts of the shape and the degree to which the parts deviate from a sphere, i.e. our choice of the prototype, without explicitly defining parts and their relations. The basic signals and systems concept that we use is the entropy. Our measure attains its lowest value for a volume enclosed by a sphere. On one hand, deformations from the prototype cause an increase in the measure. On the other hand, as deformations create congruent parts, our measure decreases due to the attained harmony. Our preliminary experimental results are consistent with our expectations. version:1
arxiv-1705-06846 | A Predictive Account of Cafe Wall Illusions Using a Quantitative Model | http://arxiv.org/abs/1705.06846 | id:1705.06846 author:Nasim Nematzadeh, David M. W. Powers category:cs.CV  published:2017-05-19 summary:This paper explores the tilt illusion effect in the Cafe Wall pattern using a classical Gaussian Receptive Field model. In this illusion, the mortar lines are misperceived as diverging or converging rather than horizontal. We examine the capability of a simple bioplausible filtering model to recognize different degrees of tilt effect in the Cafe Wall illusion based on different characteristics of the pattern. Our study employed a Difference of Gaussians model of retinal to cortical ON center and/or OFF center receptive fields. A wide range of parameters of the stimulus, for example mortar thickness, luminance, tiles contrast, phase of the tile displacement, have been studied. Our model constructs an edge map representation at multiple scales that reveals tilt cues and clues involved in the illusory perception of the Cafe Wall pattern. We present here that our model can not only detect the tilt in this pattern, but also can predict the strength of the illusion and quantify the degree of tilt. For the first time quantitative predictions of a model are reported for this stimulus. The results of our simulations are consistent with previous psychophysical findings across the full range of Cafe Wall variations tested. Our results also suggest that the Difference of Gaussians mechanism is the heart of the effects explained by, and the mechanisms proposed by the Irradiation, Brightness Induction, and Bandpass Filtering models. version:2
arxiv-1709-03064 | AppTechMiner: Mining Applications and Techniques from Scientific Articles | http://arxiv.org/abs/1709.03064 | id:1709.03064 author:Sanyam Agarwal, Mayank Singh, Soham Dan, Pawan Goyal, Animesh Mukherjee category:cs.CL  published:2017-09-10 summary:This paper presents AppTechMiner, a rule-based information extraction framework that automatically constructs a knowledge base of all application areas and problem solving techniques. Techniques include tools, methods, datasets or evaluation metrics. We also categorize individual research articles based on their application areas and the techniques proposed/improved in the article. Our system achieves high average precision (~82%) and recall (~84%) in knowledge base creation. It also performs well in application and technique assignment to an individual article (average accuracy ~66%). In the end, we further present two use cases presenting a trivial information retrieval system and an extensive temporal analysis of the usage of techniques and application areas. At present, we demonstrate the framework for the domain of computational linguistics but this can be easily generalized to any other field of research. version:1
arxiv-1709-03036 | Abductive Matching in Question Answering | http://arxiv.org/abs/1709.03036 | id:1709.03036 author:Kedar Dhamdhere, Kevin S. McCurley, Mukund Sundararajan, Ankur Taly category:cs.CL cs.LG I.2.1; H.3.3  published:2017-09-10 summary:We study question-answering over semi-structured data. We introduce a new way to apply the technique of semantic parsing by applying machine learning only to provide annotations that the system infers to be missing; all the other parsing logic is in the form of manually authored rules. In effect, the machine learning is used to provide non-syntactic matches, a step that is ill-suited to manual rules. The advantage of this approach is in its debuggability and in its transparency to the end-user. We demonstrate the effectiveness of the approach by achieving state-of-the-art performance of 40.42% accuracy on a standard benchmark dataset over tables from Wikipedia. version:1
arxiv-1709-03030 | Robust Sparse Coding via Self-Paced Learning | http://arxiv.org/abs/1709.03030 | id:1709.03030 author:Xiaodong Feng, Zhiwei Tang, Sen Wu category:cs.LG cs.CV  published:2017-09-10 summary:Sparse coding (SC) is attracting more and more attention due to its comprehensive theoretical studies and its excellent performance in many signal processing applications. However, most existing sparse coding algorithms are nonconvex and are thus prone to becoming stuck into bad local minima, especially when there are outliers and noisy data. To enhance the learning robustness, in this paper, we propose a unified framework named Self-Paced Sparse Coding (SPSC), which gradually include matrix elements into SC learning from easy to complex. We also generalize the self-paced learning schema into different levels of dynamic selection on samples, features and elements respectively. Experimental results on real-world data demonstrate the efficacy of the proposed algorithms. version:1
arxiv-1709-03028 | Convolutional Neural Networks: Ensemble Modeling, Fine-Tuning and Unsupervised Semantic Localization | http://arxiv.org/abs/1709.03028 | id:1709.03028 author:Mohammadhassan Izadyyazdanabadi, Evgenii Belykh, Michael Mooney, Nikolay Martirosyan, Jennifer Eschbacher, Peter Nakaji, Mark C. Preul, Yezhou Yang category:cs.CV q-bio.QM  published:2017-09-10 summary:Confocal laser endomicroscopy (CLE) is an advanced optical fluorescence technology undergoing assessment for applications in brain tumor surgery. Despite its promising potential, interpreting the unfamiliar gray tone images of fluorescent stains can be difficult. Many of the CLE images can be distorted by motion, extremely low or high fluorescence signal, or obscured by red blood cell accumulation, and these can be interpreted as nondiagnostic. However, just one neat CLE image might suffice for intraoperative diagnosis of the tumor. While manual examination of thousands of nondiagnostic images during surgery would be impractical, this creates an opportunity for a model to select diagnostic images for the pathologists or surgeon's review. In this study, we sought to develop a deep learning model to automatically detect the diagnostic images using a manually annotated dataset, and we employed a patient-based nested cross-validation approach to explore generalizability of the model. We explored various training regimes: deep training, shallow fine-tuning, and deep fine-tuning. Further, we investigated the effect of ensemble modeling by combining the top-5 single models crafted in the development phase. We localized histological features from diagnostic CLE images by visualization of shallow and deep neural activations. Our inter-rater experiment results confirmed that our ensemble of deeply fine-tuned models achieved higher agreement with the ground truth than the other observers. With the speed and precision of the proposed method (110 images/second; 85\% on the gold standard test subset), it has potential to be integrated into the operative workflow in the brain tumor surgery. version:1
arxiv-1709-03019 | Classifying Unordered Feature Sets with Convolutional Deep Averaging Networks | http://arxiv.org/abs/1709.03019 | id:1709.03019 author:Andrew Gardner, Jinko Kanno, Christian A. Duncan, Rastko R. Selmic category:cs.LG stat.ML  published:2017-09-10 summary:Unordered feature sets are a nonstandard data structure that traditional neural networks are incapable of addressing in a principled manner. Providing a concatenation of features in an arbitrary order may lead to the learning of spurious patterns or biases that do not actually exist. Another complication is introduced if the number of features varies between each set. We propose convolutional deep averaging networks (CDANs) for classifying and learning representations of datasets whose instances comprise variable-size, unordered feature sets. CDANs are efficient, permutation-invariant, and capable of accepting sets of arbitrary size. We emphasize the importance of nonlinear feature embeddings for obtaining effective CDAN classifiers and illustrate their advantages in experiments versus linear embeddings and alternative permutation-invariant and -equivariant architectures. version:1
arxiv-1709-03010 | Steering Output Style and Topic in Neural Response Generation | http://arxiv.org/abs/1709.03010 | id:1709.03010 author:Di Wang, Nebojsa Jojic, Chris Brockett, Eric Nyberg category:cs.CL  published:2017-09-09 summary:We propose simple and flexible training and decoding methods for influencing output style and topic in neural encoder-decoder based language generation. This capability is desirable in a variety of applications, including conversational systems, where successful agents need to produce language in a specific style and generate responses steered by a human puppeteer or external knowledge. We decompose the neural generation process into empirically easier sub-problems: a faithfulness model and a decoding method based on selective-sampling. We also describe training and sampling algorithms that bias the generation process with a specific language style restriction, or a topic restriction. Human evaluation results show that our proposed methods are able to restrict style and topic without degrading output quality in conversational tasks. version:1
arxiv-1708-08711 | Setting an attention region for convolutional neural networks using region selective features, for recognition of materials within glass vessels | http://arxiv.org/abs/1708.08711 | id:1708.08711 author:Sagi Eppel category:cs.CV  published:2017-08-29 summary:Convolutional neural networks have emerged as the leading method for the classification and segmentation of images. In some cases, it is desirable to focus the attention of the net on a specific region in the image; one such case is the recognition of the contents of transparent vessels, where the vessel region in the image is already known. This work presents a valve filter approach for focusing the attention of the net on a region of interest (ROI). In this approach, the ROI is inserted into the net as a binary map. The net uses a different set of convolution filters for the ROI and background image regions, resulting in a different set of features being extracted from each region. More accurately, for each filter used on the image, a corresponding valve filter exists that acts on the ROI map and determines the regions in which the corresponding image filter will be used. This valve filter effectively acts as a valve that inhibits specific features in different image regions according to the ROI map. In addition, a new data set for images of materials in glassware vessels in a chemistry laboratory setting is presented. This data set contains a thousand images with pixel-wise annotation according to categories ranging from filled and empty to the exact phase of the material inside the vessel. The results of the valve filter approach and fully convolutional neural nets (FCN) with no ROI input are compared based on this data set. version:3
arxiv-1709-02995 | Optimal Transport for Deep Joint Transfer Learning | http://arxiv.org/abs/1709.02995 | id:1709.02995 author:Ying Lu, Liming Chen, Alexandre Saidi category:cs.CV  published:2017-09-09 summary:Training a Deep Neural Network (DNN) from scratch requires a large amount of labeled data. For a classification task where only small amount of training data is available, a common solution is to perform fine-tuning on a DNN which is pre-trained with related source data. This consecutive training process is time consuming and does not consider explicitly the relatedness between different source and target tasks. In this paper, we propose a novel method to jointly fine-tune a Deep Neural Network with source data and target data. By adding an Optimal Transport loss (OT loss) between source and target classifier predictions as a constraint on the source classifier, the proposed Joint Transfer Learning Network (JTLN) can effectively learn useful knowledge for target classification from source data. Furthermore, by using different kind of metric as cost matrix for the OT loss, JTLN can incorporate different prior knowledge about the relatedness between target categories and source categories. We carried out experiments with JTLN based on Alexnet on image classification datasets and the results verify the effectiveness of the proposed JTLN in comparison with standard consecutive fine-tuning. This Joint Transfer Learning with OT loss is general and can also be applied to other kind of Neural Networks. version:1
arxiv-1709-02993 | Can you tell a face from a HEVC bitstream? | http://arxiv.org/abs/1709.02993 | id:1709.02993 author:Saeed Ranjbar Alvar, Hyomin Choi, Ivan V. Bajic category:cs.CV  published:2017-09-09 summary:Image and video analytics are being increasingly used on a massive scale. Not only is the amount of data growing, but the complexity of the data processing pipelines is also increasing, thereby exacerbating the problem. It is becoming increasingly important to save computational resources wherever possible. We focus on one of the poster problems of visual analytics -- face detection -- and approach the issue of reducing the computation by asking: Is it possible to detect a face without full image reconstruction from the High Efficiency Video Coding (HEVC) bitstream? We demonstrate that this is indeed possible, with accuracy comparable to conventional face detection, by training a Convolutional Neural Network on the output of the HEVC entropy decoder. version:1
arxiv-1709-02980 | RDeepSense: Reliable Deep Mobile Computing Models with Uncertainty Estimations | http://arxiv.org/abs/1709.02980 | id:1709.02980 author:Shuochao Yao, Yiran Zhao, Huajie Shao, Aston Zhang, Chao Zhang, Shen Li, Tarek Abdelzaher category:cs.LG cs.NI  published:2017-09-09 summary:Recent advances in deep learning have led various applications to unprecedented achievements, which could potentially bring higher intelligence to a broad spectrum of mobile and ubiquitous applications. Although existing studies have demonstrated the effectiveness and feasibility of running deep neural network inference operations on mobile and embedded devices, they overlooked the reliability of mobile computing models. Reliability measurements such as predictive uncertainty estimations are key factors for improving the decision accuracy and user experience. In this work, we propose RDeepSense, the first deep learning model that provides well-calibrated uncertainty estimations for resource-constrained mobile and embedded devices. RDeepSense enables the predictive uncertainty by adopting a tunable proper scoring rule as the training criterion and dropout as the implicit Bayesian approximation, which theoretically proves its correctness.To reduce the computational complexity, RDeepSense employs efficient dropout and predictive distribution estimation instead of model ensemble or sampling-based method for inference operations. We evaluate RDeepSense with four mobile sensing applications using Intel Edison devices. Results show that RDeepSense can reduce around 90% of the energy consumption while producing superior uncertainty estimations and preserving at least the same model accuracy compared with other state-of-the-art methods. version:1
arxiv-1709-02968 | Matrix and Graph Operations for Relationship Inference: An Illustration with the Kinship Inference in the China Biographical Database | http://arxiv.org/abs/1709.02968 | id:1709.02968 author:Chao-Lin Liu, Hongsu Wang category:cs.DL cs.CL cs.DB  published:2017-09-09 summary:Biographical databases contain diverse information about individuals. Person names, birth information, career, friends, family and special achievements are some possible items in the record for an individual. The relationships between individuals, such as kinship and friendship, provide invaluable insights about hidden communities which are not directly recorded in databases. We show that some simple matrix and graph-based operations are effective for inferring relationships among individuals, and illustrate the main ideas with the China Biographical Database (CBDB). version:1
arxiv-1709-02967 | Sequential 3D U-Nets for Biologically-Informed Brain Tumor Segmentation | http://arxiv.org/abs/1709.02967 | id:1709.02967 author:Andrew Beers, Ken Chang, James Brown, Emmett Sartor, CP Mammen, Elizabeth Gerstner, Bruce Rosen, Jayashree Kalpathy-Cramer category:cs.CV  published:2017-09-09 summary:Deep learning has quickly become the weapon of choice for brain lesion segmentation. However, few existing algorithms pre-configure any biological context of their chosen segmentation tissues, and instead rely on the neural network's optimizer to develop such associations de novo. We present a novel method for applying deep neural networks to the problem of glioma tissue segmentation that takes into account the structured nature of gliomas - edematous tissue surrounding mutually-exclusive regions of enhancing and non-enhancing tumor. We trained multiple deep neural networks with a 3D U-Net architecture in a tree structure to create segmentations for edema, non-enhancing tumor, and enhancing tumor regions. Specifically, training was configured such that the whole tumor region including edema was predicted first, and its output segmentation was fed as input into separate models to predict enhancing and non-enhancing tumor. Our method was trained and evaluated on the publicly available BraTS dataset, achieving Dice scores of 0.882, 0.732, and 0.730 for whole tumor, enhancing tumor and tumor core respectively. version:1
arxiv-1704-08504 | Complex spectrogram enhancement by convolutional neural network with multi-metrics learning | http://arxiv.org/abs/1704.08504 | id:1704.08504 author:Szu-Wei Fu, Ting-yao Hu, Yu Tsao, Xugang Lu category:stat.ML cs.LG cs.SD  published:2017-04-27 summary:This paper aims to address two issues existing in the current speech enhancement methods: 1) the difficulty of phase estimations; 2) a single objective function cannot consider multiple metrics simultaneously. To solve the first problem, we propose a novel convolutional neural network (CNN) model for complex spectrogram enhancement, namely estimating clean real and imaginary (RI) spectrograms from noisy ones. The reconstructed RI spectrograms are directly used to synthesize enhanced speech waveforms. In addition, since log-power spectrogram (LPS) can be represented as a function of RI spectrograms, its reconstruction is also considered as another target. Thus a unified objective function, which combines these two targets (reconstruction of RI spectrograms and LPS), is equivalent to simultaneously optimizing two commonly used objective metrics: segmental signal-to-noise ratio (SSNR) and logspectral distortion (LSD). Therefore, the learning process is called multi-metrics learning (MML). Experimental results confirm the effectiveness of the proposed CNN with RI spectrograms and MML in terms of improved standardized evaluation metrics on a speech enhancement task. version:2
arxiv-1709-02956 | Deep Residual Networks and Weight Initialization | http://arxiv.org/abs/1709.02956 | id:1709.02956 author:Masato Taki category:cs.LG stat.ML  published:2017-09-09 summary:Residual Network (ResNet) is the state-of-the-art architecture that realizes successful training of really deep neural network. It is also known that good weight initialization of neural network avoids problem of vanishing/exploding gradients. In this paper, simplified models of ResNets are analyzed. We argue that goodness of ResNet is correlated with the fact that ResNets are relatively insensitive to choice of initial weights. We also demonstrate how batch normalization improves backpropagation of deep ResNets without tuning initial values of weights. version:1
arxiv-1709-03872 | A way to improve precision of face recognition in SIPP without retrain of the deep neural network model | http://arxiv.org/abs/1709.03872 | id:1709.03872 author:Xihua Li category:cs.CV  published:2017-09-09 summary:Although face recognition has been improved much as the development of Deep Neural Networks, SIPP(Single Image Per Person) problem in face recognition has not been better solved. In this paper, multiple methods will be introduced to improve the precision of SIPP face recognition without retrain of the DNN model. First, a modified SVD based method will be introduced to get more face images of one person in order to get more intra-class variations. Second, some more tricks will be introduced to help get the most similar person ID in a complex dataset, and some theoretical explain included to prove of why our tricks effective. Third, we would like to emphasize, no need to retrain of the DNN model and this would be easy to be extended in many applications without much efforts. We do some practical testing in competition of Msceleb challenge-2 2017 which was hold by Microsoft Research and finally we rank top-10. Great improvement of coverage from 13.39\% to 19.25\%, 29.94\%, 42.11\%, 47.52\% at precision P99(99\%) would be shown in this paper. version:1
arxiv-1709-02940 | How to Train Triplet Networks with 100K Identities? | http://arxiv.org/abs/1709.02940 | id:1709.02940 author:Chong Wang, Xue Zhang, Xipeng Lan category:cs.CV  published:2017-09-09 summary:Training triplet networks with large-scale data is challenging in face recognition. Due to the number of possible triplets explodes with the number of samples, previous studies adopt the online hard negative mining(OHNM) to handle it. However, as the number of identities becomes extremely large, the training will suffer from bad local minima because effective hard triplets are difficult to be found. To solve the problem, in this paper, we propose training triplet networks with subspace learning, which splits the space of all identities into subspaces consisting of only similar identities. Combined with the batch OHNM, hard triplets can be found much easier. Experiments on the large-scale MS-Celeb-1M challenge with 100K identities demonstrate that the proposed method can largely improve the performance. In addition, to deal with heavy noise and large-scale retrieval, we also make some efforts on robust noise removing and efficient image retrieval, which are used jointly with the subspace learning to obtain the state-of-the-art performance on the MS-Celeb-1M competition (without external data in Challenge1). version:1
arxiv-1709-02929 | Model Distillation with Knowledge Transfer in Face Classification, Alignment and Verification | http://arxiv.org/abs/1709.02929 | id:1709.02929 author:Chong Wang, Xipeng Lan category:cs.CV  published:2017-09-09 summary:Knowledge distillation is a potential solution for model compression. The idea is to make a small student model imitate the output of a large teacher model, thus the student that is competitive to the teacher can be obtained. Most previous studies focus only on the classification task where they propose different teacher supervision, but other tasks are barely considered, and they mostly ignore the importance of student initialization. To overcome the two limitations, in this paper, we propose face model distillation with strong student initialization and knowledge transfer, which can boost not only the task of face classification, but also domain-similar tasks including face alignment and verification. First, in face classification, a student model with all layers initialized is trained in a multi-task way with its class labels and teacher supervision. Then, the similar multi-task training is adopted with the knowledge transferred from classification to alignment and verification. Evaluation on the CASIA-WebFace and CelebA datasets demonstrates that the student can be competitive to the teacher in all the three tasks, and even surpasses the teacher under appropriate compression rates. Moreover, we also test the proposed method on the large-scale MS-Celeb-1M database, where the student can also achieve competitive performance. version:1
arxiv-1709-02925 | Less Is More: A Comprehensive Framework for the Number of Components of Ensemble Classifiers | http://arxiv.org/abs/1709.02925 | id:1709.02925 author:Hamed R. Bonab, Fazli Can category:cs.LG stat.ML  published:2017-09-09 summary:The number of component classifiers chosen for an ensemble has a great impact on its prediction ability. In this paper, we use a geometric framework for a priori determining the ensemble size, applicable to most of the existing batch and online ensemble classifiers. There are only a limited number of studies on the ensemble size considering Majority Voting (MV) and Weighted Majority Voting (WMV). Almost all of them are designed for batch-mode, barely addressing online environments. The big data dimensions and resource limitations in terms of time and memory make the determination of the ensemble size crucial, especially for online environments. Our framework proves, for the MV aggregation rule, that the more strong components we can add to the ensemble the more accurate predictions we can achieve. On the other hand, for the WMV aggregation rule, we prove the existence of an ideal number of components equal to the number of class labels, with the premise that components are completely independent of each other and strong enough. While giving the exact definition for a strong and independent classifier in the context of an ensemble is a challenging task, our proposed geometric framework provides a theoretical explanation of diversity and its impact on the accuracy of predictions. We conduct an experimental evaluation with two different scenarios to show the practical value of our theorems. version:1
arxiv-1709-02920 | Graph Scaling Cut with L1-Norm for Classification of Hyperspectral Images | http://arxiv.org/abs/1709.02920 | id:1709.02920 author:Ramanarayan Mohanty, S L Happy, Aurobinda Routray category:cs.CV  published:2017-09-09 summary:In this paper, we propose an L1 normalized graph based dimensionality reduction method for Hyperspectral images, called as L1-Scaling Cut (L1-SC). The underlying idea of this method is to generate the optimal projection matrix by retaining the original distribution of the data. Though L2-norm is generally preferred for computation, it is sensitive to noise and outliers. However, L1-norm is robust to them. Therefore, we obtain the optimal projection matrix by maximizing the ratio of between-class dispersion to within-class dispersion using L1-norm. Furthermore, an iterative algorithm is described to solve the optimization problem. The experimental results of the HSI classification confirm the effectiveness of the proposed L1-SC method on both noisy and noiseless data. version:1
arxiv-1709-00537 | Communication-efficient Algorithm for Distributed Sparse Learning via Two-way Truncation | http://arxiv.org/abs/1709.00537 | id:1709.00537 author:Jineng Ren, Jarvis Haupt category:stat.ML cs.LG math.OC  published:2017-09-02 summary:We propose a communicationally and computationally efficient algorithm for high-dimensional distributed sparse learning. At each iteration, local machines compute the gradient on local data and the master machine solves one shifted $l_1$ regularized minimization problem. The communication cost is reduced from constant times of the dimension number for the state-of-the-art algorithm to constant times of the sparsity number via Two-way Truncation procedure. Theoretically, we prove that the estimation error of the proposed algorithm decreases exponentially and matches that of the centralized method under mild assumptions. Extensive experiments on both simulated data and real data verify that the proposed algorithm is efficient and has performance comparable with the centralized method on solving high-dimensional sparse learning problems. version:2
arxiv-1709-02911 | Semi-Supervised Instance Population of an Ontology using Word Vector Embeddings | http://arxiv.org/abs/1709.02911 | id:1709.02911 author:Vindula Jayawardana, Dimuthu Lakmal, Nisansa de Silva, Amal Shehan Perera, Keet Sugathadasa, Buddhi Ayesha, Madhavi Perera category:cs.CL  published:2017-09-09 summary:In many modern day systems such as information extraction and knowledge management agents, ontologies play a vital role in maintaining the concept hierarchies of the selected domain. However, ontology population has become a problematic process due to its nature of heavy coupling with manual human intervention. With the use of word embeddings in the field of natural language processing, it became a popular topic due to its ability to cope up with semantic sensitivity. Hence, in this study, we propose a novel way of semi-supervised ontology population through word embeddings as the basis. We built several models including traditional benchmark models and new types of models which are based on word embeddings. Finally, we ensemble them together to come up with a synergistic model with better accuracy. We demonstrate that our ensemble model can outperform the individual models. version:1
arxiv-1709-02909 | A Simple Analysis for Exp-concave Empirical Minimization with Arbitrary Convex Regularizer | http://arxiv.org/abs/1709.02909 | id:1709.02909 author:Tianbao Yang, Zhe Li, Lijun Zhang category:stat.ML cs.LG math.OC  published:2017-09-09 summary:In this paper, we present a simple analysis of {\bf fast rates} with {\it high probability} of {\bf empirical minimization} for {\it stochastic composite optimization} over a finite-dimensional bounded convex set with exponential concave loss functions and an arbitrary convex regularization. To the best of our knowledge, this result is the first of its kind. As a byproduct, we can directly obtain the fast rate with {\it high probability} for exponential concave empirical risk minimization with and without any convex regularization, which not only extends existing results of empirical risk minimization but also provides a unified framework for analyzing exponential concave empirical risk minimization with and without {\it any} convex regularization. Our proof is very simple only exploiting the covering number of a finite-dimensional bounded set and a concentration inequality of random vectors. version:1
arxiv-1709-02908 | Image Processing Operations Identification via Convolutional Neural Network | http://arxiv.org/abs/1709.02908 | id:1709.02908 author:Bolin Chen, Haodong Li, Weiqi Luo category:cs.MM cs.CV  published:2017-09-09 summary:In recent years, image forensics has attracted more and more attention, and many forensic methods have been proposed for identifying image processing operations. Up to now, most existing methods are based on hand crafted features, and just one specific operation is considered in their methods. In many forensic scenarios, however, multiple classification for various image processing operations is more practical. Besides, it is difficult to obtain effective features by hand for some image processing operations. In this paper, therefore, we propose a new convolutional neural network (CNN) based method to adaptively learn discriminative features for identifying typical image processing operations. We carefully design the high pass filter bank to get the image residuals of the input image, the channel expansion layer to mix up the resulting residuals, the pooling layers, and the activation functions employed in our method. The extensive results show that the proposed method can outperform the currently best method based on hand crafted features and three related methods based on CNN for image steganalysis and/or forensics, achieving the state-of-the-art results. Furthermore, we provide more supplementary results to show the rationality and robustness of the proposed model. version:1
arxiv-1709-02896 | Simultaneously Learning Neighborship and Projection Matrix for Supervised Dimensionality Reduction | http://arxiv.org/abs/1709.02896 | id:1709.02896 author:Yanwei Pang, Bo Zhou, Feiping Nie category:cs.CV cs.LG stat.ML  published:2017-09-09 summary:Explicitly or implicitly, most of dimensionality reduction methods need to determine which samples are neighbors and the similarity between the neighbors in the original highdimensional space. The projection matrix is then learned on the assumption that the neighborhood information (e.g., the similarity) is known and fixed prior to learning. However, it is difficult to precisely measure the intrinsic similarity of samples in high-dimensional space because of the curse of dimensionality. Consequently, the neighbors selected according to such similarity might and the projection matrix obtained according to such similarity and neighbors are not optimal in the sense of classification and generalization. To overcome the drawbacks, in this paper we propose to let the similarity and neighbors be variables and model them in low-dimensional space. Both the optimal similarity and projection matrix are obtained by minimizing a unified objective function. Nonnegative and sum-to-one constraints on the similarity are adopted. Instead of empirically setting the regularization parameter, we treat it as a variable to be optimized. It is interesting that the optimal regularization parameter is adaptive to the neighbors in low-dimensional space and has intuitive meaning. Experimental results on the YALE B, COIL-100, and MNIST datasets demonstrate the effectiveness of the proposed method. version:1
arxiv-1709-02893 | Convolutional Dictionary Learning | http://arxiv.org/abs/1709.02893 | id:1709.02893 author:Cristina Garcia-Cardona, Brendt Wohlberg category:cs.LG stat.ML  published:2017-09-09 summary:Convolutional sparse representations are a form of sparse representation with a dictionary that has a structure that is equivalent to convolution with a set of linear filters. While effective algorithms have recently been developed for the convolutional sparse coding problem, the corresponding dictionary learning problem is substantially more challenging. Furthermore, although a number of different approaches have been proposed, the absence of thorough comparisons between them makes it difficult to determine which of them represents the current state of the art. The present work both addresses this deficiency and proposes some new approaches that outperform existing ones in certain contexts. A thorough set of performance comparisons indicates a very wide range of performance differences among the existing and proposed methods, and clearly identifies those that are the most effective. version:1
arxiv-1709-02888 | Optimization assisted MCMC | http://arxiv.org/abs/1709.02888 | id:1709.02888 author:Ricky Fok, Aijun An, Xiaogang Wang category:stat.CO cs.LG  published:2017-09-09 summary:Markov Chain Monte Carlo (MCMC) sampling methods are widely used but often encounter either slow convergence or biased sampling when applied to multimodal high dimensional distributions. In this paper, we present a general framework of improving classical MCMC samplers by employing a global optimization method. The global optimization method first reduces a high dimensional search to an one dimensional geodesic to find a starting point close to a local mode. The search is accelerated and completed by using a local search method such as BFGS. We modify the target distribution by extracting a local Gaussian distribution aound the found mode. The process is repeated to find all the modes during sampling on the fly. We integrate the optimization algorithm into the Wormhole Hamiltonian Monte Carlo (WHMC) method. Experimental results show that, when applied to high dimensional, multimodal Gaussian mixture models and the network sensor localization problem, the proposed method achieves much faster convergence, with relative error from the mean improved by about an order of magnitude than WHMC in some cases. version:1
arxiv-1708-08959 | A Simple LSTM model for Transition-based Dependency Parsing | http://arxiv.org/abs/1708.08959 | id:1708.08959 author:Mohab Elkaref, Bernd Bohnet category:cs.CL  published:2017-08-29 summary:We present a simple LSTM-based transition-based dependency parser. Our model is composed of a single LSTM hidden layer replacing the hidden layer in the usual feed-forward network architecture. We also propose a new initialization method that uses the pre-trained weights from a feed-forward neural network to initialize our LSTM-based model. We also show that using dropout on the input layer has a positive effect on performance. Our final parser achieves a 93.06% unlabeled and 91.01% labeled attachment score on the Penn Treebank. We additionally replace LSTMs with GRUs and Elman units in our model and explore the effectiveness of our initialization method on individual gates constituting all three types of RNN units. version:2
arxiv-1709-04881 | Benchmarking Super-Resolution Algorithms on Real Data | http://arxiv.org/abs/1709.04881 | id:1709.04881 author:Thomas Köhler, Michel Bätz, Farzad Naderi, André Kaup, Andreas K. Maier, Christian Riess category:cs.CV  published:2017-09-08 summary:Over the past decades, various super-resolution (SR) techniques have been developed to enhance the spatial resolution of digital images. Despite the great number of methodical contributions, there is still a lack of comparative validations of SR under practical conditions, as capturing real ground truth data is a challenging task. Therefore, current studies are either evaluated 1) on simulated data or 2) on real data without a pixel-wise ground truth. To facilitate comprehensive studies, this paper introduces the publicly available Super-Resolution Erlangen (SupER) database that includes real low-resolution images along with high-resolution ground truth data. Our database comprises image sequences with more than 20k images captured from 14 scenes under various types of motions and photometric conditions. The datasets cover four spatial resolution levels using camera hardware binning. With this database, we benchmark 15 single-image and multi-frame SR algorithms. Our experiments quantitatively analyze SR accuracy and robustness under realistic conditions including independent object and camera motion or photometric variations. version:1
arxiv-1705-06566 | Learning Texture Manifolds with the Periodic Spatial GAN | http://arxiv.org/abs/1705.06566 | id:1705.06566 author:Urs Bergmann, Nikolay Jetchev, Roland Vollgraf category:cs.CV stat.ML  published:2017-05-18 summary:This paper introduces a novel approach to texture synthesis based on generative adversarial networks (GAN) (Goodfellow et al., 2014). We extend the structure of the input noise distribution by constructing tensors with different types of dimensions. We call this technique Periodic Spatial GAN (PSGAN). The PSGAN has several novel abilities which surpass the current state of the art in texture synthesis. First, we can learn multiple textures from datasets of one or more complex large images. Second, we show that the image generation with PSGANs has properties of a texture manifold: we can smoothly interpolate between samples in the structured noise space and generate novel samples, which lie perceptually between the textures of the original dataset. In addition, we can also accurately learn periodical textures. We make multiple experiments which show that PSGANs can flexibly handle diverse texture and image data sources. Our method is highly scalable and it can generate output images of arbitrary large size. version:2
arxiv-1709-02855 | Roll-back Hamiltonian Monte Carlo | http://arxiv.org/abs/1709.02855 | id:1709.02855 author:Kexin Yi, Finale Doshi-Velez category:stat.ML  published:2017-09-08 summary:We propose a new framework for Hamiltonian Monte Carlo (HMC) on truncated probability distributions with smooth underlying density functions. Traditional HMC requires computing the gradient of potential function associated with the target distribution, and therefore does not perform its full power on truncated distributions due to lack of continuity and differentiability. In our framework, we introduce a sharp sigmoid factor in the density function to approximate the probability drop at the truncation boundary. The target potential function is approximated by a new potential which smoothly extends to the entire sample space. HMC is then performed on the approximate potential. While our method is easy to implement and applies to a wide range of problems, it also achieves comparable computational efficiency on various sampling tasks compared to other baseline methods. RBHMC also gives rise to a new approach for Bayesian inference on constrained spaces. version:1
arxiv-1709-02843 | CLaC at SemEval-2016 Task 11: Exploring linguistic and psycho-linguistic Features for Complex Word Identification | http://arxiv.org/abs/1709.02843 | id:1709.02843 author:Elnaz Davoodi, Leila Kosseim category:cs.CL  published:2017-09-08 summary:This paper describes the system deployed by the CLaC-EDLK team to the "SemEval 2016, Complex Word Identification task". The goal of the task is to identify if a given word in a given context is "simple" or "complex". Our system relies on linguistic features and cognitive complexity. We used several supervised models, however the Random Forest model outperformed the others. Overall our best configuration achieved a G-score of 68.8% in the task, ranking our system 21 out of 45. version:1
arxiv-1709-02842 | Combining LSTM and Latent Topic Modeling for Mortality Prediction | http://arxiv.org/abs/1709.02842 | id:1709.02842 author:Yohan Jo, Lisa Lee, Shruti Palaskar category:cs.CL  published:2017-09-08 summary:There is a great need for technologies that can predict the mortality of patients in intensive care units with both high accuracy and accountability. We present joint end-to-end neural network architectures that combine long short-term memory (LSTM) and a latent topic model to simultaneously train a classifier for mortality prediction and learn latent topics indicative of mortality from textual clinical notes. For topic interpretability, the topic modeling layer has been carefully designed as a single-layer network with constraints inspired by LDA. Experiments on the MIMIC-III dataset show that our models significantly outperform prior models that are based on LDA topics in mortality prediction. However, we achieve limited success with our method for interpreting topics from the trained models by looking at the neural network weights. version:1
arxiv-1709-02840 | A Brief Introduction to Machine Learning for Engineers | http://arxiv.org/abs/1709.02840 | id:1709.02840 author:Osvaldo Simeone category:cs.LG cs.IT math.IT stat.ML  published:2017-09-08 summary:This monograph aims at providing an introduction to key concepts, algorithms, and theoretical frameworks in machine learning, including supervised and unsupervised learning, statistical learning theory, probabilistic graphical models and approximate inference. The intended readership consists of electrical engineers with a background in probability and linear algebra. The treatment builds on first principles, and organizes the main ideas according to clearly defined categories, such as discriminative and generative models, frequentist and Bayesian approaches, exact and approximate inference, directed and undirected models, and convex and non-convex optimization. The mathematical framework uses information-theoretic measures as a unifying tool. The text offers simple and reproducible numerical examples providing insights into key motivations and conclusions. Rather than providing exhaustive details on the existing myriad solutions in each specific category, for which the reader is referred to textbooks and papers, this monograph is meant as an entry point for an engineer into the literature on machine learning. version:1
arxiv-1709-02828 | Globally Normalized Reader | http://arxiv.org/abs/1709.02828 | id:1709.02828 author:Jonathan Raiman, John Miller category:cs.CL  published:2017-09-08 summary:Rapid progress has been made towards question answering (QA) systems that can extract answers from text. Existing neural approaches make use of expensive bi-directional attention mechanisms or score all possible answer spans, limiting scalability. We propose instead to cast extractive QA as an iterative search problem: select the answer's sentence, start word, and end word. This representation reduces the space of each search step and allows computation to be conditionally allocated to promising search paths. We show that globally normalizing the decision process and back-propagating through beam search makes this representation viable and learning efficient. We empirically demonstrate the benefits of this approach using our model, Globally Normalized Reader (GNR), which achieves the second highest single model performance on the Stanford Question Answering Dataset (68.4 EM, 76.21 F1 dev) and is 24.7x faster than bi-attention-flow. We also introduce a data-augmentation method to produce semantically valid examples by aligning named entities to a knowledge base and swapping them with new entities of the same type. This method improves the performance of all models considered in this work and is of independent interest for a variety of NLP tasks. version:1
arxiv-1709-02783 | A Statistical Comparison of Some Theories of NP Word Order | http://arxiv.org/abs/1709.02783 | id:1709.02783 author:Richard Futrell, Roger Levy, Matthew Dryer category:cs.CL  published:2017-09-08 summary:A frequent object of study in linguistic typology is the order of elements {demonstrative, adjective, numeral, noun} in the noun phrase. The goal is to predict the relative frequencies of these orders across languages. Here we use Poisson regression to statistically compare some prominent accounts of this variation. We compare feature systems derived from Cinque (2005) to feature systems given in Cysouw (2010) and Dryer (in prep). In this setting, we do not find clear reasons to prefer the model of Cinque (2005) or Dryer (in prep), but we find both of these models have substantially better fit to the typological data than the model from Cysouw (2010). version:1
arxiv-1709-02780 | Detecting Hands in Egocentric Videos: Towards Action Recognition | http://arxiv.org/abs/1709.02780 | id:1709.02780 author:Alejandro Cartas, Mariella Dimiccoli, Petia Radeva category:cs.CV  published:2017-09-08 summary:Recently, there has been a growing interest in analyzing human daily activities from data collected by wearable cameras. Since the hands are involved in a vast set of daily tasks, detecting hands in egocentric images is an important step towards the recognition of a variety of egocentric actions. However, besides extreme illumination changes in egocentric images, hand detection is not a trivial task because of the intrinsic large variability of hand appearance. We propose a hand detector that exploits skin modeling for fast hand proposal generation and Convolutional Neural Networks for hand recognition. We tested our method on UNIGE-HANDS dataset and we showed that the proposed approach achieves competitive hand detection results. version:1
arxiv-1706-08171 | Faster independent component analysis by preconditioning with Hessian approximations | http://arxiv.org/abs/1706.08171 | id:1706.08171 author:Pierre Ablin, Jean-François Cardoso, Alexandre Gramfort category:stat.ML stat.AP  published:2017-06-25 summary:Independent Component Analysis (ICA) is a technique for unsupervised exploration of multi-channel data that is widely used in observational sciences. In its classic form, ICA relies on modeling the data as linear mixtures of non-Gaussian independent sources. The maximization of the corresponding likelihood is a challenging problem if it has to be completed quickly and accurately on large sets of real data. We introduce the Preconditioned ICA for Real Data (Picard) algorithm, which is a relative L-BFGS algorithm preconditioned with sparse Hessian approximations. Extensive numerical comparisons to several algorithms of the same class demonstrate the superior performance of the proposed technique, especially on real data, for which the ICA model does not necessarily hold. version:3
arxiv-1709-02741 | Vessel Segmentation and Catheter Detection in X-Ray Angiograms Using Superpixels | http://arxiv.org/abs/1709.02741 | id:1709.02741 author:Hamid R. Fazlali, Nader Karimi, S. M. Reza Soroushmehr, Shahram Shirani, Brahmajee. K. Nallamothu, Kevin R. Ward, Shadrokh Samavi, Kayvan Najarian category:cs.CV  published:2017-09-08 summary:Coronary artery disease (CAD) is the leading causes of death around the world. One of the most common imaging methods for diagnosing this disease is X-ray angiography. Diagnosing using these images is usually challenging due to non-uniform illumination, low contrast, presence of other body tissues, presence of catheter etc. These challenges make the diagnoses task of cardiologists tougher and more prone to misdiagnosis. In this paper we propose a new automated framework for coronary arteries segmentation, catheter detection and center-line extraction in x-ray angiography images. Our proposed segmentation method is based on superpixels. In this method at first three different superpixel scales are exploited and a measure for vesselness probability of each superpixel is determined. A majority voting is used for obtaining an initial segmentation map from these three superpixel scales. This initial segmentation is refined by finding the orthogonal line on each ridge pixel of vessel region. In this framework we use our catheter detection and tracking method which detects the catheter by finding its ridge in the first frame and traces in other frames by fitting a second order polynomial on it. Also we use the image ridges for extracting the coronary arteries centerlines. We evaluated our method qualitatively and quantitatively on two different challenging datasets and compared it with one of the previous well-known coronary arteries segmentation methods. Our method could detect the catheter and reduced the false positive rate in addition to achieving better segmentation results. The evaluation results prove that our method performs better in a much shorter time. version:1
arxiv-1709-02739 | Crowdsourcing Predictors of Residential Electric Energy Usage | http://arxiv.org/abs/1709.02739 | id:1709.02739 author:Mark D. Wagy, Josh C. Bongard, James P. Bagrow, Paul D. H. Hines category:cs.HC physics.soc-ph stat.ML  published:2017-09-08 summary:Crowdsourcing has been successfully applied in many domains including astronomy, cryptography and biology. In order to test its potential for useful application in a Smart Grid context, this paper investigates the extent to which a crowd can contribute predictive hypotheses to a model of residential electric energy consumption. In this experiment, the crowd generated hypotheses about factors that make one home different from another in terms of monthly energy usage. To implement this concept, we deployed a web-based system within which 627 residential electricity customers posed 632 questions that they thought predictive of energy usage. While this occurred, the same group provided 110,573 answers to these questions as they accumulated. Thus users both suggested the hypotheses that drive a predictive model and provided the data upon which the model is built. We used the resulting question and answer data to build a predictive model of monthly electric energy consumption, using random forest regression. Because of the sparse nature of the answer data, careful statistical work was needed to ensure that these models are valid. The results indicate that the crowd can generate useful hypotheses, despite the sparse nature of the dataset. version:1
arxiv-1709-02738 | Cycles in adversarial regularized learning | http://arxiv.org/abs/1709.02738 | id:1709.02738 author:Panayotis Mertikopoulos, Christos Papadimitriou, Georgios Piliouras category:cs.GT cs.LG  published:2017-09-08 summary:Regularized learning is a fundamental technique in online optimization, machine learning and many other fields of computer science. A natural question that arises in these settings is how regularized learning algorithms behave when faced against each other. We study a natural formulation of this problem by coupling regularized learning dynamics in zero-sum games. We show that the system's behavior is Poincar\'e recurrent, implying that almost every trajectory revisits any (arbitrarily small) neighborhood of its starting point infinitely often. This cycling behavior is robust to the agents' choice of regularization mechanism (each agent could be using a different regularizer), to positive-affine transformations of the agents' utilities, and it also persists in the case of networked competition, i.e., for zero-sum polymatrix games. version:1
arxiv-1707-09219 | Recurrent Ladder Networks | http://arxiv.org/abs/1707.09219 | id:1707.09219 author:Alexander Ilin, Isabeau Prémont-Schwarz, Tele Hotloo Hao, Antti Rasmus, Rinu Boney, Harri Valpola category:cs.NE cs.LG stat.ML  published:2017-07-28 summary:We propose a recurrent extension of the Ladder networks whose structure is motivated by the inference required in hierarchical latent variable models. We demonstrate that the recurrent Ladder is able to handle a wide variety of complex learning tasks that benefit from iterative inference and temporal modeling. The architecture shows close-to-optimal results on temporal modeling of video data, competitive results on music modeling, and improved perceptual grouping based on higher order abstractions, such as stochastic textures and motion cues. We present results for fully supervised, semi-supervised, and unsupervised tasks. The results suggest that the proposed architecture and principles are powerful tools for learning a hierarchy of abstractions, learning iterative inference and handling temporal information. version:2
arxiv-1709-02726 | A Modular Analysis of Adaptive (Non-)Convex Optimization: Optimism, Composite Objectives, and Variational Bounds | http://arxiv.org/abs/1709.02726 | id:1709.02726 author:Pooria Joulani, András György, Csaba Szepesvári category:cs.LG math.OC stat.ML  published:2017-09-08 summary:Recently, much work has been done on extending the scope of online learning and incremental stochastic optimization algorithms. In this paper we contribute to this effort in two ways: First, based on a new regret decomposition and a generalization of Bregman divergences, we provide a self-contained, modular analysis of the two workhorses of online learning: (general) adaptive versions of Mirror Descent (MD) and the Follow-the-Regularized-Leader (FTRL) algorithms. The analysis is done with extra care so as not to introduce assumptions not needed in the proofs and allows to combine, in a straightforward way, different algorithmic ideas (e.g., adaptivity, optimism, implicit updates) and learning settings (e.g., strongly convex or composite objectives). This way we are able to reprove, extend and refine a large body of the literature, while keeping the proofs concise. The second contribution is a byproduct of this careful analysis: We present algorithms with improved variational bounds for smooth, composite objectives, including a new family of optimistic MD algorithms with only one projection step per round. Furthermore, we provide a simple extension of adaptive regret bounds to practically relevant non-convex problem settings with essentially no extra effort. version:1
arxiv-1709-02707 | Optimally Learning Populations of Parameters | http://arxiv.org/abs/1709.02707 | id:1709.02707 author:Kevin Tian, Weihao Kong, Gregory Valiant category:cs.LG  published:2017-09-08 summary:Consider the following fundamental estimation problem: there are $n$ entities, each with an unknown parameter $p_i \in [0,1]$, and we observe $n$ independent random variables, $X_1,\ldots,X_n$, with $X_i \sim $ Binomial$(t, p_i)$. How accurately can one recover the "histogram" (i.e. cumulative density function) of the $p_i$s? While the empirical estimates would recover the histogram to earth mover distance $\Theta(\frac{1}{\sqrt{t}})$ (equivalently, $\ell_1$ distance between the CDFs), we show that, provided $n$ is sufficiently large, we can achieve error $O(\frac{1}{t})$ which is information theoretically optimal. We also extend our results to the multi-dimensional parameter case, capturing settings where each member of the population has multiple associated parameters. Beyond the theoretical results, we demonstrate that the recovery algorithm performs well in practice on a variety of datasets, providing illuminating insights into several domains, including politics, and sports analytics. version:1
arxiv-1708-06822 | Deep EndoVO: A Recurrent Convolutional Neural Network (RCNN) based Visual Odometry Approach for Endoscopic Capsule Robots | http://arxiv.org/abs/1708.06822 | id:1708.06822 author:Mehmet Turan, Yasin Almalioglu, Helder Araujo, Ender Konukoglu, Metin Sitti category:cs.CV  published:2017-08-22 summary:Ingestible wireless capsule endoscopy is an emerging minimally invasive diagnostic technology for inspection of the GI tract and diagnosis of a wide range of diseases and pathologies. Medical device companies and many research groups have recently made substantial progresses in converting passive capsule endoscopes to active capsule robots, enabling more accurate, precise, and intuitive detection of the location and size of the diseased areas. Since a reliable real time pose estimation functionality is crucial for actively controlled endoscopic capsule robots, in this study, we propose a monocular visual odometry (VO) method for endoscopic capsule robot operations. Our method lies on the application of the deep Recurrent Convolutional Neural Networks (RCNNs) for the visual odometry task, where Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) are used for the feature extraction and inference of dynamics across the frames, respectively. Detailed analyses and evaluations made on a real pig stomach dataset proves that our system achieves high translational and rotational accuracies for different types of endoscopic capsule robot trajectories. version:2
arxiv-1709-02702 | Entropic Determinants | http://arxiv.org/abs/1709.02702 | id:1709.02702 author:Diego Granziol, Stephen Roberts category:stat.ML  published:2017-09-08 summary:The ability of many powerful machine learning algorithms to deal with large data sets without compromise is often hampered by computationally expensive linear algebra tasks, of which calculating the log determinant is a canonical example. In this paper we demonstrate the optimality of Maximum Entropy methods in approximating such calculations. We prove the equivalence between mean value constraints and sample expectations in the big data limit, that Covariance matrix eigenvalue distributions can be completely defined by moment information and that the reduction of the self entropy of a maximum entropy proposal distribution, achieved by adding more moments reduces the KL divergence between the proposal and true eigenvalue distribution. We empirically verify our results on a variety of SparseSuite matrices and establish best practices. version:1
arxiv-1709-02700 | Method to Detect Eye Position Noise from Video-Oculography when Detection of Pupil or Corneal Reflection Position Fails | http://arxiv.org/abs/1709.02700 | id:1709.02700 author:Evgeny Abdulin, Lee Friedman, Oleg V. Komogortsev category:cs.CV  published:2017-09-08 summary:We present software to detect noise in eye position signals from video-based eye-tracking systems that depend on accurate pupil and corneal reflection position estimation. When such systems transiently fail to properly detect the pupil or the corneal reflection due to occlusion from eyelids, eye lashes or various shadows, the estimated gaze position is false. This produces an artifactual signal in the position trace that is rapidly, irregularly oscillating between true and false gaze positions. We refer to this noise as RIONEPS (Rapid Irregularly Oscillating Noise of the Eye Position Signal). Our method for detecting these periods automatically is based on an estimate of the relative inefficiency of the eye position signal. We look for RIONEPS in the horizontal and vertical traces separately, and although we typically use it offline, it is suitable to adaptation for real time use. This method requires a threshold to be set, and although we provide some guidance, thresholds will have to be estimated empirically. version:1
arxiv-1709-02699 | A Real-time Trainable and Clock-less Spiking Neural Network with 1R Memristive Synapses | http://arxiv.org/abs/1709.02699 | id:1709.02699 author:Aditya Shukla, Udayan Ganguly category:cs.NE cs.ET  published:2017-09-08 summary:Owing to their unexplored but potentially superior computational capability and remarkably low power consumption for executing brain-like tasks, spiking neural networks (SNNs) have come under the scope of several research groups. For modeling a network of spiking neurons and synapses highly parallelized hardware with a distributed and localized processor and memory is essential. Highly integrable resistive RAM or ReRAM, with voltage-pulse moldable analog conductivity, has a potential to play a key role in such a hardware model, as it can and has been shown to mimic a synapse and its time dependent plasticity. Being a two terminal device, however, it is not directly suitable for naturally/biologically asynchronous SNNs because it requires ability to do reading and writing concurrently. In this work, we overcome this challenge and present a clock-less approach to implement both learning and recognition on a spiking neural network with memristive synaptic array wherein, reading and writing are performed in different frequency domains. Further, we validate our scheme in SPICE by translating a mathematical mono-layered feed-forward Iris classifying SNN. A hardware implementation of the scheme will eliminate the need for clocks and switches to drive learning and has the potential to be used in the development of real-time trainable hardware recurrent networks. version:1
arxiv-1709-05206 | LSTM Fully Convolutional Networks for Time Series Classification | http://arxiv.org/abs/1709.05206 | id:1709.05206 author:Fazle Karim, Somshubra Majumdar, Houshang Darabi, Shun Chen category:cs.LG stat.ML  published:2017-09-08 summary:Fully convolutional neural networks (FCN) have been shown to achieve state-of-the-art performance on the task of classifying time series sequences. We propose the augmentation of fully convolutional networks with long short term memory recurrent neural network (LSTM RNN) sub-modules for time series classification. Our proposed models significantly enhance the performance of fully convolutional networks with a nominal increase in model size and require minimal preprocessing of the dataset. The proposed Long Short Term Memory Fully Convolutional Network (LSTM-FCN) achieves state-of-the-art performance compared to others. We also explore the usage of attention mechanism to improve time series classification with the Attention Long Short Term Memory Fully Convolutional Network (ALSTM-FCN). Utilization of the attention mechanism allows one to visualize the decision process of the LSTM cell. Furthermore, we propose fine-tuning as a method to enhance the performance of trained models. An overall analysis of the performance of our model is provided and compared to other techniques. version:1
arxiv-1709-01562 | Optimizing for Measure of Performance in Max-Margin Parsing | http://arxiv.org/abs/1709.01562 | id:1709.01562 author:Alexander Bauer, Shinichi Nakajima, Nico Görnitz, Klaus-Robert Müller category:cs.CL  published:2017-09-05 summary:Many statistical learning problems in the area of natural language processing including sequence tagging, sequence segmentation and syntactic parsing has been successfully approached by means of structured prediction methods. An appealing property of the corresponding discriminative learning algorithms is their ability to integrate the loss function of interest directly into the optimization process, which potentially can increase the resulting performance accuracy. Here, we demonstrate on the example of constituency parsing how to optimize for F1-score in the max-margin framework of structural SVM. In particular, the optimization is with respect to the original (not binarized) trees. version:2
arxiv-1709-02679 | What Weights Work for You? Adapting Weights for Any Pareto Front Shape in Decomposition-based Evolutionary Multi-Objective Optimisation | http://arxiv.org/abs/1709.02679 | id:1709.02679 author:Miqing Li, Xin Yao category:cs.NE  published:2017-09-08 summary:The quality of solution sets generated by decomposition-based evolutionary multiobjective optimisation (EMO) algorithms depends heavily on the consistency between a given problem's Pareto front shape and the specified weights' distribution. A set of weights distributed uniformly in a simplex often lead to a set of well-distributed solutions on a Pareto front with a simplex-like shape, but may fail on other Pareto front shapes. It is an open problem on how to specify a set of appropriate weights without the information of the problem's Pareto front beforehand. In this paper, we propose an approach to adapt the weights during the evolutionary process (called AdaW). AdaW progressively seeks a suitable distribution of weights for the given problem by elaborating five parts in the weight adaptation --- weight generation, weight addition, weight deletion, archive maintenance, and weight update frequency. Experimental results have shown the effectiveness of the proposed approach. AdaW works well for Pareto fronts with very different shapes: 1) the simplex-like, 2) the inverted simplex-like, 3) the highly nonlinear, 4) the disconnect, 5) the degenerated, 6) the badly-scaled, and 7) the high-dimensional. version:1
arxiv-1709-02664 | Multi-level Feedback Web Links Selection Problem: Learning and Optimization | http://arxiv.org/abs/1709.02664 | id:1709.02664 author:Kechao Cai, Kun Chen, Longbo Huang, John C. S. Lui category:cs.LG  published:2017-09-08 summary:Selecting the right web links for a website is important because appropriate links not only can provide high attractiveness but can also increase the website's revenue. In this work, we first show that web links have an intrinsic \emph{multi-level feedback structure}. For example, consider a $2$-level feedback web link: the $1$st level feedback provides the Click-Through Rate (CTR) and the $2$nd level feedback provides the potential revenue, which collectively produce the compound $2$-level revenue. We consider the context-free links selection problem of selecting links for a homepage so as to maximize the total compound $2$-level revenue while keeping the total $1$st level feedback above a preset threshold. We further generalize the problem to links with $n~(n\ge2)$-level feedback structure. The key challenge is that the links' multi-level feedback structures are unobservable unless the links are selected on the homepage. To our best knowledge, we are the first to model the links selection problem as a constrained multi-armed bandit problem and design an effective links selection algorithm by learning the links' multi-level structure with provable \emph{sub-linear} regret and violation bounds. We uncover the multi-level feedback structures of web links in two real-world datasets. We also conduct extensive experiments on the datasets to compare our proposed \textbf{LExp} algorithm with two state-of-the-art context-free bandit algorithms and show that \textbf{LExp} algorithm is the most effective in links selection while satisfying the constraint. version:1
arxiv-1709-02653 | Locating 3D Object Proposals: A Depth-Based Online Approach | http://arxiv.org/abs/1709.02653 | id:1709.02653 author:Ramanpreet Singh Pahwa, Jiangbo Lu, Nianjuan Jiang, Tian Tsong Ng, Minh N. Do category:cs.CV  published:2017-09-08 summary:2D object proposals, quickly detected regions in an image that likely contain an object of interest, are an effective approach for improving the computational efficiency and accuracy of object detection in color images. In this work, we propose a novel online method that generates 3D object proposals in a RGB-D video sequence. Our main observation is that depth images provide important information about the geometry of the scene. Diverging from the traditional goal of 2D object proposals to provide a high recall (lots of 2D bounding boxes near potential objects), we aim for precise 3D proposals. We leverage on depth information per frame and multi-view scene information to obtain accurate 3D object proposals. Using efficient but robust registration enables us to combine multiple frames of a scene in near real time and generate 3D bounding boxes for potential 3D regions of interest. Using standard metrics, such as Precision-Recall curves and F-measure, we show that the proposed approach is significantly more accurate than the current state-of-the-art techniques. Our online approach can be integrated into SLAM based video processing for quick 3D object localization. Our method takes less than a second in MATLAB on the UW-RGBD scene dataset on a single thread CPU and thus, has potential to be used in low-power chips in Unmanned Aerial Vehicles (UAVs), quadcopters, and drones. version:1
arxiv-1709-02635 | Calibration of depth cameras using denoised depth images | http://arxiv.org/abs/1709.02635 | id:1709.02635 author:Ramanpreet Singh Pahwa, Minh N. Do, Tian Tsong Ng, Binh-Son Hua category:cs.CV  published:2017-09-08 summary:Depth sensing devices have created various new applications in scientific and commercial research with the advent of Microsoft Kinect and PMD (Photon Mixing Device) cameras. Most of these applications require the depth cameras to be pre-calibrated. However, traditional calibration methods using a checkerboard do not work very well for depth cameras due to the low image resolution. In this paper, we propose a depth calibration scheme which excels in estimating camera calibration parameters when only a handful of corners and calibration images are available. We exploit the noise properties of PMD devices to denoise depth measurements and perform camera calibration using the denoised depth as an additional set of measurements. Our synthetic and real experiments show that our depth denoising and depth based calibration scheme provides significantly better results than traditional calibration methods. version:1
arxiv-1709-02605 | Gaussian Quadrature for Kernel Features | http://arxiv.org/abs/1709.02605 | id:1709.02605 author:Tri Dao, Christopher De Sa, Christopher Ré category:cs.LG  published:2017-09-08 summary:Kernel methods have recently attracted resurgent interest, matching the performance of deep neural networks in tasks such as speech recognition. The random Fourier features map is a technique commonly used to scale up kernel machines, but employing the randomized feature map means that $O(\epsilon^{-2})$ samples are required to achieve an approximation error of at most $\epsilon$. In this paper, we investigate some alternative schemes for constructing feature maps that are deterministic, rather than random, by approximating the kernel in the frequency domain using Gaussian quadrature. We show that deterministic feature maps can be constructed, for any $\gamma > 0$, to achieve error $\epsilon$ with $O(e^{\gamma} + \epsilon^{-1/\gamma})$ samples as $\epsilon$ goes to 0. We validate our methods on datasets in different domains, such as MNIST and TIMIT, showing that deterministic features are faster to generate and achieve comparable accuracy to the state-of-the-art kernel methods based on random Fourier features. version:1
arxiv-1709-02601 | Best Practices in Convolutional Networks for Forward-Looking Sonar Image Recognition | http://arxiv.org/abs/1709.02601 | id:1709.02601 author:Matias Valdenegro-Toro category:cs.CV  published:2017-09-08 summary:Convolutional Neural Networks (CNN) have revolutionized perception for color images, and their application to sonar images has also obtained good results. But in general CNNs are difficult to train without a large dataset, need manual tuning of a considerable number of hyperparameters, and require many careful decisions by a designer. In this work, we evaluate three common decisions that need to be made by a CNN designer, namely the performance of transfer learning, the effect of object/image size and the relation between training set size. We evaluate three CNN models, namely one based on LeNet, and two based on the Fire module from SqueezeNet. Our findings are: Transfer learning with an SVM works very well, even when the train and transfer sets have no classes in common, and high classification performance can be obtained even when the target dataset is small. The ADAM optimizer combined with Batch Normalization can make a high accuracy CNN classifier, even with small image sizes (16 pixels). At least 50 samples per class are required to obtain $90\%$ test accuracy, and using Dropout with a small dataset helps improve performance, but Batch Normalization is better when a large dataset is available. version:1
arxiv-1709-02802 | Towards Proving the Adversarial Robustness of Deep Neural Networks | http://arxiv.org/abs/1709.02802 | id:1709.02802 author:Guy Katz, Clark Barrett, David L. Dill, Kyle Julian, Mykel J. Kochenderfer category:cs.LG cs.CR cs.LO stat.ML D.2.4; I.2.2  published:2017-09-08 summary:Autonomous vehicles are highly complex systems, required to function reliably in a wide variety of situations. Manually crafting software controllers for these vehicles is difficult, but there has been some success in using deep neural networks generated using machine-learning. However, deep neural networks are opaque to human engineers, rendering their correctness very difficult to prove manually; and existing automated techniques, which were not designed to operate on neural networks, fail to scale to large systems. This paper focuses on proving the adversarial robustness of deep neural networks, i.e. proving that small perturbations to a correctly-classified input to the network cannot cause it to be misclassified. We describe some of our recent and ongoing work on verifying the adversarial robustness of networks, and discuss some of the open questions we have encountered and how they might be addressed. version:1
arxiv-1709-03395 | Low-memory GEMM-based convolution algorithms for deep neural networks | http://arxiv.org/abs/1709.03395 | id:1709.03395 author:Andrew Anderson, Aravind Vasudevan, Cormac Keane, David Gregg category:cs.CV  published:2017-09-08 summary:Deep neural networks (DNNs) require very large amounts of computation both for training and for inference when deployed in the field. A common approach to implementing DNNs is to recast the most computationally expensive operations as general matrix multiplication (GEMM). However, as we demonstrate in this paper, there are a great many different ways to express DNN convolution operations using GEMM. Although different approaches all perform the same number of operations, the size of temporary data structures differs significantly. Convolution of an input matrix with dimensions $C \times H \times W$, requires $O(K^2CHW)$ additional space using the classical im2col approach. More recently memory-efficient approaches requiring just $O(KCHW)$ auxiliary space have been proposed. We present two novel GEMM-based algorithms that require just $O(MHW)$ and $O(KW)$ additional space respectively, where $M$ is the number of channels in the result of the convolution. These algorithms dramatically reduce the space overhead of DNN convolution, making it much more suitable for memory-limited embedded systems. Experimental evaluation shows that our low-memory algorithms are just as fast as the best patch-building approaches despite requiring just a fraction of the amount of additional memory. Our low-memory algorithms have excellent data locality which gives them a further edge over patch-building algorithms when multiple cores are used. As a result, our low memory algorithms often outperform the best patch-building algorithms using multiple threads. version:1
arxiv-1709-02549 | A Novel Low-Complexity Framework in Ultra-Wideband Imaging for Breast Cancer Detection | http://arxiv.org/abs/1709.02549 | id:1709.02549 author:Yasaman Ettefagh, Mohammad Hossein Moghaddam, Saeed Vahidian category:cs.CV  published:2017-09-08 summary:In this research work, a novel framework is pro- posed as an efficient successor to traditional imaging methods for breast cancer detection in order to decrease the computational complexity. In this framework, the breast is devided into seg- ments in an iterative process and in each iteration, the one having the most probability of containing tumor with lowest possible resolution is selected by using suitable decision metrics. After finding the smallest tumor-containing segment, the resolution is increased in the detected tumor-containing segment, leaving the other parts of the breast image with low resolution. Our framework is applied on the most common used beamforming techniques, such as delay and sum (DAS) and delay multiply and sum (DMAS) and according to simulation results, our framework can decrease the computational complexity significantly for both DAS and DMAS without imposing any degradation on accuracy of basic algorithms. The amount of complexity reduction can be determined manually or automatically based on two proposed methods that are described in this framework. version:1
arxiv-1708-09097 | Optimizing scoring function of dynamic programming of pairwise profile alignment using derivative free neural network | http://arxiv.org/abs/1708.09097 | id:1708.09097 author:Kazunori D Yamada category:q-bio.QM cs.NE  published:2017-08-30 summary:A profile comparison method with position-specific scoring matrix (PSSM) is one of the most accurate alignment methods. Currently, cosine similarity and correlation coefficient are used as scoring functions of dynamic programming to calculate similarity between PSSMs. However, it is unclear that these functions are optimal for profile alignment methods. At least, by definition, these functions cannot capture non-linear relationships between profiles. Therefore, in this study, we attempted to discover a novel scoring function, which was more suitable for the profile comparison method than the existing ones. Firstly we implemented a new derivative free neural network by combining the conventional neural network with evolutionary strategy optimization method. Next, using the framework, the scoring function was optimized for aligning remote sequence pairs. Nepal, the pairwise profile aligner with the novel scoring function significantly improved both alignment sensitivity and precision, compared to aligners with the existing functions. Nepal improved alignment quality because of adaptation to remote sequence alignment and increasing the expressive power of similarity score. The novel scoring function can be realized using a simple matrix operation and easily incorporated into other aligners. With our scoring function, the performance of homology detection and/or multiple sequence alignment for remote homologous sequences would be further improved. version:2
arxiv-1709-02538 | CuRTAIL: ChaRacterizing and Thwarting AdversarIal deep Learning | http://arxiv.org/abs/1709.02538 | id:1709.02538 author:Bita Darvish Rouhani, Mohammad Samragh, Tara Javidi, Farinaz Koushanfar category:cs.CR cs.LG stat.ML  published:2017-09-08 summary:This paper proposes CuRTAIL, an end-to-end computing framework for characterizing and thwarting adversarial space in the context of Deep Learning (DL). The framework protects deep neural networks against adversarial samples, which are perturbed inputs carefully crafted by malicious entities to mislead the underlying DL model. The precursor for the proposed methodology is a set of new quantitative metrics to assess the vulnerability of various deep learning architectures to adversarial samples. CuRTAIL formalizes the goal of preventing adversarial samples as a minimization of the space unexplored by the pertinent DL model that is characterized in CuRTAIL vulnerability analysis step. To thwart the adversarial machine learning attack, CuRTAIL introduces the concept of Modular Robust Redundancy (MRR) as a viable solution to achieve the formalized minimization objective. The MRR methodology explicitly characterizes the geometry of the input data and the DL model parameters. It then learns a set of complementary but disjoint models which maximally cover the unexplored subspaces of the target DL model, thus reducing the risk of integrity attacks. We extensively evaluate CuRTAIL performance against the state-of-the-art attack models including fast-sign-gradient, Jacobian Saliency Map Attack, and Deepfool. Proof-of-concept implementations for analyzing various data collections including MNIST, CIFAR10, and ImageNet corroborate CuRTAIL effectiveness to detect adversarial samples in different settings. The computations in each MRR module can be performed independently. As such, CuRTAIL detection algorithm can be completely parallelized among multiple hardware settings to achieve maximum throughput. We further provide an accompanying API to facilitate the adoption of the proposed framework for various applications. version:1
arxiv-1709-02535 | Mirror Descent Search and Acceleration | http://arxiv.org/abs/1709.02535 | id:1709.02535 author:Megumi Miyashita, Shiro Yano, Toshiyuki Kondo category:cs.LG  published:2017-09-08 summary:In recent years, attention has been focused on the relationship between black box optimization and reinforcement learning. Black box optimization is a framework for the problem of finding the input that optimizes the output represented by an unknown function. Reinforcement learning, by contrast, is a framework for finding a policy to optimize the expected cumulative reward from trial and error. In this research, we propose a reinforcement learn- ing algorithm based on the mirror descent method, which is general optimization algorithm. The proposed method is called Mirror Descent Search. The contribution of this research is roughly twofold. First, an extension method for mirror descent can be applied to reinforcement learning and such a method is here considered. Second, the relationship between existing reinforcement learning algorithms is clarified. Based on these, we propose Mirror Descent Search and derivative methods. The experimental results show that learning with the proposed method progresses faster. version:1
arxiv-1708-02949 | Classification without labels: Learning from mixed samples in high energy physics | http://arxiv.org/abs/1708.02949 | id:1708.02949 author:Eric M. Metodiev, Benjamin Nachman, Jesse Thaler category:hep-ph hep-ex stat.ML  published:2017-08-09 summary:Modern machine learning techniques can be used to construct powerful models for difficult collider physics problems. In many applications, however, these models are trained on imperfect simulations due to a lack of truth-level information in the data, which risks the model learning artifacts of the simulation. In this paper, we introduce the paradigm of classification without labels (CWoLa) in which a classifier is trained to distinguish statistical mixtures of classes, which are common in collider physics. Crucially, neither individual labels nor class proportions are required, yet we prove that the optimal classifier in the CWoLa paradigm is also the optimal classifier in the traditional fully-supervised case where all label information is available. After demonstrating the power of this method in an analytical toy example, we consider a realistic benchmark for collider physics: distinguishing quark- versus gluon-initiated jets using mixed quark/gluon training samples. More generally, CWoLa can be applied to any classification problem where labels or class proportions are unknown or simulations are unreliable, but statistical mixtures of the classes are available. version:2
arxiv-1709-01953 | Implicit Regularization in Deep Learning | http://arxiv.org/abs/1709.01953 | id:1709.01953 author:Behnam Neyshabur category:cs.LG  published:2017-09-06 summary:In an attempt to better understand generalization in deep learning, we study several possible explanations. We show that implicit regularization induced by the optimization method is playing a key role in generalization and success of deep learning models. Motivated by this view, we study how different complexity measures can ensure generalization and explain how optimization algorithms can implicitly regularize complexity measures. We empirically investigate the ability of these measures to explain different observed phenomena in deep learning. We further study the invariances in neural networks, suggest complexity measures and optimization algorithms that have similar invariances to those in neural networks and evaluate them on a number of learning tasks. version:2
arxiv-1709-02508 | Deep Subspace Clustering Networks | http://arxiv.org/abs/1709.02508 | id:1709.02508 author:Pan Ji, Tong Zhang, Hongdong Li, Mathieu Salzmann, Ian Reid category:cs.CV  published:2017-09-08 summary:We present a novel deep neural network architecture for unsupervised subspace clustering. This architecture is built upon deep auto-encoders, which non-linearly map the input data into a latent space. Our key idea is to introduce a novel self-expressive layer between the encoder and the decoder to mimic the "self-expressiveness" property that has proven effective in traditional subspace clustering. Being differentiable, our new self-expressive layer provides a simple but effective way to learn pairwise affinities between all data points through a standard back-propagation procedure. Being nonlinear, our neural-network based method is able to cluster data points having complex (often nonlinear) structures. We further propose pre-training and fine-tuning strategies that let us effectively learn the parameters of our subspace clustering networks. Our experiments show that the proposed method significantly outperforms the state-of-the-art unsupervised subspace clustering methods. version:1
arxiv-1709-02495 | DeepFeat: A Bottom Up and Top Down Saliency Model Based on Deep Features of Convolutional Neural Nets | http://arxiv.org/abs/1709.02495 | id:1709.02495 author:Ali Mahdi, Jun Qin category:cs.CV  published:2017-09-08 summary:A deep feature based saliency model (DeepFeat) is developed to leverage the understanding of the prediction of human fixations. Traditional saliency models often predict the human visual attention relying on few level image cues. Although such models predict fixations on a variety of image complexities, their approaches are limited to the incorporated features. In this study, we aim to provide an intuitive interpretation of convolu- tional neural network deep features by combining low and high level visual factors. We exploit four evaluation metrics to evaluate the correspondence between the proposed framework and the ground-truth fixations. The key findings of the results demon- strate that the DeepFeat algorithm, incorporation of bottom up and top down saliency maps, outperforms the individual bottom up and top down approach. Moreover, in comparison to nine 9 state-of-the-art saliency models, our proposed DeepFeat model achieves satisfactory performance based on all four evaluation metrics. version:1
arxiv-1709-02800 | GOOWE: Geometrically Optimum and Online-Weighted Ensemble Classifier for Evolving Data Streams | http://arxiv.org/abs/1709.02800 | id:1709.02800 author:Hamed R. Bonab, Fazli Can category:cs.LG  published:2017-09-08 summary:Designing adaptive classifiers for an evolving data stream is a challenging task due to the data size and its dynamically changing nature. Combining individual classifiers in an online setting, the ensemble approach, is a well-known solution. It is possible that a subset of classifiers in the ensemble outperforms others in a time-varying fashion. However, optimum weight assignment for component classifiers is a problem which is not yet fully addressed in online evolving environments. We propose a novel data stream ensemble classifier, called Geometrically Optimum and Online-Weighted Ensemble (GOOWE), which assigns optimum weights to the component classifiers using a sliding window containing the most recent data instances. We map vote scores of individual classifiers and true class labels into a spatial environment. Based on the Euclidean distance between vote scores and ideal-points, and using the linear least squares (LSQ) solution, we present a novel, dynamic, and online weighting approach. While LSQ is used for batch mode ensemble classifiers, it is the first time that we adapt and use it for online environments by providing a spatial modeling of online ensembles. In order to show the robustness of the proposed algorithm, we use real-world datasets and synthetic data generators using the MOA libraries. First, we analyze the impact of our weighting system on prediction accuracy through two scenarios. Second, we compare GOOWE with 8 state-of-the-art ensemble classifiers in a comprehensive experimental environment. Our experiments show that GOOWE provides improved reactions to different types of concept drift compared to our baselines. The statistical tests indicate a significant improvement in accuracy, with conservative time and memory requirements. version:1
arxiv-1709-02482 | Scalable Annotation of Fine-Grained Categories Without Experts | http://arxiv.org/abs/1709.02482 | id:1709.02482 author:Timnit Gebru, Jonathan Krause, Jia Deng, Li Fei-Fei category:cs.HC cs.CV  published:2017-09-07 summary:We present a crowdsourcing workflow to collect image annotations for visually similar synthetic categories without requiring experts. In animals, there is a direct link between taxonomy and visual similarity: e.g. a collie (type of dog) looks more similar to other collies (e.g. smooth collie) than a greyhound (another type of dog). However, in synthetic categories such as cars, objects with similar taxonomy can have very different appearance: e.g. a 2011 Ford F-150 Supercrew-HD looks the same as a 2011 Ford F-150 Supercrew-LL but very different from a 2011 Ford F-150 Supercrew-SVT. We introduce a graph based crowdsourcing algorithm to automatically group visually indistinguishable objects together. Using our workflow, we label 712,430 images by ~1,000 Amazon Mechanical Turk workers; resulting in the largest fine-grained visual dataset reported to date with 2,657 categories of cars annotated at 1/20th the cost of hiring experts. version:1
arxiv-1709-01713 | Spoken English Intelligibility Remediation with PocketSphinx Alignment and Feature Extraction Improves Substantially over the State of the Art | http://arxiv.org/abs/1709.01713 | id:1709.01713 author:Yuan Gao, Brij Mohan Lal Srivastava, James Salsman category:cs.CL stat.ML 68T10  97U50 I.2.7; K.3.1  published:2017-09-06 summary:Automatic speech recognition is used to assess spoken English learner pronunciation based on the authentic intelligibility of the learners' spoken responses determined from deep neural network (DNN) model predictions of transcription correctness. Using numeric features produced by PocketSphinx alignment mode and many recognition passes searching for the substitution and deletion of each expected phoneme and insertion of unexpected phonemes in sequence, the DNN models achieve 97% agreement with the accuracy of Amazon Mechanical Turk crowdworker transcriptions, up from 75% reported by multiple independent researchers. Using such features with DNN prediction models can help computer-aided pronunciation teaching (CAPT) systems provide intelligibility remediation. We have developed and published free open source software so that others can use these techniques. version:2
arxiv-1709-02480 | Fine-Grained Car Detection for Visual Census Estimation | http://arxiv.org/abs/1709.02480 | id:1709.02480 author:Timnit Gebru, Jonathan Krause, Yilun Wang, Duyun Chen, Jia Deng, Li Fei-Fei category:cs.CV  published:2017-09-07 summary:Targeted socioeconomic policies require an accurate understanding of a country's demographic makeup. To that end, the United States spends more than 1 billion dollars a year gathering census data such as race, gender, education, occupation and unemployment rates. Compared to the traditional method of collecting surveys across many years which is costly and labor intensive, data-driven, machine learning driven approaches are cheaper and faster--with the potential ability to detect trends in close to real time. In this work, we leverage the ubiquity of Google Street View images and develop a computer vision pipeline to predict income, per capita carbon emission, crime rates and other city attributes from a single source of publicly available visual data. We first detect cars in 50 million images across 200 of the largest US cities and train a model to predict demographic attributes using the detected cars. To facilitate our work, we have collected the largest and most challenging fine-grained dataset reported to date consisting of over 2600 classes of cars comprised of images from Google Street View and other web sources, classified by car experts to account for even the most subtle of visual differences. We use this data to construct the largest scale fine-grained detection system reported to date. Our prediction results correlate well with ground truth income data (r=0.82), Massachusetts department of vehicle registration, and sources investigating crime rates, income segregation, per capita carbon emission, and other market research. Finally, we learn interesting relationships between cars and neighborhoods allowing us to perform the first large scale sociological analysis of cities using computer vision techniques. version:1
arxiv-1709-02476 | Fine-grained Recognition in the Wild: A Multi-Task Domain Adaptation Approach | http://arxiv.org/abs/1709.02476 | id:1709.02476 author:Timnit Gebru, Judy Hoffman, Li Fei-Fei category:cs.CV  published:2017-09-07 summary:While fine-grained object recognition is an important problem in computer vision, current models are unlikely to accurately classify objects in the wild. These fully supervised models need additional annotated images to classify objects in every new scenario, a task that is infeasible. However, sources such as e-commerce websites and field guides provide annotated images for many classes. In this work, we study fine-grained domain adaptation as a step towards overcoming the dataset shift between easily acquired annotated images and the real world. Adaptation has not been studied in the fine-grained setting where annotations such as attributes could be used to increase performance. Our work uses an attribute based multi-task adaptation loss to increase accuracy from a baseline of 4.1% to 19.1% in the semi-supervised adaptation case. Prior do- main adaptation works have been benchmarked on small datasets such as [46] with a total of 795 images for some domains, or simplistic datasets such as [41] consisting of digits. We perform experiments on a subset of a new challenging fine-grained dataset consisting of 1,095,021 images of 2, 657 car categories drawn from e-commerce web- sites and Google Street View. version:1
arxiv-1709-02463 | Local Neighborhood Intensity Pattern: A new texture feature descriptor for image retrieval | http://arxiv.org/abs/1709.02463 | id:1709.02463 author:Prithaj Banerjee, Ayan Kumar Bhunia, Avirup Bhattacharyya, Partha Pratim Roy, Subrahmanyam Murala category:cs.CV  published:2017-09-07 summary:In this paper, a new texture descriptor based on the local neighborhood intensity difference is proposed for content based image retrieval (CBIR). For computation of texture features like Local Binary Pattern (LBP), the center pixel in a 3*3 window of an image is compared with all the remaining neighbors, one pixel at a time to generate a binary bit pattern. It ignores the effect of the adjacent neighbors of a particular pixel for its binary encoding and also for texture description. The proposed method is based on the concept that neighbors of a particular pixel hold a significant amount of texture information that can be considered for efficient texture representation for CBIR. Taking this into account, we develop a new texture descriptor, named as Local Neighborhood Intensity Pattern (LNIP) which considers the relative intensity difference between a particular pixel and the center pixel by considering its adjacent neighbors and generate a sign and a magnitude pattern. Since sign and magnitude patterns hold complementary information to each other, these two patterns are concatenated into a single feature descriptor to generate a more concrete and useful feature descriptor. The proposed descriptor has been tested for image retrieval on four databases, including three texture image databases - Brodatz texture image database, MIT VisTex database and Salzburg texture database and one face database AT&T face database. The precision and recall values observed on these databases are compared with some state-of-art local patterns. The proposed method showed a significant improvement over many other existing methods. version:1
arxiv-1709-01604 | The Unintended Consequences of Overfitting: Training Data Inference Attacks | http://arxiv.org/abs/1709.01604 | id:1709.01604 author:Samuel Yeom, Matt Fredrikson, Somesh Jha category:cs.CR cs.LG stat.ML  published:2017-09-05 summary:Machine learning algorithms that are applied to sensitive data pose a distinct threat to privacy. A growing body of prior work demonstrates that models produced by these algorithms may leak specific private information in the training data to an attacker, either through their structure or their observable behavior. However, the underlying cause of this privacy risk is not well understood beyond a handful of anecdotal accounts that suggest overfitting and influence might play a role. This paper examines the effect that overfitting and influence have on the ability of an attacker to learn information about training data from machine learning models, either through training set membership inference or model inversion attacks. Using both formal and empirical analyses, we illustrate a clear relationship between these factors and the privacy risk that arises in several popular machine learning algorithms. We find that overfitting is sufficient to allow an attacker to perform membership inference, and when certain conditions on the influence of certain features are present, model inversion attacks. Interestingly, our formal analysis also shows that overfitting is not necessary for these attacks, and begins to shed light on what other factors may be in play. Finally, we explore the connection between two types of attack, membership inference and model inversion, and show that there are deep connections between the two that lead to effective new attacks. version:2
arxiv-1709-02458 | End-to-end Face Detection and Cast Grouping in Movies Using Erdős-Rényi Clustering | http://arxiv.org/abs/1709.02458 | id:1709.02458 author:SouYoung Jin, Hang Su, Chris Stauffer, Erik Learned-Miller category:cs.CV  published:2017-09-07 summary:We present an end-to-end system for detecting and clustering faces by identity in full-length movies. Unlike works that start with a predefined set of detected faces, we consider the end-to-end problem of detection and clustering together. We make three separate contributions. First, we combine a state-of-the-art face detector with a generic tracker to extract high quality face tracklets. We then introduce a novel clustering method, motivated by the classic graph theory results of Erd\H{o}s and R\'enyi. It is based on the observations that large clusters can be fully connected by joining just a small fraction of their point pairs, while just a single connection between two different people can lead to poor clustering results. This suggests clustering using a verification system with very few false positives but perhaps moderate recall. We introduce a novel verification method, rank-1 counts verification, that has this property, and use it in a link-based clustering scheme. Finally, we define a novel end-to-end detection and clustering evaluation metric allowing us to assess the accuracy of the entire end-to-end system. We present state-of-the-art results on multiple video data sets and also on standard face databases. version:1
arxiv-1709-02457 | Reservoir of Diverse Adaptive Learners and Stacking Fast Hoeffding Drift Detection Methods for Evolving Data Streams | http://arxiv.org/abs/1709.02457 | id:1709.02457 author:Ali Pesaranghader, Herna Viktor, Eric Paquet category:stat.ML cs.DB cs.LG  published:2017-09-07 summary:The last decade has seen a surge of interest in adaptive learning algorithms for data stream classification, with applications ranging from predicting ozone level peaks, learning stock market indicators, to detecting computer security violations. In addition, a number of methods have been developed to detect concept drifts in these streams. Consider a scenario where we have a number of classifiers with diverse learning styles and different drift detectors. Intuitively, the current 'best' (classifier, detector) pair is application dependent and may change as a result of the stream evolution. Our research builds on this observation. We introduce the $\mbox{Tornado}$ framework that implements a reservoir of diverse classifiers, together with a variety of drift detection algorithms. In our framework, all (classifier, detector) pairs proceed, in parallel, to construct models against the evolving data streams. At any point in time, we select the pair which currently yields the best performance. We further incorporate two novel stacking-based drift detection methods, namely the $\mbox{FHDDMS}$ and $\mbox{FHDDMS}_{add}$ approaches. The experimental evaluation confirms that the current 'best' (classifier, detector) pair is not only heavily dependent on the characteristics of the stream, but also that this selection evolves as the stream flows. Further, our $\mbox{FHDDMS}$ variants detect concept drifts accurately in a timely fashion while outperforming the state-of-the-art. version:1
