arxiv-1612-05386 | The VQA-Machine: Learning How to Use Existing Vision Algorithms to Answer New Questions | http://arxiv.org/abs/1612.05386 | id:1612.05386 author:Peng Wang, Qi Wu, Chunhua Shen, Anton van den Hengel category:cs.CV  published:2016-12-16 summary:One of the most intriguing features of the Visual Question Answering (VQA) challenge is the unpredictability of the questions. Extracting the information required to answer them demands a variety of image operations from detection and counting, to segmentation and reconstruction. To train a method to perform even one of these operations accurately from {image,question,answer} tuples would be challenging, but to aim to achieve them all with a limited set of such training data seems ambitious at best. We propose here instead a more general and scalable approach which exploits the fact that very good methods to achieve these operations already exist, and thus do not need to be trained. Our method thus learns how to exploit a set of external off-the-shelf algorithms to achieve its goal, an approach that has something in common with the Neural Turing Machine. The core of our proposed method is a new co-attention model. In addition, the proposed approach generates human-readable reasons for its decision, and can still be trained end-to-end without ground truth reasons being given. We demonstrate the effectiveness on two publicly available datasets, Visual Genome and VQA, and show that it produces the state-of-the-art results in both cases. version:1
arxiv-1612-05369 | Neural networks based EEG-Speech Models | http://arxiv.org/abs/1612.05369 | id:1612.05369 author:Pengfei Sun, Jun Qin category:cs.SD cs.LG  published:2016-12-16 summary:In this paper, we describe three neural network (NN) based EEG-Speech (NES) models that map the unspoken EEG signals to the corresponding phonemes. Instead of using conventional feature extraction techniques, the proposed NES models rely on graphic learning to project both EEG and speech signals into deep representation feature spaces. This NN based linear projection helps to realize multimodal data fusion (i.e., EEG and acoustic signals). It is convenient to construct the mapping between unspoken EEG signals and phonemes. Specifically, among three NES models, two augmented models (i.e., IANES-B and IANES-G) include spoken EEG signals as either bias or gate information to strengthen the feature learning and translation of unspoken EEG signals. A combined unsupervised and supervised training is implemented stepwise to learn the mapping for all three NES models. To enhance the computational performance, three way factored NN training technique is applied to IANES-G model. Unlike many existing methods, our augmented NES models incorporate spoken-EEG signals that can efficiently suppress the artifacts in unspoken-EEG signals. Experimental results reveal that all three proposed NES models outperform the baseline SVM method, whereas IANES-G demonstrates the best performance on speech recovery and classification task comparatively. version:1
arxiv-1612-07640 | Deep Learning and Its Applications to Machine Health Monitoring: A Survey | http://arxiv.org/abs/1612.07640 | id:1612.07640 author:Rui Zhao, Ruqiang Yan, Zhenghua Chen, Kezhi Mao, Peng Wang, Robert X. Gao category:cs.LG stat.ML  published:2016-12-16 summary:Since 2006, deep learning (DL) has become a rapidly growing research direction, redefining state-of-the-art performances in a wide range of areas such as object recognition, image segmentation, speech recognition and machine translation. In modern manufacturing systems, data-driven machine health monitoring is gaining in popularity due to the widespread deployment of low-cost sensors and their connection to the Internet. Meanwhile, deep learning provides useful tools for processing and analyzing these big machinery data. The main purpose of this paper is to review and summarize the emerging research work of deep learning on machine health monitoring. After the brief introduction of deep learning techniques, the applications of deep learning in machine health monitoring systems are reviewed mainly from the following aspects: Auto-encoder (AE) and its variants, Restricted Boltzmann Machines and its variants including Deep Belief Network (DBN) and Deep Boltzmann Machines (DBM), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). Finally, some new trends of DL-based machine health monitoring methods are discussed. version:1
arxiv-1612-05365 | Output Constraint Transfer for Kernelized Correlation Filter in Tracking | http://arxiv.org/abs/1612.05365 | id:1612.05365 author:Baochang Zhang, Zhigang Li, Xianbin Cao, Qixiang Ye, Chen Chen, Linlin Shen, Alessandro Perina, Rongrong Ji category:cs.CV  published:2016-12-16 summary:Kernelized Correlation Filter (KCF) is one of the state-of-the-art object trackers. However, it does not reasonably model the distribution of correlation response during tracking process, which might cause the drifting problem, especially when targets undergo significant appearance changes due to occlusion, camera shaking, and/or deformation. In this paper, we propose an Output Constraint Transfer (OCT) method that by modeling the distribution of correlation response in a Bayesian optimization framework is able to mitigate the drifting problem. OCT builds upon the reasonable assumption that the correlation response to the target image follows a Gaussian distribution, which we exploit to select training samples and reduce model uncertainty. OCT is rooted in a new theory which transfers data distribution to a constraint of the optimized variable, leading to an efficient framework to calculate correlation filters. Extensive experiments on a commonly used tracking benchmark show that the proposed method significantly improves KCF, and achieves better performance than other state-of-the-art trackers. To encourage further developments, the source code is made available https://github.com/bczhangbczhang/OCT-KCF. version:1
arxiv-1612-05363 | Learning Residual Images for Face Attribute Manipulation | http://arxiv.org/abs/1612.05363 | id:1612.05363 author:Wei Shen, Rujie Liu category:cs.CV  published:2016-12-16 summary:Face attributes are interesting due to their detailed description of human faces. Unlike prior research working on attribute prediction, we address an inverse and more challenging problem called face attribute manipulation which aims at modifying a face image according to a given attribute value. In order to obtain an efficient representation for the manipulation, we propose to learn the corresponding residual image which is defined as the difference between images after and before the manipulation. Using the residual image, the manipulation can be operated efficiently with modest pixel modification. The framework of our approach is based on the Generative Adversarial Network. It consists of two image transformation networks imitating the attribute manipulation and its dual operation and a shared discriminative network distinguishing the generated images from different reference images. We also apply dual learning to allow the two transformation networks to learn from each other. Experiments show that the learned residual images successfully simulate the manipulations and the generated images retain most of the details in attribute-irrelevant areas. version:1
arxiv-1612-05362 | Medical Image Synthesis with Context-Aware Generative Adversarial Networks | http://arxiv.org/abs/1612.05362 | id:1612.05362 author:Dong Nie, Roger Trullo, Caroline Petitjean, Su Ruan, Dinggang Shen category:cs.CV  published:2016-12-16 summary:Computed tomography (CT) is critical for various clinical applications, e.g., radiotherapy treatment planning and also PET attenuation correction. However, CT exposes radiation during acquisition, which may cause side effects to patients. Compared to CT, magnetic resonance imaging (MRI) is much safer and does not involve any radiations. Therefore, recently, researchers are greatly motivated to estimate CT image from its corresponding MR image of the same subject for the case of radiotherapy planning. In this paper, we propose a data-driven approach to address this challenging problem. Specifically, we train a fully convolutional network to generate CT given an MR image. To better model the nonlinear relationship from MRI to CT and to produce more realistic images, we propose to use the adversarial training strategy and an image gradient difference loss function. We further apply AutoContext Model to implement a context-aware generative adversarial network. Experimental results show that our method is accurate and robust for predicting CT images from MRI images, and also outperforms three state-of-the-art methods under comparison. version:1
arxiv-1612-05360 | FusionNet: A deep fully residual convolutional neural network for image segmentation in connectomics | http://arxiv.org/abs/1612.05360 | id:1612.05360 author:Tran Minh Quan, David G. C. Hilderbrand, Won-Ki Jeong category:cs.CV  published:2016-12-16 summary:Electron microscopic connectomics is an ambitious research direction with the goal of studying comprehensive brain connectivity maps by using high-throughput, nano-scale microscopy. One of the main challenges in connectomics research is developing scalable image analysis algorithms that require minimal user intervention. Recently, deep learning has drawn much attention in computer vision because of its exceptional performance in image classification tasks. For this reason, its application to connectomic analyses holds great promise, as well. In this paper, we introduce a novel deep neural network architecture, FusionNet, for the automatic segmentation of neuronal structures in connectomics data. FusionNet leverages the latest advances in machine learning, such as semantic segmentation and residual neural networks, with the novel introduction of summation-based skip connections to allow a much deeper network architecture for a more accurate segmentation. We demonstrate the performance of the proposed method by comparing it with state-of-the-art electron microscopy (EM) segmentation methods from the ISBI EM segmentation challenge. We also show the segmentation results on two different tasks including cell membrane and cell body segmentation and a statistical analysis of cell morphology. version:1
arxiv-1612-05356 | Projected Semi-Stochastic Gradient Descent Method with Mini-Batch Scheme under Weak Strong Convexity Assumption | http://arxiv.org/abs/1612.05356 | id:1612.05356 author:Jie Liu, Martin Takac category:cs.LG math.OC stat.ML  published:2016-12-16 summary:We propose a projected semi-stochastic gradient descent method with mini-batch for improving both the theoretical complexity and practical performance of the general stochastic gradient descent method (SGD). We are able to prove linear convergence under weak strong convexity assumption. This requires no strong convexity assumption for minimizing the sum of smooth convex functions subject to a compact polyhedral set, which remains popular across machine learning community. Our PS2GD preserves the low-cost per iteration and high optimization accuracy via stochastic gradient variance-reduced technique, and admits a simple parallel implementation with mini-batches. Moreover, PS2GD is also applicable to dual problem of SVM with hinge loss. version:1
arxiv-1612-05348 | Machine Reading with Background Knowledge | http://arxiv.org/abs/1612.05348 | id:1612.05348 author:Ndapandula Nakashole, Tom M. Mitchell category:cs.AI cs.CL 68T50  published:2016-12-16 summary:Intelligent systems capable of automatically understanding natural language text are important for many artificial intelligence applications including mobile phone voice assistants, computer vision, and robotics. Understanding language often constitutes fitting new information into a previously acquired view of the world. However, many machine reading systems rely on the text alone to infer its meaning. In this paper, we pursue a different approach; machine reading methods that make use of background knowledge to facilitate language understanding. To this end, we have developed two methods: The first method addresses prepositional phrase attachment ambiguity. It uses background knowledge within a semi-supervised machine learning algorithm that learns from both labeled and unlabeled data. This approach yields state-of-the-art results on two datasets against strong baselines; The second method extracts relationships from compound nouns. Our knowledge-aware method for compound noun analysis accurately extracts relationships and significantly outperforms a baseline that does not make use of background knowledge. version:1
arxiv-1612-05340 | Automatic Labelling of Topics with Neural Embeddings | http://arxiv.org/abs/1612.05340 | id:1612.05340 author:Shraey Bhatia, Jey Han Lau, Timothy Baldwin category:cs.CL  published:2016-12-16 summary:Topics generated by topic models are typically represented as list of terms. To reduce the cognitive overhead of interpreting these topics for end-users, we propose labelling a topic with a succinct phrase that summarises its theme or idea. Using Wikipedia document titles as label candidates, we compute neural embeddings for documents and words to select the most relevant labels for topics. Compared to a state-of-the-art topic labelling system, our methodology is simpler, more efficient, and finds better topic labels. version:1
arxiv-1612-05335 | Mirrored Light Field Video Camera Adapter | http://arxiv.org/abs/1612.05335 | id:1612.05335 author:Dorian Tsai, Donald G. Dansereau, Steve Martin, Peter Corke category:cs.RO cs.CV  published:2016-12-16 summary:This paper proposes the design of a custom mirror-based light field camera adapter that is cheap, simple in construction, and accessible. Mirrors of different shape and orientation reflect the scene into an upwards-facing camera to create an array of virtual cameras with overlapping field of view at specified depths, and deliver video frame rate light fields. We describe the design, construction, decoding and calibration processes of our mirror-based light field camera adapter in preparation for an open-source release to benefit the robotic vision community. version:1
arxiv-1612-05332 | Fast, Dense Feature SDM on an iPhone | http://arxiv.org/abs/1612.05332 | id:1612.05332 author:Ashton Fagg, Simon Lucey, Sridha Sridharan category:cs.CV  published:2016-12-16 summary:In this paper, we present our method for enabling dense SDM to run at over 90 FPS on a mobile device. Our contributions are two-fold. Drawing inspiration from the FFT, we propose a Sparse Compositional Regression (SCR) framework, which enables a significant speed up over classical dense regressors. Second, we propose a binary approximation to SIFT features. Binary Approximated SIFT (BASIFT) features, which are a computationally efficient approximation to SIFT, a commonly used feature with SDM. We demonstrate the performance of our algorithm on an iPhone 7, and show that we achieve similar accuracy to SDM. version:1
arxiv-1612-05079 | SceneNet RGB-D: 5M Photorealistic Images of Synthetic Indoor Trajectories with Ground Truth | http://arxiv.org/abs/1612.05079 | id:1612.05079 author:John McCormac, Ankur Handa, Stefan Leutenegger, Andrew J. Davison category:cs.CV  published:2016-12-15 summary:We introduce SceneNet RGB-D, expanding the previous work of SceneNet to enable large scale photorealistic rendering of indoor scene trajectories. It provides pixel-perfect ground truth for scene understanding problems such as semantic segmentation, instance segmentation, and object detection, and also for geometric computer vision problems such as optical flow, depth estimation, camera pose estimation, and 3D reconstruction. Random sampling permits virtually unlimited scene configurations, and here we provide a set of 5M rendered RGB-D images from over 15K trajectories in synthetic layouts with random but physically simulated object poses. Each layout also has random lighting, camera trajectories, and textures. The scale of this dataset is well suited for pre-training data-driven computer vision techniques from scratch with RGB-D inputs, which previously has been limited by relatively small labelled datasets in NYUv2 and SUN RGB-D. It also provides a basis for investigating 3D scene labelling tasks by providing perfect camera poses and depth data as proxy for a SLAM system. We host the dataset at http://robotvault.bitbucket.org/scenenet-rgbd.html version:2
arxiv-1612-05323 | A Stochastic Large Deformation Model for Computational Anatomy | http://arxiv.org/abs/1612.05323 | id:1612.05323 author:Alexis Arnaudon, Darryl D. Holm, Akshay Pai, Stefan Sommer category:cs.CV math.NA  published:2016-12-16 summary:In the study of shapes of human organs using computational anatomy, variations are found to arise from inter-subject anatomical differences, disease-specific effects, and measurement noise. This paper introduces a stochastic model for incorporating random variations into the Large Deformation Diffeomorphic Metric Mapping (LDDMM) framework. By accounting for randomness in a particular setup which is crafted to fit the geometrical properties of LDDMM, we formulate the template estimation problem for landmarks with noise and give two methods for efficiently estimating the parameters of the noise fields from a prescribed data set. One method directly approximates the time evolution of the variance of each landmark by a finite set of differential equations, and the other is based on an Expectation-Maximisation algorithm. In the second method, the evaluation of the data likelihood is achieved without registering the landmarks, by applying bridge sampling using a stochastically perturbed version of the large deformation gradient flow algorithm. The method and the estimation algorithms are experimentally validated on synthetic examples and shape data of human corpora callosa. version:1
arxiv-1612-05322 | Towards a Deep Learning Framework for Unconstrained Face Detection | http://arxiv.org/abs/1612.05322 | id:1612.05322 author:Yutong Zheng, Chenchen Zhu, Khoa Luu, Chandrasekhar Bhagavatula, T. Hoang Ngan Le, Marios Savvides category:cs.CV  published:2016-12-16 summary:Robust face detection is one of the most important pre-processing steps to support facial expression analysis, facial landmarking, face recognition, pose estimation, building of 3D facial models, etc. Although this topic has been intensely studied for decades, it is still challenging due to numerous variants of face images in real-world scenarios. In this paper, we present a novel approach named Multiple Scale Faster Region-based Convolutional Neural Network (MS-FRCNN) to robustly detect human facial regions from images collected under various challenging conditions, e.g. large occlusions, extremely low resolutions, facial expressions, strong illumination variations, etc. The proposed approach is benchmarked on two challenging face detection databases, i.e. the Wider Face database and the Face Detection Dataset and Benchmark (FDDB), and compared against recent other face detection methods, e.g. Two-stage CNN, Multi-scale Cascade CNN, Faceness, Aggregate Chanel Features, HeadHunter, Multi-view Face Detection, Cascade CNN, etc. The experimental results show that our proposed approach consistently achieves highly competitive results with the state-of-the-art performance against other recent face detection methods. version:1
arxiv-1612-05310 | Modeling Trolling in Social Media Conversations | http://arxiv.org/abs/1612.05310 | id:1612.05310 author:Luis Gerardo Mojica, Vincent Ng category:cs.CL  published:2016-12-15 summary:Social media websites, electronic newspapers and Internet forums allow visitors to leave comments for others to read and interact. This exchange is not free from participants with malicious intentions, who troll others by positing messages that are intended to be provocative, offensive, or menacing. With the goal of facilitating the computational modeling of trolling, we propose a trolling categorization that is novel in the sense that it allows comment-based analysis from both the trolls' and the responders' perspectives, characterizing these two perspectives using four aspects, namely, the troll's intention and his intention disclosure, as well as the responder's interpretation of the troll's intention and her response strategy. Using this categorization, we annotate and release a dataset containing excerpts of Reddit conversations involving suspected trolls and their interactions with other users. Finally, we identify the difficult-to-classify cases in our corpus and suggest potential solutions for them. version:1
arxiv-1612-05299 | A Survey of Inductive Biases for Factorial Representation-Learning | http://arxiv.org/abs/1612.05299 | id:1612.05299 author:Karl Ridgeway category:cs.LG cs.AI  published:2016-12-15 summary:With the resurgence of interest in neural networks, representation learning has re-emerged as a central focus in artificial intelligence. Representation learning refers to the discovery of useful encodings of data that make domain-relevant information explicit. Factorial representations identify underlying independent causal factors of variation in data. A factorial representation is compact and faithful, makes the causal factors explicit, and facilitates human interpretation of data. Factorial representations support a variety of applications, including the generation of novel examples, indexing and search, novelty detection, and transfer learning. This article surveys various constraints that encourage a learning algorithm to discover factorial representations. I dichotomize the constraints in terms of unsupervised and supervised inductive bias. Unsupervised inductive biases exploit assumptions about the environment, such as the statistical distribution of factor coefficients, assumptions about the perturbations a factor should be invariant to (e.g. a representation of an object can be invariant to rotation, translation or scaling), and assumptions about how factors are combined to synthesize an observation. Supervised inductive biases are constraints on the representations based on additional information connected to observations. Supervisory labels come in variety of types, which vary in how strongly they constrain the representation, how many factors are labeled, how many observations are labeled, and whether or not we know the associations between the constraints and the factors they are related to. This survey brings together a wide variety of models that all touch on the problem of learning factorial representations and lays out a framework for comparing these models based on the strengths of the underlying supervised and unsupervised inductive biases. version:1
arxiv-1612-05296 | Automatic time-series phenotyping using massive feature extraction | http://arxiv.org/abs/1612.05296 | id:1612.05296 author:Ben D Fulcher, Nick S Jones category:cs.LG physics.data-an q-bio.QM  published:2016-12-15 summary:Across a far-reaching diversity of scientific and industrial applications, a general key problem involves relating the structure of time-series data to a meaningful outcome, such as detecting anomalous events from sensor recordings, or diagnosing patients from physiological time-series measurements like heart rate or brain activity. Currently, researchers must devote considerable effort manually devising, or searching for, properties of their time series that are suitable for the particular analysis problem at hand. Addressing this non-systematic and time-consuming procedure, here we introduce a new tool, hctsa, that selects interpretable and useful properties of time series automatically, by comparing implementations over 7700 time-series features drawn from diverse scientific literatures. Using two exemplar biological applications, we show how hctsa allows researchers to leverage decades of time-series research to quantify and understand informative structure in their time-series data. version:1
arxiv-1612-05276 | Learning Optimal Control of Synchronization in Networks of Coupled Oscillators using Genetic Programming-based Symbolic Regression | http://arxiv.org/abs/1612.05276 | id:1612.05276 author:Julien Gout, Markus Quade, Kamran Shafi, Robert K. Niven, Markus Abel category:nlin.AO cs.SY stat.ML  published:2016-12-15 summary:Networks of coupled dynamical systems provide a powerful way to model systems with enormously complex dynamics, such as the human brain. Control of synchronization in such networked systems has far reaching applications in many domains, including engineering and medicine. In this paper, we formulate the synchronization control in dynamical systems as an optimization problem and present a multi-objective genetic programming-based approach to infer optimal control functions that drive the system from a synchronized to a non-synchronized state and vice-versa. The genetic programming-based controller allows learning optimal control functions in an interpretable symbolic form. The effectiveness of the proposed approach is demonstrated in controlling synchronization in coupled oscillator systems linked in networks of increasing order complexity, ranging from a simple coupled oscillator system to a hierarchical network of coupled oscillators. The results show that the proposed method can learn highly-effective and interpretable control functions for such systems. version:1
arxiv-1612-05270 | A Simple Approach to Multilingual Polarity Classification in Twitter | http://arxiv.org/abs/1612.05270 | id:1612.05270 author:Eric S. Tellez, Sabino Miranda Jiménez, Mario Graff, Daniela Moctezuma, Ranyart R. Suárez, Oscar S. Siordia category:cs.CL cs.LG stat.ML  published:2016-12-15 summary:Recently, sentiment analysis has received a lot of attention due to the interest in mining opinions of social media users. Sentiment analysis consists in determining the polarity of a given text, i.e., its degree of positiveness or negativeness. Traditionally, Sentiment Analysis algorithms have been tailored to a specific language given the complexity of having a number of lexical variations and errors introduced by the people generating content. In this contribution, our aim is to provide a simple to implement and easy to use multilingual framework, that can serve as a baseline for sentiment analysis contests, and as starting point to build new sentiment analysis systems. We compare our approach in eight different languages, three of them have important international contests, namely, SemEval (English), TASS (Spanish), and SENTIPOLC (Italian). Within the competitions our approach reaches from medium to high positions in the rankings; whereas in the remaining languages our approach outperforms the reported results. version:1
arxiv-1612-05251 | Neural Networks for Joint Sentence Classification in Medical Paper Abstracts | http://arxiv.org/abs/1612.05251 | id:1612.05251 author:Franck Dernoncourt, Ji Young Lee, Peter Szolovits category:cs.CL cs.AI cs.NE stat.ML  published:2016-12-15 summary:Existing models based on artificial neural networks (ANNs) for sentence classification often do not incorporate the context in which sentences appear, and classify sentences individually. However, traditional sentence classification approaches have been shown to greatly benefit from jointly classifying subsequent sentences, such as with conditional random fields. In this work, we present an ANN architecture that combines the effectiveness of typical ANN models to classify sentences in isolation, with the strength of structured prediction. Our model achieves state-of-the-art results on two different datasets for sequential sentence classification in medical abstracts. version:1
arxiv-1612-05236 | Private Learning on Networks | http://arxiv.org/abs/1612.05236 | id:1612.05236 author:Shripad Gade, Nitin H. Vaidya category:cs.DC cs.LG math.OC  published:2016-12-15 summary:Continual data collection and widespread deployment of machine learning algorithms, particularly the distributed variants, have raised new privacy challenges. In a distributed machine learning scenario, the dataset is stored among several machines and they solve a distributed optimization problem to collectively learn the underlying model. We present a secure multi-party computation inspired privacy preserving distributed algorithm for optimizing a convex function consisting of several possibly non-convex functions. Each individual objective function is privately stored with an agent while the agents communicate model parameters with neighbor machines connected in a network. We show that our algorithm can correctly optimize the overall objective function and learn the underlying model accurately. We further prove that under a vertex connectivity condition on the topology, our algorithm preserves privacy of individual objective functions. We establish limits on the what a coalition of adversaries can learn by observing the messages and states shared over a network. version:1
arxiv-1612-05234 | Visual Compiler: Synthesizing a Scene-Specific Pedestrian Detector and Pose Estimator | http://arxiv.org/abs/1612.05234 | id:1612.05234 author:Namhoon Lee, Xinshuo Weng, Vishnu Naresh Boddeti, Yu Zhang, Fares Beainy, Kris Kitani, Takeo Kanade category:cs.CV  published:2016-12-15 summary:We introduce the concept of a Visual Compiler that generates a scene specific pedestrian detector and pose estimator without any pedestrian observations. Given a single image and auxiliary scene information in the form of camera parameters and geometric layout of the scene, the Visual Compiler first infers geometrically and photometrically accurate images of humans in that scene through the use of computer graphics rendering. Using these renders we learn a scene-and-region specific spatially-varying fully convolutional neural network, for simultaneous detection, pose estimation and segmentation of pedestrians. We demonstrate that when real human annotated data is scarce or non-existent, our data generation strategy can provide an excellent solution for bootstrapping human detection and pose estimation. Experimental results show that our approach outperforms off-the-shelf state-of-the-art pedestrian detectors and pose estimators that are trained on real data. version:1
arxiv-1612-05231 | Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNN | http://arxiv.org/abs/1612.05231 | id:1612.05231 author:Li Jing, Yichen Shen, Tena Dubček, John Peurifoy, Scott Skirlo, Max Tegmark, Marin Soljačić category:cs.LG cs.NE stat.ML  published:2016-12-15 summary:We present a method for implementing an Efficient Unitary Neural Network (EUNN) whose computational complexity is merely $\mathcal{O}(1)$ per parameter and has full tunability, from spanning part of unitary space to all of it. We apply the EUNN in Recurrent Neural Networks, and test its performance on the standard copying task and the MNIST digit recognition benchmark, finding that it significantly outperforms a non-unitary RNN, an LSTM network, an exclusively partial space URNN and a projective URNN with comparable parameter numbers. version:1
arxiv-1612-04717 | Network cross-validation by edge sampling | http://arxiv.org/abs/1612.04717 | id:1612.04717 author:Tianxi Li, Elizaveta Levina, Ji Zhu category:stat.ME stat.ML  published:2016-12-14 summary:Many models and methods are now available for network analysis, but model selection and tuning remain challenging. Cross-validation is a useful general tool for these tasks in many settings, but is not directly applicable to networks since splitting network nodes into groups requires deleting edges and destroys some of the network structure. Here we propose a new network cross-validation strategy based on splitting edges rather than nodes, which avoids losing information and is applicable to a wide range of network problems. We provide a theoretical justification for our method in a general setting, and in particular show that the method has good asymptotic properties under the stochastic block model. Numerical results on both simulated and real networks show that our approach performs well for a number of model selection and parameter tuning tasks. version:2
arxiv-1612-05202 | Building a robust sentiment lexicon with (almost) no resource | http://arxiv.org/abs/1612.05202 | id:1612.05202 author:Mickael Rouvier, Benoit Favre category:cs.CL  published:2016-12-15 summary:Creating sentiment polarity lexicons is labor intensive. Automatically translating them from resourceful languages requires in-domain machine translation systems, which rely on large quantities of bi-texts. In this paper, we propose to replace machine translation by transferring words from the lexicon through word embeddings aligned across languages with a simple linear transform. The approach leads to no degradation, compared to machine translation, when tested on sentiment polarity classification on tweets from four languages. version:1
arxiv-1612-05159 | Improving Scalability of Reinforcement Learning by Separation of Concerns | http://arxiv.org/abs/1612.05159 | id:1612.05159 author:Harm van Seijen, Mehdi Fatemi, Joshua Romoff category:cs.LG cs.AI  published:2016-12-15 summary:In this paper, we propose a framework for solving a single-agent task by using multiple agents, each focusing on different aspects of the task. This approach has two main advantages: 1) it allows for specialized agents for different parts of the task, and 2) it provides a new way to transfer knowledge, by transferring trained agents. Our framework generalizes the traditional hierarchical decomposition, in which, at any moment in time, a single agent has control until it has solved its particular subtask. We illustrate our framework using a number of examples. version:1
arxiv-1612-05153 | On the Potential of Simple Framewise Approaches to Piano Transcription | http://arxiv.org/abs/1612.05153 | id:1612.05153 author:Rainer Kelz, Matthias Dorfer, Filip Korzeniowski, Sebastian Böck, Andreas Arzt, Gerhard Widmer category:cs.SD cs.LG  published:2016-12-15 summary:In an attempt at exploring the limitations of simple approaches to the task of piano transcription (as usually defined in MIR), we conduct an in-depth analysis of neural network-based framewise transcription. We systematically compare different popular input representations for transcription systems to determine the ones most suitable for use with neural networks. Exploiting recent advances in training techniques and new regularizers, and taking into account hyper-parameter tuning, we show that it is possible, by simple bottom-up frame-wise processing, to obtain a piano transcriber that outperforms the current published state of the art on the publicly available MAPS dataset -- without any complex post-processing steps. Thus, we propose this simple approach as a new baseline for this dataset, for future transcription research to build on and improve. version:1
arxiv-1612-05131 | Transition-based Parsing with Context Enhancement and Future Reward Reranking | http://arxiv.org/abs/1612.05131 | id:1612.05131 author:Fugen Zhou, Fuxiang Wu, Zhengchen Zhang, Minghui Dong category:cs.CL  published:2016-12-15 summary:This paper presents a novel reranking model, future reward reranking, to re-score the actions in a transition-based parser by using a global scorer. Different to conventional reranking parsing, the model searches for the best dependency tree in all feasible trees constraining by a sequence of actions to get the future reward of the sequence. The scorer is based on a first-order graph-based parser with bidirectional LSTM, which catches different parsing view compared with the transition-based parser. Besides, since context enhancement has shown substantial improvement in the arc-stand transition-based parsing over the parsing accuracy, we implement context enhancement on an arc-eager transition-base parser with stack LSTMs, the dynamic oracle and dropout supporting and achieve further improvement. With the global scorer and context enhancement, the results show that UAS of the parser increases as much as 1.20% for English and 1.66% for Chinese, and LAS increases as much as 1.32% for English and 1.63% for Chinese. Moreover, we get state-of-the-art LASs, achieving 87.58% for Chinese and 93.37% for English. version:1
arxiv-1612-05086 | Coupling Adaptive Batch Sizes with Learning Rates | http://arxiv.org/abs/1612.05086 | id:1612.05086 author:Lukas Balles, Javier Romero, Philipp Hennig category:cs.LG cs.CV stat.ML  published:2016-12-15 summary:Mini-batch stochastic gradient descent and variants thereof have become standard for large-scale empirical risk minimization like the training of neural networks. These methods are usually used with a constant batch size chosen by simple empirical inspection. The batch size significantly influences the behavior of the stochastic optimization algorithm, though, since it determines the variance of the gradient estimates. This variance also changes over the optimization process; when using a constant batch size, stability and convergence is thus often enforced by means of a (manually tuned) decreasing learning rate schedule. We propose a practical method for dynamic batch size adaptation. It estimates the variance of the stochastic gradients and adapts the batch size to decrease the variance proportionally to the value of the objective function, removing the need for the aforementioned learning rate decrease. In contrast to recent related work, our algorithm couples the batch size to the learning rate, directly reflecting the known relationship between the two. On three image classification benchmarks, our batch size adaptation yields faster optimization convergence, while simultaneously simplifying learning rate tuning. A TensorFlow implementation is available. version:1
arxiv-1612-05082 | A Fully Convolutional Deep Auditory Model for Musical Chord Recognition | http://arxiv.org/abs/1612.05082 | id:1612.05082 author:Filip Korzeniowski, Gerhard Widmer category:cs.LG cs.SD  published:2016-12-15 summary:Chord recognition systems depend on robust feature extraction pipelines. While these pipelines are traditionally hand-crafted, recent advances in end-to-end machine learning have begun to inspire researchers to explore data-driven methods for such tasks. In this paper, we present a chord recognition system that uses a fully convolutional deep auditory model for feature extraction. The extracted features are processed by a Conditional Random Field that decodes the final chord sequence. Both processing stages are trained automatically and do not require expert knowledge for optimising parameters. We show that the learned auditory system extracts musically interpretable features, and that the proposed chord recognition system achieves results on par or better than state-of-the-art algorithms. version:1
arxiv-1612-05070 | Towards End-to-End Audio-Sheet-Music Retrieval | http://arxiv.org/abs/1612.05070 | id:1612.05070 author:Matthias Dorfer, Andreas Arzt, Gerhard Widmer category:cs.SD cs.IR cs.LG  published:2016-12-15 summary:This paper demonstrates the feasibility of learning to retrieve short snippets of sheet music (images) when given a short query excerpt of music (audio) -- and vice versa --, without any symbolic representation of music or scores. This would be highly useful in many content-based musical retrieval scenarios. Our approach is based on Deep Canonical Correlation Analysis (DCCA) and learns correlated latent spaces allowing for cross-modality retrieval in both directions. Initial experiments with relatively simple monophonic music show promising results. version:1
arxiv-1612-05065 | Feature Learning for Chord Recognition: The Deep Chroma Extractor | http://arxiv.org/abs/1612.05065 | id:1612.05065 author:Filip Korzeniowski, Gerhard Widmer category:cs.SD cs.LG  published:2016-12-15 summary:We explore frame-level audio feature learning for chord recognition using artificial neural networks. We present the argument that chroma vectors potentially hold enough information to model harmonic content of audio for chord recognition, but that standard chroma extractors compute too noisy features. This leads us to propose a learned chroma feature extractor based on artificial neural networks. It is trained to compute chroma features that encode harmonic information important for chord recognition, while being robust to irrelevant interferences. We achieve this by feeding the network an audio spectrum with context instead of a single frame as input. This way, the network can learn to selectively compensate noise and resolve harmonic ambiguities. We compare the resulting features to hand-crafted ones by using a simple linear frame-wise classifier for chord recognition on various data sets. The results show that the learned feature extractor produces superior chroma vectors for chord recognition. version:1
arxiv-1612-07310 | Beyond Holistic Object Recognition: Enriching Image Understanding with Part States | http://arxiv.org/abs/1612.07310 | id:1612.07310 author:Cewu Lu, Hao Su, Yongyi Lu, Li Yi, Chikeung Tang, Leonidas Guibas category:cs.CV F.2.2  published:2016-12-15 summary:Important high-level vision tasks such as human-object interaction, image captioning and robotic manipulation require rich semantic descriptions of objects at part level. Based upon previous work on part localization, in this paper, we address the problem of inferring rich semantics imparted by an object part in still images. We propose to tokenize the semantic space as a discrete set of part states. Our modeling of part state is spatially localized, therefore, we formulate the part state inference problem as a pixel-wise annotation problem. An iterative part-state inference neural network is specifically designed for this task, which is efficient in time and accurate in performance. Extensive experiments demonstrate that the proposed method can effectively predict the semantic states of parts and simultaneously correct localization errors, thus benefiting a few visual understanding applications. The other contribution of this paper is our part state dataset which contains rich part-level semantic annotations. version:1
arxiv-1612-05062 | Reflectance Adaptive Filtering Improves Intrinsic Image Estimation | http://arxiv.org/abs/1612.05062 | id:1612.05062 author:Thomas Nestmeyer, Peter V. Gehler category:cs.CV  published:2016-12-15 summary:Separation of an input image into its reflectance and shading layers poses a challenge for learning approaches because no large corpus of precise and realistic ground truth decompositions exists. The Intrinsic Images in the Wild dataset (IIW) provides a sparse set of relative human reflectance judgments, which serves as a standard benchmark for intrinsic images. This dataset led to an increase in methods that learn statistical dependencies between the images and their reflectance layer. Although learning plays a role in pushing state-of-the-art performance, we show that a standard signal processing technique achieves performance on par with recent developments. We propose a loss function that enables learning dense reflectance predictions with a CNN. Our results show a simple pixel-wise decision, without any context or prior knowledge, is sufficient to provide a strong baseline on IIW. This sets a competitive bar and we find that only two approaches surpass this result. We then develop a joint bilateral filtering method that implements strong prior knowledge about reflectance constancy. This filtering operation can be applied to any intrinsic image algorithm and we improve several previous results achieving a new state-of-the-art on IIW. Our findings suggest that the effect of learning-based approaches may be over-estimated and that it is still the use of explicit prior knowledge that drives performance on intrinsic image decompositions. version:1
arxiv-1612-05054 | Graphical RNN Models | http://arxiv.org/abs/1612.05054 | id:1612.05054 author:Ashish Bora, Sugato Basu, Joydeep Ghosh category:cs.NE cs.LG  published:2016-12-15 summary:Many time series are generated by a set of entities that interact with one another over time. This paper introduces a broad, flexible framework to learn from multiple inter-dependent time series generated by such entities. Our framework explicitly models the entities and their interactions through time. It achieves this by building on the capabilities of Recurrent Neural Networks, while also offering several ways to incorporate domain knowledge/constraints into the model architecture. The capabilities of our approach are showcased through an application to weather prediction, which shows gains over strong baselines. version:1
arxiv-1612-05053 | Expectation Propagation performs a smoothed gradient descent | http://arxiv.org/abs/1612.05053 | id:1612.05053 author:Guillaume P. Dehaene category:stat.ML stat.CO  published:2016-12-15 summary:Bayesian inference is a popular method to build learning algorithms but it is hampered by the fact that its key object, the posterior probability distribution, is often uncomputable. Expectation Propagation (EP) (Minka (2001)) is a popular algorithm that solves this issue by computing a parametric approximation (e.g: Gaussian) to the density of the posterior. However, while it is known empirically to quickly compute fine approximations, EP is extremely poorly understood which prevents it from being adopted by a larger fraction of the community. The object of the present article is to shed intuitive light on EP, by relating it to other better understood methods. More precisely, we link it to using gradient descent to compute the Laplace approximation of a target probability distribution. We show that EP is exactly equivalent to performing gradient descent on a smoothed energy landscape: i.e: the original energy landscape convoluted with some smoothing kernel. This also relates EP to algorithms that compute the Gaussian approximation which minimizes the reverse KL divergence to the target distribution, a link that has been conjectured before but has not been proved rigorously yet. These results can help practitioners to get a better feel for how EP works, as well as lead to other new results on this important method. version:1
arxiv-1612-05050 | Towards Score Following in Sheet Music Images | http://arxiv.org/abs/1612.05050 | id:1612.05050 author:Matthias Dorfer, Andreas Arzt, Gerhard Widmer category:cs.LG cs.CV  published:2016-12-15 summary:This paper addresses the matching of short music audio snippets to the corresponding pixel location in images of sheet music. A system is presented that simultaneously learns to read notes, listens to music and matches the currently played music to its corresponding notes in the sheet. It consists of an end-to-end multi-modal convolutional neural network that takes as input images of sheet music and spectrograms of the respective audio snippets. It learns to predict, for a given unseen audio snippet (covering approximately one bar of music), the corresponding position in the respective score line. Our results suggest that with the use of (deep) neural networks -- which have proven to be powerful image processing models -- working with sheet music becomes feasible and a promising future research direction. version:1
arxiv-1612-05048 | Adversarial Message Passing For Graphical Models | http://arxiv.org/abs/1612.05048 | id:1612.05048 author:Theofanis Karaletsos category:stat.ML cs.AI  published:2016-12-15 summary:Bayesian inference on structured models typically relies on the ability to infer posterior distributions of underlying hidden variables. However, inference in implicit models or complex posterior distributions is hard. A popular tool for learning implicit models are generative adversarial networks (GANs) which learn parameters of generators by fooling discriminators. Typically, GANs are considered to be models themselves and are not understood in the context of inference. Current techniques rely on inefficient global discrimination of joint distributions to perform learning, or only consider discriminating a single output variable. We overcome these limitations by treating GANs as a basis for likelihood-free inference in generative models and generalize them to Bayesian posterior inference over factor graphs. We propose local learning rules based on message passing minimizing a global divergence criterion involving cooperating local adversaries used to sidestep explicit likelihood evaluations. This allows us to compose models and yields a unified inference and learning framework for adversarial learning. Our framework treats model specification and inference separately and facilitates richly structured models within the family of Directed Acyclic Graphs, including components such as intractable likelihoods, non-differentiable models, simulators and generally cumbersome models. A key result of our treatment is the insight that Bayesian inference on structured models can be performed only with sampling and discrimination when using nonparametric variational families, without access to explicit distributions. As a side-result, we discuss the link to likelihood maximization. These approaches hold promise to be useful in the toolbox of probabilistic modelers and enrich the gamut of current probabilistic programming applications. version:1
arxiv-1612-05038 | Objective Micro-Facial Movement Detection Using FACS-Based Regions and Baseline Evaluation | http://arxiv.org/abs/1612.05038 | id:1612.05038 author:Adrian K. Davison, Cliff Lansley, Choon Ching Ng, Kevin Tan, Moi Hoon Yap category:cs.CV  published:2016-12-15 summary:Micro-facial expressions are regarded as an important human behavioural event that can highlight emotional deception. Spotting these movements is difficult for humans and machines, however research into using computer vision to detect subtle facial expressions is growing in popularity. This paper proposes an individualised baseline micro-movement detection method using 3D Histogram of Oriented Gradients (3D HOG) temporal difference method. We define a face template consisting of 26 regions based on the Facial Action Coding System (FACS). We extract the temporal features of each region using 3D HOG. Then, we use Chi-square distance to find subtle facial motion in the local regions. Finally, an automatic peak detector is used to detect micro-movements above the newly proposed adaptive baseline threshold. The performance is validated on two FACS coded datasets: SAMM and CASME II. This objective method focuses on the movement of the 26 face regions. When comparing with the ground truth, the best result was an AUC of 0.7512 and 0.7261 on SAMM and CASME II, respectively. The results show that 3D HOG outperformed for micro-movement detection, compared to state-of-the-art feature representations: Local Binary Patterns in Three Orthogonal Planes and Histograms of Oriented Optical Flow. version:1
arxiv-1612-05024 | Optimal structure and parameter learning of Ising models | http://arxiv.org/abs/1612.05024 | id:1612.05024 author:Andrey Y. Lokhov, Marc Vuffray, Sidhant Misra, Michael Chertkov category:cond-mat.stat-mech cs.LG physics.data-an stat.ML  published:2016-12-15 summary:Reconstruction of structure and parameters of a graphical model from binary samples is a problem of practical importance in a variety of disciplines, ranging from statistical physics and computational biology to image processing and machine learning. The focus of the research community shifted towards developing universal reconstruction algorithms which are both computationally efficient and require the minimal amount of expensive data. We introduce a new method, Interaction Screening, which accurately estimates the model parameters using local optimization problems. The algorithm provably achieves perfect graph structure recovery with an information-theoretically optimal number of samples and outperforms state of the art techniques, especially in the low-temperature regime which is known to be the hardest for learning. We assess the efficacy of Interaction Screening through extensive numerical tests on Ising models of various topologies and with different types of interactions, ranging from ferromagnetic to spin-glass. version:1
arxiv-1612-05005 | A Multilinear Tongue Model Derived from Speech Related MRI Data of the Human Vocal Tract | http://arxiv.org/abs/1612.05005 | id:1612.05005 author:Alexander Hewer, Stefanie Wuhrer, Ingmar Steiner, Korin Richmond category:cs.CV  published:2016-12-15 summary:We present a multilinear statistical model of the human tongue that captures anatomical and tongue pose related shape variations separately. The model was derived from 3D magnetic resonance imaging data of 11 speakers sustaining speech related vocal tract configurations. The extraction was performed by using a minimally supervised method that uses as basis an image segmentation approach and a template fitting technique. Furthermore, it uses image denoising to deal with possibly corrupt data, palate surface information reconstruction to handle palatal tongue contacts, and a bootstrap strategy to refine the obtained shapes. Our experiments concluded that limiting the degrees of freedom for the anatomical and speech related variations to 5 and 4 respectively produces a model that can reliably register unknown data while avoiding overfitting effects. version:1
arxiv-1612-05001 | Graph-based semi-supervised learning for relational networks | http://arxiv.org/abs/1612.05001 | id:1612.05001 author:Leto Peel category:cs.SI cs.LG physics.data-an stat.ML  published:2016-12-15 summary:We address the problem of semi-supervised learning in relational networks, networks in which nodes are entities and links are the relationships or interactions between them. Typically this problem is confounded with the problem of graph-based semi-supervised learning (GSSL), because both problems represent the data as a graph and predict the missing class labels of nodes. However, not all graphs are created equally. In GSSL a graph is constructed, often from independent data, based on similarity. As such, edges tend to connect instances with the same class label. Relational networks, however, can be more heterogeneous and edges do not always indicate similarity. For instance, instead of links being more likely to connect nodes with the same class label, they may occur more frequently between nodes with different class labels (link-heterogeneity). Or nodes with the same class label do not necessarily have the same type of connectivity across the whole network (class-heterogeneity), e.g. in a network of sexual interactions we may observe links between opposite genders in some parts of the graph and links between the same genders in others. Performing classification in networks with different types of heterogeneity is a hard problem that is made harder still when we do not know a-priori the type or level of heterogeneity. Here we present two scalable approaches for graph-based semi-supervised learning for the more general case of relational networks. We demonstrate these approaches on synthetic and real-world networks that display different link patterns within and between classes. Compared to state-of-the-art approaches, ours give better classification performance without prior knowledge of how classes interact. In particular, our two-step label propagation algorithm gives consistently good accuracy and runs on networks of over 1.6 million nodes and 30 million edges in around 12 seconds. version:1
arxiv-1612-04988 | TeKnowbase: Towards Construction of a Knowledge-base of Technical Concepts | http://arxiv.org/abs/1612.04988 | id:1612.04988 author:Prajna Upadhyay, Tanuma Patra, Ashwini Purkar, Maya Ramanath category:cs.CL cs.AI  published:2016-12-15 summary:In this paper, we describe the construction of TeKnowbase, a knowledge-base of technical concepts in computer science. Our main information sources are technical websites such as Webopedia and Techtarget as well as Wikipedia and online textbooks. We divide the knowledge-base construction problem into two parts -- the acquisition of entities and the extraction of relationships among these entities. Our knowledge-base consists of approximately 100,000 triples. We conducted an evaluation on a sample of triples and report an accuracy of a little over 90\%. We additionally conducted classification experiments on StackOverflow data with features from TeKnowbase and achieved improved classification accuracy. version:1
arxiv-1612-04970 | Improving Neural Network Generalization by Combining Parallel Circuits with Dropout | http://arxiv.org/abs/1612.04970 | id:1612.04970 author:Kien Tuong Phan, Tomas Henrique Maul, Tuong Thuy Vu, Lai Weng Kin category:cs.NE cs.LG  published:2016-12-15 summary:In an attempt to solve the lengthy training times of neural networks, we proposed Parallel Circuits (PCs), a biologically inspired architecture. Previous work has shown that this approach fails to maintain generalization performance in spite of achieving sharp speed gains. To address this issue, and motivated by the way Dropout prevents node co-adaption, in this paper, we suggest an improvement by extending Dropout to the PC architecture. The paper provides multiple insights into this combination, including a variety of fusion approaches. Experiments show promising results in which improved error rates are achieved in most cases, whilst maintaining the speed advantage of the PC approach. version:1
arxiv-1612-04966 | Design of Image Matched Non-Separable Wavelet using Convolutional Neural Network | http://arxiv.org/abs/1612.04966 | id:1612.04966 author:Naushad Ansari, Anubha Gupta, Rahul Duggal category:cs.CV  published:2016-12-15 summary:Image-matched nonseparable wavelets can find potential use in many applications including image classification, segmen- tation, compressive sensing, etc. This paper proposes a novel design methodology that utilizes convolutional neural net- work (CNN) to design two-channel non-separable wavelet matched to a given image. The design is proposed on quin- cunx lattice. The loss function of the convolutional neural network is setup with total squared error between the given input image to CNN and the reconstructed image at the output of CNN, leading to perfect reconstruction at the end of train- ing. Simulation results have been shown on some standard images. version:1
arxiv-1612-04956 | Cloud Dictionary: Sparse Coding and Modeling for Point Clouds | http://arxiv.org/abs/1612.04956 | id:1612.04956 author:Or Litany, Tal Remez, Alex Bronstein category:cs.CV cs.GR  published:2016-12-15 summary:With the development of range sensors such as LIDAR and time-of-flight cameras, 3D point cloud scans have become ubiquitous in computer vision applications, the most prominent ones being gesture recognition and autonomous driving. Parsimony-based algorithms have shown great success on images and videos where data points are sampled on a regular Cartesian grid. We propose an adaptation of these techniques to irregularly sampled signals by using continuous dictionaries. We present an example application in the form of point cloud denoising. version:1
arxiv-1612-04949 | Recurrent Image Captioner: Describing Images with Spatial-Invariant Transformation and Attention Filtering | http://arxiv.org/abs/1612.04949 | id:1612.04949 author:Hao Liu, Yang Yang, Fumin Shen, Lixin Duan, Heng Tao Shen category:cs.CV cs.CL  published:2016-12-15 summary:Along with the prosperity of recurrent neural network in modelling sequential data and the power of attention mechanism in automatically identify salient information, image captioning, a.k.a., image description, has been remarkably advanced in recent years. Nonetheless, most existing paradigms may suffer from the deficiency of invariance to images with different scaling, rotation, etc.; and effective integration of standalone attention to form a holistic end-to-end system. In this paper, we propose a novel image captioning architecture, termed Recurrent Image Captioner (\textbf{RIC}), which allows visual encoder and language decoder to coherently cooperate in a recurrent manner. Specifically, we first equip CNN-based visual encoder with a differentiable layer to enable spatially invariant transformation of visual signals. Moreover, we deploy an attention filter module (differentiable) between encoder and decoder to dynamically determine salient visual parts. We also employ bidirectional LSTM to preprocess sentences for generating better textual representations. Besides, we propose to exploit variational inference to optimize the whole architecture. Extensive experimental results on three benchmark datasets (i.e., Flickr8k, Flickr30k and MS COCO) demonstrate the superiority of our proposed architecture as compared to most of the state-of-the-art methods. version:1
arxiv-1612-04936 | Learning Through Dialogue Interactions | http://arxiv.org/abs/1612.04936 | id:1612.04936 author:Jiwei Li, Alexander H. Miller, Sumit Chopra, Marc'Aurelio Ranzato, Jason Weston category:cs.CL cs.AI  published:2016-12-15 summary:A good dialogue agent should have the ability to interact with users. In this work, we explore this direction by designing a simulator and a set of synthetic tasks in the movie domain that allow the learner to interact with a teacher by both asking and answering questions. We investigate how a learner can benefit from asking questions in both an offline and online reinforcement learning setting. We demonstrate that the learner improves when asking questions. Our work represents a first step in developing end-to-end learned interactive dialogue agents. version:1
arxiv-1612-03147 | Testing Ising Models | http://arxiv.org/abs/1612.03147 | id:1612.03147 author:Constantinos Daskalakis, Nishanth Dikkala, Gautam Kamath category:cs.DS cs.IT cs.LG math.IT math.PR math.ST stat.TH  published:2016-12-09 summary:Given samples from an unknown multivariate distribution $p$, is it possible to distinguish whether $p$ is the product of its marginals versus $p$ being far from every product distribution? Similarly, is it possible to distinguish whether $p$ equals a given distribution $q$ versus $p$ and $q$ being far from each other? These problems of testing independence and goodness-of-fit have received enormous attention in statistics, information theory, and theoretical computer science, with sample-optimal algorithms known in several interesting regimes of parameters. Unfortunately, it has also been understood that these problems become intractable in large dimensions, necessitating exponential sample complexity. Motivated by the exponential lower bounds for general distributions as well as the ubiquity of Markov Random Fields (MRFs) in the modeling of high-dimensional distributions, we initiate the study of distribution testing on structured multivariate distributions, and in particular the prototypical example of MRFs: the Ising Model. We demonstrate that, in this structured setting, we can avoid the curse of dimensionality, obtaining sample and time efficient testers for independence and goodness-of-fit. Along the way, we develop new tools for establishing concentration of functions of the Ising model, using the exchangeable pairs framework developed by Chatterjee, and improving upon this framework. In particular, we prove tighter concentration results for multi-linear functions of the Ising model in the high-temperature regime. version:2
arxiv-1612-04933 | Dynamical Kinds and their Discovery | http://arxiv.org/abs/1612.04933 | id:1612.04933 author:Benjamin C. Jantzen category:stat.ML cs.AI cs.LG cs.SY  published:2016-12-15 summary:We demonstrate the possibility of classifying causal systems into kinds that share a common structure without first constructing an explicit dynamical model or using prior knowledge of the system dynamics. The algorithmic ability to determine whether arbitrary systems are governed by causal relations of the same form offers significant practical applications in the development and validation of dynamical models. It is also of theoretical interest as an essential stage in the scientific inference of laws from empirical data. The algorithm presented is based on the dynamical symmetry approach to dynamical kinds. A dynamical symmetry with respect to time is an intervention on one or more variables of a system that commutes with the time evolution of the system. A dynamical kind is a class of systems sharing a set of dynamical symmetries. The algorithm presented classifies deterministic, time-dependent causal systems by directly comparing their exhibited symmetries. Using simulated, noisy data from a variety of nonlinear systems, we show that this algorithm correctly sorts systems into dynamical kinds. It is robust under significant sampling error, is immune to violations of normality in sampling error, and fails gracefully with increasing dynamical similarity. The algorithm we demonstrate is the first to address this aspect of automated scientific discovery. version:1
arxiv-1612-04904 | Regressing Robust and Discriminative 3D Morphable Models with a very Deep Neural Network | http://arxiv.org/abs/1612.04904 | id:1612.04904 author:Anh Tuan Tran, Tal Hassner, Iacopo Masi, Gerard Medioni category:cs.CV  published:2016-12-15 summary:The 3D shapes of faces are well known to be discriminative. Yet despite this, they are rarely used for face recognition and always under controlled viewing conditions. We claim that this is a symptom of a serious but often overlooked problem with existing methods for single view 3D face reconstruction: when applied "in the wild", their 3D estimates are either unstable and change for different photos of the same subject or they are over-regularized and generic. In response, we describe a robust method for regressing discriminative 3D morphable face models (3DMM). We use a convolutional neural network (CNN) to regress 3DMM shape and texture parameters directly from an input photo. We overcome the shortage of training data required for this purpose by offering a method for generating huge numbers of labeled examples. The 3D estimates produced by our CNN surpass state of the art accuracy on the MICC data set. Coupled with a 3D-3D face matching pipeline, we show the first competitive face recognition results on the LFW, YTF and IJB-A benchmarks using 3D face shapes as representations, rather than the opaque deep feature vectors used by other modern systems. version:1
arxiv-1612-04742 | Imposing higher-level Structure in Polyphonic Music Generation using Convolutional Restricted Boltzmann Machines and Constraints | http://arxiv.org/abs/1612.04742 | id:1612.04742 author:Stefan Lattner, Maarten Grachten, Gerhard Widmer category:cs.SD cs.AI cs.NE  published:2016-12-14 summary:We introduce a method for imposing higher-level structure on generated, polyphonic music. A Convolutional Restricted Boltzmann Machine (C-RBM) as a generative model is combined with gradient descent constraint optimization to provide further control over the generation process. Among other things, this allows for the use of a "template" piece, from which some structural properties can be extracted, and transferred as constraints to newly generated material. The sampling process is guided with Simulated Annealing in order to avoid local optima, and find solutions that both satisfy the constraints, and are relatively stable with respect to the C-RBM. Results show that with this approach it is possible to control the higher level self-similarity structure, the meter, as well as tonal properties of the resulting musical piece while preserving its local musical coherence. version:2
arxiv-1612-04901 | Tinkering Under the Hood: Interactive Zero-Shot Learning with Net Surgery | http://arxiv.org/abs/1612.04901 | id:1612.04901 author:Vivek Krishnan, Deva Ramanan category:cs.CV  published:2016-12-15 summary:We consider the task of visual net surgery, in which a CNN can be reconfigured without extra data to recognize novel concepts that may be omitted from the training set. While most prior work make use of linguistic cues for such "zero-shot" learning, we do so by using a pictorial language representation of the training set, implicitly learned by a CNN, to generalize to new classes. To this end, we introduce a set of visualization techniques that better reveal the activation patterns and relations between groups of CNN filters. We next demonstrate that knowledge of pictorial languages can be used to rewire certain CNN neurons into a part model, which we call a pictorial language classifier. We demonstrate the robustness of simple PLCs by applying them in a weakly supervised manner: labeling unlabeled concepts for visual classes present in the training data. Specifically we show that a PLC built on top of a CNN trained for ImageNet classification can localize humans in Graz-02 and determine the pose of birds in PASCAL-VOC without extra labeled data or additional training. We then apply PLCs in an interactive zero-shot manner, demonstrating that pictorial languages are expressive enough to detect a set of visual classes in MS-COCO that never appear in the ImageNet training set. version:1
arxiv-1612-04899 | Semi-Supervised Phone Classification using Deep Neural Networks and Stochastic Graph-Based Entropic Regularization | http://arxiv.org/abs/1612.04899 | id:1612.04899 author:Sunil Thulasidasan, Jeffrey Bilmes category:stat.ML cs.LG  published:2016-12-15 summary:We describe a graph-based semi-supervised learning framework in the context of deep neural networks that uses a graph-based entropic regularizer to favor smooth solutions over a graph induced by the data. The main contribution of this work is a computationally efficient, stochastic graph-regularization technique that uses mini-batches that are consistent with the graph structure, but also provides enough stochasticity (in terms of mini-batch data diversity) for convergence of stochastic gradient descent methods to good solutions. For this work, we focus on results of frame-level phone classification accuracy on the TIMIT speech corpus but our method is general and scalable to much larger data sets. Results indicate that our method significantly improves classification accuracy compared to the fully-supervised case when the fraction of labeled data is low, and it is competitive with other methods in the fully labeled case. version:1
arxiv-1612-04898 | Efficient Distributed Semi-Supervised Learning using Stochastic Regularization over Affinity Graphs | http://arxiv.org/abs/1612.04898 | id:1612.04898 author:Sunil Thulasidasan, Jeffrey Bilmes, Garrett Kenyon category:stat.ML cs.DC cs.LG  published:2016-12-15 summary:We describe a computationally efficient, stochastic graph-regularization technique that can be utilized for the semi-supervised training of deep neural networks in a parallel or distributed setting. We utilize a technique, first described in [13] for the construction of mini-batches for stochastic gradient descent (SGD) based on synthesized partitions of an affinity graph that are consistent with the graph structure, but also preserve enough stochasticity for convergence of SGD to good local minima. We show how our technique allows a graph-based semi-supervised loss function to be decomposed into a sum over objectives, facilitating data parallelism for scalable training of machine learning models. Empirical results indicate that our method significantly improves classification accuracy compared to the fully-supervised case when the fraction of labeled data is low, and in the parallel case, achieves significant speed-up in terms of wall-clock time to convergence. We show the results for both sequential and distributed-memory semi-supervised DNN training on a speech corpus. version:1
arxiv-1612-04897 | Learning binary or real-valued time-series via spike-timing dependent plasticity | http://arxiv.org/abs/1612.04897 | id:1612.04897 author:Takayuki Osogami category:cs.NE stat.ML  published:2016-12-15 summary:A dynamic Boltzmann machine (DyBM) has been proposed as a model of a spiking neural network, and its learning rule of maximizing the log-likelihood of given time-series has been shown to exhibit key properties of spike-timing dependent plasticity (STDP), which had been postulated and experimentally confirmed in the field of neuroscience as a learning rule that refines the Hebbian rule. Here, we relax some of the constraints in the DyBM in a way that it becomes more suitable for computation and learning. We show that learning the DyBM can be considered as logistic regression for binary-valued time-series. We also show how the DyBM can learn real-valued data in the form of a Gaussian DyBM and discuss its relation to the vector autoregressive (VAR) model. The Gaussian DyBM extends the VAR by using additional explanatory variables, which correspond to the eligibility traces of the DyBM and capture long term dependency of the time-series. Numerical experiments show that the Gaussian DyBM significantly improves the predictive accuracy over VAR. version:1
arxiv-1612-04895 | Projected Regression Methods for Inverting Fredholm Integrals: Formalism and Application to Analytical Continuation | http://arxiv.org/abs/1612.04895 | id:1612.04895 author:Louis-Francois Arsenault, Richard Neuberg, Lauren A. Hannah, Andrew J. Millis category:cond-mat.str-el stat.ML  published:2016-12-15 summary:We present a machine learning approach to the inversion of Fredholm integrals of the first kind. The approach provides a natural regularization in cases where the inverse of the Fredholm kernel is ill-conditioned. It also provides an efficient and stable treatment of constraints. The key observation is that the stability of the forward problem permits the construction of a large database of outputs for physically meaningful inputs. We apply machine learning to this database to generate a regression function of controlled complexity, which returns approximate solutions for previously unseen inputs; the approximate solutions are then projected onto the subspace of functions satisfying relevant constraints. We also derive and present uncertainty estimates. We illustrate the approach by applying it to the analytical continuation problem of quantum many-body physics, which involves reconstructing the frequency dependence of physical excitation spectra from data obtained at specific points in the complex frequency plane. Under standard error metrics the method performs as well or better than the Maximum Entropy method for low input noise and is substantially more robust to increased input noise. We expect the methodology to be similarly effective for any problem involving a formally ill-conditioned inversion, provided that the forward problem can be efficiently solved. version:1
arxiv-1612-04891 | Deep learning is effective for the classification of OCT images of normal versus Age-related Macular Degeneration | http://arxiv.org/abs/1612.04891 | id:1612.04891 author:Cecilia S. Lee, Doug M. Baughman, Aaron Y. Lee category:stat.ML cs.CV cs.LG  published:2016-12-15 summary:Objective: The advent of Electronic Medical Records (EMR) with large electronic imaging databases along with advances in deep neural networks with machine learning has provided a unique opportunity to achieve milestones in automated image analysis. Optical coherence tomography (OCT) is the most commonly obtained imaging modality in ophthalmology and represents a dense and rich dataset when combined with labels derived from the EMR. We sought to determine if deep learning could be utilized to distinguish normal OCT images from images from patients with Age-related Macular Degeneration (AMD). Methods: Automated extraction of an OCT imaging database was performed and linked to clinical endpoints from the EMR. OCT macula scans were obtained by Heidelberg Spectralis, and each OCT scan was linked to EMR clinical endpoints extracted from EPIC. The central 11 images were selected from each OCT scan of two cohorts of patients: normal and AMD. Cross-validation was performed using a random subset of patients. Area under receiver operator curves (auROC) were constructed at an independent image level, macular OCT level, and patient level. Results: Of an extraction of 2.6 million OCT images linked to clinical datapoints from the EMR, 52,690 normal and 48,312 AMD macular OCT images were selected. A deep neural network was trained to categorize images as either normal or AMD. At the image level, we achieved an auROC of 92.78% with an accuracy of 87.63%. At the macula level, we achieved an auROC of 93.83% with an accuracy of 88.98%. At a patient level, we achieved an auROC of 97.45% with an accuracy of 93.45%. Peak sensitivity and specificity with optimal cutoffs were 92.64% and 93.69% respectively. Conclusions: Deep learning techniques are effective for classifying OCT images. These findings have important implications in utilizing OCT in automated screening and computer aided diagnosis tools. version:1
arxiv-1612-04884 | Scale Coding Bag of Deep Features for Human Attribute and Action Recognition | http://arxiv.org/abs/1612.04884 | id:1612.04884 author:Fahad Shahbaz Khan, Joost van de Weijer, Rao Muhammad Anwer, Andrew D. Bagdanov, Michael Felsberg, Jorma Laaksonen category:cs.CV  published:2016-12-14 summary:Most approaches to human attribute and action recognition in still images are based on image representation in which multi-scale local features are pooled across scale into a single, scale-invariant encoding. Both in bag-of-words and the recently popular representations based on convolutional neural networks, local features are computed at multiple scales. However, these multi-scale convolutional features are pooled into a single scale-invariant representation. We argue that entirely scale-invariant image representations are sub-optimal and investigate approaches to scale coding within a Bag of Deep Features framework. Our approach encodes multi-scale information explicitly during the image encoding stage. We propose two strategies to encode multi-scale information explicitly in the final image representation. We validate our two scale coding techniques on five datasets: Willow, PASCAL VOC 2010, PASCAL VOC 2012, Stanford-40 and Human Attributes (HAT-27). On all datasets, the proposed scale coding approaches outperform both the scale-invariant method and the standard deep features of the same network. Further, combining our scale coding approaches with standard deep features leads to consistent improvement over the state-of-the-art. version:1
arxiv-1612-04875 | Robust Local Scaling using Conditional Quantiles of Graph Similarities | http://arxiv.org/abs/1612.04875 | id:1612.04875 author:Jayaraman J. Thiagarajan, Prasanna Sattigeri, Karthikeyan Natesan Ramamurthy, Bhavya Kailkhura category:stat.ML  published:2016-12-14 summary:Spectral analysis of neighborhood graphs is one of the most widely used techniques for exploratory data analysis, with applications ranging from machine learning to social sciences. In such applications, it is typical to first encode relationships between the data samples using an appropriate similarity function. Popular neighborhood construction techniques such as k-nearest neighbor (k-NN) graphs are known to be very sensitive to the choice of parameters, and more importantly susceptible to noise and varying densities. In this paper, we propose the use of quantile analysis to obtain local scale estimates for neighborhood graph construction. To this end, we build an auto-encoding neural network approach for inferring conditional quantiles of a similarity function, which are subsequently used to obtain robust estimates of the local scales. In addition to being highly resilient to noise or outlying data, the proposed approach does not require extensive parameter tuning unlike several existing methods. Using applications in spectral clustering and single-example label propagation, we show that the proposed neighborhood graphs outperform existing locally scaled graph construction approaches. version:1
arxiv-1612-04869 | Border-Peeling Clustering | http://arxiv.org/abs/1612.04869 | id:1612.04869 author:Nadav Bar, Hadar Averbuch-Elor, Daniel Cohen-Or category:cs.CV  published:2016-12-14 summary:In this paper, we present a novel non-parametric clustering technique, which is based on an iterative algorithm that peels off layers of points around the clusters. Our technique is based on the notion that each latent cluster is comprised of layers that surround its core, where the external layers, or border points, implicitly separate the clusters. Analyzing the K-nearest neighbors of the points makes it possible to identify the border points and associate them with points of inner layers. Our clustering algorithm iteratively identifies border points, peels them, and separates the latent clusters. We show that the peeling process adapts to the local density and successfully separates adjacent clusters. A notable quality of the Border-Peeling algorithm is that it does not require any parameter tuning in order to outperform state-of-the-art finely-tuned non-parametric clustering methods, including Mean-Shift and DBSCAN. We further assess our technique on high-dimensional datasets that vary in size and characteristics. In particular, we analyze the space of deep features that were trained by a convolutional neural network. version:1
arxiv-1612-04868 | Interpretable Semantic Textual Similarity: Finding and explaining differences between sentences | http://arxiv.org/abs/1612.04868 | id:1612.04868 author:I. Lopez-Gazpio, M. Maritxalar, A. Gonzalez-Agirre, G. Rigau, L. Uria, E. Agirre category:cs.CL cs.AI cs.LG  published:2016-12-14 summary:User acceptance of artificial intelligence agents might depend on their ability to explain their reasoning, which requires adding an interpretability layer that fa- cilitates users to understand their behavior. This paper focuses on adding an in- terpretable layer on top of Semantic Textual Similarity (STS), which measures the degree of semantic equivalence between two sentences. The interpretability layer is formalized as the alignment between pairs of segments across the two sentences, where the relation between the segments is labeled with a relation type and a similarity score. We present a publicly available dataset of sentence pairs annotated following the formalization. We then develop a system trained on this dataset which, given a sentence pair, explains what is similar and different, in the form of graded and typed segment alignments. When evaluated on the dataset, the system performs better than an informed baseline, showing that the dataset and task are well-defined and feasible. Most importantly, two user studies show how the system output can be used to automatically produce explanations in natural language. Users performed better when having access to the explanations, pro- viding preliminary evidence that our dataset and method to automatically produce explanations is useful in real applications. version:1
arxiv-1612-04858 | Bayesian Optimization for Machine Learning : A Practical Guidebook | http://arxiv.org/abs/1612.04858 | id:1612.04858 author:Ian Dewancker, Michael McCourt, Scott Clark category:cs.LG  published:2016-12-14 summary:The engineering of machine learning systems is still a nascent field; relying on a seemingly daunting collection of quickly evolving tools and best practices. It is our hope that this guidebook will serve as a useful resource for machine learning practitioners looking to take advantage of Bayesian optimization techniques. We outline four example machine learning problems that can be solved using open source machine learning libraries, and highlight the benefits of using Bayesian optimization in the context of these common machine learning applications. version:1
arxiv-1612-04854 | Temporal-Needle: A view and appearance invariant video descriptor | http://arxiv.org/abs/1612.04854 | id:1612.04854 author:Michal Yarom, Michal Irani category:cs.CV  published:2016-12-14 summary:The ability to detect similar actions across videos can be very useful for real-world applications in many fields. However, this task is still challenging for existing systems, since videos that present the same action, can be taken from significantly different viewing directions, performed by different actors and backgrounds and under various video qualities. Video descriptors play a significant role in these systems. In this work we propose the "temporal-needle" descriptor which captures the dynamic behavior, while being invariant to viewpoint and appearance. The descriptor is computed using multi temporal scales of the video and by computing self-similarity for every patch through time in every temporal scale. The descriptor is computed for every pixel in the video. However, to find similar actions across videos, we consider only a small subset of the descriptors - the statistical significant descriptors. This allow us to find good correspondences across videos more efficiently. Using the descriptor, we were able to detect the same behavior across videos in a variety of scenarios. We demonstrate the use of the descriptor in tasks such as temporal and spatial alignment, action detection and even show its potential in unsupervised video clustering into categories. In this work we handled only videos taken with stationary cameras, but the descriptor can be extended to handle moving camera as well. version:1
arxiv-1612-04853 | Constraint Selection in Metric Learning | http://arxiv.org/abs/1612.04853 | id:1612.04853 author:Hoel Le Capitaine category:cs.LG stat.ML  published:2016-12-14 summary:A number of machine learning algorithms are using a metric, or a distance, in order to compare individuals. The Euclidean distance is usually employed, but it may be more efficient to learn a parametric distance such as Mahalanobis metric. Learning such a metric is a hot topic since more than ten years now, and a number of methods have been proposed to efficiently learn it. However, the nature of the problem makes it quite difficult for large scale data, as well as data for which classes overlap. This paper presents a simple way of improving accuracy and scalability of any iterative metric learning algorithm, where constraints are obtained prior to the algorithm. The proposed approach relies on a loss-dependent weighted selection of constraints that are used for learning the metric. Using the corresponding dedicated loss function, the method clearly allows to obtain better results than state-of-the-art methods, both in terms of accuracy and time complexity. Some experimental results on real world, and potentially large, datasets are demonstrating the effectiveness of our proposition. version:1
arxiv-1612-04844 | The More You Know: Using Knowledge Graphs for Image Classification | http://arxiv.org/abs/1612.04844 | id:1612.04844 author:Kenneth Marino, Ruslan Salakhutdinov, Abhinav Gupta category:cs.CV  published:2016-12-14 summary:Humans have the remarkable capability to learn a large variety of visual concepts, often with very few examples, whereas current state-of-the-art vision algorithms require hundreds or thousands of examples per category and struggle with ambiguity. One characteristic that sets humans apart is our ability to acquire knowledge about the world and reason using this knowledge. This paper investigates the use of structured prior knowledge in the form of knowledge graphs and shows that using this knowledge improves performance on image classification. Specifically, we introduce the Graph Search Neural Network as a way of efficiently incorporating large knowledge graphs into a fully end-to-end learning system. We show in a number of experiments that our method outperforms baselines for multi-label classification, even under low data and few-shot settings. version:1
arxiv-1612-04831 | Uncovering the Dynamics of Crowdlearning and the Value of Knowledge | http://arxiv.org/abs/1612.04831 | id:1612.04831 author:Utkarsh Upadhyay, Isabel Valera, Manuel Gomez-Rodriguez category:cs.SI cs.LG physics.soc-ph stat.ML H.2.8  published:2016-12-14 summary:Learning from the crowd has become increasingly popular in the Web and social media. There is a wide variety of crowdlearning sites in which, on the one hand, users learn from the knowledge that other users contribute to the site, and, on the other hand, knowledge is reviewed and curated by the same users using assessment measures such as upvotes or likes. In this paper, we present a probabilistic modeling framework of crowdlearning, which uncovers the evolution of a user's expertise over time by leveraging other users' assessments of her contributions. The model allows for both off-site and on-site learning and captures forgetting of knowledge. We then develop a scalable estimation method to fit the model parameters from millions of recorded learning and contributing events. We show the effectiveness of our model by tracing activity of ~25 thousand users in Stack Overflow over a 4.5 year period. We find that answers with high knowledge value are rare. Newbies and experts tend to acquire less knowledge than users in the middle range. Prolific learners tend to be also proficient contributors that post answers with high knowledge value. version:1
arxiv-1612-04811 | Fast-AT: Fast Automatic Thumbnail Generation using Deep Neural Networks | http://arxiv.org/abs/1612.04811 | id:1612.04811 author:Seyed A. Esmaeili, Bharat Singh, Larry S. Davis category:cs.CV  published:2016-12-14 summary:Fast-AT is an automatic thumbnail generation system based on deep neural networks. It is a fully-convolutional CNN, which learns specific filters for thumbnails of different sizes and aspect ratios. During inference, the appropriate filter is selected depending on the dimensions of the target thumbnail. Unlike most previous work, Fast-AT does not utilize saliency but addresses the problem directly. In addition, it eliminates the need to conduct region search on the saliency map. The model generalizes to thumbnails of different sizes including those with extreme aspect ratios and can generate thumbnails in real time. A data set of more than 70,000 thumbnail annotations was collected to train Fast-AT. We show competitive results in comparison to existing techniques. version:1
arxiv-1612-04809 | Spectral video construction from RGB video: Application to Image Guided Neurosurgery | http://arxiv.org/abs/1612.04809 | id:1612.04809 author:Md. Abul Hasnat, Jussi Parkkinen, Markku Hauta-Kasari category:cs.CV  published:2016-12-14 summary:Spectral imaging has received enormous interest in the field of medical imaging modalities. It provides a powerful tool for the analysis of different organs and non-invasive tissues. Therefore, significant amount of research has been conducted to explore the possibility of using spectral imaging in biomedical applications. To observe spectral image information in real time during surgery and monitor the temporal changes in the organs and tissues is a demanding task. Available spectral imaging devices are not sufficient to accomplish this task with an acceptable spatial and spectral resolution. A solution to this problem is to estimate the spectral video from RGB video and perform visualization with the most prominent spectral bands. In this research, we propose a framework to generate neurosurgery spectral video from RGB video. A spectral estimation technique is applied on each RGB video frames. The RGB video is captured using a digital camera connected with an operational microscope dedicated to neurosurgery. A database of neurosurgery spectral images is used to collect training data and evaluate the estimation accuracy. A searching technique is used to identify the best training set. Five different spectrum estimation techniques are experimented to indentify the best method. Although this framework is established for neurosurgery spectral video generation, however, the methodology outlined here would also be applicable to other similar research. version:1
arxiv-1612-04804 | Anomaly Detection Using the Knowledge-based Temporal Abstraction Method | http://arxiv.org/abs/1612.04804 | id:1612.04804 author:Asaf Shabtai category:cs.LG cs.AI  published:2016-12-14 summary:The rapid growth in stored time-oriented data necessitates the development of new methods for handling, processing, and interpreting large amounts of temporal data. One important example of such processing is detecting anomalies in time-oriented data. The Knowledge-Based Temporal Abstraction method was previously proposed for intelligent interpretation of temporal data based on predefined domain knowledge. In this study we propose a framework that integrates the KBTA method with a temporal pattern mining process for anomaly detection. According to the proposed method a temporal pattern mining process is applied on a dataset of basic temporal abstraction database in order to extract patterns representing normal behavior. These patterns are then analyzed in order to identify abnormal time periods characterized by a significantly small number of normal patterns. The proposed approach was demonstrated using a dataset collected from a real server. version:1
arxiv-1612-04799 | Deep Function Machines: Generalized Neural Networks for Topological Layer Expression | http://arxiv.org/abs/1612.04799 | id:1612.04799 author:William H. Guss category:stat.ML cs.CV cs.LG  published:2016-12-14 summary:In this paper we propose a generalization of deep neural networks called deep function machines (DFMs). DFMs act on vector spaces of arbitrary (possibly infinite) dimension and we show that a family of DFMs are invariant to the dimension of input data; that is, the parameterization of the model does not directly hinge on the quality of the input (eg. high resolution images). Using this generalization we provide a new theory of universal approximation of bounded non-linear operators between function spaces locally compact Hausdorff spaces. We then suggest that DFMs provide an expressive framework for designing new neural network layer types with topological considerations in mind. Finally, we provide several examples of DFMs and in particular give a practical algorithm for neural networks approximating infinite dimensional operators. version:1
arxiv-1612-04787 | Registering large volume serial-section electron microscopy image sets for neural circuit reconstruction using FFT signal whitening | http://arxiv.org/abs/1612.04787 | id:1612.04787 author:Arthur W. Wetzel, Jennifer Bakal, Markus Dittrich, David G. C. Hildebrand, Josh L. Morgan, Jeff W. Lichtman category:cs.CV  published:2016-12-14 summary:The detailed reconstruction of neural anatomy for connectomics studies requires a combination of resolution and large three-dimensional data capture provided by serial section electron microscopy (ssEM). The convergence of high throughput ssEM imaging and improved tissue preparation methods now allows ssEM capture of complete specimen volumes up to cubic millimeter scale. The resulting multi-terabyte image sets span thousands of serial sections and must be precisely registered into coherent volumetric forms in which neural circuits can be traced and segmented. This paper introduces a Signal Whitening Fourier Transform Image Registration approach (SWiFT-IR) under development at the Pittsburgh Supercomputing Center and its use to align mouse and zebrafish brain datasets acquired using the wafer mapper ssEM imaging technology recently developed at Harvard University. Unlike other methods now used for ssEM registration, SWiFT-IR modifies its spatial frequency response during image matching to maximize a signal-to-noise measure used as its primary indicator of alignment quality. This alignment signal is more robust to rapid variations in biological content and unavoidable data distortions than either phase-only or standard Pearson correlation, thus allowing more precise alignment and statistical confidence. These improvements in turn enable an iterative registration procedure based on projections through multiple sections rather than more typical adjacent-pair matching methods. This projection approach, when coupled with known anatomical constraints and iteratively applied in a multi-resolution pyramid fashion, drives the alignment into a smooth form that properly represents complex and widely varying anatomical content such as the full cross-section zebrafish data. version:1
arxiv-1612-04785 | Quantum Monte Carlo simulation of a particular class of non-stoquastic Hamiltonians in quantum annealing | http://arxiv.org/abs/1612.04785 | id:1612.04785 author:Masayuki Ohzeki category:quant-ph cond-mat.dis-nn cond-mat.stat-mech stat.ML  published:2016-12-14 summary:Quantum annealing is a generic solver of the optimization problem that uses fictitious quantum fluctuation. Its simulation in classical computing is often performed using the quantum Monte Carlo simulation via the Suzuki--Trotter decomposition. However, the negative sign problem sometimes emerges in the simulation of quantum annealing with an elaborate driver Hamiltonian, since it belongs to a class of non-stoquastic Hamiltonians. In the present study, we propose an alternative way to avoid the negative sign problem involved in a particular class of the non-stoquastic Hamiltonians. To check the validity of the method, we demonstrate our method by applying it to a simple problem that includes the anti-ferromagnetic XX interaction, which is a typical instance of the non-stoquastic Hamiltonians. version:1
arxiv-1612-04774 | Beam Search for Learning a Deep Convolutional Neural Network of 3D Shapes | http://arxiv.org/abs/1612.04774 | id:1612.04774 author:Xu Xu, Sinisa Todorovic category:cs.CV cs.CG  published:2016-12-14 summary:This paper addresses 3D shape recognition. Recent work typically represents a 3D shape as a set of binary variables corresponding to 3D voxels of a uniform 3D grid centered on the shape, and resorts to deep convolutional neural networks(CNNs) for modeling these binary variables. Robust learning of such CNNs is currently limited by the small datasets of 3D shapes available, an order of magnitude smaller than other common datasets in computer vision. Related work typically deals with the small training datasets using a number of ad hoc, hand-tuning strategies. To address this issue, we formulate CNN learning as a beam search aimed at identifying an optimal CNN architecture, namely, the number of layers, nodes, and their connectivity in the network, as well as estimating parameters of such an optimal CNN. Each state of the beam search corresponds to a candidate CNN. Two types of actions are defined to add new convolutional filters or new convolutional layers to a parent CNN, and thus transition to children states. The utility function of each action is efficiently computed by transferring parameter values of the parent CNN to its children, thereby enabling an efficient beam search. Our experimental evaluation on the 3D ModelNet dataset demonstrates that our model pursuit using the beam search yields a CNN with superior performance on 3D shape classification than the state of the art. version:1
arxiv-1612-04770 | Detect, Replace, Refine: Deep Structured Prediction For Pixel Wise Labeling | http://arxiv.org/abs/1612.04770 | id:1612.04770 author:Spyros Gidaris, Nikos Komodakis category:cs.CV cs.LG  published:2016-12-14 summary:Pixel wise image labeling is an interesting and challenging problem with great significance in the computer vision community. In order for a dense labeling algorithm to be able to achieve accurate and precise results, it has to consider the dependencies that exist in the joint space of both the input and the output variables. An implicit approach for modeling those dependencies is by training a deep neural network that, given as input an initial estimate of the output labels and the input image, it will be able to predict a new refined estimate for the labels. In this context, our work is concerned with what is the optimal architecture for performing the label improvement task. We argue that the prior approaches of either directly predicting new label estimates or predicting residual corrections w.r.t. the initial labels with feed-forward deep network architectures are sub-optimal. Instead, we propose a generic architecture that decomposes the label improvement task to three steps: 1) detecting the initial label estimates that are incorrect, 2) replacing the incorrect labels with new ones, and finally 3) refining the renewed labels by predicting residual corrections w.r.t. them. Furthermore, we explore and compare various other alternative architectures that consist of the aforementioned Detection, Replace, and Refine components. We extensively evaluate the examined architectures in the challenging task of dense disparity estimation (stereo matching) and we report both quantitative and qualitative results on three different datasets. Finally, our dense disparity estimation network that implements the proposed generic architecture, achieves state-of-the-art results in the KITTI 2015 test surpassing prior approaches by a significant margin. version:1
arxiv-1612-04765 | CoPaSul Manual - Contour-based parametric and superpositional intonation stylization | http://arxiv.org/abs/1612.04765 | id:1612.04765 author:Uwe D. Reichel category:cs.CL  published:2016-12-14 summary:The purposes of the CoPaSul toolkit are (1) automatic prosodic annotation and (2) prosodic feature extraction from syllable to utterance level. CoPaSul stands for contour-based, parametric, superpositional intonation stylization. In this framework intonation is represented as a superposition of global and local contours that are described parametrically in terms of polynomial coefficients. On the global level (usually associated but not necessarily restricted to intonation phrases) the stylization serves to represent register in terms of time-varying F0 level and range. On the local level (e.g. accent groups), local contour shapes are described. From this parameterization several features related to prosodic boundaries and prominence can be derived. Furthermore, by coefficient clustering prosodic contour classes can be derived in a bottom-up way. Next to the stylization-based feature extraction also standard F0 and energy measures (e.g. mean and variance) as well as rhythmic aspects can be calculated. At the current state automatic annotation comprises: segmentation into interpausal chunks, syllable nucleus extraction, and unsupervised localization of prosodic phrase boundaries and prominent syllables. F0 and partly also energy feature sets can be derived for: standard measurements (as median and IQR), register in terms of F0 level and range, prosodic boundaries, local contour shapes, bottom-up derived contour classes, Gestalt of accent groups in terms of their deviation from higher level prosodic units, as well as for rhythmic aspects quantifying the relation between F0 and energy contours and prosodic event rates. version:1
arxiv-1612-04759 | Encapsulating models and approximate inference programs in probabilistic modules | http://arxiv.org/abs/1612.04759 | id:1612.04759 author:Marco F. Cusumano-Towner, Vikash K. Mansinghka category:cs.AI cs.LG stat.ML  published:2016-12-14 summary:This paper introduces the probabilistic module interface, which allows encapsulation of complex probabilistic models with latent variables alongside custom stochastic approximate inference machinery, and provides a platform-agnostic abstraction barrier separating the model internals from the host probabilistic inference system. The interface can be seen as a stochastic generalization of a standard simulation and density interface for probabilistic primitives. We show that sound approximate inference algorithms can be constructed for networks of probabilistic modules, and we demonstrate that the interface can be implemented using learned stochastic inference networks and MCMC and SMC approximate inference programs. version:1
arxiv-1612-04757 | Attentive Explanations: Justifying Decisions and Pointing to the Evidence | http://arxiv.org/abs/1612.04757 | id:1612.04757 author:Dong Huk Park, Lisa Anne Hendricks, Zeynep Akata, Bernt Schiele, Trevor Darrell, Marcus Rohrbach category:cs.CV cs.AI cs.CL  published:2016-12-14 summary:Deep models are the defacto standard in visual decision models due to their impressive performance on a wide array of visual tasks. However, they are frequently seen as opaque and are unable to explain their decisions. In contrast, humans can justify their decisions with natural language and point to the evidence in the visual world which led to their decisions. We postulate that deep models can do this as well and propose our Pointing and Justification (PJ-X) model which can justify its decision with a sentence and point to the evidence by introspecting its decision and explanation process using an attention mechanism. Unfortunately there is no dataset available with reference explanations for visual decision making. We thus collect two datasets in two domains where it is interesting and challenging to explain decisions. First, we extend the visual question answering task to not only provide an answer but also a natural language explanation for the answer. Second, we focus on explaining human activities which is traditionally more challenging than object classification. We extensively evaluate our PJ-X model, both on the justification and pointing tasks, by comparing it to prior models and ablations using both automatic and human evaluations. version:1
arxiv-1612-04755 | Super-resolution Reconstruction of SAR Image based on Non-Local Means Denoising Combined with BP Neural Network | http://arxiv.org/abs/1612.04755 | id:1612.04755 author:Zeling Wu, Haoxiang Wang category:cs.CV  published:2016-12-14 summary:In this article, we propose a super-resolution method to resolve the problem of image low spatial because of the limitation of imaging devices. We make use of the strong non-linearity mapped ability of the back-propagation neural networks(BPNN). Training sample images are got by undersampled method. The elements chose as the inputs of the BPNN are pixels referred to Non-local means(NL-Means). Making use of the self-similarity of the images, those inputs are the pixels which are pixels gained from modified NL-means which is specific for super-resolution. Besides, small change on core function of NL-means has been applied in the method we use in this article so that we can have a clearer edge in the shrunk image. Experimental results gained from the Peak Signal to Noise Ratio(PSNR) and the Equivalent Number of Look(ENL), indicate that adding the similar pixels as inputs will increase the results than not taking them into consideration. version:1
arxiv-1612-04744 | Incorporating Language Level Information into Acoustic Models | http://arxiv.org/abs/1612.04744 | id:1612.04744 author:Peidong Wang, Deliang Wang category:cs.CL cs.LG cs.SD  published:2016-12-14 summary:This paper proposed a class of novel Deep Recurrent Neural Networks which can incorporate language-level information into acoustic models. For simplicity, we named these networks Recurrent Deep Language Networks (RDLNs). Multiple variants of RDLNs were considered, including two kinds of context information, two methods to process the context, and two methods to incorporate the language-level information. RDLNs provided possible methods to fine-tune the whole Automatic Speech Recognition (ASR) system in the acoustic modeling process. version:1
arxiv-1612-04733 | Efficient phase retrieval based on dark fringe recognition with an ability of bypassing invalid fringes | http://arxiv.org/abs/1612.04733 | id:1612.04733 author:Wen-Kai Yu, An-Dong Xiong, Xu-Ri Yao, Guang-Jie Zhai, Qing Zhao category:cs.CV physics.optics  published:2016-12-14 summary:This paper discusses the noisy phase retrieval problem: recovering a complex image signal with independent noise from quadratic measurements. Inspired by the dark fringes shown in the measured images of the array detector, a novel phase retrieval approach is proposed and demonstrated both theoretically and experimentally to recognize the dark fringes and bypass the invalid fringes. A more accurate relative phase ratio between arbitrary two pixels is achieved by calculating the multiplicative ratios (or the sum of phase difference) on the path between them. Then the object phase image can be reconstructed precisely. Our approach is a good choice for retrieving high-quality phase images from noisy signals and has many potential applications in the fields such as X-ray crystallography, diffractive imaging, and so on. version:1
arxiv-1612-04732 | Multilingual Word Embeddings using Multigraphs | http://arxiv.org/abs/1612.04732 | id:1612.04732 author:Radu Soricut, Nan Ding category:cs.CL  published:2016-12-14 summary:We present a family of neural-network--inspired models for computing continuous word representations, specifically designed to exploit both monolingual and multilingual text. This framework allows us to perform unsupervised training of embeddings that exhibit higher accuracy on syntactic and semantic compositionality, as well as multilingual semantic similarity, compared to previous models trained in an unsupervised fashion. We also show that such multilingual embeddings, optimized for semantic similarity, can improve the performance of statistical machine translation with respect to how it handles words not present in the parallel data. version:1
arxiv-1612-06287 | VAST : The Virtual Acoustic Space Traveler Dataset | http://arxiv.org/abs/1612.06287 | id:1612.06287 author:Clément Gaultier, Saurabh Kataria, Antoine Deleforge category:cs.SD cs.LG  published:2016-12-14 summary:This paper introduces a new paradigm for sound source lo-calization referred to as virtual acoustic space traveling (VAST) and presents a first dataset designed for this purpose. Existing sound source localization methods are either based on an approximate physical model (physics-driven) or on a specific-purpose calibration set (data-driven). With VAST, the idea is to learn a mapping from audio features to desired audio properties using a massive dataset of simulated room impulse responses. This virtual dataset is designed to be maximally representative of the potential audio scenes that the considered system may be evolving in, while remaining reasonably compact. We show that virtually-learned mappings on this dataset generalize to real data, overcoming some intrinsic limitations of traditional binaural sound localization methods based on time differences of arrival. version:1
arxiv-1612-04683 | Unsupervised Clustering of Commercial Domains for Adaptive Machine Translation | http://arxiv.org/abs/1612.04683 | id:1612.04683 author:Mauro Cettolo, Mara Chinea Rios, Roldano Cattoni category:cs.CL  published:2016-12-14 summary:In this paper, we report on domain clustering in the ambit of an adaptive MT architecture. A standard bottom-up hierarchical clustering algorithm has been instantiated with five different distances, which have been compared, on an MT benchmark built on 40 commercial domains, in terms of dendrograms, intrinsic and extrinsic evaluations. The main outcome is that the most expensive distance is also the only one able to allow the MT engine to guarantee good performance even with few, but highly populated clusters of domains. version:1
arxiv-1612-04679 | IEDC: An Integrated Approach for Overlapping and Non-overlapping Community Detection | http://arxiv.org/abs/1612.04679 | id:1612.04679 author:Mahdi Hajiabadi, Hadi Zare, Hossein Bobarshad category:cs.SI stat.ML  published:2016-12-14 summary:Community detection is a task of fundamental importance in social network analysis. Community structures enable us to discover the hidden interactions among the network members that can be used in many knowledge-based domains such as bioinformatics, computer networks, e-commerce and forensic science. While there exist many works on community detection based on connectivity structure, they suffer from either considering the overlapping or non-overlapping community structures. In this work, we propose a novel approach for general community detection through an integrated framework to extract the overlapping and non-overlapping community structures without assuming prior structural connectivity on the networks. Our general framework is based on a primary node based criterion which consists up the internal association degree along with the external association degree to compute the criterion in the proposed approach. The evaluation of the proposed method is investigated through the extensive simulation experiments and several benchmark real network data-sets. The experimental results show that the proposed method outperforms the earlier state-of-the-art algorithms based on the well-known evaluation criteria. version:1
arxiv-1612-04675 | Recurrent Deep Stacking Networks for Speech Recognition | http://arxiv.org/abs/1612.04675 | id:1612.04675 author:Peidong Wang, Zhongqiu Wang, Deliang Wang category:cs.CL cs.SD  published:2016-12-14 summary:This paper presented our work on applying Recurrent Deep Stacking Networks (RDSNs) to Robust Automatic Speech Recognition (ASR) tasks. In the paper, we also proposed a more efficient yet comparable substitute to RDSN, Bi- Pass Stacking Network (BPSN). The main idea of these two models is to add phoneme-level information into acoustic models, transforming an acoustic model to the combination of an acoustic model and a phoneme-level N-gram model. Experiments showed that RDSN and BPsn can substantially improve the performances over conventional DNNs. version:1
arxiv-1612-04659 | Stable Memory Allocation in the Hippocampus: Fundamental Limits and Neural Realization | http://arxiv.org/abs/1612.04659 | id:1612.04659 author:Wenlong Mou, Zhi Wang, Liwei Wang category:cs.NE cs.DS cs.LG  published:2016-12-14 summary:It is believed that hippocampus functions as a memory allocator in brain, the mechanism of which remains unrevealed. In Valiant's neuroidal model, the hippocampus was described as a randomly connected graph, the computation on which maps input to a set of activated neuroids with stable size. Valiant proposed three requirements for the hippocampal circuit to become a stable memory allocator (SMA): stability, continuity and orthogonality. The functionality of SMA in hippocampus is essential in further computation within cortex, according to Valiant's model. In this paper, we put these requirements for memorization functions into rigorous mathematical formulation and introduce the concept of capacity, based on the probability of erroneous allocation. We prove fundamental limits for the capacity and error probability of SMA, in both data-independent and data-dependent settings. We also establish an example of stable memory allocator that can be implemented via neuroidal circuits. Both theoretical bounds and simulation results show that the neural SMA functions well. version:1
arxiv-1612-04647 | UnrealStereo: A Synthetic Dataset for Analyzing Stereo Vision | http://arxiv.org/abs/1612.04647 | id:1612.04647 author:Yi Zhang, Weichao Qiu, Qi Chen, Xiaolin Hu, Alan Yuille category:cs.CV  published:2016-12-14 summary:Stereo algorithm is important for robotics applications, such as quadcopter and autonomous driving. It needs to be robust enough to handle images of challenging conditions, such as raining or strong lighting. Textureless and specular regions of these images make feature matching difficult and smoothness assumption invalid. It is important to understand whether an algorithm is robust to these hazardous regions. Many stereo benchmarks have been developed to evaluate the performance and track progress. But it is not easy to quantize the effect of these hazardous regions. In this paper, we develop a synthetic image generation tool and build a benchmark with synthetic images. First, we manually tweak hazardous factors in a virtual world, such as making objects more specular or transparent, to simulate corner cases to test the robustness of stereo algorithms. Second, we use ground truth information, such as object mask, material property, to automatically identify hazardous regions and evaluate the accuracy of these regions. Our tool is based on a popular game engine Unreal Engine 4 and will be open-source. Many publicly available realistic game contents can be used by our tool which can provide an enormous resource for algorithm development and evaluation. version:1
arxiv-1612-04642 | Harmonic Networks: Deep Translation and Rotation Equivariance | http://arxiv.org/abs/1612.04642 | id:1612.04642 author:Daniel E. Worrall, Stephan J. Garbin, Daniyar Turmukhambetov, Gabriel J. Brostow category:cs.CV cs.LG stat.ML  published:2016-12-14 summary:Translating or rotating an input image should not affect the results of many computer vision tasks. Convolutional neural networks (CNNs) are already translation equivariant: input image translations produce proportionate feature map translations. This is not the case for rotations. Global rotation equivariance is typically sought through data augmentation, but patch-wise equivariance is more difficult. We present Harmonic Networks or H-Nets, a CNN exhibiting equivariance to patch-wise translation and 360-rotation. We achieve this by replacing regular CNN filters with circular harmonics, returning a maximal response and orientation for every receptive field patch. H-Nets use a rich, parameter-efficient and low computational complexity representation, and we show that deep feature maps within the network encode complicated rotational invariants. We demonstrate that our layers are general enough to be used in conjunction with the latest architectures and techniques, such as deep supervision and batch normalization. We also achieve state-of-the-art classification on rotated-MNIST, and competitive results on other benchmark challenges. version:1
arxiv-1612-04631 | Defining the Pose of any 3D Rigid Object and an Associated Metric | http://arxiv.org/abs/1612.04631 | id:1612.04631 author:Romain Brégier, Frédéric Devernay, Laetitia Leyrit, James Crowley category:cs.CV math.MG physics.class-ph  published:2016-12-14 summary:A pose of a rigid object is usually regarded as a rigid transformation, described by a translation and a rotation. In this article, we define a pose as a distinguishable static state of the considered object, and show that the usual identification of the pose space with the space of rigid transformations is abusive, as it is not adapted to objects with proper symmetries. Based solely on geometric considerations, we propose a frame-invariant metric on the pose space, valid for any physical object, and requiring no arbitrary tuning. This distance can be evaluated efficiently thanks to a representation of poses within a low dimension Euclidean space, and enables to perform efficient neighborhood queries such as radius searches or k-nearest neighbor searches within a large set of poses using off-the-shelf methods. We lastly solve the problems of projection from the Euclidean space onto the pose space, and of pose averaging for this metric. The practical value of those theoretical developments is illustrated with an application of pose estimation of instances of a 3D rigid object given an input depth map, via a Mean Shift procedure . version:1
arxiv-1612-04629 | How Grammatical is Character-level Neural Machine Translation? Assessing MT Quality with Contrastive Translation Pairs | http://arxiv.org/abs/1612.04629 | id:1612.04629 author:Rico Sennrich category:cs.CL  published:2016-12-14 summary:Analysing translation quality in regards to specific linguistic phenomena has historically been difficult and time-consuming. Neural machine translation has the attractive property that it can produce scores for arbitrary translations, and we propose a novel method to assess how well NMT systems model specific linguistic phenomena such as agreement over long distances, the production of novel words, and the faithful translation of polarity. The core idea is that we measure whether a reference translation is more probable under a NMT model than a contrastive translation which introduces a specific type of error. We present LingEval90, a large-scale data set of 90000 contrastive translation pairs based on the WMT English->German translation task, with errors automatically created with simple rules. We report a number of baseline results, and find that recently introduced character-level NMT systems perform better at transliteration than models with BPE segmentation, but perform more poorly at morphosyntactic agreement, and translating discontiguous units of meaning. version:1
arxiv-1612-04609 | Neural Emoji Recommendation in Dialogue Systems | http://arxiv.org/abs/1612.04609 | id:1612.04609 author:Ruobing Xie, Zhiyuan Liu, Rui Yan, Maosong Sun category:cs.CL  published:2016-12-14 summary:Emoji is an essential component in dialogues which has been broadly utilized on almost all social platforms. It could express more delicate feelings beyond plain texts and thus smooth the communications between users, making dialogue systems more anthropomorphic and vivid. In this paper, we focus on automatically recommending appropriate emojis given the contextual information in multi-turn dialogue systems, where the challenges locate in understanding the whole conversations. More specifically, we propose the hierarchical long short-term memory model (H-LSTM) to construct dialogue representations, followed by a softmax classifier for emoji classification. We evaluate our models on the task of emoji classification in a real-world dataset, with some further explorations on parameter sensitivity and case study. Experimental results demonstrate that our method achieves the best performances on all evaluation metrics. It indicates that our method could well capture the contextual information and emotion flow in dialogues, which is significant for emoji recommendation. version:1
arxiv-1612-04600 | Predicting Process Behaviour using Deep Learning | http://arxiv.org/abs/1612.04600 | id:1612.04600 author:Joerg Evermann, Jana-Rebecca Rehse, Peter Fettke category:cs.LG stat.ML  published:2016-12-14 summary:Predicting business process behaviour, such as the final state of a running process, the remaining time to completion or the next activity of a running process, is an important aspect of business process management. Motivated by research in natural language processing, this paper describes an application of deep learning with recurrent neural networks to the problem of predicting the next event in a business process. This is both a novel method in process prediction, which has largely relied on explicit process models, and also a novel application of deep learning methods. The approach is evaluated on two real datasets and our results surpass the state-of-the-art in prediction precision. The paper offers recommendations for researchers and practitioners and points out areas for future applications of deep learning in business process management. version:1
arxiv-1612-04599 | Retrieving sinusoids from nonuniformly sampled data using recursive formulation | http://arxiv.org/abs/1612.04599 | id:1612.04599 author:Ivan Maric category:cs.IT cs.LG math.IT  published:2016-12-14 summary:A heuristic procedure based on novel recursive formulation of sinusoid (RFS) and on regression with predictive least-squares (LS) enables to decompose both uniformly and nonuniformly sampled 1-d signals into a sparse set of sinusoids (SSS). An optimal SSS is found by Levenberg-Marquardt (LM) optimization of RFS parameters of near-optimal sinusoids combined with common criteria for the estimation of the number of sinusoids embedded in noise. The procedure estimates both the cardinality and the parameters of SSS. The proposed algorithm enables to identify the RFS parameters of a sinusoid from a data sequence containing only a fraction of its cycle. In extreme cases when the frequency of a sinusoid approaches zero the algorithm is able to detect a linear trend in data. Also, an irregular sampling pattern enables the algorithm to correctly reconstruct the under-sampled sinusoid. Parsimonious nature of the obtaining models opens the possibilities of using the proposed method in machine learning and in expert and intelligent systems needing analysis and simple representation of 1-d signals. The properties of the proposed algorithm are evaluated on examples of irregularly sampled artificial signals in noise and are compared with high accuracy frequency estimation algorithms based on linear prediction (LP) approach, particularly with respect to Cramer-Rao Bound (CRB). version:1
arxiv-1612-04573 | The Mehler-Fock Transform and some Applications in Texture Analysis and Color Processing | http://arxiv.org/abs/1612.04573 | id:1612.04573 author:Reiner Lenz category:cs.CV 43A32 I.5.4  published:2016-12-14 summary:Many stochastic processes are defined on special geometrical objects like spheres and cones. We describe how tools from harmonic analysis, i.e. Fourier analysis on groups, can be used to investigate probability density functions (pdfs) on groups and homogeneous spaces. We consider the special case of the Lorentz group SU(1,1) and the unit disk with its hyperbolic geometry, but the procedure can be generalized to a much wider class of Lie-groups. We mainly concentrate on the Mehler-Fock transform which is the radial part of the Fourier transform on the disk. Some of the characteristic features of this transform are the relation to group-convolutions, the isometry between signal and transform space, the relation to the Laplace-Beltrami operator and the relation to group representation theory. We will give an overview over these properties and their applications in signal processing. We will illustrate the theory with two examples from low-level vision and color image processing. version:1
arxiv-1612-04555 | Scalable Group Level Probabilistic Sparse Factor Analysis | http://arxiv.org/abs/1612.04555 | id:1612.04555 author:Jesper L. Hinrich, Søren F. V. Nielsen, Nicolai A. B. Riis, Casper T. Eriksen, Jacob Frøsig, Marco D. F. Kristensen, Mikkel N. Schmidt, Kristoffer H. Madsen, Morten Mørup category:stat.AP stat.ML  published:2016-12-14 summary:Many data-driven approaches exist to extract neural representations of functional magnetic resonance imaging (fMRI) data, but most of them lack a proper probabilistic formulation. We propose a group level scalable probabilistic sparse factor analysis (psFA) allowing spatially sparse maps, component pruning using automatic relevance determination (ARD) and subject specific heteroscedastic spatial noise modeling. For task-based and resting state fMRI, we show that the sparsity constraint gives rise to components similar to those obtained by group independent component analysis. The noise modeling shows that noise is reduced in areas typically associated with activation by the experimental design. The psFA model identifies sparse components and the probabilistic setting provides a natural way to handle parameter uncertainties. The variational Bayesian framework easily extends to more complex noise models than the presently considered. version:1
arxiv-1612-04538 | Grammatical Constraints on Intra-sentential Code-Switching: From Theories to Working Models | http://arxiv.org/abs/1612.04538 | id:1612.04538 author:Gayatri Bhat, Monojit Choudhury, Kalika Bali category:cs.CL  published:2016-12-14 summary:We make one of the first attempts to build working models for intra-sentential code-switching based on the Equivalence-Constraint (Poplack 1980) and Matrix-Language (Myers-Scotton 1993) theories. We conduct a detailed theoretical analysis, and a small-scale empirical study of the two models for Hindi-English CS. Our analyses show that the models are neither sound nor complete. Taking insights from the errors made by the models, we propose a new model that combines features of both the theories. version:1
arxiv-1612-04530 | Permutation-equivariant neural networks applied to dynamics prediction | http://arxiv.org/abs/1612.04530 | id:1612.04530 author:Nicholas Guttenberg, Nathaniel Virgo, Olaf Witkowski, Hidetoshi Aoki, Ryota Kanai category:cs.CV stat.ML  published:2016-12-14 summary:The introduction of convolutional layers greatly advanced the performance of neural networks on image tasks due to innately capturing a way of encoding and learning translation-invariant operations, matching one of the underlying symmetries of the image domain. In comparison, there are a number of problems in which there are a number of different inputs which are all 'of the same type' --- multiple particles, multiple agents, multiple stock prices, etc. The corresponding symmetry to this is permutation symmetry, in that the algorithm should not depend on the specific ordering of the input data. We discuss a permutation-invariant neural network layer in analogy to convolutional layers, and show the ability of this architecture to learn to predict the motion of a variable number of interacting hard discs in 2D. In the same way that convolutional layers can generalize to different image sizes, the permutation layer we describe generalizes to different numbers of objects. version:1
arxiv-1612-04526 | Astronomical image reconstruction with convolutional neural networks | http://arxiv.org/abs/1612.04526 | id:1612.04526 author:Rémi Flamary category:cs.CV astro-ph.IM stat.ML  published:2016-12-14 summary:State of the art methods in astronomical image reconstruction rely on the resolution of a regularized or constrained optimization problem. Solving this problem can be computationally intensive and usually leads to a quadratic or at least superlinear complexity w.r.t. the number of pixels in the image. We investigate in this work the use of convolutional neural networks for image reconstruction in astronomy. With neural networks, the computationally intensive tasks is the training step, but the prediction step has a fixed complexity per pixel, i.e. a linear complexity. Numerical experiments show that our approach is both computationally efficient and competitive with other state of the art methods in addition to being interpretable. version:1
arxiv-1612-04520 | Single Image Action Recognition using Semantic Body Part Actions | http://arxiv.org/abs/1612.04520 | id:1612.04520 author:Zhichen Zhao, Huimin Ma, Shaodi You category:cs.CV  published:2016-12-14 summary:In this paper, we propose a novel single image action recognition algorithm which is based on the idea of semantic body part actions. Unlike existing bottom up methods, we argue that the human action is a combination of meaningful body part actions. In detail, we divide human body into five parts: head, torso, arms, hands and legs. And for each of the body parts, we define several semantic body part actions, e.g., hand holding, hand waving. These semantic body part actions are strongly related to the body actions, e.g., writing, and jogging. Based on the idea, we propose a deep neural network based system: first, body parts are localized by a Semi-FCN network. Second, for each body parts, a Part Action Res-Net is used to predict semantic body part actions. And finally, we use SVM to fuse the body part actions and predict the entire body action. Experiments on two dataset: PASCAL VOC 2012 and Stanford-40 report mAP improvement from the state-of-the-art by 3.8% and 2.6% respectively. version:1
arxiv-1612-04499 | Mining Compatible/Incompatible Entities from Question and Answering via Yes/No Answer Classification using Distant Label Expansion | http://arxiv.org/abs/1612.04499 | id:1612.04499 author:Hu Xu, Lei Shu, Jingyuan Zhang, Philip S. Yu category:cs.CL  published:2016-12-14 summary:Product Community Question Answering (PCQA) provides useful information about products and their features (aspects) that may not be well addressed by product descriptions and reviews. We observe that a product's compatibility issues with other products are frequently discussed in PCQA and such issues are more frequently addressed in accessories, i.e., via a yes/no question "Does this mouse work with windows 10?". In this paper, we address the problem of extracting compatible and incompatible products from yes/no questions in PCQA. This problem can naturally have a two-stage framework: first, we perform Complementary Entity (product) Recognition (CER) on yes/no questions; second, we identify the polarities of yes/no answers to assign the complementary entities a compatibility label (compatible, incompatible or unknown). We leverage an existing unsupervised method for the first stage and a 3-class classifier by combining a distant PU-learning method (learning from positive and unlabeled examples) together with a binary classifier for the second stage. The benefit of using distant PU-learning is that it can help to expand more implicit yes/no answers without using any human annotated data. We conduct experiments on 4 products to show that the proposed method is effective. version:1
arxiv-1612-04468 | Sparse Factorization Layers for Neural Networks with Limited Supervision | http://arxiv.org/abs/1612.04468 | id:1612.04468 author:Parker Koch, Jason J. Corso category:cs.CV cs.AI stat.ML  published:2016-12-14 summary:Whereas CNNs have demonstrated immense progress in many vision problems, they suffer from a dependence on monumental amounts of labeled training data. On the other hand, dictionary learning does not scale to the size of problems that CNNs can handle, despite being very effective at low-level vision tasks such as denoising and inpainting. Recently, interest has grown in adapting dictionary learning methods for supervised tasks such as classification and inverse problems. We propose two new network layers that are based on dictionary learning: a sparse factorization layer and a convolutional sparse factorization layer, analogous to fully-connected and convolutional layers, respectively. Using our derivations, these layers can be dropped in to existing CNNs, trained together in an end-to-end fashion with back-propagation, and leverage semisupervision in ways classical CNNs cannot. We experimentally compare networks with these two new layers against a baseline CNN. Our results demonstrate that networks with either of the sparse factorization layers are able to outperform classical CNNs when supervised data are few. They also show performance improvements in certain tasks when compared to the CNN with no sparse factorization layers with the same exact number of parameters. version:1
arxiv-1612-04460 | Hypernyms under Siege: Linguistically-motivated Artillery for Hypernymy Detection | http://arxiv.org/abs/1612.04460 | id:1612.04460 author:Vered Shwartz, Enrico Santus, Dominik Schlechtweg category:cs.CL  published:2016-12-14 summary:The fundamental role of hypernymy in NLP has motivated the development of many methods for the automatic identification of this relation, most of which rely on word distribution. We investigate an extensive number of such unsupervised measures, using several distributional semantic models that differ by context type and feature weighting. We analyze the performance of the different methods based on their linguistic motivation. Comparison to the state-of-the-art supervised methods shows that while supervised methods generally outperform the unsupervised ones, the former are sensitive to the distribution of training instances, hurting their reliability. Being based on general linguistic hypotheses and independent from training data, unsupervised measures are more robust, and therefore are still useful artillery for hypernymy detection. version:1
arxiv-1612-04447 | Analysis of proposed PDE-based underwater image enhancement algorithms | http://arxiv.org/abs/1612.04447 | id:1612.04447 author:U. A. Nnolim category:cs.CV  published:2016-12-14 summary:This report describes the experimental analysis of proposed underwater image enhancement algorithms based on partial differential equations (PDEs). The algorithms perform simultaneous smoothing and enhancement due to the combination of both processes within the PDE-formulation. The framework enables the incorporation of suitable colour and contrast enhancement algorithms within one unified functional. Additional modification of the formulation includes the combination of the popular Contrast Limited Adaptive Histogram Equalization (CLAHE) with the proposed approach. This modification enables the hybrid algorithm to provide both local enhancement (due to the CLAHE) and global enhancement (due to the proposed contrast term). Additionally, the CLAHE clip limit parameter is computed dynamically in each iteration and used to gauge the amount of local enhancement performed by the CLAHE within the formulation. This enables the algorithm to reduce or prevent the enhancement of noisy artifacts, which if present, are also smoothed out by the anisotropic diffusion term within the PDE formulation. In other words, the modified algorithm combines the strength of the CLAHE, AD and the contrast term while minimizing their weaknesses. Ultimately, the system is optimized using image data metrics for automated enhancement and compromise between visual and quantitative results. Experiments indicate that the proposed algorithms perform a series of functions such as illumination correction, colour enhancement correction and restoration, contrast enhancement and noise suppression. Moreover, the proposed approaches surpass most other conventional algorithms found in the literature. version:1
arxiv-1612-04426 | Improving Neural Language Models with a Continuous Cache | http://arxiv.org/abs/1612.04426 | id:1612.04426 author:Edouard Grave, Armand Joulin, Nicolas Usunier category:cs.CL cs.LG  published:2016-12-13 summary:We propose an extension to neural network language models to adapt their prediction to the recent history. Our model is a simplified version of memory augmented networks, which stores past hidden activations as memory and accesses them through a dot product with the current hidden activation. This mechanism is very efficient and scales to very large memory sizes. We also draw a link between the use of external memory in neural network and cache models used with count based language models. We demonstrate on several language model datasets that our approach performs significantly better than recent memory augmented networks. version:1
arxiv-1612-04425 | On the Convergence of Asynchronous Parallel Iteration with Arbitrary Delays | http://arxiv.org/abs/1612.04425 | id:1612.04425 author:Zhimin Peng, Yangyang Xu, Ming Yan, Wotao Yin category:math.OC cs.DC math.NA stat.ML  published:2016-12-13 summary:Recent years have witnessed the surge of asynchronous parallel (async-parallel) iterative algorithms due to problems involving very large-scale data and a large number of decision variables. Because of asynchrony, the iterates are computed with outdated information, and the age of the outdated information, which we call delay, is the number of times it has been updated since its creation. Almost all recent works prove convergence under the assumption of a finite maximum delay and set their stepsize parameters accordingly. However, the maximum delay is practically unknown. This paper presents convergence analysis of an async-parallel method from a probabilistic viewpoint, and it allows for arbitrarily large delays. An explicit formula of stepsize that guarantees convergence is given depending on delays' statistics. With $p+1$ identical processors, we empirically measured that delays closely follow the Poisson distribution with parameter $p$, matching our theoretical model, and thus the stepsize can be set accordingly. Simulations on both convex and nonconvex optimization problems demonstrate the validness of our analysis and also show that the existing maximum-delay induced stepsize is too conservative, often slowing down the convergence of the algorithm. version:1
arxiv-1612-04423 | Modeling cognitive deficits following neurodegenerative diseases and traumatic brain injuries with deep convolutional neural networks | http://arxiv.org/abs/1612.04423 | id:1612.04423 author:Bethany Lusch, Jake Weholt, Pedro D. Maia, J. Nathan Kutz category:q-bio.NC q-bio.QM stat.ML  published:2016-12-13 summary:The accurate diagnosis and assessment of neurodegenerative disease and traumatic brain injuries (TBI) remain open challenges. Both cause cognitive and functional deficits due to focal axonal swellings (FAS), but it is difficult to deliver a prognosis due to our limited ability to assess damaged neurons at a cellular level in vivo. We simulate the effects of neurodegenerative disease and TBI using convolutional neural networks (CNNs) as our model of cognition. We utilize biophysically relevant statistical data on FAS to damage the connections in CNNs in a functionally relevant way. We incorporate energy constraints on the brain by pruning the CNNs to be less over-engineered. Qualitatively, we demonstrate that damage leads to human-like mistakes. Our experiments also provide quantitative assessments of how accuracy is affected by various types and levels of damage. The deficit resulting from a fixed amount of damage greatly depends on which connections are randomly injured, providing intuition for why it is difficult to predict impairments. There is a large degree of subjectivity when it comes to interpreting cognitive deficits from complex systems such as the human brain. However, we provide important insight and a quantitative framework for disorders in which FAS are implicated. version:1
arxiv-1612-04418 | User Model-Based Intent-Aware Metrics for Multilingual Search Evaluation | http://arxiv.org/abs/1612.04418 | id:1612.04418 author:Alexey Drutsa, Andrey Shutovich, Philipp Pushnyakov, Evgeniy Krokhalyov, Gleb Gusev, Pavel Serdyukov category:cs.IR cs.CL cs.HC cs.LG stat.ML H.1.2; H.5.2  published:2016-12-13 summary:Despite the growing importance of multilingual aspect of web search, no appropriate offline metrics to evaluate its quality are proposed so far. At the same time, personal language preferences can be regarded as intents of a query. This approach translates the multilingual search problem into a particular task of search diversification. Furthermore, the standard intent-aware approach could be adopted to build a diversified metric for multilingual search on the basis of a classical IR metric such as ERR. The intent-aware approach estimates user satisfaction under a user behavior model. We show however that the underlying user behavior models is not realistic in the multilingual case, and the produced intent-aware metric do not appropriately estimate the user satisfaction. We develop a novel approach to build intent-aware user behavior models, which overcome these limitations and convert to quality metrics that better correlate with standard online metrics of user satisfaction. version:1
arxiv-1612-04413 | Inferring object rankings based on noisy pairwise comparisons from multiple annotators | http://arxiv.org/abs/1612.04413 | id:1612.04413 author:Rahul Gupta, Shrikanth Narayanan category:stat.ML cs.LG  published:2016-12-13 summary:Ranking a set of objects involves establishing an order allowing for comparisons between any pair of objects in the set. Oftentimes, due to the unavailability of a ground truth of ranked orders, researchers resort to obtaining judgments from multiple annotators followed by inferring the ground truth based on the collective knowledge of the crowd. However, the aggregation is often ad-hoc and involves imposing stringent assumptions in inferring the ground truth (e.g. majority vote). In this work, we propose Expectation-Maximization (EM) based algorithms that rely on the judgments from multiple annotators and the object attributes for inferring the latent ground truth. The algorithm learns the relation between the latent ground truth and object attributes as well as annotator specific probabilities of flipping, a metric to assess annotator quality. We further extend the EM algorithm to allow for a variable probability of flipping based on the pair of objects at hand. We test our algorithms on two data sets with synthetic annotations and investigate the impact of annotator quality and quantity on the inferred ground truth. We also obtain the results on two other data sets with annotations from machine/human annotators and interpret the output trends based on the data characteristics. version:1
arxiv-1612-04403 | You Are What You Eat... Listen to, Watch, and Read | http://arxiv.org/abs/1612.04403 | id:1612.04403 author:Mason Bretan category:cs.SI cs.CL cs.IR  published:2016-12-13 summary:This article describes a data driven method for deriving the relationship between personality and media preferences. A qunatifiable representation of such a relationship can be leveraged for use in recommendation systems and ameliorate the "cold start" problem. Here, the data is comprised of an original collection of 1,316 Okcupid dating profiles. Of these profiles, 800 are labeled with one of 16 possible Myers-Briggs Type Indicators (MBTI). A personality specific topic model describing a person's favorite books, movies, shows, music, and food was generated using latent Dirichlet allocation (LDA). There were several significant findings, for example, intuitive thinking types preferred sci-fi/fantasy entertainment, extraversion correlated positively with upbeat dance music, and jazz, folk, and international cuisine correlated positively with those characterized by openness to experience. Many other correlations confirmed previous findings describing the relationship among personality, writing style, and personal preferences. (For complete word/personality type assocations see the Appendix). version:1
arxiv-1612-04402 | Finding Tiny Faces | http://arxiv.org/abs/1612.04402 | id:1612.04402 author:Peiyun Hu, Deva Ramanan category:cs.CV  published:2016-12-13 summary:Though tremendous strides have been made in object recognition, one of the remaining open challenges is detecting small objects. We explore three aspects of the problem in the context of finding small faces: the role of scale invariance, image resolution, and contextual reasoning. While most recognition approaches aim to be scale-invariant, the cues for recognizing a 3px tall face are fundamentally different than those for recognizing a 300px tall face. We take a different approach and train separate detectors for different scales. To maintain efficiency, detectors are trained in a multi-task fashion: they make use of features extracted from multiple layers of single (deep) feature hierarchy. While training detectors for large objects is straightforward, the crucial challenge remains training detectors for small objects. We show that context is crucial, and define templates that make use of massively-large receptive fields (where 99% of the template extends beyond the object of interest). Finally, we explore the role of scale in pre-trained deep networks, providing ways to extrapolate networks tuned for limited scales to rather extreme ranges. We demonstrate state-of-the-art results on massively-benchmarked face datasets (FDDB and WIDER FACE). In particular, when compared to prior art on WIDER FACE, our results reduce error by a factor of 2 (our models produce an AP of 81% while prior art ranges from 29-64%). version:1
arxiv-1612-04357 | Stacked Generative Adversarial Networks | http://arxiv.org/abs/1612.04357 | id:1612.04357 author:Xun Huang, Yixuan Li, Omid Poursaeed, John Hopcroft, Serge Belongie category:cs.CV cs.LG cs.NE stat.ML  published:2016-12-13 summary:In this paper we aim to leverage the powerful bottom-up discriminative representations to guide a top-down generative model. We propose a novel generative model named Stacked Generative Adversarial Networks (SGAN), which is trained to invert the hierarchical representations of a discriminative bottom-up deep network. Our model consists of a top-down stack of GANs, each trained to generate "plausible" lower-level representations, conditioned on higher-level representations. A representation discriminator is introduced at each feature hierarchy to encourage the representation manifold of the generator to align with that of the bottom-up discriminative network, providing intermediate supervision. In addition, we introduce a conditional loss that encourages the use of conditional information from the layer above, and a novel entropy loss that maximizes a variational lower bound on the conditional entropy of generator outputs. To the best of our knowledge, the entropy loss is the first attempt to tackle the conditional model collapse problem that is common in conditional GANs. We first train each GAN of the stack independently, and then we train the stack end-to-end. Unlike the original GAN that uses a single noise vector to represent all the variations, our SGAN decomposes variations into multiple levels and gradually resolves uncertainties in the top-down generative process. Experiments demonstrate that SGAN is able to generate diverse and high-quality images, as well as being more interpretable than a vanilla GAN. version:1
arxiv-1612-04342 | Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors | http://arxiv.org/abs/1612.04342 | id:1612.04342 author:Radu Soricut, Nan Ding category:cs.CL  published:2016-12-13 summary:We present a dual contribution to the task of machine reading-comprehension: a technique for creating large-sized machine-comprehension (MC) datasets using paragraph-vector models; and a novel, hybrid neural-network architecture that combines the representation power of recurrent neural networks with the discriminative power of fully-connected multi-layered networks. We use the MC-dataset generation technique to build a dataset of around 2 million examples, for which we empirically determine the high-ceiling of human performance (around 91% accuracy), as well as the performance of a variety of computer models. Among all the models we have experimented with, our hybrid neural-network architecture achieves the highest performance (83.2% accuracy). The remaining gap to the human-performance ceiling provides enough room for future model improvements. version:1
arxiv-1612-05502 | Defensive Player Classification in the National Basketball Association | http://arxiv.org/abs/1612.05502 | id:1612.05502 author:Neil Seward category:cs.LG cs.AI  published:2016-12-13 summary:The National Basketball Association(NBA) has expanded their data gathering and have heavily invested in new technologies to gather advanced performance metrics on players. This expanded data set allows analysts to use unique performance metrics in models to estimate and classify player performance. Instead of grouping players together based on physical attributes and positions played, analysts can group together players that play similar to each other based on these tracked metrics. Existing methods for player classification have typically used offensive metrics for clustering [1]. There have been attempts to classify players using past defensive metrics, but the lack of quality metrics has not produced promising results. The classifications presented in the paper use newly introduced defensive metrics to find different defensive positions for each player. Without knowing the number of categories that players can be cast into, Gaussian Mixture Models (GMM) can be applied to find the optimal number of clusters. In the model presented, five different defensive player types can be identified. version:1
arxiv-1612-04340 | End-to-End Deep Reinforcement Learning for Lane Keeping Assist | http://arxiv.org/abs/1612.04340 | id:1612.04340 author:Ahmad El Sallab, Mohammed Abdou, Etienne Perot, Senthil Yogamani category:stat.ML cs.LG cs.RO  published:2016-12-13 summary:Reinforcement learning is considered to be a strong AI paradigm which can be used to teach machines through interaction with the environment and learning from their mistakes, but it has not yet been successfully used for automotive applications. There has recently been a revival of interest in the topic, however, driven by the ability of deep learning algorithms to learn good representations of the environment. Motivated by Google DeepMind's successful demonstrations of learning for games from Breakout to Go, we will propose different methods for autonomous driving using deep reinforcement learning. This is of particular interest as it is difficult to pose autonomous driving as a supervised learning problem as it has a strong interaction with the environment including other vehicles, pedestrians and roadworks. As this is a relatively new area of research for autonomous driving, we will formulate two main categories of algorithms: 1) Discrete actions category, and 2) Continuous actions category. For the discrete actions category, we will deal with Deep Q-Network Algorithm (DQN) while for the continuous actions category, we will deal with Deep Deterministic Actor Critic Algorithm (DDAC). In addition to that, We will also discover the performance of these two categories on an open source car simulator for Racing called (TORCS) which stands for The Open Racing car Simulator. Our simulation results demonstrate learning of autonomous maneuvering in a scenario of complex road curvatures and simple interaction with other vehicles. Finally, we explain the effect of some restricted conditions, put on the car during the learning phase, on the convergence time for finishing its learning phase. version:1
arxiv-1612-04337 | Fast Patch-based Style Transfer of Arbitrary Style | http://arxiv.org/abs/1612.04337 | id:1612.04337 author:Tian Qi Chen, Mark Schmidt category:cs.CV cs.GR cs.LG  published:2016-12-13 summary:Artistic style transfer is an image synthesis problem where the content of an image is reproduced with the style of another. Recent works show that a visually appealing style transfer can be achieved by using the hidden activations of a pretrained convolutional neural network. However, existing methods either apply (i) an optimization procedure that works for any style image but is very expensive, or (ii) an efficient feedforward network that only allows a limited number of trained styles. In this work we propose a simpler optimization objective based on local matching that combines the content structure and style textures in a single layer of the pretrained network. We show that our objective has desirable properties such as a simpler optimization landscape, intuitive parameter tuning, and consistent frame-by-frame performance on video. Furthermore, we use 80,000 natural images and 80,000 paintings to train an inverse network that approximates the result of the optimization. This results in a procedure for artistic style transfer that is efficient but also allows arbitrary content and style images. version:1
arxiv-1612-04335 | Saliency in VR: How do people explore virtual environments? | http://arxiv.org/abs/1612.04335 | id:1612.04335 author:Vincent Sitzmann, Ana Serrano, Amy Pavel, Maneesh Agrawala, Diego Gutierrez, Gordon Wetzstein category:cs.CV  published:2016-12-13 summary:Understanding how humans explore virtual environments is crucial for many applications, such as developing compression algorithms or designing effective cinematic virtual reality (VR) content, as well as to develop predictive computational models. We have recorded 780 head and gaze trajectories from 86 users exploring omni-directional stereo panoramas using VR head-mounted displays. By analyzing the interplay between visual stimuli, head orientation, and gaze direction, we demonstrate patterns and biases of how people explore these panoramas and we present first steps toward predicting time-dependent saliency. To compare how visual attention and saliency in VR are different from conventional viewing conditions, we have also recorded users observing the same scenes in a desktop setup. Based on this data, we show how to adapt existing saliency predictors to VR, so that insights and tools developed for predicting saliency in desktop scenarios may directly transfer to these immersive applications. version:1
arxiv-1612-04318 | Incorporating Human Domain Knowledge into Large Scale Cost Function Learning | http://arxiv.org/abs/1612.04318 | id:1612.04318 author:Markus Wulfmeier, Dushyant Rao, Ingmar Posner category:cs.RO cs.AI cs.LG  published:2016-12-13 summary:Recent advances have shown the capability of Fully Convolutional Neural Networks (FCN) to model cost functions for motion planning in the context of learning driving preferences purely based on demonstration data from human drivers. While pure learning from demonstrations in the framework of Inverse Reinforcement Learning (IRL) is a promising approach, we can benefit from well informed human priors and incorporate them into the learning process. Our work achieves this by pretraining a model to regress to a manual cost function and refining it based on Maximum Entropy Deep Inverse Reinforcement Learning. When injecting prior knowledge as pretraining for the network, we achieve higher robustness, more visually distinct obstacle boundaries, and the ability to capture instances of obstacles that elude models that purely learn from demonstration data. Furthermore, by exploiting these human priors, the resulting model can more accurately handle corner cases that are scarcely seen in the demonstration data, such as stairs, slopes, and underpasses. version:1
arxiv-1612-04316 | Memcomputing Numerical Inversion with Self-Organizing Logic Gates | http://arxiv.org/abs/1612.04316 | id:1612.04316 author:Haik Manukian, Fabio L. Traversa, Massimiliano Di Ventra category:cs.ET cs.NE  published:2016-12-13 summary:We propose to use Digital Memcomputing Machines (DMMs), implemented with self-organizing logic gates (SOLGs), to solve the problem of numerical inversion. Starting from fixed-point scalar inversion we describe the generalization to solving linear systems and matrix inversion. This method, when realized in hardware, will output the result in only one computational step. As an example, we perform simulations of the scalar case using a 5-bit logic circuit made of SOLGs, and show that the circuit successfully performs the inversion. Since this type of numerical inversion can be implemented by DMM units in hardware, it is scalable, and thus of great benefit to any real-time computing application. version:1
arxiv-1612-04315 | Towards Adaptive Training of Agent-based Sparring Partners for Fighter Pilots | http://arxiv.org/abs/1612.04315 | id:1612.04315 author:Brett W. Israelsen, Nisar Ahmed, Kenneth Center, Roderick Green, Winston Bennett Jr category:stat.ML cs.AI cs.LG cs.RO  published:2016-12-13 summary:A key requirement for the current generation of artificial decision-makers is that they should adapt well to changes in unexpected situations. This paper addresses the situation in which an AI for aerial dog fighting, with tunable parameters that govern its behavior, must optimize behavior with respect to an objective function that is evaluated and learned through simulations. Bayesian optimization with a Gaussian Process surrogate is used as the method for investigating the objective function. One key benefit is that during optimization, the Gaussian Process learns a global estimate of the true objective function, with predicted outcomes and a statistical measure of confidence in areas that haven't been investigated yet. Having a model of the objective function is important for being able to understand possible outcomes in the decision space; for example this is crucial for training and providing feedback to human pilots. However, standard Bayesian optimization does not perform consistently or provide an accurate Gaussian Process surrogate function for highly volatile objective functions. We treat these problems by introducing a novel sampling technique called Hybrid Repeat/Multi-point Sampling. This technique gives the AI ability to learn optimum behaviors in a highly uncertain environment. More importantly, it not only improves the reliability of the optimization, but also creates a better model of the entire objective surface. With this improved model the agent is equipped to more accurately/efficiently predict performance in unexplored scenarios. version:1
arxiv-1612-03211 | DeepCancer: Detecting Cancer through Gene Expressions via Deep Generative Learning | http://arxiv.org/abs/1612.03211 | id:1612.03211 author:Rajendra Rana Bhat, Vivek Viswanath, Xiaolin Li category:cs.AI cs.LG q-bio.GN  published:2016-12-09 summary:Transcriptional profiling on microarrays to obtain gene expressions has been used to facilitate cancer diagnosis. We propose a deep generative machine learning architecture (called DeepCancer) that learn features from unlabeled microarray data. These models have been used in conjunction with conventional classifiers that perform classification of the tissue samples as either being cancerous or non-cancerous. The proposed model has been tested on two different clinical datasets. The evaluation demonstrates that DeepCancer model achieves a very high precision score, while significantly controlling the false positive and false negative scores. version:2
arxiv-1612-04262 | An EoS-meter of QCD transition from deep learning | http://arxiv.org/abs/1612.04262 | id:1612.04262 author:Long-Gang Pang, Kai Zhou, Nan Su, Hannah Petersen, Horst Stöcker, Xin-Nian Wang category:hep-ph cs.LG hep-th nucl-th stat.ML  published:2016-12-13 summary:Supervised learning with a deep convolutional neural network is used to identify the QCD equation of state (EoS) employed in relativistic hydrodynamic simulations of heavy-ion collisions. The final-state particle spectra $\rho(p_T,\Phi)$ provide directly accessible information from experiments. High-level correlations of $\rho(p_T,\Phi)$ learned by the neural network act as an "EoS-meter", effective in detecting the nature of the QCD transition. The EoS-meter is model independent and insensitive to other simulation input, especially the initial conditions. Thus it provides a formidable direct-connection of heavy-ion collision observable with the bulk properties of QCD. version:1
arxiv-1612-04256 | Neuro-symbolic representation learning on biological knowledge graphs | http://arxiv.org/abs/1612.04256 | id:1612.04256 author:Mona Alshahrani, Mohammed Asif Khan, Omar Maddouri, Akira R Kinjo, Núria Queralt-Rosinach, Robert Hoehndorf category:q-bio.QM cs.LG q-bio.MN  published:2016-12-13 summary:Motivation: Biological data and knowledge bases increasingly rely on Semantic Web technologies and the use of knowledge graphs for data integration, retrieval and federated queries. In the past years, feature learning methods that are applicable to graph-structured data are becoming available, but have not yet widely been applied and evaluated on structured biological knowledge. Results: We develop a novel method for feature learning on biological knowledge graphs. Our method combines symbolic methods, in particular knowledge representation using symbolic logic and automated reasoning, with neural networks to generate embeddings of nodes that encode for related information within knowledge graphs. Through the use of symbolic logic, these embeddings contain both explicit and implicit information. We apply these embeddings to the prediction of edges in the knowledge graph representing problems of function prediction, finding candidate genes of diseases, protein-protein interactions, or drug target relations, and demonstrate performance that matches and sometimes outperforms traditional approaches based on manually crafted features. Our method can be applied to any biological knowledge graph, and will thereby open up the increasing amount of Semantic Web based knowledge bases in biology to use in machine learning and data analytics. Availability and Implementation: https://github.com/bio-ontology-research-group/walking-rdf-and-owl Contact: robert.hoehndorf@kaust.edu.sa version:1
arxiv-1612-04251 | TF.Learn: TensorFlow's High-level Module for Distributed Machine Learning | http://arxiv.org/abs/1612.04251 | id:1612.04251 author:Yuan Tang category:cs.DC cs.LG  published:2016-12-13 summary:TF.Learn is a high-level Python module for distributed machine learning inside TensorFlow. It provides an easy-to-use Scikit-learn style interface to simplify the process of creating, configuring, training, evaluating, and experimenting a machine learning model. TF.Learn integrates a wide range of state-of-art machine learning algorithms built on top of TensorFlow's low level APIs for small to large-scale supervised and unsupervised problems. This module focuses on bringing machine learning to non-specialists using a general-purpose high-level language as well as researchers who want to implement, benchmark, and compare their new methods in a structured environment. Emphasis is put on ease of use, performance, documentation, and API consistency. version:1
arxiv-1612-04229 | Compressive Image Recovery Using Recurrent Generative Model | http://arxiv.org/abs/1612.04229 | id:1612.04229 author:Akshat Dave, Anil Kumar Vadathya, Kaushik Mitra category:cs.CV  published:2016-12-13 summary:Generative models are considered as the swiss knives for data modelling. In this paper we leverage the recently proposed recurrent generative model, RIDE, for applications like image inpainting and compressive image reconstruction. Recurrent networks can model long range dependencies in images and hence are suitable to handle global multiplexing in reconstruction from compressive imaging. We perform MAP inference with RIDE as prior using backpropagation to the inputs and projected gradient method. We propose a entropy thresholding based approach for preserving texture well. Our approach shows comparable results for image inpainting task. It shows superior results in compressive image reconstruction compared to traditional methods D-AMP and TVAL3 which uses global prior of minimizing TV norm. version:1
arxiv-1612-04211 | Multi-Perspective Context Matching for Machine Comprehension | http://arxiv.org/abs/1612.04211 | id:1612.04211 author:Zhiguo Wang, Haitao Mi, Wael Hamza, Radu Florian category:cs.CL  published:2016-12-13 summary:Previous machine comprehension (MC) datasets are either too small to train end-to-end deep learning models, or not difficult enough to evaluate the ability of current MC techniques. The newly released SQuAD dataset alleviates these limitations, and gives us a chance to develop more realistic MC models. Based on this dataset, we propose a Multi-Perspective Context Matching (MPCM) model, which is an end-to-end system that directly predicts the answer beginning and ending points in a passage. Our model first adjusts each word-embedding vector in the passage by multiplying a relevancy weight computed against the question. Then, we encode the question and weighted passage by using bi-directional LSTMs. For each point in the passage, our model matches the context of this point against the encoded question from multiple perspectives and produces a matching vector. Given those matched vectors, we employ another bi-directional LSTM to aggregate all the information and predict the beginning and ending points. Experimental result on the test set of SQuAD shows that our model achieves a competitive result on the leaderboard. version:1
arxiv-1612-04174 | Models of retrieval in sentence comprehension: A computational evaluation using Bayesian hierarchical modeling | http://arxiv.org/abs/1612.04174 | id:1612.04174 author:Bruno Nicenboim, Shravan Vasishth category:cs.CL stat.AP stat.ML  published:2016-12-13 summary:Research on interference has provided evidence that the formation of dependencies between non-adjacent words relies on a cue-based retrieval mechanism. Two different models can account for one of the main predictions of interference, i.e., a slowdown at a retrieval site, when several items share a feature associated with a retrieval cue: Lewis and Vasishth's (2005) activation-based model and McElree's (2000) direct access model. Even though these two models have been used almost interchangeably, they are based on different assumptions and predict differences in the relationship between reading times and response accuracy. The activation-based model follows the assumptions of ACT-R, and its retrieval process behaves as a lognormal race between accumulators of evidence with a single variance. Under this model, accuracy of the retrieval is determined by the winner of the race and retrieval time by its rate of accumulation. In contrast, the direct access model assumes a model of memory where only the probability of retrieval varies between items; in this model, differences in latencies are a by-product of the possibility and repairing incorrect retrievals. We implemented both models in a Bayesian hierarchical framework in order to evaluate them and compare them. We show that some aspects of the data are better fit under the direct access model than under the activation-based model. We suggest that this finding does not rule out the possibility that retrieval may be behaving as a race model with assumptions that follow less closely the ones from the ACT-R framework. We show that by introducing a modification of the activation model, i.e, by assuming that the accumulation of evidence for retrieval of incorrect items is not only slower but noisier (i.e., different variances for the correct and incorrect items), the model can provide a fit as good as the one of the direct access model. version:1
arxiv-1612-04118 | Information Extraction with Character-level Neural Networks and Noisy Supervision | http://arxiv.org/abs/1612.04118 | id:1612.04118 author:Philipp Meerkamp, Zhengyi Zhou category:cs.CL cs.IR cs.LG  published:2016-12-13 summary:We present an architecture for information extraction from text that augments an existing parser with a character-level neural network. To train the neural network, we compute a measure of consistency of extracted data with existing databases, and use it as a form of noisy supervision. Our architecture combines the ability of constraint-based information extraction system to easily incorporate domain knowledge and constraints with the ability of deep neural networks to leverage large amounts of data to learn complex features. The system led to large improvements over a mature and highly tuned constraint-based information extraction system used at Bloomberg for financial language text. At the same time, the new system massively reduces the development effort, allowing rule-writers to write high-recall constraints while relying on the deep neural network to remove false positives and boost precision. version:1
arxiv-1612-04113 | Vicinity-Driven Paragraph and Sentence Alignment for Comparable Corpora | http://arxiv.org/abs/1612.04113 | id:1612.04113 author:Gustavo Henrique Paetzold, Lucia Specia category:cs.CL  published:2016-12-13 summary:Parallel corpora have driven great progress in the field of Text Simplification. However, most sentence alignment algorithms either offer a limited range of alignment types supported, or simply ignore valuable clues present in comparable documents. We address this problem by introducing a new set of flexible vicinity-driven paragraph and sentence alignment algorithms that 1-N, N-1, N-N and long distance null alignments without the need for hard-to-replicate supervised models. version:1
arxiv-1612-04111 | Parsimonious Online Learning with Kernels via Sparse Projections in Function Space | http://arxiv.org/abs/1612.04111 | id:1612.04111 author:Alec Koppel, Garrett Warnell, Ethan Stump, Alejandro Ribeiro category:stat.ML cs.LG  published:2016-12-13 summary:Despite their attractiveness, popular perception is that techniques for nonparametric function approximation do not scale to streaming data due to an intractable growth in the amount of storage they require. To solve this problem in a memory-affordable way, we propose an online technique based on functional stochastic gradient descent in tandem with supervised sparsification based on greedy function subspace projections. The method, called parsimonious online learning with kernels (POLK), provides a controllable tradeoff? between its solution accuracy and the amount of memory it requires. We derive conditions under which the generated function sequence converges almost surely to the optimal function, and we establish that the memory requirement remains finite. We evaluate POLK for kernel multi-class logistic regression and kernel hinge-loss classification on three canonical data sets: a synthetic Gaussian mixture model, the MNIST hand-written digits, and the Brodatz texture database. On all three tasks, we observe a favorable tradeoff of objective function evaluation, classification performance, and complexity of the nonparametric regressor extracted the proposed method. version:1
arxiv-1612-04110 | Observation of dynamics inside an unlabeled live cell using bright-field photon microscopy: Evaluation of organelles' trajectories | http://arxiv.org/abs/1612.04110 | id:1612.04110 author:Renata Rychtarikova, Dalibor Stys category:q-bio.QM cs.CV q-bio.CB q-bio.SC  published:2016-12-13 summary:This article presents an algorithm for the evaluation of organelles' movements inside of an unmodified live cell. We used a time-lapse image series obtained using wide-field bright-field photon transmission microscopy as an algorithm input. The benefit of the algorithm is the application of the R\'enyi information entropy, namely a variable called a point information gain, which enables to highlight the borders of the intracellular organelles and to localize the organelles' centers of mass with the precision of one pixel. version:1
arxiv-1612-04108 | Corporate Disruption in the Science of Machine Learning | http://arxiv.org/abs/1612.04108 | id:1612.04108 author:Sam Work category:cs.CY cs.LG  published:2016-12-13 summary:This MSc dissertation considers the effects of the current corporate interest on researchers in the field of machine learning. Situated within the field's cyclical history of academic, public and corporate interest, this dissertation investigates how current researchers view recent developments and negotiate their own research practices within an environment of increased commercial interest and funding. The original research consists of in-depth interviews with 12 machine learning researchers working in both academia and industry. Building on theory from science, technology and society studies, this dissertation problematizes the traditional narratives of the neoliberalization of academic research by allowing the researchers themselves to discuss how their career choices, working environments and interactions with others in the field have been affected by the reinvigorated corporate interest of recent years. version:1
arxiv-1612-04062 | Spatial Pyramid Convolutional Neural Network for Social Event Detection in Static Image | http://arxiv.org/abs/1612.04062 | id:1612.04062 author:Reza Fuad Rachmadi, Keiichi Uchimura, Gou Koutaki category:cs.CV  published:2016-12-13 summary:Social event detection in a static image is a very challenging problem and it's very useful for internet of things applications including automatic photo organization, ads recommender system, or image captioning. Several publications show that variety of objects, scene, and people can be very ambiguous for the system to decide the event that occurs in the image. We proposed the spatial pyramid configuration of convolutional neural network (CNN) classifier for social event detection in a static image. By applying the spatial pyramid configuration to the CNN classifier, the detail that occurs in the image can observe more accurately by the classifier. USED dataset provided by Ahmad et al. is used to evaluate our proposed method, which consists of two different image sets, EiMM, and SED dataset. As a result, the average accuracy of our system outperforms the baseline method by 15% and 2% respectively. version:1
arxiv-1612-04061 | Learning to Hash-tag Videos with Tag2Vec | http://arxiv.org/abs/1612.04061 | id:1612.04061 author:Aditya Singh, Saurabh Saini, Rajvi Shah, PJ Narayanan category:cs.CV cs.CL  published:2016-12-13 summary:User-given tags or labels are valuable resources for semantic understanding of visual media such as images and videos. Recently, a new type of labeling mechanism known as hash-tags have become increasingly popular on social media sites. In this paper, we study the problem of generating relevant and useful hash-tags for short video clips. Traditional data-driven approaches for tag enrichment and recommendation use direct visual similarity for label transfer and propagation. We attempt to learn a direct low-cost mapping from video to hash-tags using a two step training process. We first employ a natural language processing (NLP) technique, skip-gram models with neural network training to learn a low-dimensional vector representation of hash-tags (Tag2Vec) using a corpus of 10 million hash-tags. We then train an embedding function to map video features to the low-dimensional Tag2vec space. We learn this embedding for 29 categories of short video clips with hash-tags. A query video without any tag-information can then be directly mapped to the vector space of tags using the learned embedding and relevant tags can be found by performing a simple nearest-neighbor retrieval in the Tag2Vec space. We validate the relevance of the tags suggested by our system qualitatively and quantitatively with a user study. version:1
arxiv-1612-04056 | Joint Bayesian Gaussian discriminant analysis for speaker verification | http://arxiv.org/abs/1612.04056 | id:1612.04056 author:Yiyan Wang, Haotian Xu, Zhijian Ou category:cs.SD cs.LG  published:2016-12-13 summary:State-of-the-art i-vector based speaker verification relies on variants of Probabilistic Linear Discriminant Analysis (PLDA) for discriminant analysis. We are mainly motivated by the recent work of the joint bayesian (JB) method, which is originally proposed for discriminant analysis in face verification. We apply JB to speaker verification and make three contributions beyond of the original JB. 1) In contrast to the EM iterations with approximated statistics in the original JB, the EM iterations with exact statistics is employed and gives better performance. 2) We propose to do simultaneously diagonalization (SD) of the within-class and between-class covariance matrices to achieve efficient testing, which has broader application scope than the SVD-based efficient testing method in the original JB. 3) We scrutinize similarities and differences between various Gaussian PLDAs and JB, complementing the previous analysis of comparing JB only with Prince-Elder PLDA. Extensive experiments are conducted on NIST SRE10 core condition 5, empirically validating the superiority of JB with faster convergence rate and 9 - 13% EER reduction compared with state-of-the-art PLDA. version:1
arxiv-1612-04052 | Theory and Tools for the Conversion of Analog to Spiking Convolutional Neural Networks | http://arxiv.org/abs/1612.04052 | id:1612.04052 author:Bodo Rueckauer, Iulia-Alexandra Lungu, Yuhuang Hu, Michael Pfeiffer category:stat.ML cs.CV cs.LG cs.NE  published:2016-12-13 summary:Deep convolutional neural networks (CNNs) have shown great potential for numerous real-world machine learning applications, but performing inference in large CNNs in real-time remains a challenge. We have previously demonstrated that traditional CNNs can be converted into deep spiking neural networks (SNNs), which exhibit similar accuracy while reducing both latency and computational load as a consequence of their data-driven, event-based style of computing. Here we provide a novel theory that explains why this conversion is successful, and derive from it several new tools to convert a larger and more powerful class of deep networks into SNNs. We identify the main sources of approximation errors in previous conversion methods, and propose simple mechanisms to fix these issues. Furthermore, we develop spiking implementations of common CNN operations such as max-pooling, softmax, and batch-normalization, which allow almost loss-less conversion of arbitrary CNN architectures into the spiking domain. Empirical evaluation of different network architectures on the MNIST and CIFAR10 benchmarks leads to the best SNN results reported to date. version:1
arxiv-1612-04035 | DizzyRNN: Reparameterizing Recurrent Neural Networks for Norm-Preserving Backpropagation | http://arxiv.org/abs/1612.04035 | id:1612.04035 author:Victor Dorobantu, Per Andre Stromhaug, Jess Renteria category:cs.LG  published:2016-12-13 summary:The vanishing and exploding gradient problems are well-studied obstacles that make it difficult for recurrent neural networks to learn long-term time dependencies. We propose a reparameterization of standard recurrent neural networks to update linear transformations in a provably norm-preserving way through Givens rotations. Additionally, we use the absolute value function as an element-wise non-linearity to preserve the norm of backpropagated signals over the entire network. We show that this reparameterization reduces the number of parameters and maintains the same algorithmic complexity as a standard recurrent neural network, while outperforming standard recurrent neural networks with orthogonal initializations and Long Short-Term Memory networks on the copy problem. version:1
arxiv-1612-04022 | Distributed Multi-task Relationship Learning | http://arxiv.org/abs/1612.04022 | id:1612.04022 author:Sulin Liu, Sinno Jialin Pan, Qirong Ho category:cs.LG stat.ML  published:2016-12-13 summary:In this paper, we propose a distributed multi-task learning framework that simultaneously learns predictive models for each task as well as task relationships between tasks alternatingly in the parameter server paradigm. In our framework, we first offer a general dual form for a family of regularized multi-task relationship learning methods. Subsequently, we propose a communication-efficient primal-dual distributed optimization algorithm to solve the dual problem by carefully designing local subproblems to make the dual problem decomposable. Moreover, we provide a theoretical convergence analysis for the proposed algorithm, which is specific for distributed multi-task relationship learning. We conduct extensive experiments on both synthetic and real-world datasets to evaluate our proposed framework in terms of scalability, effectiveness, and convergence. version:1
arxiv-1612-04021 | Generative Adversarial Parallelization | http://arxiv.org/abs/1612.04021 | id:1612.04021 author:Daniel Jiwoong Im, He Ma, Chris Dongjoo Kim, Graham Taylor category:cs.LG stat.ML  published:2016-12-13 summary:Generative Adversarial Networks have become one of the most studied frameworks for unsupervised learning due to their intuitive formulation. They have also been shown to be capable of generating convincing examples in limited domains, such as low-resolution images. However, they still prove difficult to train in practice and tend to ignore modes of the data generating distribution. Quantitatively capturing effects such as mode coverage and more generally the quality of the generative model still remain elusive. We propose Generative Adversarial Parallelization, a framework in which many GANs or their variants are trained simultaneously, exchanging their discriminators. This eliminates the tight coupling between a generator and discriminator, leading to improved convergence and improved coverage of modes. We also propose an improved variant of the recently proposed Generative Adversarial Metric and show how it can score individual GANs or their collections under the GAP model. version:1
arxiv-1612-04010 | An Empirical Analysis of Deep Network Loss Surfaces | http://arxiv.org/abs/1612.04010 | id:1612.04010 author:Daniel Jiwoong Im, Michael Tao, Kristin Branson category:cs.LG  published:2016-12-13 summary:The training of deep neural networks is a high-dimension optimization problem with respect to the loss function of a model. Unfortunately, these functions are of high dimension and non-convex and hence difficult to characterize. In this paper, we empirically investigate the geometry of the loss functions for state-of-the-art networks with multiple stochastic optimization methods. We do this through several experiments that are visualized on polygons to understand how and when these stochastic optimization methods find minima. version:1
arxiv-1612-04007 | A Video-Based Method for Objectively Rating Ataxia | http://arxiv.org/abs/1612.04007 | id:1612.04007 author:Ronnachai Jaroensri, Amy Zhao, Guha Balakrishnan, Derek Lo, Jeremy Schmahmann, John Guttag, Fredo Durand category:cs.CV  published:2016-12-13 summary:For many movement disorders, such as Parkinson's and ataxia, disease progression is usually assessed visually by a clinician according to a numerical rating scale, or using questionnaires. These tests are subjective, time-consuming, and must be administered by a professional. We present an automated method for quantifying the severity of motion impairment in patients with ataxia, using only video recordings. We focus on videos of the finger-to-nose test, a common movement task used to assess ataxia progression during the course of routine clinical checkups. Our method uses pose estimation and optical flow techniques to track the motion of the patient's hand in a video recording. We extract features that describe qualities of the motion such as speed and variation in performance. Using labels provided by an expert clinician, we build a supervised learning model that predicts severity according to the Brief Ataxia Rating Scale (BARS). Our model achieves a mean absolute error of 0.363 on a 0-4 scale and a prediction-label correlation of 0.835 in a leave-one-patient-out experiment. The accuracy of our system is comparable to the reported inter-rater correlation among clinicians assessing the finger-to-nose exam using a similar ataxia rating scale. This work demonstrates the feasibility of using videos to produce more objective and clinically useful measures of motor impairment. version:1
arxiv-1612-03902 | Design and Development of Bayes' Minimax Linear Classification Systems | http://arxiv.org/abs/1612.03902 | id:1612.03902 author:Denise M. Reeves category:cs.LG  published:2016-12-12 summary:This paper considers the design and development of Bayes' minimax, linear classification systems using linear discriminant functions that are Bayes' equalizer rules. Bayes' equalizer rules divide two-class feature spaces into decision regions that have equal classification errors. I will formulate the problem of learning unknown linear discriminant functions from data as a locus problem, thereby formulating geometric locus methods within a statistical framework. Solving locus problems involves finding the equation of a curve or surface defined by a given property, and finding the graph or locus of a given equation. I will devise a system of locus equations that determines Bayes' equalizer rules which is based on a variant of the inequality constrained optimization problem for linear kernel support vector machines. Thereby, I will define a class of learning machines which are fundamental building blocks for Bayes' minimax pattern recognition systems. version:2
arxiv-1612-03991 | Performance Improvements of Probabilistic Transcript-adapted ASR with Recurrent Neural Network and Language-specific Constraints | http://arxiv.org/abs/1612.03991 | id:1612.03991 author:Xiang Kong, Preethi Jyothi, Mark Hasegawa-Johnson category:cs.CL  published:2016-12-13 summary:Mismatched transcriptions have been proposed as a mean to acquire probabilistic transcriptions from non-native speakers of a language.Prior work has demonstrated the value of these transcriptions by successfully adapting cross-lingual ASR systems for different tar-get languages. In this work, we describe two techniques to refine these probabilistic transcriptions: a noisy-channel model of non-native phone misperception is trained using a recurrent neural net-work, and decoded using minimally-resourced language-dependent pronunciation constraints. Both innovations improve quality of the transcript, and both innovations reduce phone error rate of a trainedASR, by 7% and 9% respectively version:1
arxiv-1612-03990 | Evaluating Automatic Speech Recognition Systems in Comparison With Human Perception Results Using Distinctive Feature Measures | http://arxiv.org/abs/1612.03990 | id:1612.03990 author:Xiang Kong, Jeung-Yoon Choi, Stefanie Shattuck-Hufnagel category:cs.CL  published:2016-12-13 summary:This paper describes methods for evaluating automatic speech recognition (ASR) systems in comparison with human perception results, using measures derived from linguistic distinctive features. Error patterns in terms of manner, place and voicing are presented, along with an examination of confusion matrices via a distinctive-feature-distance metric. These evaluation methods contrast with conventional performance criteria that focus on the phone or word level, and are intended to provide a more detailed profile of ASR system performance,as well as a means for direct comparison with human perception results at the sub-phonemic level. version:1
arxiv-1612-05627 | Models, networks and algorithmic complexity | http://arxiv.org/abs/1612.05627 | id:1612.05627 author:Giulio Ruffini category:cs.LG  published:2016-12-13 summary:I aim to show that models, classification or generating functions, invariances and datasets are algorithmically equivalent concepts once properly defined, and provide some concrete examples of them. I then show that a) neural networks (NNs) of different kinds can be seen to implement models, b) that perturbations of inputs and nodes in NNs trained to optimally implement simple models propagate strongly, c) that there is a framework in which recurrent, deep and shallow networks can be seen to fall into a descriptive power hierarchy in agreement with notions from the theory of recursive functions. The motivation for these definitions and following analysis lies in the context of cognitive neuroscience, and in particular in Ruffini (2016), where the concept of model is used extensively, as is the concept of algorithmic complexity. version:1
arxiv-1612-03982 | Deep Convolutional Poses for Human Interaction Recognition in Monocular Videos | http://arxiv.org/abs/1612.03982 | id:1612.03982 author:Marcel Sheeny de Moraes, Sankha Mukherjee, Neil M Robertson category:cs.CV  published:2016-12-13 summary:Human interaction recognition is a challenging problem in computer vision and has been researched over the years due to its important applications. With the development of deep models for the human pose estimation problem, this work aims to verify the effectiveness of using the human pose in order to recognize the human interaction in monocular videos. This paper developed a method based on 5 steps: detect each person in the scene, track them, retrieve the human pose, extract features based on the pose and finally recognize the interaction using a classifier. The Two-Person interaction dataset was used for the development of this methodology. Using a whole sequence evaluation approach it achieved 87.56% of average accuracy of all interaction. Yun, et at achieved 91.10% using the same dataset, however their methodology used the depth sensor to recognize the interaction. The methodology developed in this paper shows that an RGB camera can be as effective as depth cameras to recognize the interaction between two persons using the recent development of deep models to estimate the human pose. version:1
arxiv-1612-03981 | Hybrid Repeat/Multi-point Sampling for Highly Volatile Objective Functions | http://arxiv.org/abs/1612.03981 | id:1612.03981 author:Brett Israelsen, Nisar Ahmed category:stat.ML cs.AI cs.LG cs.RO  published:2016-12-13 summary:A key drawback of the current generation of artificial decision-makers is that they do not adapt well to changes in unexpected situations. This paper addresses the situation in which an AI for aerial dog fighting, with tunable parameters that govern its behavior, will optimize behavior with respect to an objective function that must be evaluated and learned through simulations. Once this objective function has been modeled, the agent can then choose its desired behavior in different situations. Bayesian optimization with a Gaussian Process surrogate is used as the method for investigating the objective function. One key benefit is that during optimization the Gaussian Process learns a global estimate of the true objective function, with predicted outcomes and a statistical measure of confidence in areas that haven't been investigated yet. However, standard Bayesian optimization does not perform consistently or provide an accurate Gaussian Process surrogate function for highly volatile objective functions. We treat these problems by introducing a novel sampling technique called Hybrid Repeat/Multi-point Sampling. This technique gives the AI ability to learn optimum behaviors in a highly uncertain environment. More importantly, it not only improves the reliability of the optimization, but also creates a better model of the entire objective surface. With this improved model the agent is equipped to better adapt behaviors. version:1
arxiv-1612-03975 | ConceptNet 5.5: An Open Multilingual Graph of General Knowledge | http://arxiv.org/abs/1612.03975 | id:1612.03975 author:Robert Speer, Joshua Chin, Catherine Havasi category:cs.CL I.2.7  published:2016-12-12 summary:Machine learning about language can be improved by supplying it with specific knowledge and sources of external information. We present here a new version of the linked open data resource ConceptNet that is particularly well suited to be used with modern NLP techniques such as word embeddings. ConceptNet is a knowledge graph that connects words and phrases of natural language with labeled edges. Its knowledge is collected from many sources that include expert-created resources, crowd-sourcing, and games with a purpose. It is designed to represent the general knowledge involved in understanding language, improving natural language applications by allowing the application to better understand the meanings behind the words people use. When ConceptNet is combined with word embeddings acquired from distributional semantics (such as word2vec), it provides applications with understanding that they would not acquire from distributional semantics alone, nor from narrower resources such as WordNet or DBPedia. We demonstrate this with state-of-the-art results on intrinsic evaluations of word relatedness that translate into improvements on applications of word vectors, including solving SAT-style analogies. version:1
arxiv-1612-03969 | Tracking the World State with Recurrent Entity Networks | http://arxiv.org/abs/1612.03969 | id:1612.03969 author:Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes, Yann LeCun category:cs.CL  published:2016-12-12 summary:We introduce a new model, the Recurrent Entity Network (EntNet). It is equipped with a dynamic long-term memory which allows it to maintain and update a representation of the state of the world as it receives new data. For language understanding tasks, it can reason on-the-fly as it reads text, not just when it is required to answer a question or respond as is the case for a Memory Network (Sukhbaatar et al., 2015). Like a Neural Turing Machine or Differentiable Neural Computer (Graves et al., 2014; 2016) it maintains a fixed size memory and can learn to perform location and content-based read and write operations. However, unlike those models it has a simple parallel architecture in which several memory locations can be updated simultaneously. The EntNet sets a new state-of-the-art on the bAbI tasks, and is the first method to solve all the tasks in the 10k training examples setting. We also demonstrate that it can solve a reasoning task which requires a large number of supporting facts, which other methods are not able to solve, and can generalize past its training horizon. It can also be practically used on large scale datasets such as Children's Book Test, where it obtains competitive performance, reading the story in a single pass. version:1
arxiv-1612-03964 | Probabilistic Bisection Converges Almost as Quickly as Stochastic Approximation | http://arxiv.org/abs/1612.03964 | id:1612.03964 author:Peter I. Frazier, Shane G. Henderson, Rolf Waeber category:math.PR math.OC stat.ML  published:2016-12-12 summary:The probabilistic bisection algorithm (PBA) solves a class of stochastic root-finding problems in one dimension by successively updating a prior belief on the location of the root based on noisy responses to queries at chosen points. The responses indicate the direction of the root from the queried point, and are incorrect with a fixed probability. The fixed-probability assumption is problematic in applications, and so we extend the PBA to apply when this assumption is relaxed. The extension involves the use of a power-one test at each queried point. We explore the convergence behavior of the extended PBA, showing that it converges at a rate arbitrarily close to, but slower than, the canonical "square root" rate of stochastic approximation. version:1
arxiv-1612-03961 | Neural Networks with Manifold Learning for Diabetic Retinopathy Detection | http://arxiv.org/abs/1612.03961 | id:1612.03961 author:Arjun Raj Rajanna, Kamelia Aryafar, Rajeev Ramchandran, Christye Sisson, Ali Shokoufandeh, Raymond Ptucha category:cs.CV  published:2016-12-12 summary:Widespread outreach programs using remote retinal imaging have proven to decrease the risk from diabetic retinopathy, the leading cause of blindness in the US. However, this process still requires manual verification of image quality and grading of images for level of disease by a trained human grader and will continue to be limited by the lack of such scarce resources. Computer-aided diagnosis of retinal images have recently gained increasing attention in the machine learning community. In this paper, we introduce a set of neural networks for diabetic retinopathy classification of fundus retinal images. We evaluate the efficiency of the proposed classifiers in combination with preprocessing and augmentation steps on a sample dataset. Our experimental results show that neural networks in combination with preprocessing on the images can boost the classification accuracy on this dataset. Moreover the proposed models are scalable and can be used in large scale datasets for diabetic retinopathy detection. The models introduced in this paper can be used to facilitate the diagnosis and speed up the detection process. version:1
arxiv-1612-03959 | Autoencoder-based holographic image restoration | http://arxiv.org/abs/1612.03959 | id:1612.03959 author:Tomoyoshi Shimobaba, Yutaka Endo, Ryuji Hirayama, Yuki Nagahama, Takayuki Takahashi, Takashi Nishitsuji, Takashi Kakue, Atsushi Shiraki, Naoki Takada, Nobuyuki Masuda, Tomoyoshi Ito category:cs.CV physics.optics  published:2016-12-12 summary:We propose a holographic image restoration method using an autoencoder, which is an artificial neural network. Because holographic reconstructed images are often contaminated by direct light, conjugate light, and speckle noise, the discrimination of reconstructed images may be difficult. In this paper, we demonstrate the restoration of reconstructed images from holograms that record page data in holographic memory and QR codes by using the proposed method. version:1
arxiv-1612-03957 | Monte Carlo Structured SVI for Non-Conjugate Models | http://arxiv.org/abs/1612.03957 | id:1612.03957 author:Rishit Sheth, Roni Khardon category:stat.ML  published:2016-12-12 summary:The stochastic variational inference (SVI) paradigm, which combines variational inference, natural gradients, and stochastic updates, was recently proposed for large-scale data analysis in conjugate Bayesian models and demonstrated to be effective in several problems. This paper studies a family of Bayesian latent variable models with two levels of hidden variables but without any conjugacy requirements, making several contributions in this context. The first is observing that SVI, with an improved structured variational approximation, is applicable under more general conditions than previously thought with the only requirement being that the approximating variational distribution be in the same family as the prior. The resulting approach, Monte Carlo Structured SVI (MC-SSVI), significantly extends the scope of SVI, enabling large-scale learning in non-conjugate models. The second contribution is developing the algorithmic details of MC-SSVI for two challenging models. The application of MC-SSVI to probabilistic matrix factorization (PMF) yields an algorithm which is efficient and generic in that it is applicable to any type of observation likelihood, with improvements in convergence speed and in general applicability over previous work. The application of MC-SSVI to the correlated topic model (CTM) improves over previous work which used the much stronger mean field variational approximation. An experimental evaluation demonstrates the advantages of MC-SSVI. version:1
arxiv-1612-03950 | Sources identification using shifted non-negative matrix factorization combined with semi-supervised clustering | http://arxiv.org/abs/1612.03950 | id:1612.03950 author:Filip L. Iliev, Valentin G. Stanev, Velimir V. Vesselinov, Boian S. Alexandrov category:cs.LG stat.ML  published:2016-12-12 summary:Non-negative matrix factorization (NMF) is a well-known unsupervised learning method that has been successfully used for blind source separation of non-negative additive signals.NMF method requires the number of the original sources to be known a priori. Recently, we reported a method, we called NMFk, which by coupling the original NMF multiplicative algorithm with a custom semi-supervised clustering allows us to estimate the number of the sources based on the robustness of the reconstructed solutions. Here, an extension of NMFk is developed, called ShiftNMFk, which by combining NMFk with previously formulated ShiftNMF algorithm, Akaike Information Criterion (AIC), and a custom procedure for estimating the source locations is capable of identifying: (a) the number of the unknown sources, (b) the eventual delays in the signal propagation, (c) the locations of the sources, and (d) the speed of propagation of each of the signals in the medium. Our new method is a natural extension of NMFk that can be used for sources identification based only on observational data. We demonstrate how our novel method identifies the components of synthetic data sets, discuss its limitations, and present a Julia language implementation of ShiftNMFk algorithm. version:1
arxiv-1612-03948 | Machine learning approach for identification of release sources in advection-diffusion systems | http://arxiv.org/abs/1612.03948 | id:1612.03948 author:Valentin G. Stanev, Filip L. Iliev, Velimir V. Vesselinov, Boian S. Alexandrov category:cs.LG stat.ML  published:2016-12-12 summary:These records are then used to estimate properties of the contaminant sources, e.g., locations, release strengths and model parameters representing contaminant migration (e.g., velocity, dispersivity, etc.). These estimates are essential for a reliable assessment of the contamination hazards and risks. If there are more than one contaminant sources (with different locations and strengths), the observed records represent contaminant mixtures; typically, the number of sources is unknown. The mixing ratios of the different contaminant sources at the detectors are also unknown; this further hinders the reliability and complexity of the inverse-model analyses. To circumvent some of these challenges, we have developed a novel hybrid source identification method coupling machine learning and inverse-analysis methods, and called Green-NMFk. It performs decomposition of the observed mixtures based on Non-negative Matrix Factorization method for Blind Source Separation, coupled with custom semi-supervised clustering algorithm, and uses Green's functions of advection-diffusion equation. Our method is capable of identifying the unknown number, locations, and properties of a set of contaminant sources from measured contaminant-source mixtures with unknown mixing ratios, without any additional information. It also estimates the contaminant transport properties, such as velocity and dispersivity. Green-NMFk is not limited to contaminant transport but can be applied directly to any problem controlled by partial-differential parabolic equation where mixtures of an unknown number of physical sources are monitored at multiple locations. Green-NMFk can be also applied with different Green's functions; for example, representing anomalous (non-Fickian) dispersion or wave propagation in dispersive media. version:1
arxiv-1612-03940 | Understanding the Impact of Precision Quantization on the Accuracy and Energy of Neural Networks | http://arxiv.org/abs/1612.03940 | id:1612.03940 author:Soheil Hashemi, Nicholas Anthony, Hokchhay Tann, R. Iris Bahar, Sherief Reda category:cs.NE  published:2016-12-12 summary:Deep neural networks are gaining in popularity as they are used to generate state-of-the-art results for a variety of computer vision and machine learning applications. At the same time, these networks have grown in depth and complexity in order to solve harder problems. Given the limitations in power budgets dedicated to these networks, the importance of low-power, low-memory solutions has been stressed in recent years. While a large number of dedicated hardware using different precisions has recently been proposed, there exists no comprehensive study of different bit precisions and arithmetic in both inputs and network parameters. In this work, we address this issue and perform a study of different bit-precisions in neural networks (from floating-point to fixed-point, powers of two, and binary). In our evaluation, we consider and analyze the effect of precision scaling on both network accuracy and hardware metrics including memory footprint, power and energy consumption, and design area. We also investigate training-time methodologies to compensate for the reduction in accuracy due to limited bit precision and demonstrate that in most cases, precision scaling can deliver significant benefits in design metrics at the cost of very modest decreases in network accuracy. In addition, we propose that a small portion of the benefits achieved when using lower precisions can be forfeited to increase the network size and therefore the accuracy. We evaluate our experiments, using three well-recognized networks and datasets to show its generality. We investigate the trade-offs and highlight the benefits of using lower precisions in terms of energy and memory footprint. version:1
arxiv-1612-03928 | Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer | http://arxiv.org/abs/1612.03928 | id:1612.03928 author:Sergey Zagoruyko, Nikos Komodakis category:cs.CV  published:2016-12-12 summary:Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures. version:1
arxiv-1612-03925 | 3D fully convolutional networks for subcortical segmentation in MRI: A large-scale study | http://arxiv.org/abs/1612.03925 | id:1612.03925 author:J. Dolz, C. Desrosiers, I. Ben Ayed category:cs.CV  published:2016-12-12 summary:This study investigates a 3D and fully convolutional neural network (CNN) for subcortical brain structure segmentation in MRI. 3D CNN architectures have been generally avoided due to their computational and memory requirements during inference. We address the problem via small kernels, allowing deeper architectures. We further model both local and global context by embedding intermediate-layer outputs in the final prediction, which encourages consistency between features extracted at different scales and embeds fine-grained information directly in the segmentation process. Our model is efficiently trained end-to-end on a graphics processing unit (GPU), in a single stage, exploiting the dense inference capabilities of fully CNNs. We performed comprehensive experiments over two publicly available data sets. First, we demonstrate a state-of-the-art performance on the ISBR dataset. Then, we report a {\em large-scale} multi-site evaluation over 1112 unregistered subject data sets acquired from 17 different sites (ABIDE data set), with ages ranging from 7 to 64 years, showing that our method is robust to various acquisition protocols, demographics and clinical factors. Our method yielded segmentations that are highly consistent with a standard atlas-based approach, while running in a fraction of the time needed by atlas-based methods and avoiding registration/normalization steps. This makes it convenient for massive multi-site neuroanatomical imaging studies. To the best of our knowledge, our work is the first to study subcortical structure segmentation on such large-scale and heterogeneous data. version:1
arxiv-1612-03900 | Deep Supervised Hashing with Triplet Labels | http://arxiv.org/abs/1612.03900 | id:1612.03900 author:Xiaofang Wang, Yi Shi, Kris M. Kitani category:cs.CV  published:2016-12-12 summary:Hashing is one of the most popular and powerful approximate nearest neighbor search techniques for large-scale image retrieval. Most traditional hashing methods first represent images as off-the-shelf visual features and then produce hashing codes in a separate stage. However, off-the-shelf visual features may not be optimally compatible with the hash code learning procedure, which may result in sub-optimal hash codes. Recently, deep hashing methods have been proposed to simultaneously learn image features and hash codes using deep neural networks and have shown superior performance over traditional hashing methods. Most deep hashing methods are given supervised information in the form of pairwise labels or triplet labels. The current state-of-the-art deep hashing method DPSH~\cite{li2015feature}, which is based on pairwise labels, performs image feature learning and hash code learning simultaneously by maximizing the likelihood of pairwise similarities. Inspired by DPSH~\cite{li2015feature}, we propose a triplet label based deep hashing method which aims to maximize the likelihood of the given triplet labels. Experimental results show that our method outperforms all the baselines on CIFAR-10 and NUS-WIDE datasets, including the state-of-the-art method DPSH~\cite{li2015feature} and all the previous triplet label based deep hashing methods. version:1
arxiv-1612-03897 | Inverse Compositional Spatial Transformer Networks | http://arxiv.org/abs/1612.03897 | id:1612.03897 author:Chen-Hsuan Lin, Simon Lucey category:cs.CV cs.LG  published:2016-12-12 summary:In this paper, we establish a theoretical connection between the classical Lucas & Kanade (LK) algorithm and the emerging topic of Spatial Transformer Networks (STNs). STNs are of interest to the vision and learning communities due to their natural ability to combine alignment and classification within the same theoretical framework. Inspired by the Inverse Compositional (IC) variant of the LK algorithm, we present Inverse Compositional Spatial Transformer Networks (IC-STNs). We demonstrate that IC-STNs can achieve better performance than conventional STNs with less model capacity; in particular, we show superior performance in pure image alignment tasks as well as joint alignment/classification problems on real-world problems. version:1
arxiv-1612-03871 | Knowledge Completion for Generics using Guided Tensor Factorization | http://arxiv.org/abs/1612.03871 | id:1612.03871 author:Hanie Sedghi, Ashish Sabharwal category:cs.AI cs.LG stat.ML  published:2016-12-12 summary:We consider knowledge base (KB) completion for KBs rich in facts about common nouns (generics), such as "trees produce oxygen" or "dogs have tails". While KB completion has received much attention for named entity KBs, little emphasis has been placed on generics despite their importance for capturing general knowledge. Compared with named entity KBs such as Freebase, KBs about generics have more complex underlying regularities, are substantially more incomplete, and violate the commonly used locally closed world assumption (LCWA). Consequently, existing completion methods struggle with this new task, and the commonly used evaluation metrics become less meaningful. To address these challenges, we make three contributions: (a) a tensor factorization approach that achieves state-of-the-art results by incorporating external knowledge about relation schema and entity taxonomy, (b) taxonomy guided submodular active learning to efficiently collect additional annotations to address KB incompleteness, and (c) a more appropriate metric (yield at high precision) along with a constant-factor deterministic approximation algorithm to compute it cost-effectively with only a logarithmic number of human annotations. An empirical evaluation shows that our techniques achieve state-of-the-art results on two novel generics KBs about elementary level science. version:1
arxiv-1612-02842 | Deep Overcomplete Tensor Rank-Decompositions | http://arxiv.org/abs/1612.02842 | id:1612.02842 author:Andrew Stevens, Yunchen Pu, Yannan Sun, Greg Spell, Lawrence Carin category:stat.ML cs.LG  published:2016-12-08 summary:We introduce new dictionary learning methods for tensor-variate data. Our model need not be separable and we infer the tensor-rank of each dictionary atom. This is possible through the novel combination and extension of beta-process factor analysis (BPFA) and the multiplicative gamma process CANDECOMP/PARAFAC (MGP-CP). We also extend our tensor factor analysis (TFA) model to a deep convolutional setting. We test our approach on image processing and classification tasks achieving state of the art results for inpainting and Caltech 101. The experiments also show that atom-rank impacts overcompleteness and sparsity. version:2
arxiv-1612-03839 | Orthogonal Tensor Decompositions via Two-Mode Higher-Order SVD (HOSVD) | http://arxiv.org/abs/1612.03839 | id:1612.03839 author:Miaoyan Wang, Yun S. Song category:cs.LG stat.ML  published:2016-12-12 summary:Tensor decompositions have rich applications in statistics and machine learning, and developing efficient, accurate algorithms for the problem has received much attention recently. Here, we present a new method built on Kruskal's uniqueness theorem to decompose symmetric, nearly orthogonally decomposable tensors. Unlike the classical higher-order singular value decomposition which unfolds a tensor along a single mode, we consider unfoldings along two modes and use rank-1 constraints to characterize the underlying components. This tensor decomposition method provably handles a greater level of noise compared to previous methods and achieves a high estimation accuracy. Numerical results demonstrate that our algorithm is robust to various noise distributions and that it performs especially favorably as the order increases. version:1
arxiv-1612-03809 | Generalizable Features From Unsupervised Learning | http://arxiv.org/abs/1612.03809 | id:1612.03809 author:Mehdi Mirza, Aaron Courville, Yoshua Bengio category:stat.ML cs.CV cs.LG  published:2016-12-12 summary:Humans learn a predictive model of the world and use this model to reason about future events and the consequences of actions. In contrast to most machine predictors, we exhibit an impressive ability to generalize to unseen scenarios and reason intelligently in these settings. One important aspect of this ability is physical intuition(Lake et al., 2016). In this work, we explore the potential of unsupervised learning to find features that promote better generalization to settings outside the supervised training distribution. Our task is predicting the stability of towers of square blocks. We demonstrate that an unsupervised model, trained to predict future frames of a video sequence of stable and unstable block configurations, can yield features that support extrapolating stability prediction to blocks configurations outside the training set distribution version:1
arxiv-1612-03791 | Neural Machine Translation by Minimising the Bayes-risk with Respect to Syntactic Translation Lattices | http://arxiv.org/abs/1612.03791 | id:1612.03791 author:Felix Stahlberg, Adrià de Gispert, Eva Hasler, Bill Byrne category:cs.CL  published:2016-12-12 summary:We present a novel scheme to combine neural machine translation (NMT) with traditional statistical machine translation (SMT). Our approach borrows ideas from linearised lattice minimum Bayes-risk decoding for SMT. The NMT score is combined with the Bayes-risk of the translation according the SMT lattice. This makes our approach much more flexible than $n$-best list or lattice rescoring as the neural decoder is not restricted to the SMT search space. We show an efficient and simple way to integrate risk estimation into the NMT decoder. We test our method on English-German and Japanese-English and report significant gains over lattice rescoring on several data sets for both single and ensembled NMT. version:1
arxiv-1612-03789 | A Unit Selection Methodology for Music Generation Using Deep Neural Networks | http://arxiv.org/abs/1612.03789 | id:1612.03789 author:Mason Bretan, Gil Weinberg, Larry Heck category:cs.SD cs.AI cs.LG  published:2016-12-12 summary:Several methods exist for a computer to generate music based on data including Markov chains, recurrent neural networks, recombinancy, and grammars. We explore the use of unit selection and concatenation as a means of generating music using a procedure based on ranking, where, we consider a unit to be a variable length number of measures of music. We first examine whether a unit selection method, that is restricted to a finite size unit library, can be sufficient for encompassing a wide spectrum of music. We do this by developing a deep autoencoder that encodes a musical input and reconstructs the input by selecting from the library. We then describe a generative model that combines a deep structured semantic model (DSSM) with an LSTM to predict the next unit, where units consist of four, two, and one measures of music. We evaluate the generative model using objective metrics including mean rank and accuracy and with a subjective listening test in which expert musicians are asked to complete a forced-choiced ranking task. We compare our model to a note-level generative baseline that consists of a stacked LSTM trained to predict forward by one note. version:1
arxiv-1612-03780 | Online Reinforcement Learning for Real-Time Exploration in Continuous State and Action Markov Decision Processes | http://arxiv.org/abs/1612.03780 | id:1612.03780 author:Ludovic Hofer, Hugo Gimbert category:cs.AI cs.LG  published:2016-12-12 summary:This paper presents a new method to learn online policies in continuous state, continuous action, model-free Markov decision processes, with two properties that are crucial for practical applications. First, the policies are implementable with a very low computational cost: once the policy is computed, the action corresponding to a given state is obtained in logarithmic time with respect to the number of samples used. Second, our method is versatile: it does not rely on any a priori knowledge of the structure of optimal policies. We build upon the Fitted Q-iteration algorithm which represents the $Q$-value as the average of several regression trees. Our algorithm, the Fitted Policy Forest algorithm (FPF), computes a regression forest representing the Q-value and transforms it into a single tree representing the policy, while keeping control on the size of the policy using resampling and leaf merging. We introduce an adaptation of Multi-Resolution Exploration (MRE) which is particularly suited to FPF. We assess the performance of FPF on three classical benchmarks for reinforcement learning: the "Inverted Pendulum", the "Double Integrator" and "Car on the Hill" and show that FPF equals or outperforms other algorithms, although these algorithms rely on the use of particular representations of the policies, especially chosen in order to fit each of the three problems. Finally, we exhibit that the combination of FPF and MRE allows to find nearly optimal solutions in problems where $\epsilon$-greedy approaches would fail. version:1
arxiv-1612-03779 | PoseAgent: Budget-Constrained 6D Object Pose Estimation via Reinforcement Learning | http://arxiv.org/abs/1612.03779 | id:1612.03779 author:Alexander Krull, Eric Brachmann, Sebastian Nowozin, Frank Michel, Jamie Shotton, Carsten Rother category:cs.CV  published:2016-12-12 summary:State-of-the-art computer vision algorithms often achieve efficiency by making discrete choices about which hypotheses to explore next. This allows allocation of computational resources to promising candidates, however, such decisions are non-differentiable. As a result, these algorithms are hard to train in an end-to-end fashion. In this work we propose to learn an efficient algorithm for the task of 6D object pose estimation. Our system optimizes the parameters of an existing state-of-the art pose estimation system using reinforcement learning, where the pose estimation system now becomes the stochastic policy, parametrized by a CNN. Additionally, we present an efficient training algorithm that dramatically reduces computation time. We show empirically that our learned pose estimation procedure makes better use of limited resources and improves upon the state-of-the-art on challenging datasets. Our approach enables differentiable end-to-end training of complex algorithmic pipelines and learns to make optimal use of a given computational budget. version:1
arxiv-1612-03777 | Next-Flow: Hybrid Multi-Tasking with Next-Frame Prediction to Boost Optical-Flow Estimation in the Wild | http://arxiv.org/abs/1612.03777 | id:1612.03777 author:Nima Sedaghat category:cs.CV  published:2016-12-12 summary:CNN-based optical flow estimators have attracted attentions recently, mainly due to their impressive speed. As successful as they've been on synthetic datasets, they are still far behind the classical methods in real-world scenarios, mainly due to lack of flow ground-truth. In the current work, we seek to boost CNN-based flow estimation in real scenes with the help of the freely available self-supervised task of next-frame prediction. To this end we train the network in a hybrid way, providing it with a mixture of synthetic and real videos. With the help of a novel time-variant multi-tasking architecture, the network decides which of the tasks to learn at each point of time, depending on the availability of ground-truth. Our proposed method improves optical flow estimation in real scenes dramatically. We also experiment with prediction of "next-flow" instead of estimation of the current flow, which is intuitively more related to the task of next-frame prediction and improve the results even more. We report and evaluate results both qualitatively and quantitatively. The latter is done by training a single-stream action classifier on the estimated flow fields on UCF101 & HMDB51 and demonstrate high improvements of accuracy over the baseline: 10.2% and 9.6% respectively. Also as a side product of this work, we report significant improvements over state-of-the-art results in the task of next-frame prediction. version:1
arxiv-1612-03770 | Neurogenesis Deep Learning | http://arxiv.org/abs/1612.03770 | id:1612.03770 author:Timothy J. Draelos, Nadine E. Miner, Christopher C. Lamb, Craig M. Vineyard, Kristofor D. Carlson, Conrad D. James, James B. Aimone category:cs.NE cs.LG stat.ML  published:2016-12-12 summary:Neural machine learning methods, such as deep neural networks (DNN), have achieved remarkable success in a number of complex data processing tasks. These methods have arguably had their strongest impact on tasks such as image and audio processing - data processing domains in which humans have long held clear advantages over conventional algorithms. In contrast to biological neural systems, which are capable of learning continuously, deep artificial networks have a limited ability for incorporating new information in an already trained network. As a result, methods for continuous learning are potentially highly impactful in enabling the application of deep networks to dynamic data sets. Here, inspired by the process of adult neurogenesis in the hippocampus, we explore the potential for adding new neurons to deep layers of artificial neural networks in order to facilitate their acquisition of novel information while preserving previously trained data representations. Our results on the MNIST handwritten digit dataset and the NIST SD 19 dataset, which includes lower and upper case letters and digits, demonstrate that neurogenesis is well suited for addressing the stability-plasticity dilemma that has long challenged adaptive machine learning algorithms. version:1
arxiv-1612-03769 | Context-aware Sentiment Word Identification: sentiword2vec | http://arxiv.org/abs/1612.03769 | id:1612.03769 author:Yushi Yao, Guangjian Li category:cs.CL cs.AI  published:2016-12-12 summary:Traditional sentiment analysis often uses sentiment dictionary to extract sentiment information in text and classify documents. However, emerging informal words and phrases in user generated content call for analysis aware to the context. Usually, they have special meanings in a particular context. Because of its great performance in representing inter-word relation, we use sentiment word vectors to identify the special words. Based on the distributed language model word2vec, in this paper we represent a novel method about sentiment representation of word under particular context, to be detailed, to identify the words with abnormal sentiment polarity in long answers. Result shows the improved model shows better performance in representing the words with special meaning, while keep doing well in representing special idiomatic pattern. Finally, we will discuss the meaning of vectors representing in the field of sentiment, which may be different from general object-based conditions. version:1
arxiv-1612-03762 | From narrative descriptions to MedDRA: automagically encoding adverse drug reactions | http://arxiv.org/abs/1612.03762 | id:1612.03762 author:Carlo Combi, Margherita Zorzi, Gabriele Pozzani, Ugo Moretti category:cs.CL  published:2016-12-12 summary:The collection of narrative spontaneous reports is an irreplaceable source for the prompt detection of suspected adverse drug reactions (ADRs): qualified domain experts manually revise a huge amount of narrative descriptions and then encode texts according to MedDRA standard terminology. The manual annotation of narrative documents with medical terminology is a subtle and expensive task, since the number of reports is growing up day-by-day. MagiCoder, a Natural Language Processing algorithm, is proposed for the automatic encoding of free-text descriptions into MedDRA terms. MagiCoder procedure is efficient in terms of computational complexity (in particular, it is linear in the size of the narrative input and the terminology). We tested it on a large dataset of about 4500 manually revised reports, by performing an automated comparison between human and MagiCoder revisions. For the current base version of MagiCoder, we measured: on short descriptions, an average recall of $86\%$ and an average precision of $88\%$; on medium-long descriptions (up to 255 characters), an average recall of $64\%$ and an average precision of $63\%$. From a practical point of view, MagiCoder reduces the time required for encoding ADR reports. Pharmacologists have simply to review and validate the MagiCoder terms proposed by the application, instead of choosing the right terms among the 70K low level terms of MedDRA. Such improvement in the efficiency of pharmacologists' work has a relevant impact also on the quality of the subsequent data analysis. We developed MagiCoder for the Italian pharmacovigilance language. However, our proposal is based on a general approach, not depending on the considered language nor the term dictionary. version:1
arxiv-1612-03716 | COCO-Stuff: Thing and Stuff Classes in Context | http://arxiv.org/abs/1612.03716 | id:1612.03716 author:Holger Caesar, Jasper Uijlings, Vittorio Ferrari category:cs.CV  published:2016-12-12 summary:Semantic classes can be either things (objects with a well-defined shape, e.g. car, person) or stuff (amorphous background regions, e.g. grass, sky). While lots of classification and detection works focus on thing classes, less attention has been given to stuff classes. Nonetheless, stuff classes are important as they allow to explain important aspects of an image, including (1) scene type; (2) which thing classes are likely to be present and their location (determined through contextual reasoning); (3) physical attributes, material types and geometric properties of the scene. To understand stuff and things in context we annotate 10,000 images of the COCO dataset with a broad range of stuff classes, using a specialized stuff annotation protocol allowing us to efficiently label each pixel. On this dataset, we analyze several aspects: (a) the importance of stuff and thing classes in terms of their surface cover and how frequently they are mentioned in image captions; (b) the importance of several visual criteria to discriminate stuff and thing classes; (c) we study the spatial relations between stuff and things, highlighting the rich contextual relations that make our dataset unique. Furthermore, we show experimentally how modern semantic segmentation methods perform on stuff and thing classes and answer the question whether stuff is easier to segment than things. We release our new dataset and the trained models online, hopefully promoting further research on stuff and stuff-thing contextual relations. version:1
arxiv-1612-03707 | Empirical Evaluation of A New Approach to Simplifying Long Short-term Memory (LSTM) | http://arxiv.org/abs/1612.03707 | id:1612.03707 author:Yuzhen Lu category:cs.NE  published:2016-12-12 summary:The standard LSTM, although it succeeds in the modeling long-range dependences, suffers from a highly complex structure that can be simplified through modifications to its gate units. This paper was to perform an empirical comparison between the standard LSTM and three new simplified variants that were obtained by eliminating input signal, bias and hidden unit signal from individual gates, on the tasks of modeling two sequence datasets. The experiments show that the three variants, with reduced parameters, can achieve comparable performance with the standard LSTM. Due attention should be paid to turning the learning rate to achieve high accuracies version:1
arxiv-1612-03705 | Segmentation of large images based on super-pixels and community detection in graphs | http://arxiv.org/abs/1612.03705 | id:1612.03705 author:Oscar A. C. Linares, Glenda Michele Botelho, Francisco Aparecido Rodrigues, João Batista Neto category:cs.CV cs.AI  published:2016-12-12 summary:Image segmentation has many applications which range from machine learning to medical diagnosis. In this paper, we propose a framework for the segmentation of images based on super-pixels and algorithms for community identification in graphs. The super-pixel pre-segmentation step reduces the number of nodes in the graph, rendering the method the ability to process large images. Moreover, community detection algorithms provide more accurate segmentation than traditional approaches, such as those based on spectral graph partition. We also compare our method with two algorithms: a) the graph-based approach by Felzenszwalb and Huttenlocher and b) the contour-based method by Arbelaez. Results have shown that our method provides more precise segmentation and is faster than both of them. version:1
arxiv-1612-03689 | Poincaré inequalities on intervals -- application to sensitivity analysis | http://arxiv.org/abs/1612.03689 | id:1612.03689 author:Olivier Roustant, Franck Barthe, Bertrand Iooss category:math.ST math.PR stat.ML stat.TH  published:2016-12-12 summary:The development of global sensitivity analysis of numerical model outputs has recently raised new issues on 1-dimensional Poincar\'e inequalities. Typically two kind of sensitivity indices are linked by a Poincar\'e type inequality, which provide upper bounds of the most interpretable index by using the other one, cheaper to compute. This allows performing a low-cost screening of unessential variables. The efficiency of this screening then highly depends on the accuracy of the upper bounds in Poincar\'e inequalities. The novelty in the questions concern the wide range of probability distributions involved, which are often truncated on intervals. After providing an overview of the existing knowledge and techniques, we add some theory about Poincar\'e constants on intervals, with improvements for symmetric intervals. Then we exploit the spectral interpretation for computing exact value of Poincar\'e constants of any admissible distribution on a given interval. We give semi-analytical results for some frequent distributions (truncated exponential, triangular, truncated normal), and present a numerical method in the general case. Finally, an application is made to a hydrological problem, showing the benefits of the new results in Poincar\'e inequalities to sensitivity analysis. version:1
arxiv-1612-03663 | Analysis and Optimization of Loss Functions for Multiclass, Top-k, and Multilabel Classification | http://arxiv.org/abs/1612.03663 | id:1612.03663 author:Maksim Lapin, Matthias Hein, Bernt Schiele category:cs.CV cs.LG stat.ML  published:2016-12-12 summary:Top-k error is currently a popular performance measure on large scale image classification benchmarks such as ImageNet and Places. Despite its wide acceptance, our understanding of this metric is limited as most of the previous research is focused on its special case, the top-1 error. In this work, we explore two directions that shed more light on the top-k error. First, we provide an in-depth analysis of established and recently proposed single-label multiclass methods along with a detailed account of efficient optimization algorithms for them. Our results indicate that the softmax loss and the smooth multiclass SVM are surprisingly competitive in top-k error uniformly across all k, which can be explained by our analysis of multiclass top-k calibration. Further improvements for a specific k are possible with a number of proposed top-k loss functions. Second, we use the top-k methods to explore the transition from multiclass to multilabel learning. In particular, we find that it is possible to obtain effective multilabel classifiers on Pascal VOC using a single label per image for training, while the gap between multiclass and multilabel methods on MS COCO is more significant. Finally, our contribution of efficient algorithms for training with the considered top-k and multilabel loss functions is of independent interest. version:1
arxiv-1612-03659 | Unraveling reported dreams with text analytics | http://arxiv.org/abs/1612.03659 | id:1612.03659 author:Iris Hendrickx, Louis Onrust, Florian Kunneman, Ali Hürriyetoğlu, Antal van den Bosch, Wessel Stoop category:cs.CL  published:2016-12-12 summary:We investigate what distinguishes reported dreams from other personal narratives. The continuity hypothesis, stemming from psychological dream analysis work, states that most dreams refer to a person's daily life and personal concerns, similar to other personal narratives such as diary entries. Differences between the two texts may reveal the linguistic markers of dream text, which could be the basis for new dream analysis work and for the automatic detection of dream descriptions. We used three text analytics methods: text classification, topic modeling, and text coherence analysis, and applied these methods to a balanced set of texts representing dreams, diary entries, and other personal stories. We observed that dream texts could be distinguished from other personal narratives nearly perfectly, mostly based on the presence of uncertainty markers and descriptions of scenes. Important markers for non-dream narratives are specific time expressions and conversational expressions. Dream texts also exhibit a lower discourse coherence than other personal narratives. version:1
arxiv-1612-03651 | FastText.zip: Compressing text classification models | http://arxiv.org/abs/1612.03651 | id:1612.03651 author:Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, Hérve Jégou, Tomas Mikolov category:cs.CL cs.LG  published:2016-12-12 summary:We consider the problem of producing compact architectures for text classification, such that the full model fits in a limited amount of memory. After considering different solutions inspired by the hashing literature, we propose a method built upon product quantization to store word embeddings. While the original technique leads to a loss in accuracy, we adapt this method to circumvent quantization artefacts. Our experiments carried out on several benchmarks show that our approach typically requires two orders of magnitude less memory than fastText while being only slightly inferior with respect to accuracy. As a result, it outperforms the state of the art by a good margin in terms of the compromise between memory usage and accuracy. version:1
arxiv-1612-03630 | A Binary Convolutional Encoder-decoder Network for Real-time Natural Scene Text Processing | http://arxiv.org/abs/1612.03630 | id:1612.03630 author:Zichuan Liu, Yixing Li, Fengbo Ren, Hao Yu category:cs.CV  published:2016-12-12 summary:In this paper, we develop a binary convolutional encoder-decoder network (B-CEDNet) for natural scene text processing (NSTP). It converts a text image to a class-distinguished salience map that reveals the categorical, spatial and morphological information of characters. The existing solutions are either memory consuming or run-time consuming that cannot be applied to real-time applications on resource-constrained devices such as advanced driver assistance systems. The developed network can process multiple regions containing characters by one-off forward operation, and is trained to have binary weights and binary feature maps, which lead to both remarkable inference run-time speedup and memory usage reduction. By training with over 200, 000 synthesis scene text images (size of $32\times128$), it can achieve $90\%$ and $91\%$ pixel-wise accuracy on ICDAR-03 and ICDAR-13 datasets. It only consumes $4.59\ ms$ inference run-time realized on GPU with a small network size of 2.14 MB, which is up to $8\times$ faster and $96\%$ smaller than it full-precision version. version:1
arxiv-1612-03628 | VIBIKNet: Visual Bidirectional Kernelized Network for Visual Question Answering | http://arxiv.org/abs/1612.03628 | id:1612.03628 author:Marc Bolaños, Álvaro Peris, Francisco Casacuberta, Petia Radeva category:cs.CV cs.CL  published:2016-12-12 summary:In this paper, we address the problem of visual question answering by proposing a novel model, called VIBIKNet. Our model is based on integrating Kernelized Convolutional Neural Networks and Long-Short Term Memory units to generate an answer given a question about an image. We prove that VIBIKNet is an optimal trade-off between accuracy and computational load, in terms of memory and time consumption. We validate our method on the VQA challenge dataset and compare it to the top performing methods in order to illustrate its performance and speed. version:1
arxiv-1612-03615 | Kernel-based Reconstruction of Space-time Functions on Dynamic Graphs | http://arxiv.org/abs/1612.03615 | id:1612.03615 author:Daniel Romero, Vassilis N. Ioannidis, Georgios B. Giannakis category:cs.LG stat.ML  published:2016-12-12 summary:Graph-based methods pervade the inference toolkits of numerous disciplines including sociology, biology, neuroscience, physics, chemistry, and engineering. A challenging problem encountered in this context pertains to determining the attributes of a set of vertices given those of another subset at possibly different time instants. Leveraging spatiotemporal dynamics can drastically reduce the number of observed vertices, and hence the cost of sampling. Alleviating the limited flexibility of existing approaches, the present paper broadens the existing kernel-based graph function reconstruction framework to accommodate time-evolving functions over possibly time-evolving topologies. This approach inherits the versatility and generality of kernel-based methods, for which no knowledge on distributions or second-order statistics is required. Systematic guidelines are provided to construct two families of space-time kernels with complementary strengths. The first facilitates judicious control of regularization on a space-time frequency plane, whereas the second can afford time-varying topologies. Batch and online estimators are also put forth, and a novel kernel Kalman filter is developed to obtain these estimates at affordable computational cost. Numerical tests with real data sets corroborate the merits of the proposed methods relative to competing alternatives. version:1
arxiv-1612-03597 | Search Personalization with Embeddings | http://arxiv.org/abs/1612.03597 | id:1612.03597 author:Thanh Vu, Dat Quoc Nguyen, Mark Johnson, Dawei Song, Alistair Willis category:cs.IR cs.CL  published:2016-12-12 summary:Recent research has shown that the performance of search personalization depends on the richness of user profiles which normally represent the user's topical interests. In this paper, we propose a new embedding approach to learning user profiles, where users are embedded on a topical interest space. We then directly utilize the user profiles for search personalization. Experiments on query logs from a major commercial web search engine demonstrate that our embedding approach improves the performance of the search engine and also achieves better search performance than other strong baselines. version:1
arxiv-1612-03590 | Statistics of Visual Responses to Object Stimuli from Primate AIT Neurons to DNN Neurons | http://arxiv.org/abs/1612.03590 | id:1612.03590 author:Qiulei Dong, Zhanyi Hu category:cs.CV q-bio.NC  published:2016-12-12 summary:Cadieu et al. (Cadieu,2014) reported that deep neural networks(DNNs) could rival the representation of primate inferotemporal cortex for object recognition. Lehky et al. (Lehky,2011) provided a statistical analysis on neural responses to object stimuli in primate AIT cortex. They found the intrinsic dimensionality of object representations in AIT cortex is around 100 (Lehky,2014). Considering the outstanding performance of DNNs in object recognition, it is worthwhile investigating whether the responses of DNN neurons have similar response statistics to those of AIT neurons. Following Lehky et al.'s works, we analyze the response statistics to image stimuli and the intrinsic dimensionality of object representations of DNN neurons. Our findings show in terms of kurtosis and Pareto tail index, the response statistics on single-neuron selectivity and population sparseness of DNN neurons are fundamentally different from those of IT neurons except some special cases. By increasing the number of neurons and stimuli, the conclusions could alter substantially. In addition, with the ascendancy of the convolutional layers of DNNs, the single-neuron selectivity and population sparseness of DNN neurons increase, indicating the last convolutional layer is to learn features for object representations, while the following fully-connected layers are to learn categorization features. It is also found that a sufficiently large number of stimuli and neurons are necessary for obtaining a stable dimensionality. To our knowledge, this is the first work to analyze the response statistics of DNN neurons comparing with AIT neurons, and our results provide not only some insights into the discrepancy of DNN neurons with respect to IT neurons in object representation, but also shed some light on possible outcomes of IT neurons when the number of recorded neurons and stimuli is beyond the level in (Lehky,2011,2014). version:1
arxiv-1612-04197 | An Artificial Neural Networks based Temperature Prediction Framework for Network-on-Chip based Multicore Platform | http://arxiv.org/abs/1612.04197 | id:1612.04197 author:Sandeep Aswath Narayana category:cs.DC cs.AR cs.NE  published:2016-12-12 summary:Continuous improvement in silicon process technologies has made possible the integration of hundreds of cores on a single chip. However, power and heat have become dominant constraints in designing these massive multicore chips causing issues with reliability, timing variations and reduced lifetime of the chips. Dynamic Thermal Management (DTM) is a solution to avoid high temperatures on the die. Typical DTM schemes only address core level thermal issues. However, the Network-on-chip (NoC) paradigm, which has emerged as an enabling methodology for integrating hundreds to thousands of cores on the same die can contribute significantly to the thermal issues. Moreover, the typical DTM is triggered reactively based on temperature measurements from on-chip thermal sensor requiring long reaction times whereas predictive DTM method estimates future temperature in advance, eliminating the chance of temperature overshoot. Artificial Neural Networks (ANNs) have been used in various domains for modeling and prediction with high accuracy due to its ability to learn and adapt. This thesis concentrates on designing an ANN prediction engine to predict the thermal profile of the cores and Network-on-Chip elements of the chip. This thermal profile of the chip is then used by the predictive DTM that combines both core level and network level DTM techniques. On-chip wireless interconnect which is recently envisioned to enable energy-efficient data exchange between cores in a multicore environment, will be used to provide a broadcast-capable medium to efficiently distribute thermal control messages to trigger and manage the DTM schemes. version:1
arxiv-1612-03557 | Text-guided Attention Model for Image Captioning | http://arxiv.org/abs/1612.03557 | id:1612.03557 author:Jonghwan Mun, Minsu Cho, Bohyung Han category:cs.CV  published:2016-12-12 summary:Visual attention plays an important role to understand images and demonstrates its effectiveness in generating natural language descriptions of images. On the other hand, recent studies show that language associated with an image can steer visual attention in the scene during our cognitive process. Inspired by this, we introduce a text-guided attention model for image captioning, which learns to drive visual attention using associated captions. For this model, we propose an exemplar-based learning approach that retrieves from training data associated captions with each image, and use them to learn attention on visual features. Our attention model enables to describe a detailed state of scenes by distinguishing small or confusable objects effectively. We validate our model on MS-COCO Captioning benchmark and achieve the state-of-the-art performance in standard metrics. version:1
arxiv-1612-03551 | Reading Comprehension using Entity-based Memory Network | http://arxiv.org/abs/1612.03551 | id:1612.03551 author:Xun Wang, Katsuhito Sudoh, Masaaki Nagata, Tomohide Shibata, Kawahara Daisuke, Kurohashi Sadao category:cs.CL cs.AI  published:2016-12-12 summary:This paper introduces a novel neural network model for question answering, the \emph{entity-based memory network}. It enhances neural networks' ability of representing and calculating information over a long period by keeping records of entities contained in text. The core component is a memory pool which comprises entities' states. These entities' states are continuously updated according to the input text. Questions with regard to the input text are used to search the memory pool for related entities and answers are further predicted based on the states of retrieved entities. Compared with previous memory network models, the proposed model is capable of handling fine-grained information and more sophisticated relations based on entities. We formulated several different tasks as question answering problems and tested the proposed model. Experiments reported satisfying results. version:1
arxiv-1612-03550 | PIGMIL: Positive Instance Detection via Graph Updating for Multiple Instance Learning | http://arxiv.org/abs/1612.03550 | id:1612.03550 author:Dongkuan Xu, Jia Wu, Wei Zhang, Yingjie Tian category:cs.CV  published:2016-12-12 summary:Positive instance detection, especially for these in positive bags (true positive instances, TPIs), plays a key role for multiple instance learning (MIL) arising from a specific classification problem only provided with bag (a set of instances) label information. However, most previous MIL methods on this issue ignore the global similarity among positive instances and that negative instances are non-i.i.d., usually resulting in the detection of TPI not precise and sensitive to outliers. To the end, we propose a positive instance detection via graph updating for multiple instance learning, called PIGMIL, to detect TPI accurately. PIGMIL selects instances from working sets (WSs) of some working bags (WBs) as positive candidate pool (PCP). The global similarity among positive instances and the robust discrimination of instances of PCP from negative instances are measured to construct the consistent similarity and discrimination graph (CSDG). As a result, the primary goal (i.e. TPI detection) is transformed into PCP updating, which is approximated efficiently by updating CSDG with a random walk ranking algorithm and an instance updating strategy. At last bags are transformed into feature representation vector based on the identified TPIs to train a classifier. Extensive experiments demonstrate the high precision of PIGMIL's detection of TPIs and its excellent performance compared to classic baseline MIL methods. version:1
arxiv-1612-03530 | Recurrent Attentional Model for No-Reference Image Quality Assessment | http://arxiv.org/abs/1612.03530 | id:1612.03530 author:Diqi Chen, Yizhou Wang, Tianfu Wu, Wen Gao category:cs.CV  published:2016-12-12 summary:This paper presents a recurrent attentional model (RAM) for general no-reference image quality assessment (NR-IQA), that is to predict the perceptual quality score for an input image without using any reference image and/or prior knowledge regarding underlying distortions. The proposed RAM is inspired by the well known visual attention mechanism, both covert and overt, which affects many aspects of visual perception including image quality assessment. The attentional mechanism is, however, largely ignored in the NR-IQA literature. The proposed RAM hypothesizes that the attentional scanning path in an image should contain intrinsic information for IQA. The RAM thus consists of three components: a glimpse sub-network analyzing the quality at a fixation using multi-scale information, a location sub-network selecting where to look next by sampling a stochastic node, and a recurrent network aggregating information along the scanning path to compute the final prediction. The RAM is formulated under multi-task learning for the joint prediction of distortion type and image quality score and for the REINFORCE rule~\cite{williams1992simple} used to handle the stochastic node. The RAM is trained through back-propagation. In experiments, the RAM is tested on the TID2008 dataset with promising performance obtained, which shows the effectiveness of the proposed RAM. Furthermore, the RAM is very efficient in the sense that a small number of glimpses are used usually in testing. version:1
arxiv-1612-02590 | Scene Flow Estimation: A Survey | http://arxiv.org/abs/1612.02590 | id:1612.02590 author:Zike Yan, Xuezhi Xiang category:cs.CV  published:2016-12-08 summary:This paper is the first to review the scene flow estimation field to the best of our knowledge, which analyzes and compares methods, technical challenges, evaluation methodologies and performance of scene flow estimation. Existing algorithms are categorized in terms of scene representation, data source, and calculation scheme, and the pros and cons in each category are compared briefly. The datasets and evaluation protocols are enumerated, and the performance of the most representative methods is presented. A future vision is illustrated with few questions arisen for discussion. This survey presents a general introduction and analysis of scene flow estimation. version:2
arxiv-1612-03494 | Flu Detector: Estimating influenza-like illness rates from online user-generated content | http://arxiv.org/abs/1612.03494 | id:1612.03494 author:Vasileios Lampos category:cs.AI cs.CL cs.SI  published:2016-12-11 summary:We provide a brief technical description of an online platform for disease monitoring, titled as the Flu Detector (fludetector.cs.ucl.ac.uk). Flu Detector, in its current version (v.0.5), uses either Twitter or Google search data in conjunction with statistical Natural Language Processing models to estimate the rate of influenza-like illness in the population of England. Its back-end is a live service that collects online data, utilises modern technologies for large-scale text processing, and finally applies statistical inference models that are trained offline. The front-end visualises the various disease rate estimates. Notably, the models based on Google data achieve a high level of accuracy with respect to the most recent four flu seasons in England (2012/13 to 2015/16). This highlighted Flu Detector as having a great potential of becoming a complementary source to the domestic traditional flu surveillance schemes. version:1
arxiv-1612-03480 | Self-calibrating Neural Networks for Dimensionality Reduction | http://arxiv.org/abs/1612.03480 | id:1612.03480 author:Yuansi Chen, Cengiz Pehlevan, Dmitri B. Chklovskii category:cs.LG cs.NE q-bio.NC stat.ML  published:2016-12-11 summary:Recently, a novel family of biologically plausible online algorithms for reducing the dimensionality of streaming data has been derived from the similarity matching principle. In these algorithms, the number of output dimensions can be determined adaptively by thresholding the singular values of the input data matrix. However, setting such threshold requires knowing the magnitude of the desired singular values in advance. Here we propose online algorithms where the threshold is self-calibrating based on the singular values computed from the existing observations. To derive these algorithms from the similarity matching cost function we propose novel regularizers. As before, these online algorithms can be implemented by Hebbian/anti-Hebbian neural networks in which the learning rule depends on the chosen regularizer. We demonstrate both mathematically and via simulation the effectiveness of these online algorithms in various settings. version:1
arxiv-1612-03477 | On Choosing Training and Testing Data for Supervised Algorithms in Ground Penetrating Radar Data for Buried Threat Detection | http://arxiv.org/abs/1612.03477 | id:1612.03477 author:Daniël Reichman, Leslie M. Collins, Jordan M. Malof category:cs.CV  published:2016-12-11 summary:Ground penetrating radar (GPR) is one of the most popular and successful sensing modalities that has been investigated for landmine and subsurface threat detection. Many of the detection algorithms applied to this task are supervised and therefore require labeled examples of target and non-target data for training. Training data most often consists of 2-dimensional images (or patches) of GPR data, from which features are extracted, and provided to the classifier during training and testing. Identifying desirable training and testing locations to extract patches, which we term "keypoints", is well established in the literature. In contrast however, a large variety of strategies have been proposed regarding keypoint utilization (e.g., how many of the identified keypoints should be used at targets, or non-target, locations). Given the variety keypoint utilization strategies that are available, it is very unclear (i) which strategies are best, or (ii) whether the choice of strategy has a large impact on classifier performance. We address these questions by presenting a taxonomy of existing utilization strategies, and then evaluating their effectiveness on a large dataset using many different classifiers and features. We analyze the results and propose a new strategy, called PatchSelect, which outperforms other strategies across all experiments. version:1
arxiv-1612-03450 | Noisy subspace clustering via matching pursuits | http://arxiv.org/abs/1612.03450 | id:1612.03450 author:Michael Tschannen, Helmut Bölcskei category:cs.LG cs.IT math.IT stat.ML  published:2016-12-11 summary:Sparsity-based subspace clustering algorithms have attracted significant attention thanks to their excellent performance in practical applications. A prominent example is the sparse subspace clustering (SSC) algorithm by Elhamifar and Vidal, which performs spectral clustering based on an adjacency matrix obtained by sparsely representing each data point in terms of all the other data points via the Lasso. When the number of data points is large or the dimension of the ambient space is high, the computational complexity of SSC quickly becomes prohibitive. Dyer et al. observed that SSC-OMP obtained by replacing the Lasso by the greedy orthogonal matching pursuit (OMP) algorithm results in significantly lower computational complexity, while often yielding comparable performance. The central goal of this paper is an analytical performance characterization of SSC-OMP for noisy data. Moreover, we introduce and analyze the SSC-MP algorithm, which employs matching pursuit (MP) in lieu of OMP. Both SSC-OMP and SSC-MP are proven to succeed even when the subspaces intersect and when the data points are contaminated by severe noise. The clustering conditions we obtain for SSC-OMP and SSC-MP are similar to those for SSC and for the thresholding-based subspace clustering (TSC) algorithm due to Heckel and B\"olcskei. Analytical results in combination with numerical results indicate that both SSC-OMP and SSC-MP with a data-dependent stopping criterion automatically detect the dimensions of the subspaces underlying the data. Moreover, experiments on synthetic and real data show that SSC-MP compares very favorably to SSC, SSC-OMP, TSC, and the nearest subspace neighbor (NSN) algorithm, both in terms of clustering performance and running time. In addition, we find that, in contrast to SSC-OMP, the performance of SSC-MP is very robust with respect to the choice of parameters in the stopping criteria. version:1
arxiv-1612-03441 | Lock-Free Optimization for Non-Convex Problems | http://arxiv.org/abs/1612.03441 | id:1612.03441 author:Shen-Yi Zhao, Gong-Duo Zhang, Wu-Jun Li category:stat.ML cs.LG  published:2016-12-11 summary:Stochastic gradient descent~(SGD) and its variants have attracted much attention in machine learning due to their efficiency and effectiveness for optimization. To handle large-scale problems, researchers have recently proposed several lock-free strategy based parallel SGD~(LF-PSGD) methods for multi-core systems. However, existing works have only proved the convergence of these LF-PSGD methods for convex problems. To the best of our knowledge, no work has proved the convergence of the LF-PSGD methods for non-convex problems. In this paper, we provide the theoretical proof about the convergence of two representative LF-PSGD methods, Hogwild! and AsySVRG, for non-convex problems. Empirical results also show that both Hogwild! and AsySVRG are convergent on non-convex problems, which successfully verifies our theoretical results. version:1
arxiv-1612-03412 | Non-Redundant Spectral Dimensionality Reduction | http://arxiv.org/abs/1612.03412 | id:1612.03412 author:Yochai Blau, Tomer Michaeli category:cs.LG stat.ML  published:2016-12-11 summary:Spectral dimensionality reduction algorithms are widely used in numerous domains, including for recognition, segmentation, tracking and visualization. However, despite their popularity, these algorithms suffer from a major limitation known as the "repeated Eigen-directions" phenomenon. That is, many of the embedding coordinates they produce typically capture the same direction along the data manifold. This leads to redundant and inefficient representations that do not reveal the true intrinsic dimensionality of the data. In this paper, we propose a general method for avoiding redundancy in spectral algorithms. Our approach relies on replacing the orthogonality constraints underlying those methods by unpredictability constraints. Specifically, we require that each embedding coordinate be unpredictable (in the statistical sense) from all previous ones. We prove that these constraints necessarily prevent redundancy, and provide a simple technique to incorporate them into existing methods. As we illustrate on challenging high-dimensional scenarios, our approach produces significantly more informative and compact representations, which substantially improve visualization and classification tasks. version:1
arxiv-1612-03409 | A New Spectral Method for Latent Variable Models | http://arxiv.org/abs/1612.03409 | id:1612.03409 author:Matteo Ruffini, Marta Casanellas, Ricard Gavaldà category:stat.ML  published:2016-12-11 summary:This paper presents an algorithm for the unsupervised learning of latent variable models from unlabeled sets of data. We base our technique on spectral decomposition, providing a technique that proves to be robust both in theory and in practice. We also describe how to use this algorithm to learn the parameters of two well known text mining models: single topic model and Latent Dirichlet Allocation, providing in both cases an efficient technique to retrieve the parameters to feed the algorithm. We compare the results of our algorithm with those of existing algorithms on synthetic data, and we provide examples of applications to real world text corpora for both single topic model and LDA, obtaining meaningful results. version:1
arxiv-1612-03402 | Improved Quick Hypervolume Algorithm | http://arxiv.org/abs/1612.03402 | id:1612.03402 author:Andrzej Jaszkiewicz category:cs.NE  published:2016-12-11 summary:In this paper, we present an improved version of recently proposed Quick Hypervolume algorithm for calculating exact hypervolume of the space dominated by a set of d-dimensional points. This value is often used as a quality indicator in multiobjective evolutionary algorithms and the efficiency of calculating this indicator is of crucial importance especially in the case of large set or many dimensional spaces. We use a similar divide and conquer scheme as in the original Quick Hypervolume algorithm, we modify, however, the way the problem is split into smaller sub-problems. Through both theoretical analysis and computational study we show that our approach improves computational complexity of the algorithm and running time of its implementation. version:1
arxiv-1612-03382 | Motion Detection Robust to Severe Illumination Changes | http://arxiv.org/abs/1612.03382 | id:1612.03382 author:Sahar Yousefi, M. T. Manzuri Shalmani category:cs.CV 68U10  published:2016-12-11 summary:Recently, there has been a considerable attention to motion detection due to the explosive growth of its application in video analysis and surveillance systems. While good results can be achieved in the previous approaches, accurate motion detection remains a challenging task due to the difficulties raised by illumination variations, occlusion, camouflage, burst physical motion, dynamic texture and environmental changes such as those on climate changes, sunlight changes during a day, etc. In this paper, we propose a novel perpixel motion descriptor for both motion detection and dynamic texture segmentation which outperforms the literature in severe scenarios. The proposed descriptor is based on two complementary three-dimensional-discrete wavelet transform (3D-DWT) and three dimensional wavelet leader. In this approach, a feature vector is extracted for each pixel by applying a novel three dimensional wavelet based motion descriptor. Then, the extracted features are clustered by the well-known k-means algorithm. The experimental results demonstrate the effectiveness of our proposed method compared to the literature motion detection approaches. version:1
arxiv-1612-04158 | Automated Inference on Sociopsychological Impressions of Attractive Female Faces | http://arxiv.org/abs/1612.04158 | id:1612.04158 author:Xiaolin Wu, Xi Zhang, Chang Liu category:cs.CV  published:2016-12-11 summary:This article is a sequel to our earlier paper [24]. Our main objective is to explore the potential of supervised machine learning in face-induced social computing and cognition, riding on the momentum of much heralded successes of face processing, analysis and recognition on the tasks of biometric-based identification. We present a case study of automated statistical inference on sociopsychological perceptions of female faces controlled for race, attractiveness, age and nationality. Like in [24], our empirical evidences point to the possibility of teaching computer vision and machine learning algorithms, using example face images, to predict personality traits and behavioral predisposition. version:1
arxiv-1612-03373 | A probabilistic graphical model approach in 30 m land cover mapping with multiple data sources | http://arxiv.org/abs/1612.03373 | id:1612.03373 author:Jie Wang, Luyan Ji, Xiaomeng Huang, Haohuan Fu, Shiming Xu, Congcong Li category:stat.AP cs.CV  published:2016-12-11 summary:There is a trend to acquire high accuracy land-cover maps using multi-source classification methods, most of which are based on data fusion, especially pixel- or feature-level fusions. A probabilistic graphical model (PGM) approach is proposed in this research for 30 m resolution land-cover mapping with multi-temporal Landsat and MODerate Resolution Imaging Spectroradiometer (MODIS) data. Independent classifiers were applied to two single-date Landsat 8 scenes and the MODIS time-series data, respectively, for probability estimation. A PGM was created for each pixel in Landsat 8 data. Conditional probability distributions were computed based on data quality and reliability by using information selectively. Using the administrative territory of Beijing City (Area-1) and a coastal region of Shandong province, China (Area-2) as study areas, multiple land-cover maps were generated for comparison. Quantitative results show the effectiveness of the proposed method. Overall accuracies promoted from 74.0% (maps acquired from single-temporal Landsat images) to 81.8% (output of the PGM) for Area-1. Improvements can also be seen when using MODIS data and only a single-temporal Landsat image as input (overall accuracy: 78.4% versus 74.0% for Area-1, and 86.8% versus 83.0% for Area-2). Information from MODIS data did not help much when the PGM was applied to cloud free regions of. One of the advantages of the proposed method is that it can be applied where multi-temporal data cannot be simply stacked as a multi-layered image. version:1
arxiv-1612-03989 | A Fast Keypoint Based Hybrid Method for Copy Move Forgery Detection | http://arxiv.org/abs/1612.03989 | id:1612.03989 author:Sunil Kumar, J. V. Desa, Shaktidev Mukherjee category:cs.CV  published:2016-12-11 summary:Copy move forgery detection in digital images has become a very popular research topic in the area of image forensics. Due to the availability of sophisticated image editing tools and ever increasing hardware capabilities, it has become an easy task to manipulate the digital images. Passive forgery detection techniques are more relevant as they can be applied without the prior information about the image in question. Block based techniques are used to detect copy move forgery, but have limitations of large time complexity and sensitivity against affine operations like rotation and scaling. Keypoint based approaches are used to detect forgery in large images where the possibility of significant post processing operations like rotation and scaling is more. A hybrid approach is proposed using different methods for keypoint detection and description. Speeded Up Robust Features (SURF) are used to detect the keypoints in the image and Binary Robust Invariant Scalable Keypoints (BRISK) features are used to describe features at these keypoints. The proposed method has performed better than the existing forgery detection method using SURF significantly in terms of detection speed and is invariant to post processing operations like rotation and scaling. The proposed method is also invariant to other commonly applied post processing operations like adding Gaussian noise and JPEG compression version:1
arxiv-1612-03365 | Multiple Instance Learning: A Survey of Problem Characteristics and Applications | http://arxiv.org/abs/1612.03365 | id:1612.03365 author:Marc-André Carbonneau, Veronika Cheplygina, Eric Granger, Ghyslain Gagnon category:cs.CV cs.AI cs.IR  published:2016-12-11 summary:Multiple instance learning (MIL) is a form of weakly supervised learning where training instances are arranged in sets, called bags, and a label is provided for the entire bag. This formulation is gaining interest because it naturally fits various problems and allows to leverage weakly labeled data. Consequently, it has been used in diverse application fields such as computer vision and document classification. However, learning from bags raises important challenges that are unique to MIL. This paper provides a comprehensive survey of the characteristics which define and differentiate the types of MIL problems. Until now, these problem characteristics have not been formally identified and described. As a result, the variations in performance of MIL algorithms from one data set to another are difficult to explain. In this paper, MIL problem characteristics are grouped into four broad categories: the composition of the bags, the types of data distribution, the ambiguity of instance labels, and the task to be performed. Methods specialized to address each category are reviewed. Then, the extent to which these characteristics manifest themselves in key MIL application areas are described. Finally, experiments are conducted to compare the performance of 16 state-of-the-art MIL methods on selected problem characteristics. This paper provides insight on how the problem characteristics affect MIL algorithms, recommendations for future benchmarking and promising avenues for research. version:1
arxiv-1612-03364 | Technical Report: A Generalized Matching Pursuit Approach for Graph-Structured Sparsity | http://arxiv.org/abs/1612.03364 | id:1612.03364 author:Feng Chen, Baojian Zhou category:cs.LG cs.AI stat.ML  published:2016-12-11 summary:Sparsity-constrained optimization is an important and challenging problem that has wide applicability in data mining, machine learning, and statistics. In this paper, we focus on sparsity-constrained optimization in cases where the cost function is a general nonlinear function and, in particular, the sparsity constraint is defined by a graph-structured sparsity model. Existing methods explore this problem in the context of sparse estimation in linear models. To the best of our knowledge, this is the first work to present an efficient approximation algorithm, namely, Graph-structured Matching Pursuit (Graph-Mp), to optimize a general nonlinear function subject to graph-structured constraints. We prove that our algorithm enjoys the strong guarantees analogous to those designed for linear models in terms of convergence rate and approximation accuracy. As a case study, we specialize Graph-Mp to optimize a number of well-known graph scan statistic models for the connected subgraph detection task, and empirical evidence demonstrates that our general algorithm performs superior over state-of-the-art methods that are designed specifically for the task of connected subgraph detection. version:1
arxiv-1612-03350 | Non-negative Factorization of the Occurrence Tensor from Financial Contracts | http://arxiv.org/abs/1612.03350 | id:1612.03350 author:Zheng Xu, Furong Huang, Louiqa Raschid, Tom Goldstein category:cs.CE cs.LG stat.ML  published:2016-12-10 summary:We propose an algorithm for the non-negative factorization of an occurrence tensor built from heterogeneous networks. We use l0 norm to model sparse errors over discrete values (occurrences), and use decomposed factors to model the embedded groups of nodes. An efficient splitting method is developed to optimize the nonconvex and nonsmooth objective. We study both synthetic problems and a new dataset built from financial documents, resMBS. version:1
arxiv-1612-03349 | An Empirical Study of ADMM for Nonconvex Problems | http://arxiv.org/abs/1612.03349 | id:1612.03349 author:Zheng Xu, Soham De, Mario Figueiredo, Christoph Studer, Tom Goldstein category:math.OC cs.LG  published:2016-12-10 summary:The alternating direction method of multipliers (ADMM) is a common optimization tool for solving constrained and non-differentiable problems. We provide an empirical study of the practical performance of ADMM on several nonconvex applications, including l0 regularized linear regression, l0 regularized image denoising, phase retrieval, and eigenvector computation. Our experiments suggest that ADMM performs well on a broad class of non-convex problems. Moreover, recently proposed adaptive ADMM methods, which automatically tune penalty parameters as the method runs, can improve algorithm efficiency and solution quality compared to ADMM with a non-tuned penalty. version:1
arxiv-1612-03328 | Knowledge Elicitation via Sequential Probabilistic Inference for High-Dimensional Prediction | http://arxiv.org/abs/1612.03328 | id:1612.03328 author:Pedram Daee, Tomi Peltola, Marta Soare, Samuel Kaski category:cs.AI cs.HC cs.LG stat.ML  published:2016-12-10 summary:Prediction in a small-sized sample with a large number of covariates, the "small n, large p" problem, is challenging. This setting is encountered in multiple applications, such as precision medicine, where obtaining additional samples can be extremely costly or even impossible, and extensive research effort has recently been dedicated to finding principled solutions for accurate prediction. However, a valuable source of additional information, domain experts, has not yet been efficiently exploited. We formulate knowledge elicitation generally as a probabilistic inference process, where expert knowledge is sequentially queried to improve predictions. In the specific case of sparse linear regression, where we assume the expert has knowledge about the values of the regression coefficients or about the relevance of the features, we propose an algorithm and computational approximation for fast and efficient interaction, which sequentially identifies the most informative features on which to query expert knowledge. Evaluations of our method in experiments with simulated and real users show improved prediction accuracy already with a small effort from the expert. version:1
arxiv-1612-03319 | Anytime Monte Carlo | http://arxiv.org/abs/1612.03319 | id:1612.03319 author:Lawrence M. Murray, Sumeetpal Singh, Pierre E. Jacob, Anthony Lee category:stat.CO stat.ML  published:2016-12-10 summary:A Monte Carlo algorithm typically simulates a prescribed number of samples, taking some random real time to complete the computations necessary. This work considers the converse: to impose a real-time budget on the computation, so that the number of samples simulated is random. To complicate matters, the real time taken for each simulation may depend on the sample produced, so that the samples themselves are not independent of their number, and a length bias with respect to computation time is introduced. We propose an anytime framework to address this concern. We firstly introduce a continuous-time Markov jump process to chart the progress of the computation in real time. With respect to the target distribution, the stationary distribution of this process is length-biased by computation time. We introduce a multiple chain construction to eliminate this length bias for any Markov chain Monte Carlo (MCMC) algorithm. Exploiting this debiasing technique yields MCMC algorithms that may be interrupted at any real time to obtain a sample from the target distribution. We call these class of interruptible algorithms anytime Monte Carlo algorithms. The utility of these algorithms is demonstrated on a large-scale Sequential Monte Carlo Squared implementation using four billion particles in total, distributed across a cluster of 128 graphics processing units on the Amazon EC2 service, providing approximately 200000-way parallelism. The anytime framework is used to impose a real-time budget on move steps, ensuring that all processors are simultaneously ready for the resampling step, demonstrably reducing wait times. version:1
arxiv-1612-03301 | Gradient Coding | http://arxiv.org/abs/1612.03301 | id:1612.03301 author:Rashish Tandon, Qi Lei, Alexandros G. Dimakis, Nikos Karampatziakis category:stat.ML cs.DC cs.IT cs.LG math.IT stat.CO  published:2016-12-10 summary:We propose a novel coding theoretic framework for mitigating stragglers in distributed learning. We show how carefully replicating data blocks and coding across gradients can provide tolerance to failures and stragglers for synchronous Gradient Descent. We implement our scheme in MPI and show how we compare against baseline architectures in running time and generalization error. version:1
arxiv-1612-03284 | Salient Region Detection with Convex Hull Overlap | http://arxiv.org/abs/1612.03284 | id:1612.03284 author:Yongqing Liang, Cheng Jin, Yuejie Zhang category:cs.CV cs.AI  published:2016-12-10 summary:In this paper, we establish a novel bottom-up cue named Convex Hull Overlap (CHO), and then propose an effective approach to detect salient regions using the combination of the CHO cue and global contrast cue. Our scheme significantly differs from other earlier work in: 1) The hierarchical segmentation model based on Normalized Graph-Cut fits the splitting and merging processes in human visual perception; 2) Previous work only focuses on color and texture cues, while our CHO cue makes up the obvious gap between the spatial region covering and the region saliency. CHO is a kind of improved and enhanced Gestalt cue, while other popular figure-ground cues such as convexity and surroundedness can be regarded as the special cases of CHO. Our experiments on a large number of public data have obtained very positive results. version:1
arxiv-1612-03277 | Data Curation APIs | http://arxiv.org/abs/1612.03277 | id:1612.03277 author:Seyed-Mehdi-Reza Beheshti, Alireza Tabebordbar, Boualem Benatallah, Reza Nouri category:cs.IR cs.CL  published:2016-12-10 summary:Understanding and analyzing big data is firmly recognized as a powerful and strategic priority. For deeper interpretation of and better intelligence with big data, it is important to transform raw data (unstructured, semi-structured and structured data sources, e.g., text, video, image data sets) into curated data: contextualized data and knowledge that is maintained and made available for use by end-users and applications. In particular, data curation acts as the glue between raw data and analytics, providing an abstraction layer that relieves users from time consuming, tedious and error prone curation tasks. In this context, the data curation process becomes a vital analytics asset for increasing added value and insights. In this paper, we identify and implement a set of curation APIs and make them available (on GitHub) to researchers and developers to assist them transforming their raw data into curated data. The curation APIs enable developers to easily add features - such as extracting keyword, part of speech, and named entities such as Persons, Locations, Organizations, Companies, Products, Diseases, Drugs, etc.; providing synonyms and stems for extracted information items leveraging lexical knowledge bases for the English language such as WordNet; linking extracted entities to external knowledge bases such as Google Knowledge Graph and Wikidata; discovering similarity among the extracted information items, such as calculating similarity between string, number, date and time data; classifying, sorting and categorizing data into various types, forms or any other distinct class; and indexing structured and unstructured data - into their applications. version:1
arxiv-1612-03273 | Towards an Automated Image De-fencing Algorithm Using Sparsity | http://arxiv.org/abs/1612.03273 | id:1612.03273 author:Sankaraganesh Jonna, Krishna K. Nakka, Rajiv R. Sahay category:cs.CV  published:2016-12-10 summary:Conventional approaches to image de-fencing suffer from non-robust fence detection and are limited to processing images of static scenes. In this position paper, we propose an automatic de-fencing algorithm for images of dynamic scenes. We divide the problem of image de-fencing into the tasks of automated fence detection, motion estimation and fusion of data from multiple frames of a captured video of the dynamic scene. Fences are detected automatically using two approaches, namely, employing Gabor filter and a machine learning method. We cast the fence removal problem in an optimization framework, by modeling the formation of the degraded observations. The inverse problem is solved using split Bregman technique assuming total variation of the de-fenced image as the regularization constraint. version:1
arxiv-1612-03268 | Generalized Deep Image to Image Regression | http://arxiv.org/abs/1612.03268 | id:1612.03268 author:Venkataraman Santhanam, Vlad I. Morariu, Larry S. Davis category:cs.CV cs.LG cs.NE  published:2016-12-10 summary:We present a Deep Convolutional Neural Network architecture which serves as a generic image-to-image regressor that can be trained end-to-end without any further machinery. Our proposed architecture: the Recursively Branched Deconvolutional Network (RBDN) develops a cheap multi-context image representation very early on using an efficient recursive branching scheme with extensive parameter sharing and learnable upsampling. This multi-context representation is subjected to a highly non-linear locality preserving transformation by the remainder of our network comprising of a series of convolutions/deconvolutions without any spatial downsampling. The RBDN architecture is fully convolutional and can handle variable sized images during inference. We provide qualitative/quantitative results on $3$ diverse tasks: relighting, denoising and colorization and show that our proposed RBDN architecture obtains comparable results to the state-of-the-art on each of these tasks when used off-the-shelf without any post processing or task-specific architectural modifications. version:1
arxiv-1612-03266 | A Character-Word Compositional Neural Language Model for Finnish | http://arxiv.org/abs/1612.03266 | id:1612.03266 author:Matti Lankinen, Hannes Heikinheimo, Pyry Takala, Tapani Raiko, Juha Karhunen category:cs.CL  published:2016-12-10 summary:Inspired by recent research, we explore ways to model the highly morphological Finnish language at the level of characters while maintaining the performance of word-level models. We propose a new Character-to-Word-to-Character (C2W2C) compositional language model that uses characters as input and output while still internally processing word level embeddings. Our preliminary experiments, using the Finnish Europarl V7 corpus, indicate that C2W2C can respond well to the challenges of morphologically rich languages such as high out of vocabulary rates, the prediction of novel words, and growing vocabulary size. Notably, the model is able to correctly score inflectional forms that are not present in the training data and sample grammatically and semantically correct Finnish sentences character by character. version:1
arxiv-1612-03242 | StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks | http://arxiv.org/abs/1612.03242 | id:1612.03242 author:Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaolei Huang, Xiaogang Wang, Dimitris Metaxas category:cs.CV cs.AI stat.ML  published:2016-12-10 summary:Synthesizing photo-realistic images from text descriptions is a challenging problem in computer vision and has many practical applications. Samples generated by existing text-to-image approaches can roughly reflect the meaning of the given descriptions, but they fail to contain necessary details and vivid object parts. In this paper, we propose stacked Generative Adversarial Networks (StackGAN) to generate photo-realistic images conditioned on text descriptions. The Stage-I GAN sketches the primitive shape and basic colors of the object based on the given text description, yielding Stage-I low resolution images. The Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high resolution images with photo-realistic details. The Stage-II GAN is able to rectify defects and add compelling details with the refinement process. Samples generated by StackGAN are more plausible than those generated by existing approaches. Importantly, our StackGAN for the first time generates realistic 256 x 256 images conditioned on only text descriptions, while state-of-the-art methods can generate at most 128 x 128 images. To demonstrate the effectiveness of the proposed StackGAN, extensive experiments are conducted on CUB and Oxford-102 datasets, which contain enough object appearance variations and are widely-used for text-to-image generation analysis. version:1
arxiv-1612-03236 | Co-localization with Category-Consistent CNN Features and Geodesic Distance Co-Propagation | http://arxiv.org/abs/1612.03236 | id:1612.03236 author:Hieu Le, Chen-Ping Yu, Gregory Zelinsky, Dimitris Samaras category:cs.CV  published:2016-12-10 summary:Co-localization is the problem of localizing categorical objects using only positive sets of example images, without any form of further supervision. This is a challenging task as there is no pixel-level annotations. Motivated by human visual learning, we find the common features of an object category from convolutional kernels of a pre-trained convolutional neural network (CNN). We call these category-consistent CNN features. Then, we co-propagate their activated spatial regions using superpixel geodesic distances for localization. In our first set of experiments, we show that the proposed method achieves state-of-the-art performance on three related benchmarks: PASCAL 2007, PASCAL-2012, and the Object Discovery dataset. We also show that our method is able to detect and localize truly unseen categories, using six held-out ImagNet subset of categories with state-of-the-art accuracies. Our intuitive approach achieves this success without any region proposals or object detectors, and can be based on a CNN that was pre-trained purely on image classification tasks without further fine-tuning. version:1
arxiv-1612-03231 | A natural language interface to a graph-based bibliographic information retrieval system | http://arxiv.org/abs/1612.03231 | id:1612.03231 author:Yongjun Zhu, Erjia Yan, Il-Yeol Song category:cs.IR cs.CL  published:2016-12-10 summary:With the ever-increasing scientific literature, there is a need on a natural language interface to bibliographic information retrieval systems to retrieve related information effectively. In this paper, we propose a natural language interface, NLI-GIBIR, to a graph-based bibliographic information retrieval system. In designing NLI-GIBIR, we developed a novel framework that can be applicable to graph-based bibliographic information retrieval systems. Our framework integrates algorithms/heuristics for interpreting and analyzing natural language bibliographic queries. NLI-GIBIR allows users to search for a variety of bibliographic data through natural language. A series of text- and linguistic-based techniques are used to analyze and answer natural language queries, including tokenization, named entity recognition, and syntactic analysis. We find that our framework can effectively represents and addresses complex bibliographic information needs. Thus, the contributions of this paper are as follows: First, to our knowledge, it is the first attempt to propose a natural language interface to graph-based bibliographic information retrieval. Second, we propose a novel customized natural language processing framework that integrates a few original algorithms/heuristics for interpreting and analyzing natural language bibliographic queries. Third, we show that the proposed framework and natural language interface provide a practical solution in building real-world natural language interface-based bibliographic information retrieval systems. Our experimental results show that the presented system can correctly answer 39 out of 40 example natural language queries with varying lengths and complexities. version:1
arxiv-1612-03226 | Active Learning for Speech Recognition: the Power of Gradients | http://arxiv.org/abs/1612.03226 | id:1612.03226 author:Jiaji Huang, Rewon Child, Vinay Rao, Hairong Liu, Sanjeev Satheesh, Adam Coates category:cs.CL cs.LG stat.ML  published:2016-12-10 summary:In training speech recognition systems, labeling audio clips can be expensive, and not all data is equally valuable. Active learning aims to label only the most informative samples to reduce cost. For speech recognition, confidence scores and other likelihood-based active learning methods have been shown to be effective. Gradient-based active learning methods, however, are still not well-understood. This work investigates the Expected Gradient Length (EGL) approach in active learning for end-to-end speech recognition. We justify EGL from a variance reduction perspective, and observe that EGL's measure of informativeness picks novel samples uncorrelated with confidence scores. Experimentally, we show that EGL can reduce word errors by 11\%, or alternatively, reduce the number of samples to label by 50\%, when compared to random sampling. version:1
arxiv-1612-03225 | Optimal Generalized Decision Trees via Integer Programming | http://arxiv.org/abs/1612.03225 | id:1612.03225 author:Matt Menickelly, Oktay Gunluk, Jayant Kalagnanam, Katya Scheinberg category:cs.LG math.OC stat.ML 90C10  published:2016-12-10 summary:Decision trees have been a very popular class of predictive models for decades due to their interpretability and good performance on categorical features. However, they are not always robust and tend to overfit the data. Additionally, if allowed to grow large, they lose interpretability. In this paper, we present a novel mixed integer programming formulation to construct optimal decision trees of specified size. We take special structure of categorical features into account and allow combinatorial decisions (based on subsets of values of such a feature) at each node. We show that very good accuracy can be achieved with small trees using moderately-sized training sets. The optimization problems we solve are easily tractable with modern solvers. version:1
arxiv-1612-03217 | Automatic Lymphocyte Detection in H&E Images with Deep Neural Networks | http://arxiv.org/abs/1612.03217 | id:1612.03217 author:Jianxu Chen, Chukka Srinivas category:cs.CV  published:2016-12-09 summary:Automatic detection of lymphocyte in H&E images is a necessary first step in lots of tissue image analysis algorithms. An accurate and robust automated lymphocyte detection approach is of great importance in both computer science and clinical studies. Most of the existing approaches for lymphocyte detection are based on traditional image processing algorithms and/or classic machine learning methods. In the recent years, deep learning techniques have fundamentally transformed the way that a computer interprets images and have become a matchless solution in various pattern recognition problems. In this work, we design a new deep neural network model which extends the fully convolutional network by combining the ideas in several recent techniques, such as shortcut links. Also, we design a new training scheme taking the prior knowledge about lymphocytes into consideration. The training scheme not only efficiently exploits the limited amount of free-form annotations from pathologists, but also naturally supports efficient fine-tuning. As a consequence, our model has the potential of self-improvement by leveraging the errors collected during real applications. Our experiments show that our deep neural network model achieves good performance in the images of different staining conditions or different types of tissues. version:1
arxiv-1612-03216 | #HashtagWars: Learning a Sense of Humor | http://arxiv.org/abs/1612.03216 | id:1612.03216 author:Peter Potash, Alexey Romanov, Anna Rumshisky category:cs.CL  published:2016-12-09 summary:In this work, we present a new dataset for computational humor, specifically comparative humor ranking, which attempts to eschew the ubiquitous binary approach to humor detection. The dataset consists of tweets that are humorous responses to a given hashtag. We describe the motivation for this new dataset, as well as the collection process, which includes a description of our semi-automated system for data collection. We also present initial experiments for this dataset using both unsupervised and supervised approaches. Our best supervised system achieved 63.7% accuracy, suggesting that this task is much more difficult than comparable humor detection tasks. Initial experiments indicate that a character-level model is more suitable for this task than a token-level model, likely due to a large amount of puns that can be captured by a character-level model. version:1
arxiv-1612-03214 | Towards deep learning with spiking neurons in energy based models with contrastive Hebbian plasticity | http://arxiv.org/abs/1612.03214 | id:1612.03214 author:Thomas Mesnard, Wulfram Gerstner, Johanni Brea category:cs.LG cs.NE q-bio.NC  published:2016-12-09 summary:In machine learning, error back-propagation in multi-layer neural networks (deep learning) has been impressively successful in supervised and reinforcement learning tasks. As a model for learning in the brain, however, deep learning has long been regarded as implausible, since it relies in its basic form on a non-local plasticity rule. To overcome this problem, energy-based models with local contrastive Hebbian learning were proposed and tested on a classification task with networks of rate neurons. We extended this work by implementing and testing such a model with networks of leaky integrate-and-fire neurons. Preliminary results indicate that it is possible to learn a non-linear regression task with hidden layers, spiking neurons and a local synaptic plasticity rule. version:1
arxiv-1612-03205 | Evaluating Creative Language Generation: The Case of Rap Lyric Ghostwriting | http://arxiv.org/abs/1612.03205 | id:1612.03205 author:Peter Potash, Alexey Romanov, Anna Rumshisky category:cs.CL  published:2016-12-09 summary:Language generation tasks that seek to mimic human ability to use language creatively are difficult to evaluate, since one must consider creativity, style, and other non-trivial aspects of the generated text. The goal of this paper is to develop evaluation methods for one such task, ghostwriting of rap lyrics, and to provide an explicit, quantifiable foundation for the goals and future directions of this task. Ghostwriting must produce text that is similar in style to the emulated artist, yet distinct in content. We develop a novel evaluation methodology that addresses several complementary aspects of this task, and illustrate how such evaluation can be used to meaningfully analyze system performance. We provide a corpus of lyrics for 13 rap artists, annotated for stylistic similarity, which allows us to assess the feasibility of manual evaluation for generated verse. version:1
arxiv-1612-03186 | Low-Rank Inducing Norms with Optimality Interpretations | http://arxiv.org/abs/1612.03186 | id:1612.03186 author:Christian Grussler, Pontus Giselsson category:math.OC cs.LG stat.ML  published:2016-12-09 summary:Optimization problems with rank constraints appear in many diverse fields such as control, machine learning and image analysis. Since the rank constraint is non-convex, these problems are often approximately solved via convex relaxations. Nuclear norm regularization is the prevailing convexifying technique for dealing with these types of problem. This paper introduces a family of low-rank inducing norms and regularizers which includes the nuclear norm as a special case. A posteriori guarantees on solving an underlying rank constrained optimization problem with these convex relaxations are provided. We evaluate the performance of the low-rank inducing norms on three matrix completion problems. In all examples, the nuclear norm heuristic is outperformed by convex relaxations based on other low-rank inducing norms. For two of the problems there exist low-rank inducing norms that succeed in recovering the partially unknown matrix, while the nuclear norm fails. These low-rank inducing norms are shown to be representable as semi-definite programs and to have cheaply computable proximal mappings. The latter makes it possible to also solve problems of large size with the help of scalable first-order methods. Finally, it is proven that our findings extend to the more general class of atomic norms. In particular, this allows us to solve corresponding vector-valued problems, as well as problems with other non-convex constraints. version:1
arxiv-1612-03164 | Square Hellinger Subadditivity for Bayesian Networks and its Applications to Identity Testing | http://arxiv.org/abs/1612.03164 | id:1612.03164 author:Constantinos Daskalakis, Qinxuan Pan category:cs.LG cs.IT math.IT math.PR math.ST stat.ML stat.TH  published:2016-12-09 summary:We show that the square Hellinger distance between two Bayesian networks on the same directed graph, $G$, is subadditive with respect to the neighborhoods of $G$. Namely, if $P$ and $Q$ are the probability distributions defined by two Bayesian networks on the same DAG, our inequality states that the square Hellinger distance, $H^2(P,Q)$, between $P$ and $Q$ is upper bounded by the sum, $\sum_v H^2(P_{\{v\} \cup \Pi_v}, Q_{\{v\} \cup \Pi_v})$, of the square Hellinger distances between the marginals of $P$ and $Q$ on every node $v$ and its parents $\Pi_v$ in the DAG. Importantly, our bound does not involve the conditionals but the marginals of $P$ and $Q$. We derive a similar inequality for more general Markov Random Fields. As an application of our inequality, we show that distinguishing whether two Bayesian networks $P$ and $Q$ on the same (but potentially unknown) DAG satisfy $P=Q$ vs $d_{\rm TV}(P,Q)>\epsilon$ can be performed from $\tilde{O}( \Sigma ^{3/4(d+1)} \cdot n/\epsilon^2)$ samples, where $d$ is the maximum in-degree of the DAG and $\Sigma$ the domain of each variable of the Bayesian networks. If $P$ and $Q$ are defined on potentially different and potentially unknown trees, the sample complexity becomes $\tilde{O}( \Sigma ^{4.5} n/\epsilon^2)$, whose dependence on $n, \epsilon$ is optimal up to logarithmic factors. Lastly, if $P$ and $Q$ are product distributions over $\{0,1\}^n$ and $Q$ is known, the sample complexity becomes $O(\sqrt{n}/\epsilon^2)$, which is optimal up to constant factors. version:1
arxiv-1612-03156 | Testing Bayesian Networks | http://arxiv.org/abs/1612.03156 | id:1612.03156 author:Clement Canonne, Ilias Diakonikolas, Daniel Kane, Alistair Stewart category:cs.DS cs.IT cs.LG math.IT math.ST stat.TH  published:2016-12-09 summary:This work initiates a systematic investigation of testing {\em high-dimensional} structured distributions by focusing on testing {\em Bayesian networks} -- the prototypical family of directed graphical models. A Bayesian network is defined by a directed acyclic graph, where we associate a random variable with each node. The value at any particular node is conditionally independent of all the other non-descendant nodes once its parents are fixed. Specifically, we study the properties of identity testing and closeness testing of Bayesian networks. Our main contribution is the first non-trivial efficient testing algorithms for these problems and corresponding information-theoretic lower bounds. For a wide range of parameter settings, our testing algorithms have sample complexity {\em sublinear} in the dimension and are sample-optimal, up to constant factors. version:1
arxiv-1612-03153 | Panoptic Studio: A Massively Multiview System for Social Interaction Capture | http://arxiv.org/abs/1612.03153 | id:1612.03153 author:Hanbyul Joo, Tomas Simon, Xulong Li, Hao Liu, Lei Tan, Lin Gui, Sean Banerjee, Timothy Godisart, Bart Nabbe, Iain Matthews, Takeo Kanade, Shohei Nobuhara, Yaser Sheikh category:cs.CV  published:2016-12-09 summary:We present an approach to capture the 3D motion of a group of people engaged in a social interaction. The core challenges in capturing social interactions are: (1) occlusion is functional and frequent; (2) subtle motion needs to be measured over a space large enough to host a social group; (3) human appearance and configuration variation is immense; and (4) attaching markers to the body may prime the nature of interactions. The Panoptic Studio is a system organized around the thesis that social interactions should be measured through the integration of perceptual analyses over a large variety of view points. We present a modularized system designed around this principle, consisting of integrated structural, hardware, and software innovations. The system takes, as input, 480 synchronized video streams of multiple people engaged in social activities, and produces, as output, the labeled time-varying 3D structure of anatomical landmarks on individuals in the space. Our algorithm is designed to fuse the "weak" perceptual processes in the large number of views by progressively generating skeletal proposals from low-level appearance cues, and a framework for temporal refinement is also presented by associating body parts to reconstructed dense 3D trajectory stream. Our system and method are the first in reconstructing full body motion of more than five people engaged in social interactions without using markers. We also empirically demonstrate the impact of the number of views in achieving this goal. version:1
arxiv-1612-03148 | Optimal mean-based algorithms for trace reconstruction | http://arxiv.org/abs/1612.03148 | id:1612.03148 author:Anindya De, Ryan O'Donnell, Rocco Servedio category:cs.CC cs.DS cs.LG  published:2016-12-09 summary:In the (deletion-channel) trace reconstruction problem, there is an unknown $n$-bit source string $x$. An algorithm is given access to independent traces of $x$, where a trace is formed by deleting each bit of~$x$ independently with probability~$\delta$. The goal of the algorithm is to recover~$x$ exactly (with high probability), while minimizing samples (number of traces) and running time. Previously, the best known algorithm for the trace reconstruction problem was due to Holenstein~et~al.; it uses $\exp(\tilde{O}(n^{1/2}))$ samples and running time for any fixed $0 < \delta < 1$. It is also what we call a "mean-based algorithm", meaning that it only uses the empirical means of the individual bits of the traces. Holenstein~et~al.~also gave a lower bound, showing that any mean-based algorithm must use at least $n^{\tilde{\Omega}(\log n)}$ samples. In this paper we improve both of these results, obtaining matching upper and lower bounds for mean-based trace reconstruction. For any constant deletion rate $0 < \delta < 1$, we give a mean-based algorithm that uses $\exp(O(n^{1/3}))$ time and traces; we also prove that any mean-based algorithm must use at least $\exp(\Omega(n^{1/3}))$ traces. In fact, we obtain matching upper and lower bounds even for $\delta$ subconstant and $\rho := 1-\delta$ subconstant: when $(\log^3 n)/n \ll \delta \leq 1/2$ the bound is $\exp(-\Theta(\delta n)^{1/3})$, and when $1/\sqrt{n} \ll \rho \leq 1/2$ the bound is $\exp(-\Theta(n/\rho)^{1/3})$. Our proofs involve estimates for the maxima of Littlewood polynomials on complex disks. We show that these techniques can also be used to perform trace reconstruction with random insertions and bit-flips in addition to deletions. We also find a surprising result: for deletion probabilities $\delta > 1/2$, the presence of insertions can actually help with trace reconstruction. version:1
arxiv-1612-03144 | Feature Pyramid Networks for Object Detection | http://arxiv.org/abs/1612.03144 | id:1612.03144 author:Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie category:cs.CV  published:2016-12-09 summary:Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But recent deep learning object detectors have avoided pyramid representations, in part because they are compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using FPN in a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available. version:1
arxiv-1612-03142 | Quantifying and Predicting Image Scenicness | http://arxiv.org/abs/1612.03142 | id:1612.03142 author:Scott Workman, Richard Souvenir, Nathan Jacobs category:cs.CV  published:2016-12-09 summary:Capturing the beauty of outdoor scenes in an image motivates many amateur and professional photographers and serves as the basis for many image sharing sites. While natural beauty is often considered a subjective property of images, in this paper, we take an objective approach and provide methods for quantifying and predicting the scenicness of an image. Using a dataset containing hundreds of thousands of outdoor images captured throughout Great Britain with crowdsourced ratings of natural beauty, we propose an approach to predict scenicness which explicitly accounts for the variance of human raters. We demonstrate that quantitative measures of scenicness can benefit semantic image understanding, content-aware image processing, and a novel application of cross-view mapping, where the sparsity of labeled ground-level images can be addressed by incorporating unlabeled aerial images in the training and prediction steps. For each application, our methods for scenicness prediction result in quantitative and qualitative improvements over baseline approaches. version:1
arxiv-1612-06879 | Robust mixture of experts modeling using the skew $t$ distribution | http://arxiv.org/abs/1612.06879 | id:1612.06879 author:Faicel Chamroukhi category:stat.ME cs.LG stat.ML 62  62F  62H30  62h G.3; I.2.6; I.5.1  published:2016-12-09 summary:Mixture of Experts (MoE) is a popular framework in the fields of statistics and machine learning for modeling heterogeneity in data for regression, classification and clustering. MoE for continuous data are usually based on the normal distribution. However, it is known that for data with asymmetric behavior, heavy tails and atypical observations, the use of the normal distribution is unsuitable. We introduce a new robust non-normal mixture of experts modeling using the skew $t$ distribution. The proposed skew $t$ mixture of experts, named STMoE, handles these issues of the normal mixtures experts regarding possibly skewed, heavy-tailed and noisy data. We develop a dedicated expectation conditional maximization (ECM) algorithm to estimate the model parameters by monotonically maximizing the observed data log-likelihood. We describe how the presented model can be used in prediction and in model-based clustering of regression data. Numerical experiments carried out on simulated data show the effectiveness and the robustness of the proposed model in fitting non-linear regression functions as well as in model-based clustering. Then, the proposed model is applied to the real-world data of tone perception for musical data analysis, and the one of temperature anomalies for the analysis of climate change data. The obtained results confirm the usefulness of the model for practical data analysis applications. version:1
arxiv-1612-03772 | SimTensor: A synthetic tensor data generator | http://arxiv.org/abs/1612.03772 | id:1612.03772 author:Hadi Fanaee-T, Joao Gama category:cs.MS math.NA stat.ML  published:2016-12-09 summary:SimTensor is a multi-platform, open-source software for generating artificial tensor data (either with CP/PARAFAC or Tucker structure) for reproducible research on tensor factorization algorithms. SimTensor is a stand-alone application based on MATALB. It provides a wide range of facilities for generating tensor data with various configurations. It comes with a user-friendly graphical user interface, which enables the user to generate tensors with complicated settings in an easy way. It also has this facility to export generated data to universal formats such as CSV and HDF5, which can be imported via a wide range of programming languages (C, C++, Java, R, Fortran, MATLAB, Perl, Python, and many more). The most innovative part of SimTensor is this that can generate temporal tensors with periodic waves, seasonal effects and streaming structure. it can apply constraints such as non-negativity and different kinds of sparsity to the data. SimTensor also provides this facility to simulate different kinds of change-points and inject various types of anomalies. The source code and binary versions of SimTensor is available for download in http://www.simtensor.org. version:1
arxiv-1612-03132 | Phase transitions in Restricted Boltzmann Machines with generic priors | http://arxiv.org/abs/1612.03132 | id:1612.03132 author:Adriano Barra, Giuseppe Genovese, Peter Sollich, Daniele Tantari category:cond-mat.dis-nn cs.LG physics.data-an stat.ML  published:2016-12-09 summary:We study generalised restricted Boltzmann machines with generic priors for units and weights, interpolating between Boolean and Gaussian variables. We present a complete analysis of the replica symmetric phase diagram of these models, which can be regarded as generalised Hopfield models. We show the way the paramagnetic phase boundary is directly related to the optimal size of the training set necessary for good generalisation in a teacher- student scenario. Moreover we underline the role of the retrieval phase for both inference and learning processes. We show that retrieval is robust for a large class of weight and unit priors, beyond the standard Hopfield scenario. version:1
arxiv-1612-03129 | Shape-aware Instance Segmentation | http://arxiv.org/abs/1612.03129 | id:1612.03129 author:Zeeshan Hayder, Xuming He, Mathieu Salzmann category:cs.CV  published:2016-12-09 summary:We address the problem of instance-level semantic segmentation, which aims at jointly detecting, segmenting and classifying every individual object in an image. In this context, existing methods typically propose candidate objects, usually as bounding boxes, and directly predict a binary mask within each such proposal. As a consequence, they cannot recover from errors in the object candidate generation process, such as too small or shifted boxes. In this paper, we introduce a novel object segment representation based on the distance transform of the object masks. We then design an object mask network (OMN) with a new residual-deconvolution architecture that infers such a representation and decodes it into the final binary object mask. This allows us to predict masks that go beyond the scope of the bounding boxes and are thus robust to inaccurate object candidates. We integrate our OMN into a Multitask Network Cascade framework, and learn the resulting shape-aware instance segmentation (SAIS) network in an end-to-end manner. Our experiments on the PASCAL VOC 2012 and the CityScapes datasets demonstrate the benefits of our approach, which outperforms the state-of-the-art in both object proposal generation and instance segmentation. version:1
arxiv-1612-03117 | Advancing Bayesian Optimization: The Mixed-Global-Local (MGL) Kernel and Length-Scale Cool Down | http://arxiv.org/abs/1612.03117 | id:1612.03117 author:Kim Peter Wabersich, Marc Toussaint category:cs.LG cs.AI stat.ML 68T99  78M50  68T05  published:2016-12-09 summary:Bayesian Optimization (BO) has become a core method for solving expensive black-box optimization problems. While much research focussed on the choice of the acquisition function, we focus on online length-scale adaption and the choice of kernel function. Instead of choosing hyperparameters in view of maximum likelihood on past data, we propose to use the acquisition function to decide on hyperparameter adaptation more robustly and in view of the future optimization progress. Further, we propose a particular kernel function that includes non-stationarity and local anisotropy and thereby implicitly integrates the efficiency of local convex optimization with global Bayesian optimization. Comparisons to state-of-the art BO methods underline the efficiency of these mechanisms on global optimization benchmarks. version:1
arxiv-1612-03094 | Following Gaze Across Views | http://arxiv.org/abs/1612.03094 | id:1612.03094 author:Adrià Recasens, Carl Vondrick, Aditya Khosla, Antonio Torralba category:cs.CV  published:2016-12-09 summary:Following the gaze of people inside videos is an important signal for understanding people and their actions. In this paper, we present an approach for following gaze across views by predicting where a particular person is looking throughout a scene. We collect VideoGaze, a new dataset which we use as a benchmark to both train and evaluate models. Given one view with a person in it and a second view of the scene, our model estimates a density for gaze location in the second view. A key aspect of our approach is an end-to-end model that solves the following sub-problems: saliency, gaze pose, and geometric relationships between views. Although our model is supervised only with gaze, we show that the model learns to solve these subproblems automatically without supervision. Experiments suggest that our approach follows gaze better than standard baselines and produces plausible results for everyday situations. version:1
arxiv-1612-03079 | Clipper: A Low-Latency Online Prediction Serving System | http://arxiv.org/abs/1612.03079 | id:1612.03079 author:Daniel Crankshaw, Xin Wang, Giulio Zhou, Michael J. Franklin, Joseph E. Gonzalez, Ion Stoica category:cs.DC cs.LG  published:2016-12-09 summary:Machine learning is being deployed in a growing number of applications which demand real-time, accurate, and robust predictions under heavy query load. However, most machine learning frameworks and systems only address model training and not deployment. In this paper, we introduce Clipper, the first general-purpose low-latency prediction serving system. Interposing between end-user applications and a wide range of machine learning frameworks, Clipper introduces a modular architecture to simplify model deployment across frameworks. Furthermore, by introducing caching, batching, and adaptive model selection techniques, Clipper reduces prediction latency and improves prediction throughput, accuracy, and robustness without modifying the underlying machine learning frameworks. We evaluate Clipper on four common machine learning benchmark datasets and demonstrate its ability to meet the latency, accuracy, and throughput demands of online serving applications. Finally, we compare Clipper to the TensorFlow Serving system and demonstrate comparable prediction throughput and latency on a range of models while enabling new functionality, improved accuracy, and robustness. version:1
arxiv-1612-03052 | ActionFlowNet: Learning Motion Representation for Action Recognition | http://arxiv.org/abs/1612.03052 | id:1612.03052 author:Joe Yue-Hei Ng, Jonghyun Choi, Jan Neumann, Larry S. Davis category:cs.CV  published:2016-12-09 summary:Even with the recent advances in convolutional neural networks (CNN) in various visual recognition tasks, the state-of-the-art action recognition system still relies on hand crafted motion feature such as optical flow to achieve the best performance. We propose a multitask learning model ActionFlowNet to train a single stream network directly from raw pixels to jointly estimate optical flow while recognizing actions with convolutional neural networks, capturing both appearance and motion in a single model. We additionally provide insights to how the quality of the learned optical flow affects the action recognition. Our model not only significantly improves action recognition accuracy by a large margin (17%) compared to state-of-the-art CNN-based action recognition models trained without external large scale data and additional optical flow input, but also produces the optical flow as a side product. version:1
arxiv-1612-03019 | Automatic Model Based Dataset Generation for Fast and Accurate Crop and Weeds Detection | http://arxiv.org/abs/1612.03019 | id:1612.03019 author:Maurilio Di Cicco, Ciro Potena, Giorgio Grisetti, Alberto Pretto category:cs.CV cs.RO  published:2016-12-09 summary:Selective weeding is one of the key challenges in the field of agriculture robotics: in order to accomplish this task, a farm robot should be able to accurately detect plants and to distinguish them between crop and weeds. In this paper, we face this problem by proposing a novel and effective approach that aims to dramatically minimize the human intervention needed to train the detection and classification algorithms. The idea is to synthetically generate the training datasets by using state-of-the-art computer graphics methods and tools. We explicitly model the relevant aspects of the target environment (i.e., crop and weeds species, type of soil, light conditions): by changing the model parameters, it is possible to render a huge number of photo-realistic views of the environment, to be used as training data. The proposed methodology has been validated exploiting a very recent deep learning based image segmentation architecture called SegNet [Kendall et al.]. We trained and tested different custom-built variants of SegNet using both real and synthetically generated datasets, the reported results confirm the effectiveness and the potentiality of our approach. version:1
arxiv-1612-02954 | A series of maximum entropy upper bounds of the differential entropy | http://arxiv.org/abs/1612.02954 | id:1612.02954 author:Frank Nielsen, Richard Nock category:cs.IT cs.CV cs.LG math.IT  published:2016-12-09 summary:We present a series of closed-form maximum entropy upper bounds for the differential entropy of a continuous univariate random variable and study the properties of that series. We then show how to use those generic bounds for upper bounding the differential entropy of Gaussian mixture models. This requires to calculate the raw moments and raw absolute moments of Gaussian mixtures in closed-form that may also be handy in statistical machine learning and information theory. We report on our experiments and discuss on the tightness of those bounds. version:1
arxiv-1612-01160 | General models for rational cameras and the case of two-slit projections | http://arxiv.org/abs/1612.01160 | id:1612.01160 author:Matthew Trager, Bernd Sturmfels, John Canny, Martial Hebert, Jean Ponce category:cs.CV  published:2016-12-04 summary:The rational camera model recently introduced in [18] provides a general methodology for studying abstract nonlinear imaging systems and their multi-view geometry. This paper provides a concrete embedding of rational cameras explicitly accounting for the mapping between physical visual rays and image points, missing in the original model. This allows us to derive simple but general analytical expressions for direct and inverse projections, and define primitive rational cameras equivalent under the action of various projective transformations, leading to a generalized notion of intrinsic coordinates in this setting. The methodology is general, but it is illustrated concretely by an in-depth study of two-slit cameras, which we describe using a pair of linear projections. This simple analytical form allows us to describe models for the corresponding primitive cameras, to introduce intrinsic parameters with a clear geometric meaning, and to define an epipolar tensor characterizing two-view correspondences. In turn, this leads to new algorithms for structure from motion and self-calibration. version:3
arxiv-1612-02903 | Facial Expression Recognition using Convolutional Neural Networks: State of the Art | http://arxiv.org/abs/1612.02903 | id:1612.02903 author:Christopher Pramerdorfer, Martin Kampel category:cs.CV  published:2016-12-09 summary:The ability to recognize facial expressions automatically enables novel applications in human-computer interaction and other areas. Consequently, there has been active research in this field, with several recent works utilizing Convolutional Neural Networks (CNNs) for feature extraction and inference. These works differ significantly in terms of CNN architectures and other factors. Based on the reported results alone, the performance impact of these factors is unclear. In this paper, we review the state of the art in image-based facial expression recognition using CNNs and highlight algorithmic differences and their performance impact. On this basis, we identify existing bottlenecks and consequently directions for advancing this research field. Furthermore, we demonstrate that overcoming one of these bottlenecks - the comparatively basic architectures of the CNNs utilized in this field - leads to a substantial performance increase. By forming an ensemble of modern deep CNNs, we obtain a FER2013 test accuracy of 75.2%, outperforming previous works without requiring auxiliary training data or face registration. version:1
arxiv-1612-02897 | Analytical Stacked Gaussian Process Model | http://arxiv.org/abs/1612.02897 | id:1612.02897 author:Kareem Abdelfatah, Junshu Bao, Gabriel Terejanu category:cs.LG stat.ML  published:2016-12-09 summary:A probabilistic model is proposed by stacking a set of independently trained Gaussian processes to obtain prediction of quantities of interests that require composition of functions. Analytical derivations are provided for first and second-order moments of the stacked Gaussian process using RBF and polynomial kernels. The StackedGP model can be extended to any number of layers and nodes per layer, and it provides flexibility in kernel selection for each node. The proposed nonparametric stacked model is validated using different synthetic datasets and its performance is measured in two real-world applications. version:1
arxiv-1612-02889 | Gesture-based Bootstrapping for Egocentric Hand Segmentation | http://arxiv.org/abs/1612.02889 | id:1612.02889 author:Yubo Zhang, Vishnu Naresh Boddeti, Kris M. Kitani category:cs.CV  published:2016-12-09 summary:Accurately identifying hands in images is a key sub-task for human activity understanding with wearable first-person point-of-view cameras. Traditional hand segmentation approaches rely on a large corpus of manually labeled data to generate robust hand detectors. However, these approaches still face challenges as the appearance of the hand varies greatly across users, tasks, environments or illumination conditions. A key observation in the case of many wearable applications and interfaces is that, it is only necessary to accurately detect the user's hands in a specific situational context. Based on this observation, we introduce an interactive approach to learn a person-specific hand segmentation model that does not require any manually labeled training data. Our approach proceeds in two steps, an interactive bootstrapping step for identifying moving hand regions, followed by learning a personalized user specific hand appearance model. Concretely, our approach uses two convolutional neural networks: (1) a gesture network that uses pre-defined motion information to detect the hand region; and (2) an appearance network that learns a person specific model of the hand region based on the output of the gesture network. During training, to make the appearance network robust to errors in the gesture network, the loss function of the former network incorporates the confidence of the gesture network while learning. Experiments demonstrate the robustness of our approach with an F1 score over 0.8 on all challenging datasets across a wide range of illumination and hand appearance variations, improving over a baseline approach by over 10%. version:1
arxiv-1612-02880 | Fast Fourier single-pixel imaging using binary illumination | http://arxiv.org/abs/1612.02880 | id:1612.02880 author:Zibang Zhang, Xueying Wang, Jingang Zhong category:cs.CV  published:2016-12-09 summary:Fourier single-pixel imaging (FSI) has proven capable of reconstructing high-quality two-dimensional and three-dimensional images. The utilization of the sparsity of natural images in Fourier domain allows high-resolution images to be reconstructed from far fewer measurements than effective image pixels. However, applying original FSI in digital micro-mirror device (DMD) based high-speed imaging system turns out to be challenging, because the original FSI uses grayscale Fourier basis patterns for illumination while DMDs generate grayscale patterns at a relatively low rate. DMDs are a binary device which can only generate a black-and-white pattern at each instance. In this paper, we adopt binary Fourier patterns for illumination to achieve DMD-based high-speed single-pixel imaging. Binary Fourier patterns are generated by upsampling and then applying error diffusion based dithering to the grayscale patterns. Experiments demonstrate the proposed technique able to achieve static imaging with high quality and dynamic imaging in real time. The proposed technique potentially allows high-quality and high-speed imaging over broad wavebands. version:1
arxiv-1612-02879 | Learning representations through stochastic gradient descent in cross-validation error | http://arxiv.org/abs/1612.02879 | id:1612.02879 author:Richard S. Sutton, Vivek Veeriah category:cs.LG cs.AI stat.ML  published:2016-12-09 summary:Representations are fundamental to Artificial Intelligence. Typically, the performance of a learning system depends on its data representation. These data representations are usually hand-engineered based on some prior domain knowledge regarding the task. More recently, the trend is to learn these representations through deep neural networks as these can produce dramatical performance improvements over hand-engineered data representations. In this paper, we present a new incremental learning algorithm, called crossprop, for learning representations based on prior learning experiences. Unlike backpropagation, crossprop minimizes the cross-validation error. Specifically, our algorithm considers the influences of all the past weights on the current squared error, and uses this gradient for incrementally learning the weights in a neural network. This idea is similar to that of tuning the learning system through an offline cross-validation procedure. Crossprop is applicable to incremental learning tasks, where a sequence of examples are encountered by the learning system and they need to be processed one by one and then discarded. The learning system can use each example only once and can spend only a limited amount of computation for an example. From our preliminary experiments, we concluce that crossprop is a promising alternative for backprop for representation learning. version:1
arxiv-1612-02859 | Exploiting 2D Floorplan for Building-scale Panorama RGBD Alignment | http://arxiv.org/abs/1612.02859 | id:1612.02859 author:Erik Wijmans, Yasutaka Furukawa category:cs.CV  published:2016-12-08 summary:This paper presents a novel algorithm that utilizes a 2D floorplan to align panorama RGBD scans. While effective panorama RGBD alignment techniques exist, such a system requires extremely dense RGBD image sampling. Our approach can significantly reduce the number of necessary scans with the aid of a floorplan image. We formulate a novel Markov Random Field inference problem as a scan placement over the floorplan, as opposed to the conventional scan-to-scan alignment. The technical contributions lie in multi-modal image correspondence cues (between scans and schematic floorplan) as well as a novel coverage potential avoiding an inherent stacking bias. The proposed approach has been evaluated on five challenging large indoor spaces. To the best of our knowledge, we present the first effective system that utilizes a 2D floorplan image for building-scale 3D pointcloud alignment. The source code and the data will be shared with the community to further enhance indoor mapping research. version:1
arxiv-1612-02844 | Deep TEN: Texture Encoding Network | http://arxiv.org/abs/1612.02844 | id:1612.02844 author:Hang Zhang, Jia Xue, Kristin Dana category:cs.CV  published:2016-12-08 summary:We propose a Deep Texture Encoding Network (Deep-TEN) with a novel Encoding Layer integrated on top of convolutional layers, which ports the entire dictionary learning and encoding pipeline into a single model. Current methods build from distinct components, using standard encoders with separate off-the-shelf features such as SIFT descriptors or pre-trained CNN features for material recognition. Our new approach provides an end-to-end learning framework, where the inherent visual vocabularies are learned directly from the loss function. The features, dictionaries and the encoding representation for the classifier are all learned simultaneously. The representation is orderless and therefore is particularly useful for material and texture recognition. The Encoding Layer generalizes robust residual encoders such as VLAD and Fisher Vectors, and has the property of discarding domain specific information which makes the learned convolutional features easier to transfer. Additionally, joint training using multiple datasets of varied sizes and class labels is supported resulting in increased recognition performance. The experimental results show superior performance as compared to state-of-the-art methods using gold-standard databases such as MINC-2500, Flickr Material Database, KTH-TIPS-2b, and two recent databases 4D-Light-Field-Material and GTOS. The source code for the complete system are publicly available. version:1
arxiv-1612-02808 | 3D Shape Segmentation with Projective Convolutional Networks | http://arxiv.org/abs/1612.02808 | id:1612.02808 author:Evangelos Kalogerakis, Melinos Averkiou, Subhransu Maji, Siddhartha Chaudhuri category:cs.CV cs.GR  published:2016-12-08 summary:This paper introduces a deep architecture for segmenting 3D objects into their labeled semantic parts. Our architecture combines image-based Fully Convolutional Networks (FCNs) and surface-based Conditional Random Fields (CRFs) to yield coherent segmentations of 3D shapes. The image-based FCNs are used for efficient view-based reasoning about 3D object parts. Through a special projection layer, FCN outputs are effectively aggregated across multiple views and scales, then are projected onto the 3D object surfaces. Finally, a surface-based CRF combines the projected outputs with geometric consistency cues to yield coherent segmentations. The whole architecture (multi-view FCNs and CRF) is trained end-to-end. Our approach significantly outperforms the existing state-of-the-art methods in the currently largest segmentation benchmark (ShapeNet). Finally, we demonstrate promising segmentation results on noisy 3D shapes acquired from consumer-grade depth cameras. version:1
arxiv-1612-02803 | The Physical Systems Behind Optimization Algorithms | http://arxiv.org/abs/1612.02803 | id:1612.02803 author:Lin F. Yang, R. Arora, V. Braverman, Tuo Zhao category:cs.LG math.OC stat.ML  published:2016-12-08 summary:We provide some new insights for analyzing dynamics of optimization algorithms, which are popular in machine learning, based on differential equation approaches. Our analysis reveals a natural connection from optimization algorithm to physical systems, and is applicable to more general algorithms and optimization problems beyond general convexity and strong convexity. version:1
arxiv-1612-02802 | Interactive Prior Elicitation of Features Similarities for Small Sample Size Prediction | http://arxiv.org/abs/1612.02802 | id:1612.02802 author:Homayun Afrabandpey, Tomi Peltola, Samuel Kaski category:cs.LG cs.HC H.5.2; H.1.m  published:2016-12-08 summary:Regression under the "small $n$, large $p$" conditions, of small sample size $n$ and large number of features $p$ in the learning data set, is a recurring setting in which learning from data is difficult. With prior knowledge about relationships of the features, $p$ can effectively be reduced, but explicating such prior knowledge is difficult for experts. In this paper we introduce a new method for eliciting expert prior knowledge about the similarity of the roles of features in the prediction task. The key idea is to use an interactive multidimensional-scaling-type scatterplot display of the features to elicit the similarity relationships, and then use the elicited relationships in the prior distribution of prediction parameters. Specifically, for learning to predict a target variable with Bayesian linear regression, the feature relationships are used as the prior for the correlations of the regression coefficients. Results on simulated data and a user study on text data confirm that prior elicitation of feature similarities improves prediction accuracy. Furthermore, elicitation with an interactive scatterplot display outperforms straightforward elicitation where the users choose feature pairs from a feature list. version:1
arxiv-1612-02801 | Discovering Conversational Dependencies between Messages in Dialogs | http://arxiv.org/abs/1612.02801 | id:1612.02801 author:Wenchao Du, Pascal Poupart, Wei Xu category:cs.CL  published:2016-12-08 summary:We investigate the task of inferring conversational dependencies between messages in one-on-one online chat, which has become one of the most popular forms of customer service. We propose a novel probabilistic classifier that leverages conversational, lexical and semantic information. The approach is evaluated empirically on a set of customer service chat logs from a Chinese e-commerce website. It outperforms heuristic baselines. version:1
arxiv-1612-02780 | Improved generator objectives for GANs | http://arxiv.org/abs/1612.02780 | id:1612.02780 author:Ben Poole, Alexander A. Alemi, Jascha Sohl-Dickstein, Anelia Angelova category:cs.LG stat.ML  published:2016-12-08 summary:We present a framework to understand GAN training as alternating density ratio estimation and approximate divergence minimization. This provides an interpretation for the mismatched GAN generator and discriminator objectives often used in practice, and explains the problem of poor sample diversity. We also derive a family of generator objectives that target arbitrary $f$-divergences without minimizing a lower bound, and use them to train generative image models that target either improved sample quality or greater sample diversity. version:1
arxiv-1612-02766 | Feedback Neural Network for Weakly Supervised Geo-Semantic Segmentation | http://arxiv.org/abs/1612.02766 | id:1612.02766 author:Xianming Liu, Amy Zhang, Tobias Tiecke, Andreas Gros, Thomas S. Huang category:cs.CV  published:2016-12-08 summary:Learning from weakly-supervised data is one of the main challenges in machine learning and computer vision, especially for tasks such as image semantic segmentation where labeling is extremely expensive and subjective. In this paper, we propose a novel neural network architecture to perform weakly-supervised learning by suppressing irrelevant neuron activations. It localizes objects of interest by learning from image-level categorical labels in an end-to-end manner. We apply this algorithm to a practical challenge of transforming satellite images into a map of settlements and individual buildings. Experimental results show that the proposed algorithm achieves superior performance and efficiency when compared with various baseline models. version:1
arxiv-1612-02761 | A Maximum A Posteriori Estimation Framework for Robust High Dynamic Range Video Synthesis | http://arxiv.org/abs/1612.02761 | id:1612.02761 author:Yuelong Li, Chul Lee, Vishal Monga category:cs.CV  published:2016-12-08 summary:High dynamic range (HDR) image synthesis from multiple low dynamic range (LDR) exposures continues to be actively researched. The extension to HDR video synthesis is a topic of significant current interest due to potential cost benefits. For HDR video, a stiff practical challenge presents itself in the form of accurate correspondence estimation of objects between video frames. In particular, loss of data resulting from poor exposures and varying intensity make conventional optical flow methods highly inaccurate. We avoid exact correspondence estimation by proposing a statistical approach via maximum a posterior (MAP) estimation, and under appropriate statistical assumptions and choice of priors and models, we reduce it to an optimization problem of solving for the foreground and background of the target frame. We obtain the background through rank minimization and estimate the foreground via a novel multiscale adaptive kernel regression technique, which implicitly captures local structure and temporal motion by solving an unconstrained optimization problem. Extensive experimental results on both real and synthetic datasets demonstrate that our algorithm is more capable of delivering high-quality HDR videos than current state-of-the-art methods, under both subjective and objective assessments. Furthermore, a thorough complexity analysis reveals that our algorithm achieves better complexity-performance trade-off than conventional methods. version:1
arxiv-1612-02751 | Protein-Ligand Scoring with Convolutional Neural Networks | http://arxiv.org/abs/1612.02751 | id:1612.02751 author:Matthew Ragoza, Joshua Hochuli, Elisa Idrobo, Jocelyn Sunseri, David Ryan Koes category:stat.ML cs.LG q-bio.BM  published:2016-12-08 summary:Computational approaches to drug discovery can reduce the time and cost associated with experimental assays and enable the screening of novel chemotypes. Structure-based drug design methods rely on scoring functions to rank and predict binding affinities and poses. The ever-expanding amount of protein-ligand binding and structural data enables the use of deep machine learning techniques for protein-ligand scoring. We describe convolutional neural network (CNN) scoring functions that take as input a comprehensive 3D representation of a protein-ligand interaction. A CNN scoring function automatically learns the key features of protein-ligand interactions that correlate with binding. We train and optimize our CNN scoring functions to discriminate between correct and incorrect binding poses and known binders and non-binders. We find that our CNN scoring function outperforms the AutoDock Vina scoring function when ranking poses both for pose prediction and virtual screening. version:1
arxiv-1612-02742 | Joint Hand Detection and Rotation Estimation by Using CNN | http://arxiv.org/abs/1612.02742 | id:1612.02742 author:Xiaoming Deng, Ye Yuan, Yinda Zhang, Ping Tan, Liang Chang, Shuo Yang, Hongan Wang category:cs.CV  published:2016-12-08 summary:Hand detection is essential for many hand related tasks, e.g. parsing hand pose, understanding gesture, which are extremely useful for robotics and human-computer interaction. However, hand detection in uncontrolled environments is challenging due to the flexibility of wrist joint and cluttered background. We propose a deep learning based approach which detects hands and calibrates in-plane rotation under supervision at the same time. To guarantee the recall, we propose a context aware proposal generation algorithm which significantly outperforms the selective search. We then design a convolutional neural network(CNN) which handles object rotation explicitly to jointly solve the object detection and rotation estimation tasks. Experiments show that our method achieves better results than state-of-the-art detection models on widely-used benchmarks such as Oxford and Egohands database. We further show that rotation estimation and classification can mutually benefit each other. version:1
arxiv-1612-02741 | Coupling Distributed and Symbolic Execution for Natural Language Queries | http://arxiv.org/abs/1612.02741 | id:1612.02741 author:Lili Mou, Zhengdong Lu, Hang Li, Zhi Jin category:cs.LG cs.AI cs.CL cs.NE  published:2016-12-08 summary:Building neural networks to query a knowledge base (a table) with natural language is an emerging research topic in NLP. The neural enquirer typically necessitates multiple steps of execution because of the compositionality of queries. In previous studies, researchers have developed either distributed enquirers or symbolic ones for table querying. The distributed enquirer is end-to-end learnable, but is weak in terms of execution efficiency and explicit interpretability. The symbolic enqurier, on the contrary, is efficient during execution; but it is very difficult to train especially at initial stages. In this paper, we propose to couple distributed and symbolic execution for natural language queries. The observation is that a fully distributed executor also exhibits meaningful, albeit imperfect, interpretation. We can thus pretrain the symbolic executor with the distributed one's intermediate execution results in a step-by-step fashion. Experiments show that our approach significantly outperforms either the distributed or symbolic executor; moreover, we have recovered more than 80% execution sequences with only groundtruth denotations during training. In summary, the coupled neural enquirer takes advantages of both distributed and symbolic executors, and has high performance, high learning efficiency, high execution efficiency, and high interpretability. version:1
arxiv-1612-02739 | Controlling Robot Morphology from Incomplete Measurements | http://arxiv.org/abs/1612.02739 | id:1612.02739 author:Martin Pecka, Karel Zimmermann, Michal Reinštein, Tomáš Svoboda category:cs.RO cs.AI cs.LG cs.SY I.2.9  published:2016-12-08 summary:Mobile robots with complex morphology are essential for traversing rough terrains in Urban Search & Rescue missions (USAR). Since teleoperation of the complex morphology causes high cognitive load of the operator, the morphology is controlled autonomously. The autonomous control measures the robot state and surrounding terrain which is usually only partially observable, and thus the data are often incomplete. We marginalize the control over the missing measurements and evaluate an explicit safety condition. If the safety condition is violated, tactile terrain exploration by the body-mounted robotic arm gathers the missing data. version:1
arxiv-1612-02734 | Learning in the Machine: Random Backpropagation and the Learning Channel | http://arxiv.org/abs/1612.02734 | id:1612.02734 author:Pierre Baldi, Peter Sadowski, Zhiqin Lu category:cs.LG cs.AI cs.NE  published:2016-12-08 summary:Random backpropagation (RBP) is a variant of the backpropagation algorithm for training neural networks, where the transpose of the forward matrices are replaced by fixed random matrices in the calculation of the weight updates. It is remarkable both because of its effectiveness, in spite of using random matrices to communicate error information, and because it completely removes the taxing requirement of maintaining symmetric weights in a physical neural system. To better understand random backpropagation, we first connect it to the notions of local learning and the learning channel. Through this connection, we derive several alternatives to RBP, including skipped RBP (SRPB), adaptive RBP (ARBP), sparse RBP, and their combinations (e.g. ASRBP) and analyze their computational complexity. We then study their behavior through simulations using the MNIST and CIFAR-10 bechnmark datasets. These simulations show that most of these variants work robustly, almost as well as backpropagation, and that multiplication by the derivatives of the activation functions is important. As a follow-up, we study also the low-end of the number of bits required to communicate error information over the learning channel. We then provide partial intuitive explanations for some of the remarkable properties of RBP and its variations. Finally, we prove several mathematical results, including the convergence to fixed points of linear chains of arbitrary length, the convergence to fixed points of linear autoencoders with decorrelated data, the long-term existence of solutions for linear systems with a single hidden layer, and the convergence to fixed points of non-linear chains, when the derivative of the activation functions is included. version:1
arxiv-1612-02712 | Scalable Influence Maximization for Multiple Products in Continuous-Time Diffusion Networks | http://arxiv.org/abs/1612.02712 | id:1612.02712 author:Nan Du, Yingyu Liang, Maria-Florina Balcan, Manuel Gomez-Rodriguez, Hongyuan Zha, Le Song category:cs.SI cs.DS cs.LG stat.ML  published:2016-12-08 summary:A typical viral marketing model identifies influential users in a social network to maximize a single product adoption assuming unlimited user attention, campaign budgets, and time. In reality, multiple products need campaigns, users have limited attention, convincing users incurs costs, and advertisers have limited budgets and expect the adoptions to be maximized soon. Facing these user, monetary, and timing constraints, we formulate the problem as a submodular maximization task in a continuous-time diffusion model under the intersection of a matroid and multiple knapsack constraints. We propose a randomized algorithm estimating the user influence in a network ($ \mathcal{V} $ nodes, $ \mathcal{E} $ edges) to an accuracy of $\epsilon$ with $n=\mathcal{O}(1/\epsilon^2)$ randomizations and $\tilde{\mathcal{O}}(n \mathcal{E} +n \mathcal{V} )$ computations. By exploiting the influence estimation algorithm as a subroutine, we develop an adaptive threshold greedy algorithm achieving an approximation factor $k_a/(2+2 k)$ of the optimal when $k_a$ out of the $k$ knapsack constraints are active. Extensive experiments on networks of millions of nodes demonstrate that the proposed algorithms achieve the state-of-the-art in terms of effectiveness and scalability. version:1
arxiv-1612-02709 | Predicting Ground-Level Scene Layout from Aerial Imagery | http://arxiv.org/abs/1612.02709 | id:1612.02709 author:Menghua Zhai, Zachary Bessinger, Scott Workman, Nathan Jacobs category:cs.CV  published:2016-12-08 summary:We introduce a novel strategy for learning to extract semantically meaningful features from aerial imagery. Instead of manually labeling the aerial imagery, we propose to predict (noisy) semantic features automatically extracted from co-located ground imagery. Our network architecture takes an aerial image as input, extracts features using a convolutional neural network, and then applies an adaptive transformation to map these features into the ground-level perspective. We use an end-to-end learning approach to minimize the difference between the semantic segmentation extracted directly from the ground image and the semantic segmentation predicted solely based on the aerial image. We show that a model learned using this strategy, with no additional training, is already capable of rough semantic labeling of aerial imagery. Furthermore, we demonstrate that by finetuning this model we can achieve more accurate semantic segmentation than two baseline initialization strategies. We use our network to address the task of estimating the geolocation and geoorientation of a ground image. Finally, we show how features extracted from an aerial image can be used to hallucinate a plausible ground-level panorama. version:1
arxiv-1612-02707 | Human powered multiple imputation | http://arxiv.org/abs/1612.02707 | id:1612.02707 author:Lovedeep Gondara category:cs.LG cs.HC stat.ML  published:2016-12-08 summary:Missing data is universal and methods to deal with it far ranging from simply ignoring it to using complex modelling strategies such as multiple imputation and maximum likelihood estimation.Missing data has only been effectively imputed by machines via statistical/machine learning models. In this paper we set to answer an important question "Can humans perform reasonably well to fill in missing data, given information about the dataset?". We do so in a crowdsourcing framework, where we first translate our missing data problem to a survey question, which then can be easily completed by crowdworkers. We address challenges that are inherent to crowdsourcing in our context and present the evaluation on a real dataset. We compare human powered multiple imputation outcomes with state-of-the-art model based imputation. version:1
arxiv-1612-02706 | Mention2Vec: Entity Identification as Multitasking | http://arxiv.org/abs/1612.02706 | id:1612.02706 author:Karl Stratos category:cs.CL  published:2016-12-08 summary:Standard approaches in entity identification hard-code boundary detection and type prediction into labels (e.g., John/B-PER Smith/I-PER) and then perform Viterbi. This has two disadvantages: 1. the runtime complexity grows quadratically in the number of types, and 2. there is no natural segment-level representation. In this paper, we propose a novel neural architecture that addresses these disadvantages. We frame the problem as multitasking, separating boundary detection and type prediction but optimizing them jointly. Despite its simplicity, this architecture performs competitively with fully structured models such as BiLSTM-CRFs while scaling linearly in the number of types. Furthermore, by construction, the model induces type-disambiguating embeddings of predicted mentions. version:1
arxiv-1612-02703 | Embedding Words and Senses Together via Joint Knowledge-Enhanced Training | http://arxiv.org/abs/1612.02703 | id:1612.02703 author:Massimiliano Mancini, Jose Camacho-Collados, Ignacio Iacobacci, Roberto Navigli category:cs.CL  published:2016-12-08 summary:Word embeddings based on neural networks are widely used in Natural Language Processing. However, despite their success in capturing semantic information from massive corpora, word embeddings still conflate different meanings of a word into a single vectorial representation and do not benefit from information available in lexical resources. We address this issue by proposing a new model that jointly learns word and sense embeddings and represents them in a unified vector space by exploiting large corpora and knowledge obtained from semantic networks. We evaluate the main features of our approach qualitatively and quantitatively in various tasks, highlighting the advantages of the proposed method with respect to state-of-the-art word- and sense-based models. version:1
arxiv-1612-02699 | Deep Supervision with Shape Concepts for Occlusion-Aware 3D Object Parsing | http://arxiv.org/abs/1612.02699 | id:1612.02699 author:Chi Li, M. Zeeshan Zia, Quoc-Huy Tran, Xiang Yu, Gregory D. Hager, Manmohan Chandraker category:cs.CV  published:2016-12-08 summary:Monocular 3D object parsing is highly desirable in various scenarios including occlusion reasoning and holistic scene interpretation. We present a deep convolutional neural network (CNN) architecture to localize object semantic parts in 2D image and 3D space while inferring their visibility states, given a single RGB image. Our key insight is to exploit domain knowledge to regularize the network by deeply supervising its hidden layers, in order to sequentially infer a causal sequence of intermediate concepts associated with the final task. To acquire training data in desired quantities with ground truth 3D shape and intermediate concepts, we render 3D object CAD models to generate large-scale synthetic data and simulate challenging occlusion configurations between objects. We train the network only on synthetic data and demonstrate state-of-the-art performances on real image benchmarks including an extended version of KITTI, PASCAL VOC, PASCAL3D+ and IKEA for 2D and 3D keypoint localization and instance segmentation. The empirical results substantiate the utility of deep supervision scheme by demonstrating effective transfer of knowledge from synthetic data to real images, resulting in less overfitting compared to standard end-to-end training. version:1
arxiv-1612-02696 | A note on the triangle inequality for the Jaccard distance | http://arxiv.org/abs/1612.02696 | id:1612.02696 author:Sven Kosub category:cs.DM cs.IR cs.LG stat.ML  published:2016-12-08 summary:Two simple proofs of the triangle inequality for the Jaccard distance in terms of nonnegative, monotone, submodular functions are given and discussed. version:1
arxiv-1612-02695 | Towards better decoding and language model integration in sequence to sequence models | http://arxiv.org/abs/1612.02695 | id:1612.02695 author:Jan Chorowski, Navdeep Jaitly category:cs.NE cs.CL cs.LG stat.ML  published:2016-12-08 summary:The recently proposed Sequence-to-Sequence (seq2seq) framework advocates replacing complex data processing pipelines, such as an entire automatic speech recognition system, with a single neural network trained in an end-to-end fashion. In this contribution, we analyse an attention-based seq2seq speech recognition system that directly transcribes recordings into characters. We observe two shortcomings: overconfidence in its predictions and a tendency to produce incomplete transcriptions when language models are used. We propose practical solutions to both problems achieving competitive speaker independent word error rates on the Wall Street Journal dataset: without separate language models we reach 10.6% WER, while together with a trigram language model, we reach 6.7% WER. version:1
arxiv-1612-02675 | Domain knowledge assisted cyst segmentation in OCT retinal images | http://arxiv.org/abs/1612.02675 | id:1612.02675 author:Karthik Gopinath, Jayanthi Sivaswamy category:cs.CV  published:2016-12-08 summary:3D imaging modalities are becoming increasingly popular and relevant in retinal imaging owing to their effectiveness in highlighting structures in sub-retinal layers. OCT is one such modality which has great importance in the context of analysis of cystoid structures in subretinal layers. Signal to noise ratio(SNR) of the images obtained from OCT is less and hence automated and accurate determination of cystoid structures from OCT is a challenging task. We propose an automated method for detecting/segmenting cysts in 3D OCT volumes. The proposed method is biologically inspired and fast aided by the domain knowledge about the cystoid structures. An ensemble learning methodRandom forests is learnt for classification of detected region into cyst region. The method achieves detection and segmentation in a unified setting. We believe the proposed approach with further improvements can be a promising starting point for more robust approach. This method is validated against the training set achieves a mean dice coefficient of 0.3893 with a standard deviation of 0.2987 version:1
arxiv-1612-04862 | A fuzzy approach for segmentation of touching characters | http://arxiv.org/abs/1612.04862 | id:1612.04862 author:Giuseppe Airò Farulla, Nadir Murru, Rosaria Rossini category:cs.CV  published:2016-12-08 summary:The problem of correctly segmenting touching characters is an hard task to solve and it is of major relevance in pattern recognition. In the recent years, many methods and algorithms have been proposed; still, a definitive solution is far from being found. In this paper, we propose a novel method based on fuzzy logic. The proposed method combines in a novel way three features for segmenting touching characters that have been already proposed in other studies but have been exploited only singularly so far. The proposed strategy is based on a 3--input/1--output fuzzy inference system with fuzzy rules specifically optimized for segmenting touching characters in the case of Latin printed and handwritten characters. The system performances are illustrated and supported by numerical examples showing that our approach can achieve a reasonable good overall accuracy in segmenting characters even on tricky conditions of touching characters. Moreover, numerical results suggest that the method can be applied to many different datasets of characters by means of a convenient tuning of the fuzzy sets and rules. version:1
arxiv-1612-02649 | FCNs in the Wild: Pixel-level Adversarial and Constraint-based Adaptation | http://arxiv.org/abs/1612.02649 | id:1612.02649 author:Judy Hoffman, Dequan Wang, Fisher Yu, Trevor Darrell category:cs.CV  published:2016-12-08 summary:Fully convolutional models for dense prediction have proven successful for a wide range of visual tasks. Such models perform well in a supervised setting, but performance can be surprisingly poor under domain shifts that appear mild to a human observer. For example, training on one city and testing on another in a different geographic region and/or weather condition may result in significantly degraded performance due to pixel-level distribution shift. In this paper, we introduce the first domain adaptive semantic segmentation method, proposing an unsupervised adversarial approach to pixel prediction problems. Our method consists of both global and category specific adaptation techniques. Global domain alignment is performed using a novel semantic segmentation network with fully convolutional domain adversarial learning. This initially adapted space then enables category specific adaptation through a generalization of constrained weak learning, with explicit transfer of the spatial layout from the source to the target domains. Our approach outperforms baselines across different settings on multiple large-scale datasets, including adapting across various real city environments, different synthetic sub-domains, from simulated to real environments, and on a novel large-scale dash-cam dataset. version:1
arxiv-1612-02646 | Learning Video Object Segmentation from Static Images | http://arxiv.org/abs/1612.02646 | id:1612.02646 author:Anna Khoreva, Federico Perazzi, Rodrigo Benenson, Bernt Schiele, Alexander Sorkine-Hornung category:cs.CV  published:2016-12-08 summary:Inspired by recent advances of deep learning in instance segmentation and object tracking, we introduce video object segmentation problem as a concept of guided instance segmentation. Our model proceeds on a per-frame basis, guided by the output of the previous frame towards the object of interest in the next frame. We demonstrate that highly accurate object segmentation in videos can be enabled by using a convnet trained with static images only. The key ingredient of our approach is a combination of offline and online learning strategies, where the former serves to produce a refined mask from the previous frame estimate and the latter allows to capture the appearance of the specific object instance. Our method can handle different types of input annotations: bounding boxes and segments, as well as incorporate multiple annotated frames, making the system suitable for diverse applications. We obtain competitive results on three different datasets, independently from the type of input annotation. version:1
arxiv-1612-02631 | Progressive Tree-like Curvilinear Structure Reconstruction with Structured Ranking Learning and Graph Algorithm | http://arxiv.org/abs/1612.02631 | id:1612.02631 author:Seong-Gyun Jeong, Yuliya Tarabalka, Nicolas Nisse, Josiane Zerubia category:cs.CV  published:2016-12-08 summary:We propose a novel tree-like curvilinear structure reconstruction algorithm based on supervised learning and graph theory. In this work we analyze image patches to obtain the local major orientations and the rankings that correspond to the curvilinear structure. To extract local curvilinear features, we compute oriented gradient information using steerable filters. We then employ Structured Support Vector Machine for ordinal regression of the input image patches, where the ordering is determined by shape similarity to latent curvilinear structure. Finally, we progressively reconstruct the curvilinear structure by looking for geodesic paths connecting remote vertices in the graph built on the structured output rankings. Experimental results show that the proposed algorithm faithfully provides topological features of the curvilinear structures using minimal pixels for various datasets. version:1
arxiv-1612-03080 | Characterizing the maximum parameter of the total-variation denoising through the pseudo-inverse of the divergence | http://arxiv.org/abs/1612.03080 | id:1612.03080 author:Charles-Alban Deledalle, Nicolas Papadakis, Joseph Salmon, Samuel Vaiter category:stat.ML  published:2016-12-08 summary:We focus on the maximum regularization parameter for anisotropic total-variation denoising. It corresponds to the minimum value of the regularization parameter above which the solution remains constant. While this value is well know for the Lasso, such a critical value has not been investigated in details for the total-variation. Though, it is of importance when tuning the regularization parameter as it allows fixing an upper-bound on the grid for which the optimal parameter is sought. We establish a closed form expression for the one-dimensional case, as well as an upper-bound for the two-dimensional case, that appears reasonably tight in practice. This problem is directly linked to the computation of the pseudo-inverse of the divergence, which can be quickly obtained by performing convolutions in the Fourier domain. version:1
arxiv-1612-02605 | Towards Information-Seeking Agents | http://arxiv.org/abs/1612.02605 | id:1612.02605 author:Philip Bachman, Alessandro Sordoni, Adam Trischler category:cs.LG  published:2016-12-08 summary:We develop a general problem setting for training and testing the ability of agents to gather information efficiently. Specifically, we present a collection of tasks in which success requires searching through a partially-observed environment, for fragments of information which can be pieced together to accomplish various goals. We combine deep architectures with techniques from reinforcement learning to develop agents that solve our tasks. We shape the behavior of these agents by combining extrinsic and intrinsic rewards. We empirically demonstrate that these agents learn to search actively and intelligently for new information to reduce their uncertainty, and to exploit information they have already acquired. version:1
arxiv-1612-04739 | An Architecture for Deep, Hierarchical Generative Models | http://arxiv.org/abs/1612.04739 | id:1612.04739 author:Philip Bachman category:cs.LG  published:2016-12-08 summary:We present an architecture which lets us train deep, directed generative models with many layers of latent variables. We include deterministic paths between all latent variables and the generated output, and provide a richer set of connections between computations for inference and generation, which enables more effective communication of information throughout the model during training. To improve performance on natural images, we incorporate a lightweight autoregressive model in the reconstruction distribution. These techniques permit end-to-end training of models with 10+ layers of latent variables. Experiments show that our approach achieves state-of-the-art performance on standard image modelling benchmarks, can expose latent class structure in the absence of label information, and can provide convincing imputations of occluded regions in natural images. version:1
arxiv-1612-02589 | Multi-source Transfer Learning with Convolutional Neural Networks for Lung Pattern Analysis | http://arxiv.org/abs/1612.02589 | id:1612.02589 author:Stergios Christodoulidis, Marios Anthimopoulos, Lukas Ebner, Andreas Christe, Stavroula Mougiakakou category:cs.CV stat.ML  published:2016-12-08 summary:Early diagnosis of interstitial lung diseases is crucial for their treatment, but even experienced physicians find it difficult, as their clinical manifestations are similar. In order to assist with the diagnosis, computer-aided diagnosis (CAD) systems have been developed. These commonly rely on a fixed scale classifier that scans CT images, recognizes textural lung patterns and generates a map of pathologies. In a previous study, we proposed a method for classifying lung tissue patterns using a deep convolutional neural network (CNN), with an architecture designed for the specific problem. In this study, we present an improved method for training the proposed network by transferring knowledge from the similar domain of general texture classification. Six publicly available texture databases are used to pretrain networks with the proposed architecture, which are then fine-tuned on the lung tissue data. The resulting CNNs are combined in an ensemble and their fused knowledge is compressed back to a network with the original architecture. The proposed approach resulted in an absolute increase of about 2% in the performance of the proposed CNN. The results demonstrate the potential of transfer learning in the field of medical image analysis, indicate the textural nature of the problem and show that the method used for training a network can be as important as designing its architecture. version:1
arxiv-1612-02583 | From Motion Blur to Motion Flow: a Deep Learning Solution for Removing Heterogeneous Motion Blur | http://arxiv.org/abs/1612.02583 | id:1612.02583 author:Dong Gong, Jie Yang, Lingqiao Liu, Yanning Zhang, Ian Reid, Chunhua Shen, Anton van den Hengel, Qinfeng Shi category:cs.CV  published:2016-12-08 summary:Removing pixel-wise heterogeneous motion blur is challenging due to the ill-posed nature of the problem. The predominant solution is to estimate the blur kernel by adding a prior, but the extensive literature on the subject indicates the difficulty in identifying a prior which is suitably informative, and general. Rather than imposing a prior based on theory, we propose instead to learn one from the data. Learning a prior over the latent image would require modeling all possible image content. The critical observation underpinning our approach is thus that learning the motion flow instead allows the model to focus on the cause of the blur, irrespective of the image content. This is a much easier learning task, but it also avoids the iterative process through which latent image priors are typically applied. Our approach directly estimates the motion flow from the blurred image through a fully-convolutional deep neural network (FCN) and recovers the unblurred image from the estimated motion flow. Our FCN is the first universal end-to-end mapping from the blurred image to the dense motion flow. To train the FCN, we simulate motion flows to generate synthetic blurred-image-motion-flow pairs thus avoiding the need for human labeling. Extensive experiments on challenging realistic blurred images demonstrate that the proposed method outperforms the state-of-the-art. version:1
arxiv-1612-07120 | Imaging around corners with single-pixel detector by computational ghost imaging | http://arxiv.org/abs/1612.07120 | id:1612.07120 author:Bin Bai, Jianbin Liu, Yu Zhou, Songlin Zhang, Yuchen He, Zhuo Xu category:cs.CV physics.optics  published:2016-12-08 summary:We have designed a single-pixel camera with imaging around corners based on computational ghost imaging. It can obtain the image of an object when the camera cannot look at the object directly. Our imaging system explores the fact that a bucket detector in a ghost imaging setup has no spatial resolution capability. A series of experiments have been designed to confirm our predictions. This camera has potential applications for imaging around corner or other similar environments where the object cannot be observed directly. version:1
arxiv-1612-02575 | Filter sharing: Efficient learning of parameters for volumetric convolutions | http://arxiv.org/abs/1612.02575 | id:1612.02575 author:Rahul Venkataramani, Sheshadri Thiruvenkadam, Prasad Sudhakar, Hariharan Ravishankar, Vivek Vaidya category:cs.CV  published:2016-12-08 summary:Typical convolutional neural networks (CNNs) have several millions of parameters and require a large amount of annotated data to train them. In medical applications where training data is hard to come by, these sophisticated machine learning models are difficult to train. In this paper, we propose a method to reduce the inherent complexity of CNNs during training by exploiting the significant redundancy that is noticed in the learnt CNN filters. Our method relies on finding a small set of filters and mixing coefficients to derive every filter in each convolutional layer at the time of training itself, thereby reducing the number of parameters to be trained. We consider the problem of 3D lung nodule segmentation in CT images and demonstrate the effectiveness of our method in achieving good results with only few training examples. version:1
arxiv-1612-02572 | Predicting brain age with deep learning from raw imaging data results in a reliable and heritable biomarker | http://arxiv.org/abs/1612.02572 | id:1612.02572 author:James H Cole, Rudra PK Poudel, Dimosthenis Tsagkrasoulis, Matthan WA Caan, Claire Steves, Tim D Spector, Giovanni Montana category:stat.ML cs.CV cs.LG q-bio.NC  published:2016-12-08 summary:Machine learning analysis of neuroimaging data can accurately predict chronological age in healthy people and deviations from healthy brain ageing have been associated with cognitive impairment and disease. Here we sought to further establish the credentials of "brain-predicted age" as a biomarker of individual differences in the brain ageing process, using a predictive modelling approach based on deep learning, and specifically convolutional neural networks (CNN), and applied to both pre-processed and raw T1-weighted MRI data. Firstly, we aimed to demonstrate the accuracy of CNN brain-predicted age using a large dataset of healthy adults (N = 2001). Next, we sought to establish the heritability of brain-predicted age using a sample of monozygotic and dizygotic female twins (N = 62). Thirdly, we examined the test-retest and multi-centre reliability of brain-predicted age using two samples (within-scanner N = 20; between-scanner N = 11). CNN brain-predicted ages were generated and compared to a Gaussian Process Regression (GPR) approach, on all datasets. Input data were grey matter (GM) or white matter (WM) volumetric maps generated by Statistical Parametric Mapping (SPM) or raw data. Brain-predicted age represents an accurate, highly reliable and genetically-valid phenotype, that has potential to be used as a biomarker of brain ageing. Moreover, age predictions can be accurately generated on raw T1-MRI data, substantially reducing computation time for novel data, bringing the process closer to giving real-time information on brain health in clinical settings. version:1
arxiv-1612-00767 | Asynchronous Stochastic Gradient MCMC with Elastic Coupling | http://arxiv.org/abs/1612.00767 | id:1612.00767 author:Jost Tobias Springenberg, Aaron Klein, Stefan Falkner, Frank Hutter category:stat.ML cs.AI cs.LG  published:2016-12-02 summary:We consider parallel asynchronous Markov Chain Monte Carlo (MCMC) sampling for problems where we can leverage (stochastic) gradients to define continuous dynamics which explore the target distribution. We outline a solution strategy for this setting based on stochastic gradient Hamiltonian Monte Carlo sampling (SGHMC) which we alter to include an elastic coupling term that ties together multiple MCMC instances. The proposed strategy turns inherently sequential HMC algorithms into asynchronous parallel versions. First experiments empirically show that the resulting parallel sampler significantly speeds up exploration of the target distribution, when compared to standard SGHMC, and is less prone to the harmful effects of stale gradients than a naive parallelization approach. version:2
arxiv-1612-02287 | Global Hypothesis Generation for 6D Object Pose Estimation | http://arxiv.org/abs/1612.02287 | id:1612.02287 author:Frank Michel, Alexander Kirillov, Eric Brachmann, Alexander Krull, Stefan Gumhold, Bogdan Savchynskyy, Carsten Rother category:cs.CV  published:2016-12-07 summary:This paper addresses the task of estimating the 6D pose of a known 3D object from a single RGB-D image. Most modern approaches solve this task in three steps: i) Compute local features; ii) Generate a pool of pose-hypotheses; iii) Select and refine a pose from the pool. This work focuses on the second step. While all existing approaches generate the hypotheses pool via local reasoning, e.g. RANSAC or Hough-voting, we are the first to show that global reasoning is beneficial at this stage. In particular, we formulate a novel fully-connected Conditional Random Field (CRF) that outputs a very small number of pose-hypotheses. Despite the potential functions of the CRF being non-Gaussian, we give a new and efficient two-step optimization procedure, with some guarantees for optimality. We utilize our global hypotheses generation procedure to produce results that exceed state-of-the-art for the challenging "Occluded Object Dataset". version:2
arxiv-1612-02562 | Classification of Neurological Gait Disorders Using Multi-task Feature Learning | http://arxiv.org/abs/1612.02562 | id:1612.02562 author:Ioannis Papavasileiou, Wenlong Zhang, Song Han, Xin Wang, Jinbo Bi, Nancy Byl, Masayoshi Tomizuka category:cs.CV 68T10  published:2016-12-08 summary:As our population ages, neurological impairments and degeneration of the musculoskeletal system yield gait abnormalities, which can significantly reduce quality of life. Gait rehabilitation therapy has been widely adopted to help these patients retrain central nervous system physiology to maximize community participation and independence. To further improve the rehabilitative therapy provided to the patients, more objective methods need to be used and rely less in the subjective judgment of the therapist and patient. In this paper, an algorithmic framework is proposed to provide classification of gait affected by two common neurological diseases, stroke and Parkinson's Disease (PD), from ground contact force (GCF) data. An advanced machine learning method, multi-task learning (MTL), is used to jointly train classification models of subject's gait in three classes, stroke, Parkinson's and healthy gait. Gait parameters that can capture gait patterns related to mobility, balance, strength and gait phases are used as features for the classification. Out of all the parameters used, the MTL models capture the important ones per disease and help provide better objective assessment and therapy progress tracking. To evaluate the proposed methodology we use data from a human participant study, including five PD patients, three post-stroke patients, and three healthy subjects. Despite the diversity of the abnormalities caused from each disease, the evaluation shows that the proposed approach can successfully distinguish patient's gait from these diseases and healthy gait. Moreover, the proposed machine learning methods select the best gait parameters from each category. This work can open new research directions in effective gait assessment, targeted treatment and therapy progress tracking. version:1
arxiv-1612-02559 | AGA: Attribute Guided Augmentation | http://arxiv.org/abs/1612.02559 | id:1612.02559 author:Mandar Dixit, Roland Kwitt, Marc Niethammer, Nuno Vasconcelos category:cs.CV  published:2016-12-08 summary:We consider the problem of data augmentation, i.e., generating artificial samples to extend a given corpus of training data. Specifically, we propose attributed-guided augmentation (AGA) which learns a mapping that allows to synthesize data such that an attribute of a synthesized sample is at a desired value or strength. This is particularly interesting in situations where little data with no attribute annotation is available for learning, but we have access to a large external corpus of heavily annotated samples. While prior works primarily augment in the space of images, we propose to perform augmentation in feature space instead. We implement our approach as a deep encoder-decoder architecture that learns the synthesis function in an end-to-end manner. We demonstrate the utility of our approach on the problems of (1) one-shot object recognition in a transfer-learning setting where we have no prior knowledge of the new classes, as well as (2) object-based one-shot scene recognition. As external data, we leverage 3D depth and pose information from the SUN RGB-D dataset. Our experiments show that attribute-guided augmentation of high-level CNN features considerably improves one-shot recognition performance on both problems. version:1
arxiv-1612-02541 | Query-adaptive Image Retrieval by Deep Weighted Hashing | http://arxiv.org/abs/1612.02541 | id:1612.02541 author:Jian Zhang, Yuxin Peng, Junchao Zhang category:cs.CV H.3.1; H.3.3  published:2016-12-08 summary:The hashing methods have attracted much attention for large scale image retrieval. Some deep hashing methods have achieved promising results by taking advantage of the better representation power of deep networks recently. However, existing deep hashing methods treat all hash bits equally. On one hand, a large number of images share the same distance to a query image because of the discrete Hamming distance, which cannot provide fine-grained retrieval since the ranking of these images is ambiguous. On the other hand, different hash bits actually contribute to the image retrieval differently, treating them equally greatly affects the image retrieval accuracy. To address the two problems, we propose the query-adaptive deep weighted hashing (QaDWH) approach, which can perform fine-grained image retrieval for different queries by weighted Hamming distance. First, a novel deep hashing network is designed to learn the hash codes and corresponding class-wise hash bit weights jointly, so that the learned weights can reflect the importance of different hash bits for different image class. Second, a query-adaptive image retrieval method is proposed, which rapidly generate query image's hash bit weights by the fusion of the semantic probability of the query and the learned class-wise weights. Fine-grained image retrieval is then performed by the weighted Hamming distance, which can provide more accurate ranking than the original Hamming distance. Extensive experiments on 3 widely used datasets show that the proposed approach outperforms state-of-the-art hashing methods. version:1
arxiv-1612-02534 | Contextual Visual Similarity | http://arxiv.org/abs/1612.02534 | id:1612.02534 author:Xiaofang Wang, Kris M. Kitani, Martial Hebert category:cs.CV  published:2016-12-08 summary:Measuring visual similarity is critical for image understanding. But what makes two images similar? Most existing work on visual similarity assumes that images are similar because they contain the same object instance or category. However, the reason why images are similar is much more complex. For example, from the perspective of category, a black dog image is similar to a white dog image. However, in terms of color, a black dog image is more similar to a black horse image than the white dog image. This example serves to illustrate that visual similarity is ambiguous but can be made precise when given an explicit contextual perspective. Based on this observation, we propose the concept of contextual visual similarity. To be concrete, we examine the concept of contextual visual similarity in the application domain of image search. Instead of providing only a single image for image similarity search (\eg, Google image search), we require three images. Given a query image, a second positive image and a third negative image, dissimilar to the first two images, we define a contextualized similarity search criteria. In particular, we learn feature weights over all the feature dimensions of each image such that the distance between the query image and the positive image is small and their distances to the negative image are large after reweighting their features. The learned feature weights encode the contextualized visual similarity specified by the user and can be used for attribute specific image search. We also show the usefulness of our contextualized similarity weighting scheme for different tasks, such as answering visual analogy questions and unsupervised attribute discovery. version:1
arxiv-1612-02528 | Smoothing Effects of Bagging: Von Mises Expansions of Bagged Statistical Functionals | http://arxiv.org/abs/1612.02528 | id:1612.02528 author:Andreas Buja, Werner Stuetzle category:stat.ML 62G09  published:2016-12-08 summary:Bagging is a device intended for reducing the prediction error of learning algorithms. In its simplest form, bagging draws bootstrap samples from the training sample, applies the learning algorithm to each bootstrap sample, and then averages the resulting prediction rules. We extend the definition of bagging from statistics to statistical functionals and study the von Mises expansion of bagged statistical functionals. We show that the expansion is related to the Efron-Stein ANOVA expansion of the raw (unbagged) functional. The basic observation is that a bagged functional is always smooth in the sense that the von Mises expansion exists and is finite of length 1 + resample size $M$. This holds even if the raw functional is rough or unstable. The resample size $M$ acts as a smoothing parameter, where a smaller $M$ means more smoothing. version:1
arxiv-1612-02526 | Prediction with a Short Memory | http://arxiv.org/abs/1612.02526 | id:1612.02526 author:Sham Kakade, Percy Liang, Vatsal Sharan, Gregory Valiant category:cs.LG cs.AI cs.CC stat.ML  published:2016-12-08 summary:We consider the problem of predicting the next observation given a sequence of past observations. We show that for any distribution over observations, if the mutual information between past observations and future observations is upper bounded by $I$, then a simple Markov model over the most recent $I/\epsilon$ observations can obtain KL error $\epsilon$ with respect to the optimal predictor with access to the entire past. For a Hidden Markov Model with $n$ states, $I$ is bounded by $\log n$, a quantity that does not depend on the mixing time. We also demonstrate that the simple Markov model cannot really be improved upon: First, a window length of $I/\epsilon$ ($I/\epsilon^2$) is information-theoretically necessary for KL error ($\ell_1$ error). Second, the $d^{\Theta(I/\epsilon)}$ samples required to accurately estimate the Markov model when observations are drawn from an alphabet of size $d$ is in fact necessary for any computationally tractable algorithm, assuming the hardness of strongly refuting a certain class of CSPs. version:1
arxiv-1612-02522 | Geometric Decomposition of Feed Forward Neural Networks | http://arxiv.org/abs/1612.02522 | id:1612.02522 author:Sven Cattell category:cs.NE math.CO 92B20  published:2016-12-08 summary:There have been several attempts to mathematically understand neural networks and many more from biological and computational perspectives. The field has exploded in the last decade, yet neural networks are still treated much like a black box. In this work we describe a structure that is inherent to a feed forward neural network. This will provide a framework for future work on neural networks to improve training algorithms, compute the homology of the network, and other applications. Our approach takes a more geometric point of view and is unlike other attempts to mathematically understand neural networks that rely on a functional perspective. version:1
arxiv-1612-02521 | An Efficient Algorithm for the Piecewise-Smooth Model with Approximately Explicit Solutions | http://arxiv.org/abs/1612.02521 | id:1612.02521 author:Huihui Song, Yuhui Zheng, Kaihua Zhang category:cs.CV  published:2016-12-08 summary:This paper presents an efficient approach to image segmentation that approximates the piecewise-smooth (PS) functional in [12] with explicit solutions. By rendering some rational constraints on the initial conditions and the final solutions of the PS functional, we propose two novel formulations which can be approximated to be the explicit solutions of the evolution partial differential equations (PDEs) of the PS model, in which only one PDE needs to be solved efficiently. Furthermore, an energy term that regularizes the level set function to be a signed distance function is incorporated into our evolution formulation, and the time-consuming re-initialization is avoided. Experiments on synthetic and real images show that our method is more efficient than both the PS model and the local binary fitting (LBF) model [4], while having similar segmentation accuracy as the LBF model. version:1
arxiv-1612-02516 | Stochastic Primal-Dual Methods and Sample Complexity of Reinforcement Learning | http://arxiv.org/abs/1612.02516 | id:1612.02516 author:Yichen Chen, Mengdi Wang category:stat.ML cs.AI math.OC  published:2016-12-08 summary:We study the online estimation of the optimal policy of a Markov decision process (MDP). We propose a class of Stochastic Primal-Dual (SPD) methods which exploit the inherent minimax duality of Bellman equations. The SPD methods update a few coordinates of the value and policy estimates as a new state transition is observed. These methods use small storage and has low computational complexity per iteration. The SPD methods find an absolute-$\epsilon$-optimal policy, with high probability, using $\mathcal{O}\left(\frac{ \mathcal{S} ^4 \mathcal{A} ^2\sigma^2 }{(1-\gamma)^6\epsilon^2} \right)$ iterations/samples for the infinite-horizon discounted-reward MDP and $\mathcal{O}\left(\frac{ \mathcal{S} ^4 \mathcal{A} ^2H^6\sigma^2 }{\epsilon^2} \right)$ for the finite-horizon MDP. version:1
arxiv-1612-02513 | Complex Matrix Factorization for Face Recognition | http://arxiv.org/abs/1612.02513 | id:1612.02513 author:Viet-Hang Duong, Yuan-Shan Lee, Bach-Tung Pham, Seksan Mathulaprangsan, Pham The Bao, Jia-Ching Wang category:cs.CV  published:2016-12-08 summary:This work developed novel complex matrix factorization methods for face recognition; the methods were complex matrix factorization (CMF), sparse complex matrix factorization (SpaCMF), and graph complex matrix factorization (GraCMF). After real-valued data are transformed into a complex field, the complex-valued matrix will be decomposed into two matrices of bases and coefficients, which are derived from solutions to an optimization problem in a complex domain. The generated objective function is the real-valued function of the reconstruction error, which produces a parametric description. Factorizing the matrix of complex entries directly transformed the constrained optimization problem into an unconstrained optimization problem. Additionally, a complex vector space with N dimensions can be regarded as a 2N-dimensional real vector space. Accordingly, all real analytic properties can be exploited in the complex field. The ability to exploit these important characteristics motivated the development herein of a simpler framework that can provide better recognition results. The effectiveness of this framework will be clearly elucidated in later sections in this paper. version:1
arxiv-1612-02498 | Discrete Schroedinger Transform For Texture Recognition | http://arxiv.org/abs/1612.02498 | id:1612.02498 author:João B. Florindo, Odemir M. Bruno category:cs.CV physics.data-an  published:2016-12-08 summary:This work presents a new procedure to extract features of grey-level texture images based on the discrete Schroedinger transform. This is a non-linear transform where the image is mapped as the initial probability distribution of a wave function and such distribution evolves in time following the Schroedinger equation from Quantum Mechanics. The features are provided by statistical moments of the distribution measured at different times. The proposed method is applied to the classification of three databases of textures used for benchmark and compared to other well-known texture descriptors in the literature, such as textons, local binary patterns, multifractals, among others. All of them are outperformed by the proposed method in terms of percentage of images correctly classified. The proposal is also applied to the identification of plant species using scanned images of leaves and again it outperforms other texture methods. A test with images affected by Gaussian and "salt \& pepper" noise is also carried out, also with the best performance achieved by the Schroedinger descriptors. version:1
arxiv-1612-00595 | Parallel Chromatic MCMC with Spatial Partitioning | http://arxiv.org/abs/1612.00595 | id:1612.00595 author:Jun Song, David A. Moore category:stat.ML  published:2016-12-02 summary:We introduce a novel approach for parallelizing MCMC inference in models with spatially determined conditional independence relationships, for which existing techniques exploiting graphical model structure are not applicable. Our approach is motivated by a model of seismic events and signals, where events detected in distant regions are approximately independent given those in intermediate regions. We perform parallel inference by coloring a factor graph defined over regions of latent space, rather than individual model variables. Evaluating on a model of seismic event detection, we achieve significant speedups over serial MCMC with no degradation in inference quality. version:2
arxiv-1612-02493 | Research on the Multiple Feature Fusion Image Retrieval Algorithm based on Texture Feature and Rough Set Theory | http://arxiv.org/abs/1612.02493 | id:1612.02493 author:Xiaojie Shi, Yijun Shao category:cs.CV  published:2016-12-08 summary:Recently, we have witnessed the explosive growth of images with complex information and content. In order to effectively and precisely retrieve desired images from a large-scale image database with low time-consuming, we propose the multiple feature fusion image retrieval algorithm based on the texture feature and rough set theory in this paper. In contrast to the conventional approaches that only use the single feature or standard, we fuse the different features with operation of normalization. The rough set theory will assist us to enhance the robustness of retrieval system when facing with incomplete data warehouse. To enhance the texture extraction paradigm, we use the wavelet Gabor function that holds better robustness. In addition, from the perspectives of the internal and external normalization, we re-organize extracted feature with the better combination. The numerical experiment has verified general feasibility of our methodology. We enhance the overall accuracy compared with the other state-of-the-art algorithms. version:1
arxiv-1612-02893 | A Review of Intelligent Practices for Irrigation Prediction | http://arxiv.org/abs/1612.02893 | id:1612.02893 author:Hans Krupakar, Akshay Jayakumar, Dhivya G category:cs.LG cs.NE  published:2016-12-07 summary:Population growth and increasing droughts are creating unprecedented strain on the continued availability of water resources. Since irrigation is a major consumer of fresh water, wastage of resources in this sector could have strong consequences. To address this issue, irrigation water management and prediction techniques need to be employed effectively and should be able to account for the variabilities present in the environment. The different techniques surveyed in this paper can be classified into two categories: computational and statistical. Computational methods deal with scientific correlations between physical parameters whereas statistical methods involve specific prediction algorithms that can be used to automate the process of irrigation water prediction. These algorithms interpret semantic relationships between the various parameters of temperature, pressure, evapotranspiration etc. and store them as numerical precomputed entities specific to the conditions and the area used as the data for the training corpus used to train it. We focus on reviewing the computational methods used to determine Evapotranspiration and its implications. We compare the efficiencies of different data mining and machine learning methods implemented in this area, such as Logistic Regression, Decision Tress Classifier, SysFor, Support Vector Machine(SVM), Fuzzy Logic techniques, Artifical Neural Networks(ANNs) and various hybrids of Genetic Algorithms (GA) applied to irrigation prediction. We also recommend a possible technique for the same based on its superior results in other such time series analysis tasks. version:1
arxiv-1612-02334 | Robust Low-Complexity Randomized Methods for Locating Outliers in Large Matrices | http://arxiv.org/abs/1612.02334 | id:1612.02334 author:Xingguo Li, Jarvis Haupt category:cs.IT cs.LG math.IT stat.ML  published:2016-12-07 summary:This paper examines the problem of locating outlier columns in a large, otherwise low-rank matrix, in settings where {}{the data} are noisy, or where the overall matrix has missing elements. We propose a randomized two-step inference framework, and establish sufficient conditions on the required sample complexities under which these methods succeed (with high probability) in accurately locating the outliers for each task. Comprehensive numerical experimental results are provided to verify the theoretical bounds and demonstrate the computational efficiency of the proposed algorithm. version:1
arxiv-1612-07119 | FINN: A Framework for Fast, Scalable Binarized Neural Network Inference | http://arxiv.org/abs/1612.07119 | id:1612.07119 author:Yaman Umuroglu, Nicholas J. Fraser, Giulio Gambardella, Michaela Blott, Philip Leong, Magnus Jahre, Kees Vissers category:cs.CV cs.AR cs.LG  published:2016-12-01 summary:Research has shown that convolutional neural networks contain significant redundancy, and high classification accuracy can be obtained even when weights and activations are reduced from floating point to binary values. In this paper, we present FINN, a framework for building fast and flexible FPGA accelerators using a flexible heterogeneous streaming architecture. By utilizing a novel set of optimizations that enable efficient mapping of binarized neural networks to hardware, we implement fully connected, convolutional and pooling layers, with per-layer compute resources being tailored to user-provided throughput requirements. On a ZC706 embedded FPGA platform drawing less than 25 W total system power, we demonstrate up to 12.3 million image classifications per second with 0.31 {\mu}s latency on the MNIST dataset with 95.8% accuracy, and 21906 image classifications per second with 283 {\mu}s latency on the CIFAR-10 and SVHN datasets with respectively 80.1% and 94.9% accuracy. To the best of our knowledge, ours are the fastest classification rates reported to date on these benchmarks. version:1
