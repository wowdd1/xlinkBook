arxiv-1708-09105 | Simultaneously Color-Depth Super-Resolution with Conditional Generative Adversarial Network | http://arxiv.org/abs/1708.09105 | id:1708.09105 author:Lijun Zhao, Jie Liang, Huihui Bai, Anhong Wang, Yao Zhao category:cs.CV  published:2017-08-30 summary:Recently, Generative Adversarial Network (GAN) has been found wide applications in style transfer, image-to-image translation and image super-resolution. In this paper, a color-depth conditional GAN is proposed to concurrently resolve the problems of depth super-resolution and color super-resolution in 3D videos. Firstly, given the low-resolution depth image and low-resolution color image, a generative network is proposed to leverage mutual information of color image and depth image to enhance each other in consideration of the geometry structural dependency of color-depth image in the same scene. Secondly, three loss functions, including data loss, total variation loss, and 8-connected gradient difference loss are introduced to train this generative network in order to keep generated images close to the real ones, in addition to the adversarial loss. Experimental results demonstrate that the proposed approach produces high-quality color image and depth image from low-quality image pair, and it is superior to several other leading methods. Besides, the applications of the proposed method in other tasks are image smoothing and edge detection at the same time. version:1
arxiv-1708-09090 | Automating Direct Speech Variations in Stories and Games | http://arxiv.org/abs/1708.09090 | id:1708.09090 author:Stephanie M. Lukin, James O. Ryan, Marilyn A. Walker category:cs.CL  published:2017-08-30 summary:Dialogue authoring in large games requires not only content creation but the subtlety of its delivery, which can vary from character to character. Manually authoring this dialogue can be tedious, time-consuming, or even altogether infeasible. This paper utilizes a rich narrative representation for modeling dialogue and an expressive natural language generation engine for realizing it, and expands upon a translation tool that bridges the two. We add functionality to the translator to allow direct speech to be modeled by the narrative representation, whereas the original translator supports only narratives told by a third person narrator. We show that we can perform character substitution in dialogues. We implement and evaluate a potential application to dialogue implementation: generating dialogue for games with big, dynamic, or procedurally-generated open worlds. We present a pilot study on human perceptions of the personalities of characters using direct speech, assuming unknown personality types at the time of authoring. version:1
arxiv-1708-09085 | Argument Strength is in the Eye of the Beholder: Audience Effects in Persuasion | http://arxiv.org/abs/1708.09085 | id:1708.09085 author:Stephanie M. Lukin, Pranav Anand, Marilyn Walker, Steve Whittaker category:cs.CL  published:2017-08-30 summary:Americans spend about a third of their time online, with many participating in online conversations on social and political issues. We hypothesize that social media arguments on such issues may be more engaging and persuasive than traditional media summaries, and that particular types of people may be more or less convinced by particular styles of argument, e.g. emotional arguments may resonate with some personalities while factual arguments resonate with others. We report a set of experiments testing at large scale how audience variables interact with argument style to affect the persuasiveness of an argument, an under-researched topic within natural language processing. We show that belief change is affected by personality factors, with conscientious, open and agreeable people being more convinced by emotional arguments. version:1
arxiv-1708-09083 | Adaptive SVM+: Learning with Privileged Information for Domain Adaptation | http://arxiv.org/abs/1708.09083 | id:1708.09083 author:Nikolaos Sarafianos, Michalis Vrigkas, Ioannis A. Kakadiaris category:cs.CV  published:2017-08-30 summary:Incorporating additional knowledge in the learning process can be beneficial for several computer vision and machine learning tasks. Whether privileged information originates from a source domain that is adapted to a target domain, or as additional features available at training time only, using such privileged (i.e., auxiliary) information is of high importance as it improves the recognition performance and generalization. However, both primary and privileged information are rarely derived from the same distribution, which poses an additional challenge to the recognition task. To address these challenges, we present a novel learning paradigm that leverages privileged information in a domain adaptation setup to perform visual recognition tasks. The proposed framework, named Adaptive SVM+, combines the advantages of both the learning using privileged information (LUPI) paradigm and the domain adaptation framework, which are naturally embedded in the objective function of a regular SVM. We demonstrate the effectiveness of our approach on the publicly available Animals with Attributes and INTERACT datasets and report state-of-the-art results in both of them. version:1
arxiv-1708-09082 | PersonaBank: A Corpus of Personal Narratives and Their Story Intention Graphs | http://arxiv.org/abs/1708.09082 | id:1708.09082 author:Stephanie M. Lukin, Kevin Bowden, Casey Barackman, Marilyn A. Walker category:cs.CL  published:2017-08-30 summary:We present a new corpus, PersonaBank, consisting of 108 personal stories from weblogs that have been annotated with their Story Intention Graphs, a deep representation of the fabula of a story. We describe the topics of the stories and the basis of the Story Intention Graph representation, as well as the process of annotating the stories to produce the Story Intention Graphs and the challenges of adapting the tool to this new personal narrative domain We also discuss how the corpus can be used in applications that retell the story using different styles of tellings, co-tellings, or as a content planner. version:1
arxiv-1708-09072 | Continual One-Shot Learning of Hidden Spike-Patterns with Neural Network Simulation Expansion and STDP Convergence Predictions | http://arxiv.org/abs/1708.09072 | id:1708.09072 author:Toby Lightheart, Steven Grainger, Tien-Fu Lu category:q-bio.NC cs.CV stat.ML  published:2017-08-30 summary:This paper presents a constructive algorithm that achieves successful one-shot learning of hidden spike-patterns in a competitive detection task. It has previously been shown (Masquelier et al., 2008) that spike-timing-dependent plasticity (STDP) and lateral inhibition can result in neurons competitively tuned to repeating spike-patterns concealed in high rates of overall presynaptic activity. One-shot construction of neurons with synapse weights calculated as estimates of converged STDP outcomes results in immediate selective detection of hidden spike-patterns. The capability of continual learning is demonstrated through the successful one-shot detection of new sets of spike-patterns introduced after long intervals in the simulation time. Simulation expansion (Lightheart et al., 2013) has been proposed as an approach to the development of constructive algorithms that are compatible with simulations of biological neural networks. A simulation of a biological neural network may have orders of magnitude fewer neurons and connections than the related biological neural systems; therefore, simulated neural networks can be assumed to be a subset of a larger neural system. The constructive algorithm is developed using simulation expansion concepts to perform an operation equivalent to the exchange of neurons between the simulation and the larger hypothetical neural system. The dynamic selection of neurons to simulate within a larger neural system (hypothetical or stored in memory) may be a starting point for a wide range of developments and applications in machine learning and the simulation of biology. version:1
arxiv-1708-09066 | Block-Simultaneous Direction Method of Multipliers: A proximal primal-dual splitting algorithm for nonconvex problems with multiple constraints | http://arxiv.org/abs/1708.09066 | id:1708.09066 author:Fred Moolekamp, Peter Melchior category:math.OC cs.CV cs.LG  published:2017-08-30 summary:We introduce a generalization of the linearized Alternating Direction Method of Multipliers to optimize a real-valued function $f$ of multiple arguments with potentially multiple constraints $g_\circ$ on each of them. The function $f$ may be nonconvex as long as it is convex in every argument, while the constraints $g_\circ$ need to be convex but not smooth. If $f$ is smooth, the proposed Block-Simultaneous Direction Method of Multipliers (bSDMM) can be interpreted as a proximal analog to inexact coordinate descent methods under constraints. Unlike alternative approaches for joint solvers of multiple-constraint problems, we do not require linear operators $L$ of a constraint function $g(L\ \cdot)$ to be invertible or linked between each other. bSDMM is well-suited for a range of optimization problems, in particular for data analysis, where $f$ is the likelihood function of a model and $L$ could be a transformation matrix describing e.g. finite differences or basis transforms. We apply bSDMM to the Non-negative Matrix Factorization task of a hyperspectral unmixing problem and demonstrate convergence and effectiveness of multiple constraints on both matrix factors. The algorithms are implemented in python and released as an open-source package. version:1
arxiv-1708-09056 | Practical Attacks Against Graph-based Clustering | http://arxiv.org/abs/1708.09056 | id:1708.09056 author:Yizheng Chen, Yacin Nadji, Athanasios Kountouras, Fabian Monrose, Roberto Perdisci, Manos Antonakakis, Nikolaos Vasiloglou category:cs.CR cs.LG  published:2017-08-29 summary:Graph modeling allows numerous security problems to be tackled in a general way, however, little work has been done to understand their ability to withstand adversarial attacks. We design and evaluate two novel graph attacks against a state-of-the-art network-level, graph-based detection system. Our work highlights areas in adversarial machine learning that have not yet been addressed, specifically: graph-based clustering techniques, and a global feature space where realistic attackers without perfect knowledge must be accounted for (by the defenders) in order to be practical. Even though less informed attackers can evade graph clustering with low cost, we show that some practical defenses are possible. version:1
arxiv-1708-09038 | Convolutional Sparse Coding with Overlapping Group Norms | http://arxiv.org/abs/1708.09038 | id:1708.09038 author:Brendt Wohlberg category:cs.CV  published:2017-08-29 summary:The most widely used form of convolutional sparse coding uses an $\ell_1$ regularization term. While this approach has been successful in a variety of applications, a limitation of the $\ell_1$ penalty is that it is homogeneous across the spatial and filter index dimensions of the sparse representation array, so that sparsity cannot be separately controlled across these dimensions. The present paper considers the consequences of replacing the $\ell_1$ penalty with a mixed group norm, motivated by recent theoretical results for convolutional sparse representations. Algorithms are developed for solving the resulting problems, which are quite challenging, and the impact on the performance of the denoising problem is evaluated. The mixed group norms are found to perform very poorly in this application. While their performance is greatly improved by introducing a weighting strategy, such a strategy also improves the performance obtained from the much simpler and computationally cheaper $\ell_1$ norm. version:1
arxiv-1708-09025 | Unsupervised Terminological Ontology Learning based on Hierarchical Topic Modeling | http://arxiv.org/abs/1708.09025 | id:1708.09025 author:Xiaofeng Zhu, Diego Klabjan, Patrick Bless category:cs.CL cs.IR cs.LG  published:2017-08-29 summary:In this paper, we present hierarchical relationbased latent Dirichlet allocation (hrLDA), a data-driven hierarchical topic model for extracting terminological ontologies from a large number of heterogeneous documents. In contrast to traditional topic models, hrLDA relies on noun phrases instead of unigrams, considers syntax and document structures, and enriches topic hierarchies with topic relations. Through a series of experiments, we demonstrate the superiority of hrLDA over existing topic models, especially for building hierarchies. Furthermore, we illustrate the robustness of hrLDA in the settings of noisy data sets, which are likely to occur in many practical scenarios. Our ontology evaluation results show that ontologies extracted from hrLDA are very competitive with the ontologies created by domain experts. version:1
arxiv-1708-09740 | Sparse-then-Dense Alignment based 3D Map Reconstruction Method for Endoscopic Capsule Robots | http://arxiv.org/abs/1708.09740 | id:1708.09740 author:Mehmet Turan, Yusuf Yigit Pilavci, Ipek Ganiyusufoglu, Helder Araujo, Ender Konukoglu, Metin Sitti category:cs.CV  published:2017-08-29 summary:Since the development of capsule endoscopcy technology, substantial progress were made in converting passive capsule endoscopes to robotic active capsule endoscopes which can be controlled by the doctor. However, robotic capsule endoscopy still has some challenges. In particular, the use of such devices to generate a precise and globally consistent three-dimensional (3D) map of the entire inner organ remains an unsolved problem. Such global 3D maps of inner organs would help doctors to detect the location and size of diseased areas more accurately, precisely, and intuitively, thus permitting more accurate and intuitive diagnoses. The proposed 3D reconstruction system is built in a modular fashion including preprocessing, frame stitching, and shading-based 3D reconstruction modules. We propose an efficient scheme to automatically select the key frames out of the huge quantity of raw endoscopic images. Together with a bundle fusion approach that aligns all the selected key frames jointly in a globally consistent way, a significant improvement of the mosaic and 3D map accuracy was reached. To the best of our knowledge, this framework is the first complete pipeline for an endoscopic capsule robot based 3D map reconstruction containing all of the necessary steps for a reliable and accurate endoscopic 3D map. For the qualitative evaluations, a real pig stomach is employed. Moreover, for the first time in literature, a detailed and comprehensive quantitative analysis of each proposed pipeline modules is performed using a non-rigid esophagus gastro duodenoscopy simulator, four different endoscopic cameras, a magnetically activated soft capsule robot (MASCE), a sub-millimeter precise optical motion tracker and a fine-scale 3D optical scanner. version:1
arxiv-1708-09021 | A Connectedness Constraint for Learning Sparse Graphs | http://arxiv.org/abs/1708.09021 | id:1708.09021 author:Martin Sundin, Arun Venkitaraman, Magnus Jansson, Saikat Chatterjee category:stat.ML stat.AP  published:2017-08-29 summary:Graphs are naturally sparse objects that are used to study many problems involving networks, for example, distributed learning and graph signal processing. In some cases, the graph is not given, but must be learned from the problem and available data. Often it is desirable to learn sparse graphs. However, making a graph highly sparse can split the graph into several disconnected components, leading to several separate networks. The main difficulty is that connectedness is often treated as a combinatorial property, making it hard to enforce in e.g. convex optimization problems. In this article, we show how connectedness of undirected graphs can be formulated as an analytical property and can be enforced as a convex constraint. We especially show how the constraint relates to the distributed consensus problem and graph Laplacian learning. Using simulated and real data, we perform experiments to learn sparse and connected graphs from data. version:1
arxiv-1708-09006 | Pix2face: Direct 3D Face Model Estimation | http://arxiv.org/abs/1708.09006 | id:1708.09006 author:Daniel Crispell, Maxim Bazik category:cs.CV  published:2017-08-29 summary:An efficient, fully automatic method for 3D face shape and pose estimation in unconstrained 2D imagery is presented. The proposed method jointly estimates a dense set of 3D landmarks and facial geometry using a single pass of a modified version of the popular "U-Net" neural network architecture. Additionally, we propose a method for directly estimating a set of 3D Morphable Model (3DMM) parameters, using the estimated 3D landmarks and geometry as constraints in a simple linear system. Qualitative modeling results are presented, as well as quantitative evaluation of predicted 3D face landmarks in unconstrained video sequences. version:1
arxiv-1708-08994 | Clustering Patients with Tensor Decomposition | http://arxiv.org/abs/1708.08994 | id:1708.08994 author:Matteo Ruffini, Ricard Gavaldà, Esther Limón category:stat.ML cs.LG  published:2017-08-29 summary:In this paper we present a method for the unsupervised clustering of high-dimensional binary data, with a special focus on electronic healthcare records. We present a robust and efficient heuristic to face this problem using tensor decomposition. We present the reasons why this approach is preferable for tasks such as clustering patient records, to more commonly used distance-based methods. We run the algorithm on two datasets of healthcare records, obtaining clinically meaningful results. version:1
arxiv-1708-01204 | Improved Speech Reconstruction from Silent Video | http://arxiv.org/abs/1708.01204 | id:1708.01204 author:Ariel Ephrat, Tavi Halperin, Shmuel Peleg category:cs.CV cs.SD  published:2017-08-01 summary:Speechreading is the task of inferring phonetic information from visually observed articulatory facial movements, and is a notoriously difficult task for humans to perform. In this paper we present an end-to-end model based on a convolutional neural network (CNN) for generating an intelligible and natural-sounding acoustic speech signal from silent video frames of a speaking person. We train our model on speakers from the GRID and TCD-TIMIT datasets, and evaluate the quality and intelligibility of reconstructed speech using common objective measurements. We show that speech predictions from the proposed model attain scores which indicate significantly improved quality over existing models. In addition, we show promising results towards reconstructing speech from an unconstrained dictionary. version:3
arxiv-1709-02236 | Visual Cues to Improve Myoelectric Control of Upper Limb Prostheses | http://arxiv.org/abs/1709.02236 | id:1709.02236 author:Andrea Gigli, Arjan Gijsberts, Valentina Gregori, Matteo Cognolato, Manfredo Atzori, Barbara Caputo category:cs.CV cs.LG  published:2017-08-29 summary:The instability of myoelectric signals over time complicates their use to control highly articulated prostheses. To address this problem, studies have tried to combine surface electromyography with modalities that are less affected by the amputation and environment, such as accelerometry or gaze information. In the latter case, the hypothesis is that a subject looks at the object he or she intends to manipulate and that knowing this object's affordances allows to constrain the set of possible grasps. In this paper, we develop an automated way to detect stable fixations and show that gaze information is indeed helpful in predicting hand movements. In our multimodal approach, we automatically detect stable gazes and segment an object of interest around the subject's fixation in the visual frame. The patch extracted around this object is subsequently fed through an off-the-shelf deep convolutional neural network to obtain a high level feature representation, which is then combined with traditional surface electromyography in the classification stage. Tests have been performed on a dataset acquired from five intact subjects who performed ten types of grasps on various objects as well as in a functional setting. They show that the addition of gaze information increases the classification accuracy considerably. Further analysis demonstrates that this improvement is consistent for all grasps and concentrated during the movement onset and offset. version:1
arxiv-1705-02494 | Learning Distributed Representations of Texts and Entities from Knowledge Base | http://arxiv.org/abs/1705.02494 | id:1705.02494 author:Ikuya Yamada, Hiroyuki Shindo, Hideaki Takeda, Yoshiyasu Takefuji category:cs.CL cs.NE  published:2017-05-06 summary:We describe a neural network model that jointly learns distributed representations of texts and knowledge base (KB) entities. Given a text in the KB, we train our proposed model to predict entities that are relevant to the text. Our model is designed to be generic with the ability to address various NLP tasks with ease. We train the model using a large corpus of texts and their entity annotations extracted from Wikipedia. We evaluated the model on three important NLP tasks (i.e., sentence textual similarity, entity linking, and factoid question answering) involving both unsupervised and supervised settings. As a result, we achieved state-of-the-art results on all three of these tasks. Our code and trained models are publicly available for further academic research. version:2
arxiv-1708-08874 | Reasoning about Fine-grained Attribute Phrases using Reference Games | http://arxiv.org/abs/1708.08874 | id:1708.08874 author:Jong-Chyi Su, Chenyun Wu, Huaizu Jiang, Subhransu Maji category:cs.CV  published:2017-08-29 summary:We present a framework for learning to describe fine-grained visual differences between instances using attribute phrases. Attribute phrases capture distinguishing aspects of an object (e.g., "propeller on the nose" or "door near the wing" for airplanes) in a compositional manner. Instances within a category can be described by a set of these phrases and collectively they span the space of semantic attributes for a category. We collect a large dataset of such phrases by asking annotators to describe several visual differences between a pair of instances within a category. We then learn to describe and ground these phrases to images in the context of a *reference game* between a speaker and a listener. The goal of a speaker is to describe attributes of an image that allows the listener to correctly identify it within a pair. Data collected in a pairwise manner improves the ability of the speaker to generate, and the ability of the listener to interpret visual descriptions. Moreover, due to the compositionality of attribute phrases, the trained listeners can interpret descriptions not seen during training for image retrieval, and the speakers can generate attribute-based explanations for differences between previously unseen categories. We also show that embedding an image into the semantic space of attribute phrases derived from listeners offers 20% improvement in accuracy over existing attribute-based representations on the FGVC-aircraft dataset. version:1
arxiv-1706-03867 | Can We See Photosynthesis? Magnifying the Tiny Color Changes of Plant Green Leaves Using Eulerian Video Magnification | http://arxiv.org/abs/1706.03867 | id:1706.03867 author:Islam A. T. F. Taj-Eddin, Mahmoud Afifi, Mostafa Korashy, Ali H. Ahmed, Ng Yoke Cheng, Evelyng Hernandez, Salma M. Abdel-latif category:cs.CV  published:2017-06-12 summary:Plant aliveness is proven through laboratory experiments and special scientific instruments. In this paper, we aim to detect the degree of animation of plants based on the magnification of the small color changes in the plant's green leaves using the Eulerian video magnification. Capturing the video under a controlled environment, e.g., using a tripod and direct current (DC) light sources, reduces camera movements and minimizes light fluctuations; we aim to reduce the external factors as much as possible. The acquired video is then stabilized and a proposed algorithm used to reduce the illumination variations. Lastly, the Euler magnification is utilized to magnify the color changes on the light invariant video. The proposed system does not require any special purpose instruments as it uses a digital camera with a regular frame rate. The results of magnified color changes on both natural and plastic leaves show that the live green leaves have color changes in contrast to the plastic leaves. Hence, we can argue that the color changes of the leaves are due to biological operations, such as photosynthesis. To date, this is possibly the first work that focuses on interpreting visually, some biological operations of plants without any special purpose instruments. version:3
arxiv-1704-07072 | Camera Pose Filtering with Local Regression Geodesics on the Riemannian Manifold of Dual Quaternions | http://arxiv.org/abs/1704.07072 | id:1704.07072 author:Benjamin Busam, Tolga Birdal, Nassir Navab category:cs.CV  published:2017-04-24 summary:Time-varying, smooth trajectory estimation is of great interest to the vision community for accurate and well behaving 3D systems. In this paper, we propose a novel principal component local regression filter acting directly on the Riemannian manifold of unit dual quaternions $\mathbb{D} \mathbb{H}_1$. We use a numerically stable Lie algebra of the dual quaternions together with $\exp$ and $\log$ operators to locally linearize the 6D pose space. Unlike state of the art path smoothing methods which either operate on $SO\left(3\right)$ of rotation matrices or the hypersphere $\mathbb{H}_1$ of quaternions, we treat the orientation and translation jointly on the dual quaternion quadric in the 7-dimensional real projective space $\mathbb{R}\mathbb{P}^7$. We provide an outlier-robust IRLS algorithm for generic pose filtering exploiting this manifold structure. Besides our theoretical analysis, our experiments on synthetic and real data show the practical advantages of the manifold aware filtering on pose tracking and smoothing. version:4
arxiv-1709-02235 | Sparsity-Based Super Resolution for SEM Images | http://arxiv.org/abs/1709.02235 | id:1709.02235 author:Shahar Tsiper, Or Dicker, Idan Kaizerman, Zeev Zohar, Mordechai Segev, Yonina C. Eldar category:cs.CV  published:2017-08-29 summary:The scanning electron microscope (SEM) produces an image of a sample by scanning it with a focused beam of electrons. The electrons interact with the atoms in the sample, which emit secondary electrons that contain information about the surface topography and composition. The sample is scanned by the electron beam point by point, until an image of the surface is formed. Since its invention in 1942, SEMs have become paramount in the discovery and understanding of the nanometer world, and today it is extensively used for both research and in industry. In principle, SEMs can achieve resolution better than one nanometer. However, for many applications, working at sub-nanometer resolution implies an exceedingly large number of scanning points. For exactly this reason, the SEM diagnostics of microelectronic chips is performed either at high resolution (HR) over a small area or at low resolution (LR) while capturing a larger portion of the chip. Here, we employ sparse coding and dictionary learning to algorithmically enhance LR SEM images of microelectronic chips up to the level of the HR images acquired by slow SEM scans, while considerably reducing the noise. Our methodology consists of two steps: an offline stage of learning a joint dictionary from a sequence of LR and HR images of the same region in the chip, followed by a fast-online super-resolution step where the resolution of a new LR image is enhanced. We provide several examples with typical chips used in the microelectronics industry, as well as a statistical study on arbitrary images with characteristic structural features. Conceptually, our method works well when the images have similar characteristics. This work demonstrates that employing sparsity concepts can greatly improve the performance of SEM, thereby considerably increasing the scanning throughput without compromising on analysis quality and resolution. version:1
arxiv-1708-08863 | Gradual Learning of Deep Recurrent Neural Networks | http://arxiv.org/abs/1708.08863 | id:1708.08863 author:Ziv Aharoni, Gal Rattner, Haim Permuter category:stat.ML cs.LG  published:2017-08-29 summary:Deep Recurrent Neural Networks (RNNs) achieve state-of-the-art results in many sequence-to-sequence tasks. However, deep RNNs are difficult to train and suffer from overfitting. We introduce a training method that trains the network gradually, and treats each layer individually, to achieve improved results in language modelling tasks. Training deep LSTM with Gradual Learning (GL) obtains perplexity of 61.7 on the Penn Treebank (PTB) corpus. As far as we know (as for the 20.05.2017), GL improves the best state-of-the-art performance by a single LSTM/RHN model on the word-level PTB dataset. version:1
arxiv-1708-08844 | Semantic Texture for Robust Dense Tracking | http://arxiv.org/abs/1708.08844 | id:1708.08844 author:Jan Czarnowski, Stefan Leutenegger, Andrew Davison category:cs.CV  published:2017-08-29 summary:We argue that robust dense SLAM systems can make valuable use of the layers of features coming from a standard CNN as a pyramid of `semantic texture' which is suitable for dense alignment while being much more robust to nuisance factors such as lighting than raw RGB values. We use a straightforward Lucas-Kanade formulation of image alignment, with a schedule of iterations over the coarse-to-fine levels of a pyramid, and simply replace the usual image pyramid by the hierarchy of convolutional feature maps from a pre-trained CNN. The resulting dense alignment performance is much more robust to lighting and other variations, as we show by camera rotation tracking experiments on time-lapse sequences captured over many hours. Looking towards the future of scene representation for real-time visual SLAM, we further demonstrate that a selection using simple criteria of a small number of the total set of features output by a CNN gives just as accurate but much more efficient tracking performance. version:1
arxiv-1708-08826 | Improved Support Recovery Guarantees for the Group Lasso With Applications to Structural Health Monitoring | http://arxiv.org/abs/1708.08826 | id:1708.08826 author:Mojtaba Kadkhodaie Elyaderani, Swayambhoo Jain, Jeffrey Druce, Stefano Gonella, Jarvis Haupt category:cs.IT math.IT stat.ML  published:2017-08-29 summary:This paper considers the problem of estimating an unknown high dimensional signal from noisy linear measurements, {when} the signal is assumed to possess a \emph{group-sparse} structure in a {known,} fixed dictionary. We consider signals generated according to a natural probabilistic model, and establish new conditions under which the set of indices of the non-zero groups of the signal (called the group-level support) may be accurately estimated via the group Lasso. Our results strengthen existing coherence-based analyses that exhibit the well-known "square root" bottleneck, allowing for the number of recoverable nonzero groups to be nearly as large as the total number of groups. We also establish a sufficient recovery condition relating the number of nonzero groups and the signal to noise ratio (quantified in terms of the ratio of the squared Euclidean norms of nonzero groups and the variance of the random additive {measurement} noise), and validate this trend empirically. Finally, we examine the implications of our results in the context of a structural health monitoring application, where the group Lasso approach facilitates demixing of a propagating acoustic wavefield, acquired on the material surface by a scanning laser Doppler vibrometer, into antithetical components, one of which indicates the locations of internal material defects. version:1
arxiv-1708-08825 | 4D Multi-atlas Label Fusion using Longitudinal Images | http://arxiv.org/abs/1708.08825 | id:1708.08825 author:Yuankai Huo, Susan M. Resnick, Bennett A. Landman category:cs.CV  published:2017-08-29 summary:Longitudinal reproducibility is an essential concern in automated medical image segmentation, yet has proven to be an elusive objective as manual brain structure tracings have shown more than 10% variability. To improve reproducibility, lon-gitudinal segmentation (4D) approaches have been investigated to reconcile tem-poral variations with traditional 3D approaches. In the past decade, multi-atlas la-bel fusion has become a state-of-the-art segmentation technique for 3D image and many efforts have been made to adapt it to a 4D longitudinal fashion. However, the previous methods were either limited by using application specified energy function (e.g., surface fusion and multi model fusion) or only considered tem-poral smoothness on two consecutive time points (t and t+1) under sparsity as-sumption. Therefore, a 4D multi-atlas label fusion theory for general label fusion purpose and simultaneously considering temporal consistency on all time points is appealing. Herein, we propose a novel longitudinal label fusion algorithm, called 4D joint label fusion (4DJLF), to incorporate the temporal consistency modeling via non-local patch-intensity covariance models. The advantages of 4DJLF include: (1) 4DJLF is under the general label fusion framework by simul-taneously incorporating the spatial and temporal covariance on all longitudinal time points. (2) The proposed algorithm is a longitudinal generalization of a lead-ing joint label fusion method (JLF) that has proven adaptable to a wide variety of applications. (3) The spatial temporal consistency of atlases is modeled in a prob-abilistic model inspired from both voting based and statistical fusion. The pro-posed approach improves the consistency of the longitudinal segmentation while retaining sensitivity compared with original JLF approach using the same set of atlases. The method is available online in open-source. version:1
arxiv-1708-08819 | Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields | http://arxiv.org/abs/1708.08819 | id:1708.08819 author:Thomas Unterthiner, Bernhard Nessler, Günter Klambauer, Martin Heusel, Hubert Ramsauer, Sepp Hochreiter category:cs.LG cs.GT stat.ML  published:2017-08-29 summary:Generative adversarial networks (GANs) evolved into one of the most successful unsupervised techniques for generating realistic images. Even though it has recently been shown that GAN training converges, GAN models often end up in local Nash equilibria that are associated with mode collapse or otherwise fail to model the target distribution. We introduce Coulomb GANs, which pose the GAN learning problem as a potential field, where generated samples are attracted to training set samples but repel each other. The discriminator learns a potential field while the generator decreases the energy by moving its samples along the vector (force) field determined by the gradient of the potential field. Through decreasing the energy, the GAN model learns to generate samples according to the whole target distribution and does not only cover some of its modes. We prove that Coulomb GANs possess only one Nash equilibrium which is optimal in the sense that the model distribution equals the target distribution. We show the efficacy of Coulomb GANs on a variety of image datasets. On LSUN and celebA, Coulomb GANs set a new state of the art and produce a previously unseen variety of different samples. version:1
arxiv-1708-07791 | Shape Registration with Directional Data | http://arxiv.org/abs/1708.07791 | id:1708.07791 author:Mairéad Grogan, Rozenn Dahyot category:cs.CV I.2.10; I.5.1  published:2017-08-25 summary:We propose several cost functions for registration of shapes encoded with Euclidean and/or non-Euclidean information (unit vectors). Our framework is assessed for estimation of both rigid and non-rigid transformations between the target and model shapes corresponding to 2D contours and 3D surfaces. The experimental results obtained confirm that using the combination of a point's position and unit normal vector in a cost function can enhance the registration results compared to state of the art methods. version:2
arxiv-1708-08813 | Anomaly Detection: Review and preliminary Entropy method tests | http://arxiv.org/abs/1708.08813 | id:1708.08813 author:Pelumi Oluwasanya category:cs.LG  published:2017-08-29 summary:Anomalies are strange data points; they usually represent an unusual occurrence. Anomaly detection is presented from the perspective of Wireless sensor networks. Different approaches have been taken in the past, as we will see, not only to identify outliers, but also to establish the statistical properties of the different methods. The usual goal is to show that the approach is asymptotically efficient and that the metric used is unbiased or maybe biased. This project is based on a work done by [1]. The approach is based on the principle that the entropy of the data is increased when an anomalous data point is measured. The entropy of the data set is thus to be estimated. In this report however, preliminary efforts at confirming the results of [1] is presented. To estimate the entropy of the dataset, since no parametric form is assumed, the probability density function of the data set is first estimated using data split method. This estimated pdf value is then plugged-in to the entropy estimation formula to estimate the entropy of the dataset. The data (test signal) used in this report is Gaussian distributed with zero mean and variance 4. Results of pdf estimation using the k-nearest neighbour method using the entire dataset, and a data-split method are presented and compared based on how well they approximate the probability density function of a Gaussian with similar mean and variance. The number of nearest neighbours chosen for the purpose of this report is 8. This is arbitrary, but is reasonable since the number of anomalies introduced is expected to be less than this upon data-split. The data-split method is preferred and rightly so. version:1
arxiv-1708-08754 | Autoencoder with recurrent neural networks for video forgery detection | http://arxiv.org/abs/1708.08754 | id:1708.08754 author:Dario D'Avino, Davide Cozzolino, Giovanni Poggi, Luisa Verdoliva category:cs.CV  published:2017-08-29 summary:Video forgery detection is becoming an important issue in recent years, because modern editing software provide powerful and easy-to-use tools to manipulate videos. In this paper we propose to perform detection by means of deep learning, with an architecture based on autoencoders and recurrent neural networks. A training phase on a few pristine frames allows the autoencoder to learn an intrinsic model of the source. Then, forged material is singled out as anomalous, as it does not fit the learned model, and is encoded with a large reconstruction error. Recursive networks, implemented with the long short-term memory model, are used to exploit temporal dependencies. Preliminary results on forged videos show the potential of this approach. version:1
arxiv-1708-08732 | Multi-view Low-rank Sparse Subspace Clustering | http://arxiv.org/abs/1708.08732 | id:1708.08732 author:Maria Brbic, Ivica Kopriva category:cs.CV cs.LG math.OC stat.ML  published:2017-08-29 summary:Most existing approaches address multi-view subspace clustering problem by constructing the affinity matrix on each view separately and afterwards propose how to extend spectral clustering algorithm to handle multi-view data. This paper presents an approach to multi-view subspace clustering that learns a joint subspace representation by constructing affinity matrix shared among all views. Relying on the importance of both low-rank and sparsity constraints in the construction of the affinity matrix, we introduce the objective that balances between the agreement across different views, while at the same time encourages sparsity and low-rankness of the solution. Related low-rank and sparsity constrained optimization problem is for each view solved using the alternating direction method of multipliers. Furthermore, we extend our approach to cluster data drawn from nonlinear subspaces by solving the corresponding problem in a reproducing kernel Hilbert space. The proposed algorithm outperforms state-of-the-art multi-view subspace clustering algorithms on one synthetic and four real-world datasets. version:1
arxiv-1705-06031 | Learning to Identify Ambiguous and Misleading News Headlines | http://arxiv.org/abs/1705.06031 | id:1705.06031 author:Wei Wei, Xiaojun Wan category:cs.CL cs.CY  published:2017-05-17 summary:Accuracy is one of the basic principles of journalism. However, it is increasingly hard to manage due to the diversity of news media. Some editors of online news tend to use catchy headlines which trick readers into clicking. These headlines are either ambiguous or misleading, degrading the reading experience of the audience. Thus, identifying inaccurate news headlines is a task worth studying. Previous work names these headlines "clickbaits" and mainly focus on the features extracted from the headlines, which limits the performance since the consistency between headlines and news bodies is underappreciated. In this paper, we clearly redefine the problem and identify ambiguous and misleading headlines separately. We utilize class sequential rules to exploit structure information when detecting ambiguous headlines. For the identification of misleading headlines, we extract features based on the congruence between headlines and bodies. To make use of the large unlabeled data set, we apply a co-training method and gain an increase in performance. The experiment results show the effectiveness of our methods. Then we use our classifiers to detect inaccurate headlines crawled from different sources and conduct a data analysis. version:2
arxiv-1708-08728 | Curriculum Learning for Multi-Task Classification of Visual Attributes | http://arxiv.org/abs/1708.08728 | id:1708.08728 author:Nikolaos Sarafianos, Theodore Giannakopoulos, Christophoros Nikou, Ioannis A. Kakadiaris category:cs.CV  published:2017-08-29 summary:Visual attributes, from simple objects (e.g., backpacks, hats) to soft-biometrics (e.g., gender, height, clothing) have proven to be a powerful representational approach for many applications such as image description and human identification. In this paper, we introduce a novel method to combine the advantages of both multi-task and curriculum learning in a visual attribute classification framework. Individual tasks are grouped based on their correlation so that two groups of strongly and weakly correlated tasks are formed. The two groups of tasks are learned in a curriculum learning setup by transferring the acquired knowledge from the strongly to the weakly correlated. The learning process within each group though, is performed in a multi-task classification setup. The proposed method learns better and converges faster than learning all the tasks in a typical multi-task learning paradigm. We demonstrate the effectiveness of our approach on the publicly available, SoBiR, VIPeR and PETA datasets and report state-of-the-art results across the board. version:1
arxiv-1708-08725 | Machine Learning Approach for Detection of nonTor Traffic | http://arxiv.org/abs/1708.08725 | id:1708.08725 author:Elike Hodo, Xavier Bellekens, Ephraim Iorkyase, Andrew Hamilton, Christos Tachtatzis, Robert Atkinson category:cs.CR cs.LG  published:2017-08-29 summary:Intrusion detection has attracted a considerable interest from researchers and industries. After many years of research the community still faces the problem of building reliable and efficient intrusion detection systems (IDS) capable of handling large quantities of data with changing patterns in real time situations. The Tor network is popular in providing privacy and security to end user by anonymising the identity of internet users connecting through a series of tunnels and nodes. This work focuses on the classification of Tor traffic and nonTor traffic to expose the activities within Tor traffic that minimizes the protection of users. A study to compare the reliability and efficiency of Artificial Neural Network and Support vector machine in detecting nonTor traffic in UNB-CIC Tor Network Traffic dataset is presented in this paper. The results are analysed based on the overall accuracy, detection rate and false positive rate of the two algorithms. Experimental results show that both algorithms could detect nonTor traffic in the dataset. A hybrid Artificial neural network proved a better classifier than SVM in detecting nonTor traffic in UNB-CIC Tor Network Traffic dataset. version:1
arxiv-1707-00478 | Generalised Wasserstein Dice Score for Imbalanced Multi-class Segmentation using Holistic Convolutional Networks | http://arxiv.org/abs/1707.00478 | id:1707.00478 author:Lucas Fidon, Wenqi Li, Luis C. Garcia-Peraza-Herrera, Jinendra Ekanayake, Neil Kitchen, Sebastien Ourselin, Tom Vercauteren category:cs.CV  published:2017-07-03 summary:The Dice score is widely used for binary segmentation due to its robustness to class imbalance. Soft generalisations of the Dice score allow it to be used as a loss function for training convolutional neural networks (CNN). Although CNNs trained using mean-class Dice score achieve state-of-the-art results on multi-class segmentation, this loss function does neither take advantage of inter-class relationships nor multi-scale information. We argue that an improved loss function should balance misclassifications to favour predictions that are semantically meaningful. This paper investigates these issues in the context of multi-class brain tumour segmentation. Our contribution is threefold. 1) We propose a semantically-informed generalisation of the Dice score for multi-class segmentation based on the Wasserstein distance on the probabilistic label space. 2) We propose a holistic CNN that embeds spatial information at multiple scales with deep supervision. 3) We show that the joint use of holistic CNNs and generalised Wasserstein Dice scores achieves segmentations that are more semantically meaningful for brain tumour segmentation. version:4
arxiv-1708-08705 | Multi-Layer Convolutional Sparse Modeling: Pursuit and Dictionary Learning | http://arxiv.org/abs/1708.08705 | id:1708.08705 author:Jeremias Sulam, Vardan Papyan, Yaniv Romano, Michael Elad category:cs.CV cs.LG stat.ML  published:2017-08-29 summary:The recently proposed Multi-Layer Convolutional Sparse Coding (ML-CSC) model, consisting of a cascade of convolutional sparse layers, provides a new interpretation of Convolutional Neural Networks (CNNs). Under this framework, the computation of the forward pass in a CNN is equivalent to a pursuit algorithm aiming to estimate the nested sparse representation vectors -- or feature maps -- from a given input signal. Despite having served as a pivotal connection between CNNs and sparse modeling, a deeper understanding of the ML-CSC is still lacking: there are no pursuit algorithms that can serve this model exactly, nor are there conditions to guarantee a non-empty model. While one can easily obtain signals that approximately satisfy the ML-CSC constraints, it remains unclear how to simply sample from the model and, more importantly, how one can train the convolutional filters from real data. In this work, we propose a sound pursuit algorithm for the ML-CSC model by adopting a projection approach. We provide new and improved bounds on the stability of the solution of such pursuit and we analyze different practical alternatives to implement this in practice. We show that the training of the filters is essential to allow for non-trivial signals in the model, and we derive an online algorithm to learn the dictionaries from real data, effectively resulting in cascaded sparse convolutional layers. Last, but not least, we demonstrate the applicability of the ML-CSC model for several applications in an unsupervised setting, providing competitive results. Our work represents a bridge between matrix factorization, sparse dictionary learning and sparse auto-encoders, and we analyze these connections in detail. version:1
arxiv-1708-08694 | Natasha 2: Faster Non-Convex Optimization Than SGD | http://arxiv.org/abs/1708.08694 | id:1708.08694 author:Zeyuan Allen-Zhu category:math.OC cs.DS cs.LG cs.NE stat.ML  published:2017-08-29 summary:We design a stochastic algorithm to train any smooth neural network to $\varepsilon$-approximate local minima, using $O(\varepsilon^{-3.25})$ backpropagations. The best result was essentially $O(\varepsilon^{-4})$ by SGD. More broadly, it finds $\varepsilon$-approximate local minima of any smooth nonconvex function in rate $O(\varepsilon^{-3.25})$, with only oracle access to stochastic gradients and Hessian-vector products. version:1
arxiv-1708-08689 | Towards Poisoning of Deep Learning Algorithms with Back-gradient Optimization | http://arxiv.org/abs/1708.08689 | id:1708.08689 author:Luis Muñoz-González, Battista Biggio, Ambra Demontis, Andrea Paudice, Vasin Wongrassamee, Emil C. Lupu, Fabio Roli category:cs.LG  published:2017-08-29 summary:A number of online services nowadays rely upon machine learning to extract valuable information from data collected in the wild. This exposes learning algorithms to the threat of data poisoning, i.e., a coordinate attack in which a fraction of the training data is controlled by the attacker and manipulated to subvert the learning process. To date, these attacks have been devised only against a limited class of binary learning algorithms, due to the inherent complexity of the gradient-based procedure used to optimize the poisoning points (a.k.a. adversarial training examples). In this work, we rst extend the de nition of poisoning attacks to multiclass problems. We then propose a novel poisoning algorithm based on the idea of back-gradient optimization, i.e., to compute the gradient of interest through automatic di erentiation, while also reversing the learning procedure to drastically reduce the attack complexity. Compared to current poisoning strategies, our approach is able to target a wider class of learning algorithms, trained with gradient- based procedures, including neural networks and deep learning architectures. We empirically evaluate its e ectiveness on several application examples, including spam ltering, malware detection, and handwritten digit recognition. We nally show that, similarly to adversarial test examples, adversarial training examples can also be transferred across di erent learning algorithms. version:1
arxiv-1708-08687 | Performance Guaranteed Network Acceleration via High-Order Residual Quantization | http://arxiv.org/abs/1708.08687 | id:1708.08687 author:Zefan Li, Bingbing Ni, Wenjun Zhang, Xiaokang Yang, Wen Gao category:cs.CV  published:2017-08-29 summary:Input binarization has shown to be an effective way for network acceleration. However, previous binarization scheme could be regarded as simple pixel-wise thresholding operations (i.e., order-one approximation) and suffers a big accuracy loss. In this paper, we propose a highorder binarization scheme, which achieves more accurate approximation while still possesses the advantage of binary operation. In particular, the proposed scheme recursively performs residual quantization and yields a series of binary input images with decreasing magnitude scales. Accordingly, we propose high-order binary filtering and gradient propagation operations for both forward and backward computations. Theoretical analysis shows approximation error guarantee property of proposed method. Extensive experimental results demonstrate that the proposed scheme yields great recognition accuracy while being accelerated. version:1
arxiv-1709-01144 | Information Theoretic Analysis of DNN-HMM Acoustic Modeling | http://arxiv.org/abs/1709.01144 | id:1709.01144 author:Pranay Dighe, Afsaneh Asaei, Hervé Bourlard category:cs.SD cs.CL cs.LG  published:2017-08-29 summary:We propose an information theoretic framework for quantitative assessment of acoustic modeling for hidden Markov model (HMM) based automatic speech recognition (ASR). Acoustic modeling yields the probabilities of HMM sub-word states for a short temporal window of speech acoustic features. We cast ASR as a communication channel where the input sub-word probabilities convey the information about the output HMM state sequence. The quality of the acoustic model is thus quantified in terms of the information transmitted through this channel. The process of inferring the most likely HMM state sequence from the sub-word probabilities is known as decoding. HMM based decoding assumes that an acoustic model yields accurate state-level probabilities and the data distribution given the underlying hidden state is independent of any other state in the sequence. We quantify 1) the acoustic model accuracy and 2) its robustness to mismatch between data and the HMM conditional independence assumption in terms of some mutual information quantities. In this context, exploiting deep neural network (DNN) posterior probabilities leads to a simple and straightforward analysis framework to assess shortcomings of the acoustic model for HMM based decoding. This analysis enables us to evaluate the Gaussian mixture acoustic model (GMM) and the importance of many hidden layers in DNNs without any need of explicit speech recognition. In addition, it sheds light on the contribution of low-dimensional models to enhance acoustic modeling for better compliance with the HMM based decoding requirements. version:1
arxiv-1708-08615 | Comparing Human and Machine Errors in Conversational Speech Transcription | http://arxiv.org/abs/1708.08615 | id:1708.08615 author:Andreas Stolcke, Jasha Droppo category:cs.CL  published:2017-08-29 summary:Recent work in automatic recognition of conversational telephone speech (CTS) has achieved accuracy levels comparable to human transcribers, although there is some debate how to precisely quantify human performance on this task, using the NIST 2000 CTS evaluation set. This raises the question what systematic differences, if any, may be found differentiating human from machine transcription errors. In this paper we approach this question by comparing the output of our most accurate CTS recognition system to that of a standard speech transcription vendor pipeline. We find that the most frequent substitution, deletion and insertion error types of both outputs show a high degree of overlap. The only notable exception is that the automatic recognizer tends to confuse filled pauses ("uh") and backchannel acknowledgments ("uhhuh"). Humans tend not to make this error, presumably due to the distinctive and opposing pragmatic functions attached to these words. Furthermore, we quantify the correlation between human and machine errors at the speaker level, and investigate the effect of speaker overlap between training and test data. Finally, we report on an informal "Turing test" asking humans to discriminate between automatic and human transcription error cases. version:1
arxiv-1708-08591 | EC3: Combining Clustering and Classification for Ensemble Learning | http://arxiv.org/abs/1708.08591 | id:1708.08591 author:Tanmoy Chakraborty category:cs.LG stat.ML  published:2017-08-29 summary:Classification and clustering algorithms have been proved to be successful individually in different contexts. Both of them have their own advantages and limitations. For instance, although classification algorithms are more powerful than clustering methods in predicting class labels of objects, they do not perform well when there is a lack of sufficient manually labeled reliable data. On the other hand, although clustering algorithms do not produce label information for objects, they provide supplementary constraints (e.g., if two objects are clustered together, it is more likely that the same label is assigned to both of them) that one can leverage for label prediction of a set of unknown objects. Therefore, systematic utilization of both these types of algorithms together can lead to better prediction performance. In this paper, We propose a novel algorithm, called EC3 that merges classification and clustering together in order to support both binary and multi-class classification. EC3 is based on a principled combination of multiple classification and multiple clustering methods using an optimization function. We theoretically show the convexity and optimality of the problem and solve it by block coordinate descent method. We additionally propose iEC3, a variant of EC3 that handles imbalanced training data. We perform an extensive experimental analysis by comparing EC3 and iEC3 with 14 baseline methods (7 well-known standalone classifiers, 5 ensemble classifiers, and 2 existing methods that merge classification and clustering) on 13 standard benchmark datasets. We show that our methods outperform other baselines for every single dataset, achieving at most 10% higher AUC. Moreover our methods are faster (1.21 times faster than the best baseline), more resilient to noise and class imbalance than the best baseline method. version:1
arxiv-1708-08587 | On the Reconstruction Risk of Convolutional Sparse Dictionary Learning | http://arxiv.org/abs/1708.08587 | id:1708.08587 author:Shashank Singh, Barnabás Póczos, Jian Ma category:math.ST cs.IT cs.LG math.IT stat.ML stat.TH  published:2017-08-29 summary:Sparse dictionary learning (SDL) has become a popular method for adaptively identifying parsimonious representations of a dataset, a fundamental problem in machine learning and signal processing. While most work on SDL assumes a training dataset of independent and identically distributed samples, a variant known as convolutional sparse dictionary learning (CSDL) relaxes this assumption, allowing more general sequential data sources, such as time series or other dependent data. Although recent work has explored the statistical properties of classical SDL, the statistical properties of CSDL remain unstudied. This paper begins to study this by identifying the minimax convergence rate of CSDL in terms of reconstruction risk, by both upper bounding the risk of an established CSDL estimator and proving a matching information-theoretic lower bound. Our results indicate that consistency in reconstruction risk is possible precisely in the `ultra-sparse' setting, in which the sparsity (i.e., the number of feature occurrences) is in $o(N)$ in terms of the length N of the training sequence. Notably, our results make very weak assumptions, allowing arbitrary dictionaries and dependent measurement noise. Finally, we verify our theoretical results with numerical experiments on synthetic data. version:1
arxiv-1708-08585 | Narrative Variations in a Virtual Storyteller | http://arxiv.org/abs/1708.08585 | id:1708.08585 author:Stephanie M. Lukin, Marilyn A. Walker category:cs.CL  published:2017-08-29 summary:Research on storytelling over the last 100 years has distinguished at least two levels of narrative representation (1) story, or fabula; and (2) discourse, or sujhet. We use this distinction to create Fabula Tales, a computational framework for a virtual storyteller that can tell the same story in different ways through the implementation of general narratological variations, such as varying direct vs. indirect speech, character voice (style), point of view, and focalization. A strength of our computational framework is that it is based on very general methods for re-using existing story content, either from fables or from personal narratives collected from blogs. We first explain how a simple annotation tool allows naive annotators to easily create a deep representation of fabula called a story intention graph, and show how we use this representation to generate story tellings automatically. Then we present results of two studies testing our narratological parameters, and showing that different tellings affect the reader's perception of the story and characters. version:1
arxiv-1708-08580 | Generating Sentence Planning Variations for Story Telling | http://arxiv.org/abs/1708.08580 | id:1708.08580 author:Stephanie M. Lukin, Lena I. Reed, Marilyn A. Walker category:cs.CL  published:2017-08-29 summary:There has been a recent explosion in applications for dialogue interaction ranging from direction-giving and tourist information to interactive story systems. Yet the natural language generation (NLG) component for many of these systems remains largely handcrafted. This limitation greatly restricts the range of applications; it also means that it is impossible to take advantage of recent work in expressive and statistical language generation that can dynamically and automatically produce a large number of variations of given content. We propose that a solution to this problem lies in new methods for developing language generation resources. We describe the ES-Translator, a computational language generator that has previously been applied only to fables, and quantitatively evaluate the domain independence of the EST by applying it to personal narratives from weblogs. We then take advantage of recent work on language generation to create a parameterized sentence planner for story generation that provides aggregation operations, variations in discourse and in point of view. Finally, we present a user evaluation of different personal narrative retellings. version:1
arxiv-1708-08575 | Identifying Subjective and Figurative Language in Online Dialogue | http://arxiv.org/abs/1708.08575 | id:1708.08575 author:Stephanie M. Lukin, Luke Eisenberg, Thomas Corcoran, Marilyn A. Walker category:cs.CL  published:2017-08-29 summary:More and more of the information on the web is dialogic, from Facebook newsfeeds, to forum conversations, to comment threads on news articles. In contrast to traditional, monologic resources such as news, highly social dialogue is very frequent in social media. We aim to automatically identify sarcastic and nasty utterances in unannotated online dialogue, extending a bootstrapping method previously applied to the classification of monologic subjective sentences in Riloff and Weibe 2003. We have adapted the method to fit the sarcastic and nasty dialogic domain. Our method is as follows: 1) Explore methods for identifying sarcastic and nasty cue words and phrases in dialogues; 2) Use the learned cues to train a sarcastic (nasty) Cue-Based Classifier; 3) Learn general syntactic extraction patterns from the sarcastic (nasty) utterances and define fine-tuned sarcastic patterns to create a Pattern-Based Classifier; 4) Combine both Cue-Based and fine-tuned Pattern-Based Classifiers to maximize precision at the expense of recall and test on unannotated utterances. version:1
arxiv-1704-07431 | A Challenge Set Approach to Evaluating Machine Translation | http://arxiv.org/abs/1704.07431 | id:1704.07431 author:Pierre Isabelle, Colin Cherry, George Foster category:cs.CL  published:2017-04-24 summary:Neural machine translation represents an exciting leap forward in translation quality. But what longstanding weaknesses does it resolve, and which remain? We address these questions with a challenge set approach to translation evaluation and error analysis. A challenge set consists of a small set of sentences, each hand-designed to probe a system's capacity to bridge a particular structural divergence between languages. To exemplify this approach, we present an English-French challenge set, and use it to analyze phrase-based and neural systems. The resulting analysis provides not only a more fine-grained picture of the strengths of neural systems, but also insight into which linguistic phenomena remain out of reach. version:5
arxiv-1708-08573 | Generating Different Story Tellings from Semantic Representations of Narrative | http://arxiv.org/abs/1708.08573 | id:1708.08573 author:Elena Rishes, Stephanie M. Lukin, David K. Elson, Marilyn A. Walker category:cs.CL  published:2017-08-29 summary:In order to tell stories in different voices for different audiences, interactive story systems require: (1) a semantic representation of story structure, and (2) the ability to automatically generate story and dialogue from this semantic representation using some form of Natural Language Generation (NLG). However, there has been limited research on methods for linking story structures to narrative descriptions of scenes and story events. In this paper we present an automatic method for converting from Scheherazade's story intention graph, a semantic representation, to the input required by the Personage NLG engine. Using 36 Aesop Fables distributed in DramaBank, a collection of story encodings, we train translation rules on one story and then test these rules by generating text for the remaining 35. The results are measured in terms of the string similarity metrics Levenshtein Distance and BLEU score. The results show that we can generate the 35 stories with correct content: the test set stories on average are close to the output of the Scheherazade realizer, which was customized to this semantic representation. We provide some examples of story variations generated by personage. In future work, we will experiment with measuring the quality of the same stories generated in different voices, and with techniques for making storytelling interactive. version:1
arxiv-1708-08572 | Really? Well. Apparently Bootstrapping Improves the Performance of Sarcasm and Nastiness Classifiers for Online Dialogue | http://arxiv.org/abs/1708.08572 | id:1708.08572 author:Stephanie Lukin, Marilyn Walker category:cs.CL  published:2017-08-29 summary:More and more of the information on the web is dialogic, from Facebook newsfeeds, to forum conversations, to comment threads on news articles. In contrast to traditional, monologic Natural Language Processing resources such as news, highly social dialogue is frequent in social media, making it a challenging context for NLP. This paper tests a bootstrapping method, originally proposed in a monologic domain, to train classifiers to identify two different types of subjective language in dialogue: sarcasm and nastiness. We explore two methods of developing linguistic indicators to be used in a first level classifier aimed at maximizing precision at the expense of recall. The best performing classifier for the first phase achieves 54% precision and 38% recall for sarcastic utterances. We then use general syntactic patterns from previous work to create more general sarcasm indicators, improving precision to 62% and recall to 52%. To further test the generality of the method, we then apply it to bootstrapping a classifier for nastiness dialogic acts. Our first phase, using crowdsourced nasty indicators, achieves 58% precision and 49% recall, which increases to 75% precision and 62% recall when we bootstrap over the first level with generalized syntactic patterns. version:1
arxiv-1708-07164 | Newton-Type Methods for Non-Convex Optimization Under Inexact Hessian Information | http://arxiv.org/abs/1708.07164 | id:1708.07164 author:Peng Xu, Farbod Roosta-Khorasani, Michael W. Mahoney category:math.OC cs.CC cs.LG stat.ML  published:2017-08-23 summary:We consider variants of trust-region and cubic regularization methods for non-convex optimization, in which the Hessian matrix is approximated. Under mild conditions on the inexact Hessian, and using approximate solution of the corresponding sub-problems, we provide iteration complexity to achieve $ \epsilon $-approximate second-order optimality which have shown to be tight. Our Hessian approximation conditions constitute a major relaxation over the existing ones in the literature. Consequently, we are able to show that such mild conditions allow for the construction of the approximate Hessian through various random sampling methods. In this light, we consider the canonical problem of finite-sum minimization, provide appropriate uniform and non-uniform sub-sampling strategies to construct such Hessian approximations, and obtain optimal iteration complexity for the corresponding sub-sampled trust-region and cubic regularization methods. version:2
arxiv-1708-07570 | Leaf Counting with Deep Convolutional and Deconvolutional Networks | http://arxiv.org/abs/1708.07570 | id:1708.07570 author:Shubhra Aich, Ian Stavness category:cs.CV  published:2017-08-24 summary:In this paper, we investigate the problem of counting rosette leaves from an RGB image, an important task in plant phenotyping. We propose a data-driven approach for this task generalized over different plant species and imaging setups. To accomplish this task, we use state-of-the-art deep learning architectures: a deconvolutional network for initial segmentation and a convolutional network for leaf counting. Evaluation is performed on the leaf counting challenge dataset at CVPPP-2017. Despite the small number of training samples in this dataset, as compared to typical deep learning image sets, we obtain satisfactory performance on segmenting leaves from the background as a whole and counting the number of leaves using simple data augmentation strategies. Comparative analysis is provided against methods evaluated on the previous competition datasets. Our framework achieves mean and standard deviation of absolute count difference of 1.62 and 2.30 averaged over all five test datasets. version:2
arxiv-1708-08180 | An Optimized Union-Find Algorithm for Connected Components Labeling Using GPUs | http://arxiv.org/abs/1708.08180 | id:1708.08180 author:Jun Chen, Qiang Yao, Houari Sabirin, Keisuke Nonaka, Hiroshi Sankoh, Sei Naito category:cs.CV  published:2017-08-28 summary:In this paper, we report an optimized union-find (UF) algorithm that can label the connected components on a 2D image efficiently by employing the GPU architecture. The proposed method contains three phases: UF-based local merge, boundary analysis, and link. The coarse labeling in local merge reduces the number atomic operations, while the boundary analysis only manages the pixels on the boundary of each block. Evaluation results showed that the proposed algorithm speed up the average running time by more than 1.3X. version:2
arxiv-1706-04303 | Accurate Pulmonary Nodule Detection in Computed Tomography Images Using Deep Convolutional Neural Networks | http://arxiv.org/abs/1706.04303 | id:1706.04303 author:Jia Ding, Aoxue Li, Zhiqiang Hu, Liwei Wang category:cs.CV  published:2017-06-14 summary:Early detection of pulmonary cancer is the most promising way to enhance a patient's chance for survival. Accurate pulmonary nodule detection in computed tomography (CT) images is a crucial step in diagnosing pulmonary cancer. In this paper, inspired by the successful use of deep convolutional neural networks (DCNNs) in natural image recognition, we propose a novel pulmonary nodule detection approach based on DCNNs. We first introduce a deconvolutional structure to Faster Region-based Convolutional Neural Network (Faster R-CNN) for candidate detection on axial slices. Then, a three-dimensional DCNN is presented for the subsequent false positive reduction. Experimental results of the LUng Nodule Analysis 2016 (LUNA16) Challenge demonstrate the superior detection performance of the proposed approach on nodule detection(average FROC-score of 0.891, ranking the 1st place over all submitted results). version:3
arxiv-1708-08552 | An inexact subsampled proximal Newton-type method for large-scale machine learning | http://arxiv.org/abs/1708.08552 | id:1708.08552 author:Xuanqing Liu, Cho-Jui Hsieh, Jason D. Lee, Yuekai Sun category:cs.LG cs.NA stat.ML  published:2017-08-28 summary:We propose a fast proximal Newton-type algorithm for minimizing regularized finite sums that returns an $\epsilon$-suboptimal point in $\tilde{\mathcal{O}}(d(n + \sqrt{\kappa d})\log(\frac{1}{\epsilon}))$ FLOPS, where $n$ is number of samples, $d$ is feature dimension, and $\kappa$ is the condition number. As long as $n > d$, the proposed method is more efficient than state-of-the-art accelerated stochastic first-order methods for non-smooth regularizers which requires $\tilde{\mathcal{O}}(d(n + \sqrt{\kappa n})\log(\frac{1}{\epsilon}))$ FLOPS. The key idea is to form the subsampled Newton subproblem in a way that preserves the finite sum structure of the objective, thereby allowing us to leverage recent developments in stochastic first-order methods to solve the subproblem. Experimental results verify that the proposed algorithm outperforms previous algorithms for $\ell_1$-regularized logistic regression on real datasets. version:1
arxiv-1708-09252 | THAP: A Matlab Toolkit for Learning with Hawkes Processes | http://arxiv.org/abs/1708.09252 | id:1708.09252 author:Hongteng Xu, Hongyuan Zha category:stat.ML cs.LG  published:2017-08-28 summary:As a powerful tool of asynchronous event sequence analysis, point processes have been studied for a long time and achieved numerous successes in different fields. Among various point process models, Hawkes process and its variants attract many researchers in statistics and computer science these years because they capture the self- and mutually-triggering patterns between different events in complicated sequences explicitly and quantitatively and are broadly applicable to many practical problems. In this paper, we describe an open-source toolkit implementing many learning algorithms and analysis tools for Hawkes process model and its variants. Our toolkit systematically summarizes recent state-of-the-art algorithms as well as most classic algorithms of Hawkes processes, which is beneficial for both academical education and research. Source code can be downloaded from https://github.com/HongtengXu/Hawkes-Process-Toolkit. version:1
arxiv-1708-08484 | Joint Syntacto-Discourse Parsing and the Syntacto-Discourse Treebank | http://arxiv.org/abs/1708.08484 | id:1708.08484 author:Kai Zhao, Liang Huang category:cs.CL  published:2017-08-28 summary:Discourse parsing has long been treated as a stand-alone problem independent from constituency or dependency parsing. Most attempts at this problem are pipelined rather than end-to-end, sophisticated, and not self-contained: they assume gold-standard text segmentations (Elementary Discourse Units), and use external parsers for syntactic features. In this paper we propose the first end-to-end discourse parser that jointly parses in both syntax and discourse levels, as well as the first syntacto-discourse treebank by integrating the Penn Treebank with the RST Treebank. Built upon our recent span-based constituency parser, this joint syntacto-discourse parser requires no preprocessing whatsoever (such as segmentation or feature extraction), achieves the state-of-the-art end-to-end discourse parsing accuracy. version:1
arxiv-1708-09344 | Stem-ming the Tide: Predicting STEM attrition using student transcript data | http://arxiv.org/abs/1708.09344 | id:1708.09344 author:Lovenoor Aulck, Rohan Aras, Lysia Li, Coulter L'Heureux, Peter Lu, Jevin West category:stat.OT cs.CY physics.ed-ph stat.ML  published:2017-08-28 summary:Science, technology, engineering, and math (STEM) fields play growing roles in national and international economies by driving innovation and generating high salary jobs. Yet, the US is lagging behind other highly industrialized nations in terms of STEM education and training. Furthermore, many economic forecasts predict a rising shortage of domestic STEM-trained professions in the US for years to come. One potential solution to this deficit is to decrease the rates at which students leave STEM-related fields in higher education, as currently over half of all students intending to graduate with a STEM degree eventually attrite. However, little quantitative research at scale has looked at causes of STEM attrition, let alone the use of machine learning to examine how well this phenomenon can be predicted. In this paper, we detail our efforts to model and predict dropout from STEM fields using one of the largest known datasets used for research on students at a traditional campus setting. Our results suggest that attrition from STEM fields can be accurately predicted with data that is routinely collected at universities using only information on students' first academic year. We also propose a method to model student STEM intentions for each academic term to better understand the timing of STEM attrition events. We believe these results show great promise in using machine learning to improve STEM retention in traditional and non-traditional campus settings. version:1
arxiv-1708-08417 | Automatic Discovery and Geotagging of Objects from Street View Imagery | http://arxiv.org/abs/1708.08417 | id:1708.08417 author:Vladimir A. Krylov, Eamonn Kenny, Rozenn Dahyot category:cs.CV  published:2017-08-28 summary:Many applications such as autonomous navigation, urban planning and asset monitoring, rely on the availability of accurate information about objects and their geolocations. In this paper we propose to automatically detect and compute the GPS coordinates of recurring stationary objects of interest using street view imagery. Our processing pipeline relies on two fully convolutional neural networks: the first segments objects in the images while the second estimates their distances from the camera. To geolocate all the detected objects coherently and merge together instances observed from multiple images we propose a novel Markov Random Field model based on triangulation. We show experimentally the effectiveness of our approach on two object classes: traffic lights and telegraph poles. The experiments report high object recall rates and GPS accuracy within 2 meters, which is comparable with the precision of single-frequency GPS receivers. version:1
arxiv-1708-08407 | Folding membrane proteins by deep transfer learning | http://arxiv.org/abs/1708.08407 | id:1708.08407 author:Sheng Wang, Zhen Li, Yizhou Yu, Jinbo Xu category:q-bio.BM cs.LG  published:2017-08-28 summary:Computational elucidation of membrane protein (MP) structures is challenging partially due to lack of sufficient solved structures for homology modeling. Here we describe a high-throughput deep transfer learning method that first predicts MP contacts by learning from non-membrane proteins (non-MPs) and then predicting three-dimensional structure models using the predicted contacts as distance restraints. Tested on 510 non-redundant MPs, our method has contact prediction accuracy at least 0.18 better than existing methods, predicts correct folds for 218 MPs (TMscore at least 0.6), and generates three-dimensional models with RMSD less than 4 Angstrom and 5 Angstrom for 57 and 108 MPs, respectively. A rigorous blind test in the continuous automated model evaluation (CAMEO) project shows that our method predicted high-resolution three-dimensional models for two recent test MPs of 210 residues with RMSD close to 2 Angstrom. We estimated that our method could predict correct folds for between 1,345 and 1,871 reviewed human multi-pass MPs including a few hundred new folds, which shall facilitate the discovery of drugs targeting at membrane proteins. version:1
arxiv-1708-08333 | Framing U-Net via Deep Convolutional Framelets: Application to Sparse-view CT | http://arxiv.org/abs/1708.08333 | id:1708.08333 author:Yoseob Han, Jong Chul Ye category:cs.CV cs.LG stat.ML  published:2017-08-28 summary:X-ray computed tomography (CT) using sparse projection views is often used to reduce the radiation dose. However, due to the insufficient projection views, a reconstruction approach using the filtered back projection (FBP) produces severe streaking artifacts. Recently, deep learning approaches using large receptive field neural networks such as U-net have demonstrated impressive performance for sparse view CT reconstruction. However, theoretical justification is still lacking. The main goal of this paper is, therefore, to develop a mathematical theory and to discuss how to improve these algorithms. In particular, inspired by the recent theory of deep convolutional framelets, we show that the U-net relies on a sub-optimal non-local bases that overly emphasizes low frequency components. The discovery leads to a dual frame and a tight frame U-net architectures for effective recovery of directional image components. version:1
arxiv-1709-00387 | MIT-QCRI Arabic Dialect Identification System for the 2017 Multi-Genre Broadcast Challenge | http://arxiv.org/abs/1709.00387 | id:1709.00387 author:Suwon Shon, Ahmed Ali, James Glass category:cs.CL cs.LG cs.SD  published:2017-08-28 summary:In order to successfully annotate the Arabic speech con- tent found in open-domain media broadcasts, it is essential to be able to process a diverse set of Arabic dialects. For the 2017 Multi-Genre Broadcast challenge (MGB-3) there were two possible tasks: Arabic speech recognition, and Arabic Dialect Identification (ADI). In this paper, we describe our efforts to create an ADI system for the MGB-3 challenge, with the goal of distinguishing amongst four major Arabic dialects, as well as Modern Standard Arabic. Our research fo- cused on dialect variability and domain mismatches between the training and test domain. In order to achieve a robust ADI system, we explored both Siamese neural network models to learn similarity and dissimilarities among Arabic dialects, as well as i-vector post-processing to adapt domain mismatches. Both Acoustic and linguistic features were used for the final MGB-3 submissions, with the best primary system achieving 75% accuracy on the official 10hr test set. version:1
arxiv-1708-08327 | Feature Conservation in Adversarial Classifier Evasion: A Case Study | http://arxiv.org/abs/1708.08327 | id:1708.08327 author:Liang Tong, Bo Li, Chen Hajaj, Yevgeniy Vorobeychik category:cs.CR cs.LG  published:2017-08-28 summary:Machine learning is widely used in security applications, particularly in the form of statistical classification aimed at distinguishing benign from malicious entities. Recent research has shown that such classifiers are often vulnerable to evasion attacks, whereby adversaries change behavior to be categorized as benign while preserving malicious functionality. Research into evasion attacks has followed two paradigms: attacks in problem space, where the actual malicious instance is modified, and attacks in feature space, where the attack is abstracted into modifying numerical features of an instance to evade a classifier. In contrast, research into designing evasion-robust classifiers generally relies on feature space attack models. We make several contributions to address this gap, using PDF malware detection as a case study. First, we present a systematic retraining procedure which uses an automated problem space attack generator to design a more robust PDF malware detector. Second, we demonstrate that replacing problem space attacks with feature space attacks dramatically reduces the robustness of the resulting classifier, severely undermining feature space defense methods to date. Third, we demonstrate the existence of conserved (or invariant) features, and show how these can be leveraged to design evasion- robust classifiers that are nearly as effective, and far more efficient, than those relying on the problem space attack. Finally, we present a general approach for identifying conserved features. version:1
arxiv-1708-08325 | DeepPrior++: Improving Fast and Accurate 3D Hand Pose Estimation | http://arxiv.org/abs/1708.08325 | id:1708.08325 author:Markus Oberweger, Vincent Lepetit category:cs.CV  published:2017-08-28 summary:DeepPrior is a simple approach based on Deep Learning that predicts the joint 3D locations of a hand given a depth map. Since its publication early 2015, it has been outperformed by several impressive works. Here we show that with simple improvements: adding ResNet layers, data augmentation, and better initial hand localization, we achieve better or similar performance than more sophisticated recent methods on the three main benchmarks (NYU, ICVL, MSRA) while keeping the simplicity of the original method. Our new implementation is available at https://github.com/moberweger/deep-prior-pp . version:1
arxiv-1708-08311 | Deep Learning Sparse Ternary Projections for Compressed Sensing of Images | http://arxiv.org/abs/1708.08311 | id:1708.08311 author:Duc Minh Nguyen, Evaggelia Tsiligianni, Nikos Deligiannis category:cs.CV cs.LG stat.ML  published:2017-08-28 summary:Compressed sensing (CS) is a sampling theory that allows reconstruction of sparse (or compressible) signals from an incomplete number of measurements, using of a sensing mechanism implemented by an appropriate projection matrix. The CS theory is based on random Gaussian projection matrices, which satisfy recovery guarantees with high probability; however, sparse ternary {0, -1, +1} projections are more suitable for hardware implementation. In this paper, we present a deep learning approach to obtain very sparse ternary projections for compressed sensing. Our deep learning architecture jointly learns a pair of a projection matrix and a reconstruction operator in an end-to-end fashion. The experimental results on real images demonstrate the effectiveness of the proposed approach compared to state-of-the-art methods, with significant advantage in terms of complexity. version:1
arxiv-1705-04267 | A Cascaded Convolutional Neural Network for X-ray Low-dose CT Image Denoising | http://arxiv.org/abs/1705.04267 | id:1705.04267 author:Dufan Wu, Kyungsang Kim, Georges El Fakhri, Quanzheng Li category:cs.CV stat.ML I.2.6; I.4.3; J.3  published:2017-05-11 summary:Image denoising techniques are essential to reducing noise levels and enhancing diagnosis reliability in low-dose computed tomography (CT). Machine learning based denoising methods have shown great potential in removing the complex and spatial-variant noises in CT images. However, some residue artifacts would appear in the denoised image due to complexity of noises. A cascaded training network was proposed in this work, where the trained CNN was applied on the training dataset to initiate new trainings and remove artifacts induced by denoising. A cascades of convolutional neural networks (CNN) were built iteratively to achieve better performance with simple CNN structures. Experiments were carried out on 2016 Low-dose CT Grand Challenge datasets to evaluate the method's performance. version:2
arxiv-1708-08310 | Open-World Visual Recognition Using Knowledge Graphs | http://arxiv.org/abs/1708.08310 | id:1708.08310 author:Vincent P. A. Lonij, Ambrish Rawat, Maria-Irina Nicolae category:cs.LG cs.CV stat.ML  published:2017-08-28 summary:In a real-world setting, visual recognition systems can be brought to make predictions for images belonging to previously unknown class labels. In order to make semantically meaningful predictions for such inputs, we propose a two-step approach that utilizes information from knowledge graphs. First, a knowledge-graph representation is learned to embed a large set of entities into a semantic space. Second, an image representation is learned to embed images into the same space. Under this setup, we are able to predict structured properties in the form of relationship triples for any open-world image. This is true even when a set of labels has been omitted from the training protocols of both the knowledge graph and image embeddings. Furthermore, we append this learning framework with appropriate smoothness constraints and show how prior knowledge can be incorporated into the model. Both these improvements combined increase performance for visual recognition by a factor of six compared to our baseline. Finally, we propose a new, extended dataset which we use for experiments. version:1
arxiv-1708-04347 | Training Neural Networks with Very Little Data -- A Draft | http://arxiv.org/abs/1708.04347 | id:1708.04347 author:Hojjat Salehinejad, Joseph Barfett, Shahrokh Valaee, Timothy Dowdell category:cs.CV  published:2017-08-14 summary:Deep neural networks are complex architectures composed of many layers of nodes, resulting in a large number of parameters including weights and biases that must be estimated through training the network. Larger and more complex networks typically require more training data for adequate convergence than their more simple counterparts. The data available to train these networks is often limited or imbalanced. We propose the radial transform in polar coordinate space for image augmentation to facilitate the training of neural networks from limited source data. Pixel-wise coordinate transforms provide representations of the original image in the polar coordinate system and both augment data as well as increase the diversity of poorly represented classes. Experiments performed on MNIST and a set of multimodal medical images using the AlexNet and GoogLeNet neural network models show high classification accuracy using the proposed method. version:2
arxiv-1708-08288 | Stylizing Face Images via Multiple Exemplars | http://arxiv.org/abs/1708.08288 | id:1708.08288 author:Yibing Song, Linchao Bao, Shengfeng He, Qingxiong Yang, Ming-Hsuan Yang category:cs.CV cs.GR cs.MM  published:2017-08-28 summary:We address the problem of transferring the style of a headshot photo to face images. Existing methods using a single exemplar lead to inaccurate results when the exemplar does not contain sufficient stylized facial components for a given photo. In this work, we propose an algorithm to stylize face images using multiple exemplars containing different subjects in the same style. Patch correspondences between an input photo and multiple exemplars are established using a Markov Random Field (MRF), which enables accurate local energy transfer via Laplacian stacks. As image patches from multiple exemplars are used, the boundaries of facial components on the target image are inevitably inconsistent. The artifacts are removed by a post-processing step using an edge-preserving filter. Experimental results show that the proposed algorithm consistently produces visually pleasing results. version:1
arxiv-1708-05897 | Computer-aided diagnosis of lung nodule using gradient tree boosting and Bayesian optimization | http://arxiv.org/abs/1708.05897 | id:1708.05897 author:Mizuho Nishio, Mitsuo Nishizawa, Osamu Sugiyama, Ryosuke Kojima, Masahiro Yakami, Tomohiro Kuroda, Kaori Togashi category:cs.CV  published:2017-08-19 summary:We aimed to evaluate computer-aided diagnosis (CADx) system for lung nodule classification focusing on (i) usefulness of gradient tree boosting (XGBoost) and (ii) effectiveness of parameter optimization using Bayesian optimization (Tree Parzen Estimator, TPE) and random search. 99 lung nodules (62 lung cancers and 37 benign lung nodules) were included from public databases of CT images. A variant of local binary pattern was used for calculating feature vectors. Support vector machine (SVM) or XGBoost was trained using the feature vectors and their labels. TPE or random search was used for parameter optimization of SVM and XGBoost. Leave-one-out cross-validation was used for optimizing and evaluating the performance of our CADx system. Performance was evaluated using area under the curve (AUC) of receiver operating characteristic analysis. AUC was calculated 10 times, and its average was obtained. The best averaged AUC of SVM and XGBoost were 0.850 and 0.896, respectively; both were obtained using TPE. XGBoost was generally superior to SVM. Optimal parameters for achieving high AUC were obtained with fewer numbers of trials when using TPE, compared with random search. In conclusion, XGBoost was better than SVM for classifying lung nodules. TPE was more efficient than random search for parameter optimization. version:2
arxiv-1708-08267 | A Compromise Principle in Deep Monocular Depth Estimation | http://arxiv.org/abs/1708.08267 | id:1708.08267 author:Huan Fu, Mingming Gong, Chaohui Wang, Dacheng Tao category:cs.CV  published:2017-08-28 summary:Monocular depth estimation, which plays a key role in understanding 3D scene geometry, is fundamentally an ill-posed problem. Existing methods based on deep convolutional neural networks (DCNNs) have examined this problem by learning convolutional networks to estimate continuous depth maps from monocular images. However, we find that training a network to predict a high spatial resolution continuous depth map often suffers from poor local solutions. In this paper, we hypothesize that achieving a compromise between spatial and depth resolutions can improve network training. Based on this "compromise principle", we propose a regression-classification cascaded network (RCCN), which consists of a regression branch predicting a low spatial resolution continuous depth map and a classification branch predicting a high spatial resolution discrete depth map. The two branches form a cascaded structure allowing the classification and regression branches to benefit from each other. By leveraging large-scale raw training datasets and some data augmentation strategies, our network achieves top or state-of-the-art results on the NYU Depth V2, KITTI, and Make3D benchmarks. version:1
arxiv-1704-03805 | Attention-Set based Metric Learning for Video Face Recognition | http://arxiv.org/abs/1704.03805 | id:1704.03805 author:Yibo Hu, Xiang Wu, Ran He category:cs.CV  published:2017-04-12 summary:Face recognition has made great progress with the development of deep learning. However, video face recognition (VFR) is still an ongoing task due to various illumination, low-resolution, pose variations and motion blur. Most existing CNN-based VFR methods only obtain a feature vector from a single image and simply aggregate the features in a video, which less consider the correlations of face images in one video. In this paper, we propose a novel Attention-Set based Metric Learning (ASML) method to measure the statistical characteristics of image sets. It is a promising and generalized extension of Maximum Mean Discrepancy with memory attention weighting. First, we define an effective distance metric on image sets, which explicitly minimizes the intra-set distance and maximizes the inter-set distance simultaneously. Second, inspired by Neural Turing Machine, a Memory Attention Weighting is proposed to adapt set-aware global contents. Then ASML is naturally integrated into CNNs, resulting in an end-to-end learning scheme. Our method achieves state-of-the-art performance for the task of video face recognition on the three widely used benchmarks including YouTubeFace, YouTube Celebrities and Celebrity-1000. version:3
arxiv-1708-08245 | Digital image splicing detection based on Markov features in QDCT and QWT domain | http://arxiv.org/abs/1708.08245 | id:1708.08245 author:Ruxin Wang, Wei Lu, Shijun Xiang, Xianfeng Zhao, Jinwei Wang category:cs.CV cs.CR  published:2017-08-28 summary:Image splicing detection is of fundamental importance in digital forensics and therefore has attracted increasing attention recently. In this paper, a color image splicing detection approach is proposed based on Markov transition probability of quaternion component separation in quaternion discrete cosine transform (QDCT) domain and quaternion wavelet transform (QWT) domain. Firstly, Markov features of the intra-block and inter-block between block QDCT coefficients are obtained from the real part and three imaginary parts of QDCT coefficients respectively. Then, additional Markov features are extracted from luminance (Y) channel in quaternion wavelet transform domain to characterize the dependency of position among quaternion wavelet subband coefficients. Finally, ensemble classifier (EC) is exploited to classify the spliced and authentic color images. The experiment results demonstrate that the proposed approach can outperforms some state-of-the-art methods. version:1
arxiv-1708-08231 | Efficient Decision Trees for Multi-class Support Vector Machines Using Entropy and Generalization Error Estimation | http://arxiv.org/abs/1708.08231 | id:1708.08231 author:Pittipol Kantavat, Boonserm Kijsirikul, Patoomsiri Songsiri, Ken-ichi Fukui, Masayuki Numao category:cs.LG stat.ML  published:2017-08-28 summary:We propose new methods for Support Vector Machines (SVMs) using tree architecture for multi-class classi- fication. In each node of the tree, we select an appropriate binary classifier using entropy and generalization error estimation, then group the examples into positive and negative classes based on the selected classi- fier and train a new classifier for use in the classification phase. The proposed methods can work in time complexity between O(log2N) to O(N) where N is the number of classes. We compared the performance of our proposed methods to the traditional techniques on the UCI machine learning repository using 10-fold cross-validation. The experimental results show that our proposed methods are very useful for the problems that need fast classification time or problems with a large number of classes as the proposed methods run much faster than the traditional techniques but still provide comparable accuracy. version:1
arxiv-1707-05357 | Show and Recall: Learning What Makes Videos Memorable | http://arxiv.org/abs/1707.05357 | id:1707.05357 author:Sumit Shekhar, Dhruv Singal, Harvineet Singh, Manav Kedia, Akhil Shetty category:cs.CV  published:2017-07-17 summary:With the explosion of video content on the Internet, there is a need for research on methods for video analysis which take human cognition into account. One such cognitive measure is memorability, or the ability to recall visual content after watching it. Prior research has looked into image memorability and shown that it is intrinsic to visual content, but the problem of modeling video memorability has not been addressed sufficiently. In this work, we develop a prediction model for video memorability, including complexities of video content in it. Detailed feature analysis reveals that the proposed method correlates well with existing findings on memorability. We also describe a novel experiment of predicting video sub-shot memorability and show that our approach improves over current memorability methods in this task. Experiments on standard datasets demonstrate that the proposed metric can achieve results on par or better than the state-of-the art methods for video summarization. version:3
arxiv-1708-08201 | Automatic Dataset Augmentation | http://arxiv.org/abs/1708.08201 | id:1708.08201 author:Yalong Bai, Kuiyuan Yang, Wei-Ying Ma, Tiejun Zhao category:cs.CV  published:2017-08-28 summary:Large scale image dataset and deep convolutional neural network (DCNN) are two primary driving forces for the rapid progress made in generic object recognition tasks in recent years. While lots of network architectures have been continuously designed to pursue lower error rates, few efforts are devoted to enlarge existing datasets due to high labeling cost and unfair comparison issues. In this paper, we aim to achieve lower error rate by augmenting existing datasets in an automatic manner. Our method leverages both Web and DCNN, where Web provides massive images with rich contextual information, and DCNN replaces human to automatically label images under guidance of Web contextual information. Experiments show our method can automatically scale up existing datasets significantly from billions web pages with high accuracy, and significantly improve the performance on object recognition tasks by using the automatically augmented datasets, which demonstrates that more supervisory information has been automatically gathered from the Web. Both the dataset and models trained on the dataset are made publicly available. version:1
arxiv-1708-08197 | Cross-Age LFW: A Database for Studying Cross-Age Face Recognition in Unconstrained Environments | http://arxiv.org/abs/1708.08197 | id:1708.08197 author:Tianyue Zheng, Weihong Deng, Jiani Hu category:cs.CV  published:2017-08-28 summary:Labeled Faces in the Wild (LFW) database has been widely utilized as the benchmark of unconstrained face verification and due to big data driven machine learning methods, the performance on the database approaches nearly 100%. However, we argue that this accuracy may be too optimistic because of some limiting factors. Besides different poses, illuminations, occlusions and expressions, cross-age face is another challenge in face recognition. Different ages of the same person result in large intra-class variations and aging process is unavoidable in real world face verification. However, LFW does not pay much attention on it. Thereby we construct a Cross-Age LFW (CALFW) which deliberately searches and selects 3,000 positive face pairs with age gaps to add aging process intra-class variance. Negative pairs with same gender and race are also selected to reduce the influence of attribute difference between positive/negative pairs and achieve face verification instead of attributes classification. We evaluate several metric learning and deep learning methods on the new database. Compared to the accuracy on LFW, the accuracy drops about 10%-17% on CALFW. version:1
arxiv-1708-07590 | Hierarchical Multi-scale Attention Networks for Action Recognition | http://arxiv.org/abs/1708.07590 | id:1708.07590 author:Shiyang Yan, Jeremy S. Smith, Wenjin Lu, Bailing Zhang category:cs.CV  published:2017-08-25 summary:Recurrent Neural Networks (RNNs) have been widely used in natural language processing and computer vision. Among them, the Hierarchical Multi-scale RNN (HM-RNN), a kind of multi-scale hierarchical RNN proposed recently, can learn the hierarchical temporal structure from data automatically. In this paper, we extend the work to solve the computer vision task of action recognition. However, in sequence-to-sequence models like RNN, it is normally very hard to discover the relationships between inputs and outputs given static inputs. As a solution, attention mechanism could be applied to extract the relevant information from input thus facilitating the modeling of input-output relationships. Based on these considerations, we propose a novel attention network, namely Hierarchical Multi-scale Attention Network (HM-AN), by combining the HM-RNN and the attention mechanism and apply it to action recognition. A newly proposed gradient estimation method for stochastic neurons, namely Gumbel-softmax, is exploited to implement the temporal boundary detectors and the stochastic hard attention mechanism. To amealiate the negative effect of sensitive temperature of the Gumbel-softmax, an adaptive temperature training method is applied to better the system performance. The experimental results demonstrate the improved effect of HM-AN over LSTM with attention on the vision task. Through visualization of what have been learnt by the networks, it can be observed that both the attention regions of images and the hierarchical temporal structure can be captured by HM-AN. version:2
arxiv-1708-08190 | A Probabilistic Quality Representation Approach to Deep Blind Image Quality Prediction | http://arxiv.org/abs/1708.08190 | id:1708.08190 author:Hui Zeng, Lei Zhang, Alan C. Bovik category:cs.CV  published:2017-08-28 summary:Blind image quality assessment (BIQA) remains a very challenging problem due to the unavailability of a reference image. Deep learning based BIQA methods have been attracting increasing attention in recent years, yet it remains a difficult task to train a robust deep BIQA model because of the very limited number of training samples with human subjective scores. Most existing methods learn a regression network to minimize the prediction error of a scalar image quality score. However, such a scheme ignores the fact that an image will receive divergent subjective scores from different subjects, which cannot be adequately represented by a single scalar number. This is particularly true on complex, real-world distorted images. Moreover, images may broadly differ in their distributions of assigned subjective scores. Recognizing this, we propose a new representation of perceptual image quality, called probabilistic quality representation (PQR), to describe the image subjective score distribution, whereby a more robust loss function can be employed to train a deep BIQA model. The proposed PQR method is shown to not only speed up the convergence of deep model training, but to also greatly improve the achievable level of quality prediction accuracy relative to scalar quality score regression methods. version:1
arxiv-1708-08189 | An IoT Real-Time Biometric Authentication System Based on ECG Fiducial Extracted Features Using Discrete Cosine Transform | http://arxiv.org/abs/1708.08189 | id:1708.08189 author:Ahmed F. Hussein, Abbas K. AlZubaidi, Ali Al-Bayaty, Qais A. Habash category:cs.CV cs.CR  published:2017-08-28 summary:The conventional authentication technologies, like RFID tags and authentication cards/badges, suffer from different weaknesses, therefore a prompt replacement to use biometric method of authentication should be applied instead. Biometrics, such as fingerprints, voices, and ECG signals, are unique human characters that can be used for authentication processing. In this work, we present an IoT real-time authentication system based on using extracted ECG features to identify the unknown persons. The Discrete Cosine Transform (DCT) is used as an ECG feature extraction, where it has better characteristics for real-time system implementations. There are a substantial number of researches with a high accuracy of authentication, but most of them ignore the real-time capability of authenticating individuals. With the accuracy rate of 97.78% at around 1.21 seconds of processing time, the proposed system is more suitable for use in many applications that require fast and reliable authentication processing demands. version:1
arxiv-1708-08177 | Hyperprior on symmetric Dirichlet distribution | http://arxiv.org/abs/1708.08177 | id:1708.08177 author:Jun Lu category:cs.LG  published:2017-08-28 summary:In this article we introduce how to put vague hyperprior on Dirichlet distribution, and we update the parameter of it by adaptive rejection sampling (ARS). Finally we analyze this hyperprior in an over-fitted mixture model by some synthetic experiments. version:1
arxiv-1708-08169 | ChainerCV: a Library for Deep Learning in Computer Vision | http://arxiv.org/abs/1708.08169 | id:1708.08169 author:Yusuke Niitani, Toru Ogawa, Shunta Saito, Masaki Saito category:cs.CV  published:2017-08-28 summary:Despite significant progress of deep learning in the field of computer vision, there has not been a software library that covers these methods in a unifying manner. We introduce ChainerCV, a software library that is intended to fill this gap. ChainerCV supports numerous neural network models as well as software components needed to conduct research in computer vision. These implementations emphasize simplicity, flexibility and good software engineering practices. The library is designed to perform on par with the results reported in published papers and its tools can be used as a baseline for future research in computer vision. Our implementation includes sophisticated models like Faster R-CNN and SSD, and covers tasks such as object detection and semantic segmentation. version:1
arxiv-1705-10610 | The Importance of Automatic Syntactic Features in Vietnamese Named Entity Recognition | http://arxiv.org/abs/1705.10610 | id:1705.10610 author:Thai-Hoang Pham, Phuong Le-Hong category:cs.CL  published:2017-05-29 summary:This paper presents a state-of-the-art system for Vietnamese Named Entity Recognition (NER). By incorporating automatic syntactic features with word embeddings as input for bidirectional Long Short-Term Memory (Bi-LSTM), our system, although simpler than some deep learning architectures, achieves a much better result for Vietnamese NER. The proposed method achieves an overall F1 score of 92.05% on the test set of an evaluation campaign, organized in late 2016 by the Vietnamese Language and Speech Processing (VLSP) community. Our named entity recognition system outperforms the best previous systems for Vietnamese NER by a large margin. version:4
arxiv-1708-08157 | Characteristic and Universal Tensor Product Kernels | http://arxiv.org/abs/1708.08157 | id:1708.08157 author:Zoltan Szabo, Bharath K. Sriperumbudur category:stat.ML cs.IT math.IT stat.ME G.3; H.1.1; I.2.6  published:2017-08-28 summary:Kernel mean embeddings provide a versatile and powerful nonparametric representation of probability distributions with several fundamental applications in machine learning. Key to the success of the technique is whether the embedding is injective. This characteristic property of the underlying kernel ensures that probability distributions can be discriminated via their representations. In this paper, we consider kernels of tensor product type and various notions of characteristic property (including the one that captures joint independence of random variables) and provide a complete characterization for the corresponding embedding to be injective. This has applications, for example in independence measures such as Hilbert-Schmidt independence criterion (HSIC) to characterize the joint independence of multiple random variables. version:1
arxiv-1704-06440 | Equivalence Between Policy Gradients and Soft Q-Learning | http://arxiv.org/abs/1704.06440 | id:1704.06440 author:John Schulman, Pieter Abbeel, Xi Chen category:cs.LG  published:2017-04-21 summary:Two of the leading approaches for model-free reinforcement learning are policy gradient methods and $Q$-learning methods. $Q$-learning methods can be effective and sample-efficient when they work, however, it is not well-understood why they work, since empirically, the $Q$-values they estimate are very inaccurate. A partial explanation may be that $Q$-learning methods are secretly implementing policy gradient updates: we show that there is a precise equivalence between $Q$-learning and policy gradient methods in the setting of entropy-regularized reinforcement learning, that "soft" (entropy-regularized) $Q$-learning is exactly equivalent to a policy gradient method. We also point out a connection between $Q$-learning methods and natural policy gradient methods. Experimentally, we explore the entropy-regularized versions of $Q$-learning and policy gradients, and we find them to perform as well as (or slightly better than) the standard variants on the Atari benchmark. We also show that the equivalence holds in practical settings by constructing a $Q$-learning method that closely matches the learning dynamics of A3C without using a target network or $\epsilon$-greedy exploration schedule. version:2
arxiv-1708-08142 | Study of Set-Membership Kernel Adaptive Algorithms and Applications | http://arxiv.org/abs/1708.08142 | id:1708.08142 author:R. C. de Lamare, André Flores category:cs.LG  published:2017-08-27 summary:Adaptive algorithms based on kernel structures have been a topic of significant research over the past few years. The main advantage is that they form a family of universal approximators, offering an elegant solution to problems with nonlinearities. Nevertheless these methods deal with kernel expansions, creating a growing structure also known as dictionary, whose size depends on the number of new inputs. In this paper we derive the set-membership kernel-based normalized least-mean square (SM-NKLMS) algorithm, which is capable of limiting the size of the dictionary created in stationary environments. We also derive as an extension the set-membership kernelized affine projection (SM-KAP) algorithm. Finally several experiments are presented to compare the proposed SM-NKLMS and SM-KAP algorithms to the existing methods. version:1
arxiv-1708-08141 | One-Shot Concept Learning by Simulating Evolutionary Instinct Development | http://arxiv.org/abs/1708.08141 | id:1708.08141 author:Abrar Ahmed, Anish Bikmal category:cs.CV  published:2017-08-27 summary:Object recognition has become a crucial part of machine learning and computer vision recently. The current approach to object recognition involves Deep Learning and uses Convolutional Neural Networks to learn the pixel patterns of the objects implicitly through backpropagation. However, CNNs require thousands of examples in order to generalize successfully and often require heavy computing resources for training. This is considered rather sluggish when compared to the human ability to generalize and learn new categories given just a single example. Additionally, CNNs make it difficult to explicitly programmatically modify or intuitively interpret their learned representations. We propose a computational model that can successfully learn an object category from as few as one example and allows its learning style to be tailored explicitly to a scenario. Our model decomposes each image into two attributes: shape and color distribution. We then use a Bayesian criterion to probabilistically determine the likelihood of each category. The model takes each factor into account based on importance and calculates the conditional probability of the object belonging to each learned category. Our model is not only applicable to visual scenarios, but can also be implemented in a broader and more practical scope of situations such as Natural Language Processing as well as other places where it is possible to retrieve and construct individual attributes. Because the only condition our model presents is the ability to retrieve and construct individual attributes such as shape and color, it can be applied to essentially any class of visual objects. version:1
arxiv-1708-09000 | A Machine Learning Approach For Identifying Patients with Mild Traumatic Brain Injury Using Diffusion MRI Modeling | http://arxiv.org/abs/1708.09000 | id:1708.09000 author:Shervin Minaee, Yao Wang, Sohae Chung, Xiuyuan Wang, Els Fieremans, Steven Flanagan, Joseph Rath, Yvonne W. Lui category:cs.CV  published:2017-08-27 summary:While diffusion MRI has been extremely promising in the study of MTBI, identifying patients with recent MTBI remains a challenge. The literature is mixed with regard to localizing injury in these patients, however, gray matter such as the thalamus and white matter including the corpus callosum and frontal deep white matter have been repeatedly implicated as areas at high risk for injury. The purpose of this study is to develop a machine learning framework to classify MTBI patients and controls using features derived from multi-shell diffusion MRI in the thalamus, frontal white matter and corpus callosum. version:1
arxiv-1710-06835 | Shannon Entropy Estimation in $\infty$-Alphabets from Convergence Results | http://arxiv.org/abs/1710.06835 | id:1710.06835 author:Jorge F. Silva category:cs.IT cs.LG math.IT  published:2017-08-27 summary:The problem of Shannon entropy estimation in countable infinite alphabets is revisited from the adoption of convergence results of the entropy functional. Sufficient conditions for the convergence of the entropy are used, including scenarios with both finitely and infinitely supported distributions. From this angle, four plug-in histogram-based estimators are studied showing strong consistency and rate of convergences results for the case of finite and unknown supported distributions and families of distributions with summable tail bounded conditions. version:1
arxiv-1708-08123 | Impact of Feature Selection on Micro-Text Classification | http://arxiv.org/abs/1708.08123 | id:1708.08123 author:Ankit Vadehra, Maura R. Grossman, Gordon V. Cormack category:cs.IR cs.CL  published:2017-08-27 summary:Social media datasets, especially Twitter tweets, are popular in the field of text classification. Tweets are a valuable source of micro-text (sometimes referred to as "micro-blogs"), and have been studied in domains such as sentiment analysis, recommendation systems, spam detection, clustering, among others. Tweets often include keywords referred to as "Hashtags" that can be used as labels for the tweet. Using tweets encompassing 50 labels, we studied the impact of word versus character-level feature selection and extraction on different learners to solve a multi-class classification task. We show that feature extraction of simple character-level groups performs better than simple word groups and pre-processing methods like normalizing using Porter's Stemming and Part-of-Speech ("POS")-Lemmatization. version:1
arxiv-1708-08117 | Part-to-whole Registration of Histology and MRI using Shape Elements | http://arxiv.org/abs/1708.08117 | id:1708.08117 author:Jonas Pichat, Juan Eugenio Iglesias, Sotiris Nousias, Tarek Yousry, Sebastien Ourselin, Marc Modat category:cs.CV  published:2017-08-27 summary:Image registration between histology and magnetic resonance imaging (MRI) is a challenging task due to differences in structural content and contrast. Too thick and wide specimens cannot be processed all at once and must be cut into smaller pieces. This dramatically increases the complexity of the problem, since each piece should be individually and manually pre-aligned. To the best of our knowledge, no automatic method can reliably locate such piece of tissue within its respective whole in the MRI slice, and align it without any prior information. We propose here a novel automatic approach to the joint problem of multimodal registration between histology and MRI, when only a fraction of tissue is available from histology. The approach relies on the representation of images using their level lines so as to reach contrast invariance. Shape elements obtained via the extraction of bitangents are encoded in a projective-invariant manner, which permits the identification of common pieces of curves between two images. We evaluated the approach on human brain histology and compared resulting alignments against manually annotated ground truths. Considering the complexity of the brain folding patterns, preliminary results are promising and suggest the use of characteristic and meaningful shape elements for improved robustness and efficiency. version:1
arxiv-1708-05978 | Stochastic Primal-Dual Proximal ExtraGradient descent for compositely regularized optimization | http://arxiv.org/abs/1708.05978 | id:1708.05978 author:Tianyi Lin, Linbo Qiao, Teng Zhang, Jiashi Feng, Bofeng Zhang category:cs.LG math.OC stat.ML  published:2017-08-20 summary:We consider a wide range of regularized stochastic minimization problems with two regularization terms, one of which is composed with a linear function. This optimization model abstracts a number of important applications in artificial intelligence and machine learning, such as fused Lasso, fused logistic regression, and a class of graph-guided regularized minimization. The computational challenges of this model are in two folds. On one hand, the closed-form solution of the proximal mapping associated with the composed regularization term or the expected objective function is not available. On the other hand, the calculation of the full gradient of the expectation in the objective is very expensive when the number of input data samples is considerably large. To address these issues, we propose a stochastic variant of extra-gradient type methods, namely \textsf{Stochastic Primal-Dual Proximal ExtraGradient descent (SPDPEG)}, and analyze its convergence property for both convex and strongly convex objectives. For general convex objectives, the uniformly average iterates generated by \textsf{SPDPEG} converge in expectation with $O(1/\sqrt{t})$ rate. While for strongly convex objectives, the uniformly and non-uniformly average iterates generated by \textsf{SPDPEG} converge with $O(\log(t)/t)$ and $O(1/t)$ rates, respectively. The order of the rate of the proposed algorithm is known to match the best convergence rate for first-order stochastic algorithms. Experiments on fused logistic regression and graph-guided regularized logistic regression problems show that the proposed algorithm performs very efficiently and consistently outperforms other competing algorithms. version:2
arxiv-1708-08081 | Learning MSO-definable hypotheses on string | http://arxiv.org/abs/1708.08081 | id:1708.08081 author:Martin Grohe, Christof Löding, Martin Ritzert category:cs.LG cs.LO  published:2017-08-27 summary:We study the classification problems over string data for hypotheses specified by formulas of monadic second-order logic MSO. The goal is to design learning algorithms that run in time polynomial in the size of the training set, independently of or at least sublinear in the size of the whole data set. We prove negative as well as positive results. If the data set is an unprocessed string to which our algorithms have local access, then learning in sublinear time is impossible even for hypotheses definable in a small fragment of first-order logic. If we allow for a linear time pre-processing of the string data to build an index data structure, then learning of MSO-definable hypotheses is possible in time polynomial in the size of the training set, independently of the size of the whole data set. version:1
arxiv-1708-08053 | Anomaly Detection in Wireless Sensor Networks | http://arxiv.org/abs/1708.08053 | id:1708.08053 author:Pelumi Oluwasanya category:cs.LG stat.ML  published:2017-08-27 summary:Wireless sensor networks usually comprise a large number of sensors monitoring changes in variables. These changes in variables represent changes in physical quantities. The changes can occur for various reasons; these reasons are highlighted in this work. Outliers are unusual measurements. Outliers are important; they are information-bearing occurrences. This work seeks to identify them based on an approach presented in [1]. A critical review of most previous works in this area has been presented in [2], and few more are considered here just to set the stage. The main work can be described as this; given a set of measurements from sensors that represent a normal situation, [1] proceeds by first estimating the probability density function (pdf) of the set using a data-split approach, then estimate the entropy of the set using the arithmetic mean as an approximation for the expectation. The increase in entropy that occurs when strange data is recorded is used to detect unusual measurements in the test set depending on the desired confidence interval or false alarm rate. The results presented in [1] have been confirmed for different test signals such as the Gaussian, Beta, in one dimension and beta in two dimensions, and a beta and uniform mixture distribution in two dimensions. Finally, the method was confirmed on real data and the results are presented. The major drawbacks of [1] were identified, and a method that seeks to mitigate this using the Bhattacharyya distance is presented. This method detects more subtle anomalies, especially the type that would pass as normal in [1]. Finally, recommendations for future research are presented: the subject of interpretability, especially for subtle measurements, being the most elusive as of today. version:1
arxiv-1708-08042 | Imbalanced Malware Images Classification: a CNN based Approach | http://arxiv.org/abs/1708.08042 | id:1708.08042 author:Songqing Yue category:cs.CV cs.LG stat.ML  published:2017-08-27 summary:Deep convolutional neural networks (CNNs) can be applied to malware binary detection through images classification. The performance, however, is degraded due to the imbalance of malware families (classes). To mitigate this issue, we propose a simple yet effective weighted softmax loss which can be employed as the final layer of deep CNNs. The original softmax loss is weighted, and the weight value can be determined according to class size. A scaling parameter is also included in computing the weight. Proper selection of this parameter has been studied and an empirical option is given. The weighted loss aims at alleviating the impact of data imbalance in an end-to-end learning fashion. To validate the efficacy, we deploy the proposed weighted loss in a pre-trained deep CNN model and fine-tune it to achieve promising results on malware images classification. Extensive experiments also indicate that the new loss function can fit other typical CNNs with an improved classification performance. version:1
arxiv-1708-08022 | On the Protection of Private Information in Machine Learning Systems: Two Recent Approaches | http://arxiv.org/abs/1708.08022 | id:1708.08022 author:Martín Abadi, Úlfar Erlingsson, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Nicolas Papernot, Kunal Talwar, Li Zhang category:stat.ML cs.CR cs.LG  published:2017-08-26 summary:The recent, remarkable growth of machine learning has led to intense interest in the privacy of the data on which machine learning relies, and to new techniques for preserving privacy. However, older ideas about privacy may well remain valid and useful. This note reviews two recent works on privacy in the light of the wisdom of some of the early literature, in particular the principles distilled by Saltzer and Schroeder in the 1970s. version:1
arxiv-1708-08016 | Facial Expression Recognition using Visual Saliency and Deep Learning | http://arxiv.org/abs/1708.08016 | id:1708.08016 author:Viraj Mavani, Shanmuganathan Raman, Krishna P Miyapuram category:cs.CV  published:2017-08-26 summary:We have developed a convolutional neural network for the purpose of recognizing facial expressions in human beings. We have fine-tuned the existing convolutional neural network model trained on the visual recognition dataset used in the ILSVRC2012 to two widely used facial expression datasets - CFEE and RaFD, which when trained and tested independently yielded test accuracies of 74.79% and 95.71%, respectively. Generalization of results was evident by training on one dataset and testing on the other. Further, the image product of the cropped faces and their visual saliency maps were computed using Deep Multi-Layer Network for saliency prediction and were fed to the facial expression recognition CNN. In the most generalized experiment, we observed the top-1 accuracy in the test set to be 65.39%. General confusion trends between different facial expressions as exhibited by humans were also observed. version:1
arxiv-1708-08012 | Deep learning with convolutional neural networks for decoding and visualization of EEG pathology | http://arxiv.org/abs/1708.08012 | id:1708.08012 author:Robin Tibor Schirrmeister, Lukas Gemein, Katharina Eggensperger, Frank Hutter, Tonio Ball category:cs.LG cs.NE stat.ML I.2.6  published:2017-08-26 summary:We apply convolutional neural networks (ConvNets) to the task of distinguishing pathological from normal EEG recordings in the Temple University Hospital EEG Abnormal Corpus. We use two basic, shallow and deep ConvNet architectures recently shown to decode task-related information from EEG at least as well as established algorithms designed for this purpose. In decoding EEG pathology, both ConvNets reached substantially better accuracies (about 6% better, ~85% vs. ~79%) than the only published result for this dataset, and were still better when using only 1 minute of each recording for training and only six seconds of each recording for testing. We used automated methods to optimize architectural hyperparameters and found intriguingly different ConvNet architectures, e.g., with max pooling as the only nonlinearity. Visualizations of the ConvNet decoding behavior showed that they used spectral power changes in the delta (0-4 Hz) and theta (4-8 Hz) frequency range, possibly alongside other features, consistent with expectations derived from spectral analysis of the EEG data and from the textual medical reports. Analysis of the textual medical reports also highlighted the potential for accuracy increases by integrating contextual information, such as the age of subjects. In summary, the ConvNets and visualization techniques used in this study constitute a next step towards clinically useful automated EEG diagnosis and establish a new baseline for future work on this topic. version:1
arxiv-1708-07977 | Synthesising Wider Field Images from Narrow-Field Retinal Video Acquired Using a Low-Cost Direct Ophthalmoscope (Arclight) Attached to a Smartphone | http://arxiv.org/abs/1708.07977 | id:1708.07977 author:Keylor Daniel Chaves Viquez, Ognjen Arandjelovic, Andrew Blaikie, In Ae Hwang category:cs.CV  published:2017-08-26 summary:Access to low cost retinal imaging devices in low and middle income countries is limited, compromising progress in preventing needless blindness. The Arclight is a recently developed low-cost solar powered direct ophthalmoscope which can be attached to the camera of a smartphone to acquire retinal images and video. However, the acquired data is inherently limited by the optics of direct ophthalmoscopy, resulting in a narrow field of view with associated corneal reflections, limiting its usefulness. In this work we describe the first fully automatic method utilizing videos acquired using the Arclight attached to a mobile phone camera to create wider view, higher quality still images comparable with images obtained using much more expensive and bulky dedicated traditional retinal cameras. version:1
arxiv-1708-02455 | Fast Low-Rank Bayesian Matrix Completion with Hierarchical Gaussian Prior Models | http://arxiv.org/abs/1708.02455 | id:1708.02455 author:Linxiao Yang, Jun Fang, Huiping Duan, Hongbin Li, Bing Zeng category:cs.LG stat.ML  published:2017-08-08 summary:The problem of low rank matrix completion is considered in this paper. To exploit the underlying low-rank structure of the data matrix, we propose a hierarchical Gaussian prior model, where columns of the low-rank matrix are assumed to follow a Gaussian distribution with zero mean and a common precision matrix, and a Wishart distribution is specified as a hyperprior over the precision matrix. We show that such a hierarchical Gaussian prior has the potential to encourage a low-rank solution. Based on the proposed hierarchical prior model, a variational Bayesian method is developed for matrix completion, where the generalized approximate massage passing (GAMP) technique is embedded into the variational Bayesian inference in order to circumvent cumbersome matrix inverse operations. Simulation results show that our proposed method demonstrates superiority over existing state-of-the-art matrix completion methods. version:2
arxiv-1708-07975 | Plausible Deniability for Privacy-Preserving Data Synthesis | http://arxiv.org/abs/1708.07975 | id:1708.07975 author:Vincent Bindschaedler, Reza Shokri, Carl A. Gunter category:cs.CR cs.DB cs.LG stat.ML  published:2017-08-26 summary:Releasing full data records is one of the most challenging problems in data privacy. On the one hand, many of the popular techniques such as data de-identification are problematic because of their dependence on the background knowledge of adversaries. On the other hand, rigorous methods such as the exponential mechanism for differential privacy are often computationally impractical to use for releasing high dimensional data or cannot preserve high utility of original data due to their extensive data perturbation. This paper presents a criterion called plausible deniability that provides a formal privacy guarantee, notably for releasing sensitive datasets: an output record can be released only if a certain amount of input records are indistinguishable, up to a privacy parameter. This notion does not depend on the background knowledge of an adversary. Also, it can efficiently be checked by privacy tests. We present mechanisms to generate synthetic datasets with similar statistical properties to the input data and the same format. We study this technique both theoretically and experimentally. A key theoretical result shows that, with proper randomization, the plausible deniability mechanism generates differentially private synthetic data. We demonstrate the efficiency of this generative technique on a large dataset; it is shown to preserve the utility of original data with respect to various statistical analysis and machine learning measures. version:1
arxiv-1708-07972 | Maximum A Posteriori Estimation of Distances Between Deep Features in Still-to-Video Face Recognition | http://arxiv.org/abs/1708.07972 | id:1708.07972 author:Andrey V. Savchenko, Natalya S. Belova category:cs.CV 68T10  published:2017-08-26 summary:The paper deals with the still-to-video face recognition for the small sample size problem based on computation of distances between high-dimensional deep bottleneck features. We present the novel statistical recognition method, in which the still-to-video recognition task is casted into Maximum A Posteriori estimation. In this method we maximize the joint probabilistic density of the distances to all reference still images. It is shown that this likelihood can be estimated with the known asymptotically normal distribution of the Kullback-Leibler discriminations between nonnegative features. The experimental study with the LFW (Labeled Faces in the Wild), YTF (YouTube Faces) and IJB-A (IARPA Janus Benchmark A) datasets has been provided. We demonstrated, that the proposed approach can be applied with the state-of-the-art deep features and dissimilarity measures. Our algorithm achieves 3-5% higher accuracy when compared with conventional aggregation of decisions obtained for all frames. version:1
arxiv-1708-07967 | Faster Clustering via Non-Backtracking Random Walks | http://arxiv.org/abs/1708.07967 | id:1708.07967 author:Brian Rappaport, Anuththari Gamage, Shuchin Aeron category:stat.ML cs.LG cs.SI  published:2017-08-26 summary:This paper presents VEC-NBT, a variation on the unsupervised graph clustering technique VEC, which improves upon the performance of the original algorithm significantly for sparse graphs. VEC employs a novel application of the state-of-the-art word2vec model to embed a graph in Euclidean space via random walks on the nodes of the graph. In VEC-NBT, we modify the original algorithm to use a non-backtracking random walk instead of the normal backtracking random walk used in VEC. We introduce a modification to a non-backtracking random walk, which we call a begrudgingly-backtracking random walk, and show empirically that using this model of random walks for VEC-NBT requires shorter walks on the graph to obtain results with comparable or greater accuracy than VEC, especially for sparser graphs. version:1
arxiv-1708-06197 | Segmentation of retinal cysts from Optical Coherence Tomography volumes via selective enhancement | http://arxiv.org/abs/1708.06197 | id:1708.06197 author:Karthik Gopinath, Jayanthi Sivaswamy category:cs.CV  published:2017-08-21 summary:Automated and accurate segmentation of cystoid structures in Optical Coherence Tomography (OCT) is of interest in the early detection of retinal diseases. It is, however, a challenging task. We propose a novel method for localizing cysts in 3D OCT volumes. The proposed work is biologically inspired and based on selective enhancement of the cysts, by inducing motion to a given OCT slice. A Convolutional Neural Network (CNN) is designed to learn a mapping function that combines the result of multiple such motions to produce a probability map for cyst locations in a given slice. The final segmentation of cysts is obtained via simple clustering of the detected cyst locations. The proposed method is evaluated on two public datasets and one private dataset. The public datasets include the one released for the OPTIMA Cyst segmentation challenge (OCSC) in MICCAI 2015 and the DME dataset. After training on the OCSC train set, the method achieves a mean Dice Coefficient (DC) of 0.71 on the OCSC test set. The robustness of the algorithm was examined by cross-validation on the DME and AEI (private) datasets and a mean DC values obtained were 0.69 and 0.79, respectively. Overall, the proposed system outperforms all benchmarks. These results underscore the strengths of the proposed method in handling variations in both data acquisition protocols and scanners. version:2
arxiv-1708-07954 | Distributed Bundle Adjustment | http://arxiv.org/abs/1708.07954 | id:1708.07954 author:Karthikeyan Natesan Ramamurthy, Chung-Ching Lin, Aleksandr Aravkin, Sharath Pankanti, Raphael Viguier category:cs.CV  published:2017-08-26 summary:Most methods for Bundle Adjustment (BA) in computer vision are either centralized or operate incrementally. This leads to poor scaling and affects the quality of solution as the number of images grows in large scale structure from motion (SfM). Furthermore, they cannot be used in scenarios where image acquisition and processing must be distributed. We address this problem with a new distributed BA algorithm. Our distributed formulation uses alternating direction method of multipliers (ADMM), and, since each processor sees only a small portion of the data, we show that robust formulations improve performance. We analyze convergence of the proposed algorithm, and illustrate numerical performance, accuracy of the parameter estimates, and scalability of the distributed implementation in the context of synthetic 3D datasets with known camera position and orientation ground truth. The results are comparable to an alternate state-of-the-art centralized bundle adjustment algorithm on synthetic and real 3D reconstruction problems. The runtime of our implementation scales linearly with the number of observed points. version:1
arxiv-1708-07950 | MTIL17: English to Indian Langauge Statistical Machine Translation | http://arxiv.org/abs/1708.07950 | id:1708.07950 author:Raj Nath Patel, Prakash B. Pimpale, Sasikumar M category:cs.CL  published:2017-08-26 summary:English to Indian language machine translation poses the challenge of structural and morphological divergence. This paper describes English to Indian language statistical machine translation using pre-ordering and suffix separation. The pre-ordering uses rules to transfer the structure of the source sentences prior to training and translation. This syntactic restructuring helps statistical machine translation to tackle the structural divergence and hence better translation quality. The suffix separation is used to tackle the morphological divergence between English and highly agglutinative Indian languages. We demonstrate that the use of pre-ordering and suffix separation helps in improving the quality of English to Indian Language machine translation. version:1
arxiv-1708-07949 | TraNNsformer: Neural Network Transformation for Memristive Crossbar based Neuromorphic System Design | http://arxiv.org/abs/1708.07949 | id:1708.07949 author:Aayush Ankit, Abhronil Sengupta, Kaushik Roy category:cs.ET cs.NE  published:2017-08-26 summary:Implementation of Neuromorphic Systems using post Complementary Metal-Oxide-Semiconductor (CMOS) technology based Memristive Crossbar Array (MCA) has emerged as a promising solution to enable low-power acceleration of neural networks. However, the recent trend to design Deep Neural Networks (DNNs) for achieving human-like cognitive abilities poses significant challenges towards the scalable design of neuromorphic systems (due to the increase in computation/storage demands). Network pruning [7] is a powerful technique to remove redundant connections for designing optimally connected (maximally sparse) DNNs. However, such pruning techniques induce irregular connections that are incoherent to the crossbar structure. Eventually they produce DNNs with highly inefficient hardware realizations (in terms of area and energy). In this work, we propose TraNNsformer - an integrated training framework that transforms DNNs to enable their efficient realization on MCA-based systems. TraNNsformer first prunes the connectivity matrix while forming clusters with the remaining connections. Subsequently, it retrains the network to fine tune the connections and reinforce the clusters. This is done iteratively to transform the original connectivity into an optimally pruned and maximally clustered mapping. Without accuracy loss, TraNNsformer reduces the area (energy) consumption by 28% - 55% (49% - 67%) with respect to the original network. Compared to network pruning, TraNNsformer achieves 28% - 49% (15% - 29%) area (energy) savings. Furthermore, TraNNsformer is a technology-aware framework that allows mapping a given DNN to any MCA size permissible by the memristive technology for reliable operations. version:1
arxiv-1708-07946 | Sales Forecast in E-commerce using Convolutional Neural Network | http://arxiv.org/abs/1708.07946 | id:1708.07946 author:Kui Zhao, Can Wang category:cs.LG stat.ML  published:2017-08-26 summary:Sales forecast is an essential task in E-commerce and has a crucial impact on making informed business decisions. It can help us to manage the workforce, cash flow and resources such as optimizing the supply chain of manufacturers etc. Sales forecast is a challenging problem in that sales is affected by many factors including promotion activities, price changes, and user preferences etc. Traditional sales forecast techniques mainly rely on historical sales data to predict future sales and their accuracies are limited. Some more recent learning-based methods capture more information in the model to improve the forecast accuracy. However, these methods require case-by-case manual feature engineering for specific commercial scenarios, which is usually a difficult, time-consuming task and requires expert knowledge. To overcome the limitations of existing methods, we propose a novel approach in this paper to learn effective features automatically from the structured data using the Convolutional Neural Network (CNN). When fed with raw log data, our approach can automatically extract effective features from that and then forecast sales using those extracted features. We test our method on a large real-world dataset from CaiNiao.com and the experimental results validate the effectiveness of our method. version:1
arxiv-1708-07942 | m-TSNE: A Framework for Visualizing High-Dimensional Multivariate Time Series | http://arxiv.org/abs/1708.07942 | id:1708.07942 author:Minh Nguyen, Sanjay Purushotham, Hien To, Cyrus Shahabi category:cs.LG stat.ME  published:2017-08-26 summary:Multivariate time series (MTS) have become increasingly common in healthcare domains where human vital signs and laboratory results are collected for predictive diagnosis. Recently, there have been increasing efforts to visualize healthcare MTS data based on star charts or parallel coordinates. However, such techniques might not be ideal for visualizing a large MTS dataset, since it is difficult to obtain insights or interpretations due to the inherent high dimensionality of MTS. In this paper, we propose 'm-TSNE': a simple and novel framework to visualize high-dimensional MTS data by projecting them into a low-dimensional (2-D or 3-D) space while capturing the underlying data properties. Our framework is easy to use and provides interpretable insights for healthcare professionals to understand MTS data. We evaluate our visualization framework on two real-world datasets and demonstrate that the results of our m-TSNE show patterns that are easy to understand while the other methods' visualization may have limitations in interpretability. version:1
arxiv-1708-07937 | 3D Binary Signatures | http://arxiv.org/abs/1708.07937 | id:1708.07937 author:Siddharth Srivastava, Brejesh Lall category:cs.CV  published:2017-08-26 summary:In this paper, we propose a novel binary descriptor for 3D point clouds. The proposed descriptor termed as 3D Binary Signature (3DBS) is motivated from the matching efficiency of the binary descriptors for 2D images. 3DBS describes keypoints from point clouds with a binary vector resulting in extremely fast matching. The method uses keypoints from standard keypoint detectors. The descriptor is built by constructing a Local Reference Frame and aligning a local surface patch accordingly. The local surface patch constitutes of identifying nearest neighbours based upon an angular constraint among them. The points are ordered with respect to the distance from the keypoints. The normals of the ordered pairs of these keypoints are projected on the axes and the relative magnitude is used to assign a binary digit. The vector thus constituted is used as a signature for representing the keypoints. The matching is done by using hamming distance. We show that 3DBS outperforms state of the art descriptors on various evaluation metrics. version:1
arxiv-1708-07933 | Robust Stereo Feature Descriptor for Visual Odometry | http://arxiv.org/abs/1708.07933 | id:1708.07933 author:Ehsan Shojaedini, Reza Safabakhsh category:cs.CV  published:2017-08-26 summary:In this paper, we propose a simple way to utilize stereo camera data to improve feature descriptors. Computer vision algorithms that use a stereo camera require some calculations of 3D information. We leverage this pre-calculated information to improve feature descriptor algorithms. We use the 3D feature information to estimate the scale of each feature. This way, each feature descriptor will be more robust to scale change without significant computations. In addition, we use stereo images to construct the descriptor vector. The SIFT and FREAK descriptors are used to evaluate the proposed method. The scale normalization technique in feature tracking test improves the standard SIFT by 8.75% and improves the standard FREAK by 28.65%. We also use a simple visual odometry algorithm and test it on the KITTI datasets. The stereo FREAK descriptor raises the number of inlier matches by 19% and consequently improves the accuracy of visual odometry by 23%. version:1
arxiv-1708-07920 | Deep Learning for Target Classification from SAR Imagery: Data Augmentation and Translation Invariance | http://arxiv.org/abs/1708.07920 | id:1708.07920 author:Hidetoshi Furukawa category:cs.CV  published:2017-08-26 summary:This report deals with translation invariance of convolutional neural networks (CNNs) for automatic target recognition (ATR) from synthetic aperture radar (SAR) imagery. In particular, the translation invariance of CNNs for SAR ATR represents the robustness against misalignment of target chips extracted from SAR images. To understand the translation invariance of the CNNs, we trained CNNs which classify the target chips from the MSTAR into the ten classes under the condition of with and without data augmentation, and then visualized the translation invariance of the CNNs. According to our results, even if we use a deep residual network, the translation invariance of the CNN without data augmentation using the aligned images such as the MSTAR target chips is not so large. A more important factor of translation invariance is the use of augmented training data. Furthermore, our CNN using augmented training data achieved a state-of-the-art classification accuracy of 99.6%. These results show an importance of domain-specific data augmentation. version:1
arxiv-1708-02285 | An Adaptive Cluster-based Wiener Filter for Speckle Reduction of OCT Skin Images | http://arxiv.org/abs/1708.02285 | id:1708.02285 author:Elaheh Rashedi, Saba Adabi, Darius Mehregan, Xue-wen Chen category:cs.CV  published:2017-07-31 summary:Optical coherence tomography (OCT) has become a favorable device in the dermatology discipline due to its moderate resolution and penetration depth. OCT images, however, contain a grainy pattern, called speckle, due to the use of a broadband source in the configuration of OCT. So far, a variety of filtering techniques is introduced to reduce speckle in OCT images. Most of these methods are generic and can be applied to OCT images of different tissues. In this paper, we present an adaptive filtering method, optimized for speckle reduction of OCT skin images. Considering the architectural structure of skin layers, OCT skin images can be segmented into differentiable clusters. The image in each cluster is then filtered by a Wiener filter. The proposed method was tested on optical solid phantoms with predetermined optical properties. The algorithm was also tested on healthy human skin images. The results show that the proposed cluster-based filtering method can effectively reduce the speckle and increase the signal-to-noise ratio and contrast while preserving the edges in the image. version:3
arxiv-1708-07906 | Network Essence: PageRank Completion and Centrality-Conforming Markov Chains | http://arxiv.org/abs/1708.07906 | id:1708.07906 author:Shang-Hua Teng category:cs.SI cs.CG cs.DS math.CO stat.ML  published:2017-08-25 summary:Ji\v{r}\'i Matou\v{s}ek (1963-2015) had many breakthrough contributions in mathematics and algorithm design. His milestone results are not only profound but also elegant. By going beyond the original objects --- such as Euclidean spaces or linear programs --- Jirka found the essence of the challenging mathematical/algorithmic problems as well as beautiful solutions that were natural to him, but were surprising discoveries to the field. In this short exploration article, I will first share with readers my initial encounter with Jirka and discuss one of his fundamental geometric results from the early 1990s. In the age of social and information networks, I will then turn the discussion from geometric structures to network structures, attempting to take a humble step towards the holy grail of network science, that is to understand the network essence that underlies the observed sparse-and-multifaceted network data. I will discuss a simple result which summarizes some basic algebraic properties of personalized PageRank matrices. Unlike the traditional transitive closure of binary relations, the personalized PageRank matrices take "accumulated Markovian closure" of network data. Some of these algebraic properties are known in various contexts. But I hope featuring them together in a broader context will help to illustrate the desirable properties of this Markovian completion of networks, and motivate systematic developments of a network theory for understanding vast and ubiquitous multifaceted network data. version:1
arxiv-1708-07903 | Nationality Classification Using Name Embeddings | http://arxiv.org/abs/1708.07903 | id:1708.07903 author:Junting Ye, Shuchu Han, Yifan Hu, Baris Coskun, Meizhu Liu, Hong Qin, Steven Skiena category:cs.SI cs.CL  published:2017-08-25 summary:Nationality identification unlocks important demographic information, with many applications in biomedical and sociological research. Existing name-based nationality classifiers use name substrings as features and are trained on small, unrepresentative sets of labeled names, typically extracted from Wikipedia. As a result, these methods achieve limited performance and cannot support fine-grained classification. We exploit the phenomena of homophily in communication patterns to learn name embeddings, a new representation that encodes gender, ethnicity, and nationality which is readily applicable to building classifiers and other systems. Through our analysis of 57M contact lists from a major Internet company, we are able to design a fine-grained nationality classifier covering 39 groups representing over 90% of the world population. In an evaluation against other published systems over 13 common classes, our F1 score (0.795) is substantial better than our closest competitor Ethnea (0.580). To the best of our knowledge, this is the most accurate, fine-grained nationality classifier available. As a social media application, we apply our classifiers to the followers of major Twitter celebrities over six different domains. We demonstrate stark differences in the ethnicities of the followers of Trump and Obama, and in the sports and entertainments favored by different groups. Finally, we identify an anomalous political figure whose presumably inflated following appears largely incapable of reading the language he posts in. version:1
arxiv-1708-07889 | Batch-Based Activity Recognition from Egocentric Photo-Streams | http://arxiv.org/abs/1708.07889 | id:1708.07889 author:Alejandro Cartas, Mariella Dimiccoli, Petia Radeva category:cs.CV  published:2017-08-25 summary:Activity recognition from long unstructured egocentric photo-streams has several applications in assistive technology such as health monitoring and frailty detection, just to name a few. However, one of its main technical challenges is to deal with the low frame rate of wearable photo-cameras, which causes abrupt appearance changes between consecutive frames. In consequence, important discriminatory low-level features from motion such as optical flow cannot be estimated. In this paper, we present a batch-driven approach for training a deep learning architecture that strongly rely on Long short-term units to tackle this problem. We propose two different implementations of the same approach that process a photo-stream sequence using batches of fixed size with the goal of capturing the temporal evolution of high-level features. The main difference between these implementations is that one explicitly models consecutive batches by overlapping them. Experimental results over a public dataset acquired by three users demonstrate the validity of the proposed architectures to exploit the temporal evolution of convolutional features over time without relying on event boundaries. version:1
arxiv-1708-07888 | Active Expansion Sampling for Learning Feasible Domains in an Unbounded Input Space | http://arxiv.org/abs/1708.07888 | id:1708.07888 author:Wei Chen, Mark Fuge category:cs.LG stat.ML  published:2017-08-25 summary:Many engineering problems require identifying feasible domains under implicit constraints. One example is finding acceptable car body styling designs based on constraints like aesthetics and functionality. Current active-learning based methods learn feasible domains for bounded input spaces. However, we usually lack prior knowledge about how to set those input variable bounds. Bounds that are too small will fail to cover all feasible domains; while bounds that are too large will waste query budget. To avoid this problem, we introduce Active Expansion Sampling (AES), a method that identifies (possibly disconnected) feasible domains over an unbounded input space. AES progressively expands our knowledge of the input space, and uses successive exploitation and exploration stages to switch between learning the decision boundary and searching for new feasible domains. We show that AES has a misclassification loss guarantee within the explored region, independent of the number of iterations or labeled samples. Thus it can be used for real-time prediction of samples' feasibility within the explored region. We evaluate AES on three test examples and compare AES with a similar method -- the straddle heuristic -- that operates over fixed input variable bounds. version:1
arxiv-1708-07887 | RaspiReader: An Open Source Fingerprint Reader Facilitating Spoof Detection | http://arxiv.org/abs/1708.07887 | id:1708.07887 author:Joshua J. Engelsma, Kai Cao, Anil K. Jain category:cs.CV  published:2017-08-25 summary:We present the design and prototype of an open source, optical fingerprint reader, called RaspiReader, using ubiquitous components. RaspiReader, a low-cost and easy to assemble reader, provides the fingerprint research community a seamless and simple method for gaining more control over the sensing component of fingerprint recognition systems. In particular, we posit that this versatile fingerprint reader will encourage researchers to explore novel spoof detection methods that integrate both hardware and software. RaspiReader's hardware is customized with two cameras for fingerprint acquisition with one camera providing high contrast, frustrated total internal reflection (FTIR) images, and the other camera outputting direct images. Using both of these image streams, we extract complementary information which, when fused together, results in highly discriminative features for fingerprint spoof (presentation attack) detection. Our experimental results demonstrate a marked improvement over previous spoof detection methods which rely only on FTIR images provided by COTS optical readers. Finally, fingerprint matching experiments between images acquired from the FTIR output of the RaspiReader and images acquired from a COTS fingerprint reader verify the interoperability of the RaspiReader with existing COTS optical readers. version:1
arxiv-1708-07878 | Stereo DSO: Large-Scale Direct Sparse Visual Odometry with Stereo Cameras | http://arxiv.org/abs/1708.07878 | id:1708.07878 author:Rui Wang, Martin Schwörer, Daniel Cremers category:cs.CV  published:2017-08-25 summary:We propose Stereo Direct Sparse Odometry (Stereo DSO) as a novel method for highly accurate real-time visual odometry estimation of large-scale environments from stereo cameras. It jointly optimizes for all the model parameters within the active window, including the intrinsic/extrinsic camera parameters of all keyframes and the depth values of all selected pixels. In particular, we propose a novel approach to integrate constraints from static stereo into the bundle adjustment pipeline of temporal multi-view stereo. Real-time optimization is realized by sampling pixels uniformly from image regions with sufficient intensity gradient. Fixed-baseline stereo resolves scale drift. It also reduces the sensitivities to large optical flow and to rolling shutter effect which are known shortcomings of direct image alignment methods. Quantitative evaluation demonstrates that the proposed Stereo DSO outperforms existing state-of-the-art visual odometry methods both in terms of tracking accuracy and robustness. Moreover, our method delivers a more precise metric 3D reconstruction than previous dense/semi-dense direct approaches while providing a higher reconstruction density than feature-based methods. version:1
arxiv-1708-07860 | Multi-task Self-Supervised Visual Learning | http://arxiv.org/abs/1708.07860 | id:1708.07860 author:Carl Doersch, Andrew Zisserman category:cs.CV  published:2017-08-25 summary:We investigate methods for combining multiple self-supervised tasks--i.e., supervised tasks where data can be collected without manual labeling--in order to train a single visual representation. First, we provide an apples-to-apples comparison of four different self-supervised tasks using the very deep ResNet-101 architecture. We then combine tasks to jointly train a network. We also explore lasso regularization to encourage the network to factorize the information in its representation, and methods for "harmonizing" network inputs in order to learn a more unified representation. We evaluate all methods on ImageNet classification, PASCAL VOC detection, and NYU depth prediction. Our results show that deeper networks work better, and that combining tasks--even via a naive multi-head architecture--always improves performance. Our best joint network nearly matches the PASCAL performance of a model pre-trained on ImageNet classification, and matches the ImageNet network on NYU depth prediction. version:1
arxiv-1708-07850 | Structured Low-Rank Matrix Factorization: Global Optimality, Algorithms, and Applications | http://arxiv.org/abs/1708.07850 | id:1708.07850 author:Benjamin D. Haeffele, Rene Vidal category:cs.LG cs.CV cs.NA  published:2017-08-25 summary:Recently, convex formulations of low-rank matrix factorization problems have received considerable attention in machine learning. However, such formulations often require solving for a matrix of the size of the data matrix, making it challenging to apply them to large scale datasets. Moreover, in many applications the data can display structures beyond simply being low-rank, e.g., images and videos present complex spatio-temporal structures that are largely ignored by standard low-rank methods. In this paper we study a matrix factorization technique that is suitable for large datasets and captures additional structure in the factors by using a particular form of regularization that includes well-known regularizers such as total variation and the nuclear norm as particular cases. Although the resulting optimization problem is non-convex, we show that if the size of the factors is large enough, under certain conditions, any local minimizer for the factors yields a global minimizer. A few practical algorithms are also provided to solve the matrix factorization problem, and bounds on the distance from a given approximate solution of the optimization problem to the global optimum are derived. Examples in neural calcium imaging video segmentation and hyperspectral compressed recovery show the advantages of our approach on high-dimensional datasets. version:1
arxiv-1709-02684 | Identifying Mirror Symmetry Density with Delay in Spiking Neural Networks | http://arxiv.org/abs/1709.02684 | id:1709.02684 author:Jonathan K. George, Cesare Soci, Volker J. Sorger category:q-bio.NC cs.CV  published:2017-08-25 summary:The ability to rapidly identify symmetry and anti-symmetry is an essential attribute of intelligence. Symmetry perception is a central process in human vision and may be key to human 3D visualization. While previous work in understanding neuron symmetry perception has concentrated on the neuron as an integrator, here we show how the coincidence detecting property of the spiking neuron can be used to reveal symmetry density in spatial data. We develop a method for synchronizing symmetry-identifying spiking artificial neural networks to enable layering and feedback in the network. We show a method for building a network capable of identifying symmetry density between sets of data and present a digital logic implementation demonstrating an 8x8 leaky-integrate-and-fire symmetry detector in a field programmable gate array. Our results show that the efficiencies of spiking neural networks can be harnessed to rapidly identify symmetry in spatial data with applications in image processing, 3D computer vision, and robotics. version:1
arxiv-1708-06872 | Discovering Political Topics in Facebook Discussion threads with Spectral Contextualization | http://arxiv.org/abs/1708.06872 | id:1708.06872 author:Yilin Zhang, Marie Poux-Berthe, Chris Wells, Karolina Koc-Michalska, Karl Rohe category:stat.AP cs.CL physics.soc-ph  published:2017-08-23 summary:We propose a new technique, Spectral Contextualization, to study political engagement on Facebook during the 2012 French presidential election. In particular, we examine the Facebook posts of the eight leading candidates and the comments beneath these posts. We find evidence of both (i) candidate-centered structure, where citizens primarily comment on the wall of one candidate and (ii) issue-centered structure (i.e. on political topics), where citizens' attention and expression is primarily directed towards a specific set of issues (e.g. economics, immigration, etc). To discover issue-centered structure, we develop Spectral Contextualization, a novel approach to analyze a network with high-dimensional node covariates. This technique scales to hundreds of thousands of nodes and thousands of covariates. In the Facebook data, spectral clustering without any contextualizing information finds a mixture of (i) candidate and (ii) issue clusters. The contextualizing information with text data helps to separate these two structures. We conclude by showing that the novel methodology is consistent under a statistical model. version:2
arxiv-1708-07808 | Accelerated Reconstruction of Perfusion-Weighted MRI Enforcing Jointly Local and Nonlocal Spatio-temporal Constraints | http://arxiv.org/abs/1708.07808 | id:1708.07808 author:Cagdas Ulas, Christine Preibisch, Jonathan Sperl, Thomas Pyka, Jayashree Kalpathy-Cramer, Bjoern Menze category:cs.CV  published:2017-08-25 summary:Perfusion-weighted magnetic resonance imaging (MRI) is an imaging technique that allows one to measure tissue perfusion in an organ of interest through the injection of an intravascular paramagnetic contrast agent (CA). Due to a preference for high temporal and spatial resolution in many applications, this modality could significantly benefit from accelerated data acquisitions. In this paper, we specifically address the problem of reconstructing perfusion MR image series from a subset of k-space data. Our proposed approach is motivated by the observation that temporal variations (dynamics) in perfusion imaging often exhibit correlation across different spatial scales. Hence, we propose a model that jointly penalizes the voxel-wise deviations in temporal gradient images obtained based on a baseline, and the patch-wise dissimilarities between the spatio-temporal neighborhoods of entire image sequence. We validate our method on dynamic susceptibility contrast (DSC)-MRI and dynamic contrast-enhanced (DCE)-MRI brain perfusion datasets acquired from 10 tumor patients in total. We provide extensive analysis of reconstruction performance and perfusion parameter estimation in comparison to state-of-the-art reconstruction methods. Experimental results on clinical datasets demonstrate that our reconstruction model can potentially achieve up to 8-fold acceleration by enabling accurate estimation of perfusion parameters while preserving spatial image details and reconstructing the complete perfusion time-intensity curves (TICs). version:1
arxiv-1708-07807 | Modular Learning Component Attacks: Today's Reality, Tomorrow's Challenge | http://arxiv.org/abs/1708.07807 | id:1708.07807 author:Xinyang Zhang, Yujie Ji, Ting Wang category:cs.CR cs.LG stat.ML  published:2017-08-25 summary:Many of today's machine learning (ML) systems are not built from scratch, but are compositions of an array of {\em modular learning components} (MLCs). The increasing use of MLCs significantly simplifies the ML system development cycles. However, as most MLCs are contributed and maintained by third parties, their lack of standardization and regulation entails profound security implications. In this paper, for the first time, we demonstrate that potentially harmful MLCs pose immense threats to the security of ML systems. We present a broad class of {\em logic-bomb} attacks in which maliciously crafted MLCs trigger host systems to malfunction in a predictable manner. By empirically studying two state-of-the-art ML systems in the healthcare domain, we explore the feasibility of such attacks. For example, we show that, without prior knowledge about the host ML system, by modifying only 3.3{\textperthousand} of the MLC's parameters, each with distortion below $10^{-3}$, the adversary is able to force the misdiagnosis of target victims' skin cancers with 100\% success rate. We provide analytical justification for the success of such attacks, which points to the fundamental characteristics of today's ML models: high dimensionality, non-linearity, and non-convexity. The issue thus seems fundamental to many ML systems. We further discuss potential countermeasures to mitigate MLC-based attacks and their potential technical challenges. version:1
arxiv-1708-01525 | The physical structure of grammatical correlations: equivalences, formalizations and consequences | http://arxiv.org/abs/1708.01525 | id:1708.01525 author:Angel J. Gallego, Roman Orus category:cs.CL cond-mat.str-el physics.hist-ph quant-ph  published:2017-08-04 summary:In this paper we consider some well-known facts in syntax from a physics perspective, which allows us to establish some remarkable equivalences. Specifically, we observe that the operation MERGE put forward by N. Chomsky in 1995 can be interpreted as a physical information coarse-graining. Thus, MERGE in linguistics entails information renormalization in physics, according to different time scales. We make this point mathematically formal in terms of language models, i.e., probability distributions over word sequences, widely used in natural language processing as well as other ambits. In this setting, MERGE corresponds to a 3-index probability tensor implementing a coarse-graining, akin to a probabilistic context-free grammar. The probability vectors of meaningful sentences are naturally given by tensor networks (TN) that are mostly loop-free, such as Tree Tensor Networks and Matrix Product States. These structures have short-ranged correlations in the syntactic distance by construction and, because of the peculiarities of human language, they are extremely efficient to manipulate computationally. We also propose how to obtain such language models from probability distributions of certain TN quantum states, which we show to be efficiently preparable by a quantum computer. Moreover, using tools from quantum information and entanglement theory, we use these quantum states to prove classical lower bounds on the perplexity of the probability distribution for a set of words in a sentence. Implications of these results are discussed in the ambits of theoretical and computational linguistics, artificial intelligence, programming languages, RNA and protein sequencing, quantum many-body systems, and beyond. version:2
arxiv-1708-07787 | Delayed Sampling and Automatic Rao-Blackwellization of Probabilistic Programs | http://arxiv.org/abs/1708.07787 | id:1708.07787 author:Lawrence M. Murray, Daniel Lundén, Jan Kudlicka, David Broman, Thomas B. Schön category:stat.ML stat.CO  published:2017-08-25 summary:We introduce a dynamic mechanism for the solution of analytically-tractable substructure in probabilistic programs, to reduce variance in Monte Carlo estimators. For inference with Sequential Monte Carlo, it yields improvements such as locally-optimal proposals and Rao-Blackwellization, with little modification to model code necessary. A directed graph is maintained alongside the running program, evolving dynamically as the program triggers operations upon it. Nodes of the graph represent random variables, and edges the analytically-tractable relationships between them (e.g. conjugate priors and affine transformations). Each random variable is held in the graph for as long as possible, sampled only when used by the program in a context that cannot be resolved analytically. This allows it to be analytically conditioned on as many observations as possible before sampling. We have implemented the approach in both Anglican and a new probabilistic programming language named Birch. We demonstrate it on a number of small examples, and a larger mixed linear-nonlinear state-space model. version:1
arxiv-1708-07785 | Integral Curvature Representation and Matching Algorithms for Identification of Dolphins and Whales | http://arxiv.org/abs/1708.07785 | id:1708.07785 author:Hendrik J. Weideman, Zachary M. Jablons, Jason Holmberg, Kiirsten Flynn, John Calambokidis, Reny B. Tyson, Jason B. Allen, Randall S. Wells, Krista Hupman, Kim Urian, Charles V. Stewart category:cs.CV  published:2017-08-25 summary:We address the problem of identifying individual cetaceans from images showing the trailing edge of their fins. Given the trailing edge from an unknown individual, we produce a ranking of known individuals from a database. The nicks and notches along the trailing edge define an individual's unique signature. We define a representation based on integral curvature that is robust to changes in viewpoint and pose, and captures the pattern of nicks and notches in a local neighborhood at multiple scales. We explore two ranking methods that use this representation. The first uses a dynamic programming time-warping algorithm to align two representations, and interprets the alignment cost as a measure of similarity. This algorithm also exploits learned spatial weights to downweight matches from regions of unstable curvature. The second interprets the representation as a feature descriptor. Feature keypoints are defined at the local extrema of the representation. Descriptors for the set of known individuals are stored in a tree structure, which allows us to perform queries given the descriptors from an unknown trailing edge. We evaluate the top-k accuracy on two real-world datasets to demonstrate the effectiveness of the curvature representation, achieving top-1 accuracy scores of approximately 95% and 80% for bottlenose dolphins and humpback whales, respectively. version:1
arxiv-1708-02043 | What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption Generator? | http://arxiv.org/abs/1708.02043 | id:1708.02043 author:Marc Tanti, Albert Gatt, Kenneth P. Camilleri category:cs.CL cs.CV cs.NE  published:2017-08-07 summary:In neural image captioning systems, a recurrent neural network (RNN) is typically viewed as the primary `generation' component. This view suggests that the image features should be `injected' into the RNN. This is in fact the dominant view in the literature. Alternatively, the RNN can instead be viewed as only encoding the previously generated words. This view suggests that the RNN should only be used to encode linguistic features and that only the final representation should be `merged' with the image features at a later stage. This paper compares these two architectures. We find that, in general, late merging outperforms injection, suggesting that RNNs are better viewed as encoders, rather than generators. version:2
arxiv-1708-00277 | Learning Deep Convolutional Embeddings for Face Representation Using Joint Sample- and Set-based Supervision | http://arxiv.org/abs/1708.00277 | id:1708.00277 author:Baris Gecer, Vassileios Balntas, Tae-Kyun Kim category:cs.CV  published:2017-08-01 summary:In this work, we investigate several methods and strategies to learn deep embeddings for face recognition, using joint sample- and set-based optimization. We explain our framework that expands traditional learning with set-based supervision together with the strategies used to maintain set characteristics. We, then, briefly review the related set-based loss functions, and subsequently propose a novel Max-Margin Loss which maximizes maximum possible inter-class margin with assistance of Support Vector Machines (SVMs). It implicitly pushes all the samples towards correct side of the margin with a vector perpendicular to the hyperplane and a strength inversely proportional to the distance to it. We show that the introduced loss outperform the previous sample-based and set-based ones in terms verification of faces on two commonly used benchmarks. version:2
arxiv-1708-07770 | Evaluation of Deep Learning on an Abstract Image Classification Dataset | http://arxiv.org/abs/1708.07770 | id:1708.07770 author:Sebastian Stabinger, Antonio Rodriguez-Sanchez category:cs.CV  published:2017-08-25 summary:Convolutional Neural Networks have become state of the art methods for image classification over the last couple of years. By now they perform better than human subjects on many of the image classification datasets. Most of these datasets are based on the notion of concrete classes (i.e. images are classified by the type of object in the image). In this paper we present a novel image classification dataset, using abstract classes, which should be easy to solve for humans, but variations of it are challenging for CNNs. The classification performance of popular CNN architectures is evaluated on this dataset and variations of the dataset that might be interesting for further research are identified. version:1
arxiv-1708-07180 | Bootstrapping the Out-of-sample Predictions for Efficient and Accurate Cross-Validation | http://arxiv.org/abs/1708.07180 | id:1708.07180 author:Ioannis Tsamardinos, Elissavet Greasidou, Michalis Tsagris, Giorgos Borboudakis category:cs.LG  published:2017-08-23 summary:Cross-Validation (CV), and out-of-sample performance-estimation protocols in general, are often employed both for (a) selecting the optimal combination of algorithms and values of hyper-parameters (called a configuration) for producing the final predictive model, and (b) estimating the predictive performance of the final model. However, the cross-validated performance of the best configuration is optimistically biased. We present an efficient bootstrap method that corrects for the bias, called Bootstrap Bias Corrected CV (BBC-CV). BBC-CV's main idea is to bootstrap the whole process of selecting the best-performing configuration on the out-of-sample predictions of each configuration, without additional training of models. In comparison to the alternatives, namely the nested cross-validation and a method by Tibshirani and Tibshirani, BBC-CV is computationally more efficient, has smaller variance and bias, and is applicable to any metric of performance (accuracy, AUC, concordance index, mean squared error). Subsequently, we employ again the idea of bootstrapping the out-of-sample predictions to speed up the CV process. Specifically, using a bootstrap-based hypothesis test we stop training of models on new folds of statistically-significantly inferior configurations. We name the method Bootstrap Corrected with Early Dropping CV (BCED-CV) that is both efficient and provides accurate performance estimates. version:2
arxiv-1708-08998 | Deep Structure for end-to-end inverse rendering | http://arxiv.org/abs/1708.08998 | id:1708.08998 author:Shima Kamyab, Ali Ghodsi, S. Zohreh Azimifar category:cs.CV  published:2017-08-25 summary:Inverse rendering in a 3D format denoted to recovering the 3D properties of a scene given 2D input image(s) and is typically done using 3D Morphable Model (3DMM) based methods from single view images. These models formulate each face as a weighted combination of some basis vectors extracted from the training data. In this paper a deep framework is proposed in which the coefficients and basis vectors are computed by training an autoencoder network and a Convolutional Neural Network (CNN) simultaneously. The idea is to find a common cause which can be mapped to both the 3D structure and corresponding 2D image using deep networks. The empirical results verify the power of deep framework in finding accurate 3D shapes of human faces from their corresponding 2D images on synthetic datasets of human faces. version:1
arxiv-1708-07718 | Linear Differential Constraints for Photo-polarimetric Height Estimation | http://arxiv.org/abs/1708.07718 | id:1708.07718 author:Silvia Tozza, William A. P. Smith, Dizhong Zhu, Ravi Ramamoorthi, Edwin R. Hancock category:cs.CV cs.NA math.NA  published:2017-08-25 summary:In this paper we present a differential approach to photo-polarimetric shape estimation. We propose several alternative differential constraints based on polarisation and photometric shading information and show how to express them in a unified partial differential system. Our method uses the image ratios technique to combine shading and polarisation information in order to directly reconstruct surface height, without first computing surface normal vectors. Moreover, we are able to remove the non-linearities so that the problem reduces to solving a linear differential problem. We also introduce a new method for estimating a polarisation image from multichannel data and, finally, we show it is possible to estimate the illumination directions in a two source setup, extending the method into an uncalibrated scenario. From a numerical point of view, we use a least-squares formulation of the discrete version of the problem. To the best of our knowledge, this is the first work to consider a unified differential approach to solve photo-polarimetric shape estimation directly for height. Numerical results on synthetic and real-world data confirm the effectiveness of our proposed method. version:1
arxiv-1708-07690 | Revisiting the Centroid-based Method: A Strong Baseline for Multi-Document Summarization | http://arxiv.org/abs/1708.07690 | id:1708.07690 author:Demian Gholipour Ghalandari category:cs.CL  published:2017-08-25 summary:The centroid-based model for extractive document summarization is a simple and fast baseline that ranks sentences based on their similarity to a centroid vector. In this paper, we apply this ranking to possible summaries instead of sentences and use a simple greedy algorithm to find the best summary. Furthermore, we show possi- bilities to scale up to larger input docu- ment collections by selecting a small num- ber of sentences from each document prior to constructing the summary. Experiments were done on the DUC2004 dataset for multi-document summarization. We ob- serve a higher performance over the orig- inal model, on par with more complex state-of-the-art methods. version:1
arxiv-1708-01571 | Standard Steady State Genetic Algorithms Can Hillclimb Faster than Mutation-only Evolutionary Algorithms | http://arxiv.org/abs/1708.01571 | id:1708.01571 author:Dogan Corus, Pietro S. Oliveto category:cs.NE F.2  published:2017-08-04 summary:Explaining to what extent the real power of genetic algorithms lies in the ability of crossover to recombine individuals into higher quality solutions is an important problem in evolutionary computation. In this paper we show how the interplay between mutation and crossover can make genetic algorithms hillclimb faster than their mutation-only counterparts. We devise a Markov Chain framework that allows to rigorously prove an upper bound on the runtime of standard steady state genetic algorithms to hillclimb the OneMax function. The bound establishes that the steady-state genetic algorithms are 25% faster than all standard bit mutation-only evolutionary algorithms with static mutation rate up to lower order terms for moderate population sizes. The analysis also suggests that larger populations may be faster than populations of size 2. We present a lower bound for a greedy (2+1) GA that matches the upper bound for populations larger than 2, rigorously proving that 2 individuals cannot outperform larger population sizes under greedy selection and greedy crossover up to lower order terms. In complementary experiments the best population size is greater than 2 and the greedy genetic algorithms are faster than standard ones, further suggesting that the derived lower bound also holds for the standard steady state (2+1) GA. version:2
arxiv-1708-07644 | Joint Structured Learning and Predictions under Logical Constraints in Conditional Random Fields | http://arxiv.org/abs/1708.07644 | id:1708.07644 author:Jean-Luc Meunier category:stat.ML cs.LG  published:2017-08-25 summary:This paper is concerned with structured machine learning, in a supervised machine learning context. It discusses how to make joint structured learning on interdependent objects of different nature, as well as how to enforce logical con-straints when predicting labels. We explain how this need arose in a Document Understanding task. We then discuss a general extension to Conditional Random Field (CRF) for this purpose and present the contributed open source implementation on top of the open source PyStruct library. We evaluate its performance on a publicly available dataset. version:1
arxiv-1707-00389 | Convolutional Dictionary Learning: Acceleration and Convergence | http://arxiv.org/abs/1707.00389 | id:1707.00389 author:Il Yong Chun, Jeffrey A. Fessler category:cs.LG math.OC  published:2017-07-03 summary:Convolutional dictionary learning (CDL or sparsifying CDL) has many applications in image processing and computer vision. There has been growing interest in developing efficient algorithms for CDL, mostly relying on the augmented Lagrangian (AL) method or the variant alternating direction method of multipliers (ADMM). When their parameters are properly tuned, AL methods have shown fast convergence in CDL. However, the parameter tuning process is not trivial due to its data dependence and, in practice, the convergence of AL methods depends on the AL parameters for nonconvex CDL problems. To moderate these problems, this paper proposes a new practically feasible and convergent Block Proximal Gradient method using a Majorizer (BPG-M) for CDL. The BPG-M-based CDL is investigated with different block updating schemes and majorization matrix designs, and further accelerated by incorporating some momentum coefficient formulas and restarting techniques. All of the methods investigated incorporate a boundary artifacts removal (or, more generally, sampling) operator in the learning model. Numerical experiments show that, without needing any parameter tuning process, the proposed BPG-M approach converges more stably to desirable solutions of lower objective values than the existing state-of-the-art ADMM algorithm and its memory-efficient variant do. Compared to the ADMM approaches, the BPG-M method using a multi-block updating scheme is particularly useful in single-threaded CDL algorithm handling large datasets, due to its lower memory requirement and no polynomial computational complexity. Image denoising experiments show that, for relatively strong additive white Gaussian noise, the filters learned by BPG-M-based CDL outperform those trained by the ADMM approach. version:2
arxiv-1708-07632 | Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition | http://arxiv.org/abs/1708.07632 | id:1708.07632 author:Kensho Hara, Hirokatsu Kataoka, Yutaka Satoh category:cs.CV  published:2017-08-25 summary:Convolutional neural networks with spatio-temporal 3D kernels (3D CNNs) have an ability to directly extract spatio-temporal features from videos for action recognition. Although the 3D kernels tend to overfit because of a large number of their parameters, the 3D CNNs are greatly improved by using recent huge video databases. However, the architecture of 3D CNNs is relatively shallow against to the success of very deep neural networks in 2D-based CNNs, such as residual networks (ResNets). In this paper, we propose a 3D CNNs based on ResNets toward a better action representation. We describe the training procedure of our 3D ResNets in details. We experimentally evaluate the 3D ResNets on the ActivityNet and Kinetics datasets. The 3D ResNets trained on the Kinetics did not suffer from overfitting despite the large number of parameters of the model, and achieved better performance than relatively shallow networks, such as C3D. Our code and pretrained models (e.g. Kinetics and ActivityNet) are publicly available at https://github.com/kenshohara/3D-ResNets. version:1
arxiv-1708-07624 | SPARQL as a Foreign Language | http://arxiv.org/abs/1708.07624 | id:1708.07624 author:Tommaso Soru, Edgard Marx, Diego Moussallem, Gustavo Publio, André Valdestilhas, Diego Esteves, Ciro Baron Neto category:cs.CL cs.DB 68T99 I.2.6; I.2.7  published:2017-08-25 summary:In the last years, the Linked Data Cloud has achieved a size of more than 100 billion facts pertaining to a multitude of domains. However, accessing this information has been significantly challenging for lay users. Approaches to problems such as Question Answering on Linked Data and Link Discovery have notably played a role in increasing information access. These approaches are often based on handcrafted and/or statistical models derived from data observation. Recently, Deep Learning architectures based on Neural Networks called seq2seq have shown to achieve state-of-the-art results at translating sequences into sequences. In this direction, we propose Neural SPARQL Machines, end-to-end deep architectures to translate any natural language expression into sentences encoding SPARQL queries. Our preliminary results, restricted on selected DBpedia classes, show that Neural SPARQL Machines are a promising approach for Question Answering on Linked Data, as they can deal with known problems such as vocabulary mismatch and perform graph pattern composition. version:1
arxiv-1708-07601 | A wavelet frame coefficient total variational model for image restoration | http://arxiv.org/abs/1708.07601 | id:1708.07601 author:Wei Wang, Xiang-Gen Xia, Shengli Zhang category:cs.CV  published:2017-08-25 summary:In this paper, we propose a Rudin-Osher-Fatemi(ROF)-like model for image restoration which utilizes total variation (TV) regularization on the wavelet feature images. The model imposes more smoothing power on the cartoon image generated by the low-pass filter and less strength on the edges generated by the high-pass filters. Thus, the model can preserve more edges and details than the ROF model. Next, the existence of solution for the model was proved and a slightly modified split Bregman algorithm was used to solve it. At last, we present some experimental results to show its competitive advantage to the related methods both in quality and efficiency. version:1
arxiv-1708-07436 | Differentially Private Regression for Discrete-Time Survival Analysis | http://arxiv.org/abs/1708.07436 | id:1708.07436 author:Thông T. Nguyên, Siu Cheung Hui category:cs.LG cs.CR cs.DB  published:2017-08-24 summary:In survival analysis, regression models are used to understand the effects of explanatory variables (e.g., age, sex, weight, etc.) to the survival probability. However, for sensitive survival data such as medical data, there are serious concerns about the privacy of individuals in the data set when medical data is used to fit the regression models. The closest work addressing such privacy concerns is the work on Cox regression which linearly projects the original data to a lower dimensional space. However, the weakness of this approach is that there is no formal privacy guarantee for such projection. In this work, we aim to propose solutions for the regression problem in survival analysis with the protection of differential privacy which is a golden standard of privacy protection in data privacy research. To this end, we extend the Output Perturbation and Objective Perturbation approaches which are originally proposed to protect differential privacy for the Empirical Risk Minimization (ERM) problems. In addition, we also propose a novel sampling approach based on the Markov Chain Monte Carlo (MCMC) method to practically guarantee differential privacy with better accuracy. We show that our proposed approaches achieve good accuracy as compared to the non-private results while guaranteeing differential privacy for individuals in the private data set. version:2
arxiv-1708-07827 | Second-Order Optimization for Non-Convex Machine Learning: An Empirical Study | http://arxiv.org/abs/1708.07827 | id:1708.07827 author:Peng Xu, Farbod Roosta-Khorasan, Michael W. Mahoney category:math.OC cs.LG math.NA stat.ML  published:2017-08-25 summary:The resurgence of deep learning, as a highly effective machine learning paradigm, has brought back to life the old optimization question of non-convexity. Indeed, the challenges related to the large-scale nature of many modern machine learning applications are severely exacerbated by the inherent non-convexity in the underlying models. In this light, efficient optimization algorithms which can be effectively applied to such large-scale and non-convex learning problems are highly desired. In doing so, however, the bulk of research has been almost completely restricted to the class of 1st-order algorithms. This is despite the fact that employing the curvature information, e.g., in the form of Hessian, can indeed help with obtaining effective methods with desirable convergence properties for non-convex problems, e.g., avoiding saddle-points and convergence to local minima. The conventional wisdom, in the machine learning community is that the application of 2nd-order methods, i.e., those that employ Hessian as well as gradient information, can be highly inefficient. Consequently, 1st-order algorithms, such as stochastic gradient descent (SGD), have been at the center-stage for solving such machine learning problems. Here, we aim at addressing this misconception by considering efficient and stochastic variants of Newton's method, namely, sub-sampled trust-region and cubic regularization, whose theoretical convergence properties have recently been established in [Xu 2017]. Using a variety of experiments, we empirically evaluate the performance of these methods for solving non-convex machine learning applications. In doing so, we highlight the shortcomings of 1st-order methods, e.g., high sensitivity to hyper-parameters such as step-size and undesirable behavior near saddle-points, and showcase the advantages of employing curvature information as effective remedy. version:1
arxiv-1708-07581 | Accurate parameter estimation for Bayesian Network Classifiers using Hierarchical Dirichlet Processes | http://arxiv.org/abs/1708.07581 | id:1708.07581 author:Francois Petitjean, Wray Buntine, Geoffrey I. Webb, Nayyar Zaidi category:cs.LG stat.ML  published:2017-08-25 summary:This paper introduces a novel parameter estimation method for the probability tables of Bayesian Network Classifiers (BNCs), using Hierarchical Dirichlet Processes (HDPs). The main result of this paper is to show that proper parameter estimation allows BNCs to outperform leading learning methods such as Random Forest for both 0-1 loss and RMSE, albeit just on categorical datasets. As data assets become larger, entering the hyped world of big, accurate classification requires three main elements: (1) classifiers with low-bias that can capture the fine-detail of large datasets (2) out-of-core learners that can learn from data without having to hold it all in main memory and (3) models that can classify new data very efficiently. The latest Bayesian Network classifiers (BNCs) have these requirements. Their bias can be controlled easily by increasing the number of parents of the nodes in the graph. Their structure can be learned out of core with a limited number of passes over the data. However, as the bias is made lower to accurately model classification tasks, so is the accuracy of their parameters' estimates. In this paper, we introduce the use of Hierarchical Dirichlet Processes for accurate parameter estimation of BNCs. We conduct an extensive set of experiments on 68 standard datasets and demonstrate that our resulting classifiers perform very competitively with Random Forest in terms of prediction, while keeping the out-of-core capability and superior classification time. version:1
arxiv-1708-06073 | The Microsoft 2017 Conversational Speech Recognition System | http://arxiv.org/abs/1708.06073 | id:1708.06073 author:W. Xiong, L. Wu, F. Alleva, J. Droppo, X. Huang, A. Stolcke category:cs.CL  published:2017-08-21 summary:We describe the 2017 version of Microsoft's conversational speech recognition system, in which we update our 2016 system with recent developments in neural-network-based acoustic and language modeling to further advance the state of the art on the Switchboard speech recognition task. The system adds a CNN-BLSTM acoustic model to the set of model architectures we combined previously, and includes character-based and dialog session aware LSTM language models in rescoring. For system combination we adopt a two-stage approach, whereby subsets of acoustic models are first combined at the senone/frame level, followed by a word-level voting via confusion networks. We also added a confusion network rescoring step after system combination. The resulting system yields a 5.1\% word error rate on the 2000 Switchboard evaluation set. version:2
arxiv-1708-08997 | Learning a 3D descriptor for cross-source point cloud registration from synthetic data | http://arxiv.org/abs/1708.08997 | id:1708.08997 author:Xiaoshui Huang category:cs.CV  published:2017-08-24 summary:As the development of 3D sensors, registration of 3D data (e.g. point cloud) coming from different kind of sensor is dispensable and shows great demanding. However, point cloud registration between different sensors is challenging because of the variant of density, missing data, different viewpoint, noise and outliers, and geometric transformation. In this paper, we propose a method to learn a 3D descriptor for finding the correspondent relations between these challenging point clouds. To train the deep learning framework, we use synthetic 3D point cloud as input. Starting from synthetic dataset, we use region-based sampling method to select reasonable, large and diverse training samples from synthetic samples. Then, we use data augmentation to extend our network be robust to rotation transformation. We focus our work on more general cases that point clouds coming from different sensors, named cross-source point cloud. The experiments show that our descriptor is not only able to generalize to new scenes, but also generalize to different sensors. The results demonstrate that the proposed method successfully aligns two 3D cross-source point clouds which outperforms state-of-the-art method. version:1
arxiv-1708-00689 | Dirichlet Bayesian Network Scores and the Maximum Entropy Principle | http://arxiv.org/abs/1708.00689 | id:1708.00689 author:Marco Scutari category:math.ST stat.ME stat.ML stat.TH  published:2017-08-02 summary:A classic approach for learning Bayesian networks from data is to select the maximum a posteriori (MAP) network. In the case of discrete Bayesian networks, the MAP network is selected by maximising one of several possible Bayesian Dirichlet (BD) scores; the most famous is the Bayesian Dirichlet equivalent uniform (BDeu) score from Heckerman et al. (1995). The key properties of BDeu arise from its underlying uniform prior, which makes structure learning computationally efficient; does not require the elicitation of prior knowledge from experts; and satisfies score equivalence. In this paper we will discuss the impact of this uniform prior on structure learning from an information theoretic perspective, showing how BDeu may violate the maximum entropy principle when applied to sparse data and how it may also be problematic from a Bayesian model selection perspective. On the other hand, the BDs score proposed in Scutari (2016) arises from a piecewise prior and it does not appear to violate the maximum entropy principle, even though it is asymptotically equivalent to BDeu. version:3
arxiv-1708-07555 | A Robust Indoor Scene Recognition Method based on Sparse Representation | http://arxiv.org/abs/1708.07555 | id:1708.07555 author:Guilherme Nascimento, Camila Laranjeira, Vinicius Braz, Anisio Lacerda, Erickson R. Nascimento category:cs.CV  published:2017-08-24 summary:In this paper, we present a robust method for scene recognition, which leverages Convolutional Neural Networks (CNNs) features and Sparse Coding setting by creating a new representation of indoor scenes. Although CNNs highly benefited the fields of computer vision and pattern recognition, convolutional layers adjust weights on a global-approach, which might lead to losing important local details such as objects and small structures. Our proposed scene representation relies on both: global features that mostly refers to environment's structure, and local features that are sparsely combined to capture characteristics of common objects of a given scene. This new representation is based on fragments of the scene and leverages features extracted by CNNs. The experimental evaluation shows that the resulting representation outperforms previous scene recognition methods on Scene15 and MIT67 datasets, and performs competitively on SUN397, while being highly robust to perturbations in the input image such as noise and occlusion. version:1
arxiv-1708-07549 | Objective Classes for Micro-Facial Expression Recognition | http://arxiv.org/abs/1708.07549 | id:1708.07549 author:Adrian K. Davison, Walied Merghani, Moi Hoon Yap category:cs.CV  published:2017-08-24 summary:Micro-expressions are brief spontaneous facial expressions that appear on a face when a person conceals an emotion, making them different to normal facial expressions in subtlety and duration. Currently, emotion classes within the CASME II dataset are based on Action Units and self-reports, creating conflicts during machine learning training. We will show that classifying expressions using Action Units, instead of predicted emotion, removes the potential bias of human reporting. The proposed classes are tested using LBP-TOP, HOOF and HOG 3D feature descriptors. The experiments are evaluated on two benchmark FACS coded datasets: CASME II and SAMM. The best result achieves 86.35\% accuracy when classifying the proposed 5 classes on CASME II using HOG 3D, outperforming the result of the state-of-the-art 5-class emotional-based classification in CASME II. Results indicate that classification based on Action Units provides an objective method to improve micro-expression recognition. version:1
arxiv-1705-03951 | Learning 3D Object Categories by Looking Around Them | http://arxiv.org/abs/1705.03951 | id:1705.03951 author:David Novotny, Diane Larlus, Andrea Vedaldi category:cs.CV  published:2017-05-10 summary:Traditional approaches for learning 3D object categories use either synthetic data or manual supervision. In this paper, we propose a method which does not require manual annotations and is instead cued by observing objects from a moving vantage point. Our system builds on two innovations: a Siamese viewpoint factorization network that robustly aligns different videos together without explicitly comparing 3D shapes; and a 3D shape completion network that can extract the full shape of an object from partial observations. We also demonstrate the benefits of configuring networks to perform probabilistic predictions as well as of geometry-aware data augmentation schemes. We obtain state-of-the-art results on publicly-available benchmarks. version:2
arxiv-1708-07826 | Logistic Regression as Soft Perceptron Learning | http://arxiv.org/abs/1708.07826 | id:1708.07826 author:Raul Rojas category:stat.ML 62M45  68Q32 K.3.2; I.5.1  published:2017-08-24 summary:We comment on the fact that gradient ascent for logistic regression has a connection with the perceptron learning algorithm. Logistic learning is the "soft" variant of perceptron learning. version:1
arxiv-1708-04907 | Multi-View Stereo with Single-View Semantic Mesh Refinement | http://arxiv.org/abs/1708.04907 | id:1708.04907 author:Andrea Romanoni, Marco Ciccone, Francesco Visin, Matteo Matteucci category:cs.CV  published:2017-08-16 summary:While 3D reconstruction is a well-established and widely explored research topic, semantic 3D reconstruction has only recently witnessed an increasing share of attention from the Computer Vision community. Semantic annotations allow in fact to enforce strong class-dependent priors, as planarity for ground and walls, which can be exploited to refine the reconstruction often resulting in non-trivial performance improvements. State-of-the art methods propose volumetric approaches to fuse RGB image data with semantic labels; even if successful, they do not scale well and fail to output high resolution meshes. In this paper we propose a novel method to refine both the geometry and the semantic labeling of a given mesh. We refine the mesh geometry by applying a variational method that optimizes a composite energy made of a state-of-the-art pairwise photo-metric term and a single-view term that models the semantic consistency between the labels of the 3D mesh and those of the segmented images. We also update the semantic labeling through a novel Markov Random Field (MRF) formulation that, together with the classical data and smoothness terms, takes into account class-specific priors estimated directly from the annotated mesh. This is in contrast to state-of-the-art methods that are typically based on handcrafted or learned priors. We are the first, jointly with the very recent and seminal work of [M. Blaha et al arXiv:1706.08336, 2017], to propose the use of semantics inside a mesh refinement framework. Differently from [M. Blaha et al arXiv:1706.08336, 2017], which adopts a more classical pairwise comparison to estimate the flow of the mesh, we apply a single-view comparison between the semantically annotated image and the current 3D mesh labels; this improves the robustness in case of noisy segmentations. version:2
arxiv-1705-06830 | Exploring the structure of a real-time, arbitrary neural artistic stylization network | http://arxiv.org/abs/1705.06830 | id:1705.06830 author:Golnaz Ghiasi, Honglak Lee, Manjunath Kudlur, Vincent Dumoulin, Jonathon Shlens category:cs.CV  published:2017-05-18 summary:In this paper, we present a method which combines the flexibility of the neural algorithm of artistic style with the speed of fast style transfer networks to allow real-time stylization using any content/style image pair. We build upon recent work leveraging conditional instance normalization for multi-style transfer networks by learning to predict the conditional instance normalization parameters directly from a style image. The model is successfully trained on a corpus of roughly 80,000 paintings and is able to generalize to paintings previously unobserved. We demonstrate that the learned embedding space is smooth and contains a rich structure and organizes semantic information associated with paintings in an entirely unsupervised manner. version:2
arxiv-1708-07524 | Supervised Speech Separation Based on Deep Learning: An Overview | http://arxiv.org/abs/1708.07524 | id:1708.07524 author:DeLiang Wang, Jitong Chen category:cs.CL cs.LG cs.NE cs.SD  published:2017-08-24 summary:Speech separation is the task of separating target speech from background interference. Traditionally, speech separation is studied as a signal processing problem. A more recent approach formulates speech separation as a supervised learning problem, where the discriminative patterns of speech, speakers, and background noise are learned from training data. Over the past decade, many supervised separation algorithms have been put forward. In particular, the recent introduction of deep learning to supervised speech separation has dramatically accelerated progress and boosted separation performance. This article provides a comprehensive overview of the research on deep learning based supervised speech separation in the last several years. We first introduce the background of speech separation and the formulation of supervised separation. Then we discuss three main components of supervised separation: learning machines, training targets, and acoustic features. Much of the overview is on separation algorithms where we review monaural methods, including speech enhancement (speech-nonspeech separation), speaker separation (multi-talker separation), and speech dereverberation, as well as multi-microphone techniques. The important issue of generalization, unique to supervised learning, is discussed. This overview provides a historical perspective on how advances are made. In addition, we discuss a number of conceptual issues, including what constitutes the target source. version:1
arxiv-1708-07522 | SPARCNN: SPAtially Related Convolutional Neural Networks | http://arxiv.org/abs/1708.07522 | id:1708.07522 author:JT Turner, Kalyan Moy Gupta, David Aha category:cs.CV  published:2017-08-24 summary:The ability to accurately detect and classify objects at varying pixel sizes in cluttered scenes is crucial to many Navy applications. However, detection performance of existing state-of the-art approaches such as convolutional neural networks (CNNs) degrade and suffer when applied to such cluttered and multi-object detection tasks. We conjecture that spatial relationships between objects in an image could be exploited to significantly improve detection accuracy, an approach that had not yet been considered by any existing techniques (to the best of our knowledge) at the time the research was conducted. We introduce a detection and classification technique called Spatially Related Detection with Convolutional Neural Networks (SPARCNN) that learns and exploits a probabilistic representation of inter-object spatial configurations within images from training sets for more effective region proposals to use with state-of-the-art CNNs. Our empirical evaluation of SPARCNN on the VOC 2007 dataset shows that it increases classification accuracy by 8% when compared to a region proposal technique that does not exploit spatial relations. More importantly, we obtained a higher performance boost of 18.8% when task difficulty in the test set is increased by including highly obscured objects and increased image clutter. version:1
arxiv-1709-05283 | Correlating Satellite Cloud Cover with Sky Cameras | http://arxiv.org/abs/1709.05283 | id:1709.05283 author:Shilpa Manandhar, Soumyabrata Dev, Yee Hui Lee, Yu Song Meng category:cs.CV  published:2017-08-24 summary:The role of clouds is manifold in understanding the various events in the atmosphere, and also in studying the radiative balance of the earth. The conventional manner of such cloud analysis is performed mainly via satellite images. However, because of its low temporal- and spatial- resolutions, ground-based sky cameras are now getting popular. In this paper, we study the relation between the cloud cover obtained from MODIS images, with the coverage obtained from ground-based sky cameras. This will help us to better understand cloud formation in the atmosphere - both from satellite images and ground-based observations. version:1
arxiv-1708-08760 | Study of Clear Sky Models for Singapore | http://arxiv.org/abs/1708.08760 | id:1708.08760 author:Soumyabrata Dev, Shilpa Manandhar, Yee Hui Lee, Stefan Winkler category:physics.ao-ph cs.CV  published:2017-08-24 summary:The estimation of total solar irradiance falling on the earth's surface is important in the field of solar energy generation and forecasting. Several clear-sky solar radiation models have been developed over the last few decades. Most of these models are based on empirical distribution of various geographical parameters; while a few models consider various atmospheric effects in the solar energy estimation. In this paper, we perform a comparative analysis of several popular clear-sky models, in the tropical region of Singapore. This is important in countries like Singapore, where we are primarily focused on reliable and efficient solar energy generation. We analyze and compare three popular clear-sky models that are widely used in the literature. We validate our solar estimation results using actual solar irradiance measurements obtained from collocated weather stations. We finally conclude the most reliable clear sky model for Singapore, based on all clear sky days in a year. version:1
arxiv-1708-08995 | Analyzing Cloud Optical Properties Using Sky Cameras | http://arxiv.org/abs/1708.08995 | id:1708.08995 author:Shilpa Manandhar, Soumyabrata Dev, Yee Hui Lee, Yu Song Meng category:cs.CV physics.ao-ph  published:2017-08-24 summary:Clouds play a significant role in the fluctuation of solar radiation received by the earth's surface. It is important to study the various cloud properties, as it impacts the total solar irradiance falling on the earth's surface. One of such important optical properties of the cloud is the Cloud Optical Thickness (COT). It is defined with the amount of light that can pass through the clouds. The COT values are generally obtained from satellite images. However, satellite images have a low temporal- and spatial- resolutions; and are not suitable for study in applications as solar energy generation and forecasting. Therefore, ground-based sky cameras are now getting popular in such fields. In this paper, we analyze the cloud optical thickness value, from the ground-based sky cameras, and provide future research directions. version:1
arxiv-1708-07485 | Multivariate Dependency Measure based on Copula and Gaussian Kernel | http://arxiv.org/abs/1708.07485 | id:1708.07485 author:Angshuman Roy, Alok Goswami, C. A. Murthy category:math.ST stat.ML stat.TH  published:2017-08-24 summary:We propose a new multivariate dependency measure. It is obtained by considering a Gaussian kernel based distance between the copula transform of the given d-dimensional distribution and the uniform copula and then appropriately normalizing it. The resulting measure is shown to satisfy a number of desirable properties. A nonparametric estimate is proposed for this dependency measure and its properties (finite sample as well as asymptotic) are derived. Some comparative studies of the proposed dependency measure estimate with some widely used dependency measure estimates on artificial datasets are included. A non-parametric test of independence between two or more random variables based on this measure is proposed. A comparison of the proposed test with some existing nonparametric multivariate test for independence is presented. version:1
arxiv-1708-00411 | Depth Super-Resolution Meets Uncalibrated Photometric Stereo | http://arxiv.org/abs/1708.00411 | id:1708.00411 author:Songyou Peng, Bjoern Haefner, Yvain Quéau, Daniel Cremers category:cs.CV  published:2017-08-01 summary:A novel depth super-resolution approach for RGB-D sensors is presented. It disambiguates depth super-resolution through high-resolution photometric clues and, symmetrically, it disambiguates uncalibrated photometric stereo through low-resolution depth cues. To this end, an RGB-D sequence is acquired from the same viewing angle, while illuminating the scene from various uncalibrated directions. This sequence is handled by a variational framework which fits high-resolution shape and reflectance, as well as lighting, to both the low-resolution depth measurements and the high-resolution RGB ones. The key novelty consists in a new PDE-based photometric stereo regularizer which implicitly ensures surface regularity. This allows to carry out depth super-resolution in a purely data-driven manner, without the need for any ad-hoc prior or material calibration. Real-world experiments are carried out using an out-of-the-box RGB-D sensor and a hand-held LED light source. version:2
arxiv-1708-07480 | An Ensemble Classifier for Predicting the Onset of Type II Diabetes | http://arxiv.org/abs/1708.07480 | id:1708.07480 author:John Semerdjian, Spencer Frank category:stat.ML  published:2017-08-24 summary:Prediction of disease onset from patient survey and lifestyle data is quickly becoming an important tool for diagnosing a disease before it progresses. In this study, data from the National Health and Nutrition Examination Survey (NHANES) questionnaire is used to predict the onset of type II diabetes. An ensemble model using the output of five classification algorithms was developed to predict the onset on diabetes based on 16 features. The ensemble model had an AUC of 0.834 indicating high performance. version:1
arxiv-1708-07476 | M2D: Monolog to Dialog Generation for Conversational Story Telling | http://arxiv.org/abs/1708.07476 | id:1708.07476 author:Kevin K. Bowden, Grace I. Lin, Lena I. Reed, Marilyn A. Walker category:cs.CL  published:2017-08-24 summary:Storytelling serves many different social functions, e.g. stories are used to persuade, share troubles, establish shared values, learn social behaviors, and entertain. Moreover, stories are often told conversationally through dialog, and previous work suggests that information provided dialogically is more engaging than when provided in monolog. In this paper, we present algorithms for converting a deep representation of a story into a dialogic storytelling, that can vary aspects of the telling, including the personality of the storytellers. We conduct several experiments to test whether dialogic storytellings are more engaging, and whether automatically generated variants in linguistic form that correspond to personality differences can be recognized in an extended storytelling dialog. version:1
arxiv-1708-07455 | Review on Computer Vision Techniques in Emergency Situation | http://arxiv.org/abs/1708.07455 | id:1708.07455 author:Laura Lopez-Fuentes, Joost van de Weijer, Manuel Gonzalez-Hidalgo, Harald Skinnemoen, Andrew D. Bagdanov category:cs.CV  published:2017-08-24 summary:In emergency situations, actions that save lives and limit the impact of hazards are crucial. In order to act, situational awareness is needed to decide what to do. Geolocalized photos and video of the situations as they evolve can be crucial in better understanding them and making decisions faster. Cameras are almost everywhere these days, either in terms of smartphones, installed CCTV cameras, UAVs or others. However, this poses challenges in big data and information overflow. Moreover, most of the time there are no disasters at any given location, so humans aiming to detect sudden situations may not be as alert as needed at any point in time. Consequently, computer vision tools can be an excellent decision support. The number of emergencies where computer vision tools has been considered or used is very wide, and there is a great overlap across related emergency research. Researchers tend to focus on state-of-the-art systems that cover the same emergency as they are studying, obviating important research in other fields. In order to unveil this overlap, the survey is divided along four main axes: the types of emergencies that have been studied in computer vision, the objective that the algorithms can address, the type of hardware needed and the algorithms used. Therefore, this review provides a broad overview of the progress of computer vision covering all sorts of emergencies. version:1
arxiv-1708-07452 | Automatic Myocardial Segmentation by Using A Deep Learning Network in Cardiac MRI | http://arxiv.org/abs/1708.07452 | id:1708.07452 author:Ariel H. Curiale, Flavio D. Colavecchia, Pablo Kaluza, Roberto A. Isoardi, German Mato category:cs.CV  published:2017-08-24 summary:Cardiac function is of paramount importance for both prognosis and treatment of different pathologies such as mitral regurgitation, ischemia, dyssynchrony and myocarditis. Cardiac behavior is determined by structural and functional features. In both cases, the analysis of medical imaging studies requires to detect and segment the myocardium. Nowadays, magnetic resonance imaging (MRI) is one of the most relevant and accurate non-invasive diagnostic tools for cardiac structure and function. In this work we propose to use a deep learning technique to assist the automatization of myocardial segmentation in cardiac MRI. We present several improvements to previous works in this paper: we propose to use the Jaccard distance as optimization objective function, we integrate a residual learning strategy into the code, and we introduce a batch normalization layer to train the fully convolutional neural network. Our results demonstrate that this architecture outperforms previous approaches based on a similar network architecture, and that provides a suitable approach for myocardial segmentation. Our benchmark shows that the automatic myocardial segmentation takes less than 22 seg. for a volume of 128~x~128~x~13 pixels in a 3.1 GHz intel core i7. version:1
arxiv-1708-07450 | Bayesian Compressive Sensing Using Normal Product Priors | http://arxiv.org/abs/1708.07450 | id:1708.07450 author:Zhou Zhou, Kaihui Liu, Jun Fang category:stat.ML cs.IT cs.LG math.IT  published:2017-08-24 summary:In this paper, we introduce a new sparsity-promoting prior, namely, the "normal product" prior, and develop an efficient algorithm for sparse signal recovery under the Bayesian framework. The normal product distribution is the distribution of a product of two normally distributed variables with zero means and possibly different variances. Like other sparsity-encouraging distributions such as the Student's $t$-distribution, the normal product distribution has a sharp peak at origin, which makes it a suitable prior to encourage sparse solutions. A two-stage normal product-based hierarchical model is proposed. We resort to the variational Bayesian (VB) method to perform the inference. Simulations are conducted to illustrate the effectiveness of our proposed algorithm as compared with other state-of-the-art compressed sensing algorithms. version:1
arxiv-1708-07012 | Variational autoencoders for tissue heterogeneity exploration from (almost) no preprocessed mass spectrometry imaging data | http://arxiv.org/abs/1708.07012 | id:1708.07012 author:Paolo Inglese, James L. Alexander, Anna Mroz, Zoltan Takats, Robert Glen category:q-bio.QM cs.LG stat.ML  published:2017-08-23 summary:The paper presents the application of Variational Autoencoders (VAE) for data dimensionality reduction and explorative analysis of mass spectrometry imaging data (MSI). The results confirm that VAEs are capable of detecting the patterns associated with the different tissue sub-types with performance than standard approaches. version:2
arxiv-1708-07403 | CloudScan - A configuration-free invoice analysis system using recurrent neural networks | http://arxiv.org/abs/1708.07403 | id:1708.07403 author:Rasmus Berg Palm, Ole Winther, Florian Laws category:cs.CL  published:2017-08-24 summary:We present CloudScan; an invoice analysis system that requires zero configuration or upfront annotation. In contrast to previous work, CloudScan does not rely on templates of invoice layout, instead it learns a single global model of invoices that naturally generalizes to unseen invoice layouts. The model is trained using data automatically extracted from end-user provided feedback. This automatic training data extraction removes the requirement for users to annotate the data precisely. We describe a recurrent neural network model that can capture long range context and compare it to a baseline logistic regression model corresponding to the current CloudScan production system. We train and evaluate the system on 8 important fields using a dataset of 326,471 invoices. The recurrent neural network and baseline model achieve 0.891 and 0.887 average F1 scores respectively on seen invoice layouts. For the harder task of unseen invoice layouts, the recurrent neural network model outperforms the baseline with 0.840 average F1 compared to 0.788. version:1
arxiv-1708-07367 | Mixing time estimation in reversible Markov chains from a single sample path | http://arxiv.org/abs/1708.07367 | id:1708.07367 author:Daniel Hsu, Aryeh Kontorovich, David A. Levin, Yuval Peres, Csaba Szepesvári category:math.ST cs.LG math.PR stat.ML stat.TH  published:2017-08-24 summary:The spectral gap $\gamma$ of a finite, ergodic, and reversible Markov chain is an important parameter measuring the asymptotic rate of convergence. In applications, the transition matrix $P$ may be unknown, yet one sample of the chain up to a fixed time $n$ may be observed. We consider here the problem of estimating $\gamma$ from this data. Let $\pi$ be the stationary distribution of $P$, and $\pi_\star = \min_x \pi(x)$. We show that if $n = \tilde{O}\bigl(\frac{1}{\gamma \pi_\star}\bigr)$, then $\gamma$ can be estimated to within multiplicative constants with high probability. When $\pi$ is uniform on $d$ states, this matches (up to logarithmic correction) a lower bound of $\tilde{\Omega}\bigl(\frac{d}{\gamma}\bigr)$ steps required for precise estimation of $\gamma$. Moreover, we provide the first procedure for computing a fully data-dependent interval, from a single finite-length trajectory of the chain, that traps the mixing time $t_{\text{mix}}$ of the chain at a prescribed confidence level. The interval does not require the knowledge of any parameters of the chain. This stands in contrast to previous approaches, which either only provide point estimates, or require a reset mechanism, or additional prior knowledge. The interval is constructed around the relaxation time $t_{\text{relax}} = 1/\gamma$, which is strongly related to the mixing time, and the width of the interval converges to zero roughly at a $1/\sqrt{n}$ rate, where $n$ is the length of the sample path. version:1
arxiv-1708-07755 | Gait Recognition from Motion Capture Data | http://arxiv.org/abs/1708.07755 | id:1708.07755 author:Michal Balazia, Petr Sojka category:cs.CV 68T05  68T10 I.5  published:2017-08-24 summary:Gait recognition from motion capture data, as a pattern classification discipline, can be improved by the use of machine learning. This paper contributes to the state-of-the-art with a statistical approach for extracting robust gait features directly from raw data by a modification of Linear Discriminant Analysis with Maximum Margin Criterion. Experiments on the CMU MoCap database show that the suggested method outperforms thirteen relevant methods based on geometric features and a method to learn the features by a combination of Principal Component Analysis and Linear Discriminant Analysis. The methods are evaluated in terms of the distribution of biometric templates in respective feature spaces expressed in a number of class separability coefficients and classification metrics. Results also indicate a high portability of learned features, that means, we can learn what aspects of walk people generally differ in and extract those as general gait features. Recognizing people without needing group-specific features is convenient as particular people might not always provide annotated learning data. As a contribution to reproducible research, our evaluation framework and database have been made publicly available. This research makes motion capture technology directly applicable for human recognition. version:1
arxiv-1708-07347 | An LSTM-Based Dynamic Customer Model for Fashion Recommendation | http://arxiv.org/abs/1708.07347 | id:1708.07347 author:Sebastian Heinz, Christian Bracher, Roland Vollgraf category:cs.IR cs.LG  published:2017-08-24 summary:Online fashion sales present a challenging use case for personalized recommendation: Stores offer a huge variety of items in multiple sizes. Small stocks, high return rates, seasonality, and changing trends cause continuous turnover of articles for sale on all time scales. Customers tend to shop rarely, but often buy multiple items at once. We report on backtest experiments with sales data of 100k frequent shoppers at Zalando, Europe's leading online fashion platform. To model changing customer and store environments, our recommendation method employs a pair of neural networks: To overcome the cold start problem, a feedforward network generates article embeddings in "fashion space," which serve as input to a recurrent neural network that predicts a style vector in this space for each client, based on their past purchase sequence. We compare our results with a static collaborative filtering approach, and a popularity ranking baseline. version:1
arxiv-1708-07336 | Active Sampling of Pairs and Points for Large-scale Linear Bipartite Ranking | http://arxiv.org/abs/1708.07336 | id:1708.07336 author:Wei-Yuan Shen, Hsuan-Tien Lin category:cs.LG cs.IR  published:2017-08-24 summary:Bipartite ranking is a fundamental ranking problem that learns to order relevant instances ahead of irrelevant ones. The pair-wise approach for bi-partite ranking construct a quadratic number of pairs to solve the problem, which is infeasible for large-scale data sets. The point-wise approach, albeit more efficient, often results in inferior performance. That is, it is difficult to conduct bipartite ranking accurately and efficiently at the same time. In this paper, we develop a novel active sampling scheme within the pair-wise approach to conduct bipartite ranking efficiently. The scheme is inspired from active learning and can reach a competitive ranking performance while focusing only on a small subset of the many pairs during training. Moreover, we propose a general Combined Ranking and Classification (CRC) framework to accurately conduct bipartite ranking. The framework unifies point-wise and pair-wise approaches and is simply based on the idea of treating each instance point as a pseudo-pair. Experiments on 14 real-word large-scale data sets demonstrate that the proposed algorithm of Active Sampling within CRC, when coupled with a linear Support Vector Machine, usually outperforms state-of-the-art point-wise and pair-wise ranking approaches in terms of both accuracy and efficiency. version:1
arxiv-1708-07335 | Relaxed Spatio-Temporal Deep Feature Aggregation for Real-Fake Expression Prediction | http://arxiv.org/abs/1708.07335 | id:1708.07335 author:Savas Ozkan, Gozde Bozdagi Akar category:cs.CV  published:2017-08-24 summary:Frame-level visual features are generally aggregated in time with the techniques such as LSTM, Fisher Vectors, NetVLAD etc. to produce a robust video-level representation. We here introduce a learnable aggregation technique whose primary objective is to retain short-time temporal structure between frame-level features and their spatial interdependencies in the representation. Also, it can be easily adapted to the cases where there have very scarce training samples. We evaluate the method on a real-fake expression prediction dataset to demonstrate its superiority. Our method obtains 65% score on the test dataset in the official MAP evaluation and there is only one misclassified decision with the best reported result in the Chalearn Challenge (i.e. 66:7%) . Lastly, we believe that this method can be extended to different problems such as action/event recognition in future. version:1
arxiv-1708-07311 | Generalized maximum entropy estimation | http://arxiv.org/abs/1708.07311 | id:1708.07311 author:Tobias Sutter, David Sutter, Peyman Mohajerin Esfahani, John Lygeros category:math.OC cs.IT cs.LG math.IT  published:2017-08-24 summary:We consider the problem of estimating a probability distribution that maximizes the entropy while satisfying a finite number of moment constraints, possibly corrupted by noise. Based on duality of convex programming, we present a novel approximation scheme using a smoothed fast gradient method that is equipped with explicit bounds on the approximation error. We further demonstrate how the presented scheme can be used for approximating the chemical master equation through the zero-information moment closure method. version:1
arxiv-1708-07308 | Ease.ml: Towards Multi-tenant Resource Sharing for Machine Learning Workloads | http://arxiv.org/abs/1708.07308 | id:1708.07308 author:Tian Li, Jie Zhong, Ji Liu, Wentao Wu, Ce Zhang category:cs.DB cs.LG stat.ML  published:2017-08-24 summary:We present ease.ml, a declarative machine learning service platform we built to support more than ten research groups outside the computer science departments at ETH Zurich for their machine learning needs. With ease.ml, a user defines the high-level schema of a machine learning application and submits the task via a Web interface. The system automatically deals with the rest, such as model selection and data movement. In this paper, we describe the ease.ml architecture and focus on a novel technical problem introduced by ease.ml regarding resource allocation. We ask, as a "service provider" that manages a shared cluster of machines among all our users running machine learning workloads, what is the resource allocation strategy that maximizes the global satisfaction of all our users? Resource allocation is a critical yet subtle issue in this multi-tenant scenario, as we have to balance between efficiency and fairness. We first formalize the problem that we call multi-tenant model selection, aiming for minimizing the total regret of all users running automatic model selection tasks. We then develop a novel algorithm that combines multi-armed bandits with Bayesian optimization and prove a regret bound under the multi-tenant setting. Finally, we report our evaluation of ease.ml on synthetic data and on one service we are providing to our users, namely, image classification with deep neural networks. Our experimental evaluation results show that our proposed solution can be up to 9.8x faster in achieving the same global quality for all users as the two popular heuristics used by our users before ease.ml. version:1
arxiv-1708-07281 | Recent Advances in the Applications of Convolutional Neural Networks to Medical Image Contour Detection | http://arxiv.org/abs/1708.07281 | id:1708.07281 author:Zizhao Zhang, Fuyong Xing, Hai Su, Xiaoshuang Shi, Lin Yang category:cs.CV  published:2017-08-24 summary:The fast growing deep learning technologies have become the main solution of many machine learning problems for medical image analysis. Deep convolution neural networks (CNNs), as one of the most important branch of the deep learning family, have been widely investigated for various computer-aided diagnosis tasks including long-term problems and continuously emerging new problems. Image contour detection is a fundamental but challenging task that has been studied for more than four decades. Recently, we have witnessed the significantly improved performance of contour detection thanks to the development of CNNs. Beyond purusing performance in existing natural image benchmarks, contour detection plays a particularly important role in medical image analysis. Segmenting various objects from radiology images or pathology images requires accurate detection of contours. However, some problems, such as discontinuity and shape constraints, are insufficiently studied in CNNs. It is necessary to clarify the challenges to encourage further exploration. The performance of CNN based contour detection relies on the state-of-the-art CNN architectures. Careful investigation of their design principles and motivations is critical and beneficial to contour detection. In this paper, we first review recent development of medical image contour detection and point out the current confronting challenges and problems. We discuss the development of general CNNs and their applications in image contours (or edges) detection. We compare those methods in detail, clarify their strengthens and weaknesses. Then we review their recent applications in medical image analysis and point out limitations, with the goal to light some potential directions in medical image analysis. We expect the paper to cover comprehensive technical ingredients of advanced CNNs to enrich the study in the medical image domain. version:1
arxiv-1708-07279 | Combining Discrete and Neural Features for Sequence Labeling | http://arxiv.org/abs/1708.07279 | id:1708.07279 author:Jie Yang, Zhiyang Teng, Meishan Zhang, Yue Zhang category:cs.CL  published:2017-08-24 summary:Neural network models have recently received heated research attention in the natural language processing community. Compared with traditional models with discrete features, neural models have two main advantages. First, they take low-dimensional, real-valued embedding vectors as inputs, which can be trained over large raw data, thereby addressing the issue of feature sparsity in discrete models. Second, deep neural networks can be used to automatically combine input features, and including non-local features that capture semantic patterns that cannot be expressed using discrete indicator features. As a result, neural network models have achieved competitive accuracies compared with the best discrete models for a range of NLP tasks. On the other hand, manual feature templates have been carefully investigated for most NLP tasks over decades and typically cover the most useful indicator pattern for solving the problems. Such information can be complementary the features automatically induced from neural networks, and therefore combining discrete and neural features can potentially lead to better accuracy compared with models that leverage discrete or neural features only. In this paper, we systematically investigate the effect of discrete and neural feature combination for a range of fundamental NLP tasks based on sequence labeling, including word segmentation, POS tagging and named entity recognition for Chinese and English, respectively. Our results on standard benchmarks show that state-of-the-art neural models can give accuracies comparable to the best discrete models in the literature for most tasks and combing discrete and neural features unanimously yield better results. version:1
arxiv-1708-06616 | Contrast and visual saliency similarity induced index for image quality assessment | http://arxiv.org/abs/1708.06616 | id:1708.06616 author:Huizhen Jia, Tonghan Wang category:cs.CV  published:2017-08-22 summary:Perceptual image quality assessment (IQA) defines/utilizes a computational model to assess the image quality in consistent with human opinions. A good IQA model should consider both the effectiveness and efficiency, while most previous IQA models are hard to reach simultaneously. So we attempt to make another effort to develop an effective and efficiency image quality assessment metric. Considering that contrast is a distinctive visual attribute that indicates the quality of an image, and visual saliency (VS) attracts the most attention of the human visual system, the proposed model utilized these two features to characterize the image local quality. After obtaining the local contrast quality map and global visual saliency quality map, we add the weighted standard deviation of the previous two quality maps together to yield the final quality score. The experimental results on three benchmark database (LIVE, TID2008, CSIQ) showed that the proposed model yields the best performance in terms of the correlation with human judgments of visual quality. Furthermore, it is more efficient when compared with other competing IQA models. version:2
arxiv-1708-07265 | An Image Analysis Approach to the Calligraphy of Books | http://arxiv.org/abs/1708.07265 | id:1708.07265 author:Henrique F. de Arruda, Vanessa Q. Marinho, Thales S. Lima, Diego R. Amancio, Luciano da F. Costa category:cs.CL cs.CV  published:2017-08-24 summary:Text network analysis has received increasing attention as a consequence of its wide range of applications. In this work, we extend a previous work founded on the study of topological features of mesoscopic networks. Here, the geometrical properties of visualized networks are quantified in terms of several image analysis techniques and used as subsidies for authorship attribution. It was found that the visual features account for performance similar to that achieved by using topological measurements. In addition, the combination of these two types of features improved the performance. version:1
arxiv-1708-07259 | Dynamic Tensor Clustering | http://arxiv.org/abs/1708.07259 | id:1708.07259 author:Will Wei Sun, Lexin Li category:stat.ML math.ST stat.TH  published:2017-08-24 summary:Dynamic tensor data are becoming prevalent in numerous applications. Existing tensor clustering methods either fail to account for the dynamic nature of the data, or are inapplicable to a general-order tensor. Also there is often a gap between statistical guarantee and computational efficiency for existing tensor clustering solutions. In this article, we aim to bridge this gap by proposing a new dynamic tensor clustering method, which takes into account both sparsity and fusion structures, and enjoys strong statistical guarantees as well as high computational efficiency. Our proposal is based upon a new structured tensor factorization that encourages both sparsity and smoothness in parameters along the specified tensor modes. Computationally, we develop a highly efficient optimization algorithm that benefits from substantial dimension reduction. In theory, we first establish a non-asymptotic error bound for the estimator from the structured tensor factorization. Built upon this error bound, we then derive the rate of convergence of the estimated cluster centers, and show that the estimated clusters recover the true cluster structures with a high probability. Moreover, our proposed method can be naturally extended to co-clustering of multiple modes of the tensor data. The efficacy of our approach is illustrated via simulations and a brain dynamic functional connectivity analysis from an Autism spectrum disorder study. version:1
arxiv-1708-05127 | Deep Binary Reconstruction for Cross-modal Hashing | http://arxiv.org/abs/1708.05127 | id:1708.05127 author:Xuelong Li, Di Hu, Feiping Nie category:cs.CV cs.MM  published:2017-08-17 summary:With the increasing demand of massive multimodal data storage and organization, cross-modal retrieval based on hashing technique has drawn much attention nowadays. It takes the binary codes of one modality as the query to retrieve the relevant hashing codes of another modality. However, the existing binary constraint makes it difficult to find the optimal cross-modal hashing function. Most approaches choose to relax the constraint and perform thresholding strategy on the real-value representation instead of directly solving the original objective. In this paper, we first provide a concrete analysis about the effectiveness of multimodal networks in preserving the inter- and intra-modal consistency. Based on the analysis, we provide a so-called Deep Binary Reconstruction (DBRC) network that can directly learn the binary hashing codes in an unsupervised fashion. The superiority comes from a proposed simple but efficient activation function, named as Adaptive Tanh (ATanh). The ATanh function can adaptively learn the binary codes and be trained via back-propagation. Extensive experiments on three benchmark datasets demonstrate that DBRC outperforms several state-of-the-art methods in both image2text and text2image retrieval task. version:2
arxiv-1708-07242 | GALILEO: A Generalized Low-Entropy Mixture Model | http://arxiv.org/abs/1708.07242 | id:1708.07242 author:Cetin Savkli, Jeffrey Lin, Philip Graff, Matthew Kinsey category:stat.ML cs.DS cs.LG math.PR  published:2017-08-24 summary:We present a new method of generating mixture models for data with categorical attributes. The keys to this approach are an entropy-based density metric in categorical space and annealing of high-entropy/low-density components from an initial state with many components. Pruning of low-density components using the entropy-based density allows GALILEO to consistently find high-quality clusters and the same optimal number of clusters. GALILEO has shown promising results on a range of test datasets commonly used for categorical clustering benchmarks. We demonstrate that the scaling of GALILEO is linear in the number of records in the dataset, making this method suitable for very large categorical datasets. version:1
arxiv-1708-07227 | Proportionate gradient updates with PercentDelta | http://arxiv.org/abs/1708.07227 | id:1708.07227 author:Sami Abu-El-Haija category:cs.LG  published:2017-08-24 summary:Deep Neural Networks are generally trained using iterative gradient updates. Magnitudes of gradients are affected by many factors, including choice of activation functions and initialization. More importantly, gradient magnitudes can greatly differ across layers, with some layers receiving much smaller gradients than others. causing some layers to train slower than others and therefore slowing down the overall convergence. We analytically explain this disproportionality. Then we propose to explicitly train all layers at the same speed, by scaling the gradient w.r.t. every trainable tensor to be proportional to its current value. In particular, at every batch, we want to update all trainable tensors, such that the relative change of the L1-norm of the tensors is the same, across all layers of the network, throughout training time. Experiments on MNIST show that our method appropriately scales gradients, such that the relative change in trainable tensors is approximately equal across layers. In addition, measuring the test accuracy with training time, shows that our method trains faster than other methods, giving higher test accuracy given same budget of training steps. version:1
arxiv-1705-00607 | Determinantal Point Processes for Mini-Batch Diversification | http://arxiv.org/abs/1705.00607 | id:1705.00607 author:Cheng Zhang, Hedvig Kjellstrom, Stephan Mandt category:cs.LG stat.ML  published:2017-05-01 summary:We study a mini-batch diversification scheme for stochastic gradient descent (SGD). While classical SGD relies on uniformly sampling data points to form a mini-batch, we propose a non-uniform sampling scheme based on the Determinantal Point Process (DPP). The DPP relies on a similarity measure between data points and gives low probabilities to mini-batches which contain redundant data, and higher probabilities to mini-batches with more diverse data. This simultaneously balances the data and leads to stochastic gradients with lower variance. We term this approach Diversified Mini-Batch SGD (DM-SGD). We show that regular SGD and a biased version of stratified sampling emerge as special cases. Furthermore, DM-SGD generalizes stratified sampling to cases where no discrete features exist to bin the data into groups. We show experimentally that our method results more interpretable and diverse features in unsupervised setups, and in better classification accuracies in supervised setups. version:2
arxiv-1708-07199 | 3D Morphable Models as Spatial Transformer Networks | http://arxiv.org/abs/1708.07199 | id:1708.07199 author:Anil Bas, Patrik Huber, William A. P. Smith, Muhammad Awais, Josef Kittler category:cs.CV 68T45 I.4.8; I.2.10  published:2017-08-23 summary:In this paper, we show how a 3D Morphable Model (i.e. a statistical model of the 3D shape of a class of objects such as faces) can be used to spatially transform input data as a module (a 3DMM-STN) within a convolutional neural network. This is an extension of the original spatial transformer network in that we are able to interpret and normalise 3D pose changes and self-occlusions. The trained localisation part of the network is independently useful since it learns to fit a 3D morphable model to a single image. We show that the localiser can be trained using only simple geometric loss functions on a relatively small dataset yet is able to perform robust normalisation on highly uncontrolled images including occlusion, self-occlusion and large pose changes. version:1
arxiv-1708-07193 | Applications of Trajectory Data in Transportation: Literature Review and Maryland Case Study | http://arxiv.org/abs/1708.07193 | id:1708.07193 author:Nikola Marković, Przemysław Sekuła, Zachary Vander Laan, Gennady Andrienko, Natalia Andrienko category:stat.ML cs.CY  published:2017-08-23 summary:This paper considers applications of trajectory data in transportation, and makes two primary contributions. First, it provides a comprehensive literature review detailing ways in which trajectory data has been used for transportation systems analysis, distilling existing research into the following six areas: demand estimation, modeling human behavior, designing public transit, measuring and predicting traffic performance, quantifying environmental impact, and safety analysis. Additionally, it presents innovative applications of trajectory data for the state of Maryland, employing visualization and machine learning techniques to extract value from 20 million GPS traces. These visual analytics will be implemented in the Regional Integrated Transportation Information System (RITIS), which provides free data sharing and visual analytics tools to help transportation agencies attain situational awareness, evaluate performance, and share insights with the public. version:1
arxiv-1708-07178 | Massively-Parallel Feature Selection for Big Data | http://arxiv.org/abs/1708.07178 | id:1708.07178 author:Ioannis Tsamardinos, Giorgos Borboudakis, Pavlos Katsogridakis, Polyvios Pratikakis, Vassilis Christophides category:cs.LG stat.ML  published:2017-08-23 summary:We present the Parallel, Forward-Backward with Pruning (PFBP) algorithm for feature selection (FS) in Big Data settings (high dimensionality and/or sample size). To tackle the challenges of Big Data FS PFBP partitions the data matrix both in terms of rows (samples, training examples) as well as columns (features). By employing the concepts of $p$-values of conditional independence tests and meta-analysis techniques PFBP manages to rely only on computations local to a partition while minimizing communication costs. Then, it employs powerful and safe (asymptotically sound) heuristics to make early, approximate decisions, such as Early Dropping of features from consideration in subsequent iterations, Early Stopping of consideration of features within the same iteration, or Early Return of the winner in each iteration. PFBP provides asymptotic guarantees of optimality for data distributions faithfully representable by a causal network (Bayesian network or maximal ancestral graph). Our empirical analysis confirms a super-linear speedup of the algorithm with increasing sample size, linear scalability with respect to the number of features and processing cores, while dominating other competitive algorithms in its class. version:1
arxiv-1708-07147 | Classification via Tensor Decompositions of Echo State Networks | http://arxiv.org/abs/1708.07147 | id:1708.07147 author:Ashley Prater category:cs.LG cs.NE stat.ML  published:2017-08-23 summary:This work introduces a tensor-based method to perform supervised classification on spatiotemporal data processed in an echo state network. Typically when performing supervised classification tasks on data processed in an echo state network, the entire collection of hidden layer node states from the training dataset is shaped into a matrix, allowing one to use standard linear algebra techniques to train the output layer. However, the collection of hidden layer states is multidimensional in nature, and representing it as a matrix may lead to undesirable numerical conditions or loss of spatial and temporal correlations in the data. This work proposes a tensor-based supervised classification method on echo state network data that preserves and exploits the multidimensional nature of the hidden layer states. The method, which is based on orthogonal Tucker decompositions of tensors, is compared with the standard linear output weight approach in several numerical experiments on both synthetic and natural data. The results show that the tensor-based approach tends to outperform the standard approach in terms of classification accuracy. version:1
arxiv-1708-07120 | Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates | http://arxiv.org/abs/1708.07120 | id:1708.07120 author:Leslie N. Smith, Nicholay Topin category:cs.LG cs.CV cs.NE stat.ML  published:2017-08-23 summary:In this paper, we show a phenomenon where residual networks can be trained using an order of magnitude fewer iterations than is used with standard training methods, which we named "super-convergence". One of the key elements of super-convergence is training with cyclical learning rates and a large maximum learning rate. Furthermore, we present evidence that training with large learning rates improves performance by regularizing the network. In addition, we show that super-convergence provides a greater boost in performance relative to standard training when the amount of labeled training data is limited. We also provide an explanation for the benefits of a large learning rate using a simplification of the Hessian Free optimization method to compute an estimate of the optimal learning rate. The architectures and code to replicate the figures in this paper are available at github.com/lnsmith54/super-convergence. version:1
arxiv-1708-07104 | Automatic Detection of Fake News | http://arxiv.org/abs/1708.07104 | id:1708.07104 author:Verónica Pérez-Rosas, Bennett Kleinberg, Alexandra Lefevre, Rada Mihalcea category:cs.CL  published:2017-08-23 summary:The proliferation of misleading information in everyday access media outlets such as social media feeds, news blogs, and online newspapers have made it challenging to identify trustworthy news sources, thus increasing the need for computational tools able to provide insights into the reliability of online content. In this paper, we focus on the automatic identification of fake content in online news. Our contribution is twofold. First, we introduce two novel datasets for the task of fake news detection, covering seven different news domains. We describe the collection, annotation, and validation process in detail and present several exploratory analysis on the identification of linguistic differences in fake and legitimate news content. Second, we conduct a set of learning experiments to build accurate fake news detectors. In addition, we provide comparative analyses of the automatic and manual identification of fake news. version:1
arxiv-1708-07089 | Predicting Aesthetic Score Distribution through Cumulative Jensen-Shannon Divergence | http://arxiv.org/abs/1708.07089 | id:1708.07089 author:Xin Jin, Le Wu, Chenggen Song, Xiaodong Li, Geng Zhao, Siyu Chen, Jingying Chi, Siwei Peng, Shiming Ge category:cs.CV  published:2017-08-23 summary:Aesthetic quality prediction is a challenging task in the computer vision community because of the complex interplay with semantic contents and photographic technologies. Recent studies on the powerful deep learning based aesthetic quality assessment usually use a binary high-low label or a numerical score to represent the aesthetic quality. However the scalar representation cannot describe well the underlying varieties of the human perception of aesthetics. In this work, we propose to predict the aesthetic score distribution (i.e., a score distribution vector of the ordinal basic human ratings) using Deep Convolutional Neural Network (DCNN). Conventional DCNNs which aim to minimize the difference between the predicted scalar numbers or vectors and the ground truth cannot be directly used for the ordinal basic rating distribution. Thus, a novel CNN based on the Cumulative distribution with Jensen-Shannon divergence (CJS-CNN) is presented to predict the aesthetic score distribution of human ratings, with a new reliability-sensitive learning method based on the kurtosis of the score distribution. Experimental results on large scale aesthetic dataset demonstrate the effectiveness of our introduced CJS-CNN in this task. In addition, by recasting the predicted score histogram to a binary score using the mean value and a relative small scale CNN, the proposed method outperforms the state-of-the-art methods on aesthetic image classification. version:1
arxiv-1707-03360 | Multiscale dictionary of rat locomotion | http://arxiv.org/abs/1707.03360 | id:1707.03360 author:Haozhe Shan, Peggy Mason category:q-bio.QM stat.ML  published:2017-07-11 summary:To effectively connect animal behaviors to activities and patterns in the nervous system, it is ideal have a precise, accurate, and complete description of stereotyped modules and their dynamics in behaviors. In case of rodent behaviors, observers have identified and described several stereotyped behaviors, such as grooming and lateral threat. Discovering behavioral repertoires in this way is imprecise, slow and contaminated with biases and individual differences. As a replacement, we propose a framework for unbiased, efficient and precise investigation of rat locomotor activities. We propose that locomotion possesses multiscale dynamics that can be well approximated by multiple Markov processes running in parallel at different spatial-temporal scales. To capture motifs and transition dynamics on multiple scales, we developed a segmentation-decomposition procedure, which imposes explicit constraints on timescales on parallel Hidden Markov Models (HMM). Each HMM describes the motifs and transition dynamics at its respective timescale. We showed that the motifs discovered across timescales have experimental significance and space-dependent heterogeneity. Through statistical tests, we show that locomotor dynamics largely conforms with Markov property across scales. Finally, using layered HMMs, we showed that motif assembly is strongly constrained to a few fixed sequences. The motifs potentially reflect outputs of canonical underlying behavioral output motifs. Our approach and results for the first time capture behavioral dynamics at different spatial-temporal scales, painting a more complete picture of how behaviors are organized. version:2
arxiv-1707-08819 | A Downsampled Variant of ImageNet as an Alternative to the CIFAR datasets | http://arxiv.org/abs/1707.08819 | id:1707.08819 author:Patryk Chrabaszcz, Ilya Loshchilov, Frank Hutter category:cs.CV cs.LG  published:2017-07-27 summary:The original ImageNet dataset is a popular large-scale benchmark for training Deep Neural Networks. Since the cost of performing experiments (e.g, algorithm design, architecture search, and hyperparameter tuning) on the original dataset might be prohibitive, we propose to consider a downsampled version of ImageNet. In contrast to the CIFAR datasets and earlier downsampled versions of ImageNet, our proposed ImageNet32$\times$32 (and its variants ImageNet64$\times$64 and ImageNet16$\times$16) contains exactly the same number of classes and images as ImageNet, with the only difference that the images are downsampled to 32$\times$32 pixels per image (64$\times$64 and 16$\times$16 pixels for the variants, respectively). Experiments on these downsampled variants are dramatically faster than on the original ImageNet and the characteristics of the downsampled datasets with respect to optimal hyperparameters appear to remain similar. The proposed datasets and scripts to reproduce our results are available at http://image-net.org/download-images and https://github.com/PatrykChrabaszcz/Imagenet32_Scripts version:3
arxiv-1708-07066 | Single Reference Image based Scene Relighting via Material Guided Filtering | http://arxiv.org/abs/1708.07066 | id:1708.07066 author:Xin Jin, Yannan Li, Ningning Liu, Xiaodong Li, Xianggang Jiang, Chaoen Xiao, Shiming Ge category:cs.CV  published:2017-08-23 summary:Image relighting is to change the illumination of an image to a target illumination effect without known the original scene geometry, material information and illumination condition. We propose a novel outdoor scene relighting method, which needs only a single reference image and is based on material constrained layer decomposition. Firstly, the material map is extracted from the input image. Then, the reference image is warped to the input image through patch match based image warping. Lastly, the input image is relit using material constrained layer decomposition. The experimental results reveal that our method can produce similar illumination effect as that of the reference image on the input image using only a single reference image. version:1
arxiv-1708-07042 | Scale-invariant unconstrained online learning | http://arxiv.org/abs/1708.07042 | id:1708.07042 author:Wojciech Kotłowski category:cs.LG stat.ML  published:2017-08-23 summary:We consider a variant of online convex optimization in which both the instances (input vectors) and the comparator (weight vector) are unconstrained. We exploit a natural scale invariance symmetry in our unconstrained setting: the predictions of the optimal comparator are invariant under any linear transformation of the instances. Our goal is to design online algorithms which also enjoy this property, i.e. are scale-invariant. We start with the case of coordinate-wise invariance, in which the individual coordinates (features) can be arbitrarily rescaled. We give an algorithm, which achieves essentially optimal regret bound in this setup, expressed by means of a coordinate-wise scale-invariant norm of the comparator. We then study general invariance with respect to arbitrary linear transformations. We first give a negative result, showing that no algorithm can achieve a meaningful bound in terms of scale-invariant norm of the comparator in the worst case. Next, we compliment this result with a positive one, providing an algorithm which "almost" achieves the desired bound, incurring only a logarithmic overhead in terms of the norm of the instances. version:1
arxiv-1708-07034 | Application of a Convolutional Neural Network for image classification to the analysis of collisions in High Energy Physics | http://arxiv.org/abs/1708.07034 | id:1708.07034 author:Celia Fernández Madrazo, Ignacio Heredia Cacha, Lara Lloret Iglesias, Jesús Marco de Lucas category:cs.CV hep-ex  published:2017-08-23 summary:The application of deep learning techniques using convolutional neural networks to the classification of particle collisions in High Energy Physics is explored. An intuitive approach to transform physical variables, like momenta of particles and jets, into a single image that captures the relevant information, is proposed. The idea is tested using a well known deep learning framework on a simulation dataset, including leptonic ttbar events and the corresponding background at 7 TeV from the CMS experiment at LHC, available as Open Data. This initial test shows competitive results when compared to more classical approaches, like those using feedforward neural networks. version:1
arxiv-1708-07025 | Bayesian Learning of Clique Tree Structure | http://arxiv.org/abs/1708.07025 | id:1708.07025 author:Cetin Savkli, J. Ryan Carr, Philip Graff, Lauren Kennell category:cs.LG math.PR stat.ML  published:2017-08-23 summary:The problem of categorical data analysis in high dimensions is considered. A discussion of the fundamental difficulties of probability modeling is provided, and a solution to the derivation of high dimensional probability distributions based on Bayesian learning of clique tree decomposition is presented. The main contributions of this paper are an automated determination of the optimal clique tree structure for probability modeling, the resulting derived probability distribution, and a corresponding unified approach to clustering and anomaly detection based on the probability distribution. version:1
arxiv-1708-07023 | CNN-Based Prediction of Frame-Level Shot Importance for Video Summarization | http://arxiv.org/abs/1708.07023 | id:1708.07023 author:Mohaiminul Al Nahian, A. S. M. Iftekhar, Mohammad Tariqul Islam, S. M. Mahbubur Rahman, Dimitrios Hatzinakos category:cs.CV  published:2017-08-23 summary:In the Internet, ubiquitous presence of redundant, unedited, raw videos has made video summarization an important problem. Traditional methods of video summarization employ a heuristic set of hand-crafted features, which in many cases fail to capture subtle abstraction of a scene. This paper presents a deep learning method that maps the context of a video to the importance of a scene similar to that is perceived by humans. In particular, a convolutional neural network (CNN)-based architecture is proposed to mimic the frame-level shot importance for user-oriented video summarization. The weights and biases of the CNN are trained extensively through off-line processing, so that it can provide the importance of a frame of an unseen video almost instantaneously. Experiments on estimating the shot importance is carried out using the publicly available database TVSum50. It is shown that the performance of the proposed network is substantially better than that of commonly referred feature-based methods for estimating the shot importance in terms of mean absolute error, absolute error variance, and relative F-measure. version:1
arxiv-1708-07021 | Statistical Selection of CNN-Based Audiovisual Features for Instantaneous Estimation of Human Emotional States | http://arxiv.org/abs/1708.07021 | id:1708.07021 author:Ramesh Basnet, Mohammad Tariqul Islam, Tamanna Howlader, S. M. Mahbubur Rahman, Dimitrios Hatzinakos category:cs.CV  published:2017-08-23 summary:Automatic prediction of continuous-level emotional state requires selection of suitable affective features to develop a regression system based on supervised machine learning. This paper investigates the performance of features statistically learned using convolutional neural networks for instantaneously predicting the continuous dimensions of emotional states. Features with minimum redundancy and maximum relevancy are chosen by using the mutual information-based selection process. The performance of frame-by-frame prediction of emotional state using the moderate length features as proposed in this paper is evaluated on spontaneous and naturalistic human-human conversation of RECOLA database. Experimental results show that the proposed model can be used for instantaneous prediction of emotional state with an accuracy higher than traditional audio or video features that are used for affective computation. version:1
arxiv-1708-06997 | The Unconstrained Ear Recognition Challenge | http://arxiv.org/abs/1708.06997 | id:1708.06997 author:Žiga Emeršič, Dejan Štepec, Vitomir Štruc, Peter Peer, Anjith George, Adil Ahmad, Elshibani Omar, Terrance E. Boult, Reza Safdari, Yuxiang Zhou, Stefanos Zafeiriou, Dogucan Yaman, Fevziye I. Eyiokur, Hazim K. Ekenel category:cs.CV  published:2017-08-23 summary:In this paper we present the results of the Unconstrained Ear Recognition Challenge (UERC), a group benchmarking effort centered around the problem of person recognition from ear images captured in uncontrolled conditions. The goal of the challenge was to assess the performance of existing ear recognition techniques on a challenging large-scale dataset and identify open problems that need to be addressed in the future. Five groups from three continents participated in the challenge and contributed six ear recognition techniques for the evaluation, while multiple baselines were made available for the challenge by the UERC organizers. A comprehensive analysis was conducted with all participating approaches addressing essential research questions pertaining to the sensitivity of the technology to head rotation, flipping, gallery size, large-scale recognition and others. The top performer of the UERC was found to ensure robust performance on a smaller part of the dataset (with 180 subjects) regardless of image characteristics, but still exhibited a significant performance drop when the entire dataset comprising 3,704 subjects was used for testing. version:1
arxiv-1708-06977 | Incremental Learning of Object Detectors without Catastrophic Forgetting | http://arxiv.org/abs/1708.06977 | id:1708.06977 author:Konstantin Shmelkov, Cordelia Schmid, Karteek Alahari category:cs.CV  published:2017-08-23 summary:Despite their success for object detection, convolutional neural networks are ill-equipped for incremental learning, i.e., adapting the original model trained on a set of classes to additionally detect objects of new classes, in the absence of the initial training data. They suffer from "catastrophic forgetting" - an abrupt degradation of performance on the original set of classes, when the training objective is adapted to the new classes. We present a method to address this issue, and learn object detectors incrementally, when neither the original training data nor annotations for the original classes in the new training set are available. The core of our proposed solution is a loss function to balance the interplay between predictions on the new classes and a new distillation loss which minimizes the discrepancy between responses for old classes from the original and the updated networks. This incremental learning can be performed multiple times, for a new set of classes in each step, with a moderate drop in performance compared to the baseline network trained on the ensemble of data. We present object detection results on the PASCAL VOC 2007 and COCO datasets, along with a detailed empirical analysis of the approach. version:1
arxiv-1708-08992 | A simple expression for the map of Asplund's distances with the multiplicative Logarithmic Image Processing (LIP) law | http://arxiv.org/abs/1708.08992 | id:1708.08992 author:Guillaume Noyel, Michel Jourlin category:cs.CV  published:2017-08-23 summary:We introduce a simple expression for the map of Asplund's distances with the multiplicative Logarithmic Image Processing (LIP) law. It is a difference between a morphological dilation and a morphological erosion with an additive structuring function which corresponds to a morphological gradient. version:1
arxiv-1708-06973 | Exploiting Convolution Filter Patterns for Transfer Learning | http://arxiv.org/abs/1708.06973 | id:1708.06973 author:Mehmet Aygün, Yusuf Aytar, Hazım Kemal Ekenel category:cs.CV  published:2017-08-23 summary:In this paper, we introduce a new regularization technique for transfer learning. The aim of the proposed approach is to capture statistical relationships among convolution filters learned from a well-trained network and transfer this knowledge to another network. Since convolution filters of the prevalent deep Convolutional Neural Network (CNN) models share a number of similar patterns, in order to speed up the learning procedure, we capture such correlations by Gaussian Mixture Models (GMMs) and transfer them using a regularization term. We have conducted extensive experiments on the CIFAR10, Places2, and CMPlaces datasets to assess generalizability, task transferability, and cross-model transferability of the proposed approach, respectively. The experimental results show that the feature representations have efficiently been learned and transferred through the proposed statistical regularization scheme. Moreover, our method is an architecture independent approach, which is applicable for a variety of CNN architectures. version:1
arxiv-1708-06966 | In search of inliers: 3d correspondence by local and global voting | http://arxiv.org/abs/1708.06966 | id:1708.06966 author:Anders Glent Buch, Yang Yang, Norbert Krüger, Henrik Gordon Petersen category:cs.CV  published:2017-08-23 summary:We present a method for finding correspondence between 3D models. From an initial set of feature correspondences, our method uses a fast voting scheme to separate the inliers from the outliers. The novelty of our method lies in the use of a combination of local and global constraints to determine if a vote should be cast. On a local scale, we use simple, low-level geometric invariants. On a global scale, we apply covariant constraints for finding compatible correspondences. We guide the sampling for collecting voters by downward dependencies on previous voting stages. All of this together results in an accurate matching procedure. We evaluate our algorithm by controlled and comparative testing on different datasets, giving superior performance compared to state of the art methods. In a final experiment, we apply our method for 3D object detection, showing potential use of our method within higher-level vision. version:1
arxiv-1708-06963 | Pose Estimation using Local Structure-Specific Shape and Appearance Context | http://arxiv.org/abs/1708.06963 | id:1708.06963 author:Anders Glent Buch, Dirk Kraft, Joni-Kristian Kamarainen, Henrik Gordon Petersen, Norbert Krüger category:cs.CV  published:2017-08-23 summary:We address the problem of estimating the alignment pose between two models using structure-specific local descriptors. Our descriptors are generated using a combination of 2D image data and 3D contextual shape data, resulting in a set of semi-local descriptors containing rich appearance and shape information for both edge and texture structures. This is achieved by defining feature space relations which describe the neighborhood of a descriptor. By quantitative evaluations, we show that our descriptors provide high discriminative power compared to state of the art approaches. In addition, we show how to utilize this for the estimation of the alignment pose between two point sets. We present experiments both in controlled and real-life scenarios to validate our approach. version:1
arxiv-1708-06935 | Hierarchical Multinomial-Dirichlet model for the estimation of conditional probability tables | http://arxiv.org/abs/1708.06935 | id:1708.06935 author:L. Azzimonti, G. Corani, M. Zaffalon category:stat.ML  published:2017-08-23 summary:We present a novel approach for estimating conditional probability tables, based on a joint, rather than independent, estimate of the conditional distributions belonging to the same table. We derive exact analytical expressions for the estimators and we analyse their properties both analytically and via simulation. We then apply this method to the estimation of parameters in a Bayesian network. Given the structure of the network, the proposed approach better estimates the joint distribution and significantly improves the classification performance with respect to traditional approaches. version:1
arxiv-1708-09461 | A Type II Fuzzy Entropy Based Multi-Level Image Thresholding Using Adaptive Plant Propagation Algorithm | http://arxiv.org/abs/1708.09461 | id:1708.09461 author:Sayan Nag category:cs.CV math.OC physics.data-an stat.CO  published:2017-08-23 summary:One of the most straightforward, direct and efficient approaches to Image Segmentation is Image Thresholding. Multi-level Image Thresholding is an essential viewpoint in many image processing and Pattern Recognition based real-time applications which can effectively and efficiently classify the pixels into various groups denoting multiple regions in an Image. Thresholding based Image Segmentation using fuzzy entropy combined with intelligent optimization approaches are commonly used direct methods to properly identify the thresholds so that they can be used to segment an Image accurately. In this paper a novel approach for multi-level image thresholding is proposed using Type II Fuzzy sets combined with Adaptive Plant Propagation Algorithm (APPA). Obtaining the optimal thresholds for an image by maximizing the entropy is extremely tedious and time consuming with increase in the number of thresholds. Hence, Adaptive Plant Propagation Algorithm (APPA), a memetic algorithm based on plant intelligence, is used for fast and efficient selection of optimal thresholds. This fact is reasonably justified by comparing the accuracy of the outcomes and computational time consumed by other modern state-of-the-art algorithms such as Particle Swarm Optimization (PSO), Gravitational Search Algorithm (GSA) and Genetic Algorithm (GA). version:1
arxiv-1708-06899 | Human experts vs. machines in taxa recognition | http://arxiv.org/abs/1708.06899 | id:1708.06899 author:Johanna Ärje, Ville Tirronen, Salme Kärkkäinen, Kristian Meissner, Jenni Raitoharju, Moncef Gabbouj, Serkan Kiranyaz category:stat.ML cs.LG q-bio.QM  published:2017-08-23 summary:Biomonitoring of waterbodies is vital as the number of anthropogenic stressors on aquatic ecosystems keeps growing. However, the continuous decrease in funding makes it impossible to meet monitoring goals or sustain traditional manual sample processing. In this paper, we review what kind of statistical tools can be used to enhance the cost efficiency of biomonitoring: We explore automated identification of freshwater macroinvertebrates which are used as one indicator group in biomonitoring of aquatic ecosystems. We present the first classification results of a new imaging system producing multiple images per specimen. Moreover, these results are compared with the results of human experts. On a data set of 29 taxonomical groups, automated classification produces a higher average accuracy than human experts. version:1
arxiv-1708-06670 | CNN Fixations: An unraveling approach to visualize the discriminative image regions | http://arxiv.org/abs/1708.06670 | id:1708.06670 author:Konda Reddy Mopuri, Utsav Garg, R. Venkatesh Babu category:cs.CV  published:2017-08-22 summary:Deep convolutional neural networks (CNN) have revolutionized various fields of vision research and have seen unprecedented adoption for multiple tasks such as classification, detection, captioning, etc. However, they offer little transparency into their inner workings and are often treated as black boxes that deliver excellent performance. In this work, we aim at alleviating this opaqueness of CNNs by providing visual explanations for the network's predictions. Our approach can analyze variety of CNN based models trained for vision applications such as object recognition and caption generation. Unlike existing methods, we achieve this via unraveling the forward pass operation. Proposed method exploits feature dependencies across the layer hierarchy and uncovers the discriminative image locations that guide the network's predictions. We name these locations CNN-Fixations, loosely analogous to human eye fixations. Our approach is a generic method that requires no architectural changes, additional training or gradient computation and computes the important image locations (CNN Fixations). We demonstrate through a variety of applications that our approach is able to localize the discriminative image locations across different network architectures, diverse vision tasks and data modalities. version:2
arxiv-1708-06858 | ElasticPlay: Interactive Video Summarization with Dynamic Time Budgets | http://arxiv.org/abs/1708.06858 | id:1708.06858 author:Haojian Jin, Yale Song, Koji Yatani category:cs.MM cs.CV cs.HC  published:2017-08-23 summary:Video consumption is being shifted from sit-and-watch to selective skimming. Existing video player interfaces, however, only provide indirect manipulation to support this emerging behavior. Video summarization alleviates this issue to some extent, shortening a video based on the desired length of a summary as an input variable. But an optimal length of a summarized video is often not available in advance. Moreover, the user cannot edit the summary once it is produced, limiting its practical applications. We argue that video summarization should be an interactive, mixed-initiative process in which users have control over the summarization procedure while algorithms help users achieve their goal via video understanding. In this paper, we introduce ElasticPlay, a mixed-initiative approach that combines an advanced video summarization technique with direct interface manipulation to help users control the video summarization process. Users can specify a time budget for the remaining content while watching a video; our system then immediately updates the playback plan using our proposed cut-and-forward algorithm, determining which parts to skip or to fast-forward. This interactive process allows users to fine-tune the summarization result with immediate feedback. We show that our system outperforms existing video summarization techniques on the TVSum50 dataset. We also report two lab studies (22 participants) and a Mechanical Turk deployment study (60 participants), and show that the participants responded favorably to ElasticPlay. version:1
arxiv-1708-06850 | Learning Deep Neural Network Representations for Koopman Operators of Nonlinear Dynamical Systems | http://arxiv.org/abs/1708.06850 | id:1708.06850 author:Enoch Yeung, Soumya Kundu, Nathan Hodas category:cs.LG  published:2017-08-22 summary:The Koopman operator has recently garnered much attention for its value in dynamical systems analysis and data-driven model discovery. However, its application has been hindered by the computational complexity of extended dynamic mode decomposition; this requires a combinatorially large basis set to adequately describe many nonlinear systems of interest, e.g. cyber-physical infrastructure systems, biological networks, social systems, and fluid dynamics. Often the dictionaries generated for these problems are manually curated, requiring domain-specific knowledge and painstaking tuning. In this paper we introduce a deep learning framework for learning Koopman operators of nonlinear dynamical systems. We show that this novel method automatically selects efficient deep dictionaries, outperforming state-of-the-art methods. We benchmark this method on partially observed nonlinear systems, including the glycolytic oscillator and show it is able to predict quantitatively 100 steps into the future, using only a single timepoint, and qualitative oscillatory behavior 400 steps into the future. version:1
arxiv-1708-06831 | Multiple-Kernel Based Vehicle Tracking Using 3D Deformable Model and Camera Self-Calibration | http://arxiv.org/abs/1708.06831 | id:1708.06831 author:Zheng Tang, Gaoang Wang, Tao Liu, Young-Gun Lee, Adwin Jahn, Xu Liu, Xiaodong He, Jenq-Neng Hwang category:cs.CV  published:2017-08-22 summary:Tracking of multiple objects is an important application in AI City geared towards solving salient problems related to safety and congestion in an urban environment. Frequent occlusion in traffic surveillance has been a major problem in this research field. In this challenge, we propose a model-based vehicle localization method, which builds a kernel at each patch of the 3D deformable vehicle model and associates them with constraints in 3D space. The proposed method utilizes shape fitness evaluation besides color information to track vehicle objects robustly and efficiently. To build 3D car models in a fully unsupervised manner, we also implement evolutionary camera self-calibration from tracking of walking humans to automatically compute camera parameters. Additionally, the segmented foreground masks which are crucial to 3D modeling and camera self-calibration are adaptively refined by multiple-kernel feedback from tracking. For object detection/classification, the state-of-the-art single shot multibox detector (SSD) is adopted to train and test on the NVIDIA AI City Dataset. To improve the accuracy on categories with only few objects, like bus, bicycle and motorcycle, we also employ the pretrained model from YOLO9000 with multi-scale testing. We combine the results from SSD and YOLO9000 based on ensemble learning. Experiments show that our proposed tracking system outperforms both state-of-the-art of tracking by segmentation and tracking by detection. version:1
arxiv-1704-07945 | Spatio-temporal Person Retrieval via Natural Language Queries | http://arxiv.org/abs/1704.07945 | id:1704.07945 author:Masataka Yamaguchi, Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada category:cs.CV  published:2017-04-26 summary:In this paper, we address the problem of spatio-temporal person retrieval from multiple videos using a natural language query, in which we output a tube (i.e., a sequence of bounding boxes) which encloses the person described by the query. For this problem, we introduce a novel dataset consisting of videos containing people annotated with bounding boxes for each second and with five natural language descriptions. To retrieve the tube of the person described by a given natural language query, we design a model that combines methods for spatio-temporal human detection and multimodal retrieval. We conduct comprehensive experiments to compare a variety of tube and text representations and multimodal retrieval methods, and present a strong baseline in this task as well as demonstrate the efficacy of our tube representation and multimodal feature embedding technique. Finally, we demonstrate the versatility of our model by applying it to two other important tasks. version:2
arxiv-1708-06819 | Dynamic Input Structure and Network Assembly for Few-Shot Learning | http://arxiv.org/abs/1708.06819 | id:1708.06819 author:Nathan Hilliard, Nathan O. Hodas, Courtney D. Corley category:cs.LG stat.ML  published:2017-08-22 summary:The ability to learn from a small number of examples has been a difficult problem in machine learning since its inception. While methods have succeeded with large amounts of training data, research has been underway in how to accomplish similar performance with fewer examples, known as one-shot or more generally few-shot learning. This technique has been shown to have promising performance, but in practice requires fixed-size inputs making it impractical for production systems where class sizes can vary. This impedes training and the final utility of few-shot learning systems. This paper describes an approach to constructing and training a network that can handle arbitrary example sizes dynamically as the system is used. version:1
arxiv-1707-02880 | Deep Bilateral Learning for Real-Time Image Enhancement | http://arxiv.org/abs/1707.02880 | id:1707.02880 author:Michaël Gharbi, Jiawen Chen, Jonathan T. Barron, Samuel W. Hasinoff, Frédo Durand category:cs.GR cs.CV  published:2017-07-10 summary:Performance is a critical challenge in mobile image processing. Given a reference imaging pipeline, or even human-adjusted pairs of images, we seek to reproduce the enhancements and enable real-time evaluation. For this, we introduce a new neural network architecture inspired by bilateral grid processing and local affine color transforms. Using pairs of input/output images, we train a convolutional neural network to predict the coefficients of a locally-affine model in bilateral space. Our architecture learns to make local, global, and content-dependent decisions to approximate the desired image transformation. At runtime, the neural network consumes a low-resolution version of the input image, produces a set of affine transformations in bilateral space, upsamples those transformations in an edge-preserving fashion using a new slicing node, and then applies those upsampled transformations to the full-resolution image. Our algorithm processes high-resolution images on a smartphone in milliseconds, provides a real-time viewfinder at 1080p resolution, and matches the quality of state-of-the-art approximation techniques on a large class of image operators. Unlike previous work, our model is trained off-line from data and therefore does not require access to the original operator at runtime. This allows our model to learn complex, scene-dependent transformations for which no reference implementation is available, such as the photographic edits of a human retoucher. version:2
arxiv-1708-06779 | Reflection Separation and Deblurring of Plenoptic Images | http://arxiv.org/abs/1708.06779 | id:1708.06779 author:Paramanand Chandramouli, Mehdi Noroozi, Paolo Favaro category:cs.CV  published:2017-08-22 summary:In this paper, we address the problem of reflection removal and deblurring from a single image captured by a plenoptic camera. We develop a two-stage approach to recover the scene depth and high resolution textures of the reflected and transmitted layers. For depth estimation in the presence of reflections, we train a classifier through convolutional neural networks. For recovering high resolution textures, we assume that the scene is composed of planar regions and perform the reconstruction of each layer by using an explicit form of the plenoptic camera point spread function. The proposed framework also recovers the sharp scene texture with different motion blurs applied to each layer. We demonstrate our method on challenging real and synthetic images. version:1
arxiv-1708-06767 | Seeing Through Noise: Speaker Separation and Enhancement using Visually-derived Speech | http://arxiv.org/abs/1708.06767 | id:1708.06767 author:Aviv Gabbay, Ariel Ephrat, Tavi Halperin, Shmuel Peleg category:cs.CV cs.SD  published:2017-08-22 summary:When video is recorded in a studio, sound is clear of external noises and unrelated sounds. However, most video is not shot at studios. Voice of people shot in family events is mixed with music and with other voices. Video conferences from home or office are often disturbed by other people, ringing phones, or barking dogs. TV reporting from city streets is mixed with traffic noise, sound of winds, etc. We propose to use visual information of face and mouth movements as seen in the video to enhance the voice of a speaker, and in particular eliminate sounds that do not relate to the face movements. The method is based on spectral information of speech as predicted by a video-to-speech system. Without visual information, the task of isolating a specific human voice while filtering out other voices or background noise is known as the cocktail party problem. This problem is solvable when N voices are recorded by N microphones. We address the challenging single microphone case, and show that visual information of the speaker can help solve this problem. version:1
arxiv-1708-06742 | Twin Networks: Using the Future as a Regularizer | http://arxiv.org/abs/1708.06742 | id:1708.06742 author:Dmitriy Serdyuk, Rosemary Nan Ke, Alessandro Sordoni, Chris Pal, Yoshua Bengio category:cs.LG stat.ML  published:2017-08-22 summary:Being able to model long-term dependencies in sequential data, such as text, has been among the long-standing challenges of recurrent neural networks (RNNs). This issue is strictly related to the absence of explicit planning in current RNN architectures. More explicitly, the RNNs are trained to predict only the next token given previous ones. In this paper, we introduce a simple way of encouraging the RNNs to plan for the future. In order to accomplish this, we introduce an additional neural network which is trained to generate the sequence in reverse order, and we require closeness between the states of the forward RNN and backward RNN that predict the same token. At each step, the states of the forward RNN are required to match the future information contained in the backward states. We hypothesize that the approach eases modeling of long-term dependencies thus helping in generating more globally consistent samples. The model trained with conditional generation for a speech recognition task achieved 12\% relative improvement (CER of 6.7 compared to a baseline of 7.6). version:1
arxiv-1708-06734 | Representation Learning by Learning to Count | http://arxiv.org/abs/1708.06734 | id:1708.06734 author:Mehdi Noroozi, Hamed Pirsiavash, Paolo Favaro category:cs.CV  published:2017-08-22 summary:We introduce a novel method for representation learning that uses an artificial supervision signal based on counting visual primitives. This supervision signal is obtained from an equivariance relation, which does not require any manual annotation. We relate transformations of images to transformations of the representations. More specifically, we look for the representation that satisfies such relation rather than the transformations that match a given representation. In this paper, we use two image transformations in the context of counting: scaling and tiling. The first transformation exploits the fact that the number of visual primitives should be invariant to scale. The second transformation allows us to equate the total number of visual primitives in each tile to that in the whole image. These two transformations are combined in one constraint and used to train a neural network with a contrastive loss. The proposed task produces representations that perform on par or exceed the state of the art in transfer learning benchmarks. version:1
arxiv-1708-06733 | BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain | http://arxiv.org/abs/1708.06733 | id:1708.06733 author:Tianyu Gu, Brendan Dolan-Gavitt, Siddharth Garg category:cs.CR cs.LG  published:2017-08-22 summary:Deep learning-based techniques have achieved state-of-the-art performance on a wide variety of recognition and classification tasks. However, these networks are typically computationally expensive to train, requiring weeks of computation on many GPUs; as a result, many users outsource the training procedure to the cloud or rely on pre-trained models that are then fine-tuned for a specific task. In this paper we show that outsourced training introduces new security risks: an adversary can create a maliciously trained network (a backdoored neural network, or a \emph{BadNet}) that has state-of-the-art performance on the user's training and validation samples, but behaves badly on specific attacker-chosen inputs. We first explore the properties of BadNets in a toy example, by creating a backdoored handwritten digit classifier. Next, we demonstrate backdoors in a more realistic scenario by creating a U.S. street sign classifier that identifies stop signs as speed limits when a special sticker is added to the stop sign; we then show in addition that the backdoor in our US street sign detector can persist even if the network is later retrained for another task and cause a drop in accuracy of {25}\% on average when the backdoor trigger is present. These results demonstrate that backdoors in neural networks are both powerful and---because the behavior of neural networks is difficult to explicate---stealthy. This work provides motivation for further research into techniques for verifying and inspecting neural networks, just as we have developed tools for verifying and debugging software. version:1
arxiv-1708-06720 | WordSup: Exploiting Word Annotations for Character based Text Detection | http://arxiv.org/abs/1708.06720 | id:1708.06720 author:Han Hu, Chengquan Zhang, Yuxuan Luo, Yuzhuo Wang, Junyu Han, Errui Ding category:cs.CV  published:2017-08-22 summary:Imagery texts are usually organized as a hierarchy of several visual elements, i.e. characters, words, text lines and text blocks. Among these elements, character is the most basic one for various languages such as Western, Chinese, Japanese, mathematical expression and etc. It is natural and convenient to construct a common text detection engine based on character detectors. However, training character detectors requires a vast of location annotated characters, which are expensive to obtain. Actually, the existing real text datasets are mostly annotated in word or line level. To remedy this dilemma, we propose a weakly supervised framework that can utilize word annotations, either in tight quadrangles or the more loose bounding boxes, for character detector training. When applied in scene text detection, we are thus able to train a robust character detector by exploiting word annotations in the rich large-scale real scene text datasets, e.g. ICDAR15 and COCO-text. The character detector acts as a key role in the pipeline of our text detection engine. It achieves the state-of-the-art performance on several challenging scene text detection benchmarks. We also demonstrate the flexibility of our pipeline by various scenarios, including deformed text detection and math expression recognition. version:1
arxiv-1708-06714 | A Deterministic Nonsmooth Frank Wolfe Algorithm with Coreset Guarantees | http://arxiv.org/abs/1708.06714 | id:1708.06714 author:Sathya N. Ravi, Maxwell D. Collins, Vikas Singh category:math.OC cs.NA stat.ML 65K10  published:2017-08-22 summary:We present a new Frank-Wolfe (FW) type algorithm that is applicable to minimization problems with a nonsmooth convex objective. We provide convergence bounds and show that the scheme yields so-called coreset results for various Machine Learning problems including 1-median, Balanced Development, Sparse PCA, Graph Cuts, and the $\ell_1$-norm-regularized Support Vector Machine (SVM) among others. This means that the algorithm provides approximate solutions to these problems in time complexity bounds that are not dependent on the size of the input problem. Our framework, motivated by a growing body of work on sublinear algorithms for various data analysis problems, is entirely deterministic and makes no use of smoothing or proximal operators. Apart from these theoretical results, we show experimentally that the algorithm is very practical and in some cases also offers significant computational advantages on large problem instances. We provide an open source implementation that can be adapted for other problems that fit the overall structure. version:1
arxiv-1708-06703 | What does 2D geometric information really tell us about 3D face shape? | http://arxiv.org/abs/1708.06703 | id:1708.06703 author:Anil Bas, William A. P. Smith category:cs.CV  published:2017-08-22 summary:A face image contains geometric cues in the form of configurational information and contours that can be used to estimate 3D face shape. While it is clear that 3D reconstruction from 2D points is highly ambiguous if no further constraints are enforced, one might expect that the face-space constraint solves this problem. We show that this is not the case and that geometric information is an ambiguous cue. There are two sources for this ambiguity. The first is that, within the space of 3D face shapes, there are flexibility modes that remain when some parts of the face are fixed. The second occurs only under perspective projection and is a result of perspective transformation as camera distance varies. Two different faces, when viewed at different distances, can give rise to the same 2D geometry. To demonstrate these ambiguities, we develop new algorithms for fitting a 3D morphable model to 2D landmarks or contours under either orthographic or perspective projection and show how to compute flexibility modes for both cases. We show that both fitting problems can be posed as a separable nonlinear least squares problem and solved efficiently. We provide quantitative and qualitative evidence that the ambiguity exists in synthetic data and real images. version:1
arxiv-1708-05884 | Teaching UAVs to Race Using UE4Sim | http://arxiv.org/abs/1708.05884 | id:1708.05884 author:Matthias Mueller, Vincent Casser, Neil Smith, Dominik L. Michels, Bernard Ghanem category:cs.CV  published:2017-08-19 summary:Automating the navigation of unmanned aerial vehicles (UAVs) in diverse scenarios has gained much attention in the recent years. However, teaching UAVs to fly in challenging environments remains an unsolved problem, mainly due to the lack of data for training. In this paper, we develop a photo-realistic simulator that can afford the generation of large amounts of training data (both images rendered from the UAV camera and its controls) to teach a UAV to autonomously race through challenging tracks. We train a deep neural network to predict UAV controls from raw image data for the task of autonomous UAV racing. Training is done through imitation learning enabled by data augmentation to allow for the correction of navigation mistakes. Extensive experiments demonstrate that our trained network (when sufficient data augmentation is used) outperforms state-of-the-art methods and flies more consistently than many human pilots. version:2
arxiv-1708-06690 | A Spatiotemporal Oriented Energy Network for Dynamic Texture Recognition | http://arxiv.org/abs/1708.06690 | id:1708.06690 author:Isma Hadji, Richard P. Wildes category:cs.CV  published:2017-08-22 summary:This paper presents a novel hierarchical spatiotemporal orientation representation for spacetime image analysis. It is designed to combine the benefits of the multilayer architecture of ConvNets and a more controlled approach to spacetime analysis. A distinguishing aspect of the approach is that unlike most contemporary convolutional networks no learning is involved; rather, all design decisions are specified analytically with theoretical motivations. This approach makes it possible to understand what information is being extracted at each stage and layer of processing as well as to minimize heuristic choices in design. Another key aspect of the network is its recurrent nature, whereby the output of each layer of processing feeds back to the input. To keep the network size manageable across layers, a novel cross-channel feature pooling is proposed. The multilayer architecture that results systematically reveals hierarchical image structure in terms of multiscale, multiorientation properties of visual spacetime. To illustrate its utility, the network has been applied to the task of dynamic texture recognition. Empirical evaluation on multiple standard datasets shows that it sets a new state-of-the-art. version:1
arxiv-1708-06678 | Learning Combinations of Sigmoids Through Gradient Estimation | http://arxiv.org/abs/1708.06678 | id:1708.06678 author:Stratis Ioannidis, Andrea Montanari category:stat.ML cs.LG  published:2017-08-22 summary:We develop a new approach to learn the parameters of regression models with hidden variables. In a nutshell, we estimate the gradient of the regression function at a set of random points, and cluster the estimated gradients. The centers of the clusters are used as estimates for the parameters of hidden units. We justify this approach by studying a toy model, whereby the regression function is a linear combination of sigmoids. We prove that indeed the estimated gradients concentrate around the parameter vectors of the hidden units, and provide non-asymptotic bounds on the number of required samples. To the best of our knowledge, no comparable guarantees have been proven for linear combinations of sigmoids. version:1
arxiv-1708-06673 | Tags2Parts: Discovering Semantic Regions from Shape Tags | http://arxiv.org/abs/1708.06673 | id:1708.06673 author:Sanjeev Muralikrishnan, Vladimir G. Kim, Siddhartha Chaudhuri category:cs.CV cs.GR  published:2017-08-22 summary:We propose a novel method for discovering shape regions that strongly correlate with user-prescribed tags. For example, given a collection of chairs tagged as either "has armrest" or "lacks armrest", our system correctly highlights the armrest regions as the main distinctive parts between the two chair types. To obtain point-wise predictions from shape-wise tags we develop a novel neural network architecture that is trained with tag classification loss, but is designed to rely on segmentation to predict the tag. Our network is inspired by U-Net, but we replicate shallow U structures several times with new skip connections and pooling layers, and call the resulting architecture "WU-Net". We test our method on segmentation benchmarks and show that even with weak supervision of whole shape tags, our method is able to infer meaningful semantic regions, without ever observing shape segmentations. Further, once trained, the model can process shapes for which the tag is entirely unknown. As a bonus, our network architecture is directly operational in a strongly-supervised scenario and outperforms state-of-the-art strongly-supervised methods on standard benchmarks. version:1
arxiv-1708-06656 | On Image Classification: Correlation v.s. Causality | http://arxiv.org/abs/1708.06656 | id:1708.06656 author:Zheyan Shen, Peng Cui, Kun Kuang, Bo Li category:cs.CV  published:2017-08-22 summary:Image classification is one of the fundamental problems in computer vision. Owing to the availability of large image datasets like ImageNet and YFCC100M, a plethora of research has been conducted to do high precision image classification and many remarkable achievements have been made. The success of most existing methods hinges on a basic hypothesis that the testing image set has the same distribution as the training image set. However, in many real applications, we cannot guarantee the validity of the i.i.d. hypothesis since the testing image set is unseen. It is thus desirable to learn an image classifier, which can perform well even in non-i.i.d. situations. In this paper, we propose a novel Causally Regularized Logistic Regression (CRLR) algorithm to address the non-i.i.d. problem without knowing testing data information by searching for causal features. The causal features refer to characteristics truly determining whether a special object belongs to a category or not. Algorithmically, we propose a causal regularizer for causal feature identification by jointly optimizing it with a logistic loss term. Assisted with the causal regularizer, we can estimate the causal contribution (causal effect) of each focal image feature (viewed as a treatment variable) by sample reweighting which ensures the distributions of all remaining image features between images with different focal feature levels are close. The resultant classifier will be based on the estimated causal contributions of the features, rather than traditional correlation-based contributions. To validate the e effectiveness of our CRLR algorithm, we manually construct a new image dataset from YFCC100M, simulating various non-i.i.d. situations in the real world, and conduct extensive experiments for image classification. Experimental results clearly demonstrate that our CRLR algorithm outperforms the state-of-the-art methods. version:1
arxiv-1708-06637 | Activity Recognition based on a Magnitude-Orientation Stream Network | http://arxiv.org/abs/1708.06637 | id:1708.06637 author:Carlos Caetano, Victor H. C. de Melo, Jefersson A. dos Santos, William Robson Schwartz category:cs.CV  published:2017-08-22 summary:The temporal component of videos provides an important clue for activity recognition, as a number of activities can be reliably recognized based on the motion information. In view of that, this work proposes a novel temporal stream for two-stream convolutional networks based on images computed from the optical flow magnitude and orientation, named Magnitude-Orientation Stream (MOS), to learn the motion in a better and richer manner. Our method applies simple nonlinear transformations on the vertical and horizontal components of the optical flow to generate input images for the temporal stream. Experimental results, carried on two well-known datasets (HMDB51 and UCF101), demonstrate that using our proposed temporal stream as input to existing neural network architectures can improve their performance for activity recognition. Results demonstrate that our temporal stream provides complementary information able to improve the classical two-stream methods, indicating the suitability of our approach to be used as a temporal video representation. version:1
arxiv-1708-06561 | Color and Gradient Features for Text Segmentation from Video Frames | http://arxiv.org/abs/1708.06561 | id:1708.06561 author:P. Shivakumara, D. S. Guru, H. T. Basavaraju category:cs.CV  published:2017-08-22 summary:Text segmentation in a video is drawing attention of researchers in the field of image processing, pattern recognition and document image analysis because it helps in annotating and labeling video events accurately. We propose a novel idea of generating an enhanced frame from the R, G, and B channels of an input frame by grouping high and low values using Min-Max clustering criteria. We also perform sliding window on enhanced frame to group high and low values from the neighboring pixel values to further enhance the frame. Subsequently, we use k-means with k=2 clustering algorithm to separate text and non-text regions. The fully connected components will be identified in the skeleton of the frame obtained by k-means clustering. Concept of connected component analysis based on gradient feature has been adapted for the purpose of symmetry verification. The components which satisfy symmetric verification are selected to be the representatives of text regions and they are permitted to grow to cover their respective region fully containing text. The method is tested on variety of video frames to evaluate the performance of the method in terms of recall, precision and f-measure. The results show that method is promising and encouraging. version:1
arxiv-1708-06555 | Long-Short Range Context Neural Networks for Language Modeling | http://arxiv.org/abs/1708.06555 | id:1708.06555 author:Youssef Oualil, Mittul Singh, Clayton Greenberg, Dietrich Klakow category:cs.CL cs.LG 97K50 I.2.7  published:2017-08-22 summary:The goal of language modeling techniques is to capture the statistical and structural properties of natural languages from training corpora. This task typically involves the learning of short range dependencies, which generally model the syntactic properties of a language and/or long range dependencies, which are semantic in nature. We propose in this paper a new multi-span architecture, which separately models the short and long context information while it dynamically merges them to perform the language modeling task. This is done through a novel recurrent Long-Short Range Context (LSRC) network, which explicitly models the local (short) and global (long) context using two separate hidden states that evolve in time. This new architecture is an adaptation of the Long-Short Term Memory network (LSTM) to take into account the linguistic properties. Extensive experiments conducted on the Penn Treebank (PTB) and the Large Text Compression Benchmark (LTCB) corpus showed a significant reduction of the perplexity when compared to state-of-the-art language modeling techniques. version:1
arxiv-1708-06550 | Golden Years, Golden Shores: A Study of Elders in Online Travel Communities | http://arxiv.org/abs/1708.06550 | id:1708.06550 author:Bartłomiej Balcerzak, Radosław Nielek category:cs.CL cs.CY  published:2017-08-22 summary:In this paper we present our exploratory findings related to extracting knowledge and experiences from a community of senior tourists. By using tools of qualitative analysis as well as review of literature, we managed to verify a set of hypotheses related to the content created by senior tourists when participating in on-line communities. We also produced a codebook, representing various themes one may encounter in such communities. This codebook, derived from our own qualitative research, as well a literature review will serve as a basis for further development of automated tools of knowledge extraction. We also managed to find that older adults more often than other poster in tourists forums, mention their age in discussion, more often share their experiences and motivation to travel, however they do not differ in relation to describing barriers encountered while traveling. version:1
arxiv-1708-06539 | Stacked transfer learning for tropical cyclone intensity prediction | http://arxiv.org/abs/1708.06539 | id:1708.06539 author:Ratneel Vikash Deo, Rohitash Chandra, Anuraganand Sharma category:cs.LG stat.ML  published:2017-08-22 summary:Tropical cyclone wind-intensity prediction is a challenging task considering drastic changes climate patterns over the last few decades. In order to develop robust prediction models, one needs to consider different characteristics of cyclones in terms of spatial and temporal characteristics. Transfer learning incorporates knowledge from a related source dataset to compliment a target datasets especially in cases where there is lack or data. Stacking is a form of ensemble learning focused for improving generalization that has been recently used for transfer learning problems which is referred to as transfer stacking. In this paper, we employ transfer stacking as a means of studying the effects of cyclones whereby we evaluate if cyclones in different geographic locations can be helpful for improving generalization performs. Moreover, we use conventional neural networks for evaluating the effects of duration on cyclones in prediction performance. Therefore, we develop an effective strategy that evaluates the relationships between different types of cyclones through transfer learning and conventional learning methods via neural networks. version:1
arxiv-1708-05237 | S$^3$FD: Single Shot Scale-invariant Face Detector | http://arxiv.org/abs/1708.05237 | id:1708.05237 author:Shifeng Zhang, Xiangyu Zhu, Zhen Lei, Hailin Shi, Xiaobo Wang, Stan Z. Li category:cs.CV  published:2017-08-17 summary:This paper presents a real-time face detector, named Single Shot Scale-invariant Face Detector (S$^3$FD), which performs superiorly on various scales of faces with a single deep neural network, especially for small faces. Specifically, we try to solve the common problem that anchor-based detectors deteriorate dramatically as the objects become smaller. We make contributions in the following three aspects: 1) proposing a scale-equitable face detection framework to handle different scales of faces well. We tile anchors on a wide range of layers to ensure that all scales of faces have enough features for detection. Besides, we design anchor scales based on the effective receptive field and a proposed equal proportion interval principle; 2) improving the recall rate of small faces by a scale compensation anchor matching strategy; 3) reducing the false positive rate of small faces via a max-out background label. As a consequence, our method achieves state-of-the-art detection performance on all the common face detection benchmarks, including the AFW, PASCAL face, FDDB and WIDER FACE datasets, and can run at 36 FPS on a Nvidia Titan X (Pascal) for VGA-resolution images. version:2
arxiv-1708-06525 | Neural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection | http://arxiv.org/abs/1708.06525 | id:1708.06525 author:Xiaojun Xu, Chang Liu, Qian Feng, Heng Yin, Le Song, Dawn Song category:cs.CR cs.NE  published:2017-08-22 summary:The problem of cross-platform binary code similarity detection aims at detecting whether two binary functions coming from different platforms are similar or not. It has many security applications, including plagiarism detection, malware detection, vulnerability search, etc. Existing approaches rely on approximate graph matching algorithms, which are inevitably slow and sometimes inaccurate, and hard to adapt to a new task. To address these issues, in this work, we propose a novel neural network-based approach to compute the embedding, i.e., a numeric vector, based on the control flow graph of each binary function, then the similarity detection can be done efficiently by measuring the distance between the embeddings for two functions. We implement a prototype called Gemini. Our extensive evaluation shows that Gemini outperforms the state-of-the-art approaches by large margins with respect to similarity detection accuracy. Further, Gemini can speed up prior art's embedding generation time by 3 to 4 orders of magnitude and reduce the required training time from more than 1 week down to 30 minutes to 10 hours. Our real world case studies demonstrate that Gemini can identify significantly more vulnerable firmware images than the state-of-the-art, i.e., Genius. Our research showcases a successful application of deep learning on computer security problems. version:1
arxiv-1708-06510 | Handling Homographs in Neural Machine Translation | http://arxiv.org/abs/1708.06510 | id:1708.06510 author:Frederick Liu, Han Lu, Graham Neubig category:cs.CL  published:2017-08-22 summary:Homographs, words with different meanings but the same surface form, have long caused difficulty for machine translation systems, as it is difficult to select the correct translation based on the context. However, with the advent of neural machine translation (NMT) systems, which can theoretically take into account global sentential context, one may hypothesize that this problem has been alleviated. In this paper, we first provide empirical evidence that existing NMT systems in fact still have significant problems in properly translating ambiguous words. We then proceed to describe methods, inspired by the word sense disambiguation literature, that model the context of the input word with context-aware word embeddings that help to differentiate the word sense be- fore feeding it into the encoder. Experiments on three language pairs demonstrate that such models improve the performance of NMT systems both in terms of BLEU score and in the accuracy of translating homographs. version:1
arxiv-1708-06509 | ProbFlow: Joint Optical Flow and Uncertainty Estimation | http://arxiv.org/abs/1708.06509 | id:1708.06509 author:Anne S. Wannenwetsch, Margret Keuper, Stefan Roth category:cs.CV  published:2017-08-22 summary:Optical flow estimation remains challenging due to untextured areas, motion boundaries, occlusions, and more. Thus, the estimated flow is not equally reliable across the image. To that end, post-hoc confidence measures have been introduced to assess the per-pixel reliability of the flow. We overcome the artificial separation of optical flow and confidence estimation by introducing a method that jointly predicts optical flow and its underlying uncertainty. Starting from common energy-based formulations, we rely on the corresponding posterior distribution of the flow given the images. We derive a variational inference scheme based on mean field, which incorporates best practices from energy minimization. An uncertainty measure is obtained along the flow at every pixel as the (marginal) entropy of the variational distribution. We demonstrate the flexibility of our probabilistic approach by applying it to two different energies and on two benchmarks. We not only obtain flow results that are competitive with the underlying energy minimization approach, but also a reliable uncertainty measure that significantly outperforms existing post-hoc approaches. version:1
arxiv-1708-06495 | Towards Automatic Construction of Diverse, High-quality Image Dataset | http://arxiv.org/abs/1708.06495 | id:1708.06495 author:Yazhou Yao, Jian Zhang, Fumin Shen, Dongxiang Zhang, Zhenmin Tang, Heng Tao Shen category:cs.CV cs.MM  published:2017-08-22 summary:The availability of labeled image datasets has been shown critical for high-level image understanding, which continuously drives the progress of feature designing and models developing. However, constructing labeled image datasets is laborious and monotonous. To eliminate manual annotation, in this work, we propose a novel image dataset construction framework by employing multiple textual metadata. We aim at collecting diverse and accurate images for given queries from the Web. Specifically, we formulate noisy textual metadata removing and noisy images filtering as a multi-view and multi-instance learning problem separately. Our proposed approach not only improves the accuracy but also enhances the diversity of the selected images. To verify the effectiveness of our proposed approach, we construct an image dataset with 100 categories. The experiments show significant performance gains by using the generated data of our approach on several tasks, such as image classification, cross-dataset generalization, and object detection. The proposed method also consistently outperforms existing weakly supervised and web-supervised approaches. version:1
arxiv-1708-06453 | Sharpness-aware Low dose CT denoising using conditional generative adversarial network | http://arxiv.org/abs/1708.06453 | id:1708.06453 author:Xin Yi, Paul Babyn category:cs.CV  published:2017-08-22 summary:Low Dose Computed tomography (CT) has offered tremendous benefits in radiation restricted applications, but the quantum noise as resulted by the insufficient number of photons could potentially harm the diagnostic performance. Current image-based denoising methods tend to produce a blur effect on the final reconstructed results especially in high noise levels. In this paper, a deep learning based approach was proposed to mitigate this problem. An adversarially trained network and a sharpness detection network were trained to guide the training process. Experiments on both simulated and real dataset shows that the results of the proposed method have very small resolution loss and achieves better performance relative to the-state-of-art methods both quantitatively and visually. version:1
arxiv-1705-00334 | Scaling Active Search using Linear Similarity Functions | http://arxiv.org/abs/1705.00334 | id:1705.00334 author:Sibi Venkatesan, James K. Miller, Jeff Schneider, Artur Dubrawski category:stat.ML cs.LG  published:2017-04-30 summary:Active Search has become an increasingly useful tool in information retrieval problems where the goal is to discover as many target elements as possible using only limited label queries. With the advent of big data, there is a growing emphasis on the scalability of such techniques to handle very large and very complex datasets. In this paper, we consider the problem of Active Search where we are given a similarity function between data points. We look at an algorithm introduced by Wang et al. [2013] for Active Search over graphs and propose crucial modifications which allow it to scale significantly. Their approach selects points by minimizing an energy function over the graph induced by the similarity function on the data. Our modifications require the similarity function to be a dot-product between feature vectors of data points, equivalent to having a linear kernel for the adjacency matrix. With this, we are able to scale tremendously: for $n$ data points, the original algorithm runs in $O(n^2)$ time per iteration while ours runs in only $O(nr + r^2)$ given $r$-dimensional features. We also describe a simple alternate approach using a weighted-neighbor predictor which also scales well. In our experiments, we show that our method is competitive with existing semi-supervised approaches. We also briefly discuss conditions under which our algorithm performs well. version:2
arxiv-1708-02691 | Universal Function Approximation by Deep Neural Nets with Bounded Width and ReLU Activations | http://arxiv.org/abs/1708.02691 | id:1708.02691 author:Boris Hanin category:stat.ML cs.CG cs.LG math.FA math.ST stat.TH  published:2017-08-09 summary:This article concerns the expressive power of depth in neural nets with ReLU activations and bounded width. We are particularly interested in the following questions: what is the minimal width $w_{\text{min}}(d)$ so that ReLU nets of width $w_{\text{min}}(d)$ (and arbitrary depth) can approximate any continuous function on the unit cube $[0,1]^d$ aribitrarily well? For ReLU nets near this minimal width, what can one say about the depth necessary to approximate a given function? We obtain an essentially complete answer to these questions for convex functions. Our approach is based on the observation that, due to the convexity of the ReLU activation, ReLU nets are particularly well-suited for representing convex functions. In particular, we prove that ReLU nets with width $d+1$ can approximate any continuous convex function of $d$ variables arbitrarily well. Moreover, when approximating convex, piecewise affine functions by such nets, we obtain matching upper and lower bounds on the required depth, proving that our construction is essentially optimal. These results then give quantitative depth estimates for the rate of approximation of any continuous scalar function on the $d$-dimensional cube $[0,1]^d$ by ReLU nets with width $d+3.$ version:2
arxiv-1708-06438 | Sum-Product Graphical Models | http://arxiv.org/abs/1708.06438 | id:1708.06438 author:Mattia Desana, Christoph Schnörr category:stat.ML cs.LG  published:2017-08-21 summary:This paper introduces a new probabilistic architecture called Sum-Product Graphical Model (SPGM). SPGMs combine traits from Sum-Product Networks (SPNs) and Graphical Models (GMs): Like SPNs, SPGMs always enable tractable inference using a class of models that incorporate context specific independence. Like GMs, SPGMs provide a high-level model interpretation in terms of conditional independence assumptions and corresponding factorizations. Thus, the new architecture represents a class of probability distributions that combines, for the first time, the semantics of graphical models with the evaluation efficiency of SPNs. We also propose a novel algorithm for learning both the structure and the parameters of SPGMs. A comparative empirical evaluation demonstrates competitive performances of our approach in density estimation. version:1
arxiv-1708-06433 | PiCANet: Learning Pixel-wise Contextual Attention in ConvNets and Its Application in Saliency Detection | http://arxiv.org/abs/1708.06433 | id:1708.06433 author:Nian Liu, Junwei Han category:cs.CV  published:2017-08-21 summary:Context plays an important role in many computer vision tasks. Previous models usually construct contextual information from the whole context region. However, not all context locations are helpful and some of them may be detrimental to the final task. To solve this problem, we propose a novel pixel-wise contextual attention network, i.e., the PiCANet, to learn to selectively attend to informative context locations for each pixel. Specifically, it can generate an attention map over the context region for each pixel, where each attention weight corresponds to the contextual relevance of each context location w.r.t. the specified pixel location. Thus, an attended contextual feature can be constructed by using the attention map to aggregate the contextual features. We formulate PiCANet in a global form and a local form to attend to global contexts and local contexts, respectively. Our designs for the two forms are both fully differentiable. Thus they can be embedded into any CNN architectures for various computer vision tasks in an end-to-end manner. We take saliency detection as an example application to demonstrate the effectiveness of the proposed PiCANets. Specifically, we embed global and local PiCANets into an encoder-decoder Convnet hierarchically. Thorough analyses indicate that the global PiCANet helps to construct global contrast while the local PiCANets help to enhance the feature maps to be more homogenous, thus making saliency detection results more accurate and uniform. As a result, our proposed saliency model achieves state-of-the-art results on 4 benchmark datasets. version:1
arxiv-1708-06426 | Cold Fusion: Training Seq2Seq Models Together with Language Models | http://arxiv.org/abs/1708.06426 | id:1708.06426 author:Anuroop Sriram, Heewoo Jun, Sanjeev Satheesh, Adam Coates category:cs.CL  published:2017-08-21 summary:Sequence-to-sequence (Seq2Seq) models with attention have excelled at tasks which involve generating natural language sentences such as machine translation, image captioning and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language model. In this work, we present the Cold Fusion method, which leverages a pre-trained language model during training, and show its effectiveness on the speech recognition task. We show that Seq2Seq models with Cold Fusion are able to better utilize language information enjoying i) faster convergence and better generalization, and ii) almost complete transfer to a new domain while using less than 10% of the labeled training data. version:1
arxiv-1708-06418 | STNet: Selective Tuning of Convolutional Networks for Object Localization | http://arxiv.org/abs/1708.06418 | id:1708.06418 author:Mahdi Biparva, John Tsotsos category:cs.CV  published:2017-08-21 summary:Visual attention modeling has recently gained momentum in developing visual hierarchies provided by Convolutional Neural Networks. Despite recent successes of feedforward processing on the abstraction of concepts form raw images, the inherent nature of feedback processing has remained computationally controversial. Inspired by the computational models of covert visual attention, we propose the Selective Tuning of Convolutional Networks (STNet). It is composed of both streams of Bottom-Up and Top-Down information processing to selectively tune the visual representation of Convolutional networks. We experimentally evaluate the performance of STNet for the weakly-supervised localization task on the ImageNet benchmark dataset. We demonstrate that STNet not only successfully surpasses the state-of-the-art results but also generates attention-driven class hypothesis maps. version:1
arxiv-1708-05625 | Winqi: A System for 6D Localization and SLAM Augmentation Using Wideangle Optics and Coded Light Beacons | http://arxiv.org/abs/1708.05625 | id:1708.05625 author:Aaron Wetzler, Ron Kimmel category:cs.CV  published:2017-08-18 summary:Simultaneous Localization and Mapping (SLAM) systems use commodity visible/near visible digital sensors coupled with processing units that detect, recognize and track image points in a camera stream. These systems are cheap, fast and make use of readily available camera technologies. However, SLAM systems suffer from issues of drift as well as sensitivity to lighting variation such as shadows and changing brightness. Beaconless SLAM systems will continue to suffer from this inherent drift problem irrespective of the improvements in on-board camera resolution, speed and inertial sensor precision. To cancel out destructive forms of drift, relocalization algorithms are used which use known detected landmarks together with loop closure processes to continually readjust the current location and orientation estimates to match "known" positions. However this is inherently problematic because these landmarks themselves may have been recorded with errors and they may also change under different illumination conditions. In this note we describe a unique beacon light coding system which is robust to desynchronized clock bit drift. The described beacons and codes are designed to be used in industrial or consumer environments for full standalone 6dof tracking or as known error free landmarks in a SLAM pipeline. version:2
arxiv-1708-06376 | Automated Feature Extraction for Website Fingerprinting through Deep Learning | http://arxiv.org/abs/1708.06376 | id:1708.06376 author:Vera Rimmer, Davy Preuveneers, Marc Juarez, Tom Van Goethem, Wouter Joosen category:cs.CR cs.LG  published:2017-08-21 summary:Several studies have shown that the network traffic that is generated by a visit to a website over Tor reveals information specific to the website through the timing and sizes of network packets. By capturing traffic traces between users and their Tor entry guard, a network eavesdropper can leverage this meta-data to reveal which website Tor users are visiting. The success of such attacks heavily depends on the particular set of traffic features that are used to construct the fingerprint. Typically, these features are manually engineered and, as such, any change introduced to the Tor network can render these carefully constructed features ineffective. In this paper, we show that an adversary can automate the feature engineering process, and thus automatically deanonymize Tor traffic by applying our novel method based on deep learning. We evaluate our approach on a dataset comprised of more than three million network traces, which is the largest dataset of web traffic ever gathered for website fingerprinting, and find that the performance achieved by deep learning techniques is comparable to known approaches which include various research efforts spanning over multiple years. Furthermore, it eliminates the need for feature design and selection which is a tedious work and has been one of the main focus of prior work. We conclude that the ability to automatically construct the most relevant traffic features and perform accurate traffic recognition makes our deep learning based approach an efficient, flexible and robust technique for website fingerprinting. version:1
arxiv-1708-06320 | Learning Spread-out Local Feature Descriptors | http://arxiv.org/abs/1708.06320 | id:1708.06320 author:Xu Zhang, Felix X. Yu, Sanjiv Kumar, Shih-Fu Chang category:cs.CV  published:2017-08-21 summary:We propose a simple, yet powerful regularization technique that can be used to significantly improve both the pairwise and triplet losses in learning local feature descriptors. The idea is that in order to fully utilize the expressive power of the descriptor space, good local feature descriptors should be sufficiently "spread-out" over the space. In this work, we propose a regularization term to maximize the spread in feature descriptor inspired by the property of uniform distribution. We show that the proposed regularization with triplet loss outperforms existing Euclidean distance based descriptor learning techniques by a large margin. As an extension, the proposed regularization technique can also be used to improve image-level deep feature embedding. version:1
arxiv-1708-06297 | Employing Weak Annotations for Medical Image Analysis Problems | http://arxiv.org/abs/1708.06297 | id:1708.06297 author:Martin Rajchl, Lisa M. Koch, Christian Ledig, Jonathan Passerat-Palmbach, Kazunari Misawa, Kensaku Mori, Daniel Rueckert category:cs.CV  published:2017-08-21 summary:To efficiently establish training databases for machine learning methods, collaborative and crowdsourcing platforms have been investigated to collectively tackle the annotation effort. However, when this concept is ported to the medical imaging domain, reading expertise will have a direct impact on the annotation accuracy. In this study, we examine the impact of expertise and the amount of available annotations on the accuracy outcome of a liver segmentation problem in an abdominal computed tomography (CT) image database. In controlled experiments, we study this impact for different types of weak annotations. To address the decrease in accuracy associated with lower expertise, we propose a method for outlier correction making use of a weakly labelled atlas. Using this approach, we demonstrate that weak annotations subject to high error rates can achieve a similarly high accuracy as state-of-the-art multi-atlas segmentation approaches relying on a large amount of expert manual segmentations. Annotations of this nature can realistically be obtained from a non-expert crowd and can potentially enable crowdsourcing of weak annotation tasks for medical image analysis. version:1
arxiv-1708-06347 | Deep vs. Diverse Architectures for Classification Problems | http://arxiv.org/abs/1708.06347 | id:1708.06347 author:Colleen M. Farrelly category:stat.ML cs.LG  published:2017-08-21 summary:This study compares various superlearner and deep learning architectures (machine-learning-based and neural-network-based) for classification problems across several simulated and industrial datasets to assess performance and computational efficiency, as both methods have nice theoretical convergence properties. Superlearner formulations outperform other methods at small to moderate sample sizes (500-2500) on nonlinear and mixed linear/nonlinear predictor relationship datasets, while deep neural networks perform well on linear predictor relationship datasets of all sizes. This suggests faster convergence of the superlearner compared to deep neural network architectures on many messy classification problems for real-world data. Superlearners also yield interpretable models, allowing users to examine important signals in the data; in addition, they offer flexible formulation, where users can retain good performance with low-computational-cost base algorithms. K-nearest-neighbor (KNN) regression demonstrates improvements using the superlearner framework, as well; KNN superlearners consistently outperform deep architectures and KNN regression, suggesting that superlearners may be better able to capture local and global geometric features through utilizing a variety of algorithms to probe the data space. version:1
arxiv-1708-06235 | Deep Convolutional Neural Networks for Massive MIMO Fingerprint-Based Positioning | http://arxiv.org/abs/1708.06235 | id:1708.06235 author:Joao Vieira, Erik Leitinger, Muris Sarajlic, Xuhong Li, Fredrik Tufvesson category:stat.ML cs.IT math.IT  published:2017-08-21 summary:This paper provides an initial investigation on the application of convolutional neural networks (CNNs) for fingerprint-based positioning using measured massive MIMO channels. When represented in appropriate domains, massive MIMO channels have a sparse structure which can be efficiently learned by CNNs for positioning purposes. We evaluate the positioning accuracy of state-of-the-art CNNs with channel fingerprints generated from a channel model with a rich clustered structure: the COST 2100 channel model. We find that moderately deep CNNs can achieve fractional-wavelength positioning accuracies, provided that an enough representative data set is available for training. version:1
arxiv-1708-06227 | Recognizing Involuntary Actions from 3D Skeleton Data Using Body States | http://arxiv.org/abs/1708.06227 | id:1708.06227 author:Mozhgan Mokari, Hoda Mohammadzade, Benyamin Ghojogh category:cs.CV  published:2017-08-21 summary:Human action recognition has been one of the most active fields of research in computer vision for last years. Two dimensional action recognition methods are facing serious challenges such as occlusion and missing the third dimension of data. Development of depth sensors has made it feasible to track positions of human body joints over time. This paper proposes a novel method of action recognition which uses temporal 3D skeletal Kinect data. This method introduces the definition of body states and then every action is modeled as a sequence of these states. The learning stage uses Fisher Linear Discriminant Analysis (LDA) to construct discriminant feature space for discriminating the body states. Moreover, this paper suggests the use of the Mahalonobis distance as an appropriate distance metric for the classification of the states of involuntary actions. Hidden Markov Model (HMM) is then used to model the temporal transition between the body states in each action. According to the results, this method significantly outperforms other popular methods, with recognition rate of 88.64% for eight different actions and up to 96.18% for classifying fall actions. version:1
arxiv-1705-01861 | Action Tubelet Detector for Spatio-Temporal Action Localization | http://arxiv.org/abs/1705.01861 | id:1705.01861 author:Vicky Kalogeiton, Philippe Weinzaepfel, Vittorio Ferrari, Cordelia Schmid category:cs.CV  published:2017-05-04 summary:Current state-of-the-art approaches for spatio-temporal action localization rely on detections at the frame level that are then linked or tracked across time. In this paper, we leverage the temporal continuity of videos instead of operating at the frame level. We propose the ACtion Tubelet detector (ACT-detector) that takes as input a sequence of frames and outputs tubelets, i.e., sequences of bounding boxes with associated scores. The same way state-of-the-art object detectors rely on anchor boxes, our ACT-detector is based on anchor cuboids. We build upon the SSD framework. Convolutional features are extracted for each frame, while scores and regressions are based on the temporal stacking of these features, thus exploiting information from a sequence. Our experimental results show that leveraging sequences of frames significantly improves detection performance over using individual frames. The gain of our tubelet detector can be explained by both more accurate scores and more precise localization. Our ACT-detector outperforms the state-of-the-art methods for frame-mAP and video-mAP on the J-HMDB and UCF-101 datasets, in particular at high overlap thresholds. version:3
arxiv-1708-06219 | On the approximation by single hidden layer feedforward neural networks with fixed weights | http://arxiv.org/abs/1708.06219 | id:1708.06219 author:Namig J. Guliyev, Vugar E. Ismailov category:cs.NE cs.IT math.IT math.NA  published:2017-08-21 summary:Feedforward neural networks have wide applicability in various disciplines of science due to their universal approximation property. Some authors have shown that single hidden layer feedforward neural networks (SLFNs) with fixed weights still possess the universal approximation property provided that approximated functions are univariate. But this phenomenon does not lay any restrictions on the number of neurons in the hidden layer. The more this number, the more the probability of the considered network to give precise results. In this note, we constructively prove that SLFNs with the fixed weight $1$ and two neurons in the hidden layer can approximate any continuous function on a compact subset of the real line. The applicability of this result is demonstrated in various numerical examples. Finally, we show that SLFNs with fixed weights cannot approximate all continuous multivariate functions. version:1
arxiv-1708-06185 | Seernet at EmoInt-2017: Tweet Emotion Intensity Estimator | http://arxiv.org/abs/1708.06185 | id:1708.06185 author:Venkatesh Duppada, Sushant Hiray category:cs.CL  published:2017-08-21 summary:The paper describes experiments on estimating emotion intensity in tweets using a generalized regressor system. The system combines lexical, syntactic and pre-trained word embedding features, trains them on general regressors and finally combines the best performing models to create an ensemble. The proposed system stood 3rd out of 22 systems in the leaderboard of WASSA-2017 Shared Task on Emotion Intensity. version:1
arxiv-1708-06131 | Evasion Attacks against Machine Learning at Test Time | http://arxiv.org/abs/1708.06131 | id:1708.06131 author:Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Srndic, Pavel Laskov, Giorgio Giacinto, Fabio Roli category:cs.CR cs.LG  published:2017-08-21 summary:In security-sensitive applications, the success of machine learning depends on a thorough vetting of their resistance to adversarial data. In one pertinent, well-motivated attack scenario, an adversary may attempt to evade a deployed system at test time by carefully manipulating attack samples. In this work, we present a simple but effective gradient-based approach that can be exploited to systematically assess the security of several, widely-used classification algorithms against evasion attacks. Following a recently proposed framework for security evaluation, we simulate attack scenarios that exhibit different risk levels for the classifier by increasing the attacker's knowledge of the system and her ability to manipulate attack samples. This gives the classifier designer a better picture of the classifier performance under evasion attacks, and allows him to perform a more informed model selection (or parameter setting). We evaluate our approach on the relevant security task of malware detection in PDF files, and show that such systems can be easily evaded. We also sketch some countermeasures suggested by our analysis. version:1
arxiv-1708-06128 | Revisiting knowledge transfer for training object class detectors | http://arxiv.org/abs/1708.06128 | id:1708.06128 author:Jasper Uijlings, Stefan Popov, Vittorio Ferrari category:cs.CV  published:2017-08-21 summary:We propose to revisit knowledge transfer for training object detectors on target classes with only weakly supervised training images. We present a unified knowledge transfer framework based on training a single neural network multi-class object detector over all source classes, organized in a semantic hierarchy. This provides proposal scoring functions at multiple levels in the hierarchy, which we use to guide object localization in the target training set. Compared to works using a manually engineered class-generic objectness measure as a vehicle for transfer, our learned top-level scoring function for 'entity' is much stronger. Compared to works that perform class-specific transfer from a few most related source classes to the target class, our framework enables to explore a broad rage of generality of transfer. Experiments on 200 object classes in the ILSVRC 2013 dataset show that our technique (1) leads to much greater performance improvements than manually engineered objectness; (2) outperforms the best reported transfer learning results on this dataset by a wide margin (+40% correct localization on the target training set, and +14% mAP on the target test set). version:1
arxiv-1708-06126 | e-Counterfeit: a mobile-server platform for document counterfeit detection | http://arxiv.org/abs/1708.06126 | id:1708.06126 author:Albert Berenguel, Oriol Ramos Terrades, Josep Lladós, Cristina Cañero category:cs.CV  published:2017-08-21 summary:This paper presents a novel application to detect counterfeit identity documents forged by a scan-printing operation. Texture analysis approaches are proposed to extract validation features from security background that is usually printed in documents as IDs or banknotes. The main contribution of this work is the end-to-end mobile-server architecture, which provides a service for non-expert users and therefore can be used in several scenarios. The system also provides a crowdsourcing mode so labeled images can be gathered, generating databases for incremental training of the algorithms. version:1
arxiv-1708-06118 | Distantly Supervised Road Segmentation | http://arxiv.org/abs/1708.06118 | id:1708.06118 author:Satoshi Tsutsui, Tommi Kerola, Shunta Saito category:cs.CV  published:2017-08-21 summary:We present an approach for road segmentation that only requires image-level annotations at training time. We leverage distant supervision, which allows us to train our model using images that are different from the target domain. Using large publicly available image databases as distant supervisors, we develop a simple method to automatically generate weak pixel-wise road masks. These are used to iteratively train a fully convolutional neural network, which produces our final segmentation model. We evaluate our method on the Cityscapes dataset, where we compare it with a fully supervised approach. Further, we discuss the trade-off between annotation cost and performance. Overall, our distantly supervised approach achieves 93.8% of the performance of the fully supervised approach, while using orders of magnitude less annotation work. version:1
arxiv-1708-05636 | What does a convolutional neural network recognize in the moon? | http://arxiv.org/abs/1708.05636 | id:1708.05636 author:Daigo Shoji category:cs.CV astro-ph.EP physics.geo-ph  published:2017-08-18 summary:Many people see a human face or animals in the pattern of the maria on the moon. Although the pattern corresponds to the actual variation in composition of the lunar surface, the culture and environment of each society influence the recognition of these objects (i.e., symbols) as specific entities. In contrast, a convolutional neural network (CNN) recognizes objects from characteristic shapes in a training data set. Using CNN, this study evaluates the probabilities of the pattern of lunar maria categorized into the shape of a crab, a lion and a hare. If Mare Frigoris (a dark band on the moon) is included in the lunar image, the lion is recognized. However, in an image without Mare Frigoris, the hare has the highest probability of recognition. Thus, the recognition of objects similar to the lunar pattern depends on which part of the lunar maria is taken into account. In human recognition, before we find similarities between the lunar maria and objects such as animals, we may be persuaded in advance to see a particular image from our culture and environment and then adjust the lunar pattern to the shape of the imagined object. version:2
arxiv-1708-06077 | ExSIS: Extended Sure Independence Screening for Ultrahigh-dimensional Linear Models | http://arxiv.org/abs/1708.06077 | id:1708.06077 author:Talal Ahmed, Waheed U. Bajwa category:math.ST cs.IT math.IT stat.ML stat.TH  published:2017-08-21 summary:Statistical inference can be computationally prohibitive in ultrahigh-dimensional linear models. Correlation-based variable screening, in which one leverages marginal correlations for removal of irrelevant variables from the model prior to statistical inference, can be used to overcome this challenge. Prior works on correlation-based variable screening either impose strong statistical priors on the linear model or assume specific post-screening inference methods. This paper first extends the analysis of correlation-based variable screening to arbitrary linear models and post-screening inference techniques. In particular, ($i$) it shows that a condition---termed the screening condition---is sufficient for successful correlation-based screening of linear models, and ($ii$) it provides insights into the dependence of marginal correlation-based screening on different problem parameters. Numerical experiments confirm that these insights are not mere artifacts of analysis; rather, they are reflective of the challenges associated with marginal correlation-based variable screening. Second, the paper explicitly derives the screening condition for two families of linear models, namely, sub-Gaussian linear models and arbitrary (random or deterministic) linear models. In the process, it establishes that---under appropriate conditions---it is possible to reduce the dimension of an ultrahigh-dimensional, arbitrary linear model to almost the sample size even when the number of active variables scales almost linearly with the sample size. version:1
arxiv-1708-06075 | Scientific Information Extraction with Semi-supervised Neural Tagging | http://arxiv.org/abs/1708.06075 | id:1708.06075 author:Yi Luan, Mari Ostendorf, Hannaneh Hajishirzi category:cs.CL  published:2017-08-21 summary:This paper addresses the problem of extracting keyphrases from scientific articles and categorizing them as corresponding to a task, process, or material. We cast the problem as sequence tagging and introduce semi-supervised methods to a neural tagging model, which builds on recent advances in named entity recognition. Since annotated training data is scarce in this domain, we introduce a graph-based semi-supervised algorithm together with a data selection scheme to leverage unannotated articles. Both inductive and transductive semi-supervised learning strategies outperform state-of-the-art information extraction performance on the 2017 SemEval Task 10 ScienceIE task. version:1
arxiv-1708-06068 | Vector Space Model as Cognitive Space for Text Classification | http://arxiv.org/abs/1708.06068 | id:1708.06068 author:Barathi Ganesh HB, Anand Kumar M, Soman KP category:cs.CL 68T50  published:2017-08-21 summary:In this era of digitization, knowing the user's sociolect aspects have become essential features to build the user specific recommendation systems. These sociolect aspects could be found by mining the user's language sharing in the form of text in social media and reviews. This paper describes about the experiment that was performed in PAN Author Profiling 2017 shared task. The objective of the task is to find the sociolect aspects of the users from their tweets. The sociolect aspects considered in this experiment are user's gender and native language information. Here user's tweets written in a different language from their native language are represented as Document - Term Matrix with document frequency as the constraint. Further classification is done using the Support Vector Machine by taking gender and native language as target classes. This experiment attains the average accuracy of 73.42% in gender prediction and 76.26% in the native language identification task. version:1
arxiv-1708-06046 | nuts-flow/ml: data pre-processing for deep learning | http://arxiv.org/abs/1708.06046 | id:1708.06046 author:S. Maetschke, R. Tennakoon, C. Vecchiola, R. Garnavi category:cs.LG cs.SE  published:2017-08-21 summary:Data preprocessing is a fundamental part of any machine learning application and frequently the most time-consuming aspect when developing a machine learning solution. Preprocessing for deep learning is characterized by pipelines that lazily load data and perform data transformation, augmentation, batching and logging. Many of these functions are common across applications but require different arrangements for training, testing or inference. Here we introduce a novel software framework named nuts-flow/ml that encapsulates common preprocessing operations as components, which can be flexibly arranged to rapidly construct efficient preprocessing pipelines for deep learning. version:1
arxiv-1708-06026 | DeepBreath: Deep Learning of Breathing Patterns for Automatic Stress Recognition using Low-Cost Thermal Imaging in Unconstrained Settings | http://arxiv.org/abs/1708.06026 | id:1708.06026 author:Youngjun Cho, Nadia Bianchi-Berthouze, Simon J. Julier category:cs.HC cs.CV physics.med-ph  published:2017-08-20 summary:We propose DeepBreath, a deep learning model which automatically recognises people's psychological stress level (mental overload) from their breathing patterns. Using a low cost thermal camera, we track a person's breathing patterns as temperature changes around his/her nostril. The paper's technical contribution is threefold. First of all, instead of creating hand-crafted features to capture aspects of the breathing patterns, we transform the uni-dimensional breathing signals into two dimensional respiration variability spectrogram (RVS) sequences. The spectrograms easily capture the complexity of the breathing dynamics. Second, a spatial pattern analysis based on a deep Convolutional Neural Network (CNN) is directly applied to the spectrogram sequences without the need of hand-crafting features. Finally, a data augmentation technique, inspired from solutions for over-fitting problems in deep learning, is applied to allow the CNN to learn with a small-scale dataset from short-term measurements (e.g., up to a few hours). The model is trained and tested with data collected from people exposed to two types of cognitive tasks (Stroop Colour Word Test, Mental Computation test) with sessions of different difficulty levels. Using normalised self-report as ground truth, the CNN reaches 84.59% accuracy in discriminating between two levels of stress and 56.52% in discriminating between three levels. In addition, the CNN outperformed powerful shallow learning methods based on a single layer neural network. Finally, the dataset of labelled thermal images will be open to the community. version:1
arxiv-1708-06025 | Portuguese Word Embeddings: Evaluating on Word Analogies and Natural Language Tasks | http://arxiv.org/abs/1708.06025 | id:1708.06025 author:Nathan Hartmann, Erick Fonseca, Christopher Shulby, Marcos Treviso, Jessica Rodrigues, Sandra Aluisio category:cs.CL  published:2017-08-20 summary:Word embeddings have been found to provide meaningful representations for words in an efficient way; therefore, they have become common in Natural Language Processing sys- tems. In this paper, we evaluated different word embedding models trained on a large Portuguese corpus, including both Brazilian and European variants. We trained 31 word embedding models using FastText, GloVe, Wang2Vec and Word2Vec. We evaluated them intrinsically on syntactic and semantic analogies and extrinsically on POS tagging and sentence semantic similarity tasks. The obtained results suggest that word analogies are not appropriate for word embedding evaluation; task-specific evaluations appear to be a better option. version:1
arxiv-1708-06023 | Joint Multi-view Face Alignment in the Wild | http://arxiv.org/abs/1708.06023 | id:1708.06023 author:Jiankang Deng, George Trigeorgis, Yuxiang Zhou, Stefanos Zafeiriou category:cs.CV  published:2017-08-20 summary:The de facto algorithm for facial landmark estimation involves running a face detector with a subsequent deformable model fitting on the bounding box. This encompasses two basic problems: i) the detection and deformable fitting steps are performed independently, while the detector might not provide best-suited initialisation for the fitting step, ii) the face appearance varies hugely across different poses, which makes the deformable face fitting very challenging and thus distinct models have to be used (\eg, one for profile and one for frontal faces). In this work, we propose the first, to the best of our knowledge, joint multi-view convolutional network to handle large pose variations across faces in-the-wild, and elegantly bridge face detection and facial landmark localisation tasks. Existing joint face detection and landmark localisation methods focus only on a very small set of landmarks. By contrast, our method can detect and align a large number of landmarks for semi-frontal (68 landmarks) and profile (39 landmarks) faces. We evaluate our model on a plethora of datasets including standard static image datasets such as IBUG, 300W, COFW, and the latest Menpo Benchmark for both semi-frontal and profile faces. Significant improvement over state-of-the-art methods on deformable face tracking is witnessed on 300VW benchmark. We also demonstrate state-of-the-art results for face detection on FDDB and MALF datasets. version:1
arxiv-1708-06022 | Learning to Paraphrase for Question Answering | http://arxiv.org/abs/1708.06022 | id:1708.06022 author:Li Dong, Jonathan Mallinson, Siva Reddy, Mirella Lapata category:cs.CL  published:2017-08-20 summary:Question answering (QA) systems are sensitive to the many different ways natural language expresses the same information need. In this paper we turn to paraphrases as a means of capturing this knowledge and present a general framework which learns felicitous paraphrases for various QA tasks. Our method is trained end-to-end using question-answer pairs as a supervision signal. A question and its paraphrases serve as input to a neural scoring model which assigns higher weights to linguistic expressions most likely to yield correct answers. We evaluate our approach on QA over Freebase and answer sentence selection. Experimental results on three datasets show that our framework consistently improves performance, achieving competitive results despite the use of simple QA models. version:1
arxiv-1708-06020 | Improving Deep Learning using Generic Data Augmentation | http://arxiv.org/abs/1708.06020 | id:1708.06020 author:Luke Taylor, Geoff Nitschke category:cs.LG stat.ML  published:2017-08-20 summary:Deep artificial neural networks require a large corpus of training data in order to effectively learn, where collection of such training data is often expensive and laborious. Data augmentation overcomes this issue by artificially inflating the training set with label preserving transformations. Recently there has been extensive use of generic data augmentation to improve Convolutional Neural Network (CNN) task performance. This study benchmarks various popular data augmentation schemes to allow researchers to make informed decisions as to which training methods are most appropriate for their data sets. Various geometric and photometric schemes are evaluated on a coarse-grained data set using a relatively simple CNN. Experimental results, run using 4-fold cross-validation and reported in terms of Top-1 and Top-5 accuracy, indicate that cropping in geometric augmentation significantly increases CNN task performance. version:1
arxiv-1708-06008 | Boltzmann machines and energy-based models | http://arxiv.org/abs/1708.06008 | id:1708.06008 author:Takayuki Osogami category:cs.NE  published:2017-08-20 summary:We review Boltzmann machines and energy-based models. A Boltzmann machine defines a probability distribution over binary-valued patterns. One can learn parameters of a Boltzmann machine via gradient based approaches in a way that log likelihood of data is increased. The gradient and Laplacian of a Boltzmann machine admit beautiful mathematical representations, although computing them is in general intractable. This intractability motivates approximate methods, including Gibbs sampler and contrastive divergence, and tractable alternatives, namely energy-based models. version:1
arxiv-1708-05992 | LSTM Network for Inflected Abbreviation Expansion | http://arxiv.org/abs/1708.05992 | id:1708.05992 author:Piotr Żelasko category:cs.CL  published:2017-08-20 summary:In this paper, the problem of recovery of morphological information lost in abbreviated forms is addressed with a focus on highly inflected languages. Evidence is presented that the correct inflected form of an expanded abbreviation can in many cases be deduced solely from morphosyntactic tags of the context. The prediction model is a deep bidirectional LSTM network with tag embedding. The network is trained on over 10 million words from the Polish Sejm Corpus and achieves 74.2\% prediction accuracy on a smaller, but more general National Corpus of Polish. Analysis of errors suggests that performance in this task may improve if some prior knowledge about the abbreviated word is incorporated into the model. version:1
arxiv-1708-05987 | Perceptual audio loss function for deep learning | http://arxiv.org/abs/1708.05987 | id:1708.05987 author:Dan Elbaz, Michael Zibulevsky category:cs.SD cs.LG  published:2017-08-20 summary:PESQ and POLQA , are standards are standards for automated assessment of voice quality of speech as experienced by human beings. The predictions of those objective measures should come as close as possible to subjective quality scores as obtained in subjective listening tests. Wavenet is a deep neural network originally developed as a deep generative model of raw audio wave-forms. Wavenet architecture is based on dilated causal convolutions, which exhibit very large receptive fields. In this short paper we suggest using the Wavenet architecture, in particular its large receptive filed in order to learn PESQ algorithm. By doing so we can use it as a differentiable loss function for speech enhancement. version:1
arxiv-1708-05979 | An Efficient Single Chord-based Accumulation Technique (SCA) to Detect More Reliable Corners | http://arxiv.org/abs/1708.05979 | id:1708.05979 author:Mohammad Asiful Hossain, Abdul Kawsar Tushar, Shofiullah Babor category:cs.CV  published:2017-08-20 summary:Corner detection is a vital operation in numerous computer vision applications. The Chord-to-Point Distance Accumulation (CPDA) detector is recognized as the contour-based corner detector producing the lowest localization error while localizing corners in an image. However, in our experiment part, we demonstrate that CPDA detector often misses some potential corners. Moreover, the detection algorithm of CPDA is computationally costly. In this paper, We focus on reducing localization error as well as increasing average repeatability. The preprocessing and refinements steps of proposed process are similar to CPDA. Our experimental results will show the effectiveness and robustness of proposed process over CPDA. version:1
arxiv-1708-05974 | Shapelet-based Sparse Representation for Landcover Classification of Hyperspectral Images | http://arxiv.org/abs/1708.05974 | id:1708.05974 author:Ribana Roscher, Björn Waske category:cs.CV  published:2017-08-20 summary:This paper presents a sparse representation-based classification approach with a novel dictionary construction procedure. By using the constructed dictionary sophisticated prior knowledge about the spatial nature of the image can be integrated. The approach is based on the assumption that each image patch can be factorized into characteristic spatial patterns, also called shapelets, and patch-specific spectral information. A set of shapelets is learned in an unsupervised way and spectral information are embodied by training samples. A combination of shapelets and spectral information are represented in an undercomplete spatial-spectral dictionary for each individual patch, where the elements of the dictionary are linearly combined to a sparse representation of the patch. The patch-based classification is obtained by means of the representation error. Experiments are conducted on three well-known hyperspectral image datasets. They illustrate that our proposed approach shows superior results in comparison to sparse representation-based classifiers that use only limited spatial information and behaves competitively with or better than state-of-the-art classifiers utilizing spatial information and kernelized sparse representation-based classifiers. version:1
arxiv-1708-05966 | Incremental Import Vector Machines for Classifying Hyperspectral Data | http://arxiv.org/abs/1708.05966 | id:1708.05966 author:Ribana Roscher, Björn Waske, Wolfgang Förstner category:cs.CV  published:2017-08-20 summary:In this paper we propose an incremental learning strategy for import vector machines (IVM), which is a sparse kernel logistic regression approach. We use the procedure for the concept of self-training for sequential classification of hyperspectral data. The strategy comprises the inclusion of new training samples to increase the classification accuracy and the deletion of non-informative samples to be memory- and runtime-efficient. Moreover, we update the parameters in the incremental IVM model without re-training from scratch. Therefore, the incremental classifier is able to deal with large data sets. The performance of the IVM in comparison to support vector machines (SVM) is evaluated in terms of accuracy and experiments are conducted to assess the potential of the probabilistic outputs of the IVM. Experimental results demonstrate that the IVM and SVM perform similar in terms of classification accuracy. However, the number of import vectors is significantly lower when compared to the number of support vectors and thus, the computation time during classification can be decreased. Moreover, the probabilities provided by IVM are more reliable, when compared to the probabilistic information, derived from an SVM's output. In addition, the proposed self-training strategy can increase the classification accuracy. Overall, the IVM and the its incremental version is worthwhile for the classification of hyperspectral data. version:1
arxiv-1708-05963 | Neural Networks Compression for Language Modeling | http://arxiv.org/abs/1708.05963 | id:1708.05963 author:Artem M. Grachev, Dmitry I. Ignatov, Andrey V. Savchenko category:stat.ML cs.CL cs.LG cs.NE 62M45  68T50  published:2017-08-20 summary:In this paper, we consider several compression techniques for the language modeling problem based on recurrent neural networks (RNNs). It is known that conventional RNNs, e.g, LSTM-based networks in language modeling, are characterized with either high space complexity or substantial inference time. This problem is especially crucial for mobile applications, in which the constant interaction with the remote server is inappropriate. By using the Penn Treebank (PTB) dataset we compare pruning, quantization, low-rank factorization, tensor train decomposition for LSTM networks in terms of model size and suitability for fast inference. version:1
arxiv-1708-05956 | An End-to-End Trainable Neural Network Model with Belief Tracking for Task-Oriented Dialog | http://arxiv.org/abs/1708.05956 | id:1708.05956 author:Bing Liu, Ian Lane category:cs.CL  published:2017-08-20 summary:We present a novel end-to-end trainable neural network model for task-oriented dialog systems. The model is able to track dialog state, issue API calls to knowledge base (KB), and incorporate structured KB query results into system responses to successfully complete task-oriented dialogs. The proposed model produces well-structured system responses by jointly learning belief tracking and KB result processing conditioning on the dialog history. We evaluate the model in a restaurant search domain using a dataset that is converted from the second Dialog State Tracking Challenge (DSTC2) corpus. Experiment results show that the proposed model can robustly track dialog state given the dialog history. Moreover, our model demonstrates promising results in producing appropriate system responses, outperforming prior end-to-end trainable neural network models using per-response accuracy evaluation metrics. version:1
arxiv-1708-05943 | Neural Machine Translation with Extended Context | http://arxiv.org/abs/1708.05943 | id:1708.05943 author:Jörg Tiedemann, Yves Scherrer category:cs.CL  published:2017-08-20 summary:We investigate the use of extended context in attention-based neural machine translation. We base our experiments on translated movie subtitles and discuss the effect of increasing the segments beyond single translation units. We study the use of extended source language context as well as bilingual context extensions. The models learn to distinguish between information from different segments and are surprisingly robust with respect to translation quality. In this pilot study, we observe interesting cross-sentential attention patterns that improve textual coherence in translation at least in some selected cases. version:1
arxiv-1708-05942 | The Helsinki Neural Machine Translation System | http://arxiv.org/abs/1708.05942 | id:1708.05942 author:Robert Östling, Yves Scherrer, Jörg Tiedemann, Gongbo Tang, Tommi Nieminen category:cs.CL  published:2017-08-20 summary:We introduce the Helsinki Neural Machine Translation system (HNMT) and how it is applied in the news translation task at WMT 2017, where it ranked first in both the human and automatic evaluations for English--Finnish. We discuss the success of English--Finnish translations and the overall advantage of NMT over a strong SMT baseline. We also discuss our submissions for English--Latvian, English--Chinese and Chinese--English. version:1
arxiv-1708-01383 | Convergence of Variance-Reduced Stochastic Learning under Random Reshuffling | http://arxiv.org/abs/1708.01383 | id:1708.01383 author:Bicheng Ying, Kun Yuan, Ali H. Sayed category:cs.LG math.OC stat.ML  published:2017-08-04 summary:Several useful variance-reduced stochastic gradient algorithms, such as SVRG, SAGA, Finito, and SAG, have been proposed to minimize empirical risks with linear convergence properties to the exact minimizers. The existing convergence results assume uniform data sampling with replacement. However, it has been observed that random reshuffling can deliver superior performance. No formal proofs or guarantees of exact convergence exist for variance-reduced algorithms under random reshuffling. This paper resolves this open convergence issue and provides the first theoretical guarantee of linear convergence under random reshuffling for SAGA; the argument is also adaptable to other variance-reduced algorithms. Under random reshuffling, the paper further proposes a new amortized variance-reduced gradient (AVRG) algorithm with constant storage requirements compared to SAGA and with balanced gradient computations compared to SVRG. The balancing in computations are attained by amortizing the full gradient calculation across all iterations. AVRG is also shown analytically to converge linearly. version:2
arxiv-1708-08988 | Dual-fisheye lens stitching for 360-degree imaging | http://arxiv.org/abs/1708.08988 | id:1708.08988 author:Tuan Ho, Madhukar Budagavi category:cs.CV cs.MM  published:2017-08-20 summary:Dual-fisheye lens cameras have been increasingly used for 360-degree immersive imaging. However, the limited overlapping field of views and misalignment between the two lenses give rise to visible discontinuities in the stitching boundaries. This paper introduces a novel method for dual-fisheye camera stitching that adaptively minimizes the discontinuities in the overlapping regions to generate full spherical 360-degree images. Results show that this approach can produce good quality stitched images for Samsung Gear 360 -- a dual-fisheye camera, even with hard-to-stitch objects in the stitching borders. version:1
arxiv-1708-05924 | A Deep Q-Network for the Beer Game with Partial Information | http://arxiv.org/abs/1708.05924 | id:1708.05924 author:Afshin Oroojlooyjadid, MohammadReza Nazari, Lawrence Snyder, Martin Takáč category:cs.LG cs.MA  published:2017-08-20 summary:The beer game is a decentralized, multi-agent, cooperative problem that can be modeled as a serial supply chain network in which agents cooperatively attempt to minimize the total cost of the network even though each agent can only observe its own local information. We develop a variant of the Deep Q-Network algorithm to solve this problem. Extensive numerical experiment show the effectiveness of our algorithm. Unlike most algorithms in literature, our algorithm does not have any limits on the parameter values, and it provides good solutions even if the agents do not follow a rational policy. The algorithm can be extended to other decentralized multi-agent cooperative games with partially observed information, which is a common type of situation in supply chain problems. version:1
arxiv-1708-05917 | Accelerating Kernel Classifiers Through Borders Mapping | http://arxiv.org/abs/1708.05917 | id:1708.05917 author:Peter Mills category:stat.ML cs.LG  published:2017-08-20 summary:Support vector machines (SVM) and other kernel techniques represent a family of powerful statistical classification methods with high accuracy and broad applicability. Because they use all or a significant portion of the training data, however, they can be slow, especially for large problems. Piecewise linear classifiers are similarly versatile, yet have the additional advantages of simplicity, ease of interpretation and, if the number of component linear classifiers is not too large, speed. Here we show how a simple, piecewise linear classifier can be trained from a kernel-based classifier in order to improve the classification speed. The method works by finding the root of the difference in conditional probabilities between pairs of opposite classes to build up a representation of the decision boundary. When tested on 17 different datasets, it succeeded in improving the classification speed of a SVM for 9 of them by factors as high as 88 times or more. The method is best suited to problems with continuum features data and smooth probability functions. Because the component linear classifiers are built up individually from an existing classifier, rather than through a simultaneous optimization procedure, the classifier is also fast to train. version:1
arxiv-1708-05907 | Electricity Theft Detection using Machine Learning | http://arxiv.org/abs/1708.05907 | id:1708.05907 author:Niklas Dahringer category:cs.CR cs.CY cs.LG  published:2017-08-19 summary:Non-technical losses (NTL) in electric power grids arise through electricity theft, broken electric meters or billing errors. They can harm the power supplier as well as the whole economy of a country through losses of up to 40% of the total power distribution. For NTL detection, researchers use artificial intelligence to analyse data. This work is about improving the extraction of more meaningful features from a data set. With these features, the prediction quality will increase. version:1
arxiv-1704-07050 | Using Global Constraints and Reranking to Improve Cognates Detection | http://arxiv.org/abs/1704.07050 | id:1704.07050 author:Michael Bloodgood, Benjamin Strauss category:cs.CL cs.LG stat.ML  published:2017-04-24 summary:Global constraints and reranking have not been used in cognates detection research to date. We propose methods for using global constraints by performing rescoring of the score matrices produced by state of the art cognates detection systems. Using global constraints to perform rescoring is complementary to state of the art methods for performing cognates detection and results in significant performance improvements beyond current state of the art performance on publicly available datasets with different language pairs and various conditions such as different levels of baseline state of the art performance and different data size conditions, including with more realistic large data size conditions than have been evaluated with in the past. version:2
arxiv-1708-05894 | An Improved Multi-Output Gaussian Process RNN with Real-Time Validation for Early Sepsis Detection | http://arxiv.org/abs/1708.05894 | id:1708.05894 author:Joseph Futoma, Sanjay Hariharan, Mark Sendak, Nathan Brajer, Meredith Clement, Armando Bedoya, Cara O'Brien, Katherine Heller category:stat.ML stat.AP stat.ME  published:2017-08-19 summary:Sepsis is a poorly understood and potentially life-threatening complication that can occur as a result of infection. Early detection and treatment improves patient outcomes, and as such it poses an important challenge in medicine. In this work, we develop a flexible classifier that leverages streaming lab results, vitals, and medications to predict sepsis before it occurs. We model patient clinical time series with multi-output Gaussian processes, maintaining uncertainty about the physiological state of a patient while also imputing missing values. The mean function takes into account the effects of medications administered on the trajectories of the physiological variables. Latent function values from the Gaussian process are then fed into a deep recurrent neural network to classify patient encounters as septic or not, and the overall model is trained end-to-end using back-propagation. We train and validate our model on a large dataset of 18 months of heterogeneous inpatient stays from the Duke University Health System, and develop a new "real-time" validation scheme for simulating the performance of our model as it will actually be used. Our proposed method substantially outperforms clinical baselines, and improves on a previous related model for detecting sepsis. Our model's predictions will be displayed in a real-time analytics dashboard to be used by a sepsis rapid response team to help detect and improve treatment of sepsis. version:1
arxiv-1708-05891 | Arabic Multi-Dialect Segmentation: bi-LSTM-CRF vs. SVM | http://arxiv.org/abs/1708.05891 | id:1708.05891 author:Mohamed Eldesouki, Younes Samih, Ahmed Abdelali, Mohammed Attia, Hamdy Mubarak, Kareem Darwish, Kallmeyer Laura category:cs.CL  published:2017-08-19 summary:Arabic word segmentation is essential for a variety of NLP applications such as machine translation and information retrieval. Segmentation entails breaking words into their constituent stems, affixes and clitics. In this paper, we compare two approaches for segmenting four major Arabic dialects using only several thousand training examples for each dialect. The two approaches involve posing the problem as a ranking problem, where an SVM ranker picks the best segmentation, and as a sequence labeling problem, where a bi-LSTM RNN coupled with CRF determines where best to segment words. We are able to achieve solid segmentation results for all dialects using rather limited training data. We also show that employing Modern Standard Arabic data for domain adaptation and assuming context independence improve overall results. version:1
arxiv-1708-06708 | A rule based algorithm for detecting negative words in Persian | http://arxiv.org/abs/1708.06708 | id:1708.06708 author:Reza Takhshid, Adel Rahimi category:cs.CL  published:2017-08-19 summary:In this paper, we present a novel method for detecting negative words in Persian. We first used an algorithm to an exceptions list which was later modified by hand. We then used the mentioned lists and a Persian polarity corpus in our rule based algorithm to detect negative words. version:1
arxiv-1708-05873 | What Drives the International Development Agenda? An NLP Analysis of the United Nations General Debate 1970-2016 | http://arxiv.org/abs/1708.05873 | id:1708.05873 author:Alexander Baturo, Niheer Dasandi, Slava J. Mikhaylov category:cs.CL cs.SI  published:2017-08-19 summary:There is surprisingly little known about agenda setting for international development in the United Nations (UN) despite it having a significant influence on the process and outcomes of development efforts. This paper addresses this shortcoming using a novel approach that applies natural language processing techniques to countries' annual statements in the UN General Debate. Every year UN member states deliver statements during the General Debate on their governments' perspective on major issues in world politics. These speeches provide invaluable information on state preferences on a wide range of issues, including international development, but have largely been overlooked in the study of global politics. This paper identifies the main international development topics that states raise in these speeches between 1970 and 2016, and examine the country-specific drivers of international development rhetoric. version:1
arxiv-1708-05869 | UE4Sim: A Photo-Realistic Simulator for Computer Vision Applications | http://arxiv.org/abs/1708.05869 | id:1708.05869 author:Matthias Mueller, Vincent Casser, Jean Lahoud, Neil Smith, Bernard Ghanem category:cs.CV  published:2017-08-19 summary:We present a photo-realistic training and evaluation simulator (UE4Sim) with extensive applications across various fields of computer vision. Built on top of the Unreal Engine, the simulator integrates full featured physics based cars, unmanned aerial vehicles (UAVs), and animated human actors in diverse urban and suburban 3D environments. We demonstrate the versatility of the simulator with two case studies: autonomous UAV-based tracking of moving objects and autonomous driving using supervised learning. The simulator fully integrates both several state-of-the-art tracking algorithms with a benchmark evaluation tool and a deep neural network (DNN) architecture for training vehicles to drive autonomously. It generates synthetic photo-realistic datasets with automatic ground truth annotations to easily extend existing real-world datasets and provides extensive synthetic data variety through its ability to reconfigure synthetic worlds on the fly using an automatic world generation tool. version:1
arxiv-1708-05857 | The CLaC Discourse Parser at CoNLL-2015 | http://arxiv.org/abs/1708.05857 | id:1708.05857 author:Majid Laali, Elnaz Davoodi, Leila Kosseim category:cs.CL  published:2017-08-19 summary:This paper describes our submission (kosseim15) to the CoNLL-2015 shared task on shallow discourse parsing. We used the UIMA framework to develop our parser and used ClearTK to add machine learning functionality to the UIMA framework. Overall, our parser achieves a result of 17.3 F1 on the identification of discourse relations on the blind CoNLL-2015 test set, ranking in sixth place. version:1
arxiv-1708-05851 | Image2song: Song Retrieval via Bridging Image Content and Lyric Words | http://arxiv.org/abs/1708.05851 | id:1708.05851 author:Xuelong Li, Di Hu, Xiaoqiang Lu category:cs.CV cs.IR cs.MM  published:2017-08-19 summary:Image is usually taken for expressing some kinds of emotions or purposes, such as love, celebrating Christmas. There is another better way that combines the image and relevant song to amplify the expression, which has drawn much attention in the social network recently. Hence, the automatic selection of songs should be expected. In this paper, we propose to retrieve semantic relevant songs just by an image query, which is named as the image2song problem. Motivated by the requirements of establishing correlation in semantic/content, we build a semantic-based song retrieval framework, which learns the correlation between image content and lyric words. This model uses a convolutional neural network to generate rich tags from image regions, a recurrent neural network to model lyric, and then establishes correlation via a multi-layer perceptron. To reduce the content gap between image and lyric, we propose to make the lyric modeling focus on the main image content via a tag attention. We collect a dataset from the social-sharing multimodal data to study the proposed problem, which consists of (image, music clip, lyric) triplets. We demonstrate that our proposed model shows noticeable results in the image2song retrieval task and provides suitable songs. Besides, the song2image task is also performed. version:1
arxiv-1708-05828 | High Voltage Insulator Surface Evaluation Using Image Processing | http://arxiv.org/abs/1708.05828 | id:1708.05828 author:Damira Pernebayeva, Mehdi Bagheri, Alex Pappachen James category:cs.CV  published:2017-08-19 summary:High voltage insulators are widely deployed in power systems to isolate the live- and dead-part of overhead lines as well as to support the power line conductors mechanically. Permanent, secure and safe operation of power transmission lines require that the high voltage insulators are inspected and monitor, regularly. Severe environment conditions will influence insulator surface and change creepage distance. Consequently, power utilities and transmission companies face significant problem in operation due to insulator damage or contamination. In this study, a new technique is developed for real-time inspection of insulator and estimating the snow, ice and water over the insulator surface which can be a potential risk of operation breakdown. To examine the proposed system, practical experiment is conducted using ceramic insulator for capturing the images with snow, ice and wet surface conditions. Gabor and Standard deviation filters are utilized for image feature extraction. The best achieved recognition accuracy rate was 87% using statistical approach the Standard deviation. version:1
arxiv-1708-05827 | Visual Forecasting by Imitating Dynamics in Natural Sequences | http://arxiv.org/abs/1708.05827 | id:1708.05827 author:Kuo-Hao Zeng, William B. Shen, De-An Huang, Min Sun, Juan Carlos Niebles category:cs.CV  published:2017-08-19 summary:We introduce a general framework for visual forecasting, which directly imitates visual sequences without additional supervision. As a result, our model can be applied at several semantic levels and does not require any domain knowledge or handcrafted features. We achieve this by formulating visual forecasting as an inverse reinforcement learning (IRL) problem, and directly imitate the dynamics in natural sequences from their raw pixel values. The key challenge is the high-dimensional and continuous state-action space that prohibits the application of previous IRL algorithms. We address this computational bottleneck by extending recent progress in model-free imitation with trainable deep feature representations, which (1) bypasses the exhaustive state-action pair visits in dynamic programming by using a dual formulation and (2) avoids explicit state sampling at gradient computation using a deep feature reparametrization. This allows us to apply IRL at scale and directly imitate the dynamics in high-dimensional continuous visual sequences from the raw pixel values. We evaluate our approach at three different level-of-abstraction, from low level pixels to higher level semantics: future frame generation, action anticipation, visual story forecasting. At all levels, our approach outperforms existing methods. version:1
arxiv-1708-05234 | FaceBoxes: A CPU Real-time Face Detector with High Accuracy | http://arxiv.org/abs/1708.05234 | id:1708.05234 author:Shifeng Zhang, Xiangyu Zhu, Zhen Lei, Hailin Shi, Xiaobo Wang, Stan Z. Li category:cs.CV  published:2017-08-17 summary:Although tremendous strides have been made in face detection, one of the remaining open challenges is to achieve real-time speed on the CPU as well as maintain high performance, since effective models for face detection tend to be computationally prohibitive. To address this challenge, we propose a novel face detector, named FaceBoxes, with superior performance on both speed and accuracy. Specifically, our method has a lightweight yet powerful network structure that consists of the Rapidly Digested Convolutional Layers (RDCL) and the Multiple Scale Convolutional Layers (MSCL). The RDCL is designed to enable FaceBoxes to achieve real-time speed on the CPU. The MSCL aims at enriching the receptive fields and discretizing anchors over different layers to handle faces of various scales. Besides, we propose a new anchor densification strategy to make different types of anchors have the same density on the image, which significantly improves the recall rate of small faces. As a consequence, the proposed detector runs at 20 FPS on a single CPU core and 125 FPS using a GPU for VGA-resolution images. Moreover, the speed of FaceBoxes is invariant to the number of faces. We comprehensively evaluate this method and present state-of-the-art detection performance on several face detection benchmark datasets, including the AFW, PASCAL face, and FDDB. version:2
arxiv-1708-05821 | Analysing Soccer Games with Clustering and Conceptors | http://arxiv.org/abs/1708.05821 | id:1708.05821 author:Olivia Michael, Oliver Obst, Falk Schmidsberger, Frieder Stolzenburg category:cs.LG  published:2017-08-19 summary:We present a new approach for identifying situations and behaviours, which we call "moves", from soccer games in the 2D simulation league. Being able to identify key situations and behaviours are useful capabilities for analysing soccer matches, anticipating opponent behaviours to aid selection of appropriate tactics, and also as a prerequisite for automatic learning of behaviours and policies. To support a wide set of strategies, our goal is to identify situations from data, in an unsupervised way without making use of pre-defined soccer specific concepts such as "pass" or "dribble". The recurrent neural networks we use in our approach act as a high-dimensional projection of the recent history of a situation on the field. Similar situations, i.e., with similar histories, are found by clustering of network states. The same networks are also used to learn so-called conceptors, that are lower-dimensional manifolds that describe trajectories through a high-dimensional state space that enable situation-specific predictions from the same neural network. With the proposed approach, we can segment games into sequences of situations that are learnt in an unsupervised way, and learn conceptors that are useful for the prediction of the near future of the respective situation. version:1
arxiv-1708-05812 | Discovery of Visual Semantics by Unsupervised and Self-Supervised Representation Learning | http://arxiv.org/abs/1708.05812 | id:1708.05812 author:Gustav Larsson category:cs.CV  published:2017-08-19 summary:The success of deep learning in computer vision is rooted in the ability of deep networks to scale up model complexity as demanded by challenging visual tasks. As complexity is increased, so is the need for large amounts of labeled data to train the model. This is associated with a costly human annotation effort. To address this concern, with the long-term goal of leveraging the abundance of cheap unlabeled data, we explore methods of unsupervised "pre-training." In particular, we propose to use self-supervised automatic image colorization. We show that traditional methods for unsupervised learning, such as layer-wise clustering or autoencoders, remain inferior to supervised pre-training. In search for an alternative, we develop a fully automatic image colorization method. Our method sets a new state-of-the-art in revitalizing old black-and-white photography, without requiring human effort or expertise. Additionally, it gives us a method for self-supervised representation learning. In order for the model to appropriately re-color a grayscale object, it must first be able to identify it. This ability, learned entirely self-supervised, can be used to improve other visual tasks, such as classification and semantic segmentation. As a future direction for self-supervision, we investigate if multiple proxy tasks can be combined to improve generalization. This turns out to be a challenging open problem. We hope that our contributions to this endeavor will provide a foundation for future efforts in making self-supervision compete with supervised pre-training. version:1
arxiv-1708-05803 | Measuring the Effect of Discourse Relations on Blog Summarization | http://arxiv.org/abs/1708.05803 | id:1708.05803 author:Shamima Mithun, Leila Kosseim category:cs.CL  published:2017-08-19 summary:The work presented in this paper attempts to evaluate and quantify the use of discourse relations in the context of blog summarization and compare their use to more traditional and factual texts. Specifically, we measured the usefulness of 6 discourse relations - namely comparison, contingency, illustration, attribution, topic-opinion, and attributive for the task of text summarization from blogs. We have evaluated the effect of each relation using the TAC 2008 opinion summarization dataset and compared them with the results with the DUC 2007 dataset. The results show that in both textual genres, contingency, comparison, and illustration relations provide a significant improvement on summarization content; while attribution, topic-opinion, and attributive relations do not provide a consistent and significant improvement. These results indicate that, at least for summarization, discourse relations are just as useful for informal and affective texts as for more traditional news articles. version:1
arxiv-1708-05801 | ClaC: Semantic Relatedness of Words and Phrases | http://arxiv.org/abs/1708.05801 | id:1708.05801 author:Reda Siblini, Leila Kosseim category:cs.CL  published:2017-08-19 summary:The measurement of phrasal semantic relatedness is an important metric for many natural language processing applications. In this paper, we present three approaches for measuring phrasal semantics, one based on a semantic network model, another on a distributional similarity model, and a hybrid between the two. Our hybrid approach achieved an F-measure of 77.4% on the task of evaluating the semantic similarity of words and compositional phrases. version:1
arxiv-1708-05800 | On the Contribution of Discourse Structure on Text Complexity Assessment | http://arxiv.org/abs/1708.05800 | id:1708.05800 author:Elnaz Davoodi, Leila Kosseim category:cs.CL  published:2017-08-19 summary:This paper investigates the influence of discourse features on text complexity assessment. To do so, we created two data sets based on the Penn Discourse Treebank and the Simple English Wikipedia corpora and compared the influence of coherence, cohesion, surface, lexical and syntactic features to assess text complexity. Results show that with both data sets coherence features are more correlated to text complexity than the other types of features. In addition, feature selection revealed that with both data sets the top most discriminating feature is a coherence feature. version:1
arxiv-1708-05798 | The CLaC Discourse Parser at CoNLL-2016 | http://arxiv.org/abs/1708.05798 | id:1708.05798 author:Majid Laali, Andre Cianflone, Leila Kosseim category:cs.CL  published:2017-08-19 summary:This paper describes our submission "CLaC" to the CoNLL-2016 shared task on shallow discourse parsing. We used two complementary approaches for the task. A standard machine learning approach for the parsing of explicit relations, and a deep learning approach for non-explicit relations. Overall, our parser achieves an F1-score of 0.2106 on the identification of discourse relations (0.3110 for explicit relations and 0.1219 for non-explicit relations) on the blind CoNLL-2016 test set. version:1
arxiv-1708-05797 | CLaC @ QATS: Quality Assessment for Text Simplification | http://arxiv.org/abs/1708.05797 | id:1708.05797 author:Elnaz Davoodi, Leila Kosseim category:cs.CL  published:2017-08-19 summary:This paper describes our approach to the 2016 QATS quality assessment shared task. We trained three independent Random Forest classifiers in order to assess the quality of the simplified texts in terms of grammaticality, meaning preservation and simplicity. We used the language model of Google-Ngram as feature to predict the grammaticality. Meaning preservation is predicted using two complementary approaches based on word embedding and WordNet synonyms. A wider range of features including TF-IDF, sentence length and frequency of cue phrases are used to evaluate the simplicity aspect. Overall, the accuracy of the system ranges from 33.33% for the overall aspect to 58.73% for grammaticality. version:1
arxiv-1708-05789 | Semi-supervised Conditional GANs | http://arxiv.org/abs/1708.05789 | id:1708.05789 author:Kumar Sricharan, Raja Bala, Matthew Shreve, Hui Ding, Kumar Saketh, Jin Sun category:stat.ML cs.LG  published:2017-08-19 summary:We introduce a new model for building conditional generative models in a semi-supervised setting to conditionally generate data given attributes by adapting the GAN framework. The proposed semi-supervised GAN (SS-GAN) model uses a pair of stacked discriminators to learn the marginal distribution of the data, and the conditional distribution of the attributes given the data respectively. In the semi-supervised setting, the marginal distribution (which is often harder to learn) is learned from the labeled + unlabeled data, and the conditional distribution is learned purely from the labeled data. Our experimental results demonstrate that this model performs significantly better compared to existing semi-supervised conditional GAN models. version:1
