arxiv-1701-07517 | Hardware Translation Coherence for Virtualized Systems | http://arxiv.org/abs/1701.07517 | id:1701.07517 author:Zi Yan, Guilherme Cox, Jan Vesely, Abhishek Bhattacharjee category:cs.AR  published:2017-01-25 summary:To improve system performance, modern operating systems (OSes) often undertake activities that require modification of virtual-to-physical page translation mappings. For example, the OS may migrate data between physical frames to defragment memory and enable superpages. The OS may migrate pages of data between heterogeneous memory devices. We refer to all such activities as page remappings. Unfortunately, page remappings are expensive. We show that translation coherence is a major culprit and that systems employing virtualization are especially badly affected by their overheads. In response, we propose hardware translation invalidation and coherence or HATRIC, a readily implementable hardware mechanism to piggyback translation coherence atop existing cache coherence protocols. We perform detailed studies using KVM-based virtualization, showing that HATRIC achieves up to 30% performance and 10% energy benefits, for per-CPU area overheads of 2%. We also quantify HATRIC's benefits on systems running Xen and find up to 33% performance improvements. version:2
arxiv-1702-04645 | A parallel implementation of the Synchronised Louvain method | http://arxiv.org/abs/1702.04645 | id:1702.04645 author:Benjamin ChiÃªm, Andine Havelange, Paul Van Dooren category:cs.DS cs.DC cs.SI  published:2017-02-15 summary:Community detection in networks is a very actual and important field of research with applications in many areas. But, given that the amount of processed data increases more and more, existing algorithms need to be adapted for very large graphs. The objective of this project was to parallelise the Synchronised Louvain Method, a community detection algorithm developed by Arnaud Browet, in order to improve its performances in terms of computation time and thus be able to faster detect communities in very large graphs. To reach this goal, we used the API OpenMP to parallelise the algorithm and then carried out performance tests. We studied the computation time and speedup of the parallelised algorithm and were able to bring out some qualitative trends. We obtained a great speedup, compared with the theoretical prediction of Amdahl law. To conclude, using the parallel implementation of the algorithm of Browet on large graphs seems to give good results, both in terms of computation time and speedup. Further tests should be carried out in order to obtain more quantitative results. version:1
arxiv-1702-04594 | Local Search for Minimum Weight Dominating Set with Two-Level Configuration Checking and Frequency Based Scoring Function | http://arxiv.org/abs/1702.04594 | id:1702.04594 author:Yiyuan Wang, Shaowei Cai, Minghao Yin category:cs.AI  published:2017-02-15 summary:The Minimum Weight Dominating Set (MWDS) problem is an important generalization of the Minimum Dominating Set (MDS) problem with extensive applications. This paper proposes a new local search algorithm for the MWDS problem, which is based on two new ideas. The first idea is a heuristic called two-level configuration checking (CC2), which is a new variant of a recent powerful configuration checking strategy (CC) for effectively avoiding the recent search paths. The second idea is a novel scoring function based on the frequency of being uncovered of vertices. Our algorithm is called CC2FS, according to the names of the two ideas. The experimental results show that, CC2FS performs much better than some state-of-the-art algorithms in terms of solution quality on a broad range of MWDS benchmarks. version:1
arxiv-1702-04584 | Developing an ontology for the access to the contents of an archival fonds: the case of the Catasto Gregoriano | http://arxiv.org/abs/1702.04584 | id:1702.04584 author:Lina Antonietta Coppola category:cs.AI cs.DL  published:2017-02-15 summary:The research was proposed to exploit and extend the relational and contextual nature of the information assets of the Catasto Gregoriano, kept at the Archivio di Stato in Rome. Developed within the MODEUS project (Making Open Data Effectively Usable), this study originates from the following key ideas of MODEUS: to require Open Data to be expressed in terms of an ontology, and to include such an ontology as a documentation of the data themselves. Thus, Open Data are naturally linked by means of the ontology, which meets the requirements of the Linked Open Data vision. version:1
arxiv-1702-05383 | Theorem Proving Based on Semantics of DNA Strand Graph | http://arxiv.org/abs/1702.05383 | id:1702.05383 author:Kumar S. Ray, Mandrita Mondal category:cs.AI  published:2017-02-15 summary:Because of several technological limitations of traditional silicon based computing, for past few years a paradigm shift, from silicon to carbon, is occurring in computational world. DNA computing has been considered to be quite promising in solving computational and reasoning problems by using DNA strands. Resolution, an important aspect of automated theorem proving and mathematical logic, is a rule of inference which leads to proof by contradiction technique for sentences in propositional logic and first-order logic. This can also be called refutation theorem-proving. In this paper we have shown how the theorem proving with resolution refutation by DNA computation can be represented by the semantics of process calculus and strand graph. version:1
arxiv-1610-02797 | Guidance algorithm for smooth trajectory tracking of a fixed wing UAV flying in wind flows | http://arxiv.org/abs/1610.02797 | id:1610.02797 author:Hector Garcia de Marina, Yuri A. Kapitanyuk, Murat Bronz, Gautier Hattenberger, Ming Cao category:cs.RO cs.SY  published:2016-10-10 summary:This paper presents an algorithm for solving the problem of tracking smooth curves by a fixed wing unmanned aerial vehicle travelling with a constant airspeed and under a constant wind disturbance. The algorithm is based on the idea of following a guiding vector field which is constructed from the implicit function that describes the desired (possibly time-varying) trajectory. The output of the algorithm can be directly expressed in terms of the bank angle of the UAV in order to achieve coordinated turns. Furthermore, the algorithm can be tuned offline such that physical constraints of the UAV, e.g. the maximum bank angle, will not be violated in a neighborhood of the desired trajectory. We provide the corresponding theoretical convergence analysis and performance results from actual flights. version:2
arxiv-1605-06588 | Optimal Number of Choices in Rating Contexts | http://arxiv.org/abs/1605.06588 | id:1605.06588 author:Sam Ganzfried category:cs.AI math.PR  published:2016-05-21 summary:In many settings people must give numerical scores to entities from a small discrete set. For instance, rating physical attractiveness from 1-5 on dating sites, or papers from 1-10 for conference reviewing. We study the problem of understanding when using a different number of options is optimal. For concreteness we assume the true underlying scores are integers from 1-100. We consider the case when scores are uniform random and Gaussian. We study when using 2, 3, 4, 5, and 10 options is optimal in these models. One may expect that using more options would always improve performance in this model, but we show that this is not necessarily the case, and that using fewer choices -- even just two -- can surprisingly be optimal in certain situations. While in theory for this setting it would be optimal to use all 100 options, in practice this is prohibitive, and it is preferable to utilize a smaller number of options due to humans' limited computational resources. Our results suggest that using a smaller number of options than is typical could be optimal in certain situations. This would have many potential applications, as settings requiring entities to be ranked by humans are ubiquitous. version:5
arxiv-1702-04474 | Leveraging cloud based big data analytics in knowledge management for enhanced decision making in organizations | http://arxiv.org/abs/1702.04474 | id:1702.04474 author:Mohammad Shorfuzzaman category:cs.DC cs.CY  published:2017-02-15 summary:In recent past, big data opportunities have gained much momentum to enhance knowledge management in organizations. However, big data due to its various properties like high volume, variety, and velocity can no longer be effectively stored and analyzed with traditional data management techniques to generate values for knowledge development. Hence, new technologies and architectures are required to store and analyze this big data through advanced data analytics and in turn generate vital real-time knowledge for effective decision making by organizations. More specifically, it is necessary to have a single infrastructure which provides common functionality of knowledge management, and flexible enough to handle different types of big data and big data analysis tasks. Cloud computing infrastructures capable of storing and processing large volume of data can be used for efficient big data processing because it minimizes the initial cost for the large-scale computing infrastructure demanded by big data analytics. This paper aims to explore the impact of big data analytics on knowledge management and proposes a cloud-based conceptual framework that can analyze big data in real time to facilitate enhanced decision making intended for competitive advantage. Thus, this framework will pave the way for organizations to explore the relationship between big data analytics and knowledge management which are mostly deemed as two distinct entities. version:1
arxiv-1702-04467 | Adding Concurrency to Smart Contracts | http://arxiv.org/abs/1702.04467 | id:1702.04467 author:Thomas Dickerson, Paul Gazzillo, Maurice Herlihy, Eric Koskinen category:cs.DC  published:2017-02-15 summary:Modern cryptocurrency systems, such as Ethereum, permit complex financial transactions through scripts called smart contracts. These smart contracts are executed many, many times, always without real concurrency. First, all smart contracts are serially executed by miners before appending them to the blockchain. Later, those contracts are serially re-executed by validators to verify that the smart contracts were executed correctly by miners. Serial execution limits system throughput and fails to exploit today's concurrent multicore and cluster architectures. Nevertheless, serial execution appears to be required: contracts share state, and contract programming languages have a serial semantics. This paper presents a novel way to permit miners and validators to execute smart contracts in parallel, based on techniques adapted from software transactional memory. Miners execute smart contracts speculatively in parallel, allowing non-conflicting contracts to proceed concurrently, and "discovering" a serializable concurrent schedule for a block's transactions, This schedule is captured and encoded as a deterministic fork-join program used by validators to re-execute the miner's parallel schedule deterministically but concurrently. Smart contract benchmarks run on a JVM with ScalaSTM show that a speedup of of 1.33x can be obtained for miners and 1.69x for validators with just three concurrent threads. version:1
arxiv-1701-08877 | 1.5 bit-per-stage 8-bit Pipelined CMOS A/D Converter for Neuromophic Vision Processor | http://arxiv.org/abs/1701.08877 | id:1701.08877 author:Yilei F. Li, Li Du category:cs.AR  published:2017-01-31 summary:Neuromorphic vision processor is an electronic implementation of vision algorithm processor on semiconductor. To image the world, a low-power CMOS image sensor array is required in the vision processor. The image sensor array is typically formed through photo diodes and analog to digital converter (ADC). To achieve low power acquisition, a low-power mid-resolution ADC is necessary. In this paper, a 1.8V, 8-bit, 166MS/s pipelined ADC was proposed in a 0.18 um CMOS technology. The ADC used operational amplifier sharing architecture to reduce power consumption and achieved maximum DNL of 0.24 LSB, maximum INL of 0.35 LSB, at a power consumption of 38.9mW. When input frequency is 10.4MHz, it achieved an SNDR 45.9dB, SFDR 50dB, and an ENOB of 7.33 bit. version:2
arxiv-1701-06741 | Variability-Aware Design for Energy Efficient Computational Artificial Intelligence Platform | http://arxiv.org/abs/1701.06741 | id:1701.06741 author:Rhonda P. Zhang category:cs.AR  published:2017-01-24 summary:Portable computing devices, which include tablets, smart phones and various types of wearable sensors, experienced a rapid development in recent years. One of the most critical limitations for these devices is the power consumption as they use batteries as the power supply. However, the bottleneck of the power saving schemes in both hardware design and software algorithm is the huge variability in power consumption. The variability is caused by a myriad of factors, including the manufacturing process, the ambient environment (temperature, humidity), the aging effects and etc. As the technology node scaled down to 28nm and even lower, the variability becomes more severe. As a result, a platform for variability characterization seems to be very necessary and helpful. version:3
arxiv-1609-05264 | Asynchronous and Dynamic Coverage Control Scheme for Persistent Surveillance Missions | http://arxiv.org/abs/1609.05264 | id:1609.05264 author:Jeffrey R. Peters, Sean J. Wang, Amit Surana, Francesco Bullo category:cs.MA cs.RO cs.SY I.2.11; I.2.9; J.2  published:2016-09-17 summary:A decomposition-based coverage control scheme is proposed for multi-agent, persistent surveillance missions operating in a communication-constrained, dynamic environment. The proposed approach decouples high-level task assignment from low-level motion planning in a modular framework. Coverage assignments and surveillance parameters are managed by a central base station, and transmitted to mobile agents via unplanned and asynchronous exchanges. Coverage updates promote load balancing, while maintaining geometric and temporal characteristics that allow effective pairing with generic path planners. Namely, the proposed scheme guarantees that (i) coverage regions are connected and collectively cover the environment, (ii) subregions may only go uncovered for bounded periods of time, (iii) collisions (or sensing overlaps) are inherently avoided, and (iv) under static event likelihoods, the collective coverage regions converge to a Pareto-optimal configuration. This management scheme is then paired with a generic path planner satisfying loose assumptions. The scheme is illustrated through simulated surveillance missions. version:2
arxiv-1702-04389 | Entropy Non-increasing Games for the Improvement of Dataflow Programming | http://arxiv.org/abs/1702.04389 | id:1702.04389 author:Norbert BÃ¡tfai, RenÃ¡tÃ³ Besenczi, GergÅ Bogacsovics, Fanny Monori category:cs.AI 68T01 I.2.1  published:2017-02-14 summary:In this article, we introduce a new conception of a family of esport games called Samu Entropy to try to improve dataflow program graphs like the ones that are based on Google's TensorFlow. Currently, the Samu Entropy project specifies only requirements for new esport games to be developed with particular attention to the investigation of the relationship between esport and artificial intelligence. It is quite obvious that there is a very close and natural relationship between esport games and artificial intelligence. Furthermore, the project Samu Entropy focuses not only on using artificial intelligence, but on creating AI in a new way. We present a reference game called Face Battle that implements the Samu Entropy requirements. version:1
arxiv-1702-04323 | Don't cry over spilled records: Memory elasticity of data-parallel applications and its application to cluster scheduling | http://arxiv.org/abs/1702.04323 | id:1702.04323 author:Calin Iorgulescu, Florin Dinu, Aunn Raza, Wajih Ul Hassan, Willy Zwaenepoel category:cs.DC C.2.4; H.3.4  published:2017-02-14 summary:Understanding the performance of data-parallel workloads when resource-constrained has significant practical importance but unfortunately has received only limited attention. This paper identifies, quantifies and demonstrates memory elasticity, an intrinsic property of data-parallel tasks. Memory elasticity allows tasks to run with significantly less memory that they would ideally want while only paying a moderate performance penalty. For example, we find that given as little as 10% of ideal memory, PageRank and NutchIndexing Hadoop reducers become only 1.2x/1.75x and 1.08x slower. We show that memory elasticity is prevalent in the Hadoop, Spark, Tez and Flink frameworks. We also show that memory elasticity is predictable in nature by building simple models for Hadoop and extending them to Tez and Spark. To demonstrate the potential benefits of leveraging memory elasticity, this paper further explores its application to cluster scheduling. In this setting, we observe that the resource vs. time trade-off enabled by memory elasticity becomes a task queuing time vs task runtime trade-off. Tasks may complete faster when scheduled with less memory because their waiting time is reduced. We show that a scheduler can turn this task-level trade-off into improved job completion time and cluster-wide memory utilization. We have integrated memory elasticity into Apache YARN. We show gains of up to 60% in average job completion time on a 50-node Hadoop cluster. Extensive simulations show similar improvements over a large number of scenarios. version:1
arxiv-1607-03884 | An investigation of GPU-based stiff chemical kinetics integration methods | http://arxiv.org/abs/1607.03884 | id:1607.03884 author:Nicholas J. Curtis, Kyle E. Niemeyer, Chih-Jen Sung category:physics.comp-ph cs.DC physics.chem-ph  published:2016-07-13 summary:A fifth-order implicit Runge-Kutta method and two fourth-order exponential integration methods equipped with Krylov subspace approximations were implemented for the GPU and paired with the analytical chemical kinetic Jacobian software pyJac. The performance of each algorithm was evaluated by integrating thermochemical state data sampled from stochastic partially stirred reactor simulations and compared with the commonly used CPU-based implicit integrator CVODE. We estimated that the implicit Runge-Kutta method running on a single GPU is equivalent to CVODE running on 12-38 CPU cores for integration of a single global integration time step of 1e-6 s with hydrogen and methane models. In the stiffest case studied---the methane model with a global integration time step of 1e-4 s---thread divergence and higher memory traffic significantly decreased GPU performance to the equivalent of CVODE running on approximately three CPU cores. The exponential integration algorithms performed more slowly than the implicit integrators on both the CPU and GPU. Thread divergence and memory traffic were identified as the main limiters of GPU integrator performance, and techniques to mitigate these issues were discussed. Use of a finite-difference Jacobian on the GPU---in place of the analytical Jacobian provided by pyJac---greatly decreased integrator performance due to thread divergence, resulting in maximum slowdowns of 7.11-240.96 times; in comparison, the corresponding slowdowns on the CPU were just 1.39-2.61 times, underscoring the importance of use of an analytical Jacobian for efficient GPU integration. Finally, future research directions for working towards enabling realistic chemistry in reactive-flow simulations via GPU\slash SIMD accelerated stiff chemical kinetic integration were identified. version:3
arxiv-1702-04282 | T-SKIRT: Online Estimation of Student Proficiency in an Adaptive Learning System | http://arxiv.org/abs/1702.04282 | id:1702.04282 author:Chaitanya Ekanadham, Yan Karklin category:cs.AI  published:2017-02-14 summary:We develop T-SKIRT: a temporal, structured-knowledge, IRT-based method for predicting student responses online. By explicitly accounting for student learning and employing a structured, multidimensional representation of student proficiencies, the model outperforms standard IRT-based methods on an online response prediction task when applied to real responses collected from students interacting with diverse pools of educational content. version:1
arxiv-1702-04263 | Okapi: Causally Consistent Geo-Replication Made Faster, Cheaper and More Available | http://arxiv.org/abs/1702.04263 | id:1702.04263 author:Diego Didona, Kristina Spirovska, Willy Zwaenepoel category:cs.DC  published:2017-02-14 summary:Okapi is a new causally consistent geo-replicated key- value store. Okapi leverages two key design choices to achieve high performance. First, it relies on hybrid logical/physical clocks to achieve low latency even in the presence of clock skew. Second, Okapi achieves higher resource efficiency and better availability, at the expense of a slight increase in update visibility latency. To this end, Okapi implements a new stabilization protocol that uses a combination of vector and scalar clocks and makes a remote update visible when its delivery has been acknowledged by every data center. We evaluate Okapi with different workloads on Amazon AWS, using three geographically distributed regions and 96 nodes. We compare Okapi with two recent approaches to causal consistency, Cure and GentleRain. We show that Okapi delivers up to two orders of magnitude better performance than GentleRain and that Okapi achieves up to 3.5x lower latency and a 60% reduction of the meta-data overhead with respect to Cure. version:1
arxiv-1702-04250 | LAMMPS' PPPM Long-Range Solver for the Second Generation Xeon Phi | http://arxiv.org/abs/1702.04250 | id:1702.04250 author:William McDoniel, Markus HÃ¶hnerbach, Rodrigo Canales, Ahmed E. Ismail, Paolo Bientinesi category:cs.CE cs.DC cs.PF  published:2017-02-14 summary:Molecular Dynamics is an important tool for computational biologists, chemists, and materials scientists, consuming a sizable amount of supercomputing resources. Many of the investigated systems contain charged particles, which can only be simulated accurately using a long-range solver, such as PPPM. We extend the popular LAMMPS molecular dynamics code with an implementation of PPPM particularly suitable for the second generation Intel Xeon Phi. Our main target is the optimization of computational kernels by means of vectorization, and we observe speedups in these kernels of up to 12x. These improvements carry over to LAMMPS users, with overall speedups ranging between 2-3x, without requiring users to retune input parameters. Furthermore, our optimizations make it easier for users to determine optimal input parameters for attaining top performance. version:1
arxiv-1702-04242 | Bizur: A Key-value Consensus Algorithm for Scalable File-systems | http://arxiv.org/abs/1702.04242 | id:1702.04242 author:Ezra N. Hoch, Yaniv Ben-Yehuda, Noam Lewis, Avi Vigder category:cs.DC cs.DB  published:2017-02-14 summary:Bizur is a consensus algorithm exposing a key-value interface. It is used by a distributed file-system that scales to 100s of servers, delivering millions of IOPS, both data and metadata, with consistent low-latency. Bizur is aimed for services that require strongly consistent state, but do not require a distributed log; for example, a distributed lock manager or a distributed service locator. By avoiding a distributed log scheme, Bizur outperforms distributed log based consensus algorithms, producing more IOPS and guaranteeing lower latencies during normal operation and especially during failures. Paxos-like algorithms (e.g., Zab and Raft) which are used by existing distributed file-systems, can have artificial contention points due to their dependence on a distributed log. The distributed log is needed when replicating a general service, but when the desired service is key-value based, the contention points created by the distributed log can be avoided. Bizur does exactly that, by reaching consensus independently on independent keys. This independence allows Bizur to handle failures more efficiently and to scale much better than other consensus algorithms, allowing the file-system that utilizes Bizur to scale with it. version:1
arxiv-1702-04164 | Better Process Mapping and Sparse Quadratic Assignment | http://arxiv.org/abs/1702.04164 | id:1702.04164 author:Christian Schulz, Jesper Larsson TrÃ¤ff category:cs.DC cs.DS  published:2017-02-14 summary:Communication and topology aware process mapping is a powerful approach to reduce communication time in parallel applications with known communication patterns on large, distributed memory systems. We address the problem as a quadratic assignment problem (QAP), and present algorithms to construct initial mappings of processes to processors as well as fast local search algorithms to further improve the mappings. By exploiting assumptions that typically hold for applications and modern supercomputer systems such as sparse communication patterns and hierarchically organized communication systems, we arrive at significantly more powerful algorithms for these special QAPs. Our multilevel construction algorithms employ recently developed, perfectly balanced graph partitioning techniques and excessively exploit the given communication system hierarchy. We present improvements to a local search algorithm of Brandfass et al., and decrease the running time by reducing the time needed to perform swaps in the assignment as well as by carefully constraining local search neighborhoods. Experiments indicate that our algorithms not only dramatically speed up local search, but due to the multilevel approach also find much better solutions~in~practice. version:1
arxiv-1701-03499 | VESPA: VIPT Enhancements for Superpage Accesses | http://arxiv.org/abs/1701.03499 | id:1701.03499 author:Mayank Parasar, Abhishek Bhattacharjee, Tushar Krishna category:cs.AR 68-06  published:2017-01-12 summary:L1 caches are critical to the performance of modern computer systems. Their design involves a delicate balance between fast lookups, high hit rates, low access energy, and simplicity of implementation. Unfortunately, constraints imposed by virtual memory make it difficult to satisfy all these attributes today. Specifically, the modern staple of supporting virtual-indexing and physical-tagging (VIPT) for parallel TLB-L1 lookups means that L1 caches are usually grown with greater associativity rather than sets. This compromises performance -- by degrading access times without significantly boosting hit rates -- and increases access energy. We propose VIPT Enhancements for SuperPage Accesses or VESPA in response. VESPA side-steps the traditional problems of VIPT by leveraging the increasing ubiquity of superpages; since superpages have more page offset bits, they can accommodate L1 cache organizations with more sets than baseline pages can. VESPA dynamically adapts to any OS distribution of page sizes to operate L1 caches with good access times, hit rates, and energy, for both single- and multi-threaded workloads. Since the hardware changes are modest, and there are no OS or application changes, VESPA is readily-implementable. By superpages (also called huge or large pages) we refer to any page sizes supported by the architecture bigger than baseline page size. version:2
arxiv-1702-04028 | Scheduling Algorithms for Asymmetric Multi-core Processors | http://arxiv.org/abs/1702.04028 | id:1702.04028 author:Alan David category:cs.DC  published:2017-02-14 summary:Growing power dissipation due to high performance requirement of processor suggests multicore processor technology, which has become the technology for present and next decade. Research advocates asymmetric multi-core processor system for better utilization of chip real state. However, asymmetric multi core architecture poses a new challenge to operating system scheduler, which traditionally assumes homogeneous hardware. So, scheduling threads to core has become a major issue to operating system kernel. In this paper, proposed scheduling algorithms for asymmetric multicore processors have been categorized. This paper explores some representative algorithms of these classes to get an overview of scheduling algorithms for asymmetric multicore system. version:1
arxiv-1702-04022 | Correct-by-Construction Approach for Self-Evolvable Robots | http://arxiv.org/abs/1702.04022 | id:1702.04022 author:Gang Chen, Zhaodan Kong category:cs.RO  published:2017-02-13 summary:The paper presents a new formal way of modeling and designing reconfigurable robots, in which case the robots are allowed to reconfigure not only structurally but also functionally. We call such kind of robots "self-evolvable", which have the potential to be more flexible to be used in a wider range of tasks, in a wider range of environments, and with a wider range of users. To accommodate such a concept, i.e., allowing a self-evovable robot to be configured and reconfigured, we present a series of formal constructs, e.g., structural reconfigurable grammar and functional reconfigurable grammar. Furthermore, we present a correct-by-construction strategy, which, given the description of a workspace, the formula specifying a task, and a set of available modules, is capable of constructing during the design phase a robot that is guaranteed to perform the task satisfactorily. We use a planar multi-link manipulator as an example throughout the paper to demonstrate the proposed modeling and designing procedures. version:1
arxiv-1603-03491 | Bayesian Opponent Exploitation in Imperfect-Information Games | http://arxiv.org/abs/1603.03491 | id:1603.03491 author:Sam Ganzfried, Qingyun Sun category:cs.GT cs.AI cs.MA math.PR stat.CO  published:2016-03-10 summary:Two fundamental problems in computational game theory are computing a Nash equilibrium and learning to exploit opponents given observations of their play (opponent exploitation). The latter is perhaps even more important than the former: Nash equilibrium does not have a compelling theoretical justification in game classes other than two-player zero-sum, and for all games one can potentially do better by exploiting perceived weaknesses of the opponent than by following a static equilibrium strategy throughout the match. The natural setting for opponent exploitation is the Bayesian setting where we have a prior model that is integrated with observations to create a posterior opponent model that we respond to. The most natural, and a well-studied prior distribution is the Dirichlet distribution. An exact polynomial-time algorithm is known for best-responding to the posterior distribution for an opponent assuming a Dirichlet prior with multinomial sampling in normal-form games; however, for imperfect-information games the best known algorithm is based on approximating an infinite integral without theoretical guarantees. We present the first exact algorithm for a natural class of imperfect-information games. We demonstrate that our algorithm runs quickly in practice and outperforms the best prior approaches. We also present an algorithm for the uniform prior setting. version:4
arxiv-1607-06156 | An Adaptive Parallel Algorithm for Computing Connected Components | http://arxiv.org/abs/1607.06156 | id:1607.06156 author:Chirag Jain, Patrick Flick, Tony Pan, Oded Green, Srinivas Aluru category:cs.DC  published:2016-07-21 summary:We present an efficient distributed memory parallel algorithm for computing connected components in undirected graphs based on Shiloach-Vishkin's PRAM approach. We discuss multiple optimization techniques that reduce communication volume as well as load-balance the algorithm. We also note that the efficiency of the parallel graph connectivity algorithm depends on the underlying graph topology. Particularly for short diameter graph components, we observe that parallel Breadth First Search (BFS) method offers better performance. However, running parallel BFS is not efficient for computing large diameter components or large number of small components. To address this challenge, we employ a heuristic that allows the algorithm to quickly predict the type of the network by computing the degree distribution and follow the optimal hybrid route. Using large graphs with diverse topologies from domains including metagenomics, web crawl, social graph and road networks, we show that our hybrid implementation is efficient and scalable for each of the graph types. Our approach achieves a runtime of 215 seconds using 32K cores of Cray XC30 for a metagenomic graph with over 50 billion edges. When compared against the previous state-of-the-art method, we see performance improvements up to 24x. version:3
arxiv-1702-03935 | Data-Intensive Supercomputing in the Cloud: Global Analytics for Satellite Imagery | http://arxiv.org/abs/1702.03935 | id:1702.03935 author:Michael S. Warren, Samuel W. Skillman, Rick Chartrand, Tim Kelton, Ryan Keisler, David Raleigh, Matthew Turk category:cs.DC cs.AI  published:2017-02-13 summary:We present our experiences using cloud computing to support data-intensive analytics on satellite imagery for commercial applications. Drawing from our background in high-performance computing, we draw parallels between the early days of clustered computing systems and the current state of cloud computing and its potential to disrupt the HPC market. Using our own virtual file system layer on top of cloud remote object storage, we demonstrate aggregate read bandwidth of 230 gigabytes per second using 512 Google Compute Engine (GCE) nodes accessing a USA multi-region standard storage bucket. This figure is comparable to the best HPC storage systems in existence. We also present several of our application results, including the identification of field boundaries in Ukraine, and the generation of a global cloud-free base layer from Landsat imagery. version:1
arxiv-1702-03812 | Reservoir Computing Using Non-Uniform Binary Cellular Automata | http://arxiv.org/abs/1702.03812 | id:1702.03812 author:Stefano Nichele, Magnus S. Gundersen category:cs.ET cs.AI  published:2017-02-13 summary:The Reservoir Computing (RC) paradigm utilizes a dynamical system, i.e., a reservoir, and a linear classifier, i.e., a read-out layer, to process data from sequential classification tasks. In this paper the usage of Cellular Automata (CA) as a reservoir is investigated. The use of CA in RC has been showing promising results. In this paper, selected state-of-the-art experiments are reproduced. It is shown that some CA-rules perform better than others, and the reservoir performance is improved by increasing the size of the CA reservoir itself. In addition, the usage of parallel loosely coupled CA-reservoirs, where each reservoir has a different CA-rule, is investigated. The experiments performed on quasi-uniform CA reservoir provide valuable insights in CA reservoir design. The results herein show that some rules do not work well together, while other combinations work remarkably well. This suggests that non-uniform CA could represent a powerful tool for novel CA reservoir implementations. version:1
arxiv-1702-03741 | Random walk based in-network computation of arbitrary functions | http://arxiv.org/abs/1702.03741 | id:1702.03741 author:Iqra Altaf Gillani, Pooja Vyavahare, Amitabha Bagchi category:cs.DC cs.NI  published:2017-02-13 summary:We study the in-network computation of arbitrary functions whose computation schema is a complete binary tree, i.e., we assume that the network wants to compute a function of $K$ operands, each of which is available at a distinct node in the network, and rather than simply collecting the $K$ operands at a single sink node and computing the function, we want to compute the function during the process of moving the data towards the sink. Such settings have been studied in the literature but largely only for symmetric functions, e.g. average, parity etc., which have the specific property that the output is invariant to permutations of the operands. To the best of our knowledge, we present the first decentralised algorithms for arbitrary functions. We propose two algorithms, Fixed Metropolis-Compute and Flexible Metropolis-Compute, for this problem, both of which use random walks on the network as their basic primitive. Assuming that time is slotted we provide upper bounds on time taken to compute the function, characterising this time in terms of the fundamental parameters of the random walk on a graph: the hitting time in the case of Fixed Metropolis-Compute, and the mixing time in the case of Flexible Metropolis-Compute. Assuming a stochastic model for the generation of streams of data at each source, we also provide lower and upper bound on the rate at which Fixed Metropolis-Compute is able to compute the stream of associated function values. version:1
arxiv-1702-03724 | On Seeking Consensus Between Document Similarity Measures | http://arxiv.org/abs/1702.03724 | id:1702.03724 author:MieczysÅaw KÅopotek category:cs.AI  published:2017-02-13 summary:This paper investigates the application of consensus clustering and meta-clustering to the set of all possible partitions of a data set. We show that when using a "complement" of Rand Index as a measure of cluster similarity, the total-separation partition, putting each element in a separate set, is chosen. version:1
arxiv-1702-03660 | Discrete Cosserat Approach for Multi-Section Soft Robots Dynamics | http://arxiv.org/abs/1702.03660 | id:1702.03660 author:Federico Renda, Frederic Boyer, Jorge Dias, Lakmal Seneviratne category:cs.RO  published:2017-02-13 summary:In spite of recent progress, soft robotics still suffers from a lack of unified modeling framework. Nowadays, the most adopted model for the design and control of soft robots is the piece-wise constant curvature model, with its consolidated benefits and drawbacks. In this work, an alternative model for multisection soft robots dynamics is presented based on a discrete Cosserat approach, which, not only takes into account shear and torsional deformations, essentials to cope with out-of-plane external loads, but also inherits the geometrical and mechanical properties of the continuous Cosserat model, making it the natural soft robotics counterpart of the traditional rigid robotics dynamics model. The soundness of the model is demonstrated through extensive simulation and experimental results for both plane and out-of-plane motions. version:1
arxiv-1702-03657 | Trie Compression for GPU Accelerated Multi-Pattern Matching | http://arxiv.org/abs/1702.03657 | id:1702.03657 author:Xavier Bellekens, Amar Seeam, Christos Tachtatzis, Robert Atkinson category:cs.DS cs.DC  published:2017-02-13 summary:Graphics Processing Units allow for running massively parallel applications offloading the CPU from computationally intensive resources, however GPUs have a limited amount of memory. In this paper a trie compression algorithm for massively parallel pattern matching is presented demonstrating 85% less space requirements than the original highly efficient parallel failure-less aho-corasick, whilst demonstrating over 22 Gbps throughput. The algorithm presented takes advantage of compressed row storage matrices as well as shared and texture memory on the GPU. version:1
arxiv-1702-03594 | Genetic and Memetic Algorithm with Diversity Equilibrium based on Greedy Diversification | http://arxiv.org/abs/1702.03594 | id:1702.03594 author:AndrÃ©s Herrera-Poyatos, Francisco Herrera category:cs.AI I.2.8  published:2017-02-12 summary:The lack of diversity in a genetic algorithm's population may lead to a bad performance of the genetic operators since there is not an equilibrium between exploration and exploitation. In those cases, genetic algorithms present a fast and unsuitable convergence. In this paper we develop a novel hybrid genetic algorithm which attempts to obtain a balance between exploration and exploitation. It confronts the diversity problem using the named greedy diversification operator. Furthermore, the proposed algorithm applies a competition between parent and children so as to exploit the high quality visited solutions. These operators are complemented by a simple selection mechanism designed to preserve and take advantage of the population diversity. Additionally, we extend our proposal to the field of memetic algorithms, obtaining an improved model with outstanding results in practice. The experimental study shows the validity of the approach as well as how important is taking into account the exploration and exploitation concepts when designing an evolutionary algorithm. version:1
arxiv-1702-03592 | Graph Neural Networks and Boolean Satisfiability | http://arxiv.org/abs/1702.03592 | id:1702.03592 author:Benedikt BÃ¼nz, Matthew Lamm category:cs.AI  published:2017-02-12 summary:In this paper we explore whether or not deep neural architectures can learn to classify Boolean satisfiability (SAT). We devote considerable time to discussing the theoretical properties of SAT. Then, we define a graph representation for Boolean formulas in conjunctive normal form, and train neural classifiers over general graph structures called Graph Neural Networks, or GNNs, to recognize features of satisfiability. To the best of our knowledge this has never been tried before. Our preliminary findings are potentially profound. In a weakly-supervised setting, that is, without problem specific feature engineering, Graph Neural Networks can learn features of satisfiability. version:1
arxiv-1702-03563 | System Modeling in the COSMA Environment | http://arxiv.org/abs/1702.03563 | id:1702.03563 author:Wiktor B. Daszczuk, Waldemar Grabski, Jerzy MieÅcicki, Jacek WytrÄbowicz category:cs.DC  published:2017-02-12 summary:The aim of this paper is to demonstrate how the COSMA environment can be used for system modeling. This environment is a set of tools based on Concurrent State Machines paradigm and is developed in the Institute of Computer Science at the Warsaw University of Technology. Our demonstration example is a distributed brake control system dedicated for a railway transport. The paper shortly introduces COSMA. Next it shows how the example model can be validated by our temporal logic analyzer. version:1
arxiv-1702-03555 | Agreeing to Cross: How Drivers and Pedestrians Communicate | http://arxiv.org/abs/1702.03555 | id:1702.03555 author:Amir Rasouli, Iuliia Kotseruba, John K. Tsotsos category:cs.RO  published:2017-02-12 summary:The contribution of this paper is twofold. The first is a novel dataset for studying behaviors of traffic participants while crossing. Our dataset contains more than 650 samples of pedestrian behaviors in various street configurations and weather conditions. These examples were selected from approx. 240 hours of driving in the city, suburban and urban roads. The second contribution is an analysis of our data from the point of view of joint attention. We identify what types of non-verbal communication cues road users use at the point of crossing, their responses, and under what circumstances the crossing event takes place. It was found that in more than 90% of the cases pedestrians gaze at the approaching cars prior to crossing in non-signalized crosswalks. The crossing action, however, depends on additional factors such as time to collision (TTC), explicit driver's reaction or structure of the crosswalk. version:1
arxiv-1604-00681 | Experimental Assessment of Aggregation Principles in Argumentation-enabled Collective Intelligence | http://arxiv.org/abs/1604.00681 | id:1604.00681 author:Edmond Awad, Jean-FranÃ§ois Bonnefon, Martin Caminada, Thomas Malone, Iyad Rahwan category:cs.AI  published:2016-04-03 summary:On the Web, there is always a need to aggregate opinions from the crowd (as in posts, social networks, forums, etc.). Different mechanisms have been implemented to capture these opinions such as "Like" in Facebook, "Favorite" in Twitter, thumbs-up/down, flagging, and so on. However, in more contested domains (e.g. Wikipedia, political discussion, and climate change discussion) these mechanisms are not sufficient since they only deal with each issue independently without considering the relationships between different claims. We can view a set of conflicting arguments as a graph in which the nodes represent arguments and the arcs between these nodes represent the defeat relation. A group of people can then collectively evaluate such graphs. To do this, the group must use a rule to aggregate their individual opinions about the entire argument graph. Here, we present the first experimental evaluation of different principles commonly employed by aggregation rules presented in the literature. We use randomized controlled experiments to investigate which principles people consider better at aggregating opinions under different conditions. Our analysis reveals a number of factors, not captured by traditional formal models, that play an important role in determining the efficacy of aggregation. These results help bring formal models of argumentation closer to real-world application. version:2
arxiv-1702-03534 | Leader Election in Trees with Customized Advice | http://arxiv.org/abs/1702.03534 | id:1702.03534 author:Barun Gorain, Andrzej Pelc category:cs.DC cs.DM  published:2017-02-12 summary:Leader election is a basic symmetry breaking problem in distributed computing. All nodes of a network have to agree on a single node, called the leader. If the nodes of the network have distinct labels, then agreeing on a single node means that all nodes have to output the label of the elected leader. If the nodes are anonymous, the task of leader election is formulated as follows: every node of the network must output a simple path starting at it, which is coded as a sequence of port numbers, such that all these paths end at a common node, the leader. In this paper, we study deterministic leader election in anonymous trees. Our goal is to establish tradeoffs between the allocated time $\tau$ and the amount of information that has to be given {\em a priori} to the nodes of a network to enable leader election in time $\tau$. Following the framework of {\em algorithms with advice}, this information is provided to all nodes at the start by an oracle knowing the entire tree, in form of binary strings assigned to all nodes. There are two possible variants of formulating this advice assignment. Either the strings provided to all nodes are identical, or strings assigned to different nodes may be potentially different, i.e., advice can be {\em customized}. As opposed to previous papers on leader election with advice, in this paper we consider the latter option. The maximum length of all assigned binary strings is called the {\em size of advice}. For a given time $\tau$ allocated to leader election, we give upper and lower bounds on the minimum size of advice sufficient to perform leader election in time $\tau$. All our bounds except one pair are tight up to multiplicative constants, and in this one exceptional case, the gap between the upper and the lower bound is very small. version:1
arxiv-1607-03238 | Scratchpad Sharing in GPUs | http://arxiv.org/abs/1607.03238 | id:1607.03238 author:Vishwesh Jatala, Jayvant Anantpur, Amey Karkare category:cs.AR  published:2016-07-12 summary:GPGPU applications exploit on-chip scratchpad memory available in the Graphics Processing Units (GPUs) to improve performance. The amount of thread level parallelism present in the GPU is limited by the number of resident threads, which in turn depends on the availability of scratchpad memory in its streaming multiprocessor (SM). Since the scratchpad memory is allocated at thread block granularity, part of the memory may remain unutilized. In this paper, we propose architectural and compiler optimizations to improve the scratchpad utilization. Our approach, Scratchpad Sharing, addresses scratchpad under-utilization by launching additional thread blocks in each SM. These thread blocks use unutilized scratchpad and also share scratchpad with other resident blocks. To improve the performance of scratchpad sharing, we propose Owner Warp First (OWF) scheduling that schedules warps from the additional thread blocks effectively. The performance of this approach, however, is limited by the availability of the shared part of scratchpad. We propose compiler optimizations to improve the availability of shared scratchpad. We describe a scratchpad allocation scheme that helps in allocating scratchpad variables such that shared scratchpad is accessed for short duration. We introduce a new instruction, relssp, that when executed, releases the shared scratchpad. Finally, we describe an analysis for optimal placement of relssp instructions such that shared scratchpad is released as early as possible. We implemented the hardware changes using the GPGPU-Sim simulator and implemented the compiler optimizations in Ocelot framework. We evaluated the effectiveness of our approach on 19 kernels from 3 benchmarks suites: CUDA-SDK, GPGPU-Sim, and Rodinia. The kernels that underutilize scratchpad memory show an average improvement of 19% and maximum improvement of 92.17% compared to the baseline approach. version:5
arxiv-1702-03488 | Octopus: A Framework for Cost-Quality-Time Optimization in Crowdsourcing | http://arxiv.org/abs/1702.03488 | id:1702.03488 author:Karan Goel, Shreya Rajpal, Mausam category:cs.AI cs.HC cs.MA  published:2017-02-12 summary:Managing micro-tasks on crowdsourcing marketplaces involves balancing conflicting objectives -- the quality of work, total cost incurred and time to completion. Previous agents have focused on cost-quality, or cost-time tradeoffs, limiting their real-world applicability. As a step towards this goal we present Octopus, the first AI agent that jointly manages all three objectives in tandem. Octopus is based on a computationally tractable, multi-agent formulation consisting of three components; one that sets the price per ballot to adjust the rate of completion of tasks, another that optimizes each task for quality and a third that performs task selection. We demonstrate that Octopus outperforms existing state-of-the-art approaches in simulation and experiments with real data, demonstrating its superior performance. We also deploy Octopus on Amazon Mechanical Turk to establish its ability to manage tasks in a real-world, dynamic setting. version:1
arxiv-1702-03466 | Safe Open-Loop Strategies for Handling Intermittent Communications in Multi-Robot Systems | http://arxiv.org/abs/1702.03466 | id:1702.03466 author:Siddharth Mayya, Magnus Egerstedt category:cs.MA cs.RO  published:2017-02-11 summary:In multi-robot systems where a central decision maker is specifying the movement of each individual robot, a communication failure can severely impair the performance of the system. This paper develops a motion strategy that allows robots to safely handle critical communication failures for such multi-robot architectures. For each robot, the proposed algorithm computes a time horizon over which collisions with other robots are guaranteed not to occur. These safe time horizons are included in the commands being transmitted to the individual robots. In the event of a communication failure, the robots execute the last received velocity commands for the corresponding safe time horizons leading to a provably safe open-loop motion strategy. The resulting algorithm is computationally effective and is agnostic to the task that the robots are performing. The efficacy of the strategy is verified in simulation as well as on a team of differential-drive mobile robots. version:1
arxiv-1702-03289 | Efficient Resource Allocation in Mass Customization based on Service Oriented Architecture | http://arxiv.org/abs/1702.03289 | id:1702.03289 author:Ali Vatankhah Barenji, Reza Vatankhah Barenji category:cs.DC  published:2017-02-11 summary:Mass customization explains the phenomenon to provide a unique designed products and services to all customer by achieving a high process integration and flexibility. It has been used as a competitive approach by many companies. Adequate resource implementation in mass customization-particularly in terms of resource usage, it is therefore important to meet customer's requirement in terms effective responsiveness and meeting deadlines, at the same time offering high scalability. An architecture for solving the resource allocation issue in mass customized flexible manufacturing system was illustrated, by putting in place a couple of advance reservation systems and scheduling algorithms for effective usage of the product. version:1
arxiv-1702-03456 | On Realistic Target Coverage by Autonomous Drones | http://arxiv.org/abs/1702.03456 | id:1702.03456 author:Ahmed Saeed, Ahmed Abdelkader, Mouhyemen Khan, Azin Neishaboori, Khaled A. Harras, Amr Mohamed category:cs.RO  published:2017-02-11 summary:Low-cost mini-drones with advanced sensing and maneuverability enable a new class of intelligent sensing systems. This trend motivated several research efforts to employ drones as standalone systems or to assist legacy deployments. However, several fundamental challenges remain unsolved including: 1) Adequate coverage of sizable targets; 2) Target orientation that render coverage effective only from certain view points; 3) Occlusion by elements in the environment, including other targets. In this paper, we present Argus, a system that provides coverage of wide and oriented targets, using camera-mounted drones, taking into account the challenges stated above. Argus relies on a geometric model that captures both target shapes and coverage constraints. With drones being the scarcest resource in Argus, we study the problem of minimizing the number of drones required to cover a set of such targets and derive a best-possible approximation algorithm. Furthermore, we present a sampling heuristic that yields a comparable performance, yet is up to 100x faster than the approximation algorithm. We build a prototype of Argus to demonstrate and evaluate the proposed coverage algorithms as part of a complete autonomous surveillance system. We evaluate the proposed algorithms using simulations to compare their performance at scale under various conditions. Finally, we present extensions and discuss open problems related to the studied problem. version:1
arxiv-1612-07837 | SampleRNN: An Unconditional End-to-End Neural Audio Generation Model | http://arxiv.org/abs/1612.07837 | id:1612.07837 author:Soroush Mehri, Kundan Kumar, Ishaan Gulrajani, Rithesh Kumar, Shubham Jain, Jose Sotelo, Aaron Courville, Yoshua Bengio category:cs.SD cs.AI  published:2016-12-22 summary:In this paper we propose a novel model for unconditional audio generation based on generating one audio sample at a time. We show that our model, which profits from combining memory-less modules, namely autoregressive multilayer perceptrons, and stateful recurrent neural networks in a hierarchical structure is able to capture underlying sources of variations in the temporal sequences over very long time spans, on three datasets of different nature. Human evaluation on the generated samples indicate that our model is preferred over competing models. We also show how each component of the model contributes to the exhibited performance. version:2
arxiv-1702-03449 | 1-bit Massive MU-MIMO Precoding in VLSI | http://arxiv.org/abs/1702.03449 | id:1702.03449 author:Oscar CastaÃ±eda, Sven Jacobsson, Giuseppe Durisi, Mikael Coldrey, Tom Goldstein, Christoph Studer category:cs.IT cs.AR math.IT  published:2017-02-11 summary:Massive multiuser (MU) multiple-input multiple-output (MIMO) will be a core technology in fifth-generation (5G) wireless systems as it offers significant improvements in spectral efficiency compared to existing multi-antenna technologies. The presence of hundreds of antenna elements at the base station (BS), however, results in excessively high hardware costs and power consumption, and requires high interconnect throughput between the baseband-processing unit and the radio unit. Massive MU-MIMO that uses low-resolution analog-to-digital and digital-to-analog converters (DACs) has the potential to address all these issues. In this paper, we focus on downlink precoding for massive MU-MIMO systems with 1-bit DACs at the BS. The objective is to design precoders that simultaneously mitigate multi-user interference (MUI) and quantization artifacts. We propose two nonlinear 1-bit precoding algorithms and corresponding very-large scale integration (VLSI) designs. Our algorithms rely on biconvex relaxation, which enables the design of efficient 1-bit precoding algorithms that achieve superior error-rate performance compared to that of linear precoding algorithms followed by quantization. To showcase the efficacy of our algorithms, we design VLSI architectures that enable efficient 1-bit precoding for massive MU-MIMO systems in which hundreds of antennas serve tens of user equipments. We present corresponding field-programmable gate array (FPGA) implementations to demonstrate that 1-bit precoding enables reliable and high-rate downlink data transmission in practical systems. version:1
arxiv-1702-03433 | Path Assignment Techniques For Vehicle Tracking | http://arxiv.org/abs/1702.03433 | id:1702.03433 author:Richard Altendorfer, Sebastian Wirkert category:cs.SY cs.RO  published:2017-02-11 summary:Many driver assistance systems such as Adaptive Cruise Control require the identification of the closest vehicle that is in the host vehicle's path. This entails an assignment of detected vehicles to the host vehicle path or neighboring paths. After reviewing approaches to the estimation of the host vehicle path and lane assignment techniques we introduce two methods that are motivated by the rationale to filter measured data as late in the processing stages as possible in order to avoid delays and other artifacts of intermediate filters. These filters generate discrete posterior probability distributions from which a path or "lane" index is extracted by a median estimator. The relative performance of those methods is illustrated by a ROC using experimental data and labeled ground truth data. version:1
arxiv-1702-03429 | Decoupled Sampling Based Planning Method for Multiple Autonomous Vehicles | http://arxiv.org/abs/1702.03429 | id:1702.03429 author:Fatemeh Mohseni, Mahdi Morsali category:cs.RO  published:2017-02-11 summary:This paper proposes a sampling based planning algorithm to control autonomous vehicles. We propose an improved Rapidly-exploring Random Tree which includes the definition of K- nearest points and propose a two-stage sampling strategy to adjust RRT in other to perform maneuver while avoiding collision. The simulation results show the success of the algorithm. version:1
arxiv-1509-08690 | Kempe's Universality Theorem for Rational Space Curves | http://arxiv.org/abs/1509.08690 | id:1509.08690 author:Zijia Li, Josef Schicho, Hans-Peter SchrÃ¶cker category:cs.CG cs.RO cs.SC math.AG math.RA  published:2015-09-29 summary:We prove that every bounded rational space curve of degree d and circularity c can be drawn by a linkage with 9/2 d - 6c + 1 revolute joints. Our proof is based on two ingredients. The first one is the factorization theory of motion polynomials. The second one is the construction of a motion polynomial of minimum degree with given orbit. Our proof also gives the explicity construction of the linkage. version:4
arxiv-1702-03401 | A Minimax Algorithm Better Than Alpha-beta?: No and Yes | http://arxiv.org/abs/1702.03401 | id:1702.03401 author:Aske Plaat, Jonathan Schaeffer, Wim Pijls, Arie de Bruin category:cs.AI  published:2017-02-11 summary:This paper has three main contributions to our understanding of fixed-depth minimax search: (A) A new formulation for Stockman's SSS* algorithm, based on Alpha-Beta, is presented. It solves all the perceived drawbacks of SSS*, finally transforming it into a practical algorithm. In effect, we show that SSS* = alpha-beta + ransposition tables. The crucial step is the realization that transposition tables contain so-called solution trees, structures that are used in best-first search algorithms like SSS*. Having created a practical version, we present performance measurements with tournament game-playing programs for three different minimax games, yielding results that contradict a number of publications. (B) Based on the insights gained in our attempts at understanding SSS*, we present a framework that facilitates the construction of several best-first fixed- depth game-tree search algorithms, known and new. The framework is based on depth-first null-window Alpha-Beta search, enhanced with storage to allow for the refining of previous search results. It focuses attention on the essential differences between algorithms. (C) We present a new instance of the framework, MTD(f). It is well-suited for use with iterative deepening, and performs better than algorithms that are currently used in most state-of-the-art game-playing programs. We provide experimental evidence to explain why MTD(f) performs better than the other fixed-depth minimax algorithms. version:1
arxiv-1703-00073 | Physically unclonable function using initial waveform of ring oscillators on 65 nm CMOS technology | http://arxiv.org/abs/1703.00073 | id:1703.00073 author:Tetsufumi Tanamoto, Satoshi Takaya, Nobuaki Sakamoto, Hirotsugu Kasho, Shinichi Yasuda, Takao Marukame, Shinobu Fujita, Yuichiro Mitani category:cs.CR cs.AR  published:2017-02-10 summary:A silicon physically unclonable function (PUF) using ring oscillators (ROs) has the advantage of easy application in both an application specific integrated circuit (ASIC) and a field-programmable gate array (FPGA). Here, we provide a RO-PUF using the initial waveform of the ROs based on 65 nm CMOS technology. Compared with the conventional RO-PUF, the number of ROs is greatly reduced and the time needed to generate an ID is within a couple of system clocks. version:1
arxiv-1608-02193 | Spacetimes with Semantics (III) - The Structure of Functional Knowledge Representation and Artificial Reasoning | http://arxiv.org/abs/1608.02193 | id:1608.02193 author:Mark Burgess category:cs.AI cs.SY  published:2016-08-07 summary:Using the previously developed concepts of semantic spacetime, I explore the interpretation of knowledge representations, and their structure, as a semantic system, within the framework of promise theory. By assigning interpretations to phenomena, from observers to observed, we may approach a simple description of knowledge-based functional systems, with direct practical utility. The focus is especially on the interpretation of concepts, associative knowledge, and context awareness. The inference seems to be that most if not all of these concepts emerge from purely semantic spacetime properties, which opens the possibility for a more generalized understanding of what constitutes a learning, or even `intelligent' system. Some key principles emerge for effective knowledge representation: 1) separation of spacetime scales, 2) the recurrence of four irreducible types of association, by which intent propagates: aggregation, causation, cooperation, and similarity, 3) the need for discrimination of identities (discrete), which is assisted by distinguishing timeline simultaneity from sequential events, and 4) the ability to learn (memory). It is at least plausible that emergent knowledge abstraction capabilities have their origin in basic spacetime structures. These notes present a unified view of mostly well-known results; they allow us to see information models, knowledge representations, machine learning, and semantic networking (transport and information base) in a common framework. The notion of `smart spaces' thus encompasses artificial systems as well as living systems, across many different scales, e.g. smart cities and organizations. version:3
arxiv-1605-04151 | Perception-aware Path Planning | http://arxiv.org/abs/1605.04151 | id:1605.04151 author:Gabriele Costante, Christian Forster, Jeffrey Delmerico, Paolo Valigi, Davide Scaramuzza category:cs.RO  published:2016-05-13 summary:In this paper, we give a double twist to the problem of planning under uncertainty. State-of-the-art planners seek to minimize the localization uncertainty by only considering the geometric structure of the scene. In this paper, we argue that motion planning for vision-controlled robots should be perception aware in that the robot should also favor texture-rich areas to minimize the localization uncertainty during a goal-reaching task. Thus, we describe how to optimally incorporate the photometric information (i.e., texture) of the scene, in addition to the the geometric one, to compute the uncertainty of vision-based localization during path planning. To avoid the caveats of feature-based localization systems (i.e., dependence on feature type and user-defined thresholds), we use dense, direct methods. This allows us to compute the localization uncertainty directly from the intensity values of every pixel in the image. We also describe how to compute trajectories online, considering also scenarios with no prior knowledge about the map. The proposed framework is general and can easily be adapted to different robotic platforms and scenarios. The effectiveness of our approach is demonstrated with extensive experiments in both simulated and real-world environments using a vision-controlled micro aerial vehicle. version:2
arxiv-1602-05852 | Consensus in Rooted Dynamic Networks with Short-Lived Stability | http://arxiv.org/abs/1602.05852 | id:1602.05852 author:Kyrill Winkler, Manfred Schwarz, Ulrich Schmid category:cs.DC cs.DS  published:2016-02-18 summary:We consider the problem of solving consensus using deterministic algorithms in a synchronous dynamic network with unreliable, directional point-to-point links, which are under the control of a message adversary. In contrast to a large body of existing work that focuses on oblivious message adversaries where the communication graphs are picked from a predefined set, we consider message adversaries where guarantees about stable periods that occur only eventually can be expressed. We reveal to what extent such eventual stability is necessary and sufficient, that is, we present the shortest period of stability that permits solving consensus, a result that should prove quite useful in systems that exhibit erratic boot-up phases or recover after repeatedly occurring, massive transient faults. Contrary to the case of longer stability periods, where we show how standard algorithmic techniques for solving consensus can be employed, the short-lived nature of the stability phase forces us to use more unusual algorithmic methods that avoid waiting explicitly for the stability period to occur. version:3
arxiv-1701-03616 | Improved Leader Election for Self-Organizing Programmable Matter | http://arxiv.org/abs/1701.03616 | id:1701.03616 author:Joshua J. Daymude, Robert Gmyr, Andrea W. Richa, Christian Scheideler, Thim Strothmann category:cs.ET cs.DC  published:2017-01-13 summary:We consider programmable matter that consists of computationally limited devices (which we call particles) that are able to self-organize in order to achieve some collective goal without the need for central control or external intervention. We use the geometric amoebot model to describe such self-organizing particle systems, which defines how particles can actively move and establish or release bonds with one another. Under this model, we investigate the feasibility of solving fundamental problems relevant to programmable matter. In this paper, we present an efficient local-control algorithm which solves the leader election problem in O(n) asynchronous rounds with high probability, where n is the number of particles in the system. Our algorithm relies only on local information (e.g., particles do not have unique identifiers, any knowledge of n, or any sort of global coordinate system), and requires only constant memory per particle. version:2
arxiv-1611-00128 | A Certifiably Correct Algorithm for Synchronization over the Special Euclidean Group | http://arxiv.org/abs/1611.00128 | id:1611.00128 author:David M. Rosen, Luca Carlone, Afonso S. Bandeira, John J. Leonard category:cs.RO math.OC  published:2016-11-01 summary:Many geometric estimation problems take the form of synchronization over the special Euclidean group: estimate the values of a set of poses given noisy measurements of a subset of their pairwise relative transforms. This problem is typically formulated as a maximum-likelihood estimation that requires solving a nonconvex nonlinear program, which is computationally intractable in general. Nevertheless, in this paper we present an algorithm that is able to efficiently recover certifiably globally optimal solutions of this estimation problem in a non-adversarial noise regime. The crux of our approach is the development of a semidefinite relaxation of the maximum-likelihood estimation whose minimizer provides the exact MLE so long as the magnitude of the noise corrupting the available measurements falls below a certain critical threshold; furthermore, whenever exactness obtains, it is possible to verify this fact a posteriori, thereby certifying the optimality of the recovered estimate. We develop a specialized optimization scheme for solving large-scale instances of this semidefinite relaxation by exploiting its low-rank, geometric, and graph-theoretic structure to reduce it to an equivalent optimization problem on a low-dimensional Riemannian manifold, and then design a Riemannian truncated-Newton trust-region method to solve this reduction efficiently. We combine this fast optimization approach with a simple rounding procedure to produce our algorithm, SE-Sync. Experimental evaluation on a variety of simulated and real-world pose-graph SLAM datasets shows that SE-Sync is capable of recovering globally optimal solutions when the available measurements are corrupted by noise up to an order of magnitude greater than that typically encountered in robotics applications, and does so at a computational cost that scales comparably with that of direct Newton-type local search techniques. version:3
arxiv-1702-03008 | Finer-grained Locking in Concurrent Dynamic Planar Convex Hulls | http://arxiv.org/abs/1702.03008 | id:1702.03008 author:K. Alex Mills, James Smith category:cs.DC D.1.3; F.2.2; I.3.5  published:2017-02-09 summary:The convex hull of a planar point set is the smallest convex polygon containing each point in the set. The dynamic convex hull problem concerns efficiently maintaining the convex hull of a set of points subject to additions and removals. One algorithm for this problem uses two external balanced binary search trees (BSTs) (M. H. Overmars, J. van Leeuwen 1981). We present the first concurrent solution for this problem, which uses a single BST that stores references to intermediate convex hull solutions at each node. We implement and evaluate two lock-based approaches: a) fine-grained locking, where each node of the tree is protected by a lock, and b) "finer-grained locking", where each node contains a separate lock for each of the left and right chains. In our throughput experiments, we observe that finer-grained locking yields an 8-60% improvement over fine-grained locking, and a 38-61x improvement over coarsegrained locking and software transactional memory (STM). When applied to find the convex hull of static point sets, our approach outperforms a parallel divide-and-conquer implementation by 2-4x using an equivalent number of threads. version:1
arxiv-1612-04687 | Real-time interactive sequence generation and control with Recurrent Neural Network ensembles | http://arxiv.org/abs/1612.04687 | id:1612.04687 author:Memo Akten, Mick Grierson category:cs.AI cs.HC  published:2016-12-14 summary:Recurrent Neural Networks (RNN), particularly Long Short Term Memory (LSTM) RNNs, are a popular and very successful method for learning and generating sequences. However, current generative RNN techniques do not allow real-time interactive control of the sequence generation process, thus aren't well suited for live creative expression. We propose a method of real-time continuous control and 'steering' of sequence generation using an ensemble of RNNs and dynamically altering the mixture weights of the models. We demonstrate the method using character based LSTM networks and a gestural interface allowing users to 'conduct' the generation of text. version:2
arxiv-1702-02978 | Elastic Resource Management with Adaptive State Space Partitioning of Markov Decision Processes | http://arxiv.org/abs/1702.02978 | id:1702.02978 author:Konstantinos Lolos, Ioannis Konstantinou, Verena Kantere, Nectarios Koziris category:cs.DC  published:2017-02-09 summary:Modern large-scale computing deployments consist of complex applications running over machine clusters. An important issue in these is the offering of elasticity, i.e., the dynamic allocation of resources to applications to meet fluctuating workload demands. Threshold based approaches are typically employed, yet they are difficult to configure and optimize. Approaches based on reinforcement learning have been proposed, but they require a large number of states in order to model complex application behavior. Methods that adaptively partition the state space have been proposed, but their partitioning criteria and strategies are sub-optimal. In this work we present MDP_DT, a novel full-model based reinforcement learning algorithm for elastic resource management that employs adaptive state space partitioning. We propose two novel statistical criteria and three strategies and we experimentally prove that they correctly decide both where and when to partition, outperforming existing approaches. We experimentally evaluate MDP_DT in a real large scale cluster over variable not-encountered workloads and we show that it takes more informed decisions compared to static and model-free approaches, while requiring a minimal amount of training data. version:1
arxiv-1702-02968 | Comparative benchmarking of cloud computing vendors with High Performance Linpack | http://arxiv.org/abs/1702.02968 | id:1702.02968 author:Mohammad Mohammadi, Timur Bazhirov category:cs.PF cs.DC  published:2017-02-09 summary:We present a comparative analysis of the maximum performance achieved by the Linpack benchmark on compute intensive hardware publicly available from multiple cloud providers. We study both performance within a single compute node, and speedup for distributed memory calculations with up to 32 nodes or at least 512 computing cores. We distinguish between hyper-threaded and non-hyper-threaded scenarios and estimate the performance per single computing core. We also compare results with a traditional supercomputing system for reference. Our findings provide a way to rank the cloud providers and demonstrate the viability of the cloud for high performance computing applications. version:1
arxiv-1702-02890 | Answer Set Solving with Bounded Treewidth Revisited | http://arxiv.org/abs/1702.02890 | id:1702.02890 author:Johannes Fichte, Markus Hecher, Michael Morak, Stefan Woltran category:cs.LO cs.AI cs.CC  published:2017-02-09 summary:Parameterized algorithms are a way to solve hard problems more efficiently, given that a specific parameter of the input is small. In this paper, we apply this idea to the field of answer set programming (ASP). To this end, we propose two kinds of graph representations of programs to exploit their treewidth as a parameter. Treewidth roughly measures to which extent the internal structure of a program resembles a tree. Our main contribution is the design of parameterized dynamic programming algorithms, which run in linear time if the treewidth and weights of the given program are bounded. Compared to previous work, our algorithms handle the full syntax of ASP. Finally, we report on an empirical evaluation that shows good runtime behaviour for benchmark instances of low treewidth, especially for counting answer sets. version:1
arxiv-1701-07544 | Spherical Planetary Robot for Rugged Terrain Traversal | http://arxiv.org/abs/1701.07544 | id:1701.07544 author:Laksh Raura, Andrew Warren, Jekan Thangavelautham category:cs.RO astro-ph.IM  published:2017-01-26 summary:Wheeled planetary rovers such as the Mars Exploration Rovers (MERs) and Mars Science Laboratory (MSL) have provided unprecedented, detailed images of the Mars surface. However, these rovers are large and are of high-cost as they need to carry sophisticated instruments and science laboratories. We propose the development of low-cost planetary rovers that are the size and shape of cantaloupes and that can be deployed from a larger rover. The rover named SphereX is 2 kg in mass, is spherical, holonomic and contains a hopping mechanism to jump over rugged terrain. A small low-cost rover complements a larger rover, particularly to traverse rugged terrain or roll down a canyon, cliff or crater to obtain images and science data. While it may be a one-way journey for these small robots, they could be used tactically to obtain high-reward science data. The robot is equipped with a pair of stereo cameras to perform visual navigation and has room for a science payload. In this paper, we analyze the design and development of a laboratory prototype. The results show a promising pathway towards development of a field system. version:2
arxiv-1605-08023 | Online Placement of Multi-Component Applications in Edge Computing Environments | http://arxiv.org/abs/1605.08023 | id:1605.08023 author:Shiqiang Wang, Murtaza Zafer, Kin K. Leung category:cs.DC cs.DS cs.NI math.OC  published:2016-05-25 summary:Mobile edge computing is a new cloud computing paradigm which makes use of small-sized edge-clouds to provide real-time services to users. These mobile edge-clouds (MECs) are located in close proximity to users, thus enabling users to seamlessly access applications running on MECs. Due to the co-existence of the core (centralized) cloud, users, and one or multiple layers of MECs, an important problem is to decide where (on which computational entity) to place different components of an application. This problem, known as the application or workload placement problem, is notoriously hard, and therefore, heuristic algorithms without performance guarantees are generally employed in common practice, which may unknowingly suffer from poor performance as compared to the optimal solution. In this paper, we address the application placement problem and focus on developing algorithms with provable performance bounds. We model the user application as an application graph and the physical computing system as a physical graph, with resource demands/availabilities annotated on these graphs. We first consider the placement of a linear application graph and propose an algorithm for finding its optimal solution. Using this result, we then generalize the formulation and obtain online approximation algorithms with polynomial-logarithmic (poly-log) competitive ratio for tree application graph placement. We jointly consider node and link assignment, and incorporate multiple types of computational resources at nodes. version:2
arxiv-1702-02848 | Distributed Domination on Graph Classes of Bounded Expansion | http://arxiv.org/abs/1702.02848 | id:1702.02848 author:Saeed Akhoondian Amiri, Patrice Ossona de Mendez, Roman Rabinovich, Sebastian Siebertz category:cs.DC cs.DS  published:2017-02-09 summary:We provide a new constant factor approximation algorithm for the (connected) distance-$r$ dominating set problem on graph classes of bounded expansion. Classes of bounded expansion include many familiar classes of sparse graphs such as planar graphs and graphs with excluded (topological) minors, and notably, these classes form the most general subgraph closed classes of graphs for which a sequential constant factor approximation algorithm for the distance-$r$ dominating set problem is currently known. Our algorithm can be implemented in the $\mathcal{CONGEST}_{\mathrm{BC}}$ model of distributed computing and uses $\mathcal{O}(r^2 \log n)$ communication rounds. Our techniques, which may be of independent interest, are based on a distributed computation of sparse neighborhood covers of small radius on bounded expansion classes. We show how to compute an $r$-neighborhood cover of radius $2r$ and overlap $f(r)$ on every class of bounded expansion in $\mathcal{O}(r^2\log n)$ communication rounds. Finally, we show how to use the greater power of the $\mathcal{LOCAL}$ model to turn any distance-$r$ dominating set into a constantly larger connected distance-$r$ dominating set in $3r+1$ rounds on any class of bounded expansion. Combining this algorithm, e.g., with the constant factor approximation algorithm for dominating sets on planar graphs of Lenzen et al. gives a constant factor approximation algorithm for connected dominating sets on planar graphs in a constant number of rounds in the $\mathcal{LOCAL}$ model, where the approximation ratio is only $6$ times larger than that of Lenzen et al.'s algorithm. version:1
arxiv-1610-07339 | Optimizing egalitarian performance in the side-effects model of colocation for data center resource management | http://arxiv.org/abs/1610.07339 | id:1610.07339 author:Fanny Pascual, Krzysztof Rzadca category:cs.DC  published:2016-10-24 summary:In data centers, up to dozens of tasks are colocated on a single physical machine. Machines are used more efficiently, but tasks' performance deteriorates, as colocated tasks compete for shared resources. As tasks are heterogeneous, the resulting performance dependencies are complex. In our previous work [18] we proposed a new combinatorial optimization model that uses two parameters of a task - its size and its type - to characterize how a task influences the performance of other tasks allocated to the same machine. In this paper, we study the egalitarian optimization goal: maximizing the worst-off performance. This problem generalizes the classic makespan minimization on multiple processors (P Cmax). We prove that polynomially-solvable variants of multiprocessor scheduling are NP-hard and hard to approximate when the number of types is not constant. For a constant number of types, we propose a PTAS, a fast approximation algorithm, and a series of heuristics. We simulate the algorithms on instances derived from a trace of one of Google clusters. Algorithms aware of jobs' types lead to better performance compared with algorithms solving P Cmax. The notion of type enables us to model degeneration of performance caused by using standard combinatorial optimization methods. Types add a layer of additional complexity. However, our results - approximation algorithms and good average-case performance - show that types can be handled efficiently. version:2
arxiv-1702-02821 | Phase Transitions of the Typical Algorithmic Complexity of the Random Satisfiability Problem Studied with Linear Programming | http://arxiv.org/abs/1702.02821 | id:1702.02821 author:Hendrik Schawe, Roman Bleim, Alexander K. Hartmann category:cond-mat.dis-nn cond-mat.stat-mech cs.AI cs.CC  published:2017-02-09 summary:The Boolean Satisfiability problem asks if a Boolean formula is satisfiable by some assignment of the variables or not. It belongs to the NP-complete complexity class and hence no algorithm with polynomial time worst-case complexity is known, i.e., the problem is hard. The K-SAT problem is the subset of the Boolean Satisfiability problem, for which the Boolean formula has the conjunctive normal form with K literals per clause. This problem is still NP-complete for $K \ge 3$. Although the worst case complexity of NP-complete problems is conjectured to be exponential, there might be subsets of the realizations where solutions can typically be found in polynomial time. In fact, random $K$-SAT, with the number of clauses to number of variables ratio $\alpha$ as control parameter, shows a phase transition between a satisfiable phase and an unsatisfiable phase, at which the hardest problems are located. We use here several linear programming approaches to reveal further "easy-hard" transition points at which the typical hardness of the problems increases which means that such algorithms can solve the problem on one side efficiently but not beyond this point. For one of these transitions, we observed a coincidence with a structural transition of the literal factor graphs of the problem instances. We also investigated cutting-plane approaches, which often increase the computational efficiency. Also we tried out a mapping to another NP-complete optimization problem using a specific algorithm for that problem. In both cases, no improvement of the performance was observed, i.e., no shift of the easy-hard transition to higher values of $\alpha$. version:1
arxiv-1702-02799 | UStore: A Distributed Storage With Rich Semantics | http://arxiv.org/abs/1702.02799 | id:1702.02799 author:Anh Dinh, Ji Wang, Sheng Wang, Gang Chen, Wei-Ngan Chin, Qian Lin, Beng Chin Ooi, Pingcheng Ruan, Kian-Lee Tan, Zhongle Xie, Hao Zhang, Meihui Zhang category:cs.DB cs.DC  published:2017-02-09 summary:Today's storage systems expose abstractions which are either too low-level (e.g., key-value store, raw-block store) that they require developers to re-invent the wheels, or too high-level (e.g., relational databases, Git) that they lack generality to support many classes of applications. In this work, we propose and implement a general distributed data storage system, called UStore, which has rich semantics. UStore delivers three key properties, namely immutability, sharing and security, which unify and add values to many classes of today's applications, and which also open the door for new applications. By keeping the core properties within the storage, UStore helps reduce application development efforts while offering high performance at hand. The storage embraces current hardware trends as key enablers. It is built around a data-structure similar to that of Git, a popular source code versioning system, but it also synthesizes many designs from distributed systems and databases. Our current implementation of UStore has better performance than general in-memory key-value storage systems, especially for version scan operations. We port and evaluate four applications on top of UStore: a Git-like application, a collaborative data science application, a transaction management application, and a blockchain application. We demonstrate that UStore enables faster development and the UStore-backed applications can have better performance than the existing implementations. version:1
arxiv-1702-02735 | Towards Autonomous UAV Landing Based on Infrared Beacons and Particle Filtering | http://arxiv.org/abs/1702.02735 | id:1702.02735 author:Vsevolod Khithov, Alexander Petrov, Igor Tishchenko, Konstantin Yakovlev category:cs.RO  published:2017-02-09 summary:Autonomous fixed-wing UAV landing based on differential GPS is now a mainstream providing reliable and precise landing. But the task still remains challenging when GPS availability is limited like for military UAVs. We discuss a solution of this problem based on computer vision and dot markings along stationary or makeshift runway. We focus our attempts on using infrared beacons along with narrow-band filter as promising way to mark any makeshift runway and utilize particle filtering to fuse both IMU and visual data. We believe that unlike many other vision-based methods this solution is capable of tracking UAV position up to engines stop. System overview, algorithm description and it's evaluation on synthesized sequence along real recorded trajectory is presented. version:1
arxiv-1505-04224 | Tight Bounds for Connectivity and Set Agreement in Byzantine Synchronous Systems | http://arxiv.org/abs/1505.04224 | id:1505.04224 author:Hammurabi Mendes, Maurice Herlihy category:cs.DC  published:2015-05-16 summary:In this paper, we show that the protocol complex of a Byzantine synchronous system can remain $(k - 1)$-connected for up to $\lceil t/k \rceil$ rounds, where $t$ is the maximum number of Byzantine processes, and $t \ge k \ge 1$. This topological property implies that $\lceil t/k \rceil + 1$ rounds are necessary to solve $k$-set agreement in Byzantine synchronous systems, compared to $\lfloor t/k \rfloor + 1$ rounds in synchronous crash-failure systems. We also show that our connectivity bound is tight as we indicate solutions to Byzantine $k$-set agreement in exactly $\lceil t/k \rceil + 1$ synchronous rounds, at least when $n$ is suitably large compared to $t$. In conclusion, we see how Byzantine failures can potentially require one extra round to solve $k$-set agreement, and, for $n$ suitably large compared to $t$, at most that. version:3
arxiv-1607-04358 | Modelling resource contention in multi-robot task allocation problems with uncertain timing | http://arxiv.org/abs/1607.04358 | id:1607.04358 author:Andrew W. Palmer, Andrew J. Hill, Steven J. Scheding category:cs.MA cs.RO  published:2016-07-15 summary:This paper proposes an analytical framework for modelling resource contention in multi-robot systems, where the travel times and task durations are uncertain. It uses several approximation methods to quickly and accurately calculate the probability distributions describing the times at which the tasks start and finish. Specific contributions include a method for calculating the probability of a set of independent normally distributed random events occurring in a given order, an upper bound on that probability, and a method for calculating the most likely and $n$-th most likely orders of occurrence for a set of independent normally distributed random events that have equal standard deviations. The complete framework is shown to be much faster than a Monte Carlo approach for the same accuracy in two multi-robot task allocation problems. This is a general framework that is agnostic to the optimisation method and objective function used, and is applicable to a wide range of robotics and non-robotics problems. version:2
arxiv-1702-00483 | FPGA-based real-time 105-channel data acquisition platform for imaging system | http://arxiv.org/abs/1702.00483 | id:1702.00483 author:Chengkai Guo, Jason Y. Du category:cs.AR  published:2017-01-18 summary:In this paper, a real-time 105-channel data acquisition platform based on FPGA for imaging will be implemented for mm-wave imaging systems. PC platform is also realized for imaging results monitoring purpose. Mm-wave imaging expands our vision by letting us see things under poor visibility conditions. With this extended vision ability, a wide range of military imaging missions would benefit, such as surveillance, precision targeting, navigation, and rescue. Based on the previously designed imager modules, this project would go on finishing the PCB design (both schematic and layout) of the following signal processing systems consisting of Programmable Gain Amplifier(PGA) (4 PGA for each ADC) and 16-channel Analog to Digital Converter (ADC) (7 ADC in total). Then the system verification would be performed on the Artix-7 35T Arty FPGA with the developing of proper controlling code to configure the ADC and realize the communication between the FPGA and the PC (through both UART and Ethernet). For the verification part, a simple test on a breadboard with a simple analog input (generated from a resistor divider) would first be performed. After the PCB design is finished, the whole system would be tested again with a precise reference and analog input. version:2
arxiv-1608-07547 | TriCheck: Memory Model Verification at the Trisection of Software, Hardware, and ISA | http://arxiv.org/abs/1608.07547 | id:1608.07547 author:Caroline Trippel, Yatin A. Manerkar, Daniel Lustig, Michael Pellauer, Margaret Martonosi category:cs.AR  published:2016-08-26 summary:Memory consistency models (MCMs) which govern inter-module interactions in a shared memory system, are a significant, yet often under-appreciated, aspect of system design. MCMs are defined at the various layers of the hardware-software stack, requiring thoroughly verified specifications, compilers, and implementations at the interfaces between layers. Current verification techniques evaluate segments of the system stack in isolation, such as proving compiler mappings from a high-level language (HLL) to an ISA or proving validity of a microarchitectural implementation of an ISA. This paper makes a case for full-stack MCM verification and provides a toolflow, TriCheck, capable of verifying that the HLL, compiler, ISA, and implementation collectively uphold MCM requirements. The work showcases TriCheck's ability to evaluate a proposed ISA MCM in order to ensure that each layer and each mapping is correct and complete. Specifically, we apply TriCheck to the open source RISC-V ISA, seeking to verify accurate, efficient, and legal compilations from C11. We uncover under-specifications and potential inefficiencies in the current RISC-V ISA documentation and identify possible solutions for each. As an example, we find that a RISC-V-compliant microarchitecture allows 144 outcomes forbidden by C11 to be observed out of 1,701 litmus tests examined. Overall, this paper demonstrates the necessity of full-stack verification for detecting MCM-related bugs in the hardware-software stack. version:2
arxiv-1702-02511 | Design of Stochastic Robotic Swarms for Target Performance Metrics in Boundary Coverage Tasks | http://arxiv.org/abs/1702.02511 | id:1702.02511 author:Ganesh P Kumar, Spring Berman category:cs.RO  published:2017-02-08 summary:In this work, we analyze \textit{stochastic coverage schemes} (SCS) for robotic swarms in which the robots randomly attach to a one-dimensional boundary of interest using local communication and sensing, without relying on global position information or a map of the environment. Robotic swarms may be required to perform boundary coverage in a variety of applications, including environmental monitoring, collective transport, disaster response, and nanomedicine. We present a novel analytical approach to computing and designing the statistical properties of the communication and sensing networks that are formed by random robot configurations on a boundary. We are particularly interested in the event that a robot configuration forms a connected communication network or maintains continuous sensor coverage of the boundary. Using tools from order statistics, random geometric graphs, and computational geometry, we derive formulas for properties of the random graphs generated by robots that are independently and identically distributed along a boundary. We also develop order-of-magnitude estimates of these properties based on Poisson approximations and threshold functions. For cases where the SCS generates a uniform distribution of robots along the boundary, we apply our analytical results to develop a procedure for computing the robot population size, diameter, sensing range, or communication range that yields a random communication network or sensor network with desired properties. version:1
arxiv-1702-02482 | A study on implementing a multithreaded version of the SIRENE detector simulation software for high energy neutrinos | http://arxiv.org/abs/1702.02482 | id:1702.02482 author:Petros Giannakopoulos, Michail Gkoumas, Ioannis Diplas, Georgios Voularinos, Theofanis Vlachos, Konstantia Balasi, Ekaterini Tzamariudaki, Christos Filippidis, Yiannis Cotronis, Christos Markou category:cs.DC  published:2017-02-08 summary:The primary objective of SIRENE is to simulate the response to neutrino events of any type of high energy neutrino telescope. Additionally, it implements different geometries for a neutrino detector and different configurations and characteristics of photo-multiplier tubes (PMTs) inside the optical modules of the detector through a library of C+ + classes. This could be considered a massive statistical analysis of photo-electrons. Aim of this work is the development of a multithreaded version of the SIRENE detector simulation software for high energy neutrinos. This approach allows utilization of multiple CPU cores leading to a potentially significant decrease in the required execution time compared to the sequential code. We are making use of the OpenMP framework for the production of multithreaded code running on the CPU. Finally, we analyze the feasibility of a GPU-accelerated implementation. version:1
arxiv-1702-02460 | Deterministic Backbone Creation in an SINR Network without Knowledge of Location | http://arxiv.org/abs/1702.02460 | id:1702.02460 author:Dariusz R. Kowalski, William K. Moses Jr., Shailesh Vaya category:cs.DC cs.DS F.2.2; G.2.2  published:2017-02-08 summary:For a given network, a backbone is an overlay network consisting of a connected dominating set with additional accessibility properties. Once a backbone is created for a network, it can be utilized for fast communication amongst the nodes of the network. The Signal-to-Interference-plus-Noise-Ratio (SINR) model has become the standard for modeling communication among devices in wireless networks. For this model, the community has pondered what the most realistic solutions for communication problems in wireless networks would look like. Such solutions would have the characteristic that they would make the least number of assumptions about the availability of information about the participating nodes. Solving problems when nothing at all is known about the network and having nodes just start participating would be ideal. However, this is quite challenging and most likely not feasible. The pragmatic approach is then to make meaningful assumptions about the available information and present efficient solutions based on this information. We present a solution for creation of backbone in the SINR model, when nodes do not have access to their physical coordinates or the coordinates of other nodes in the network. This restriction models the deployment of nodes in various situations for sensing hurricanes, cyclones, and so on, where only information about nodes prior to their deployment may be known but not their actual locations post deployment. We assume that nodes have access to knowledge of their label, the labels of nodes within their neighborhood, the range from which labels are taken $[N]$ and the total number of participating nodes $n$. We also assume that nodes wake up spontaneously. We present an efficient deterministic protocol to create a backbone with a round complexity of $O(\Delta \lg^2 N)$. version:1
arxiv-1702-02439 | An Executable Sequential Specification for Spark Aggregation | http://arxiv.org/abs/1702.02439 | id:1702.02439 author:Yu-Fang Chen, Chih-Duo Hong, OndÅej LengÃ¡l, Shin-Cheng Mu, Nishant Sinha, Bow-Yaw Wang category:cs.DC cs.LO  published:2017-02-08 summary:Spark is a new promising platform for scalable data-parallel computation. It provides several high-level application programming interfaces (APIs) to perform parallel data aggregation. Since execution of parallel aggregation in Spark is inherently non-deterministic, a natural requirement for Spark programs is to give the same result for any execution on the same data set. We present PureSpark, an executable formal Haskell specification for Spark aggregate combinators. Our specification allows us to deduce the precise condition for deterministic outcomes from Spark aggregation. We report case studies analyzing deterministic outcomes and correctness of Spark programs. version:1
arxiv-1702-02422 | Parallel implementation of a vehicle rail dynamical model for multi-core systems | http://arxiv.org/abs/1702.02422 | id:1702.02422 author:Anas M. Al-Oraiqat category:cs.DC  published:2017-02-08 summary:This research presents a model of a complex dynamic object running on a multi-core system. Discretization and numerical integration for multibody models of vehicle rail elements in the vertical longitudinal plane fluctuations is considered. The implemented model and solution of the motion differential equations allow estimating the basic processes occurring in the system with various external influences. Hence the developed programming model can be used for performing analysis and comparing new vehicle designs. Keywords-dynamic model; multi-core system; SMP system; rolling stock. version:1
arxiv-1702-02207 | Parallel implementation of the coupled harmonic oscillator | http://arxiv.org/abs/1702.02207 | id:1702.02207 author:Anas M. Al-Oraiqat category:cs.DC  published:2017-02-08 summary:This article presents the parallel implementation of the coupled harmonic oscillator. From the analytical solution of the coupled harmonic oscillator, the design parameters are obtained. After that, a numerical integration of the system with MATLAB, which is used as a tool of benchmark evaluation, is performed. Next, parallel implementation is performed using a well-known approach like OpenMP and WinAPI. Taking into account the errors of basic parameters of the simulated process, the generated oscillations of the proposed parallel realization are almost identical to the actual solution of the harmonic oscillator model. Test ways to optimize the parallel architecture of computing processes for software implementations of the considered application is carried out. The developed model is used to study a fixed priority scheduling algorithm for real-time parallel threads execution. The proposed parallel implementation of the considered dynamic system has an independent value and can be considered as a test for determining the characteristics of multi-core systems for time-critical simulation problems. Keywords: Harmonic oscillator, model, SMP, parallel programming, OpenMP; version:1
arxiv-1702-02313 | FASHION: Fault-Aware Self-Healing Intelligent On-chip Network | http://arxiv.org/abs/1702.02313 | id:1702.02313 author:Pengju Ren, Michel A. Kinsy, Mengjiao Zhu, Shreeya Khadka, Mihailo Isakov, Aniruddh Ramrakhyani, Tushar Krishna, Nanning Zheng category:cs.AR  published:2017-02-08 summary:To avoid packet loss and deadlock scenarios that arise due to faults or power gating in multicore and many-core systems, the network-on-chip needs to possess resilient communication and load-balancing properties. In this work, we introduce the Fashion router, a self-monitoring and self-reconfiguring design that allows for the on-chip network to dynamically adapt to component failures. First, we introduce a distributed intelligence unit, called Self-Awareness Module (SAM), which allows the router to detect permanent component failures and build a network connectivity map. Using local information, SAM adapts to faults, guarantees connectivity and deadlock-free routing inside the maximal connected subgraph and keeps routing tables up-to-date. Next, to reconfigure network links or virtual channels around faulty/power-gated components, we add bidirectional link and unified virtual channel structure features to the Fashion router. This version of the router, named Ex-Fashion, further mitigates the negative system performance impacts, leads to larger maximal connected subgraph and sustains a relatively high degree of fault-tolerance. To support the router, we develop a fault diagnosis and recovery algorithm executed by the Built-In Self-Test, self-monitoring, and self-reconfiguration units at runtime to provide fault-tolerant system functionalities. The Fashion router places no restriction on topology, position or number of faults. It drops 54.3-55.4% fewer nodes for same number of faults (between 30 and 60 faults) in an 8x8 2D-mesh over other state-of-the-art solutions. It is scalable and efficient. The area overheads are 2.311% and 2.659% when implemented in 8x8 and 16x16 2D-meshes using the TSMC 65nm library at 1.38GHz clock frequency. version:1
arxiv-1607-06269 | A Survey on Load Balancing Algorithms for VM Placement in Cloud Computing | http://arxiv.org/abs/1607.06269 | id:1607.06269 author:Minxian Xu, Wenhong Tian, Rajkumar Buyya category:cs.DC  published:2016-07-21 summary:The emergence of cloud computing based on virtualization technologies brings huge opportunities to host virtual resource at low cost without the need of owning any infrastructure. Virtualization technologies enable users to acquire, configure and be charged on pay-per-use basis. However, Cloud data centers mostly comprise heterogeneous commodity servers hosting multiple virtual machines (VMs) with potential various specifications and fluctuating resource usages, which may cause imbalanced resource utilization within servers that may lead to performance degradation and service level agreements (SLAs) violations. To achieve efficient scheduling, these challenges should be addressed and solved by using load balancing strategies, which have been proved to be NP-hard problem. From multiple perspectives, this work identifies the challenges and analyzes existing algorithms for allocating VMs to PMs in infrastructure Clouds, especially focuses on load balancing. A detailed classification targeting load balancing algorithms for VM placement in cloud data centers is investigated and the surveyed algorithms are classified according to the classification. The goal of this paper is to provide a comprehensive and comparative understanding of existing literature and aid researchers by providing an insight for potential future enhancements. version:3
arxiv-1702-02256 | Acceleration of low-latency gravitational wave searches using Maxwell-microarchitecture GPUs | http://arxiv.org/abs/1702.02256 | id:1702.02256 author:Xiangyu Guo, Qi Chu, Shin Kee Chung, Zhihui Du, Linqing Wen category:astro-ph.IM cs.DC  published:2017-02-08 summary:Low-latency detections of gravitational waves (GWs) are crucial to enable prompt follow-up observations to astrophysical transients by conventional telescopes. We have developed a low-latency pipeline using a technique called Summed Parallel Infinite Impulse Response (SPIIR) filtering, realized by a Graphic Processing Unit (GPU). In this paper, we exploit the new \textit{Maxwell} memory access architecture in NVIDIA GPUs, namely the read-only data cache, warp-shuffle, and cross-warp atomic techniques. We report a 3-fold speed-up over our previous implementation of this filtering technique. To tackle SPIIR with relatively few filters, we develop a new GPU thread configuration with a nearly 10-fold speedup. In addition, we implement a multi-rate scheme of SPIIR filtering using Maxwell GPUs. We achieve more than 100-fold speed-up over a single core CPU for the multi-rate filtering scheme. This results in an overall of 21-fold CPU usage reduction for the entire SPIIR pipeline. version:1
arxiv-1610-04391 | A guiding vector field algorithm for path following control of nonholonomic mobile robots | http://arxiv.org/abs/1610.04391 | id:1610.04391 author:Yuri A. Kapitanyuk, Anton V. Proskurnikov, Ming Cao category:cs.SY cs.RO math.OC  published:2016-10-14 summary:In this paper we propose an algorithm for path following control of the nonholonomic mobile robot based on the idea of the guiding vector field (GVF). The desired path may be an arbitrary smooth curve in its implicit form, that is, a level set of a predefined smooth function. Using this function and the robot's kinematic model, we design a GVF, whose integral curves converge to the trajectory. A nonlinear motion controller is then proposed which steers the robot along such an integral curve, bringing it to the desired path. We establish global convergence conditions for our algorithm and demonstrate its applicability and performance by experiments with real wheeled robots. version:2
arxiv-1702-02470 | Propagation via Kernelization: The Vertex Cover Constraint | http://arxiv.org/abs/1702.02470 | id:1702.02470 author:ClÃ©ment Carbonnel, Emmanuel HÃ©brard category:cs.AI  published:2017-02-07 summary:The technique of kernelization consists in extracting, from an instance of a problem, an essentially equivalent instance whose size is bounded in a parameter k. Besides being the basis for efficient param-eterized algorithms, this method also provides a wealth of information to reason about in the context of constraint programming. We study the use of kernelization for designing propagators through the example of the Vertex Cover constraint. Since the classic kernelization rules often correspond to dominance rather than consistency, we introduce the notion of "loss-less" kernel. While our preliminary experimental results show the potential of the approach, they also show some of its limits. In particular, this method is more effective for vertex covers of large and sparse graphs, as they tend to have, relatively, smaller kernels. version:1
arxiv-1702-01973 | Achieving Dilution without Knowledge of Coordinates in the SINR Model | http://arxiv.org/abs/1702.01973 | id:1702.01973 author:William K. Moses Jr., Shailesh Vaya category:cs.DC F.2.2  published:2017-02-07 summary:Considerable literature has been developed for various fundamental distributed problems in the SINR (Signal-to-Interference-plus-Noise-Ratio) model for radio transmission. A setting typically studied is when all nodes transmit a signal of the same strength, and each device only has access to knowledge about the total number of nodes in the network $n$, the range from which each node's label is taken $[1,\dots,N]$, and the label of the device itself. In addition, an assumption is made that each node also knows its coordinates in the Euclidean plane. In this paper, we create a technique which allows algorithm designers to remove that last assumption. The assumption about the unavailability of the knowledge of the physical coordinates of the nodes truly captures the `ad-hoc' nature of wireless networks. Previous work in this area uses a flavor of a technique called dilution, in which nodes transmit in a (predetermined) round-robin fashion, and are able to reach all their neighbors. However, without knowing the physical coordinates, it's not possible to know the coordinates of their containing (pivotal) grid box and seemingly not possible to use dilution (to coordinate their transmissions). We propose a new technique to achieve dilution without using the knowledge of physical coordinates. This technique exploits the understanding that the transmitting nodes lie in 2-D space, segmented by an appropriate pivotal grid, without explicitly referring to the actual physical coordinates of these nodes. Using this technique, it is possible for every weak device to successfully transmit its message to all of its neighbors in $\Theta(\lg N)$ rounds, as long as the density of transmitting nodes in any physical grid box is bounded by a known constant. This technique, we feel, is an important generic tool for devising practical protocols when physical coordinates of the nodes are not known. version:1
arxiv-1608-05742 | Extending the OpenAI Gym for robotics: a toolkit for reinforcement learning using ROS and Gazebo | http://arxiv.org/abs/1608.05742 | id:1608.05742 author:Iker Zamora, Nestor Gonzalez Lopez, Victor Mayoral Vilches, Alejandro Hernandez Cordero category:cs.RO  published:2016-08-19 summary:This paper presents an extension of the OpenAI Gym for robotics using the Robot Operating System (ROS) and the Gazebo simulator. The content discusses the software architecture proposed and the results obtained by using two Reinforcement Learning techniques: Q-Learning and Sarsa. Ultimately, the output of this work presents a benchmarking system for robotics that allows different techniques and algorithms to be compared using the same virtual conditions. version:2
arxiv-1701-07154 | Cost-Aware Resource Allocation for Fog-Cloud Computing Systems | http://arxiv.org/abs/1701.07154 | id:1701.07154 author:Liang Yu, Tao Jiang, Ming Sun, Yulong Zou category:cs.DC  published:2017-01-25 summary:As a complement to cloud computing, fog computing can offer many benefits in terms of avoiding the long wide-area network (WAN) propagation delay and relieving the network bandwidth burden by providing local services to nearby end users, resulting in a reduced revenue loss associated with the WAN propagation delay and network bandwidth cost for a cloud provider. However, serving the requests of end-users would lead to additional energy costs for fog devices, thus the could provider must compensate fog devices for their losses. In this paper, we investigate the problem of minimizing the total cost of a cloud provider without sacrificing the interests of fog devices. To be specific, we first formulate a total cost minimization problem for the cloud provider, where the cost consists of four parts, namely the energy cost of data centers, network bandwidth cost, revenue loss associated with WAN propagation delay, and the economic compensation paid to fog devices. Note that the formulated problem is a large-scale mixed integer linear programming, which is in general NP-hard. To solve the problem efficiently, a distributed heuristic algorithm is designed based on Proximal Jacobian Alternating Direction Method of Multipliers (ADMM), which determines the number of active fog devices, workload allocation, and the number of active servers in each cloud data center. Extensive simulation results show the effectiveness of the designed heuristic algorithm. version:2
arxiv-1702-01894 | CAAD: Computer Architecture for Autonomous Driving | http://arxiv.org/abs/1702.01894 | id:1702.01894 author:Shaoshan Liu, Jie Tang, Zhe Zhang, Jean-Luc Gaudiot category:cs.AR cs.RO  published:2017-02-07 summary:We describe the computing tasks involved in autonomous driving, examine existing autonomous driving computing platform implementations. To enable autonomous driving, the computing stack needs to simultaneously provide high performance, low power consumption, and low thermal dissipation, at low cost. We discuss possible approaches to design computing platforms that will meet these needs. version:1
arxiv-1702-01886 | Extracting Lifted Mutual Exclusion Invariants from Temporal Planning Domains | http://arxiv.org/abs/1702.01886 | id:1702.01886 author:Sara Bernardini, Fabio Fagnani, David E. Smith category:cs.AI  published:2017-02-07 summary:We present a technique for automatically extracting mutual exclusion invariants from temporal planning instances. It first identifies a set of invariant templates by inspecting the lifted representation of the domain and then checks these templates against properties that assure invariance. Our technique builds on other approaches to invariant synthesis presented in the literature, but departs from their limited focus on instantaneous actions by addressing temporal domains. To deal with time, we formulate invariance conditions that account for the entire structure of the actions and the possible concurrent interactions between them. As a result, we construct a significantly more comprehensive technique than previous methods, which is able to find not only invariants for temporal domains, but also a broader set of invariants for non-temporal domains. The experimental results reported in this paper provide evidence that identifying a broader set of invariants results in the generation of fewer multi-valued state variables with larger domains. We show that, in turn, this reduction in the number of variables reflects positively on the performance of a number of temporal planners that use a variable/value representation by significantly reducing their running time. version:1
arxiv-1702-01848 | Data-Driven Learning and Planning for Environmental Sampling | http://arxiv.org/abs/1702.01848 | id:1702.01848 author:Kai-Chieh Ma, Lantao Liu, Hordur K. Heidarsson, Gaurav S. Sukhatme category:cs.RO  published:2017-02-07 summary:Robots such as autonomous underwater vehicles (AUVs) and autonomous surface vehicles (ASVs) have been used for sensing and monitoring aquatic environments such as oceans and lakes. Environmental sampling is a challenging task because the environmental attributes to be observed can vary both spatially and temporally, and the target environment is usually a large and continuous domain whereas the sampling data is typically sparse and limited. The challenges require that the sampling method must be informative and efficient enough to catch up with the environmental dynamics. In this paper we present a planning and learning method that enables a sampling robot to perform persistent monitoring tasks by learning and refining a spatiotemporal environmental model. Our environmental sampling framework consists of two components: to maximize the information collected, we propose an informative planning component that efficiently generates sampling waypoints that contain the maximal information; To alleviate the computational bottleneck caused by large-scale data accumulated, we develop a component based on a sparse Gaussian Process whose hyperparameters are learned online by taking advantage of only a subset of data that provides the greatest contribution. We validate our method with both simulations running on real ocean data and field trials with an ASV in a lake environment. Our experiments show that the proposed framework is both accurate and efficient in learning the spatiotemporal environmental model version:1
arxiv-1604-01277 | Landmark-Based Plan Recognition | http://arxiv.org/abs/1604.01277 | id:1604.01277 author:Ramon Fraga Pereira, Felipe Meneguzzi category:cs.AI  published:2016-04-05 summary:Recognition of goals and plans using incomplete evidence from action execution can be done efficiently by using planning techniques. In many applications it is important to recognize goals and plans not only accurately, but also quickly. In this paper, we develop a heuristic approach for recognizing plans based on planning techniques that rely on ordering constraints to filter candidate goals from observations. These ordering constraints are called landmarks in the planning literature, which are facts or actions that cannot be avoided to achieve a goal. We show the applicability of planning landmarks in two settings: first, we use it directly to develop a heuristic-based plan recognition approach; second, we refine an existing planning-based plan recognition approach by pre-filtering its candidate goals. Our empirical evaluation shows that our approach is not only substantially more accurate than the state-of-the-art in all available datasets, it is also an order of magnitude faster. version:3
arxiv-1702-01805 | A Digital Hardware Fast Algorithm and FPGA-based Prototype for a Novel 16-point Approximate DCT for Image Compression Applications | http://arxiv.org/abs/1702.01805 | id:1702.01805 author:F. M. Bayer, R. J. Cintra, A. Edirisuriya, A. Madanayake category:cs.MM cs.AR cs.DS cs.IT math.IT stat.ME  published:2017-02-06 summary:The discrete cosine transform (DCT) is the key step in many image and video coding standards. The 8-point DCT is an important special case, possessing several low-complexity approximations widely investigated. However, 16-point DCT transform has energy compaction advantages. In this sense, this paper presents a new 16-point DCT approximation with null multiplicative complexity. The proposed transform matrix is orthogonal and contains only zeros and ones. The proposed transform outperforms the well-know Walsh-Hadamard transform and the current state-of-the-art 16-point approximation. A fast algorithm for the proposed transform is also introduced. This fast algorithm is experimentally validated using hardware implementations that are physically realized and verified on a 40 nm CMOS Xilinx Virtex-6 XC6VLX240T FPGA chip for a maximum clock rate of 342 MHz. Rapid prototypes on FPGA for 8-bit input word size shows significant improvement in compressed image quality by up to 1-2 dB at the cost of only eight adders compared to the state-of-art 16-point DCT approximation algorithm in the literature [S. Bouguezel, M. O. Ahmad, and M. N. S. Swamy. A novel transform for image compression. In {\em Proceedings of the 53rd IEEE International Midwest Symposium on Circuits and Systems (MWSCAS)}, 2010]. version:1
arxiv-1603-07322 | On Delay-Optimal Scheduling in Queueing Systems with Replications | http://arxiv.org/abs/1603.07322 | id:1603.07322 author:Yin Sun, C. Emre Koksal, Ness B. Shroff category:cs.PF cs.DC cs.IT cs.NI math.IT math.PR  published:2016-03-23 summary:In modern computer systems, jobs are divided into short tasks and executed in parallel. Empirical observations in practical systems suggest that the task service times are highly random and the job service time is bottlenecked by the slowest straggling task. One common solution for straggler mitigation is to replicate a task on multiple servers and wait for one replica of the task to finish early. The delay performance of replications depends heavily on the scheduling decisions of when to replicate, which servers to replicate on, and which job to serve first. So far, little is understood on how to optimize these scheduling decisions for minimizing the delay to complete the jobs. In this paper, we present a comprehensive study on delay-optimal scheduling of replications in both centralized and distributed multi-server systems. Low-complexity scheduling policies are designed and are proven to be delay-optimal or near delay-optimal in stochastic ordering among all causal and non-preemptive policies. These theoretical results are established for general system settings and delay metrics that allow for arbitrary arrival processes, arbitrary job sizes, arbitrary due times, and heterogeneous servers with data locality constraints. Novel sample-path tools are developed to prove these results. version:8
arxiv-1702-01786 | Unobtrusive Deferred Update Stabilization for Efficient Geo-Replication | http://arxiv.org/abs/1702.01786 | id:1702.01786 author:Chathuri Gunawardhana, Manuel Bravo, LuÃ­s Rodrigues category:cs.DC cs.DB  published:2017-02-06 summary:In this paper we propose a novel approach to manage the throughput vs latency tradeoff that emerges when managing updates in geo-replicated systems. Our approach consists in allowing full concurrency when processing local updates and using a deferred local serialisation procedure before shipping updates to remote datacenters. This strategy allows to implement inexpensive mechanisms to ensure system consistency requirements while avoiding intrusive effects on update operations, a major performance limitation of previous systems. We have implemented our approach as a variant of Riak KV. Our extensive evaluation shows that we outperform sequencer-based approaches by almost an order of magnitude in the maximum achievable throughput. Furthermore, unlike previous sequencer-free solutions, our approach reaches nearly optimal remote update visibility latencies without limiting throughput. version:1
arxiv-1702-01785 | Model-driven Scheduling for Distributed Stream Processing Systems | http://arxiv.org/abs/1702.01785 | id:1702.01785 author:Anshu Shukla, Yogesh Simmhan category:cs.DC  published:2017-02-06 summary:Distributed Stream Processing frameworks are being commonly used with the evolution of Internet of Things(IoT). These frameworks are designed to adapt to the dynamic input message rate by scaling in/out.Apache Storm, originally developed by Twitter is a widely used stream processing engine while others includes Flink, Spark streaming. For running the streaming applications successfully there is need to know the optimal resource requirement, as over-estimation of resources adds extra cost.So we need some strategy to come up with the optimal resource requirement for a given streaming application. In this article, we propose a model-driven approach for scheduling streaming applications that effectively utilizes a priori knowledge of the applications to provide predictable scheduling behavior. Specifically, we use application performance models to offer reliable estimates of the resource allocation required. Further, this intuition also drives resource mapping, and helps narrow the estimated and actual dataflow performance and resource utilization. Together, this model-driven scheduling approach gives a predictable application performance and resource utilization behavior for executing a given DSPS application at a target input stream rate on distributed resources. version:1
arxiv-1702-01783 | From Formalised State Machines to Implementations of Robotic Controllers | http://arxiv.org/abs/1702.01783 | id:1702.01783 author:Wei Li, Alvaro Miyazawa, Pedro Ribeiro, Ana Cavalcanti, Jim Woodcock, Jon Timmis category:cs.RO cs.SE  published:2017-02-06 summary:Controllers for autonomous robotic systems can be specified using state machines. However, these are typically developed in an ad hoc manner without formal semantics, which makes it difficult to analyse the controller. Simulations are often used during the development, but a rigorous connection between the designed controller and the implementation is often overlooked. This paper presents a state-machine based notation, RoboChart, together with a tool to automatically create code from the state machines, establishing a rigorous connection between specification and implementation. In RoboChart, a robot's controller is specified either graphically or using a textual description language. The controller code for simulation is automatically generated through a direct mapping from the specification. We demonstrate our approach using two case studies (self-organized aggregation and swarm taxis) in swarm robotics. The simulations are presented using two different simulators showing the general applicability of our approach. version:1
arxiv-1702-02063 | Performance Control of Tendon-Driven Endoscopic Surgical Robots With Friction and Hysteresis | http://arxiv.org/abs/1702.02063 | id:1702.02063 author:Thanh Nho Do, Tegoeh Tjahjowidodo, Michael Wai Shing Lau, Soo Jay Phee category:cs.RO math.DS  published:2017-02-06 summary:In this study, a new position control scheme for the tendon-sheath mechanism (TSM) which is used in flexible medical devices is presented. TSM is widely used in dexterous robotic applications because it can flexibly work in limited space, in constrained environments, and provides efficient power transmission from the external actuator to the distal joint. However, nonlinearities from friction and backlash hysteresis between the tendon and the sheath pose challenges in achieving precise position controls of the end effector. Previous studies on the TSM only address the control problem under the assumptions of known tendon-sheath configuration and known model parameters of the backlash hysteresis nonlinearity. These approaches can have adverse impact and limitations on the overall system performances and practical implementation. This paper presents a new approach to model and control the TSM-driven flexible robotic systems. The designed controller does not require exact knowledge of nonlinear friction and backlash hysteresis parameters, only their bounds are online estimated. Simulation and experimental validation results show that the proposed control scheme can significantly improve the tracking performances without the presence of the exact knowledge of the model parameters and the sheath configuration. version:1
arxiv-1702-01601 | Exploring the bidimensional space: A dynamic logic point of view | http://arxiv.org/abs/1702.01601 | id:1702.01601 author:Philippe Balbiani, David FernÃ¡ndez-Duque, Emiliano Lorini category:cs.AI cs.LO  published:2017-02-06 summary:We present a family of logics for reasoning about agents' positions and motion in the plane which have several potential applications in the area of multi-agent systems (MAS), such as multi-agent planning and robotics. The most general logic includes (i) atomic formulas for representing the truth of a given fact or the presence of a given agent at a certain position of the plane, (ii) atomic programs corresponding to the four basic orientations in the plane (up, down, left, right) as well as the four program constructs of propositional dynamic logic (sequential composition, nondeterministic composition, iteration and test). As this logic is not computably enumerable, we study some interesting decidable and axiomatizable fragments of it. We also present a decidable extension of the iteration-free fragment of the logic by special programs representing motion of agents in the plane. version:1
arxiv-1702-07252 | Experimental Validation of Contact Dynamicsfor In-Hand Manipulation | http://arxiv.org/abs/1702.07252 | id:1702.07252 author:Roman Kolbert, Nikhil Chavan-Dafle, Alberto Rodriguez category:cs.RO  published:2017-02-06 summary:This paper evaluates state-of-the-art contact models at predicting the motions and forces involved in simple in-hand robotic manipulations. In particular it focuses on three primitive actions --linear sliding, pivoting, and rolling-- that involve contacts between a gripper, a rigid object, and their environment. The evaluation is done through thousands of controlled experiments designed to capture the motion of object and gripper, and all contact forces and torques at 250Hz. We demonstrate that a contact modeling approach based on Coulomb's friction law and maximum energy principle is effective at reasoning about interaction to first order, but limited for making accurate predictions. We attribute the major limitations to 1) the non-uniqueness of force resolution inherent to grasps with multiple hard contacts of complex geometries, 2) unmodeled dynamics due to contact compliance, and 3) unmodeled geometries dueto manufacturing defects. version:1
arxiv-1703-00375 | On Using Micro-Clouds to Deliver the Fog | http://arxiv.org/abs/1703.00375 | id:1703.00375 author:Yehia Elkhatib, Barry Porter, Heverson B. Ribeiro, Mohamed Faten Zhani, Junaid Qadir, Etienne Riviere category:cs.DC  published:2017-02-06 summary:Cloud computing has demonstrated itself to be a scalable and cost-efficient solution for many real-world applications. However, its modus operandi is not ideally suited to resource-constrained environments that are characterized by limited network bandwidth and high latencies. With the increasing proliferation and sophistication of edge devices, the idea of fog computing proposes to offload some of the computation to the edge. To this end, micro-clouds---which are modular and portable assemblies of small single-board computers---have started to gain attention as infrastructures to support fog computing by offering isolated resource provisioning at the edge in a cost-effective way. We investigate the feasibility and readiness of micro-clouds for delivering the vision of fog computing. Through a number of experiments, we showcase the potential of micro-clouds formed by collections of Raspberry Pi computers to host a range of fog-related applications, particularly for locations where there is limited network bandwidths and long latencies. version:1
arxiv-1610-00913 | Distributed Cooperative Manipulation under Timed Temporal Specifications | http://arxiv.org/abs/1610.00913 | id:1610.00913 author:Christos K. Verginis, Dimos V. Dimarogonas category:cs.RO  published:2016-10-04 summary:This paper addresses the problem of cooperative manipulation of a single object by N robotic agents under local goal specifications given as Metric Interval Temporal Logic (MITL) formulas. In particular, we propose a distributed model-free control protocol for the trajectory tracking of the cooperatively manipulated object without necessitating feedback of the contact forces/torques or inter-agent communication. This allows us to abstract the motion of the coupled object-agents system as a finite transition system and, by employing standard automata-based methodologies, we derive a hybrid control algorithm for the satisfaction of a given MITL formula. In addition, we use load sharing coefficients to represent potential differences in power capabilities among the agents. Finally, simulation studies verify the validity of the proposed scheme. version:4
arxiv-1702-01510 | Survey of modern Fault Diagnosis methods in networks | http://arxiv.org/abs/1702.01510 | id:1702.01510 author:Zi Jian Yang, Yong Wang category:cs.AI  published:2017-02-06 summary:With the advent of modern computer networks, fault diagnosis has been a focus of research activity. This paper reviews the history of fault diagnosis in networks and discusses the main methods in information gathering section, information analyzing section and diagnosing and revolving section of fault diagnosis in networks. Emphasis will be placed upon knowledge-based methods with discussing the advantages and shortcomings of the different methods. The survey is concluded with a description of some open problems. version:1
arxiv-1702-01508 | Transplantation of Data Mining Algorithms to Cloud Computing Platform when Dealing Big Data | http://arxiv.org/abs/1702.01508 | id:1702.01508 author:Yong Wang, Ya Wei Zhao category:cs.DC  published:2017-02-06 summary:This paper made a short review of Cloud Computing and Big Data, and discussed the portability of general data mining algorithms to Cloud Computing platform. It revealed the Cloud Computing platform based on Map-Reduce cannot solve all the Big Data and data mining problems. Transplanting the general data mining algorithms to the real-time Cloud Computing platform will be one of the research focuses in Cloud Computing and Big Data. version:1
arxiv-1612-05143 | Sampling-based Motion Planning for Active Multirotor System Identification | http://arxiv.org/abs/1612.05143 | id:1612.05143 author:Rik BÃ¤hnemann, Michael Burri, Enric Galceran, Roland Siegwart, Juan Nieto category:cs.RO  published:2016-12-15 summary:This paper reports on an algorithm for planning trajectories that allow a multirotor micro aerial vehicle (MAV) to quickly identify a set of unknown parameters. In many problems like self calibration or model parameter identification some states are only observable under a specific motion. These motions are often hard to find, especially for inexperienced users. Therefore, we consider system model identification in an active setting, where the vehicle autonomously decides what actions to take in order to quickly identify the model. Our algorithm approximates the belief dynamics of the system around a candidate trajectory using an extended Kalman filter (EKF). It uses sampling-based motion planning to explore the space of possible beliefs and find a maximally informative trajectory within a user-defined budget. We validate our method in simulation and on a real system showing the feasibility and repeatability of the proposed approach. Our planner creates trajectories which reduce model parameter convergence time and uncertainty by a factor of four. version:2
arxiv-1702-01443 | Enhancing Elasticity of SaaS Applications using Queuing Theory | http://arxiv.org/abs/1702.01443 | id:1702.01443 author:Ashraf A. Shahin category:cs.DC  published:2017-02-05 summary:Elasticity is one of key features of cloud computing. Elasticity allows Software as a Service (SaaS) applications' provider to reduce cost of running applications. In large SaaS applications that are developed using service-oriented architecture model, each service is deployed in a separated virtual machine and may use one or more services to complete its task. Although, scaling service independently from its required services propagates scaling problem to other services, most of current elasticity approaches do not consider functional dependencies between services, which increases the probability of violating service level agreement. In this paper, architecture of SaaS application is modeled as multi-class M/M/m processor sharing queuing model with deadline to take into account functional dependencies between services during estimating required scaling resources. Experimental results show effectiveness of the proposed model in estimating required resources during scaling virtual resources. version:1
arxiv-1702-01396 | A Tabu Search based clustering algorithm and its parallel implementation on Spark | http://arxiv.org/abs/1702.01396 | id:1702.01396 author:Yinhao Lu, Buyang Cao, Fred Glover category:cs.DC cs.SI  published:2017-02-05 summary:The well-known K-means clustering algorithm has been employed widely in different application domains ranging from data analytics to logistics applications. However, the K-means algorithm can be affected by factors such as the initial choice of centroids and can readily become trapped in a local optimum. In this paper, we propose an improved K-means clustering algorithm that is augmented by a Tabu Search strategy, and which is better adapted to meet the needs of big data applications. Our design is further enhanced to take advantage of parallel processing based on the Spark framework. Computational experiments demonstrate the superiority of our Tabu Search based clustering algorithm over a widely used version of the K-means approach embodied in Spark MLlib, comparing the algorithms in terms of scalability, accuracy, and effectiveness. version:1
arxiv-1604-04575 | Proof-relevant $Ï$-calculus: a constructive account of concurrency and causality | http://arxiv.org/abs/1604.04575 | id:1604.04575 author:Roly Perera, James Cheney category:cs.LO cs.DC  published:2016-04-15 summary:We present a formalisation in Agda of the theory of concurrent transitions, residuation, and causal equivalence of traces for the pi-calculus. Our formalisation employs de Bruijn indices and dependently-typed syntax, and aligns the "proved transitions" proposed by Boudol and Castellani in the context of CCS with the proof terms naturally present in Agda's representation of the labelled transition relation. Our main contributions are proofs of the "diamond lemma" for the residuals of concurrent transitions and a formal definition of equivalence of traces up to permutation of transitions. In the pi-calculus transitions represent propagating binders whenever their actions involve bound names. To accommodate these cases, we require a more general diamond lemma where the target states of equivalent traces are no longer identical, but are related by a braiding that rewires the bound and free names to reflect the particular interleaving of events involving binders. Our approach may be useful for modelling concurrency in other languages where transitions carry metadata sensitive to particular interleavings, such as dynamically allocated memory addresses. version:2
arxiv-1404-4250 | Witness structures and immediate snapshot complexes | http://arxiv.org/abs/1404.4250 | id:1404.4250 author:Dmitry N. Kozlov category:cs.DC 57-XX  published:2014-04-16 summary:In this paper we introduce and study a new family of combinatorial simplicial complexes, which we call immediate snapshot complexes. Our construction and terminology is strongly motivated by theoretical distributed computing, as these complexes are combinatorial models of the standard protocol complexes associated to immediate snapshot read/write shared memory communication model. In order to define the immediate snapshot complexes we need a new combinatorial object, which we call a witness structure. These objects are indexing the simplices in the immediate snapshot complexes, while a special operation on them, called ghosting, describes the combinatorics of taking simplicial boundary. In general, we develop the theory of witness structures and use it to prove several combinatorial as well as topological properties of the immediate snapshot complexes. version:3
arxiv-1612-07386 | SE-Sync: A Certifiably Correct Algorithm for Synchronization over the Special Euclidean Group | http://arxiv.org/abs/1612.07386 | id:1612.07386 author:David M. Rosen, Luca Carlone, Afonso S. Bandeira, John J. Leonard category:cs.RO  published:2016-12-21 summary:Many important geometric estimation problems take the form of synchronization over the special Euclidean group: estimate the values of a set of poses given a set of relative measurements between them. This problem is typically formulated as a nonconvex maximum-likelihood estimation that is computationally hard to solve in general. Nevertheless, in this paper we present an algorithm that is able to efficiently recover certifiably globally optimal solutions of the special Euclidean synchronization problem in a non-adversarial noise regime. The crux of our approach is the development of a semidefinite relaxation of the maximum-likelihood estimation whose minimizer provides an exact MLE so long as the magnitude of the noise corrupting the available measurements falls below a certain critical threshold; furthermore, whenever exactness obtains, it is possible to verify this fact a posteriori, thereby certifying the optimality of the recovered estimate. We develop a specialized optimization scheme for solving large-scale instances of this relaxation by exploiting its low-rank, geometric, and graph-theoretic structure to reduce it to an equivalent optimization problem on a low-dimensional Riemannian manifold, and design a truncated-Newton trust-region method to solve this reduction efficiently. Finally, we combine this fast optimization approach with a simple rounding procedure to produce our algorithm, SE-Sync. Experimental evaluation on a variety of simulated and real-world pose-graph SLAM datasets shows that SE-Sync is able to recover certifiably globally optimal solutions when the available measurements are corrupted by noise up to an order of magnitude greater than that typically encountered in robotics and computer vision applications, and does so more than an order of magnitude faster than the Gauss-Newton-based approach that forms the basis of current state-of-the-art techniques. version:2
arxiv-1610-09261 | CHOPtrey: contextual online polynomial extrapolation for enhanced multi-core co-simulation of complex systems | http://arxiv.org/abs/1610.09261 | id:1610.09261 author:Abir Ben Khaled-El Feki, Laurent Duval, Cyril Faure, Daniel Simon, Mongi Ben Gaid category:cs.SY cs.CE cs.DC  published:2016-10-28 summary:The growing complexity of Cyber-Physical Systems (CPS), together with increasingly available parallelism provided by multi-core chips, fosters the parallelization of simulation. Simulation speed-ups are expected from co-simulation and parallelization based on model splitting into weak-coupled sub-models, as for instance in the framework of Functional Mockup Interface (FMI). However, slackened synchronization between sub-models and their associated solvers running in parallel introduces integration errors, which must be kept inside acceptable bounds. CHOPtrey denotes a forecasting framework enhancing the performance of complex system co-simulation, with a trivalent articulation. First, we consider the framework of a Computationally Hasty Online Prediction system (CHOPred). It allows to improve the trade-off between integration speed-ups, needing large communication steps, and simulation precision, needing frequent updates for model inputs. Second, smoothed adaptive forward prediction improves co-simulation accuracy. It is obtained by past-weighted extrapolation based on Causal Hopping Oblivious Polynomials (CHOPoly). And third, signal behavior is segmented to handle the discontinuities of the exchanged signals: the segmentation is performed in a Contextual \& Hierarchical Ontology of Patterns (CHOPatt). Implementation strategies and simulation results demonstrate the framework ability to adaptively relax data communication constraints beyond synchronization points which sensibly accelerate simulation. The CHOPtrey framework extends the range of applications of standard Lagrange-type methods, often deemed unstable. The embedding of predictions in lag-dependent smoothing and discontinuity handling demonstrates its practical efficiency. version:2
arxiv-1702-01332 | Manyopt: An Extensible Tool for Mixed, Non-Linear Optimization Through SMT Solving | http://arxiv.org/abs/1702.01332 | id:1702.01332 author:Andrea Callia D'Iddio, Michael Huth category:cs.AI cs.MS  published:2017-02-04 summary:Optimization of Mixed-Integer Non-Linear Programming (MINLP) supports important decisions in applications such as Chemical Process Engineering. But current solvers have limited ability for deductive reasoning or the use of domain-specific theories, and the management of integrality constraints does not yet exploit automated reasoning tools such as SMT solvers. This seems to limit both scalability and reach of such tools in practice. We therefore present a tool, ManyOpt, for MINLP optimization that enables experimentation with reduction techniques which transform a MINLP problem to feasibility checking realized by an SMT solver. ManyOpt is similar to the SAT solver ManySAT in that it runs a specified number of such reduction techniques in parallel to get the strongest result on a given MINLP problem. The tool is implemented in layers, which we may see as features and where reduction techniques are feature vectors. Some of these features are inspired by known MINLP techniques whereas others are novel and specific to SMT. Our experimental results on standard benchmarks demonstrate the benefits of this approach. The tool supports a variety of SMT solvers and is easily extensible with new features, courtesy of its layered structure. For example, logical formulas for deductive reasoning are easily added to constrain further the optimization of a MINLP problem of interest. version:1
arxiv-1505-05312 | A New Oscillating-Error Technique for Classifiers | http://arxiv.org/abs/1505.05312 | id:1505.05312 author:Kieran Greer category:cs.AI  published:2015-05-20 summary:This paper describes a new method for reducing the error in a classifier. It uses an error correction update that includes the very simple rule of either adding or subtracting the error adjustment, based on whether the variable value is currently larger or smaller than the desired value. While a traditional neuron would sum the inputs together and then apply a function to the total, this new method can change the function decision for each input value. This gives added flexibility to the convergence procedure, where through a series of transpositions, variables that are far away can continue towards the desired value, whereas variables that are originally much closer can oscillate from one side to the other. Tests show that the method can successfully classify some benchmark datasets. It can also work in a batch mode, with reduced training times and can be used as part of a neural network architecture. Some comparisons with an earlier wave shape paper are also made. version:6
arxiv-1702-01295 | Embedded Systems Architecture for SLAM Applications | http://arxiv.org/abs/1702.01295 | id:1702.01295 author:Jie Tang, Shaoshan Liu, Jean-Luc Gaudiot category:cs.AR  published:2017-02-04 summary:In recent years, we have observed a clear trend in the rapid rise of autonomous vehicles, robotics, virtual reality, and augmented reality. The core technology enabling these applications, Simultaneous Localization And Mapping (SLAM), imposes two main challenges: first, these workloads are computationally intensive and they often have real-time requirements; second, these workloads run on battery-powered mobile devices with limited energy budget. In short, the essence of these challenges is that performance should be improved while simultaneously reducing energy consumption, two rather contradicting goals by conventional wisdom. In this paper, we take a close look at state-of-the-art Simultaneous Localization And Mapping (SLAM) workloads, especially how these workloads behave on mobile devices. Based on the results, we propose a mobile architecture to improve SLAM performance on mobile devices. version:1
arxiv-1607-01883 | Sampling-based Incremental Information Gathering with Applications to Robotic Exploration and Environmental Monitoring | http://arxiv.org/abs/1607.01883 | id:1607.01883 author:Maani Ghaffari Jadidi, Jaime Valls Miro, Gamini Dissanayake category:cs.RO  published:2016-07-07 summary:In this article, we propose a sampling-based motion planning algorithm equipped with an information-theoretic convergence criterion for incremental informative motion planning. The proposed approach allows dense map representations and incorporates the full state uncertainty into the planning process. The problem is formulated as a maximization problem with a budget constraint. Our approach is built on rapidly-exploring information gathering algorithms and benefits from advantages of sampling-based optimal motion planning algorithms. We propose two information functions and their variants for fast and online computations. We prove an information-theoretic convergence for the entire exploration and information gathering mission based on the least upper bound of the average map entropy. The convergence criterion gives rise to a natural automatic stopping criterion for information-driven motion control. We demonstrate the performance of the proposed algorithms using three scenarios: comparison of the proposed information functions and sensor configuration selection, robotic exploration in unknown environments, and a wireless signal strength monitoring task in a lake from a publicly available dataset collected using an autonomous surface vehicle. version:4
arxiv-1702-02032 | Solving the Brachistochrone Problem by an Influence Diagram | http://arxiv.org/abs/1702.02032 | id:1702.02032 author:JiÅÃ­ Vomlel category:math.OC cs.AI 68T37 I.2  published:2017-02-04 summary:Influence diagrams are a decision-theoretic extension of probabilistic graphical models. In this paper we show how they can be used to solve the Brachistochrone problem. We present results of numerical experiments on this problem, compare the solution provided by the influence diagram with the optimal solution. The R code used for the experiments is presented in the Appendix. version:1
arxiv-1608-04431 | Parallel Non-divergent Flow Accumulation For Trillion Cell Digital Elevation Models On Desktops Or Clusters | http://arxiv.org/abs/1608.04431 | id:1608.04431 author:Richard Barnes category:cs.DC cs.DS  published:2016-08-15 summary:Continent-scale datasets challenge hydrological algorithms for processing digital elevation models. Flow accumulation is an important input for many such algorithms; here, I parallelize its calculation. The new algorithm works on one or many cores, or multiple machines, and can take advantage of large memories or cope with small ones. Unlike previous parallel algorithms, the new algorithm guarantees a fixed number of memory access and communication events per raster cell. In testing, the new algorithm ran faster and used fewer resources than previous algorithms, exhibiting ~30% strong and weak scaling efficiencies up to 48 cores and linear scaling across datasets ranging over three orders of magnitude. The largest dataset tested had two trillion (2*10^12) cells. With 48 cores, processing required 24 minutes wall-time (14.5 compute-hours). This test is three orders of magnitude larger than any previously performed in the literature. Complete, well-commented source code and correctness tests are available on Github. version:2
arxiv-1702-01075 | Safe Certificate-Based Maneuvers for Teams of Quadrotors Using Differential Flatness | http://arxiv.org/abs/1702.01075 | id:1702.01075 author:Li Wang, Aaron D. Ames, Magnus Egerstedt category:cs.RO  published:2017-02-03 summary:Safety Barrier Certificates that ensure collision-free maneuvers for teams of differential flatness-based quadrotors are presented in this paper. Synthesized with control barrier functions, the certificates are used to modify the nominal trajectory in a minimally invasive way to avoid collisions. The proposed collision avoidance strategy complements existing flight control and planning algorithms by providing trajectory modifications with provable safety guarantees. The effectiveness of this strategy is supported both by the theoretical results and experimental validation on a team of five quadrotors. version:1
arxiv-1702-01067 | Sense Amplifier Comparator with Offset Correction for Decision Feedback Equalization based Receivers | http://arxiv.org/abs/1702.01067 | id:1702.01067 author:Naveen Kadayinti, Dinesh Sharma category:cs.AR  published:2017-02-03 summary:A decision feedback circuit with integrated offset compensation is presented in this paper. The circuit is built around the sense amplifier comparator. The feedback loop is closed around the first stage of the comparator resulting in minimum loop latency. The feedback loop is implemented using a switched capacitor network that picks from one of pre-computed voltages to be fed back. The comparator's offset that is to be compensated for, is added in the same path. Hence, an extra offset correction input is not required. The circuit is used as a receiver for a 10 mm low swing interconnect implemented in UMC 130 nm CMOS technology. The circuit is tested at a frequency of 1 GHz and it consumes 145 $\mu$A from a 1.2V supply at this frequency. version:1
arxiv-1702-00938 | A Multi-Gbps Unrolled Hardware List Decoder for a Systematic Polar Code | http://arxiv.org/abs/1702.00938 | id:1702.00938 author:Pascal Giard, Alexios Balatsoukas-Stimming, Thomas Christoph MÃ¼ller, Andreas Burg, Claude Thibeault, Warren J. Gross category:cs.AR  published:2017-02-03 summary:Polar codes are a new class of block codes with an explicit construction that provably achieve the capacity of various communications channels, even with the low-complexity successive-cancellation (SC) decoding algorithm. Yet, the more complex successive-cancellation list (SCL) decoding algorithm is gathering more attention lately as it significantly improves the error-correction performance of short- to moderate-length polar codes, especially when they are concatenated with a cyclic redundancy check code. However, as SCL decoding explores several decoding paths, existing hardware implementations tend to be significantly slower than SC-based decoders. In this paper, we show how the unrolling technique, which has already been used in the context of SC decoding, can be adapted to SCL decoding yielding a multi-Gbps SCL-based polar decoder with an error-correction performance that is competitive when compared to an LDPC code of similar length and rate. Post-place-and-route ASIC results for 28 nm CMOS are provided showing that this decoder can sustain a throughput greater than 10 Gbps at 468 MHz with an energy efficiency of 7.25 pJ/bit. version:1
arxiv-1608-02707 | Energy Efficient Scheduling of Cloud Application Components with Brownout | http://arxiv.org/abs/1608.02707 | id:1608.02707 author:Minxian Xu, Amir Vahid Dastjerdi, Rajkumar Buyya category:cs.DC  published:2016-08-09 summary:It is common for cloud data centers meeting unexpected loads like request bursts, which may lead to overloaded situation and performance degradation. Dynamic Voltage Frequency Scaling and VM consolidation have been proved effective to manage overloads. However, they cannot function when the whole data center is overloaded. Brownout provides a promising direction to avoid overloads through configuring applications to temporarily degrade user experience. Additionally, brownout can also be applied to reduce data center energy consumption. As a complementary option for Dynamic Voltage Frequency Scaling and VM consolidation, our combined brownout approach reduces energy consumption through selectively and dynamically deactivating application optional components, which can also be applied to self-contained microservices. The results show that our approach can save more than 20% energy consumption and there are trade-offs between energy saving and discount offered to users. version:3
arxiv-1702-00858 | The Value of Inferring the Internal State of Traffic Participants for Autonomous Freeway Driving | http://arxiv.org/abs/1702.00858 | id:1702.00858 author:Zachary Sunberg, Christopher Ho, Mykel Kochenderfer category:cs.AI  published:2017-02-02 summary:Safe interaction with human drivers is one of the primary challenges for autonomous vehicles. In order to plan driving maneuvers effectively, the vehicle's control system must infer and predict how humans will behave based on their latent internal state (e.g., intentions and aggressiveness). This research uses a simple model for human behavior with unknown parameters that make up the internal states of the traffic participants and presents a method for quantifying the value of estimating these states and planning with their uncertainty explicitly modeled. An upper performance bound is established by an omniscient Monte Carlo Tree Search (MCTS) planner that has perfect knowledge of the internal states. A baseline lower bound is established by planning with MCTS assuming that all drivers have the same internal state. MCTS variants are then used to solve a partially observable Markov decision process (POMDP) that models the internal state uncertainty to determine whether inferring the internal state offers an advantage over the baseline. Applying this method to a freeway lane changing scenario reveals that there is a significant performance gap between the upper bound and baseline. POMDP planning techniques come close to closing this gap, especially when important hidden model parameters are correlated with measurable parameters. version:1
arxiv-1702-00841 | Distributed Optimization Using the Primal-Dual Method of Multipliers | http://arxiv.org/abs/1702.00841 | id:1702.00841 author:G. Zhang, R. Heusdens category:cs.DC math.OC  published:2017-02-02 summary:In this paper, we propose the primal-dual method of multipliers (PDMM) for distributed optimization over a graph. In particular, we optimize a sum of convex functions defined over a graph, where every edge in the graph carries a linear equality constraint. In designing the new algorithm, an augmented primal-dual Lagrangian function is constructed which smoothly captures the graph topology. It is shown that a saddle point of the constructed function provides an optimal solution of the original problem. Further under both the synchronous and asynchronous updating schemes, PDMM has the convergence rate of O(1/K) (where K denotes the iteration index) for general closed, proper and convex functions. Other properties of PDMM such as convergence speeds versus different parameter- settings and resilience to transmission failure are also investigated through the experiments of distributed averaging. version:1
arxiv-1702-00780 | Two forms of minimality in ASPIC+ | http://arxiv.org/abs/1702.00780 | id:1702.00780 author:Zimi Li, Andrea Cohen, Simon Parsons category:cs.AI cs.LO  published:2017-02-02 summary:Many systems of structured argumentation explicitly require that the facts and rules that make up the argument for a conclusion be the minimal set required to derive the conclusion. ASPIC+ does not place such a requirement on arguments, instead requiring that every rule and fact that are part of an argument be used in its construction. Thus ASPIC+ arguments are minimal in the sense that removing any element of the argument would lead to a structure that is not an argument. In this brief note we discuss these two types of minimality and show how the first kind of minimality can, if desired, be recovered in ASPIC+. version:1
arxiv-1702-00733 | Analysis of Rigid Extended Object Co-Manipulation by Human Dyads: Lateral Movement Characterization | http://arxiv.org/abs/1702.00733 | id:1702.00733 author:Erich A. Mielke, Eric C. Townsend, Marc D. Killpack category:cs.RO  published:2017-02-02 summary:During co-manipulation involving humans and robots, it is necessary to base robot controllers on human behaviors to achieve comfortable and coordinated movement between the human-robot dyad. In this paper, we describe an experiment between human-human dyads and we record the force and motion data as the leader-follower dyads moved in translation and rotation. The force/motion data was then analyzed for patterns found during lateral translation only. For extended objects, lateral translation and in-place rotation are ambiguous, but this paper determines a way to characterize lateral translation triggers for future use in human-robot interaction. The study has 4 main results. First, interaction forces are apparent and necessary for co-manipulation. Second, minimum-jerk trajectories are found in the lateral direction only for lateral movement. Third, the beginning of a lateral movement is characterized by distinct force triggers by the leader. Last, there are different metrics that can be attributed to determine which dyads moved most effectively in the lateral direction. version:1
arxiv-1702-00694 | Integrating Soft Robotics with ROS - A hybrid pick and place arm | http://arxiv.org/abs/1702.00694 | id:1702.00694 author:Ross M. McKenzie, Thomas W. Barraclough, Adam A. Stokes category:cs.RO  published:2017-02-02 summary:Soft robotic systems present a variety of new opportunities for solving complex problems. The use of soft robotic grippers, for example, can simplify the complexity in tasks such as the of grasping irregular and delicate objects. Adoption of soft robotics by academia and industry, however, has been slow and this is, in-part, due to the amount of hardware and software that must be developed from scratch for each use of soft system components. In this paper we detail the design, fabrication and validation of an open-source framework that we designed to lower the barrier to entry for integrating soft robotic subsystems. This framework is built on ROS (the Robot Operating System) and we use it to demonstrate a modular, soft-hard hybrid system which is capable of completing pick and place tasks. By lowering this barrier to entry we hope that system designers and researchers will find it easy to integrate soft components into their existing ROS-enabled robotic systems. version:1
arxiv-1511-01287 | Local Conflict Coloring | http://arxiv.org/abs/1511.01287 | id:1511.01287 author:Pierre Fraigniaud, Marc Heinrich, Adrian Kosowski category:cs.DS cs.DC  published:2015-11-04 summary:Locally finding a solution to symmetry-breaking tasks such as vertex-coloring, edge-coloring, maximal matching, maximal independent set, etc., is a long-standing challenge in distributed network computing. More recently, it has also become a challenge in the framework of centralized local computation. We introduce conflict coloring as a general symmetry-breaking task that includes all the aforementioned tasks as specific instantiations --- conflict coloring includes all locally checkable labeling tasks from [Naor\&Stockmeyer, STOC 1993]. Conflict coloring is characterized by two parameters $l$ and $d$, where the former measures the amount of freedom given to the nodes for selecting their colors, and the latter measures the number of constraints which colors of adjacent nodes are subject to.We show that, in the standard LOCAL model for distributed network computing, if $l/d \textgreater{} \Delta$, then conflict coloring can be solved in $\tilde O(\sqrt{\Delta})+\log^*n$ rounds in $n$-node graphs with maximum degree $\Delta$, where $\tilde O$ ignores the polylog factors in $\Delta$. The dependency in~$n$ is optimal, as a consequence of the $\Omega(\log^*n)$ lower bound by [Linial, SIAM J. Comp. 1992] for $(\Delta+1)$-coloring. An important special case of our result is a significant improvement over the best known algorithm for distributed $(\Delta+1)$-coloring due to [Barenboim, PODC 2015], which required $\tilde O(\Delta^{3/4})+\log^*n$ rounds. Improvements for other variants of coloring, including $(\Delta+1)$-list-coloring, $(2\Delta-1)$-edge-coloring, $T$-coloring, etc., also follow from our general result on conflict coloring. Likewise, in the framework of centralized local computation algorithms (LCAs), our general result yields an LCA which requires a smaller number of probes than the previously best known algorithm for vertex-coloring, and works for a wide range of coloring problems. version:2
arxiv-1702-00787 | Distributed Approximation Algorithms for the Multiple Knapsack Problem | http://arxiv.org/abs/1702.00787 | id:1702.00787 author:Ananth Murthy, Chandan Yeshwanth, Shrisha Rao category:cs.DS cs.DC cs.DM 68W15  68W15 C.2.4; I.1.2  published:2017-02-02 summary:We consider the distributed version of the Multiple Knapsack Problem (MKP), where $m$ items are to be distributed amongst $n$ processors, each with a knapsack. We propose different distributed approximation algorithms with a tradeoff between time and message complexities. The algorithms are based on the greedy approach of assigning the best item to the knapsack with the largest capacity. These algorithms obtain a solution with a bound of $\frac{1}{n+1}$ times the optimum solution, with either $\mathcal{O}\left(m\log n\right)$ time and $\mathcal{O}\left(m n\right)$ messages, or $\mathcal{O}\left(m\right)$ time and $\mathcal{O}\left(mn^{2}\right)$ messages. version:1
arxiv-1702-00539 | Procedural Content Generation via Machine Learning (PCGML) | http://arxiv.org/abs/1702.00539 | id:1702.00539 author:Adam Summerville, Sam Snodgrass, Matthew Guzdial, Christoffer HolmgÃ¥rd, Amy K. Hoover, Aaron Isaksen, Andy Nealen, Julian Togelius category:cs.AI  published:2017-02-02 summary:This survey explores Procedural Content Generation via Machine Learning (PCGML), defined as the generation of game content using machine learning models trained on existing content. As the importance of PCG for game development increases, researchers explore new avenues for generating high-quality content with or without human involvement; this paper addresses the relatively new paradigm of using machine learning (in contrast with search-based, solver-based, and constructive methods). We focus on what is most often considered functional game content such as platformer levels, game maps, interactive fiction stories, and cards in collectible card games, as opposed to cosmetic content such as sprites and sound effects. In addition to using PCG for autonomous generation, co-creativity, mixed-initiative design, and compression, PCGML is suited for repair, critique, and content analysis because of its focus on modeling existing content. We discuss various data sources and representations that affect the resulting generated content. Multiple PCGML methods are covered, including neural networks, long short-term memory (LSTM) networks, autoencoders, and deep convolutional networks; Markov models, $n$-grams, and multi-dimensional Markov chains; clustering; and matrix factorization. Finally, we discuss open problems in the application of PCGML, including learning from small datasets, lack of training data, multi-layered learning, style-transfer, parameter tuning, and PCG as a game mechanic. version:1
arxiv-1612-05497 | A correlation coefficient of belief functions | http://arxiv.org/abs/1612.05497 | id:1612.05497 author:Wen Jiang category:cs.AI  published:2016-12-16 summary:How to manage conflict is still an open issue in Dempster-Shafer evidence theory. The correlation coefficient can be used to measure the similarity of evidence in Dempster-Shafer evidence theory. However, existing correlation coefficients of belief functions have some shortcomings. In this paper, a new correlation coefficient is proposed with many desirable properties. One of its applications is to measure the conflict degree among belief functions. Some numerical examples and comparisons demonstrate the effectiveness of the correlation coefficient. version:2
arxiv-1104-2444 | A Simplified and Improved Free-Variable Framework for Hilbert's epsilon as an Operator of Indefinite Committed Choice | http://arxiv.org/abs/1104.2444 | id:1104.2444 author:Claus-Peter Wirth category:cs.AI math.LO  published:2011-04-13 summary:Free variables occur frequently in mathematics and computer science with ad hoc and altering semantics. We present the most recent version of our free-variable framework for two-valued logics with properly improved functionality, but only two kinds of free variables left (instead of three): implicitly universally and implicitly existentially quantified ones, now simply called "free atoms" and "free variables", respectively. The quantificational expressiveness and the problem-solving facilities of our framework exceed standard first-order and even higher-order modal logics, and directly support Fermat's descente infinie. With the improved version of our framework, we can now model also Henkin quantification, neither using quantifiers (binders) nor raising (Skolemization). We propose a new semantics for Hilbert's epsilon as a choice operator with the following features: We avoid overspecification (such as right-uniqueness), but admit indefinite choice, committed choice, and classical logics. Moreover, our semantics for the epsilon supports reductive proof search optimally. version:9
arxiv-1702-00425 | Probabilistic Completeness of Randomized Possibility Graphs Applied to Bipedal Walking in Semi-unstructured Environments | http://arxiv.org/abs/1702.00425 | id:1702.00425 author:Michael X. Grey, Aaron D. Ames, C. Karen Liu category:cs.RO 68T40  published:2017-02-01 summary:We present a theoretical analysis of a recent whole body motion planning method, the Randomized Possibility Graph, which uses a high-level decomposition of the feasibility constraint manifold in order to rapidly find routes that may lead to a solution. These routes are then examined by lower-level planners to determine feasibility. In this paper, we show that this approach is probabilistically complete for bipedal robots performing quasi-static walking in "semi-unstructured" environments. Furthermore, we show that the decomposition into higher and lower level planners allows for a considerably higher rate of convergence in the probability of finding a solution when one exists. We illustrate this improved convergence with a series of simulated scenarios. version:1
arxiv-1702-00325 | Hybrid Fuel Cells Power for Long Duration Robot Missions in Field Environments | http://arxiv.org/abs/1702.00325 | id:1702.00325 author:Jekan Thangavelautham, Danielle Gallardo, Daniel Strawser, Steven Dubowsky category:cs.RO cs.SY  published:2017-02-01 summary:Mobile robots are often needed for long duration missions. These include search and rescue, sentry, repair, surveillance and entertainment. Current power supply technology limit walking and climbing robots from many such missions. Internal combustion engines have high noise and emit toxic exhaust while rechargeable batteries have low energy densities and high rates of self-discharge. In theory, fuel cells do not have such limitations. In particular Proton Exchange Membrane (PEMs) can provide very high energy densities, are clean and quiet. However, PEM fuel cells are found to be unreliable due to performance degradation. This can be mitigated by protecting the fuel cell in a fuel-cell battery hybrid configuration using filtering electronics that ensure the fuel cell is isolated from electrical noise and a battery to isolate it from power surges. Simulation results are presented for a HOAP 2 humanoid robot that suggests a fuel cell powered hybrid power supply superior to conventional batteries. version:1
arxiv-1702-00318 | A Hybrid Evolutionary Algorithm Based on Solution Merging for the Longest Arc-Preserving Common Subsequence Problem | http://arxiv.org/abs/1702.00318 | id:1702.00318 author:Christian Blum, Maria J. Blesa category:cs.AI  published:2017-02-01 summary:The longest arc-preserving common subsequence problem is an NP-hard combinatorial optimization problem from the field of computational biology. This problem finds applications, in particular, in the comparison of arc-annotated Ribonucleic acid (RNA) sequences. In this work we propose a simple, hybrid evolutionary algorithm to tackle this problem. The most important feature of this algorithm concerns a crossover operator based on solution merging. In solution merging, two or more solutions to the problem are merged, and an exact technique is used to find the best solution within this union. It is experimentally shown that the proposed algorithm outperforms a heuristic from the literature. version:1
arxiv-1701-07615 | On the Design of Distributed Programming Models | http://arxiv.org/abs/1701.07615 | id:1701.07615 author:Christopher S. Meiklejohn category:cs.DC  published:2017-01-26 summary:Programming large-scale distributed applications requires new abstractions and models to be done well. We demonstrate that these models are possible. Following from both the FLP result and CAP theorem, we show that concurrent programming models are necessary, but not sufficient, in the construction of large-scale distributed systems because of the problem of failure and network partitions: languages need to be able to capture and encode the tradeoffs between consistency and availability. We present two programming models, Lasp and Austere, each of which makes a strong tradeoff with respects to the CAP theorem. These two models outline the bounds of distributed model design: strictly AP or strictly CP. We argue that all possible distributed programming models must come from this design space, and present one practical design that allows declarative specification of consistency tradeoffs, called Spry. version:2
arxiv-1702-00208 | Machines and Algorithms | http://arxiv.org/abs/1702.00208 | id:1702.00208 author:Peter A Boyle category:hep-lat cs.AR cs.DC physics.comp-ph  published:2017-02-01 summary:I discuss the evolution of computer architectures with a focus on QCD and with reference to the interplay between architecture, engineering, data motion and algorithms. New architectures are discussed and recent performance results are displayed. I also review recent progress in multilevel solver and integation algorithms. version:1
arxiv-1702-00137 | Blue Sky Ideas in Artificial Intelligence Education from the EAAI 2017 New and Future AI Educator Program | http://arxiv.org/abs/1702.00137 | id:1702.00137 author:Eric Eaton, Sven Koenig, Claudia Schulz, Francesco Maurelli, John Lee, Joshua Eckroth, Mark Crowley, Richard G. Freedman, Rogelio E. Cardona-Rivera, Tiago Machado, Tom Williams category:cs.AI cs.CY  published:2017-02-01 summary:The 7th Symposium on Educational Advances in Artificial Intelligence (EAAI'17, co-chaired by Sven Koenig and Eric Eaton) launched the EAAI New and Future AI Educator Program to support the training of early-career university faculty, secondary school faculty, and future educators (PhD candidates or postdocs who intend a career in academia). As part of the program, awardees were asked to address one of the following "blue sky" questions: * How could/should Artificial Intelligence (AI) courses incorporate ethics into the curriculum? * How could we teach AI topics at an early undergraduate or a secondary school level? * AI has the potential for broad impact to numerous disciplines. How could we make AI education more interdisciplinary, specifically to benefit non-engineering fields? This paper is a collection of their responses, intended to help motivate discussion around these issues in AI education. version:1
arxiv-1608-02274 | Distributed Real-Time Energy Management in Data Center Microgrids | http://arxiv.org/abs/1608.02274 | id:1608.02274 author:Liang Yu, Tao Jiang, Yulong Zou category:cs.DC  published:2016-08-07 summary:Data center operators are typically faced with three significant problems when running their data centers, i.e., rising electricity bills, growing carbon footprints and unexpected power outages. To mitigate these issues, running data centers in microgrids is a good choice since microgrids can enhance the energy efficiency, sustainability and reliability of electrical services. Thus, in this paper, we investigate the problem of energy management for multiple data center microgrids. Specifically, we intend to minimize the long-term operational cost of data center microgrids by taking into account the uncertainties in electricity prices, renewable outputs and data center workloads. We first formulate a stochastic programming problem with the considerations of many factors, e.g., providing heterogeneous service delay guarantees for batch workloads, interactive workload allocation, batch workload shedding, electricity buying/selling, battery charging/discharging efficiency, and the ramping constraints of backup generators. Then, we design a realtime and distributed algorithm for the formulated problem based on Lyapunov optimization technique and a variant of alternating direction method of multipliers (ADMM). Moreover, the performance guarantees provided by the proposed algorithm are analyzed. Extensive simulation results indicate the effectiveness of the proposed algorithm in operational cost reduction for data center microgrids. version:3
arxiv-1605-01018 | Making Decisions with Spatially and Temporally Uncertain Data | http://arxiv.org/abs/1605.01018 | id:1605.01018 author:Lantao Liu, Gaurav S. Sukhatme category:cs.RO  published:2016-05-03 summary:We consider a decision-making problem where the environment varies both in space and time. Such problems arise naturally when considering e.g., the navigation of an underwater robot amidst ocean currents or the navigation of an aerial vehicle in wind. To model such spatiotemporal variation, we extend the standard Markov Decision Process (MDP) to a new framework called the Time-Varying Markov Decision Process (TVMDP). The TVMDP has a time-varying state transition model and transforms the standard MDP that considers only {\em immediate} and {\em static} uncertainty descriptions of state transitions, to a framework that is able to adapt to future time-varying uncertainty over some horizon. We show how to solve a TVMDP via a redesign of the MDP value propagation mechanisms by incorporating the introduced dynamics along the temporal dimension. We validate our framework in a marine robotics navigation setting using real spatiotemporal ocean data and show that it outperforms prior efforts to explicitly accommodate time by including it in the state. version:2
arxiv-1501-04343 | Algorithms for Scheduling Malleable Cloud Tasks | http://arxiv.org/abs/1501.04343 | id:1501.04343 author:Xiaohu Wu, Patrick Loiseau category:cs.DC cs.DS  published:2015-01-18 summary:Due to the ubiquity of batch data processing in cloud computing, the related problem of scheduling malleable batch tasks and its extensions have received significant attention recently. In this paper, we consider a fundamental model where a set of n tasks is to be processed on C identical machines and each task is specified by a value, a workload, a deadline and a parallelism bound. Within the parallelism bound, the number of machines assigned to a task can vary over time without affecting its workload. For this model, we obtain two core results: a sufficient and necessary condition such that a set of tasks can be finished by their deadlines on C machines, and an algorithm to produce such a schedule. These core results provide a conceptual tool and an optimal scheduling algorithm that enable proposing new algorithmic analysis and design and improving existing algorithms under various objectives. version:7
arxiv-1605-01778 | Combinatorial Aspects of the Distribution of Rough Objects | http://arxiv.org/abs/1605.01778 | id:1605.01778 author:A. Mani category:cs.AI cs.IT math.CO math.IT math.LO 05E99  94D99  06A11  published:2016-05-05 summary:The inverse problem of general rough sets, considered by the present author in some of her earlier papers, in one of its manifestations is essentially the question of when an agent's view about crisp and non crisp objects over a set of objects has a rough evolution. In this research the nature of the problem is examined from number-theoretic and combinatorial perspectives under very few assumptions about the nature of data and some necessary conditions are proved. version:2
arxiv-1701-07550 | GNC of the SphereX Robot for Extreme Environment Exploration on Mars | http://arxiv.org/abs/1701.07550 | id:1701.07550 author:Himangshu Kalita, Ravi Teja Nallapu, Andrew Warren, Jekan Thangavelautham category:cs.RO astro-ph.IM  published:2017-01-26 summary:Wheeled ground robots are limited from exploring extreme environments such as caves, lava tubes and skylights. Small robots that can utilize unconventional mobility through hopping, flying or rolling can overcome these limitations. Mul-tiple robots operating as a team offer significant benefits over a single large ro-bot, as they are not prone to single-point failure, enable distributed command and control and enable execution of tasks in parallel. These robots can complement large rovers and landers, helping to explore inaccessible sites, obtaining samples and for planning future exploration missions. Our robots, the SphereX, are 3-kg in mass, spherical and contain computers equivalent to current smartphones. They contain an array of guidance, navigation and control sensors and electronics. SphereX contains room for a 1-kg science payload, including for sample return. Our work in this field has recognized the need for miniaturized chemical mobility systems that provide power and propulsion. Our research explored the use of miniature rockets, including solid rockets, bi-propellants including RP1/hydrogen-peroxide and polyurethane/ammonium-perchlorate. These propulsion options provide maximum flight times of 10 minutes on Mars. Flying, especially hovering consumes significant fuel; hence, we have been developing our robots to perform ballistic hops that enable the robots to travel efficiently over long distances. Techniques are being developed to enable mid-course correction during a ballistic hop. Using multiple cameras, it is possible to reconstitute an image scene from motion blur. Hence our approach is to enable photo mapping as the robots travel on a ballistic hop. The same images would also be used for navigation and path planning. Using our proposed design approach, we are developing low-cost methods for surface exploration of planetary bodies using a network of small robots. version:2
arxiv-1701-09000 | On the Semantics and Complexity of Probabilistic Logic Programs | http://arxiv.org/abs/1701.09000 | id:1701.09000 author:Fabio Gagliardi Cozman, Denis Deratani MauÃ¡ category:cs.AI  published:2017-01-31 summary:We examine the meaning and the complexity of probabilistic logic programs that consist of a set of rules and a set of independent probabilistic facts (that is, programs based on Sato's distribution semantics). We focus on two semantics, respectively based on stable and on well-founded models. We show that the semantics based on stable models (referred to as the "credal semantics") produces sets of probability models that dominate infinitely monotone Choquet capacities, we describe several useful consequences of this result. We then examine the complexity of inference with probabilistic logic programs. We distinguish between the complexity of inference when a probabilistic program and a query are given (the inferential complexity), and the complexity of inference when the probabilistic program is fixed and the query is given (the query complexity, akin to data complexity as used in database theory). We obtain results on the inferential and query complexity for acyclic, stratified, and cyclic propositional and relational programs, complexity reaches various levels of the counting hierarchy and even exponential levels. version:1
arxiv-1612-05971 | An Integrated Optimization + Learning Approach to Optimal Dynamic Pricing for the Retailer with Multi-type Customers in Smart Grids | http://arxiv.org/abs/1612.05971 | id:1612.05971 author:Fanlin Meng, Xiao-Jun Zeng, Yan Zhang, Chris J. Dent, Dunwei Gong category:cs.SY cs.AI cs.GT math.OC  published:2016-12-18 summary:In this paper, we consider a realistic and meaningful scenario in the context of smart grids where an electricity retailer serves three different types of customers, i.e., customers with an optimal home energy management system embedded in their smart meters (C-HEMS), customers with only smart meters (C-SM), and customers without smart meters (C-NONE). The main objective of this paper is to support the retailer to make optimal day-ahead dynamic pricing decisions in such a mixed customer pool. To this end, we propose a two-level decision-making framework where the retailer acting as upper-level agent firstly announces its electricity prices of next 24 hours and customers acting as lower-level agents subsequently schedule their energy usages accordingly. For the lower level problem, we model the price responsiveness of different customers according to their unique characteristics. For the upper level problem, we optimize the dynamic prices for the retailer to maximize its profit subject to realistic market constraints. The above two-level model is tackled by genetic algorithms (GAs) based distributed optimization methods while its feasibility and effectiveness are confirmed via simulation results. version:2
arxiv-1702-06000 | 'Viral' Turing Machines, Computation from Noise and Combinatorial Hierarchies | http://arxiv.org/abs/1702.06000 | id:1702.06000 author:T. E. Raptis category:cs.AI nlin.CG  published:2017-01-31 summary:The interactive computation paradigm is reviewed and a particular example is extended to form the stochastic analog of a computational process via a transcription of a minimal Turing Machine into an equivalent asynchronous Cellular Automaton with an exponential waiting times distribution of effective transitions. Furthermore, a special toolbox for analytic derivation of recursive relations of important statistical and other quantities is introduced in the form of an Inductive Combinatorial Hierarchy. version:1
arxiv-1701-04217 | Automatic SDF-based Code Generation from Simulink Models for Embedded Software Development | http://arxiv.org/abs/1701.04217 | id:1701.04217 author:Maher Fakih, Sebastian Warsitz category:cs.DC cs.SE  published:2017-01-16 summary:Matlab/Simulink is a wide-spread tool for model-based design of embedded systems. Supporting hierarchy, domain specific building blocks, functional simulation and automatic code-generation, makes it well-suited for the design of control and signal processing systems. In this work, we propose an automated translation methodology for a subset of Simulink models to Synchronous dataflow Graphs (SDFGs) including the automatic code-generation of SDF-compatible embedded code. A translation of Simulink models to SDFGs, is very suitable due to Simulink actor-oriented modeling nature, allowing the application of several optimization techniques from the SDFG domain. Because of their well-defined semantics, SDFGs can be analyzed at compiling phase to obtain deadlock-free and memory-efficient schedules. In addition, several real-time analysis methods exist which allow throughput-optimal mappings of SDFGs to Multiprocessor on Chip (MPSoC) while guaranteeing upper-bounded latencies. The correctness of our translation is justified by integrating the SDF generated code as a software-in-the-loop (SIL) and comparing its results with the results of the model-in-the-loop (MIL) simulation of reference Simulink models. The translation is demonstrated with the help of two case studies: a Transmission Controller Unit (TCU) and an Automatic Climate Control. version:2
arxiv-1701-08921 | Sparse Optimization for Robust and Efficient Loop Closing | http://arxiv.org/abs/1701.08921 | id:1701.08921 author:Yasir Latif, Guoquan Huang, John Leonard, Jose Neira category:cs.RO  published:2017-01-31 summary:It is essential for a robot to be able to detect revisits or loop closures for long-term visual navigation.A key insight explored in this work is that the loop-closing event inherently occurs sparsely, that is, the image currently being taken matches with only a small subset (if any) of previous images. Based on this observation, we formulate the problem of loop-closure detection as a sparse, convex $\ell_1$-minimization problem. By leveraging fast convex optimization techniques, we are able to efficiently find loop closures, thus enabling real-time robot navigation. This novel formulation requires no offline dictionary learning, as required by most existing approaches, and thus allows online incremental operation. Our approach ensures a unique hypothesis by choosing only a single globally optimal match when making a loop-closure decision. Furthermore, the proposed formulation enjoys a flexible representation with no restriction imposed on how images should be represented, while requiring only that the representations are "close" to each other when the corresponding images are visually similar. The proposed algorithm is validated extensively using real-world datasets. version:1
arxiv-1701-08920 | A parallel approach to bi-objective integer programming | http://arxiv.org/abs/1701.08920 | id:1701.08920 author:William Pettersson, Melih Ozlen category:math.OC cs.DC cs.DS 90-08  90C29  published:2017-01-31 summary:To obtain a better understanding of the trade-offs between various objectives, Bi-Objective Integer Programming (BOIP) algorithms calculate the set of all non-dominated vectors and present these as the solution to a BOIP problem. Historically, these algorithms have been compared in terms of the number of single-objective IPs solved and total CPU time taken to produce the solution to a problem. This is equitable, as researchers can often have access to widely differing amounts of computing power. However, the real world has recently seen a large uptake of multi-core processors in computers, laptops, tablets and even mobile phones. With this in mind, we look at how to best utilise parallel processing to improve the elapsed time of optimisation algorithms. We present two methods of parallelising the recursive algorithm presented by Ozlen, Burton and MacRae. Both new methods utilise two threads and improve running times. One of the new methods, the Meeting algorithm, halves running time to achieve near-perfect parallelisation. The results are compared with the efficiency of parallelisation within the commercial IP solver IBM ILOG CPLEX, and the new methods are both shown to perform better. version:1
arxiv-1701-08915 | Accelerated Evaluation of Automated Vehicles Using Piecewise Mixture Models | http://arxiv.org/abs/1701.08915 | id:1701.08915 author:Zhiyuan Huang, Ding Zhao, Henry Lam, David J. LeBlanc category:cs.SY cs.RO  published:2017-01-31 summary:The process to certify highly Automated Vehicles has not yet been defined by any country in the world. Currently, companies test Automated Vehicles on public roads, which is time-consuming and inefficient. We proposed the Accelerated Evaluation concept, which uses a modified statistics of the surrounding vehicles and the Importance Sampling theory to reduce the evaluation time by several orders of magnitude, while ensuring the evaluation results are statistically accurate. In this paper, we further improve the accelerated evaluation concept by using Piecewise Mixture Distribution models, instead of Single Parametric Distribution models. We developed and applied this idea to forward collision control system reacting to vehicles making cut-in lane changes. The behavior of the cut-in vehicles was modeled based on more than 403,581 lane changes collected by the University of Michigan Safety Pilot Model Deployment Program. Simulation results confirm that the accuracy and efficiency of the Piecewise Mixture Distribution method outperformed single parametric distribution methods in accuracy and efficiency, and accelerated the evaluation process by almost four orders of magnitude. version:1
arxiv-1701-08878 | Deep Reinforcement Learning for Robotic Manipulation-The state of the art | http://arxiv.org/abs/1701.08878 | id:1701.08878 author:Smruti Amarjyoti category:cs.RO cs.AI  published:2017-01-31 summary:The focus of this work is to enumerate the various approaches and algorithms that center around application of reinforcement learning in robotic ma- ]]nipulation tasks. Earlier methods utilized specialized policy representations and human demonstrations to constrict the policy. Such methods worked well with continuous state and policy space of robots but failed to come up with generalized policies. Subsequently, high dimensional non-linear function approximators like neural networks have been used to learn policies from scratch. Several novel and recent approaches have also embedded control policy with efficient perceptual representation using deep learning. This has led to the emergence of a new branch of dynamic robot control system called deep r inforcement learning(DRL). This work embodies a survey of the most recent algorithms, architectures and their implementations in simulations and real world robotic platforms. The gamut of DRL architectures are partitioned into two different branches namely, discrete action space algorithms(DAS) and continuous action space algorithms(CAS). Further, the CAS algorithms are divided into stochastic continuous action space(SCAS) and deterministic continuous action space(DCAS) algorithms. Along with elucidating an organ- isation of the DRL algorithms this work also manifests some of the state of the art applications of these approaches in robotic manipulation tasks. version:1
arxiv-1701-08868 | Interaction Information for Causal Inference: The Case of Directed Triangle | http://arxiv.org/abs/1701.08868 | id:1701.08868 author:AmirEmad Ghassami, Negar Kiyavash category:cs.AI  published:2017-01-30 summary:Interaction information is one of the multivariate generalizations of mutual information, which expresses the amount information shared among a set of variables, beyond the information, which is shared in any proper subset of those variables. Unlike (conditional) mutual information, which is always non-negative, interaction information can be negative. We utilize this property to find the direction of causal influences among variables in a triangle topology under some mild assumptions. version:1
arxiv-1701-08849 | Accurate Measurement of Power Consumption Overhead During FPGA Dynamic Partial Reconfiguration | http://arxiv.org/abs/1701.08849 | id:1701.08849 author:Amor Nafkha, Yves Louet category:cs.AR  published:2017-01-30 summary:In the context of embedded systems design, two important challenges are still under investigation. First, improve real-time data processing, reconfigurability, scalability, and self-adjusting capabilities of hardware components. Second, reduce power consumption through low-power design techniques as clock gating, logic gating, and dynamic partial reconfiguration (DPR) capabilities. Today, several application, e.g., cryptography, Software-defined radio or aerospace missions exploit the benefits of DPR of programmable logic devices. The DPR allows well defined reconfigurable FPGA region to be modified during runtime. However, it introduces an overhead in term of power consumption and time during the reconfiguration phase. In this paper, we present an investigation of power consumption overhead of the DPR process using a high-speed digital oscilloscope and the shunt resistor method. Results in terms of reconfiguration time and power consumption overhead for Virtex 5 FPGAs are shown. version:1
arxiv-1701-08832 | Expert Level control of Ramp Metering based on Multi-task Deep Reinforcement Learning | http://arxiv.org/abs/1701.08832 | id:1701.08832 author:Francois Belletti, Daniel Haziza, Gabriel Gomes, Alexandre M. Bayen category:cs.AI  published:2017-01-30 summary:This article shows how the recent breakthroughs in Reinforcement Learning (RL) that have enabled robots to learn to play arcade video games, walk or assemble colored bricks, can be used to perform other tasks that are currently at the core of engineering cyberphysical systems. We present the first use of RL for the control of systems modeled by discretized non-linear Partial Differential Equations (PDEs) and devise a novel algorithm to use non-parametric control techniques for large multi-agent systems. We show how neural network based RL enables the control of discretized PDEs whose parameters are unknown, random, and time-varying. We introduce an algorithm of Mutual Weight Regularization (MWR) which alleviates the curse of dimensionality of multi-agent control schemes by sharing experience between agents while giving each agent the opportunity to specialize its action policy so as to tailor it to the local parameters of the part of the system it is located in. version:1
arxiv-1701-08800 | Mutual Inclusivity of the Critical Path and its Partial Schedule on Heterogeneous Systems | http://arxiv.org/abs/1701.08800 | id:1701.08800 author:Aravind Vasudevan, David Gregg category:cs.DC  published:2017-01-30 summary:The critical path of a group of tasks is an important measure that is commonly used to guide task allocation and scheduling on parallel computers. The critical path is the longest chain of dependencies in an acyclic task dependence graph. A problem arises on heterogeneous parallel machines where computation and communication costs can vary between different types of processor. Existing solutions for heterogeneous machines attempt to estimate the critical path using average values of computation and communication costs. However, this ignores opportunities to match specific tasks to specific classes of processor and communication links, and can result in quite misleading paths being identified as critical. We argue that an accurate critical path must consider the mapping of tasks to classes of processor and communication links. We formulate a polynomial time algorithm to find such a critical path. Our Critical Earliest Finish Time (CEFT) algorithm finds both the length of the critical path and an allocation of tasks to processors on that path. We compared CEFT experimentally to existing approaches such as averaging execution times across processors. The latter approach fails to accurately model the execution cost of tasks, and as a result fails to identify a correct critical path in 83.99% of cases in our experiments. We also adapted a critical path-oriented scheduling algorithm (CPOP) to use our critical path algorithm and found that the resulting schedules are faster. version:1
arxiv-1701-08735 | Real-Time Control for Autonomous Racing Based on Viability Theory | http://arxiv.org/abs/1701.08735 | id:1701.08735 author:Alexander Liniger, John Lygeros category:cs.SY cs.RO math.OC  published:2017-01-30 summary:In this paper we consider autonomous driving of miniature race cars. The viability kernel is used to efficiently generate finite look ahead trajectories that maximize progress while remaining recursively feasible with respect to static obstacles (e.g., stay inside the track). Together with a low level model predictive controller, this method makes real time autonomous racing possible. The viability kernel computation is based on space discretization. To make the calculation robust against discretization errors, we propose a novel numerical scheme based on game theoretical methods, in particular the discriminating kernel. We show that the resulting algorithm provides an inner approximation of the viability kernel and guarantees that, for all states in the cell surrounding a viable grid point, there exists a control that keeps the system within the kernel. The performance of the proposed control method is studied in simulation where we determine the effects of various design choices and parameters and in experiments on an autonomous racing set-up maintained at the Automatic Control Laboratory of ETH Zurich. Both simulation and experimental results suggest that the more conservative approximation using the discriminating kernel results in safer driving (in terms of constraint violations) at the cost of a small increase in lap time. version:1
arxiv-1701-09042 | Comparing Dataset Characteristics that Favor the Apriori, Eclat or FP-Growth Frequent Itemset Mining Algorithms | http://arxiv.org/abs/1701.09042 | id:1701.09042 author:Jeff Heaton category:cs.DB cs.AI  published:2017-01-30 summary:Frequent itemset mining is a popular data mining technique. Apriori, Eclat, and FP-Growth are among the most common algorithms for frequent itemset mining. Considerable research has been performed to compare the relative performance between these three algorithms, by evaluating the scalability of each algorithm as the dataset size increases. While scalability as data size increases is important, previous papers have not examined the performance impact of similarly sized datasets that contain different itemset characteristics. This paper explores the effects that two dataset characteristics can have on the performance of these three frequent itemset algorithms. To perform this empirical analysis, a dataset generator is created to measure the effects of frequent item density and the maximum transaction size on performance. The generated datasets contain the same number of rows. This provides some insight into dataset characteristics that are conducive to each algorithm. The results of this paper's research demonstrate Eclat and FP-Growth both handle increases in maximum transaction size and frequent itemset density considerably better than the Apriori algorithm. This paper explores the effects that two dataset characteristics can have on the performance of these three frequent itemset algorithms. To perform this empirical analysis, a dataset generator is created to measure the effects of frequent item density and the maximum transaction size on performance. The generated datasets contain the same number of rows. This provides some insight into dataset characteristics that are conducive to each algorithm. The results of this paper's research demonstrate Eclat and FP-Growth both handle increases in maximum transaction size and frequent itemset density considerably better than the Apriori algorithm. version:1
arxiv-1606-05830 | Past, Present, and Future of Simultaneous Localization And Mapping: Towards the Robust-Perception Age | http://arxiv.org/abs/1606.05830 | id:1606.05830 author:Cesar Cadena, Luca Carlone, Henry Carrillo, Yasir Latif, Davide Scaramuzza, Jose Neira, Ian Reid, John J. Leonard category:cs.RO  published:2016-06-19 summary:Simultaneous Localization and Mapping (SLAM)consists in the concurrent construction of a model of the environment (the map), and the estimation of the state of the robot moving within it. The SLAM community has made astonishing progress over the last 30 years, enabling large-scale real-world applications, and witnessing a steady transition of this technology to industry. We survey the current state of SLAM. We start by presenting what is now the de-facto standard formulation for SLAM. We then review related work, covering a broad set of topics including robustness and scalability in long-term mapping, metric and semantic representations for mapping, theoretical performance guarantees, active SLAM and exploration, and other new frontiers. This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM. By looking at the published research with a critical eye, we delineate open challenges and new research issues, that still deserve careful scientific investigation. The paper also contains the authors' take on two questions that often animate discussions during robotics conferences: Do robots need SLAM? and Is SLAM solved? version:4
arxiv-1701-08761 | C3A: A Cognitive Collaborative Control Architecture For an Intelligent Wheelchair | http://arxiv.org/abs/1701.08761 | id:1701.08761 author:Rupam Bhattacharyya, Adity Saikia, Shyamanta M. Hazarika category:cs.RO cs.AI  published:2017-01-30 summary:Retention of residual skills for persons who partially lose their cognitive or physical ability is of utmost importance. Research is focused on developing systems that provide need-based assistance for retention of such residual skills. This paper describes a novel cognitive collaborative control architecture C3A, designed to address the challenges of developing need- based assistance for wheelchair navigation. Organization of C3A is detailed and results from simulation of the proposed architecture is presented. For simulation of our proposed architecture, we have used ROS (Robot Operating System) as a control framework and a 3D robotic simulator called USARSim (Unified System for Automation and Robot Simulation). version:1
arxiv-1701-08530 | RIoTBench: A Real-time IoT Benchmark for Distributed Stream Processing Platforms | http://arxiv.org/abs/1701.08530 | id:1701.08530 author:Anshu Shukla, Shilpa Chaturvedi, Yogesh Simmhan category:cs.DC  published:2017-01-30 summary:The Internet of Things (IoT) is an emerging technology paradigm where millions of sensors and actuators help monitor and manage, physical, environmental and human systems in real-time. The inherent closedloop responsiveness and decision making of IoT applications make them ideal candidates for using low latency and scalable stream processing platforms. Distributed Stream Processing Systems (DSPS) hosted on Cloud data-centers are becoming the vital engine for real-time data processing and analytics in any IoT software architecture. But the efficacy and performance of contemporary DSPS have not been rigorously studied for IoT applications and data streams. Here, we develop RIoTBench, a Realtime IoT Benchmark suite, along with performance metrics, to evaluate DSPS for streaming IoT applications. The benchmark includes 27 common IoT tasks classified across various functional categories and implemented as reusable micro-benchmarks. Further, we propose four IoT application benchmarks composed from these tasks, and that leverage various dataflow semantics of DSPS. The applications are based on common IoT patterns for data pre-processing, statistical summarization and predictive analytics. These are coupled with four stream workloads sourced from real IoT observations on smart cities and fitness, with peak streams rates that range from 500 to 10000 messages/sec and diverse frequency distributions. We validate the RIoTBench suite for the popular Apache Storm DSPS on the Microsoft Azure public Cloud, and present empirical observations. This suite can be used by DSPS researchers for performance analysis and resource scheduling, and by IoT practitioners to evaluate DSPS platforms. version:1
arxiv-1701-08521 | pMR: A high-performance communication library | http://arxiv.org/abs/1701.08521 | id:1701.08521 author:Peter Georg, Daniel Richtmann, Tilo Wettig category:hep-lat cs.DC physics.comp-ph  published:2017-01-30 summary:On many parallel machines, the time LQCD applications spent in communication is a significant contribution to the total wall-clock time, especially in the strong-scaling limit. We present a novel high-performance communication library that can be used as a de facto drop-in replacement for MPI in existing software. Its lightweight nature that avoids some of the unnecessary overhead introduced by MPI allows us to improve the communication performance of applications without any algorithmic or complicated implementation changes. As a first real-world benchmark, we make use of the pMR library in the coarse-grid solve of the Regensburg implementation of the DD-$\alpha$AMG algorithm. On realistic lattices, we see an improvement of a factor 2x in pure communication time and total execution time savings of up to 20%. version:1
arxiv-1701-08474 | IFCIoT: Integrated Fog Cloud IoT Architectural Paradigm for Future Internet of Things | http://arxiv.org/abs/1701.08474 | id:1701.08474 author:Arslan Munir, Prasanna Kansakar, Samee U. Khan category:cs.DC  published:2017-01-30 summary:We propose a novel integrated fog cloud IoT (IFCIoT) architectural paradigm that promises increased performance, energy efficiency, reduced latency, quicker response time, scalability, and better localized accuracy for future IoT applications. The fog nodes (e.g., edge servers, smart routers, base stations) receive computation offloading requests and sensed data from various IoT devices. To enhance performance, energy efficiency, and real-time responsiveness of applications, we propose a reconfigurable and layered fog node (edge server) architecture that analyzes the applications' characteristics and reconfigure the architectural resources to better meet the peak workload demands. The layers of the proposed fog node architecture include application layer, analytics layer, virtualization layer, reconfiguration layer, and hardware layer. The layered architecture facilitates abstraction and implementation for fog computing paradigm that is distributed in nature and where multiple vendors (e.g., applications, services, data and content providers) are involved. We also elaborate the potential applications of IFCIoT architecture, such as smart cities, intelligent transportation systems, localized weather maps and environmental monitoring, and real-time agricultural data analytics and control. version:1
arxiv-1701-08444 | A review on cloud robotics based frameworks to solve simultaneous localization and mapping (slam) problem | http://arxiv.org/abs/1701.08444 | id:1701.08444 author:Rajesh Doriya, Paresh Sao, Vinit Payal, Vibhav Anand, Pavan Chakraborty category:cs.RO  published:2017-01-29 summary:Cloud Robotics is one of the emerging area of robotics. It has created a lot of attention due to its direct practical implications on Robotics. In Cloud Robotics, the concept of cloud computing is used to offload computational extensive jobs of the robots to the cloud. Apart from this, additional functionalities can also be offered on run to the robots on demand. Simultaneous Localization and Mapping (SLAM) is one of the computational intensive algorithm in robotics used by robots for navigation and map building in an unknown environment. Several Cloud based frameworks are proposed specifically to address the problem of SLAM, DAvinCi, Rapyuta and C2TAM are some of those framework. In this paper, we presented a detailed review of all these framework implementation for SLAM problem. version:1
arxiv-1702-00311 | Transaction Support over Redis: An Overview | http://arxiv.org/abs/1702.00311 | id:1702.00311 author:Yuqing Zhu, Jianxun Liu, Mengying Guo, Wenlong Ma, Yungang Bao category:cs.DC  published:2017-01-29 summary:This document outlines the approach to supporting cross-node transactions over a Redis cluster. version:1
arxiv-1611-08696 | Optimizing Expectation with Guarantees in POMDPs (Technical Report) | http://arxiv.org/abs/1611.08696 | id:1611.08696 author:Krishnendu Chatterjee, Petr NovotnÃ½, Guillermo A. PÃ©rez, Jean-FranÃ§ois Raskin, ÄorÄe Å½ikeliÄ category:cs.AI cs.GT  published:2016-11-26 summary:A standard objective in partially-observable Markov decision processes (POMDPs) is to find a policy that maximizes the expected discounted-sum payoff. However, such policies may still permit unlikely but highly undesirable outcomes, which is problematic especially in safety-critical applications. Recently, there has been a surge of interest in POMDPs where the goal is to maximize the probability to ensure that the payoff is at least a given threshold, but these approaches do not consider any optimization beyond satisfying this threshold constraint. In this work we go beyond both the "expectation" and "threshold" approaches and consider a "guaranteed payoff optimization (GPO)" problem for POMDPs, where we are given a threshold $t$ and the objective is to find a policy $\sigma$ such that a) each possible outcome of $\sigma$ yields a discounted-sum payoff of at least $t$, and b) the expected discounted-sum payoff of $\sigma$ is optimal (or near-optimal) among all policies satisfying a). We present a practical approach to tackle the GPO problem and evaluate it on standard POMDP benchmarks. version:2
arxiv-1701-08361 | Accelerated Computing in Magnetic Resonance Imaging -- Real-Time Imaging Using Non-Linear Inverse Reconstruction | http://arxiv.org/abs/1701.08361 | id:1701.08361 author:Sebastian Schaetz, Dirk Voit, Jens Frahm, Martin Uecker category:cs.DC physics.med-ph  published:2017-01-29 summary:Purpose: To develop generic optimization strategies for image reconstruction using graphical processing units (GPUs) in magnetic resonance imaging (MRI) and to exemplarily report about our experience with a highly accelerated implementation of the non-linear inversion algorithm (NLINV) for dynamic MRI with high frame rates. Methods: The NLINV algorithm is optimized and ported to run on an a multi-GPU single-node server. The algorithm is mapped to multiple GPUs by decomposing the data domain along the channel dimension. Furthermore, the algorithm is decomposed along the temporal domain by relaxing a temporal regularization constraint, allowing the algorithm to work on multiple frames in parallel. Finally, an autotuning method is presented that is capable of combining different decomposition variants to achieve optimal algorithm performance in different imaging scenarios. Results: The algorithm is successfully ported to a multi-GPU system and allows online image reconstruction with high frame rates. Real-time reconstruction with low latency and frame rates up to 30 frames per second is demonstrated. Conclusion: Novel parallel decomposition methods are presented which are applicable to many iterative algorithms for dynamic MRI. Using these methods to parallelize the NLINV algorithm on multiple GPUs it is possible to achieve online image reconstruction with high frame rates. version:1
arxiv-1701-07512 | ACIA, not ACID: Conditions, Properties and Challenges | http://arxiv.org/abs/1701.07512 | id:1701.07512 author:Yuqing Zhu, Jianxun Liu, Mengying Guo, Wenlong Ma, Guolei Yi, Yungang Bao category:cs.DC  published:2017-01-25 summary:Although ACID is the previous golden rule for transaction support, durability is now not a basic requirement for data storage. Rather, high availability is becoming the first-class property required by online applications. We show that high availability of data is almost surely a stronger property than durability. We thus propose ACIA (Atomicity, Consistency, Isolation, Availability) as the new standard for transaction support. Essentially, the shift from ACID to ACIA is due to the change of assumed conditions for data management. Four major condition changes exist. With ACIA transactions, more diverse requirements can be flexibly supported for applications through the specification of consistency levels, isolation levels and fault tolerance levels. Clarifying the ACIA properties enables the exploitation of techniques used for ACID transactions, as well as bringing about new challenges for research. version:2
arxiv-1702-00259 | Fault diagnosability of data center networks | http://arxiv.org/abs/1702.00259 | id:1702.00259 author:Mei-Mei Gu, Rong-Xia Hao, Shuming Zhou category:cs.DC math.CO 68R10  05C90 G.2.2  published:2017-01-29 summary:The data center networks $D_{n,k}$, proposed in 2008, has many desirable features such as high network capacity. A kind of generalization of diagnosability for network $G$ is $g$-good-neighbor diagnosability which is denoted by $t_g(G)$. Let $\kappa^g(G)$ be the $R^g$-connectivity. Lin et. al. in [IEEE Trans. on Reliability, 65 (3) (2016) 1248--1262] and Xu et. al in [Theor. Comput. Sci. 659 (2017) 53--63] gave the same problem independently that: the relationship between the $R^g$-connectivity $\kappa^g(G)$ and $t_g(G)$ of a general graph $G$ need to be studied in the future. In this paper, this open problem is solved for general regular graphs. We firstly establish the relationship of $\kappa^g(G)$ and $t_g(G)$, and obtain that $t_g(G)=\kappa^g(G)+g$ under some conditions. Secondly, we obtain the $g$-good-neighbor diagnosability of $D_{k,n}$ which are $t_g(D_{k,n})=(g+1)(k-1)+n+g$ for $1\leq g\leq n-1$ under the PMC model and the MM model, respectively. Further more, we show that $D_{k,n}$ is tightly super $(n+k-1)$-connected for $n\geq 2$ and $k\geq 2$ and we also prove that the largest connected component of the survival graph contains almost all of the remaining vertices in $D_{k,n}$ when $2k+n-2$ vertices removed. version:1
arxiv-1701-08343 | Rhythm Transcription of Polyphonic Piano Music Based on Merged-Output HMM for Multiple Voices | http://arxiv.org/abs/1701.08343 | id:1701.08343 author:Eita Nakamura, Kazuyoshi Yoshii, Shigeki Sagayama category:cs.AI cs.SD  published:2017-01-29 summary:In a recent conference paper, we have reported a rhythm transcription method based on a merged-output hidden Markov model (HMM) that explicitly describes the multiple-voice structure of polyphonic music. This model solves a major problem of conventional methods that could not properly describe the nature of multiple voices as in polyrhythmic scores or in the phenomenon of loose synchrony between voices. In this paper we present a complete description of the proposed model and develop an inference technique, which is valid for any merged-output HMMs for which output probabilities depend on past events. We also examine the influence of the architecture and parameters of the method in terms of accuracies of rhythm transcription and voice separation and perform comparative evaluations with six other algorithms. Using MIDI recordings of classical piano pieces, we found that the proposed model outperformed other methods by more than 12 points in the accuracy for polyrhythmic performances and performed almost as good as the best one for non-polyrhythmic performances. This reveals the state-of-the-art methods of rhythm transcription for the first time in the literature. Publicly available source codes are also provided for future comparisons. version:1
arxiv-1606-03634 | The Opacity of Backbones | http://arxiv.org/abs/1606.03634 | id:1606.03634 author:Lane A. Hemaspaandra, David E. NarvÃ¡ez category:cs.AI cs.CC cs.LO F.4.1; F.1.3  published:2016-06-11 summary:A backbone of a boolean formula $F$ is a collection $S$ of its variables for which there is a unique partial assignment $a_S$ such that $F[a_S]$ is satisfiable [MZK+99,WGS03]. This paper studies the nontransparency of backbones. We show that, under the widely believed assumption that integer factoring is hard, there exist sets of boolean formulas that have obvious, nontrivial backbones yet finding the values, $a_S$, of those backbones is intractable. We also show that, under the same assumption, there exist sets of boolean formulas that obviously have large backbones yet producing such a backbone $S$ is intractable. Further, we show that if integer factoring is not merely worst-case hard but is frequently hard, as is widely believed, then the frequency of hardness in our two results is not too much less than that frequency. version:4
arxiv-1701-08306 | Practical Reasoning with Norms for Autonomous Software Agents (Full Edition) | http://arxiv.org/abs/1701.08306 | id:1701.08306 author:Zohreh Shams, Marina De Vos, Julian Padget, Wamberto W. Vasconcelos category:cs.AI  published:2017-01-28 summary:Autonomous software agents operating in dynamic environments need to constantly reason about actions in pursuit of their goals, while taking into consideration norms which might be imposed on those actions. Normative practical reasoning supports agents making decisions about what is best for them to (not) do in a given situation. What makes practical reasoning challenging is the interplay between goals that agents are pursuing and the norms that the agents are trying to uphold. We offer a formalisation to allow agents to plan for multiple goals and norms in the presence of durative actions that can be executed concurrently. We compare plans based on decision-theoretic notions (i.e. utility) such that the utility gain of goals and utility loss of norm violations are the basis for this comparison. The set of optimal plans consists of plans that maximise the overall utility, each of which can be chosen by the agent to execute. We provide an implementation of our proposal in Answer Set Programming, thus allowing us to state the original problem in terms of a logic program that can be queried for solutions with specific properties. The implementation is proven to be sound and complete. version:1
arxiv-1701-08301 | Pure Rough Mereology and Counting | http://arxiv.org/abs/1701.08301 | id:1701.08301 author:A. Mani category:cs.AI cs.IT cs.LO math.IT math.LO  published:2017-01-28 summary:The study of mereology (parts and wholes) in the context of formal approaches to vagueness can be approached in a number of ways. In the context of rough sets, mereological concepts with a set-theoretic or valuation based ontology acquire complex and diverse behavior. In this research a general rough set framework called granular operator spaces is extended and the nature of parthood in it is explored from a minimally intrusive point of view. This is used to develop counting strategies that help in classifying the framework. The developed methodologies would be useful for drawing involved conclusions about the nature of data (and validity of assumptions about it) from antichains derived from context. The problem addressed is also about whether counting procedures help in confirming that the approximations involved in formation of data are indeed rough approximations? version:1
arxiv-1701-08191 | Incremental Maintenance Of Association Rules Under Support Threshold Change | http://arxiv.org/abs/1701.08191 | id:1701.08191 author:Mohamed Anis Bach Tobji, Mohamed Salah Gouider category:cs.AI cs.DB  published:2017-01-27 summary:Maintenance of association rules is an interesting problem. Several incremental maintenance algorithms were proposed since the work of (Cheung et al, 1996). The majority of these algorithms maintain rule bases assuming that support threshold doesn't change. In this paper, we present incremental maintenance algorithm under support threshold change. This solution allows user to maintain its rule base under any support threshold. version:1
arxiv-1701-08190 | Comparative Study Of Data Mining Query Languages | http://arxiv.org/abs/1701.08190 | id:1701.08190 author:Mohamed Anis Bach Tobji category:cs.AI cs.DB  published:2017-01-27 summary:Since formulation of Inductive Database (IDB) problem, several Data Mining (DM) languages have been proposed, confirming that KDD process could be supported via inductive queries (IQ) answering. This paper reviews the existing DM languages. We are presenting important primitives of the DM language and classifying our languages according to primitives' satisfaction. In addition, we presented languages' syntaxes and tried to apply each one to a database sample to test a set of KDD operations. This study allows us to highlight languages capabilities and limits, which is very useful for future work and perspectives. version:1
arxiv-1701-08179 | Balancing and Walking Using Full Dynamics LQR Control With Contact Constraints | http://arxiv.org/abs/1701.08179 | id:1701.08179 author:Sean Mason, Nicholas Rotella, Stefan Schaal, Ludovic Righetti category:cs.RO  published:2017-01-27 summary:Torque control algorithms which consider robot dynamics and contact constraints are important for creating dynamic behaviors for humanoids. As computational power increases, algorithms tend to also increase in complexity. However, it is not clear how much complexity is really required to create controllers which exhibit good performance. In this paper, we study the capabilities of a simple approach based on contact consistent LQR controllers designed around key poses to control various tasks on a humanoid robot. We present extensive experimental results on a hydraulic, torque controlled humanoid performing balancing and stepping tasks. This feedback control approach captures the necessary synergies between the DoFs of the robot to guarantee good control performance. We show that for the considered tasks, it is only necessary to re-linearize the dynamics of the robot at different contact configurations and that increasing the number of LQR controllers along desired trajectories does not improve performance. Our result suggest that very simple controllers can yield good performance competitive with current state of the art, but more complex, optimization-based whole-body controllers. A video of the experiments can be found at https://youtu.be/5T08CNKV1hw. version:1
arxiv-1701-08125 | Organic Computing in the Spotlight | http://arxiv.org/abs/1701.08125 | id:1701.08125 author:Sven Tomforde, Bernhard Sick, Christian MÃ¼ller-Schloer category:cs.MA cs.AI 68T05 I.2.8  I.2.11  published:2017-01-27 summary:Organic Computing is an initiative in the field of systems engineering that proposed to make use of concepts such as self-adaptation and self-organisation to increase the robustness of technical systems. Based on the observation that traditional design and operation concepts reach their limits, transferring more autonomy to the systems themselves should result in a reduction of complexity for users, administrators, and developers. However, there seems to be a need for an updated definition of the term "Organic Computing", of desired properties of technical, organic systems, and the objectives of the Organic Computing initiative. With this article, we will address these points. version:1
arxiv-1701-08096 | Efficiently Summarising Event Sequences with Rich Interleaving Patterns | http://arxiv.org/abs/1701.08096 | id:1701.08096 author:Apratim Bhattacharyya, Jilles Vreeken category:cs.AI cs.DB  published:2017-01-27 summary:Discovering the key structure of a database is one of the main goals of data mining. In pattern set mining we do so by discovering a small set of patterns that together describe the data well. The richer the class of patterns we consider, and the more powerful our description language, the better we will be able to summarise the data. In this paper we propose \ourmethod, a novel greedy MDL-based method for summarising sequential data using rich patterns that are allowed to interleave. Experiments show \ourmethod is orders of magnitude faster than the state of the art, results in better models, as well as discovers meaningful semantics in the form patterns that identify multiple choices of values. version:1
arxiv-1701-08051 | Efficient Kinematic Planning for Mobile Manipulators with Non-holonomic Constraints Using Optimal Control | http://arxiv.org/abs/1701.08051 | id:1701.08051 author:Markus Giftthaler, Farbod Farshidian, Timothy Sandy, Lukas Stadelmann, Jonas Buchli category:cs.RO  published:2017-01-27 summary:This work addresses the problem of kinematic trajectory planning for mobile manipulators with non-holonomic constraints, and holonomic operational-space tracking constraints. We obtain whole-body trajectories and time-varying kinematic feedback controllers by solving a Constrained Sequential Linear Quadratic Optimal Control problem. The employed algorithm features high efficiency through a continuous-time formulation that benefits from adaptive step-size integrators and through linear complexity in the number of integration steps. In a first application example, we solve kinematic trajectory planning problems for a 26 DoF wheeled robot. In a second example, we apply Constrained SLQ to a real-world mobile manipulator in a receding-horizon optimal control fashion, where we obtain optimal controllers and plans at rates up to 100 Hz. version:1
arxiv-1701-08022 | KMC 3: counting and manipulating k-mer statistics | http://arxiv.org/abs/1701.08022 | id:1701.08022 author:Marek Kokot, Maciej DÅugosz, Sebastian Deorowicz category:q-bio.GN cs.DC cs.DS  published:2017-01-27 summary:Summary: Counting all k-mers in a given dataset is a standard procedure in many bioinformatics applications. We introduce KMC3, a significant improvement of the former KMC2 algorithm together with KMC tools for manipulating k-mer databases. Usefulness of the tools is shown on a few real problems. Availability: Program is freely available at http://sun.aei.polsl.pl/REFRESH/kmc. Contact: sebastian.deorowicz@polsl.pl version:1
arxiv-1701-08665 | Redefinition of the concept of fuzzy set based on vague partition from the perspective of axiomatization | http://arxiv.org/abs/1701.08665 | id:1701.08665 author:Xiaodong Pan, Yang Xu category:cs.AI 94D05 H.1.2  published:2017-01-27 summary:Based on the in-depth analysis of the essence and features of vague phenomena, this paper focuses on establishing the axiomatical foundation of membership degree theory for vague phenomena, presents an axiomatic system to govern membership degrees and their interconnections. On this basis, the concept of vague partition is introduced, further, the concept of fuzzy set introduced by Zadeh in 1965 is redefined based on vague partition from the perspective of axiomatization. The thesis defended in this paper is that the relationship among vague attribute values should be the starting point to recognize and model vague phenomena from a quantitative view. version:1
arxiv-1701-07851 | Human-Robot Mutual Adaptation in Shared Autonomy | http://arxiv.org/abs/1701.07851 | id:1701.07851 author:Stefanos Nikolaidis, Yu Xiang Zhu, David Hsu, Siddhartha Srinivasa category:cs.RO  published:2017-01-26 summary:Shared autonomy integrates user input with robot autonomy in order to control a robot and help the user to complete a task. Our work aims to improve the performance of such a human-robot team: the robot tries to guide the human towards an effective strategy, sometimes against the human's own preference, while still retaining his trust. We achieve this through a principled human-robot mutual adaptation formalism. We integrate a bounded-memory adaptation model of the human into a partially observable stochastic decision model, which enables the robot to adapt to an adaptable human. When the human is adaptable, the robot guides the human towards a good strategy, maybe unknown to the human in advance. When the human is stubborn and not adaptable, the robot complies with the human's preference in order to retain their trust. In the shared autonomy setting, unlike many other common human-robot collaboration settings, only the robot actions can change the physical state of the world, and the human and robot goals are not fully observable. We address these challenges and show in a human subject experiment that the proposed mutual adaptation formalism improves human-robot team performance, while retaining a high level of user trust in the robot, compared to the common approach of having the robot strictly following participants' preference. version:1
arxiv-1701-02369 | Reinforcement Learning based Embodied Agents Modelling Human Users Through Interaction and Multi-Sensory Perception | http://arxiv.org/abs/1701.02369 | id:1701.02369 author:Kory W. Mathewson, Patrick M. Pilarski category:cs.HC cs.AI cs.RO  published:2017-01-09 summary:This paper extends recent work in interactive machine learning (IML) focused on effectively incorporating human feedback. We show how control and feedback signals complement each other in systems which model human reward. We demonstrate that simultaneously incorporating human control and feedback signals can improve interactive robotic systems' performance on a self-mirrored movement control task where an RL-agent controlled right arm attempts to match the preprogrammed movement pattern of the left arm. We illustrate the impact of varying human feedback parameters on task performance by investigating the probability of giving feedback on each time step and the likelihood of given feedback being correct. We further illustrate that varying the temporal decay with which the agent incorporates human feedback has a significant impact on task performance. We found that smearing human feedback over time steps improves performance and we show varying the probability of feedback at each time step, and an increased likelihood of those feedbacks being 'correct' can impact agent performance. We conclude that understanding latent variables in human feedback is crucial for learning algorithms acting in human-machine interaction domains. version:3
arxiv-1701-07799 | Flying, Hopping Pit-Bots for Cave and Lava Tube Exploration on the Moon and Mars | http://arxiv.org/abs/1701.07799 | id:1701.07799 author:Jekanthan Thangavelautham, Mark S. Robinson, Alexander Taits, Tyler McKinney, Sean Amidan, Adam Polak category:cs.RO astro-ph.IM  published:2017-01-26 summary:Wheeled ground robots are limited from exploring extreme environments such as caves, lava tubes and skylights. Small robots that utilize unconventional mobility through hopping, flying and rolling can overcome many roughness limitations and thus extend exploration sites of interest on Moon and Mars. In this paper we introduce a network of 3 kg, 0.30 m diameter ball robots (pit-bots) that can fly, hop and roll using an onboard miniature propulsion system. These pit-bots can be deployed from a lander or large rover. Each robot is equipped with a smartphone sized computer, stereo camera and laser rangefinder to per-form navigation and mapping. The ball robot can carry a payload of 1 kg or perform sample return. Our studies show a range of 5 km and 0.7 hours flight time on the Moon. version:1
arxiv-1701-07769 | Ethical Considerations in Artificial Intelligence Courses | http://arxiv.org/abs/1701.07769 | id:1701.07769 author:Emanuelle Burton, Judy Goldsmith, Sven Koenig, Benjamin Kuipers, Nicholas Mattei, Toby Walsh category:cs.AI cs.CY cs.GL K.3.2; K.4.1; K.7.m  published:2017-01-26 summary:The recent surge in interest in ethics in artificial intelligence may leave many educators wondering how to address moral, ethical, and philosophical issues in their AI courses. As instructors we want to develop curriculum that not only prepares students to be artificial intelligence practitioners, but also to understand the moral, ethical, and philosophical impacts that artificial intelligence will have on society. In this article we provide practical case studies and links to resources for use by AI educators. We also provide concrete suggestions on how to integrate AI ethics into a general artificial intelligence course and how to teach a stand-alone artificial intelligence ethics course. version:1
arxiv-1701-07657 | Logic Programming Petri Nets | http://arxiv.org/abs/1701.07657 | id:1701.07657 author:Giovanni Sileno category:cs.AI  published:2017-01-26 summary:With the purpose of modeling, specifying and reasoning in an integrated fashion with procedural and declarative aspects (both commonly present in cases or scenarios), the paper introduces Logic Programming Petri Nets (LPPN), an extension to the Petri Net notation providing an interface to logic programming constructs. Two semantics are presented. First, a hybrid operational semantics that separates the process component, treated with Petri nets, from the constraint/terminological component, treated with Answer Set Programming (ASP). Second, a denotational semantics maps the notation to ASP fully, via Event Calculus. These two alternative specifications enable a preliminary evaluation in terms of reasoning efficiency. version:1
arxiv-1701-07594 | Intelligent real-time MEMS sensor fusion and calibration | http://arxiv.org/abs/1701.07594 | id:1701.07594 author:Dusan Nemec, Ales Janota, Marian Hrubos, Vojtech Simak category:cs.RO  published:2017-01-26 summary:This paper discusses an innovative adaptive heterogeneous fusion algorithm based on estimation of the mean square error of all variables used in real time processing. The algorithm is designed for a fusion between derivative and absolute sensors and is explained by the fusion of the 3-axial gyroscope, 3-axial accelerometer and 3-axial magnetometer into attitude and heading estimation. Our algorithm has similar error performance in the steady state but much faster dynamic response compared to the fixed-gain fusion algorithm. In comparison with the extended Kalman filter the proposed algorithm converges faster and takes less computational time. On the other hand, Kalman filter has smaller mean square output error in a steady state but becomes unstable if the estimated state changes too rapidly. Additionally, the noisy fusion deviation can be used in the process of calibration. The paper proposes and explains a real-time calibration method based on machine learning working in the online mode during run-time. This allows compensation of sensor thermal drift right in the sensors working environment without need of re-calibration in the laboratory. version:1
arxiv-1701-07549 | Robot Coverage Path Planning for General Surfaces Using Quadratic Differentials | http://arxiv.org/abs/1701.07549 | id:1701.07549 author:Yu-Yao Lin, Chien-Chun Ni, Na Lei, Xianfeng David Gu, Jie Gao category:cs.RO  published:2017-01-26 summary:Robot Coverage Path planning (i.e., provide full coverage of a given domain by one or multiple robots) is a classical problem in the field of robotics and motion planning. The goal is to provide nearly full coverage while also minimize duplicately visited area. In this paper we focus on the scenario of path planning on general surfaces including planar domains with complex topology, complex terrain or general surface in 3D space. The main idea is to adopt a natural, intrinsic and global parametrization of the surface for robot path planning, namely the holomorphic quadratic differentials. Except for a small number of zero points (singularities), each point on the surface is given a uv-coordinates naturally represented by a complex number. We show that natural, efficient robot paths can be obtained by using such coordinate systems. The method is based on intrinsic geometry and thus can be adapted to general surface exploration in 3D. version:1
arxiv-1701-07547 | Optimized Bucket Wheel Design for Asteroid Excavation | http://arxiv.org/abs/1701.07547 | id:1701.07547 author:Ravi Teja Nallapu, Andrew Thoesen, Laurence Garvie, Erik Asphaug, Jekanthan Thangavelautham category:cs.RO astro-ph.IM  published:2017-01-26 summary:Current spacecraft need to launch with all of their required fuel for travel. This limits the system performance, payload capacity, and mission flexibility. One compelling alternative is to perform In-Situ Resource Utilization (ISRU) by extracting fuel from small bodies in local space such as asteroids or small satellites. Compared to the Moon or Mars, the microgravity on an asteroid demands a fraction of the energy for digging and accessing hydrated regolith just below the surface. Previous asteroid excavation efforts have focused on discrete capture events (an extension of sampling technology) or whole-asteroid capture and processing. This paper proposes an optimized bucket wheel design for surface excavation of an asteroid or small-body. Asteroid regolith is excavated and water extracted for use as rocket propellant. Our initial study focuses on system design, bucket wheel mechanisms, and capture dynamics applied to ponded materials known to exist on asteroids like Itokawa and Eros and small satellites like Phobos and Deimos. For initial evaluation of material-spacecraft dynamics and mechanics, we assume lunar-like regolith for bulk density, particle size and cohesion. We shall present our estimates for the energy balance of excavation and processing versus fuel gained. Conventional electrolysis of water is used to produce hydrogen and oxygen. It is compared with steam for propulsion and both show significant delta-v. We show that a return trip from Deimos to Earth is possible for a 12 kg craft using ISRU processed fuel. version:1
arxiv-1701-07500 | Scalable Architecture for Anomaly Detection and Visualization in Power Generating Assets | http://arxiv.org/abs/1701.07500 | id:1701.07500 author:Paras Jain, Chirag Tailor, Sam Ford, Liexiao Ding, Michael Phillips, Fang Liu, Nagi Gebraeel, Duen Horng Chau category:cs.DC  published:2017-01-25 summary:Power-generating assets (e.g., jet engines, gas turbines) are often instrumented with tens to hundreds of sensors for monitoring physical and performance degradation. Anomaly detection algorithms highlight deviations from predetermined benchmarks with the goal of detecting incipient faults. We are developing an integrated system to address three key challenges within analyzing sensor data from power-generating assets: (1) difficulty in ingesting and analyzing data from large numbers of machines; (2) prevalence of false alarms generated by anomaly detection algorithms resulting in unnecessary downtime and maintenance; and (3) lack of an integrated visualization that helps users understand and explore the flagged anomalies and relevant sensor context in the energy domain. We present preliminary results and our key findings in addressing these challenges. Our system's scalable event ingestion framework, based on OpenTSDB, ingests nearly 400,000 sensor data samples per seconds using a 30 machine cluster. To reduce false alarm rates, we leverage the False Discovery Rate (FDR) algorithm which significantly reduces the number of false alarms. Our visualization tool presents the anomalies and associated content flagged by the FDR algorithm to inform users and practitioners in their decision making process. We believe our integrated platform will help reduce maintenance costs significantly while increasing asset lifespan. We are working to extend our system on multiple fronts, such as scaling to more data and more compute nodes (70 in total). version:1
arxiv-1701-07294 | Weak Coverage of a Rectangular Barrier | http://arxiv.org/abs/1701.07294 | id:1701.07294 author:Stefan Dobrev, Evangelos Kranakis, Danny Krizanc, Manuel Lafond, Jan Manuch, Lata Narayanan, Jaroslav Opatrny, Ladislav Stacho category:cs.DC math.OC  published:2017-01-25 summary:Assume n wireless mobile sensors are initially dispersed in an ad hoc manner in a rectangular region. They are required to move to final locations so that they can detect any intruder crossing the region in a direction parallel to the sides of the rectangle, and thus provide weak barrier coverage of the region. We study three optimization problems related to the movement of sensors to achieve weak barrier coverage: minimizing the number of sensors moved (MinNum), minimizing the average distance moved by the sensors (MinSum), and minimizing the maximum distance moved by the sensors (MinMax). We give an O(n^{3/2}) time algorithm for the MinNum problem for sensors of diameter 1 that are initially placed at integer positions; in contrast we show that the problem is NP-hard even for sensors of diameter 2 that are initially placed at integer positions. We show that the MinSum problem is solvable in O(n log n) time for homogeneous range sensors in arbitrary initial positions, while it is NP-hard for heterogeneous sensor ranges. Finally, we prove that even very restricted homogeneous versions of the MinMax problem are NP-hard. version:1
arxiv-1701-07254 | Cascaded Incremental Nonlinear Dynamic Inversion Control for MAV Disturbance Rejection | http://arxiv.org/abs/1701.07254 | id:1701.07254 author:Ewoud J. J. Smeur, Guido C. H. E. de Croon, Qiping Chu category:cs.RO  published:2017-01-25 summary:Micro Aerial Vehicles (MAVs) are limited in their operation outdoors near obstacles by their ability to withstand wind gusts. Currently widespread position control methods such as Proportional Integral Derivative control do not perform well under the influence of gusts. Incremental Nonlinear Dynamic Inversion (INDI) is a sensor-based control technique that can control nonlinear systems subject to disturbances. It was developed for the attitude control of manned aircraft or MAVs. In this paper we generalize this method to the outer loop control of MAVs under severe gust loads. Significant improvements over a traditional Proportional Integral Derivative (PID) controller are demonstrated in an experiment where the quadrotor flies in and out of a windtunnel exhaust at 10 m/s. The control method does not rely on frequent position updates, as is demonstrated in an outside experiment using a standard GPS module. Finally, we investigate the effect of using a linearization to calculate thrust vector increments, compared to a nonlinear calculation. The method requires little modeling and is computationally efficient. version:1
arxiv-1611-06189 | Query Complexity of Tournament Solutions | http://arxiv.org/abs/1611.06189 | id:1611.06189 author:Palash Dey category:cs.DS cs.AI cs.DM  published:2016-11-18 summary:A directed graph where there is exactly one edge between every pair of vertices is called a {\em tournament}. Finding the "best" set of vertices of a tournament is a well studied problem in social choice theory. A {\em tournament solution} takes a tournament as input and outputs a subset of vertices of the input tournament. However, in many applications, for example, choosing the best set of drugs from a given set of drugs, the edges of the tournament are given only implicitly and knowing the orientation of an edge is costly. In such scenarios, we would like to know the best set of vertices (according to some tournament solution) by "querying" as few edges as possible. We, in this paper, precisely study this problem for commonly used tournament solutions: given an oracle access to the edges of a tournament T, find $f(T)$ by querying as few edges as possible, for a tournament solution f. We first show that the set of Condorcet non-losers in a tournament can be found by querying $2n-\lfloor \log n \rfloor -2$ edges only and this is tight in the sense that every algorithm for finding the set of Condorcet non-losers needs to query at least $2n-\lfloor \log n \rfloor -2$ edges in the worst case, where $n$ is the number of vertices in the input tournament. We then move on to study other popular tournament solutions and show that any algorithm for finding the Copeland set, the Slater set, the Markov set, the bipartisan set, the uncovered set, the Banks set, and the top cycle must query $\Omega(n^2)$ edges in the worst case. On the positive side, we are able to circumvent our strong query complexity lower bound results by proving that, if the size of the top cycle of the input tournament is at most $k$, then we can find all the tournament solutions mentioned above by querying $O(nk + \frac{n\log n}{\log(1-\frac{1}{k})})$ edges only. version:3
arxiv-1701-08680 | Fog-Assisted wIoT: A Smart Fog Gateway for End-to-End Analytics in Wearable Internet of Things | http://arxiv.org/abs/1701.08680 | id:1701.08680 author:Nicholas Constant, Debanjan Borthakur, Mohammadreza Abtahi, Harishchandra Dubey, Kunal Mankodiya category:cs.DC cs.CY cs.NI  published:2017-01-25 summary:Today, wearable internet-of-things (wIoT) devices continuously flood the cloud data centers at an enormous rate. This increases a demand to deploy an edge infrastructure for computing, intelligence, and storage close to the users. The emerging paradigm of fog computing could play an important role to make wIoT more efficient and affordable. Fog computing is known as the cloud on the ground. This paper presents an end-to-end architecture that performs data conditioning and intelligent filtering for generating smart analytics from wearable data. In wIoT, wearable sensor devices serve on one end while the cloud backend offers services on the other end. We developed a prototype of smart fog gateway (a middle layer) using Intel Edison and Raspberry Pi. We discussed the role of the smart fog gateway in orchestrating the process of data conditioning, intelligent filtering, smart analytics, and selective transfer to the cloud for long-term storage and temporal variability monitoring. We benchmarked the performance of developed prototypes on real-world data from smart e-textile gloves. Results demonstrated the usability and potential of proposed architecture for converting the real-world data into useful analytics while making use of knowledge-based models. In this way, the smart fog gateway enhances the end-to-end interaction between wearables (sensor devices) and the cloud. version:1
arxiv-1701-07123 | Towards Automatic Learning of Heuristics for Mechanical Transformations of Procedural Code | http://arxiv.org/abs/1701.07123 | id:1701.07123 author:Guillermo Vigueras, Manuel Carro, Salvador Tamarit, Julio MariÃ±o category:cs.PL cs.AI I.2.6; C.1.4  published:2017-01-25 summary:The current trends in next-generation exascale systems go towards integrating a wide range of specialized (co-)processors into traditional supercomputers. Due to the efficiency of heterogeneous systems in terms of Watts and FLOPS per surface unit, opening the access of heterogeneous platforms to a wider range of users is an important problem to be tackled. However, heterogeneous platforms limit the portability of the applications and increase development complexity due to the programming skills required. Program transformation can help make programming heterogeneous systems easier by defining a step-wise transformation process that translates a given initial code into a semantically equivalent final code, but adapted to a specific platform. Program transformation systems require the definition of efficient transformation strategies to tackle the combinatorial problem that emerges due to the large set of transformations applicable at each step of the process. In this paper we propose a machine learning-based approach to learn heuristics to define program transformation strategies. Our approach proposes a novel combination of reinforcement learning and classification methods to efficiently tackle the problems inherent to this type of systems. Preliminary results demonstrate the suitability of this approach. version:1
arxiv-1701-07103 | Artificial Intelligence Approaches To UCAV Autonomy | http://arxiv.org/abs/1701.07103 | id:1701.07103 author:Amir Husain, Bruce Porter category:cs.AI cs.RO  published:2017-01-24 summary:This paper covers a number of approaches that leverage Artificial Intelligence algorithms and techniques to aid Unmanned Combat Aerial Vehicle (UCAV) autonomy. An analysis of current approaches to autonomous control is provided followed by an exploration of how these techniques can be extended and enriched with AI techniques including Artificial Neural Networks (ANN), Ensembling and Reinforcement Learning (RL) to evolve control strategies for UCAVs. version:1
arxiv-1702-01018 | On Robustness in Multilayer Interdependent Network | http://arxiv.org/abs/1702.01018 | id:1702.01018 author:Joydeep Banerjee, Chenyang Zhou, Arunabha Sen category:cs.NI cs.AI  published:2017-01-24 summary:Critical Infrastructures like power and communication networks are highly interdependent on each other for their full functionality. Many significant research have been pursued to model the interdependency and failure analysis of these interdependent networks. However, most of these models fail to capture the complex interdependencies that might actually exist between the infrastructures. The \emph{Implicative Interdependency Model} that utilizes Boolean Logic to capture complex interdependencies was recently proposed which overcome the limitations of the existing models. A number of problems were studies based on this model. In this paper we study the \textit{Robustness} problem in Interdependent Power and Communication Network. The robustness is defined with respect to two parameters $K \in I^{+} \cup \{0\}$ and $\rho \in (0,1]$. We utilized the \emph{Implicative Interdependency Model} model to capture the complex interdependency between the two networks. The model classifies the interdependency relations into four cases. Computational complexity of the problem is analyzed for each of these cases. A polynomial time algorithm is designed for the first case that outputs the optimal solution. All the other cases are proved to be NP-complete. An in-approximability bound is provided for the third case. For the general case we formulate an Integer Linear Program to get the optimal solution and a polynomial time heuristic. The applicability of the heuristic is evaluated using power and communication network data of Maricopa County, Arizona. The experimental results showed that the heuristic almost always produced near optimal value of parameter $K$ for $\rho < 0.42$. version:1
arxiv-1607-01404 | PRIMME_SVDS: A High-Performance Preconditioned SVD Solver for Accurate Large-Scale Computations | http://arxiv.org/abs/1607.01404 | id:1607.01404 author:Lingfei Wu, Eloy Romero, Andreas Stathopoulos category:cs.MS cs.DC cs.NA  published:2016-07-05 summary:The increasing number of applications requiring the solution of large scale singular value problems have rekindled interest in iterative methods for the SVD. Some promising recent ad- vances in large scale iterative methods are still plagued by slow convergence and accuracy limitations for computing smallest singular triplets. Furthermore, their current implementations in MATLAB cannot address the required large problems. Recently, we presented a preconditioned, two-stage method to effectively and accurately compute a small number of extreme singular triplets. In this research, we present a high-performance software, PRIMME SVDS, that implements our hybrid method based on the state-of-the-art eigensolver package PRIMME for both largest and smallest singular values. PRIMME SVDS fills a gap in production level software for computing the partial SVD, especially with preconditioning. The numerical experiments demonstrate its superior performance compared to other state-of-the-art software and its good parallel performance under strong and weak scaling. version:2
arxiv-1701-06828 | Security and Privacy of performing Data Analytics in the cloud - A three-way handshake of Technology, Policy, and Management | http://arxiv.org/abs/1701.06828 | id:1701.06828 author:Nidhi Rastogi, Marie Joan Kristine Gloria, James Hendler category:cs.DC cs.CY cs.NI  published:2017-01-24 summary:Cloud platform came into existence primarily to accelerate IT delivery and to promote innovation. To this point, it has performed largely well to the expectations of technologists, businesses and customers. The service aspect of this technology has paved the road for a faster set up of infrastructure and related goals for both startups and established organizations. This has further led to quicker delivery of many user-friendly applications to the market while proving to be a commercially viable option to companies with limited resources. On the technology front, the creation and adoption of this ecosystem has allowed easy collection of massive data from various sources at one place, where the place is sometimes referred as just the cloud. Efficient data mining can be performed on raw data to extract potentially useful information, which was not possible at this scale before. Targeted advertising is a common example that can help businesses. Despite these promising offerings, concerns around security and privacy of user information suppressed wider acceptance and an all-encompassing deployment of the cloud platform. In this paper, we discuss security and privacy concerns that occur due to data exchanging hands between a cloud servicer provider (CSP) and the primary cloud user - the data collector, from the content generator. We offer solutions that encompass technology, policy and sound management of the cloud service asserting that this approach has the potential to provide a holistic solution. version:1
arxiv-1205-2170 | Collaborative search on the plane without communication | http://arxiv.org/abs/1205.2170 | id:1205.2170 author:Ofer Feinerman, Amos Korman, Zvi Lotker, Jean-SÃ©bastien Sereni category:cs.DC cs.DM  published:2012-05-10 summary:We generalize the classical cow-path problem [7, 14, 38, 39] into a question that is relevant for collective foraging in animal groups. Specifically, we consider a setting in which k identical (probabilistic) agents, initially placed at some central location, collectively search for a treasure in the two-dimensional plane. The treasure is placed at a target location by an adversary and the goal is to find it as fast as possible as a function of both k and D, where D is the distance between the central location and the target. This is biologically motivated by cooperative, central place foraging such as performed by ants around their nest. In this type of search there is a strong preference to locate nearby food sources before those that are further away. Our focus is on trying to find what can be achieved if communication is limited or altogether absent. Indeed, to avoid overlaps agents must be highly dispersed making communication difficult. Furthermore, if agents do not commence the search in synchrony then even initial communication is problematic. This holds, in particular, with respect to the question of whether the agents can communicate and conclude their total number, k. It turns out that the knowledge of k by the individual agents is crucial for performance. Indeed, it is a straightforward observation that the time required for finding the treasure is $\Omega$(D + D 2 /k), and we show in this paper that this bound can be matched if the agents have knowledge of k up to some constant approximation. We present an almost tight bound for the competitive penalty that must be paid, in the running time, if agents have no information about k. Specifically, on the negative side, we show that in such a case, there is no algorithm whose competitiveness is O(log k). On the other hand, we show that for every constant $\epsilon \textgreater{} 0$, there exists a rather simple uniform search algorithm which is $O( \log^{1+\epsilon} k)$-competitive. In addition, we give a lower bound for the setting in which agents are given some estimation of k. As a special case, this lower bound implies that for any constant $\epsilon \textgreater{} 0$, if each agent is given a (one-sided) $k^\epsilon$-approximation to k, then the competitiveness is $\Omega$(log k). Informally, our results imply that the agents can potentially perform well without any knowledge of their total number k, however, to further improve, they must be given a relatively good approximation of k. Finally, we propose a uniform algorithm that is both efficient and extremely simple suggesting its relevance for actual biological scenarios. version:2
arxiv-1701-06783 | The Autonomic Architecture of the Licas System | http://arxiv.org/abs/1701.06783 | id:1701.06783 author:Kieran Greer category:cs.SE cs.DC  published:2017-01-24 summary:Licas (lightweight internet-based communication for autonomic services) is a distributed framework for building service-based systems. The framework provides a p2p server and more intelligent processing of information through its AI algorithms. Distributed communication includes XML-RPC, REST, HTTP and Web Services. It has matured a lot over the last few years to provide a robust platform for building different types of system, where Microservices, SOA or IoT would be possible. The system is also mobile-compatible with Android. This paper focuses in particular on the autonomic setup and how it might be used. A novel linking mechanism has been described previously [5] that can be used to dynamically link sources and this can also be included as part of the autonomic framework. version:1
arxiv-1701-06745 | Proceedings of the 12th Workshop on User Interfaces for Theorem Provers | http://arxiv.org/abs/1701.06745 | id:1701.06745 author:Serge Autexier, Pedro Quaresma category:cs.HC cs.AI cs.LO  published:2017-01-24 summary:The UITP workshop series brings together researchers interested in designing, developing and evaluating user interfaces for automated reasoning tools, such as interactive proof assistants, automated theorem provers, model finders, tools for formal methods, and tools for visualising and manipulating logical formulas and proofs. The twelth edition of UITP took place in Coimbra, Portugal, and was part of the International Joint Conference on Automated Reasoning (IJCAR'16). The workshop consisted of an invited talk, six presentations of submitted papers and lively hands-on session for reasoning tools and their user-interface. These post-proceedings contain four contributed papers accepted for publication after a second round of reviewing after the workshop as well as the invited paper. version:1
arxiv-1607-04818 | Asynchronous Parallel Algorithms for Nonconvex Big-Data Optimization. Part I: Model and Convergence | http://arxiv.org/abs/1607.04818 | id:1607.04818 author:Loris Cannelli, Francisco Facchinei, Vyacheslav Kungurtsev, Gesualdo Scutari category:math.OC cs.DC  published:2016-07-17 summary:We propose a novel asynchronous parallel algorithmic framework for the minimization of the sum of a smooth nonconvex function and a convex nonsmooth regularizer, subject to both convex and nonconvex constraints. The proposed framework hinges on successive convex approximation techniques and a novel probabilistic model that captures key elements of modern computational architectures and asynchronous implementations in a more faithful way than current state of the art models. Key features of the proposed framework are: i) it accommodates inconsistent read, meaning that components of the vector variables may be written by some cores while being simultaneously read by others; ii) it covers in a unified way several different specific solution methods, and iii) it accommodates a variety of possible parallel computing architectures. Almost sure convergence to stationary solutions is proved. Numerical results, reported in the companion paper, on both convex and nonconvex problems show our method can consistently outperform existing parallel asynchronous algorithms. version:2
arxiv-1701-06699 | Imitating Driver Behavior with Generative Adversarial Networks | http://arxiv.org/abs/1701.06699 | id:1701.06699 author:Alex Kuefler, Jeremy Morton, Tim Wheeler, Mykel Kochenderfer category:cs.AI  published:2017-01-24 summary:The ability to accurately predict and simulate human driving behavior is critical for the development of intelligent transportation systems. Traditional modeling methods have employed simple parametric models and behavioral cloning. This paper adopts a method for overcoming the problem of cascading errors inherent in prior approaches, resulting in realistic behavior that is robust to trajectory perturbations. We extend Generative Adversarial Imitation Learning to the training of recurrent policies, and we demonstrate that our model outperforms rule-based controllers and maximum likelihood models in realistic highway simulations. Our model both reproduces emergent behavior of human drivers, such as lane change rate, while maintaining realistic control over long time horizons. version:1
arxiv-1701-06635 | Space-Time Graph Modeling of Ride Requests Based on Real-World Data | http://arxiv.org/abs/1701.06635 | id:1701.06635 author:Abhinav Jauhri, Brian Foo, Jerome Berclaz, Chih Chi Hu, Radek Grzeszczuk, Vasu Parameswaran, John Paul Shen category:cs.AI J.4; I.2.6; K.4.1  published:2017-01-23 summary:This paper focuses on modeling ride requests and their variations over location and time, based on analyzing extensive real-world data from a ride-sharing service. We introduce a graph model that captures the spatial and temporal variability of ride requests and the potentials for ride pooling. We discover these ride request graphs exhibit a well known property called densification power law often found in real graphs modelling human behaviors. We show the pattern of ride requests and the potential of ride pooling for a city can be characterized by the densification factor of the ride request graphs. Previous works have shown that it is possible to automatically generate synthetic versions of these graphs that exhibit a given densification factor. We present an algorithm for automatic generation of synthetic ride request graphs that match quite well the densification factor of ride request graphs from actual ride request data. version:1
arxiv-1605-05590 | MapReduce and Streaming Algorithms for Diversity Maximization in Metric Spaces of Bounded Doubling Dimension | http://arxiv.org/abs/1605.05590 | id:1605.05590 author:Matteo Ceccarello, Andrea Pietracaprina, Geppino Pucci, Eli Upfal category:cs.DC  published:2016-05-18 summary:Given a dataset of points in a metric space and an integer $k$, a diversity maximization problem requires determining a subset of $k$ points maximizing some diversity objective measure, e.g., the minimum or the average distance between two points in the subset. Diversity maximization is computationally hard, hence only approximate solutions can be hoped for. Although its applications are mainly in massive data analysis, most of the past research on diversity maximization focused on the sequential setting. In this work we present space and pass/round-efficient diversity maximization algorithms for the Streaming and MapReduce models and analyze their approximation guarantees for the relevant class of metric spaces of bounded doubling dimension. Like other approaches in the literature, our algorithms rely on the determination of high-quality core-sets, i.e., (much) smaller subsets of the input which contain good approximations to the optimal solution for the whole input. For a variety of diversity objective functions, our algorithms attain an $(\alpha+\epsilon)$-approximation ratio, for any constant $\epsilon>0$, where $\alpha$ is the best approximation ratio achieved by a polynomial-time, linear-space sequential algorithm for the same diversity objective. This improves substantially over the approximation ratios attainable in Streaming and MapReduce by state-of-the-art algorithms for general metric spaces. We provide extensive experimental evidence of the effectiveness of our algorithms on both real world and synthetic datasets, scaling up to over a billion points. version:4
arxiv-1701-06388 | Constraint programming for planning test campaigns of communications satellites | http://arxiv.org/abs/1701.06388 | id:1701.06388 author:Emmanuel HÃ©brard, Marie-JosÃ© Huguet, Daniel Veysseire, Ludivine Sauvan, Bertrand Cabon category:cs.AI  published:2017-01-23 summary:The payload of communications satellites must go through a series of tests to assert their ability to survive in space. Each test involves some equipment of the payload to be active, which has an impact on the temperature of the payload. Sequencing these tests in a way that ensures the thermal stability of the payload and minimizes the overall duration of the test campaign is a very important objective for satellite manufacturers. The problem can be decomposed in two sub-problems corresponding to two objectives: First, the number of distinct configurations necessary to run the tests must be minimized. This can be modeled as packing the tests into configurations, and we introduce a set of implied constraints to improve the lower bound of the model. Second, tests must be sequenced so that the number of times an equipment unit has to be switched on or off is minimized. We model this aspect using the constraint Switch, where a buffer with limited capacity represents the currently active equipment units, and we introduce an improvement of the propagation algorithm for this constraint. We then introduce a search strategy in which we sequentially solve the sub-problems (packing and sequencing). Experiments conducted on real and random instances show the respective interest of our contributions. version:1
arxiv-1701-06382 | Design of an Audio Interface for Patmos | http://arxiv.org/abs/1701.06382 | id:1701.06382 author:Daniel Sanz Ausin, Fabian Goerge category:cs.AR  published:2017-01-23 summary:This paper describes the design and implementation of an audio interface for the Patmos processor, which runs on an Altera DE2-115 FPGA board. This board has an audio codec included, the WM8731. The interface described in this work allows to receive and send audio from and to the WM8731, and to synthesize, store or manipulate audio signals writing C programs for Patmos. The audio interface described in this paper is intended to be used with the Patmos processor. Patmos is an open source RISC ISAs with a load-store architecture, that is optimized for Real-Time Systems. Patmos is part of a project founded by the European Union called T-CREST (Time-predictable Multi-Core Architecture for Embedded Systems).[5] The structure of this project is integrated with the Patmos project: new hardware modules have been added as IOs, which allow the communication between the processor and the audio codec. These modules include a clock generator for the audio chip, ADC and DAC modules for the audio conversion from analog to digital and vice versa, and an I2C module which allows setting configuration parameters on the audio codec. Moreover, a top module has been created, which connects all the modules previously mentioned between them, to Patmos and to the WM8731, using the external pins of the FPGA. version:1
arxiv-1701-06356 | Let's HPC: A web-based interactive platform to aid High Performance Computing education | http://arxiv.org/abs/1701.06356 | id:1701.06356 author:Akshar Varma, Yashwant Keswani, Yashodhan Bhatnagar, Bhaskar Chaudhury category:cs.CY cs.DC  published:2017-01-23 summary:Let's HPC (www.letshpc.org) is an open-access online platform to supplement conventional classroom oriented High Performance Computing (HPC) and Parallel & Distributed Computing (PDC) education. The web based platform provides online plotting and analysis tools which allow users to learn, evaluate, teach and see the performance of parallel algorithms from a system's viewpoint. The user can quantitatively compare and understand the importance of numerous deterministic as well as non-deterministic factors of both the software and the hardware that impact the performance of parallel programs. At the heart of this platform is a database archiving the performance and execution environment related data of standard parallel algorithms executed on different computing architectures using different programming environments, this data is contributed by various stakeholders in the HPC community. The plotting and analysis tools of our platform can be combined seamlessly with the database to aid self-learning, teaching, evaluation and discussion of different HPC related topics. Instructors of HPC/PDC related courses can use the platform's tools to illustrate the importance of proper analysis in understanding factors impacting performance, to encourage peer learning among students, as well as to allow students to prepare a standard lab/project report aiding the instructor in uniform evaluation. The platform's modular design enables easy inclusion of performance related data from contributors as well as addition of new features in the future. version:1
arxiv-1702-00312 | Dynamic load balancing for large-scale adaptive finite element computation | http://arxiv.org/abs/1702.00312 | id:1702.00312 author:Hui Liu, Tao Cui, Wei Leng, Linbo Zhang category:cs.DC  published:2017-01-23 summary:For the parallel computation of partial differential equations, one key is the grid partitioning. It requires that each process owns the same amount of computations, and also, the partitioning quality should be proper to reduce the communications among processes. When calculating the partial differential equations using adaptive finite element methods, the grid and the basis functions adjust in each iteration, which introduce load balancing issues. The grid should be redistributed dynamically. This paper studies dynamic load balancing algorithms and the implementation on the adaptive finite element platform PHG. The numerical experiments show that algorithms studied in this paper have good partitioning quality, and they are efficient. version:1
arxiv-1701-06562 | Certificate Linking and Caching for Logical Trust | http://arxiv.org/abs/1701.06562 | id:1701.06562 author:Qiang Cao, Vamsi Thummala, Jeffrey S. Chase, Yuanjun Yao, Bing Xie category:cs.CR cs.DC  published:2017-01-22 summary:SAFE is a data-centric platform for building multi-domain networked systems, i.e., systems whose participants are controlled by different principals. Participants make trust decisions by issuing local queries over logic content exchanged in certificates. The contribution of SAFE is to address a key barrier to practical use of logical trust: the problem of identifying, gathering, and assembling the certificates that are relevant to each trust decision. SAFE uses a simple linking abstraction to organize and share certificates according to scripted primitives that implement the application's trust kernel and isolate it from logic concerns. We show that trust scripting with logical data exchange yields compact trust cores for example applications: federated naming, nested groups and roles, secure IP prefix delegation and routing, attestation-based access control, and a federated infrastructure-as-a-service system. Linking allows granular control over dynamic logic content based on dependency relationships, enabling a logic server to make secure inferences at high throughput. version:1
arxiv-1701-06167 | Binary Matrix Guessing Problem | http://arxiv.org/abs/1701.06167 | id:1701.06167 author:ÃaÄrÄ± LatifoÄlu category:cs.AI 68T05  published:2017-01-22 summary:We introduce the Binary Matrix Guessing Problem and provide two algorithms to solve this problem. The first algorithm we introduce is Elementwise Probing Algorithm (EPA) which is very fast under a score which utilizes Frobenius Distance. The second algorithm is Additive Reinforcement Learning Algorithm which combines ideas from perceptron algorithm and reinforcement learning algorithm. This algorithm is significantly slower compared to first one, but less restrictive and generalizes better. We compare computational performance of both algorithms and provide numerical results. version:1
arxiv-1701-06071 | Improving grasp performance using in-hand proximity and contact sensing | http://arxiv.org/abs/1701.06071 | id:1701.06071 author:Radhen Patel, Rebecca Cox, Branden Romero, Nikolaus Correll category:cs.RO  published:2017-01-21 summary:We describe the grasping and manipulation strategy that we employed at the autonomous track of the Robotic Grasping and Manipulation Competition at IROS 2016. A salient feature of our architecture is the tight coupling between visual (Asus Xtion) and tactile perception (Robotic Materials), to reduce the uncertainty in sensing and actuation. We demonstrate the importance of tactile sensing and reactive control during the final stages of grasping using a Kinova Robotic arm. The set of tools and algorithms for object grasping presented here have been integrated into the open-source Robot Operating System (ROS). version:1
arxiv-1701-06049 | Interactive Learning from Policy-Dependent Human Feedback | http://arxiv.org/abs/1701.06049 | id:1701.06049 author:James MacGlashan, Mark K Ho, Robert Loftin, Bei Peng, David Roberts, Matthew E. Taylor, Michael L. Littman category:cs.AI I.2.6  published:2017-01-21 summary:For agents and robots to become more useful, they must be able to quickly learn from non-technical users. This paper investigates the problem of interactively learning behaviors communicated by a human teacher using positive and negative feedback. Much previous work on this problem has made the assumption that people provide feedback for decisions that is dependent on the behavior they are teaching and is independent from the learner's current policy. We present empirical results that show this assumption to be false---whether human trainers give a positive or negative feedback for a decision is influenced by the learner's current policy. We argue that policy-dependent feedback, in addition to being commonplace, enables useful training strategies from which agents should benefit. Based on this insight, we introduce Convergent Actor-Critic by Humans (COACH), an algorithm for learning from policy-dependent feedback that converges to a local optimum. Finally, we demonstrate that COACH can successfully learn multiple behaviors on a physical robot, even with noisy image features. version:1
arxiv-1701-05996 | ARM Wrestling with Big Data: A Study of ARM64 and x64 Servers for Data Intensive Workloads | http://arxiv.org/abs/1701.05996 | id:1701.05996 author:Jayanth Kalyanasundaram, Yogesh Simmhan category:cs.DC  published:2017-01-21 summary:ARM processors have dominated the mobile device market in the last decade due to their favorable computing to energy ratio. In this age of Cloud data centers and Big Data analytics, the focus is increasingly on power efficient processing, rather than just high throughput computing. ARM's first commodity server-grade processor is the recent AMD A1100-series processor, based on a 64-bit ARM Cortex A57 architecture. In this paper, we study the performance and energy efficiency of a server based on this ARM64 CPU, relative to a comparable server running an AMD Opteron 3300-series x64 CPU, for Big Data workloads. Specifically, we study these for Intel's HiBench suite of web, query and machine learning benchmarks on Apache Hadoop v2.7 in a pseudo-distributed setup, for data sizes up to $20GB$ files, $5M$ web pages and $500M$ tuples. Our results show that the ARM64 server's runtime performance is comparable to the x64 server for integer-based workloads like Sort and Hive queries, and only lags behind for floating-point intensive benchmarks like PageRank, when they do not exploit data parallelism adequately. We also see that the ARM64 server takes 1/3rd the energy, and has an Energy Delay Product (EDP) that is $50-71\%$ lower than the x64 server. These results hold significant promise for data centers hosting ARM64 servers to reduce their operational costs, while offering a competitive performance for Big Data workloads. version:1
arxiv-1701-05986 | Distributed Random-Fixed Projected Algorithm for Constrained Optimization Over Digraphs | http://arxiv.org/abs/1701.05986 | id:1701.05986 author:Pei Xie, Keyou You, Shiji Song, Cheng Wu category:cs.DC math.OC  published:2017-01-21 summary:This paper is concerned with a constrained optimization problem over a directed graph (digraph) of nodes, in which the cost function is a sum of local objectives, and each node only knows its local objective and constraints. To collaboratively solve the optimization, most of the existing works require the interaction graph to be balanced or "doubly-stochastic", which is quite restrictive and not necessary as shown in this paper. We focus on an epigraph form of the original optimization to resolve the "unbalanced" problem, and design a novel two-step recursive algorithm with a simple structure. Under strongly connected digraphs, we prove that each node asymptotically converges to some common optimal solution. Finally, simulations are performed to illustrate the effectiveness of the proposed algorithms. version:1
arxiv-1701-05982 | Observations on Factors Affecting Performance of MapReduce based Apriori on Hadoop Cluster | http://arxiv.org/abs/1701.05982 | id:1701.05982 author:Sudhakar Singh, Rakhi Garg, P. K. Mishra category:cs.DB cs.DC cs.DS  published:2017-01-21 summary:Designing fast and scalable algorithm for mining frequent itemsets is always being a most eminent and promising problem of data mining. Apriori is one of the most broadly used and popular algorithm of frequent itemset mining. Designing efficient algorithms on MapReduce framework to process and analyze big datasets is contemporary research nowadays. In this paper, we have focused on the performance of MapReduce based Apriori on homogeneous as well as on heterogeneous Hadoop cluster. We have investigated a number of factors that significantly affects the execution time of MapReduce based Apriori running on homogeneous and heterogeneous Hadoop Cluster. Factors are specific to both algorithmic and non-algorithmic improvements. Considered factors specific to algorithmic improvements are filtered transactions and data structures. Experimental results show that how an appropriate data structure and filtered transactions technique drastically reduce the execution time. The non-algorithmic factors include speculative execution, nodes with poor performance, data locality & distribution of data blocks, and parallelism control with input split size. We have applied strategies against these factors and fine tuned the relevant parameters in our particular application. Experimental results show that if cluster specific parameters are taken care of then there is a significant reduction in execution time. Also we have discussed the issues regarding MapReduce implementation of Apriori which may significantly influence the performance. version:1
arxiv-1701-05945 | Exploiting the Cloud Control Plane for Fun and Profit | http://arxiv.org/abs/1701.05945 | id:1701.05945 author:Josef Spillner category:cs.DC C.2.4; H.3.5; D.1.1  published:2017-01-20 summary:Cloud providers typically charge for their services. There are diverse pricing models which often follow a pay-per-use paradigm. The consumers' payments are expected to cover all cost which incurs to the provider for processing, storage, bandwidth, data centre operation and engineering efforts, among others. In contrast, the consumer management interfaces are free of charge as they are expected to cause only a minority of the load compared to the actual computing services. With new service models and more complex and powerful management abilities, it is time to rethink this decision. The paper shows how to exploit the control plane of AWS Lambda to implement stateful services practically for free and under some circumstances even guaranteed for free which if widely deployed would cause a monetary loss for the provider. It also elaborates on the consistency model for AWS Lambda. version:1
arxiv-1701-05929 | A Planning and Control Framework for Humanoid Systems: Robust, Optimal, and Real-time Performance | http://arxiv.org/abs/1701.05929 | id:1701.05929 author:Ye Zhao category:cs.RO math.OC  published:2017-01-20 summary:Humanoid robots are increasingly demanded to operate in interactive and human-surrounded environments while achieving sophisticated locomotion and manipulation tasks. To accomplish these tasks, roboticists unremittingly seek for advanced methods that generate whole-body coordination behaviors and meanwhile fulfill various planning and control objectives. Undoubtedly, these goals pose fundamental challenges to the robotics and control community. To take an incremental step towards reducing the performance gap between theoretical foundations and real implementations, we present a planning and control framework for the humanoid, especially legged robots, for achieving high performance and generating agile motions. A particular concentration is on the robust, optimal and real-time performance. This framework constitutes three hierarchical layers: First, we present a robust optimal phase-space planning framework for dynamic legged locomotion over rough terrain. This framework is a hybrid motion planner incorporating a series of pivotal components. Second, we take a step toward formally synthesizing high-level reactive planners for whole-body locomotion in constrained environments. We formulate a two-player temporal logic game between the contact planner and its possibly-adversarial environment. Third, we propose a distributed control architecture for the latency-prone humanoid robotic systems. A central experimental phenomenon is observed that the stability of high impedance distributed controllers is highly sensitive to damping feedback delay but much less to stiffness feedback delay. We pursue a detailed analysis of the distributed controllers where damping feedback effort is executed in proximity to the control plant, and stiffness feedback effort is implemented in a latency-prone centralized control process. version:1
arxiv-1609-04214 | "Flow Size Difference" Can Make a Difference: Detecting Malicious TCP Network Flows Based on Benford's Law | http://arxiv.org/abs/1609.04214 | id:1609.04214 author:Aamo Iorliam, Santosh Tirunagari, Anthony T. S. Ho, Shujun Li, Adrian Waller, Norman Poh category:cs.CR cs.AI cs.NI C.2; K.6.5  published:2016-09-14 summary:Statistical characteristics of network traffic have attracted a significant amount of research for automated network intrusion detection, some of which looked at applications of natural statistical laws such as Zipf's law, Benford's law and the Pareto distribution. In this paper, we present the application of Benford's law to a new network flow metric "flow size difference", which have not been studied before by other researchers, to build an unsupervised flow-based intrusion detection system (IDS). The method was inspired by our observation on a large number of TCP flow datasets where normal flows tend to follow Benford's law closely but malicious flows tend to deviate significantly from it. The proposed IDS is unsupervised, so it can be easily deployed without any training. It has two simple operational parameters with a clear semantic meaning, allowing the IDS operator to set and adapt their values intuitively to adjust the overall performance of the IDS. We tested the proposed IDS on two (one closed and one public) datasets, and proved its efficiency in terms of AUC (area under the ROC curve). Our work showed the "flow size difference" has a great potential to improve the performance of any flow-based network IDSs. version:2
arxiv-1701-00384 | A Resource Management Protocol for Mobile Cloud Using Auto-Scaling | http://arxiv.org/abs/1701.00384 | id:1701.00384 author:Chathura Sarathchand, Kun Yang, Ritosa Patrik, Michael Georgiades, Kezhi Wang category:cs.DC  published:2017-01-02 summary:Cloud radio access networks (C-RAN) and Mobile Cloud Computing (MCC) have emerged as promising candidates for the next generation access network techniques. MCC enables resource limited mobile devices to offload computationally intensive tasks to the cloud, while C-RAN offers a technology that addresses the increasing mobile traffic. In this paper, we propose a protocol for task offloading and for managing resources in both C-RAN and mobile cloud together using a centralised controller. Experiments on resource management using cloud auto-scaling shows that resource (CPU, RAM, Storage) scaling times vary. version:3
arxiv-1701-05724 | Logical Inferences with Contexts of RDF Triples | http://arxiv.org/abs/1701.05724 | id:1701.05724 author:Vinh Nguyen, Amit Sheth category:cs.AI cs.DB  published:2017-01-20 summary:Logical inference, an integral feature of the Semantic Web, is the process of deriving new triples by applying entailment rules on knowledge bases. The entailment rules are determined by the model-theoretic semantics. Incorporating context of an RDF triple (e.g., provenance, time, and location) into the inferencing process requires the formal semantics to be capable of describing the context of RDF triples also in the form of triples, or in other words, RDF contextual triples about triples. The formal semantics should also provide the rules that could entail new contextual triples about triples. In this paper, we propose the first inferencing mechanism that allows context of RDF triples, represented in the form of RDF triples about triples, to be the first-class citizens in the model-theoretic semantics and in the logical rules. Our inference mechanism is well-formalized with all new concepts being captured in the model-theoretic semantics. This formal semantics also allows us to derive a new set of entailment rules that could entail new contextual triples about triples. To demonstrate the feasibility and the scalability of the proposed mechanism, we implement a new tool in which we transform the existing knowledge bases to our representation of RDF triples about triples and provide the option for this tool to compute the inferred triples for the proposed rules. We evaluate the computation of the proposed rules on a large scale using various real-world knowledge bases such as Bio2RDF NCBI Genes and DBpedia. The results show that the computation of the inferred triples can be highly scalable. On average, one billion inferred triples adds 5-6 minutes to the overall transformation process. NCBI Genes, with 20 billion triples in total, took only 232 minutes for the transformation of 12 billion triples and added 42 minutes for inferring 8 billion triples to the overall process. version:1
arxiv-1612-06915 | AIVAT: A New Variance Reduction Technique for Agent Evaluation in Imperfect Information Games | http://arxiv.org/abs/1612.06915 | id:1612.06915 author:Neil Burch, Martin Schmid, Matej MoravÄÃ­k, Michael Bowling category:cs.AI  published:2016-12-20 summary:Evaluating agent performance when outcomes are stochastic and agents use randomized strategies can be challenging when there is limited data available. The variance of sampled outcomes may make the simple approach of Monte Carlo sampling inadequate. This is the case for agents playing heads-up no-limit Texas hold'em poker, where man-machine competitions have involved multiple days of consistent play and still not resulted in statistically significant conclusions even when the winner's margin is substantial. In this paper, we introduce AIVAT, a low variance, provably unbiased value assessment tool that uses an arbitrary heuristic estimate of state value, as well as the explicit strategy of a subset of the agents. Unlike existing techniques which reduce the variance from chance events, or only consider game ending actions, AIVAT reduces the variance both from choices by nature and by players with a known strategy. The resulting estimator in no-limit poker can reduce the number of hands needed to draw statistical conclusions by more than a factor of 10. version:2
arxiv-1612-08048 | Liquid Democracy: An Analysis in Binary Aggregation and Diffusion | http://arxiv.org/abs/1612.08048 | id:1612.08048 author:ZoÃ© Christoff, Davide Grossi category:cs.MA cs.AI cs.SI  published:2016-12-23 summary:The paper proposes an analysis of liquid democracy (or, delegable proxy voting) from the perspective of binary aggregation and of binary diffusion models. We show how liquid democracy on binary issues can be embedded into the framework of binary aggregation with abstentions, enabling the transfer of known results about the latter---such as impossibility theorems---to the former. This embedding also sheds light on the relation between delegation cycles in liquid democracy and the probability of collective abstentions, as well as the issue of individual rationality in a delegable proxy voting setting. We then show how liquid democracy on binary issues can be modeled and analyzed also as a specific process of dynamics of binary opinions on networks. These processes---called Boolean DeGroot processes---are a special case of the DeGroot stochastic model of opinion diffusion. We establish the convergence conditions of such processes and show they provide some novel insights on how the effects of delegation cycles and individual rationality could be mitigated within liquid democracy. The study is a first attempt to provide theoretical foundations to the delgable proxy features of the liquid democracy voting system. Our analysis suggests recommendations on how the system may be modified to make it more resilient with respect to the handling of delegation cycles and of inconsistent majorities. version:2
arxiv-1701-05451 | Feasibility of Fog Computing | http://arxiv.org/abs/1701.05451 | id:1701.05451 author:Blesson Varghese, Nan Wang, Dimitrios S. Nikolopoulos, Rajkumar Buyya category:cs.DC  published:2017-01-19 summary:As billions of devices get connected to the Internet, it will not be sustainable to use the cloud as a centralised server. The way forward is to decentralise computations away from the cloud towards the edge of the network closer to the user. This reduces the latency of communication between a user device and the cloud, and is the premise of 'fog computing' defined in this paper. The aim of this paper is to highlight the feasibility and the benefits in improving the Quality-of-Service and Experience by using fog computing. For an online game use-case, we found that the average response time for a user is improved by 20% when using the edge of the network in comparison to using a cloud-only model. It was also observed that the volume of traffic between the edge and the cloud server is reduced by over 90% for the use-case. The preliminary results highlight the potential of fog computing in achieving a sustainable computing model and highlights the benefits of integrating the edge of the network into the computing ecosystem. version:1
arxiv-1701-05431 | A task-driven implementation of a simple numerical solver for hyperbolic conservation laws | http://arxiv.org/abs/1701.05431 | id:1701.05431 author:Mohamed Essadki, Jonathan Jung, Adam Larat, Milan Pelletier, Vincent Perrier category:cs.DC cs.MS math.NA  published:2017-01-19 summary:This article describes the implementation of an all-in-one numerical procedure within the runtime StarPU. In order to limit the complexity of the method, for the sake of clarity of the presentation of the non-classical task-driven programming environnement, we have limited the numerics to first order in space and time. Results show that the task distribution is efficient if the tasks are numerous and individually large enough so that the task heap can be saturated by tasks which computational time covers the task management overhead. Next, we also see that even though they are mostly faster on graphic cards, not all the tasks are suitable for GPUs, which brings forward the importance of the task scheduler. Finally, we look at a more realistic system of conservation laws with an expensive source term, what allows us to conclude and open on future works involving higher local arithmetic intensity, by increasing the order of the numerical method or by enriching the model (increased number of parameters and therefore equations). version:1
arxiv-1701-05291 | Heterogeneous Information Network Embedding for Meta Path based Proximity | http://arxiv.org/abs/1701.05291 | id:1701.05291 author:Zhipeng Huang, Nikos Mamoulis category:cs.AI  published:2017-01-19 summary:A network embedding is a representation of a large graph in a low-dimensional space, where vertices are modeled as vectors. The objective of a good embedding is to preserve the proximity between vertices in the original graph. This way, typical search and mining methods can be applied in the embedded space with the help of off-the-shelf multidimensional indexing approaches. Existing network embedding techniques focus on homogeneous networks, where all vertices are considered to belong to a single class. version:1
arxiv-1702-03253 | D4M 3.0 | http://arxiv.org/abs/1702.03253 | id:1702.03253 author:Lauren Milechin, Alexander Chen, Vijay Gadepally, Dylan Hutchison, Siddharth Samsi, Jeremy Kepner category:cs.DC cs.DB  published:2017-01-19 summary:The D4M tool is used by hundreds of researchers to perform complex analytics on unstructured data. Over the past few years, the D4M toolbox has evolved to support connectivity with a variety of database engines, graph analytics in the Apache Accumulo database, and an implementation using the Julia programming language. In this article, we describe some of our latest additions to the D4M toolbox and our upcoming D4M 3.0 release. version:1
arxiv-1702-03886 | Unit Commitment on the Cloud | http://arxiv.org/abs/1702.03886 | id:1702.03886 author:Mushfiqur R. Sarker, Jianhui Wang category:cs.DC  published:2017-01-18 summary:The advent of High Performance Computing (HPC) has provided the computational capacity required for power system operators (SO) to obtain solutions in the least time to highly-complex applications, i.e., Unit Commitment (UC). The UC problem, which attempts to schedule the least-cost combination of generating units to meet the load, is increasing in complexity and problem size due to deployments of renewable resources and smart grid technologies. The current approach to solving the UC problem consists of in-house HPC infrastructures, which experience issues at scale, and demands high maintenance and capital expenditures. On the other hand, cloud computing is an ideal substitute due to its powerful computational capacity, rapid scalability, and high cost-effectiveness. In this work, the benefits and challenges of outsourcing the UC application to the cloud are explored. A quantitative analysis of the computational performance gain is explored for a large-scale UC problem solved on the cloud and compared to traditional in-house HPC infrastructure. The results show substantial reduction in solve time when outsourced to the cloud. version:1
arxiv-1603-08714 | Properties of ABA+ for Non-Monotonic Reasoning: Errata | http://arxiv.org/abs/1603.08714 | id:1603.08714 author:Kristijonas Cyras category:cs.AI  published:2016-03-29 summary:This technical report provides errata of [K. Cyras, F. Toni, Properties of ABA+ for Non-Monotonic Reasoning, in: 16th International Workshop on Non-Monotonic Reasoning (NMR), Cape Town, South Africa, 2016 pp. 25-34.] Propositions 19, 20, 22, Corollary 23 and (partially) Proposition 24 from Section 6 (Non-Monotonic Reasoning Properties) in that paper are withdrawn as unproven, and thus assumed to be false, while additional results are provided. The rest of the paper in question stands unchanged. version:2
arxiv-1607-04549 | DiaSys: Improving SoC Insight Through On-Chip Diagnosis | http://arxiv.org/abs/1607.04549 | id:1607.04549 author:Philipp Wagner, Thomas Wild, Andreas Herkersdorf category:cs.DC cs.AR cs.SE  published:2016-07-15 summary:To find the cause of a functional or non-functional defect (bug) in software running on a multi-processor System-on-Chip (MPSoC), developers need insight into the chip. Tracing systems provide this insight non-intrusively, at the cost of high off-chip bandwidth requirements. This I/O bottleneck limits the observability, a problem becoming more severe as more functionality is integrated on-chip. In this paper, we present DiaSys, an MPSoC diagnosis system with the potential to replace today's tracing systems. Its main idea is to partially execute the analysis of observation data on the chip; in consequence, more information and less data is sent to the attached host PC. With DiaSys, the data analysis is performed by the diagnosis application. Its input are events, which are generated by observation hardware at interesting points in the program execution (like a function call). Its outputs are events with higher information density. The event transformation is modeled as dataflow application. For execution, it is mapped in part to dedicated and distributed on-chip components, and in part to the host PC; the off-chip boundary is transparent to the developer of the diagnosis application. We implement DiaSys as extension to an existing SoC with four tiles and a mesh network running on an FPGA platform. Two usage examples confirm that DiaSys is flexible enough to replace a tracing system, while significantly lowering the off-chip bandwidth requirements. In our examples, the debugging of a race-condition bug, and the creation of a lock contention profile, we see a reduction of trace bandwidth of more than three orders of magnitude, compared to a full trace created by a common tracing system. version:2
arxiv-1701-05059 | Ontology based system to guide internship assignment process | http://arxiv.org/abs/1701.05059 | id:1701.05059 author:Abir M 'Baya, Jannik Laval, Nejib Moalla, Yacine Ouzrout, Abdelaziz Bouras category:cs.AI  published:2017-01-18 summary:Internship assignment is a complicated process for universities since it is necessary to take into account a multiplicity of variables to establish a compromise between companies' requirements and student competencies acquired during the university training. These variables build up a complex relations map that requires the formulation of an exhaustive and rigorous conceptual scheme. In this research a domain ontological model is presented as support to the student's decision making for opportunities of University studies level of the University Lumiere Lyon 2 (ULL) education system. The ontology is designed and created using methodological approach offering the possibility of improving the progressive creation, capture and knowledge articulation. In this paper, we draw a balance taking the demands of the companies across the capabilities of the students. This will be done through the establishment of an ontological model of an educational learners' profile and the internship postings which are written in a free text and using uncontrolled vocabulary. Furthermore, we outline the process of semantic matching which improves the quality of query results. version:1
arxiv-1604-08080 | Concurrent Data Structures Linked in Time | http://arxiv.org/abs/1604.08080 | id:1604.08080 author:GermÃ¡n AndrÃ©s Delbianco, Ilya Sergey, Aleksandar Nanevski, Anindya Banerjee category:cs.LO cs.DC cs.PL F.3.1; F.1.2; D.2.4  published:2016-04-27 summary:Arguments about correctness of a concurrent data structure are typically carried out by using the notion of linearizability and specifying the linearization points of the data structure's procedures. Such arguments are often cumbersome as the linearization points' position in time can be dynamic (depend on the interference, run-time values and events from the past, or even future), non-local (appear in procedures other than the one considered), and whose position in the execution trace may only be determined after the considered procedure has already terminated. In this paper we propose a new method, based on a separation-style logic, for reasoning about concurrent objects with such linearization points. We embrace the dynamic nature of linearization points, and encode it as part of the data structure's auxiliary state, so that it can be dynamically modified in place by auxiliary code, as needed when some appropriate run-time event occurs. We name the idea linking-in-time, because it reduces temporal reasoning to spatial reasoning. For example, modifying a temporal position of a linearization point can be modeled similarly to a pointer update in separation logic. Furthermore, the auxiliary state provides a convenient way to concisely express the properties essential for reasoning about clients of such concurrent objects. We illustrate the method by verifying (mechanically in Coq) an intricate optimal snapshot algorithm due to Jayanti, as well as some clients. version:4
arxiv-1610-03524 | Improved Parallel Construction of Wavelet Trees and Rank/Select Structures | http://arxiv.org/abs/1610.03524 | id:1610.03524 author:Julian Shun category:cs.DC  published:2016-10-11 summary:Existing parallel algorithms for wavelet tree construction have a work complexity of $O(n\log\sigma)$. This paper presents parallel algorithms for the problem with improved work complexity. Our first algorithm is based on parallel integer sorting and has either $O(n\log\log n\lceil\log\sigma/\sqrt{\log n\log\log n}\rceil)$ work and polylogarithmic depth, or $O(n\lceil\log\sigma/\sqrt{\log n}\rceil)$ work and sub-linear depth. We also describe another algorithm that has $O(n\lceil\log\sigma/\sqrt{\log n} \rceil)$ work and $O(\sigma+\log n)$ depth. We then show how to use similar ideas to construct variants of wavelet trees (arbitrary-shaped binary trees and multiary trees) as well as wavelet matrices in parallel with lower work complexity than prior algorithms. Finally, we show that the rank and select structures on binary sequences and multiary sequences, which are stored on wavelet tree nodes, can be constructed in parallel with improved work bounds, matching those of the best existing sequential algorithms for constructing rank and select structures. version:2
arxiv-1607-08485 | A symbolic algebra for the computation of expected utilities in multiplicative influence diagrams | http://arxiv.org/abs/1607.08485 | id:1607.08485 author:Manuele Leonelli, Eva Riccomagno, Jim Q. Smith category:cs.AI  published:2016-07-28 summary:Influence diagrams provide a compact graphical representation of decision problems. Several algorithms for the quick computation of their associated expected utilities are available in the literature. However, often they rely on a full quantification of both probabilistic uncertainties and utility values. For problems where all random variables and decision spaces are finite and discrete, here we develop a symbolic way to calculate the expected utilities of influence diagrams that does not require a full numerical representation. Within this approach expected utilities correspond to families of polynomials. After characterizing their polynomial structure, we develop an efficient symbolic algorithm for the propagation of expected utilities through the diagram and provide an implementation of this algorithm using a computer algebra system. We then characterize many of the standard manipulations of influence diagrams as transformations of polynomials. We also generalize the decision analytic framework of these diagrams by defining asymmetries as operations over the expected utility polynomials. version:2
arxiv-1701-04907 | OpenCluster: A Flexible Distributed Computing Framework for Astronomical Data Processing | http://arxiv.org/abs/1701.04907 | id:1701.04907 author:Shoulin Wei, Feng Wang, Hui Deng, Cuiyin Liu, Wei Dai, Bo Liang, Ying Mei, Congming Shi, Yingbo Liu, Jingping Wu category:astro-ph.IM cs.DC  published:2017-01-18 summary:The volume of data generated by modern astronomical telescopes is extremely large and rapidly growing. However, current high-performance data processing architectures/frameworks are not well suited for astronomers because of their limitations and programming difficulties. In this paper, we therefore present OpenCluster, an open-source distributed computing framework to support rapidly developing high-performance processing pipelines of astronomical big data. We first detail the OpenCluster design principles and implementations and present the APIs facilitated by the framework. We then demonstrate a case in which OpenCluster is used to resolve complex data processing problems for developing a pipeline for the Mingantu Ultrawide Spectral Radioheliograph. Finally, we present our OpenCluster performance evaluation. Overall, OpenCluster provides not only high fault tolerance and simple programming interfaces, but also a flexible means of scaling up the number of interacting entities. OpenCluster thereby provides an easily integrated distributed computing framework for quickly developing a high-performance data processing system of astronomical telescopes and for significantly reducing software development expenses. version:1
arxiv-1503-08659 | Binary Adder Circuits of Asymptotically Minimum Depth, Linear Size, and Fan-Out Two | http://arxiv.org/abs/1503.08659 | id:1503.08659 author:Stephan Held, Sophie Theresa Spirkl category:cs.AR cs.CC cs.DC B.2.4  published:2015-03-30 summary:We consider the problem of constructing fast and small binary adder circuits. Among widely-used adders, the Kogge-Stone adder is often considered the fastest, because it computes the carry bits for two $n$-bit numbers (where $n$ is a power of two) with a depth of $2\log_2 n$ logic gates, size $4 n\log_2 n$, and all fan-outs bounded by two. Fan-outs of more than two are avoided, because they lead to the insertion of repeaters for repowering the signal and additional depth in the physical implementation. However, the depth bound of the Kogge-Stone adder is off by a factor of two from the lower bound of $\log_2 n$. This bound is achieved asymptotically in two separate constructions by Brent and Krapchenko. Brent's construction gives neither a bound on the fan-out nor the size, while Krapchenko's adder has linear size, but can have up to linear fan-out. With a fan-out bound of two, neither construction achieves a depth of less than $2 \log_2 n$. In a further approach, Brent and Kung proposed an adder with linear size and fan-out two, but twice the depth of the Kogge-Stone adder. These results are 33-43 years old and no substantial theoretical improvement for has been made since then. In this paper we integrate the individual advantages of all previous adder circuits into a new family of full adders, the first to improve on the depth bound of $2\log_2 n$ while maintaining a fan-out bound of two. Our adders achieve an asymptotically optimum logic gate depth of $\log_2 n + o(\log_2 n)$ and linear size $\mathcal {O}(n)$. version:3
arxiv-1610-01728 | RedThreads: An Interface for Application-level Fault Detection/Correction through Adaptive Redundant Multithreading | http://arxiv.org/abs/1610.01728 | id:1610.01728 author:Saurabh Hukerikar, Keita Teranishi, Pedro C. Diniz, Robert F. Lucas category:cs.DC  published:2016-10-06 summary:In the presence of accelerated fault rates, which are projected to be the norm on future exascale systems, it will become increasingly difficult for high-performance computing (HPC) applications to accomplish useful computation. Due to the fault-oblivious nature of current HPC programming paradigms and execution environments, HPC applications are insufficiently equipped to deal with errors. We believe that HPC applications should be enabled with capabilities to actively search for and correct errors in their computations. The redundant multithreading (RMT) approach offers lightweight replicated execution streams of program instructions within the context of a single application process. However, the use of complete redundancy incurs significant overhead to the application performance. In this paper we present RedThreads, an interface that provides application-level fault detection and correction based on RMT, but applies the thread-level redundancy adaptively. We describe the RedThreads syntax and semantics, and the supporting compiler infrastructure and runtime system. Our approach enables application programmers to scope the extent of redundant computation. Additionally, the runtime system permits the use of RMT to be dynamically enabled, or disabled, based on the resiliency needs of the application and the state of the system. Our experimental results demonstrate how adaptive RMT exploits programmer insight and runtime inference to dynamically navigate the trade-off space between an application's resilience coverage and the associated performance overhead of redundant computation. version:2
arxiv-1701-04763 | A Game-Theoretic Approach for Runtime Capacity Allocation in MapReduce | http://arxiv.org/abs/1701.04763 | id:1701.04763 author:Eugenio Gianniti, Danilo Ardagna, Michele Ciavotta, Mauro Passacantando category:cs.DC  published:2017-01-17 summary:Nowadays many companies have available large amounts of raw, unstructured data. Among Big Data enabling technologies, a central place is held by the MapReduce framework and, in particular, by its open source implementation, Apache Hadoop. For cost effectiveness considerations, a common approach entails sharing server clusters among multiple users. The underlying infrastructure should provide every user with a fair share of computational resources, ensuring that Service Level Agreements (SLAs) are met and avoiding wastes. In this paper we consider two mathematical programming problems that model the optimal allocation of computational resources in a Hadoop 2.x cluster with the aim to develop new capacity allocation techniques that guarantee better performance in shared data centers. Our goal is to get a substantial reduction of power consumption while respecting the deadlines stated in the SLAs and avoiding penalties associated with job rejections. The core of this approach is a distributed algorithm for runtime capacity allocation, based on Game Theory models and techniques, that mimics the MapReduce dynamics by means of interacting players, namely the central Resource Manager and Class Managers. version:1
arxiv-1701-04733 | BTAS: A Library for Tropical Algebra | http://arxiv.org/abs/1701.04733 | id:1701.04733 author:Ahsan Humayun, Dr. Muhammad Asif, Dr. Muhammmad Kashif Hanif category:cs.DC  published:2017-01-17 summary:GPUs are dedicated processors used for complex calculations and simulations and they can be effectively used for tropical algebra computations. Tropical algebra is based on max-plus algebra and min-plus algebra. In this paper we proposed and designed a library based on Tropical Algebra which is used to provide standard vector and matrix operations namely Basic Tropical Algebra Subroutines (BTAS). The testing of BTAS library is conducted by implementing the sequential version of Floyd Warshall Algorithm on CPU and furthermore parallel version on GPU. The developed library for tropical algebra delivered extensively better results on a less expensive GPU as compared to the same on CPU. version:1
arxiv-1701-04663 | Intrinsically Motivated Acquisition of Modular Slow Features for Humanoids in Continuous and Non-Stationary Environments | http://arxiv.org/abs/1701.04663 | id:1701.04663 author:Varun Raj Kompella, Laurenz Wiskott category:cs.AI  published:2017-01-17 summary:A compact information-rich representation of the environment, also called a feature abstraction, can simplify a robot's task of mapping its raw sensory inputs to useful action sequences. However, in environments that are non-stationary and only partially observable, a single abstraction is probably not sufficient to encode most variations. Therefore, learning multiple sets of spatially or temporally local, modular abstractions of the inputs would be beneficial. How can a robot learn these local abstractions without a teacher? More specifically, how can it decide from where and when to start learning a new abstraction? A recently proposed algorithm called Curious Dr. MISFA addresses this problem. The algorithm is based on two underlying learning principles called artificial curiosity and slowness. The former is used to make the robot self-motivated to explore by rewarding itself whenever it makes progress learning an abstraction; the later is used to update the abstraction by extracting slowly varying components from raw sensory inputs. Curious Dr. MISFA's application is, however, limited to discrete domains constrained by a pre-defined state space and has design limitations that make it unstable in certain situations. This paper presents a significant improvement that is applicable to continuous environments, is computationally less expensive, simpler to use with fewer hyper parameters, and stable in certain non-stationary environments. We demonstrate the efficacy and stability of our method in a vision-based robot simulator. version:1
arxiv-1608-00214 | Near-Optimal Self-Stabilising Counting and Firing Squads | http://arxiv.org/abs/1608.00214 | id:1608.00214 author:Christoph Lenzen, Joel Rybicki category:cs.DC  published:2016-07-31 summary:Consider a fully-connected synchronous distributed system consisting of $n$ nodes, where up to $f$ nodes may be faulty and every node starts in an arbitrary initial state. In the synchronous $C$-counting problem, all nodes need to eventually agree on a counter that is increased by one modulo $C$ in each round for given $C>1$. In the self-stabilising firing squad problem, the task is to eventually guarantee that all non-faulty nodes have simultaneous responses to external inputs: if a subset of the correct nodes receive an external "go" signal as input, then all correct nodes should agree on a round (in the not-too-distant future) in which to jointly output a "fire" signal. Moreover, no node should generate a "fire" signal without some correct node having previously received a "go" signal as input. We present a framework reducing both tasks to binary consensus at very small cost. For example, we obtain a deterministic algorithm for self-stabilising Byzantine firing squads with optimal resilience $f<n/3$, asymptotically optimal stabilisation and response time $O(f)$, and message size $O(\log f)$. As our framework does not restrict the type of consensus routines used, we also obtain efficient randomised solutions, and it is straightforward to adapt our framework for other types of permanent faults. version:2
arxiv-1701-05080 | Individual versus collective cognition in social insects | http://arxiv.org/abs/1701.05080 | id:1701.05080 author:Ofer Feinerman, Amos KormanÃ« category:q-bio.NC cs.DC  published:2017-01-17 summary:The concerted responses of eusocial insects to environmental stimuli are often referred to as collective cognition on the level of the colony.To achieve collective cognitiona group can draw on two different sources: individual cognitionand the connectivity between individuals.Computation in neural-networks, for example,is attributedmore tosophisticated communication schemes than to the complexity of individual neurons. The case of social insects, however, can be expected to differ. This is since individual insects are cognitively capable units that are often able to process information that is directly relevant at the level of the colony.Furthermore, involved communication patterns seem difficult to implement in a group of insects since these lack clear network structure.This review discusses links between the cognition of an individual insect and that of the colony. We provide examples for collective cognition whose sources span the full spectrum between amplification of individual insect cognition and emergent group-level processes. version:1
arxiv-1701-04645 | Une mesure d'expertise pour le crowdsourcing | http://arxiv.org/abs/1701.04645 | id:1701.04645 author:Hosna Ouni, Arnaud Martin, Laetitia Gros, Mouloud Kharoune, Zoltan Miklos category:cs.AI cs.HC  published:2017-01-17 summary:Crowdsourcing, a major economic issue, is the fact that the firm outsources internal task to the crowd. It is a form of digital subcontracting for the general public. The evaluation of the participants work quality is a major issue in crowdsourcing. Indeed, contributions must be controlled to ensure the effectiveness and relevance of the campaign. We are particularly interested in small, fast and not automatable tasks. Several methods have been proposed to solve this problem, but they are applicable when the "golden truth" is not always known. This work has the particularity to propose a method for calculating the degree of expertise in the presence of gold data in crowdsourcing. This method is based on the belief function theory and proposes a structuring of data using graphs. The proposed approach will be assessed and applied to the data. version:1
arxiv-1701-04612 | Secure Content-Based Routing Using Intel Software Guard Extensions | http://arxiv.org/abs/1701.04612 | id:1701.04612 author:Rafael Pires, Marcelo Pasin, Pascal Felber, Christof Fetzer category:cs.DC  published:2017-01-17 summary:Content-based routing (CBR) is a powerful model that supports scalable asynchronous communication among large sets of geographically distributed nodes. Yet, preserving privacy represents a major limitation for the wide adoption of CBR, notably when the routers are located in public clouds. Indeed, a CBR router must see the content of the messages sent by data producers, as well as the filters (or subscriptions) registered by data consumers. This represents a major deterrent for companies for which data is a key asset, as for instance in the case of financial markets or to conduct sensitive business-to-business transactions. While there exists some techniques for privacy-preserving computation, they are either prohibitively slow or too limited to be usable in real systems. In this paper, we follow a different strategy by taking advantage of trusted hardware extensions that have just been introduced in off-the-shelf processors and provide a trusted execution environment. We exploit Intel's new software guard extensions (SGX) to implement a CBR engine in a secure enclave. Thanks to the hardware-based trusted execution environment (TEE), the compute-intensive CBR operations can operate on decrypted data shielded by the enclave and leverage efficient matching algorithms. Extensive experimental evaluation shows that SGX adds only limited overhead to insecure plaintext matching outside secure enclaves while providing much better performance and more powerful filtering capabilities than alternative software-only solutions. To the best of our knowledge, this work is the first to demonstrate the practical benefits of SGX for privacy-preserving CBR. version:1
arxiv-1701-04569 | Multiobjective Optimization of Solar Powered Irrigation System with Fuzzy Type-2 Noise Modelling | http://arxiv.org/abs/1701.04569 | id:1701.04569 author:T. Ganesan, P. Vasant, I. Elamvazuthi category:cs.AI  published:2017-01-17 summary:Optimization is becoming a crucial element in industrial applications involving sustainable alternative energy systems. During the design of such systems, the engineer/decision maker would often encounter noise factors (e.g. solar insolation and ambient temperature fluctuations) when their system interacts with the environment. In this chapter, the sizing and design optimization of the solar powered irrigation system was considered. This problem is multivariate, noisy, nonlinear and multiobjective. This design problem was tackled by first using the Fuzzy Type II approach to model the noise factors. Consequently, the Bacterial Foraging Algorithm (BFA) (in the context of a weighted sum framework) was employed to solve this multiobjective fuzzy design problem. This method was then used to construct the approximate Pareto frontier as well as to identify the best solution option in a fuzzy setting. Comprehensive analyses and discussions were performed on the generated numerical results with respect to the implemented solution methods. version:1
arxiv-1701-04528 | From Community Detection to Community Profiling | http://arxiv.org/abs/1701.04528 | id:1701.04528 author:Hongyun Cai, Vincent W. Zheng, Fanwei Zhu, Kevin Chen-Chuan Chang, Zi Huang category:cs.SI cs.AI  published:2017-01-17 summary:Most existing community-related studies focus on detection, which aim to find the community membership for each user from user friendship links. However, membership alone, without a complete profile of what a community is and how it interacts with other communities, has limited applications. This motivates us to consider systematically profiling the communities and thereby developing useful community-level applications. In this paper, we for the first time formalize the concept of community profiling. With rich user information on the network, such as user published content and user diffusion links, we characterize a community in terms of both its internal content profile and external diffusion profile. The difficulty of community profiling is often underestimated. We novelly identify three unique challenges and propose a joint Community Profiling and Detection (CPD) model to address them accordingly. We also contribute a scalable inference algorithm, which scales linearly with the data size and it is easily parallelizable. We evaluate CPD on large-scale real-world data sets, and show that it is significantly better than the state-of-the-art baselines in various tasks. version:1
arxiv-1701-04350 | An Object-oriented approach to Robotic planning using Taxi domain | http://arxiv.org/abs/1701.04350 | id:1701.04350 author:Aasheesh Singh category:cs.RO  published:2017-01-16 summary:This paper aims to implement Object-Oriented Markov Decision Process (OO-MDPs) for goal planning and navigation of robot in an indoor environment. We use the OO-MDP representation of the environment which is a natural way of modeling the environment based on objects and their interactions. The paper aims to extend the well known Taxi domain example which has been tested on grid world environment to robotics domain with larger state-spaces. For the purpose of this project we have created simulation of the environment and robot in ROS with Gazebo and Rviz as visualization tools.The mobile robot uses a 2D LIDAR module to perform SLAM in the unknown environment. The goal of this project is to be able to make an autonomous agent capable of performing planning and navigation in an indoor environment to deliver boxes (passengers in Taxi domain) placed at random locations to a particular location (warehouse). The approach can be extended to a wide variety of mobile and manipulative robots version:1
arxiv-1503-03880 | Modeling and Energy Optimization of LDPC Decoder Circuits with Timing Violations | http://arxiv.org/abs/1503.03880 | id:1503.03880 author:FranÃ§ois Leduc-Primeau, Frank R. Kschischang, Warren J. Gross category:cs.IT cs.AR math.IT  published:2015-03-12 summary:This paper proposes a "quasi-synchronous" design approach for signal processing circuits, in which timing violations are permitted, but without the need for a hardware compensation mechanism. The case of a low-density parity-check (LDPC) decoder is studied, and a method for accurately modeling the effect of timing violations at a high level of abstraction is presented. The error-correction performance of code ensembles is then evaluated using density evolution while taking into account the effect of timing faults. Following this, several quasi-synchronous LDPC decoder circuits based on the offset min-sum algorithm are optimized, providing a 23%-40% reduction in energy consumption or energy-delay product, while achieving the same performance and occupying the same area as conventional synchronous circuits. version:4
arxiv-1611-00463 | A Load-Balanced Parallel and Distributed Sorting Algorithm Implemented with PGX.D | http://arxiv.org/abs/1611.00463 | id:1611.00463 author:Zahra Khatami, Sungpack Hong, Jinsoo Lee, Siegfried Depner, Hassan Chafi, J. Ramanujam, Hartmut Kaiser category:cs.DC  published:2016-11-02 summary:Sorting has been one of the most challenging studied problems in different scientific researches. Although many techniques and algorithms have been proposed on the theory of having efficient parallel sorting implementation, however achieving desired performance on different types of the architectures with large number of processors is still a challenging issue. Maximizing parallelism level in applications can be achieved by minimizing overheads due to load imbalance and waiting time due to memory latencies. In this paper, we present a distributed sorting algorithm implemented in PGX.D, a fast distributed graph processing system, which outperforms the Spark's distributed sorting implementation by around 2x-3x by hiding communication latencies and minimizing unnecessary overheads. Furthermore, it shows that the proposed PGX.D sorting method handles dataset containing many duplicated data entries efficiently and always results in keeping balanced workloads for different input data distribution types. version:2
arxiv-1701-03937 | Hedera: Scalable Indexing and Exploring Entities in Wikipedia Revision History | http://arxiv.org/abs/1701.03937 | id:1701.03937 author:Tuan Tran, Tu Ngoc Nguyen category:cs.AI cs.IR H.3.2  published:2017-01-14 summary:Much of work in semantic web relying on Wikipedia as the main source of knowledge often work on static snapshots of the dataset. The full history of Wikipedia revisions, while contains much more useful information, is still difficult to access due to its exceptional volume. To enable further research on this collection, we developed a tool, named Hedera, that efficiently extracts semantic information from Wikipedia revision history datasets. Hedera exploits Map-Reduce paradigm to achieve rapid extraction, it is able to handle one entire Wikipedia articles revision history within a day in a medium-scale cluster, and supports flexible data structures for various kinds of semantic web study. version:1
arxiv-1701-03922 | Computing Resource Allocation in Three-Tier IoT Fog Networks: a Joint Optimization Approach Combining Stackelberg Game and Matching | http://arxiv.org/abs/1701.03922 | id:1701.03922 author:Huaqing Zhang, Yong Xiao, Shengrong Bu, Dusit Niyato, Richard Yu, Zhu Han category:cs.GT cs.DC  published:2017-01-14 summary:Fog computing is a promising architecture to provide economic and low latency data services for future Internet of things (IoT)-based network systems. It relies on a set of low-power fog nodes that are close to the end users to offload the services originally targeting at cloud data centers. In this paper, we consider a specific fog computing network consisting of a set of data service operators (DSOs) each of which controls a set of fog nodes to provide the required data service to a set of data service subscribers (DSSs). How to allocate the limited computing resources of fog nodes (FNs) to all the DSSs to achieve an optimal and stable performance is an important problem. In this paper, we propose a joint optimization framework for all FNs, DSOs and DSSs to achieve the optimal resource allocation schemes in a distributed fashion. In the framework, we first formulate a Stackelberg game to analyze the pricing problem for the DSOs as well as the resource allocation problem for the DSSs. Under the scenarios that the DSOs can know the expected amount of resource purchased by the DSSs, a many-to-many matching game is applied to investigate the pairing problem between DSOs and FNs. Finally, within the same DSO, we apply another layer of many-to-many matching between each of the paired FNs and serving DSSs to solve the FN-DSS pairing problem. Simulation results show that our proposed framework can significantly improve the performance of the IoT-based network systems. version:1
arxiv-1701-03893 | Analysis of Distributed ADMM Algorithm for Consensus Optimization in Presence of Error | http://arxiv.org/abs/1701.03893 | id:1701.03893 author:Layla Majzoobi, Farshad Lahouti category:cs.DC math.OC  published:2017-01-14 summary:ADMM is a popular algorithm for solving convex optimization problems. Applying this algorithm to distributed consensus optimization problem results in a fully distributed iterative solution which relies on processing at the nodes and communication between neighbors. Local computations usually suffer from different types of errors, due to e.g., observation or quantization noise, which can degrade the performance of the algorithm. In this work, we focus on analyzing the convergence behavior of distributed ADMM for consensus optimization in presence of additive node error. We specifically show that (a noisy) ADMM converges linearly under certain conditions and also examine the associated convergence point. Numerical results are provided which demonstrate the effectiveness of the presented analysis. version:1
arxiv-1701-03878 | HoLiSwap: Reducing Wire Energy in L1 Caches | http://arxiv.org/abs/1701.03878 | id:1701.03878 author:Yatish Turakhia, Subhasis Das, Tor M. Aamodt, William J. Dally category:cs.AR  published:2017-01-14 summary:This paper describes HoLiSwap a method to reduce L1 cache wire energy, a significant fraction of total cache energy, by swapping hot lines to the cache way nearest to the processor. We observe that (i) a small fraction (<3%) of cache lines (hot lines) serve over 60% of the L1 cache accesses and (ii) the difference in wire energy between the nearest and farthest cache subarray can be over 6$\times$. Our method exploits this difference in wire energy to dynamically identify hot lines and swap them to the nearest physical way in a set-associative L1 cache. This provides up to 44% improvement in the wire energy (1.82% saving in overall system energy) with no impact on the cache miss rate and 0.13% performance drop. We also show that HoLiSwap can simplify way-prediction. version:1
arxiv-1701-03868 | Minimally Naturalistic Artificial Intelligence | http://arxiv.org/abs/1701.03868 | id:1701.03868 author:Steven Stenberg Hansen category:cs.AI  published:2017-01-14 summary:The rapid advancement of machine learning techniques has re-energized research into general artificial intelligence. While the idea of domain-agnostic meta-learning is appealing, this emerging field must come to terms with its relationship to human cognition and the statistics and structure of the tasks humans perform. The position of this article is that only by aligning our agents' abilities and environments with those of humans do we stand a chance at developing general artificial intelligence (GAI). A broad reading of the famous 'No Free Lunch' theorem is that there is no universally optimal inductive bias or, equivalently, bias-free learning is impossible. This follows from the fact that there are an infinite number of ways to extrapolate data, any of which might be the one used by the data generating environment; an inductive bias prefers some of these extrapolations to others, which lowers performance in environments using these adversarial extrapolations. We may posit that the optimal GAI is the one that maximally exploits the statistics of its environment to create its inductive bias; accepting the fact that this agent is guaranteed to be extremely sub-optimal for some alternative environments. This trade-off appears benign when thinking about the environment as being the physical universe, as performance on any fictive universe is obviously irrelevant. But, we should expect a sharper inductive bias if we further constrain our environment. Indeed, we implicitly do so by defining GAI in terms of accomplishing that humans consider useful. One common version of this is need the for 'common-sense reasoning', which implicitly appeals to the statistics of physical universe as perceived by humans. version:1
arxiv-1701-05478 | Decoupled Access-Execute on ARM big.LITTLE | http://arxiv.org/abs/1701.05478 | id:1701.05478 author:Anton Weber, Kim-Anh Tran, Stefanos Kaxiras, Alexandra Jimborean category:cs.DC  published:2017-01-13 summary:Energy-efficiency plays a significant role given the battery lifetime constraints in embedded systems and hand-held devices. In this work we target the ARM big.LITTLE, a heterogeneous platform that is dominant in the mobile and embedded market, which allows code to run transparently on different microarchitectures with individual energy and performance characteristics. It allows to se more energy efficient cores to conserve power during simple tasks and idle times and switch over to faster, more power hungry cores when performance is needed. This proposal explores the power-savings and the performance gains that can be achieved by utilizing the ARM big.LITTLE core in combination with Decoupled Access-Execute (DAE). DAE is a compiler technique that splits code regions into two distinct phases: a memory-bound Access phase and a compute-bound Execute phase. By scheduling the memory-bound phase on the LITTLE core, and the compute-bound phase on the big core, we conserve energy while caching data from main memory and perform computations at maximum performance. Our preliminary findings show that applying DAE on ARM big.LITTLE has potential. By prefetching data in Access we can achieve an IPC improvement of up to 37% in the Execute phase, and manage to shift more than half of the program runtime to the LITTLE core. We also provide insight into advantages and disadvantages of our approach, present preliminary results and discuss potential solutions to overcome locking overhead. version:1
arxiv-1701-03839 | Exploring Model Predictive Control to Generate Optimal Control Policies for HRI Dynamical Systems | http://arxiv.org/abs/1701.03839 | id:1701.03839 author:Steven Jens Jorgensen, Orion Campbell, Travis Llado, Donghyun Kim, Junhyeok Ahn, Luis Sentis category:cs.HC cs.RO  published:2017-01-13 summary:We model Human-Robot-Interaction (HRI) scenarios as linear dynamical systems and use Model Predictive Control (MPC) with mixed integer constraints to generate human-aware control policies. We motivate the approach by presenting two scenarios. The first involves an assistive robot that aims to maximize productivity while minimizing the human's workload, and the second involves a listening humanoid robot that manages its eye contact behavior to maximize "connection" and minimize social "awkwardness" with the human during the interaction. Our simulation results show that the robot generates useful behaviors as it finds control policies to minimize the specified cost function. Further, we implement the second scenario on a humanoid robot and test the eye contact scenario with 48 human participants to demonstrate and evaluate the desired controller behavior. The humanoid generated 25% more eye contact when it was told to maximize connection over when it was told to maximize awkwardness. However, despite showing the desired behavior, there was no statistical difference between the participant's perceived connection with the humanoid. version:1
arxiv-1502-02298 | Belief Revision, Minimal Change and Relaxation: A General Framework based on Satisfaction Systems, and Applications to Description Logics | http://arxiv.org/abs/1502.02298 | id:1502.02298 author:Marc Aiguier, Jamal Atif, Isabelle Bloch, CÃ©line Hudelot category:cs.AI  published:2015-02-08 summary:Belief revision of knowledge bases represented by a set of sentences in a given logic has been extensively studied but for specific logics, mainly propositional, and also recently Horn and description logics. Here, we propose to generalize this operation from a model-theoretic point of view, by defining revision in an abstract model theory known under the name of satisfaction systems. In this framework, we generalize to any satisfaction systems the characterization of the well known AGM postulates given by Katsuno and Mendelzon for propositional logic in terms of minimal change among interpretations. Moreover, we study how to define revision, satisfying the AGM postulates, from relaxation notions that have been first introduced in description logics to define dissimilarity measures between concepts, and the consequence of which is to relax the set of models of the old belief until it becomes consistent with the new pieces of knowledge. We show how the proposed general framework can be instantiated in different logics such as propositional, first-order, description and Horn logics. In particular for description logics, we introduce several concrete relaxation operators tailored for the description logic $\ALC{}$ and its fragments $\EL{}$ and $\ELext{}$, discuss their properties and provide some illustrative examples. version:2
arxiv-1701-03714 | On the links between argumentation-based reasoning and nonmonotonic reasoning | http://arxiv.org/abs/1701.03714 | id:1701.03714 author:Zimi Li, Nir Oren, Simon Parsons category:cs.AI  published:2017-01-13 summary:In this paper we investigate the links between instantiated argumentation systems and the axioms for non-monotonic reasoning described in [9] with the aim of characterising the nature of argument based reasoning. In doing so, we consider two possible interpretations of the consequence relation, and describe which axioms are met by ASPIC+ under each of these interpretations. We then consider the links between these axioms and the rationality postulates. Our results indicate that argument based reasoning as characterised by ASPIC+ is - according to the axioms of [9] - non-cumulative and non-monotonic, and therefore weaker than the weakest non-monotonic reasoning systems they considered possible. This weakness underpins ASPIC+'s success in modelling other reasoning systems, and we conclude by considering the relationship between ASPIC+ and other weak logical systems. version:1
arxiv-1701-03709 | Power and Execution Time Measurement Methodology for SDF Applications on FPGA-based MPSoCs | http://arxiv.org/abs/1701.03709 | id:1701.03709 author:Christof Schlaak, Maher Fakih, Ralf Stemmer category:cs.DC cs.AR cs.OS 68M20  published:2017-01-13 summary:Timing and power consumption play an important role in the design of embedded systems. Furthermore, both properties are directly related to the safety requirements of many embedded systems. With regard to availability requirements, power considerations are of uttermost importance for battery operated systems. Validation of timing and power requires observability of these properties. In many cases this is difficult, because the observability is either not possible or requires big extra effort in the system validation process. In this paper, we present a measurement-based approach for the joint timing and power analysis of Synchronous Dataflow (SDF) applications running on a shared memory multiprocessor systems-on-chip (MPSoC) architecture. As a proof-of-concept, we implement an MPSoC system with configurable power and timing measurement interfaces inside a Field Programmable Gate Array (FPGA). Our experiments demonstrate the viability of our approach being able of accurately analyzing different mappings of image processing applications (Sobel filter and JPEG encoder) on an FPGA-based MPSoC implementation. version:1
arxiv-1701-03608 | Towards An Architecture-Centric Approach to Manage Variability of Cloud Robotics | http://arxiv.org/abs/1701.03608 | id:1701.03608 author:Lei Zhang, Huaxi, Zhang, Zheng Fang, Xianbo Xiang, Marianne Huchard, Rene Zapata category:cs.RO  published:2017-01-13 summary:Cloud robotics is a field of robotics that attempts to invoke Cloud technologies such as Cloud computing, Cloud storage, and other Internet technologies centered around the benefits of converged infrastructure and shared services for robotics. In a few short years, Cloud robotics as a newly emerged field has already received much research and industrial attention. The use of the Cloud for robotics and automation brings some potential benefits largely ameliorating the performance of robotic systems. However, there are also some challenges. First of all, from the viewpoint of architecture, how to model and describe the architectures of Cloud robotic systems? How to manage the variability of Cloud robotic systems? How to maximize the reuse of their architectures? In this paper, we present an architecture approach to easily design and understand Cloud robotic systems and manage their variability. version:1
arxiv-1701-03573 | Mobile Robotic Fabrication at 1:1 scale: the In situ Fabricator | http://arxiv.org/abs/1701.03573 | id:1701.03573 author:Markus Giftthaler, Timothy Sandy, Kathrin DÃ¶rfler, Ian Brooks, Mark Buckingham, Gonzalo Rey, Matthias Kohler, Fabio Gramazio, Jonas Buchli category:cs.RO  published:2017-01-13 summary:This paper presents the concept of an In situ Fabricator, a mobile robot intended for on-site manufacturing, assembly and digital fabrication. We present an overview of a prototype system, its capabilities, and highlight the importance of high-performance control, estimation and planning algorithms for achieving desired construction goals. Next, we detail on two architectural application scenarios: first, building a full-size undulating brick wall, which required a number of repositioning and autonomous localisation manoeuvres. Second, the Mesh Mould concrete process, which shows that an In situ Fabricator in combination with an innovative digital fabrication tool can be used to enable completely novel building technologies. Subsequently, important limitations and disadvantages of our approach are discussed. Based on that, we identify the need for a new type of robotic actuator, which facilitates the design of novel full-scale construction robots. We provide brief insight into the development of this actuator and conclude the paper with an outlook on the next-generation In situ Fabricator, which is currently under development. version:1
arxiv-1701-03571 | Fuzzy Clustering Data Given in the Ordinal Scale | http://arxiv.org/abs/1701.03571 | id:1701.03571 author:Zhengbing Hu, Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko, Viktoriia O. Samitova category:cs.AI  published:2017-01-13 summary:A fuzzy clustering algorithm for multidimensional data is proposed in this article. The data is described by vectors whose components are linguistic variables defined in an ordinal scale. The obtained results confirm the efficiency of the proposed approach. version:1
arxiv-1701-03519 | Computing Scores of Forwarding Schemes in Switched Networks with Probabilistic Faults | http://arxiv.org/abs/1701.03519 | id:1701.03519 author:Guy Avni, Shubham Goel, Thomas A. Henzinger, Guillermo Rodriguez-Navas category:cs.DC  published:2017-01-12 summary:Time-triggered switched networks are a deterministic communication infrastructure used by real-time distributed embedded systems. Due to the criticality of the applications running over them, developers need to ensure that end-to-end communication is dependable and predictable. Traditional approaches assume static networks that are not flexible to changes caused by reconfigurations or, more importantly, faults, which are dealt with in the application using redundancy. We adopt the concept of handling faults in the switches from non-real-time networks while maintaining the required predictability. We study a class of forwarding schemes that can handle various types of failures. We consider probabilistic failures. For a given network with a forwarding scheme and a constant $\ell$, we compute the {\em score} of the scheme, namely the probability (induced by faults) that at least $\ell$ messages arrive on time. We reduce the scoring problem to a reachability problem on a Markov chain with a "product-like" structure. Its special structure allows us to reason about it symbolically, and reduce the scoring problem to #SAT. Our solution is generic and can be adapted to different networks and other contexts. Also, we show the computational complexity of the scoring problem is #P-complete, and we study methods to estimate the score. We evaluate the effectiveness of our techniques with an implementation. version:1
arxiv-1607-08089 | Walking on Partial Footholds Including Line Contacts with the Humanoid Robot Atlas | http://arxiv.org/abs/1607.08089 | id:1607.08089 author:Georg Wiedebach, Sylvain Bertrand, Tingfan Wu, Luca Fiorio, Stephen McCrory, Robert Griffin, Francesco Nori, Jerry Pratt category:cs.RO  published:2016-07-27 summary:We present a method for humanoid robot walking on partial footholds such as small stepping stones and rocks with sharp surfaces. Our algorithm does not rely on prior knowledge of the foothold, but information about an expected foothold can be used to improve the stepping performance. After a step is taken, the robot explores the new contact surface by attempting to shift the center of pressure around the foot. The available foothold is inferred by the way in which the foot rotates about contact edges and/or by the achieved center of pressure locations on the foot during exploration. This estimated contact area is then used by a whole body momentum-based control algorithm. To walk and balance on partial footholds, we combine fast, dynamic stepping with the use of upper body angular momentum to regain balance. We applied this method to the Atlas humanoid designed by Boston Dynamics to walk over small contact surfaces, such as line and point contacts. We present experimental results and discuss performance limitations. version:2
arxiv-1701-03477 | Space-time balancing domain decomposition | http://arxiv.org/abs/1701.03477 | id:1701.03477 author:Santiago Badia, Marc Olm category:cs.NA cs.DC  published:2017-01-12 summary:In this work, we propose two-level space-time domain decomposition preconditioners for parabolic problems discretized using finite elements. They are motivated as an extension to space-time of balancing domain decomposition by constraints preconditioners. The key ingredients to be defined are the sub-assembled space and operator, the coarse degrees of freedom (DOFs) in which we want to enforce continuity among subdomains at the preconditioner level, and the transfer operator from the sub-assembled to the original finite element space. With regard to the sub-assembled operator, a perturbation of the time derivative is needed to end up with a well-posed preconditioner. The set of coarse DOFs includes the time average (at the space-time subdomain) of classical space constraints plus new constraints between consecutive subdomains in time. Numerical experiments show that the proposed schemes are weakly scalable in time, i.e., we can efficiently exploit increasing computational resources to solve more time steps in the same {total elapsed} time. Further, the scheme is also weakly space-time scalable, since it leads to asymptotically constant iterations when solving larger problems both in space and time. Excellent {wall clock} time weak scalability is achieved for space-time parallel solvers on some thousands of cores. version:1
arxiv-1701-03319 | Towards a Semantics-Aware Code Transformation Toolchain for Heterogeneous Systems | http://arxiv.org/abs/1701.03319 | id:1701.03319 author:Salvador Tamarit, Julio MariÃ±o, Guillermo Vigueras, Manuel Carro category:cs.PL cs.DC cs.SE C.1.3; D.3.4; I.2.2  published:2017-01-12 summary:Obtaining good performance when programming heterogeneous computing platforms poses significant challenges. We present a program transformation environment, implemented in Haskell, where architecture-agnostic scientific C code with semantic annotations is transformed into functionally equivalent code better suited for a given platform. The transformation steps are represented as rules that can be fired when certain syntactic and semantic conditions are fulfilled. These rules are not hard-wired into the rewriting engine: they are written in a C-like language and are automatically processed and incorporated into the rewriting engine. That makes it possible for end-users to add their own rules or to provide sets of rules that are adapted to certain specific domains or purposes. version:1
arxiv-1701-03318 | Comparing MapReduce and Pipeline Implementations for Counting Triangles | http://arxiv.org/abs/1701.03318 | id:1701.03318 author:Edelmira Pasarella, Maria-Esther Vidal, Cristina Zoltan category:cs.DC cs.DS D.1.3; F.1.2  published:2017-01-12 summary:A common method to define a parallel solution for a computational problem consists in finding a way to use the Divide and Conquer paradigm in order to have processors acting on its own data and scheduled in a parallel fashion. MapReduce is a programming model that follows this paradigm, and allows for the definition of efficient solutions by both decomposing a problem into steps on subsets of the input data and combining the results of each step to produce final results. Albeit used for the implementation of a wide variety of computational problems, MapReduce performance can be negatively affected whenever the replication factor grows or the size of the input is larger than the resources available at each processor. In this paper we show an alternative approach to implement the Divide and Conquer paradigm, named dynamic pipeline. The main features of dynamic pipelines are illustrated on a parallel implementation of the well-known problem of counting triangles in a graph. This problem is especially interesting either when the input graph does not fit in memory or is dynamically generated. To evaluate the properties of pipeline, a dynamic pipeline of processes and an ad-hoc version of MapReduce are implemented in the language Go, exploiting its ability to deal with channels and spawned processes. An empirical evaluation is conducted on graphs of different topologies, sizes, and densities. Observed results suggest that dynamic pipelines allows for an efficient implementation of the problem of counting triangles in a graph, particularly, in dense and large graphs, drastically reducing the execution time with respect to the MapReduce implementation. version:1
arxiv-1608-05874 | Efficient non-anonymous composition operator for modeling complex dependable systems | http://arxiv.org/abs/1608.05874 | id:1608.05874 author:Silvano Chiaradonna, Felicita Di Giandomenico, Giulio Masetti category:cs.DC  published:2016-08-20 summary:A new model composer is proposed to automatically generate non-anonymous model replicas in the context of performability and dependability evaluation. It is a state-sharing composer that extends the standard anonymous replication composer in order to share the state of a replica among a set of other specific replicas or among the eplica and another external model. This new composition operator aims to improve expressiveness and performance with respect to the standard anonymous replicator, namely the one adopted by the M{\"o}bius modeling framework. version:2
arxiv-1701-03296 | Using Multiple Seasonal Holt-Winters Exponential Smoothing to Predict Cloud Resource Provisioning | http://arxiv.org/abs/1701.03296 | id:1701.03296 author:Ashraf A. Shahin category:cs.DC  published:2017-01-12 summary:Elasticity is one of the key features of cloud computing that attracts many SaaS providers to minimize their services' cost. Cost is minimized by automatically provision and release computational resources depend on actual computational needs. However, delay of starting up new virtual resources can cause Service Level Agreement violation. Consequently, predicting cloud resources provisioning gains a lot of attention to scale computational resources in advance. However, most of current approaches do not consider multi-seasonality in cloud workloads. This paper proposes cloud resource provisioning prediction algorithm based on Holt-Winters exponential smoothing method. The proposed algorithm extends Holt-Winters exponential smoothing method to model cloud workload with multi-seasonal cycles. Prediction accuracy of the proposed algorithm has been improved by employing Artificial Bee Colony algorithm to optimize its parameters. Performance of the proposed algorithm has been evaluated and compared with double and triple exponential smoothing methods. Our results have shown that the proposed algorithm outperforms other methods. version:1
arxiv-1701-03295 | Automatic Cloud Resource Scaling Algorithm based on Long Short-Term Memory Recurrent Neural Network | http://arxiv.org/abs/1701.03295 | id:1701.03295 author:Ashraf A. Shahin category:cs.DC  published:2017-01-12 summary:Scalability is an important characteristic of cloud computing. With scalability, cost is minimized by provisioning and releasing resources according to demand. Most of current Infrastructure as a Service (IaaS) providers deliver threshold-based auto-scaling techniques. However, setting up thresholds with right values that minimize cost and achieve Service Level Agreement is not an easy task, especially with variant and sudden workload changes. This paper has proposed dynamic threshold based auto-scaling algorithms that predict required resources using Long Short-Term Memory Recurrent Neural Network and auto-scale virtual resources based on predicted values. The proposed algorithms have been evaluated and compared with some of existing algorithms. Experimental results show that the proposed algorithms outperform other algorithms. version:1
arxiv-1606-04669 | Parallel Space Saving on Multi and Many-Core Processors | http://arxiv.org/abs/1606.04669 | id:1606.04669 author:Massimo Cafaro, Marco Pulimeno, Italo Epicoco, Giovanni Aloisio category:cs.DC  published:2016-06-15 summary:Given an array $\mathcal{A}$ of $n$ elements and a value $2 \leq k \leq n$, a frequent item or $k$-majority element is an element occurring in $\mathcal{A}$ more than $n/k$ times. The $k$-majority problem requires finding all of the $k$-majority elements. In this paper we deal with parallel shared-memory algorithms for frequent items; we present a shared-memory version of the Space Saving algorithm and we study its behavior with regard to accuracy and performance on many and multi-core processors, including the Intel Phi accelerator. We also investigate a hybrid MPI/OpenMP version against a pure MPI based version. Through extensive experimental results we prove that the MPI/OpenMP parallel version of the algorithm significantly enhances the performance of the earlier pure MPI version of the same algorithm. Results also prove that for this algorithm the Intel Phi accelerator does not introduce any improvement with respect to the Xeon octa-core processor. version:2
arxiv-1701-03053 | Proceedings of the Workshop on High Performance Energy Efficient Embedded Systems (HIP3ES) 2017 | http://arxiv.org/abs/1701.03053 | id:1701.03053 author:David Castells-Rufas, CÃ©dric Bastoul category:cs.DC  published:2017-01-11 summary:Proceedings of the Workshop on High Performance Energy Efficient Embedded Systems (HIP3ES) 2017. Stockholm, Sweden, January 25th. Collocated with HIPEAC 2017 Conference. version:1
arxiv-1701-03043 | Robust Group LASSO Over Decentralized Networks | http://arxiv.org/abs/1701.03043 | id:1701.03043 author:Manxi Wang, Yongcheng Li, Xiaohan Wei, Qing Ling category:cs.DC  published:2017-01-11 summary:This paper considers the recovery of group sparse signals over a multi-agent network, where the measurements are subject to sparse errors. We first investigate the robust group LASSO model and its centralized algorithm based on the alternating direction method of multipliers (ADMM), which requires a central fusion center to compute a global row-support detector. To implement it in a decentralized network environment, we then adopt dynamic average consensus strategies that enable dynamic tracking of the global row-support detector. Numerical experiments demonstrate the effectiveness of the proposed algorithms. version:1
arxiv-1701-03004 | Parallel mining of time-faded heavy hitters | http://arxiv.org/abs/1701.03004 | id:1701.03004 author:Massimo Cafaro, Marco Pulimeno, Italo Epicoco category:cs.DS cs.DC  published:2017-01-11 summary:We present PFDCMSS, a novel message-passing based parallel algorithm for mining time-faded heavy hitters. The algorithm is a parallel version of the recently published FDCMSS sequential algorithm. We formally prove its correctness by showing that the underlying data structure, a sketch augmented with a Space Saving stream summary holding exactly two counters, is mergeable. Whilst mergeability of traditional sketches derives immediately from theory, we show that merging our augmented sketch is non trivial. Nonetheless, the resulting parallel algorithm is fast and simple to implement. To the best of our knowledge, PFDCMSS is the first parallel algorithm solving the problem of mining time-faded heavy hitters on message-passing parallel architectures. Extensive experimental results confirm that PFDCMSS retains the extreme accuracy and error bound provided by FDCMSS whilst providing excellent parallel scalability. version:1
arxiv-1701-03000 | A Framework for Knowledge Management and Automated Reasoning Applied on Intelligent Transport Systems | http://arxiv.org/abs/1701.03000 | id:1701.03000 author:Aneta Vulgarakis Feljan, Athanasios Karapantelakis, Leonid Mokrushin, Hongxin Liang, Rafia Inam, Elena Fersman, Carlos R. B. Azevedo, Klaus Raizer, Ricardo S. Souza category:cs.AI  published:2017-01-11 summary:Cyber-Physical Systems in general, and Intelligent Transport Systems (ITS) in particular use heterogeneous data sources combined with problem solving expertise in order to make critical decisions that may lead to some form of actions e.g., driver notifications, change of traffic light signals and braking to prevent an accident. Currently, a major part of the decision process is done by human domain experts, which is time-consuming, tedious and error-prone. Additionally, due to the intrinsic nature of knowledge possession this decision process cannot be easily replicated or reused. Therefore, there is a need for automating the reasoning processes by providing computational systems a formal representation of the domain knowledge and a set of methods to process that knowledge. In this paper, we propose a knowledge model that can be used to express both declarative knowledge about the systems' components, their relations and their current state, as well as procedural knowledge representing possible system behavior. In addition, we introduce a framework for knowledge management and automated reasoning (KMARF). The idea behind KMARF is to automatically select an appropriate problem solver based on formalized reasoning expertise in the knowledge base, and convert a problem definition to the corresponding format. This approach automates reasoning, thus reducing operational costs, and enables reusability of knowledge and methods across different domains. We illustrate the approach on a transportation planning use case. version:1
arxiv-1701-02991 | Node-Independent Spanning Trees in Gaussian Networks | http://arxiv.org/abs/1701.02991 | id:1701.02991 author:Zaid Hussain, Bader AlBdaiwi, Anton Cerny category:cs.DC  published:2017-01-11 summary:Message broadcasting in networks could be carried over spanning trees. A set of spanning trees in the same network is node independent if two conditions are satisfied. First, all trees are rooted at node $r$. Second, for every node $u$ in the network, all trees' paths from $r$ to $u$ are node-disjoint, excluding the end nodes $r$ and $u$. Independent spanning trees have applications in fault-tolerant communications and secure message distributions. Gaussian networks and two-dimensional toroidal networks share similar topological characteristics. They are regular of degree four, symmetric, and node-transitive. Gaussian networks, however, have relatively lesser network diameter that could result in a better performance. This promotes Gaussian networks to be a potential alternative for two-dimensional toroidal networks. In this paper, we present constructions for node independent spanning trees in dense Gaussian networks. Based on these constructions, we design routing algorithms that can be used in fault-tolerant routing and secure message distribution. We also design fault-tolerant algorithms to construct these trees in parallel. version:1
arxiv-1701-02408 | To Vote Before Decide: A Logless One-Phase Commit Protocol for Highly-Available Datastores | http://arxiv.org/abs/1701.02408 | id:1701.02408 author:Yuqing Zhu, Philip S. Yu, Guolei Yi, Wenlong Ma, Mengying Guo, Jianxun Liu category:cs.DC  published:2017-01-10 summary:Highly-available datastores are widely deployed for online applications. However, many online applications are not contented with the simple data access interface currently provided by highly-available datastores. Distributed transaction support is demanded by applications such as large-scale online payment used by Alipay or Paypal. Current solutions to distributed transaction can spend more than half of the whole transaction processing time in distributed commit. An efficient atomic commit protocol is highly desirable. This paper presents the HACommit protocol, a logless one-phase commit protocol for highly-available systems. HACommit has transaction participants vote for a commit before the client decides to commit or abort the transaction; in comparison, the state-of-the-art practice for distributed commit is to have the client decide before participants vote. The change enables the removal of both the participant logging and the coordinator logging steps in the distributed commit process; it also makes possible that, after the client initiates the transaction commit, the transaction data is visible to other transactions within one communication roundtrip time (i.e., one phase). In the evaluation with extensive experiments, HACommit outperforms recent atomic commit solutions for highly-available datastores under different workloads. In the best case, HACommit can commit in one fifth of the time 2PC does. version:2
arxiv-1604-08612 | Mysteries of Visual Experience | http://arxiv.org/abs/1604.08612 | id:1604.08612 author:Jerome Feldman category:q-bio.NC cs.AI  published:2016-04-28 summary:Science is a crowning glory of the human spirit and its applications remain our best hope for social progress. But there are limitations to current science and perhaps to any science. The general mind-body problem is known to be intractable and currently mysterious. This is one of many deep problems that are universally agreed to be beyond the current purview of Science, including quantum phenomena, etc. But all of these famous unsolved problems are either remote from everyday experience (entanglement, dark matter) or are hard to even define sharply (phenomenology, consciousness, etc.). In this note, we will consider some obvious computational problems in vision that arise every time that we open our eyes and yet are demonstrably incompatible with current theories of neural computation. The focus will be on two related phenomena, known as the neural binding problem and the illusion of a detailed stable visual world. version:3
arxiv-1509-02384 | A unified heuristic and an annotated bibliography for a large class of earliness-tardiness scheduling problems | http://arxiv.org/abs/1509.02384 | id:1509.02384 author:Arthur Kramer, Anand Subramanian category:cs.AI  published:2015-09-08 summary:This work proposes a unified heuristic algorithm for a large class of earliness-tardiness (E-T) scheduling problems. We consider single/parallel machine E-T problems that may or may not consider some additional features such as idle time, setup times and release dates. In addition, we also consider those problems whose objective is to minimize either the total (average) weighted completion time or the total (average) weighted flow time, which arise as particular cases when the due dates of all jobs are either set to zero or to their associated release dates, respectively. The developed local search based metaheuristic framework is quite simple, but at the same time relies on sophisticated procedures for efficiently performing local search according to the characteristics of the problem. We present efficient move evaluation approaches for some parallel machine problems that generalize the existing ones for single machine problems. The algorithm was tested in hundreds of instances of several E-T problems and particular cases. The results obtained show that our unified heuristic is capable of producing high quality solutions when compared to the best ones available in the literature that were obtained by specific methods. Moreover, we provide an extensive annotated bibliography on the problems related to those considered in this work, where we not only indicate the approach(es) used in each publication, but we also point out the characteristics of the problem(s) considered. Beyond that, we classify the existing methods in different categories so as to have a better idea of the popularity of each type of solution procedure. version:3
arxiv-1701-02641 | Distributed Algorithm for Collision Avoidance at Road Intersections in the Presence of Communication Failures | http://arxiv.org/abs/1701.02641 | id:1701.02641 author:Vladimir Savic, Elad M. Schiller, Marina Papatriantafilou category:cs.NI cs.DC cs.SY  published:2017-01-10 summary:Vehicle-to-vehicle (V2V) communication is a crucial component of the future autonomous driving systems since it enables improved awareness of the surrounding environment, even without extensive processing of sensory information. However, V2V communication is prone to failures and delays, so a distributed fault-tolerant approach is required for safe and efficient transportation. In this paper, we focus on the intersection crossing (IC) problem with autonomous vehicles that cooperate via V2V communications, and propose a novel distributed IC algorithm that can handle an unknown number of communication failures. Our analysis shows that both safety and liveness requirements are satisfied in all realistic situations. We also found, based on a real data set, that the crossing delay is only slightly increased even in the presence of highly correlated failures. version:1
arxiv-1701-02628 | Greed is Good: Optimistic Algorithms for Bipartite-Graph Partial Coloring on Multicore Architectures | http://arxiv.org/abs/1701.02628 | id:1701.02628 author:Mustafa Kemal TaÅ, Kamer Kaya, Erik Saule category:cs.DC cs.DS  published:2017-01-10 summary:In parallel computing, a valid graph coloring yields a lock-free processing of the colored tasks, data points, etc., without expensive synchronization mechanisms. However, coloring is not free and the overhead can be significant. In particular, for the bipartite-graph partial coloring (BGPC) and distance-2 graph coloring (D2GC) problems, which have various use-cases within the scientific computing and numerical optimization domains, the coloring overhead can be in the order of minutes with a single thread for many real-life graphs. In this work, we propose parallel algorithms for bipartite-graph partial coloring on shared-memory architectures. Compared to the existing shared-memory BGPC algorithms, the proposed ones employ greedier and more optimistic techniques that yield a better parallel coloring performance. In particular, on 16 cores, the proposed algorithms perform more than 4x faster than their counterparts in the ColPack library which is, to the best of our knowledge, the only publicly-available coloring library for multicore architectures. In addition to BGPC, the proposed techniques are employed to devise parallel distance-2 graph coloring algorithms and similar performance improvements have been observed. Finally, we propose two costless balancing heuristics for BGPC that can reduce the skewness and imbalance on the cardinality of color sets (almost) for free. The heuristics can also be used for the D2GC problem and in general, they will probably yield a better color-based parallelization performance especially on many-core architectures. version:1
arxiv-1701-02555 | The ANTS problem | http://arxiv.org/abs/1701.02555 | id:1701.02555 author:Ofer Feinerman, Amos Korman category:cs.DC  published:2017-01-10 summary:We introduce the Ants Nearby Treasure Search (ANTS) problem, which models natural cooperative foraging behavior such as that performed by ants around their nest. In this problem, k probabilistic agents, initially placed at a central location, collectively search for a treasure on the two-dimensional grid. The treasure is placed at a target location by an adversary and the agents' goal is to find it as fast as possible as a function of both k and D, where D is the (unknown) distance between the central location and the target. We concentrate on the case in which agents cannot communicate while searching. It is straightforward to see that the time until at least one agent finds the target is at least $\Omega$(D + D 2 /k), even for very sophisticated agents, with unrestricted memory. Our algorithmic analysis aims at establishing connections between the time complexity and the initial knowledge held by agents (e.g., regarding their total number k), as they commence the search. We provide a range of both upper and lower bounds for the initial knowledge required for obtaining fast running time. For example, we prove that log log k + $\Theta$(1) bits of initial information are both necessary and sufficient to obtain asymptotically optimal running time, i.e., O(D +D 2 /k). We also we prove that for every 0 \textless{} \textless{} 1, running in time O(log 1-- k $\times$(D +D 2 /k)) requires that agents have the capacity for storing $\Omega$(log k) different states as they leave the nest to start the search. To the best of our knowledge, the lower bounds presented in this paper provide the first non-trivial lower bounds on the memory complexity of probabilistic agents in the context of search problems. We view this paper as a "proof of concept" for a new type of interdisciplinary methodology. To fully demonstrate this methodology, the theoretical tradeoff presented here (or a similar one) should be combined with measurements of the time performance of searching ants. version:1
arxiv-1701-02545 | IoFClime: The fuzzy logic and the Internet of Things to control indoor temperature regarding the outdoor ambient conditions | http://arxiv.org/abs/1701.02545 | id:1701.02545 author:Daniel Meana-LloriÃ¡n, Cristian GonzÃ¡lez GarcÃ­a, B. Cristina Pelayo G-Bustelo, Juan Manuel Cueva Lovelle, Nestor Garcia-Fernandez category:cs.AI  published:2017-01-10 summary:The Internet of Things is arriving to our homes or cities through fields already known like Smart Homes, Smart Cities, or Smart Towns. The monitoring of environmental conditions of cities can help to adapt the indoor locations of the cities in order to be more comfortable for people who stay there. A way to improve the indoor conditions is an efficient temperature control, however, it depends on many factors like the different combinations of outdoor temperature and humidity. Therefore, adjusting the indoor temperature is not setting a value according to other value. There are many more factors to take into consideration, hence the traditional logic based in binary states cannot be used. Many problems cannot be solved with a set of binary solutions and we need a new way of development. Fuzzy logic is able to interpret many states, more than two states, giving to computers the capacity to react in a similar way to people. In this paper we will propose a new approach to control the temperature using the Internet of Things together its platforms and fuzzy logic regarding not only the indoor temperature but also the outdoor temperature and humidity in order to save energy and to set a more comfortable environment for their users. Finally, we will conclude that the fuzzy approach allows us to achieve an energy saving around 40% and thus, save money. version:1
arxiv-1701-02543 | Predicting Citywide Crowd Flows Using Deep Spatio-Temporal Residual Networks | http://arxiv.org/abs/1701.02543 | id:1701.02543 author:Junbo Zhang, Yu Zheng, Dekang Qi, Ruiyuan Li, Xiuwen Yi, Tianrui Li category:cs.AI  published:2017-01-10 summary:Forecasting the flow of crowds is of great importance to traffic management and public safety, and very challenging as it is affected by many complex factors, including spatial dependencies (nearby and distant), temporal dependencies (closeness, period, trend), and external conditions (e.g., weather and events). We propose a deep-learning-based approach, called ST-ResNet, to collectively forecast two types of crowd flows (i.e. inflow and outflow) in each and every region of a city. We design an end-to-end structure of ST-ResNet based on unique properties of spatio-temporal data. More specifically, we employ the residual neural network framework to model the temporal closeness, period, and trend properties of crowd traffic. For each property, we design a branch of residual convolutional units, each of which models the spatial properties of crowd traffic. ST-ResNet learns to dynamically aggregate the output of the three residual neural networks based on data, assigning different weights to different branches and regions. The aggregation is further combined with external factors, such as weather and day of the week, to predict the final traffic of crowds in each and every region. We have developed a real-time system based on Microsoft Azure Cloud, called UrbanFlow, providing the crowd flow monitoring and forecasting in Guiyang City of China. In addition, we present an extensive experimental evaluation using two types of crowd flows in Beijing and New York City (NYC), where ST-ResNet outperforms nine well-known baselines. version:1
arxiv-1701-02514 | On Centroidal Dynamics and Integrability of Average Angular Velocity | http://arxiv.org/abs/1701.02514 | id:1701.02514 author:Alessandro Saccon, Silvio Traversaro, Francesco Nori, Henk Nijmeijer category:cs.RO  published:2017-01-10 summary:In the literature on robotics and multibody dynamics, the concept of average angular velocity has received considerable attention in recent years. We address the question of whether the average angular velocity defines an orientation framethat depends only on the current robot configuration and provide a simple algebraic condition to check whether this holds. In the language of geometric mechanics, this condition corresponds to requiring the flatness of the mechanical connection associated to the robotic system. Here, however, we provide both a reinterpretation and a proof of this result accessible to readers with a background in rigid body kinematics and multibody dynamics but not necessarily acquainted with differential geometry, still providing precise links to the geometric mechanics literature. This should help spreading the algebraic condition beyond the scope of geometric mechanics,contributing to a proper utilization and understanding of the concept of average angular velocity. version:1
arxiv-1701-03037 | Towards Smart Proof Search for Isabelle | http://arxiv.org/abs/1701.03037 | id:1701.03037 author:Yutaka Nagashima category:cs.AI  published:2017-01-10 summary:Despite the recent progress in automatic theorem provers, proof engineers are still suffering from the lack of powerful proof automation. In this position paper we first report our proof strategy language based on a meta-tool approach. Then, we propose an AI-based approach to drastically improve proof automation for Isabelle, while identifying three major challenges we plan to address for this objective. version:1
arxiv-1603-08976 | Local Search Yields a PTAS for k-Means in Doubling Metrics | http://arxiv.org/abs/1603.08976 | id:1603.08976 author:Zachary Friggstad, Mohsen Rezapour, Mohammad R. Salavatipour category:cs.DS cs.AI cs.CG  published:2016-03-29 summary:The most well known and ubiquitous clustering problem encountered in nearly every branch of science is undoubtedly $k$-means: given a set of data points and a parameter $k$, select $k$ centres and partition the data points into $k$ clusters around these centres so that the sum of squares of distances of the points to their cluster centre is minimized. Typically these data points lie $\mathbb{R}^d$ for some $d\geq 2$. $k$-means and the first algorithms for it were introduced in the 1950's. Since then, hundreds of papers have studied this problem and many algorithms have been proposed for it. The most commonly used algorithm is known as Lloyd-Forgy, which is also referred to as "the" $k$-means algorithm, and various extensions of it often work very well in practice. However, they may produce solutions whose cost is arbitrarily large compared to the optimum solution. Kanungo et al. [2004] analyzed a simple local search heuristic to get a polynomial-time algorithm with approximation ratio $9+\epsilon$ for any fixed $\epsilon>0$ for $k$-means in Euclidean space. Finding an algorithm with a better approximation guarantee has remained one of the biggest open questions in this area, in particular whether one can get a true PTAS for fixed dimension Euclidean space. We settle this problem by showing that a simple local search algorithm provides a PTAS for $k$-means in $\mathbb{R}^d$ for any fixed $d$. More precisely, for any error parameter $\epsilon>0$, the local search algorithm that considers swaps of up to $\rho=d^{O(d)}\cdot{\epsilon}^{-O(d/\epsilon)}$ centres at a time finds a solution using exactly $k$ centres whose cost is at most a $(1+\epsilon)$-factor greater than the optimum. Finally, we provide the first demonstration that local search yields a PTAS for the uncapacitated facility location problem and $k$-median with non-uniform opening costs in doubling metrics. version:2
arxiv-1701-02324 | An $N \log N$ Parallel Fast Direct Solver for Kernel Matrices | http://arxiv.org/abs/1701.02324 | id:1701.02324 author:Chenhan D. Yu, William B. March, George Biros category:cs.DC cs.NA  published:2017-01-09 summary:Kernel matrices appear in machine learning and non-parametric statistics. Given $N$ points in $d$ dimensions and a kernel function that requires $\mathcal{O}(d)$ work to evaluate, we present an $\mathcal{O}(dN\log N)$-work algorithm for the approximate factorization of a regularized kernel matrix, a common computational bottleneck in the training phase of a learning task. With this factorization, solving a linear system with a kernel matrix can be done with $\mathcal{O}(N\log N)$ work. Our algorithm only requires kernel evaluations and does not require that the kernel matrix admits an efficient global low rank approximation. Instead our factorization only assumes low-rank properties for the off-diagonal blocks under an appropriate row and column ordering. We also present a hybrid method that, when the factorization is prohibitively expensive, combines a partial factorization with iterative methods. As a highlight, we are able to approximately factorize a dense $11M\times11M$ kernel matrix in 2 minutes on 3,072 x86 "Haswell" cores and a $4.5M\times4.5M$ matrix in 1 minute using 4,352 "Knights Landing" cores. version:1
arxiv-1511-01166 | A bi-criteria path planning algorithm for robotics applications | http://arxiv.org/abs/1511.01166 | id:1511.01166 author:Zachary Clawson, Xuchu Ding, Brendan Englot, Thomas A. Frewen, William M. Sisson, Alexander Vladimirsky category:cs.RO cs.SY I.2.8; I.2.9; G.2.2  published:2015-11-04 summary:Realistic path planning applications often require optimizing with respect to several criteria simultaneously. Here we introduce an efficient algorithm for bi-criteria path planning on graphs. Our approach is based on augmenting the state space to keep track of the "budget" remaining to satisfy the constraints on secondary cost. The resulting augmented graph is acyclic and the primary cost can be then minimized by a simple upward sweep through budget levels. The efficiency and accuracy of our algorithm is tested on Probabilistic Roadmap graphs to minimize the distance of travel subject to a constraint on the overall threat exposure of the robot. We also present the results from field experiments illustrating the use of this approach on realistic robotic systems. version:2
arxiv-1612-06507 | Survivable and Bandwidth-Guaranteed Embedding of Virtual Clusters in Cloud Data Centers (Extended Version) | http://arxiv.org/abs/1612.06507 | id:1612.06507 author:Ruozhou Yu, Guoliang Xue, Xiang Zhang, Dan Li category:cs.NI cs.DC  published:2016-12-20 summary:Cloud computing has emerged as a powerful and elastic platform for internet service hosting, yet it also draws concerns of the unpredictable performance of cloud-based services due to network congestion. To offer predictable performance, the virtual cluster abstraction of cloud services has been proposed, which enables allocation and performance isolation regarding both computing resources and network bandwidth in a simplified virtual network model. One issue arisen in virtual cluster allocation is the survivability of tenant services against physical failures. Existing works have studied virtual cluster backup provisioning with fixed primary embeddings, but have not considered the impact of primary embeddings on backup resource consumption. To address this issue, in this paper we study how to embed virtual clusters survivably in the cloud data center, by jointly optimizing primary and backup embeddings of the virtual clusters. We formally define the survivable virtual cluster embedding problem. We then propose a novel algorithm, which computes the most resource-efficient embedding given a tenant request. Since the optimal algorithm has high time complexity, we further propose a faster heuristic algorithm, which is several orders faster than the optimal solution, yet able to achieve similar performance. Besides theoretical analysis, we evaluate our algorithms via extensive simulations. version:2
arxiv-1701-01963 | Resource Management in Cloud Networking Using Economic Analysis and Pricing Models: A Survey | http://arxiv.org/abs/1701.01963 | id:1701.01963 author:Nguyen Cong Luong, Ping Wang, Dusit Niyato, Wen Yonggang, Zhu Han category:cs.GT cs.DC cs.NI  published:2017-01-08 summary:This paper presents a comprehensive literature review on applications of economic and pricing models for resource management in cloud networking. To achieve sustainable profit advantage, cost reduction, and flexibility in provisioning of cloud resources, resource management in cloud networking requires adaptive and robust designs to address many issues, e.g., resource allocation, bandwidth reservation, request allocation, and workload allocation. Economic and pricing models have received a lot of attention as they can lead to desirable performance in terms of social welfare, fairness, truthfulness, profit, user satisfaction, and resource utilization. This paper reviews applications of the economic and pricing models to develop adaptive algorithms and protocols for resource management in cloud networking. Besides, we survey a variety of incentive mechanisms using the pricing strategies in sharing resources in edge computing. In addition, we consider using pricing models in cloud-based Software Defined Wireless Networking (cloud-based SDWN). Finally, we highlight important challenges, open issues and future research directions of applying economic and pricing models to cloud networking version:1
arxiv-1701-01676 | SD-CPS: Taming the Challenges of Cyber-Physical Systems with a Software-Defined Approach | http://arxiv.org/abs/1701.01676 | id:1701.01676 author:Pradeeban Kathiravelu, LuÃ­s Veiga category:cs.NI cs.DC  published:2017-01-06 summary:Cyber-Physical Systems (CPS) revolutionize various application domains with integration and interoperability of networking, computing systems, and mechanical devices. Due to its scale and variety, CPS faces a number of challenges and opens up a few research questions in terms of management, fault-tolerance, and scalability. We propose a software-defined approach inspired by Software-Defined Networking (SDN), to address the challenges for a wider CPS adoption. We thus design a middleware architecture for the correct and resilient operation of CPS, to manage and coordinate the interacting devices centrally in the cyberspace whilst not sacrificing the functionality and performance benefits inherent to a distributed execution. version:1
arxiv-1701-01657 | Autonomous Multirobot Excavation for Lunar Applications | http://arxiv.org/abs/1701.01657 | id:1701.01657 author:Jekanthan Thangavelautham, Kenneth Law, Terence Fu, Nader Abu El Samid, Alexander D. S. Smith, Gabriele M. T. D'Eleuterio category:cs.RO astro-ph.IM  published:2017-01-06 summary:In this paper, a control approach called Artificial Neural Tissue (ANT) is applied to multirobot excavation for lunar base preparation tasks including clearing landing pads and burying of habitat modules. We show for the first time, a team of autonomous robots excavating a terrain to match a given 3D blueprint. Constructing mounds around landing pads will provide physical shielding from debris during launch/landing. Burying a human habitat modules under 0.5 m of lunar regolith is expected to provide both radiation shielding and maintain temperatures of -25 $^{o}$C. This minimizes base life-support complexity and reduces launch mass. ANT is compelling for a lunar mission because it doesn't require a team of astronauts for excavation and it requires minimal supervision. The robot teams are shown to autonomously interpret blueprints, excavate and prepare sites for a lunar base. Because little pre-programmed knowledge is provided, the controllers discover creative techniques. ANT evolves techniques such as slot-dozing that would otherwise require excavation experts. This is critical in making an excavation mission feasible when it is prohibitively expensive to send astronauts. The controllers evolve elaborate negotiation behaviors to work in close quarters. These and other techniques such as concurrent evolution of the controller and team size are shown to tackle problem of antagonism, when too many robots interfere reducing the overall efficiency or worse, resulting in gridlock. While many challenges remain with this technology our work shows a compelling pathway for field testing this approach. version:1
arxiv-1701-01648 | Locality Sim: Cloud Simulator with Data Locality | http://arxiv.org/abs/1701.01648 | id:1701.01648 author:Ahmed H. Abase, Mohamed H. Khafagy, Fatma A. Omara category:cs.DC 68Uxx C.2.4  published:2017-01-06 summary:Cloud Computing (CC) is a model for enabling on-demand access to a shared pool of configurable computing resources. Testing and evaluating the performance of the cloud environment for allocating, provisioning, scheduling, and data allocation policy have great attention to be achieved. Therefore, using cloud simulator would save time and money, and provide a flexible environment to evaluate new research work. Unfortunately, the current simulators (e.g., CloudSim, NetworkCloudSim, GreenCloud, etc..) deal with the data as for size only without any consideration about the data allocation policy and locality. On the other hand, the NetworkCloudSim simulator is considered one of the most common used simulators because it includes different modules which support needed functions to a simulated cloud environment, and it could be extended to include new extra modules. According to work in this paper, the NetworkCloudSim simulator has been extended and modified to support data locality. The modified simulator is called LocalitySim. The accuracy of the proposed LocalitySim simulator has been proved by building a mathematical model. Also, the proposed simulator has been used to test the performance of the three-tire data center as a case study with considering the data locality feature. version:1
arxiv-1701-01630 | Reducing Competitive Cache Misses in Modern Processor Architectures | http://arxiv.org/abs/1701.01630 | id:1701.01630 author:Milcho Prisagjanec, Pece Mitrevski category:cs.AR B.3.2; B.3.3  published:2017-01-06 summary:The increasing number of threads inside the cores of a multicore processor, and competitive access to the shared cache memory, become the main reasons for an increased number of competitive cache misses and performance decline. Inevitably, the development of modern processor architectures leads to an increased number of cache misses. In this paper, we make an attempt to implement a technique for decreasing the number of competitive cache misses in the first level of cache memory. This technique enables competitive access to the entire cache memory when there is a hit - but, if there are cache misses, memory data (by using replacement techniques) is put in a virtual part given to threads, so that competitive cache misses are avoided. By using a simulator tool, the results show a decrease in the number of cache misses and performance increase for up to 15%. The conclusion that comes out of this research is that cache misses are a real challenge for future processor designers, in order to hide memory latency. version:1
arxiv-1612-01120 | The Complexity of Bayesian Networks Specified by Propositional and Relational Languages | http://arxiv.org/abs/1612.01120 | id:1612.01120 author:Fabio Gagliardi Cozman, Denis Deratani MauÃ¡ category:cs.AI  published:2016-12-04 summary:We examine the complexity of inference in Bayesian networks specified by logical languages. We consider representations that range from fragments of propositional logic to function-free first-order logic with equality; in doing so we cover a variety of plate models and of probabilistic relational models. We study the complexity of inferences when network, query and domain are the input (the inferential and the combined complexity), when the network is fixed and query and domain are the input (the query/data complexity), and when the network and query are fixed and the domain is the input (the domain complexity). We draw connections with probabilistic databases and liftability results, and obtain complexity classes that range from polynomial to exponential levels. version:3
arxiv-1701-01575 | DSA: Scalable Distributed Sequence Alignment System Using SIMD Instructions | http://arxiv.org/abs/1701.01575 | id:1701.01575 author:Bo Xu, Changlong Li, Hang Zhuang, Jiali Wang, Qingfeng Wang, Jinhong Zhou, Xuehai Zhou category:cs.DC  published:2017-01-06 summary:Sequence alignment algorithms are a basic and critical component of many bioinformatics fields. With rapid development of sequencing technology, the fast growing reference database volumes and longer length of query sequence become new challenges for sequence alignment. However, the algorithm is prohibitively high in terms of time and space complexity. In this paper, we present DSA, a scalable distributed sequence alignment system that employs Spark to process sequences data in a horizontally scalable distributed environment, and leverages data parallel strategy based on Single Instruction Multiple Data (SIMD) instruction to parallelize the algorithm in each core of worker node. The experimental results demonstrate that 1) DSA has outstanding performance and achieves up to 201x speedup over SparkSW. 2) DSA has excellent scalability and achieves near linear speedup when increasing the number of nodes in cluster. version:1
arxiv-1701-02246 | Mathematics in Caging of Robotics | http://arxiv.org/abs/1701.02246 | id:1701.02246 author:Hiroyasu Hamada, Satoshi Makita, Shigeki Matsutani category:math.MG cs.RO  published:2017-01-06 summary:It is a crucial problem in robotics field to cage an object using robots like multifingered hand. However the problem what is the caging for general geometrical objects and robots has not been well-described in mathematics though there were many rigorous studies on the methods how to cage an object by certain robots. In this article, we investigate the caging problem more mathematically and describe the problem in terms of recursion of the simple euclidean moves. Using the description, we show that the caging has the degree of difficulty which is closely related to a combinatorial problem and a wire puzzle. It implies that in order to capture an object by caging, from a practical viewpoint the difficulty plays an important role. version:1
arxiv-1701-01547 | Stochastic Optimal Control for Modeling Reaching Movements in the Presence of Obstacles: Theory and Simulation | http://arxiv.org/abs/1701.01547 | id:1701.01547 author:Arun Kumar Singh, Sigal Berman, Ilana Nisky category:cs.RO  published:2017-01-06 summary:In many human-in-the-loop robotic applications such as robot-assisted surgery and remote teleoperation, predicting the intended motion of the human operator may be useful for successful implementation of shared control, guidance virtual fixtures, and predictive control. Developing computational models of human movements is a critical foundation for such motion prediction frameworks. With this motivation, we present a computational framework for modeling reaching movements in the presence of obstacles. We propose a stochastic optimal control framework that consists of probabilistic collision avoidance constraints and a cost function that trades-off between effort and end-state variance in the presence of a signal-dependent noise. First, we present a series of reformulations to convert the original non-linear and non-convex optimal control into a parametric quadratic programming problem. We show that the parameters can be tuned to model various collision avoidance strategies, thereby capturing the quintessential variability associated with human motion. Then, we present a simulation study that demonstrates the complex interaction between avoidance strategies, control cost, and the probability of collision avoidance. The proposed framework can benefit a variety of applications that require teleoperation in cluttered spaces, including robot-assisted surgery. In addition, it can also be viewed as a new optimizer which produces smooth and probabilistically-safe trajectories under signal dependent noise. version:1
arxiv-1604-00932 | Asking the metaquestions in constraint tractability | http://arxiv.org/abs/1604.00932 | id:1604.00932 author:Hubie Chen, Benoit Larose category:cs.CC cs.AI  published:2016-04-04 summary:The constraint satisfaction problem (CSP) involves deciding, given a set of variables and a set of constraints on the variables, whether or not there is an assignment to the variables satisfying all of the constraints. One formulation of the CSP is as the problem of deciding, given a pair (G,H) of relational structures, whether or not there is a homomorphism from the first structure to the second structure. The CSP is in general NP-hard; a common way to restrict this problem is to fix the second structure H, so that each structure H gives rise to a problem CSP(H). The problem family CSP(H) has been studied using an algebraic approach, which links the algorithmic and complexity properties of each problem CSP(H) to a set of operations, the so-called polymorphisms of H. Certain types of polymorphisms are known to imply the polynomial-time tractability of $CSP(H)$, and others are conjectured to do so. This article systematically studies---for various classes of polymorphisms---the computational complexity of deciding whether or not a given structure H admits a polymorphism from the class. Among other results, we prove the NP-completeness of deciding a condition conjectured to characterize the tractable problems CSP(H), as well as the NP-completeness of deciding if CSP(H) has bounded width. version:2
arxiv-1701-01487 | Designing a Safe Autonomous Artificial Intelligence Agent based on Human Self-Regulation | http://arxiv.org/abs/1701.01487 | id:1701.01487 author:Mark Muraven category:cs.AI cs.SY  published:2017-01-05 summary:There is a growing focus on how to design safe artificial intelligent (AI) agents. As systems become more complex, poorly specified goals or control mechanisms may cause AI agents to engage in unwanted and harmful outcomes. Thus it is necessary to design AI agents that follow initial programming intentions as the program grows in complexity. How to specify these initial intentions has also been an obstacle to designing safe AI agents. Finally, there is a need for the AI agent to have redundant safety mechanisms to ensure that any programming errors do not cascade into major problems. Humans are autonomous intelligent agents that have avoided these problems and the present manuscript argues that by understanding human self-regulation and goal setting, we may be better able to design safe AI agents. Some general principles of human self-regulation are outlined and specific guidance for AI design is given. version:1
arxiv-1702-02903 | Robust Orchestration of Concurrent Application Workflows in Mobile Device Clouds | http://arxiv.org/abs/1702.02903 | id:1702.02903 author:Parul Pandey, Hariharasudhan Viswanathan, Dario Pompili category:cs.DC  published:2017-01-05 summary:A hybrid mobile/fixed device cloud that harnesses sensing, computing, communication, and storage capabilities of mobile and fixed devices in the field as well as those of computing and storage servers in remote datacenters is envisioned. Mobile device clouds can be harnessed to enable innovative pervasive applications that rely on real-time, in-situ processing of sensor data collected in the field. To support concurrent mobile applications on the device cloud, a robust and secure distributed computing framework, called Maestro, is proposed. The key components of Maestro are (i) a task scheduling mechanism that employs controlled task replication in addition to task reallocation for robustness and (ii) Dedup for task deduplication among concurrent pervasive workflows. An architecture-based solution that relies on task categorization and authorized access to the categories of tasks is proposed for different levels of protection. Experimental evaluation through prototype testbed of Android- and Linux-based mobile devices as well as simulations is performed to demonstrate Maestro's capabilities. version:1
arxiv-1701-01461 | Understanding the complexity of #SAT using knowledge compilation | http://arxiv.org/abs/1701.01461 | id:1701.01461 author:Florent Capelli category:cs.CC cs.AI  published:2017-01-05 summary:Two main techniques have been used so far to solve the #P-hard problem #SAT. The first one, used in practice, is based on an extension of DPLL for model counting called exhaustive DPLL. The second approach, more theoretical, exploits the structure of the input to compute the number of satisfying assignments by usually using a dynamic programming scheme on a decomposition of the formula. In this paper, we make a first step toward the separation of these two techniques by exhibiting a family of formulas that can be solved in polynomial time with the first technique but needs an exponential time with the second one. We show this by observing that both techniques implicitely construct a very specific boolean circuit equivalent to the input formula. We then show that every beta-acyclic formula can be represented by a polynomial size circuit corresponding to the first method and exhibit a family of beta-acyclic formulas which cannot be represented by polynomial size circuits corresponding to the second method. This result shed a new light on the complexity of #SAT and related problems on beta-acyclic formulas. As a byproduct, we give new handy tools to design algorithms on beta-acyclic hypergraphs. version:1
arxiv-1404-1718 | Applications of Algorithmic Probability to the Philosophy of Mind | http://arxiv.org/abs/1404.1718 | id:1404.1718 author:Gabriel Leuenberger category:cs.AI  published:2014-04-07 summary:This paper presents formulae that can solve various seemingly hopeless philosophical conundrums. We discuss the simulation argument, teleportation, mind-uploading, the rationality of utilitarianism, and the ethics of exploiting artificial general intelligence. Our approach arises from combining the essential ideas of formalisms such as algorithmic probability, the universal intelligence measure, space-time-embedded intelligence, and Hutter's observer localization. We argue that such universal models can yield the ultimate solutions, but a novel research direction would be required in order to find computationally efficient approximations thereof. version:8
arxiv-1504-07443 | Combining Existential Rules and Transitivity: Next Steps | http://arxiv.org/abs/1504.07443 | id:1504.07443 author:Jean-FranÃ§ois Baget, Meghyn Bienvenu, Marie-Laure Mugnier, Swan Rocher category:cs.AI 68T30  published:2015-04-28 summary:We consider existential rules (aka Datalog+) as a formalism for specifying ontologies. In recent years, many classes of existential rules have been exhibited for which conjunctive query (CQ) entailment is decidable. However, most of these classes cannot express transitivity of binary relations, a frequently used modelling construct. In this paper, we address the issue of whether transitivity can be safely combined with decidable classes of existential rules. First, we prove that transitivity is incompatible with one of the simplest decidable classes, namely aGRD (acyclic graph of rule dependencies), which clarifies the landscape of `finite expansion sets' of rules. Second, we show that transitivity can be safely added to linear rules (a subclass of guarded rules, which generalizes the description logic DL-Lite-R) in the case of atomic CQs, and also for general CQs if we place a minor syntactic restriction on the rule set. This is shown by means of a novel query rewriting algorithm that is specially tailored to handle transitivity rules. Third, for the identified decidable cases, we pinpoint the combined and data complexities of query entailment. version:2
