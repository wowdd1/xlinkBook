arxiv-1710-03474 | DocEmul: a Toolkit to Generate Structured Historical Documents | http://arxiv.org/abs/1710.03474 | id:1710.03474 author:Samuele Capobianco, Simone Marinai category:cs.CV  published:2017-10-10 summary:We propose a toolkit to generate structured synthetic documents emulating the actual document production process. Synthetic documents can be used to train systems to perform document analysis tasks. In our case we address the record counting task on handwritten structured collections containing a limited number of examples. Using the DocEmul toolkit we can generate a larger dataset to train a deep architecture to predict the number of records for each page. The toolkit is able to generate synthetic collections and also perform data augmentation to create a larger trainable dataset. It includes one method to extract the page background from real pages which can be used as a substrate where records can be written on the basis of variable structures and using cursive fonts. Moreover, it is possible to extend the synthetic collection by adding random noise, page rotations, and other visual variations. We performed some experiments on two different handwritten collections using the toolkit to generate synthetic data to train a Convolutional Neural Network able to count the number of records in the real collections. version:1
arxiv-1710-03463 | Learning to Generalize: Meta-Learning for Domain Generalization | http://arxiv.org/abs/1710.03463 | id:1710.03463 author:Da Li, Yongxin Yang, Yi-Zhe Song, Timothy M. Hospedales category:cs.LG  published:2017-10-10 summary:Domain shift refers to the well known problem that a model trained in one source domain performs poorly when applied to a target domain with different statistics. {Domain Generalization} (DG) techniques attempt to alleviate this issue by producing models which by design generalize well to novel testing domains. We propose a novel {meta-learning} method for domain generalization. Rather than designing a specific model that is robust to domain shift as in most previous DG work, we propose a model agnostic training procedure for DG. Our algorithm simulates train/test domain shift during training by synthesizing virtual testing domains within each mini-batch. The meta-optimization objective requires that steps to improve training domain performance should also improve testing domain performance. This meta-learning procedure trains models with good generalization ability to novel domains. We evaluate our method and achieve state of the art results on a recent cross-domain image classification benchmark, as well demonstrating its potential on two classic reinforcement learning tasks. version:1
arxiv-1710-03444 | Safe Semi-Supervised Learning of Sum-Product Networks | http://arxiv.org/abs/1710.03444 | id:1710.03444 author:Martin Trapp, Tamas Madl, Robert Peharz, Franz Pernkopf, Robert Trappl category:stat.ML cs.LG  published:2017-10-10 summary:In several domains obtaining class annotations is expensive while at the same time unlabelled data are abundant. While most semi-supervised approaches enforce restrictive assumptions on the data distribution, recent work has managed to learn semi-supervised models in a non-restrictive regime. However, so far such approaches have only been proposed for linear models. In this work, we introduce semi-supervised parameter learning for Sum-Product Networks (SPNs). SPNs are deep probabilistic models admitting inference in linear time in number of network edges. Our approach has several advantages, as it (1) allows generative and discriminative semi-supervised learning, (2) guarantees that adding unlabelled data can increase, but not degrade, the performance (safe), and (3) is computationally efficient and does not enforce restrictive assumptions on the data distribution. We show on a variety of data sets that safe semi-supervised learning with SPNs is competitive compared to state-of-the-art and can lead to a better generative and discriminative objective value than a purely supervised approach. version:1
arxiv-1710-03442 | On- and Off-Policy Monotonic Policy Improvement | http://arxiv.org/abs/1710.03442 | id:1710.03442 author:Ryo Iwaki, Minoru Asada category:cs.AI cs.LG stat.ML  published:2017-10-10 summary:Monotonic policy improvement and off-policy learning are two main desirable properties for reinforcement learning algorithms. In this study, we show that the monotonic policy improvement is guaranteed from on- and off-policy mixture data. Based on the theoretical result, we provide an algorithm which uses the experience replay technique for trust region policy optimization. The proposed method can be regarded as a variant of off-policy natural policy gradient method. version:1
arxiv-1709-04496 | An Exploration of 2D and 3D Deep Learning Techniques for Cardiac MR Image Segmentation | http://arxiv.org/abs/1709.04496 | id:1709.04496 author:Christian F. Baumgartner, Lisa M. Koch, Marc Pollefeys, Ender Konukoglu category:cs.CV  published:2017-09-13 summary:Accurate segmentation of the heart is an important step towards evaluating cardiac function. In this paper, we present a fully automated framework for segmentation of the left (LV) and right (RV) ventricular cavities and the myocardium (Myo) on short-axis cardiac MR images. We investigate various 2D and 3D convolutional neural network architectures for this task. We investigate the suitability of various state-of-the art 2D and 3D convolutional neural network architectures, as well as slight modifications thereof, for this task. Experiments were performed on the ACDC 2017 challenge training dataset comprising cardiac MR images of 100 patients, where manual reference segmentations were made available for end-diastolic (ED) and end-systolic (ES) frames. We find that processing the images in a slice-by-slice fashion using 2D networks is beneficial due to a relatively large slice thickness. However, the exact network architecture only plays a minor role. We report mean Dice coefficients of $0.950$ (LV), $0.893$ (RV), and $0.899$ (Myo), respectively with an average evaluation time of 1.1 seconds per volume on a modern GPU. version:2
arxiv-1710-05985 | Compressed Sensing, ASBSR-method of image sampling and reconstruction and the problem of digital image acquisition with lowest possible sampling rate | http://arxiv.org/abs/1710.05985 | id:1710.05985 author:Leonid P. Yaroslavsky category:cs.CV eess.IV  published:2017-10-10 summary:The problem of minimization of the number of measurements needed for digital image acquisition and reconstruction with a given accuracy is addressed. Basics of the sampling theory are outlined to show that the lower bound of signal sampling rate sufficient for signal reconstruction with a given accuracy is equal to the spectrum sparsity of the signal sparse approximation that has this accuracy. The capability of Compressed Sensing of reconstruction of signals sampled with aliasing is demystified using a simple and intuitive model and limitations of this capability are discussed. It is revealed that the Compressed Sensing approach advanced as a solution to the sampling rate minimization problem is far from reaching the sampling rate theoretical minimum. A method of image Arbitrary Sampling and Bounded Spectrum Reconstruction (ASBSR-method) is described that allows to draw near the image sampling rate theoretical minimum. Presented and discussed are also results of experimental verification of the ASBSR-method and its possible applicability extensions to solving various under-determined inverse problems such as color image demosaicing, image in-painting, image reconstruction from their sparsely sampled or decimated projections, image reconstruction from module of its Fourier spectrum and image reconstruction from its sparse samples in Fourier domain version:1
arxiv-1710-04076 | Deep Semantic Abstractions of Everyday Human Activities: On Commonsense Representations of Human Interactions | http://arxiv.org/abs/1710.04076 | id:1710.04076 author:Jakob Suchan, Mehul Bhatt category:cs.RO cs.AI cs.CV  published:2017-10-10 summary:We propose a deep semantic characterization of space and motion categorically from the viewpoint of grounding embodied human-object interactions. Our key focus is on an ontological model that would be adept to formalisation from the viewpoint of commonsense knowledge representation, relational learning, and qualitative reasoning about space and motion in cognitive robotics settings. We demonstrate key aspects of the space & motion ontology and its formalization as a representational framework in the backdrop of select examples from a dataset of everyday activities. Furthermore, focussing on human-object interaction data obtained from RGBD sensors, we also illustrate how declarative (spatio-temporal) reasoning in the (constraint) logic programming family may be performed with the developed deep semantic abstractions. version:1
arxiv-1710-03430 | Learning to Rank Question-Answer Pairs using Hierarchical Recurrent Encoder with Latent Topic Clustering | http://arxiv.org/abs/1710.03430 | id:1710.03430 author:Seunghyun Yoon, Joongbo Shin, Kyomin Jung category:cs.CL cs.AI  published:2017-10-10 summary:In this paper, we propose a novel end-to-end neural architecture for ranking answers from candidates that adapts a hierarchical recurrent neural network and a latent topic clustering module. With our proposed model, a text is encoded to a vector representation from an word-level to a chunk-level to effectively capture the entire meaning. In particular, by adapting the hierarchical structure, our model prevents performance degradations in longer text comprehension while other recurrent neural networks suffer from it. Additionally, the latent topic clustering module extracts semantic information from target samples. This clustering module is useful for any text related tasks by allowing each data sample to find its nearest topic cluster, thus helping the neural network model analyze the entire data. We evaluate our models on the Ubuntu Dialogue Corpus and consumer electronic domain question answering dataset, which is related to Samsung products. The proposed model shows better performances than conventional architectures, resulting in state-of-the-art results for ranking question-answer pairs. version:1
arxiv-1710-03425 | AdaDNNs: Adaptive Ensemble of Deep Neural Networks for Scene Text Recognition | http://arxiv.org/abs/1710.03425 | id:1710.03425 author:Chun Yang, Xu-Cheng Yin, Zejun Li, Jianwei Wu, Chunchao Guo, Hongfa Wang, Lei Xiao category:cs.CV  published:2017-10-10 summary:Recognizing text in the wild is a really challenging task because of complex backgrounds, various illuminations and diverse distortions, even with deep neural networks (convolutional neural networks and recurrent neural networks). In the end-to-end training procedure for scene text recognition, the outputs of deep neural networks at different iterations are always demonstrated with diversity and complementarity for the target object (text). Here, a simple but effective deep learning method, an adaptive ensemble of deep neural networks (AdaDNNs), is proposed to simply select and adaptively combine classifier components at different iterations from the whole learning system. Furthermore, the ensemble is formulated as a Bayesian framework for classifier weighting and combination. A variety of experiments on several typical acknowledged benchmarks, i.e., ICDAR Robust Reading Competition (Challenge 1, 2 and 4) datasets, verify the surprised improvement from the baseline DNNs, and the effectiveness of AdaDNNs compared with the recent state-of-the-art methods. version:1
arxiv-1709-09118 | Tensor Product Generation Networks | http://arxiv.org/abs/1709.09118 | id:1709.09118 author:Qiuyuan Huang, Paul Smolensky, Xiaodong He, Li Deng, Dapeng Wu category:cs.CV cs.CL  published:2017-09-26 summary:We present a new tensor product generation network (TPGN) that generates natural language descriptions for images. The model has a novel architecture that instantiates a general framework for encoding and processing symbolic structure through neural network computation. This framework is built on Tensor Product Representations (TPRs). We evaluated the proposed TPGN on the MS COCO image captioning task. The experimental results show that the TPGN outperforms the LSTM based state-of-the-art baseline with a significant margin. Further, we show that our caption generation model can be interpreted as generating sequences of grammatical categories and retrieving words by their categories from a plan encoded as a distributed representation. version:4
arxiv-1710-03414 | Network of Recurrent Neural Networks | http://arxiv.org/abs/1710.03414 | id:1710.03414 author:Chao-Ming Wang category:cs.NE cs.AI  published:2017-10-10 summary:We describe a class of systems theory based neural networks called "Network Of Recurrent neural networks" (NOR), which introduces a new structure level to RNN related models. In NOR, RNNs are viewed as the high-level neurons and are used to build the high-level layers. More specifically, we propose several methodologies to design different NOR topologies according to the theory of system evolution. Then we carry experiments on three different tasks to evaluate our implementations. Experimental results show our models outperform simple RNN remarkably under the same number of parameters, and sometimes achieve even better results than GRU and LSTM. version:1
arxiv-1709-06262 | Compressing Low Precision Deep Neural Networks Using Sparsity-Induced Regularization in Ternary Networks | http://arxiv.org/abs/1709.06262 | id:1709.06262 author:Julian Faraone, Nicholas Fraser, Giulio Gambardella, Michaela Blott, Philip H. W. Leong category:cs.CV  published:2017-09-19 summary:A low precision deep neural network training technique for producing sparse, ternary neural networks is presented. The technique incorporates hard- ware implementation costs during training to achieve significant model compression for inference. Training involves three stages: network training using L2 regularization and a quantization threshold regularizer, quantization pruning, and finally retraining. Resulting networks achieve improved accuracy, reduced memory footprint and reduced computational complexity compared with conventional methods, on MNIST and CIFAR10 datasets. Our networks are up to 98% sparse and 5 & 11 times smaller than equivalent binary and ternary models, translating to significant resource and speed benefits for hardware implementations. version:2
arxiv-1710-03383 | Real-Time Action Detection in Video Surveillance using Sub-Action Descriptor with Multi-CNN | http://arxiv.org/abs/1710.03383 | id:1710.03383 author:Cheng-Bin Jin, Shengzhe Li, Hakil Kim category:cs.CV  published:2017-10-10 summary:When we say a person is texting, can you tell the person is walking or sitting? Emphatically, no. In order to solve this incomplete representation problem, this paper presents a sub-action descriptor for detailed action detection. The sub-action descriptor consists of three levels: the posture, the locomotion, and the gesture level. The three levels give three sub-action categories for one action to address the representation problem. The proposed action detection model simultaneously localizes and recognizes the actions of multiple individuals in video surveillance using appearance-based temporal features with multi-CNN. The proposed approach achieved a mean average precision (mAP) of 76.6% at the frame-based and 83.5% at the video-based measurement on the new large-scale ICVL video surveillance dataset that the authors introduce and make available to the community with this paper. Extensive experiments on the benchmark KTH dataset demonstrate that the proposed approach achieved better performance, which in turn boosts the action recognition performance over the state-of-the-art. The action detection model can run at around 25 fps on the ICVL and more than 80 fps on the KTH dataset, which is suitable for real-time surveillance applications. version:1
arxiv-1710-03370 | iVQA: Inverse Visual Question Answering | http://arxiv.org/abs/1710.03370 | id:1710.03370 author:Feng Liu, Tao Xiang, Timothy M. Hospedales, Wankou Yang, Changyin Sun category:cs.CV  published:2017-10-10 summary:In recent years, visual question answering (VQA) has become topical as a long-term goal to drive computer vision and multi-disciplinary AI research. The premise of VQA's significance, is that both the image and textual question need to be well understood and mutually grounded in order to infer the correct answer. However, current VQA models perhaps `understand' less than initially hoped, and instead master the easier task of exploiting cues given away in the question and biases in the answer distribution. In this paper we propose the inverse problem of VQA (iVQA), and explore its suitability as a benchmark for visuo-linguistic understanding. The iVQA task is to generate a question that corresponds to a given image and answer pair. Since the answers are less informative than the questions, and the questions have less learnable bias, an iVQA model needs to better understand the image to be successful. We pose question generation as a multi-modal dynamic inference process and propose an iVQA model that can gradually adjust its focus of attention guided by both a partially generated question and the answer. For evaluation, apart from existing linguistic metrics, we propose a new ranking metric. This metric compares the ground truth question's rank among a list of distractors, which allows the drawbacks of different algorithms and sources of error to be studied. Experimental results show that our model can generate diverse, grammatically correct and content correlated questions that match the given answer. version:1
arxiv-1709-10250 | DAGGER: A sequential algorithm for FDR control on DAGs | http://arxiv.org/abs/1709.10250 | id:1709.10250 author:Aaditya Ramdas, Jianbo Chen, Martin J. Wainwright, Michael I. Jordan category:stat.ME cs.LG math.ST stat.ML stat.TH  published:2017-09-29 summary:We propose a top-down algorithm for multiple testing on directed acyclic graphs (DAGs), where nodes represent hypotheses and edges specify a partial ordering in which hypotheses must be tested. The procedure is guaranteed to reject a sub-DAG with bounded false discovery rate (FDR) while satisfying the logical constraint that a rejected node's parents must also be rejected. It is designed for sequential testing settings, when the DAG structure is known a priori, but the p-values are obtained selectively (such as sequential conduction of experiments), but the algorithm is also applicable in non-sequential settings when all p-values can be calculated in advance (such as variable/model selection). Our DAGGER algorithm, shorthand for Greedily Evolving Rejections on DAGs, allows for independence, positive or arbitrary dependence of the p-values, and is guaranteed to work on two different types of DAGs: (a) intersection DAGs in which all nodes are intersection hypotheses, with parents being supersets of children, or (b) general DAGs in which all nodes may be elementary hypotheses. The DAGGER procedure has the appealing property that it specializes to known algorithms in the special cases of trees and line graphs, and simplifies to the classic Benjamini-Hochberg procedure when the DAG has no edges. We explore the empirical performance of DAGGER using simulations, as well as a real dataset corresponding to a gene ontology DAG, showing that it performs favorably in terms of time and power. version:2
arxiv-1710-03368 | Energy-efficient Amortized Inference with Cascaded Deep Classifiers | http://arxiv.org/abs/1710.03368 | id:1710.03368 author:Jiaqi Guan, Yang Liu, Qiang Liu, Jian Peng category:cs.LG  published:2017-10-10 summary:Deep neural networks have been remarkable successful in various AI tasks but often cast high computation and energy cost for energy-constrained applications such as mobile sensing. We address this problem by proposing a novel framework that optimizes the prediction accuracy and energy cost simultaneously, thus enabling effective cost-accuracy trade-off at test time. In our framework, each data instance is pushed into a cascade of deep neural networks with increasing sizes, and a selection module is used to sequentially determine when a sufficiently accurate classifier can be used for this data instance. The cascade of neural networks and the selection module are jointly trained in an end-to-end fashion by the REINFORCE algorithm to optimize a trade-off between the computational cost and the predictive accuracy. Our method is able to simultaneously improve the accuracy and efficiency by learning to assign easy instances to fast yet sufficiently accurate classifiers to save computation and energy cost, while assigning harder instances to deeper and more powerful classifiers to ensure satisfiable accuracy. With extensive experiments on several image classification datasets using cascaded ResNet classifiers, we demonstrate that our method outperforms the standard well-trained ResNets in accuracy but only requires less than 20% and 50% FLOPs cost on the CIFAR-10/100 datasets and 66% on the ImageNet dataset, respectively. version:1
arxiv-1710-03203 | Deep Learning Paradigm with Transformed Monolingual Word Embeddings for Multilingual Sentiment Analysis | http://arxiv.org/abs/1710.03203 | id:1710.03203 author:Yujie Lu, Tatsunori Mori category:cs.CL  published:2017-10-09 summary:The surge of social media use brings huge demand of multilingual sentiment analysis (MSA) for unveiling cultural difference. So far, traditional methods resorted to machine translation---translating texts in other languages to English, and then adopt the methods once worked in English. However, this paradigm is conditioned by the quality of machine translation. In this paper, we propose a new deep learning paradigm to assimilate the differences between languages for MSA. We first pre-train monolingual word embeddings separately, then map word embeddings in different spaces into a shared embedding space, and then finally train a parameter-sharing deep neural network for MSA. The experimental results show that our paradigm is effective. Especially, our CNN model outperforms a state-of-the-art baseline by around 2.1% in terms of classification accuracy. version:2
arxiv-1708-02635 | Anomaly Detection in Multivariate Non-stationary Time Series for Automatic DBMS Diagnosis | http://arxiv.org/abs/1708.02635 | id:1708.02635 author:Doyup Lee category:stat.ML cs.LG stat.AP  published:2017-08-08 summary:Anomaly detection in database management systems (DBMSs) is difficult because of increasing number of statistics (stat) and event metrics in big data system. In this paper, I propose an automatic DBMS diagnosis system that detects anomaly periods with abnormal DB stat metrics and finds causal events in the periods. Reconstruction error from deep autoencoder and statistical process control approach are applied to detect time period with anomalies. Related events are found using time series similarity measures between events and abnormal stat metrics. After training deep autoencoder with DBMS metric data, efficacy of anomaly detection is investigated from other DBMSs containing anomalies. Experiment results show effectiveness of proposed model, especially, batch temporal normalization layer. Proposed model is used for publishing automatic DBMS diagnosis reports in order to determine DBMS configuration and SQL tuning. version:2
arxiv-1710-03348 | What does Attention in Neural Machine Translation Pay Attention to? | http://arxiv.org/abs/1710.03348 | id:1710.03348 author:Hamidreza Ghader, Christof Monz category:cs.CL  published:2017-10-09 summary:Attention in neural machine translation provides the possibility to encode relevant parts of the source sentence at each translation step. As a result, attention is considered to be an alignment model as well. However, there is no work that specifically studies attention and provides analysis of what is being learned by attention models. Thus, the question still remains that how attention is similar or different from the traditional alignment. In this paper, we provide detailed analysis of attention and compare it to traditional alignment. We answer the question of whether attention is only capable of modelling translational equivalent or it captures more information. We show that attention is different from alignment in some cases and is capturing useful information other than alignments. version:1
arxiv-1710-03344 | Iterative PET Image Reconstruction Using Convolutional Neural Network Representation | http://arxiv.org/abs/1710.03344 | id:1710.03344 author:Kuang Gong, Jiahui Guan, Kyungsang Kim, Xuezhu Zhang, Georges El Fakhri, Jinyi Qi, Quanzheng Li category:cs.CV physics.med-ph stat.ML  published:2017-10-09 summary:PET image reconstruction is challenging due to the ill-poseness of the inverse problem and limited number of detected photons. Recently deep neural networks have been widely and successfully used in computer vision tasks and attracted growing interests in medical imaging. In this work, we trained a deep residual convolutional neural network to improve PET image quality by using the existing inter-patient information. An innovative feature of the proposed method is that we embed the neural network in the iterative reconstruction framework for image representation, rather than using it as a post-processing tool. We formulate the objective function as a constraint optimization problem and solve it using the alternating direction method of multipliers (ADMM) algorithm. Both simulation data and hybrid real data are used to evaluate the proposed method. Quantification results show that our proposed iterative neural network method can outperform the neural network denoising and conventional penalized maximum likelihood methods. version:1
arxiv-1710-03337 | Standard detectors aren't (currently) fooled by physical adversarial stop signs | http://arxiv.org/abs/1710.03337 | id:1710.03337 author:Jiajun Lu, Hussein Sibai, Evan Fabry, David Forsyth category:cs.CV cs.AI cs.GR  published:2017-10-09 summary:An adversarial example is an example that has been adjusted to produce the wrong label when presented to a system at test time. If adversarial examples existed that could fool a detector, they could be used to (for example) wreak havoc on roads populated with smart vehicles. Recently, we described our difficulties creating physical adversarial stop signs that fool a detector. More recently, Evtimov et al. produced a physical adversarial stop sign that fools a proxy model of a detector. In this paper, we show that these physical adversarial stop signs do not fool two standard detectors (YOLO and Faster RCNN) in standard configuration. Evtimov et al.'s construction relies on a crop of the image to the stop sign; this crop is then resized and presented to a classifier. We argue that the cropping and resizing procedure largely eliminates the effects of rescaling and of view angle. Whether an adversarial attack is robust under rescaling and change of view direction remains moot. We argue that attacking a classifier is very different from attacking a detector, and that the structure of detectors -- which must search for their own bounding box, and which cannot estimate that box very accurately -- makes it quite likely that adversarial patterns are strongly disrupted. Finally, an adversarial pattern on a physical object that could fool a detector would have to be adversarial in the face of a wide family of parametric distortions (scale; view angle; box shift inside the detector; illumination; and soon). Such a pattern would be of great theoretical and practical interest. There is currently no evidence that such patterns exist. version:1
arxiv-1708-03985 | AffectNet: A Database for Facial Expression, Valence, and Arousal Computing in the Wild | http://arxiv.org/abs/1708.03985 | id:1708.03985 author:Ali Mollahosseini, Behzad Hasani, Mohammad H. Mahoor category:cs.CV  published:2017-08-14 summary:Automated affective computing in the wild setting is a challenging problem in computer vision. Existing annotated databases of facial expressions in the wild are small and mostly cover discrete emotions (aka the categorical model). There are very limited annotated facial databases for affective computing in the continuous dimensional model (e.g., valence and arousal). To meet this need, we collected, annotated, and prepared for public distribution a new database of facial emotions in the wild (called AffectNet). AffectNet contains more than 1,000,000 facial images from the Internet by querying three major search engines using 1250 emotion related keywords in six different languages. About half of the retrieved images were manually annotated for the presence of seven discrete facial expressions and the intensity of valence and arousal. AffectNet is by far the largest database of facial expression, valence, and arousal in the wild enabling research in automated facial expression recognition in two different emotion models. Two baseline deep neural networks are used to classify images in the categorical model and predict the intensity of valence and arousal. Various evaluation metrics show that our deep neural network baselines can perform better than conventional machine learning methods and off-the-shelf facial expression recognition systems. version:4
arxiv-1710-03323 | Massive Open Online Courses Temporal Profiling for Dropout Prediction | http://arxiv.org/abs/1710.03323 | id:1710.03323 author:Tom Rolandus Hagedoorn, Gerasimos Spanakis category:cs.IR cs.LG  published:2017-10-09 summary:Massive Open Online Courses (MOOCs) are attracting the attention of people all over the world. Regardless the platform, numbers of registrants for online courses are impressive but in the same time, completion rates are disappointing. Understanding the mechanisms of dropping out based on the learner profile arises as a crucial task in MOOCs, since it will allow intervening at the right moment in order to assist the learner in completing the course. In this paper, the dropout behaviour of learners in a MOOC is thoroughly studied by first extracting features that describe the behavior of learners within the course and then by comparing three classifiers (Logistic Regression, Random Forest and AdaBoost) in two tasks: predicting which users will have dropped out by a certain week and predicting which users will drop out on a specific week. The former has showed to be considerably easier, with all three classifiers performing equally well. However, the accuracy for the second task is lower, and Logistic Regression tends to perform slightly better than the other two algorithms. We found that features that reflect an active attitude of the user towards the MOOC, such as submitting their assignment, posting on the Forum and filling their Profile, are strong indicators of persistence. version:1
arxiv-1710-03282 | Checkpoint Ensembles: Ensemble Methods from a Single Training Process | http://arxiv.org/abs/1710.03282 | id:1710.03282 author:Hugh Chen, Scott Lundberg, Su-In Lee category:cs.LG  published:2017-10-09 summary:We present the checkpoint ensembles method that can learn ensemble models on a single training process. Although checkpoint ensembles can be applied to any parametric iterative learning technique, here we focus on neural networks. Neural networks' composable and simple neurons make it possible to capture many individual and interaction effects among features. However, small sample sizes and sampling noise may result in patterns in the training data that are not representative of the true relationship between the features and the outcome. As a solution, regularization during training is often used (e.g. dropout). However, regularization is no panacea -- it does not perfectly address overfitting. Even with methods like dropout, two methodologies are commonly used in practice. First is to utilize a validation set independent to the training set as a way to decide when to stop training. Second is to use ensemble methods to further reduce overfitting and take advantage of local optima (i.e. averaging over the predictions of several models). In this paper, we explore checkpoint ensembles -- a simple technique that combines these two ideas in one training process. Checkpoint ensembles improve performance by averaging the predictions from "checkpoints" of the best models within single training process. We use three real-world data sets -- text, image, and electronic health record data -- using three prediction models: a vanilla neural network, a convolutional neural network, and a long short term memory network to show that checkpoint ensembles outperform existing methods: a method that selects a model by minimum validation score, and two methods that average models by weights. Our results also show that checkpoint ensembles capture a portion of the performance gains that traditional ensembles provide. version:1
arxiv-1710-03276 | Lagged Exact Bayesian Online Changepoint Detection | http://arxiv.org/abs/1710.03276 | id:1710.03276 author:Michael Byrd, Linh Nghiem, Jing Cao category:stat.ML  published:2017-10-09 summary:Identifying changes in the generative process of sequential data, known as changepoint detection, has become an increasingly important topic for a wide variety of fields. A recently developed approach, which we call EXact Online Bayesian Changepoint Detection (EXO), has shown reasonable results with efficient computation for real time updates. However, when the changes are relatively small, EXO starts to have difficulty in detecting changepoints accurately. We propose a new algorithm called $\ell$-Lag EXact Online Bayesian Changepoint Detection (LEXO-$\ell$), which improves the accuracy of the detection by incorporating $\ell$ time lags in the inference. We prove that LEXO-1 finds the exact posterior distribution for the current run length and can be computed efficiently, with extension to arbitrary lag. Additionally, we show that LEXO-1 performs better than EXO in an extensive simulation study; this study is extended to higher order lags to illustrate the performance of the generalized methodology. Lastly, we illustrate applicability with two real world data examples comparing EXO and LEXO-1. version:1
arxiv-1710-03268 | Considerations of automated machine learning in clinical metabolic profiling: Altered homocysteine plasma concentration associated with metformin exposure | http://arxiv.org/abs/1710.03268 | id:1710.03268 author:Alena Orlenko, Jason H. Moore, Patryk Orzechowski, Randal S. Olson, Junmei Cairns, Pedro J. Caraballo, Richard M. Weinshilboum, Liewei Wang, Matthew K. Breitenstein category:q-bio.MN q-bio.PE q-bio.QM stat.AP stat.ML  published:2017-10-09 summary:With the maturation of metabolomics science and proliferation of biobanks, clinical metabolic profiling is an increasingly opportunistic frontier for advancing translational clinical research. Automated Machine Learning (AutoML) approaches provide exciting opportunity to guide feature selection in agnostic metabolic profiling endeavors, where potentially thousands of independent data points must be evaluated. In previous research, AutoML using high-dimensional data of varying types has been demonstrably robust, outperforming traditional approaches. However, considerations for application in clinical metabolic profiling remain to be evaluated. Particularly, regarding the robustness of AutoML to identify and adjust for common clinical confounders. In this study, we present a focused case study regarding AutoML considerations for using the Tree-Based Optimization Tool (TPOT) in metabolic profiling of exposure to metformin in a biobank cohort. First, we propose a tandem rank-accuracy measure to guide agnostic feature selection and corresponding threshold determination in clinical metabolic profiling endeavors. Second, while AutoML, using default parameters, demonstrated potential to lack sensitivity to low-effect confounding clinical covariates, we demonstrated residual training and adjustment of metabolite features as an easily applicable approach to ensure AutoML adjustment for potential confounding characteristics. Finally, we present increased homocysteine with long-term exposure to metformin as a potentially novel, non-replicated metabolite association suggested by TPOT; an association not identified in parallel clinical metabolic profiling endeavors. While considerations are recommended, including adjustment approaches for clinical confounders, AutoML presents an exciting tool to enhance clinical metabolic profiling and advance translational research endeavors. version:1
arxiv-1710-03266 | $α$-Variational Inference with Statistical Guarantees | http://arxiv.org/abs/1710.03266 | id:1710.03266 author:Yun Yang, Debdeep Pati, Anirban Bhattacharya category:math.ST stat.CO stat.ME stat.ML stat.TH  published:2017-10-09 summary:We propose a variational approximation to Bayesian posterior distributions, called $\alpha$-VB, with provable statistical guarantees for models with and without latent variables. The standard variational approximation is a special case of $\alpha$-VB with $\alpha=1$. When $\alpha \in(0,1)$, a novel class of variational inequalities are developed for linking the Bayes risk under the variational approximation to the objective function in the variational optimization problem, implying that maximizing the evidence lower bound in variational inference has the effect of minimizing the Bayes risk within the variational density family. Operating in a frequentist setup, the variational inequalities imply that point estimates constructed from the $\alpha$-VB procedure converge at an optimal rate to the true parameter in a wide range of problems. We illustrate our general theory with a number of examples, including the mean-field variational approximation to (low)-high-dimensional Bayesian linear regression with spike and slab priors, mixture of Gaussian models, latent Dirichlet allocation, and (mixture of) Gaussian variational approximation in regular parametric models. version:1
arxiv-1710-03263 | Function space analysis of deep learning representation layers | http://arxiv.org/abs/1710.03263 | id:1710.03263 author:Oren Elisha, Shai Dekel category:cs.AI cs.LG stat.ML  published:2017-10-09 summary:In this paper we propose a function space approach to Representation Learning and the analysis of the representation layers in deep learning architectures. We show how to compute a weak-type Besov smoothness index that quantifies the geometry of the clustering in the feature space. This approach was already applied successfully to improve the performance of machine learning algorithms such as the Random Forest and tree-based Gradient Boosting. Our experiments demonstrate that in well-known and well-performing trained networks, the Besov smoothness of the training set, measured in the corresponding hidden layer feature map representation, increases from layer to layer. We also contribute to the understanding of generalization by showing how the Besov smoothness of the representations, decreases as we add more mis-labeling to the training data. We hope this approach will contribute to the de-mystification of some aspects of deep learning. version:1
arxiv-1710-03255 | Multitask training with unlabeled data for end-to-end sign language fingerspelling recognition | http://arxiv.org/abs/1710.03255 | id:1710.03255 author:Bowen Shi, Karen Livescu category:cs.CL cs.CV  published:2017-10-09 summary:We address the problem of automatic American Sign Language fingerspelling recognition from video. Prior work has largely relied on frame-level labels, hand-crafted features, or other constraints, and has been hampered by the scarcity of data for this task. We introduce a model for fingerspelling recognition that addresses these issues. The model consists of an auto-encoder-based feature extractor and an attention-based neural encoder-decoder, which are trained jointly. The model receives a sequence of image frames and outputs the fingerspelled word, without relying on any frame-level training labels or hand-crafted features. In addition, the auto-encoder subcomponent makes it possible to leverage unlabeled data to improve the feature learning. The model achieves 11.6% and 4.4% absolute letter accuracy improvement respectively in signer-independent and signer- adapted fingerspelling recognition over previous approaches that required frame-level training labels. version:1
arxiv-1709-00727 | Hand Gesture Real Time Paint Tool - Box | http://arxiv.org/abs/1709.00727 | id:1709.00727 author:Vandit Gajjar, Viraj Mavani, Ayesha Gurnani category:cs.CV  published:2017-09-03 summary:With current development universally in computing, now a days user interaction approaches with mouse, keyboard, touch-pens etc. are not sufficient. Directly using of hands or hand gestures as an input device is a method to attract people with providing the applications, through Machine Learning and Computer Vision. Human-computer interaction application in which you can simply draw different shapes, fill the colors, moving the folder from one place to another place and rotating your image with rotating your hand gesture all this will be without touching your device only. In this paper Machine Learning based hand gestures recognition is presented, with the use of Computer Vision different types of gesture applications have been created. version:2
arxiv-1710-03184 | On formalizing fairness in prediction with machine learning | http://arxiv.org/abs/1710.03184 | id:1710.03184 author:Pratik Gajane category:cs.LG cs.AI stat.ML  published:2017-10-09 summary:Machine learning algorithms for prediction are increasingly being used in critical decisions affecting human lives. Various fairness formalizations, with no firm consensus yet, are employed to prevent such algorithms from systematically discriminating against people based on certain attributes protected by law. The aim of this article is to survey how fairness is formalized in the machine learning literature for the task of prediction and present these formalizations with their corresponding notions of distributive justice from the social sciences literature. We provide theoretical as well as empirical critiques of these notions from the social sciences literature and explain how these critiques limit the suitability of the corresponding fairness formalizations to certain domains. We also suggest two notions of distributive justice which address some of these critiques and discuss avenues for prospective fairness formalizations. version:1
arxiv-1709-06178 | A Fast Algorithm Based on a Sylvester-like Equation for LS Regression with GMRF Prior | http://arxiv.org/abs/1709.06178 | id:1709.06178 author:Qi Wei, Emilie Chouzenoux, Jean-Yves Tourneret, Jean-Christophe Pesquet category:cs.CV  published:2017-09-18 summary:This paper presents a fast approach for penalized least squares (LS) regression problems using a 2D Gaussian Markov random field (GMRF) prior. More precisely, the computation of the proximity operator of the LS criterion regularized by different GMRF potentials is formulated as solving a Sylvester-like matrix equation. By exploiting the structural properties of GMRFs, this matrix equation is solved columnwise in an analytical way. The proposed algorithm can be embedded into a wide range of proximal algorithms to solve LS regression problems including a convex penalty. Experiments carried out in the case of a constrained LS regression problem arising in a multichannel image processing application, provide evidence that an alternating direction method of multipliers performs quite efficiently in this context. version:2
arxiv-1710-03163 | Random Projection and Its Applications | http://arxiv.org/abs/1710.03163 | id:1710.03163 author:Mahmoud Nabil category:cs.LG cs.AI  published:2017-10-09 summary:Random Projection is a foundational research topic that connects a bunch of machine learning algorithms under a similar mathematical basis. It is used to reduce the dimensionality of the dataset by projecting the data points efficiently to a smaller dimensions while preserving the original relative distance between the data points. In this paper, we are intended to explain random projection method, by explaining its mathematical background and foundation, the applications that are currently adopting it, and an overview on its current research perspective. version:1
arxiv-1709-07911 | Avoidance of Manual Labeling in Robotic Autonomous Navigation Through Multi-Sensory Semi-Supervised Learning | http://arxiv.org/abs/1709.07911 | id:1709.07911 author:Junhong Xu, Shangyue Zhu, Hanqing Guo, Shaoen Wu category:cs.LG cs.RO  published:2017-09-22 summary:Imitation learning holds the promise to address challenging robotic tasks such as autonomous navigation. It however requires a human supervisor to oversee the training process and send correct control commands to robots without feedback, which is always prone to error and expensive. To minimize human involvement and avoid manual labeling of data in the robotic autonomous navigation with imitation learning, this paper proposes a novel semi-supervised imitation learning solution based on a multi-sensory design. This solution includes a suboptimal sensor policy based on sensor fusion to automatically label states encountered by a robot to avoid human supervision during training. In addition, a recording policy is developed to throttle the adversarial affect of learning too much from the suboptimal sensor policy. This solution allows the robot to learn a navigation policy in a self-supervised manner. With extensive experiments in indoor environments, this solution can achieve near human performance in most of the tasks and even surpasses human performance in case of unexpected events such as hardware failures or human operation errors. To best of our knowledge, this is the first work that synthesizes sensor fusion and imitation learning to enable robotic autonomous navigation in the real world without human supervision. version:3
arxiv-1709-10380 | An Empirical Evaluation of Rule Extraction from Recurrent Neural Networks | http://arxiv.org/abs/1709.10380 | id:1709.10380 author:Qinglong Wang, Kaixuan Zhang, Alexander G. Ororbia II, Xinyu Xing, Xue Liu, C. Lee Giles category:cs.LG  published:2017-09-29 summary:Rule extraction from black-box models is critical in domains that require model validation before implementation, as can be the case in credit scoring and medical diagnosis. Though already a challenging problem in statistical learning in general, the difficulty is even greater when highly non-linear, recursive models, like recurrent neural networks (RNNs), are fit to data. Here, we study the extraction of rules from second order recurrent neural networks (RNNs) trained to recognize the Tomita grammars. We show that production rules can be stably extracted from trained RNNs and that in certain cases the rules outperform the trained RNNs. version:2
arxiv-1710-03113 | From Subspaces to Metrics and Beyond: Toward Multi-Diversified Ensemble Clustering of High-Dimensional Data | http://arxiv.org/abs/1710.03113 | id:1710.03113 author:Dong Huang, Chang-Dong Wang, Jian-Huang Lai, Chee-Keong Kwoh category:cs.LG cs.CV  published:2017-10-09 summary:The emergence of high-dimensional data in various areas has brought new challenges to the ensemble clustering research. To deal with the curse of dimensionality, considerable efforts in ensemble clustering have been made by incorporating various subspace-based techniques. Besides the emphasis on subspaces, rather limited attention has been paid to the potential diversity in similarity/dissimilarity metrics. It remains a surprisingly open problem in ensemble clustering how to create and aggregate a large number of diversified metrics, and furthermore, how to jointly exploit the multi-level diversity in the large number of metrics, subspaces, and clusters, in a unified ensemble clustering framework. To tackle this problem, this paper proposes a novel multi-diversified ensemble clustering approach. In particular, we create a large number of diversified metrics by randomizing a scaled exponential similarity kernel, which are then coupled with random subspaces to form a large set of metric-subspace pairs. Based on the similarity matrices derived from these metric-subspace pairs, an ensemble of diversified base clusterings can thereby be constructed. Further, an entropy-based criterion is adopted to explore the cluster-wise diversity in ensembles, based on which the consensus function is therefore presented. Experimental results on twenty high-dimensional datasets have confirmed the superiority of our approach over the state-of-the-art. version:1
arxiv-1710-03112 | Handwritten digit string recognition by combination of residual network and RNN-CTC | http://arxiv.org/abs/1710.03112 | id:1710.03112 author:Hongjian Zhan, Qingqing Wang, Yue Lu category:cs.CV  published:2017-10-09 summary:Recurrent neural network (RNN) and connectionist temporal classification (CTC) have showed successes in many sequence labeling tasks with the strong ability of dealing with the problems where the alignment between the inputs and the target labels is unknown. Residual network is a new structure of convolutional neural network and works well in various computer vision tasks. In this paper, we take advantage of the architectures mentioned above to create a new network for handwritten digit string recognition. First we design a residual network to extract features from input images, then we employ a RNN to model the contextual information within feature sequences and predict recognition results. At the top of this network, a standard CTC is applied to calculate the loss and yield the final results. These three parts compose an end-to-end trainable network. The proposed new architecture achieves the highest performances on ORAND-CAR-A and ORAND-CAR-B with recognition rates 89.75% and 91.14%, respectively. In addition, the experiments on a generated captcha dataset which has much longer string length show the potential of the proposed network to handle long strings. version:1
arxiv-1710-03107 | Verification of Binarized Neural Networks | http://arxiv.org/abs/1710.03107 | id:1710.03107 author:Chih-Hong Cheng, Georg Nührenberg, Harald Ruess category:cs.SE cs.LG cs.LO  published:2017-10-09 summary:We study the problem of formal verification of Binarized Neural Networks (BNN), which have recently been proposed as a power-efficient alternative to more traditional learning networks. More precisely, given a trained BNN and a relation between possible inputs and outputs of this BNN, we develop verification procedures for establishing that the BNN indeed meets this specification for all possible inputs. For solving the verification problem of BNNs we build on well-known methods for hardware verification.The BNN verification problem is first encoded as a combinational miter. In a second step this miter is then transformed into a corresponding propositional satisfiability (SAT) problem. The main contributions of this paper are a number of essential optimizations for making this approach to BNN verification scalable. First, we provide a transformation on fully conntected BNNs for reducing the order of the number of bitwise operations in each layer of the BNN from quadratic to linear. Second, we are identifying redundant computations in a BNN based on {\em optimal factoring} techniques, and we provide transformations on BNNs for avoiding these multiple computations. We prove that the problem of optimal factoring is NP-hard, and we design efficient search procedures for generating approximate solutions of the optimal factoring problem. Third, we design a compositional verification procedure for analyzing each layer of a BNN separately, and for iteratively combining and refining local verification results. We experimentally demonstrate the scalability of our verification techniques to moderately-sized BNNs for embedded applications with thousands of neurons and inputs. version:1
arxiv-1710-03224 | Person Recognition in Social Media Photos | http://arxiv.org/abs/1710.03224 | id:1710.03224 author:Seong Joon Oh, Rodrigo Benenson, Mario Fritz, Bernt Schiele category:cs.CV  published:2017-10-09 summary:People nowadays share large parts of their personal lives through social media. Being able to automatically recognise people in personal photos may greatly enhance user convenience by easing photo album organisation. For human identification task, however, traditional focus of computer vision has been face recognition and pedestrian re-identification. Person recognition in social media photos sets new challenges for computer vision, including non-cooperative subjects (e.g. backward viewpoints, unusual poses) and great changes in appearance. To tackle this problem, we build a simple person recognition framework that leverages convnet features from multiple image regions (head, body, etc.). We propose new recognition scenarios that focus on the time and appearance gap between training and testing samples. We present an in-depth analysis of the importance of different features according to time and viewpoint generalisability. In the process, we verify that our simple approach achieves the state of the art result on the PIPA benchmark, arguably the largest social media based benchmark for person recognition to date with diverse poses, viewpoints, social groups, and events. Compared the conference version of the paper, this paper additionally presents (1) analysis of a face recogniser (DeepID2+), (2) new method naeil2 that combines the conference version method naeil and DeepID2+ to achieve state of the art results even compared to post-conference works, (3) discussion of related work since the conference version, (4) additional analysis including the head viewpoint-wise breakdown of performance, and (5) results on the open-world setup. version:1
arxiv-1710-03077 | Deeper, Broader and Artier Domain Generalization | http://arxiv.org/abs/1710.03077 | id:1710.03077 author:Da Li, Yongxin Yang, Yi-Zhe Song, Timothy M. Hospedales category:cs.CV  published:2017-10-09 summary:The problem of domain generalization is to learn from multiple training domains, and extract a domain-agnostic model that can then be applied to an unseen domain. Domain generalization (DG) has a clear motivation in contexts where there are target domains with distinct characteristics, yet sparse data for training. For example recognition in sketch images, which are distinctly more abstract and rarer than photos. Nevertheless, DG methods have primarily been evaluated on photo-only benchmarks focusing on alleviating the dataset bias where both problems of domain distinctiveness and data sparsity can be minimal. We argue that these benchmarks are overly straightforward, and show that simple deep learning baselines perform surprisingly well on them. In this paper, we make two main contributions: Firstly, we build upon the favorable domain shift-robust properties of deep learning methods, and develop a low-rank parameterized CNN model for end-to-end DG learning. Secondly, we develop a DG benchmark dataset covering photo, sketch, cartoon and painting domains. This is both more practically relevant, and harder (bigger domain shift) than existing benchmarks. The results show that our method outperforms existing DG alternatives, and our dataset provides a more significant DG challenge to drive future research. version:1
arxiv-1710-03070 | full-FORCE: A Target-Based Method for Training Recurrent Networks | http://arxiv.org/abs/1710.03070 | id:1710.03070 author:Brian DePasquale, Christopher J. Cueva, Kanaka Rajan, G. Sean Escola, L. F. Abbott category:cs.NE cs.LG q-bio.NC stat.ML  published:2017-10-09 summary:Trained recurrent networks are powerful tools for modeling dynamic neural computations. We present a target-based method for modifying the full connectivity matrix of a recurrent network to train it to perform tasks involving temporally complex input/output transformations. The method introduces a second network during training to provide suitable "target" dynamics useful for performing the task. Because it exploits the full recurrent connectivity, the method produces networks that perform tasks with fewer neurons and greater noise robustness than traditional least-squares (FORCE) approaches. In addition, we show how introducing additional input signals into the target-generating network, which act as task hints, greatly extends the range of tasks that can be learned and provides control over the complexity and nature of the dynamics of the trained, task-performing network. version:1
arxiv-1709-09902 | Improving Efficiency in Convolutional Neural Network with Multilinear Filters | http://arxiv.org/abs/1709.09902 | id:1709.09902 author:Dat Thanh Tran, Alexandros Iosifidis, Moncef Gabbouj category:cs.CV cs.AI cs.NE  published:2017-09-28 summary:The excellent performance of deep neural networks has enabled us to solve several automatization problems, opening an era of autonomous devices. However, current deep net architectures are heavy with millions of parameters and require billions of floating point operations. Several works have been developed to compress a pre-trained deep network to reduce memory footprint and, possibly, computation. Instead of compressing a pre-trained network, in this work, we propose a generic neural network layer structure employing multilinear projection as the primary feature extractor. The proposed architecture requires several times less memory as compared to the traditional Convolutional Neural Networks (CNN), while inherits the similar design principles of a CNN. In addition, the proposed architecture is equipped with two computation schemes that enable computation reduction or scalability. Experimental results show the effectiveness of our compact projection that outperforms traditional CNN, while requiring far fewer parameters. version:2
arxiv-1710-03059 | Learning Graph Representations with Embedding Propagation | http://arxiv.org/abs/1710.03059 | id:1710.03059 author:Alberto Garcia-Duran, Mathias Niepert category:cs.LG  published:2017-10-09 summary:We propose Embedding Propagation (EP), an unsupervised learning framework for graph-structured data. EP learns vector representations of graphs by passing two types of messages between neighboring nodes. Forward messages consist of label representations such as representations of words and other attributes associated with the nodes. Backward messages consist of gradients that result from aggregating the label representations and applying a reconstruction loss. Node representations are finally computed from the representation of their labels. With significantly fewer parameters and hyperparameters an instance of EP is competitive with and often outperforms state of the art unsupervised and semi-supervised learning methods on a range of benchmark data sets. version:1
arxiv-1710-03035 | Unifying Local and Global Change Detection in Dynamic Networks | http://arxiv.org/abs/1710.03035 | id:1710.03035 author:Wenzhe Li, Dong Guo, Greg Ver Steeg, Aram Galstyan category:cs.LG stat.ML  published:2017-10-09 summary:Many real-world networks are complex dynamical systems, where both local (e.g., changing node attributes) and global (e.g., changing network topology) processes unfold over time. Local dynamics may provoke global changes in the network, and the ability to detect such effects could have profound implications for a number of real-world problems. Most existing techniques focus individually on either local or global aspects of the problem or treat the two in isolation from each other. In this paper we propose a novel network model that simultaneously accounts for both local and global dynamics. To the best of our knowledge, this is the first attempt at modeling and detecting local and global change points on dynamic networks via a unified generative framework. Our model is built upon the popular mixed membership stochastic blockmodels (MMSB) with sparse co-evolving patterns. We derive an efficient stochastic gradient Langevin dynamics (SGLD) sampler for our proposed model, which allows it to scale to potentially very large networks. Finally, we validate our model on both synthetic and real-world data and demonstrate its superiority over several baselines. version:1
arxiv-1705-05154 | Layerwise Systematic Scan: Deep Boltzmann Machines and Beyond | http://arxiv.org/abs/1705.05154 | id:1705.05154 author:Heng Guo, Kaan Kara, Ce Zhang category:cs.LG cs.DS  published:2017-05-15 summary:For Markov chain Monte Carlo methods, one of the greatest discrepancies between theory and system is the scan order - while most theoretical development on the mixing time analysis deals with random updates, real-world systems are implemented with systematic scans. We bridge this gap for models that exhibit a bipartite structure, including, most notably, the Restricted/Deep Boltzmann Machine. The de facto implementation for these models scans variables in a layerwise fashion. We show that the Gibbs sampler with a layerwise alternating scan order has its relaxation time (in terms of epochs) no larger than that of a random-update Gibbs sampler (in terms of variable updates). We also construct examples to show that this bound is asymptotically tight. Through standard inequalities, our result also implies a comparison on the mixing times. version:2
arxiv-1710-03029 | SGD for robot motion? The effectiveness of stochastic optimization on a new benchmark for biped locomotion tasks | http://arxiv.org/abs/1710.03029 | id:1710.03029 author:Martim Brandao, Kenji Hashimoto, Atsuo Takanishi category:cs.RO cs.LG math.OC  published:2017-10-09 summary:Trajectory optimization and posture generation are hard problems in robot locomotion, which can be non-convex and have multiple local optima. Progress on these problems is further hindered by a lack of open benchmarks, since comparisons of different solutions are difficult to make. In this paper we introduce a new benchmark for trajectory optimization and posture generation of legged robots, using a pre-defined scenario, robot and constraints, as well as evaluation criteria. We evaluate state-of-the-art trajectory optimization algorithms based on sequential quadratic programming (SQP) on the benchmark, as well as new stochastic and incremental optimization methods borrowed from the large-scale machine learning literature. Interestingly we show that some of these stochastic and incremental methods, which are based on stochastic gradient descent (SGD), achieve higher success rates than SQP on tough initializations. Inspired by this observation we also propose a new incremental variant of SQP which updates only a random subset of the costs and constraints at each iteration. The algorithm is the best performing in both success rate and convergence speed, improving over SQP by up to 30% in both criteria. The benchmark's resources and a solution evaluation script are made openly available. version:1
arxiv-1710-03027 | A Bottom Up Procedure for Text Line Segmentation of Latin Script | http://arxiv.org/abs/1710.03027 | id:1710.03027 author:Himanshu Jain, Archana Praveen Kumar category:cs.CV 68T45  published:2017-10-09 summary:In this paper we present a bottom up procedure for segmentation of text lines written or printed in the Latin script. The proposed method uses a combination of image morphology, feature extraction and Gaussian mixture model to perform this task. The experimental results show the validity of the procedure. version:1
arxiv-1710-03025 | A Sequential Thinning Algorithm For Multi-Dimensional Binary Patterns | http://arxiv.org/abs/1710.03025 | id:1710.03025 author:Himanshu Jain category:cs.CV 68T10  published:2017-10-09 summary:Thinning is the removal of contour pixels/points of connected components in an image to produce their skeleton with retained connectivity and structural properties. The output requirements of a thinning procedure often vary with application. This paper proposes a sequential algorithm that is very easy to understand and modify based on application to perform the thinning of multi-dimensional binary patterns. The algorithm was tested on 2D and 3D patterns and showed very good results. Moreover, comparisons were also made with two of the state-of-the-art methods used for 2D patterns. The results obtained prove the validity of the procedure. version:1
arxiv-1710-03023 | An automatic deep learning approach for coronary artery calcium segmentation | http://arxiv.org/abs/1710.03023 | id:1710.03023 author:G. Santini, D. Della Latta, N. Martini, G. Valvano, A. Gori, A. Ripoli, C. L. Susini, L. Landini, D. Chiappino category:cs.CV  published:2017-10-09 summary:Coronary artery calcium (CAC) is a significant marker of atherosclerosis and cardiovascular events. In this work we present a system for the automatic quantification of calcium score in ECG-triggered non-contrast enhanced cardiac computed tomography (CT) images. The proposed system uses a supervised deep learning algorithm, i.e. convolutional neural network (CNN) for the segmentation and classification of candidate lesions as coronary or not, previously extracted in the region of the heart using a cardiac atlas. We trained our network with 45 CT volumes; 18 volumes were used to validate the model and 56 to test it. Individual lesions were detected with a sensitivity of 91.24%, a specificity of 95.37% and a positive predicted value (PPV) of 90.5%; comparing calcium score obtained by the system and calcium score manually evaluated by an expert operator, a Pearson coefficient of 0.983 was obtained. A high agreement (Cohen's k = 0.879) between manual and automatic risk prediction was also observed. These results demonstrated that convolutional neural networks can be effectively applied for the automatic segmentation and classification of coronary calcifications. version:1
arxiv-1710-04133 | Driving Behavior Analysis through CAN Bus Data in an Uncontrolled Environment | http://arxiv.org/abs/1710.04133 | id:1710.04133 author:Umberto Fugiglando, Emanuele Massaro, Paolo Santi, Sebastiano Milardo, Kacem Abida, Rainer Stahlmann, Florian Netter, Carlo Ratti category:cs.LG cs.CY physics.data-an  published:2017-10-09 summary:Cars can nowadays record several thousands of signals through the CAN bus technology and potentially provide real-time information on the car, the driver and the surrounding environment. This paper proposes a new method for the analysis and classification of driver behavior using a selected subset of CAN bus signals, specifically gas pedal position, brake pedal pressure, steering wheel angle, steering wheel momentum, velocity, RPM, frontal and lateral acceleration. Data has been collected in a completely uncontrolled experiment, where 64 people drove 10 cars for or a total of over 2000 driving trips without any type of pre-determined driving instruction on a wide variety of road scenarios. We propose an unsupervised learning technique that clusters drivers in different groups, and offers a validation method to test the robustness of clustering in a wide range of experimental settings. The minimal amount of data needed to preserve robust driver clustering is also computed. The presented study provides a new methodology for near-real-time classification of driver behavior in uncontrolled environments. version:1
arxiv-1710-03013 | Distributed Kernel K-Means for Large Scale Clustering | http://arxiv.org/abs/1710.03013 | id:1710.03013 author:Marco Jacopo Ferrarotti, Sergio Decherchi, Walter Rocchia category:cs.DC stat.ML  published:2017-10-09 summary:Clustering samples according to an effective metric and/or vector space representation is a challenging unsupervised learning task with a wide spectrum of applications. Among several clustering algorithms, k-means and its kernelized version have still a wide audience because of their conceptual simplicity and efficacy. However, the systematic application of the kernelized version of k-means is hampered by its inherent square scaling in memory with the number of samples. In this contribution, we devise an approximate strategy to minimize the kernel k-means cost function in which the trade-off between accuracy and velocity is automatically ruled by the available system memory. Moreover, we define an ad-hoc parallelization scheme well suited for hybrid cpu-gpu state-of-the-art parallel architectures. We proved the effectiveness both of the approximation scheme and of the parallelization method on standard UCI datasets and on molecular dynamics (MD) data in the realm of computational chemistry. In this applicative domain, clustering can play a key role for both quantitively estimating kinetics rates via Markov State Models or to give qualitatively a human compatible summarization of the underlying chemical phenomenon under study. For these reasons, we selected it as a valuable real-world application scenario. version:1
arxiv-1710-03608 | CTD: Fast, Accurate, and Interpretable Method for Static and Dynamic Tensor Decompositions | http://arxiv.org/abs/1710.03608 | id:1710.03608 author:Jungwoo Lee, Dongjin Choi, Lee Sael category:cs.NA cs.LG stat.ML  published:2017-10-09 summary:How can we find patterns and anomalies in a tensor, or multi-dimensional array, in an efficient and directly interpretable way? How can we do this in an online environment, where a new tensor arrives each time step? Finding patterns and anomalies in a tensor is a crucial problem with many applications, including building safety monitoring, patient health monitoring, cyber security, terrorist detection, and fake user detection in social networks. Standard PARAFAC and Tucker decomposition results are not directly interpretable. Although a few sampling-based methods have previously been proposed towards better interpretability, they need to be made faster, more memory efficient, and more accurate. In this paper, we propose CTD, a fast, accurate, and directly interpretable tensor decomposition method based on sampling. CTD-S, the static version of CTD, provably guarantees a high accuracy that is 17 ~ 83x more accurate than that of the state-of-the-art method. Also, CTD-S is made 5 ~ 86x faster, and 7 ~ 12x more memory-efficient than the state-of-the-art method by removing redundancy. CTD-D, the dynamic version of CTD, is the first interpretable dynamic tensor decomposition method ever proposed. Also, it is made 2 ~ 3x faster than already fast CTD-S by exploiting factors at previous time step and by reordering operations. With CTD, we demonstrate how the results can be effectively interpreted in the online distributed denial of service (DDoS) attack detection. version:1
arxiv-1710-03011 | Personalized Saliency and its Prediction | http://arxiv.org/abs/1710.03011 | id:1710.03011 author:Yanyu Xu, Junru Wu, Nianyi Li, Shenghua Gao, Jingyi Yu category:cs.CV  published:2017-10-09 summary:Almost all existing visual saliency models focus on predicting a universal saliency map across all observers. Yet psychology studies suggest that visual attention of different observers can vary a lot under some specific circumstances, especially when they view scenes with multiple salient objects. However, few work explores this visual attention difference probably because of lacking a proper dataset, as well as complex correlation between visual attention, personal preferences, and image contents. In this paper, we set out to study this heterogenous visual attention pattern between different observers and build the first dataset for personalized saliency detection. Further, we propose to decompose a personalized saliency map (referred to as PSM) into a universal saliency map (referred to as USM) which can be predicted by any existing saliency detection models and a discrepancy between them. Then personalized saliency detection is casted as the task of discrepancy estimation between PSM and USM. To tackle this task we propose two solutions: i) The discrepancy estimation for different observers are casted as different but related tasks. Then we feed the image and its USM into a multi-task convolutional neural network framework to estimate the discrepancy between PSM and USM for each observer; ii) As the discrepancy is related to both image contents and the observers' person-specific information, we feed the image and its associated USM into a convolutional neural network with person-specific information encoded filters to estimate the discrepancy. Extensive experimental results demonstrate the effectiveness of our models for PSM prediction as well their generalization capability for unseen observers. version:1
arxiv-1710-03006 | Page Stream Segmentation with Convolutional Neural Nets Combining Textual and Visual Features | http://arxiv.org/abs/1710.03006 | id:1710.03006 author:Gregor Wiedemann, Gerhard Heyer category:cs.CL I.5.4  published:2017-10-09 summary:For digitization of paper files via OCR, preservation of document contexts of single scanned images is a major requirement. Page stream segmentation (PSS) is the task to automatically separate a stream of scanned images into multi-page documents. This can be immensely helpful in the context of "digital mailrooms" or retro-digitization of large paper archives. In a digitization project together with a German federal archive, we developed a novel PSS approach based on convolutional neural networks (CNN). Our approach combines image and text features to achieve optimal document separation results. Evaluation shows that our approach achieves accuracies up to 93 % which can be regarded as a new state-of-the-art for this task. version:1
arxiv-1708-06401 | A Tutorial on Hawkes Processes for Events in Social Media | http://arxiv.org/abs/1708.06401 | id:1708.06401 author:Marian-Andrei Rizoiu, Young Lee, Swapnil Mishra, Lexing Xie category:stat.ML cs.SI  published:2017-08-21 summary:This chapter provides an accessible introduction for point processes, and especially Hawkes processes, for modeling discrete, inter-dependent events over continuous time. We start by reviewing the definitions and the key concepts in point processes. We then introduce the Hawkes process, its event intensity function, as well as schemes for event simulation and parameter estimation. We also describe a practical example drawn from social media data - we show how to model retweet cascades using a Hawkes self-exciting process. We presents a design of the memory kernel, and results on estimating parameters and predicting popularity. The code and sample event data are available as an online appendix version:2
arxiv-1708-08487 | On denoising autoencoders trained to minimise binary cross-entropy | http://arxiv.org/abs/1708.08487 | id:1708.08487 author:Antonia Creswell, Kai Arulkumaran, Anil A. Bharath category:cs.CV cs.LG stat.ML  published:2017-08-28 summary:Denoising autoencoders (DAEs) are powerful deep learning models used for feature extraction, data generation and network pre-training. DAEs consist of an encoder and decoder which may be trained simultaneously to minimise a loss (function) between an input and the reconstruction of a corrupted version of the input. There are two common loss functions used for training autoencoders, these include the mean-squared error (MSE) and the binary cross-entropy (BCE). When training autoencoders on image data a natural choice of loss function is BCE, since pixel values may be normalised to take values in [0,1] and the decoder model may be designed to generate samples that take values in (0,1). We show theoretically that DAEs trained to minimise BCE may be used to take gradient steps in the data space towards regions of high probability under the data-generating distribution. Previously this had only been shown for DAEs trained using MSE. As a consequence of the theory, iterative application of a trained DAE moves a data sample from regions of low probability to regions of higher probability under the data-generating distribution. Firstly, we validate the theory by showing that novel data samples, consistent with the training data, may be synthesised when the initial data samples are random noise. Secondly, we motivate the theory by showing that initial data samples synthesised via other methods may be improved via iterative application of a trained DAE to those initial samples. version:2
arxiv-1710-02985 | Age Group and Gender Estimation in the Wild with Deep RoR Architecture | http://arxiv.org/abs/1710.02985 | id:1710.02985 author:Ke Zhang, Ce Gao, Liru Guo, Miao Sun, Xingfang Yuan, Tony X. Han, Zhenbing Zhao, Baogang Li category:cs.CV  published:2017-10-09 summary:Automatically predicting age group and gender from face images acquired in unconstrained conditions is an important and challenging task in many real-world applications. Nevertheless, the conventional methods with manually-designed features on in-the-wild benchmarks are unsatisfactory because of incompetency to tackle large variations in unconstrained images. This difficulty is alleviated to some degree through Convolutional Neural Networks (CNN) for its powerful feature representation. In this paper, we propose a new CNN based method for age group and gender estimation leveraging Residual Networks of Residual Networks (RoR), which exhibits better optimization ability for age group and gender classification than other CNN architectures.Moreover, two modest mechanisms based on observation of the characteristics of age group are presented to further improve the performance of age estimation.In order to further improve the performance and alleviate over-fitting problem, RoR model is pre-trained on ImageNet firstly, and then it is fune-tuned on the IMDB-WIKI-101 data set for further learning the features of face images, finally, it is used to fine-tune on Adience data set. Our experiments illustrate the effectiveness of RoR method for age and gender estimation in the wild, where it achieves better performance than other CNN methods. Finally, the RoR-152+IMDB-WIKI-101 with two mechanisms achieves new state-of-the-art results on Adience benchmark. version:1
arxiv-1710-02984 | Algorithm guided outlining of 105 pancreatic cancer liver metastases in Ultrasound | http://arxiv.org/abs/1710.02984 | id:1710.02984 author:Alexander Hann, Lucas Bettac, Mark M. Haenle, Tilmann Graeter, Andreas W. Berger, Jens Dreyhaupt, Dieter Schmalstieg, Wolfram G. Zoller, Jan Egger category:cs.CV cs.GR  published:2017-10-09 summary:Manual segmentation of hepatic metastases in ultrasound images acquired from patients suffering from pancreatic cancer is common practice. Semiautomatic measurements promising assistance in this process are often assessed using a small number of lesions performed by examiners who already know the algorithm. In this work, we present the application of an algorithm for the segmentation of liver metastases due to pancreatic cancer using a set of 105 different images of metastases. The algorithm and the two examiners had never assessed the images before. The examiners first performed a manual segmentation and, after five weeks, a semiautomatic segmentation using the algorithm. They were satisfied in up to 90% of the cases with the semiautomatic segmentation results. Using the algorithm was significantly faster and resulted in a median Dice similarity score of over 80%. Estimation of the inter-operator variability by using the intra class correlation coefficient was good with 0.8. In conclusion, the algorithm facilitates fast and accurate segmentation of liver metastases, comparable to the current gold standard of manual segmentation. version:1
arxiv-1704-05228 | Sentiment analysis based on rhetorical structure theory: Learning deep neural networks from discourse trees | http://arxiv.org/abs/1704.05228 | id:1704.05228 author:Mathias Kraus, Stefan Feuerriegel category:cs.CL  published:2017-04-18 summary:Prominent applications of sentiment analysis are countless, covering areas such as marketing, customer service and communication. The conventional bag-of-words approach for measuring sentiment merely counts term frequencies; however, it neglects the position of the terms within the discourse. As a remedy, we develop a discourse-aware method that builds upon the discourse structure of documents. For this purpose, we utilize rhetorical structure theory to label (sub-)clauses according to their hierarchical relationships and then assign polarity scores to individual leaves. To learn from the resulting rhetorical structure, we propose a tensor-based, tree-structured deep neural network (named Discourse-LSTM) in order to process the complete discourse tree. The underlying attention mechanism infers the salient passages of narrative materials. In addition, we suggest two algorithms for data augmentation (node reordering and artificial leaf insertion) that increase our training set and reduce overfitting. Our benchmarks demonstrate the superior performance of our approach. Moreover, the attention mechanism reveals the salient text passages and thereby provides explanatory insights. version:2
arxiv-1710-02973 | LD-SDS: Towards an Expressive Spoken Dialogue System based on Linked-Data | http://arxiv.org/abs/1710.02973 | id:1710.02973 author:Alexandros Papangelis, Panagiotis Papadakos, Margarita Kotti, Yannis Stylianou, Yannis Tzitzikas, Dimitris Plexousakis category:cs.IR cs.CL  published:2017-10-09 summary:In this work we discuss the related challenges and describe an approach towards the fusion of state-of-the-art technologies from the Spoken Dialogue Systems (SDS) and the Semantic Web and Information Retrieval domains. We envision a dialogue system named LD-SDS that will support advanced, expressive, and engaging user requests, over multiple, complex, rich, and open-domain data sources that will leverage the wealth of the available Linked Data. Specifically, we focus on: a) improving the identification, disambiguation and linking of entities occurring in data sources and user input; b) offering advanced query services for exploiting the semantics of the data, with reasoning and exploratory capabilities; and c) expanding the typical information seeking dialogue model (slot filling) to better reflect real-world conversational search scenarios. version:1
arxiv-1706-04815 | S-Net: From Answer Extraction to Answer Generation for Machine Reading Comprehension | http://arxiv.org/abs/1706.04815 | id:1706.04815 author:Chuanqi Tan, Furu Wei, Nan Yang, Weifeng Lv, Ming Zhou category:cs.CL  published:2017-06-15 summary:In this paper, we present a novel approach to machine reading comprehension for the MS-MARCO dataset. Unlike the SQuAD dataset that aims to answer a question with exact text spans in a passage, the MS-MARCO dataset defines the task as answering a question from multiple passages and the words in the answer are not necessary in the passages. We therefore develop an extraction-then-synthesis framework to synthesize answers from extraction results. Specifically, the answer extraction model is first employed to predict the most important sub-spans from the passage as evidence, and the answer synthesis model takes the evidence as additional features along with the question and passage to further elaborate the final answers. We build the answer extraction model with state-of-the-art neural networks for single passage reading comprehension, and propose an additional task of passage ranking to help answer extraction in multiple passages. The answer synthesis model is based on the sequence-to-sequence neural networks with extracted evidences as features. Experiments show that our extraction-then-synthesis method outperforms state-of-the-art methods. version:4
arxiv-1710-02952 | Conic Scan-and-Cover algorithms for nonparametric topic modeling | http://arxiv.org/abs/1710.02952 | id:1710.02952 author:Mikhail Yurochkin, Aritra Guha, XuanLong Nguyen category:stat.ML  published:2017-10-09 summary:We propose new algorithms for topic modeling when the number of topics is unknown. Our approach relies on an analysis of the concentration of mass and angular geometry of the topic simplex, a convex polytope constructed by taking the convex hull of vertices representing the latent topics. Our algorithms are shown in practice to have accuracy comparable to a Gibbs sampler in terms of topic estimation, which requires the number of topics be given. Moreover, they are one of the fastest among several state of the art parametric techniques. Statistical consistency of our estimator is established under some conditions. version:1
arxiv-1710-02950 | Maximum Regularized Likelihood Estimators: A General Prediction Theory and Applications | http://arxiv.org/abs/1710.02950 | id:1710.02950 author:Rui Zhuang, Johannes Lederer category:stat.ML math.ST stat.TH  published:2017-10-09 summary:Maximum regularized likelihood estimators (MRLEs) are arguably the most established class of estimators in high-dimensional statistics. In this paper, we derive guarantees for MRLEs in Kullback-Leibler divergence, a general measure of prediction accuracy. We assume only that the densities have a convex parametrization and that the regularization is definite and positive homogenous. The results thus apply to a very large variety of models and estimators, such as tensor regression and graphical models with convex and non-convex regularized methods. A main conclusion is that MRLEs are broadly consistent in prediction - regardless of whether restricted eigenvalues or similar conditions hold. version:1
arxiv-1710-02939 | Does Normalization Methods Play a Role for Hyperspectral Image Classification? | http://arxiv.org/abs/1710.02939 | id:1710.02939 author:Faxian Cao, Zhijing Yang, Jinchang Ren, Mengying Jiang, Wing-Kuen Ling category:cs.CV  published:2017-10-09 summary:For Hyperspectral image (HSI) datasets, each class have their salient feature and classifiers classify HSI datasets according to the class's saliency features, however, there will be different salient features when use different normalization method. In this letter, we report the effect on classifiers by different normalization methods and recommend the best normalization methods for classifier after analyzing the impact of different normalization methods on classifiers. Pavia University datasets, Indian Pines datasets and Kennedy Space Center datasets will apply to several typical classifiers in order to evaluate and analysis the impact of different normalization methods on typical classifiers. version:1
arxiv-1710-02932 | Visual Servoing of Unmanned Surface Vehicle from Small Tethered Unmanned Aerial Vehicle | http://arxiv.org/abs/1710.02932 | id:1710.02932 author:Haresh Karnan, Aritra Biswas, Pranav Vaidik Dhulipala, Jan Dufek, Robin Murphy category:cs.CV cs.RO  published:2017-10-09 summary:This paper presents an algorithm and the implementation of a motor schema to aid the visual localization subsystem of the ongoing EMILY project at Texas A and M University. The EMILY project aims to team an Unmanned Surface Vehicle (USV) with an Unmanned Aerial Vehicle (UAV) to augment the search and rescue of marine casualties during an emergency response phase. The USV is designed to serve as a flotation device once it reaches the victims. A live video feed from the UAV is provided to the casuality responders giving them a visual estimate of the USVs orientation and position to help with its navigation. One of the challenges involved with casualty response using a USV UAV team is to simultaneously control the USV and track it. In this paper, we present an implemented solution to automate the UAV camera movements to keep the USV in view at all times. The motor schema proposed, uses the USVs coordinates from the visual localization subsystem to control the UAVs camera movements and track the USV with minimal camera movements such that the USV is always in the cameras field of view. version:1
arxiv-1710-03222 | Forecasting Across Time Series Databases using Long Short-Term Memory Networks on Groups of Similar Series | http://arxiv.org/abs/1710.03222 | id:1710.03222 author:Kasun Bandara, Christoph Bergmeir, Slawek Smyl category:cs.LG cs.DB econ.EM stat.AP stat.ML  published:2017-10-09 summary:With the advent of Big Data, nowadays in many applications databases containing large quantities of similar time series are available. Forecasting time series in these domains with traditional univariate forecasting procedures leaves great potentials for producing accurate forecasts untapped. Recurrent neural networks, and in particular Long Short-Term Memory (LSTM) networks have proven recently that they are able to outperform state-of-the-art univariate time series forecasting methods in this context, when trained across all available time series. However, if the time series database is heterogeneous accuracy may degenerate, so that on the way towards fully automatic forecasting methods in this space, a notion of similarity between the time series needs to be built into the methods. To this end, we present a prediction model using LSTMs on subgroups of similar time series, which are identified by time series clustering techniques. The proposed methodology is able to consistently outperform the baseline LSTM model, and it achieves competitive results on benchmarking datasets, in particular outperforming all other methods on the CIF2016 dataset. version:1
arxiv-1710-02925 | Natural Language Inference from Multiple Premises | http://arxiv.org/abs/1710.02925 | id:1710.02925 author:Alice Lai, Yonatan Bisk, Julia Hockenmaier category:cs.CL  published:2017-10-09 summary:We define a novel textual entailment task that requires inference over multiple premise sentences. We present a new dataset for this task that minimizes trivial lexical inferences, emphasizes knowledge of everyday events, and presents a more challenging setting for textual entailment. We evaluate several strong neural baselines and analyze how the multiple premise task differs from standard textual entailment. version:1
arxiv-1710-02924 | Enhancing Transparency of Black-box Soft-margin SVM by Integrating Data-based Prior Information | http://arxiv.org/abs/1710.02924 | id:1710.02924 author:Shaohan Chen, Chuanhou Gao, Ping Zhang category:stat.ML cs.LG  published:2017-10-09 summary:The lack of transparency often makes the black-box models difficult to be applied to many practical domains. For this reason, the current work, from the black-box model input port, proposes to incorporate data-based prior information into the black-box soft-margin SVM model to enhance its transparency. The concept and incorporation mechanism of data-based prior information are successively developed, based on which the transparent or partly transparent SVM optimization model is designed and then solved through handily rewriting the optimization problem as a nonlinear quadratic programming problem. An algorithm for mining data-based linear prior information from data set is also proposed, which generates a linear expression with respect to two appropriate inputs identified from all inputs of system. At last, the proposed transparency strategy is applied to eight benchmark examples and two real blast furnace examples for effectiveness exhibition. version:1
arxiv-1710-02914 | Face Sketch Matching via Coupled Deep Transform Learning | http://arxiv.org/abs/1710.02914 | id:1710.02914 author:Shruti Nagpal, Maneet Singh, Richa Singh, Mayank Vatsa, Afzel Noore, Angshul Majumdar category:cs.CV  published:2017-10-09 summary:Face sketch to digital image matching is an important challenge of face recognition that involves matching across different domains. Current research efforts have primarily focused on extracting domain invariant representations or learning a mapping from one domain to the other. In this research, we propose a novel transform learning based approach termed as DeepTransformer, which learns a transformation and mapping function between the features of two domains. The proposed formulation is independent of the input information and can be applied with any existing learned or hand-crafted feature. Since the mapping function is directional in nature, we propose two variants of DeepTransformer: (i) semi-coupled and (ii) symmetrically-coupled deep transform learning. This research also uses a novel IIIT-D Composite Sketch with Age (CSA) variations database which contains sketch images of 150 subjects along with age-separated digital photos. The performance of the proposed models is evaluated on a novel application of sketch-to-sketch matching, along with sketch-to-digital photo matching. Experimental results demonstrate the robustness of the proposed models in comparison to existing state-of-the-art sketch matching algorithms and a commercial face recognition system. version:1
arxiv-1710-02909 | UG^2: a Video Benchmark for Assessing the Impact of Image Restoration andEnhancement on Automatic Visual Recognition | http://arxiv.org/abs/1710.02909 | id:1710.02909 author:Rosaura G. Vidal, Sreya Banerjee, Klemen Grm, Vitomir Struc, Walter J. Scheirer category:cs.CV  published:2017-10-09 summary:Advances in image restoration and enhancement techniques have led to discussion about how such algorithmscan be applied as a pre-processing step to improve automatic visual recognition. In principle, techniques like deblurring and super-resolution should yield improvements by de-emphasizing noise and increasing signal in an input image. But the historically divergent goals of the computational photography and visual recognition communities have created a significant need for more work in this direction. To facilitate new research, we introduce a new benchmark dataset called UG^2, which contains three difficult real-world scenarios: uncontrolled videos taken by UAVs and manned gliders, as well as controlled videos taken on the ground. Over 160,000 annotated frames forhundreds of ImageNet classes are available, which are used for baseline experiments that assess the impact of known and unknown image artifacts and other conditions on common deep learning-based object classification approaches. Further, current image restoration and enhancement techniques are evaluated by determining whether or not theyimprove baseline classification performance. Results showthat there is plenty of room for algorithmic innovation, making this dataset a useful tool going forward. version:1
arxiv-1710-02901 | Response to "Counterexample to global convergence of DSOS and SDSOS hierarchies" | http://arxiv.org/abs/1710.02901 | id:1710.02901 author:Amir Ali Ahmadi, Anirudha Majumdar category:math.OC cs.DS cs.SY stat.ML  published:2017-10-09 summary:In a recent note [8], the author provides a counterexample to the global convergence of what his work refers to as "the DSOS and SDSOS hierarchies" for polynomial optimization problems (POPs) and purports that this refutes claims in our extended abstract [4] and slides in [3]. The goal of this paper is to clarify that neither [4], nor [3], and certainly not our full paper [5], ever defined DSOS or SDSOS hierarchies as it is done in [8]. It goes without saying that no claims about convergence properties of the hierarchies in [8] were ever made as a consequence. What was stated in [4,3] was completely different: we stated that there exist hierarchies based on DSOS and SDSOS optimization that converge. This is indeed true as we discuss in this response. We also emphasize that we were well aware that some (S)DSOS hierarchies do not converge even if their natural SOS counterparts do. This is readily implied by an example in our prior work [5], which makes the counterexample in [8] superfluous. Finally, we provide concrete counterarguments to claims made in [8] that aim to challenge the scalability improvements obtained by DSOS and SDSOS optimization as compared to sum of squares (SOS) optimization. [3] A. A. Ahmadi and A. Majumdar. DSOS and SDSOS: More tractable alternatives to SOS. Slides at the meeting on Geometry and Algebra of Linear Matrix Inequalities, CIRM, Marseille, 2013. [4] A. A. Ahmadi and A. Majumdar. DSOS and SDSOS optimization: LP and SOCP-based alternatives to sum of squares optimization. In proceedings of the 48th annual IEEE Conference on Information Sciences and Systems, 2014. [5] A. A. Ahmadi and A. Majumdar. DSOS and SDSOS optimization: more tractable alternatives to sum of squares and semidefinite optimization. arXiv:1706.02586, 2017. [8] C. Josz. Counterexample to global convergence of DSOS and SDSOS hierarchies. arXiv:1707.02964, 2017. version:1
arxiv-1710-02869 | Using the Value of Information to Explore Stochastic, Discrete Multi-Armed Bandits | http://arxiv.org/abs/1710.02869 | id:1710.02869 author:Isaac J. Sledge, Jose C. Principe category:cs.AI cs.LG stat.ML  published:2017-10-08 summary:In this paper, we propose an information-theoretic exploration strategy for stochastic, discrete multi-armed bandits that achieves optimal regret. Our strategy is based on the value of information criterion. This criterion measures the trade-off between policy information and obtainable rewards. High amounts of policy information are associated with exploration-dominant searches of the space and yield high rewards. Low amounts of policy information favor the exploitation of existing knowledge. Information, in this criterion, is quantified by a parameter that can be varied during search. We demonstrate that a simulated-annealing-like update of this parameter, with a sufficiently fast cooling schedule, leads to an optimal regret that is logarithmic with respect to the number of episodes. version:1
arxiv-1710-02866 | On Matching Skulls to Digital Face Images: A Preliminary Approach | http://arxiv.org/abs/1710.02866 | id:1710.02866 author:Shruti Nagpal, Maneet Singh, Arushi Jain, Richa Singh, Mayank Vatsa, Afzel Noore category:cs.CV  published:2017-10-08 summary:Forensic application of automatically matching skull with face images is an important research area linking biometrics with practical applications in forensics. It is an opportunity for biometrics and face recognition researchers to help the law enforcement and forensic experts in giving an identity to unidentified human skulls. It is an extremely challenging problem which is further exacerbated due to lack of any publicly available database related to this problem. This is the first research in this direction with a two-fold contribution: (i) introducing the first of its kind skull-face image pair database, IdentifyMe, and (ii) presenting a preliminary approach using the proposed semi-supervised formulation of transform learning. The experimental results and comparison with existing algorithms showcase the challenging nature of the problem. We assert that the availability of the database will inspire researchers to build sophisticated skull-to-face matching algorithms. version:1
arxiv-1710-02861 | Clickbait detection using word embeddings | http://arxiv.org/abs/1710.02861 | id:1710.02861 author:Vijayasaradhi Indurthi, Subba Reddy Oota category:cs.CL cs.IR  published:2017-10-08 summary:Clickbait is a pejorative term describing web content that is aimed at generating online advertising revenue, especially at the expense of quality or accuracy, relying on sensationalist headlines or eye-catching thumbnail pictures to attract click-throughs and to encourage forwarding of the material over online social networks. We use distributed word representations of the words in the title as features to identify clickbaits in online news media. We train a machine learning model using linear regression to predict the cickbait score of a given tweet. Our methods achieve an F1-score of 64.98\% and an MSE of 0.0791. Compared to other methods, our method is simple, fast to train, does not require extensive feature engineering and yet moderately effective. version:1
arxiv-1710-02856 | Gender and Ethnicity Classification of Iris Images using Deep Class-Encoder | http://arxiv.org/abs/1710.02856 | id:1710.02856 author:Maneet Singh, Shruti Nagpal, Mayank Vatsa, Richa Singh, Afzel Noore, Angshul Majumdar category:cs.CV  published:2017-10-08 summary:Soft biometric modalities have shown their utility in different applications including reducing the search space significantly. This leads to improved recognition performance, reduced computation time, and faster processing of test samples. Some common soft biometric modalities are ethnicity, gender, age, hair color, iris color, presence of facial hair or moles, and markers. This research focuses on performing ethnicity and gender classification on iris images. We present a novel supervised autoencoder based approach, Deep Class-Encoder, which uses class labels to learn discriminative representation for the given sample by mapping the learned feature vector to its label. The proposed model is evaluated on two datasets each for ethnicity and gender classification. The results obtained using the proposed Deep Class-Encoder demonstrate its effectiveness in comparison to existing approaches and state-of-the-art methods. version:1
arxiv-1710-02855 | The IIT Bombay English-Hindi Parallel Corpus | http://arxiv.org/abs/1710.02855 | id:1710.02855 author:Anoop Kunchukuttan, Pratik Mehta, Pushpak Bhattacharyya category:cs.CL  published:2017-10-08 summary:We present the IIT Bombay English-Hindi Parallel Corpus. The corpus is a compilation of parallel corpora previously available in the public domain as well as new parallel corpora we collected. The corpus contains 1.49 million parallel segments, of which 694k segments were not previously available in the public domain. The corpus has been pre-processed for machine translation, and we report baseline phrase-based SMT and NMT translation results on this corpus. This corpus has been used in two editions of shared tasks at the Workshop on Asian Language Transation (2016 and 2017). The corpus is freely available for non-commercial research. To the best of our knowledge, this is the largest publicly available English-Hindi parallel corpus. version:1
arxiv-1710-02844 | Reconstruction of Hidden Representation for Robust Feature Extraction | http://arxiv.org/abs/1710.02844 | id:1710.02844 author:Zeng Yu, Tianrui Li, Ning Yu, Yi Pan, Hongmei Chen, Bing Liu category:cs.LG cs.CV stat.ML  published:2017-10-08 summary:This paper aims to develop a new and robust approach to feature representation. Motivated by the success of Auto-Encoders, we first theoretical summarize the general properties of all algorithms that are based on traditional Auto-Encoders: 1) The reconstruction error of the input or corrupted input can not be lower than a lower bound, which can be viewed as a guiding principle for reconstructing the input or corrupted input. 2) The reconstruction of a hidden representation achieving its ideal situation is the necessary condition for the reconstruction of the input to reach the ideal state. 3) Minimizing the Frobenius norm of the Jacobian matrix has a deficiency and may result in a much worse local optimum value. 4) Minimizing the reconstruction error of the hidden representation is more robust than minimizing the Frobenius norm of the Jacobian matrix. Based on the above analysis, we propose a new model termed Double Denoising Auto-Encoders (DDAEs), which uses corruption and reconstruction on both the input and the hidden representation. We demonstrate that the proposed model is highly flexible and extensible. We also show that for handling inessential features, our model is more robust than Denoising Auto-Encoders (DAEs). Comparative experiments illustrate that our model is significantly better for representation learning than the state-of-the-art models. version:1
arxiv-1710-02836 | RUM: network Representation learning throUgh Multi-level structural information preservation | http://arxiv.org/abs/1710.02836 | id:1710.02836 author:Yanlei Yu, Zhiwu Lu, Jiajun Liu, Guoping Zhao, Ji-Rong Wen, Kai Zheng category:cs.LG cs.SI  published:2017-10-08 summary:We have witnessed the discovery of many techniques for network representation learning in recent years, ranging from encoding the context in random walks to embedding the lower order connections, to finding latent space representations with auto-encoders. However, existing techniques are looking mostly into the local structures in a network, while higher-level properties such as global community structures are often neglected. We propose a novel network representations learning model framework called RUM (network Representation learning throUgh Multi-level structural information preservation). In RUM, we incorporate three essential aspects of a node that capture a network's characteristics in multiple levels: a node's affiliated local triads, its neighborhood relationships, and its global community affiliations. Therefore the framework explicitly and comprehensively preserves the structural information of a network, extending the encoding process both to the local end of the structural information spectrum and to the global end. The framework is also flexible enough to take various community discovery algorithms as its preprocessor. Empirical results show that the representations learned by RUM have demonstrated substantial performance advantages in real-life tasks. version:1
arxiv-1710-02823 | Structural Feature Selection for Event Logs | http://arxiv.org/abs/1710.02823 | id:1710.02823 author:Markku Hinkka, Teemu Lehto, Keijo Heljanko, Alexander Jung category:cs.LG cs.DB cs.SE stat.ML  published:2017-10-08 summary:We consider the problem of classifying business process instances based on structural features derived from event logs. The main motivation is to provide machine learning based techniques with quick response times for interactive computer assisted root cause analysis. In particular, we create structural features from process mining such as activity and transition occurrence counts, and ordering of activities to be evaluated as potential features for classification. We show that adding such structural features increases the amount of information thus potentially increasing classification accuracy. However, there is an inherent trade-off as using too many features leads to too long run-times for machine learning classification models. One way to improve the machine learning algorithms' run-time is to only select a small number of features by a feature selection algorithm. However, the run-time required by the feature selection algorithm must also be taken into account. Also, the classification accuracy should not suffer too much from the feature selection. The main contributions of this paper are as follows: First, we propose and compare six different feature selection algorithms by means of an experimental setup comparing their classification accuracy and achievable response times. Second, we discuss the potential use of feature selection results for computer assisted root cause analysis as well as the properties of different types of structural features in the context of feature selection. version:1
arxiv-1710-02820 | Micro-Expression Spotting: A Benchmark | http://arxiv.org/abs/1710.02820 | id:1710.02820 author:Xiaopeng Hong, Thuong-Khanh Tran, Guoying Zhao category:cs.CV  published:2017-10-08 summary:Micro-expressions are rapid and involuntary facial expressions, which indicate the suppressed or concealed emotions. Recently, the research on automatic micro-expression (ME) spotting obtains increasing attention. ME spotting is a crucial step prior to further ME analysis tasks. The spotting results can be used as important cues to assist many other human-oriented tasks and thus have many potential applications. In this paper, by investigating existing ME spotting methods, we recognize the immediacy of standardizing the performance evaluation of micro-expression spotting methods. To this end, we construct a micro-expression spotting benchmark (MESB). Firstly, we set up a sliding window based multi-scale evaluation framework. Secondly, we introduce a series of protocols. Thirdly, we also provide baseline results of popular methods. The MESB facilitates the research on ME spotting with fairer and more comprehensive evaluation and also enables to leverage the cutting-edge machine learning tools widely. version:1
arxiv-1709-09686 | Application of a Hybrid Bi-LSTM-CRF model to the task of Russian Named Entity Recognition | http://arxiv.org/abs/1709.09686 | id:1709.09686 author:L. T. Anh, M. Y. Arkhipov, M. S. Burtsev category:cs.CL  published:2017-09-27 summary:Named Entity Recognition (NER) is one of the most common tasks of the natural language processing. The purpose of NER is to find and classify tokens in text documents into predefined categories called tags, such as person names, quantity expressions, percentage expressions, names of locations, organizations, as well as expression of time, currency and others. Although there is a number of approaches have been proposed for this task in Russian language, it still has a substantial potential for the better solutions. In this work, we studied several deep neural network models starting from vanilla Bi-directional Long Short-Term Memory (Bi-LSTM) then supplementing it with Conditional Random Fields (CRF) as well as highway networks and finally adding external word embeddings. All models were evaluated across three datasets: Gareev's dataset, Person-1000, FactRuEval-2016. We found that extension of Bi-LSTM model with CRF significantly increased the quality of predictions. Encoding input tokens with external word embeddings reduced training time and allowed to achieve state of the art for the Russian NER task. version:2
arxiv-1709-08853 | Object-oriented Neural Programming (OONP) for Document Understanding | http://arxiv.org/abs/1709.08853 | id:1709.08853 author:Zhengdong Lu, Haotian Cui, Xianggen Liu, Yukun Yan, Daqi Zheng category:cs.LG cs.AI cs.CL cs.NE  published:2017-09-26 summary:We propose Object-oriented Neural Programming (OONP), a framework for semantically parsing documents in specific domains. Basically, OONP reads a document and parses it into a predesigned object-oriented data structure (referred to as ontology in this paper) that reflects the domain-specific semantics of the document. An OONP parser models semantic parsing as a decision process: a neural net-based Reader sequentially goes through the document, and during the process it builds and updates an intermediate ontology to summarize its partial understanding of the text it covers. OONP supports a rich family of operations (both symbolic and differentiable) for composing the ontology, and a big variety of forms (both symbolic and differentiable) for representing the state and the document. An OONP parser can be trained with supervision of different forms and strength, including supervised learning (SL) , reinforcement learning (RL) and hybrid of the two. Our experiments on both synthetic and real-world document parsing tasks have shown that OONP can learn to handle fairly complicated ontology with training data of modest sizes. version:4
arxiv-1710-01255 | Variational Grid Setting Network | http://arxiv.org/abs/1710.01255 | id:1710.01255 author:Yu-Neng Chuang, Zi-Yu Huang, Yen-Lung Tsai category:cs.CV  published:2017-09-30 summary:We propose a new neural network architecture for automatic generation of missing characters in a Chinese font set. We call the neural network architecture the Variational Grid Setting Network which is based on the variational autoencoder (VAE) with some tweaks. The neural network model is able to generate missing characters relatively large in size ($256 \times 256$ pixels). Moreover, we show that one can use very few samples for training data set, and get a satisfied result. version:2
arxiv-1708-06374 | On a Formal Model of Safe and Scalable Self-driving Cars | http://arxiv.org/abs/1708.06374 | id:1708.06374 author:Shai Shalev-Shwartz, Shaked Shammah, Amnon Shashua category:cs.RO cs.AI stat.ML  published:2017-08-21 summary:In recent years, car makers and tech companies have been racing towards self driving cars. It seems that the main parameter in this race is who will have the first car on the road. The goal of this paper is to add to the equation two additional crucial parameters. The first is standardization of safety assurance --- what are the minimal requirements that every self-driving car must satisfy, and how can we verify these requirements. The second parameter is scalability --- engineering solutions that lead to unleashed costs will not scale to millions of cars, which will push interest in this field into a niche academic corner, and drive the entire field into a "winter of autonomous driving". In the first part of the paper we propose a white-box, interpretable, mathematical model for safety assurance. In the second part we describe a design of a system that adheres to our safety assurance requirements and is scalable to millions of cars. version:2
arxiv-1709-08104 | On Principal Components Regression, Random Projections, and Column Subsampling | http://arxiv.org/abs/1709.08104 | id:1709.08104 author:Martin Slawski category:math.ST stat.ML stat.TH  published:2017-09-23 summary:Principal Components Regression (PCR) is a traditional tool for dimension reduction in linear regression that has been both criticized and defended. One concern about PCR is that obtaining the leading principal components tends to be computationally demanding for large data sets. While random projections do not possess the optimality properties of the leading principal subspace, they are computationally appealing and hence have become increasingly popular in recent years. In this paper, we present an analysis showing that for random projections satisfying a Johnson-Lindenstrauss embedding property, the prediction error in subsequent regression is close to that of PCR, at the expense of requiring a slightly large number of random projections than principal components. Column sub-sampling constitutes an even cheaper way of randomized dimension reduction outside the class of Johnson-Lindenstrauss transforms. We provide numerical results based on synthetic and real data as well as basic theory revealing differences and commonalities in terms of statistical performance. version:2
arxiv-1710-02772 | Smarnet: Teaching Machines to Read and Comprehend Like Human | http://arxiv.org/abs/1710.02772 | id:1710.02772 author:Zheqian Chen, Rongqin Yang, Bin Cao, Zhou Zhao, Deng Cai, Xiaofei He category:cs.CL cs.IR  published:2017-10-08 summary:Machine Comprehension (MC) is a challenging task in Natural Language Processing field, which aims to guide the machine to comprehend a passage and answer the given question. Many existing approaches on MC task are suffering the inefficiency in some bottlenecks, such as insufficient lexical understanding, complex question-passage interaction, incorrect answer extraction and so on. In this paper, we address these problems from the viewpoint of how humans deal with reading tests in a scientific way. Specifically, we first propose a novel lexical gating mechanism to dynamically combine the words and characters representations. We then guide the machines to read in an interactive way with attention mechanism and memory network. Finally we add a checking layer to refine the answer for insurance. The extensive experiments on two popular datasets SQuAD and TriviaQA show that our method exceeds considerable performance than most state-of-the-art solutions at the time of submission. version:1
arxiv-1710-02766 | Bayesian Alignments of Warped Multi-Output Gaussian Processes | http://arxiv.org/abs/1710.02766 | id:1710.02766 author:Markus Kaiser, Clemens Otte, Thomas Runkler, Carl Henrik Ek category:stat.ML cs.LG  published:2017-10-08 summary:We present a Bayesian extension to convolution processes which defines a representation between multiple functions by an embedding in a shared latent space. The proposed model allows for both arbitrary alignments of the inputs and and also non-parametric output warpings to transform the observations. This gives rise to multiple deep Gaussian process models connected via latent generating processes. We derive an efficient variational approximation based on nested variational compression and show how the model can be used to extract shared information between dependent time series, recovering an interpretable functional decomposition of the learning problem. version:1
arxiv-1710-02765 | Protein identification with deep learning: from abc to xyz | http://arxiv.org/abs/1710.02765 | id:1710.02765 author:Ngoc Hieu Tran, Zachariah Levine, Lei Xin, Baozhen Shan, Ming Li category:cs.CE cs.LG q-bio.BM  published:2017-10-08 summary:Proteins are the main workhorses of biological functions in a cell, a tissue, or an organism. Identification and quantification of proteins in a given sample, e.g. a cell type under normal/disease conditions, are fundamental tasks for the understanding of human health and disease. In this paper, we present DeepNovo, a deep learning-based tool to address the problem of protein identification from tandem mass spectrometry data. The idea was first proposed in the context of de novo peptide sequencing [1] in which convolutional neural networks and recurrent neural networks were applied to predict the amino acid sequence of a peptide from its spectrum, a similar task to generating a caption from an image. We further develop DeepNovo to perform sequence database search, the main technique for peptide identification that greatly benefits from numerous existing protein databases. We combine two modules de novo sequencing and database search into a single deep learning framework for peptide identification, and integrate de Bruijn graph assembly technique to offer a complete solution to reconstruct protein sequences from tandem mass spectrometry data. This paper describes a comprehensive protocol of DeepNovo for protein identification, including training neural network models, dynamic programming search, database querying, estimation of false discovery rate, and de Bruijn graph assembly. Training and testing data, model implementations, and comprehensive tutorials in form of IPython notebooks are available in our GitHub repository (https://github.com/nh2tran/DeepNovo). version:1
arxiv-1710-02759 | Keynote: Small Neural Nets Are Beautiful: Enabling Embedded Systems with Small Deep-Neural-Network Architectures | http://arxiv.org/abs/1710.02759 | id:1710.02759 author:Forrest Iandola, Kurt Keutzer category:cs.CV  published:2017-10-07 summary:Over the last five years Deep Neural Nets have offered more accurate solutions to many problems in speech recognition, and computer vision, and these solutions have surpassed a threshold of acceptability for many applications. As a result, Deep Neural Networks have supplanted other approaches to solving problems in these areas, and enabled many new applications. While the design of Deep Neural Nets is still something of an art form, in our work we have found basic principles of design space exploration used to develop embedded microprocessor architectures to be highly applicable to the design of Deep Neural Net architectures. In particular, we have used these design principles to create a novel Deep Neural Net called SqueezeNet that requires as little as 480KB of storage for its model parameters. We have further integrated all these experiences to develop something of a playbook for creating small Deep Neural Nets for embedded systems. version:1
arxiv-1709-08145 | Comparison of Batch Normalization and Weight Normalization Algorithms for the Large-scale Image Classification | http://arxiv.org/abs/1709.08145 | id:1709.08145 author:Igor Gitman, Boris Ginsburg category:cs.CV  published:2017-09-24 summary:Batch normalization (BN) has become a de facto standard for training deep convolutional networks. However, BN accounts for a significant fraction of training run-time and is difficult to accelerate, since it is a memory-bandwidth bounded operation. Such a drawback of BN motivates us to explore recently proposed weight normalization algorithms (WN algorithms), i.e. weight normalization, normalization propagation and weight normalization with translated ReLU. These algorithms don't slow-down training iterations and were experimentally shown to outperform BN on relatively small networks and datasets. However, it is not clear if these algorithms could replace BN in practical, large-scale applications. We answer this question by providing a detailed comparison of BN and WN algorithms using ResNet-50 network trained on ImageNet. We found that although WN achieves better training accuracy, the final test accuracy is significantly lower ($\approx 6\%$) than that of BN. This result demonstrates the surprising strength of the BN regularization effect which we were unable to compensate for using standard regularization techniques like dropout and weight decay. We also found that training of deep networks with WN algorithms is significantly less stable compared to BN, limiting their practical applications. version:2
arxiv-1710-02756 | A New Spectral Clustering Algorithm | http://arxiv.org/abs/1710.02756 | id:1710.02756 author:W. R. Casper, Balu Nadiga category:cs.LG cs.CV physics.geo-ph  published:2017-10-07 summary:We present a new clustering algorithm that is based on searching for natural gaps in the components of the lowest energy eigenvectors of the Laplacian of a graph. In comparing the performance of the proposed method with a set of other popular methods (KMEANS, spectral-KMEANS, and an agglomerative method) in the context of the Lancichinetti-Fortunato-Radicchi (LFR) Benchmark for undirected weighted overlapping networks, we find that the new method outperforms the other spectral methods considered in certain parameter regimes. Finally, in an application to climate data involving one of the most important modes of interannual climate variability, the El Nino Southern Oscillation phenomenon, we demonstrate the ability of the new algorithm to readily identify different flavors of the phenomenon. version:1
arxiv-1710-02754 | Texture Fuzzy Segmentation using Skew Divergence Adaptive Affinity Functions | http://arxiv.org/abs/1710.02754 | id:1710.02754 author:José F. S. Neto, Waldson P. N. Leandro, Matheus A. Gadelha, Tiago S. Santos, Bruno M. Carvalho, Edgar Garduño category:cs.CV cs.AI cs.GR  published:2017-10-07 summary:Digital image segmentation is the process of assigning distinct labels to different objects in a digital image, and the fuzzy segmentation algorithm has been successfully used in the segmentation of images from a wide variety of sources. However, the traditional fuzzy segmentation algorithm fails to segment objects that are characterized by textures whose patterns cannot be successfully described by simple statistics computed over a very restricted area. In this paper, we propose an extension of the fuzzy segmentation algorithm that uses adaptive textural affinity functions to perform the segmentation of such objects on bidimensional images. The adaptive affinity functions compute their appropriate neighborhood size as they compute the texture descriptors surrounding the seed spels (spatial elements), according to the characteristics of the texture being processed. The algorithm then segments the image with an appropriate neighborhood for each object. We performed experiments on mosaic images that were composed using images from the Brodatz database, and compared our results with the ones produced by a recently published texture segmentation algorithm, showing the applicability of our method. version:1
arxiv-1710-02745 | Multi-Document Summarization using Distributed Bag-of-Words Model | http://arxiv.org/abs/1710.02745 | id:1710.02745 author:Kaustubh Mani, Ishan Verma, Lipika Dey category:cs.CL  published:2017-10-07 summary:As the number of documents on the web is growing exponentially, multi-document summarization is becoming more and more important since it can provide the main ideas in a document set in short time. In this paper, we present an unsupervised centroid-based document-level reconstruction framework using distributed bag of words model. Specifically, our approach selects summary sentences in order to minimize the reconstruction error between the summary and the documents. We apply sentence selection and beam search, to further improve the performance of our model. Experimental results show that performance of our model is competitive against the state-of-the-art unsupervised algorithms on standard benchmark datasets. version:1
arxiv-1710-02736 | Beyond Log-concavity: Provable Guarantees for Sampling Multi-modal Distributions using Simulated Tempering Langevin Monte Carlo | http://arxiv.org/abs/1710.02736 | id:1710.02736 author:Rong Ge, Holden Lee, Andrej Risteski category:cs.LG cs.DS stat.ML  published:2017-10-07 summary:A key task in Bayesian statistics is sampling from distributions that are only specified up to a partition function (i.e., constant of proportionality). However, without any assumptions, sampling (even approximately) can be #P-hard, and few works have provided "beyond worst-case" guarantees for such settings. For log-concave distributions, classical results going back to Bakry and \'Emery (1985) show that natural continuous-time Markov chains called Langevin diffusions mix in polynomial time. The most salient feature of log-concavity violated in practice is uni-modality: commonly, the distributions we wish to sample from are multi-modal. In the presence of multiple deep and well-separated modes, Langevin diffusion suffers from torpid mixing. We address this problem by combining Langevin diffusion with simulated tempering. The result is a Markov chain that mixes more rapidly by transitioning between different temperatures of the distribution. We analyze this Markov chain for the canonical multi-modal distribution: a mixture of gaussians (of equal variance). The algorithm based on our Markov chain provably samples from distributions that are close to mixtures of gaussians, given access to the gradient of the log-pdf. For the analysis, we use a spectral decomposition theorem for graphs (Gharan and Trevisan, 2014) and a Markov chain decomposition technique (Madras and Randall, 2002). version:1
arxiv-1710-02728 | Image Identification Using SIFT Algorithm: Performance Analysis against Different Image Deformations | http://arxiv.org/abs/1710.02728 | id:1710.02728 author:Ebrahim Karami, Mohamed Shehata, Andrew Smith category:cs.CV  published:2017-10-07 summary:Image identification is one of the most challenging tasks in different areas of computer vision. Scale-invariant feature transform is an algorithm to detect and describe local features in images to further use them as an image matching criteria. In this paper, the performance of the SIFT matching algorithm against various image distortions such as rotation, scaling, fisheye and motion distortion are evaluated and false and true positive rates for a large number of image pairs are calculated and presented. We also evaluate the distribution of the matched keypoint orientation difference for each image deformation. version:1
arxiv-1710-02726 | Image Matching Using SIFT, SURF, BRIEF and ORB: Performance Comparison for Distorted Images | http://arxiv.org/abs/1710.02726 | id:1710.02726 author:Ebrahim Karami, Siva Prasad, Mohamed Shehata category:cs.CV  published:2017-10-07 summary:Fast and robust image matching is a very important task with various applications in computer vision and robotics. In this paper, we compare the performance of three different image matching techniques, i.e., SIFT, SURF, and ORB, against different kinds of transformations and deformations such as scaling, rotation, noise, fish eye distortion, and shearing. For this purpose, we manually apply different types of transformations on original images and compute the matching evaluation parameters such as the number of key points in images, the matching rate, and the execution time required for each algorithm and we will show that which algorithm is the best more robust against each kind of distortion. Index Terms-Image matching, scale invariant feature transform (SIFT), speed up robust feature (SURF), robust independent elementary features (BRIEF), oriented FAST, rotated BRIEF (ORB). version:1
arxiv-1708-00524 | Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm | http://arxiv.org/abs/1708.00524 | id:1708.00524 author:Bjarke Felbo, Alan Mislove, Anders Søgaard, Iyad Rahwan, Sune Lehmann category:stat.ML cs.LG  published:2017-08-01 summary:NLP tasks are often limited by scarcity of manually annotated data. In social media sentiment analysis and related tasks, researchers have therefore used binarized emoticons and specific hashtags as forms of distant supervision. Our paper shows that by extending the distant supervision to a more diverse set of noisy labels, the models can learn richer representations. Through emoji prediction on a dataset of 1246 million tweets containing one of 64 common emojis we obtain state-of-the-art performance on 8 benchmark datasets within sentiment, emotion and sarcasm detection using a single pretrained model. Our analyses confirm that the diversity of our emotional labels yield a performance improvement over previous distant supervision approaches. version:2
arxiv-1710-02718 | OSU Multimodal Machine Translation System Report | http://arxiv.org/abs/1710.02718 | id:1710.02718 author:Mingbo Ma, Dapeng Li, Kai Zhao, Liang Huang category:cs.CL  published:2017-10-07 summary:This paper describes Oregon State University's submissions to the shared WMT'17 task "multimodal translation task I". In this task, all the sentence pairs are image captions in different languages. The key difference between this task and conventional machine translation is that we have corresponding images as additional information for each sentence pair. In this paper, we introduce a simple but effective system which takes an image shared between different languages, feeding it into the both encoding and decoding side. We report our system's performance for English-French and English-German with Flickr30K (in-domain) and MSCOCO (out-of-domain) datasets. Our system achieves the best performance in TER for English-German for MSCOCO dataset. version:1
arxiv-1710-02717 | Group Sparse CNNs for Question Classification with Answer Sets | http://arxiv.org/abs/1710.02717 | id:1710.02717 author:Mingbo Ma, Liang Huang, Bing Xiang, Bowen Zhou category:cs.CL  published:2017-10-07 summary:Question classification is an important task with wide applications. However, traditional techniques treat questions as general sentences, ignoring the corresponding answer data. In order to consider answer information into question modeling, we first introduce novel group sparse autoencoders which refine question representation by utilizing group information in the answer set. We then propose novel group sparse CNNs which naturally learn question representation with respect to their answers by implanting group sparse autoencoders into traditional CNNs. The proposed model significantly outperform strong baselines on four datasets. version:1
arxiv-1710-00450 | Asymptotic Allocation Rules for a Class of Dynamic Multi-armed Bandit Problems | http://arxiv.org/abs/1710.00450 | id:1710.00450 author:T. W. U. Madhushani, D. H. S. Maithripala, N. E. Leonard category:cs.LG 60-01  published:2017-10-02 summary:This paper presents a class of Dynamic Multi-Armed Bandit problems where the reward can be modeled as the noisy output of a time varying linear stochastic dynamic system that satisfies some boundedness constraints. The class allows many seemingly different problems with time varying option characteristics to be considered in a single framework. It also opens up the possibility of considering many new problems of practical importance. For instance it affords the simultaneous consideration of temporal option unavailabilities and the depen- dencies between options with time varying option characteristics in a seamless manner. We show that, for this class of problems, the combination of any Upper Confidence Bound type algorithm with any efficient reward estimator for the expected reward ensures the logarithmic bounding of the expected cumulative regret. We demonstrate the versatility of the approach by the explicit consideration of a new example of practical interest. version:2
arxiv-1710-02704 | Nonsparse learning with latent variables | http://arxiv.org/abs/1710.02704 | id:1710.02704 author:Zemin Zheng, Jinchi Lv, Wei Lin category:stat.ME math.ST stat.ML stat.TH 62J  published:2017-10-07 summary:As a popular tool for producing meaningful and interpretable models, large-scale sparse learning works efficiently when the underlying structures are indeed or close to sparse. However, naively applying the existing regularization methods can result in misleading outcomes due to model misspecification. In particular, the direct sparsity assumption on coefficient vectors has been questioned in real applications. Therefore, we consider nonsparse learning with the conditional sparsity structure that the coefficient vector becomes sparse after taking out the impacts of certain unobservable latent variables. A new methodology of nonsparse learning with latent variables (NSL) is proposed to simultaneously recover the significant observable predictors and latent factors as well as their effects. We explore a common latent family incorporating population principal components and derive the convergence rates of both sample principal components and their score vectors that hold for a wide class of distributions. With the properly estimated latent variables, properties including model selection consistency and oracle inequalities under various prediction and estimation losses are established for the proposed methodology. Our new methodology and results are evidenced by simulation and real data examples. version:1
arxiv-1710-00886 | Classification of Time-Series Images Using Deep Convolutional Neural Networks | http://arxiv.org/abs/1710.00886 | id:1710.00886 author:Nima Hatami, Yann Gavet, Johan Debayle category:cs.CV  published:2017-10-02 summary:Convolutional Neural Networks (CNN) has achieved a great success in image recognition task by automatically learning a hierarchical feature representation from raw data. While the majority of Time-Series Classification (TSC) literature is focused on 1D signals, this paper uses Recurrence Plots (RP) to transform time-series into 2D texture images and then take advantage of the deep CNN classifier. Image representation of time-series introduces different feature types that are not available for 1D signals, and therefore TSC can be treated as texture image recognition task. CNN model also allows learning different levels of representations together with a classifier, jointly and automatically. Therefore, using RP and CNN in a unified framework is expected to boost the recognition rate of TSC. Experimental results on the UCR time-series classification archive demonstrate competitive accuracy of the proposed approach, compared not only to the existing deep architectures, but also to the state-of-the art TSC algorithms. version:2
arxiv-1710-02650 | Topic Modeling based on Keywords and Context | http://arxiv.org/abs/1710.02650 | id:1710.02650 author:Johannes Schneider category:cs.CL cs.IR cs.LG  published:2017-10-07 summary:Current topic models often suffer from discovering topics not matching human intuition, unnatural switching of topics within documents and high computational demands. We address these concerns by proposing a topic model and an inference algorithm based on automatically identifying characteristic keywords for topics. Keywords influence topic-assignments of nearby words. Our algorithm learns (key)word-topic scores and it self-regulates the number of topics. Inference is simple and easily parallelizable. Qualitative analysis yields comparable results to state-of-the-art models (eg. LDA), but with different strengths and weaknesses. Quantitative analysis using 9 datasets shows gains in terms of classification accuracy, PMI score, computational performance and consistency of topic assignments within documents, while most often using less topics. version:1
arxiv-1709-03082 | A Neural Network Architecture Combining Gated Recurrent Unit (GRU) and Support Vector Machine (SVM) for Intrusion Detection in Network Traffic Data | http://arxiv.org/abs/1709.03082 | id:1709.03082 author:Abien Fred Agarap category:cs.NE cs.CR cs.LG stat.ML  published:2017-09-10 summary:Gated Recurrent Unit (GRU) is a recently-developed variation of the long short-term memory (LSTM) unit, both of which are types of recurrent neural network (RNN). Through empirical evidence, both models have been proven to be effective in a wide variety of machine learning tasks such as natural language processing (Wen et al., 2015), speech recognition (Chorowski et al., 2015), and text classification (Yang et al., 2016). Conventionally, like most neural networks, both of the aforementioned RNN variants employ the Softmax function as its final output layer for its prediction, and the cross-entropy function for computing its loss. In this paper, we present an amendment to this norm by introducing linear support vector machine (SVM) as the replacement for Softmax in the final output layer of a GRU model. Furthermore, the cross-entropy function shall be replaced with a margin-based function. While there have been similar studies (Alalshekmubarak & Smith, 2013; Tang, 2013), this proposal is primarily intended for binary classification on intrusion detection using the 2013 network traffic data from the honeypot systems of Kyoto University. Results show that the GRU-SVM model performs relatively higher than the conventional GRU-Softmax model. The proposed model reached a training accuracy of ~81.54% and a testing accuracy of ~84.15%, while the latter was able to reach a training accuracy of ~63.07% and a testing accuracy of ~70.75%. In addition, the juxtaposition of these two final output layers indicate that the SVM would outperform Softmax in prediction time - a theoretical implication which was supported by the actual training and testing time in the study. version:4
arxiv-1710-02642 | Ranking and Selection with Covariates for Personalized Decision Making | http://arxiv.org/abs/1710.02642 | id:1710.02642 author:Haihui Shen, L. Jeff Hong, Xiaowei Zhang category:stat.ML stat.ME  published:2017-10-07 summary:We consider a ranking and selection problem in the context of personalized decision making, where the best alternative is not universal but varies as a function of observable covariates. The goal of ranking and selection with covariates (R&S-C) is to use sampling to compute a decision rule that can specify the best alternative with certain statistical guarantee for each subsequent individual after observing his or her covariates. A linear model is proposed to capture the relationship between the mean performance of an alternative and the covariates. Under the indifference-zone formulation, we develop two-stage procedures for both homoscedastic and heteroscedastic sampling errors, respectively, and prove their statistical validity, which is defined in terms of probability of correct selection. We also generalize the well-known slippage configuration, and prove that the generalized slippage configuration is the least favorable configuration of our procedures. Extensive numerical experiments are conducted to investigate the performance of the proposed procedures. Finally, we demonstrate the usefulness of R&S-C via a case study of selecting the best treatment regimen in the prevention of esophageal cancer. We find that by leveraging disease-related personal information, R&S-C can improve substantially the expected quality-adjusted life years for some groups of patients through providing patient-specific treatment regimen. version:1
arxiv-1710-00478 | Margin Sample Mining Loss: A Deep Learning Based Method for Person Re-identification | http://arxiv.org/abs/1710.00478 | id:1710.00478 author:Qiqi Xiao, Hao Luo, Chi Zhang category:cs.CV  published:2017-10-02 summary:Person re-identification (ReID) is an important task in computer vision. Recently, deep learning with a metric learning loss has become a common framework for ReID. In this paper, we also propose a new metric learning loss with hard sample mining called margin smaple mining loss (MSML) which can achieve better accuracy compared with other metric learning losses, such as triplet loss. In experi- ments, our proposed methods outperforms most of the state-of-the-art algorithms on Market1501, MARS, CUHK03 and CUHK-SYSU. version:3
arxiv-1710-02619 | Ranking and Selection as Stochastic Control | http://arxiv.org/abs/1710.02619 | id:1710.02619 author:Yijie Peng, Edwin K. P. Chong, Chun-Hung Chen, Michael C. Fu category:cs.LG stat.ML IEEE  published:2017-10-07 summary:Under a Bayesian framework, we formulate the fully sequential sampling and selection decision in statistical ranking and selection as a stochastic control problem, and derive the associated Bellman equation. Using value function approximation, we derive an approximately optimal allocation policy. We show that this policy is not only computationally efficient but also possesses both one-step-ahead and asymptotic optimality for independent normal sampling distributions. Moreover, the proposed allocation policy is easily generalizable in the approximate dynamic programming paradigm. version:1
arxiv-1710-05711 | Deep Self-Paced Learning for Person Re-Identification | http://arxiv.org/abs/1710.05711 | id:1710.05711 author:Sanping Zhou, Jinjun Wang, Deyu Meng, Xiaomeng Xin, Yubing Li, Yihong Gong, Nanning Zheng category:cs.CV cs.LG  published:2017-10-07 summary:Person re-identification (Re-ID) usually suffers from noisy samples with background clutter and mutual occlusion, which makes it extremely difficult to distinguish different individuals across the disjoint camera views. In this paper, we propose a novel deep self-paced learning (DSPL) algorithm to alleviate this problem, in which we apply a self-paced constraint and symmetric regularization to help the relative distance metric training the deep neural network, so as to learn the stable and discriminative features for person Re-ID. Firstly, we propose a soft polynomial regularizer term which can derive the adaptive weights to samples based on both the training loss and model age. As a result, the high-confidence fidelity samples will be emphasized and the low-confidence noisy samples will be suppressed at early stage of the whole training process. Such a learning regime is naturally implemented under a self-paced learning (SPL) framework, in which samples weights are adaptively updated based on both model age and sample loss using an alternative optimization method. Secondly, we introduce a symmetric regularizer term to revise the asymmetric gradient back-propagation derived by the relative distance metric, so as to simultaneously minimize the intra-class distance and maximize the inter-class distance in each triplet unit. Finally, we build a part-based deep neural network, in which the features of different body parts are first discriminately learned in the lower convolutional layers and then fused in the higher fully connected layers. Experiments on several benchmark datasets have demonstrated the superior performance of our method as compared with the state-of-the-art approaches. version:1
arxiv-1710-02615 | A Transfer-Learning Approach for Accelerated MRI using Deep Neural Networks | http://arxiv.org/abs/1710.02615 | id:1710.02615 author:Salman Ul Hassan Dar, Tolga Çukur category:cs.CV  published:2017-10-07 summary:Neural network based architectures have recently been proposed for reconstruction of undersampled MR acquisitions. A deep network containing many free parameters is typically trained using a relatively large set of fully-sampled MRI data, and later used for on-line reconstruction of undersampled data. Ideally network performance should be optimized by drawing the training and testing data from the same domain. In practice, however, large datasets comprising hundreds of subjects scanned under a common protocol are rare. Here, we propose a transfer-learning approach to address the problem of data scarcity in training deep networks for accelerated MRI. The proposed approach trains neural networks using thousands of samples from a public dataset of natural images (ImageNet). The network is then fine-tuned using only few tens of MR images acquired in the testing domain (T1- or T2-weighted MRI). The ImageNet-trained network yields nearly identical reconstructions to networks trained directly in the testing domain using thousands of MR images, and it outperforms conventional compressed sensing reconstructions in terms of image quality. The proposed approach might facilitate the use of neural networks for MRI reconstruction without the need for collection of extensive imaging datasets. version:1
arxiv-1709-10205 | Neural and Synaptic Array Transceiver: A Brain-Inspired Computing Framework for Embedded Learning | http://arxiv.org/abs/1709.10205 | id:1709.10205 author:Georgios Detorakis, Sadique Sheik, Charles Augustine, Somnath Paul, Bruno U. Pedroni, Nikil Dutt, Jeffrey Krichmar, Gert Cauwenberghs, Emre Neftci category:cs.NE cs.AI  published:2017-09-29 summary:Embedded, continual learning for autonomous and adaptive behavior is a key application of neuromorphic hardware designed to mimic the dynamics and architecture of biological neural networks. However, neuromorphic implementations of embedded learning at large scales that are both flexible and efficient have been hindered by a lack of a suitable algorithmic framework. As a result, most neuromorphic hardware are trained off-line on large clusters of dedicated processors or GPUs and transferred post hoc to the device. We address this by introducing the neural and synaptic array transceiver (NSAT), a neuromorphic computational framework facilitating flexible and efficient embedded learning. NSAT supports event-driven supervised, unsupervised and reinforcement learning algorithms including deep learning. We demonstrate the NSAT in a wide range of tasks, including the simulation of Mihalas-Niebur neuron, dynamic neural fields, event-driven random back-propagation for event-based deep learning, event-based contrastive divergence for unsupervised learning, and voltage-based learning rules for sequence learning. We anticipate that this contribution will establish the foundation for a new generation of devices enabling adaptive mobile systems, wearable devices, and robots with data-driven autonomy. version:2
arxiv-1710-02603 | Low-Rank RNN Adaptation for Context-Aware Language Modeling | http://arxiv.org/abs/1710.02603 | id:1710.02603 author:Aaron Jaech, Mari Ostendorf category:cs.CL  published:2017-10-06 summary:A context-aware language model uses location, user and/or domain metadata (context) to adapt its predictions. In neural language models, context information is typically represented as an embedding and it is given to the RNN as an additional input, which has been shown to be useful in many applications. We introduce a more powerful mechanism for using context to adapt an RNN by letting the context vector control a low-rank transformation of the recurrent layer weight matrix. Experiments show that allowing a greater fraction of the model parameters to be adjusted has benefits in terms of perplexity, classification, and generation for several different types of context. version:1
arxiv-1710-02584 | Bag-Level Aggregation for Multiple Instance Active Learning in Instance Classification Problems | http://arxiv.org/abs/1710.02584 | id:1710.02584 author:Marc-André Carbonneau, Eric Granger, Ghyslain Gagnon category:cs.CV  published:2017-10-06 summary:A growing number of applications, e.g. video surveillance and medical image analysis, require training recognition systems from large amounts of weakly annotated data while some targeted interactions with a domain expert are allowed to improve the training process. In such cases, active learning (AL) can reduce labeling costs for training a classifier by querying the expert to provide the labels of most informative instances. This paper focuses on AL methods for instance classification problems in multiple instance learning (MIL), where data is arranged into sets, called bags, that are weakly labeled. Most AL methods focus on single instance learning problems. These methods are not suitable for MIL problems because they cannot account for the bag structure of data. In this paper, new methods for bag-level aggregation of instance informativeness are proposed for multiple instance active learning (MIAL). The \textit{aggregated informativeness} method identifies the most informative instances based on classifier uncertainty, and queries bags incorporating the most information. The other proposed method, called \textit{cluster-based aggregative sampling}, clusters data hierarchically in the instance space. The informativeness of instances is assessed by considering bag labels, inferred instance labels, and the proportion of labels that remain to be discovered in clusters. Both proposed methods significantly outperform reference methods in extensive experiments using benchmark data from several application domains. Results indicate that using an appropriate strategy to address MIAL problems yields a significant reduction in the number of queries needed to achieve the same level of performance as single instance AL methods. version:1
arxiv-1710-01329 | Improving Lexical Choice in Neural Machine Translation | http://arxiv.org/abs/1710.01329 | id:1710.01329 author:Toan Q. Nguyen, David Chiang category:cs.CL  published:2017-10-03 summary:We explore two solutions to the problem of mistranslating rare words in neural machine translation. First, we argue that the standard output layer, which computes the inner product of a vector representing the context with all possible output word embeddings, rewards frequent words disproportionately, and we propose to fix the norms of both vectors to a constant value. Second, we integrate a simple lexical module which is jointly trained with the rest of the model. We evaluate our approaches on eight language pairs with data sizes ranging from 100k to 8M words, and achieve improvements of up to +4.5 BLEU, surpassing phrase-based translation in nearly all settings. version:2
arxiv-1710-02572 | An optimization approach to learning falling rule lists | http://arxiv.org/abs/1710.02572 | id:1710.02572 author:Chaofan Chen, Cynthia Rudin category:cs.LG  published:2017-10-06 summary:A falling rule list is a probabilistic decision list for binary classification, consisting of a series of if-then rules with antecedents in the if clauses and probabilities of the desired outcome ("1") in the then clauses. Just as in a regular decision list, the order of rules in a falling rule list is important -- each example is classified by the first rule whose antecedent it satisfies. Unlike a regular decision list, a falling rule list requires the probabilities of the desired outcome ("1") to be monotonically decreasing down the list. We propose an optimization approach to learning falling rule lists and "softly" falling rule lists, along with Monte-Carlo search algorithms that use bounds on the optimal solution to prune the search space. version:1
arxiv-1710-02569 | Low-resource bilingual lexicon extraction using graph based word embeddings | http://arxiv.org/abs/1710.02569 | id:1710.02569 author:Ximena Gutierrez-Vasques, Victor Mijangos category:cs.CL  published:2017-10-06 summary:In this work we focus on the task of automatically extracting bilingual lexicon for the language pair Spanish-Nahuatl. This is a low-resource setting where only a small amount of parallel corpus is available. Most of the downstream methods do not work well under low-resources conditions. This is specially true for the approaches that use vectorial representations like Word2Vec. Our proposal is to construct bilingual word vectors from a graph. This graph is generated using translation pairs obtained from an unsupervised word alignment method. We show that, in a low-resource setting, these type of vectors are successful in representing words in a bilingual semantic space. Moreover, when a linear transformation is applied to translate words from one language to another, our graph based representations considerably outperform the popular setting that uses Word2Vec. version:1
arxiv-1710-02566 | CAMREP- Concordia Action and Motion Repository | http://arxiv.org/abs/1710.02566 | id:1710.02566 author:Kaustubha Mendhurwar, Qing Gu, Vladimir de la Cruz, Sudhir Mudur, Tiberiu Popa category:cs.CV  published:2017-10-06 summary:Action recognition, motion classification, gait analysis and synthesis are fundamental problems in a number of fields such as computer graphics, bio-mechanics and human computer interaction that generate a large body of research. This type of data is complex because it is inherently multidimensional and has multiple modalities such as video, motion capture data, accelerometer data, etc. While some of this data, such as monocular video are easy to acquire, others are much more difficult and expensive such as motion capture data or multi-view video. This creates a large barrier of entry in the research community for data driven research. We have embarked on creating a new large repository of motion and action data (CAMREP) consisting of several motion and action databases. What makes this database unique is that we use a variety of modalities, enabling multi-modal analysis. Presently, the size of datasets varies with some having a large number of subjects while others having smaller numbers. We have also acquired long capture sequences in a number of cases, making some datasets rather large. version:1
arxiv-1708-00111 | A Continuous Relaxation of Beam Search for End-to-end Training of Neural Sequence Models | http://arxiv.org/abs/1708.00111 | id:1708.00111 author:Kartik Goyal, Graham Neubig, Chris Dyer, Taylor Berg-Kirkpatrick category:cs.LG cs.CL cs.NE I.2.7; I.2.6  published:2017-08-01 summary:Beam search is a desirable choice of test-time decoding algorithm for neural sequence models because it potentially avoids search errors made by simpler greedy methods. However, typical cross entropy training procedures for these models do not directly consider the behaviour of the final decoding method. As a result, for cross-entropy trained models, beam decoding can sometimes yield reduced test performance when compared with greedy decoding. In order to train models that can more effectively make use of beam search, we propose a new training procedure that focuses on the final loss metric (e.g. Hamming loss) evaluated on the output of beam search. While well-defined, this "direct loss" objective is itself discontinuous and thus difficult to optimize. Hence, in our approach, we form a sub-differentiable surrogate objective by introducing a novel continuous approximation of the beam search decoding procedure. In experiments, we show that optimizing this new training objective yields substantially better results on two sequence tasks (Named Entity Recognition and CCG Supertagging) when compared with both cross entropy trained greedy decoding and cross entropy trained beam decoding baselines. version:2
arxiv-1707-02641 | Automated versus do-it-yourself methods for causal inference: Lessons learned from a data analysis competition | http://arxiv.org/abs/1707.02641 | id:1707.02641 author:Vincent Dorie, Jennifer Hill, Uri Shalit, Marc Scott, Dan Cervone category:stat.ME stat.ML  published:2017-07-09 summary:Statisticians have made great strides towards assumption-free estimation of causal estimands in the past few decades. However this explosion in research has resulted in a breadth of inferential strategies that both create opportunities for more reliable inference as well as complicate the choices that an applied researcher has to make and defend. Relatedly, researchers advocating for new methods typically compare their method to (at best) 2 or 3 other causal inference strategies and test using simulations that may or may not be designed to equally tease out flaws in all the competing methods. The causal inference data analysis challenge, "Is Your SATT Where It's At?", launched as part of the 2016 Atlantic Causal Inference Conference, sought to make progress with respect to both of these issues. The researchers creating the data testing grounds were distinct from the researchers submitting methods whose efficacy would be evaluated. Results from 30 competitors across the two versions of the competition (black box algorithms and do-it-yourself analyses) are presented along with post-hoc analyses that reveal information about the characteristics of causal inference strategies and settings that affect performance. The most consistent conclusion was that methods that flexibly model the response surface perform better overall than methods that fail to do so. version:3
arxiv-1710-02560 | The DIRHA-English corpus and related tasks for distant-speech recognition in domestic environments | http://arxiv.org/abs/1710.02560 | id:1710.02560 author:Mirco Ravanelli, Maurizio Omologo category:eess.AS cs.CL cs.SD  published:2017-10-06 summary:This paper introduces the contents and the possible usage of the DIRHA-ENGLISH multi-microphone corpus, recently realized under the EC DIRHA project. The reference scenario is a domestic environment equipped with a large number of microphones and microphone arrays distributed in space. The corpus is composed of both real and simulated material, and it includes 12 US and 12 UK English native speakers. Each speaker uttered different sets of phonetically-rich sentences, newspaper articles, conversational speech, keywords, and commands. From this material, a large set of 1-minute sequences was generated, which also includes typical domestic background noise as well as inter/intra-room reverberation effects. Dev and test sets were derived, which represent a very precious material for different studies on multi-microphone speech processing and distant-speech recognition. Various tasks and corresponding Kaldi recipes have already been developed. The paper reports a first set of baseline results obtained using different techniques, including Deep Neural Networks (DNN), aligned with the state-of-the-art at international level. version:1
arxiv-1710-02543 | Socially-compliant Navigation through Raw Depth Inputs with Generative Adversarial Imitation Learning | http://arxiv.org/abs/1710.02543 | id:1710.02543 author:Lei Tai, Jingwei Zhang, Ming Liu, Wolfram Burgard category:cs.RO cs.AI cs.LG  published:2017-10-06 summary:We present an approach for mobile robots to learn to navigate in pedestrian-rich environments via raw depth inputs, in a social-compliant manner. To achieve this, we adopt a generative adversarial imitation learning (GAIL) strategy for motion planning, which improves upon a supervised policy model pre-trained via behavior cloning. Our approach overcomes the disadvantages of previous methods, as they heavily depend on the full knowledge of the location and velocity information of nearby pedestrians, which not only requires specific sensors but also consumes much computation time for extracting such state information from raw sensor input. In this paper, our proposed GAIL-based model performs directly on raw depth inputs and plans in real-time. Experiments show that our GAIL-based approach greatly improves the behavior of mobile robots from pure behavior cloning both safely and efficiently. Real-world implementation also shows that our method is capable of guiding autonomous vehicles to navigate in a social-compliant manner directly through raw depth inputs. version:1
arxiv-1709-08267 | HDLTex: Hierarchical Deep Learning for Text Classification | http://arxiv.org/abs/1709.08267 | id:1709.08267 author:Kamran Kowsari, Donald E. Brown, Mojtaba Heidarysafa, Kiana Jafari Meimandi, Matthew S. Gerber, Laura E. Barnes category:cs.LG cs.CL cs.IR  published:2017-09-24 summary:The continually increasing number of documents produced each year necessitates ever improving information processing methods for searching, retrieving, and organizing text. Central to these information processing methods is document classification, which has become an important application for supervised learning. Recently the performance of these traditional classifiers has degraded as the number of documents has increased. This is because along with this growth in the number of documents has come an increase in the number of categories. This paper approaches this problem differently from current document classification methods that view the problem as multi-class classification. Instead we perform hierarchical classification using an approach we call Hierarchical Deep Learning for Text classification (HDLTex). HDLTex employs stacks of deep learning architectures to provide specialized understanding at each level of the document hierarchy. version:2
arxiv-1710-02534 | Contrastive Learning for Image Captioning | http://arxiv.org/abs/1710.02534 | id:1710.02534 author:Bo Dai, Dahua Lin category:cs.CV  published:2017-10-06 summary:Image captioning, a popular topic in computer vision, has achieved substantial progress in recent years. However, the distinctiveness of natural descriptions is often overlooked in previous work. It is closely related to the quality of captions, as distinctive captions are more likely to describe images with their unique aspects. In this work, we propose a new learning method, Contrastive Learning (CL), for image captioning. Specifically, via two constraints formulated on top of a reference model, the proposed method can encourage distinctiveness, while maintaining the overall quality of the generated captions. We tested our method on two challenging datasets, where it improves the baseline model by significant margins. We also showed in our studies that the proposed method is generic and can be used for models with various structures. version:1
arxiv-1710-02514 | On the Challenges of Sentiment Analysis for Dynamic Events | http://arxiv.org/abs/1710.02514 | id:1710.02514 author:Monireh Ebrahimi, Amir Hossein Yazdavar, Amit Sheth category:cs.CL  published:2017-10-06 summary:With the proliferation of social media over the last decade, determining people's attitude with respect to a specific topic, document, interaction or events has fueled research interest in natural language processing and introduced a new channel called sentiment and emotion analysis. For instance, businesses routinely look to develop systems to automatically understand their customer conversations by identifying the relevant content to enhance marketing their products and managing their reputations. Previous efforts to assess people's sentiment on Twitter have suggested that Twitter may be a valuable resource for studying political sentiment and that it reflects the offline political landscape. According to a Pew Research Center report, in January 2016 44 percent of US adults stated having learned about the presidential election through social media. Furthermore, 24 percent reported use of social media posts of the two candidates as a source of news and information, which is more than the 15 percent who have used both candidates' websites or emails combined. The first presidential debate between Trump and Hillary was the most tweeted debate ever with 17.1 million tweets. version:1
arxiv-1709-01634 | The Voynich Manuscript is Written in Natural Language: The Pahlavi Hypothesis | http://arxiv.org/abs/1709.01634 | id:1709.01634 author:J. Michael Herrmann category:cs.CL  published:2017-09-06 summary:The late medieval Voynich Manuscript (VM) has resisted decryption and was considered a meaningless hoax or an unsolvable cipher. Here, we provide evidence that the VM is written in natural language by establishing a relation of the Voynich alphabet and the Iranian Pahlavi script. Many of the Voynich characters are upside-down versions of their Pahlavi counterparts, which may be an effect of different writing directions. Other Voynich letters can be explained as ligatures or departures from Pahlavi with the intent to cope with known problems due to the stupendous ambiguity of Pahlavi text. While a translation of the VM text is not attempted here, we can confirm the Voynich-Pahlavi relation at the character level by the transcription of many words from the VM illustrations and from parts of the main text. Many of the transcribed words can be identified as terms from Zoroastrian cosmology which is in line with the use of Pahlavi script in Zoroastrian communities from medieval times. version:2
arxiv-1710-02458 | Machine Learning for Drug Overdose Surveillance | http://arxiv.org/abs/1710.02458 | id:1710.02458 author:Daniel B. Neill, William Herlands category:cs.CY cs.LG stat.ML  published:2017-10-06 summary:We describe two recently proposed machine learning approaches for discovering emerging trends in fatal accidental drug overdoses. The Gaussian Process Subset Scan enables early detection of emerging patterns in spatio-temporal data, accounting for both the non-iid nature of the data and the fact that detecting subtle patterns requires integration of information across multiple spatial areas and multiple time steps. We apply this approach to 17 years of county-aggregated data for monthly opioid overdose deaths in the New York City metropolitan area, showing clear advantages in the utility of discovered patterns as compared to typical anomaly detection approaches. To detect and characterize emerging overdose patterns that differentially affect a subpopulation of the data, including geographic, demographic, and behavioral patterns (e.g., which combinations of drugs are involved), we apply the Multidimensional Tensor Scan to 8 years of case-level overdose data from Allegheny County, PA. We discover previously unidentified overdose patterns which reveal unusual demographic clusters, show impacts of drug legislation, and demonstrate potential for early detection and targeted intervention. These approaches to early detection of overdose patterns can inform prevention and response efforts, as well as understanding the effects of policy changes. version:1
arxiv-1710-02441 | Dictionary-Free MRI PERK: Parameter Estimation via Regression with Kernels | http://arxiv.org/abs/1710.02441 | id:1710.02441 author:Gopal Nataraj, Jon-Fredrik Nielsen, Clayton Scott, Jeffrey A. Fessler category:stat.ML eess.SP physics.med-ph  published:2017-10-06 summary:This paper introduces a fast, general method for dictionary-free parameter estimation in quantitative magnetic resonance imaging (QMRI) via regression with kernels (PERK). PERK first uses prior distributions and the nonlinear MR signal model to simulate many parameter-measurement pairs. Inspired by machine learning, PERK then takes these parameter-measurement pairs as labeled training points and learns from them a nonlinear regression function using kernel functions and convex optimization. PERK admits a simple implementation as per-voxel nonlinear lifting of MRI measurements followed by linear minimum mean-squared error regression. We demonstrate PERK for $T_1,T_2$ estimation, a well-studied application where it is simple to compare PERK estimates against dictionary-based grid search estimates. Numerical simulations as well as single-slice phantom and in vivo experiments demonstrate that PERK and grid search produce comparable $T_1,T_2$ estimates in white and gray matter, but PERK is consistently at least $23\times$ faster. This acceleration factor will increase by several orders of magnitude for full-volume QMRI estimation problems involving more latent parameters per voxel. version:1
arxiv-1710-02437 | Learning Word Embeddings for Hyponymy with Entailment-Based Distributional Semantics | http://arxiv.org/abs/1710.02437 | id:1710.02437 author:James Henderson category:cs.CL  published:2017-10-06 summary:Lexical entailment, such as hyponymy, is a fundamental issue in the semantics of natural language. This paper proposes distributional semantic models which efficiently learn word embeddings for entailment, using a recently-proposed framework for modelling entailment in a vector-space. These models postulate a latent vector for a pseudo-phrase containing two neighbouring word vectors. We investigate both modelling words as the evidence they contribute about this phrase vector, or as the posterior distribution of a one-word phrase vector, and find that the posterior vectors perform better. The resulting word embeddings outperform the best previous results on predicting hyponymy between words, in unsupervised and semi-supervised experiments. version:1
arxiv-1708-09427 | End-to-end Training for Whole Image Breast Cancer Diagnosis using An All Convolutional Design | http://arxiv.org/abs/1708.09427 | id:1708.09427 author:Li Shen category:cs.CV cs.AI stat.ML  published:2017-08-30 summary:We develop an end-to-end training algorithm for whole-image breast cancer diagnosis based on mammograms. It requires lesion annotations only at the first stage of training. After that, a whole image classifier can be trained using only image level labels. This greatly reduced the reliance on lesion annotations. Our approach is implemented using an all convolutional design that is simple yet provides superior performance in comparison with the previous methods. On DDSM, our best single-model achieves a per-image AUC score of 0.88 and three-model averaging increases the score to 0.91. On INbreast, our best single-model achieves a per-image AUC score of 0.96. Based on the same data, our models beat the top-performing teams method from a recent breast cancer diagnosis competition. We also demonstrate that a whole image model trained on DDSM can be easily transferred to INbreast using only a small amount of training data. Code and model availability: https://github.com/lishen/end2end-all-conv version:2
arxiv-1710-02410 | End-to-end Driving via Conditional Imitation Learning | http://arxiv.org/abs/1710.02410 | id:1710.02410 author:Felipe Codevilla, Matthias Müller, Alexey Dosovitskiy, Antonio López, Vladlen Koltun category:cs.RO cs.CV cs.LG  published:2017-10-06 summary:Deep networks trained on demonstrations of human driving have learned to follow roads and avoid obstacles. However, driving policies trained via imitation learning cannot be controlled at test time. A vehicle trained end-to-end to imitate an expert cannot be guided to take a specific turn at an upcoming intersection. This limits the utility of such systems. We propose to condition imitation learning on high-level command input. At test time, the learned driving policy functions as a chauffeur that handles sensorimotor coordination but continues to respond to navigational commands. We evaluate different architectures for conditional imitation learning in vision-based driving. We conduct experiments in realistic three-dimensional simulations of urban driving and on a 1/5 scale robotic truck that is trained to drive in a residential area. Both systems drive based on visual input yet remain responsive to high-level navigational commands. Experimental results demonstrate that the presented approach significantly outperforms a number of baselines. The supplementary video can be viewed at https://youtu.be/cFtnflNe5fM version:1
arxiv-1710-02368 | Accumulated Gradient Normalization | http://arxiv.org/abs/1710.02368 | id:1710.02368 author:Joeri Hermans, Gerasimos Spanakis, Rico Möckel category:stat.ML cs.DC cs.LG  published:2017-10-06 summary:This work addresses the instability in asynchronous data parallel optimization. It does so by introducing a novel distributed optimizer which is able to efficiently optimize a centralized model under communication constraints. The optimizer achieves this by pushing a normalized sequence of first-order gradients to a parameter server. This implies that the magnitude of a worker delta is smaller compared to an accumulated gradient, and provides a better direction towards a minimum compared to first-order gradients, which in turn also forces possible implicit momentum fluctuations to be more aligned since we make the assumption that all workers contribute towards a single minima. As a result, our approach mitigates the parameter staleness problem more effectively since staleness in asynchrony induces (implicit) momentum, and achieves a better convergence rate compared to other optimizers such as asynchronous EASGD and DynSGD, which we show empirically. version:1
arxiv-1710-02365 | Czech Text Document Corpus v 2.0 | http://arxiv.org/abs/1710.02365 | id:1710.02365 author:Pavel Král, Ladislav Lenc category:cs.CL  published:2017-10-06 summary:This paper introduces "Czech Text Document Corpus v 2.0", a collection of text documents for automatic document classification in Czech language. It is composed of 11,955 text documents provided by the Czech News Agency and is freely available for research purposes at http://home.zcu.cz/~pkral/sw.This corpus was created in order to facilitate a~straightforward comparison of the document classification approaches on Czech data. It is particularly dedicated for evaluation of multi-label document classification approaches, because one document is usually labelled with more than one label. Besides the information about the document classes, the corpus is annotated at morphological layer. This paper further shows the results of selected state-of-the-art methods on this corpus to offer the possibility of an easy comparison with these approaches. version:1
arxiv-1709-01073 | Predicting Remaining Useful Life using Time Series Embeddings based on Recurrent Neural Networks | http://arxiv.org/abs/1709.01073 | id:1709.01073 author:Narendhar Gugulothu, Vishnu TV, Pankaj Malhotra, Lovekesh Vig, Puneet Agarwal, Gautam Shroff category:cs.LG  published:2017-09-04 summary:We consider the problem of estimating the remaining useful life (RUL) of a system or a machine from sensor data. Many approaches for RUL estimation based on sensor data make assumptions about how machines degrade. Additionally, sensor data from machines is noisy and often suffers from missing values in many practical settings. We propose Embed-RUL: a novel approach for RUL estimation from sensor data that does not rely on any degradation-trend assumptions, is robust to noise, and handles missing values. Embed-RUL utilizes a sequence-to-sequence model based on Recurrent Neural Networks (RNNs) to generate embeddings for multivariate time series subsequences. The embeddings for normal and degraded machines tend to be different, and are therefore found to be useful for RUL estimation. We show that the embeddings capture the overall pattern in the time series while filtering out the noise, so that the embeddings of two machines with similar operational behavior are close to each other, even when their sensor readings have significant and varying levels of noise content. We perform experiments on publicly available turbofan engine dataset and a proprietary real-world dataset, and demonstrate that Embed-RUL outperforms the previously reported state-of-the-art on several metrics. version:2
arxiv-1710-02338 | Projection Based Weight Normalization for Deep Neural Networks | http://arxiv.org/abs/1710.02338 | id:1710.02338 author:Lei Huang, Xianglong Liu, Bo Lang, Bo Li category:cs.LG cs.AI cs.CV  published:2017-10-06 summary:Optimizing deep neural networks (DNNs) often suffers from the ill-conditioned problem. We observe that the scaling-based weight space symmetry property in rectified nonlinear network will cause this negative effect. Therefore, we propose to constrain the incoming weights of each neuron to be unit-norm, which is formulated as an optimization problem over Oblique manifold. A simple yet efficient method referred to as projection based weight normalization (PBWN) is also developed to solve this problem. PBWN executes standard gradient updates, followed by projecting the updated weight back to Oblique manifold. This proposed method has the property of regularization and collaborates well with the commonly used batch normalization technique. We conduct comprehensive experiments on several widely-used image datasets including CIFAR-10, CIFAR-100, SVHN and ImageNet for supervised learning over the state-of-the-art convolutional neural networks, such as Inception, VGG and residual networks. The results show that our method is able to improve the performance of DNNs with different architectures consistently. We also apply our method to Ladder network for semi-supervised learning on permutation invariant MNIST dataset, and our method outperforms the state-of-the-art methods: we obtain test errors as 2.52%, 1.06%, and 0.91% with only 20, 50, and 100 labeled samples, respectively. version:1
arxiv-1710-02322 | Human Pose Regression by Combining Indirect Part Detection and Contextual Information | http://arxiv.org/abs/1710.02322 | id:1710.02322 author:Diogo C. Luvizon, Hedi Tabia, David Picard category:cs.CV  published:2017-10-06 summary:In this paper, we propose an end-to-end trainable regression approach for human pose estimation from still images. We use the proposed Soft-argmax function to convert feature maps directly to joint coordinates, resulting in a fully differentiable framework. Our method is able to learn heat maps representations indirectly, without additional steps of artificial ground truth generation. Consequently, contextual information can be included to the pose predictions in a seamless way. We evaluated our method on two very challenging datasets, the Leeds Sports Poses (LSP) and the MPII Human Pose datasets, reaching the best performance among all the existing regression methods and comparable results to the state-of-the-art detection based approaches. version:1
arxiv-1710-02318 | A Semantic Relevance Based Neural Network for Text Summarization and Text Simplification | http://arxiv.org/abs/1710.02318 | id:1710.02318 author:Shuming Ma, Xu Sun category:cs.CL  published:2017-10-06 summary:Text summarization and text simplification are two major ways to simplify the text for poor readers, including children, non-native speakers, and the functionally illiterate. Text summarization is to produce a brief summary of the main ideas of the text, while text simplification aims to reduce the linguistic complexity of the text and retain the original meaning. Recently, most approaches for text summarization and text simplification are based on the sequence-to-sequence model, which achieves much success in many text generation tasks. However, although the generated simplified texts are similar to source texts literally, they have low semantic relevance. In this work, our goal is to improve semantic relevance between source texts and simplified texts for text summarization and text simplification. We introduce a Semantic Relevance Based neural model to encourage high semantic similarity between texts and summaries. In our model, the source text is represented by a gated attention encoder, while the summary representation is produced by a decoder. Besides, the similarity score between the representations is maximized during training. Our experiments show that the proposed model outperforms the state-of-the-art systems on two benchmark corpus. version:1
arxiv-1710-02316 | A Multiscale Patch Based Convolutional Network for Brain Tumor Segmentation | http://arxiv.org/abs/1710.02316 | id:1710.02316 author:Jean Stawiaski category:cs.CV q-bio.NC  published:2017-10-06 summary:This article presents a multiscale patch based convolutional neural network for the automatic segmentation of brain tumors in multi-modality 3D MR images. We use multiscale deep supervision and inputs to train a convolutional network. We evaluate the effectiveness of the proposed approach on the BRATS 2017 segmentation challenge where we obtained dice scores of 0.755, 0.900, 0.782 and 95% Hausdorff distance of 3.63mm, 4.10mm, and 6.81mm for enhanced tumor core, whole tumor and tumor core respectively. version:1
arxiv-1710-02310 | Detecting the Moment of Completion: Temporal Models for Localising Action Completion | http://arxiv.org/abs/1710.02310 | id:1710.02310 author:Farnoosh Heidarivincheh, Majid Mirmehdi, Dima Damen category:cs.CV  published:2017-10-06 summary:Action completion detection is the problem of modelling the action's progression towards localising the moment of completion - when the action's goal is confidently considered achieved. In this work, we assess the ability of two temporal models, namely Hidden Markov Models (HMM) and Long-Short Term Memory (LSTM), to localise completion for six object interactions: switch, plug, open, pull, pick and drink. We use a supervised approach, where annotations of pre-completion and post-completion frames are available per action, and fine-tuned CNN features are used to train temporal models. Tested on the Action-Completion-2016 dataset, we detect completion within 10 frames of annotations for ~75% of completed action sequences using both temporal models. Results show that fine-tuned CNN features outperform hand-crafted features for localisation, and that observing incomplete instances is necessary when incomplete sequences are also present in the test set. version:1
arxiv-1710-02298 | Rainbow: Combining Improvements in Deep Reinforcement Learning | http://arxiv.org/abs/1710.02298 | id:1710.02298 author:Matteo Hessel, Joseph Modayil, Hado van Hasselt, Tom Schaul, Georg Ostrovski, Will Dabney, Dan Horgan, Bilal Piot, Mohammad Azar, David Silver category:cs.AI cs.LG  published:2017-10-06 summary:The deep reinforcement learning community has made several independent improvements to the DQN algorithm. However, it is unclear which of these extensions are complementary and can be fruitfully combined. This paper examines six extensions to the DQN algorithm and empirically studies their combination. Our experiments show that the combination provides state-of-the-art performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. We also provide results from a detailed ablation study that shows the contribution of each component to overall performance. version:1
arxiv-1710-02286 | Deep Convolutional Neural Networks as Generic Feature Extractors | http://arxiv.org/abs/1710.02286 | id:1710.02286 author:Lars Hertel, Erhardt Barth, Thomas Käster, Thomas Martinetz category:cs.CV cs.LG cs.NE  published:2017-10-06 summary:Recognizing objects in natural images is an intricate problem involving multiple conflicting objectives. Deep convolutional neural networks, trained on large datasets, achieve convincing results and are currently the state-of-the-art approach for this task. However, the long time needed to train such deep networks is a major drawback. We tackled this problem by reusing a previously trained network. For this purpose, we first trained a deep convolutional network on the ILSVRC2012 dataset. We then maintained the learned convolution kernels and only retrained the classification part on different datasets. Using this approach, we achieved an accuracy of 67.68 % on CIFAR-100, compared to the previous state-of-the-art result of 65.43 %. Furthermore, our findings indicate that convolutional networks are able to learn generic feature extractors that can be used for different tasks. version:1
arxiv-1710-02277 | Efficient K-Shot Learning with Regularized Deep Networks | http://arxiv.org/abs/1710.02277 | id:1710.02277 author:Donghyun Yoo, Haoqi Fan, Vishnu Naresh Boddeti, Kris M. Kitani category:cs.CV cs.LG stat.ML  published:2017-10-06 summary:Feature representations from pre-trained deep neural networks have been known to exhibit excellent generalization and utility across a variety of related tasks. Fine-tuning is by far the simplest and most widely used approach that seeks to exploit and adapt these feature representations to novel tasks with limited data. Despite the effectiveness of fine-tuning, itis often sub-optimal and requires very careful optimization to prevent severe over-fitting to small datasets. The problem of sub-optimality and over-fitting, is due in part to the large number of parameters used in a typical deep convolutional neural network. To address these problems, we propose a simple yet effective regularization method for fine-tuning pre-trained deep networks for the task of k-shot learning. To prevent overfitting, our key strategy is to cluster the model parameters while ensuring intra-cluster similarity and inter-cluster diversity of the parameters, effectively regularizing the dimensionality of the parameter search space. In particular, we identify groups of neurons within each layer of a deep network that shares similar activation patterns. When the network is to be fine-tuned for a classification task using only k examples, we propagate a single gradient to all of the neuron parameters that belong to the same group. The grouping of neurons is non-trivial as neuron activations depend on the distribution of the input data. To efficiently search for optimal groupings conditioned on the input data, we propose a reinforcement learning search strategy using recurrent networks to learn the optimal group assignments for each network layer. Experimental results show that our method can be easily applied to several popular convolutional neural networks and improve upon other state-of-the-art fine-tuning based k-shot learning strategies by more than10% version:1
arxiv-1710-02086 | Indowordnets help in Indian Language Machine Translation | http://arxiv.org/abs/1710.02086 | id:1710.02086 author:Sreelekha S, Pushpak Bhattacharyya category:cs.CL  published:2017-10-05 summary:Being less resource languages, Indian-Indian and English-Indian language MT system developments faces the difficulty to translate various lexical phenomena. In this paper, we present our work on a comparative study of 440 phrase-based statistical trained models for 110 language pairs across 11 Indian languages. We have developed 110 baseline Statistical Machine Translation systems. Then we have augmented the training corpus with Indowordnet synset word entries of lexical database and further trained 110 models on top of the baseline system. We have done a detailed performance comparison using various evaluation metrics such as BLEU score, METEOR and TER. We observed significant improvement in evaluations of translation quality across all the 440 models after using the Indowordnet. These experiments give a detailed insight in two ways : (1) usage of lexical database with synset mapping for resource poor languages (2) efficient usage of Indowordnet sysnset mapping. More over, synset mapped lexical entries helped the SMT system to handle the ambiguity to a great extent during the translation. version:2
arxiv-1710-02268 | Discovering Playing Patterns: Time Series Clustering of Free-To-Play Game Data | http://arxiv.org/abs/1710.02268 | id:1710.02268 author:Alain Saas, Anna Guitart, África Periáñez category:stat.ML cs.LG  published:2017-10-06 summary:The classification of time series data is a challenge common to all data-driven fields. However, there is no agreement about which are the most efficient techniques to group unlabeled time-ordered data. This is because a successful classification of time series patterns depends on the goal and the domain of interest, i.e. it is application-dependent. In this article, we study free-to-play game data. In this domain, clustering similar time series information is increasingly important due to the large amount of data collected by current mobile and web applications. We evaluate which methods cluster accurately time series of mobile games, focusing on player behavior data. We identify and validate several aspects of the clustering: the similarity measures and the representation techniques to reduce the high dimensionality of time series. As a robustness test, we compare various temporal datasets of player activity from two free-to-play video-games. With these techniques we extract temporal patterns of player behavior relevant for the evaluation of game events and game-business diagnosis. Our experiments provide intuitive visualizations to validate the results of the clustering and to determine the optimal number of clusters. Additionally, we assess the common characteristics of the players belonging to the same group. This study allows us to improve the understanding of player dynamics and churn behavior. version:1
arxiv-1710-02266 | Eigen-Distortions of Hierarchical Representations | http://arxiv.org/abs/1710.02266 | id:1710.02266 author:Alexander Berardino, Johannes Ballé, Valero Laparra, Eero P. Simoncelli category:cs.CV  published:2017-10-06 summary:We develop a method for comparing hierarchical image representations in terms of their ability to explain perceptual sensitivity in humans. Specifically, we utilize Fisher information to establish a model-derived prediction of sensitivity to local perturbations around a given natural image. For a given image, we compute the eigenvectors of the Fisher information matrix with largest and smallest eigenvalues, corresponding to the model-predicted most- and least-noticeable image distortions, respectively. For human subjects, we then measure the amount of each distortion that can be reliably detected when added to the image, and compare these thresholds to the predictions of the corresponding model. We use this method to test the ability of a variety of representations to mimic human perceptual sensitivity. We find that the early layers of VGG16, a deep neural network optimized for object recognition, provide a better match to human perception than later layers, and a better match than a 4-stage convolutional neural network (CNN) trained on a database of human ratings of distorted image quality. On the other hand, we find that simple models of early visual processing, incorporating one or more stages of local gain control, trained on the same database of distortion ratings, provide substantially better predictions of human sensitivity than both the CNN and all layers of VGG16. version:1
arxiv-1710-02264 | Churn Prediction in Mobile Social Games: Towards a Complete Assessment Using Survival Ensembles | http://arxiv.org/abs/1710.02264 | id:1710.02264 author:África Periáñez, Alain Saas, Anna Guitart, Colin Magne category:stat.ML  published:2017-10-06 summary:Reducing user attrition, i.e. churn, is a broad challenge faced by several industries. In mobile social games, decreasing churn is decisive to increase player retention and rise revenues. Churn prediction models allow to understand player loyalty and to anticipate when they will stop playing a game. Thanks to these predictions, several initiatives can be taken to retain those players who are more likely to churn. Survival analysis focuses on predicting the time of occurrence of a certain event, churn in our case. Classical methods, like regressions, could be applied only when all players have left the game. The challenge arises for datasets with incomplete churning information for all players, as most of them still connect to the game. This is called a censored data problem and is in the nature of churn. Censoring is commonly dealt with survival analysis techniques, but due to the inflexibility of the survival statistical algorithms, the accuracy achieved is often poor. In contrast, novel ensemble learning techniques, increasingly popular in a variety of scientific fields, provide high-class prediction results. In this work, we develop, for the first time in the social games domain, a survival ensemble model which provides a comprehensive analysis together with an accurate prediction of churn. For each player, we predict the probability of churning as function of time, which permits to distinguish various levels of loyalty profiles. Additionally, we assess the risk factors that explain the predicted player survival times. Our results show that churn prediction by survival ensembles significantly improves the accuracy and robustness of traditional analyses, like Cox regression. version:1
arxiv-1710-02262 | Games and Big Data: A Scalable Multi-Dimensional Churn Prediction Model | http://arxiv.org/abs/1710.02262 | id:1710.02262 author:Paul Bertens, Anna Guitart, África Periáñez category:stat.ML  published:2017-10-06 summary:The emergence of mobile games has caused a paradigm shift in the video-game industry. Game developers now have at their disposal a plethora of information on their players, and thus can take advantage of reliable models that can accurately predict player behavior and scale to huge datasets. Churn prediction, a challenge common to a variety of sectors, is particularly relevant for the mobile game industry, as player retention is crucial for the successful monetization of a game. In this article, we present an approach to predicting game abandon based on survival ensembles. Our method provides accurate predictions on both the level at which each player will leave the game and their accumulated playtime until that moment. Further, it is robust to different data distributions and applicable to a wide range of response variables, while also allowing for efficient parallelization of the algorithm. This makes our model well suited to perform real-time analyses of churners, even for games with millions of daily active users. version:1
arxiv-1710-02260 | FPGA based Parallelized Architecture of Efficient Graph based Image Segmentation Algorithm | http://arxiv.org/abs/1710.02260 | id:1710.02260 author:Roopal Nahar, Akanksha Baranwal, K. Madhava Krishna category:cs.CV cs.DC  published:2017-10-06 summary:Efficient and real time segmentation of color images has a variety of importance in many fields of computer vision such as image compression, medical imaging, mapping and autonomous navigation. Being one of the most computationally expensive operation, it is usually done through software imple- mentation using high-performance processors. In robotic systems, however, with the constrained platform dimensions and the need for portability, low power consumption and simultaneously the need for real time image segmentation, we envision hardware parallelism as the way forward to achieve higher acceleration. Field-programmable gate arrays (FPGAs) are among the best suited for this task as they provide high computing power in a small physical area. They exceed the computing speed of software based implementations by breaking the paradigm of sequential execution and accomplishing more per clock cycle operations by enabling hardware level parallelization at an architectural level. In this paper, we propose three novel architectures of a well known Efficient Graph based Image Segmentation algorithm. These proposed implementations optimizes time and power consumption when compared to software implementations. The hybrid design proposed, has notable furtherance of acceleration capabilities delivering atleast 2X speed gain over other implemen- tations, which henceforth allows real time image segmentation that can be deployed on Mobile Robotic systems. version:1
arxiv-1710-02254 | Lattice Recurrent Unit: Improving Convergence and Statistical Efficiency for Sequence Modeling | http://arxiv.org/abs/1710.02254 | id:1710.02254 author:Chaitanya Ahuja, Louis-Phillipe Morency category:cs.LG cs.AI cs.NE  published:2017-10-06 summary:Recurrent neural networks have shown remarkable success in modeling sequences. However low resource situations still adversely affect the generalizability of these models. We introduce a new family of models, called Lattice Recurrent Units (LRU), to address the challenge of learning deep multi-layer recurrent models with limited resources. LRU models achieve this goal by creating distinct (but coupled) flow of information inside the units: a first flow along time dimension and a second flow along depth dimension. It also offers a symmetry in how information can flow horizontally and vertically. We analyze the effects of decoupling three different components of our LRU model: Reset Gate, Update Gate and Projected State. We evaluate this family on new LRU models on computational convergence rates and statistical efficiency. Our experiments are performed on four publicly-available datasets, comparing with Grid-LSTM and Recurrent Highway networks. Our results show that LRU has better empirical computational convergence rates and statistical efficiency values, along with learning more accurate language models. version:1
arxiv-1710-02248 | Learnable Explicit Density for Continuous Latent Space and Variational Inference | http://arxiv.org/abs/1710.02248 | id:1710.02248 author:Chin-Wei Huang, Ahmed Touati, Laurent Dinh, Michal Drozdzal, Mohammad Havaei, Laurent Charlin, Aaron Courville category:cs.LG cs.AI stat.ML  published:2017-10-06 summary:In this paper, we study two aspects of the variational autoencoder (VAE): the prior distribution over the latent variables and its corresponding posterior. First, we decompose the learning of VAEs into layerwise density estimation, and argue that having a flexible prior is beneficial to both sample generation and inference. Second, we analyze the family of inverse autoregressive flows (inverse AF) and show that with further improvement, inverse AF could be used as universal approximation to any complicated posterior. Our analysis results in a unified approach to parameterizing a VAE, without the need to restrict ourselves to use factorial Gaussians in the latent real space. version:1
arxiv-1710-02242 | Solving differential equations with unknown constitutive relations as recurrent neural networks | http://arxiv.org/abs/1710.02242 | id:1710.02242 author:Tobias Hagge, Panos Stinis, Enoch Yeung, Alexandre M. Tartakovsky category:cs.LG math.NA  published:2017-10-06 summary:We solve a system of ordinary differential equations with an unknown functional form of a sink (reaction rate) term. We assume that the measurements (time series) of state variables are partially available, and we use recurrent neural network to "learn" the reaction rate from this data. This is achieved by including a discretized ordinary differential equations as part of a recurrent neural network training problem. We extend TensorFlow's recurrent neural network architecture to create a simple but scalable and effective solver for the unknown functions, and apply it to a fedbatch bioreactor simulation problem. Use of techniques from recent deep learning literature enables training of functions with behavior manifesting over thousands of time steps. Our networks are structurally similar to recurrent neural networks, but differences in design and function require modifications to the conventional wisdom about training such networks. version:1
arxiv-1710-02238 | How Much Chemistry Does a Deep Neural Network Need to Know to Make Accurate Predictions? | http://arxiv.org/abs/1710.02238 | id:1710.02238 author:Garrett B. Goh, Charles Siegel, Abhinav Vishnu, Nathan O. Hodas, Nathan Baker category:stat.ML cs.AI cs.CV cs.LG  published:2017-10-05 summary:In the last few years, we have seen the rise of deep learning applications in a broad range of chemistry research problems. Recently, we reported on the development of Chemception, a deep convolutional neural network (CNN) architecture for general-purpose small molecule property prediction. In this work, we investigate the effects of systematically removing and adding basic chemical information to the image channels of the 2D images used to train Chemception. By augmenting images with only 3 additional basic chemical information, we demonstrate that Chemception now outperforms contemporary deep learning models trained on more sophisticated chemical representations (molecular fingerprints) for the prediction of toxicity, activity, and solvation free energy, as well as physics-based free energy simulation methods. Thus, our work demonstrates that a firm grasp of first-principles chemical knowledge is not a pre-requisite for deep learning models to accurately predict chemical properties. Lastly, by altering the chemical information content in the images, and examining the resulting performance of Chemception, we also identify two different learning patterns in predicting toxicity/activity as compared to solvation free energy, and these patterns suggest that Chemception is learning about its tasks in the manner that is consistent with established knowledge. version:1
arxiv-1710-02236 | Primal-Dual Optimization Algorithms over Riemannian Manifolds: an Iteration Complexity Analysis | http://arxiv.org/abs/1710.02236 | id:1710.02236 author:Junyu Zhang, Shiqian Ma, Shuzhong Zhang category:math.OC stat.ML  published:2017-10-05 summary:In this paper we study nonconvex and nonsmooth multi-block optimization over Riemannian manifolds with coupled linear constraints. Such optimization problems naturally arise from machine learning, statistical learning, compressive sensing, image processing, and tensor PCA, among others. We develop an ADMM-like primal-dual approach based on decoupled solvable subroutines such as linearized proximal mappings. First, we introduce the optimality conditions for the afore-mentioned optimization models. Then, the notion of $\epsilon$-stationary solutions is introduced as a result. The main part of the paper is to show that the proposed algorithms enjoy an iteration complexity of $O(1/\epsilon^2)$ to reach an $\epsilon$-stationary solution. For prohibitively large-size tensor or machine learning models, we present a sampling-based stochastic algorithm with the same iteration complexity bound in expectation. In case the subproblems are not analytically solvable, a feasible curvilinear line-search variant of the algorithm based on retraction operators is proposed. Finally, we show specifically how the algorithms can be implemented to solve a variety of practical problems such as the NP-hard maximum bisection problem, the $\ell_q$ regularized sparse tensor principal component analysis and the community detection problem. Our preliminary numerical results show great potentials of the proposed methods. version:1
arxiv-1710-02224 | Dilated Recurrent Neural Networks | http://arxiv.org/abs/1710.02224 | id:1710.02224 author:Shiyu Chang, Yang Zhang, Wei Han, Mo Yu, Xiaoxiao Guo, Wei Tan, Xiaodong Cui, Michael Witbrock, Mark Hasegawa-Johnson, Thomas Huang category:cs.AI cs.LG  published:2017-10-05 summary:Notoriously, learning with recurrent neural networks (RNNs) on long sequences is a difficult task. There are three major challenges: 1) extracting complex dependencies, 2) vanishing and exploding gradients, and 3) efficient parallelization. In this paper, we introduce a simple yet effective RNN connection structure, the DILATEDRNN, which simultaneously tackles all these challenges. The proposed architecture is characterized by multi-resolution dilated recurrent skip connections and can be combined flexibly with different RNN cells. Moreover, the DILATEDRNN reduces the number of parameters and enhances training efficiency significantly, while matching state-of-the-art performance (even with Vanilla RNN cells) in tasks involving very long-term dependencies. To provide a theory-based quantification of the architecture's advantages, we introduce a memory capacity measure - the mean recurrent length, which is more suitable for RNNs with long skip connections than existing measures. We rigorously prove the advantages of the DILATEDRNN over other recurrent neural architectures. version:1
arxiv-1710-02221 | Stacked Structure Learning for Lifted Relational Neural Networks | http://arxiv.org/abs/1710.02221 | id:1710.02221 author:Gustav Sourek, Martin Svatos, Filip Zelezny, Steven Schockaert, Ondrej Kuzelka category:cs.LG cs.AI stat.ML  published:2017-10-05 summary:Lifted Relational Neural Networks (LRNNs) describe relational domains using weighted first-order rules which act as templates for constructing feed-forward neural networks. While previous work has shown that using LRNNs can lead to state-of-the-art results in various ILP tasks, these results depended on hand-crafted rules. In this paper, we extend the framework of LRNNs with structure learning, thus enabling a fully automated learning process. Similarly to many ILP methods, our structure learning algorithm proceeds in an iterative fashion by top-down searching through the hypothesis space of all possible Horn clauses, considering the predicates that occur in the training examples as well as invented soft concepts entailed by the best weighted rules found so far. In the experiments, we demonstrate the ability to automatically induce useful hierarchical soft concepts leading to deep LRNNs with a competitive predictive power. version:1
arxiv-1710-02213 | Video Denoising and Enhancement via Dynamic Video Layering | http://arxiv.org/abs/1710.02213 | id:1710.02213 author:Han Guo, Namrata Vaswani category:cs.CV  published:2017-10-05 summary:Video denoising refers to the problem of removing "noise" from a video sequence. Here the term "noise" is used in a broad sense to refer to any corruption or outlier or interference that is not the quantity of interest. In this work, we develop a novel approach to video denoising that is based on the idea that many noisy or corrupted videos can be split into three parts - the "low-rank layer", the "sparse layer", and a small residual (which is small and bounded). We show, using extensive experiments, that our denoising approach outperforms the state-of-the-art denoising algorithms. version:1
arxiv-1710-01614 | Constructing multi-modality and multi-classifier radiomics predictive models through reliable classifier fusion | http://arxiv.org/abs/1710.01614 | id:1710.01614 author:Zhiguo Zhou, Zhi-Jie Zhou, Hongxia Hao, Shulong Li, Xi Chen, You Zhang, Michael Folkert, Jing Wang category:cs.LG physics.med-ph stat.ML  published:2017-10-04 summary:Radiomics aims to extract and analyze large numbers of quantitative features from medical images and is highly promising in staging, diagnosing, and predicting outcomes of cancer treatments. Nevertheless, several challenges need to be addressed to construct an optimal radiomics predictive model. First, the predictive performance of the model may be reduced when features extracted from an individual imaging modality are blindly combined into a single predictive model. Second, because many different types of classifiers are available to construct a predictive model, selecting an optimal classifier for a particular application is still challenging. In this work, we developed multi-modality and multi-classifier radiomics predictive models that address the aforementioned issues in currently available models. Specifically, a new reliable classifier fusion strategy was proposed to optimally combine output from different modalities and classifiers. In this strategy, modality-specific classifiers were first trained, and an analytic evidential reasoning (ER) rule was developed to fuse the output score from each modality to construct an optimal predictive model. One public data set and two clinical case studies were performed to validate model performance. The experimental results indicated that the proposed ER rule based radiomics models outperformed the traditional models that rely on a single classifier or simply use combined features from different modalities. version:2
arxiv-1710-02196 | Porcupine Neural Networks: (Almost) All Local Optima are Global | http://arxiv.org/abs/1710.02196 | id:1710.02196 author:Soheil Feizi, Hamid Javadi, Jesse Zhang, David Tse category:stat.ML cs.LG  published:2017-10-05 summary:Neural networks have been used prominently in several machine learning and statistics applications. In general, the underlying optimization of neural networks is non-convex which makes their performance analysis challenging. In this paper, we take a novel approach to this problem by asking whether one can constrain neural network weights to make its optimization landscape have good theoretical properties while at the same time, be a good approximation for the unconstrained one. For two-layer neural networks, we provide affirmative answers to these questions by introducing Porcupine Neural Networks (PNNs) whose weight vectors are constrained to lie over a finite set of lines. We show that most local optima of PNN optimizations are global while we have a characterization of regions where bad local optimizers may exist. Moreover, our theoretical and empirical results suggest that an unconstrained neural network can be approximated using a polynomially-large PNN. version:1
arxiv-1710-02187 | BPEmb: Tokenization-free Pre-trained Subword Embeddings in 275 Languages | http://arxiv.org/abs/1710.02187 | id:1710.02187 author:Benjamin Heinzerling, Michael Strube category:cs.CL  published:2017-10-05 summary:We present BPEmb, a collection of pre-trained subword unit embeddings in 275 languages, based on Byte-Pair Encoding (BPE). In an evaluation using fine-grained entity typing as testbed, BPEmb performs competitively, and for some languages bet- ter than alternative subword approaches, while requiring vastly fewer resources and no tokenization. BPEmb is available at https://github.com/bheinzerling/bpemb version:1
arxiv-1710-01330 | Robotic Pick-and-Place of Novel Objects in Clutter with Multi-Affordance Grasping and Cross-Domain Image Matching | http://arxiv.org/abs/1710.01330 | id:1710.01330 author:Andy Zeng, Shuran Song, Kuan-Ting Yu, Elliott Donlon, Francois R. Hogan, Maria Bauza, Daolin Ma, Orion Taylor, Melody Liu, Eudald Romo, Nima Fazeli, Ferran Alet, Nikhil Chavan Dafle, Rachel Holladay, Isabella Morona, Prem Qu Nair, Druck Green, Ian Taylor, Weber Liu, Thomas Funkhouser, Alberto Rodriguez category:cs.RO cs.CV  published:2017-10-03 summary:This paper presents a robotic pick-and-place system that is capable of grasping and recognizing both known and novel objects in cluttered environments. The key new feature of the system is that it handles a wide range of object categories without needing any task-specific training data for novel objects. To achieve this, it first uses a category-agnostic affordance prediction algorithm to select among four different grasping primitive behaviors. It then recognizes picked objects with a cross-domain image classification framework that matches observed images to product images. Since product images are readily available for a wide range of objects (e.g., from the web), the system works out-of-the-box for novel objects without requiring any additional training data. Exhaustive experimental results demonstrate that our multi-affordance grasping achieves high success rates for a wide variety of objects in clutter, and our recognition algorithm achieves high accuracy for both known and novel grasped objects. The approach was part of the MIT-Princeton Team system that took 1st place in the stowing task at the 2017 Amazon Robotics Challenge. All code, datasets, and pre-trained models are available online at http://arc.cs.princeton.edu version:2
arxiv-1710-02174 | A study of Thompson Sampling with Parameter h | http://arxiv.org/abs/1710.02174 | id:1710.02174 author:Qiang Ha category:cs.LG cs.IT math.IT  published:2017-10-05 summary:Thompson Sampling algorithm is a well known Bayesian algorithm for solving stochastic multi-armed bandit. At each time step the algorithm chooses each arm with probability proportional to it being the current best arm. We modify the strategy by introducing a paramter h which alters the importance of the probability of an arm being the current best arm. We show that the optimality of Thompson sampling is robust to this perturbation within a range of parameter values for two arm bandits. version:1
arxiv-1710-02139 | Tracking Persons-of-Interest via Unsupervised Representation Adaptation | http://arxiv.org/abs/1710.02139 | id:1710.02139 author:Shun Zhang, Jia-Bin Huang, Jongwoo Lim, Yihong Gong, Jinjun Wang, Narendra Ahuja, Ming-Hsuan Yang category:cs.CV  published:2017-10-05 summary:Multi-face tracking in unconstrained videos is a challenging problem as faces of one person often appear drastically different in multiple shots due to significant variations in scale, pose, expression, illumination, and make-up. Existing multi-target tracking methods often use low-level features which are not sufficiently discriminative for identifying faces with such large appearance variations. In this paper, we tackle this problem by learning discriminative, video-specific face representations using convolutional neural networks (CNNs). Unlike existing CNN-based approaches which are only trained on large-scale face image datasets offline, we use the contextual constraints to generate a large number of training samples for a given video, and further adapt the pre-trained face CNN to specific videos using discovered training samples. Using these training samples, we optimize the embedding space so that the Euclidean distances correspond to a measure of semantic face similarity via minimizing a triplet loss function. With the learned discriminative features, we apply the hierarchical clustering algorithm to link tracklets across multiple shots to generate trajectories. We extensively evaluate the proposed algorithm on two sets of TV sitcoms and YouTube music videos, analyze the contribution of each component, and demonstrate significant performance improvement over existing techniques. version:1
arxiv-1709-10204 | A Neural Comprehensive Ranker (NCR) for Open-Domain Question Answering | http://arxiv.org/abs/1709.10204 | id:1709.10204 author:Bin Bi, Hao Ma category:cs.CL cs.AI cs.LG cs.NE  published:2017-09-29 summary:This paper proposes a novel neural machine reading model for open-domain question answering at scale. Existing machine comprehension models typically assume that a short piece of relevant text containing answers is already identified and given to the models, from which the models are designed to extract answers. This assumption, however, is not realistic for building a large-scale open-domain question answering system which requires both deep text understanding and identifying relevant text from corpus simultaneously. In this paper, we introduce Neural Comprehensive Ranker (NCR) that integrates both passage ranking and answer extraction in one single framework. A Q&A system based on this framework allows users to issue an open-domain question without needing to provide a piece of text that must contain the answer. Experiments show that the unified NCR model is able to outperform the states-of-the-art in both retrieval of relevant text and answer extraction. version:2
arxiv-1710-02134 | DiffuserCam: Lensless Single-exposure 3D Imaging | http://arxiv.org/abs/1710.02134 | id:1710.02134 author:Nick Antipa, Grace Kuo, Reinhard Heckel, Ben Mildenhall, Emrah Bostan, Ren Ng, Laura Waller category:cs.CV  published:2017-10-05 summary:We demonstrate a compact and easy-to-build computational camera for single-shot 3D imaging. Our lensless system consists solely of a diffuser placed in front of a standard image sensor. Every point within the volumetric field-of-view projects a unique pseudorandom pattern of caustics on the sensor. By using a physical approximation and simple calibration scheme, we solve the large-scale inverse problem in a computationally efficient way. The caustic patterns enable compressed sensing, which exploits sparsity in the sample to solve for more 3D voxels than pixels on the 2D sensor. Our 3D voxel grid is chosen to match the experimentally measured two-point optical resolution across the field-of-view, resulting in 100 million voxels being reconstructed from a single 1.3 megapixel image. However, the effective resolution varies significantly with scene content. Because this effect is common to a wide range of computational cameras, we provide new theory for analyzing resolution in such systems. version:1
arxiv-1710-02124 | Multiframe Scene Flow with Piecewise Rigid Motion | http://arxiv.org/abs/1710.02124 | id:1710.02124 author:Vladislav Golyanik, Kihwan Kim, Robert Maier, Matthias Nießner, Didier Stricker, Jan Kautz category:cs.CV  published:2017-10-05 summary:We introduce a novel multiframe scene flow approach that jointly optimizes the consistency of the patch appearances and their local rigid motions from RGB-D image sequences. In contrast to the competing methods, we take advantage of an oversegmentation of the reference frame and robust optimization techniques. We formulate scene flow recovery as a global non-linear least squares problem which is iteratively solved by a damped Gauss-Newton approach. As a result, we obtain a qualitatively new level of accuracy in RGB-D based scene flow estimation which can potentially run in real-time. Our method can handle challenging cases with rigid, piecewise rigid, articulated and moderate non-rigid motion, and does not rely on prior knowledge about the types of motions and deformations. Extensive experiments on synthetic and real data show that our method outperforms state-of-the-art. version:1
arxiv-1710-02113 | Anatomical Pattern Analysis for decoding visual stimuli in human brains | http://arxiv.org/abs/1710.02113 | id:1710.02113 author:Muhammad Yousefnezhad, Daoqiang Zhang category:stat.ML cs.CV q-bio.NC  published:2017-10-05 summary:Background: A universal unanswered question in neuroscience and machine learning is whether computers can decode the patterns of the human brain. Multi-Voxels Pattern Analysis (MVPA) is a critical tool for addressing this question. However, there are two challenges in the previous MVPA methods, which include decreasing sparsity and noise in the extracted features and increasing the performance of prediction. Methods: In overcoming mentioned challenges, this paper proposes Anatomical Pattern Analysis (APA) for decoding visual stimuli in the human brain. This framework develops a novel anatomical feature extraction method and a new imbalance AdaBoost algorithm for binary classification. Further, it utilizes an Error-Correcting Output Codes (ECOC) method for multiclass prediction. APA can automatically detect active regions for each category of the visual stimuli. Moreover, it enables us to combine homogeneous datasets for applying advanced classification. Results and Conclusions: Experimental studies on 4 visual categories (words, consonants, objects and scrambled photos) demonstrate that the proposed approach achieves superior performance to state-of-the-art methods. version:1
arxiv-1706-02684 | Learning Local Receptive Fields and their Weight Sharing Scheme on Graphs | http://arxiv.org/abs/1706.02684 | id:1706.02684 author:Jean-Charles Vialatte, Vincent Gripon, Gilles Coppin category:cs.LG cs.CV cs.NE  published:2017-06-08 summary:We propose a simple and generic layer formulation that extends the properties of convolutional layers to any domain that can be described by a graph. Namely, we use the support of its adjacency matrix to design learnable weight sharing filters able to exploit the underlying structure of signals in the same fashion as for images. The proposed formulation makes it possible to learn the weights of the filter as well as a scheme that controls how they are shared across the graph. We perform validation experiments with image datasets and show that these filters offer performances comparable with convolutional ones. version:3
arxiv-1710-02103 | Learning Graphical Models from a Distributed Stream | http://arxiv.org/abs/1710.02103 | id:1710.02103 author:Yu Zhang, Srikanta Tirthapura, Graham Cormode category:cs.AI cs.LG stat.ML  published:2017-10-05 summary:A current challenge for data management systems is to support the construction and maintenance of machine learning models over data that is large, multi-dimensional, and evolving. While systems that could support these tasks are emerging, the need to scale to distributed, streaming data requires new models and algorithms. In this setting, as well as computational scalability and model accuracy, we also need to minimize the amount of communication between distributed processors, which is the chief component of latency. We study Bayesian networks, the workhorse of graphical models, and present a communication-efficient method for continuously learning and maintaining a Bayesian network model over data that is arriving as a distributed stream partitioned across multiple processors. We show a strategy for maintaining model parameters that leads to an exponential reduction in communication when compared with baseline approaches to maintain the exact MLE (maximum likelihood estimation). Meanwhile, our strategy provides similar prediction errors for the target distribution and for classification tasks. version:1
arxiv-1710-02398 | Bilingual Words and Phrase Mappings for Marathi and Hindi SMT | http://arxiv.org/abs/1710.02398 | id:1710.02398 author:S Sreelekha, Pushpak Bhattacharyya category:cs.CL  published:2017-10-05 summary:Lack of proper linguistic resources is the major challenges faced by the Machine Translation system developments when dealing with the resource poor languages. In this paper, we describe effective ways to utilize the lexical resources to improve the quality of statistical machine translation. Our research on the usage of lexical resources mainly focused on two ways, such as; augmenting the parallel corpus with more vocabulary and to provide various word forms. We have augmented the training corpus with various lexical resources such as lexical words, function words, kridanta pairs and verb phrases. We have described the case studies, evaluations and detailed error analysis for both Marathi to Hindi and Hindi to Marathi machine translation systems. From the evaluations we observed that, there is an incremental growth in the quality of machine translation as the usage of various lexical resources increases. Moreover, usage of various lexical resources helps to improve the coverage and quality of machine translation where limited parallel corpus is available. version:1
arxiv-1710-02101 | Reliable Learning of Bernoulli Mixture Models | http://arxiv.org/abs/1710.02101 | id:1710.02101 author:Amir Najafi, Abolfazl Motahari, Hamid R. Rabiee category:cs.LG cs.IT math.IT stat.ML  published:2017-10-05 summary:In this paper, we have derived a set of sufficient conditions for reliable clustering of data produced by Bernoulli Mixture Models (BMM), when the number of clusters is unknown. A BMM refers to a random binary vector whose components are independent Bernoulli trials with cluster-specific frequencies. The problem of clustering BMM data arises in many real-world applications, most notably in population genetics where researchers aim at inferring the population structure from multilocus genotype data. Our findings stipulate a minimum dataset size and a minimum number of Bernoulli trials (or genotyped loci) per sample, such that the existence of a clustering algorithm with a sufficient accuracy is guaranteed. Moreover, the mathematical intuitions and tools behind our work can help researchers in designing more effective and theoretically-plausible heuristic methods for similar problems. version:1
arxiv-1710-02100 | Phrase Pair Mappings for Hindi-English Statistical Machine Translation | http://arxiv.org/abs/1710.02100 | id:1710.02100 author:S Sreelekha, Pushpak Bhattacharyya category:cs.CL  published:2017-10-05 summary:In this paper, we present our work on the creation of lexical resources for the Machine Translation between English and Hindi. We describes the development of phrase pair mappings for our experiments and the comparative performance evaluation between different trained models on top of the baseline Statistical Machine Translation system. We focused on augmenting the parallel corpus with more vocabulary as well as with various inflected forms by exploring different ways. We have augmented the training corpus with various lexical resources such as lexical words, synset words, function words and verb phrases. We have described the case studies, automatic and subjective evaluations, detailed error analysis for both the English to Hindi and Hindi to English machine translation systems. We further analyzed that, there is an incremental growth in the quality of machine translation with the usage of various lexical resources. Thus lexical resources do help uplift the translation quality of resource poor langugaes. version:1
arxiv-1710-02095 | Machine Translation Evaluation with Neural Networks | http://arxiv.org/abs/1710.02095 | id:1710.02095 author:Francisco Guzmán, Shafiq R. Joty, Lluís Màrquez, Preslav Nakov category:cs.CL 68T50 I.2.7  published:2017-10-05 summary:We present a framework for machine translation evaluation using neural networks in a pairwise setting, where the goal is to select the better translation from a pair of hypotheses, given the reference translation. In this framework, lexical, syntactic and semantic information from the reference and the two hypotheses is embedded into compact distributed vector representations, and fed into a multi-layer neural network that models nonlinear interactions between each of the hypotheses and the reference, as well as between the two hypotheses. We experiment with the benchmark datasets from the WMT Metrics shared task, on which we obtain the best results published so far, with the basic network configuration. We also perform a series of experiments to analyze and understand the contribution of the different components of the network. We evaluate variants and extensions, including fine-tuning of the semantic embeddings, and sentence-based representations modeled with convolutional and recurrent neural networks. In summary, the proposed framework is flexible and generalizable, allows for efficient learning and scoring, and provides an MT evaluation metric that correlates with human judgments, and is on par with the state of the art. version:1
arxiv-1710-02094 | The use of neural networks in the analysis of sleep stages and the diagnosis of narcolepsy | http://arxiv.org/abs/1710.02094 | id:1710.02094 author:Jens B. Stephansen, Aditya Ambati, Eileen B. Leary, Hyatt E. Moore, Oscar Carrillo, Ling Lin, Birgit Hogl, Ambra Stefani, Seung Chul Hong, Tae Won Kim, Fabio Pizza, Giuseppe Plazzi, Stefano Vandi, Elena Antelmi, Dimitri Perrin, Samuel T. Kuna, Paula K. Schweitzer, Clete Kushida, Paul E. Peppard, Poul Jennum, Helge B. D. Sorensen, Emmanuel Mignot category:cs.NE  published:2017-10-05 summary:We used neural networks in ~3,000 sleep recordings from over 10 locations to automate sleep stage scoring, producing a probability distribution called an hypnodensity graph. Accuracy was validated in 70 subjects scored by six technicians (gold standard). Our best model performed better than any individual scorer, reaching an accuracy of 0.87 (and 0.95 when predictions are weighed by scorer agreement). It also scores sleep stages down to 5-second instead of the conventional 30-second scoring-epochs. Accuracy did not vary by sleep disorder except for narcolepsy, suggesting scoring difficulties by machine and/or humans. A narcolepsy biomarker was extracted and validated in 105 type-1 narcoleptics versus 331 controls producing a specificity of 0.96 and a sensitivity of 0.91. Similar performances were obtained against a high pretest probability sample of type-2 narcolepsy and idiopathic hypersomnia patients. Addition of HLA-DQB1*06:02 increased specificity to 0.99. Our method streamlines scoring and diagnoses narcolepsy accurately. version:1
arxiv-1710-02093 | Morphology Generation for Statistical Machine Translation | http://arxiv.org/abs/1710.02093 | id:1710.02093 author:S Sreelekha, Pushpak Bhattacharyya category:cs.CL  published:2017-10-05 summary:When translating into morphologically rich languages, Statistical MT approaches face the problem of data sparsity. The severity of the sparseness problem will be high when the corpus size of morphologically richer language is less. Even though we can use factored models to correctly generate morphological forms of words, the problem of data sparseness limits their performance. In this paper, we describe a simple and effective solution which is based on enriching the input corpora with various morphological forms of words. We use this method with the phrase-based and factor-based experiments on two morphologically rich languages: Hindi and Marathi when translating from English. We evaluate the performance of our experiments both in terms automatic evaluation and subjective evaluation such as adequacy and fluency. We observe that the morphology injection method helps in improving the quality of translation. We further analyze that the morph injection method helps in handling the data sparseness problem to a great level. version:1
arxiv-1710-02081 | Online Photometric Calibration for Auto Exposure Video for Realtime Visual Odometry and SLAM | http://arxiv.org/abs/1710.02081 | id:1710.02081 author:Paul Bergmann, Rui Wang, Daniel Cremers category:cs.CV  published:2017-10-05 summary:Recent direct visual odometry and SLAM algorithms have demonstrated impressive levels of precision. However, they require a photometric camera calibration in order to achieve competitive results. Hence, the respective algorithm cannot be directly applied to an off-the-shelf-camera or to a video sequence acquired with an unknown camera. In this work we propose a method for online photometric calibration which enables to process auto exposure videos with visual odometry precisions that are on par with those of photometrically calibrated videos. Our algorithm recovers the exposure times of consecutive frames, the camera response function, and the attenuation factors of the sensor irradiance due to vignetting. Gain robust KLT feature tracks are used to obtain scene point correspondences as input to a nonlinear optimization framework. We show that our approach can reliably calibrate arbitrary video sequences by evaluating it on datasets for which full photometric ground truth is available. We further show that our calibration can improve the performance of a state-of-the-art direct visual odometry method that works solely on pixel intensities, calibrating for photometric parameters in an online fashion in realtime. version:1
arxiv-1709-07772 | Probabilistic Synchronous Parallel | http://arxiv.org/abs/1709.07772 | id:1709.07772 author:Liang Wang, Ben Catterall, Richard Mortier category:cs.DC cs.LG  published:2017-09-22 summary:Most machine learning and deep neural network algorithms rely on certain iterative algorithms to optimise their utility/cost functions, e.g. Stochastic Gradient Descent. In distributed learning, the networked nodes have to work collaboratively to update the model parameters, and the way how they proceed is referred to as synchronous parallel design (or barrier control). Synchronous parallel protocol is the building block of any distributed learning framework, and its design has direct impact on the performance and scalability of the system. In this paper, we propose a new barrier control technique - Probabilistic Synchronous Parallel (PSP). Com- paring to the previous Bulk Synchronous Parallel (BSP), Stale Synchronous Parallel (SSP), and (Asynchronous Parallel) ASP, the proposed solution e ectively improves both the convergence speed and the scalability of the SGD algorithm by introducing a sampling primitive into the system. Moreover, we also show that the sampling primitive can be applied atop of the existing barrier control mechanisms to derive fully distributed PSP-based synchronous parallel. We not only provide a thorough theoretical analysis1 on the convergence of PSP-based SGD algorithm, but also implement a full-featured distributed learning framework called Actor and perform intensive evaluation atop of it. version:2
arxiv-1710-02076 | On the Effective Use of Pretraining for Natural Language Inference | http://arxiv.org/abs/1710.02076 | id:1710.02076 author:Ignacio Cases, Minh-Thang Luong, Christopher Potts category:cs.CL  published:2017-10-05 summary:Neural networks have excelled at many NLP tasks, but there remain open questions about the performance of pretrained distributed word representations and their interaction with weight initialization and other hyperparameters. We address these questions empirically using attention-based sequence-to-sequence models for natural language inference (NLI). Specifically, we compare three types of embeddings: random, pretrained (GloVe, word2vec), and retrofitted (pretrained plus WordNet information). We show that pretrained embeddings outperform both random and retrofitted ones in a large NLI corpus. Further experiments on more controlled data sets shed light on the contexts for which retrofitted embeddings can be useful. We also explore two principled approaches to initializing the rest of the model parameters, Gaussian and orthogonal, showing that the latter yields gains of up to 2.9% in the NLI task. version:1
arxiv-1710-00935 | Interpretable Convolutional Neural Networks | http://arxiv.org/abs/1710.00935 | id:1710.00935 author:Quanshi Zhang, Ying Nian Wu, Song-Chun Zhu category:cs.CV  published:2017-10-02 summary:This paper proposes a method to modify traditional convolutional neural networks (CNNs) into interpretable CNNs, in order to clarify knowledge representations in high conv-layers of CNNs. In an interpretable CNN, each filter in a high conv-layer represents a certain object part. We do not need any annotations of object parts or textures to supervise the learning process. Instead, the interpretable CNN automatically assigns each filter in a high conv-layer with an object part during the learning process. Our method can be applied to different types of CNNs with different structures. The clear knowledge representation in an interpretable CNN can help people understand the logics inside a CNN, i.e., based on which patterns the CNN makes the decision. Experiments showed that filters in an interpretable CNN were more semantically meaningful than those in traditional CNNs. version:2
arxiv-1710-02039 | Integrating Boundary and Center Correlation Filters for Visual Tracking with Aspect Ratio Variation | http://arxiv.org/abs/1710.02039 | id:1710.02039 author:Feng Li, Yingjie Yao, Peihua Li, David Zhang, Wangmeng Zuo, Ming-Hsuan Yang category:cs.CV  published:2017-10-05 summary:The aspect ratio variation frequently appears in visual tracking and has a severe influence on performance. Although many correlation filter (CF)-based trackers have also been suggested for scale adaptive tracking, few studies have been given to handle the aspect ratio variation for CF trackers. In this paper, we make the first attempt to address this issue by introducing a family of 1D boundary CFs to localize the left, right, top, and bottom boundaries in videos. This allows us cope with the aspect ratio variation flexibly during tracking. Specifically, we present a novel tracking model to integrate 1D Boundary and 2D Center CFs (IBCCF) where boundary and center filters are enforced by a near-orthogonality regularization term. To optimize our IBCCF model, we develop an alternating direction method of multipliers. Experiments on several datasets show that IBCCF can effectively handle aspect ratio variation, and achieves state-of-the-art performance in terms of accuracy and robustness. version:1
arxiv-1710-02030 | McDiarmid Drift Detection Methods for Evolving Data Streams | http://arxiv.org/abs/1710.02030 | id:1710.02030 author:Ali Pesaranghader, Herna Viktor, Eric Paquet category:stat.ML cs.DB cs.LG  published:2017-10-05 summary:Increasingly, Internet of Things (IoT) domains, such as sensor networks, smart cities, and social networks, generate vast amounts of data. Such data are not only unbounded and rapidly evolving. Rather, the content thereof dynamically evolves over time, often in unforeseen ways. These variations are due to so-called concept drifts, caused by changes in the underlying data generation mechanisms. In a classification setting, concept drift causes the previously learned models to become inaccurate, unsafe and even unusable. Accordingly, concept drifts need to be detected, and handled, as soon as possible. In medical applications and military zones, for example, change in behaviors should be detected in near real-time, to avoid potential loss of life. To this end, we introduce the McDiarmid Drift Detection Method (MDDM), which utilizes McDiarmid's inequality in order to detect concept drift. The MDDM approach proceeds by sliding a window over prediction results, and associate window entries with weights. Higher weights are assigned to the most recent entries, in order to emphasize their importance. As instances are processed, the detection algorithm compares a weighted mean of elements inside the sliding window with the maximum weighted mean observed so far. A significant difference between the two weighted means, upper-bounded by the McDiarmid inequality, implies a concept drift. Our extensive experimentation against synthetic and real-world data streams show that our novel method outperforms the state-of-the-art. Specifically, MDDM yields shorter detection delays as well as lower false negative rates, while maintaining high classification accuracies. version:1
arxiv-1710-02004 | Alternating Iteratively Reweighted Minimization Algorithms for Low-Rank Matrix Factorization | http://arxiv.org/abs/1710.02004 | id:1710.02004 author:Paris V. Giampouras, Athanasios A. Rontogiannis, Konstantinos D. Koutroumbas category:cs.LG  published:2017-10-05 summary:Nowadays, the availability of large-scale data in disparate application domains urges the deployment of sophisticated tools for extracting valuable knowledge out of this huge bulk of information. In that vein, low-rank representations (LRRs) which seek low-dimensional embeddings of data have naturally appeared. In an effort to reduce computational complexity and improve estimation performance, LRR has been viewed via a matrix factorization (MF) perspective. Recently, low-rank MF (LRMF) approaches have been proposed for tackling the inherent weakness of MF i.e., the unawareness of the dimension of the low-dimensional space where data reside. Herein, inspired by the merits of iterative reweighted schemes for rank minimization, we come up with a generic low-rank promoting regularization function. Then, focusing on a specific instance of it, we propose a regularizer that imposes column-sparsity jointly on the two matrix factors that result from MF, thus promoting low-rankness on the optimization problem. The problems of denoising, matrix completion and non-negative matrix factorization (NMF) are redefined according to the new LRMF formulation and solved via efficient Newton-type algorithms with proven theoretical guarantees as to their convergence and rates of convergence to stationary points. The effectiveness of the proposed algorithms is verified in diverse simulated and real data experiments. version:1
arxiv-1709-04511 | An Empirical Study of AI Population Dynamics with Million-agent Reinforcement Learning | http://arxiv.org/abs/1709.04511 | id:1709.04511 author:Yaodong Yang, Lantao Yu, Yiwei Bai, Jun Wang, Weinan Zhang, Ying Wen, Yong Yu category:cs.AI cs.LG cs.MA  published:2017-09-13 summary:In this paper, we conduct an empirical study on discovering the ordered collective dynamics obtained by a population of artificial intelligence (AI) agents. Our intention is to put AI agents into a simulated natural context, and then to understand their induced dynamics at the population level. In particular, we aim to verify if the principles developed in the real world could also be used in understanding an artificially-created intelligent population. To achieve this, we simulate a large-scale predator-prey world, where the laws of the world are designed by only the findings or logical equivalence that have been discovered in nature. We endow the agents with the intelligence based on deep reinforcement learning, and scale the population size up to millions. Our results show that the population dynamics of AI agents, driven only by each agent's individual self interest, reveals an ordered pattern that is similar to the Lotka-Volterra model studied in population biology. We further discover the emergent behaviors of collective adaptations in studying how the agents' grouping behaviors will change with the environmental resources. Both of the two findings could be explained by the self-organization theory in nature. version:3
arxiv-1707-01395 | Towards lightweight convolutional neural networks for object detection | http://arxiv.org/abs/1707.01395 | id:1707.01395 author:Dmitriy Anisimov, Tatiana Khanova category:cs.CV cs.NE  published:2017-07-05 summary:We propose model with larger spatial size of feature maps and evaluate it on object detection task. With the goal to choose the best feature extraction network for our model we compare several popular lightweight networks. After that we conduct a set of experiments with channels reduction algorithms in order to accelerate execution. Our vehicle detection models are accurate, fast and therefore suit for embedded visual applications. With only 1.5 GFLOPs our best model gives 93.39 AP on validation subset of challenging DETRAC dataset. The smallest of our models is the first to achieve real-time inference speed on CPU with reasonable accuracy drop to 91.43 AP. version:3
arxiv-1710-01977 | Machine Learning Based Detection of Clickbait Posts in Social Media | http://arxiv.org/abs/1710.01977 | id:1710.01977 author:Xinyue Cao, Thai Le, Jason, Zhang category:cs.CL  published:2017-10-05 summary:Clickbait (headlines) make use of misleading titles that hide critical information from or exaggerate the content on the landing target pages to entice clicks. As clickbaits often use eye-catching wording to attract viewers, target contents are often of low quality. Clickbaits are especially widespread on social media such as Twitter, adversely impacting user experience by causing immense dissatisfaction. Hence, it has become increasingly important to put forward a widely applicable approach to identify and detect clickbaits. In this paper, we make use of a dataset from the clickbait challenge 2017 (clickbait-challenge.com) comprising of over 21,000 headlines/titles, each of which is annotated by at least five judgments from crowdsourcing on how clickbait it is. We attempt to build an effective computational clickbait detection model on this dataset. We first considered a total of 331 features, filtered out many features to avoid overfitting and improve the running time of learning, and eventually selected the 60 most important features for our final model. Using these features, Random Forest Regression achieved the following results: MSE=0.035 MSE, Accuracy=0.82, and F1-sore=0.61 on the clickbait class. version:1
arxiv-1709-07149 | Learning RBM with a DC programming Approach | http://arxiv.org/abs/1709.07149 | id:1709.07149 author:Vidyadhar Upadhya, P. S. Sastry category:cs.LG stat.ML  published:2017-09-21 summary:By exploiting the property that the RBM log-likelihood function is the difference of convex functions, we formulate a stochastic variant of the difference of convex functions (DC) programming to minimize the negative log-likelihood. Interestingly, the traditional contrastive divergence algorithm is a special case of the above formulation and the hyperparameters of the two algorithms can be chosen such that the amount of computation per mini-batch is identical. We show that for a given computational budget the proposed algorithm almost always reaches a higher log-likelihood more rapidly, compared to the standard contrastive divergence algorithm. Further, we modify this algorithm to use the centered gradients and show that it is more efficient and effective compared to the standard centered gradient algorithm on benchmark datasets. version:2
arxiv-1710-01949 | Semantic keyword spotting by learning from images and speech | http://arxiv.org/abs/1710.01949 | id:1710.01949 author:Herman Kamper, Gregory Shakhnarovich, Karen Livescu category:cs.CL cs.CV  published:2017-10-05 summary:We consider the problem of representing semantic concepts in speech by learning from untranscribed speech paired with images of scenes. This setting is relevant in low-resource speech processing, robotics, and human language acquisition research. We use an external image tagger to generate soft labels, which serve as targets for training a neural model that maps speech to keyword labels. We introduce a newly collected data set of human semantic relevance judgements and an associated task, semantic keyword spotting, where the goal is to search for spoken utterances that are semantically relevant to a given text query. Without seeing any text, the model trained on parallel speech and images achieves a precision of almost 60% on its top ten semantic retrievals. Compared to a model trained on transcriptions, our model matches human judgements better by some measures, especially in retrieving non-verbatim semantic matches. version:1
arxiv-1710-01931 | Forecasting Player Behavioral Data and Simulating in-Game Events | http://arxiv.org/abs/1710.01931 | id:1710.01931 author:Anna Guitart, Pei Pei Chen, Paul Bertens, África Periáñez category:stat.ML  published:2017-10-05 summary:Understanding player behavior is fundamental in game data science. Video games evolve as players interact with the game, so being able to foresee player experience would help to ensure a successful game development. In particular, game developers need to evaluate beforehand the impact of in-game events. Simulation optimization of these events is crucial to increase player engagement and maximize monetization. We present an experimental analysis of several methods to forecast game-related variables, with two main aims: to obtain accurate predictions of in-app purchases and playtime in an operational production environment, and to perform simulations of in-game events in order to maximize sales and playtime. Our ultimate purpose is to take a step towards the data-driven development of games. The results suggest that, even though the performance of traditional approaches such as ARIMA is still better, the outcomes of state-of-the-art techniques like deep learning are promising. Deep learning comes up as a well-suited general model that could be used to forecast a variety of time series with different dynamic behaviors. version:1
arxiv-1710-01927 | Data Augmentation of Spectral Data for Convolutional Neural Network (CNN) Based Deep Chemometrics | http://arxiv.org/abs/1710.01927 | id:1710.01927 author:Esben Jannik Bjerrum, Mads Glahder, Thomas Skov category:cs.LG  published:2017-10-05 summary:Deep learning methods are used on spectroscopic data to predict drug content in tablets from near infrared (NIR) spectra. Using convolutional neural networks (CNNs), features are ex- tracted from the spectroscopic data. Extended multiplicative scatter correction (EMSC) and a novel spectral data augmentation method are benchmarked as preprocessing steps. The learned models perform better or on par with hypothetical optimal partial least squares (PLS) models for all combinations of preprocessing. Data augmentation with subsequent EMSC in combination gave the best results. The deep learning model CNNs also outperform the PLS models in an extrapolation chal- lenge created using data from a second instrument and from an analyte concentration not covered by the training data. Qualitative investigations of the CNNs kernel activations show their resemblance to wellknown data processing methods such as smoothing, slope/derivative, thresholds and spectral region selection. version:1
arxiv-1710-01925 | Plane-extraction from depth-data using a Gaussian mixture regression model | http://arxiv.org/abs/1710.01925 | id:1710.01925 author:Richard T. Marriott, Alexander Paschevich, Radu Horaud category:cs.CV  published:2017-10-05 summary:We propose a novel algorithm for unsupervised extraction of piecewise planar models from depth-data. Among other applications, such models are a good way of enabling autonomous agents (robots, cars, drones, etc.) to effectively perceive their surroundings and to navigate in three dimensions. We propose to do this by fitting the data with a piecewise-linear Gaussian mixture regression model whose components are skewed over planes, making them flat in appearance rather than being ellipsoidal, by embedding an outlier-trimming process that is formally incorporated into the proposed expectation-maximization algorithm, and by selectively fusing contiguous, coplanar components. Part of our motivation is an attempt to estimate more accurate plane-extraction by allowing each model component to make use of all available data through probabilistic clustering. The algorithm is thoroughly evaluated against a standard benchmark and is shown to rank among the best of the existing state-of-the-art methods. version:1
arxiv-1710-01916 | A self-organizing neural network architecture for learning human-object interactions | http://arxiv.org/abs/1710.01916 | id:1710.01916 author:Luiza Mici, German I. Parisi, Stefan Wermter category:cs.NE cs.CV cs.HC  published:2017-10-05 summary:The visual recognition of transitive actions comprising human-object interactions is a key component enabling artificial systems to operate in natural environments. This challenging task requires, in addition to the recognition of articulated body actions, the extraction of semantic elements from the scene such as the identity of the manipulated objects. In this paper, we present a self-organizing neural network for the recognition of human-object interactions from RGB-D videos. Our model consists of a hierarchy of Grow When Required (GWR) networks which learn prototypical representations of body motion patterns and objects, also accounting for the development of action-object mappings in an unsupervised fashion. To demonstrate this ability, we report experimental results on a dataset of daily activities collected for the purpose of this study as well as on a publicly available benchmark dataset. In line with neurophysiological studies, our self-organizing architecture shows higher neural activation for congruent action-object pairs learned during training sessions with respect to artificially created incongruent ones. We show that our model achieves good classification accuracy on the benchmark dataset in an unsupervised fashion, showing competitive performance with respect to strictly supervised state-of-the-art approaches. version:1
arxiv-1709-09890 | B-CNN: Branch Convolutional Neural Network for Hierarchical Classification | http://arxiv.org/abs/1709.09890 | id:1709.09890 author:Xinqi Zhu, Michael Bain category:cs.CV  published:2017-09-28 summary:Convolutional Neural Network (CNN) image classifiers are traditionally designed to have sequential convolutional layers with a single output layer. This is based on the assumption that all target classes should be treated equally and exclusively. However, some classes can be more difficult to distinguish than others, and classes may be organized in a hierarchy of categories. At the same time, a CNN is designed to learn internal representations that abstract from the input data based on its hierarchical layered structure. So it is natural to ask if an inverse of this idea can be applied to learn a model that can predict over a classification hierarchy using multiple output layers in decreasing order of class abstraction. In this paper, we introduce a variant of the traditional CNN model named the Branch Convolutional Neural Network (B-CNN). A B-CNN model outputs multiple predictions ordered from coarse to fine along the concatenated convolutional layers corresponding to the hierarchical structure of the target classes, which can be regarded as a form of prior knowledge on the output. To learn with B-CNNs a novel training strategy, named the Branch Training strategy (BT-strategy), is introduced which balances the strictness of the prior with the freedom to adjust parameters on the output layers to minimize the loss. In this way we show that CNN based models can be forced to learn successively coarse to fine concepts in the internal layers at the output stage, and that hierarchical prior knowledge can be adopted to boost CNN models' classification performance. Our models are evaluated to show that the B-CNN extensions improve over the corresponding baseline CNN on the benchmark datasets MNIST, CIFAR-10 and CIFAR-100. version:2
arxiv-1710-02546 | Real-Time Illegal Parking Detection System Based on Deep Learning | http://arxiv.org/abs/1710.02546 | id:1710.02546 author:Xuemei Xie, Chenye Wang, Shu Chen, Guangming Shi, Zhifu Zhao category:cs.CV cs.LG stat.ML  published:2017-10-05 summary:The increasing illegal parking has become more and more serious. Nowadays the methods of detecting illegally parked vehicles are based on background segmentation. However, this method is weakly robust and sensitive to environment. Benefitting from deep learning, this paper proposes a novel illegal vehicle parking detection system. Illegal vehicles captured by camera are firstly located and classified by the famous Single Shot MultiBox Detector (SSD) algorithm. To improve the performance, we propose to optimize SSD by adjusting the aspect ratio of default box to accommodate with our dataset better. After that, a tracking and analysis of movement is adopted to judge the illegal vehicles in the region of interest (ROI). Experiments show that the system can achieve a 99% accuracy and real-time (25FPS) detection with strong robustness in complex environments. version:1
arxiv-1709-07739 | Single-pixel imaging with Morlet wavelet correlated random patterns | http://arxiv.org/abs/1709.07739 | id:1709.07739 author:Krzysztof M. Czajkowski, Anna Pastuszczak, Rafał Kotyński category:eess.IV cs.CV  published:2017-09-22 summary:Single-pixel imaging is an indirect imaging technique which utilizes simplified optical hardware and advanced computational methods. It offers novel solutions for hyper-spectral imaging, polarimetric imaging, three-dimensional imaging, holographic imaging, optical encryption and imaging through scattering media. The main limitations for its use come from relatively high measurement and reconstruction times. In this paper we propose to reduce the required signal acquisition time by using a novel sampling scheme based on a random selection of Morlet wavelets convolved with white noise. While such functions exhibit random properties, they are locally determined by Morlet wavelet parameters. The proposed method is equivalent to random sampling of the properly selected part of the feature space, which maps the measured images accurately both in the spatial and spatial frequency domains. We compare both numerically and experimentally the image quality obtained with our sampling protocol against widely-used sampling with Walsh-Hadamard or noiselet functions. The results show considerable improvement over the former methods, enabling single-pixel imaging at low compression rates on the order of a few percent. version:2
arxiv-1706-03458 | Deep Learning for Precipitation Nowcasting: A Benchmark and A New Model | http://arxiv.org/abs/1706.03458 | id:1706.03458 author:Xingjian Shi, Zhihan Gao, Leonard Lausen, Hao Wang, Dit-Yan Yeung, Wai-kin Wong, Wang-chun Woo category:cs.CV  published:2017-06-12 summary:With the goal of making high-resolution forecasts of regional rainfall, precipitation nowcasting has become an important and fundamental technology underlying various public services ranging from rainstorm warnings to flight safety. Recently, the Convolutional LSTM (ConvLSTM) model has been shown to outperform traditional optical flow based methods for precipitation nowcasting, suggesting that deep learning models have a huge potential for solving the problem. However, the convolutional recurrence structure in ConvLSTM-based models is location-invariant while natural motion and transformation (e.g., rotation) are location-variant in general. Furthermore, since deep-learning-based precipitation nowcasting is a newly emerging area, clear evaluation protocols have not yet been established. To address these problems, we propose both a new model and a benchmark for precipitation nowcasting. Specifically, we go beyond ConvLSTM and propose the Trajectory GRU (TrajGRU) model that can actively learn the location-variant structure for recurrent connections. Besides, we provide a benchmark that includes a real-world large-scale dataset from the Hong Kong Observatory, a new training loss, and a comprehensive evaluation protocol to facilitate future research and gauge the state of the art. version:2
arxiv-1710-01878 | To prune, or not to prune: exploring the efficacy of pruning for model compression | http://arxiv.org/abs/1710.01878 | id:1710.01878 author:Michael Zhu, Suyog Gupta category:stat.ML cs.LG  published:2017-10-05 summary:Model pruning seeks to induce sparsity in a deep neural network's various connection matrices, thereby reducing the number of nonzero-valued parameters in the model. Recent reports (Han et al., 2015; Narang et al., 2017) prune deep networks at the cost of only a marginal loss in accuracy and achieve a sizable reduction in model size. This hints at the possibility that the baseline models in these experiments are perhaps severely over-parameterized at the outset and a viable alternative for model compression might be to simply reduce the number of hidden units while maintaining the model's dense connection structure, exposing a similar trade-off in model size and accuracy. We investigate these two distinct paths for model compression within the context of energy-efficient inference in resource-constrained environments and propose a new gradual pruning technique that is simple and straightforward to apply across a variety of models/datasets with minimal tuning and can be seamlessly incorporated within the training process. We compare the accuracy of large, but pruned models (large-sparse) and their smaller, but dense (small-dense) counterparts with identical memory footprint. Across a broad range of neural network architectures (deep CNNs, stacked LSTM, and seq2seq LSTM models), we find large-sparse models to consistently outperform small-dense models and achieve up to 10x reduction in number of non-zero parameters with minimal loss in accuracy. version:1
arxiv-1709-04594 | Revisiting Spectral Graph Clustering with Generative Community Models | http://arxiv.org/abs/1709.04594 | id:1709.04594 author:Pin-Yu Chen, Lingfei Wu category:stat.ML cs.SI  published:2017-09-14 summary:The methodology of community detection can be divided into two principles: imposing a network model on a given graph, or optimizing a designed objective function. The former provides guarantees on theoretical detectability but falls short when the graph is inconsistent with the underlying model. The latter is model-free but fails to provide quality assurance for the detected communities. In this paper, we propose a novel unified framework to combine the advantages of these two principles. The presented method, SGC-GEN, not only considers the detection error caused by the corresponding model mismatch to a given graph, but also yields a theoretical guarantee on community detectability by analyzing Spectral Graph Clustering (SGC) under GENerative community models (GCMs). SGC-GEN incorporates the predictability on correct community detection with a measure of community fitness to GCMs. It resembles the formulation of supervised learning problems by enabling various community detection loss functions and model mismatch metrics. We further establish a theoretical condition for correct community detection using the normalized graph Laplacian matrix under a GCM, which provides a novel data-driven loss function for SGC-GEN. In addition, we present an effective algorithm to implement SGC-GEN, and show that the computational complexity of SGC-GEN is comparable to the baseline methods. Our experiments on 18 real-world datasets demonstrate that SGC-GEN possesses superior and robust performance compared to 6 baseline methods under 7 representative clustering metrics. version:2
arxiv-1710-01820 | Energy-Based Spherical Sparse Coding | http://arxiv.org/abs/1710.01820 | id:1710.01820 author:Bailey Kong, Charless C. Fowlkes category:cs.CV  published:2017-10-04 summary:In this paper, we explore an efficient variant of convolutional sparse coding with unit norm code vectors where reconstruction quality is evaluated using an inner product (cosine distance). To use these codes for discriminative classification, we describe a model we term Energy-Based Spherical Sparse Coding (EB-SSC) in which the hypothesized class label introduces a learned linear bias into the coding step. We evaluate and visualize performance of stacking this encoder to make a deep layered model for image classification. version:1
arxiv-1708-04814 | GSLAM: Initialization-robust Monocular Visual SLAM via Global Structure-from-Motion | http://arxiv.org/abs/1708.04814 | id:1708.04814 author:Chengzhou Tang, Oliver Wang, Ping Tan category:cs.CV  published:2017-08-16 summary:Many monocular visual SLAM algorithms are derived from incremental structure-from-motion (SfM) methods. This work proposes a novel monocular SLAM method which integrates recent advances made in global SfM. In particular, we present two main contributions to visual SLAM. First, we solve the visual odometry problem by a novel rank-1 matrix factorization technique which is more robust to the errors in map initialization. Second, we adopt a recent global SfM method for the pose-graph optimization, which leads to a multi-stage linear formulation and enables L1 optimization for better robustness to false loops. The combination of these two approaches generates more robust reconstruction and is significantly faster (4X) than recent state-of-the-art SLAM systems. We also present a new dataset recorded with ground truth camera motion in a Vicon motion capture room, and compare our method to prior systems on it and established benchmark datasets. version:2
arxiv-1710-04203 | Crowdsourcing for Beyond Polarity Sentiment Analysis A Pure Emotion Lexicon | http://arxiv.org/abs/1710.04203 | id:1710.04203 author:Giannis Haralabopoulos, Elena Simperl category:cs.CL cs.HC  published:2017-10-04 summary:Sentiment analysis aims to uncover emotions conveyed through information. In its simplest form, it is performed on a polarity basis, where the goal is to classify information with positive or negative emotion. Recent research has explored more nuanced ways to capture emotions that go beyond polarity. For these methods to work, they require a critical resource: a lexicon that is appropriate for the task at hand, in terms of the range of emotions it captures diversity. In the past, sentiment analysis lexicons have been created by experts, such as linguists and behavioural scientists, with strict rules. Lexicon evaluation was also performed by experts or gold standards. In our paper, we propose a crowdsourcing method for lexicon acquisition, which is scalable, cost-effective, and doesn't require experts or gold standards. We also compare crowd and expert evaluations of the lexicon, to assess the overall lexicon quality, and the evaluation capabilities of the crowd. version:1
arxiv-1710-01813 | Neural Task Programming: Learning to Generalize Across Hierarchical Tasks | http://arxiv.org/abs/1710.01813 | id:1710.01813 author:Danfei Xu, Suraj Nair, Yuke Zhu, Julian Gao, Animesh Garg, Li Fei-Fei, Silvio Savarese category:cs.AI cs.LG cs.RO  published:2017-10-04 summary:In this work, we propose a novel robot learning framework called Neural Task Programming (NTP), which bridges the idea of few-shot learning from demonstration and neural program induction. NTP takes as input a task specification (e.g., video demonstration of a task) and recursively decomposes it into finer sub-task specifications. These specifications are fed to a hierarchical neural program, where bottom-level programs are callable subroutines that interact with the environment. We validate our method in three robot manipulation tasks. NTP achieves strong generalization across sequential tasks that exhibit hierarchal and compositional structures. The experimental results show that NTP learns to generalize well to- wards unseen tasks with increasing lengths, variable topologies, and changing objectives. version:1
arxiv-1710-01809 | Syntactic and Semantic Features For Code-Switching Factored Language Models | http://arxiv.org/abs/1710.01809 | id:1710.01809 author:Heike Adel, Ngoc Thang Vu, Katrin Kirchhoff, Dominic Telaar, Tanja Schultz category:cs.CL  published:2017-10-04 summary:This paper presents our latest investigations on different features for factored language models for Code-Switching speech and their effect on automatic speech recognition (ASR) performance. We focus on syntactic and semantic features which can be extracted from Code-Switching text data and integrate them into factored language models. Different possible factors, such as words, part-of-speech tags, Brown word clusters, open class words and clusters of open class word embeddings are explored. The experimental results reveal that Brown word clusters, part-of-speech tags and open-class words are the most effective at reducing the perplexity of factored language models on the Mandarin-English Code-Switching corpus SEAME. In ASR experiments, the model containing Brown word clusters and part-of-speech tags and the model also including clusters of open class word embeddings yield the best mixed error rate results. In summary, the best language model can significantly reduce the perplexity on the SEAME evaluation set by up to 10.8% relative and the mixed error rate by up to 3.4% relative. version:1
arxiv-1710-00132 | Dense RGB-D semantic mapping with Pixel-Voxel neural network | http://arxiv.org/abs/1710.00132 | id:1710.00132 author:Cheng Zhao, Li Sun, Pulak Purkait, Rustam Stolkin category:cs.CV  published:2017-09-30 summary:For intelligent robotics applications, extending 3D mapping to 3D semantic mapping enables robots to, not only localize themselves with respect to the scene's geometrical features but also simultaneously understand the higher level meaning of the scene contexts. Most previous methods focus on geometric 3D reconstruction and scene understanding independently notwithstanding the fact that joint estimation can boost the accuracy of the semantic mapping. In this paper, a dense RGB-D semantic mapping system with a Pixel-Voxel network is proposed, which can perform dense 3D mapping while simultaneously recognizing and semantically labelling each point in the 3D map. The proposed Pixel-Voxel network obtains global context information by using PixelNet to exploit the RGB image and meanwhile, preserves accurate local shape information by using VoxelNet to exploit the corresponding 3D point cloud. Unlike the existing architecture that fuses score maps from different models with equal weights, we proposed a Softmax weighted fusion stack that adaptively learns the varying contributions of PixelNet and VoxelNet, and fuses the score maps of the two models according to their respective confidence levels. The proposed Pixel-Voxel network achieves the state-of-the-art semantic segmentation performance on the SUN RGB-D benchmark dataset. The runtime of the proposed system can be boosted to 11-12Hz, enabling near to real-time performance using an i7 8-cores PC with Titan X GPU. version:3
arxiv-1710-01799 | Counterfactual Language Model Adaptation for Suggesting Phrases | http://arxiv.org/abs/1710.01799 | id:1710.01799 author:Kenneth C. Arnold, Kai-Wei Chang, Adam T. Kalai category:cs.CL  published:2017-10-04 summary:Mobile devices use language models to suggest words and phrases for use in text entry. Traditional language models are based on contextual word frequency in a static corpus of text. However, certain types of phrases, when offered to writers as suggestions, may be systematically chosen more often than their frequency would predict. In this paper, we propose the task of generating suggestions that writers accept, a related but distinct task to making accurate predictions. Although this task is fundamentally interactive, we propose a counterfactual setting that permits offline training and evaluation. We find that even a simple language model can capture text characteristics that improve acceptability. version:1
arxiv-1710-01789 | Enhanced Neural Machine Translation by Learning from Draft | http://arxiv.org/abs/1710.01789 | id:1710.01789 author:Aodong Li, Shiyue Zhang, Dong Wang, Thomas Fang Zheng category:cs.CL  published:2017-10-04 summary:Neural machine translation (NMT) has recently achieved impressive results. A potential problem of the existing NMT algorithm, however, is that the decoding is conducted from left to right, without considering the right context. This paper proposes an two-stage approach to solve the problem. In the first stage, a conventional attention-based NMT system is used to produce a draft translation, and in the second stage, a novel double-attention NMT system is used to refine the translation, by looking at the original input as well as the draft translation. This drafting-and-refinement can obtain the right-context information from the draft, hence producing more consistent translations. We evaluated this approach using two Chinese-English translation tasks, one with 44k pairs and 1M pairs respectively. The experiments showed that our approach achieved positive improvements over the conventional NMT system: the improvements are 2.4 and 0.9 BLEU points on the small-scale and large-scale tasks, respectively. version:1
arxiv-1710-01788 | Multitask Learning using Task Clustering with Applications to Predictive Modeling and GWAS of Plant Varieties | http://arxiv.org/abs/1710.01788 | id:1710.01788 author:Ming Yu, Addie M. Thompson, Karthikeyan Natesan Ramamurthy, Eunho Yang, Aurélie C. Lozano category:stat.ML  published:2017-10-04 summary:Inferring predictive maps between multiple input and multiple output variables or tasks has innumerable applications in data science. Multi-task learning attempts to learn the maps to several output tasks simultaneously with information sharing between them. We propose a novel multi-task learning framework for sparse linear regression, where a full task hierarchy is automatically inferred from the data, with the assumption that the task parameters follow a hierarchical tree structure. The leaves of the tree are the parameters for individual tasks, and the root is the global model that approximates all the tasks. We apply the proposed approach to develop and evaluate: (a) predictive models of plant traits using large-scale and automated remote sensing data, and (b) GWAS methodologies mapping such derived phenotypes in lieu of hand-measured traits. We demonstrate the superior performance of our approach compared to other methods, as well as the usefulness of discovering hierarchical groupings between tasks. Our results suggest that richer genetic mapping can indeed be obtained from the remote sensing data. In addition, our discovered groupings reveal interesting insights from a plant science perspective. version:1
arxiv-1707-03017 | Learning Visual Reasoning Without Strong Priors | http://arxiv.org/abs/1707.03017 | id:1707.03017 author:Ethan Perez, Harm de Vries, Florian Strub, Vincent Dumoulin, Aaron Courville category:cs.CV cs.AI cs.CL stat.ML  published:2017-07-10 summary:Achieving artificial visual reasoning - the ability to answer image-related questions which require a multi-step, high-level process - is an important step towards artificial general intelligence. This multi-modal task requires learning a question-dependent, structured reasoning process over images from language. Standard deep learning approaches tend to exploit biases in the data rather than learn this underlying structure, while leading methods learn to visually reason successfully but are hand-crafted for reasoning. We show that a general-purpose, Conditional Batch Normalization approach achieves state-of-the-art results on the CLEVR Visual Reasoning benchmark with a 2.4% error rate. We outperform the next best end-to-end method (4.5%) and even methods that use extra supervision (3.1%). We probe our model to shed light on how it reasons, showing it has learned a question-dependent, multi-step process. Previous work has operated under the assumption that visual reasoning calls for a specialized architecture, but we show that a general architecture with proper conditioning can learn to visually reason effectively. version:4
arxiv-1710-01779 | Building a Web-Scale Dependency-Parsed Corpus from CommonCrawl | http://arxiv.org/abs/1710.01779 | id:1710.01779 author:Alexander Panchenko, Eugen Ruppert, Stefano Faralli, Simone Paolo Ponzetto, Chris Biemann category:cs.CL  published:2017-10-04 summary:We present DepCC, the largest to date linguistically analyzed corpus in English including 365 million documents, composed of 252 billion tokens and 7.5 billion of named entity occurrences in 14.3 billion sentences from a web-scale crawl of the CommonCrawl project. The sentences are processed with a dependency parser and with a named entity tagger and contain provenance information, enabling various applications ranging from training syntax-based word embeddings based on to open information extraction and question answering. We demonstrate the utility of this corpus on the verb similarity task by showing that a distributional model trained on our corpus yields better results than models trained on smaller corpora, like Wikipedia. This distributional model outperforms the state of art models of verb similarity trained on smaller corpora on the SimVerb3500 dataset. version:1
arxiv-1710-01758 | Accelerating CS in Parallel Imaging Reconstructions Using an Efficient and Effective Circulant Preconditioner | http://arxiv.org/abs/1710.01758 | id:1710.01758 author:Kirsten Koolstra, Jeroen van Gemert, Peter Börnert, Andrew Webb, Rob Remis category:cs.CV  published:2017-10-04 summary:Purpose: Design of a preconditioner for fast and efficient parallel imaging and compressed sensing reconstructions. Theory: Parallel imaging and compressed sensing reconstructions become time consuming when the problem size or the number of coils is large, due to the large linear system of equations that has to be solved in l_1 and l_2-norm based reconstruction algorithms. Such linear systems can be solved efficiently using effective preconditioning techniques. Methods: In this paper we construct such a preconditioner by approximating the system matrix of the linear system, which comprises the data fidelity and includes total variation and wavelet regularization, by a matrix with the assumption that is a block circulant matrix with circulant blocks. Due to its circulant structure, the preconditioner can be constructed quickly and its inverse can be evaluated fast using only two fast Fourier transformations. We test the performance of the preconditioner for the conjugate gradient method as the linear solver, integrated into the Split Bregman algorithm. Results: The designed circulant preconditioner reduces the number of iterations required in the conjugate gradient method by almost a factor of~5. The speed up results in a total acceleration factor of approximately 2.5 for the entire reconstruction algorithm when implemented in MATLAB, while the initialization time of the preconditioner is negligible. Conclusion: The proposed preconditioner reduces the reconstruction time for parallel imaging and compressed sensing in a Split Bregman implementation and can easily handle large systems since it is Fourier-based, allowing for efficient computations. Key words: preconditioning; compressed sensing; Split Bregman; parallel imaging version:1
arxiv-1710-01749 | Semantic 3D Reconstruction with Finite Element Bases | http://arxiv.org/abs/1710.01749 | id:1710.01749 author:Audrey Richard, Christoph Vogel, Maros Blaha, Thomas Pock, Konrad Schindler category:cs.CV  published:2017-10-04 summary:We propose a novel framework for the discretisation of multi-label problems on arbitrary, continuous domains. Our work bridges the gap between general FEM discretisations, and labeling problems that arise in a variety of computer vision tasks, including for instance those derived from the generalised Potts model. Starting from the popular formulation of labeling as a convex relaxation by functional lifting, we show that FEM discretisation is valid for the most general case, where the regulariser is anisotropic and non-metric. While our findings are generic and applicable to different vision problems, we demonstrate their practical implementation in the context of semantic 3D reconstruction, where such regularisers have proved particularly beneficial. The proposed FEM approach leads to a smaller memory footprint as well as faster computation, and it constitutes a very simple way to enable variable, adaptive resolution within the same model. version:1
arxiv-1710-01720 | Smooth Pinball Neural Network for Probabilistic Forecasting of Wind Power | http://arxiv.org/abs/1710.01720 | id:1710.01720 author:Kostas Hatalis, Alberto J. Lamadrid, Katya Scheinberg, Shalinee Kishore category:stat.ML  published:2017-10-04 summary:Uncertainty analysis in the form of probabilistic forecasting can significantly improve decision making processes in the smart power grid for better integrating renewable energy sources such as wind. Whereas point forecasting provides a single expected value, probabilistic forecasts provide more information in the form of quantiles, prediction intervals, or full predictive densities. This paper analyzes the effectiveness of a novel approach for nonparametric probabilistic forecasting of wind power that combines a smooth approximation of the pinball loss function with a neural network architecture and a weighting initialization scheme to prevent the quantile cross over problem. A numerical case study is conducted using publicly available wind data from the Global Energy Forecasting Competition 2014. Multiple quantiles are estimated to form 10%, to 90% prediction intervals which are evaluated using a quantile score and reliability measures. Benchmark models such as the persistence and climatology distributions, multiple quantile regression, and support vector quantile regression are used for comparison where results demonstrate the proposed approach leads to improved performance while preventing the problem of overlapping quantile estimates. version:1
arxiv-1710-01711 | Grader variability and the importance of reference standards for evaluating machine learning models for diabetic retinopathy | http://arxiv.org/abs/1710.01711 | id:1710.01711 author:Jonathan Krause, Varun Gulshan, Ehsan Rahimy, Peter Karth, Kasumi Widner, Greg S. Corrado, Lily Peng, Dale R. Webster category:cs.CV  published:2017-10-04 summary:Diabetic retinopathy (DR) and diabetic macular edema are common complications of diabetes which can lead to vision loss. The grading of DR is a fairly complex process that requires the detection of fine features such as microaneurysms, intraretinal hemorrhages, and intraretinal microvascular abnormalities. Because of this, there can be a fair amount of grader variability. There are different methods of obtaining the reference standard and resolving disagreements between graders, and while it is usually accepted that adjudication until full consensus will yield the best reference standard, the difference between various methods of resolving disagreements has not been examined extensively. In this study, we examine the variability in different methods of grading, definitions of reference standards, and their effects on building deep learning models for the detection of diabetic eye disease. We find that a small set of adjudicated DR grades allows substantial improvements in algorithm performance. The resulting algorithm's performance was on par with that of individual U.S. board-certified ophthalmologists and retinal specialists. version:1
arxiv-1710-01688 | On the Sample Complexity of the Linear Quadratic Regulator | http://arxiv.org/abs/1710.01688 | id:1710.01688 author:Sarah Dean, Horia Mania, Nikolai Matni, Benjamin Recht, Stephen Tu category:math.OC cs.LG stat.ML  published:2017-10-04 summary:This paper addresses the optimal control problem known as the Linear Quadratic Regulator in the case when the dynamics are unknown. We propose a multi-stage procedure, called Coarse-ID control, that estimates a model from a few experimental trials, estimates the error in that model with respect to the truth, and then designs a controller using both the model and uncertainty estimate. Our technique uses contemporary tools from random matrix theory to bound the error in the estimation procedure. We also employ a recently developed approach to control synthesis called System Level Synthesis that enables robust control design by solving a convex optimization problem. We provide end-to-end bounds on the relative error in control cost that are nearly optimal in the number of parameters and that highlight salient properties of the system to be controlled such as closed-loop sensitivity and optimal control magnitude. We show experimentally that the Coarse-ID approach enables efficient computation of a stabilizing controller in regimes where simple control schemes that do not take the model uncertainty into account fail to stabilize the true system. version:1
arxiv-1710-05705 | Blind Image Fusion for Hyperspectral Imaging with the Directional Total Variation | http://arxiv.org/abs/1710.05705 | id:1710.05705 author:Leon Bungert, David A. Coomes, Matthias J. Ehrhardt, Jennifer Rasch, Rafael Reisenhofer, Carola-Bibiane Schönlieb category:cs.CV cs.NA math.NA  published:2017-10-04 summary:Hyperspectral imaging is a cutting-edge type of remote sensing used for mapping vegetation properties, rock minerals and other materials. A major drawback of hyperspectral imaging devices is their intrinsic low spatial resolution. In this paper, we propose a method for increasing the spatial resolution of a hyperspectral image by fusing it with an image of higher spatial resolution that was obtained with a different imaging modality. This is accomplished by solving a variational problem in which the regularization functional is the directional total variation. To accommodate for possible mis-registrations between the two images, we consider a non-convex blind super-resolution problem where both a fused image and the corresponding convolution kernel are estimated. Using this approach, our model can realign the given images if needed. Our experimental results indicate that the non-convexity is negligible in practice and that reliable solutions can be computed using a variety of different optimization algorithms. Numerical results on real remote sensing data from plant sciences and urban monitoring show the potential of the proposed method and suggests that it is robust with respect to the regularization parameters, mis-registration and the shape of the kernel. version:1
arxiv-1709-05321 | Learning Functional Causal Models with Generative Neural Networks | http://arxiv.org/abs/1709.05321 | id:1709.05321 author:Olivier Goudet, Diviyan Kalainathan, Philippe Caillou, David Lopez-Paz, Isabelle Guyon, Michèle Sebag, Aris Tritas, Paola Tubaro category:stat.ML  published:2017-09-15 summary:We introduce a new approach to functional causal modeling from observational data. The approach, called Causal Generative Neural Networks (CGNN), leverages the power of neural networks to learn a generative model of the joint distribution of the observed variables, by minimizing the Maximum Mean Discrepancy between generated and observed data. An approximate learning criterion is proposed to scale the computational cost of the approach to linear complexity in the number of observations. The performance of CGNN is studied throughout three experiments. First, we apply CGNN to the problem of cause-effect inference, where two CGNNs model $P(Y X,\textrm{noise})$ and $P(X Y,\textrm{noise})$ identify the best causal hypothesis out of $X\rightarrow Y$ and $Y\rightarrow X$. Second, CGNN is applied to the problem of identifying v-structures and conditional independences. Third, we apply CGNN to problem of multivariate functional causal modeling: given a skeleton describing the dependences in a set of random variables $\{X_1, \ldots, X_d\}$, CGNN orients the edges in the skeleton to uncover the directed acyclic causal graph describing the causal structure of the random variables. On all three tasks, CGNN is extensively assessed on both artificial and real-world data, comparing favorably to the state-of-the-art. Finally, we extend CGNN to handle the case of confounders, where latent variables are involved in the overall causal model. version:2
arxiv-1710-01641 | Differentially Private Database Release via Kernel Mean Embeddings | http://arxiv.org/abs/1710.01641 | id:1710.01641 author:Matej Balog, Ilya Tolstikhin, Bernhard Schölkopf category:stat.ML  published:2017-10-04 summary:We lay theoretical foundations for new database release mechanisms that allow third-parties to construct consistent estimators of population statistics, while ensuring that the privacy of each individual contributing to the database is protected. The proposed framework rests on two main ideas. First, releasing (an estimate of) the kernel mean embedding of the data generating random variable instead of the database itself still allows third-parties to construct consistent estimators of a wide class of population statistics. Second, the algorithm can satisfy the definition of differential privacy by basing the released kernel mean embedding on entirely synthetic data points, while controlling accuracy through the metric available in a Reproducing Kernel Hilbert Space. We describe two instantiations of the proposed framework, suitable under different scenarios, and prove theoretical results guaranteeing differential privacy of the resulting algorithms and the consistency of estimators constructed from their outputs. version:1
arxiv-1710-01602 | GraphMatch: Efficient Large-Scale Graph Construction for Structure from Motion | http://arxiv.org/abs/1710.01602 | id:1710.01602 author:Qiaodong Cui, Victor Fragoso, Chris Sweeney, Pradeep Sen category:cs.CV  published:2017-10-04 summary:We present GraphMatch, an approximate yet efficient method for building the matching graph for large-scale structure-from-motion (SfM) pipelines. Unlike modern SfM pipelines that use vocabulary (Voc.) trees to quickly build the matching graph and avoid a costly brute-force search of matching image pairs, GraphMatch does not require an expensive offline pre-processing phase to construct a Voc. tree. Instead, GraphMatch leverages two priors that can predict which image pairs are likely to match, thereby making the matching process for SfM much more efficient. The first is a score computed from the distance between the Fisher vectors of any two images. The second prior is based on the graph distance between vertices in the underlying matching graph. GraphMatch combines these two priors into an iterative "sample-and-propagate" scheme similar to the PatchMatch algorithm. Its sampling stage uses Fisher similarity priors to guide the search for matching image pairs, while its propagation stage explores neighbors of matched pairs to find new ones with a high image similarity score. Our experiments show that GraphMatch finds the most image pairs as compared to competing, approximate methods while at the same time being the most efficient. version:1
arxiv-1710-01115 | Detection of Inferior Myocardial Infarction using Shallow Convolutional Neural Networks | http://arxiv.org/abs/1710.01115 | id:1710.01115 author:Tahsin Reasat, Celia Shahnaz category:cs.CV 68T10  68T10 I.5.1; I.5.4  published:2017-10-03 summary:Myocardial Infarction is one of leading causes of death worldwide. This paper presents a Convolutional Neural Network (CNN) architecture which takes raw Electrocardiography (ECG) signal from lead II, III and AVF and differentiates between inferior myocardial infarction (IMI) and healthy signals. The performance of the model is evaluated on IMI and healthy signals obtained from Physikalisch-Technische Bundesanstalt (PTB) database. A subject-oriented approach is taken to comprehend the generalization capability of the model and compared with the current state of the art. In a subject-oriented approach, the network is tested on one patient and trained on rest of the patients. Our model achieved a superior metrics scores (accuracy= 84.54%, sensitivity= 85.33% and specificity= 84.09%) compared to the benchmark. We also analyzed the discriminating strength of the features extracted by the convolutional layers by means of geometric separability index and euclidean distance and compared it with the benchmark model. version:2
arxiv-1710-01592 | Spectral estimation of the percolation transition in clustered networks | http://arxiv.org/abs/1710.01592 | id:1710.01592 author:Pan Zhang category:physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech cs.CY stat.ML  published:2017-10-04 summary:There have been several spectral bounds for the percolation transition in networks, using spectrum of matrices associated with the network such as the adjacency matrix and the non-backtracking matrix. However they are far from being tight when the network is sparse and displays clustering or transitivity, which is represented by existence of short loops e.g. triangles. In this work, for the bond percolation, we first propose a message passing algorithm for calculating size of percolating clusters considering effects of triangles, then relate the percolation transition to the leading eigenvalue of a matrix that we name the triangle-non-backtracking matrix, by analyzing stability of the message passing equations. We establish that our method gives a tighter lower-bound to the bond percolation transition than previous spectral bounds, and it becomes exact for an infinite network with no loops longer than 3. We evaluate numerically our methods on synthetic and real-world networks, and discuss further generalizations of our approach to include higher-order sub-structures. version:1
arxiv-1709-03749 | Deep Mean-Shift Priors for Image Restoration | http://arxiv.org/abs/1709.03749 | id:1709.03749 author:Siavash Arjomand Bigdeli, Meiguang Jin, Paolo Favaro, Matthias Zwicker category:cs.CV cs.LG  published:2017-09-12 summary:In this paper we introduce a natural image prior that directly represents a Gaussian-smoothed version of the natural image distribution. We include our prior in a formulation of image restoration as a Bayes estimator that also allows us to solve noise-blind image restoration problems. We show that the gradient of our prior corresponds to the mean-shift vector on the natural image distribution. In addition, we learn the mean-shift vector field using denoising autoencoders, and use it in a gradient descent approach to perform Bayes risk minimization. We demonstrate competitive results for noise-blind deblurring, super-resolution, and demosaicing. version:2
arxiv-1710-01559 | Monitoring tool usage in cataract surgery videos using boosted convolutional and recurrent neural networks | http://arxiv.org/abs/1710.01559 | id:1710.01559 author:Hassan Al Hajj, Mathieu Lamard, Pierre-Henri Conze, Béatrice Cochener, Gwenolé Quellec category:cs.CV  published:2017-10-04 summary:With an estimated 19 million operations performed annually, cataract surgery is the most common surgical procedure. This paper investigates the automatic monitoring of tool usage during a cataract surgery, with potential applications in report generation, surgical training and real-time decision support. In this study, tool usage is monitored in videos recorded through the surgical microscope. Following state-of-the-art video analysis solutions, each frame of the video is analyzed by convolutional neural networks (CNNs) whose outputs are fed to recurrent neural networks (RNNs) in order to take temporal relationships between events into account. Novelty lies in the way those CNNs and RNNs are trained. Computational complexity prevents the end-to-end training of "CNN+RNN" systems. Therefore, CNNs are usually trained first, independently from the RNNs. This approach is clearly suboptimal for surgical tool analysis: many tools are very similar to one another, but they can generally be differentiated based on past events. CNNs should be trained to extract the most useful visual features in combination with the temporal context. A novel boosting strategy is proposed to achieve this goal: the CNN and RNN parts of the system are simultaneously enriched by progressively adding weak classifiers (either CNNs or RNNs) trained to improve the overall classification accuracy. Experiments were performed in a new dataset of 50 cataract surgery videos where the usage of 21 surgical tools was manually annotated. Very good classification performance are achieved in this dataset: tool usage could be labeled with an average area under the ROC curve of $A_z$ = 0.9717 in offline mode (using past, present and future information) and $A_z$ = 0.9696 in online mode (using past and present information only). version:1
arxiv-1709-01695 | A Compact Kernel Approximation for 3D Action Recognition | http://arxiv.org/abs/1709.01695 | id:1709.01695 author:Jacopo Cavazza, Pietro Morerio, Vittorio Murino category:cs.CV  published:2017-09-06 summary:3D action recognition was shown to benefit from a covariance representation of the input data (joint 3D positions). A kernel machine feed with such feature is an effective paradigm for 3D action recognition, yielding state-of-the-art results. Yet, the whole framework is affected by the well-known scalability issue. In fact, in general, the kernel function has to be evaluated for all pairs of instances inducing a Gram matrix whose complexity is quadratic in the number of samples. In this work we reduce such complexity to be linear by proposing a novel and explicit feature map to approximate the kernel function. This allows to train a linear classifier with an explicit feature encoding, which implicitly implements a Log-Euclidean machine in a scalable fashion. Not only we prove that the proposed approximation is unbiased, but also we work out an explicit strong bound for its variance, attesting a theoretical superiority of our approach with respect to existing ones. Experimentally, we verify that our representation provides a compact encoding and outperforms other approximation schemes on a number of publicly available benchmark datasets for 3D action recognition. version:2
arxiv-1710-01507 | A Neural Clickbait Detection Engine | http://arxiv.org/abs/1710.01507 | id:1710.01507 author:Siddhartha Gairola, Yash Kumar Lal, Vaibhav Kumar, Dhruv Khattar category:cs.IR cs.CL cs.CY cs.SI  published:2017-10-04 summary:In an age where people are becoming increasing likely to trust information found through online media, journalists have begun employing techniques to lure readers to articles by using catchy headlines, called clickbait. These headlines entice the user into clicking through the article whilst not providing information relevant to the headline itself. Previous methods of detecting clickbait have explored techniques heavily dependent on feature engineering, with little experimentation having been tried with neural network architectures. We introduce a novel model combining recurrent neural networks, attention layers and image embeddings. Our model uses a combination of distributed word embeddings derived from unannotated corpora, character level embeddings calculated through Convolutional Neural Networks. These representations are passed through a bidirectional LSTM with an attention layer. The image embeddings are also learnt from large data using CNNs. Experi- mental results show that our model achieves an F1 score of 65.37% beating the previous benchmark of 55.21%. version:1
arxiv-1710-01504 | Discourse Structure in Machine Translation Evaluation | http://arxiv.org/abs/1710.01504 | id:1710.01504 author:Shafiq Joty, Francisco Guzmán, Lluís Màrquez, Preslav Nakov category:cs.CL 68T50 I.2.7  published:2017-10-04 summary:In this article, we explore the potential of using sentence-level discourse structure for machine translation evaluation. We first design discourse-aware similarity measures, which use all-subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory (RST). Then, we show that a simple linear combination with these measures can help improve various existing machine translation evaluation metrics regarding correlation with human judgments both at the segment- and at the system-level. This suggests that discourse information is complementary to the information used by many of the existing evaluation metrics, and thus it could be taken into account when developing richer evaluation metrics, such as the WMT-14 winning combined metric DiscoTKparty. We also provide a detailed analysis of the relevance of various discourse elements and relations from the RST parse trees for machine translation evaluation. In particular we show that: (i) all aspects of the RST tree are relevant, (ii) nuclearity is more useful than relation type, and (iii) the similarity of the translation RST tree to the reference tree is positively correlated with translation quality. version:1
arxiv-1710-01494 | Strengths and Weaknesses of Deep Learning Models for Face Recognition Against Image Degradations | http://arxiv.org/abs/1710.01494 | id:1710.01494 author:Klemen Grm, Vitomir Štruc, Anais Artiges, Matthieu Caron, Hazim Kemal Ekenel category:stat.ML  published:2017-10-04 summary:Deep convolutional neural networks (CNNs) based approaches are the state-of-the-art in various computer vision tasks, including face recognition. Considerable research effort is currently being directed towards further improving deep CNNs by focusing on more powerful model architectures and better learning techniques. However, studies systematically exploring the strengths and weaknesses of existing deep models for face recognition are still relatively scarce in the literature. In this paper, we try to fill this gap and study the effects of different covariates on the verification performance of four recent deep CNN models using the Labeled Faces in the Wild (LFW) dataset. Specifically, we investigate the influence of covariates related to: image quality -- blur, JPEG compression, occlusion, noise, image brightness, contrast, missing pixels; and model characteristics -- CNN architecture, color information, descriptor computation; and analyze their impact on the face verification performance of AlexNet, VGG-Face, GoogLeNet, and SqueezeNet. Based on comprehensive and rigorous experimentation, we identify the strengths and weaknesses of the deep learning models, and present key areas for potential future research. Our results indicate that high levels of noise, blur, missing pixels, and brightness have a detrimental effect on the verification performance of all models, whereas the impact of contrast changes and compression artifacts is limited. It has been found that the descriptor computation strategy and color information does not have a significant influence on performance. version:1
arxiv-1710-01493 | Image Labeling Based on Graphical Models Using Wasserstein Messages and Geometric Assignment | http://arxiv.org/abs/1710.01493 | id:1710.01493 author:Ruben Hühnerbein, Fabrizio Savarino, Freddie Åström, Christoph Schnörr category:cs.LG cs.CV cs.NA math.OC  published:2017-10-04 summary:We introduce a novel approach to Maximum A Posteriori inference based on discrete graphical models. By utilizing local Wasserstein distances for coupling assignment measures across edges of the underlying graph, a given discrete objective function is smoothly approximated and restricted to the assignment manifold. A corresponding multiplicative update scheme combines in a single process (i) geometric integration of the resulting Riemannian gradient flow and (ii) rounding to integral solutions that represent valid labelings. Throughout this process, local marginalization constraints known from the established LP relaxation are satisfied, whereas the smooth geometric setting results in rapidly converging iterations that can be carried out in parallel for every edge. version:1
arxiv-1710-01492 | Semantic Sentiment Analysis of Twitter Data | http://arxiv.org/abs/1710.01492 | id:1710.01492 author:Preslav Nakov category:cs.CL 68T50 I.2.7  published:2017-10-04 summary:Internet and the proliferation of smart mobile devices have changed the way information is created, shared, and spreads, e.g., microblogs such as Twitter, weblogs such as LiveJournal, social networks such as Facebook, and instant messengers such as Skype and WhatsApp are now commonly used to share thoughts and opinions about anything in the surrounding world. This has resulted in the proliferation of social media content, thus creating new opportunities to study public opinion at a scale that was never possible before. Naturally, this abundance of data has quickly attracted business and research interest from various fields including marketing, political science, and social studies, among many others, which are interested in questions like these: Do people like the new Apple Watch? Do Americans support ObamaCare? How do Scottish feel about the Brexit? Answering these questions requires studying the sentiment of opinions people express in social media, which has given rise to the fast growth of the field of sentiment analysis in social media, with Twitter being especially popular for research due to its scale, representativeness, variety of topics discussed, as well as ease of public access to its messages. Here we present an overview of work on sentiment analysis on Twitter. version:1
arxiv-1710-01490 | Multifractal analysis of the time series of daily means of wind speed in complex regions | http://arxiv.org/abs/1710.01490 | id:1710.01490 author:Mohamed Laib, Jean Golay, Luciano Telesca, Mikhail Kanevski category:stat.AP stat.ME stat.ML  published:2017-10-04 summary:In this paper, we applied the multifractal detrended fluctuation analysis to the daily means of wind speed measured by 119 weather stations distributed over the territory of Switzerland. The analysis was focused on the inner time fluctuations of wind speed, which could be more linked with the local conditions of the highly varying topography of Switzerland. Our findings point out to a persistent behaviour of all the measured wind speed series (indicated by a Hurst exponent significantly larger than 0.5), and to a high multifractality degree indicating a relative dominance of the large fluctuations in the dynamics of wind speed, especially in the Swiss plateau, which is comprised between the Jura and Alp mountain ranges. The study represents a contribution to the understanding of the dynamical mechanisms of wind speed variability in mountainous regions. version:1
arxiv-1710-01025 | MMCR4NLP: Multilingual Multiway Corpora Repository for Natural Language Processing | http://arxiv.org/abs/1710.01025 | id:1710.01025 author:Raj Dabre, Sadao Kurohashi category:cs.CL  published:2017-10-03 summary:Multilinguality is gradually becoming ubiquitous in the sense that more and more researchers have successfully shown that using additional languages help improve the results in many Natural Language Processing tasks. Multilingual Multiway Corpora (MMC) contain the same sentence in multiple languages. Such corpora have been primarily used for Multi-Source and Pivot Language Machine Translation but are also useful for developing multilingual sequence taggers by transfer learning. While these corpora are available, they are not organized for multilingual experiments and researchers need to write boilerplate code every time they want to use said corpora. Moreover, because there is no official MMC collection it becomes difficult to compare against existing approaches. As such we present our work on creating a unified and systematically organized repository of MMC spanning a large number of languages. We also provide training, development and test splits for corpora where official splits are unavailable. We hope that this will help speed up the pace of multilingual NLP research and ensure that NLP researchers obtain results that are more trustable since they can be compared easily. We indicate corpora sources, extraction procedures if any and relevant statistics. We also make our collection public for research purposes. version:2
arxiv-1710-01487 | Cross-Language Question Re-Ranking | http://arxiv.org/abs/1710.01487 | id:1710.01487 author:Giovanni Da San Martino, Salvatore Romeo, Alberto Barron-Cedeno, Shafiq Joty, Lluis Marquez, Alessandro Moschitti, Preslav Nakov category:cs.CL 68T50 I.2.7  published:2017-10-04 summary:We study how to find relevant questions in community forums when the language of the new questions is different from that of the existing questions in the forum. In particular, we explore the Arabic-English language pair. We compare a kernel-based system with a feed-forward neural network in a scenario where a large parallel corpus is available for training a machine translation system, bilingual dictionaries, and cross-language word embeddings. We observe that both approaches degrade the performance of the system when working on the translated text, especially the kernel-based system, which depends heavily on a syntactic kernel. We address this issue using a cross-language tree kernel, which compares the original Arabic tree to the English trees of the related questions. We show that this kernel almost closes the performance gap with respect to the monolingual system. On the neural network side, we use the parallel corpus to train cross-language embeddings, which we then use to represent the Arabic input and the English related questions in the same space. The results also improve to close to those of the monolingual neural network. Overall, the kernel system shows a better performance compared to the neural network in all cases. version:1
arxiv-1710-01467 | Mean-field theory of input dimensionality reduction in unsupervised deep neural networks | http://arxiv.org/abs/1710.01467 | id:1710.01467 author:Haiping Huang category:cs.LG cond-mat.stat-mech stat.ML  published:2017-10-04 summary:Deep neural networks as powerful tools are widely used in various domains. However, the nature of computations in each layer of the deep networks is far from being understood. Increasing the interpretability of deep neural networks is thus important. Here, we construct a mean-field framework to understand how compact representations are developed across layers, not only in deterministic random deep networks but also in generative deep networks where network parameters are learned from input data. Our theory shows that the deep computation implements a dimensionality reduction while maintaining a finite level of weak correlations between neurons for possible feature extraction. This work paves the way for understanding how a sensory hierarchy works in general. version:1
arxiv-1710-01462 | Secrets in Computing Optical Flow by Convolutional Networks | http://arxiv.org/abs/1710.01462 | id:1710.01462 author:Junxuan Li category:cs.CV  published:2017-10-04 summary:Convolutional neural networks (CNNs) have been widely used over many areas in compute vision. Especially in classification. Recently, FlowNet and several works on opti- cal estimation using CNNs shows the potential ability of CNNs in doing per-pixel regression. We proposed several CNNs network architectures that can estimate optical flow, and fully unveiled the intrinsic different between these structures. version:1
arxiv-1710-01457 | Learning to Segment Human by Watching YouTube | http://arxiv.org/abs/1710.01457 | id:1710.01457 author:Xiaodan Liang, Yunchao Wei, Liang Lin, Yunpeng Chen, Xiaohui Shen, Jianchao Yang, Shuicheng Yan category:cs.CV  published:2017-10-04 summary:An intuition on human segmentation is that when a human is moving in a video, the video-context (e.g., appearance and motion clues) may potentially infer reasonable mask information for the whole human body. Inspired by this, based on popular deep convolutional neural networks (CNN), we explore a very-weakly supervised learning framework for human segmentation task, where only an imperfect human detector is available along with massive weakly-labeled YouTube videos. In our solution, {the video-context guided human mask inference and CNN based segmentation network learning iterate to mutually enhance each other until no further improvement gains.} In the first step, each video is decomposed into supervoxels by the unsupervised video segmentation. The superpixels within the supervoxels are then classified as human or non-human by graph optimization with unary energies from the imperfect human detection results and the predicted confidence maps by the CNN trained in the previous iteration. In the second step, the video-context derived human masks are used as direct labels to train CNN. Extensive experiments on the challenging PASCAL VOC 2012 semantic segmentation benchmark demonstrate that the proposed framework has already achieved superior results than all previous weakly-supervised methods with object class or bounding box annotations. In addition, by augmenting with the annotated masks from PASCAL VOC 2012, our method reaches a new state-of-the-art performance on the human segmentation task. version:1
arxiv-1710-01453 | Content-Adaptive Sketch Portrait Generation by Decompositional Representation Learning | http://arxiv.org/abs/1710.01453 | id:1710.01453 author:Dongyu Zhang, Liang Lin, Tianshui Chen, Xian Wu, Wenwei Tan, Ebroul Izquierdo category:cs.CV  published:2017-10-04 summary:Sketch portrait generation benefits a wide range of applications such as digital entertainment and law enforcement. Although plenty of efforts have been dedicated to this task, several issues still remain unsolved for generating vivid and detail-preserving personal sketch portraits. For example, quite a few artifacts may exist in synthesizing hairpins and glasses, and textural details may be lost in the regions of hair or mustache. Moreover, the generalization ability of current systems is somewhat limited since they usually require elaborately collecting a dictionary of examples or carefully tuning features/components. In this paper, we present a novel representation learning framework that generates an end-to-end photo-sketch mapping through structure and texture decomposition. In the training stage, we first decompose the input face photo into different components according to their representational contents (i.e., structural and textural parts) by using a pre-trained Convolutional Neural Network (CNN). Then, we utilize a Branched Fully Convolutional Neural Network (BFCN) for learning structural and textural representations, respectively. In addition, we design a Sorted Matching Mean Square Error (SM-MSE) metric to measure texture patterns in the loss function. In the stage of sketch rendering, our approach automatically generates structural and textural representations for the input photo and produces the final result via a probabilistic fusion scheme. Extensive experiments on several challenging benchmarks suggest that our approach outperforms example-based synthesis algorithms in terms of both perceptual and objective metrics. In addition, the proposed method also has better generalization ability across dataset without additional training. version:1
arxiv-1710-01444 | Visual Tracking via Learning Dynamic Patch-based Graph Representation | http://arxiv.org/abs/1710.01444 | id:1710.01444 author:Chenglong Li, Liang Lin, Wangmeng Zuo, Jin Tang, Ming-Hsuan Yang category:cs.CV  published:2017-10-04 summary:Existing visual tracking methods usually localize a target object with a bounding box, in which the performance of the foreground object trackers or detectors is often affected by the inclusion of background clutter. To handle this problem, we learn a patch-based graph representation for visual tracking. The tracked object is modeled by with a graph by taking a set of non-overlapping image patches as nodes, in which the weight of each node indicates how likely it belongs to the foreground and edges are weighted for indicating the appearance compatibility of two neighboring nodes. This graph is dynamically learned and applied in object tracking and model updating. During the tracking process, the proposed algorithm performs three main steps in each frame. First, the graph is initialized by assigning binary weights of some image patches to indicate the object and background patches according to the predicted bounding box. Second, the graph is optimized to refine the patch weights by using a novel alternating direction method of multipliers. Third, the object feature representation is updated by imposing the weights of patches on the extracted image features. The object location is predicted by maximizing the classification score in the structured support vector machine. Extensive experiments show that the proposed tracking algorithm performs well against the state-of-the-art methods on large-scale benchmark datasets. version:1
arxiv-1710-01437 | Duality of Graphical Models and Tensor Networks | http://arxiv.org/abs/1710.01437 | id:1710.01437 author:Elina Robeva, Anna Seigal category:math.ST cs.AI quant-ph stat.ML stat.TH  published:2017-10-04 summary:In this article we show the duality between tensor networks and undirected graphical models with discrete variables. We study tensor networks on hypergraphs, which we call tensor hypernetworks. We show that the tensor hypernetwork on a hypergraph exactly corresponds to the graphical model given by the dual hypergraph. We translate various notions under duality. For example, marginalization in a graphical model is dual to contraction in the tensor network. Algorithms also translate under duality. We show that belief propagation corresponds to a known algorithm for tensor network contraction. This article is a reminder that the research areas of graphical models and tensor networks can benefit from interaction. version:1
arxiv-1710-01422 | Effective Image Differencing with ConvNets for Real-time Transient Hunting | http://arxiv.org/abs/1710.01422 | id:1710.01422 author:Nima Sedaghat, Ashish Mahabal category:astro-ph.IM cs.CV  published:2017-10-04 summary:Large sky surveys are increasingly relying on image subtraction pipelines for real-time (and archival) transient detection. In this process one has to contend with varying PSF, small brightness variations in many sources, as well as artifacts resulting from saturated stars, and, in general, matching errors. Very often the differencing is done with a reference image that is deeper than individual images and the attendant difference in noise characteristics can also lead to artifacts. We present here a deep-learning approach to transient detection that encapsulates all the steps of a traditional image subtraction pipeline -- image registration, background subtraction, noise removal, psf matching, and subtraction -- into a single real-time convolutional network. Once trained the method works lighteningly fast, and given that it does multiple steps at one go, the advantages for multi-CCD, fast surveys like ZTF and LSST are obvious. version:1
arxiv-1710-01420 | AutoMode: Relational Learning With Less Black Magic | http://arxiv.org/abs/1710.01420 | id:1710.01420 author:Jose Picado, Sudhanshu Pathak, Arash Termehchy, Alan Fern category:cs.DB cs.LG  published:2017-10-03 summary:Relational databases are valuable resources for learning novel and interesting relations and concepts. Relational learning algorithms learn the Datalog definition of new relations in terms of the existing relations in the database. In order to constraint the search through the large space of candidate definitions, users must tune the algorithm by specifying a language bias. Unfortunately, specifying the language bias is done via trial and error and is guided by the expert's intuitions. Hence, it normally takes a great deal of time and effort to effectively use these algorithms. In particular, it is hard to find a user that knows computer science concepts, such as database schema, and has a reasonable intuition about the target relation in special domains, such as biology. We propose AutoMode, a system that leverages information in the schema and content of the database to automatically induce the language bias used by popular relational learning systems. We show that AutoMode delivers the same accuracy as using manually-written language bias by imposing only a slight overhead on the running time of the learning algorithm. version:1
arxiv-1710-01416 | Smoothness-based Edge Detection using Low-SNR Camera for Robot Navigation | http://arxiv.org/abs/1710.01416 | id:1710.01416 author:Vu Hoang Minh, Tajwar Abrar Aleef, Usama Pervaiz, Yeman Brhane Hagos, Saed Khawaldeh category:cs.CV cs.RO stat.AP stat.ML  published:2017-10-03 summary:In the emerging advancement in the branch of autonomous robotics, the ability of a robot to efficiently localize and construct maps of its surrounding is crucial. This paper deals with utilizing thermal-infrared cameras, as opposed to conventional cameras as the primary sensor to capture images of the robot's surroundings. For localization, the images need to be further processed before feeding them to a navigational system. The main motivation of this paper was to develop an edge detection methodology capable of utilizing the low-SNR poor output from such a thermal camera and effectively detect smooth edges of the surrounding environment. The enhanced edge detector proposed in this paper takes the raw image from the thermal sensor, denoises the images, applies Canny edge detection followed by CSS method. The edges are ranked to remove any noise and only edges of the highest rank are kept. Then, the broken edges are linked by computing edge metrics and a smooth edge of the surrounding is displayed in a binary image. Several comparisons are also made in the paper between the proposed technique and the existing techniques. version:1
arxiv-1710-01411 | Transferring Semantic Roles Using Translation and Syntactic Information | http://arxiv.org/abs/1710.01411 | id:1710.01411 author:Maryam Aminian, Mohammad Sadegh Rasooli, Mona Diab category:cs.CL  published:2017-10-03 summary:Our paper addresses the problem of annotation projection for semantic role labeling for resource-poor languages using supervised annotations from a resource-rich language through parallel data. We propose a transfer method that employs information from source and target syntactic dependencies as well as word alignment density to improve the quality of an iterative bootstrapping method. Our experiments yield a $3.5$ absolute labeled F-score improvement over a standard annotation projection method. version:1
arxiv-1710-01410 | Learning Registered Point Processes from Idiosyncratic Observations | http://arxiv.org/abs/1710.01410 | id:1710.01410 author:Hongteng Xu, Lawrence Carin, Hongyuan Zha category:stat.ML  published:2017-10-03 summary:A parametric point process model is developed, with modeling based on the assumption that sequential observations often share latent phenomena, while also possessing idiosyncratic effects. An alternating optimization method is proposed to learn a "registered" point process that accounts for shared structure, as well as "warping" functions that characterize idiosyncratic aspects of each observed sequence. Under reasonable constraints, in each iteration we update the sample-specific warping functions by solving a set of constrained nonlinear programming problems in parallel, and update the model by maximum likelihood estimation. The justifiability, complexity and robustness of the proposed method are investigated in detail. Experiments on both synthetic and real-world data demonstrate that the method yields explainable point process models, achieving encouraging results compared to state-of-the-art methods. version:1
arxiv-1710-01408 | A Fully Convolutional Network for Semantic Labeling of 3D Point Clouds | http://arxiv.org/abs/1710.01408 | id:1710.01408 author:Mohammed Yousefhussien, David J. Kelbe, Emmett J. Ientilucci, Carl Salvaggio category:cs.CV cs.LG stat.ML  published:2017-10-03 summary:When classifying point clouds, a large amount of time is devoted to the process of engineering a reliable set of features which are then passed to a classifier of choice. Generally, such features - usually derived from the 3D-covariance matrix - are computed using the surrounding neighborhood of points. While these features capture local information, the process is usually time-consuming, and requires the application at multiple scales combined with contextual methods in order to adequately describe the diversity of objects within a scene. In this paper we present a 1D-fully convolutional network that consumes terrain-normalized points directly with the corresponding spectral data,if available, to generate point-wise labeling while implicitly learning contextual features in an end-to-end fashion. Our method uses only the 3D-coordinates and three corresponding spectral features for each point. Spectral features may either be extracted from 2D-georeferenced images, as shown here for Light Detection and Ranging (LiDAR) point clouds, or extracted directly for passive-derived point clouds,i.e. from muliple-view imagery. We train our network by splitting the data into square regions, and use a pooling layer that respects the permutation-invariance of the input points. Evaluated using the ISPRS 3D Semantic Labeling Contest, our method scored second place with an overall accuracy of 81.6%. We ranked third place with a mean F1-score of 63.32%, surpassing the F1-score of the method with highest accuracy by 1.69%. In addition to labeling 3D-point clouds, we also show that our method can be easily extended to 2D-semantic segmentation tasks, with promising initial results. version:1
arxiv-1709-07326 | AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection | http://arxiv.org/abs/1709.07326 | id:1709.07326 author:Thanh-Toan Do, Anh Nguyen, Ian Reid, Darwin G. Caldwell, Nikos G. Tsagarakis category:cs.CV cs.RO  published:2017-09-21 summary:We propose AffordanceNet, a new deep learning approach to simultaneously detect multiple objects and their affordances from RGB images. Our AffordanceNet has two branches: an object detection branch to localize and classify the object, and an affordance detection branch to assign each pixel in the object to its most probable affordance label. The proposed framework employs three key components for effectively handling the multiclass problem in the affordance mask: a sequence of deconvolutional layers, a robust resizing strategy, and a multi-task loss function. The experimental results on the public datasets show that our AffordanceNet outperforms recent state-of-the-art methods by a fair margin, while its end-to-end architecture allows the inference at the speed of 150ms per image. This makes our AffordanceNet is well suitable for real-time robotic applications. Furthermore, we demonstrate the effectiveness of AffordanceNet in different testing environments and in real robotic applications. The source code is available at https://github.com/nqanh/affordance-net. version:2
arxiv-1710-01406 | Robust Hypothesis Test for Nonlinear Effect with Gaussian Processes | http://arxiv.org/abs/1710.01406 | id:1710.01406 author:Jeremiah Zhe Liu, Brent Coull category:stat.ML  published:2017-10-03 summary:This work constructs a hypothesis test for detecting whether an data-generating function $h: R^p \rightarrow R$ belongs to a specific reproducing kernel Hilbert space H0 , where the structure of $H_0$ is only partially known. Utilizing the theory of reproducing kernels, we reduce this hypothesis to a simple one-sided score test for a scalar parameter, develop a testing procedure that is robust against the mis-specification of kernel functions, and also propose an ensemble-based estimator for the null model to guarantee test performance in small samples. To demonstrate the utility of the proposed method, we apply our test to the problem of detecting nonlinear interaction between groups of continuous features. We evaluate the finite-sample performance of our test under different data-generating functions and estimation strategies for the null model. Our results reveal interesting connections between notions in machine learning (model underfit/overfit) and those in statisticalinference (i.e. Type I error/power of hypothesis test), and also highlight unexpected consequences of common model estimating strategies (e.g. estimating kernel hyperparameters using maximum likelihood estimation) on model inference. version:1
arxiv-1710-01370 | BodyDigitizer: An Open Source Photogrammetry-based 3D Body Scanner | http://arxiv.org/abs/1710.01370 | id:1710.01370 author:Travis Gesslein, Daniel Scherer, Jens Grubert category:cs.CV cs.HC  published:2017-10-03 summary:With the rising popularity of Augmented and Virtual Reality, there is a need for representing humans as virtual avatars in various application domains ranging from remote telepresence, games to medical applications. Besides explicitly modelling 3D avatars, sensing approaches that create person-specific avatars are becoming popular. However, affordable solutions typically suffer from a low visual quality and professional solution are often too expensive to be deployed in nonprofit projects. We present an open-source project, BodyDigitizer, which aims at providing both build instructions and configuration software for a high-resolution photogrammetry-based 3D body scanner. Our system encompasses up to 96 Rasperry PI cameras, active LED lighting, a sturdy frame construction and open-source configuration software. %We demonstrate the applicability of the body scanner in a nonprofit Mixed Reality health project. The detailed build instruction and software are available at http://www.bodydigitizer.org. version:1
arxiv-1710-01351 | Understanding the visual speech signal | http://arxiv.org/abs/1710.01351 | id:1710.01351 author:Helen L Bear category:cs.CV  published:2017-10-03 summary:For machines to lipread, or understand speech from lip movement, they decode lip-motions (known as visemes) into the spoken sounds. We investigate the visual speech channel to further our understanding of visemes. This has applications beyond machine lipreading; speech therapists, animators, and psychologists can benefit from this work. We explain the influence of speaker individuality, and demonstrate how one can use visemes to boost lipreading. version:1
arxiv-1708-05029 | Deep Neural Network Capacity | http://arxiv.org/abs/1708.05029 | id:1708.05029 author:Aosen Wang, Hua Zhou, Wenyao Xu, Xin Chen category:cs.CV  published:2017-08-16 summary:In recent years, deep neural network exhibits its powerful superiority on information discrimination in many computer vision applications. However, the capacity of deep neural network architecture is still a mystery to the researchers. Intuitively, larger capacity of neural network can always deposit more information to improve the discrimination ability of the model. But, the learnable parameter scale is not feasible to estimate the capacity of deep neural network. Due to the overfitting, directly increasing hidden nodes number and hidden layer number are already demonstrated not necessary to effectively increase the network discrimination ability. In this paper, we propose a novel measurement, named "total valid bits", to evaluate the capacity of deep neural networks for exploring how to quantitatively understand the deep learning and the insights behind its super performance. Specifically, our scheme to retrieve the total valid bits incorporates the skilled techniques in both training phase and inference phase. In the network training, we design decimal weight regularization and 8-bit forward quantization to obtain the integer-oriented network representations. Moreover, we develop adaptive-bitwidth and non-uniform quantization strategy in the inference phase to find the neural network capacity, total valid bits. By allowing zero bitwidth, our adaptive-bitwidth quantization can execute the model reduction and valid bits finding simultaneously. In our extensive experiments, we first demonstrate that our total valid bits is a good indicator of neural network capacity. We also analyze the impact on network capacity from the network architecture and advanced training skills, such as dropout and batch normalization. version:2
arxiv-1710-01347 | Simple Cortex: A Model of Cells in the Sensory Nervous System | http://arxiv.org/abs/1710.01347 | id:1710.01347 author:David Di Giorgio category:cs.AI cs.NE  published:2017-10-03 summary:Neuroscience research has produced many theories and computational neural models of sensory nervous systems. Notwithstanding many different perspectives towards developing intelligent machines, artificial intelligence has ultimately been influenced by neuroscience. Therefore, this paper provides an introduction to biologically inspired machine intelligence by exploring the basic principles of sensation and perception as well as the structure and behavior of biological sensory nervous systems like the neocortex. Concepts like spike timing, synaptic plasticity, inhibition, neural structure, and neural behavior are applied to a new model, Simple Cortex (SC). A software implementation of SC has been built and demonstrates fast observation, learning, and prediction of spatio-temporal sensory-motor patterns and sequences. Finally, this paper suggests future areas of improvement and growth for Simple Cortex and other related machine intelligence models. version:1
arxiv-1708-08508 | Subspace Selection to Suppress Confounding Source Domain Information in AAM Transfer Learning | http://arxiv.org/abs/1708.08508 | id:1708.08508 author:Azin Asgarian, Ahmed Bilal Ashraf, David Fleet, Babak Taati category:cs.CV cs.AI cs.LG  published:2017-08-28 summary:Active appearance models (AAMs) are a class of generative models that have seen tremendous success in face analysis. However, model learning depends on the availability of detailed annotation of canonical landmark points. As a result, when accurate AAM fitting is required on a different set of variations (expression, pose, identity), a new dataset is collected and annotated. To overcome the need for time consuming data collection and annotation, transfer learning approaches have received recent attention. The goal is to transfer knowledge from previously available datasets (source) to a new dataset (target). We propose a subspace transfer learning method, in which we select a subspace from the source that best describes the target space. We propose a metric to compute the directional similarity between the source eigenvectors and the target subspace. We show an equivalence between this metric and the variance of target data when projected onto source eigenvectors. Using this equivalence, we select a subset of source principal directions that capture the variance in target data. To define our model, we augment the selected source subspace with the target subspace learned from a handful of target examples. In experiments done on six publicly available datasets, we show that our approach outperforms the state of the art in terms of the RMS fitting error as well as the percentage of test examples for which AAM fitting converges to the ground truth. version:2
arxiv-1710-01297 | Visual gesture variability between talkers in continuous visual speech | http://arxiv.org/abs/1710.01297 | id:1710.01297 author:Helen L Bear category:cs.CV  published:2017-10-03 summary:Recent adoption of deep learning methods to the field of machine lipreading research gives us two options to pursue to improve system performance. Either, we develop end-to-end systems holistically or, we experiment to further our understanding of the visual speech signal. The latter option is more difficult but this knowledge would enable researchers to both improve systems and apply the new knowledge to other domains such as speech therapy. One challenge in lipreading systems is the correct labeling of the classifiers. These labels map an estimated function between visemes on the lips and the phonemes uttered. Here we ask if such maps are speaker-dependent? Prior work investigated isolated word recognition from speaker-dependent (SD) visemes, we extend this to continuous speech. Benchmarked against SD results, and the isolated words performance, we test with RMAV dataset speakers and observe that with continuous speech, the trajectory between visemes has a greater negative effect on the speaker differentiation. version:1
arxiv-1710-01292 | Visual speech recognition: aligning terminologies for better understanding | http://arxiv.org/abs/1710.01292 | id:1710.01292 author:Helen L Bear, Sarah Taylor category:cs.CV  published:2017-10-03 summary:We are at an exciting time for machine lipreading. Traditional research stemmed from the adaptation of audio recognition systems. But now, the computer vision community is also participating. This joining of two previously disparate areas with different perspectives on computer lipreading is creating opportunities for collaborations, but in doing so the literature is experiencing challenges in knowledge sharing due to multiple uses of terms and phrases and the range of methods for scoring results. In particular we highlight three areas with the intention to improve communication between those researching lipreading; the effects of interchanging between speech reading and lipreading; speaker dependence across train, validation, and test splits; and the use of accuracy, correctness, errors, and varying units (phonemes, visemes, words, and sentences) to measure system performance. We make recommendations as to how we can be more consistent. version:1
arxiv-1710-01288 | Decoding visemes: improving machine lipreading (PhD thesis) | http://arxiv.org/abs/1710.01288 | id:1710.01288 author:Helen L Bear category:cs.CV  published:2017-10-03 summary:Machine lipreading (MLR) is speech recognition from visual cues and a niche research problem in speech processing & computer vision. Current challenges fall into two groups: the content of the video, such as rate of speech or; the parameters of the video recording e.g, video resolution. We show that HD video is not needed to successfully lipread with a computer. The term "viseme" is used in machine lipreading to represent a visual cue or gesture which corresponds to a subgroup of phonemes where the phonemes are visually indistinguishable. A phoneme is the smallest sound one can utter, because there are more phonemes per viseme, maps between units show a many-to-one relationship. Many maps have been presented, we compare these and our results show Lee's is best. We propose a new method of speaker-dependent phoneme-to-viseme maps and compare these to Lee's. Our results show the sensitivity of phoneme clustering and we use our new knowledge to augment a conventional MLR system. It has been observed in MLR, that classifiers need training on test subjects to achieve accuracy. Thus machine lipreading is highly speaker-dependent. Conversely speaker independence is robust classification of non-training speakers. We investigate the dependence of phoneme-to-viseme maps between speakers and show there is not a high variability of visemes, but there is high variability in trajectory between visemes of individual speakers with the same ground truth. This implies a dependency upon the number of visemes within each set for each individual. We show that prior phoneme-to-viseme maps rarely have enough visemes and the optimal size, which varies by speaker, ranges from 11-35. Finally we decode from visemes back to phonemes and into words. Our novel approach uses the optimum range visemes within hierarchical training of phoneme classifiers and demonstrates a significant increase in classification accuracy. version:1
arxiv-1710-01278 | Dilated Convolutions for Modeling Long-Distance Genomic Dependencies | http://arxiv.org/abs/1710.01278 | id:1710.01278 author:Ankit Gupta, Alexander M. Rush category:q-bio.GN q-bio.QM stat.ML  published:2017-10-03 summary:We consider the task of detecting regulatory elements in the human genome directly from raw DNA. Past work has focused on small snippets of DNA, making it difficult to model long-distance dependencies that arise from DNA's 3-dimensional conformation. In order to study long-distance dependencies, we develop and release a novel dataset for a larger-context modeling task. Using this new data set we model long-distance interactions using dilated convolutional neural networks, and compare them to standard convolutions and recurrent neural networks. We show that dilated convolutions are effective at modeling the locations of regulatory markers in the human genome, such as transcription factor binding sites, histone modifications, and DNAse hypersensitivity sites. version:1
arxiv-1709-09683 | Exact Camera Location Recovery by Least Unsquared Deviations | http://arxiv.org/abs/1709.09683 | id:1709.09683 author:Gilad Lerman, Yunpeng Shi, Teng Zhang category:cs.CV math.OC  published:2017-09-27 summary:We establish exact recovery for the Least Unsquared Deviations (LUD) algorithm of \"{O}zyesil and Singer. More precisely, we show that for sufficiently many cameras with given corrupted pairwise directions, where both camera locations and pairwise directions are generated by a special probabilistic model, the LUD algorithm exactly recovers the camera locations with high probability. A similar exact recovery guarantee was established for the ShapeFit algorithm by Hand, Lee and Voroninski, but with typically less corruption. version:2
arxiv-1710-05703 | A Survey on Optical Character Recognition System | http://arxiv.org/abs/1710.05703 | id:1710.05703 author:Noman Islam, Zeeshan Islam, Nazia Noor category:cs.CV cs.AI cs.NI  published:2017-10-03 summary:Optical Character Recognition (OCR) has been a topic of interest for many years. It is defined as the process of digitizing a document image into its constituent characters. Despite decades of intense research, developing OCR with capabilities comparable to that of human still remains an open challenge. Due to this challenging nature, researchers from industry and academic circles have directed their attentions towards Optical Character Recognition. Over the last few years, the number of academic laboratories and companies involved in research on Character Recognition has increased dramatically. This research aims at summarizing the research so far done in the field of OCR. It provides an overview of different aspects of OCR and discusses corresponding proposals aimed at resolving issues of OCR. version:1
arxiv-1709-05790 | Learning Disordered Topological Phases by Statistical Recovery of Symmetry | http://arxiv.org/abs/1709.05790 | id:1709.05790 author:Nobuyuki Yoshioka, Yutaka Akagi, Hosho Katsura category:cond-mat.dis-nn cond-mat.stat-mech cond-mat.supr-con stat.ML  published:2017-09-18 summary:In this letter, we apply the artificial neural network in a supervised manner to map out the quantum phase diagram of disordered topological superconductor in class DIII. Given the disorder that keeps the discrete symmetries of the ensemble as a whole, translational symmetry which is broken in the quasiparticle distribution individually is recovered statistically by taking an ensemble average. By using this, we classify the phases by the artificial neural network that learned the quasiparticle distribution in the clean limit, and show that the result is totally consistent with the calculation by the transfer matrix method or noncommutative geometry approach. If all three phases, namely the $\mathbb{Z}_2$, trivial, and the thermal metal phases appear in the clean limit, the machine can classify them with high confidence over the entire phase diagram. If only the former two phases are present, we find that the machine remains confused in the certain region, leading us to conclude the detection of the unknown phase which is eventually identified as the thermal metal phase. In our method, only the first moment of the quasiparticle distribution is used for input, but application to a wider variety of systems is expected by the inclusion of higher moments. version:2
arxiv-1710-01202 | Person Re-Identification with Vision and Language | http://arxiv.org/abs/1710.01202 | id:1710.01202 author:Fei Yan, Krystian Mikolajczyk, Josef Kittler category:cs.CV  published:2017-10-03 summary:In this paper we propose a new approach to person re-identification using images and natural language descriptions. We propose a joint vision and language model based on CCA and CNN architectures to match across the two modalities as well as to enrich visual examples for which there are no language descriptions. We also introduce new annotations in the form of natural language descriptions for two standard Re-ID benchmarks, namely CUHK03 and VIPeR. We perform experiments on these two datasets with techniques based on CNN, hand-crafted features as well as LSTM for analysing visual and natural description data. We investigate and demonstrate the advantages of using natural language descriptions compared to attributes as well as CNN compared to LSTM in the context of Re-ID. We show that the joint use of language and vision can significantly improve the state-of-the-art performance on standard Re-ID benchmarks. version:1
arxiv-1709-06493 | Learning to update Auto-associative Memory in Recurrent Neural Networks for Improving Sequence Memorization | http://arxiv.org/abs/1709.06493 | id:1709.06493 author:Wei Zhang, Bowen Zhou category:cs.AI cs.LG stat.ML  published:2017-09-19 summary:Learning to remember long sequences remains a challenging task for recurrent neural networks. Register memory and attention mechanisms were both proposed to resolve the issue with either high computational cost to retain memory differentiability, or by discounting the RNN representation learning towards encoding shorter local contexts than encouraging long sequence encoding. Associative memory, which studies the compression of multiple patterns in a fixed size memory, were rarely considered in recent years. Although some recent work tries to introduce associative memory in RNN and mimic the energy decay process in Hopfield nets, it inherits the shortcoming of rule-based memory updates, and the memory capacity is limited. This paper proposes a method to learn the memory update rule jointly with task objective to improve memory capacity for remembering long sequences. Also, we propose an architecture that uses multiple such associative memory for more complex input encoding. We observed some interesting facts when compared to other RNN architectures on some well-studied sequence learning tasks. version:3
arxiv-1707-03574 | Terahertz Security Image Quality Assessment by No-reference Model Observers | http://arxiv.org/abs/1707.03574 | id:1707.03574 author:Menghan Hu, Xiongkuo Min, Guangtao Zhai, Wenhan Zhu, Yucheng Zhu, Zhaodi Wang, Xiaokang Yang, Guang Tian category:cs.CV  published:2017-07-12 summary:To provide the possibility of developing objective image quality assessment (IQA) algorithms for THz security images, we constructed the THz security image database (THSID) including a total of 181 THz security images with the resolution of 127*380. The main distortion types in THz security images were first analyzed for the design of subjective evaluation criteria to acquire the mean opinion scores. Subsequently, the existing no-reference IQA algorithms, which were 5 opinion-aware approaches viz., NFERM, GMLF, DIIVINE, BRISQUE and BLIINDS2, and 8 opinion-unaware approaches viz., QAC, SISBLIM, NIQE, FISBLIM, CPBD, S3 and Fish_bb, were executed for the evaluation of the THz security image quality. The statistical results demonstrated the superiority of Fish_bb over the other testing IQA approaches for assessing the THz image quality with PLCC (SROCC) values of 0.8925 (-0.8706), and with RMSE value of 0.3993. The linear regression analysis and Bland-Altman plot further verified that the Fish__bb could substitute for the subjective IQA. Nonetheless, for the classification of THz security images, we tended to use S3 as a criterion for ranking THz security image grades because of the relatively low false positive rate in classifying bad THz image quality into acceptable category (24.69%). Interestingly, due to the specific property of THz image, the average pixel intensity gave the best performance than the above complicated IQA algorithms, with the PLCC, SROCC and RMSE of 0.9001, -0.8800 and 0.3857, respectively. This study will help the users such as researchers or security staffs to obtain the THz security images of good quality. Currently, our research group is attempting to make this research more comprehensive. version:2
arxiv-1710-01169 | Decoding visemes: improving machine lipreading | http://arxiv.org/abs/1710.01169 | id:1710.01169 author:Helen L. Bear, Richard Harvey category:cs.CV  published:2017-10-03 summary:To undertake machine lip-reading, we try to recognise speech from a visual signal. Current work often uses viseme classification supported by language models with varying degrees of success. A few recent works suggest phoneme classification, in the right circumstances, can outperform viseme classification. In this work we present a novel two-pass method of training phoneme classifiers which uses previously trained visemes in the first pass. With our new training algorithm, we show classification performance which significantly improves on previous lip-reading results. version:1
arxiv-1709-08019 | Semi-Supervised Hierarchical Semantic Object Parsing | http://arxiv.org/abs/1709.08019 | id:1709.08019 author:Jalal Mirakhorli, Hamidreza Amindavar category:cs.AI cs.CV  published:2017-09-23 summary:Models based on convolutional Neural Networks (CNNs) have been proven very successful for semantic segmentation and object parsing that yield hierarchies of features. Our key insight is to build convolutional networks that take input of arbitrary size and produce object parsing output with efficient inference and learning. In this work, we focus on the task of Instance Segmentation and parsing which recognizes and localizes objects down to a pixel level base on deep CNN. Therefore, unlike some related work, a pixel cannot belong to multiple instances and parsing. Our model is based on a deep neural network trained for object masking that supervised with input image and follow incorporates a Conditional Random Field (CRF) with end-to-end trainable pricewise order potentials based on object parsing outputs. In each CRF unit we designed terms to capture the short range and long range dependencies from various neighbors. The accurate instance-level segmentations that our network produce is reflected by the considerable improvements obtained over previous work at high APr thresholds. We demonstrate the effectiveness of our model with extensive experiments on challenging dataset subset of PASCAL VOC2012. version:2
arxiv-1710-01142 | Finding phonemes: improving machine lip-reading | http://arxiv.org/abs/1710.01142 | id:1710.01142 author:Helen L. Bear, Richard W. Harvey, Yuxuan Lan category:cs.CV cs.CL  published:2017-10-03 summary:In machine lip-reading there is continued debate and research around the correct classes to be used for recognition. In this paper we use a structured approach for devising speaker-dependent viseme classes, which enables the creation of a set of phoneme-to-viseme maps where each has a different quantity of visemes ranging from two to 45. Viseme classes are based upon the mapping of articulated phonemes, which have been confused during phoneme recognition, into viseme groups. Using these maps, with the LiLIR dataset, we show the effect of changing the viseme map size in speaker-dependent machine lip-reading, measured by word recognition correctness and so demonstrate that word recognition with phoneme classifiers is not just possible, but often better than word recognition with viseme classifiers. Furthermore, there are intermediate units between visemes and phonemes which are better still. version:1
arxiv-1710-01122 | Speaker-independent machine lip-reading with speaker-dependent viseme classifiers | http://arxiv.org/abs/1710.01122 | id:1710.01122 author:Helen L. Bear, Stephen J. Cox, Richard W. Harvey category:cs.CV  published:2017-10-03 summary:In machine lip-reading, which is identification of speech from visual-only information, there is evidence to show that visual speech is highly dependent upon the speaker [1]. Here, we use a phoneme-clustering method to form new phoneme-to-viseme maps for both individual and multiple speakers. We use these maps to examine how similarly speakers talk visually. We conclude that broadly speaking, speakers have the same repertoire of mouth gestures, where they differ is in the use of the gestures. version:1
arxiv-1710-01103 | Isotropic and Steerable Wavelets in N Dimensions. A multiresolution analysis framework for ITK | http://arxiv.org/abs/1710.01103 | id:1710.01103 author:Pablo Hernandez-Cerdan category:cs.CV  published:2017-10-03 summary:This document describes the implementation of the external module ITKIsotropicWavelets, a multiresolution (MRA) analysis framework using isotropic and steerable wavelets in the frequency domain. This framework provides the backbone for state of the art filters for denoising, feature detection or phase analysis in N-dimensions. It focus on reusability, and highly decoupled modules for easy extension and implementation of new filters, and it contains a filter for multiresolution phase analysis, The backbone of the multi-scale analysis is provided by an isotropic band-limited wavelet pyramid, and the detection of directional features is provided by coupling the pyramid with a generalized Riesz transform. The generalized Riesz transform of order N behaves like a smoothed version of the Nth order derivatives of the signal. Also, it is steerable: its components impulse responses can be rotated to any spatial orientation, reducing computation time when detecting directional features. version:1
arxiv-1710-01095 | Towards an Inferential Lexicon of Event Selecting Predicates for French | http://arxiv.org/abs/1710.01095 | id:1710.01095 author:Ingrid Falk, Fabienne Martin category:cs.CL  published:2017-10-03 summary:We present a manually constructed seed lexicon encoding the inferential profiles of French event selecting predicates across different uses. The inferential profile (Karttunen, 1971a) of a verb is designed to capture the inferences triggered by the use of this verb in context. It reflects the influence of the clause-embedding verb on the factuality of the event described by the embedded clause. The resource developed provides evidence for the following three hypotheses: (i) French implicative verbs have an aspect dependent profile (their inferential profile varies with outer aspect), while factive verbs have an aspect independent profile (they keep the same inferential profile with both imperfective and perfective aspect); (ii) implicativity decreases with imperfective aspect: the inferences triggered by French implicative verbs combined with perfective aspect are often weakened when the same verbs are combined with imperfective aspect; (iii) implicativity decreases with an animate (deep) subject: the inferences triggered by a verb which is implicative with an inanimate subject are weakened when the same verb is used with an animate subject. The resource additionally shows that verbs with different inferential profiles display clearly distinct sub-categorisation patterns. In particular, verbs that have both factive and implicative readings are shown to prefer infinitival clauses in their implicative reading, and tensed clauses in their factive reading. version:1
arxiv-1710-01093 | Which phoneme-to-viseme maps best improve visual-only computer lip-reading? | http://arxiv.org/abs/1710.01093 | id:1710.01093 author:Helen L. Bear, Richard W. Harvey, Barry-John Theobald, Yuxuan Lan category:cs.CV cs.CL  published:2017-10-03 summary:A critical assumption of all current visual speech recognition systems is that there are visual speech units called visemes which can be mapped to units of acoustic speech, the phonemes. Despite there being a number of published maps it is infrequent to see the effectiveness of these tested, particularly on visual-only lip-reading (many works use audio-visual speech). Here we examine 120 mappings and consider if any are stable across talkers. We show a method for devising maps based on phoneme confusions from an automated lip-reading system, and we present new mappings that show improvements for individual talkers. version:1
arxiv-1710-01084 | Some observations on computer lip-reading: moving from the dream to the reality | http://arxiv.org/abs/1710.01084 | id:1710.01084 author:Helen L. Bear, Gari Owen, Richard Harvey, Barry-John Theobald category:cs.CV  published:2017-10-03 summary:In the quest for greater computer lip-reading performance there are a number of tacit assumptions which are either present in the datasets (high resolution for example) or in the methods (recognition of spoken visual units called visemes for example). Here we review these and other assumptions and show the surprising result that computer lip-reading is not heavily constrained by video resolution, pose, lighting and other practical factors. However, the working assumption that visemes, which are the visual equivalent of phonemes, are the best unit for recognition does need further examination. We conclude that visemes, which were defined over a century ago, are unlikely to be optimal for a modern computer lip-reading system. version:1
arxiv-1710-01073 | Resolution limits on visual speech recognition | http://arxiv.org/abs/1710.01073 | id:1710.01073 author:Helen L. Bear, Richard Harvey, Barry-John Theobald, Yuxuan Lan category:cs.CV  published:2017-10-03 summary:Visual-only speech recognition is dependent upon a number of factors that can be difficult to control, such as: lighting; identity; motion; emotion and expression. But some factors, such as video resolution are controllable, so it is surprising that there is not yet a systematic study of the effect of resolution on lip-reading. Here we use a new data set, the Rosetta Raven data, to train and test recognizers so we can measure the affect of video resolution on recognition accuracy. We conclude that, contrary to common practice, resolution need not be that great for automatic lip-reading. However it is highly unlikely that automatic lip-reading can work reliably when the distance between the bottom of the lower lip and the top of the upper lip is less than four pixels at rest. version:1
arxiv-1710-00575 | Remote Sensing Image Classification with Large Scale Gaussian Processes | http://arxiv.org/abs/1710.00575 | id:1710.00575 author:Pablo Morales-Alvarez, Adrian Perez-Suay, Rafael Molina, Gustau Camps-Valls category:cs.LG stat.AP stat.ML  published:2017-10-02 summary:Current remote sensing image classification problems have to deal with an unprecedented amount of heterogeneous and complex data sources. Upcoming missions will soon provide large data streams that will make land cover/use classification difficult. Machine learning classifiers can help at this, and many methods are currently available. A popular kernel classifier is the Gaussian process classifier (GPC), since it approaches the classification problem with a solid probabilistic treatment, thus yielding confidence intervals for the predictions as well as very competitive results to state-of-the-art neural networks and support vector machines. However, its computational cost is prohibitive for large scale applications, and constitutes the main obstacle precluding wide adoption. This paper tackles this problem by introducing two novel efficient methodologies for Gaussian Process (GP) classification. We first include the standard random Fourier features approximation into GPC, which largely decreases its computational cost and permits large scale remote sensing image classification. In addition, we propose a model which avoids randomly sampling a number of Fourier frequencies, and alternatively learns the optimal ones within a variational Bayes approach. The performance of the proposed methods is illustrated in complex problems of cloud detection from multispectral imagery and infrared sounding data. Excellent empirical results support the proposal in both computational cost and accuracy. version:2
arxiv-1710-01020 | Learning Affinity via Spatial Propagation Networks | http://arxiv.org/abs/1710.01020 | id:1710.01020 author:Sifei Liu, Shalini De Mello, Jinwei Gu, Guangyu Zhong, Ming-Hsuan Yang, Jan Kautz category:cs.CV cs.LG  published:2017-10-03 summary:In this paper, we propose spatial propagation networks for learning the affinity matrix for vision tasks. We show that by constructing a row/column linear propagation model, the spatially varying transformation matrix exactly constitutes an affinity matrix that models dense, global pairwise relationships of an image. Specifically, we develop a three-way connection for the linear propagation model, which (a) formulates a sparse transformation matrix, where all elements can be the output from a deep CNN, but (b) results in a dense affinity matrix that effectively models any task-specific pairwise similarity matrix. Instead of designing the similarity kernels according to image features of two points, we can directly output all the similarities in a purely data-driven manner. The spatial propagation network is a generic framework that can be applied to many affinity-related tasks, including but not limited to image matting, segmentation and colorization, to name a few. Essentially, the model can learn semantically-aware affinity values for high-level vision tasks due to the powerful learning capability of the deep neural network classifier. We validate the framework on the task of refinement for image segmentation boundaries. Experiments on the HELEN face parsing and PASCAL VOC-2012 semantic segmentation tasks show that the spatial propagation network provides a general, effective and efficient solution for generating high-quality segmentation results. version:1
arxiv-1710-01013 | Training Feedforward Neural Networks with Standard Logistic Activations is Feasible | http://arxiv.org/abs/1710.01013 | id:1710.01013 author:Emanuele Sansone, Francesco G. B. De Natale category:cs.NE cs.LG stat.ML  published:2017-10-03 summary:Training feedforward neural networks with standard logistic activations is considered difficult because of the intrinsic properties of these sigmoidal functions. This work aims at showing that these networks can be trained to achieve generalization performance comparable to those based on hyperbolic tangent activations. The solution consists on applying a set of conditions in parameter initialization, which have been derived from the study of the properties of a single neuron from an information-theoretic perspective. The proposed initialization is validated through an extensive experimental analysis. version:1
arxiv-1710-00998 | Is Structure Necessary for Modeling Argument Expectations in Distributional Semantics? | http://arxiv.org/abs/1710.00998 | id:1710.00998 author:Emmanuele Chersoni, Enrico Santus, Philippe Blache, Alessandro Lenci category:cs.CL  published:2017-10-03 summary:Despite the number of NLP studies dedicated to thematic fit estimation, little attention has been paid to the related task of composing and updating verb argument expectations. The few exceptions have mostly modeled this phenomenon with structured distributional models, implicitly assuming a similarly structured representation of events. Recent experimental evidence, however, suggests that human processing system could also exploit an unstructured "bag-of-arguments" type of event representation to predict upcoming input. In this paper, we re-implement a traditional structured model and adapt it to compare the different hypotheses concerning the degree of structure in our event knowledge, evaluating their relative performance in the task of the argument expectations update. version:1
arxiv-1710-00987 | Annotation and Detection of Emotion in Text-based Dialogue Systems with CNN | http://arxiv.org/abs/1710.00987 | id:1710.00987 author:Jialiang Zhao, Qi Gao category:cs.CL  published:2017-10-03 summary:Knowledge of users' emotion states helps improve human-computer interaction. In this work, we presented EmoNet, an emotion detector of Chinese daily dialogues based on deep convolutional neural networks. In order to maintain the original linguistic features, such as the order, commonly used methods like segmentation and keywords extraction were not adopted, instead we increased the depth of CNN and tried to let CNN learn inner linguistic relationships. Our main contribution is that we presented a new model and a new pipeline which can be used in multi-language environment to solve sentimental problems. Experimental results shows EmoNet has a great capacity in learning the emotion of dialogues and achieves a better result than other state of art detectors do. version:1
arxiv-1710-00983 | Joint Person Re-identification and Camera Network Topology Inference in Multiple Cameras | http://arxiv.org/abs/1710.00983 | id:1710.00983 author:Yeong-Jun Cho, Su-A Kim, Jae-Han Park, Kyuewang Lee, Kuk-Jin Yoon category:cs.CV  published:2017-10-03 summary:Person re-identification is the task of recognizing or identifying a person across multiple views in multi-camera networks. Although there has been much progress in person re-identification, person re-identification in large-scale multi-camera networks still remains a challenging task because of the large spatio-temporal uncertainty and high complexity due to a large number of cameras and people. To handle these difficulties, additional information such as camera network topology should be provided, which is also difficult to automatically estimate, unfortunately. In this study, we propose a unified framework which jointly solves both person re-identification and camera network topology inference problems with minimal prior knowledge about the environments. The proposed framework takes general multi-camera network environments into account and can be applied to online person re-identification in large-scale multi-camera networks. In addition, to effectively show the superiority of the proposed framework, we provide a new person re-identification dataset with full annotations, named SLP, captured in the multi-camera network consisting of nine non-overlapping cameras. Experimental results using our person re-identification and public datasets show that the proposed methods are promising for both person re-identification and camera topology inference tasks. version:1
arxiv-1709-07646 | SwGridNet: A Deep Convolutional Neural Network based on Grid Topology for Image Classification | http://arxiv.org/abs/1709.07646 | id:1709.07646 author:Atsushi Takeda category:cs.CV  published:2017-09-22 summary:Deep convolutional neural networks (CNNs) achieve remarkable performance on image classification tasks. Recent studies, however, have demonstrated that generalization abilities are more important than the depth of neural networks for improving performance on image classification tasks. Herein, a new neural network called SwGridNet is proposed. A SwGridNet includes many convolutional processing units which connect mutually as a grid network where many processing paths exist between input and output. A SwGridNet has high generalization capability because the multipath architecture has the same effect of ensemble learning. As described in this paper, details of the SwGridNet network architecture are presented. Experimentally obtained results presented in this paper show that SwGridNets respectively achieve test error rates of 2.95% and 15.67% in a CIFAR-10 and CIFAR-100 classification tasks. The results indicate that the SwGridNet performance approximates that of state-of-the-art deep CNNs. version:3
arxiv-1710-00977 | Facial Key Points Detection using Deep Convolutional Neural Network - NaimishNet | http://arxiv.org/abs/1710.00977 | id:1710.00977 author:Naimish Agarwal, Artus Krohn-Grimberghe, Ranjana Vyas category:cs.CV cs.LG stat.ML  published:2017-10-03 summary:Facial Key Points (FKPs) Detection is an important and challenging problem in the fields of computer vision and machine learning. It involves predicting the co-ordinates of the FKPs, e.g. nose tip, center of eyes, etc, for a given face. In this paper, we propose a LeNet adapted Deep CNN model - NaimishNet, to operate on facial key points data and compare our model's performance against existing state of the art approaches. version:1
arxiv-1710-00974 | A concatenating framework of shortcut convolutional neural networks | http://arxiv.org/abs/1710.00974 | id:1710.00974 author:Yujian Li, Ting Zhang, Zhaoying Liu, Haihe Hu category:cs.CV  published:2017-10-03 summary:It is well accepted that convolutional neural networks play an important role in learning excellent features for image classification and recognition. However, in tradition they only allow adjacent layers connected, limiting integration of multi-scale information. To further improve their performance, we present a concatenating framework of shortcut convolutional neural networks. This framework can concatenate multi-scale features by shortcut connections to the fully-connected layer that is directly fed to the output layer. We do a large number of experiments to investigate performance of the shortcut convolutional neural networks on many benchmark visual datasets for different tasks. The datasets include AR, FERET, FaceScrub, CelebA for gender classification, CUReT for texture classification, MNIST for digit recognition, and CIFAR-10 for object recognition. Experimental results show that the shortcut convolutional neural networks can achieve better results than the traditional ones on these tasks, with more stability in different settings of pooling schemes, activation functions, optimizations, initializations, kernel numbers and kernel sizes. version:1
arxiv-1710-00969 | Event Identification as a Decision Process with Non-linear Representation of Text | http://arxiv.org/abs/1710.00969 | id:1710.00969 author:Yukun Yan, Daqi Zheng, Zhengdong Lu, Sen Song category:cs.CL  published:2017-10-03 summary:We propose scale-free Identifier Network(sfIN), a novel model for event identification in documents. In general, sfIN first encodes a document into multi-scale memory stacks, then extracts special events via conducting multi-scale actions, which can be considered as a special type of sequence labelling. The design of large scale actions makes it more efficient processing a long document. The whole model is trained with both supervised learning and reinforcement learning. version:1
arxiv-1710-00962 | GP-GAN: Gender Preserving GAN for Synthesizing Faces from Landmarks | http://arxiv.org/abs/1710.00962 | id:1710.00962 author:Xing Di, Vishwanath A. Sindagi, Vishal M. Patel category:cs.CV  published:2017-10-03 summary:Facial landmarks constitute the most compressed representation of faces and are known to preserve information such as pose, gender and facial structure present in the faces. Several works exist that attempt to perform high-level face-related analysis tasks based on landmarks. In contrast, in this work, an attempt is made to tackle the inverse problem of synthesizing faces from their respective landmarks. The primary aim of this work is to demonstrate that information preserved by landmarks (gender in particular) can be further accentuated by leveraging generative models to synthesize corresponding faces. Though the problem is particularly challenging due to its ill-posed nature, we believe that successful synthesis will enable several applications such as boosting performance of high-level face related tasks using landmark points and performing dataset augmentation. To this end, a novel face-synthesis method known as Gender Preserving Generative Adversarial Network (GP-GAN) that is guided by adversarial loss, perceptual loss and a gender preserving loss is presented. Further, we propose a novel generator sub-network UDeNet for GP-GAN that leverages advantages of U-Net and DenseNet architectures. Extensive experiments and comparison with recent methods are performed to verify the effectiveness of the proposed method. version:1
arxiv-1710-00956 | Monte Carlo approximation certificates for k-means clustering | http://arxiv.org/abs/1710.00956 | id:1710.00956 author:Dustin G. Mixon, Soledad Villar category:stat.ML math.OC  published:2017-10-03 summary:Efficient algorithms for $k$-means clustering frequently converge to suboptimal partitions, and given a partition, it is difficult to detect $k$-means optimality. In this paper, we develop an a posteriori certifier of approximate optimality for $k$-means clustering. The certifier is a sub-linear Monte Carlo algorithm based on Peng and Wei's semidefinite relaxation of $k$-means. In particular, solving the relaxation for small random samples of the dataset produces a high-confidence lower bound on the $k$-means objective, and being sub-linear, our algorithm is faster than $k$-means++ when the number of data points is large. We illustrate the performance of our algorithm with both numerical experiments and a performance guarantee: If the data points are drawn independently from any mixture of two Gaussians over $\mathbb{R}^m$ with identity covariance, then with probability $1-O(1/m)$, our $\operatorname{poly}(m)$-time algorithm produces a 3-approximation certificate with 99% confidence. version:1
arxiv-1710-00947 | VIDOSAT: High-dimensional Sparsifying Transform Learning for Online Video Denoising | http://arxiv.org/abs/1710.00947 | id:1710.00947 author:Bihan Wen, Saiprasad Ravishankar, Yoram Bresler category:cs.CV  published:2017-10-03 summary:Techniques exploiting the sparsity of images in a transform domain have been effective for various applications in image and video processing. Transform learning methods involve cheap computations and have been demonstrated to perform well in applications such as image denoising and medical image reconstruction. Recently, we proposed methods for online learning of sparsifying transforms from streaming signals, which enjoy good convergence guarantees, and involve lower computational costs than online synthesis dictionary learning. In this work, we apply online transform learning to video denoising. We present a novel framework for online video denoising based on high-dimensional sparsifying transform learning for spatio-temporal patches. The patches are constructed either from corresponding 2D patches in successive frames or using an online block matching technique. The proposed online video denoising requires little memory, and offers efficient processing. Numerical experiments compare the performance to the proposed video denoising scheme but fixing the transform to be 3D DCT, as well as prior schemes such as dictionary learning-based schemes, and the state-of-the-art VBM3D and VBM4D on several video data sets, demonstrating the promising performance of the proposed methods. version:1
arxiv-1709-04447 | A Learning Approach to Secure Learning | http://arxiv.org/abs/1709.04447 | id:1709.04447 author:Linh Nguyen, Arunesh Sinha category:cs.CR cs.CV cs.LG  published:2017-09-13 summary:Deep Neural Networks (DNNs) have been shown to be vulnerable against adversarial examples, which are data points cleverly constructed to fool the classifier. Such attacks can be devastating in practice, especially as DNNs are being applied to ever increasing critical tasks like image recognition in autonomous driving. In this paper, we introduce a new perspective on the problem. We do so by first defining robustness of a classifier to adversarial exploitation. Next, we show that the problem of adversarial example generation and defense both can be posed as learning problems, which are duals of each other. We also show formally that our defense aims to increase robustness of the classifier. We demonstrate the efficacy of our techniques by experimenting with the MNIST and CIFAR-10 datasets. version:2
arxiv-1710-00936 | Identifying Nominals with No Head Match Co-references Using Deep Learning | http://arxiv.org/abs/1710.00936 | id:1710.00936 author:M. Stone, R. Arora category:cs.CL  published:2017-10-02 summary:Identifying nominals with no head match is a long-standing challenge in coreference resolution with current systems performing significantly worse than humans. In this paper we present a new neural network architecture which outperforms the current state-of-the-art system on the English portion of the CoNLL 2012 Shared Task. This is done by using a logistic regression on features produced by two submodels, one of which is has the architecture proposed in [CM16a] while the other combines domain specific embeddings of the antecedent and the mention. We also propose some simple additional features which seem to improve performance for all models substantially, increasing F1 by almost 4% on basic logistic regression and other complex models. version:1
arxiv-1710-00925 | Fine-Grained Head Pose Estimation Without Keypoints | http://arxiv.org/abs/1710.00925 | id:1710.00925 author:Nataniel Ruiz, Eunji Chong, James M. Rehg category:cs.CV  published:2017-10-02 summary:Estimating the head pose of a person is a crucial problem that has a large amount of applications such as aiding in gaze estimation, modeling attention, fitting 3D models to video and performing face alignment. Traditionally head pose is computed by estimating some keypoints from the target face and solving the 2D to 3D correspondence problem with a mean human head model. We argue that this is a fragile method because it relies entirely on landmark detection performance, the extraneous head model and an ad-hoc fitting step. We present an elegant and robust way to determine pose by training a multi-loss convolutional neural network on 300W-LP, a large synthetically expanded dataset, to predict intrinsic Euler angles (yaw, pitch and roll) directly from image intensities through joint binned pose classification and regression. We present empirical tests on common in-the-wild pose benchmark datasets which show state-of-the-art results. Additionally we test our method on a dataset usually used for pose estimation using depth and start to close the gap with state-of-the-art depth pose methods. We open-source our training and testing code as well as release our pre-trained models. version:1
arxiv-1710-00923 | Minimal Dependency Translation: a Framework for Computer-Assisted Translation for Under-Resourced Languages | http://arxiv.org/abs/1710.00923 | id:1710.00923 author:Michael Gasser category:cs.CL  published:2017-10-02 summary:This paper introduces Minimal Dependency Translation (MDT), an ongoing project to develop a rule-based framework for the creation of rudimentary bilingual lexicon-grammars for machine translation and computer-assisted translation into and out of under-resourced languages as well as initial steps towards an implementation of MDT for English-to-Amharic translation. The basic units in MDT, called groups, are headed multi-item sequences. In addition to wordforms, groups may contain lexemes, syntactic-semantic categories, and grammatical features. Each group is associated with one or more translations, each of which is a group in a target language. During translation, constraint satisfaction is used to select a set of source-language groups for the input sentence and to sequence the words in the associated target-language groups. version:1
arxiv-1710-00920 | End-to-end Learning for 3D Facial Animation from Raw Waveforms of Speech | http://arxiv.org/abs/1710.00920 | id:1710.00920 author:Hai X. Pham, Yuting Wang, Vladimir Pavlovic category:cs.CV  published:2017-10-02 summary:We present a deep learning framework for real-time speech-driven 3D facial animation from just raw waveforms. Our deep neural network directly maps an input sequence of speech audio to a series of micro facial action unit activations and head rotations to drive a 3D blendshape face model. In particular, our deep model is able to learn the latent representations of time-varying contextual information and affective states within the speech. Hence, our model not only activates appropriate facial action units at inference to depict different utterance generating actions, in the form of lip movements, but also, without any assumption, automatically estimates emotional intensity of the speaker and reproduces her ever-changing affective states by adjusting strength of facial unit activations. For example, in a happy speech, the mouth opens wider than normal, while other facial units are relaxed; or in a surprised state, both eyebrows raise higher. Experiments on a diverse audiovisual corpus of different actors across a wide range of emotional states show interesting and promising results of our approach. Being speaker-independent, our generalized model is readily applicable to various tasks in human-machine interaction and animation. version:1
arxiv-1710-00904 | Online and Distributed Robust Regressions under Adversarial Data Corruption | http://arxiv.org/abs/1710.00904 | id:1710.00904 author:Xuchao Zhang, Liang Zhao, Arnold P. Boedihardjo, Chang-Tien Lu category:cs.DS cs.LG stat.ML  published:2017-10-02 summary:In today's era of big data, robust least-squares regression becomes a more challenging problem when considering the adversarial corruption along with explosive growth of datasets. Traditional robust methods can handle the noise but suffer from several challenges when applied in huge dataset including 1) computational infeasibility of handling an entire dataset at once, 2) existence of heterogeneously distributed corruption, and 3) difficulty in corruption estimation when data cannot be entirely loaded. This paper proposes online and distributed robust regression approaches, both of which can concurrently address all the above challenges. Specifically, the distributed algorithm optimizes the regression coefficients of each data block via heuristic hard thresholding and combines all the estimates in a distributed robust consolidation. Furthermore, an online version of the distributed algorithm is proposed to incrementally update the existing estimates with new incoming data. We also prove that our algorithms benefit from strong robustness guarantees in terms of regression coefficient recovery with a constant upper bound on the error of state-of-the-art batch methods. Extensive experiments on synthetic and real datasets demonstrate that our approaches are superior to those of existing methods in effectiveness, with competitive efficiency. version:1
arxiv-1710-00889 | How is Distributed ADMM Affected by Network Topology? | http://arxiv.org/abs/1710.00889 | id:1710.00889 author:Guilherme França, José Bento category:stat.ML math.OC  published:2017-10-02 summary:When solving consensus optimization problems over a graph, there is often an explicit characterization of the convergence rate of Gradient Descent (GD) using the spectrum of the graph Laplacian. The same type of problems under the Alternating Direction Method of Multipliers (ADMM) are, however, poorly understood. For instance, simple but important non-strongly-convex consensus problems have not yet being analyzed, especially concerning the dependency of the convergence rate on the graph topology. Recently, for a non-strongly-convex consensus problem, a connection between distributed ADMM and lifted Markov chains was proposed, followed by a conjecture that ADMM is faster than GD by a square root factor in its convergence time, in close analogy to the mixing speedup achieved by lifting several Markov chains. Nevertheless, a proof of such a claim is is still lacking. Here we provide a full characterization of the convergence of distributed over-relaxed ADMM for the same type of consensus problem in terms of the topology of the underlying graph. Our results provide explicit formulas for optimal parameter selection in terms of the second largest eigenvalue of the transition matrix of the graph's random walk. Another consequence of our results is a proof of the aforementioned conjecture, which interestingly, we show it is valid for any graph, even the ones whose random walks cannot be accelerated via Markov chain lifting. version:1
arxiv-1710-00888 | Sentiment Perception of Readers and Writers in Emoji use | http://arxiv.org/abs/1710.00888 | id:1710.00888 author:Jose Berengueres, Dani Castro category:cs.IR cs.CL cs.HC  published:2017-10-02 summary:Previous research has traditionally analyzed emoji sentiment from the point of view of the reader of the content not the author. Here, we analyze emoji sentiment from the point of view of the author and present a emoji sentiment benchmark that was built from an employee happiness dataset where emoji happen to be annotated with daily happiness of the author of the comment. The data spans over 3 years, and 4k employees of 56 companies based in Barcelona. We compare sentiment of writers to readers. Results indicate that, there is an 82% agreement in how emoji sentiment is perceived by readers and writers. Finally, we report that when authors use emoji they report higher levels of happiness. Emoji use was not found to be correlated with differences in author moodiness. version:1
arxiv-1710-00880 | Unsupervised Hypernym Detection by Distributional Inclusion Vector Embedding | http://arxiv.org/abs/1710.00880 | id:1710.00880 author:Haw-Shiuan Chang, ZiYun Wang, Luke Vilnis, Andrew McCallum category:cs.CL  published:2017-10-02 summary:Modeling hypernymy, such as poodle is-a dog, is an important generalization aid to many NLP tasks, such as entailment, relation extraction, and question answering. Supervised learning from labeled hypernym sources, such as WordNet, limit the coverage of these models, which can be addressed by learning hypernyms from unlabeled text. Existing unsupervised methods either do not scale to large vocabularies or yield unacceptably poor accuracy. This paper introduces distributional inclusion vector embedding (DIVE), a simple-to-implement unsupervised method of hypernym discovery via per-word non-negative vector embeddings learned by modeling diversity of word context with specialized negative sampling. In an experimental evaluation more comprehensive than any previous literature of which we are aware - evaluating on 11 datasets using multiple existing as well as newly proposed scoring metrics - we find that our method can provide up to double or triple the precision of previous unsupervised methods, and also sometimes outperforms previous semi-supervised methods, yielding many new state-of-the-art results. version:1
arxiv-1710-00870 | Rethinking Feature Discrimination and Polymerization for Large-scale Recognition | http://arxiv.org/abs/1710.00870 | id:1710.00870 author:Yu Liu, Hongyang Li, Xiaogang Wang category:cs.CV  published:2017-10-02 summary:Feature matters. How to train a deep network to acquire discriminative features across categories and polymerized features within classes has always been at the core of many computer vision tasks, specially for large-scale recognition systems where test identities are unseen during training and the number of classes could be at million scale. In this paper, we address this problem based on the simple intuition that the cosine distance of features in high-dimensional space should be close enough within one class and far away across categories. To this end, we proposed the congenerous cosine (COCO) algorithm to simultaneously optimize the cosine similarity among data. It inherits the softmax property to make inter-class features discriminative as well as shares the idea of class centroid in metric learning. Unlike previous work where the center is a temporal, statistical variable within one mini-batch during training, the formulated centroid is responsible for clustering inner-class features to enforce them polymerized around the network truncus. COCO is bundled with discriminative training and learned end-to-end with stable convergence. Experiments on five benchmarks have been extensively conducted to verify the effectiveness of our approach on both small-scale classification task and large-scale human recognition problem. version:1
arxiv-1710-00814 | Detecting Adversarial Attacks on Neural Network Policies with Visual Foresight | http://arxiv.org/abs/1710.00814 | id:1710.00814 author:Yen-Chen Lin, Ming-Yu Liu, Min Sun, Jia-Bin Huang category:cs.CV cs.CR cs.LG  published:2017-10-02 summary:Deep reinforcement learning has shown promising results in learning control policies for complex sequential decision-making tasks. However, these neural network-based policies are known to be vulnerable to adversarial examples. This vulnerability poses a potentially serious threat to safety-critical systems such as autonomous vehicles. In this paper, we propose a defense mechanism to defend reinforcement learning agents from adversarial attacks by leveraging an action-conditioned frame prediction module. Our core idea is that the adversarial examples targeting at a neural network-based policy are not effective for the frame prediction model. By comparing the action distribution produced by a policy from processing the current observed frame to the action distribution produced by the same policy from processing the predicted frame from the action-conditioned frame prediction module, we can detect the presence of adversarial examples. Beyond detecting the presence of adversarial examples, our method allows the agent to continue performing the task using the predicted frame when the agent is under attack. We evaluate the performance of our algorithm using five games in Atari 2600. Our results demonstrate that the proposed defense mechanism achieves favorable performance against baseline algorithms in detecting adversarial examples and in earning rewards when the agents are under attack. version:1
arxiv-1710-00811 | Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams | http://arxiv.org/abs/1710.00811 | id:1710.00811 author:Aaron Tuor, Samuel Kaplan, Brian Hutchinson, Nicole Nichols, Sean Robinson category:cs.NE cs.CR cs.LG stat.ML 62-07  published:2017-10-02 summary:Analysis of an organization's computer network activity is a key component of early detection and mitigation of insider threat, a growing concern for many organizations. Raw system logs are a prototypical example of streaming data that can quickly scale beyond the cognitive power of a human analyst. As a prospective filter for the human analyst, we present an online unsupervised deep learning approach to detect anomalous network activity from system logs in real time. Our models decompose anomaly scores into the contributions of individual user behavior features for increased interpretability to aid analysts reviewing potential cases of insider threat. Using the CERT Insider Threat Dataset v6.2 and threat detection recall as our performance metric, our novel deep and recurrent neural network models outperform Principal Component Analysis, Support Vector Machine and Isolation Forest based anomaly detection baselines. For our best model, the events labeled as insider threat activity in our dataset had an average anomaly score in the 95.53 percentile, demonstrating our approach's potential to greatly reduce analyst workloads. version:1
arxiv-1709-01268 | Tensor Representation in High-Frequency Financial Data for Price Change Prediction | http://arxiv.org/abs/1709.01268 | id:1709.01268 author:Dat Thanh Tran, Martin Magris, Juho Kanniainen, Moncef Gabbouj, Alexandros Iosifidis category:cs.CE cs.LG cs.NA q-fin.TR  published:2017-09-05 summary:Nowadays, with the availability of massive amount of trade data collected, the dynamics of the financial markets pose both a challenge and an opportunity for high frequency traders. In order to take advantage of the rapid, subtle movement of assets in High Frequency Trading (HFT), an automatic algorithm to analyze and detect patterns of price change based on transaction records must be available. The multichannel, time-series representation of financial data naturally suggests tensor-based learning algorithms. In this work, we investigate the effectiveness of two multilinear methods for the mid-price prediction problem against other existing methods. The experiments in a large scale dataset which contains more than 4 millions limit orders show that by utilizing tensor representation, multilinear models outperform vector-based approaches and other competing ones. version:3
arxiv-1710-00803 | Compiling and Processing Historical and Contemporary Portuguese Corpora | http://arxiv.org/abs/1710.00803 | id:1710.00803 author:Marcos Zampieri category:cs.CL  published:2017-10-02 summary:This technical report describes the framework used for processing three large Portuguese corpora. Two corpora contain texts from newspapers, one published in Brazil and the other published in Portugal. The third corpus is Colonia, a historical Portuguese collection containing texts written between the 16th and the early 20th century. The report presents pre-processing methods, segmentation, and annotation of the corpora as well as indexing and querying methods. Finally, it presents published research papers using the corpora. version:1
arxiv-1710-00760 | AUC Maximization with K-hyperplane | http://arxiv.org/abs/1710.00760 | id:1710.00760 author:Majdi Khalid, Indrakshi Ray, Hamidreza Chitsaz category:cs.LG  published:2017-10-02 summary:Area Under the ROC Curve (AUC) is a reliable metric for measuring the quality of the classification performance on imbalanced data. The existing pairwise learn to rank linear algorithms can optimize the AUC metric efficiently, but lack modeling the nonlinearity underlying the data. The large scale and nonlinear distribution of many real world data render the kernelized variants of these linear classifiers impractical. In this paper, we propose a linear K-hyperplane classifier for AUC maximization. The proposed method employs a set of linear pairwise classifiers in order to approximate the nonlinear decision boundary. More specifically, we define a set of landmark points using unsupervised algorithm, and associate each landmark with a linear pairwise classifier. These linear classifiers are learned jointly on pairs of instances where each instance in the pair is weighted based on its distance from the corresponding landmark point. We use a local coding algorithm to estimate the weights of the instances. Experiments on several benchmark datasets demonstrate that our classifier is efficient and able to achieve roughly comparable AUC classification performance as compared to kernalized pairwise classifier. The proposed classifier also outperforms the linear RankSVM classifiers in terms of AUC performance. version:1
arxiv-1709-03572 | Real-Time Multiple Object Tracking - A Study on the Importance of Speed | http://arxiv.org/abs/1709.03572 | id:1709.03572 author:Samuel Murray category:cs.CV  published:2017-09-11 summary:In this project, we implement a multiple object tracker, following the tracking-by-detection paradigm, as an extension of an existing method. It works by modelling the movement of objects by solving the filtering problem, and associating detections with predicted new locations in new frames using the Hungarian algorithm. Three different similarity measures are used, which use the location and shape of the bounding boxes. Compared to other trackers on the MOTChallenge leaderboard, our method, referred to as C++SORT, is the fastest non-anonymous submission, while also achieving decent score on other metrics. By running our model on the Okutama-Action dataset, sampled at different frame-rates, we show that the performance is greatly reduced when running the model - including detecting objects - in real-time. In most metrics, the score is reduced by 50%, but in certain cases as much as 90%. We argue that this indicates that other, slower methods could not be used for tracking in real-time, but that more research is required specifically on this. version:2
arxiv-1710-00756 | Neural Color Transfer between Images | http://arxiv.org/abs/1710.00756 | id:1710.00756 author:Mingming He, Jing Liao, Lu Yuan, Pedro V. Sander category:cs.CV  published:2017-10-02 summary:We propose a new algorithm for color transfer between images that have perceptually similar semantic structures. We aim to achieve a more accurate color transfer that leverages semantically-meaningful dense correspondence between images. To accomplish this, our algorithm uses neural representations for matching. Additionally, the color transfer should be spatially-variant and globally coherent. Therefore, our algorithm optimizes a local linear model for color transfer satisfying both local and global constraints. Our proposed approach jointly optimize matching and color transfer, adopting a coarse-to-fine strategy. The proposed method can be successfully extended from "one-to-one" to "one-to-many" color transfers. The latter further addresses the problem of mismatching elements of the input image. We validate our proposed method by testing it on a large variety of image content. version:1
arxiv-1710-01269 | Spinal cord gray matter segmentation using deep dilated convolutions | http://arxiv.org/abs/1710.01269 | id:1710.01269 author:Christian S. Perone, Evan Calabrese, Julien Cohen-Adad category:cs.CV  published:2017-10-02 summary:Gray matter (GM) tissue changes have been associated with a wide range of neurological disorders and was also recently found relevant as a biomarker for disability in amyotrophic lateral sclerosis. The ability to automatically segment the GM is, therefore, an important task for modern studies of the spinal cord. In this work, we devise a modern, simple and end-to-end fully automated human spinal cord gray matter segmentation method using Deep Learning, that works both on in vivo and ex vivo MRI acquisitions. We evaluate our method against six independently developed methods on a GM segmentation challenge and report state-of-the-art results in 8 out of 10 different evaluation metrics as well as major network parameter reduction when compared to the traditional medical imaging architectures such as U-Nets. version:1
arxiv-1710-00725 | Learning hard quantum distributions with variational autoencoders | http://arxiv.org/abs/1710.00725 | id:1710.00725 author:Andrea Rocchetto, Edward Grant, Sergii Strelchuk, Giuseppe Carleo, Simone Severini category:quant-ph stat.ML  published:2017-10-02 summary:Studying general quantum many-body systems is one of the major challenges in modern physics because it requires an amount of computational resources that scales exponentially with the size of the system.Simulating the evolution of a state, or even storing its description, rapidly becomes intractable for exact classical algorithms. Recently, machine learning techniques, in the form of restricted Boltzmann machines, have been proposed as a way to efficiently represent certain quantum states with applications in state tomography and ground state estimation. Here, we introduce a new representation of states based on variational autoencoders. Variational autoencoders are a type of generative model in the form of a neural network. We probe the power of this representation by encoding probability distributions associated with states from different classes. Our simulations show that deep networks give a better representation for states that are hard to sample from, while providing no benefit for random states. This suggests that the probability distributions associated to hard quantum states might have a compositional structure that can be exploited by layered neural networks. Specifically, we consider the learnability of a class of quantum states introduced by Fefferman and Umans. Such states are provably hard to sample for classical computers, but not for quantum ones, under plausible computational complexity assumptions. The good level of compression achieved for hard states suggests these methods can be suitable for characterising states of the size expected in first generation quantum hardware. version:1
arxiv-1710-00689 | Building Chatbots from Forum Data: Model Selection Using Question Answering Metrics | http://arxiv.org/abs/1710.00689 | id:1710.00689 author:Martin Boyanov, Ivan Koychev, Preslav Nakov, Alessandro Moschitti, Giovanni Da San Martino category:cs.CL 68T50 I.2.7  published:2017-10-02 summary:We propose to use question answering (QA) data from Web forums to train chatbots from scratch, i.e., without dialog training data. First, we extract pairs of question and answer sentences from the typically much longer texts of questions and answers in a forum. We then use these shorter texts to train seq2seq models in a more efficient way. We further improve the parameter optimization using a new model selection strategy based on QA measures. Finally, we propose to use extrinsic evaluation with respect to a QA task as an automatic evaluation method for chatbots. The evaluation shows that the model achieves a MAP of 63.5% on the extrinsic task. Moreover, it can answer correctly 49.5% of the questions when they are similar to questions asked in the forum, and 47.3% of the questions when they are more conversational in style. version:1
arxiv-1710-00672 | Conditional Chromatic Filtering with Spatial Enhancement for Restoring Pansharpened Images | http://arxiv.org/abs/1710.00672 | id:1710.00672 author:Joan Duran, Antoni Buades category:cs.CV math.FA  published:2017-10-02 summary:Pansharpening techniques aim at fusing the structural detail of the panchromatic and the color accuracy of the low-resolution spectral bands provided by Earth observation satellites to produce a high-resolution multispectral image. A large number of methods have been proposed in the literature, most of which were developed based on certain assumptions about the acquisition system. If any of these assumptions are not fulfilled, the quality of the fused products may be seriously compromised. We propose a post-processing restoration strategy to improve the quality of pansharpened images. In a first stage, we introduce a nonlocal variational model for filtering the chromatic components conditionally to the geometry of the panchromatic. In the second stage, the structural component is replaced by the locally histogram-matched panchromatic for spatial enhancement. An exhaustive performance evaluation of the proposed restoration strategy illustrates its efficiency. version:1
arxiv-1710-00633 | Deep Convolutional Neural Networks for Interpretable Analysis of EEG Sleep Stage Scoring | http://arxiv.org/abs/1710.00633 | id:1710.00633 author:Albert Vilamala, Kristoffer H. Madsen, Lars K. Hansen category:cs.CV stat.ML  published:2017-10-02 summary:Sleep studies are important for diagnosing sleep disorders such as insomnia, narcolepsy or sleep apnea. They rely on manual scoring of sleep stages from raw polisomnography signals, which is a tedious visual task requiring the workload of highly trained professionals. Consequently, research efforts to purse for an automatic stage scoring based on machine learning techniques have been carried out over the last years. In this work, we resort to multitaper spectral analysis to create visually interpretable images of sleep patterns from EEG signals as inputs to a deep convolutional network trained to solve visual recognition tasks. As a working example of transfer learning, a system able to accurately classify sleep stages in new unseen patients is presented. Evaluations in a widely-used publicly available dataset favourably compare to state-of-the-art results, while providing a framework for visual interpretation of outcomes. version:1
