arxiv-1708-00033 | An efficient MPI/OpenMP parallelization of the Hartree-Fock method for the second generation of Intel Xeon Phi processor | http://arxiv.org/abs/1708.00033 | id:1708.00033 author:Vladimir Mironov, Yuri Alexeev, Kristopher Keipert, Michael D'mello, Alexander Moskovsky, Mark S. Gordon category:cs.DC D.1.3; J.2  published:2017-07-31 summary:Modern OpenMP threading techniques are used to convert the MPI-only Hartree-Fock code in the GAMESS program to a hybrid MPI/OpenMP algorithm. Two separate implementations that differ by the sharing or replication of key data structures among threads are considered, density and Fock matrices. All implementations are benchmarked on a super-computer of 3,000 Intel Xeon Phi processors. With 64 cores per processor, scaling numbers are reported on up to 192,000 cores. The hybrid MPI/OpenMP implementation reduces the memory footprint by approximately 200 times compared to the legacy code. The MPI/OpenMP code was shown to run up to six times faster than the original for a range of molecular system sizes. version:2
arxiv-1708-04078 | uStash: a Novel Mobile Content Delivery System for Improving User QoE in Public Transport | http://arxiv.org/abs/1708.04078 | id:1708.04078 author:Fang-Zhou Jiang, Kanchana Thilakarathna, Sirine Mrabet, Mohamed Ali Kaafar, Aruna Seneviratne category:cs.NI cs.DC cs.MM  published:2017-08-14 summary:Mobile data traffic is growing exponentially and it is even more challenging to distribute content efficiently while users are "on the move" such as in public transport.The use of mobile devices for accessing content (e.g. videos) while commuting are both expensive and unreliable, although it is becoming common practice worldwide. Leveraging on the spatial and temporal correlation of content popularity and users' diverse network connectivity, we propose a novel content distribution system, \textit{uStash}, which guarantees better QoE with regards to access delays and cost of usage. The proposed collaborative download and content stashing schemes provide the uStash provider the flexibility to control the cost of content access via cellular networks. We model the uStash system in a probabilistic framework and thereby analytically derive the optimal portions for collaborative downloading. Then, we validate the proposed models using real-life trace driven simulations. In particular, we use dataset from 22 inter-city buses running on 6 different routes and from a mobile VoD service provider to show that uStash reduces the cost of monthly cellular data by approximately 50\% and the expected delay for content access by 60\% compared to content downloaded via users' cellular network connections. version:1
arxiv-1708-04028 | Counterexample Guided Inductive Optimization Applied to Mobile Robots Path Planning (Extended Version) | http://arxiv.org/abs/1708.04028 | id:1708.04028 author:Rodrigo F. Araújo, Alexandre Ribeiro, Iury V. Bessa, Lucas C. Cordeiro, João E. C. Filho category:cs.RO cs.AI  published:2017-08-14 summary:We describe and evaluate a novel optimization-based off-line path planning algorithm for mobile robots based on the Counterexample-Guided Inductive Optimization (CEGIO) technique. CEGIO iteratively employs counterexamples generated from Boolean Satisfiability (SAT) and Satisfiability Modulo Theories (SMT) solvers, in order to guide the optimization process and to ensure global optimization. This paper marks the first application of CEGIO for planning mobile robot path. In particular, CEGIO has been successfully applied to obtain optimal two-dimensional paths for autonomous mobile robots using off-the-shelf SAT and SMT solvers. version:1
arxiv-1709-06537 | DC-Prophet: Predicting Catastrophic Machine Failures in DataCenters | http://arxiv.org/abs/1709.06537 | id:1709.06537 author:You-Luen Lee, Da-Cheng Juan, Xuan-An Tseng, Yu-Ting Chen, Shih-Chieh Chang category:cs.DC stat.ML  published:2017-08-14 summary:When will a server fail catastrophically in an industrial datacenter? Is it possible to forecast these failures so preventive actions can be taken to increase the reliability of a datacenter? To answer these questions, we have studied what are probably the largest, publicly available datacenter traces, containing more than 104 million events from 12,500 machines. Among these samples, we observe and categorize three types of machine failures, all of which are catastrophic and may lead to information loss, or even worse, reliability degradation of a datacenter. We further propose a two-stage framework-DC-Prophet-based on One-Class Support Vector Machine and Random Forest. DC-Prophet extracts surprising patterns and accurately predicts the next failure of a machine. Experimental results show that DC-Prophet achieves an AUC of 0.93 in predicting the next machine failure, and a F3-score of 0.88 (out of 1). On average, DC-Prophet outperforms other classical machine learning methods by 39.45% in F3-score. version:1
arxiv-1708-03993 | Optimizing Gross Merchandise Volume via DNN-MAB Dynamic Ranking Paradigm | http://arxiv.org/abs/1708.03993 | id:1708.03993 author:Yan Yan, Wentao Guo, Meng Zhao, Jinghe Hu, Weipeng P. Yan category:cs.AI cs.IR  published:2017-08-14 summary:With the transition from people's traditional `brick-and-mortar' shopping to online mobile shopping patterns in web 2.0 $\mathit{era}$, the recommender system plays a critical role in E-Commerce and E-Retails. This is especially true when designing this system for more than $\mathbf{236~million}$ daily active users. Ranking strategy, the key module of the recommender system, needs to be precise, accurate, and responsive for estimating customers' intents. We propose a dynamic ranking paradigm, named as DNN-MAB, that is composed of a pairwise deep neural network (DNN) $\mathit{pre}$-ranker connecting a revised multi-armed bandit (MAB) dynamic $\mathit{post}$-ranker. By taking into account of explicit and implicit user feedbacks such as impressions, clicks, conversions, etc. DNN-MAB is able to adjust DNN $\mathit{pre}$-ranking scores to assist customers locating items they are interested in most so that they can converge quickly and frequently. To the best of our knowledge, frameworks like DNN-MAB have not been discussed in the previous literature to either E-Commerce or machine learning audiences. In practice, DNN-MAB has been deployed to production and it easily outperforms against other state-of-the-art models by significantly lifting the gross merchandise volume (GMV) which is the objective metrics at JD. version:1
arxiv-1708-03080 | A Simple and Realistic Pedestrian Model for Crowd Simulation and Application | http://arxiv.org/abs/1708.03080 | id:1708.03080 author:Wonho Kang, Youngnam Han category:cs.MA cs.AI nlin.CG  published:2017-08-10 summary:The simulation of pedestrian crowd that reflects reality is a major challenge for researches. Several crowd simulation models have been proposed such as cellular automata model, agent-based model, fluid dynamic model, etc. It is important to note that agent-based model is able, over others approaches, to provide a natural description of the system and then to capture complex human behaviors. In this paper, we propose a multi-agent simulation model in which pedestrian positions are updated at discrete time intervals. It takes into account the major normal conditions of a simple pedestrian situated in a crowd such as preferences, realistic perception of environment, etc. Our objective is to simulate the pedestrian crowd realistically towards a simulation of believable pedestrian behaviors. Typical pedestrian phenomena, including the unidirectional and bidirectional movement in a corridor as well as the flow through bottleneck, are simulated. The conducted simulations show that our model is able to produce realistic pedestrian behaviors. The obtained fundamental diagram and flow rate at bottleneck agree very well with classic conclusions and empirical study results. It is hoped that the idea of this study may be helpful in promoting the modeling and simulation of pedestrian crowd in a simple way. version:2
arxiv-1707-09394 | Inverse Reinforcement Learning in Large State Spaces via Function Approximation | http://arxiv.org/abs/1707.09394 | id:1707.09394 author:Kun Li, Joel W. Burdick category:cs.LG cs.RO  published:2017-07-28 summary:This paper introduces a new method for inverse reinforcement learning in large-scale and high-dimensional state spaces. To avoid solving the computationally expensive reinforcement learning problems in reward learning, we propose a function approximation method to ensure that the Bellman Optimality Equation always holds, and then estimate a function to maximize the likelihood of the observed motion. The time complexity of the proposed method is linearly proportional to the cardinality of the action set, thus it can handle large state spaces efficiently. We test the proposed method in a simulated environment, and show that it is more accurate than existing methods and significantly better in scalability. We also show that the proposed method can extend many existing methods to high-dimensional state spaces. We then apply the method to evaluating the effect of rehabilitative stimulations on patients with spinal cord injuries based on the observed patient motions. version:3
arxiv-1708-03910 | Semi-supervised emotion lexicon expansion with label propagation and specialized word embeddings | http://arxiv.org/abs/1708.03910 | id:1708.03910 author:Mario Giulianelli category:cs.CL cs.AI cs.NE  published:2017-08-13 summary:There exist two main approaches to automatically extract affective orientation: lexicon-based and corpus-based. In this work, we argue that these two methods are compatible and show that combining them can improve the accuracy of emotion classifiers. In particular, we introduce a novel variant of the Label Propagation algorithm that is tailored to distributed word representations, we apply batch gradient descent to accelerate the optimization of label propagation and to make the optimization feasible for large graphs, and we propose a reproducible method for emotion lexicon expansion. We conclude that label propagation can expand an emotion lexicon in a meaningful way and that the expanded emotion lexicon can be leveraged to improve the accuracy of an emotion classifier. version:1
arxiv-1708-03903 | Distributed Exact Weighted All-Pairs Shortest Paths in $\tilde O(n^{5/4})$ Rounds | http://arxiv.org/abs/1708.03903 | id:1708.03903 author:Chien-Chung Huang, Danupon Nanongkai, Thatchaphol Saranurak category:cs.DC cs.DS C.2.4; F.2.0; G.2.2  published:2017-08-13 summary:We study computing {\em all-pairs shortest paths} (APSP) on distributed networks (the CONGEST model). The goal is for every node in the (weighted) network to know the distance from every other node using communication. The problem admits $(1+o(1))$-approximation $\tilde O(n)$-time algorithms ~\cite{LenzenP-podc15,Nanongkai-STOC14}, which are matched with $\tilde \Omega(n)$-time lower bounds~\cite{Nanongkai-STOC14,LenzenP_stoc13,FrischknechtHW12}\footnote{$\tilde \Theta$, $\tilde O$ and $\tilde \Omega$ hide polylogarithmic factors. Note that the lower bounds also hold even in the unweighted case and in the weighted case with polynomial approximation ratios.}. No $\omega(n)$ lower bound or $o(m)$ upper bound were known for exact computation. In this paper, we present an $\tilde O(n^{5/4})$-time randomized (Las Vegas) algorithm for exact weighted APSP; this provides the first improvement over the naive $O(m)$-time algorithm when the network is not so sparse. Our result also holds for the case where edge weights are {\em asymmetric} (a.k.a. the directed case where communication is bidirectional). Our techniques also yield an $\tilde O(n^{3/4}k^{1/2}+n)$-time algorithm for the {\em $k$-source shortest paths} problem where we want every node to know distances from $k$ sources; this improves Elkin's recent bound~\cite{Elkin-STOC17} when $k=\tilde \omega(n^{1/4})$. version:1
arxiv-1708-03901 | Belief Tree Search for Active Object Recognition | http://arxiv.org/abs/1708.03901 | id:1708.03901 author:Mohsen Malmir, Garrison W. Cottrell category:cs.AI cs.CV  published:2017-08-13 summary:Active Object Recognition (AOR) has been approached as an unsupervised learning problem, in which optimal trajectories for object inspection are not known and are to be discovered by reducing label uncertainty measures or training with reinforcement learning. Such approaches have no guarantees of the quality of their solution. In this paper, we treat AOR as a Partially Observable Markov Decision Process (POMDP) and find near-optimal policies on training data using Belief Tree Search (BTS) on the corresponding belief Markov Decision Process (MDP). AOR then reduces to the problem of knowledge transfer from near-optimal policies on training set to the test set. We train a Long Short Term Memory (LSTM) network to predict the best next action on the training set rollouts. We sho that the proposed AOR method generalizes well to novel views of familiar objects and also to novel objects. We compare this supervised scheme against guided policy search, and find that the LSTM network reaches higher recognition accuracy compared to the guided policy method. We further look into optimizing the observation function to increase the total collected reward of optimal policy. In AOR, the observation function is known only approximately. We propose a gradient-based method update to this approximate observation function to increase the total reward of any policy. We show that by optimizing the observation function and retraining the supervised LSTM network, the AOR performance on the test set improves significantly. version:1
arxiv-1708-03900 | Sensitivity Analysis of Core Specialization Techniques | http://arxiv.org/abs/1708.03900 | id:1708.03900 author:Prathmesh Kallurkar, Smruti R. Sarangi category:cs.AR  published:2017-08-13 summary:The instruction footprint of OS-intensive workloads such as web servers, database servers, and file servers typically exceeds the size of the instruction cache (32 KB). Consequently, such workloads incur a lot of i-cache misses, which reduces their performance drastically. Several papers have proposed to improve the performance of such workloads using core specialization. In this scheme, tasks with different instruction footprints are executed on different cores. In this report, we study the performance of five state of the art core specialization techniques: SelectiveOffload [6], FlexSC [8], DisAggregateOS [5], SLICC [2], and SchedTask [3] for different system parameters. Our studies show that for a suite of 8 popular OS-intensive workloads, SchedTask performs best for all evaluated configurations. version:1
arxiv-1709-08689 | The Benefits of Low Operating Voltage Devices to the Energy Efficiency of Parallel Systems | http://arxiv.org/abs/1709.08689 | id:1709.08689 author:Samuel Xavier-de-Souza, Eduardo A. Neves, Alex F. A. Furtunato, Luiz F. Q. Silveira, Kyriakos Georgiou, Kerstin I. Eder category:cs.DC  published:2017-08-13 summary:Programmable circuits such as general-purpose processors or FPGAs have their end-user energy efficiency strongly dependent on the program that they execute. Ultimately, it is the programmer's ability to code and, in the case of general purpose processors, the compiler's ability to translate source code into a sequence of native instructions that make the circuit deliver the expected performance to the end user. This way, the benefits of energy-efficient circuits build upon energy-efficient devices could be obfuscated by poorly written software. Clearly, having well-written software running on conventional circuits is no better in terms of energy efficiency than having poorly written software running on energy-efficient circuits. Therefore, to get the most out of the energy-saving capabilities of programmable circuits that support low voltage operating modes, it is necessary to address software issues that might work against the benefits of operating in such modes. version:1
arxiv-1603-00794 | Robotic Playing for Hierarchical Complex Skill Learning | http://arxiv.org/abs/1603.00794 | id:1603.00794 author:Simon Hangl, Emre Ugur, Sandor Szedmak, Justus Piater category:cs.RO  published:2016-03-02 summary:In complex manipulation scenarios (e.g. tasks requiring complex interaction of two hands or in-hand manipulation), generalization is a hard problem. Current methods still either require a substantial amount of (supervised) training data and / or strong assumptions on both the environment and the task. In this paradigm, controllers solving these tasks tend to be complex. We propose a paradigm of maintaining simpler controllers solving the task in a small number of specific situations. In order to generalize to novel situations, the robot transforms the environment from novel situations into a situation where the solution of the task is already known. Our solution to this problem is to play with objects and use previously trained skills (basis skills). These skills can either be used for estimating or for changing the current state of the environment and are organized in skill hierarchies. The approach is evaluated in complex pick-and-place scenarios that involve complex manipulation. We further show that these skills can be learned by autonomous playing. version:2
arxiv-1708-03882 | Monadic Remote Invocation | http://arxiv.org/abs/1708.03882 | id:1708.03882 author:Raphael Jolly category:cs.PL cs.DC D.3.2; D.3.3  published:2017-08-13 summary:In order to achieve Separation of Concerns in the domain of remote method invocation, a small functional adapter is added atop Java RMI, eliminating the need for every remote object to implement java.rmi.Remote and making it possible to remotely access existing code, unchanged. The Remote monad is introduced, and its implementation and usage are detailed. Reusing the existing, proven technology of RMI allows not to re-invent the underlying network protocol. As a result, orthogonal remote invocation is achieved with little or no implementation effort. version:1
arxiv-1708-03852 | VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator | http://arxiv.org/abs/1708.03852 | id:1708.03852 author:Tong Qin, Peiliang Li, Shaojie Shen category:cs.RO  published:2017-08-13 summary:A monocular visual-inertial system (VINS), consisting of a camera and a low-cost inertial measurement unit (IMU), forms the minimum sensor suite for metric six degrees-of-freedom (DOF) state estimation. However, the lack of direct distance measurement poses significant challenges in terms of IMU processing, estimator initialization, extrinsic calibration, and nonlinear optimization. In this work, we present VINS-Mono: a robust and versatile monocular visual-inertial state estimator.Our approach starts with a robust procedure for estimator initialization and failure recovery. A tightly-coupled, nonlinear optimization-based method is used to obtain high accuracy visual-inertial odometry by fusing pre-integrated IMU measurements and feature observations. A loop detection module, in combination with our tightly-coupled formulation, enables relocalization with minimum computation overhead.We additionally perform four degrees-of-freedom pose graph optimization to enforce global consistency. We validate the performance of our system on public datasets and real-world experiments and compare against other state-of-the-art algorithms. We also perform onboard closed-loop autonomous flight on the MAV platform and port the algorithm to an iOS-based demonstration. We highlight that the proposed work is a reliable, complete, and versatile system that is applicable for different applications that require high accuracy localization. We open source our implementations for both PCs and iOS mobile devices. version:1
arxiv-1609-08524 | UbuntuWorld 1.0 LTS - A Platform for Automated Problem Solving & Troubleshooting in the Ubuntu OS | http://arxiv.org/abs/1609.08524 | id:1609.08524 author:Tathagata Chakraborti, Kartik Talamadupula, Kshitij P. Fadnis, Murray Campbell, Subbarao Kambhampati category:cs.AI  published:2016-09-27 summary:In this paper, we present UbuntuWorld 1.0 LTS - a platform for developing automated technical support agents in the Ubuntu operating system. Specifically, we propose to use the Bash terminal as a simulator of the Ubuntu environment for a learning-based agent and demonstrate the usefulness of adopting reinforcement learning (RL) techniques for basic problem solving and troubleshooting in this environment. We provide a plug-and-play interface to the simulator as a python package where different types of agents can be plugged in and evaluated, and provide pathways for integrating data from online support forums like AskUbuntu into an automated agent's learning process. Finally, we show that the use of this data significantly improves the agent's learning efficiency. We believe that this platform can be adopted as a real-world test bed for research on automated technical support. version:2
arxiv-1708-03792 | Evacuating Two Robots from Two Unknown Exits on the Perimeter of a Disk | http://arxiv.org/abs/1708.03792 | id:1708.03792 author:Debasish Pattanayak, H. Ramesh, Partha Sarathi Mandal, Stefan Schmid category:cs.DC  published:2017-08-12 summary:Distributed evacuation of mobile robots is a recent development. We consider the evacuation problem of two robots which are initially located at the center of a unit disk. Both the robots have to evacuate the disk through the exits situated on the perimeter of the disk at an unknown location. The distance between two exits along the perimeter $d$ is given. We consider two different communication models. First, in the wireless model, the robots can send a message to each other over a long distance. Second, in face-to-face communication model, the robots can exchange information with each other only when they touch each other. The objective of the evacuation problem is to design an algorithm which minimizes the evacuation time of both the robots. For the wireless communication model, we propose a generic algorithm for two robots moving to two points on the perimeter with an initial separation of $\zeta \leq d$. We also investigate evacuation problem for both unlabeled and labeled exits in the wireless communication model. For the face-to-face communication model, we propose two different algorithms for $\zeta =0$ and $\zeta =d$ for unlabeled exits. We also propose a generic algorithm for $\zeta \leq d$ for labeled exits. We provide lower bounds corresponding to different $d$ values in the face-to-face communication model. We evaluate the performance our algorithms with simulation for both of the communication models. version:1
arxiv-1609-00292 | Crowdsourcing with Unsure Option | http://arxiv.org/abs/1609.00292 | id:1609.00292 author:Yao-Xiang Ding, Zhi-Hua Zhou category:cs.AI cs.HC  published:2016-09-01 summary:One of the fundamental problems in crowdsourcing is the trade-off between the number of the workers needed for high-accuracy aggregation and the budget to pay. For saving budget, it is important to ensure high quality of the crowd-sourced labels, hence the total cost on label collection will be reduced. Since the self-confidence of the workers often has a close relationship with their abilities, a possible way for quality control is to request the workers to return the labels only when they feel confident, by means of providing unsure option to them. On the other hand, allowing workers to choose unsure option also leads to the potential danger of budget waste. In this work, we propose the analysis towards understanding when providing the unsure option indeed leads to significant cost reduction, as well as how the confidence threshold is set. We also propose an online mechanism, which is alternative for threshold selection when the estimation of the crowd ability distribution is difficult. version:2
arxiv-1708-03655 | Communicating Robot Arm Motion Intent Through Mixed Reality Head-mounted Displays | http://arxiv.org/abs/1708.03655 | id:1708.03655 author:Eric Rosen, David Whitney, Elizabeth Phillips, Gary Chien, James Tompkin, George Konidaris, Stefanie Tellex category:cs.RO cs.HC  published:2017-08-11 summary:Efficient motion intent communication is necessary for safe and collaborative work environments with collocated humans and robots. Humans efficiently communicate their motion intent to other humans through gestures, gaze, and social cues. However, robots often have difficulty efficiently communicating their motion intent to humans via these methods. Many existing methods for robot motion intent communication rely on 2D displays, which require the human to continually pause their work and check a visualization. We propose a mixed reality head-mounted display visualization of the proposed robot motion over the wearer's real-world view of the robot and its environment. To evaluate the effectiveness of this system against a 2D display visualization and against no visualization, we asked 32 participants to labeled different robot arm motions as either colliding or non-colliding with blocks on a table. We found a 16% increase in accuracy with a 62% decrease in the time it took to complete the task compared to the next best system. This demonstrates that a mixed-reality HMD allows a human to more quickly and accurately tell where the robot is going to move than the compared baselines. version:1
arxiv-1708-03309 | Systematic Testing of Convolutional Neural Networks for Autonomous Driving | http://arxiv.org/abs/1708.03309 | id:1708.03309 author:Tommaso Dreossi, Shromona Ghosh, Alberto Sangiovanni-Vincentelli, Sanjit A. Seshia category:cs.CV cs.AI  published:2017-08-10 summary:We present a framework to systematically analyze convolutional neural networks (CNNs) used in classification of cars in autonomous vehicles. Our analysis procedure comprises an image generator that produces synthetic pictures by sampling in a lower dimension image modification subspace and a suite of visualization tools. The image generator produces images which can be used to test the CNN and hence expose its vulnerabilities. The presented framework can be used to extract insights of the CNN classifier, compare across classification models, or generate training and validation datasets. version:2
arxiv-1708-03549 | Dynamic controllers for column synchronization of rotation matrices: a QR-factorization approach | http://arxiv.org/abs/1708.03549 | id:1708.03549 author:Johan Thunberg, Johan Markdahl, Jorge Goncalves category:math.OC cs.DC cs.MA cs.SY  published:2017-08-11 summary:In the multi-agent systems setting, this paper addresses continuous-time distributed synchronization of columns of rotation matrices. More precisely, k specific columns shall be synchronized and only the corresponding k columns of the relative rotations between the agents are assumed to be available for the control design. When one specific column is considered, the problem is equivalent to synchronization on the (d-1)-dimensional unit sphere and when all the columns are considered the problem is equivalent to synchronization on SO(d). We design dynamic control laws that solve these synchronization problems. The control laws are based on the introduction of auxiliary variables in combination with a QR-factorization approach. The benefit of this QR-factorization approach is that we can decouple the dynamics of the k columns from the remaining d-k ones. Under the control scheme, the closed loop system achieves almost global convergence to synchronization for quasi-strong graph interaction topologies. version:1
arxiv-1707-08783 | Analysis of Italian Word Embeddings | http://arxiv.org/abs/1707.08783 | id:1707.08783 author:Rocco Tripodi, Stefano Li Pira category:cs.CL cs.AI  published:2017-07-27 summary:In this work we analyze the performances of two of the most used word embeddings algorithms, skip-gram and continuous bag of words on Italian language. These algorithms have many hyper-parameter that have to be carefully tuned in order to obtain accurate word representation in vectorial space. We provide an accurate analysis and an evaluation, showing what are the best configuration of parameters for specific tasks. version:3
arxiv-1708-04529 | Learning from Noisy Label Distributions | http://arxiv.org/abs/1708.04529 | id:1708.04529 author:Yuya Yoshikawa category:cs.LG cs.AI stat.ML  published:2017-08-11 summary:In this paper, we consider a novel machine learning problem, that is, learning a classifier from noisy label distributions. In this problem, each instance with a feature vector belongs to at least one group. Then, instead of the true label of each instance, we observe the label distribution of the instances associated with a group, where the label distribution is distorted by an unknown noise. Our goals are to (1) estimate the true label of each instance, and (2) learn a classifier that predicts the true label of a new instance. We propose a probabilistic model that considers true label distributions of groups and parameters that represent the noise as hidden variables. The model can be learned based on a variational Bayesian method. In numerical experiments, we show that the proposed model outperforms existing methods in terms of the estimation of the true labels of instances. version:1
arxiv-1708-03395 | Phase Transitions, Optimal Errors and Optimality of Message-Passing in Generalized Linear Models | http://arxiv.org/abs/1708.03395 | id:1708.03395 author:Jean Barbier, Florent Krzakala, Nicolas Macris, Léo Miolane, Lenka Zdeborová category:cs.IT cond-mat.dis-nn cs.AI cs.LG math-ph math.IT math.MP  published:2017-08-10 summary:We consider generalized linear models where an unknown $n$-dimensional signal vector is observed through the successive application of a random matrix and a non-linear (possibly probabilistic) componentwise function. We consider the models in the high-dimensional limit, where the observation consists of $m$ points, and $m/n {\to} {\alpha}$ where ${\alpha}$ stays finite in the limit $m, n {\to} {\infty}$. This situation is ubiquitous in applications ranging from supervised machine learning to signal processing. A substantial amount of work suggests that both the inference and learning tasks in these problems have sharp intrinsic limitations when the available data become too scarce or too noisy. Here, we provide rigorous asymptotic predictions for these thresholds through the proof of a simple expression for the mutual information between the observations and the signal. Thanks to this expression we also obtain as a consequence the optimal value of the generalization error in many statistical learning models of interest, such as the teacher-student binary perceptron, and introduce several new models with remarquable properties. We compute these thresholds (or "phase transitions") using ideas from statistical physics that are turned into rigorous methods thanks to a new powerful smart-path interpolation technique called the stochastic interpolation method, which has recently been introduced by two of the authors. Moreover we show that a polynomial-time algorithm refered to as generalized approximate message-passing reaches the optimal generalization performance for a large set of parameters in these problems. Our results clarify the difficulties and challenges one has to face when solving complex high-dimensional statistical problems. version:1
arxiv-1708-03389 | A Logical Approach to Cloud Federation | http://arxiv.org/abs/1708.03389 | id:1708.03389 author:Qiang Cao, Yuanjun Yao, Jeff Chase category:cs.DC cs.CR  published:2017-08-10 summary:Federated clouds raise a variety of challenges for managing identity, resource access, naming, connectivity, and object access control. This paper shows how to address these challenges in a comprehensive and uniform way using a data-centric approach. The foundation of our approach is a trust logic in which participants issue authenticated statements about principals, objects, attributes, and relationships in a logic language, with reasoning based on declarative policy rules. We show how to use the logic to implement a trust infrastructure for cloud federation that extends the model of NSF GENI, a federated IaaS testbed. It captures shared identity management, GENI authority services, cross-site interconnection using L2 circuits, and a naming and access control system similar to AWS Identity and Access Management (IAM), but extended to a federated system without central control. version:1
arxiv-1708-03341 | Technical Problems With "Programmable self-assembly in a thousand-robot swarm" | http://arxiv.org/abs/1708.03341 | id:1708.03341 author:Muaz A. Niazi category:cs.AI cs.MA cs.RO nlin.AO nlin.PS  published:2017-08-10 summary:Rubenstein et al. present an interesting system of programmable self-assembled structure formation using 1000 Kilobot robots. The paper claims to advance work in artificial swarms similar to capabilities of natural systems besides being highly robust. However, the system lacks in terms of matching motility and complex shapes with holes, thereby limiting practical similarity to self-assembly in living systems. version:1
arxiv-1412-1913 | A Portfolio Approach to Algorithm Selection for Discrete Time-Cost Trade-off Problem | http://arxiv.org/abs/1412.1913 | id:1412.1913 author:Santosh Mungle category:cs.AI  published:2014-12-05 summary:It is a known fact that the performance of optimization algorithms for NP-Hard problems vary from instance to instance. We observed the same trend when we comprehensively studied multi-objective evolutionary algorithms (MOEAs) on a six benchmark instances of discrete time-cost trade-off problem (DTCTP) in a construction project. In this paper, instead of using a single algorithm to solve DTCTP, we use a portfolio approach that takes multiple algorithms as its constituent. We proposed portfolio comprising of four MOEAs, Non-dominated Sorting Genetic Algorithm II (NSGA-II), the strength Pareto Evolutionary Algorithm II (SPEA-II), Pareto archive evolutionary strategy (PAES) and Niched Pareto Genetic Algorithm II (NPGA-II) to solve DTCTP. The result shows that the portfolio approach is computationally fast and qualitatively superior to its constituent algorithms for all benchmark instances. Moreover, portfolio approach provides an insight in selecting the best algorithm for all benchmark instances of DTCTP. version:2
arxiv-1708-03274 | Simulating a Shared Register in a System that Never Stops Changing | http://arxiv.org/abs/1708.03274 | id:1708.03274 author:Hagit Attiya, Hyun Chul Chung, Faith Ellen, Saptaparni Kumar, Jennifer L. Welch category:cs.DC  published:2017-08-10 summary:Simulating a shared register can mask the intricacies of designing algorithms for asynchronous message-passing systems subject to crash failures, since it allows them to run algorithms designed for the simpler shared-memory model. Typically such simulations replicate the value of the register in multiple servers and require readers and writers to communicate with a majority of servers. The success of this approach for static systems, where the set of nodes (readers, writers, and servers) is fixed, has motivated several similar simulations for dynamic systems, where nodes may enter and leave. However, existing simulations need to assume that the system eventually stops changing for a long enough period or that the system size is bounded. This paper presents the first simulation of an atomic read/write register in a crash-prone asynchronous system that can change size and withstand nodes continually entering and leaving. The simulation allows the system to keep changing, provided that the number of nodes entering and leaving during a fixed time interval is at most a constant fraction of the current system size. The simulation also tolerates node crashes as long as the number of failed nodes in the system is at most a constant fraction of the current system size. version:1
arxiv-1708-03269 | Routing Unmanned Vehicles in GPS-Denied Environments | http://arxiv.org/abs/1708.03269 | id:1708.03269 author:Kaarthik Sundar, Sohum Misra, Sivakumar Rathinam, Rajnikant Sharma category:cs.RO  published:2017-08-10 summary:Most of the routing algorithms for unmanned vehicles, that arise in data gathering and monitoring applications in the literature, rely on the Global Positioning System (GPS) information for localization. However, disruption of GPS signals either intentionally or unintentionally could potentially render these algorithms not applicable. In this article, we present a novel method to address this difficulty by combining methods from cooperative localization and routing. In particular, the article formulates a fundamental combinatorial optimization problem to plan routes for an unmanned vehicle in a GPS-restricted environment while enabling localization for the vehicle. We also develop algorithms to compute optimal paths for the vehicle using the proposed formulation. Extensive simulation results are also presented to corroborate the effectiveness and performance of the proposed formulation and algorithms. version:1
arxiv-1708-03264 | Contextuality from missing and versioned data | http://arxiv.org/abs/1708.03264 | id:1708.03264 author:Jason Morton category:cs.DB cs.DC stat.CO  published:2017-08-10 summary:Traditionally categorical data analysis (e.g. generalized linear models) works with simple, flat datasets akin to a single table in a database with no notion of missing data or conflicting versions. In contrast, modern data analysis must deal with distributed databases with many partial local tables that need not always agree. The computational agents tabulating these tables are spatially separated, with binding speed-of-light constraints and data arriving too rapidly for these distributed views ever to be fully informed and globally consistent. Contextuality is a mathematical property which describes a kind of inconsistency arising in quantum mechanics (e.g. in Bell's theorem). In this paper we show how contextuality can arise in common data collection scenarios, including missing data and versioning (as in low-latency distributed databases employing snapshot isolation). In the companion paper, we develop statistical models adapted to this regime. version:1
arxiv-1708-03246 | SESA: Supervised Explicit Semantic Analysis | http://arxiv.org/abs/1708.03246 | id:1708.03246 author:Dasha Bogdanova, Majid Yazdani category:cs.CL cs.AI  published:2017-08-10 summary:In recent years supervised representation learning has provided state of the art or close to the state of the art results in semantic analysis tasks including ranking and information retrieval. The core idea is to learn how to embed items into a latent space such that they optimize a supervised objective in that latent space. The dimensions of the latent space have no clear semantics, and this reduces the interpretability of the system. For example, in personalization models, it is hard to explain why a particular item is ranked high for a given user profile. We propose a novel model of representation learning called Supervised Explicit Semantic Analysis (SESA) that is trained in a supervised fashion to embed items to a set of dimensions with explicit semantics. The model learns to compare two objects by representing them in this explicit space, where each dimension corresponds to a concept from a knowledge base. This work extends Explicit Semantic Analysis (ESA) with a supervised model for ranking problems. We apply this model to the task of Job-Profile relevance in LinkedIn in which a set of skills defines our explicit dimensions of the space. Every profile and job are encoded to this set of skills their similarity is calculated in this space. We use RNNs to embed text input into this space. In addition to interpretability, our model makes use of the web-scale collaborative skills data that is provided by users for each LinkedIn profile. Our model provides state of the art result while it remains interpretable. version:1
arxiv-1708-03229 | Automatic Selection of t-SNE Perplexity | http://arxiv.org/abs/1708.03229 | id:1708.03229 author:Yanshuai Cao, Luyu Wang category:cs.AI cs.LG stat.AP stat.ML  published:2017-08-10 summary:t-Distributed Stochastic Neighbor Embedding (t-SNE) is one of the most widely used dimensionality reduction methods for data visualization, but it has a perplexity hyperparameter that requires manual selection. In practice, proper tuning of t-SNE perplexity requires users to understand the inner working of the method as well as to have hands-on experience. We propose a model selection objective for t-SNE perplexity that requires negligible extra computation beyond that of the t-SNE itself. We empirically validate that the perplexity settings found by our approach are consistent with preferences elicited from human experts across a number of datasets. The similarities of our approach to Bayesian information criteria (BIC) and minimum description length (MDL) are also analyzed. version:1
arxiv-1707-09965 | Tuning MPI Collectives by Verifying Performance Guidelines | http://arxiv.org/abs/1707.09965 | id:1707.09965 author:Sascha Hunold, Alexandra Carpen-Amarie category:cs.DC  published:2017-07-31 summary:MPI collective operations provide a standardized interface for performing data movements within a group of processes. The efficiency of collective communication operations depends on the actual algorithm, its implementation, and the specific communication problem (type of communication, message size, number of processes). Many MPI libraries provide numerous algorithms for specific collective operations. The strategy for selecting an efficient algorithm is often times predefined (hard-coded) in MPI libraries, but some of them, such as Open MPI, allow users to change the algorithm manually. Finding the best algorithm for each case is a hard problem, and several approaches to tune these algorithmic parameters have been proposed. We use an orthogonal approach to the parameter-tuning of MPI collectives, that is, instead of testing individual algorithmic choices provided by an MPI library, we compare the latency of a specific MPI collective operation to the latency of semantically equivalent functions, which we call the mock-up implementations. The structure of the mock-up implementations is defined by self-consistent performance guidelines. The advantage of this approach is that tuning using mock-up implementations is always possible, whether or not an MPI library allows users to select a specific algorithm at run-time. We implement this concept in a library called PGMPITuneLib, which is layered between the user code and the actual MPI implementation. This library selects the best-performing algorithmic pattern of an MPI collective by intercepting MPI calls and redirecting them to our mock-up implementations. Experimental results show that PGMPITuneLib can significantly reduce the latency of MPI collectives, and also equally important, that it can help identifying the tuning potential of MPI libraries. version:2
arxiv-1708-03209 | Tosca: Operationalizing Commitments Over Information Protocols | http://arxiv.org/abs/1708.03209 | id:1708.03209 author:Thomas C. King, Akın Günay, Amit K. Chopra, Munindar P. Singh category:cs.AI  published:2017-08-10 summary:The notion of commitment is widely studied as a high-level abstraction for modeling multiagent interaction. An important challenge is supporting flexible decentralized enactments of commitment specifications. In this paper, we combine recent advances on specifying commitments and information protocols. Specifically, we contribute Tosca, a technique for automatically synthesizing information protocols from commitment specifications. Our main result is that the synthesized protocols support commitment alignment, which is the idea that agents must make compatible inferences about their commitments despite decentralization. version:1
arxiv-1708-03157 | TensorFlow Enabled Genetic Programming | http://arxiv.org/abs/1708.03157 | id:1708.03157 author:Kai Staats, Edward Pantridge, Marco Cavaglia, Iurii Milovanov, Arun Aniyan category:cs.DC  published:2017-08-10 summary:Genetic Programming, a kind of evolutionary computation and machine learning algorithm, is shown to benefit significantly from the application of vectorized data and the TensorFlow numerical computation library on both CPU and GPU architectures. The open source, Python Karoo GP is employed for a series of 190 tests across 6 platforms, with real-world datasets ranging from 18 to 5.5M data points. This body of tests demonstrates that datasets measured in tens and hundreds of data points see 2-15x improvement when moving from the scalar/SymPy configuration to the vector/TensorFlow configuration, with a single core performing on par or better than multiple CPU cores and GPUs. A dataset composed of 90,000 data points demonstrates a single vector/TensorFlow CPU core performing 875x better than 40 scalar/Sympy CPU cores. And a dataset containing 5.5M data points sees GPU configurations out-performing CPU configurations on average by 1.3x. version:1
arxiv-1708-03151 | The Static and Stochastic VRPTW with both random Customers and Reveal Times: algorithms and recourse strategies | http://arxiv.org/abs/1708.03151 | id:1708.03151 author:Michael Saint-Guillain, Christine Solnon, Yves Deville category:cs.AI cs.DM  published:2017-08-10 summary:Unlike its deterministic counterpart, static and stochastic vehicle routing problems (SS-VRP) aim at modeling and solving real-life operational problems by considering uncertainty on data. We consider the SS-VRPTW-CR introduced in Saint-Guillain et al. (2017). Like the SS-VRP introduced by Bertsimas (1992), we search for optimal first stage routes for a fleet of vehicles to handle a set of stochastic customer demands, i.e., demands are uncertain and we only know their probabilities. In addition to capacity constraints, customer demands are also constrained by time windows. Unlike all SS-VRP variants, the SS-VRPTW-CR does not make any assumption on the time at which a stochastic demand is revealed, i.e., the reveal time is stochastic as well. To handle this new problem, we introduce waiting locations: Each vehicle is assigned a sequence of waiting locations from which it may serve some associated demands, and the objective is to minimize the expected number of demands that cannot be satisfied in time. In this paper, we propose two new recourse strategies for the SS-VRPTW-CR, together with their closed-form expressions for efficiently computing their expectations: The first one allows us to take vehicle capacities into account; The second one allows us to optimize routes by avoiding some useless trips. We propose two algorithms for searching for routes with optimal expected costs: The first one is an extended branch-and-cut algorithm, based on a stochastic integer formulation, and the second one is a local search based heuristic method. We also introduce a new public benchmark for the SS-VRPTW-CR, based on real-world data coming from the city of Lyon. We evaluate our two algorithms on this benchmark and empirically demonstrate the expected superiority of the SS-VRPTW-CR anticipative actions over a basic "wait-and-serve" policy. version:1
arxiv-1709-06622 | Distributed Training Large-Scale Deep Architectures | http://arxiv.org/abs/1709.06622 | id:1709.06622 author:Shang-Xuan Zou, Chun-Yen Chen, Jui-Lin Wu, Chun-Nan Chou, Chia-Chin Tsao, Kuan-Chieh Tung, Ting-Wei Lin, Cheng-Lung Sung, Edward Y. Chang category:cs.DC cs.LG stat.ML  published:2017-08-10 summary:Scale of data and scale of computation infrastructures together enable the current deep learning renaissance. However, training large-scale deep architectures demands both algorithmic improvement and careful system configuration. In this paper, we focus on employing the system approach to speed up large-scale training. Via lessons learned from our routine benchmarking effort, we first identify bottlenecks and overheads that hinter data parallelism. We then devise guidelines that help practitioners to configure an effective system and fine-tune parameters to achieve desired speedup. Specifically, we develop a procedure for setting minibatch size and choosing computation algorithms. We also derive lemmas for determining the quantity of key components such as the number of GPUs and parameter servers. Experiments and examples show that these guidelines help effectively speed up large-scale deep learning training. version:1
arxiv-1708-03055 | Optimal Control for Constrained Coverage Path Planning | http://arxiv.org/abs/1708.03055 | id:1708.03055 author:Ankit Manerikar, Debasmit Das, Pranay Banerjee category:cs.RO cs.SY  published:2017-08-10 summary:The problem of constrained coverage path planning involves a robot trying to cover maximum area of an environment under some constraints that appear as obstacles in the map. Out of the several coverage path planning methods, we consider augmenting the linear sweep-based coverage method to achieve minimum energy/ time optimality along with maximum area coverage. In addition, we also study the effects of variation of different parameters on the performance of the modified method. version:1
arxiv-1708-03053 | Application Level High Speed Transfer Optimization Based on Historical Analysis and Real-time Tuning | http://arxiv.org/abs/1708.03053 | id:1708.03053 author:Engin Arslan, Tevfik Kosar category:cs.DC  published:2017-08-10 summary:Data-intensive scientific and commercial applications increasingly require frequent movement of large datasets from one site to the other(s). Despite growing network capacities, these data movements rarely achieve the promised data transfer rates of the underlying physical network due to poorly tuned data transfer protocols. Accurately and efficiently tuning the data transfer protocol parameters in a dynamically changing network environment is a major challenge and remains as an open research problem. In this paper, we present predictive end-to-end data transfer optimization algorithms based on historical data analysis and real-time background traffic probing, dubbed HARP. Most of the previous work in this area are solely based on real time network probing which results either in an excessive sampling overhead or fails to accurately predict the optimal transfer parameters. Combining historical data analysis with real time sampling enables our algorithms to tune the application level data transfer parameters accurately and efficiently to achieve close-to-optimal end-to-end data transfer throughput with very low overhead. Our experimental analysis over a variety of network settings shows that HARP outperforms existing solutions by up to 50% in terms of the achieved throughput. version:1
arxiv-1708-03044 | "Is there anything else I can help you with?": Challenges in Deploying an On-Demand Crowd-Powered Conversational Agent | http://arxiv.org/abs/1708.03044 | id:1708.03044 author:Ting-Hao Kenneth Huang, Walter S. Lasecki, Amos Azaria, Jeffrey P. Bigham category:cs.HC cs.AI cs.CL  published:2017-08-10 summary:Intelligent conversational assistants, such as Apple's Siri, Microsoft's Cortana, and Amazon's Echo, have quickly become a part of our digital life. However, these assistants have major limitations, which prevents users from conversing with them as they would with human dialog partners. This limits our ability to observe how users really want to interact with the underlying system. To address this problem, we developed a crowd-powered conversational assistant, Chorus, and deployed it to see how users and workers would interact together when mediated by the system. Chorus sophisticatedly converses with end users over time by recruiting workers on demand, which in turn decide what might be the best response for each user sentence. Up to the first month of our deployment, 59 users have held conversations with Chorus during 320 conversational sessions. In this paper, we present an account of Chorus' deployment, with a focus on four challenges: (i) identifying when conversations are over, (ii) malicious users and workers, (iii) on-demand recruiting, and (iv) settings in which consensus is not enough. Our observations could assist the deployment of crowd-powered conversation systems and crowd-powered systems in general. version:1
arxiv-1708-03019 | Addendum to: Summary Information for Reasoning About Hierarchical Plans | http://arxiv.org/abs/1708.03019 | id:1708.03019 author:Lavindra de Silva, Sebastian Sardina, Lin Padgham category:cs.AI  published:2017-08-09 summary:Hierarchically structured agent plans are important for efficient planning and acting, and they also serve (among other things) to produce "richer" classical plans, composed not just of a sequence of primitive actions, but also "abstract" ones representing the supplied hierarchies. A crucial step for this and other approaches is deriving precondition and effect "summaries" from a given plan hierarchy. This paper provides mechanisms to do this for more pragmatic and conventional hierarchies than in the past. To this end, we formally define the notion of a precondition and an effect for a hierarchical plan; we present data structures and algorithms for automatically deriving this information; and we analyse the properties of the presented algorithms. We conclude the paper by detailing how our algorithms may be used together with a classical planner in order to obtain abstract plans. version:1
arxiv-1708-02983 | Scaling Deep Learning on GPU and Knights Landing clusters | http://arxiv.org/abs/1708.02983 | id:1708.02983 author:Yang You, Aydin Buluc, James Demmel category:cs.DC  published:2017-08-09 summary:The speed of deep neural networks training has become a big bottleneck of deep learning research and development. For example, training GoogleNet by ImageNet dataset on one Nvidia K20 GPU needs 21 days. To speed up the training process, the current deep learning systems heavily rely on the hardware accelerators. However, these accelerators have limited on-chip memory compared with CPUs. To handle large datasets, they need to fetch data from either CPU memory or remote processors. We use both self-hosted Intel Knights Landing (KNL) clusters and multi-GPU clusters as our target platforms. From an algorithm aspect, current distributed machine learning systems are mainly designed for cloud systems. These methods are asynchronous because of the slow network and high fault-tolerance requirement on cloud systems. We focus on Elastic Averaging SGD (EASGD) to design algorithms for HPC clusters. Original EASGD used round-robin method for communication and updating. The communication is ordered by the machine rank ID, which is inefficient on HPC clusters. First, we redesign four efficient algorithms for HPC systems to improve EASGD's poor scaling on clusters. Async EASGD, Async MEASGD, and Hogwild EASGD are faster \textcolor{black}{than} their existing counterparts (Async SGD, Async MSGD, and Hogwild SGD, resp.) in all the comparisons. Finally, we design Sync EASGD, which ties for the best performance among all the methods while being deterministic. In addition to the algorithmic improvements, we use some system-algorithm codesign techniques to scale up the algorithms. By reducing the percentage of communication from 87% to 14%, our Sync EASGD achieves 5.3x speedup over original EASGD on the same platform. We get 91.5% weak scaling efficiency on 4253 KNL cores, which is higher than the state-of-the-art implementation. version:1
arxiv-1708-02977 | Hierarchically-Attentive RNN for Album Summarization and Storytelling | http://arxiv.org/abs/1708.02977 | id:1708.02977 author:Licheng Yu, Mohit Bansal, Tamara L. Berg category:cs.CL cs.AI cs.CV cs.LG  published:2017-08-09 summary:We address the problem of end-to-end visual storytelling. Given a photo album, our model first selects the most representative (summary) photos, and then composes a natural language story for the album. For this task, we make use of the Visual Storytelling dataset and a model composed of three hierarchically-attentive Recurrent Neural Nets (RNNs) to: encode the album photos, select representative (summary) photos, and compose the story. Automatic and human evaluations show our model achieves better performance on selection, generation, and retrieval than baselines. version:1
arxiv-1708-02922 | Towards Long-endurance Flight: Design and Implementation of a Variable-pitch Gasoline-engine Quadrotor | http://arxiv.org/abs/1708.02922 | id:1708.02922 author:T. Pang, K. Peng, F. Lin, B. M. Chen category:cs.RO  published:2017-08-09 summary:Majority of today's fixed-pitch, electric-power quadrotors have short flight endurance ($<$ 1 hour) which greatly limits their applications. This paper presents a design methodology for the construction of a long-endurance quadrotor using variable-pitch rotors and a gasoline-engine. The methodology consists of three aspects. Firstly, the rotor blades and gasoline engine are selected as a pair, so that sufficient lift can be comfortably provided by the engine. Secondly, drivetrain and airframe are designed. Major challenges include airframe vibration minimization and power transmission from one engine to four rotors while keeping alternate rotors contra-rotating. Lastly, a PD controller is tuned to facilitate preliminary flight tests. The methodology has been verified by the construction and successful flight of our gasoline quadrotor prototype, which is designed to have a flight time of 2 to 3 hours and a maximum take-off weight of 10 kg. version:1
arxiv-1708-02906 | Implementing $\Diamond P$ with Bounded Messages on a Network of ADD Channels | http://arxiv.org/abs/1708.02906 | id:1708.02906 author:Saptaparni Kumar, Jennifer Welch category:cs.DC  published:2017-08-09 summary:We present an implementation of the eventually perfect failure detector ($\Diamond P$) from the original hierarchy of the Chandra-Toueg oracles on an arbitrary partitionable network composed of unreliable channels that can lose and reorder messages. Prior implementations of $\Diamond P$ have assumed different partially synchronous models ranging from bounded point-to-point message delay and reliable communication to unbounded message size and known network topologies. We implement $\Diamond P$ under very weak assumptions on an arbitrary, partitionable network composed of Average Delayed/Dropped (ADD) channels to model unreliable communication. Unlike older implementations, our failure detection algorithm uses bounded-sized messages to eventually detect all nodes that are unreachable (crashed or disconnected) from it. version:1
arxiv-1609-07008 | Scaling betweenness centrality using communication-efficient sparse matrix multiplication | http://arxiv.org/abs/1609.07008 | id:1609.07008 author:Edgar Solomonik, Maciej Besta, Flavio Vella, Torsten Hoefler category:cs.DC cs.DM cs.MS G.1.0; G.2.2  published:2016-09-22 summary:Betweenness centrality (BC) is a crucial graph problem that measures the significance of a vertex by the number of shortest paths leading through it. We propose Maximal Frontier Betweenness Centrality (MFBC): a succinct BC algorithm based on novel sparse matrix multiplication routines that performs a factor of $p^{1/3}$ less communication on $p$ processors than the best known alternatives, for graphs with $n$ vertices and average degree $k=n/p^{2/3}$. We formulate, implement, and prove the correctness of MFBC for weighted graphs by leveraging monoids instead of semirings, which enables a surprisingly succinct formulation. MFBC scales well for both extremely sparse and relatively dense graphs. It automatically searches a space of distributed data decompositions and sparse matrix multiplication algorithms for the most advantageous configuration. The MFBC implementation outperforms the well-known CombBLAS library by up to 8x and shows more robust performance. Our design methodology is readily extensible to other graph problems. version:2
arxiv-1708-02861 | Multi-Cell-Aware Opportunistic Random Access for Machine-Type Communications | http://arxiv.org/abs/1708.02861 | id:1708.02861 author:Huifa Lin, Won-Yong Shin category:cs.IT cs.DC cs.NI math.IT  published:2017-08-09 summary:Due to the difficulty of coordination in multi-cell random access, it is a practical challenge how to achieve the optimal throughput with decentralized transmission. In this paper, we propose a decentralized multi-cell-aware opportunistic random access (MA-ORA) protocol that achieves the optimal throughput scaling in an ultra-dense $K$-cell random access network with one access point (AP) and $N$ users in each cell, which is suited for machine-type communications. Unlike opportunistic scheduling for cellular multiple access where users are selected by base stations, under our MA-ORA protocol, each user opportunistically transmits with a predefined physical layer data rate in a decentralized manner if the desired signal power to the serving AP is sufficiently large and the generating interference leakage power to the other APs is sufficiently small (i.e., two threshold conditions are fulfilled). As a main result, it is proved that the aggregate throughput scales as $\frac{K}{e}(1-\epsilon) \log (\textsf{snr} \log N)$ in a high signal-to-noise ratio (SNR) regime if $N$ scales faster than $\textsf{snr}^{\frac{K-1}{1-\delta}}$ for small constants $\epsilon, \delta>0$. Our analytical result is validated by computer simulations. In addition, numerical evaluation confirms that under a practical setting, the proposed MA-ORA protocol outperforms conventional opportunistic random access protocols in terms of throughput. version:1
arxiv-1708-02851 | Measuring Inconsistency in Argument Graphs | http://arxiv.org/abs/1708.02851 | id:1708.02851 author:Anthony Hunter category:cs.AI  published:2017-08-09 summary:There have been a number of developments in measuring inconsistency in logic-based representations of knowledge. In contrast, the development of inconsistency measures for computational models of argument has been limited. To address this shortcoming, this paper provides a general framework for measuring inconsistency in abstract argumentation, together with some proposals for specific measures, and a consideration of measuring inconsistency in logic-based instantiations of argument graphs, including a review of some existing proposals and a consideration of how existing logic-based measures of inconsistency can be applied. version:1
arxiv-1708-02845 | Path Planning with Divergence-Based Distance Functions | http://arxiv.org/abs/1708.02845 | id:1708.02845 author:Renjie Chen, Craig Gotsman, Kai Hormann category:cs.RO  published:2017-08-09 summary:Distance functions between points in a domain are sometimes used to automatically plan a gradient-descent path towards a given target point in the domain, avoiding obstacles that may be present. A key requirement from such distance functions is the absence of spurious local minima, which may foil such an approach, and this has led to the common use of harmonic potential functions. Based on the planar Laplace operator, the potential function guarantees the absence of spurious minima, but is well known to be slow to numerically compute and prone to numerical precision issues. To alleviate the first of these problems, we propose a family of novel divergence distances. These are based on f-divergence of the Poisson kernel of the domain. We define the divergence distances and compare them to the harmonic potential function and other related distance functions. Our first result is theoretical: We show that the family of divergence distances are equivalent to the harmonic potential function on simply-connected domains, namely generate paths which are identical to those generated by the potential function. The proof is based on the concept of conformal invariance. Our other results are more practical and relate to two special cases of divergence distances, one based on the Kullback-Leibler divergence and one based on the total variation divergence. We show that using divergence distances instead of the potential function and other distances has a significant computational advantage, as, following a pre-processing stage, they may be computed up to an order of magnitude faster than the others when taking advantage of certain sparsity properties of the Poisson kernel. Furthermore, the computation is "embarrassingly parallel", so may be implemented on a GPU with up to three orders of magnitude speedup. version:1
arxiv-1708-02838 | Decoupled Learning of Environment Characteristics for Safe Exploration | http://arxiv.org/abs/1708.02838 | id:1708.02838 author:Pieter Van Molle, Tim Verbelen, Steven Bohez, Sam Leroux, Pieter Simoens, Bart Dhoedt category:cs.AI  published:2017-08-09 summary:Reinforcement learning is a proven technique for an agent to learn a task. However, when learning a task using reinforcement learning, the agent cannot distinguish the characteristics of the environment from those of the task. This makes it harder to transfer skills between tasks in the same environment. Furthermore, this does not reduce risk when training for a new task. In this paper, we introduce an approach to decouple the environment characteristics from the task-specific ones, allowing an agent to develop a sense of survival. We evaluate our approach in an environment where an agent must learn a sequence of collection tasks, and show that decoupled learning allows for a safer utilization of prior knowledge. version:1
arxiv-1708-02837 | SPLODE: Semi-Probabilistic Point and Line Odometry with Depth Estimation from RGB-D Camera Motion | http://arxiv.org/abs/1708.02837 | id:1708.02837 author:Pedro F. Proença, Yang Gao category:cs.RO cs.CV  published:2017-08-09 summary:Active depth cameras suffer from several limitations, which cause incomplete and noisy depth maps, and may consequently affect the performance of RGB-D Odometry. To address this issue, this paper presents a visual odometry method based on point and line features that leverages both measurements from a depth sensor and depth estimates from camera motion. Depth estimates are generated continuously by a probabilistic depth estimation framework for both types of features to compensate for the lack of depth measurements and inaccurate feature depth associations. The framework models explicitly the uncertainty of triangulating depth from both point and line observations to validate and obtain precise estimates. Furthermore, depth measurements are exploited by propagating them through a depth map registration module and using a frame-to-frame motion estimation method that considers 3D-to-2D and 2D-to-3D reprojection errors, independently. Results on RGB-D sequences captured on large indoor and outdoor scenes, where depth sensor limitations are critical, show that the combination of depth measurements and estimates through our approach is able to overcome the absence and inaccuracy of depth measurements. version:1
arxiv-1708-02825 | Mutual Visibility by Robots with Persistent Memory | http://arxiv.org/abs/1708.02825 | id:1708.02825 author:Subhash Bhagat, Krishnendu Mukhopadhyaya category:cs.DC  published:2017-08-09 summary:This paper addresses the mutual visibility problem for a set of semi-synchronous, opaque robots occupying distinct positions in the Euclidean plane. Since robots are opaque, if three robots lie on a line, the middle robot obstructs the visions of the two other robots. The mutual visibility problem asks the robots to coordinate their movements to form a configuration, within finite time and without collision, in which no three robots are collinear. Robots are endowed with a constant bits of persistent memory. In this work, we consider the FSTATE computational model in which the persistent memory is used by the robots only to remember their previous internal states. Except from this persistent memory, robots are oblivious i.e., they do not carry forward any other information from their previous computational cycles. The paper presents a distributed algorithm to solve the mutual visibility problem for a set of semi-synchronous robots using only 1 bit of persistent memory. The proposed algorithm does not impose any other restriction on the capability of the robots and guarantees collision-free movements for the robots. version:1
arxiv-1708-02544 | Stochastic Optimization with Bandit Sampling | http://arxiv.org/abs/1708.02544 | id:1708.02544 author:Farnood Salehi, L. Elisa Celis, Patrick Thiran category:cs.LG cs.AI math.OC stat.ML  published:2017-08-08 summary:Many stochastic optimization algorithms work by estimating the gradient of the cost function on the fly by sampling datapoints uniformly at random from a training set. However, the estimator might have a large variance, which inadvertently slows down the convergence rate of the algorithms. One way to reduce this variance is to sample the datapoints from a carefully selected non-uniform distribution. In this work, we propose a novel non-uniform sampling approach that uses the multi-armed bandit framework. Theoretically, we show that our algorithm asymptotically approximates the optimal variance within a factor of 3. Empirically, we show that using this datapoint-selection technique results in a significant reduction in the convergence time and variance of several stochastic optimization algorithms such as SGD, SVRG and SAGA. This approach for sampling datapoints is general, and can be used in conjunction with any algorithm that uses an unbiased gradient estimation -- we expect it to have broad applicability beyond the specific examples explored in this work. version:2
arxiv-1708-02816 | A Passivity-based Concurrent Whole-Body Control (cWBC) of Persistently Interacting Human-Exoskeleton Systems | http://arxiv.org/abs/1708.02816 | id:1708.02816 author:Federico L. Moro, Niccolò Iannacci, Giovanni Legnani, Lorenzo Molinari Tosatti category:cs.RO  published:2017-08-09 summary:This paper presents a concurrent whole-body control (cWBC) for human-exoskeleton systems that are tightly coupled at a Cartesian level (e.g., feet, hands, torso). The exoskeleton generates joint torques that i) cancel the effects of gravity on the coupled system, ii) perform a primary task (e.g., maintaining the balance of the system), and iii) exploit the kinematic redundancy of the system to amplify the forces exerted by the human operator. The coupled dynamic system is demonstrated to be passive, as its overall energy always goes dissipated until a minimum is reached. The proposed method is designed specifically to control exoskeletons for power augmentation worn by healthy operators in applications such as manufacturing, as it allows to increase the worker's capabilities, therefore reducing the risk of injuries. version:1
arxiv-1708-03259 | Preference fusion and Condorcet's Paradox under uncertainty | http://arxiv.org/abs/1708.03259 | id:1708.03259 author:Yiru Zhang, Tassadit Bouadi, Arnaud Martin category:cs.AI cs.GT  published:2017-08-09 summary:Facing an unknown situation, a person may not be able to firmly elicit his/her preferences over different alternatives, so he/she tends to express uncertain preferences. Given a community of different persons expressing their preferences over certain alternatives under uncertainty, to get a collective representative opinion of the whole community, a preference fusion process is required. The aim of this work is to propose a preference fusion method that copes with uncertainty and escape from the Condorcet paradox. To model preferences under uncertainty, we propose to develop a model of preferences based on belief function theory that accurately describes and captures the uncertainty associated with individual or collective preferences. This work improves and extends the previous results. This work improves and extends the contribution presented in a previous work. The benefits of our contribution are twofold. On the one hand, we propose a qualitative and expressive preference modeling strategy based on belief-function theory which scales better with the number of sources. On the other hand, we propose an incremental distance-based algorithm (using Jousselme distance) for the construction of the collective preference order to avoid the Condorcet Paradox. version:1
arxiv-1708-04670 | DeepFaceLIFT: Interpretable Personalized Models for Automatic Estimation of Self-Reported Pain | http://arxiv.org/abs/1708.04670 | id:1708.04670 author:Dianbo Liu, Fengjiao Peng, Andrew Shea, Ognjen, Rudovic, Rosalind Picard category:cs.CV cs.AI cs.LG  published:2017-08-09 summary:Previous research on automatic pain estimation from facial expressions has focused primarily on "one-size-fits-all" metrics (such as PSPI). In this work, we focus on directly estimating each individual's self-reported visual-analog scale (VAS) pain metric, as this is considered the gold standard for pain measurement. The VAS pain score is highly subjective and context-dependent, and its range can vary significantly among different persons. To tackle these issues, we propose a novel two-stage personalized model, named DeepFaceLIFT, for automatic estimation of VAS. This model is based on (1) Neural Network and (2) Gaussian process regression models, and is used to personalize the estimation of self-reported pain via a set of hand-crafted personal features and multi-task learning. We show on the benchmark dataset for pain analysis (The UNBC-McMaster Shoulder Pain Expression Archive) that the proposed personalized model largely outperforms the traditional, unpersonalized models: the intra-class correlation improves from a baseline performance of 19\% to a personalized performance of 35\% while also providing confidence in the model\textquotesingle s estimates -- in contrast to existing models for the target task. Additionally, DeepFaceLIFT automatically discovers the pain-relevant facial regions for each person, allowing for an easy interpretation of the pain-related facial cues. version:1
arxiv-1708-07074 | Neighborhood-Based Label Propagation in Large Protein Graphs | http://arxiv.org/abs/1708.07074 | id:1708.07074 author:Sabeur Aridhi, Seyed Ziaeddin Alborzi, Malika Smaïl-Tabbone, Marie-Dominique Devignes, David Ritchie category:cs.DC cs.LG  published:2017-08-09 summary:Understanding protein function is one of the keys to understanding life at the molecular level. It is also important in several scenarios including human disease and drug discovery. In this age of rapid and affordable biological sequencing, the number of sequences accumulating in databases is rising with an increasing rate. This presents many challenges for biologists and computer scientists alike. In order to make sense of this huge quantity of data, these sequences should be annotated with functional properties. UniProtKB consists of two components: i) the UniProtKB/Swiss-Prot database containing protein sequences with reliable information manually reviewed by expert bio-curators and ii) the UniProtKB/TrEMBL database that is used for storing and processing the unknown sequences. Hence, for all proteins we have available the sequence along with few more information such as the taxon and some structural domains. Pairwise similarity can be defined and computed on proteins based on such attributes. Other important attributes, while present for proteins in Swiss-Prot, are often missing for proteins in TrEMBL, such as their function and cellular localization. The enormous number of protein sequences now in TrEMBL calls for rapid procedures to annotate them automatically. In this work, we present DistNBLP, a novel Distributed Neighborhood-Based Label Propagation approach for large-scale annotation of proteins. To do this, the functional annotations of reviewed proteins are used to predict those of non-reviewed proteins using label propagation on a graph representation of the protein database. DistNBLP is built on top of the "akka" toolkit for building resilient distributed message-driven applications. version:1
arxiv-1708-00630 | ProjectionNet: Learning Efficient On-Device Deep Networks Using Neural Projections | http://arxiv.org/abs/1708.00630 | id:1708.00630 author:Sujith Ravi category:cs.LG cs.AI cs.NE  published:2017-08-02 summary:Deep neural networks have become ubiquitous for applications related to visual recognition and language understanding tasks. However, it is often prohibitive to use typical neural networks on devices like mobile phones or smart watches since the model sizes are huge and cannot fit in the limited memory available on such devices. While these devices could make use of machine learning models running on high-performance data centers with CPUs or GPUs, this is not feasible for many applications because data can be privacy sensitive and inference needs to be performed directly "on" device. We introduce a new architecture for training compact neural networks using a joint optimization framework. At its core lies a novel objective that jointly trains using two different types of networks--a full trainer neural network (using existing architectures like Feed-forward NNs or LSTM RNNs) combined with a simpler "projection" network that leverages random projections to transform inputs or intermediate representations into bits. The simpler network encodes lightweight and efficient-to-compute operations in bit space with a low memory footprint. The two networks are trained jointly using backpropagation, where the projection network learns from the full network similar to apprenticeship learning. Once trained, the smaller network can be used directly for inference at low memory and computation cost. We demonstrate the effectiveness of the new approach at significantly shrinking the memory requirements of different types of neural networks while preserving good accuracy on visual recognition and text classification tasks. We also study the question "how many neural bits are required to solve a given task?" using the new framework and show empirical results contrasting model predictive capacity (in bits) versus accuracy on several datasets. version:2
arxiv-1708-02940 | Role of Secondary Attributes to Boost the Prediction Accuracy of Students Employability Via Data Mining | http://arxiv.org/abs/1708.02940 | id:1708.02940 author:Pooja Thakar, Anil Mehta, Manisha category:cs.CY cs.AI  published:2017-08-09 summary:Data Mining is best-known for its analytical and prediction capabilities. It is used in several areas such as fraud detection, predicting client behavior, money market behavior, bankruptcy prediction. It can also help in establishing an educational ecosystem, which discovers useful knowledge, and assist educators to take proactive decisions to boost student performance and employability. This paper presents an empirical study that compares varied classification algorithms on two datasets of MCA (Masters in Computer Applications) students collected from various affiliated colleges of a reputed state university in India. One dataset includes only primary attributes, whereas other dataset is feeded with secondary psychometric attributes in it. The results showcase that solely primary academic attributes do not lead to smart prediction accuracy of students employability, once they square measure within the initial year of their education. The study analyzes and stresses the role of secondary psychometric attributes for better prediction accuracy and analysis of students performance. Timely prediction and analysis of students performance can help Management, Teachers and Students to work on their gray areas for better results and employment opportunities. version:1
arxiv-1708-02937 | Enabling Massive Deep Neural Networks with the GraphBLAS | http://arxiv.org/abs/1708.02937 | id:1708.02937 author:Jeremy Kepner, Manoj Kumar, José Moreira, Pratap Pattnaik, Mauricio Serrano, Henry Tufo category:cs.DC cs.LG  published:2017-08-09 summary:Deep Neural Networks (DNNs) have emerged as a core tool for machine learning. The computations performed during DNN training and inference are dominated by operations on the weight matrices describing the DNN. As DNNs incorporate more stages and more nodes per stage, these weight matrices may be required to be sparse because of memory limitations. The GraphBLAS.org math library standard was developed to provide high performance manipulation of sparse weight matrices and input/output vectors. For sufficiently sparse matrices, a sparse matrix library requires significantly less memory than the corresponding dense matrix implementation. This paper provides a brief description of the mathematics underlying the GraphBLAS. In addition, the equations of a typical DNN are rewritten in a form designed to use the GraphBLAS. An implementation of the DNN is given using a preliminary GraphBLAS C library. The performance of the GraphBLAS implementation is measured relative to a standard dense linear algebra library implementation. For various sizes of DNN weight matrices, it is shown that the GraphBLAS sparse implementation outperforms a BLAS dense implementation as the weight matrix becomes sparser. version:1
arxiv-1708-02645 | Embracing a new era of highly efficient and productive quantum Monte Carlo simulations | http://arxiv.org/abs/1708.02645 | id:1708.02645 author:Amrita Mathuriya, Ye Luo, Raymond C. Clay III, Anouar Benali, Luke Shulenburger, Jeongnim Kim category:cs.DC  published:2017-08-08 summary:QMCPACK has enabled cutting-edge materials research on supercomputers for over a decade. It scales nearly ideally but has low single-node efficiency due to the physics-based abstractions using array-of-structures objects, causing inefficient vectorization. We present a systematic approach to transform QMCPACK to better exploit the new hardware features of modern CPUs in portable and maintainable ways. We develop miniapps for fast prototyping and optimizations. We implement new containers in structure-of-arrays data layout to facilitate vectorizations by the compilers. Further speedup and smaller memory-footprints are obtained by computing data on the fly with the vectorized routines and expanding single-precision use. All these are seamlessly incorporated in production QMCPACK. We demonstrate upto 4.5x speedups on recent Intel processors and IBM Blue Gene/Q for representative workloads. Energy consumption is reduced significantly commensurate to the speedup factor. Memory-footprints are reduced by up-to 3.8x, opening the possibility to solve much larger problems of future. version:1
arxiv-1708-02638 | Distributed rank-1 dictionary learning: Towards fast and scalable solutions for fMRI big data analytics | http://arxiv.org/abs/1708.02638 | id:1708.02638 author:Milad Makkie, Xiang Li, Binbin Lin, Jieping Ye, Mojtaba Sedigh Fazli, Tianming Liu, Shannon Quinn category:cs.DS cs.DC q-bio.NC  published:2017-08-08 summary:The use of functional brain imaging for research and diagnosis has benefitted greatly from the recent advancements in neuroimaging technologies, as well as the explosive growth in size and availability of fMRI data. While it has been shown in literature that using multiple and large scale fMRI datasets can improve reproducibility and lead to new discoveries, the computational and informatics systems supporting the analysis and visualization of such fMRI big data are extremely limited and largely under-discussed. We propose to address these shortcomings in this work, based on previous success in using dictionary learning method for functional network decomposition studies on fMRI data. We presented a distributed dictionary learning framework based on rank-1 matrix decomposition with sparseness constraint (D-r1DL framework). The framework was implemented using the Spark distributed computing engine and deployed on three different processing units: an in-house server, in-house high performance clusters, and the Amazon Elastic Compute Cloud (EC2) service. The whole analysis pipeline was integrated with our neuroinformatics system for data management, user input/output, and real-time visualization. Performance and accuracy of D-r1DL on both individual and group-wise fMRI Human Connectome Project (HCP) dataset shows that the proposed framework is highly scalable. The resulting group-wise functional network decompositions are highly accurate, and the fast processing time confirm this claim. In addition, D-r1DL can provide real-time user feedback and results visualization which are vital for large-scale data analysis. version:1
arxiv-1708-02637 | TensorFlow Estimators: Managing Simplicity vs. Flexibility in High-Level Machine Learning Frameworks | http://arxiv.org/abs/1708.02637 | id:1708.02637 author:Heng-Tze Cheng, Zakaria Haque, Lichan Hong, Mustafa Ispir, Clemens Mewald, Illia Polosukhin, Georgios Roumpos, D Sculley, Jamie Smith, David Soergel, Yuan Tang, Philipp Tucker, Martin Wicke, Cassandra Xia, Jianwei Xie category:cs.DC cs.LG  published:2017-08-08 summary:We present a framework for specifying, training, evaluating, and deploying machine learning models. Our focus is on simplifying cutting edge machine learning for practitioners in order to bring such technologies into production. Recognizing the fast evolution of the field of deep learning, we make no attempt to capture the design space of all possible model architectures in a domain- specific language (DSL) or similar configuration language. We allow users to write code to define their models, but provide abstractions that guide develop- ers to write models in ways conducive to productionization. We also provide a unifying Estimator interface, making it possible to write downstream infrastructure (e.g. distributed training, hyperparameter tuning) independent of the model implementation. We balance the competing demands for flexibility and simplicity by offering APIs at different levels of abstraction, making common model architectures available out of the box, while providing a library of utilities designed to speed up experimentation with model architectures. To make out of the box models flexible and usable across a wide range of problems, these canned Estimators are parameterized not only over traditional hyperparameters, but also using feature columns, a declarative specification describing how to interpret input data. We discuss our experience in using this framework in re- search and production environments, and show the impact on code health, maintainability, and development speed. version:1
arxiv-1708-01285 | Proof of Work Without All the Work | http://arxiv.org/abs/1708.01285 | id:1708.01285 author:Diksha Gupta, Jared Saia, Maxwell Young category:cs.DC cs.CR  published:2017-08-03 summary:Proof-of-work (PoW) is a popular algorithmic tool used to enhance network security by imposing a computational cost on participating devices. Unfortunately, traditional PoW schemes require that correct devices work perpetually in order to remain vigilant against possible malicious behavior. In other words, computational costs are unbounded regardless of whether the network is under attack. This shortcoming is highlighted by recent studies showing that PoW is highly inefficient with respect to operating cost and ecological footprint. We address this issue by designing a general PoW scheme for securing open distributed systems, whereby the cost to devices grows slowly as a function of the cost incurred by an attacker. Consequently, if the network is attacked, our scheme guarantees security, with algorithmic costs that are commensurate with the cost of the attacker. Conversely, in the absence of attack, algorithmic costs are small. Our results hold in a dynamic system where participants join and depart over time. We demonstrate how our PoW scheme can be leveraged to address important security problems in distributed computing including: Sybil attacks, Byzantine consensus, and Committee election. version:2
arxiv-1708-02596 | Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning | http://arxiv.org/abs/1708.02596 | id:1708.02596 author:Anusha Nagabandi, Gregory Kahn, Ronald S. Fearing, Sergey Levine category:cs.LG cs.AI cs.RO  published:2017-08-08 summary:Model-free deep reinforcement learning methods have successfully learned complex behavioral strategies for a wide range of tasks, but typically require many samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that medium-sized neural network models can in fact be combined with model predictive control to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits to accomplish various complex locomotion tasks. We also propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We perform this pre-initialization by using rollouts from the trained model-based controller as supervision to pre-train a policy, and then fine-tune the policy using a model-free method. We empirically demonstrate that this resulting hybrid algorithm can drastically accelerate model-free learning and outperform purely model-free learners on several MuJoCo locomotion benchmark tasks, achieving sample efficiency gains over a purely model-free learner of 330x on swimmer, 26x on hopper, 4x on half-cheetah, and 3x on ant. Videos can be found at https://sites.google.com/view/mbmf version:1
arxiv-1708-02579 | Snowflake: A Model Agnostic Accelerator for Deep Convolutional Neural Networks | http://arxiv.org/abs/1708.02579 | id:1708.02579 author:Vinayak Gokhale, Aliasger Zaidy, Andre Xian Ming Chang, Eugenio Culurciello category:cs.AR  published:2017-08-08 summary:Deep convolutional neural networks (CNNs) are the deep learning model of choice for performing object detection, classification, semantic segmentation and natural language processing tasks. CNNs require billions of operations to process a frame. This computational complexity, combined with the inherent parallelism of the convolution operation make CNNs an excellent target for custom accelerators. However, when optimizing for different CNN hierarchies and data access patterns, it is difficult for custom accelerators to achieve close to 100% computational efficiency. In this work, we present Snowflake, a scalable and efficient accelerator that is agnostic to CNN workloads, and was designed to always perform at near-peak hardware utilization. Snowflake is able to achieve a computational efficiency of over 91% on modern CNN models. Snowflake, implemented on a Xilinx Zynq XC7Z045 SoC is capable of achieving a peak throughput of 128G-ops/s and a measured throughput of 100 frames per second and 120 G-ops/s on the AlexNet CNN model, 36 frames per second and 116G- ops/s on the GoogLeNet CNN model and 17 frames per second and 122 G-ops/s on the ResNet-50 CNN model. To the best of our knowledge, Snowflake is the only implemented system capable of achieving over 91% efficiency on modern CNNs and the only implemented system with GoogLeNet and ResNet as part of the benchmark suite. version:1
arxiv-1708-02553 | Robust Computer Algebra, Theorem Proving, and Oracle AI | http://arxiv.org/abs/1708.02553 | id:1708.02553 author:Gopal P. Sarma, Nick J. Hay category:cs.AI cs.SC  published:2017-08-08 summary:In the context of superintelligent AI systems, the term "oracle" has two meanings. One refers to modular systems queried for domain-specific tasks. Another usage, referring to a class of systems which may be useful for addressing the value alignment and AI control problems, is a superintelligent AI system that only answers questions. The aim of this manuscript is to survey contemporary research problems related to oracles which align with long-term research goals of AI safety. We examine existing question answering systems and argue that their high degree of architectural heterogeneity makes them poor candidates for rigorous analysis as oracles. On the other hand, we identify computer algebra systems (CASs) as being primitive examples of domain-specific oracles for mathematics and argue that efforts to integrate computer algebra systems with theorem provers, systems which have largely been developed independent of one another, provide a concrete set of problems related to the notion of provable safety that has emerged in the AI safety community. We review approaches to interfacing CASs with theorem provers, describe well-defined architectural deficiencies that have been identified with CASs, and suggest possible lines of research and practical software projects for scientists interested in AI safety. version:1
arxiv-1708-02551 | Semantic Instance Segmentation with a Discriminative Loss Function | http://arxiv.org/abs/1708.02551 | id:1708.02551 author:Bert De Brabandere, Davy Neven, Luc Van Gool category:cs.CV cs.RO  published:2017-08-08 summary:Semantic instance segmentation remains a challenging task. In this work we propose to tackle the problem with a discriminative loss function, operating at the pixel level, that encourages a convolutional network to produce a representation of the image that can easily be clustered into instances with a simple post-processing step. The loss function encourages the network to map each pixel to a point in feature space so that pixels belonging to the same instance lie close together while different instances are separated by a wide margin. Our approach of combining an off-the-shelf network with a principled loss function inspired by a metric learning objective is conceptually simple and distinct from recent efforts in instance segmentation. In contrast to previous works, our method does not rely on object proposals or recurrent mechanisms. A key contribution of our work is to demonstrate that such a simple setup without bells and whistles is effective and can perform on par with more complex methods. Moreover, we show that it does not suffer from some of the limitations of the popular detect-and-segment approaches. We achieve competitive performance on the Cityscapes and CVPPP leaf segmentation benchmarks. version:1
arxiv-1708-02550 | Fast Scene Understanding for Autonomous Driving | http://arxiv.org/abs/1708.02550 | id:1708.02550 author:Davy Neven, Bert De Brabandere, Stamatios Georgoulis, Marc Proesmans, Luc Van Gool category:cs.CV cs.RO  published:2017-08-08 summary:Most approaches for instance-aware semantic labeling traditionally focus on accuracy. Other aspects like runtime and memory footprint are arguably as important for real-time applications such as autonomous driving. Motivated by this observation and inspired by recent works that tackle multiple tasks with a single integrated architecture, in this paper we present a real-time efficient implementation based on ENet that solves three autonomous driving related tasks at once: semantic scene segmentation, instance segmentation and monocular depth estimation. Our approach builds upon a branched ENet architecture with a shared encoder but different decoder branches for each of the three tasks. The presented method can run at 21 fps at a resolution of 1024x512 on the Cityscapes dataset without sacrificing accuracy compared to running each task separately. version:1
arxiv-1708-02543 | Impossibility of $n-1$-strong-equllibrium for Distributed Consensus with Rational Agents | http://arxiv.org/abs/1708.02543 | id:1708.02543 author:Amit Jacob Fanani, Itay Harel category:cs.DC cs.GT  published:2017-08-08 summary:An algorithm for $n-1$-strong-equillibrium for distributed consensus in a ring with rational agents was proposed by Afek et al. (2014). A proof of impossibility of $n-1$-strong-equillibrium for distributed consensus in every topology with rational agents, when $n$ is even, is presented. Furthermore, we show that the algorithm proposed by Afek et al. is the only algorithm which can solve the problem when $n$ is odd. Finally, we prove that the proposed algorithm provides a $n-2$-strong-equillibrium in a synchronous ring when $n$ is even. version:1
arxiv-1708-02536 | A Framework for Inferring Causality from Multi-Relational Observational Data using Conditional Independence | http://arxiv.org/abs/1708.02536 | id:1708.02536 author:Sudeepa Roy, Babak Salimi category:cs.DB cs.AI  published:2017-08-08 summary:The study of causality or causal inference - how much a given treatment causally affects a given outcome in a population - goes way beyond correlation or association analysis of variables, and is critical in making sound data driven decisions and policies in a multitude of applications. The gold standard in causal inference is performing "controlled experiments", which often is not possible due to logistical or ethical reasons. As an alternative, inferring causality on "observational data" based on the "Neyman-Rubin potential outcome model" has been extensively used in statistics, economics, and social sciences over several decades. In this paper, we present a formal framework for sound causal analysis on observational datasets that are given as multiple relations and where the population under study is obtained by joining these base relations. We study a crucial condition for inferring causality from observational data, called the "strong ignorability assumption" (the treatment and outcome variables should be independent in the joined relation given the observed covariates), using known conditional independences that hold in the base relations. We also discuss how the structure of the conditional independences in base relations given as graphical models help infer new conditional independences in the joined relation. The proposed framework combines concepts from databases, statistics, and graphical models, and aims to initiate new research directions spanning these fields to facilitate powerful data-driven decisions in today's big data world. version:1
arxiv-1708-02531 | Deep Binaries: Encoding Semantic-Rich Cues for Efficient Textual-Visual Cross Retrieval | http://arxiv.org/abs/1708.02531 | id:1708.02531 author:Yuming Shen, Li Liu, Ling Shao, Jingkuan Song category:cs.CV cs.AI  published:2017-08-08 summary:Cross-modal hashing is usually regarded as an effective technique for large-scale textual-visual cross retrieval, where data from different modalities are mapped into a shared Hamming space for matching. Most of the traditional textual-visual binary encoding methods only consider holistic image representations and fail to model descriptive sentences. This renders existing methods inappropriate to handle the rich semantics of informative cross-modal data for quality textual-visual search tasks. To address the problem of hashing cross-modal data with semantic-rich cues, in this paper, a novel integrated deep architecture is developed to effectively encode the detailed semantics of informative images and long descriptive sentences, named as Textual-Visual Deep Binaries (TVDB). In particular, region-based convolutional networks with long short-term memory units are introduced to fully explore image regional details while semantic cues of sentences are modeled by a text convolutional network. Additionally, we propose a stochastic batch-wise training routine, where high-quality binary codes and deep encoding functions are efficiently optimized in an alternating manner. Experiments are conducted on three multimedia datasets, i.e. Microsoft COCO, IAPR TC-12, and INRIA Web Queries, where the proposed TVDB model significantly outperforms state-of-the-art binary coding methods in the task of cross-modal retrieval. version:1
arxiv-1708-04325 | Review Paper: Inertial Measurement | http://arxiv.org/abs/1708.04325 | id:1708.04325 author:William T. Conlin category:cs.RO  published:2017-08-08 summary:Applications of inertial measurement units are extremely diverse, and are expected to see a further increase in number due to current trends in robotics as well as recent advances in Micro Electromechanical sensors (MEMS). The traditional method of inertial measurement has depended on costly, power-intensive, error-prone Inertial Measurement Units (IMUs) that represent a single point of failure. Promising areas of current research include methods for combining multiple redundant sensors, which collectively provide more accurate and more dependable estimates of state, and wholly new IMU layouts that seek to reduce error. New types include: gyro-free, timing, wireless, distributed redundant IMUs, and IMUs that incorporate MEMS components for miniaturization in general. This review paper highlights these new research directions and lays out the design and experimental implementation of a complementary filter for inertial measurement. version:1
arxiv-1708-02419 | Towards a Concurrent and Distributed Route Selection for Payment Channel Networks | http://arxiv.org/abs/1708.02419 | id:1708.02419 author:Elias Rohrer, Jann-Frederik Laß, Florian Tschorsch category:cs.NI cs.CR cs.DC  published:2017-08-08 summary:Payment channel networks use off-chain transactions to provide virtually arbitrary transaction rates. In this paper, we provide a new perspective on payment channels and consider them as a flow network. We propose an extended push-relabel algorithm to find payment flows in a payment channel network. Our algorithm enables a distributed and concurrent execution without violating capacity constraints. To this end, we introduce the concept of capacity locking. We prove that flows are valid and present first results. version:1
arxiv-1201-3667 | A Logic of Interactive Proofs (Formal Theory of Knowledge Transfer) | http://arxiv.org/abs/1201.3667 | id:1201.3667 author:Simon Kramer category:cs.LO cs.CR cs.DC cs.MA math.LO  published:2012-01-17 summary:We propose a logic of interactive proofs as a framework for an intuitionistic foundation for interactive computation, which we construct via an interactive analog of the Goedel-McKinsey-Tarski-Artemov definition of Intuitionistic Logic as embedded into a classical modal logic of proofs, and of the Curry-Howard isomorphism between intuitionistic proofs and typed programs. Our interactive proofs effectuate a persistent epistemic impact in their intended communities of peer reviewers that consists in the induction of the (propositional) knowledge of their proof goal by means of the (individual) knowledge of the proof with the interpreting reviewer. That is, interactive proofs effectuate a transfer of propositional knowledge (knowable facts) via the transmission of certain individual knowledge (knowable proofs) in multi-agent distributed systems. In other words, we as a community can have the formal common knowledge that a proof is that which if known to one of our peer members would induce the knowledge of its proof goal with that member. Last but not least, we prove non-trivial interactive computation as definable within our simply typed interactive Combinatory Logic to be nonetheless equipotent to non-interactive computation as defined by simply typed Combinatory Logic. version:6
arxiv-1708-02392 | Learning Human-Robot Collaboration Insights through the Integration of Muscle Activity in Interaction Motion Models | http://arxiv.org/abs/1708.02392 | id:1708.02392 author:Longxin Chen, Juan Rojas, Shuangda Duan, Yisheng Guan category:cs.RO  published:2017-08-08 summary:Recent progress in human-robot collaboration makes fast and fluid interactions possible, even when human observations are partial and occluded. Methods like Interaction Probabilistic Movement Primitives (ProMP) model human trajectories through motion capture systems. However, such representation does not properly model tasks where similar motions handle different objects. Under current approaches, a robot would not adapt its pose and dynamics for proper handling. We integrate the use of Electromyography (EMG) into the Interaction ProMP framework and utilize muscular signals to augment the human observation representation. The contribution of our paper is increased task discernment when trajectories are similar but tools are different and require the robot to adjust its pose for proper handling. Interaction ProMPs are used with an augmented vector that integrates muscle activity. Augmented time-normalized trajectories are used in training to learn correlation parameters and robot motions are predicted by finding the best weight combination and temporal scaling for a task. Collaborative single task scenarios with similar motions but different objects were used and compared. For one experiment only joint angles were recorded, for the other EMG signals were additionally integrated. Task recognition was computed for both tasks. Observation state vectors with augmented EMG signals were able to completely identify differences across tasks, while the baseline method failed every time. Integrating EMG signals into collaborative tasks significantly increases the ability of the system to recognize nuances in the tasks that are otherwise imperceptible, up to 74.6% in our studies. Furthermore, the integration of EMG signals for collaboration also opens the door to a wide class of human-robot physical interactions based on haptic communication that has been largely unexploited in the field. version:1
arxiv-1708-02383 | Learning how to Active Learn: A Deep Reinforcement Learning Approach | http://arxiv.org/abs/1708.02383 | id:1708.02383 author:Meng Fang, Yuan Li, Trevor Cohn category:cs.CL cs.AI cs.LG  published:2017-08-08 summary:Active learning aims to select a small subset of data for annotation such that a classifier learned on the data is highly accurate. This is usually done using heuristic selection methods, however the effectiveness of such methods is limited and moreover, the performance of heuristics varies between datasets. To address these shortcomings, we introduce a novel formulation by reframing the active learning as a reinforcement learning problem and explicitly learning a data selection policy, where the policy takes the role of the active learning heuristic. Importantly, our method allows the selection policy learned using simulation on one language to be transferred to other languages. We demonstrate our method using cross-lingual named entity recognition, observing uniform improvements over traditional active learning. version:1
arxiv-1708-02382 | Visual-inertial self-calibration on informative motion segments | http://arxiv.org/abs/1708.02382 | id:1708.02382 author:Thomas Schneider, Mingyang Li, Michael Burri, Juan Nieto, Roland Siegwart, Igor Gilitschenski category:cs.RO  published:2017-08-08 summary:Environmental conditions and external effects, such as shocks, have a significant impact on the calibration parameters of visual-inertial sensor systems. Thus long-term operation of these systems cannot fully rely on factory calibration. Since the observability of certain parameters is highly dependent on the motion of the device, using short data segments at device initialization may yield poor results. When such systems are additionally subject to energy constraints, it is also infeasible to use full-batch approaches on a big dataset and careful selection of the data is of high importance. In this paper, we present a novel approach for resource efficient self-calibration of visual-inertial sensor systems. This is achieved by casting the calibration as a segment-based optimization problem that can be run on a small subset of informative segments. Consequently, the computational burden is limited as only a predefined number of segments is used. We also propose an efficient information-theoretic selection to identify such informative motion segments. In evaluations on a challenging dataset, we show our approach to significantly outperform state-of-the-art in terms of computational burden while maintaining a comparable accuracy. version:1
arxiv-1709-01812 | Stocator: A High Performance Object Store Connector for Spark | http://arxiv.org/abs/1709.01812 | id:1709.01812 author:Gil Vernik, Michael Factor, Elliot K. Kolodner, Pietro Michiardi, Effi Ofer, Francesco Pace category:cs.DC  published:2017-08-08 summary:We present Stocator, a high performance object store connector for Apache Spark, that takes advantage of object store semantics. Previous connectors have assumed file system semantics, in particular, achieving fault tolerance and allowing speculative execution by creating temporary files to avoid interference between worker threads executing the same task and then renaming these files. Rename is not a native object store operation; not only is it not atomic, but it is implemented using a costly copy operation and a delete. Instead our connector leverages the inherent atomicity of object creation, and by avoiding the rename paradigm it greatly decreases the number of operations on the object store as well as enabling a much simpler approach to dealing with the eventually consistent semantics typical of object stores. We have implemented Stocator and shared it in open source. Performance testing shows that it is as much as 18 times faster for write intensive workloads and performs as much as 30 times fewer operations on the object store than the legacy Hadoop connectors, reducing costs both for the client and the object storage service provider. version:1
arxiv-1708-02363 | Beyond the technical challenges for deploying Machine Learning solutions in a software company | http://arxiv.org/abs/1708.02363 | id:1708.02363 author:Ilias Flaounas category:cs.HC cs.AI cs.SE stat.ML  published:2017-08-08 summary:Recently software development companies started to embrace Machine Learning (ML) techniques for introducing a series of advanced functionality in their products such as personalisation of the user experience, improved search, content recommendation and automation. The technical challenges for tackling these problems are heavily researched in literature. A less studied area is a pragmatic approach to the role of humans in a complex modern industrial environment where ML based systems are developed. Key stakeholders affect the system from inception and up to operation and maintenance. Product managers want to embed "smart" experiences for their users and drive the decisions on what should be built next; software engineers are challenged to build or utilise ML software tools that require skills that are well outside of their comfort zone; legal and risk departments may influence design choices and data access; operations teams are requested to maintain ML systems which are non-stationary in their nature and change behaviour over time; and finally ML practitioners should communicate with all these stakeholders to successfully build a reliable system. This paper discusses some of the challenges we faced in Atlassian as we started investing more in the ML space. version:1
arxiv-1708-02361 | Verification & Validation of Agent Based Simulations using the VOMAS (Virtual Overlay Multi-agent System) approach | http://arxiv.org/abs/1708.02361 | id:1708.02361 author:Muaz A. Niazi, Amir Hussain, Mario Kolberg category:cs.MA cs.AI cs.SE nlin.AO nlin.CG  published:2017-08-08 summary:Agent Based Models are very popular in a number of different areas. For example, they have been used in a range of domains ranging from modeling of tumor growth, immune systems, molecules to models of social networks, crowds and computer and mobile self-organizing networks. One reason for their success is their intuitiveness and similarity to human cognition. However, with this power of abstraction, in spite of being easily applicable to such a wide number of domains, it is hard to validate agent-based models. In addition, building valid and credible simulations is not just a challenging task but also a crucial exercise to ensure that what we are modeling is, at some level of abstraction, a model of our conceptual system; the system that we have in mind. In this paper, we address this important area of validation of agent based models by presenting a novel technique which has broad applicability and can be applied to all kinds of agent-based models. We present a framework, where a virtual overlay multi-agent system can be used to validate simulation models. In addition, since agent-based models have been typically growing, in parallel, in multiple domains, to cater for all of these, we present a new single validation technique applicable to all agent based models. Our technique, which allows for the validation of agent based simulations uses VOMAS: a Virtual Overlay Multi-agent System. This overlay multi-agent system can comprise various types of agents, which form an overlay on top of the agent based simulation model that needs to be validated. Other than being able to watch and log, each of these agents contains clearly defined constraints, which, if violated, can be logged in real time. To demonstrate its effectiveness, we show its broad applicability in a wide variety of simulation models ranging from social sciences to computer networks in spatial and non-spatial conceptual models. version:1
arxiv-1708-02357 | Towards A Novel Unified Framework for Developing Formal, Network and Validated Agent-Based Simulation Models of Complex Adaptive Systems | http://arxiv.org/abs/1708.02357 | id:1708.02357 author:Muaz A. Niazi category:cs.MA cs.AI cs.NI cs.SI nlin.AO  published:2017-08-08 summary:Literature on the modeling and simulation of complex adaptive systems (cas) has primarily advanced vertically in different scientific domains with scientists developing a variety of domain-specific approaches and applications. However, while cas researchers are inher-ently interested in an interdisciplinary comparison of models, to the best of our knowledge, there is currently no single unified framework for facilitating the development, comparison, communication and validation of models across different scientific domains. In this thesis, we propose first steps towards such a unified framework using a combination of agent-based and complex network-based modeling approaches and guidelines formulated in the form of a set of four levels of usage, which allow multidisciplinary researchers to adopt a suitable framework level on the basis of available data types, their research study objectives and expected outcomes, thus allowing them to better plan and conduct their respective re-search case studies. version:1
arxiv-1708-02354 | 2D SLAM Quality Evaluation Methods | http://arxiv.org/abs/1708.02354 | id:1708.02354 author:Anton Filatov, Artyom Filatov, Kirill Krinkin, Baian Chen, Diana Molodan category:cs.RO  published:2017-08-08 summary:SLAM (Simultaneous Localization and mapping) is one of the most challenging problems for mobile platforms and there is a huge amount of modern SLAM algorithms. The choice of the algorithm that might be used in every particular problem requires prior knowledge about advantages and disadvantages of each algorithm. This paper presents the approach for comparison of SLAM algorithms that allows to find the most accurate one. The accent of research is made on 2D SLAM algorithms and the focus of analysis is 2D map that is built after algorithm performance. Three metrics for evaluation of maps are presented in this paper version:1
arxiv-1708-02330 | What Makes a Place? Building Bespoke Place Dependent Object Detectors for Robotics | http://arxiv.org/abs/1708.02330 | id:1708.02330 author:Jeffrey Hawke, Alex Bewley, Ingmar Posner category:cs.RO cs.CV  published:2017-08-07 summary:This paper is about enabling robots to improve their perceptual performance through repeated use in their operating environment, creating local expert detectors fitted to the places through which a robot moves. We leverage the concept of 'experiences' in visual perception for robotics, accounting for bias in the data a robot sees by fitting object detector models to a particular place. The key question we seek to answer in this paper is simply: how do we define a place? We build bespoke pedestrian detector models for autonomous driving, highlighting the necessary trade off between generalisation and model capacity as we vary the extent of the place we fit to. We demonstrate a sizeable performance gain over a current state-of-the-art detector when using computationally lightweight bespoke place-fitted detector models. version:1
arxiv-1708-02314 | Multibiometric Secure System Based on Deep Learning | http://arxiv.org/abs/1708.02314 | id:1708.02314 author:Veeru Talreja, Matthew C. Valenti, Nasser M. Nasrabadi category:cs.AI cs.CV cs.IT math.IT  published:2017-08-07 summary:In this paper, we propose a secure multibiometric system that uses deep neural networks and error-correction coding. We present a feature-level fusion framework to generate a secure multibiometric template from each user's multiple biometrics. Two fusion architectures, fully connected architecture and bilinear architecture, are implemented to develop a robust multibiometric shared representation. The shared representation is used to generate a cancelable biometric template that involves the selection of a different set of reliable and discriminative features for each user. This cancelable template is a binary vector and is passed through an appropriate error-correcting decoder to find a closest codeword and this codeword is hashed to generate the final secure template. The efficacy of the proposed approach is shown using a multimodal database where we achieve state-of-the-art matching performance, along with cancelability and security. version:1
arxiv-1708-02313 | GPLAC: Generalizing Vision-Based Robotic Skills using Weakly Labeled Images | http://arxiv.org/abs/1708.02313 | id:1708.02313 author:Avi Singh, Larry Yang, Sergey Levine category:cs.LG cs.CV cs.RO  published:2017-08-07 summary:We tackle the problem of learning robotic sensorimotor control policies that can generalize to visually diverse and unseen environments. Achieving broad generalization typically requires large datasets, which are difficult to obtain for task-specific interactive processes such as reinforcement learning or learning from demonstration. However, much of the visual diversity in the world can be captured through passively collected datasets of images or videos. In our method, which we refer to as GPLAC (Generalized Policy Learning with Attentional Classifier), we use both interaction data and weakly labeled image data to augment the generalization capacity of sensorimotor policies. Our method combines multitask learning on action selection and an auxiliary binary classification objective, together with a convolutional neural network architecture that uses an attentional mechanism to avoid distractors. We show that pairing interaction data from just a single environment with a diverse dataset of weakly labeled data results in greatly improved generalization to unseen environments, and show that this generalization depends on both the auxiliary objective and the attentional architecture that we propose. We demonstrate our results in both simulation and on a real robotic manipulator, and demonstrate substantial improvement over standard convolutional architectures and domain adaptation methods. version:1
arxiv-1708-02312 | Shortcut-Stacked Sentence Encoders for Multi-Domain Inference | http://arxiv.org/abs/1708.02312 | id:1708.02312 author:Yixin Nie, Mohit Bansal category:cs.CL cs.AI cs.LG  published:2017-08-07 summary:We present a simple sequential sentence encoder for multi-domain natural language inference. Our encoder is based on stacked bidirectional LSTM-RNNs with shortcut connections and fine-tuning of word embeddings. The overall supervised model uses the above encoder to encode two input sentences into two vectors, and then uses a classifier over the vector combination to label the relationship between these two sentences as that of entailment, contradiction, or neural. Our Shortcut-Stacked sentence encoders achieve strong improvements over existing encoders on matched and mismatched multi-domain natural language inference (top non-ensemble single-model result in the EMNLP RepEval 2017 Shared Task (Nangia et al., 2017)). Moreover, they achieve the new state-of-the-art encoding result on the original SNLI dataset (Bowman et al., 2015). version:1
arxiv-1708-02300 | Reinforced Video Captioning with Entailment Rewards | http://arxiv.org/abs/1708.02300 | id:1708.02300 author:Ramakanth Pasunuru, Mohit Bansal category:cs.CL cs.AI cs.CV cs.LG  published:2017-08-07 summary:Sequence-to-sequence models have shown promising improvements on the temporal task of video captioning, but they optimize word-level cross-entropy loss during training. First, using policy gradient and mixed-loss methods for reinforcement learning, we directly optimize sentence-level task-based metrics (as rewards), achieving significant improvements over the baseline, based on both automatic metrics and human evaluation on multiple datasets. Next, we propose a novel entailment-enhanced reward (CIDEnt) that corrects phrase-matching based metrics (such as CIDEr) to only allow for logically-implied partial matches and avoid contradictions, achieving further significant improvements over the CIDEr-reward model. Overall, our CIDEnt-reward model achieves the new state-of-the-art on the MSR-VTT dataset. version:1
arxiv-1708-01318 | The UMD Neural Machine Translation Systems at WMT17 Bandit Learning Task | http://arxiv.org/abs/1708.01318 | id:1708.01318 author:Amr Sharaf, Shi Feng, Khanh Nguyen, Kianté Brantley, Hal Daumé III category:cs.CL cs.AI cs.HC  published:2017-08-03 summary:We describe the University of Maryland machine translation systems submitted to the WMT17 German-English Bandit Learning Task. The task is to adapt a translation system to a new domain, using only bandit feedback: the system receives a German sentence to translate, produces an English sentence, and only gets a scalar score as feedback. Targeting these two challenges (adaptation and bandit learning), we built a standard neural machine translation system and extended it in two ways: (1) robust reinforcement learning techniques to learn effectively from the bandit feedback, and (2) domain adaptation using data selection from a large corpus of parallel data. version:2
arxiv-1708-01349 | ACTS in Need: Automatic Configuration Tuning with Scalability Guarantees | http://arxiv.org/abs/1708.01349 | id:1708.01349 author:Yuqing Zhu, Jianxun Liu, Mengying Guo, Wenlong Ma, Yungang Bao category:cs.DC  published:2017-08-04 summary:To support the variety of Big Data use cases, many Big Data related systems expose a large number of user-specifiable configuration parameters. Highlighted in our experiments, a MySQL deployment with well-tuned configuration parameters achieves a peak throughput as 12 times much as one with the default setting. However, finding the best setting for the tens or hundreds of configuration parameters is mission impossible for ordinary users. Worse still, many Big Data applications require the support of multiple systems co-deployed in the same cluster. As these co-deployed systems can interact to affect the overall performance, they must be tuned together. Automatic configuration tuning with scalability guarantees (ACTS) is in need to help system users. Solutions to ACTS must scale to various systems, workloads, deployments, parameters and resource limits. Proposing and implementing an ACTS solution, we demonstrate that ACTS can benefit users not only in improving system performance and resource utilization, but also in saving costs and enabling fairer benchmarking. version:2
arxiv-1708-02254 | Asking Too Much? The Rhetorical Role of Questions in Political Discourse | http://arxiv.org/abs/1708.02254 | id:1708.02254 author:Justine Zhang, Arthur Spirling, Cristian Danescu-Niculescu-Mizil category:cs.CL cs.AI cs.CY cs.SI physics.soc-ph  published:2017-08-07 summary:Questions play a prominent role in social interactions, performing rhetorical functions that go beyond that of simple informational exchange. The surface form of a question can signal the intention and background of the person asking it, as well as the nature of their relation with the interlocutor. While the informational nature of questions has been extensively examined in the context of question-answering applications, their rhetorical aspects have been largely understudied. In this work we introduce an unsupervised methodology for extracting surface motifs that recur in questions, and for grouping them according to their latent rhetorical role. By applying this framework to the setting of question sessions in the UK parliament, we show that the resulting typology encodes key aspects of the political discourse---such as the bifurcation in questioning behavior between government and opposition parties---and reveals new insights into the effects of a legislator's tenure and political career ambitions. version:1
arxiv-1708-02205 | Robust Dynamic Locomotion via Reinforcement Learning and Novel Whole Body Controller | http://arxiv.org/abs/1708.02205 | id:1708.02205 author:Donghyun Kim, Jaemin Lee, Luis Sentis category:cs.RO  published:2017-08-07 summary:We propose a robust dynamic walking controller consisting of a dynamic locomotion planner, a reinforcement learning process for robustness, and a novel whole-body locomotion controller (WBLC). Previous approaches specify either the position or the timing of steps, however, the proposed locomotion planner simultaneously computes both of these parameters as locomotion outputs. Our locomotion strategy relies on devising a reinforcement learning (RL) approach for robust walking. The learned policy generates multi step walking patterns, and the process is quick enough to be suitable for real-time controls. For learning, we devise an RL strategy that uses a phase space planner (PSP) and a linear inverted pendulum model to make the problem tractable and very fast. Then, the learned policy is used to provide goal-based commands to the WBLC, which calculates the torque commands to be executed in full-humanoid robots. The WBLC combines multiple prioritized tasks and calculates the associated reaction forces based on practical inequality constraints. The novel formulation includes efficient calculation of the time derivatives of various Jacobians. This provides high-fidelity dynamic control of fast motions. More specifically, we compute the time derivative of the Jacobian for various tasks and the Jacobian of the centroidal momentum task by utilizing Lie group operators and operational space dynamics respectively. The integration of RL-PSP and the WBLC provides highly robust, versatile, and practical locomotion including steering while walking and handling push disturbances of up to 520 N during an interval of 0.1 sec. Theoretical and numerical results are tested through a 3D physics-based simulation of the humanoid robot Valkyrie. version:1
arxiv-1708-02199 | Early Evaluation of Intel Optane Non-Volatile Memory with HPC I/O Workloads | http://arxiv.org/abs/1708.02199 | id:1708.02199 author:Kai Wu, Frank Ober, Shari Hamlin, Dong Li category:cs.DC  published:2017-08-07 summary:High performance computing (HPC) applications have a high requirement on storage speed and capacity. Non-volatile memory is a promising technology to replace traditional storage devices to improve HPC performance. Earlier in 2017, Intel and Micron released first NVM product -- Intel Optane SSDs. Optane is much faster and more durable than the traditional storage device. It creates a bridge to narrow the performance gap between DRAM and storage. But is the existing HPC I/O stack still suitable for new NVM devices like Intel Optane? How does HPC I/O workload perform with Intel Optane? In this paper, we analyze the performance of I/O intensive HPC applications with Optane as a block device and try to answer the above questions. We study the performance from three perspectives: (1) basic read and write bandwidth of Optane, (2) a performance comparison study between Optane and HDD, including checkpoint workload, MPI individual I/O vs. POSIX I/O, and MPI individual I/O vs. MPI collective I/O, and (3) the impact of Optane on the performance of a parallel file system, PVFS2. version:1
arxiv-1708-02191 | Unsupervised Domain Adaptation for Face Recognition in Unlabeled Videos | http://arxiv.org/abs/1708.02191 | id:1708.02191 author:Kihyuk Sohn, Sifei Liu, Guangyu Zhong, Xiang Yu, Ming-Hsuan Yang, Manmohan Chandraker category:cs.CV cs.AI  published:2017-08-07 summary:Despite rapid advances in face recognition, there remains a clear gap between the performance of still image-based face recognition and video-based face recognition, due to the vast difference in visual quality between the domains and the difficulty of curating diverse large-scale video datasets. This paper addresses both of those challenges, through an image to video feature-level domain adaptation approach, to learn discriminative video frame representations. The framework utilizes large-scale unlabeled video data to reduce the gap between different domains while transferring discriminative knowledge from large-scale labeled still images. Given a face recognition network that is pretrained in the image domain, the adaptation is achieved by (i) distilling knowledge from the network to a video adaptation network through feature matching, (ii) performing feature restoration through synthetic data augmentation and (iii) learning a domain-invariant feature through a domain adversarial discriminator. We further improve performance through a discriminator-guided feature fusion that boosts high-quality frames while eliminating those degraded by video domain-specific factors. Experiments on the YouTube Faces and IJB-A datasets demonstrate that each module contributes to our feature-level domain adaptation framework and substantially improves video face recognition performance to achieve state-of-the-art accuracy. We demonstrate qualitatively that the network learns to suppress diverse artifacts in videos such as pose, illumination or occlusion without being explicitly trained for them. version:1
arxiv-1708-02190 | Intrinsically Motivated Goal Exploration Processes with Automatic Curriculum Learning | http://arxiv.org/abs/1708.02190 | id:1708.02190 author:Sébastien Forestier, Yoan Mollard, Pierre-Yves Oudeyer category:cs.AI cs.LG  published:2017-08-07 summary:Intrinsically motivated spontaneous exploration is a key enabler of autonomous lifelong learning in human children. It allows them to discover and acquire large repertoires of skills through self-generation, self-selection, self-ordering and self-experimentation of learning goals. We present the unsupervised multi-goal reinforcement learning formal framework as well as an algorithmic approach called intrinsically motivated goal exploration processes (IMGEP) to enable similar properties of autonomous learning in machines. The IMGEP algorithmic architecture relies on several principles: 1) self-generation of goals as parameterized reinforcement learning problems; 2) selection of goals based on intrinsic rewards; 3) exploration with parameterized time-bounded policies and fast incremental goal-parameterized policy search; 4) systematic reuse of information acquired when targeting a goal for improving other goals. We present a particularly efficient form of IMGEP that uses a modular representation of goal spaces as well as intrinsic rewards based on learning progress. We show how IMGEPs automatically generate a learning curriculum within an experimental setup where a real humanoid robot can explore multiple spaces of goals with several hundred continuous dimensions. While no particular target goal is provided to the system beforehand, this curriculum allows the discovery of skills of increasing complexity, that act as stepping stone for learning more complex skills (like nested tool use). We show that learning several spaces of diverse problems can be more efficient for learning complex skills than only trying to directly learn these complex skills. We illustrate the computational efficiency of IMGEPs as these robotic experiments use a simple memory-based low-level policy representations and search algorithm, enabling the whole system to learn online and incrementally on a Raspberry Pi 3. version:1
arxiv-1708-02188 | PowerAI DDL | http://arxiv.org/abs/1708.02188 | id:1708.02188 author:Minsik Cho, Ulrich Finkler, Sameer Kumar, David Kung, Vaibhav Saxena, Dheeraj Sreedhar category:cs.DC cs.AI cs.LG  published:2017-08-07 summary:As deep neural networks become more complex and input datasets grow larger, it can take days or even weeks to train a deep neural network to the desired accuracy. Therefore, distributed Deep Learning at a massive scale is a critical capability, since it offers the potential to reduce the training time from weeks to hours. In this paper, we present a software-hardware co-optimized distributed Deep Learning system that can achieve near-linear scaling up to hundreds of GPUs. The core algorithm is a multi-ring communication pattern that provides a good tradeoff between latency and bandwidth and adapts to a variety of system configurations. The communication algorithm is implemented as a library for easy use. This library has been integrated into Tensorflow, Caffe, and Torch. We train Resnet-101 on Imagenet 22K with 64 IBM Power8 S822LC servers (256 GPUs) in about 7 hours to an accuracy of 33.8 % validation accuracy. Microsoft's ADAM and Google's DistBelief results did not reach 30 % validation accuracy for Imagenet 22K. Compared to Facebook AI Research's recent paper on 256 GPU training, we use a different communication algorithm, and our combined software and hardware system offers better communication overhead for Resnet-50. A PowerAI DDL enabled version of Torch completed 90 epochs of training on Resnet 50 for 1K classes in 50 minutes using 64 IBM Power8 S822LC servers (256 GPUs). version:1
arxiv-1707-09938 | Wavelet Residual Network for Low-Dose CT via Deep Convolutional Framelets | http://arxiv.org/abs/1707.09938 | id:1707.09938 author:Eunhee Kang, Jaejun Yoo, Jong Chul Ye category:stat.ML cs.AI cs.CV cs.LG  published:2017-07-31 summary:Model based iterative reconstruction (MBIR) algorithms for low-dose X-ray CT are computationally expensive. To address this problem, we recently proposed the world-first deep convolutional neural network (CNN) for low-dose X-ray CT and won the second place in 2016 AAPM Low-Dose CT Grand Challenge. However, some of the texture were not fully recovered. To cope with this problem, here we propose a deep residual learning approach in directional wavelet domain. The proposed method is motivated by an observation that a deep convolutional neural network can be interpreted as a multilayer convolutional framelets expansion using non-local basis convolved with data-driven local basis. We further extend the idea to derive a deep convolutional framelet expansion by combining global redundant transforms and signal boosting from multiple signal representations. Extensive experimental results confirm that the proposed network has significantly improved performance and preserves the detail texture of the original images version:2
arxiv-1708-02167 | Regulating Highly Automated Robot Ecologies: Insights from Three User Studies | http://arxiv.org/abs/1708.02167 | id:1708.02167 author:Wen Shen, Alanoud Al Khemeiri, Abdulla Almehrezi, Wael Al Enezi, Iyad Rahwan, Jacob W. Crandall category:cs.AI cs.CY cs.HC  published:2017-08-07 summary:Highly automated robot ecologies (HARE), or societies of independent autonomous robots or agents, are rapidly becoming an important part of much of the world's critical infrastructure. As with human societies, regulation, wherein a governing body designs rules and processes for the society, plays an important role in ensuring that HARE meet societal objectives. However, to date, a careful study of interactions between a regulator and HARE is lacking. In this paper, we report on three user studies which give insights into how to design systems that allow people, acting as the regulatory authority, to effectively interact with HARE. As in the study of political systems in which governments regulate human societies, our studies analyze how interactions between HARE and regulators are impacted by regulatory power and individual (robot or agent) autonomy. Our results show that regulator power, decision support, and adaptive autonomy can each diminish the social welfare of HARE, and hint at how these seemingly desirable mechanisms can be designed so that they become part of successful HARE. version:1
arxiv-1708-02153 | A Characterization of Monotone Influence Measures for Data Classification | http://arxiv.org/abs/1708.02153 | id:1708.02153 author:Jakub Sliwinski, Martin Strobel, Yair Zick category:cs.AI  published:2017-08-07 summary:In this work we focus on the following question: how important was the i-th feature in determining the outcome for a given datapoint? We identify a family of influence measures; functions that, given a datapoint x, assign a value phi_i(x) to every feature i, which roughly corresponds to that i's importance in determining the outcome for x. This family is uniquely derived from a set of axioms: desirable properties that any reasonable influence measure should satisfy. Departing from prior work on influence measures, we assume no knowledge of - or access to - the underlying classifier labelling the dataset. In other words, our influence measures are based on the dataset alone, and do not make any queries to the classifier. While this requirement naturally limits the scope of explanations we provide, we show that it is effective on real datasets. version:1
arxiv-1708-02139 | STARDATA: A StarCraft AI Research Dataset | http://arxiv.org/abs/1708.02139 | id:1708.02139 author:Zeming Lin, Jonas Gehring, Vasil Khalidov, Gabriel Synnaeve category:cs.AI  published:2017-08-07 summary:We release a dataset of 65646 StarCraft replays that contains 1535 million frames and 496 million player actions. We provide full game state data along with the original replays that can be viewed in StarCraft. The game state data was recorded every 3 frames which ensures suitability for a wide variety of machine learning tasks such as strategy classification, inverse reinforcement learning, imitation learning, forward modeling, partial information extraction, and others. We use TorchCraft to extract and store the data, which standardizes the data format for both reading from replays and reading directly from the game. Furthermore, the data can be used on different operating systems and platforms. The dataset contains valid, non-corrupted replays only and its quality and diversity was ensured by a number of heuristics. We illustrate the diversity of the data with various statistics and provide examples of tasks that benefit from the dataset. We make the dataset available at https://github.com/TorchCraft/StarData . En Taro Adun! version:1
arxiv-1609-06161 | Self-Stabilizing Robots in Highly Dynamic Environments | http://arxiv.org/abs/1609.06161 | id:1609.06161 author:Marjorie Bournat, Ajoy K. Datta, Swan Dubois category:cs.DC  published:2016-09-20 summary:This paper deals with the classical problem of exploring a ring by a cohort of synchronous robots. We focus on the perpetual version of this problem in which it is required that each node of the ring is visited by a robot infinitely often. The challenge in this paper is twofold. First, we assume that the robots evolve in a highly dynamic ring, \ie edges may appear and disappear unpredictably without any recurrence, periodicity, nor stability assumption. The only assumption we made (known as temporal connectivity assumption) is that each node is infinitely often reachable from any other node. Second, we aim at providing a self-stabilizing algorithm to the robots, i.e., the algorithm must guarantee an eventual correct behavior regardless of the initial state and positions of the robots.In this harsh environment, our contribution is to fully characterize, for each size of the ring, the necessary and sufficient number of robots to solve deterministically the problem. version:3
arxiv-1708-02086 | An Insight on the Ratio of Transmission of Motion (RoToM) and its Relation to the Centroidal Inertia Matrix | http://arxiv.org/abs/1708.02086 | id:1708.02086 author:Federico L. Moro category:cs.RO  published:2017-08-07 summary:This paper analyses the dynamic response of a robot when subject to an external force that is applied to its Center of Mass (CoM). The Ratio of Transmission of Motion (RoToM) is proposed as a novel indicator of what part of the applied force generates motion, and what part is dissipated by the passive forces due to mechanical constraints. It depends on the configuration of the robot and on the direction of the force, and is always between 0 and 1. Extending this concept, a transmissibility ellipsoid is used to describe the behavior of the robot given a certain configuration, and varying the direction of the applied force. Another physical measure that is related to the transmissibility ellipsoid is the transmissibility index: it provides an indication on how similarly the system behaves when subject to forces coming from different directions. The presented analysis aims to provide a deeper insight on the centroidal dynamics of a robot, and on its dependence on the configuration. It can be beneficial for developing whole-body controllers of redundant robots for e.g., reducing the effort in terms of joint torques to compensate for gravity, and more in general for designing interaction control architectures. version:1
arxiv-1705-05595 | GraphH: High Performance Big Graph Analytics in Small Clusters | http://arxiv.org/abs/1705.05595 | id:1705.05595 author:Peng Sun, Yonggang Wen, Ta Nguyen Binh Duong, Xiaokui Xiao category:cs.DC  published:2017-05-16 summary:It is common for real-world applications to analyze big graphs using distributed graph processing systems. Popular in-memory systems require an enormous amount of resources to handle big graphs. While several out-of-core approaches have been proposed for processing big graphs on disk, the high disk I/O overhead could significantly reduce performance. In this paper, we propose GraphH to enable high-performance big graph analytics in small clusters. Specifically, we design a two-stage graph partition scheme to evenly divide the input graph into partitions, and propose a GAB (Gather-Apply-Broadcast) computation model to make each worker process a partition in memory at a time. We use an edge cache mechanism to reduce the disk I/O overhead, and design a hybrid strategy to improve the communication performance. GraphH can efficiently process big graphs in small clusters or even a single commodity server. Extensive evaluations have shown that GraphH could be up to 7.8x faster compared to popular in-memory systems, such as Pregel+ and PowerGraph when processing generic graphs, and more than 100x faster than recently proposed out-of-core systems, such as GraphD and Chaos when processing big graphs. version:5
arxiv-1708-02030 | CRAFT: A library for easier application-level Checkpoint/Restart and Automatic Fault Tolerance | http://arxiv.org/abs/1708.02030 | id:1708.02030 author:Faisal Shahzad, Jonas Thies, Moritz Kreutzer, Thomas Zeiser, Georg Hager, Gerhard Wellein category:cs.DC  published:2017-08-07 summary:In order to efficiently use the future generations of supercomputers, fault tolerance and power consumption are two of the prime challenges anticipated by the High Performance Computing (HPC) community. Checkpoint/Restart (CR) has been and still is the most widely used technique to deal with hard failures. Application-level CR is the most effective CR technique in terms of overhead efficiency but it takes a lot of implementation effort. This work presents the implementation of our C++ based library CRAFT (Checkpoint-Restart and Automatic Fault Tolerance), which serves two purposes. First, it provides an extendable library that significantly eases the implementation of application-level checkpointing. The most basic and frequently used checkpoint data types are already part of CRAFT and can be directly used out of the box. The library can be easily extended to add more data types. As means of overhead reduction, the library offers a build-in asynchronous checkpointing mechanism and also supports the Scalable Checkpoint/Restart (SCR) library for node level checkpointing. Second, CRAFT provides an easier interface for User-Level Failure Mitigation (ULFM) based dynamic process recovery, which significantly reduces the complexity and effort of failure detection and communication recovery mechanism. By utilizing both functionalities together, applications can write application-level checkpoints and recover dynamically from process failures with very limited programming effort. This work presents the design and use of our library in detail. The associated overheads are thoroughly analyzed using several benchmarks. version:1
arxiv-1601-03411 | Analysis of Algorithms and Partial Algorithms | http://arxiv.org/abs/1601.03411 | id:1601.03411 author:Andrew MacFie category:cs.AI cs.DS  published:2016-01-13 summary:We present an alternative methodology for the analysis of algorithms, based on the concept of expected discounted reward. This methodology naturally handles algorithms that do not always terminate, so it can (theoretically) be used with partial algorithms for undecidable problems, such as those found in artificial general intelligence (AGI) and automated theorem proving. We mention an approach to self-improving AGI enabled by this methodology. Aug 2017 addendum: This article was originally written with multiple audiences in mind. It is really best put in the following terms. Goertzel, Hutter, Legg, and others have developed a definition of an intelligence score for a general abstract agent: expected lifetime reward in a random environment. AIXI is generally the optimal agent according to this score, but there may be reasons to analyze other agents and compare score values. If we want to use this definition of intelligence in practice, perhaps we can start by analyzing some simple agents. Common algorithms can be thought of as simple agents (environment is input, reward is based on running time) so we take the goal of applying the agent intelligence score to algorithms. That is, we want to find, what are the IQ scores of algorithms? We can do some very simple analysis, but the real answer is that even for simple algorithms, the intelligence score is too difficult to work with in practice. version:5
arxiv-1708-01938 | A Framework for Visually Realistic Multi-robot Simulation in Natural Environment | http://arxiv.org/abs/1708.01938 | id:1708.01938 author:Ori Ganoni, Ramakrishnan Mukundan category:cs.RO cs.CV  published:2017-08-06 summary:This paper presents a generalized framework for the simulation of multiple robots and drones in highly realistic models of natural environments. The proposed simulation architecture uses the Unreal Engine4 for generating both optical and depth sensor outputs from any position and orientation within the environment and provides several key domain specific simulation capabilities. Various components and functionalities of the system have been discussed in detail. The simulation engine also allows users to test and validate a wide range of computer vision algorithms involving different drone configurations under many types of environmental effects such as wind gusts. The paper demonstrates the effectiveness of the system by giving experimental results for a test scenario where one drone tracks the simulated motion of another in a complex natural environment. version:1
arxiv-1708-01931 | Towards Social Autonomous Vehicles: Efficient Collision Avoidance Scheme Using Richardson's Arms Race Model | http://arxiv.org/abs/1708.01931 | id:1708.01931 author:Faisal Riaz, Muaz A. Niazi category:cs.AI cs.HC cs.MA  published:2017-08-06 summary:Background Road collisions and casualties pose a serious threat to commuters around the globe. Autonomous Vehicles (AVs) aim to make the use of technology to reduce the road accidents. However, the most of research work in the context of collision avoidance has been performed to address, separately, the rear end, front end and lateral collisions in less congested and with high inter-vehicular distances. Purpose The goal of this paper is to introduce the concept of a social agent, which interact with other AVs in social manners like humans are social having the capability of predicting intentions, i.e. mentalizing and copying the actions of each other, i.e. mirroring. The proposed social agent is based on a human-brain inspired mentalizing and mirroring capabilities and has been modelled for collision detection and avoidance under congested urban road traffic. Method We designed our social agent having the capabilities of mentalizing and mirroring and for this purpose we utilized Exploratory Agent Based Modeling (EABM) level of Cognitive Agent Based Computing (CABC) framework proposed by Niazi and Hussain. Results Our simulation and practical experiments reveal that by embedding Richardson's arms race model within AVs, collisions can be avoided while travelling on congested urban roads in a flock like topologies. The performance of the proposed social agent has been compared at two different levels. version:1
arxiv-1708-01930 | Enhanced Emotion Enabled Cognitive Agent Based Rear End Collision Avoidance Controller for Autonomous Vehicles | http://arxiv.org/abs/1708.01930 | id:1708.01930 author:Faisal Riaz, Muaz A. Niazi category:cs.AI cs.MA cs.RO cs.SY  published:2017-08-06 summary:Rear end collisions are deadliest in nature and cause most of traffic casualties and injuries. In the existing research, many rear end collision avoidance solutions have been proposed. However, the problem with these proposed solutions is that they are highly dependent on precise mathematical models. Whereas, the real road driving is influenced by non-linear factors such as road surface situations, driver reaction time, pedestrian flow and vehicle dynamics, hence obtaining the accurate mathematical model of the vehicle control system is challenging. This problem with precise control based rear end collision avoidance schemes has been addressed using fuzzy logic, but the excessive number of fuzzy rules straightforwardly prejudice their efficiency. Furthermore, these fuzzy logic based controllers have been proposed without using proper agent based modeling that helps in mimicking the functions of an artificial human driver executing these fuzzy rules. Keeping in view these limitations, we have proposed an Enhanced Emotion Enabled Cognitive Agent (EEEC_Agent) based controller that helps the Autonomous Vehicles (AVs) to perform rear end collision avoidance with less number of rules, designed after fear emotion, and high efficiency. To introduce a fear emotion generation mechanism in EEEC_Agent, Orton, Clore & Collins (OCC) model has been employed. The fear generation mechanism of EEEC_Agent has been verified using NetLogo simulation. Furthermore, practical validation of EEEC_Agent functions has been performed using specially built prototype AV platform. Eventually, the qualitative comparative study with existing state of the art research works reflect that proposed model outperforms recent research. version:1
arxiv-1708-01927 | Emotion Controlled Spectrum Mobility Scheme for Efficient Syntactic Interoperability In Cognitive Radio Based Internet of Vehicles | http://arxiv.org/abs/1708.01927 | id:1708.01927 author:Faisal Riaz, Muaz A. Niazi category:cs.NI cs.AI cs.GT cs.MA  published:2017-08-06 summary:Blind spots are one of the causes of road accidents in the hilly and flat areas. These blind spot accidents can be decreased by establishing an Internet of Vehicles (IoV) using Vehicle-2-Vehicle (V2V) and Vehicle-2-Infrastrtructure (V2I) communication systems. But the problem with these IoV is that most of them are using DSRC or single Radio Access Technology (RAT) as a wireless technology, which has been proven to be failed for efficient communication between vehicles. Recently, Cognitive Radio (CR) based IoV have to be proven best wireless communication systems for vehicular networks. However, the spectrum mobility is a challenging task to keep CR based vehicular networks interoperable and has not been addressed sufficiently in existing research. In our previous research work, the Cognitive Radio Site (CR-Site) has been proposed as in-vehicle CR-device, which can be utilized to establish efficient IoV systems. H In this paper, we have introduced the Emotions Inspired Cognitive Agent (EIC_Agent) based spectrum mobility mechanism in CR-Site and proposed a novel emotions controlled spectrum mobility scheme for efficient syntactic interoperability between vehicles. For this purpose, a probabilistic deterministic finite automaton using fear factor is proposed to perform efficient spectrum mobility using fuzzy logic. In addition, the quantitative computation of different fear intensity levels has been performed with the help of fuzzy logic. The system has been tested using active data from different GSM service providers on Mangla-Mirpur road. This is supplemented by extensive simulation experiments which validate the proposed scheme for CR based high-speed vehicular networks. The qualitative comparison with the existing-state-of the-art has proven the superiority of the proposed emotions controlled syntactic interoperable spectrum mobility scheme within cognitive radio based IoV systems. version:1
arxiv-1708-01925 | Designing Autonomous Vehicles: Evaluating the Role of Human Emotions and Social Norms | http://arxiv.org/abs/1708.01925 | id:1708.01925 author:Faisal Riaz, Muaz A. Niazi category:cs.MA cs.AI cs.CY cs.RO cs.SY  published:2017-08-06 summary:Humans are going to delegate the rights of driving to the autonomous vehicles in near future. However, to fulfill this complicated task, there is a need for a mechanism, which enforces the autonomous vehicles to obey the road and social rules that have been practiced by well-behaved drivers. This task can be achieved by introducing social norms compliance mechanism in the autonomous vehicles. This research paper is proposing an artificial society of autonomous vehicles as an analogy of human social society. Each AV has been assigned a social personality having different social influence. Social norms have been introduced which help the AVs in making the decisions, influenced by emotions, regarding road collision avoidance. Furthermore, social norms compliance mechanism, by artificial social AVs, has been proposed using prospect based emotion i.e. fear, which is conceived from OCC model. Fuzzy logic has been employed to compute the emotions quantitatively. Then, using SimConnect approach, fuzzy values of fear has been provided to the Netlogo simulation environment to simulate artificial society of AVs. Extensive testing has been performed using the behavior space tool to find out the performance of the proposed approach in terms of the number of collisions. For comparison, the random-walk model based artificial society of AVs has been proposed as well. A comparative study with a random walk, prove that proposed approach provides a better option to tailor the autopilots of future AVS, Which will be more socially acceptable and trustworthy by their riders in terms of safe road travel. version:1
arxiv-1708-01911 | Training of Deep Neural Networks based on Distance Measures using RMSProp | http://arxiv.org/abs/1708.01911 | id:1708.01911 author:Thomas Kurbiel, Shahrzad Khaleghian category:cs.LG cs.AI stat.ML  published:2017-08-06 summary:The vanishing gradient problem was a major obstacle for the success of deep learning. In recent years it was gradually alleviated through multiple different techniques. However the problem was not really overcome in a fundamental way, since it is inherent to neural networks with activation functions based on dot products. In a series of papers, we are going to analyze alternative neural network structures which are not based on dot products. In this first paper, we revisit neural networks built up of layers based on distance measures and Gaussian activation functions. These kinds of networks were only sparsely used in the past since they are hard to train when using plain stochastic gradient descent methods. We show that by using Root Mean Square Propagation (RMSProp) it is possible to efficiently learn multi-layer neural networks. Furthermore we show that when appropriately initialized these kinds of neural networks suffer much less from the vanishing and exploding gradient problem than traditional neural networks even for deep networks. version:1
arxiv-1709-06927 | Mist Computing: Principles, Trends and Future Direction | http://arxiv.org/abs/1709.06927 | id:1709.06927 author:Manas Kumar Yogi, K. Chandrasekhar, G. Vijay Kumar category:cs.NI cs.DC  published:2017-08-06 summary:In this paper we present the novel idea of computing near the edge of IOT architecture which enhances the inherent efficiency while computing complex applications. This concept is termed as mist computing. We believe this computing will bring about an massive revolution in future computing technologies. instead of thrusting the control responsibility to gateways while data transmission the control is decentralised to end nodes which decrease the communicational delay of the network thereby increasing the throughput. version:1
arxiv-1708-01867 | An Information-Theoretic Optimality Principle for Deep Reinforcement Learning | http://arxiv.org/abs/1708.01867 | id:1708.01867 author:Felix Leibfried, Jordi Grau-Moya, Haitham B. Ammar category:cs.AI cs.LG stat.ML  published:2017-08-06 summary:In this paper, we address the problem of cumulative reward overestimation in deep reinforcement learning methodologically. We generalise notions from information-theoretic bounded rationality to handle high-dimensional state spaces efficiently. The resultant algorithm encompasses a wide range of learning outcomes that can be demonstrated by tuning a Lagrange multiplier that intrinsically penalises rewards. We show that deep Q-networks fall naturally as a special case from our proposed approach. We further contribute by introducing a novel scheduling scheme for bounded-rational behaviour that ensures sample efficiency and robustness. In experiments on Atari games, we show that our algorithm outperforms various deep reinforcement learning algorithms (e.g., deep and double deep Q-networks) in terms of both, game- play performance and sample complexity. version:1
arxiv-1708-01834 | Exploiting Physical Dynamics to Detect Actuator and Sensor Attacks in Mobile Robots | http://arxiv.org/abs/1708.01834 | id:1708.01834 author:Pinyao Guo, Hunmin Kim, Nurali Virani, Jun Xu, Minghui Zhu, Peng Liu category:cs.CR cs.RO  published:2017-08-06 summary:Mobile robots are cyber-physical systems where the cyberspace and the physical world are strongly coupled. Attacks against mobile robots can transcend cyber defenses and escalate into disastrous consequences in the physical world. In this paper, we focus on the detection of active attacks that are capable of directly influencing robot mission operation. Through leveraging physical dynamics of mobile robots, we develop RIDS, a novel robot intrusion detection system that can detect actuator attacks as well as sensor attacks for nonlinear mobile robots subject to stochastic noises. We implement and evaluate a RIDS on Khepera mobile robot against concrete attack scenarios via various attack channels including signal interference, sensor spoofing, logic bomb, and physical damage. Evaluation of 20 experiments shows that the averages of false positive rates and false negative rates are both below 1%. Average detection delay for each attack remains within 0.40s. version:1
arxiv-1708-01829 | Declarative Statistics | http://arxiv.org/abs/1708.01829 | id:1708.01829 author:Roberto Rossi, Özgür Akgün, Steven Prestwich, S. Armagan Tarim category:cs.AI stat.ME  published:2017-08-06 summary:In this work we introduce declarative statistics, a suite of declarative modelling tools for statistical analysis. Statistical constraints represent the key building block of declarative statistics. First, we introduce a range of relevant counting and matrix constraints and associated decompositions, some of which novel, that are instrumental in the design of statistical constraints. Second, we introduce a selection of novel statistical constraints and associated decompositions, which constitute a self-contained toolbox that can be used to tackle a wide range of problems typically encountered by statisticians. Finally, we deploy these statistical constraints to a wide range of application areas drawn from classical statistics and we contrast our framework against established practices. version:1
arxiv-1708-01797 | Reuse, don't Recycle: Transforming Lock-free Algorithms that Throw Away Descriptors | http://arxiv.org/abs/1708.01797 | id:1708.01797 author:Maya Arbel-Raviv, Trevor Brown category:cs.DC D.1.3  published:2017-08-05 summary:In many lock-free algorithms, threads help one another, and each operation creates a descriptor that describes how other threads should help it. Allocating and reclaiming descriptors introduces significant space and time overhead. We introduce the first descriptor abstract data type (ADT), which captures the usage of descriptors by lock-free algorithms. We then develop a weak descriptor ADT which has weaker semantics, but can be implemented significantly more efficiently. We show how a large class of lock-free algorithms can be transformed to use weak descriptors, and demonstrate our technique by transforming several algorithms, including the leading k-compare-and-swap (k-CAS) algorithm. The original k-CAS algorithm allocates at least k+1 new descriptors per k-CAS. In contrast, our implementation allocates two descriptors per process, and each process simply reuses its two descriptors. Experiments on a variety of workloads show significant performance improvements over implementations that reclaim descriptors, and reductions of up to three orders of magnitude in peak memory usage. version:1
arxiv-1708-01791 | Thompson Sampling Guided Stochastic Searching on the Line for Deceptive Environments with Applications to Root-Finding Problems | http://arxiv.org/abs/1708.01791 | id:1708.01791 author:Sondre Glimsdal, Ole-Christoffer Granmo category:cs.AI  published:2017-08-05 summary:The multi-armed bandit problem forms the foundation for solving a wide range of on-line stochastic optimization problems through a simple, yet effective mechanism. One simply casts the problem as a gambler that repeatedly pulls one out of N slot machine arms, eliciting random rewards. Learning of reward probabilities is then combined with reward maximization, by carefully balancing reward exploration against reward exploitation. In this paper, we address a particularly intriguing variant of the multi-armed bandit problem, referred to as the {\it Stochastic Point Location (SPL) Problem}. The gambler is here only told whether the optimal arm (point) lies to the "left" or to the "right" of the arm pulled, with the feedback being erroneous with probability $1-\pi$. This formulation thus captures optimization in continuous action spaces with both {\it informative} and {\it deceptive} feedback. To tackle this class of problems, we formulate a compact and scalable Bayesian representation of the solution space that simultaneously captures both the location of the optimal arm as well as the probability of receiving correct feedback. We further introduce the accompanying Thompson Sampling guided Stochastic Point Location (TS-SPL) scheme for balancing exploration against exploitation. By learning $\pi$, TS-SPL also supports {\it deceptive} environments that are lying about the direction of the optimal arm. This, in turn, allows us to solve the fundamental Stochastic Root Finding (SRF) Problem. Empirical results demonstrate that our scheme deals with both deceptive and informative environments, significantly outperforming competing algorithms both for SRF and SPL. version:1
arxiv-1708-01776 | e-QRAQ: A Multi-turn Reasoning Dataset and Simulator with Explanations | http://arxiv.org/abs/1708.01776 | id:1708.01776 author:Clemens Rosenbaum, Tian Gao, Tim Klinger category:cs.LG cs.AI cs.CL  published:2017-08-05 summary:In this paper we present a new dataset and user simulator e-QRAQ (explainable Query, Reason, and Answer Question) which tests an Agent's ability to read an ambiguous text; ask questions until it can answer a challenge question; and explain the reasoning behind its questions and answer. The User simulator provides the Agent with a short, ambiguous story and a challenge question about the story. The story is ambiguous because some of the entities have been replaced by variables. At each turn the Agent may ask for the value of a variable or try to answer the challenge question. In response the User simulator provides a natural language explanation of why the Agent's query or answer was useful in narrowing down the set of possible answers, or not. To demonstrate one potential application of the e-QRAQ dataset, we train a new neural architecture based on End-to-End Memory Networks to successfully generate both predictions and partial explanations of its current understanding of the problem. We observe a strong correlation between the quality of the prediction and explanation. version:1
arxiv-1708-01733 | Boosting Variational Inference: an Optimization Perspective | http://arxiv.org/abs/1708.01733 | id:1708.01733 author:Francesco Locatello, Rajiv Khanna, Joydeep Ghosh, Gunnar Rätsch category:cs.LG cs.AI stat.ML  published:2017-08-05 summary:Variational Inference is a popular technique to approximate a possibly intractable Bayesian posterior with a more tractable one. Recently, Boosting Variational Inference has been proposed as a new paradigm to approximate the posterior by a mixture of densities by greedily adding components to the mixture. In the present work, we study the convergence properties of this approach from a modern optimization viewpoint by establishing connections to the classic Frank-Wolfe algorithm. Our analyses yields novel theoretical insights on the Boosting of Variational Inference regarding the sufficient conditions for convergence, explicit sublinear/linear rates, and algorithmic simplifications. version:1
arxiv-1708-01729 | Inception Score, Label Smoothing, Gradient Vanishing and -log(D(x)) Alternative | http://arxiv.org/abs/1708.01729 | id:1708.01729 author:Zhiming Zhou, Weinan Zhang, Jun Wang category:cs.LG cs.AI cs.CV stat.ML  published:2017-08-05 summary:In this paper, we study several GAN related topics mathematically, including Inception score, label smoothing, gradient vanishing and the -log(D(x)) alternative. We show that Inception score is actually equivalent to Mode score, both consisting of two entropy terms, which has the drawback of ignoring the prior distribution of the labels. We thus propose AM score as an alternative that leverages cross-entropy and takes the reference distribution into account. Empirical results indicate that AM score outperforms Inception score. We study label smoothing, gradient vanishing and -log(D(x)) alternative from the perspective of class-aware gradient, with which we show the exact problems when applying label smoothing to fake samples along with the log(1-D(x)) generator loss, which is previously unclear, and more importantly show that the problem does not exist when using the -log(D(x)) generator loss. version:1
arxiv-1708-05069 | A causation coefficient and taxonomy of correlation/causation relationships | http://arxiv.org/abs/1708.05069 | id:1708.05069 author:Joshua Brulé category:stat.ME cs.AI stat.OT  published:2017-08-05 summary:This paper introduces a causation coefficient which is defined in terms of probabilistic causal models. This coefficient is suggested as the natural causal analogue of the Pearson correlation coefficient and permits comparing causation and correlation to each other in a simple, yet rigorous manner. Together, these coefficients provide a natural way to classify the possible correlation/causation relationships that can occur in practice and examples of each relationship are provided. In addition, the typical relationship between correlation and causation is analyzed to provide insight into why correlation and causation are often conflated. Finally, example calculations of the causation coefficient are shown on a real data set. version:1
arxiv-1708-01648 | 3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks | http://arxiv.org/abs/1708.01648 | id:1708.01648 author:Chuhang Zou, Ersin Yumer, Jimei Yang, Duygu Ceylan, Derek Hoiem category:cs.CV cs.AI cs.LG stat.ML  published:2017-08-04 summary:The success of various applications including robotics, digital content creation, and visualization demand a structured and abstract representation of the 3D world from limited sensor data. Inspired by the nature of human perception of 3D shapes as a collection of simple parts, we explore such an abstract shape representation based on primitives. Given a single depth image of an object, we present 3D-PRNN, a generative recurrent neural network that synthesizes multiple plausible shapes composed of a set of primitives. Our generative model encodes symmetry characteristics of common man-made objects, preserves long-range structural coherence, and describes objects of varying complexity with a compact representation. We also propose a method based on Gaussian Fields to generate a large scale dataset of primitive-based shape representations to train our network. We evaluate our approach on a wide range of examples and show that it outperforms nearest-neighbor based shape retrieval methods and is on-par with voxel-based generative models while using a significantly reduced parameter space. version:1
arxiv-1708-01636 | Game theory models for communication between agents: a review | http://arxiv.org/abs/1708.01636 | id:1708.01636 author:Aisha D. Farooqui, Muaz A. Niazi category:cs.GT cs.AI cs.MA  published:2017-08-04 summary:In the real world, agents or entities are in a continuous state of interactions. These inter- actions lead to various types of complexity dynamics. One key difficulty in the study of complex agent interactions is the difficulty of modeling agent communication on the basis of rewards. Game theory offers a perspective of analysis and modeling these interactions. Previously, while a large amount of literature is available on game theory, most of it is from specific domains and does not cater for the concepts from an agent- based perspective. Here in this paper, we present a comprehensive multidisciplinary state-of-the-art review and taxonomy of game theory models of complex interactions between agents. version:1
arxiv-1708-01628 | Validation of Enhanced Emotion Enabled Cognitive Agent Using Virtual Overlay Multi-Agent System Approach | http://arxiv.org/abs/1708.01628 | id:1708.01628 author:Faisal Riaz, Muaz A. Niazi category:cs.MA cs.AI cs.GT cs.SY  published:2017-08-04 summary:Making roads safer by avoiding road collisions is one of the main reasons for inventing Autonomous vehicles (AVs). In this context, designing agent-based collision avoidance components of AVs which truly represent human cognition and emotions look is a more feasible approach as agents can replace human drivers. However, to the best of our knowledge, very few human emotion and cognition-inspired agent-based studies have previously been conducted in this domain. Furthermore, these agent-based solutions have not been validated using any key validation technique. Keeping in view this lack of validation practices, we have selected state-of-the-art Emotion Enabled Cognitive Agent (EEC_Agent), which was proposed to avoid lateral collisions between semi-AVs. The architecture of EEC_Agent has been revised using Exploratory Agent Based Modeling (EABM) level of the Cognitive Agent Based Computing (CABC) framework and real-time fear emotion generation mechanism using the Ortony, Clore & Collins (OCC) model has also been introduced. Then the proposed fear generation mechanism has been validated using the Validated Agent Based Modeling level of CABC framework using a Virtual Overlay MultiAgent System (VOMAS). Extensive simulation and practical experiments demonstrate that the Enhanced EEC_Agent exhibits the capability to feel different levels of fear, according to different traffic situations and also needs a smaller Stopping Sight Distance (SSD) and Overtaking Sight Distance (OSD) as compared to human drivers. version:1
arxiv-1708-01599 | Agent based Tools for Modeling and Simulation of Self-Organization in Peer-to-Peer, Ad-Hoc and other Complex Networks | http://arxiv.org/abs/1708.01599 | id:1708.01599 author:Muaz A. Niazi, Amir Hussain category:cs.NI cs.AI cs.MA cs.SI  published:2017-08-04 summary:Agent-based modeling and simulation tools provide a mature platform for development of complex simulations. They however, have not been applied much in the domain of mainstream modeling and simulation of computer networks. In this article, we evaluate how and if these tools can offer any value-addition in the modeling & simulation of complex networks such as pervasive computing, large-scale peer-to-peer systems, and networks involving considerable environment and human/animal/habitat interaction. Specifically, we demonstrate the effectiveness of NetLogo - a tool that has been widely used in the area of agent-based social simulation. version:1
arxiv-1708-01611 | Identification of Probabilities | http://arxiv.org/abs/1708.01611 | id:1708.01611 author:Paul M. B. Vitanyi, Nick Chater category:cs.LG cs.AI  published:2017-08-04 summary:Within psychology, neuroscience and artificial intelligence, there has been increasing interest in the proposal that the brain builds probabilistic models of sensory and linguistic input: that is, to infer a probabilistic model from a sample. The practical problems of such inference are substantial: the brain has limited data and restricted computational resources. But there is a more fundamental question: is the problem of inferring a probabilistic model from a sample possible even in principle? We explore this question and find some surprisingly positive and general results. First, for a broad class of probability distributions characterised by computability restrictions, we specify a learning algorithm that will almost surely identify a probability distribution in the limit given a finite i.i.d. sample of sufficient but unknown length. This is similarly shown to hold for sequences generated by a broad class of Markov chains, subject to computability assumptions. The technical tool is the strong law of large numbers. Second, for a large class of dependent sequences, we specify an algorithm which identifies in the limit a computable measure for which the sequence is typical, in the sense of Martin-Lof (there may be more than one such measure). The technical tool is the theory of Kolmogorov complexity. We analyse the associated predictions in both cases. We also briefly consider special cases, including language learning, and wider theoretical implications for psychology. version:1
arxiv-1708-02271 | Implementation of Torque Controller for Brushless Motors on the Omni-directional Wheeled Mobile Robot | http://arxiv.org/abs/1708.02271 | id:1708.02271 author:Piyamate Wasuntapichaikul, Kanjanapan Sukvichai, Yodyium Tipsuwan category:cs.RO  published:2017-08-04 summary:The major issue for the wheeled mobile robot is the low level controller gains tuning up especially in the robot competition. The floor surface can be damaged by the robot wheels during the competition, therefore the surface coefficient can be changed over time. PI gains have to be tuned before every match along the competition. In this research, the torque controller is defined and implemented in order to solve this problem. Torque controller consists of a PI controller for the robot wheel's angular velocity and a dynamic equation of brushless motor. The motor dynamics can be derived from the energy conservation law. Three different carpets, which have the different friction coefficients, are used in the experiments. The robot wheel's angular velocity profiles are generated from the robot kinematics with different initial conditions. The output paths of the robot with the torque controller are compared with the output paths of the robot with regular PI controller when the same wheel angular velocity profiles are applied. The results show that the torque controller can provide a better robot path than the normal PI controller. version:1
arxiv-1708-01476 | LIKWID Monitoring Stack: A flexible framework enabling job specific performance monitoring for the masses | http://arxiv.org/abs/1708.01476 | id:1708.01476 author:Thomas Röhl, Jan Eitzinger, Georg Hager, Gerhard Wellein category:cs.DC  published:2017-08-04 summary:System monitoring is an established tool to measure the utilization and health of HPC systems. Usually system monitoring infrastructures make no connection to job information and do not utilize hardware performance monitoring (HPM) data. To increase the efficient use of HPC systems automatic and continuous performance monitoring of jobs is an essential component. It can help to identify pathological cases, provides instant performance feedback to the users, offers initial data to judge on the optimization potential of applications and helps to build a statistical foundation about application specific system usage. The LIKWID monitoring stack is a modular framework build on top of the LIKWID tools library. It aims on enabling job specific performance monitoring using HPM data, system metrics and application-level data for small to medium sized commodity clusters. Moreover, it is designed to integrate in existing monitoring infrastructures to speed up the change from pure system monitoring to job-aware monitoring. version:1
arxiv-1708-01462 | How Amdahl's low restricts supercomputer applications and building ever bigger supercomputers | http://arxiv.org/abs/1708.01462 | id:1708.01462 author:János Végh category:cs.DC  published:2017-08-04 summary:This paper reinterprets Amdahl's law in terms of execution time and applies this simple model to supercomputing. The systematic discussion results in practical formulas enabling to calculate expected running time using large number of processors from experimental runs using low number of processors, delivers a quantitative measure of computational efficiency of supercomputing applications. Through separating non-parallelizable contribution to fractions according to their origin, Amdahl's law enables to derive a timeline for supercomputers (quite similar to Moore's law) and describes why Amdahl's law limits the size of supercomputers. The paper validates that Amdahl's 50-years old model (with slight extension) correctly describes the performance limitations of the present supercomputers. Using some simple and reasonable assumptions, the absolute performance bound of supercomputers is concluded, furthermore that serious enhancements are still necessary to achieve the exaFLOPS dream value. version:1
arxiv-1708-01419 | DoKnowMe: Towards a Domain Knowledge-driven Methodology for Performance Evaluation | http://arxiv.org/abs/1708.01419 | id:1708.01419 author:Zheng Li, Liam O'Brien, Maria Kihl category:cs.DC cs.PF  published:2017-08-04 summary:Software engineering considers performance evaluation to be one of the key portions of software quality assurance. Unfortunately, there seems to be a lack of standard methodologies for performance evaluation even in the scope of experimental computer science. Inspired by the concept of "instantiation" in object-oriented programming, we distinguish the generic performance evaluation logic from the distributed and ad-hoc relevant studies, and develop an abstract evaluation methodology (by analogy of "class") we name Domain Knowledge-driven Methodology (DoKnowMe). By replacing five predefined domain-specific knowledge artefacts, DoKnowMe could be instantiated into specific methodologies (by analogy of "object") to guide evaluators in performance evaluation of different software and even computing systems. We also propose a generic validation framework with four indicators (i.e.~usefulness, feasibility, effectiveness and repeatability), and use it to validate DoKnowMe in the Cloud services evaluation domain. Given the positive and promising validation result, we plan to integrate more common evaluation strategies to improve DoKnowMe and further focus on the performance evaluation of Cloud autoscaler systems. version:1
arxiv-1708-01414 | Boosting Metrics for Cloud Services Evaluation -- The Last Mile of Using Benchmark Suites | http://arxiv.org/abs/1708.01414 | id:1708.01414 author:Zheng Li, Liam O'Brien, Rainbow Cai, He Zhang category:cs.DC cs.PF  published:2017-08-04 summary:Benchmark suites are significant for evaluating various aspects of Cloud services from a holistic view. However, there is still a gap between using benchmark suites and achieving holistic impression of the evaluated Cloud services. Most Cloud service evaluation work intended to report individual benchmarking results without delivering summary measures. As a result, it could be still hard for customers with such evaluation reports to understand an evaluated Cloud service from a global perspective. Inspired by the boosting approaches to machine learning, we proposed the concept Boosting Metrics to represent all the potential approaches that are able to integrate a suite of benchmarking results. This paper introduces two types of preliminary boosting metrics, and demonstrates how the boosting metrics can be used to supplement primary measures of individual Cloud service features. In particular, boosting metrics can play a summary Response role in applying experimental design to Cloud services evaluation. Although the concept Boosting Metrics was refined based on our work in the Cloud Computing domain, we believe it can be easily adapted to the evaluation work of other computing paradigms. version:1
arxiv-1708-01413 | Distributed Solution of Large-Scale Linear Systems via Accelerated Projection-Based Consensus | http://arxiv.org/abs/1708.01413 | id:1708.01413 author:Navid Azizan-Ruhi, Farshad Lahouti, Salman Avestimehr, Babak Hassibi category:cs.LG cs.DC math.NA  published:2017-08-04 summary:Solving a large-scale system of linear equations is a key step at the heart of many algorithms in machine learning, scientific computing, and beyond. When the problem dimension is large, computational and/or memory constraints make it desirable, or even necessary, to perform the task in a distributed fashion. In this paper, we consider a common scenario in which a taskmaster intends to solve a large-scale system of linear equations by distributing subsets of the equations among a number of computing machines/cores. We propose an accelerated distributed consensus algorithm, in which at each iteration every machine updates its solution by adding a scaled version of the projection of an error signal onto the nullspace of its system of equations, and where the taskmaster conducts an averaging over the solutions with momentum. The convergence behavior of the proposed algorithm is analyzed in detail and analytically shown to compare favorably with the convergence rate of alternative distributed methods, namely distributed gradient descent, distributed versions of Nesterov's accelerated gradient descent and heavy-ball method, the Cimmino method, and ADMM. On randomly chosen linear systems, as well as on real-world data sets, the proposed method offers significant speed-up relative to all the aforementioned methods. Finally, our analysis suggests a novel variation of the distributed heavy-ball method, which employs a particular distributed preconditioning, and which achieves the same theoretical convergence rate as the proposed consensus-based method. version:1
arxiv-1708-01412 | On Evaluating Commercial Cloud Services: A Systematic Review | http://arxiv.org/abs/1708.01412 | id:1708.01412 author:Zheng Li, He Zhang, Liam O'Brien, Rainbow Cai, Shayne Flint category:cs.DC cs.PF  published:2017-08-04 summary:Background: Cloud Computing is increasingly booming in industry with many competing providers and services. Accordingly, evaluation of commercial Cloud services is necessary. However, the existing evaluation studies are relatively chaotic. There exists tremendous confusion and gap between practices and theory about Cloud services evaluation. Aim: To facilitate relieving the aforementioned chaos, this work aims to synthesize the existing evaluation implementations to outline the state-of-the-practice and also identify research opportunities in Cloud services evaluation. Method: Based on a conceptual evaluation model comprising six steps, the Systematic Literature Review (SLR) method was employed to collect relevant evidence to investigate the Cloud services evaluation step by step. Results: This SLR identified 82 relevant evaluation studies. The overall data collected from these studies essentially represent the current practical landscape of implementing Cloud services evaluation, and in turn can be reused to facilitate future evaluation work. Conclusions: Evaluation of commercial Cloud services has become a world-wide research topic. Some of the findings of this SLR identify several research gaps in the area of Cloud services evaluation (e.g., the Elasticity and Security evaluation of commercial Cloud services could be a long-term challenge), while some other findings suggest the trend of applying commercial Cloud services (e.g., compared with PaaS, IaaS seems more suitable for customers and is particularly important in industry). This SLR study itself also confirms some previous experiences and reveals new Evidence-Based Software Engineering (EBSE) lessons. version:1
arxiv-1708-01401 | Spot Pricing in the Cloud Ecosystem: A Comparative Investigation | http://arxiv.org/abs/1708.01401 | id:1708.01401 author:Zheng Li, He Zhang, Liam O'Brien, Shu Jiang, You Zhou, Maria Kihl, Rajiv Ranjan category:cs.DC  published:2017-08-04 summary:Background: Spot pricing is considered as a significant supplement for building a full-fledged market economy for the Cloud ecosystem. However, it seems that both providers and consumers are still hesitating to enter the Cloud spot market. The relevant academic community also has conflicting opinions about Cloud spot pricing in terms of revenue generation. Aim: This work aims to systematically identify, assess, synthesize and report the published evidence in favor of or against spot-price scheme compared with fixed-price scheme of Cloud computing, so as to help relieve the aforementioned conflict. Method: We employed the systematic literature review (SLR) method to collect and investigate the empirical studies of Cloud spot pricing indexed by major electronic libraries. Results: This SLR identified 61 primary studies that either delivered discussions or conducted experiments to perform comparison between spot pricing and fixed pricing in the Cloud domain. The reported benefits and limitations were summarized to facilitate cost-benefit analysis of being a Cloud spot pricing player, while four types of theories were distinguished to help both researchers and practitioners better understand the Cloud spot market. Conclusions: This SLR shows that the academic community strongly advocates the emerging Cloud spot market. Although there is still a lack of practical and easily deployable market-driven mechanisms, the overall findings of our work indicate that spot pricing plays a promising role in the sustainability of Cloud resource exploitation. version:1
arxiv-1708-01397 | Using a Predator-Prey Model to Explain Variations of Cloud Spot Price | http://arxiv.org/abs/1708.01397 | id:1708.01397 author:Zheng Li, William Tarneberg, Maria Kihl, Anders Robertsson category:cs.DC cs.CE  published:2017-08-04 summary:The spot pricing scheme has been considered to be resource-efficient for providers and cost-effective for consumers in the Cloud market. Nevertheless, unlike the static and straightforward strategies of trading on-demand and reserved Cloud services, the market-driven mechanism for trading spot service would be complicated for both implementation and understanding. The largely invisible market activities and their complex interactions could especially make Cloud consumers hesitate to enter the spot market. To reduce the complexity in understanding the Cloud spot market, we decided to reveal the backend information behind spot price variations. Inspired by the methodology of reverse engineering, we developed a Predator-Prey model that can simulate the interactions between demand and resource based on the visible spot price traces. The simulation results have shown some basic regular patterns of market activities with respect to Amazon's spot instance type m3.large. Although the findings of this study need further validation by using practical data, our work essentially suggests a promising approach (i.e.~using a Predator-Prey model) to investigate spot market activities. version:1
arxiv-1708-01391 | On a Feedback Control-based Mechanism of Bidding for Cloud Spot Service | http://arxiv.org/abs/1708.01391 | id:1708.01391 author:Zheng Li, Maria Kihl, Anders Robertsson category:cs.DC cs.CE  published:2017-08-04 summary:As a cost-effective option for Cloud consumers, spot service has been considered to be a significant supplement for building a full-fledged market economy for the Cloud ecosystem. However, unlike the static and straightforward way of trading on-demand and reserved Cloud services, the market-driven regulations of employing spot service could be too complicated for Cloud consumers to comprehensively understand. In particular, it would be both difficult and tedious for potential consumers to determine suitable bids from time to time. To reduce the complexity in applying spot resources, we propose to use a feedback control to help make bidding decisions. Based on an arccotangent-function-type system model, our novel bidding mechanism imitates fuzzy and intuitive human activities to refine and issue new bids according to previous errors. The validation is conducted by using Amazon's historical spot price trace to perform a set of simulations and comparisons. The result shows that the feedback control-based mechanism obtains a better trade-off between bidding rationality and success rate than the other five comparable strategies. Although this mechanism is only for black-box bidding (price prediction) at this current stage, it can be conveniently and gradually upgraded to take into account external constraints in the future. version:1
arxiv-1708-01388 | Performance Overhead Comparison between Hypervisor and Container based Virtualization | http://arxiv.org/abs/1708.01388 | id:1708.01388 author:Zheng Li, Maria Kihl, Qinghua Lu, Jens A. Andersson category:cs.DC  published:2017-08-04 summary:The current virtualization solution in the Cloud widely relies on hypervisor-based technologies. Along with the recent popularity of Docker, the container-based virtualization starts receiving more attention for being a promising alternative. Since both of the virtualization solutions are not resource-free, their performance overheads would lead to negative impacts on the quality of Cloud services. To help fundamentally understand the performance difference between these two types of virtualization solutions, we use a physical machine with "just-enough" resource as a baseline to investigate the performance overhead of a standalone Docker container against a standalone virtual machine (VM). With findings contrary to the related work, our evaluation results show that the virtualization's performance overhead could vary not only on a feature-by-feature basis but also on a job-to-job basis. Although the container-based solution is undoubtedly lightweight, the hypervisor-based technology does not come with higher performance overhead in every case. For example, Docker containers particularly exhibit lower QoS in terms of storage transaction speed. version:1
arxiv-1708-04134 | A Measure for Dialog Complexity and its Application in Streamlining Service Operations | http://arxiv.org/abs/1708.04134 | id:1708.04134 author:Q Vera Liao, Biplav Srivastava, Pavan Kapanipathi category:cs.CL cs.AI I.2.7  published:2017-08-04 summary:Dialog is a natural modality for interaction between customers and businesses in the service industry. As customers call up the service provider, their interactions may be routine or extraordinary. We believe that these interactions, when seen as dialogs, can be analyzed to obtain a better understanding of customer needs and how to efficiently address them. We introduce the idea of a dialog complexity measure to characterize multi-party interactions, propose a general data-driven method to calculate it, use it to discover insights in public and enterprise dialog datasets, and demonstrate its beneficial usage in facilitating better handling of customer requests and evaluating service agents. version:1
arxiv-1708-01365 | Load Balancing using Hilbert Space-filling Curves for Parallel Reservoir Simulations | http://arxiv.org/abs/1708.01365 | id:1708.01365 author:Hui Liu, Kun Wang, Bo Yang, Min Yang, Ruijian He, Lihua Shen, He Zhong, Zhangxin Chen category:cs.DC  published:2017-08-04 summary:The goal of load balancing (grid partitioning) is to minimize overall computations and communications, and to make sure that all processors have a similar workload. Geometric methods divide a grid by using a location of a cell while topological methods work with connectivity of cells, which is generally described as a graph. This paper introduces a Hilbert space-filling curve method. A space-filling curve is a continuous curve and defines a map between a one-dimensional space and a multi-dimensional space. A Hilbert space-filling curve is one special space-filling curve discovered by Hilbert and has many useful characteristics, such as good locality, which means that two objects that are close to each other in a multi-dimensional space are also close to each other in a one dimensional space. This property can model communications in grid-based parallel applications. The idea of the Hilbert space-filling curve method is to map a computational domain into a one-dimensional space, partition the one-dimensional space to certain intervals, and assign all cells in a same interval to a MPI. To implement a load balancing method, a mapping kernel is required to convert high-dimensional coordinates to a scalar value and an efficient one-dimensional partitioning module that divides a one-dimensional space and makes sure that all intervals have a similar workload. The Hilbert space-filling curve method is compared with ParMETIS, a famous graph partitioning package. The results show that our Hilbert space-filling curve method has good partition quality. It has been applied to grids with billions of cells, and linear scalability has been obtained on IBM Blue Gene/Q. version:1
arxiv-1708-01354 | CASSL: Curriculum Accelerated Self-Supervised Learning | http://arxiv.org/abs/1708.01354 | id:1708.01354 author:Adithyavairavan Murali, Lerrel Pinto, Dhiraj Gandhi, Abhinav Gupta category:cs.RO cs.CV cs.LG  published:2017-08-04 summary:Recent self-supervised learning approaches focus on using a few thousand data points to learn policies for high-level, low-dimensional action spaces. However, scaling this framework for high-dimensional control require either scaling up the data collection efforts or using a clever sampling strategy for training. We present a novel approach - Curriculum Accelerated Self-Supervised Learning (CASSL) - to train policies that map visual information to high-level, higher- dimensional action spaces. CASSL orders the sampling of training data based on control dimensions: the learning and sampling are focused on few control parameters before other parameters. The right curriculum for learning is suggested by variance-based global sensitivity analysis of the control space. We apply our CASSL framework to learning how to grasp using an adaptive, underactuated multi-fingered gripper, a challenging system to control. Our experimental results indicate that CASSL provides significant improvement and generalization compared to baseline methods such as staged curriculum learning (8% increase) and complete end-to-end learning with random exploration (14% improvement) tested on a set of novel objects. version:1
arxiv-1708-01341 | AccurateML: Information-aggregation-based Approximate Processing for Fast and Accurate Machine Learning on MapReduce | http://arxiv.org/abs/1708.01341 | id:1708.01341 author:Rui Han, Fan Zhang, Zhentao Wang category:cs.DC  published:2017-08-04 summary:The growing demands of processing massive datasets have promoted irresistible trends of running machine learning applications on MapReduce. When processing large input data, it is often of greater values to produce fast and accurate enough approximate results than slow exact results. Existing techniques produce approximate results by processing parts of the input data, thus incurring large accuracy losses when using short job execution times, because all the skipped input data potentially contributes to result accuracy. We address this limitation by proposing AccurateML that aggregates information of input data in each map task to create small aggregated data points. These aggregated points enable all map tasks producing initial outputs quickly to save computation times and decrease the outputs' size to reduce communication times. Our approach further identifies the parts of input data most related to result accuracy, thus first using these parts to improve the produced outputs to minimize accuracy losses. We evaluated AccurateML using real machine learning applications and datasets. The results show: (i) it reduces execution times by 30 times with small accuracy losses compared to exact results; (ii) when using the same execution times, it achieves 2.71 times reductions in accuracy losses compared to existing approximate processing techniques. version:1
arxiv-1411-4186 | Linear Time Average Consensus on Fixed Graphs and Implications for Decentralized Optimization and Multi-Agent Control | http://arxiv.org/abs/1411.4186 | id:1411.4186 author:Alex Olshevsky category:math.OC cs.DC cs.SY  published:2014-11-15 summary:We describe a protocol for the average consensus problem on any fixed undirected graph whose convergence time scales linearly in the total number nodes $n$. The protocol is completely distributed, with the exception of requiring all nodes to know the same upper bound $U$ on the total number of nodes which is correct within a constant multiplicative factor. We next discuss applications of this protocol to problems in multi-agent control connected to the consensus problem. In particular, we describe protocols for formation maintenance and leader-following with convergence times which also scale linearly with the number of nodes. Finally, we develop a distributed protocol for minimizing an average of (possibly nondifferentiable) convex functions $ (1/n) \sum_{i=1}^n f_i(\theta)$, in the setting where only node $i$ in an undirected, connected graph knows the function $f_i(\theta)$. Under the same assumption about all nodes knowing $U$, and additionally assuming that the subgradients of each $f_i(\theta)$ have absolute values upper bounded by some constant $L$ known to the nodes, we show that after $T$ iterations our protocol has error which is $O(L \sqrt{n/T})$. version:7
arxiv-1708-01306 | MPI Streams for HPC Applications | http://arxiv.org/abs/1708.01306 | id:1708.01306 author:Ivy Bo Peng, Stefano Markidis, Roberto Gioiosa, Gokcen Kestor, Erwin Laure category:cs.DC  published:2017-08-03 summary:Data streams are a sequence of data flowing between source and destination processes. Streaming is widely used for signal, image and video processing for its efficiency in pipelining and effectiveness in reducing demand for memory. The goal of this work is to extend the use of data streams to support both conventional scientific applications and emerging data analytic applications running on HPC platforms. We introduce an extension called MPIStream to the de-facto programming standard on HPC, MPI. MPIStream supports data streams either within a single application or among multiple applications. We present three use cases using MPI streams in HPC applications together with their parallel performance. We show the convenience of using MPI streams to support the needs from both traditional HPC and emerging data analytics applications running on supercomputers. version:1
arxiv-1708-01304 | Preparing HPC Applications for the Exascale Era: A Decoupling Strategy | http://arxiv.org/abs/1708.01304 | id:1708.01304 author:Ivy Bo Peng, Roberto Gioiosa, Gokcen Kestor, Erwin Laure, Stefano Markidis category:cs.DC  published:2017-08-03 summary:Production-quality parallel applications are often a mixture of diverse operations, such as computation- and communication-intensive, regular and irregular, tightly coupled and loosely linked operations. In conventional construction of parallel applications, each process performs all the operations, which might result inefficient and seriously limit scalability, especially at large scale. We propose a decoupling strategy to improve the scalability of applications running on large-scale systems. Our strategy separates application operations onto groups of processes and enables a dataflow processing paradigm among the groups. This mechanism is effective in reducing the impact of load imbalance and increases the parallel efficiency by pipelining multiple operations. We provide a proof-of-concept implementation using MPI, the de-facto programming system on current supercomputers. We demonstrate the effectiveness of this strategy by decoupling the reduce, particle communication, halo exchange and I/O operations in a set of scientific and data-analytics applications. A performance evaluation on 8,192 processes of a Cray XC40 supercomputer shows that the proposed approach can achieve up to 4x performance improvement. version:1
arxiv-1708-01159 | Using Graph Properties to Speed-up GPU-based Graph Traversal: A Model-driven Approach | http://arxiv.org/abs/1708.01159 | id:1708.01159 author:Merijn Verstraaten, Ana Lucia Varbanescu, Cees de Laat category:cs.DC  published:2017-08-03 summary:While it is well-known and acknowledged that the performance of graph algorithms is heavily dependent on the input data, there has been surprisingly little research to quantify and predict the impact the graph structure has on performance. Parallel graph algorithms, running on many-core systems such as GPUs, are no exception: most research has focused on how to efficiently implement and tune different graph operations on a specific GPU. However, the performance impact of the input graph has only been taken into account indirectly as a result of the graphs used to benchmark the system. In this work, we present a case study investigating how to use the properties of the input graph to improve the performance of the breadth-first search (BFS) graph traversal. To do so, we first study the performance variation of 15 different BFS implementations across 248 graphs. Using this performance data, we show that significant speed-up can be achieved by combining the best implementation for each level of the traversal. To make use of this data-dependent optimization, we must correctly predict the relative performance of algorithms per graph level, and enable dynamic switching to the optimal algorithm for each level at runtime. We use the collected performance data to train a binary decision tree, to enable high-accuracy predictions and fast switching. We demonstrate empirically that our decision tree is both fast enough to allow dynamic switching between implementations, without noticeable overhead, and accurate enough in its prediction to enable significant BFS speedup. We conclude that our model-driven approach (1) enables BFS to outperform state of the art GPU algorithms, and (2) can be adapted for other BFS variants, other algorithms, or more specific datasets. version:1
arxiv-1708-01135 | Long range forces in a performance portable Molecular Dynamics framework | http://arxiv.org/abs/1708.01135 | id:1708.01135 author:William R. Saunders, James Grant, Eike H. Müller category:cs.DC cs.SE physics.comp-ph  published:2017-08-03 summary:Molecular Dynamics (MD) codes predict the fundamental properties of matter by following the trajectories of a collection of interacting model particles. To exploit diverse modern manycore hardware, efficient codes must use all available parallelism. At the same time they need to be portable and easily extendible by the domain specialist (physicist/chemist) without detailed knowledge of this hardware. To address this challenge, we recently described a new Domain Specific Language (DSL) for the development of performance portable MD codes based on a "Separation of Concerns": a Python framework automatically generates efficient parallel code for a range of target architectures. Electrostatic interactions between charged particles are important in many physical systems and often dominate the runtime. Here we discuss the inclusion of long-range interaction algorithms in our code generation framework. These algorithms require global communications and careful consideration has to be given to any impact on parallel scalability. We implemented an Ewald summation algorithm for electrostatic forces, present scaling comparisons for different system sizes and compare to the performance of existing codes. We also report on further performance optimisations delivered with OpenMP shared memory parallelism. version:1
arxiv-1708-01104 | A glass-box interactive machine learning approach for solving NP-hard problems with the human-in-the-loop | http://arxiv.org/abs/1708.01104 | id:1708.01104 author:Andreas Holzinger, Markus Plass, Katharina Holzinger, Gloria Cerasela Crisan, Camelia-M. Pintea, Vasile Palade category:cs.AI stat.ML  published:2017-08-03 summary:The goal of Machine Learning to automatically learn from data, extract knowledge and to make decisions without any human intervention. Such automatic (aML) approaches show impressive success. Recent results even demonstrate intriguingly that deep learning applied for automatic classification of skin lesions is on par with the performance of dermatologists, yet outperforms the average. As human perception is inherently limited, such approaches can discover patterns, e.g. that two objects are similar, in arbitrarily high-dimensional spaces what no human is able to do. Humans can deal only with limited amounts of data, whilst big data is beneficial for aML; however, in health informatics, we are often confronted with a small number of data sets, where aML suffer of insufficient training samples and many problems are computationally hard. Here, interactive machine learning (iML) may be of help, where a human-in-the-loop contributes to reduce the complexity of NP-hard problems. A further motivation for iML is that standard black-box approaches lack transparency, hence do not foster trust and acceptance of ML among end-users. Rising legal and privacy aspects, e.g. with the new European General Data Protection Regulations, make black-box approaches difficult to use, because they often are not able to explain why a decision has been made. In this paper, we present some experiments to demonstrate the effectiveness of the human-in-the-loop approach, particularly in opening the black-box to a glass-box and thus enabling a human directly to interact with an learning algorithm. We selected the Ant Colony Optimization framework, and applied it on the Traveling Salesman Problem, which is a good example, due to its relevance for health informatics, e.g. for the study of protein folding. From studies of how humans extract so much from so little data, fundamental ML-research also may benefit. version:1
arxiv-1708-01065 | Reader-Aware Multi-Document Summarization: An Enhanced Model and The First Dataset | http://arxiv.org/abs/1708.01065 | id:1708.01065 author:Piji Li, Lidong Bing, Wai Lam category:cs.CL cs.AI  published:2017-08-03 summary:We investigate the problem of reader-aware multi-document summarization (RA-MDS) and introduce a new dataset for this problem. To tackle RA-MDS, we extend a variational auto-encodes (VAEs) based MDS framework by jointly considering news documents and reader comments. To conduct evaluation for summarization performance, we prepare a new dataset. We describe the methods for data collection, aspect annotation, and summary writing as well as scrutinizing by experts. Experimental results show that reader comments can improve the summarization performance, which also demonstrates the usefulness of the proposed dataset. The annotated dataset for RA-MDS is available online. version:1
arxiv-1708-01035 | Detection of Abnormal Input-Output Associations | http://arxiv.org/abs/1708.01035 | id:1708.01035 author:Charmgil Hong, Siqi Liu, Milos Hauskrecht category:cs.AI  published:2017-08-03 summary:We study a novel outlier detection problem that aims to identify abnormal input-output associations in data, whose instances consist of multi-dimensional input (context) and output (responses) pairs. We present our approach that works by analyzing data in the conditional (input--output) relation space, captured by a decomposable probabilistic model. Experimental results demonstrate the ability of our approach in identifying multivariate conditional outliers. version:1
arxiv-1708-00965 | Dual Quadrics from Object Detection BoundingBoxes as Landmark Representations in SLAM | http://arxiv.org/abs/1708.00965 | id:1708.00965 author:Niko Sünderhauf, Michael Milford category:cs.RO  published:2017-08-03 summary:Research in Simultaneous Localization And Mapping (SLAM) is increasingly moving towards richer world representations involving objects and high level features that enable a semantic model of the world for robots, potentially leading to a more meaningful set of robot-world interactions. Many of these advances are grounded in state-of-the-art computer vision techniques primarily developed in the context of image-based benchmark datasets, leaving several challenges to be addressed in adapting them for use in robotics. In this paper, we derive a formulation for Simultaneous Localization And Mapping (SLAM) that uses dual quadrics as 3D landmark representations, and show how 2D bounding boxes (such as those typically obtained from visual object detection systems) can directly constrain the quadric parameters. Our paper demonstrates how to jointly estimate the robot pose and dual quadric parameters in factor graph based SLAM with a general perspective camera, and covers the use-cases of a robot moving with a monocular camera with and without the availability of additional depth information. version:1
arxiv-1609-07849 | Meaningful Maps With Object-Oriented Semantic Mapping | http://arxiv.org/abs/1609.07849 | id:1609.07849 author:Niko Sünderhauf, Trung T. Pham, Yasir Latif, Michael Milford, Ian Reid category:cs.RO  published:2016-09-26 summary:For intelligent robots to interact in meaningful ways with their environment, they must understand both the geometric and semantic properties of the scene surrounding them. The majority of research to date has addressed these mapping challenges separately, focusing on either geometric or semantic mapping. In this paper we address the problem of building environmental maps that include both semantically meaningful, object-level entities and point- or mesh-based geometrical representations. We simultaneously build geometric point cloud models of previously unseen instances of known object classes and create a map that contains these object models as central entities. Our system leverages sparse, feature-based RGB-D SLAM, image-based deep-learning object detection and 3D unsupervised segmentation. version:2
arxiv-1607-06044 | Tail Index for a Distributed Storage System with Pareto File Size Distribution | http://arxiv.org/abs/1607.06044 | id:1607.06044 author:Vaneet Aggarwal, Tian Lan category:cs.IT cs.DC cs.NI math.IT  published:2016-07-20 summary:Distributed storage systems often employ erasure codes to achieve high data reliability while attaining space efficiency. Such storage systems are known to be susceptible to long tails in response time. It has been shown that in modern online applications such as Bing, Facebook, and Amazon, the long tail of latency is of particular concern, with $99.9$th percentile response times that are orders of magnitude worse than the mean. Taming tail latency is very challenging in erasure-coded storage systems since quantify tail latency (i.e., $x$th-percentile latency for arbitrary $x\in[0,1]$) has been a long-standing open problem. In this paper, we propose a mathematical model to quantify {\em tail index} of service latency for arbitrary erasure-coded storage systems, by characterizing the asymptotic behavior of latency distribution tails. When file size has a heavy tailed distribution, we find tail index, defined as the exponent at which latency tail probability diminishes to zero, in closed-form, and further show that a family of probabilistic scheduling algorithms are (asymptotically) optimal since they are able to achieve the exact tail index. version:2
arxiv-1708-00940 | An Energy Minimization Approach to 3D Non-Rigid Deformable Surface Estimation Using RGBD Data | http://arxiv.org/abs/1708.00940 | id:1708.00940 author:Bryan Willimon, Steven Hickson, Ian Walker, Stan Birchfield category:cs.CV cs.RO  published:2017-08-02 summary:We propose an algorithm that uses energy mini- mization to estimate the current configuration of a non-rigid object. Our approach utilizes an RGBD image to calculate corresponding SURF features, depth, and boundary informa- tion. We do not use predetermined features, thus enabling our system to operate on unmodified objects. Our approach relies on a 3D nonlinear energy minimization framework to solve for the configuration using a semi-implicit scheme. Results show various scenarios of dynamic posters and shirts in different configurations to illustrate the performance of the method. In particular, we show that our method is able to estimate the configuration of a textureless nonrigid object with no correspondences available. version:1
arxiv-1708-00171 | PROBE-GK: Predictive Robust Estimation using Generalized Kernels | http://arxiv.org/abs/1708.00171 | id:1708.00171 author:Valentin Peretroukhin, William Vega-Brown, Nicholas Roy, Jonathan Kelly category:cs.RO cs.CV  published:2017-08-01 summary:Many algorithms in computer vision and robotics make strong assumptions about uncertainty, and rely on the validity of these assumptions to produce accurate and consistent state estimates. In practice, dynamic environments may degrade sensor performance in predictable ways that cannot be captured with static uncertainty parameters. In this paper, we employ fast nonparametric Bayesian inference techniques to more accurately model sensor uncertainty. By setting a prior on observation uncertainty, we derive a predictive robust estimator, and show how our model can be learned from sample images, both with and without knowledge of the motion used to generate the data. We validate our approach through Monte Carlo simulations, and report significant improvements in localization accuracy relative to a fixed noise model in several settings, including on synthetic data, the KITTI dataset, and our own experimental platform. version:2
arxiv-1708-00174 | PROBE: Predictive Robust Estimation for Visual-Inertial Navigation | http://arxiv.org/abs/1708.00174 | id:1708.00174 author:Valentin Peretroukhin, Lee Clement, Matthew Giamou, Jonathan Kelly category:cs.RO cs.CV  published:2017-08-01 summary:Navigation in unknown, chaotic environments continues to present a significant challenge for the robotics community. Lighting changes, self-similar textures, motion blur, and moving objects are all considerable stumbling blocks for state-of-the-art vision-based navigation algorithms. In this paper we present a novel technique for improving localization accuracy within a visual-inertial navigation system (VINS). We make use of training data to learn a model for the quality of visual features with respect to localization error in a given environment. This model maps each visual observation from a predefined prediction space of visual-inertial predictors onto a scalar weight, which is then used to scale the observation covariance matrix. In this way, our model can adjust the influence of each observation according to its quality. We discuss our choice of predictors and report substantial reductions in localization error on 4 km of data from the KITTI dataset, as well as on experimental datasets consisting of 700 m of indoor and outdoor driving on a small ground rover equipped with a Skybotix VI-Sensor. version:2
arxiv-1706-08840 | Gradient Episodic Memory for Continual Learning | http://arxiv.org/abs/1706.08840 | id:1706.08840 author:David Lopez-Paz, Marc'Aurelio Ranzato category:cs.LG cs.AI  published:2017-06-26 summary:One major obstacle towards artificial intelligence is the poor ability of models to quickly solve new problems, without forgetting previously acquired knowledge. To better understand this issue, we study the problem of continual learning, where the model observes, once and one by one, examples concerning a sequence of tasks. First, we propose a set of metrics to evaluate models learning over a continuum of data. These metrics characterize models not only by their test accuracy, but also in terms of their ability to transfer knowledge across tasks. Second, we propose a model for continual learning, called Gradient of Episodic Memory (GEM), which alleviates forgetting while allowing beneficial transfer of knowledge to previous tasks. Our experiments on variants of MNIST and CIFAR-100 demonstrate the strong performance of GEM when compared to the state-of-the-art. version:4
arxiv-1708-00922 | Improved GelSight Tactile Sensor for Measuring Geometry and Slip | http://arxiv.org/abs/1708.00922 | id:1708.00922 author:Siyuan Dong, Wenzhen Yuan, Edward Adelson category:cs.RO  published:2017-08-02 summary:A GelSight sensor uses an elastomeric slab covered with a reflective membrane to measure tactile signals. It measures the 3D geometry and contact force information with high spacial resolution, and successfully helped many challenging robot tasks. A previous sensor, based on a semi-specular membrane, produces high resolution but with limited geometry accuracy. In this paper, we describe a new design of GelSight for robot gripper, using a Lambertian membrane and new illumination system, which gives greatly improved geometric accuracy while retaining the compact size. We demonstrate its use in measuring surface normals and reconstructing height maps using photometric stereo. We also use it for the task of slip detection, using a combination of information about relative motions on the membrane surface and the shear distortions. Using a robotic arm and a set of 37 everyday objects with varied properties, we find that the sensor can detect translational and rotational slip in general cases, and can be used to improve the stability of the grasp. version:1
arxiv-1708-00898 | Seating Assignment Using Constrained Signed Spectral Clustering | http://arxiv.org/abs/1708.00898 | id:1708.00898 author:João Sedoc, Aline Normoyle category:cs.DC cs.SI  published:2017-08-02 summary:In this paper, we present a novel method for constrained cluster size signed spectral clustering which allows us to subdivide large groups of people based on their relationships. In general, signed clustering only requires K hard clusters and does not constrain the cluster sizes. We extend signed clustering to include cluster size constraints. Using an example of seating assignment, we efficiently find groups of people with high social affinity while mitigating awkward social interaction between people who dislike each other. version:1
arxiv-1708-00339 | Attend and Predict: Understanding Gene Regulation by Selective Attention on Chromatin | http://arxiv.org/abs/1708.00339 | id:1708.00339 author:Ritambhara Singh, Jack Lanchantin, Arshdeep Sekhon, Yanjun Qi category:cs.LG cs.AI cs.NE  published:2017-08-01 summary:The past decade has seen a revolution in genomic technologies that enable a flood of genome-wide profiling of chromatin marks. Recent literature tried to understand gene regulation by predicting gene expression from large-scale chromatin measurements. Two fundamental challenges exist for such learning tasks: (1) genome-wide chromatin signals are spatially structured, high-dimensional and highly modular; and (2) the core aim is to understand what are the relevant factors and how they work together? Previous studies either failed to model complex dependencies among input signals or relied on separate feature analysis to explain the decisions. This paper presents an attention-based deep learning approach; we call AttentiveChrome, that uses a unified architecture to model and to interpret dependencies among chromatin factors for controlling gene regulation. AttentiveChrome uses a hierarchy of multiple Long short-term memory (LSTM) modules to encode the input signals and to model how various chromatin marks cooperate automatically. AttentiveChrome trains two levels of attention jointly with the target prediction, enabling it to attend differentially to relevant marks and to locate important positions per mark. We evaluate the model across 56 different cell types (tasks) in human. Not only is the proposed architecture more accurate, but its attention scores also provide a better interpretation than state-of-the-art feature visualization methods such as saliency map. Code and data are shared at www.deepchrome.org version:2
arxiv-1708-00777 | A Survey on Modeling Energy Consumption of Cloud Applications: Deconstruction, State of the Art, and Trade-off Debates | http://arxiv.org/abs/1708.00777 | id:1708.00777 author:Zheng Li, Selome Tesfatsion, Saeed Bastani, Ahmed Ali-Eldin, Erik Elmroth, Maria Kihl, Rajiv Ranjan category:cs.DC  published:2017-08-02 summary:Given the complexity and heterogeneity in Cloud computing scenarios, the modeling approach has widely been employed to investigate and analyze the energy consumption of Cloud applications, by abstracting real-world objects and processes that are difficult to observe or understand directly. It is clear that the abstraction sacrifices, and usually does not need, the complete reflection of the reality to be modeled. Consequently, current energy consumption models vary in terms of purposes, assumptions, application characteristics and environmental conditions, with possible overlaps between different research works. Therefore, it would be necessary and valuable to reveal the state-of-the-art of the existing modeling efforts, so as to weave different models together to facilitate comprehending and further investigating application energy consumption in the Cloud domain. By systematically selecting, assessing and synthesizing 76 relevant studies, we rationalized and organized over 30 energy consumption models with unified notations. To help investigate the existing models and facilitate future modeling work, we deconstructed the runtime execution and deployment environment of Cloud applications, and identified 18 environmental factors and 12 workload factors that would be influential on the energy consumption. In particular, there are complicated trade-offs and even debates when dealing with the combinational impacts of multiple factors. version:1
arxiv-1708-00754 | Fairness-aware machine learning: a perspective | http://arxiv.org/abs/1708.00754 | id:1708.00754 author:Indre Zliobaite category:cs.AI cs.CY cs.LG stat.ML  published:2017-08-02 summary:Algorithms learned from data are increasingly used for deciding many aspects in our life: from movies we see, to prices we pay, or medicine we get. Yet there is growing evidence that decision making by inappropriately trained algorithms may unintentionally discriminate people. For example, in automated matching of candidate CVs with job descriptions, algorithms may capture and propagate ethnicity related biases. Several repairs for selected algorithms have already been proposed, but the underlying mechanisms how such discrimination happens from the computational perspective are not yet scientifically understood. We need to develop theoretical understanding how algorithms may become discriminatory, and establish fundamental machine learning principles for prevention. We need to analyze machine learning process as a whole to systematically explain the roots of discrimination occurrence, which will allow to devise global machine learning optimization criteria for guaranteed prevention, as opposed to pushing empirical constraints into existing algorithms case-by-case. As a result, the state-of-the-art will advance from heuristic repairing, to proactive and theoretically supported prevention. This is needed not only because law requires to protect vulnerable people. Penetration of big data initiatives will only increase, and computer science needs to provide solid explanations and accountability to the public, before public concerns lead to unnecessarily restrictive regulations against machine learning. version:1
arxiv-1708-00730 | Helping AI to Play Hearthstone: AAIA'17 Data Mining Challenge | http://arxiv.org/abs/1708.00730 | id:1708.00730 author:Andrzej Janusz, Maciej Świechowski, Tomasz Tajmajer category:cs.AI cs.GT  published:2017-08-02 summary:This paper summarizes the AAIA'17 Data Mining Challenge: Helping AI to Play Hearthstone which was held between March 23, and May 15, 2017 at the Knowledge Pit platform. We briefly describe the scope and background of this competition in the context of a more general project related to the development of an AI engine for video games, called Grail. We also discuss the outcomes of this challenge and demonstrate how predictive models for the assessment of player's winning chances can be utilized in a construction of an intelligent agent for playing Hearthstone. Finally, we show a few selected machine learning approaches for modeling state and action values in Hearthstone. We provide evaluation for a few promising solutions that may be used to create more advanced types of agents, especially in conjunction with Monte Carlo Tree Search algorithms. version:1
arxiv-1708-00720 | Bifrost: a Python/C++ Framework for High-Throughput Stream Processing in Astronomy | http://arxiv.org/abs/1708.00720 | id:1708.00720 author:Miles D. Cranmer, Benjamin R. Barsdell, Danny C. Price, Jayce Dowell, Hugh Garsden, Veronica Dike, Tarraneh Eftekhari, Alexander M. Hegedus, Joseph Malins, Kenneth S. Obenberger, Frank Schinzel, Kevin Stovall, Gregory B. Taylor, Lincoln J. Greenhill category:astro-ph.IM cs.DC physics.ins-det  published:2017-08-02 summary:Radio astronomy observatories with high throughput back end instruments require real-time data processing. While computing hardware continues to advance rapidly, development of real-time processing pipelines remains difficult and time-consuming, which can limit scientific productivity. Motivated by this, we have developed Bifrost: an open-source software framework for rapid pipeline development. Bifrost combines a high-level Python interface with highly efficient reconfigurable data transport and a library of computing blocks for CPU and GPU processing. The framework is generalizable, but initially it emphasizes the needs of high-throughput radio astronomy pipelines, such as the ability to process data buffers as if they were continuous streams, the capacity to partition processing into distinct data sequences (e.g., separate observations), and the ability to extract specific intervals from buffered data. Computing blocks in the library are designed for applications such as interferometry, pulsar dedispersion and timing, and transient search pipelines. We describe the design and implementation of the Bifrost framework and demonstrate its use as the backbone in the correlation and beamforming back end of the Long Wavelength Array station in the Sevilleta National Wildlife Refuge, NM. version:1
arxiv-1708-00675 | Optical Target Tracking by Scheduled Range Measurements | http://arxiv.org/abs/1708.00675 | id:1708.00675 author:Mohammad Hossein Ferdowsi, Ebrahim Sabzikar category:cs.SY cs.RO  published:2017-08-02 summary:In this paper, optical target tracking, by regular target bearing measurements and target range in a lower and scheduled measurement rate is considered. Variance of the target range estimation error is used as scheduling criterion. For this purpose, target dynamic state vector in modified spherical coordinates is stated in such a way that all target states be decoupled from range-related target state. Target state dynamic equations in modified spherical coordinates for nearly constant velocity, nearly constant acceleration and coordinated turn rate kinematic models, are analytically derived. For resulted state dynamic equations, a UKF-IMM filter with range measurement scheduling is utilized as a tracking filter. It is shown that target states are estimated properly and applied filter has high performance in maneuvering target tracking. version:1
arxiv-1708-00674 | Deep Detection of People and their Mobility Aids for a Hospital Robot | http://arxiv.org/abs/1708.00674 | id:1708.00674 author:Andres Vasquez, Marina Kollmitz, Andreas Eitel, Wolfram Burgard category:cs.RO cs.CV  published:2017-08-02 summary:Robots operating in populated environments encounter many different types of people, some of whom might have an advanced need for cautious interaction, because of physical impairments or their advanced age. Robots therefore need to recognize such advanced demands to provide appropriate assistance, guidance or other forms of support. In this paper, we propose a depth-based perception pipeline that estimates the position and velocity of people in the environment and categorizes them according to the mobility aids they use: pedestrian, person in wheelchair, person in a wheelchair with a person pushing them, person with crutches and person using a walker. We present a fast region proposal method that feeds a Region-based Convolutional Network (Fast R-CNN). With this, we speed up the object detection process by a factor of seven compared to a dense sliding window approach. We furthermore propose a probabilistic position, velocity and class estimator to smooth the CNN's detections and account for occlusions and misclassifications. In addition, we introduce a new hospital dataset with over 17,000 annotated RGB-D images. Extensive experiments confirm that our pipeline successfully keeps track of people and their mobility aids, even in challenging situations with multiple people from different categories and frequent occlusions. Videos of our experiments and the dataset are available at http://www2.informatik.uni-freiburg.de/~kollmitz/MobilityAids version:1
arxiv-1708-00667 | Deep Reinforcement Learning for Inquiry Dialog Policies with Logical Formula Embeddings | http://arxiv.org/abs/1708.00667 | id:1708.00667 author:Takuya Hiraoka, Masaaki Tsuchida, Yotaro Watanabe category:cs.AI cs.CL  published:2017-08-02 summary:This paper is the first attempt to learn the policy of an inquiry dialog system (IDS) by using deep reinforcement learning (DRL). Most IDS frameworks represent dialog states and dialog acts with logical formulae. In order to make learning inquiry dialog policies more effective, we introduce a logical formula embedding framework based on a recursive neural network. The results of experiments to evaluate the effect of 1) the DRL and 2) the logical formula embedding framework show that the combination of the two are as effective or even better than existing rule-based methods for inquiry dialog policies. version:1
arxiv-1708-00631 | On the Importance of Consistency in Training Deep Neural Networks | http://arxiv.org/abs/1708.00631 | id:1708.00631 author:Chengxi Ye, Yezhou Yang, Cornelia Fermuller, Yiannis Aloimonos category:cs.LG cs.AI cs.CV cs.NE  published:2017-08-02 summary:We explain that the difficulties of training deep neural networks come from a syndrome of three consistency issues. This paper describes our efforts in their analysis and treatment. The first issue is the training speed inconsistency in different layers. We propose to address it with an intuitive, simple-to-implement, low footprint second-order method. The second issue is the scale inconsistency between the layer inputs and the layer residuals. We explain how second-order information provides favorable convenience in removing this roadblock. The third and most challenging issue is the inconsistency in residual propagation. Based on the fundamental theorem of linear algebra, we provide a mathematical characterization of the famous vanishing gradient problem. Thus, an important design principle for future optimization and neural network design is derived. We conclude this paper with the construction of a novel contractive neural network. version:1
arxiv-1708-00625 | Deep Recurrent Generative Decoder for Abstractive Text Summarization | http://arxiv.org/abs/1708.00625 | id:1708.00625 author:Piji Li, Wai Lam, Lidong Bing, Zihao Wang category:cs.CL cs.AI  published:2017-08-02 summary:We propose a new framework for abstractive text summarization based on a sequence-to-sequence oriented encoder-decoder model equipped with a deep recurrent generative decoder (DRGN). Latent structure information implied in the target summaries is learned based on a recurrent latent random model for improving the summarization quality. Neural variational inference is employed to address the intractable posterior inference for the recurrent latent variables. Abstractive summaries are generated based on both the generative latent variables and the discriminative deterministic states. Extensive experiments on some benchmark datasets in different languages show that DRGN achieves improvements over the state-of-the-art methods. version:1
arxiv-1708-00544 | Performance Measurements of Supercomputing and Cloud Storage Solutions | http://arxiv.org/abs/1708.00544 | id:1708.00544 author:Michael Jones, Jeremy Kepner, William Arcand, David Bestor, Bill Bergeron, Vijay Gadepally, Michael Houle, Matthew Hubbell, Peter Michaleas, Andrew Prout, Albert Reuther, Siddharth Samsi, Paul Monticiollo category:cs.DC astro-ph.IM cs.NI cs.OS cs.PF  published:2017-08-01 summary:Increasing amounts of data from varied sources, particularly in the fields of machine learning and graph analytics, are causing storage requirements to grow rapidly. A variety of technologies exist for storing and sharing these data, ranging from parallel file systems used by supercomputers to distributed block storage systems found in clouds. Relatively few comparative measurements exist to inform decisions about which storage systems are best suited for particular tasks. This work provides these measurements for two of the most popular storage technologies: Lustre and Amazon S3. Lustre is an open-source, high performance, parallel file system used by many of the largest supercomputers in the world. Amazon's Simple Storage Service, or S3, is part of the Amazon Web Services offering, and offers a scalable, distributed option to store and retrieve data from anywhere on the Internet. Parallel processing is essential for achieving high performance on modern storage systems. The performance tests used span the gamut of parallel I/O scenarios, ranging from single-client, single-node Amazon S3 and Lustre performance to a large-scale, multi-client test designed to demonstrate the capabilities of a modern storage appliance under heavy load. These results show that, when parallel I/O is used correctly (i.e., many simultaneous read or write processes), full network bandwidth performance is achievable and ranged from 10 gigabits/s over a 10 GigE S3 connection to 0.35 terabits/s using Lustre on a 1200 port 10 GigE switch. These results demonstrate that S3 is well-suited to sharing vast quantities of data over the Internet, while Lustre is well-suited to processing large quantities of data locally. version:1
arxiv-1708-00543 | Balancing Explicability and Explanation in Human-Aware Planning | http://arxiv.org/abs/1708.00543 | id:1708.00543 author:Sarath Sreedharan, Tathagata Chakraborti, Subbarao Kambhampati category:cs.AI  published:2017-08-01 summary:Human aware planning requires an agent to be aware of the intentions, capabilities and mental model of the human in the loop during its decision process. This can involve generating plans that are explicable to a human observer as well as the ability to provide explanations when such plans cannot be generated. This has led to the notion "multi-model planning" which aim to incorporate effects of human expectation in the deliberative process of a planner - either in the form of explicable task planning or explanations produced thereof. In this paper, we bring these two concepts together and show how a planner can account for both these needs and achieve a trade-off during the plan generation process itself by means of a model-space search method MEGA. This in effect provides a comprehensive perspective of what it means for a decision making agent to be "human-aware" by bringing together existing principles of planning under the umbrella of a single plan generation process. We situate our discussion specifically keeping in mind the recent work on explicable planning and explanation generation, and illustrate these concepts in modified versions of two well known planning domains, as well as a demonstration on a robot involved in a typical search and reconnaissance task with an external supervisor. version:1
arxiv-1708-06209 | On the Nanocommunications at THz Band in Graphene-Enabled Wireless Network-on-Chip | http://arxiv.org/abs/1708.06209 | id:1708.06209 author:Quoc-Tuan Vien, Michael Opoku Agyeman, Tuan Anh Le, Terrence Mak category:cs.DC  published:2017-08-01 summary:One of the main challenges towards the growing computation-intensive applications with scalable bandwidth requirement is the deployment of a dense number of on-chip cores within a chip package. To this end, this paper investigates the Wireless Network- on-Chip (WiNoC), which is enabled by graphene-based nanoantennas (GNAs) in Terahertz frequency band. We first develop a channel model between the GNAs taking into account the practical issues of the propagation medium, such as transmission frequency, operating temperature, ambient pressure, and distance between the GNAs. In the Terahertz band, not only dielectric propagation loss but also molecular absorption attenuation (MAA) caused by various molecules and their isotopologues within the chip package constitutes the signal transmission loss. We further propose an optimal power allocation to achieve the channel capacity. The proposed channel model shows that the MAA significantly degrades the performance at certain frequency ranges compared to the conventional channel model, even when the GNAs are very closely located. More specifically, at transmission frequency of 1 THz, the channel capacity of the proposed model is shown to be much lower than that of the conventional model over the whole range of temperature and ambient pressure of up to 26.8% and 25%, respectively. version:1
arxiv-1708-00463 | Hierarchical Subtask Discovery With Non-Negative Matrix Factorization | http://arxiv.org/abs/1708.00463 | id:1708.00463 author:Adam C. Earle, Andrew M. Saxe, Benjamin Rosman category:cs.AI  published:2017-08-01 summary:Hierarchical reinforcement learning methods offer a powerful means of planning flexible behavior in complicated domains. However, learning an appropriate hierarchical decomposition of a domain into subtasks remains a substantial challenge. We present a novel algorithm for subtask discovery, based on the recently introduced multitask linearly-solvable Markov decision process (MLMDP) framework. The MLMDP can perform never-before-seen tasks by representing them as a linear combination of a previously learned basis set of tasks. In this setting, the subtask discovery problem can naturally be posed as finding an optimal low-rank approximation of the set of tasks the agent will face in a domain. We use non-negative matrix factorization to discover this minimal basis set of tasks, and show that the technique learns intuitive decompositions in a variety of domains. Our method has several qualitatively desirable features: it is not limited to learning subtasks with single goal states, instead learning distributed patterns of preferred states; it learns qualitatively different hierarchical decompositions in the same domain depending on the ensemble of tasks the agent will face; and it may be straightforwardly iterated to obtain deeper hierarchical decompositions. version:1
arxiv-1708-00807 | Adversarial-Playground: A Visualization Suite Showing How Adversarial Examples Fool Deep Learning | http://arxiv.org/abs/1708.00807 | id:1708.00807 author:Andrew P. Norton, Yanjun Qi category:cs.CR cs.AI cs.LG I.2.6  K.6.5  published:2017-08-01 summary:Recent studies have shown that attackers can force deep learning models to misclassify so-called "adversarial examples": maliciously generated images formed by making imperceptible modifications to pixel values. With growing interest in deep learning for security applications, it is important for security experts and users of machine learning to recognize how learning systems may be attacked. Due to the complex nature of deep learning, it is challenging to understand how deep models can be fooled by adversarial examples. Thus, we present a web-based visualization tool, Adversarial-Playground, to demonstrate the efficacy of common adversarial methods against a convolutional neural network (CNN) system. Adversarial-Playground is educational, modular and interactive. (1) It enables non-experts to compare examples visually and to understand why an adversarial example can fool a CNN-based image classifier. (2) It can help security experts explore more vulnerability of deep learning as a software module. (3) Building an interactive visualization is challenging in this domain due to the large feature space of image classification (generating adversarial examples is slow in general and visualizing images are costly). Through multiple novel design choices, our tool can provide fast and accurate responses to user requests. Empirically, we find that our client-server division strategy reduced the response time by an average of 1.5 seconds per sample. Our other innovation, a faster variant of JSMA evasion algorithm, empirically performed twice as fast as JSMA and yet maintains a comparable evasion rate. Project source code and data from our experiments available at: https://github.com/QData/AdversarialDNN-Playground version:1
arxiv-1708-00276 | Distributed Approximation of Maximum Independent Set and Maximum Matching | http://arxiv.org/abs/1708.00276 | id:1708.00276 author:Reuven Bar-Yehuda, Keren Censor-Hillel, Mohsen Ghaffari, Gregory Schwartzman category:cs.DC cs.DS  published:2017-08-01 summary:We present a simple distributed $\Delta$-approximation algorithm for maximum weight independent set (MaxIS) in the $\mathsf{CONGEST}$ model which completes in $O(\texttt{MIS}(G)\cdot \log W)$ rounds, where $\Delta$ is the maximum degree, $\texttt{MIS}(G)$ is the number of rounds needed to compute a maximal independent set (MIS) on $G$, and $W$ is the maximum weight of a node. %Whether our algorithm is randomized or deterministic depends on the \texttt{MIS} algorithm used as a black-box. Plugging in the best known algorithm for MIS gives a randomized solution in $O(\log n \log W)$ rounds, where $n$ is the number of nodes. We also present a deterministic $O(\Delta +\log^* n)$-round algorithm based on coloring. We then show how to use our MaxIS approximation algorithms to compute a $2$-approximation for maximum weight matching without incurring any additional round penalty in the $\mathsf{CONGEST}$ model. We use a known reduction for simulating algorithms on the line graph while incurring congestion, but we show our algorithm is part of a broad family of \emph{local aggregation algorithms} for which we describe a mechanism that allows the simulation to run in the $\mathsf{CONGEST}$ model without an additional overhead. Next, we show that for maximum weight matching, relaxing the approximation factor to ($2+\varepsilon$) allows us to devise a distributed algorithm requiring $O(\frac{\log \Delta}{\log\log\Delta})$ rounds for any constant $\varepsilon>0$. For the unweighted case, we can even obtain a $(1+\varepsilon)$-approximation in this number of rounds. These algorithms are the first to achieve the provably optimal round complexity with respect to dependency on $\Delta$. version:1
arxiv-1708-00225 | CREST: Convolutional Residual Learning for Visual Tracking | http://arxiv.org/abs/1708.00225 | id:1708.00225 author:Yibing Song, Chao Ma, Lijun Gong, Jiawei Zhang, Rynson Lau, Ming-Hsuan Yang category:cs.CV cs.AI cs.MM  published:2017-08-01 summary:Discriminative correlation filters (DCFs) have been shown to perform superiorly in visual tracking. They only need a small set of training samples from the initial frame to generate an appearance model. However, existing DCFs learn the filters separately from feature extraction, and update these filters using a moving average operation with an empirical weight. These DCF trackers hardly benefit from the end-to-end training. In this paper, we propose the CREST algorithm to reformulate DCFs as a one-layer convolutional neural network. Our method integrates feature extraction, response map generation as well as model update into the neural networks for an end-to-end training. To reduce model degradation during online update, we apply residual learning to take appearance changes into account. Extensive experiments on the benchmark datasets demonstrate that our CREST tracker performs favorably against state-of-the-art trackers. version:1
arxiv-1708-00224 | Fast Preprocessing for Robust Face Sketch Synthesis | http://arxiv.org/abs/1708.00224 | id:1708.00224 author:Yibing Song, Jiawei Zhang, Linchao Bao, Qingxiong Yang category:cs.CV cs.AI cs.GR cs.MM  published:2017-08-01 summary:Exemplar-based face sketch synthesis methods usually meet the challenging problem that input photos are captured in different lighting conditions from training photos. The critical step causing the failure is the search of similar patch candidates for an input photo patch. Conventional illumination invariant patch distances are adopted rather than directly relying on pixel intensity difference, but they will fail when local contrast within a patch changes. In this paper, we propose a fast preprocessing method named Bidirectional Luminance Remapping (BLR), which interactively adjust the lighting of training and input photos. Our method can be directly integrated into state-of-the-art exemplar-based methods to improve their robustness with ignorable computational cost. version:1
arxiv-1708-00200 | Anytime, Anywhere Anomaly Recovery through an Online Robot Introspection Framework | http://arxiv.org/abs/1708.00200 | id:1708.00200 author:Hongmin Wu, Hongbin Lin, Shuangqi Luo, Shuangda Duan, Chen Xiang, Bo Zhao, Juan Rojas category:cs.RO  published:2017-08-01 summary:Robotic introspection and online decision making have been an area of increased focus. The goal is to endow robots with the ability to understand their actions and make timely decisions to reach their goals. Particularly, in unstructured environments, external perturbations are hard to model in low-level control systems and often lead to failure. Robots must then understand nominal and anomalous conditions and trigger timely responses to behaviors that allow the robot to recover and even learn from them and prevent them. Our contribution is the implementation of a fast and robust robot introspection system that allows recovery from (one or multiple) anomalous situations at any point in the task. The system handles both internal modeling errors as well as external perturbations. The robustness of the system is demonstrated across multiple manipulation tasks. The system assumes tasks are decomposed into a sequence of nodes, where each node performs a dual role: one of motion generation and one of introspection. Motion generation is flexible and can be done with any type of accessible approach. Introspection is done by modeling the robots multimodal signals using a range of HMMs including nonparametric Bayesian hidden Markov models. Such models yield strong expressive power to discriminate both nominal and anomalous situations. We made use of a generic strategy for recovery that is easy and flexible to design across different tasks. A new metric for anomaly detection, critical in the proper assessment of the system after recovery has taken place was also designed. We show how the system recovers from both pose estimation errors that lead to collisions in pick tasks as well as external human collisions. Furthermore, the system is able to robustly recover from collisions that occur at multiple points in the task; even, when anomalies repeatedly appear at a specific point in the task. version:1
arxiv-1708-00154 | Neural Rating Regression with Abstractive Tips Generation for Recommendation | http://arxiv.org/abs/1708.00154 | id:1708.00154 author:Piji Li, Zihao Wang, Zhaochun Ren, Lidong Bing, Wai Lam category:cs.CL cs.AI cs.IR  published:2017-08-01 summary:Recently, some E-commerce sites launch a new interaction box called Tips on their mobile apps. Users can express their experience and feelings or provide suggestions using short texts typically several words or one sentence. In essence, writing some tips and giving a numerical rating are two facets of a user's product assessment action, expressing the user experience and feelings. Jointly modeling these two facets is helpful for designing a better recommendation system. While some existing models integrate text information such as item specifications or user reviews into user and item latent factors for improving the rating prediction, no existing works consider tips for improving recommendation quality. We propose a deep learning based framework named NRT which can simultaneously predict precise ratings and generate abstractive tips with good linguistic quality simulating user experience and feelings. For abstractive tips generation, gated recurrent neural networks are employed to "translate" user and item latent representations into a concise sentence. Extensive experiments on benchmark datasets from different domains show that NRT achieves significant improvements over the state-of-the-art methods. Moreover, the generated tips can vividly predict the user experience and feelings. version:1
arxiv-1708-00133 | Deep Transfer in Reinforcement Learning by Language Grounding | http://arxiv.org/abs/1708.00133 | id:1708.00133 author:Karthik Narasimhan, Regina Barzilay, Tommi Jaakkola category:cs.CL cs.AI cs.LG  published:2017-08-01 summary:In this paper, we explore the utilization of natural language to drive transfer for reinforcement learning (RL). Despite the wide-spread application of deep RL techniques, learning generalized policy representations that work across domains remains a challenging problem. We demonstrate that textual descriptions of environments provide a compact intermediate channel to facilitate effective policy transfer. We employ a model-based RL approach consisting of a differentiable planning module, a model-free component and a factorized representation to effectively utilize entity descriptions. Our model outperforms prior work on both transfer and multi-task scenarios in a variety of different environments. version:1
arxiv-1708-00117 | Compiling Deep Learning Models for Custom Hardware Accelerators | http://arxiv.org/abs/1708.00117 | id:1708.00117 author:Andre Xian Ming Chang, Aliasger Zaidy, Vinayak Gokhale, Eugenio Culurciello category:cs.DC cs.LG  published:2017-08-01 summary:Convolutional neural networks (CNNs) are the core of most state-of-the-art deep learning algorithms specialized for object detection and classification. CNNs are both computationally complex and embarrassingly parallel. Two properties that leave room for potential software and hardware optimizations for embedded systems. Given a programmable hardware accelerator with a CNN oriented custom instructions set, the compiler's task is to exploit the hardware's full potential, while abiding with the hardware constraints and maintaining generality to run different CNN models with varying workload properties. Snowflake is an efficient and scalable hardware accelerator implemented on programmable logic devices. It implements a control pipeline for a custom instruction set. The goal of this paper is to present Snowflake's compiler that generates machine level instructions from Torch7 model description files. The main software design points explored in this work are: model structure parsing, CNN workload breakdown, loop rearrangement for memory bandwidth optimizations and memory access balancing. The performance achieved by compiler generated instructions matches against hand optimized code for convolution layers. Generated instructions also efficiently execute AlexNet and ResNet18 inference on Snowflake. Snowflake with $256$ processing units was synthesized on Xilinx's Zynq XC7Z045 FPGA. At $250$ MHz, AlexNet achieved in $93.6$ frames/s and $1.2$ GB/s of off-chip memory bandwidth, and $21.4$ frames/s and $2.2$ GB/s for ResNet18. Total on-chip power is $5$ W. version:1
arxiv-1708-00109 | A Labelling Framework for Probabilistic Argumentation | http://arxiv.org/abs/1708.00109 | id:1708.00109 author:Regis Riveret, Pietro Baroni, Yang Gao, Guido Governatori, Antonino Rotolo, Giovanni Sartor category:cs.AI  published:2017-08-01 summary:The combination of argumentation and probability paves the way to new accounts of qualitative and quantitative uncertainty, thereby offering new theoretical and applicative opportunities. Due to a variety of interests, probabilistic argumentation is approached in the literature with different frameworks, pertaining to structured and abstract argumentation, and with respect to diverse types of uncertainty, in particular the uncertainty on the credibility of the premises, the uncertainty about which arguments to consider, and the uncertainty on the acceptance status of arguments or statements. Towards a general framework for probabilistic argumentation, we investigate a labelling-oriented framework encompassing a basic setting for rule-based argumentation and its (semi-) abstract account, along with diverse types of uncertainty. Our framework provides a systematic treatment of various kinds of uncertainty and of their relationships and allows us to retrieve (by derivation) multiple statements (sometimes assumed) or results from the literature. version:1
arxiv-1708-00107 | Learned in Translation: Contextualized Word Vectors | http://arxiv.org/abs/1708.00107 | id:1708.00107 author:Bryan McCann, James Bradbury, Caiming Xiong, Richard Socher category:cs.CL cs.AI cs.LG  published:2017-08-01 summary:Computer vision has benefited from initializing multiple deep layers with weights pretrained on large supervised training sets like ImageNet. Natural language processing (NLP) typically sees initialization of only the lowest layer of deep models with pretrained word vectors. In this paper, we use a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation (MT) to contextualize word vectors. We show that adding these context vectors (CoVe) improves performance over using only unsupervised word and character vectors on a wide variety of common NLP tasks: sentiment analysis (SST, IMDb), question classification (TREC), entailment (SNLI), and question answering (SQuAD). For fine-grained sentiment analysis and entailment, CoVe improves performance of our baseline models to the state of the art. version:1
arxiv-1708-00102 | Advantages and Limitations of using Successor Features for Transfer in Reinforcement Learning | http://arxiv.org/abs/1708.00102 | id:1708.00102 author:Lucas Lehnert, Stefanie Tellex, Michael L. Littman category:cs.AI cs.LG stat.ML  published:2017-07-31 summary:One question central to Reinforcement Learning is how to learn a feature representation that supports algorithm scaling and re-use of learned information from different tasks. Successor Features approach this problem by learning a feature representation that satisfies a temporal constraint. We present an implementation of an approach that decouples the feature representation from the reward function, making it suitable for transferring knowledge between domains. We then assess the advantages and limitations of using Successor Features for transfer. version:1
arxiv-1708-00052 | Streaming Architecture for Large-Scale Quantized Neural Networks on an FPGA-Based Dataflow Platform | http://arxiv.org/abs/1708.00052 | id:1708.00052 author:Chaim Baskin, Natan Liss, Avi Mendelson, Evgenii Zheltonozhskii category:cs.CV cs.AR cs.LG  published:2017-07-31 summary:Deep neural networks (DNNs) are used by different applications that are executed on a range of computer architectures, from IoT devices to supercomputers. The footprint of these networks is huge as well as their computational and communication needs. In order to ease the pressure on resources, research indicates that in many cases a low precision representation (1-2 bit per parameter) of weights and other parameters can achieve similar accuracy while requiring less resources. Using quantized values enables the use of FPGAs to run NNs, since FPGAs are well fitted to these primitives; e.g., FPGAs provide efficient support for bitwise operations and can work with arbitrary-precision representation of numbers. This paper presents a new streaming architecture for running QNNs on FPGAs. The proposed architecture scales out better than alternatives, allowing us to take advantage of systems with multiple FPGAs. We also included support for skip connections, that are used in state-of-the art NNs, and shown that our architecture allows to add those connections almost for free. All this allowed us to implement an 18-layer ResNet for $224\times224$ images classification, achieving $57.5\%$ top-1 accuracy. In addition, we implemented a full-sized quantized AlexNet. In contrast to previous works, we use 2-bit activations instead of 1-bit ones, which improves AlexNet's top-1 accuracy from $41.8\%$ to $51.03\%$ for the ImageNet classification. Both AlexNet and ResNet can handle 1000-class real-time classification on an FPGA. Our implementation of ResNet-18 consumes $5\times$ less power and is $4\times$ slower for ImageNet, when compared to the same NN on the latest Nvidia GPUs. Smaller NNs, that fit a single FPGA, are running faster then on GPUs on small ($32\times32$) inputs, while consuming up to $20\times$ less energy and power. version:1
arxiv-1704-05712 | Universal Adversarial Perturbations Against Semantic Image Segmentation | http://arxiv.org/abs/1704.05712 | id:1704.05712 author:Jan Hendrik Metzen, Mummadi Chaithanya Kumar, Thomas Brox, Volker Fischer category:stat.ML cs.AI cs.CV cs.LG cs.NE  published:2017-04-19 summary:While deep learning is remarkably successful on perceptual tasks, it was also shown to be vulnerable to adversarial perturbations of the input. These perturbations denote noise added to the input that was generated specifically to fool the system while being quasi-imperceptible for humans. More severely, there even exist universal perturbations that are input-agnostic but fool the network on the majority of inputs. While recent work has focused on image classification, this work proposes attacks against semantic image segmentation: we present an approach for generating (universal) adversarial perturbations that make the network yield a desired target segmentation as output. We show empirically that there exist barely perceptible universal noise patterns which result in nearly the same predicted segmentation for arbitrary inputs. Furthermore, we also show the existence of universal noise which removes a target class (e.g., all pedestrians) from the segmentation while leaving the segmentation mostly unchanged otherwise. version:3
arxiv-1611-01711 | Causes for Query Answers from Databases: Datalog Abduction, View-Updates, and Integrity Constraints | http://arxiv.org/abs/1611.01711 | id:1611.01711 author:Leopoldo Bertossi, Babak Salimi category:cs.DB cs.AI  published:2016-11-06 summary:Causality has been recently introduced in databases, to model, characterize, and possibly compute causes for query answers. Connections between QA-causality and consistency-based diagnosis and database repairs (wrt. integrity constraint violations) have already been established. In this work we establish precise connections between QA-causality and both abductive diagnosis and the view-update problem in databases, allowing us to obtain new algorithmic and complexity results for QA-causality. We also obtain new results on the complexity of view-conditioned causality, and investigate the notion of QA-causality in the presence of integrity constraints, obtaining complexity results from a connection with view-conditioned causality. The abduction connection under integrity constraints allows us to obtain algorithmic tools for QA-causality. version:3
arxiv-1707-09952 | Multiscale Co-Design Analysis of Energy, Latency, Area, and Accuracy of a ReRAM Analog Neural Training Accelerator | http://arxiv.org/abs/1707.09952 | id:1707.09952 author:Matthew J. Marinella, Sapan Agarwal, Alexander Hsia, Isaac Richter, Robin Jacobs-Gedrim, John Niroula, Steven J. Plimpton, Engin Ipek, Conrad D. James category:cs.AR cs.NE  published:2017-07-31 summary:Neural networks are an increasingly attractive algorithm for natural language processing and pattern recognition applications. Deep networks with >50M parameters made possible by modern GPU clusters operating at <50 pJ per op and more recently, production accelerators capable of <5pJ per operation at the board level. However, with the slowing of CMOS scaling, new paradigms will be required to achieve the next several orders of magnitude in performance per watt gains. Using an analog resistive memory (ReRAM) crossbar to perform key matrix operations in an accelerator is an attractive option that is gaining significant interest. This work presents a detailed design using a state of the art 14/16 nm PDK for of an analog crossbar circuit block designed to process three key kernels required in training and inference of neural networks. A detailed circuit and device-level analysis of energy, latency, area, and accuracy are given and compared to relevant designs using standard digital ReRAM and SRAM operations. It is shown that the analog accelerator has a 310x energy and 270x latency advantage over a similar block utilizing only digital ReRAM and takes only 11 fJ per multiply and accumulate (MAC). Although training accuracy is degraded in the analog accelerator, several options to improve this are presented. The possible gains over a similar digital-only version of this accelerator block suggest that continued optimization of analog resistive memories is valuable. This detailed circuit and device analysis of a training accelerator may serve as a foundation for further architecture-level studies. version:1
arxiv-1607-00174 | Using Blockchain for Peer-to-Peer Proof-of-Location | http://arxiv.org/abs/1607.00174 | id:1607.00174 author:Giacomo Brambilla, Michele Amoretti, Francesco Zanichelli category:cs.DC cs.CR C.2.4  published:2016-07-01 summary:Location-Based Services (LBSs) build upon geographic information to provide users with location-dependent functionalities. In such a context, it is particularly important that geographic locations claimed by users are the actual ones. Centralized verification approaches proposed in the last few years are not satisfactory, as they entail a high risk to the privacy of users. In this paper, we present and evaluate a novel decentralized, infrastructure-independent proof-of-location scheme based on the blockchain technology. Our scheme guarantees both location trustworthiness and user privacy preservation. version:2
arxiv-1707-09899 | Fashioning with Networks: Neural Style Transfer to Design Clothes | http://arxiv.org/abs/1707.09899 | id:1707.09899 author:Prutha Date, Ashwinkumar Ganesan, Tim Oates category:cs.CV cs.AI cs.IR cs.NE  published:2017-07-31 summary:Convolutional Neural Networks have been highly successful in performing a host of computer vision tasks such as object recognition, object detection, image segmentation and texture synthesis. In 2015, Gatys et. al [7] show how the style of a painter can be extracted from an image of the painting and applied to another normal photograph, thus recreating the photo in the style of the painter. The method has been successfully applied to a wide range of images and has since spawned multiple applications and mobile apps. In this paper, the neural style transfer algorithm is applied to fashion so as to synthesize new custom clothes. We construct an approach to personalize and generate new custom clothes based on a users preference and by learning the users fashion choices from a limited set of clothes from their closet. The approach is evaluated by analyzing the generated images of clothes and how well they align with the users fashion style. version:1
arxiv-1609-05247 | Viewpoint Selection for Grasp Detection | http://arxiv.org/abs/1609.05247 | id:1609.05247 author:Marcus Gualtieri, Robert Platt category:cs.RO  published:2016-09-16 summary:In grasp detection, the robot estimates the position and orientation of potential grasp configurations directly from sensor data. This paper explores the relationship between viewpoint and grasp detection performance. Specifically, we consider the scenario where the approximate position and orientation of a desired grasp is known in advance and we want to select a viewpoint that will enable a grasp detection algorithm to localize it more precisely and with higher confidence. Our main findings are that the right viewpoint can dramatically increase the number of detected grasps and the classification accuracy of the top-n detections. We use this insight to create a viewpoint selection algorithm and compare it against a random viewpoint selection strategy and a strategy that views the desired grasp head-on. We find that the head-on strategy and our proposed viewpoint selection strategy can improve grasp success rates on a real robot by 8% and 4%, respectively. Moreover, we find that the combination of the two methods can improve grasp success rates by as much as 12%. version:3
arxiv-1707-09850 | CODE-RADE - Community Infrastructure for the Delivery of Physics Applications | http://arxiv.org/abs/1707.09850 | id:1707.09850 author:Bruce Becker, Sean Murray category:cs.DC  published:2017-07-31 summary:Scientific computing can in some sense be distilled to the execution of an application - or rather sets of applications which are combined into complex workflows. Due to the complexity and number both of scientific packages as well as computing platforms, delivering these applications to end users has always been a significant challenge through the grid era, and remains so in the cloud era. In this contribution we describe a platform for user-driven, continuous integration and delivery of research applications in a distributed environment - project CODE-RADE. Starting with 6 hypotheses describing the problem at hand, we put forward technical and social solutions to these. Combining widely-used and thoroughly-tested tools, we show how it is possible to manage the dependencies and configurations of a wide range of scientific applications, in an almost fully-automated way. The CODE-RADE platform is a means for developing trust between public computing and data infrastructures on the one hand and various developer and scientific communities on the other hand. Predefined integration tests are specified for any new application, allowing the system to be user-driven. This greatly accelerates time-to-production for scientific applications, while reducing the workload for administrators of HPC, grid and cloud installations. Finally, we will give some insight into how this platform could be extended to address issues of reproducibility and collaboration in scientific research in Africa. version:1
arxiv-1708-02283 | Real-Time Visual Localisation in a Tagged Environment | http://arxiv.org/abs/1708.02283 | id:1708.02283 author:Jérémy Taquet, Gaël Écorchard, Libor Přeučil category:cs.CV cs.RO  published:2017-07-31 summary:In a robotised warehouse a major issue is the safety of human operators in case of intervention in the work area of the robots. The current solution is to shut down every robot but it causes a loss of productivity, especially for large robotised warehouses. In order to avoid this loss we need to ensure the operator's security during his/her intervention in the warehouse without powering off the robots. The human operator needs to be localised in the warehouse and the trajectories of the robots have to be modified so that they do not interfere with the human. The purpose of this paper is to demonstrate a visual localisation method with visual elements that are already available in the current warehouse setup. version:1
arxiv-1707-09809 | Speed-up of Self-Organizing Networks for Routing Problems in a Polygonal Domain | http://arxiv.org/abs/1707.09809 | id:1707.09809 author:Miroslav Kulich, Roman Sushkov, Libor Přeučil category:cs.RO  published:2017-07-31 summary:Routing problems are optimization problems that consider a set of goals in a graph to be visited by a vehicle (or a fleet of them) in an optimal way, while numerous constraints have to be satisfied. We present a solution based on multidimensional scaling which significantly reduces computational time of a self-organizing neural network solving a typical routing problem -- the Travelling Salesman Problem (TSP) in a polygonal domain, i.e. in a space where obstacles are represented by polygons. The preliminary results show feasibility of the proposed approach and although the results are presented only for TSP, the method is general so it can be used also for other variants of routing problems. version:1
arxiv-1707-09808 | Practical Aspects of Autonomous Exploration with a Kinect2 sensor | http://arxiv.org/abs/1707.09808 | id:1707.09808 author:Miroslav Kulich, Vojtěch Lhotský, Libor Přeučil category:cs.RO  published:2017-07-31 summary:Exploration of an unknown environment by a mobile robot is a complex task involving solution of many fundamental problems from data processing, localization to high-level planning and decision making. The exploration framework we developed is based on processing of RGBD data provided by a MS Kinect2 sensor, which allows to take advantage of state-of-the-art SLAM (Simultaneous Localization and Mapping) algorithms and to autonomously build a realistic 3D map of the environment with projected visual information about the scene. In this paper, we describe practical issues that appeared during deployment of the framework in real indoor and outdoor environments and discuss especially properties of SLAM algorithms processing MS Kinect2 data on an embedded computer. version:1
arxiv-1707-09790 | Evaluating Music Recommender Systems for Groups | http://arxiv.org/abs/1707.09790 | id:1707.09790 author:Zsolt Mezei, Carsten Eickhoff category:cs.AI cs.HC cs.IR  published:2017-07-31 summary:Recommendation to groups of users is a challenging and currently only passingly studied task. Especially the evaluation aspect often appears ad-hoc and instead of truly evaluating on groups of users, synthesizes groups by merging individual preferences. In this paper, we present a user study, recording the individual and shared preferences of actual groups of participants, resulting in a robust, standardized evaluation benchmark. Using this benchmarking dataset, that we share with the research community, we compare the respective performance of a wide range of music group recommendation techniques proposed in the version:1
arxiv-1703-01148 | Runtime Optimization of Join Location in Parallel Data Management Systems | http://arxiv.org/abs/1703.01148 | id:1703.01148 author:Bikash Chandra, S. Sudarshan category:cs.DB cs.DC 68P15 H.2  published:2017-03-03 summary:Applications running on parallel systems often need to join a streaming relation or a stored relation with data indexed in a parallel data storage system. Some applications also compute UDFs on the joined tuples. The join can be done at the data storage nodes, corresponding to reduce side joins, or by fetching data from the storage system to compute nodes, corresponding to map side join. Both may be suboptimal: reduce side joins may cause skew, while map side joins may lead to a lot of data being transferred and replicated. In this paper, we present techniques to make runtime decisions between the two options on a per key basis, in order to improve the throughput of the join, accounting for UDF computation if any. Our techniques are based on an extended ski-rental algorithm and provide worst-case performance guarantees with respect to the optimal point in the space considered by us. Our techniques use load balancing taking into account the CPU, network and I/O costs as well as the load on compute and storage nodes. We have implemented our techniques on Hadoop, Spark and the Muppet stream processing engine. Our experiments show that our optimization techniques provide a significant improvement in throughput over existing techniques. version:3
arxiv-1707-09718 | Adaptive Second-order Sliding Mode Control of UAVs for Civil Applications | http://arxiv.org/abs/1707.09718 | id:1707.09718 author:Van Truong Hoang, Ansu Man Singh, Manh Duong Phung, Quang Ha category:cs.SY cs.RO  published:2017-07-31 summary:Quadcopters, as unmanned aerial vehicles (UAVs), have great potential in civil applications such as surveying, building monitoring, and infrastructure condition assessment. Quadcopters, however, are relatively sensitive to noises and disturbances so that their performance may be quickly downgraded in the case of inadequate control, system uncertainties and/or external disturbances. In this study, we deal with the quadrotor low-level control by proposing a robust scheme named the adaptive second-order quasi-continuous sliding mode control (adaptive 2-QCSM). The ultimate objective is for robust attitude control of the UAV in monitoring and inspection of built infrastructure. First, the mathematical model of the quadcopter is derived considering nonlinearity, strong coupling, uncertain dynamics and external disturbances. The control design includes the selection of the sliding manifold and the development of quasi-continuous second-order sliding mode controller with an adaptive gain. Stability of the overall control system is analysed by using a global Lyapunov function for convergence of both the sliding dynamics and adaptation scheme. Extensive simulations have been carried out for evaluation. Results show that the proposed controller can achieve robustness against disturbances or parameter variations and has better tracking performance in comparison with experimental responses of a UAV in a real-time monitoring task. version:1
arxiv-1707-09715 | Automatic Crack Detection in Built Infrastructure Using Unmanned Aerial Vehicles | http://arxiv.org/abs/1707.09715 | id:1707.09715 author:Manh Duong Phung, Van Truong Hoang, Tran Hiep Dinh, Quang Ha category:cs.SY cs.CV cs.RO  published:2017-07-31 summary:This paper addresses the problem of crack detection which is essential for health monitoring of built infrastructure. Our approach includes two stages, data collection using unmanned aerial vehicles (UAVs) and crack detection using histogram analysis. For the data collection, a 3D model of the structure is first created by using laser scanners. Based on the model, geometric properties are extracted to generate way points necessary for navigating the UAV to take images of the structure. Then, our next step is to stick together those obtained images from the overlapped field of view. The resulting image is then clustered by histogram analysis and peak detection. Potential cracks are finally identified by using locally adaptive thresholds. The whole process is automatically carried out so that the inspection time is significantly improved while safety hazards can be minimised. A prototypical system has been developed for evaluation and experimental results are included. version:1
arxiv-1707-09706 | Developing Knowledge-enhanced Chronic Disease Risk Prediction Models from Regional EHR Repositories | http://arxiv.org/abs/1707.09706 | id:1707.09706 author:Jing Mei, Eryu Xia, Xiang Li, Guotong Xie category:cs.AI stat.AP  published:2017-07-31 summary:Precision medicine requires the precision disease risk prediction models. In literature, there have been a lot well-established (inter-)national risk models, but when applying them into the local population, the prediction performance becomes unsatisfactory. To address the localization issue, this paper exploits the way to develop knowledge-enhanced localized risk models. On the one hand, we tune models by learning from regional Electronic Health Record (EHR) repositories, and on the other hand, we propose knowledge injection into the EHR data learning process. For experiments, we leverage the Pooled Cohort Equations (PCE, as recommended in ACC/AHA guidelines to estimate the risk of ASCVD) to develop a localized ASCVD risk prediction model in diabetes. The experimental results show that, if directly using the PCE algorithm on our cohort, the AUC is only 0.653, while our knowledge-enhanced localized risk model can achieve higher prediction performance with AUC of 0.723 (improved by 10.7%). version:1
arxiv-1707-09704 | Cost and Actual Causation | http://arxiv.org/abs/1707.09704 | id:1707.09704 author:Liang Zhou category:cs.AI  published:2017-07-31 summary:I propose the purpose our concept of actual causation serves is minimizing various cost in intervention practice. Actual causation has three features: nonredundant sufficiency, continuity and abnormality; these features correspond to the minimization of exploitative cost, exploratory cost and risk cost in intervention practice. Incorporating these three features, a definition of actual causation is given. I test the definition in 66 causal cases from actual causation literature and show that this definition's application fit intuition better than some other causal modelling based definitions. version:1
arxiv-1707-05301 | Cheap or Robust? The Practical Realization of Self-Driving Wheelchair Technology | http://arxiv.org/abs/1707.05301 | id:1707.05301 author:Maya Burhanpurkar, Mathieu Labbé, Charlie Guan, François Michaud, Jonathan Kelly category:cs.RO  published:2017-07-17 summary:To date, self-driving experimental wheelchair technologies have been either inexpensive or robust, but not both. Yet, in order to achieve real-world acceptance, both qualities are fundamentally essential. We present a unique approach to achieve inexpensive and robust autonomous and semi-autonomous assistive navigation for existing fielded wheelchairs, of which there are approximately 5 million units in Canada and United States alone. Our prototype wheelchair platform is capable of localization and mapping, as well as robust obstacle avoidance, using only a commodity RGB-D sensor and wheel odometry. As a specific example of the navigation capabilities, we focus on the single most common navigation problem: the traversal of narrow doorways in arbitrary environments. The software we have developed is generalizable to corridor following, desk docking, and other navigation tasks that are either extremely difficult or impossible for people with upper-body mobility impairments. version:2
arxiv-1707-09668 | Handling Nested Parallelism and Extreme Load Imbalance in an Orbital Analysis Code | http://arxiv.org/abs/1707.09668 | id:1707.09668 author:Benjamin James Gaska, Neha Jothi, Mahdi Soltan Mohammadi, Kat Volk, Michelle Mills Strout category:cs.DC  published:2017-07-30 summary:Nested parallelism exists in scientific codes that are searching multi-dimensional spaces. However, implementations of nested parallelism often have overhead and load balance issues. The Orbital Analysis code we present exhibits a sparse search space, significant load imbalances, and stopping when the first solution is reached. All these aspects of the algorithm exacerbate the problem of using nested parallelism effectively. In this paper, we present an inspector/executor strategy for chunking such computations into parallel wavefronts. The presented shared memory parallelization is no longer nested and exhibits significantly less load imbalance. We evaluate this approach on an Orbital analysis code, and we improve the execution time from the original implementation by an order of magnitude. As part of a Graduate Computer Science course in Parallel Programming models, we show how the approach can be implemented in parallel Perl, Python, Chapel, Pthreads, and OpenMP. Future work includes investigating how to automate and generalize the parallelization approach. version:1
arxiv-1707-09661 | A Vision For Continuous Automated Game Design | http://arxiv.org/abs/1707.09661 | id:1707.09661 author:Michael Cook category:cs.AI  published:2017-07-30 summary:ANGELINA is an automated game design system which has previously been built as a single software block which designs games from start to finish. In this paper we outline a roadmap for the development of a new version of ANGELINA, designed to iterate on games in different ways to produce a continuous creative process that will improve the quality of its work, but more importantly improve the perception of the software as being an independently creative piece of software. We provide an initial report of the system's structure here as well as results from the first working module of the system. version:1
arxiv-1705-00324 | Meeting in a Polygon by Anonymous Oblivious Robots | http://arxiv.org/abs/1705.00324 | id:1705.00324 author:Giuseppe A. Di Luna, Paola Flocchini, Nicola Santoro, Giovanni Viglietta, Masafumi Yamashita category:cs.DC cs.CG cs.RO  published:2017-04-30 summary:The Meeting problem for $k\geq 2$ searchers in a polygon $P$ (possibly with holes) consists in making the searchers move within $P$, according to a distributed algorithm, in such a way that at least two of them eventually come to see each other, regardless of their initial positions. The polygon is initially unknown to the searchers, and its edges obstruct both movement and vision. Depending on the shape of $P$, we minimize the number of searchers $k$ for which the Meeting problem is solvable. Specifically, if $P$ has a rotational symmetry of order $\sigma$ (where $\sigma=1$ corresponds to no rotational symmetry), we prove that $k=\sigma+1$ searchers are sufficient, and the bound is tight. Furthermore, we give an improved algorithm that optimally solves the Meeting problem with $k=2$ searchers in all polygons whose barycenter is not in a hole (which includes the polygons with no holes). Our algorithms can be implemented in a variety of standard models of mobile robots operating in Look-Compute-Move cycles. For instance, if the searchers have memory but are anonymous, asynchronous, and have no agreement on a coordinate system or a notion of clockwise direction, then our algorithms work even if the initial memory contents of the searchers are arbitrary and possibly misleading. Moreover, oblivious searchers can execute our algorithms as well, encoding information by carefully positioning themselves within the polygon. This code is computable with basic arithmetic operations, and each searcher can geometrically construct its own destination point at each cycle using only a compass. We stress that such memoryless searchers may be located anywhere in the polygon when the execution begins, and hence the information they initially encode is arbitrary. Our algorithms use a self-stabilizing map construction subroutine which is of independent interest. version:2
arxiv-1707-09585 | Virtual PET Images from CT Data Using Deep Convolutional Networks: Initial Results | http://arxiv.org/abs/1707.09585 | id:1707.09585 author:Avi Ben-Cohen, Eyal Klang, Stephen P. Raskin, Michal Marianne Amitai, Hayit Greenspan category:cs.CV cs.AI  published:2017-07-30 summary:In this work we present a novel system for PET estimation using CT scans. We explore the use of fully convolutional networks (FCN) and conditional generative adversarial networks (GAN) to export PET data from CT data. Our dataset includes 25 pairs of PET and CT scans where 17 were used for training and 8 for testing. The system was tested for detection of malignant tumors in the liver region. Initial results look promising showing high detection performance with a TPR of 92.3% and FPR of 0.25 per case. Future work entails expansion of the current system to the entire body using a much larger dataset. Such a system can be used for tumor detection and drug treatment evaluation in a CT-only environment instead of the expansive and radioactive PET-CT scan. version:1
arxiv-1703-00095 | Active End-Effector Pose Selection for Tactile Object Recognition through Monte Carlo Tree Search | http://arxiv.org/abs/1703.00095 | id:1703.00095 author:Mabel M. Zhang, Nikolay Atanasov, Kostas Daniilidis category:cs.RO  published:2017-03-01 summary:This paper considers the problem of active object recognition using touch only. The focus is on adaptively selecting a sequence of wrist poses that achieves accurate recognition by enclosure grasps. It seeks to minimize the number of touches and maximize recognition confidence. The actions are formulated as wrist poses relative to each other, making the algorithm independent of absolute workspace coordinates. The optimal sequence is approximated by Monte Carlo tree search. We demonstrate results in a physics engine and on a real robot. In the physics engine, most object instances were recognized in at most 16 grasps. On a real robot, our method recognized objects in 2--9 grasps and outperformed a greedy baseline. version:3
arxiv-1707-06334 | Fully Decentralized Policies for Multi-Agent Systems: An Information Theoretic Approach | http://arxiv.org/abs/1707.06334 | id:1707.06334 author:Roel Dobbe, David Fridovich-Keil, Claire Tomlin category:cs.SY cs.AI cs.IT math.IT math.OC nlin.AO 68  published:2017-07-20 summary:Learning cooperative policies for multi-agent systems is often challenged by partial observability and a lack of coordination. In some settings, the structure of a problem allows a distributed solution with limited communication. Here, we consider a scenario where no communication is available, and instead we learn local policies for all agents that collectively mimic the solution to a centralized multi-agent static optimization problem. Our main contribution is an information theoretic framework based on rate distortion theory which facilitates analysis of how well the resulting fully decentralized policies are able to reconstruct the optimal solution. Moreover, this framework provides a natural extension that addresses which nodes an agent should communicate with to improve the performance of its individual policy. version:2
arxiv-1706-02113 | Energy Efficient Scheduling of Application Components via Brownout and Approximate Markov Decision Process | http://arxiv.org/abs/1706.02113 | id:1706.02113 author:Minxian Xu, Rajkumar Buyya category:cs.DC  published:2017-06-07 summary:Unexpected loads in Cloud data centers may trigger overloaded situation and performance degradation. To guarantee system performance, cloud computing environment is required to have the ability to handle overloads. The existing approaches, like Dynamic Voltage Frequency Scaling and VM consolidation, are effective in handling partial overloads, however, they cannot function when the whole data center is overloaded. Brownout has been proved to be a promising approach to relieve the overloads through deactivating application non-mandatory components or microservices temporarily. Moreover, brownout has been applied to reduce data center energy consumption. It shows that there are trade-offs between energy saving and discount offered to users (revenue loss) when one or more services are not provided temporarily. In this paper, we propose a brownout-based approximate Markov Decision Process approach to improve the aforementioned trade-offs. The results based on real trace demonstrate that our approach saves 20% energy consumption than VM consolidation approach. Compared with existing energy-efficient brownout approach, our approach reduces the discount amount given to users while saving similar energy consumption. version:3
arxiv-1509-08764 | On the Min-cost Traveling Salesman Problem with Drone | http://arxiv.org/abs/1509.08764 | id:1509.08764 author:Quang Minh Ha, Yves Deville, Quang Dung Pham, Minh Hoàng Hà category:cs.AI  published:2015-09-29 summary:Over the past few years, unmanned aerial vehicles (UAV), also known as drones, have been adopted as part of a new logistic method in the commercial sector called "last-mile delivery". In this novel approach, they are deployed alongside trucks to deliver goods to customers to improve the quality of service and reduce the transportation cost. This approach gives rise to a new variant of the traveling salesman problem (TSP), called TSP with drone (TSP-D). A variant of this problem that aims to minimize the time at which truck and drone finish the service (or, in other words, to maximize the quality of service) was studied in the work of Murray and Chu (2015). In contrast, this paper considers a new variant of TSP-D in which the objective is to minimize operational costs including total transportation cost and one created by waste time a vehicle has to wait for the other. The problem is first formulated mathematically. Then, two algorithms are proposed for the solution. The first algorithm (TSP-LS) was adapted from the approach proposed by Murray and Chu (2015), in which an optimal TSP solution is converted to a feasible TSP-D solution by local searches. The second algorithm, a Greedy Randomized Adaptive Search Procedure (GRASP), is based on a new split procedure that optimally splits any TSP tour into a TSP-D solution. After a TSP-D solution has been generated, it is then improved through local search operators. Numerical results obtained on various instances of both objective functions with different sizes and characteristics are presented. The results show that GRASP outperforms TSP-LS in terms of solution quality under an acceptable running time. version:3
arxiv-1608-04329 | GPU-accelerated Gibbs Sampling: a case study of the Horseshoe Probit model | http://arxiv.org/abs/1608.04329 | id:1608.04329 author:Alexander Terenin, Shawfeng Dong, David Draper category:stat.CO cs.DC  published:2016-08-15 summary:Gibbs sampling is a widely used Markov Chain Monte Carlo (MCMC) method for numerically approximating integrals of interest in Bayesian statistics and other mathematical sciences. Many implementations of MCMC methods do not extend easily to parallel computing environments, as their inherently sequential nature incurs a large synchronization cost. In the case study illustrated by this paper, we show how to do Gibbs sampling in a fully data-parallel manner on a graphics processing unit (GPU), for a large class of exchangeable models that admit latent variable representations. We demonstrate our method on a Horseshoe Probit regression model, and find that our implementation scales effectively to thousands of predictors and millions of data points simultaneously. version:4
arxiv-1705-07381 | Generalizing the Role of Determinization in Probabilistic Planning | http://arxiv.org/abs/1705.07381 | id:1705.07381 author:Luis Pineda, Shlomo Zilberstein category:cs.AI  published:2017-05-21 summary:The stochastic shortest path problem (SSP) is a highly expressive model for probabilistic planning. The computational hardness of SSPs has sparked interest in determinization-based planners that can quickly solve large problems. However, existing methods employ a simplistic approach to determinization. In particular, they ignore the possibility of tailoring the determinization to the specific characteristics of the target domain. In this work we examine this question, by showing that learning a good determinization for a planning domain can be done efficiently and can improve performance. Moreover, we show how to directly incorporate probabilistic reasoning into the planning problem when a good determinization is not sufficient by itself. Based on these insights, we introduce a planner, FF-LAO*, that outperforms state-of-the-art probabilistic planners on several well-known competition benchmarks. version:2
arxiv-1111-5239 | Distributed Signal Processing via Chebyshev Polynomial Approximation | http://arxiv.org/abs/1111.5239 | id:1111.5239 author:David I Shuman, Pierre Vandergheynst, Daniel Kressner, Pascal Frossard category:cs.DC  published:2011-11-22 summary:Unions of graph multiplier operators are an important class of linear operators for processing signals defined on graphs. We present a novel method to efficiently distribute the application of these operators. The proposed method features approximations of the graph multipliers by shifted Chebyshev polynomials, whose recurrence relations make them readily amenable to distributed computation. We demonstrate how the proposed method can be applied to distributed processing tasks such as smoothing, denoising, inverse filtering, and semi-supervised classification, and show that the communication requirements of the method scale gracefully with the size of the network. version:3
arxiv-1707-09488 | Cloud Computing - Architecture and Applications | http://arxiv.org/abs/1707.09488 | id:1707.09488 author:Jaydip Sen, Shanrong Zhao, Xiaoying Wang, Guojing Zhang, Mengqin Yang, Jian Wang, Yun Long, Sergey Andreev, Roman Florea, Aleksandr Ometov, Adam Surak, Yevgeni Koucheryavy, Muhammad Ahmad Ashraf, Waleed Tariq Sethi, Abdullah Alfakhri, Saleh Alshebeili, Amr Alasaad category:cs.DC  published:2017-07-29 summary:In the era of Internet of Things and with the explosive worldwide growth of electronic data volume, and associated need of processing, analysis, and storage of such humongous volume of data, it has now become mandatory to exploit the power of massively parallel architecture for fast computation. Cloud computing provides a cheap source of such computing framework for large volume of data for real-time applications. It is, therefore, not surprising to see that cloud computing has become a buzzword in the computing fraternity over the last decade. This book presents some critical applications in cloud frameworks along with some innovation design of algorithms and architecture for deployment in cloud environment. It is a valuable source of knowledge for researchers, engineers, practitioners, and graduate and doctoral students working in the field of cloud computing. It will also be useful for faculty members of graduate schools and universities. version:1
arxiv-1707-09487 | Method and apparatus for automatic text input insertion in digital devices with a restricted number of keys | http://arxiv.org/abs/1707.09487 | id:1707.09487 author:Nikolaos Tselios, Manolis Maragoudakis category:cs.HC cs.AI  published:2017-07-29 summary:A device which contains number of symbol input keys, where the number of available keys is less than the number of symbols of an alphabet of any given language, screen, and dynamic reordering table of the symbols which are mapped onto those keys, according to a disambiguation method based on the previously entered symbols. The device incorporates a previously entered keystrokes tracking mechanism, and the key selected by the user detector, as well as a mechanism to select the dynamic symbol reordering mapped onto this key according to the information contained to the reordering table. The reordering table occurs from a disambiguation method which reorders the symbol appearance. The reordering information occurs from Bayesian Belief network construction and training from text corpora of the specific language. version:1
arxiv-1707-07298 | Preference Reasoning in Matching Procedures: Application to the Admission Post-Baccalaureat Platform | http://arxiv.org/abs/1707.07298 | id:1707.07298 author:Youssef Hamadi, Souhila Kaci category:cs.AI  published:2017-07-23 summary:Because preferences naturally arise and play an important role in many real-life decisions, they are at the backbone of various fields. In particular preferences are increasingly used in almost all matching procedures-based applications. In this work we highlight the benefit of using AI insights on preferences in a large scale application, namely the French Admission Post-Baccalaureat Platform (APB). Each year APB allocates hundreds of thousands first year applicants to universities. This is done automatically by matching applicants preferences to university seats. In practice, APB can be unable to distinguish between applicants which leads to the introduction of random selection. This has created frustration in the French public since randomness, even used as a last mean does not fare well with the republican egalitarian principle. In this work, we provide a solution to this problem. We take advantage of recent AI Preferences Theory results to show how to enhance APB in order to improve expressiveness of applicants preferences and reduce their exposure to random decisions. version:2
arxiv-1707-09457 | Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints | http://arxiv.org/abs/1707.09457 | id:1707.09457 author:Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, Kai-Wei Chang category:cs.AI cs.CL cs.CV stat.ML  published:2017-07-29 summary:Language is increasingly being used to define rich visual recognition problems with supporting image collections sourced from the web. Structured prediction models are used in these tasks to take advantage of correlations between co-occurring labels and visual input but risk inadvertently encoding social biases found in web corpora. In this work, we study data and models associated with multilabel object classification and visual semantic role labeling. We find that (a) datasets for these tasks contain significant gender bias and (b) models trained on these datasets further amplify existing bias. For example, the activity cooking is over 33% more likely to involve females than males in a training set, and a trained model further amplifies the disparity to 68% at test time. We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an algorithm based on Lagrangian relaxation for collective inference. Our method results in almost no performance loss for the underlying recognition task but decreases the magnitude of bias amplification by 47.5% and 40.5% for multilabel classification and visual semantic role labeling, respectively. version:1
arxiv-1707-09455 | Data Transfer Optimization Based on Offline Knowledge Discovery and Adaptive Real-time Sampling | http://arxiv.org/abs/1707.09455 | id:1707.09455 author:MD S Q Zulkar Nine, Kemal Guner, Ziyun Huang, Xiangyu Wang, Jinhui Xu, Tevfik Kosar category:cs.DC  published:2017-07-29 summary:The amount of data moved over dedicated and non-dedicated network links increases much faster than the increase in the network capacity, but the current solutions fail to guarantee even the promised achievable transfer throughputs. In this paper, we propose a novel dynamic throughput optimization model based on mathematical modeling with offline knowledge discovery/analysis and adaptive online decision making. In offline analysis, we mine historical transfer logs to perform knowledge discovery about the transfer characteristics. Online phase uses the discovered knowledge from the offline analysis along with real-time investigation of the network condition to optimize the protocol parameters. As real-time investigation is expensive and provides partial knowledge about the current network status, our model uses historical knowledge about the network and data to reduce the real-time investigation overhead while ensuring near optimal throughput for each transfer. Our network and data agnostic solution is tested over different networks and achieved up to 93% accuracy compared with the optimal achievable throughput possible on those networks. version:1
arxiv-1707-09450 | Address Translation Design Tradeoffs for Heterogeneous Systems | http://arxiv.org/abs/1707.09450 | id:1707.09450 author:Yunsung Kim, Guilherme Cox, Martha A. Kim, Abhishek Bhattacharjee category:cs.AR cs.PF  published:2017-07-29 summary:This paper presents a broad, pathfinding design space exploration of memory management units (MMUs) for heterogeneous systems. We consider a variety of designs, ranging from accelerators tightly coupled with CPUs (and using their MMUs) to fully independent accelerators that have their own MMUs. We find that regardless of the CPU-accelerator communication, accelerators should not rely on the CPU MMU for any aspect of address translation, and instead must have its own, local, fully-fledged MMU. That MMU, however, can and should be as application-specific as the accelerator itself, as our data indicates that even a 100% hit rate in a small, standard L1 Translation Lookaside Buffer (TLB) presents a substantial accelerator performance overhead. Furthermore, we isolate the benefits of individual MMU components (e.g., TLBs versus page table walkers) and discover that their relative performance, area, and energy are workload dependent, with their interplay resulting in different area-optimal and energy-optimal configurations. version:1
arxiv-1707-09422 | Hyperprofile-based Computation Offloading for Mobile Edge Networks | http://arxiv.org/abs/1707.09422 | id:1707.09422 author:Andrew Crutcher, Caleb Koch, Kyle Coleman, Jon Patman, Flavio Esposito, Prasad Calyam category:cs.NI cs.AI  published:2017-07-28 summary:In recent studies, researchers have developed various computation offloading frameworks for bringing cloud services closer to the user via edge networks. Specifically, an edge device needs to offload computationally intensive tasks because of energy and processing constraints. These constraints present the challenge of identifying which edge nodes should receive tasks to reduce overall resource consumption. We propose a unique solution to this problem which incorporates elements from Knowledge-Defined Networking (KDN) to make intelligent predictions about offloading costs based on historical data. Each server instance can be represented in a multidimensional feature space where each dimension corresponds to a predicted metric. We compute features for a "hyperprofile" and position nodes based on the predicted costs of offloading a particular task. We then perform a k-Nearest Neighbor (kNN) query within the hyperprofile to select nodes for offloading computation. This paper formalizes our hyperprofile-based solution and explores the viability of using machine learning (ML) techniques to predict metrics useful for computation offloading. We also investigate the effects of using different distance metrics for the queries. Our results show various network metrics can be modeled accurately with regression, and there are circumstances where kNN queries using Euclidean distance as opposed to rectilinear distance is more favorable. version:1
arxiv-1707-09414 | Optimized Broadcast for Deep Learning Workloads on Dense-GPU InfiniBand Clusters: MPI or NCCL? | http://arxiv.org/abs/1707.09414 | id:1707.09414 author:Ammar Ahmad Awan, Ching-Hsiang Chu, Hari Subramoni, Dhabaleswar K. Panda category:cs.DC  published:2017-07-28 summary:Dense Multi-GPU systems have recently gained a lot of attention in the HPC arena. Traditionally, MPI runtimes have been primarily designed for clusters with a large number of nodes. However, with the advent of MPI+CUDA applications and CUDA-Aware MPI runtimes like MVAPICH2 and OpenMPI, it has become important to address efficient communication schemes for such dense Multi-GPU nodes. This coupled with new application workloads brought forward by Deep Learning frameworks like Caffe and Microsoft CNTK pose additional design constraints due to very large message communication of GPU buffers during the training phase. In this context, special-purpose libraries like NVIDIA NCCL have been proposed for GPU-based collective communication on dense GPU systems. In this paper, we propose a pipelined chain (ring) design for the MPI_Bcast collective operation along with an enhanced collective tuning framework in MVAPICH2-GDR that enables efficient intra-/inter-node multi-GPU communication. We present an in-depth performance landscape for the proposed MPI_Bcast schemes along with a comparative analysis of NVIDIA NCCL Broadcast and NCCL-based MPI_Bcast. The proposed designs for MVAPICH2-GDR enable up to 14X and 16.6X improvement, compared to NCCL-based solutions, for intra- and inter-node broadcast latency, respectively. In addition, the proposed designs provide up to 7% improvement over NCCL-based solutions for data parallel training of the VGG network on 128 GPUs using Microsoft CNTK. version:1
arxiv-1707-09405 | Photographic Image Synthesis with Cascaded Refinement Networks | http://arxiv.org/abs/1707.09405 | id:1707.09405 author:Qifeng Chen, Vladlen Koltun category:cs.CV cs.AI cs.GR cs.LG  published:2017-07-28 summary:We present an approach to synthesizing photographic images conditioned on semantic layouts. Given a semantic label map, our approach produces an image with photographic appearance that conforms to the input layout. The approach thus functions as a rendering engine that takes a two-dimensional semantic specification of the scene and produces a corresponding photographic image. Unlike recent and contemporaneous work, our approach does not rely on adversarial training. We show that photographic images can be synthesized from semantic layouts by a single feedforward network with appropriate structure, trained end-to-end with a direct regression objective. The presented approach scales seamlessly to high resolutions; we demonstrate this by synthesizing photographic images at 2-megapixel resolution, the full resolution of our training data. Extensive perceptual experiments on datasets of outdoor and indoor scenes demonstrate that images synthesized by the presented approach are considerably more realistic than alternative approaches. The results are shown in the supplementary video at https://youtu.be/0fhUJT21-bs version:1
arxiv-1707-09393 | Online Inverse Reinforcement Learning via Bellman Gradient Iteration | http://arxiv.org/abs/1707.09393 | id:1707.09393 author:Kun Li, Joel W. Burdick category:cs.RO  published:2017-07-28 summary:This paper develops an online inverse reinforcement learning algorithm aimed at efficiently recovering a reward function from ongoing observations of an agent's actions. To reduce the computation time and storage space in reward estimation, this work assumes that each observed action implies a change of the Q-value distribution, and relates the change to the reward function via the gradient of Q-value with respect to reward function parameter. The gradients are computed with a novel Bellman Gradient Iteration method that allows the reward function to be updated whenever a new observation is available. The method's convergence to a local optimum is proved. This work tests the proposed method in two simulated environments, and evaluates the algorithm's performance under a linear reward function and a non-linear reward function. The results show that the proposed algorithm only requires a limited computation time and storage space, but achieves an increasing accuracy as the number of observations grows. We also present a potential application to robot cleaners at home. version:1
arxiv-1707-09376 | Face Deidentification with Generative Deep Neural Networks | http://arxiv.org/abs/1707.09376 | id:1707.09376 author:Blaž Meden, Refik Can Mallı, Sebastjan Fabijan, Hazım Kemal Ekenel, Vitomir Štruc, Peter Peer category:cs.CV cs.AI cs.LG  published:2017-07-28 summary:Face deidentification is an active topic amongst privacy and security researchers. Early deidentification methods relying on image blurring or pixelization were replaced in recent years with techniques based on formal anonymity models that provide privacy guaranties and at the same time aim at retaining certain characteristics of the data even after deidentification. The latter aspect is particularly important, as it allows to exploit the deidentified data in applications for which identity information is irrelevant. In this work we present a novel face deidentification pipeline, which ensures anonymity by synthesizing artificial surrogate faces using generative neural networks (GNNs). The generated faces are used to deidentify subjects in images or video, while preserving non-identity-related aspects of the data and consequently enabling data utilization. Since generative networks are very adaptive and can utilize a diverse set of parameters (pertaining to the appearance of the generated output in terms of facial expressions, gender, race, etc.), they represent a natural choice for the problem of face deidentification. To demonstrate the feasibility of our approach, we perform experiments using automated recognition tools and human annotators. Our results show that the recognition performance on deidentified images is close to chance, suggesting that the deidentification process based on GNNs is highly effective. version:1
arxiv-1707-09324 | Empirical Evaluation of Abstract Argumentation: Supporting the Need for Bipolar and Probabilistic Approaches | http://arxiv.org/abs/1707.09324 | id:1707.09324 author:Sylwia Polberg, Anthony Hunter category:cs.AI  published:2017-07-28 summary:In dialogical argumentation it is often assumed that the involved parties always correctly identify the intended statements posited by each other, realize all of the associated relations, conform to the three acceptability states (accepted, rejected, undecided), adjust their views when new and correct information comes in, and that a framework handling only attack relations is sufficient to represent their opinions. Although it is natural to make these assumptions as a starting point for further research, removing them or even acknowledging that such removal should happen is more challenging for some of these concepts than for others. Probabilistic argumentation is one of the approaches that can be harnessed for more accurate user modelling. The epistemic approach allows us to represent how much a given argument is believed by a given person, offering us the possibility to express more than just three agreement states. It is equipped with a wide range of postulates, including those that do not make any restrictions concerning how initial arguments should be viewed, thus potentially being more adequate for handling beliefs of the people that have not fully disclosed their opinions in comparison to Dung's semantics. The constellation approach can be used to represent the views of different people concerning the structure of the framework we are dealing with, including cases in which not all relations are acknowledged or when they are seen differently than intended. Finally, bipolar argumentation frameworks can be used to express both positive and negative relations between arguments. In this paper we describe the results of an experiment in which participants judged dialogues in terms of agreement and structure. We compare our findings with the aforementioned assumptions as well as with the constellation and epistemic approaches to probabilistic argumentation and bipolar argumentation. version:1
arxiv-1707-09317 | A Minimum-Cost Flow Model for Workload Optimization on Cloud Infrastructure | http://arxiv.org/abs/1707.09317 | id:1707.09317 author:Frederick Nwanganga, Mandana Saebi, Gregory Madey, Nitesh Chawla category:cs.DC  published:2017-07-28 summary:Recent technology advancements in the areas of compute, storage and networking, along with the increased demand for organizations to cut costs while remaining responsive to increasing service demands have led to the growth in the adoption of cloud computing services. Cloud services provide the promise of improved agility, resiliency, scalability and a lowered Total Cost of Ownership (TCO). This research introduces a framework for minimizing cost and maximizing resource utilization by using an Integer Linear Programming (ILP) approach to optimize the assignment of workloads to servers on Amazon Web Services (AWS) cloud infrastructure. The model is based on the classical minimum-cost flow model, known as the assignment model. version:1
arxiv-1707-09315 | Self-Synchronization in Duty-cycled Internet of Things (IoT) Applications | http://arxiv.org/abs/1707.09315 | id:1707.09315 author:Poonam Yadav, Julie A. McCann, Tiago Pereira category:cs.DC  published:2017-07-28 summary:In recent years, the networks of low-power devices have gained popularity. Typically these devices are wireless and interact to form large networks such as the Machine to Machine (M2M) networks, Internet of Things (IoT), Wearable Computing, and Wireless Sensor Networks. The collaboration among these devices is a key to achieving the full potential of these networks. A major problem in this field is to guarantee robust communication between elements while keeping the whole network energy efficient. In this paper, we introduce an extended and improved emergent broadcast slot (EBS) scheme, which facilitates collaboration for robust communication and is energy efficient. In the EBS, nodes communication unit remains in sleeping mode and are awake just to communicate. The EBS scheme is fully decentralized, that is, nodes coordinate their wake-up window in partially overlapped manner within each duty-cycle to avoid message collisions. We show the theoretical convergence behavior of the scheme, which is confirmed through real test-bed experimentation. version:1
arxiv-1707-02919 | A Brief Survey of Text Mining: Classification, Clustering and Extraction Techniques | http://arxiv.org/abs/1707.02919 | id:1707.02919 author:Mehdi Allahyari, Seyedamin Pouriyeh, Mehdi Assefi, Saied Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, Krys Kochut category:cs.CL cs.AI cs.IR  published:2017-07-10 summary:The amount of text that is generated every day is increasing dramatically. This tremendous volume of mostly unstructured text cannot be simply processed and perceived by computers. Therefore, efficient and effective techniques and algorithms are required to discover useful patterns. Text mining is the task of extracting meaningful information from text, which has gained significant attentions in recent years. In this paper, we describe several of the most fundamental text mining tasks and techniques including text pre-processing, classification and clustering. Additionally, we briefly explain text mining in biomedical and health care domains. version:2
arxiv-1707-09242 | Consistency models with global operation sequencing and their composition (extended version) | http://arxiv.org/abs/1707.09242 | id:1707.09242 author:Alexey Gotsman, Sebastian Burckhardt category:cs.DC cs.LO  published:2017-07-28 summary:Modern distributed systems often achieve availability and scalability by providing consistency guarantees about the data they manage weaker than linearizability. We consider a class of such consistency models that, despite this weakening, guarantee that clients eventually agree on a global sequence of operations, while seeing a subsequence of this final sequence at any given point of time. Examples of such models include the classical Total Store Order (TSO) and recently proposed dual TSO, Global Sequence Protocol (GSP) and Ordered Sequential Consistency. We define a unified model, called Global Sequence Consistency (GSC), that has the above models as its special cases, and investigate its key properties. First, we propose a condition under which multiple objects each satisfying GSC can be composed so that the whole set of objects satisfies GSC. Second, we prove an interesting relationship between special cases of GSC---GSP, TSO and dual TSO: we show that clients that do not communicate out-of-band cannot tell the difference between these models. To obtain these results, we propose a novel axiomatic specification of GSC and prove its equivalence to the operational definition of the model. version:1
arxiv-1707-09226 | Modeling and Control of Humanoid Robots in Dynamic Environments: iCub Balancing on a Seesaw | http://arxiv.org/abs/1707.09226 | id:1707.09226 author:Gabriele Nava, Daniele Pucci, Nuno Guedelha, Silvio Traversaro, Francesco Romano, Stefano Dafarra, Francesco Nori category:cs.RO  published:2017-07-28 summary:Future applications involving humanoid robots may require physical interaction between the robot and a dynamic environment. In this case, classical balancing and walking controllers that neglect the environment dynamics may not be sufficient for achieving a stable robot behaviour. This paper presents a modeling and control framework for balancing humanoid robots in contact with a dynamic environment. We first model the dynamics of the robot and the environment, together with the contact constraints. Then, a control strategy for stabilizing the extended system is proposed. Theoretical results are verified in simulation with a model of the robot iCub balancing on a seesaw. version:1
arxiv-1705-10635 | A Predictive Momentum-Based Whole-Body Torque Controller: Theory and Simulations for the iCub Stepping | http://arxiv.org/abs/1705.10635 | id:1705.10635 author:Stefano Dafarra, Francesco Romano, Gabriele Nava, Francesco Nori category:cs.RO  published:2017-05-30 summary:When balancing, a humanoid robot can be easily subjected to unexpected disturbances like external pushes. In these circumstances, reactive movements as steps become a necessary requirement in order to avoid potentially harmful falling states. In this paper we conceive a Model Predictive Controller which determines a desired set of contact wrenches by predicting the future evolution of the robot, while taking into account constraints switching in case of steps. The control inputs computed by this strategy, namely the desired contact wrenches, are directly obtained on the robot through a modification of the momentum-based whole-body torque controller currently implemented on iCub. The proposed approach is validated through simulations in a stepping scenario, revealing high robustness and reliability when executing a recovery strategy. version:2
arxiv-1707-09098 | MEMEN: Multi-layer Embedding with Memory Networks for Machine Comprehension | http://arxiv.org/abs/1707.09098 | id:1707.09098 author:Boyuan Pan, Hao Li, Zhou Zhao, Bin Cao, Deng Cai, Xiaofei He category:cs.AI cs.CL  published:2017-07-28 summary:Machine comprehension(MC) style question answering is a representative problem in natural language processing. Previous methods rarely spend time on the improvement of encoding layer, especially the embedding of syntactic information and name entity of the words, which are very crucial to the quality of encoding. Moreover, existing attention methods represent each query word as a vector or use a single vector to represent the whole query sentence, neither of them can handle the proper weight of the key words in query sentence. In this paper, we introduce a novel neural network architecture called Multi-layer Embedding with Memory Network(MEMEN) for machine reading task. In the encoding layer, we employ classic skip-gram model to the syntactic and semantic information of the words to train a new kind of embedding layer. We also propose a memory network of full-orientation matching of the query and passage to catch more pivotal information. Experiments show that our model has competitive results both from the perspectives of precision and efficiency in Stanford Question Answering Dataset(SQuAD) among all published results and achieves the state-of-the-art results on TriviaQA dataset. version:1
arxiv-1707-09079 | Learning to Teach Reinforcement Learning Agents | http://arxiv.org/abs/1707.09079 | id:1707.09079 author:Anestis Fachantidis, Matthew E. Taylor, Ioannis Vlahavas category:cs.AI  published:2017-07-28 summary:In this article we study the transfer learning model of action advice under a budget. We focus on reinforcement learning teachers providing action advice to heterogeneous students playing the game of Pac-Man under a limited advice budget. First, we examine several critical factors affecting advice quality in this setting, such as the average performance of the teacher, its variance and the importance of reward discounting in advising. The experiments show the non-trivial importance of the coefficient of variation (CV) as a statistic for choosing policies that generate advice. The CV statistic relates variance to the corresponding mean. Second, the article studies policy learning for distributing advice under a budget. Whereas most methods in the relevant literature rely on heuristics for advice distribution we formulate the problem as a learning one and propose a novel RL algorithm capable of learning when to advise, adapting to the student and the task at hand. Furthermore, we argue that learning to advise under a budget is an instance of a more generic learning problem: Constrained Exploitation Reinforcement Learning. version:1
arxiv-1707-07763 | Domain Recursion for Lifted Inference with Existential Quantifiers | http://arxiv.org/abs/1707.07763 | id:1707.07763 author:Seyed Mehran Kazemi, Angelika Kimmig, Guy Van den Broeck, David Poole category:cs.AI  published:2017-07-24 summary:In recent work, we proved that the domain recursion inference rule makes domain-lifted inference possible on several relational probability models (RPMs) for which the best known time complexity used to be exponential. We also identified two classes of RPMs for which inference becomes domain lifted when using domain recursion. These two classes subsume the largest lifted classes that were previously known. In this paper, we show that domain recursion can also be applied to models with existential quantifiers. Currently, all lifted inference algorithms assume that existential quantifiers have been removed in pre-processing by Skolemization. We show that besides introducing potentially inconvenient negative weights, Skolemization may increase the time complexity of inference. We give two example models where domain recursion can replace Skolemization, avoids the need for dealing with negative numbers, and reduces the time complexity of inference. These two examples may be interesting from three theoretical aspects: 1- they provide a better and deeper understanding of domain recursion and, in general, (lifted) inference, 2- they may serve as evidence that there are larger classes of models for which domain recursion can satisfyingly replace Skolemization, and 3- they may serve as evidence that better Skolemization techniques exist. version:2
arxiv-1707-09062 | Deep Kernels for Optimizing Locomotion Controllers | http://arxiv.org/abs/1707.09062 | id:1707.09062 author:Rika Antonova, Akshara Rai, Christopher G. Atkeson category:cs.RO cs.LG  published:2017-07-27 summary:Sample efficiency is important when optimizing parameters of locomotion controllers, since hardware experiments are time consuming and expensive. Bayesian Optimization, a sample-efficient optimization framework, has recently been widely applied to address this problem, but further improvements in sample efficiency are needed for practical applicability to real-world robots and high-dimensional controllers. To address this, prior work has proposed using domain expertise for constructing custom distance metrics for locomotion. In this work we show how to learn such a distance metric automatically, without relying on domain experts. We use a neural network to learn an informed distance metric from data obtained in high-fidelity simulations. We conduct experiments on two different controllers and robot architectures. First, we demonstrate improvement in sample efficiency when optimizing a 5-dimensional controller on the ATRIAS robot hardware. We then conduct simulation experiments to optimize a 16-dimensional controller for a 7-link robot model and obtain significant improvements even when optimizing in perturbed environments. This demonstrates that our approach is able to enhance sample efficiency for two different controllers, hence is a fitting candidate for further experiments on hardware in the future. version:1
arxiv-1707-08989 | Monocular Visual Teach and Repeat Aided by Local Ground Planarity | http://arxiv.org/abs/1707.08989 | id:1707.08989 author:Lee Clement, Jonathan Kelly, Timothy D. Barfoot category:cs.RO  published:2017-07-27 summary:Visual Teach and Repeat (VT\&R) allows an autonomous vehicle to repeat a previously traversed route without a global positioning system. Existing implementations of VT\&R typically rely on 3D sensors such as stereo cameras for mapping and localization, but many mobile robots are equipped with only 2D monocular vision for tasks such as teleoperated bomb disposal. While simultaneous localization and mapping (SLAM) algorithms exist that can recover 3D structure and motion from monocular images, the scale ambiguity inherent in these methods complicates the estimation and control of lateral path-tracking error, which is essential for achieving high-accuracy path following. In this paper, we propose a monocular vision pipeline that enables kilometre-scale route repetition with centimetre-level accuracy by approximating the ground surface near the vehicle as planar (with some uncertainty) and recovering absolute scale from the known position and orientation of the camera relative to the vehicle. This system provides added value to many existing robots by allowing for high-accuracy autonomous route repetition with a simple software upgrade and no additional sensors. We validate our system over 4.3 km of autonomous navigation and demonstrate accuracy on par with the conventional stereo pipeline, even in highly non-planar terrain. version:1
arxiv-1707-08912 | A Family of Metrics for Clustering Algorithms | http://arxiv.org/abs/1707.08912 | id:1707.08912 author:Clark Alexander, Sofya Akhmametyeva category:cs.DM cs.AI cs.CG  published:2017-07-27 summary:We give the motivation for scoring clustering algorithms and a metric $M : A \rightarrow \mathbb{N}$ from the set of clustering algorithms to the natural numbers which we realize as \begin{equation} M(A) = \sum_i \alpha_i f_i - \beta_i ^{w_i} \end{equation} where $\alpha_i,\beta_i,w_i$ are parameters used for scoring the feature $f_i$, which is computed empirically.. We give a method by which one can score features such as stability, noise sensitivity, etc and derive the necessary parameters. We conclude by giving a sample set of scores. version:1
arxiv-1705-07262 | Batch Reinforcement Learning on the Industrial Benchmark: First Experiences | http://arxiv.org/abs/1705.07262 | id:1705.07262 author:Daniel Hein, Steffen Udluft, Michel Tokic, Alexander Hentschel, Thomas A. Runkler, Volkmar Sterzing category:cs.LG cs.AI cs.NE cs.SY  published:2017-05-20 summary:The Particle Swarm Optimization Policy (PSO-P) has been recently introduced and proven to produce remarkable results on interacting with academic reinforcement learning benchmarks in an off-policy, batch-based setting. To further investigate the properties and feasibility on real-world applications, this paper investigates PSO-P on the so-called Industrial Benchmark (IB), a novel reinforcement learning (RL) benchmark that aims at being realistic by including a variety of aspects found in industrial applications, like continuous state and action spaces, a high dimensional, partially observable state space, delayed effects, and complex stochasticity. The experimental results of PSO-P on IB are compared to results of closed-form control policies derived from the model-based Recurrent Control Neural Network (RCNN) and the model-free Neural Fitted Q-Iteration (NFQ). Experiments show that PSO-P is not only of interest for academic benchmarks, but also for real-world industrial applications, since it also yielded the best performing policy in our IB setting. Compared to other well established RL techniques, PSO-P produced outstanding results in performance and robustness, requiring only a relatively low amount of effort in finding adequate parameters or making complex design decisions. version:2
arxiv-1707-08901 | Providing Self-Aware Systems with Reflexivity | http://arxiv.org/abs/1707.08901 | id:1707.08901 author:Alessandro Valitutti, Giuseppe Trautteur category:cs.AI  published:2017-07-27 summary:We propose a new type of self-aware systems inspired by ideas from higher-order theories of consciousness. First, we discussed the crucial distinction between introspection and reflexion. Then, we focus on computational reflexion as a mechanism by which a computer program can inspect its own code at every stage of the computation. Finally, we provide a formal definition and a proof-of-concept implementation of computational reflexion, viewed as an enriched form of program interpretation and a way to dynamically "augment" a computational process. version:1
arxiv-1707-08900 | Methods for compressible fluid simulation on GPUs using high-order finite differences | http://arxiv.org/abs/1707.08900 | id:1707.08900 author:Johannes Pekkilä, Miikka S. Väisälä, Maarit J. Käpylä, Petri J. Käpylä, Omer Anjum category:physics.comp-ph astro-ph.IM cs.DC physics.flu-dyn  published:2017-07-27 summary:We focus on implementing and optimizing a sixth-order finite-difference solver for simulating compressible fluids on a GPU using third-order Runge-Kutta integration. Since graphics processing units perform well in data-parallel tasks, this makes them an attractive platform for fluid simulation. However, high-order stencil computation is memory-intensive with respect to both main memory and the caches of the GPU. We present two approaches for simulating compressible fluids using 55-point and 19-point stencils. We seek to reduce the requirements for memory bandwidth and cache size in our methods by using cache blocking and decomposing a latency-bound kernel into several bandwidth-bound kernels. Our fastest implementation is bandwidth-bound and integrates $343$ million grid points per second on a Tesla K40t GPU, achieving a $3.6 \times$ speedup over a comparable hydrodynamics solver benchmarked on two Intel Xeon E5-2690v3 processors. Our alternative GPU implementation is latency-bound and achieves the rate of $168$ million updates per second. version:1
arxiv-1707-08879 | Non-Count Symmetries in Boolean & Multi-Valued Prob. Graphical Models | http://arxiv.org/abs/1707.08879 | id:1707.08879 author:Ankit Anand, Ritesh Noothigattu, Parag Singla, Mausam category:cs.AI  published:2017-07-27 summary:Lifted inference algorithms commonly exploit symmetries in a probabilistic graphical model (PGM) for efficient inference. However, existing algorithms for Boolean-valued domains can identify only those pairs of states as symmetric, in which the number of ones and zeros match exactly (count symmetries). Moreover, algorithms for lifted inference in multi-valued domains also compute a multi-valued extension of count symmetries only. These algorithms miss many symmetries in a domain. In this paper, we present first algorithms to compute non-count symmetries in both Boolean-valued and multi-valued domains. Our methods can also find symmetries between multi-valued variables that have different domain cardinalities. The key insight in the algorithms is that they change the unit of symmetry computation from a variable to a variable-value (VV) pair. Our experiments find that exploiting these symmetries in MCMC can obtain substantial computational gains over existing algorithms. version:1
arxiv-1707-08866 | Deep Residual Learning for Weakly-Supervised Relation Extraction | http://arxiv.org/abs/1707.08866 | id:1707.08866 author:Yi Yao Huang, William Yang Wang category:cs.CL cs.AI  published:2017-07-27 summary:Deep residual learning (ResNet) is a new method for training very deep neural networks using identity map-ping for shortcut connections. ResNet has won the ImageNet ILSVRC 2015 classification task, and achieved state-of-the-art performances in many computer vision tasks. However, the effect of residual learning on noisy natural language processing tasks is still not well understood. In this paper, we design a novel convolutional neural network (CNN) with residual learning, and investigate its impacts on the task of distantly supervised noisy relation extraction. In contradictory to popular beliefs that ResNet only works well for very deep networks, we found that even with 9 layers of CNNs, using identity mapping could significantly improve the performance for distantly-supervised relation extraction. version:1
arxiv-1705-04085 | Automatic Extrinsic Calibration for Lidar-Stereo Vehicle Sensor Setups | http://arxiv.org/abs/1705.04085 | id:1705.04085 author:Carlos Guindel, Jorge Beltrán, David Martín, Fernando García category:cs.CV cs.RO 68T45 I.4.8; I.2.9; I.4.1  published:2017-05-11 summary:Sensor setups consisting of a combination of 3D range scanner lasers and stereo vision systems are becoming a popular choice for on-board perception systems in vehicles; however, the combined use of both sources of information implies a tedious calibration process. We present a method for extrinsic calibration of lidar-stereo camera pairs without user intervention. Our calibration approach is aimed to cope with the constraints commonly found in automotive setups, such as low-resolution and specific sensor poses. To demonstrate the performance of our method, we also introduce a novel approach for the quantitative assessment of the calibration results, based on a simulation environment. Tests using real devices have been conducted as well, proving the usability of the system and the improvement over the existing approaches. Code is available at http://wiki.ros.org/velo2cam_calibration version:3
arxiv-1707-08484 | MST in O(1) Rounds of the Congested Clique | http://arxiv.org/abs/1707.08484 | id:1707.08484 author:Tomasz Jurdzinski, Krzysztof Nowicki category:cs.DC cs.DS  published:2017-07-26 summary:We present a distributed randomized algorithm finding Minimum Spanning Tree (MST) of a given graph in O(1) rounds, with high probability, in the Congested Clique model. The input graph in the Congested Clique model is a graph of n nodes, where each node initially knows only its incident edges. The communication graph is a clique with limited edge bandwidth: each two nodes (not necessarily neighbours in the input graph) can exchange $O(\log n)$ bits. As in previous works, the key part of the MST algorithm is an efficient Connected Components (CC) algorithm. However, unlike the former approaches, we do not aim at simulating the standard Boruvka algorithm, at least at initial stages of the CC algorithm. Instead, we develop a new technique which combines connected components of sample sparse subgraphs of the input graph in order to accelerate the process of uncovering connected components of the original input graph. More specifically, we develop a sparsification technique which reduces an initial CC problem in $O(1)$ rounds to its two restricted instances. The former instance has a graph with maximal degree $O(\log \log n)$ as the input -- here our sample-combining technique helps. In the latter instance, a partition of the input graph into $O(n/\log \log n)$ connected components is known. This gives an opportunity to apply previous algorithms to determine connected components in $O(1)$ rounds. Our result improves over previous $O(\log* n)$ algorithm of Ghaffari et al. [PODC 2016], $O(\log \log \log n)$ algorithm of Hegeman et al. [PODC 2015] and the $O(\log \log n)$ algorithm of Lotker et al. [SPAA 2003; SICOMP 2005]. It also determines $\Theta(1)$ round complexity in the congested clique for MST, as well as other graph problems, including bipartiteness, cut verification, s-t connectivity, cycle containment and $O(\log \Delta)$ round complexity of the maximal independent set (MIS). version:2
arxiv-1707-08817 | Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards | http://arxiv.org/abs/1707.08817 | id:1707.08817 author:Matej Večerík, Todd Hester, Jonathan Scholz, Fumin Wang, Olivier Pietquin, Bilal Piot, Nicolas Heess, Thomas Rothörl, Thomas Lampe, Martin Riedmiller category:cs.AI  published:2017-07-27 summary:We propose a general and model-free approach for Reinforcement Learning (RL) on real robotics with sparse rewards. We build upon the Deep Deterministic Policy Gradient (DDPG) algorithm to use demonstrations. Both demonstrations and actual interactions are used to fill a replay buffer and the sampling ratio between demonstrations and transitions is automatically tuned via a prioritized replay mechanism. Typically, carefully engineered shaping rewards are required to enable the agents to efficiently explore on high dimensional control problems such as robotics. They are also required for model-based acceleration methods relying on local solvers such as iLQG (e.g. Guided Policy Search and Normalized Advantage Function). The demonstrations replace the need for carefully engineered rewards, and reduce the exploration problem encountered by classical RL approaches in these domains. Demonstrations are collected by a robot kinesthetically force-controlled by a human demonstrator. Results on four simulated insertion tasks show that DDPG from demonstrations out-performs DDPG, and does not require engineered rewards. Finally, we demonstrate the method on a real robotics task consisting of inserting a clip (flexible object) into a rigid object. version:1
arxiv-1708-06334 | An Intelligent Cloud Storage Gateway for Medical Imaging | http://arxiv.org/abs/1708.06334 | id:1708.06334 author:Carlos Viana-Ferreira, António Guerra, João F. Silva, Sérgio Matos, Carlos Costa category:cs.DC  published:2017-07-27 summary:Historically, medical imaging repositories have been supported by indoor infrastructures. However, the amount of diagnostic imaging procedures has continuously increased over the last decades, imposing several challenges associated with the storage volume, data redundancy and availability. Cloud platforms are focused on delivering hardware and software services over the Internet, becoming an appealing solution for repository outsourcing. Although this option may bring financial and technological benefits, it also presents new challenges. In medical imaging scenarios, communication latency is a critical issue that still hinders the adoption of this paradigm. This paper proposes an intelligent Cloud storage gateway that optimizes data access times. This is achieved through a new cache architecture that combines static rules and pattern recognition for eviction and prefetching. The evaluation results, obtained through simulations over a real-world dataset, show that cache hit ratios can reach around 80%, leading reductions of image retrieval times by over 60%. The combined use of eviction and prefetching policies pro- posed can significantly reduce communication latency, even when using a small cache in comparison to the total size of the repository. Apart from the performance gains, the proposed system is capable of adjusting to specific workflows of different institutions. version:1
arxiv-1707-08764 | A New Modal Framework for Epistemic Logic | http://arxiv.org/abs/1707.08764 | id:1707.08764 author:Yanjing Wang category:cs.AI cs.LO  published:2017-07-27 summary:Recent years witnessed a growing interest in non-standard epistemic logics of knowing whether, knowing how, knowing what, knowing why and so on. The new epistemic modalities introduced in those logics all share, in their semantics, the general schema of $\exists x \Box \phi$, e.g., knowing how to achieve $\phi$ roughly means that there exists a way such that you know that it is a way to ensure that $\phi$. Moreover, the resulting logics are decidable. Inspired by those particular logics, in this work, we propose a very general and powerful framework based on quantifier-free predicate language extended by a new modality $\Box^x$, which packs exactly $\exists x \Box$ together. We show that the resulting language, though much more expressive, shares many good properties of the basic propositional modal logic over arbitrary models, such as finite-tree-model property and van Benthem-like characterization w.r.t.\ first-order modal logic. We axiomatize the logic over S5 frames with intuitive axioms to capture the interaction between $\Box^x$ and know-that operator in an epistemic setting. version:1
arxiv-1707-08763 | Reconciling Bayesian Epistemology and Narration-based Approaches to Judiciary Fact-finding | http://arxiv.org/abs/1707.08763 | id:1707.08763 author:Rafal Urbaniak category:cs.AI cs.LO  published:2017-07-27 summary:Legal probabilism (LP) claims the degrees of conviction in juridical fact-finding are to be modeled exactly the way degrees of beliefs are modeled in standard bayesian epistemology. Classical legal probabilism (CLP) adds that the conviction is justified if the credence in guilt given the evidence is above an appropriate guilt probability threshold. The views are challenged on various counts, especially by the proponents of the so-called narrative approach, on which the fact-finders' decision is the result of a dynamic interplay between competing narratives of what happened. I develop a way a bayesian epistemologist can make sense of the narrative approach. I do so by formulating a probabilistic framework for evaluating competing narrations in terms of formal explications of the informal evaluation criteria used in the narrative approach. version:1
arxiv-1707-08762 | Argument-based Belief in Topological Structures | http://arxiv.org/abs/1707.08762 | id:1707.08762 author:Chenwei Shi, Sonja Smets, Fernando R. Velázquez-Quesada category:cs.AI cs.LO  published:2017-07-27 summary:This paper combines two studies: a topological semantics for epistemic notions and abstract argumentation theory. In our combined setting, we use a topological semantics to represent the structure of an agent's collection of evidence, and we use argumentation theory to single out the relevant sets of evidence through which a notion of beliefs grounded on arguments is defined. We discuss the formal properties of this newly defined notion, providing also a formal language with a matching modality together with a sound and complete axiom system for it. Despite the fact that our agent can combine her evidence in a 'rational' way (captured via the topological structure), argument-based beliefs are not closed under conjunction. This illustrates the difference between an agent's reasoning abilities (i.e. the way she is able to combine her available evidence) and the closure properties of her beliefs. We use this point to argue for why the failure of closure under conjunction of belief should not bear the burden of the failure of rationality. version:1
arxiv-1707-08759 | Together We Know How to Achieve: An Epistemic Logic of Know-How (Extended Abstract) | http://arxiv.org/abs/1707.08759 | id:1707.08759 author:Pavel Naumov, Jia Tao category:cs.AI cs.LO  published:2017-07-27 summary:The existence of a coalition strategy to achieve a goal does not necessarily mean that the coalition has enough information to know how to follow the strategy. Neither does it mean that the coalition knows that such a strategy exists. The paper studies an interplay between the distributed knowledge, coalition strategies, and coalition "know-how" strategies. The main technical result is a sound and complete trimodal logical system that describes the properties of this interplay. version:1
arxiv-1707-08755 | Group Recommendations: Axioms, Impossibilities, and Random Walks | http://arxiv.org/abs/1707.08755 | id:1707.08755 author:Omer Lev, Moshe Tennenholtz category:cs.SI cs.AI cs.GT cs.MA  published:2017-07-27 summary:We introduce an axiomatic approach to group recommendations, in line of previous work on the axiomatic treatment of trust-based recommendation systems, ranking systems, and other foundational work on the axiomatic approach to internet mechanisms in social choice settings. In group recommendations we wish to recommend to a group of agents, consisting of both opinionated and undecided members, a joint choice that would be acceptable to them. Such a system has many applications, such as choosing a movie or a restaurant to go to with a group of friends, recommending games for online game players, & other communal activities. Our method utilizes a given social graph to extract information on the undecided, relying on the agents influencing them. We first show that a set of fairly natural desired requirements (a.k.a axioms) leads to an impossibility, rendering mutual satisfaction of them unreachable. However, we also show a modified set of axioms that fully axiomatize a group variant of the random-walk recommendation system, expanding a previous result from the individual recommendation case. version:1
arxiv-1707-08751 | A Knowledge-Based Analysis of the Blockchain Protocol | http://arxiv.org/abs/1707.08751 | id:1707.08751 author:Joseph Y. Halpern, Rafael Pass category:cs.CR cs.DC cs.LO  published:2017-07-27 summary:At the heart of the Bitcoin is a blockchain protocol, a protocol for achieving consensus on a public ledger that records bitcoin transactions. To the extent that a blockchain protocol is used for applications such as contract signing and making certain transactions (such as house sales) public, we need to understand what guarantees the protocol gives us in terms of agents' knowledge. Here, we provide a complete characterization of agent's knowledge when running a blockchain protocol using a variant of common knowledge that takes into account the fact that agents can enter and leave the system, it is not known which agents are in fact following the protocol (some agents may want to deviate if they can gain by doing so), and the fact that the guarantees provided by blockchain protocols are probabilistic. We then consider some scenarios involving contracts and show that this level of knowledge suffices for some scenarios, but not others. version:1
arxiv-1707-08750 | An Epistemic Foundation for Authentication Logics (Extended Abstract) | http://arxiv.org/abs/1707.08750 | id:1707.08750 author:Joseph Y. Halpern, Ron van der Meyden, Riccardo Pucella category:cs.CR cs.AI cs.LO cs.MA  published:2017-07-27 summary:While there have been many attempts, going back to BAN logic, to base reasoning about security protocols on epistemic notions, they have not been all that successful. Arguably, this has been due to the particular logics chosen. We present a simple logic based on the well-understood modal operators of knowledge, time, and probability, and show that it is able to handle issues that have often been swept under the rug by other approaches, while being flexible enough to capture all the higher- level security notions that appear in BAN logic. Moreover, while still assuming that the knowledge operator allows for unbounded computation, it can handle the fact that a computationally bounded agent cannot decrypt messages in a natural way, by distinguishing strings and message terms. We demonstrate that our logic can capture BAN logic notions by providing a translation of the BAN operators into our logic, capturing belief by a form of probabilistic knowledge. version:1
arxiv-1707-09378 | The Topology of Statistical Verifiability | http://arxiv.org/abs/1707.09378 | id:1707.09378 author:Konstantin Genin, Kevin T. Kelly category:cs.LG cs.AI math.PR  published:2017-07-27 summary:Topological models of empirical and formal inquiry are increasingly prevalent. They have emerged in such diverse fields as domain theory [1, 16], formal learning theory [18], epistemology and philosophy of science [10, 15, 8, 9, 2], statistics [6, 7] and modal logic [17, 4]. In those applications, open sets are typically interpreted as hypotheses deductively verifiable by true propositional information that rules out relevant possibilities. However, in statistical data analysis, one routinely receives random samples logically compatible with every statistical hypothesis. We bridge the gap between propositional and statistical data by solving for the unique topology on probability measures in which the open sets are exactly the statistically verifiable hypotheses. Furthermore, we extend that result to a topological characterization of learnability in the limit from statistical data. version:1
arxiv-1707-08741 | Binary Voting with Delegable Proxy: An Analysis of Liquid Democracy | http://arxiv.org/abs/1707.08741 | id:1707.08741 author:Zoé Christoff, Davide Grossi category:cs.MA cs.AI cs.CY cs.GT  published:2017-07-27 summary:The paper provides an analysis of the voting method known as delegable proxy voting, or liquid democracy. The analysis first positions liquid democracy within the theory of binary aggregation. It then focuses on two issues of the system: the occurrence of delegation cycles; and the effect of delegations on individual rationality when voting on logically interdependent propositions. It finally points to proposals on how the system may be modified in order to address the above issues. version:1
arxiv-1707-08740 | Preservation of Semantic Properties during the Aggregation of Abstract Argumentation Frameworks | http://arxiv.org/abs/1707.08740 | id:1707.08740 author:Weiwei Chen, Ulle Endriss category:cs.AI  published:2017-07-27 summary:An abstract argumentation framework can be used to model the argumentative stance of an agent at a high level of abstraction, by indicating for every pair of arguments that is being considered in a debate whether the first attacks the second. When modelling a group of agents engaged in a debate, we may wish to aggregate their individual argumentation frameworks to obtain a single such framework that reflects the consensus of the group. Even when agents disagree on many details, there may well be high-level agreement on important semantic properties, such as the acceptability of a given argument. Using techniques from social choice theory, we analyse under what circumstances such semantic properties agreed upon by the individual agents can be preserved under aggregation. version:1
arxiv-1707-08736 | Relaxing Exclusive Control in Boolean Games | http://arxiv.org/abs/1707.08736 | id:1707.08736 author:Francesco Belardinelli, Umberto Grandi, Andreas Herzig, Dominique Longin, Emiliano Lorini, Arianna Novaro, Laurent Perrussel category:cs.AI cs.LO  published:2017-07-27 summary:In the typical framework for boolean games (BG) each player can change the truth value of some propositional atoms, while attempting to make her goal true. In standard BG goals are propositional formulas, whereas in iterated BG goals are formulas of Linear Temporal Logic. Both notions of BG are characterised by the fact that agents have exclusive control over their set of atoms, meaning that no two agents can control the same atom. In the present contribution we drop the exclusivity assumption and explore structures where an atom can be controlled by multiple agents. We introduce Concurrent Game Structures with Shared Propositional Control (CGS-SPC) and show that they ac- count for several classes of repeated games, including iterated boolean games, influence games, and aggregation games. Our main result shows that, as far as verification is concerned, CGS-SPC can be reduced to concurrent game structures with exclusive control. This result provides a polynomial reduction for the model checking problem of specifications in Alternating-time Temporal Logic on CGS-SPC. version:1
arxiv-1707-08735 | A Logic for Global and Local Announcements | http://arxiv.org/abs/1707.08735 | id:1707.08735 author:Francesco Belardinelli, Hans van Ditmarsch, Wiebe van der Hoek category:cs.LO cs.AI  published:2017-07-27 summary:In this paper we introduce {\em global and local announcement logic} (GLAL), a dynamic epistemic logic with two distinct announcement operators -- $[\phi]^+_A$ and $[\phi]^-_A$ indexed to a subset $A$ of the set $Ag$ of all agents -- for global and local announcements respectively. The boundary case $[\phi]^+_{Ag}$ corresponds to the public announcement of $\phi$, as known from the literature. Unlike standard public announcements, which are {\em model transformers}, the global and local announcements are {\em pointed model transformers}. In particular, the update induced by the announcement may be different in different states of the model. Therefore, the resulting computations are trees of models, rather than the typical sequences. A consequence of our semantics is that modally bisimilar states may be distinguished in our logic. Then, we provide a stronger notion of bisimilarity and we show that it preserves modal equivalence in GLAL. Additionally, we show that GLAL is strictly more expressive than public announcement logic with common knowledge. We prove a wide range of validities for GLAL involving the interaction between dynamics and knowledge, and show that the satisfiability problem for GLAL is decidable. We illustrate the formal machinery by means of detailed epistemic scenarios. version:1
arxiv-1707-08734 | Common Knowledge in a Logic of Gossips | http://arxiv.org/abs/1707.08734 | id:1707.08734 author:Krzysztof R. Apt, Dominik Wojtczak category:cs.LO cs.AI  published:2017-07-27 summary:Gossip protocols aim at arriving, by means of point-to-point or group communications, at a situation in which all the agents know each other secrets. Recently a number of authors studied distributed epistemic gossip protocols. These protocols use as guards formulas from a simple epistemic logic, which makes their analysis and verification substantially easier. We study here common knowledge in the context of such a logic. First, we analyze when it can be reduced to iterated knowledge. Then we show that the semantics and truth for formulas without nested common knowledge operator are decidable. This implies that implementability, partial correctness and termination of distributed epistemic gossip protocols that use non-nested common knowledge operator is decidable, as well. Given that common knowledge is equivalent to an infinite conjunction of nested knowledge, these results are non-trivial generalizations of the corresponding decidability results for the original epistemic logic, established in (Apt & Wojtczak, 2016). K. R. Apt & D. Wojtczak (2016): On Decidability of a Logic of Gossips. In Proc. of JELIA 2016, pp. 18-33, doi:10.1007/ 978-3-319-48758-8_2. version:1
arxiv-1708-02654 | Cheryl's Birthday | http://arxiv.org/abs/1708.02654 | id:1708.02654 author:Hans van Ditmarsch, Michael Ian Hartley, Barteld Kooi, Jonathan Welton, Joseph B. W. Yeo category:cs.AI cs.GL cs.LO  published:2017-07-27 summary:We present four logic puzzles and after that their solutions. Joseph Yeo designed 'Cheryl's Birthday'. Mike Hartley came up with a novel solution for 'One Hundred Prisoners and a Light Bulb'. Jonathan Welton designed 'A Blind Guess' and 'Abby's Birthday'. Hans van Ditmarsch and Barteld Kooi authored the puzzlebook 'One Hundred Prisoners and a Light Bulb' that contains other knowledge puzzles, and that can also be found on the webpage http://personal.us.es/hvd/lightbulb.html dedicated to the book. version:1
arxiv-1707-08716 | A vehicle with a two-wheel steering system mobile in shallow dense granular media | http://arxiv.org/abs/1707.08716 | id:1707.08716 author:Po-Yi Lee, Meng-Chi Tsai, I-Ta Hsieh, Pin-Ju Tseng, Guo-Jie Jason Gao category:cond-mat.soft cs.RO  published:2017-07-27 summary:We design a vehicle with a steering system made of two independently rotatable wheels on the front. We quantify the effectiveness of the steering system in the mobility and maneuverability of the vehicle running in a box containing a layer ping-pong balls with a packing density 0.8, below the random close packing value 0.84 in 2D. The steering system can reduce the resistance exerted by the jammed balls formed ahead of the fast-moving vehicle. Moreover, if only one of the two steering wheels rotates, the vehicle can turn into the direction opposite to the rotating wheel. The steering system performs more efficiently if the wheels engage the ping-pong balls better by increasing the contact area between the wheels and the balls. We advocate applying our design to machines moving in granular materials with a moderate packing density. version:1
arxiv-1708-00376 | Using Program Induction to Interpret Transition System Dynamics | http://arxiv.org/abs/1708.00376 | id:1708.00376 author:Svetlin Penkov, Subramanian Ramamoorthy category:cs.AI  published:2017-07-26 summary:Explaining and reasoning about processes which underlie observed black-box phenomena enables the discovery of causal mechanisms, derivation of suitable abstract representations and the formulation of more robust predictions. We propose to learn high level functional programs in order to represent abstract models which capture the invariant structure in the observed data. We introduce the $\pi$-machine (program-induction machine) -- an architecture able to induce interpretable LISP-like programs from observed data traces. We propose an optimisation procedure for program learning based on backpropagation, gradient descent and A* search. We apply the proposed method to two problems: system identification of dynamical systems and explaining the behaviour of a DQN agent. Our results show that the $\pi$-machine can efficiently induce interpretable programs from individual data traces. version:1
arxiv-1707-03938 | Representation Learning for Grounded Spatial Reasoning | http://arxiv.org/abs/1707.03938 | id:1707.03938 author:Michael Janner, Karthik Narasimhan, Regina Barzilay category:cs.CL cs.AI cs.LG  published:2017-07-13 summary:The interpretation of spatial references is highly contextual, requiring joint inference over both language and the environment. We consider the task of spatial reasoning in a simulated environment, where an agent can act and receive rewards. The proposed model learns a representation of the world steered by instruction text. This design allows for precise alignment of local neighborhoods with corresponding verbalizations, while also handling global references in the instructions. We train our model with reinforcement learning using a variant of generalized value iteration. The model outperforms state-of-the-art approaches on several metrics, yielding a 45% reduction in goal localization error. version:1
arxiv-1707-01959 | Well-Founded Operators for Normal Hybrid MKNF Knowledge Bases | http://arxiv.org/abs/1707.01959 | id:1707.01959 author:Jianmin Ji, Fangfang Liu, Jia-Huai You category:cs.AI  published:2017-07-06 summary:Hybrid MKNF knowledge bases have been considered one of the dominant approaches to combining open world ontology languages with closed world rule-based languages. Currently, the only known inference methods are based on the approach of guess-and-verify, while most modern SAT/ASP solvers are built under the DPLL architecture. The central impediment here is that it is not clear what constitutes a constraint propagator, a key component employed in any DPLL-based solver. In this paper, we address this problem by formulating the notion of unfounded sets for nondisjunctive hybrid MKNF knowledge bases, based on which we propose and study two new well-founded operators. We show that by employing a well-founded operator as a constraint propagator, a sound and complete DPLL search engine can be readily defined. We compare our approach with the operator based on the alternating fixpoint construction by Knorr et al [2011] and show that, when applied to arbitrary partial partitions, the new well-founded operators not only propagate more truth values but also circumvent the non-converging behavior of the latter. In addition, we study the possibility of simplifying a given hybrid MKNF knowledge base by employing a well-founded operator, and show that, out of the two operators proposed in this paper, the weaker one can be applied for this purpose and the stronger one cannot. These observations are useful in implementing a grounder for hybrid MKNF knowledge bases, which can be applied before the computation of MKNF models. The paper is under consideration for acceptance in TPLP. version:2
arxiv-1707-03908 | Automatic Mapping of NES Games with Mappy | http://arxiv.org/abs/1707.03908 | id:1707.03908 author:Joseph C. Osborn, Adam Summerville, Michael Mateas category:cs.AI  published:2017-07-12 summary:Game maps are useful for human players, general-game-playing agents, and data-driven procedural content generation. These maps are generally made by hand-assembling manually-created screenshots of game levels. Besides being tedious and error-prone, this approach requires additional effort for each new game and level to be mapped. The results can still be hard for humans or computational systems to make use of, privileging visual appearance over semantic information. We describe a software system, Mappy, that produces a good approximation of a linked map of rooms given a Nintendo Entertainment System game program and a sequence of button inputs exploring its world. In addition to visual maps, Mappy outputs grids of tiles (and how they change over time), positions of non-tile objects, clusters of similar rooms that might in fact be the same room, and a set of links between these rooms. We believe this is a necessary step towards developing larger corpora of high-quality semantically-annotated maps for PCG via machine learning and other applications. version:1
arxiv-1707-03902 | Autoencoder-augmented Neuroevolution for Visual Doom Playing | http://arxiv.org/abs/1707.03902 | id:1707.03902 author:Samuel Alvernaz, Julian Togelius category:cs.AI cs.NE  published:2017-07-12 summary:Neuroevolution has proven effective at many reinforcement learning tasks, but does not seem to scale well to high-dimensional controller representations, which are needed for tasks where the input is raw pixel data. We propose a novel method where we train an autoencoder to create a comparatively low-dimensional representation of the environment observation, and then use CMA-ES to train neural network controllers acting on this input data. As the behavior of the agent changes the nature of the input data, the autoencoder training progresses throughout evolution. We test this method in the VizDoom environment built on the classic FPS Doom, where it performs well on a health-pack gathering task. version:1
arxiv-1707-03899 | A Topologist's View of Kinematic Maps and Manipulation Complexity | http://arxiv.org/abs/1707.03899 | id:1707.03899 author:Petar Pavešić category:math.AT cs.RO 55M99  70B15  published:2017-07-12 summary:In this paper we combine a survey of the most important topological properties of kinematic maps that appear in robotics, with the exposition of some basic results regarding the topological complexity of a map. In particular, we discuss mechanical devices that consist of rigid parts connected by joints and show how the geometry of the joints determines the forward kinematic map that relates the configuration of joints with the pose of the end-effector of the device. We explain how to compute the dimension of the joint space and describe topological obstructions for a kinematic map to be a fibration or to admit a continuous section. In the second part of the paper we define the complexity of a continuous map and show how the concept can be viewed as a measure of the difficulty to find a robust manipulation plan for a given mechanical device. We also derive some basic estimates for the complexity and relate it to the degree of instability of a manipulation plan. version:1
arxiv-1707-03886 | A Formal Framework to Characterize Interpretability of Procedures | http://arxiv.org/abs/1707.03886 | id:1707.03886 author:Amit Dhurandhar, Vijay Iyengar, Ronny Luss, Karthikeyan Shanmugam category:cs.AI  published:2017-07-12 summary:We provide a novel notion of what it means to be interpretable, looking past the usual association with human understanding. Our key insight is that interpretability is not an absolute concept and so we define it relative to a target model, which may or may not be a human. We define a framework that allows for comparing interpretable procedures by linking it to important practical aspects such as accuracy and robustness. We characterize many of the current state-of-the-art interpretable methods in our framework portraying its general applicability. version:1
arxiv-1707-03881 | Identification and Interpretation of Belief Structure in Dempster-Shafer Theory | http://arxiv.org/abs/1707.03881 | id:1707.03881 author:Mieczysław A. Kłopotek category:cs.AI  published:2017-07-12 summary:Mathematical Theory of Evidence called also Dempster-Shafer Theory (DST) is known as a foundation for reasoning when knowledge is expressed at various levels of detail. Though much research effort has been committed to this theory since its foundation, many questions remain open. One of the most important open questions seems to be the relationship between frequencies and the Mathematical Theory of Evidence. The theory is blamed to leave frequencies outside (or aside of) its framework. The seriousness of this accusation is obvious: (1) no experiment may be run to compare the performance of DST-based models of real world processes against real world data, (2) data may not serve as foundation for construction of an appropriate belief model. In this paper we develop a frequentist interpretation of the DST bringing to fall the above argument against DST. An immediate consequence of it is the possibility to develop algorithms acquiring automatically DST belief models from data. We propose three such algorithms for various classes of belief model structures: for tree structured belief networks, for poly-tree belief networks and for general type belief networks. version:1
arxiv-1707-03872 | Independence, Conditionality and Structure of Dempster-Shafer Belief Functions | http://arxiv.org/abs/1707.03872 | id:1707.03872 author:Mieczysław A. Kłopotek category:cs.AI  published:2017-07-12 summary:Several approaches of structuring (factorization, decomposition) of Dempster-Shafer joint belief functions from literature are reviewed with special emphasis on their capability to capture independence from the point of view of the claim that belief functions generalize bayes notion of probability. It is demonstrated that Zhu and Lee's {Zhu:93} logical networks and Smets' {Smets:93} directed acyclic graphs are unable to capture statistical dependence/independence of bayesian networks {Pearl:88}. On the other hand, though Shenoy and Shafer's hypergraphs can explicitly represent bayesian network factorization of bayesian belief functions, they disclaim any need for representation of independence of variables in belief functions. Cano et al. {Cano:93} reject the hypergraph representation of Shenoy and Shafer just on grounds of missing representation of variable independence, but in their frameworks some belief functions factorizable in Shenoy/Shafer framework cannot be factored. The approach in {Klopotek:93f} on the other hand combines the merits of both Cano et al. and of Shenoy/Shafer approach in that for Shenoy/Shafer approach no simpler factorization than that in {Klopotek:93f} approach exists and on the other hand all independences among variables captured in Cano et al. framework and many more are captured in {Klopotek:93f} approach.% version:1
arxiv-1707-03865 | Mechanics Automatically Recognized via Interactive Observation: Jumping | http://arxiv.org/abs/1707.03865 | id:1707.03865 author:Adam Summerville, Joseph C. Osborn, Christoffer Holmgård, Daniel W. Zhang category:cs.AI  published:2017-07-12 summary:Jumping has been an important mechanic since its introduction in Donkey Kong. It has taken a variety of forms and shown up in numerous games, with each jump having a different feel. In this paper, we use a modified Nintendo Entertainment System (NES) emulator to semi-automatically run experiments on a large subset (30%) of NES platform games. We use these experiments to build models of jumps from different developers, series, and games across the history of the console. We then examine these models to gain insights into different forms of jumping and their associated feel. version:1
arxiv-1707-03856 | Buffer Size for Routing Limited-Rate Adversarial Traffic | http://arxiv.org/abs/1707.03856 | id:1707.03856 author:Avery Miller, Boaz Patt-Shamir category:cs.DC  published:2017-07-12 summary:We consider the slight variation of the adversarial queuing theory model, in which an adversary injects packets with routes into the network subject to the following constraint: For any link $e$, the total number of packets injected in any time window $[t,t')$ and whose route contains $e$, is at most $\rho(t'-t)+\sigma$, where $\rho$ and $\sigma$ are non-negative parameters. Informally, $\rho$ bounds the long-term rate of injections and $\sigma$ bounds the "burstiness" of injection: $\sigma=0$ means that the injection is as smooth as it can be. It is known that greedy scheduling of the packets (under which a link is not idle if there is any packet ready to be sent over it) may result in $\Omega(n)$ buffer size even on an $n$-line network and very smooth injections ($\sigma=0$). In this paper we propose a simple non-greedy scheduling policy and show that, in a tree where all packets are destined at the root, no buffer needs to be larger than $\sigma+2\rho$ to ensure that no overflows occur, which is optimal in our model. The rule of our algorithm is to forward a packet only if its next buffer is completely empty. The policy is centralized: in a single step, a long "train" of packets may progress together. We show that in some sense central coordination is required, by presenting an injection pattern with $\sigma=0$ for the $n$-node line that results in $\Omega(n)$ packets in a buffer if local control is used, even for the more sophisticated "downhill" algorithm, which forwards a packet only if its next buffer is less occupied than its current one. version:1
arxiv-1707-03804 | Source-Target Inference Models for Spatial Instruction Understanding | http://arxiv.org/abs/1707.03804 | id:1707.03804 author:Hao Tan, Mohit Bansal category:cs.CL cs.AI cs.LG cs.RO  published:2017-07-12 summary:Models that can execute natural language instructions for situated robotic tasks such as assembly and navigation have several useful applications in homes, offices, and remote scenarios. We study the semantics of spatially-referred configuration and arrangement instructions, based on the challenging blank-labeled block dataset of Bisk et al. (2016). This task involves finding a source block and moving it to the target position (mentioned via a reference block and offset), where the blocks have no names or colors and are just referred to via spatial location features. We present novel models for the subtasks of source block classification and target position regression, based on joint-loss language and spatial-world representation learning, as well as CNN-based and dual attention models to compute the alignment between the world blocks and the instruction phrases. For target position prediction, we compare two inference approaches: annealed sampling via policy gradient versus expectation inference via supervised regression. Our models achieve the new state-of-the-art on this task, with an improvement of 47% on source block accuracy and 22% on target position distance. version:1
arxiv-1707-03744 | P-Tree Programming | http://arxiv.org/abs/1707.03744 | id:1707.03744 author:Christian Oesch category:cs.AI  published:2017-07-12 summary:We propose a novel method for automatic program synthesis. P-Tree Programming represents the program search space through a single probabilistic prototype tree. From this prototype tree we form program instances which we evaluate on a given problem. The error values from the evaluations are propagated through the prototype tree. We use them to update the probability distributions that determine the symbol choices of further instances. The iterative method is applied to several symbolic regression benchmarks from the literature. It outperforms standard Genetic Programming to a large extend. Furthermore, it relies on a concise set of parameters which are held constant for all problems. The algorithm can be employed for most of the typical computational intelligence tasks such as classification, automatic program induction, and symbolic regression. version:1
arxiv-1707-03743 | Learning Macromanagement in StarCraft from Replays using Deep Learning | http://arxiv.org/abs/1707.03743 | id:1707.03743 author:Niels Justesen, Sebastian Risi category:cs.AI  published:2017-07-12 summary:The real-time strategy game StarCraft has proven to be a challenging environment for artificial intelligence techniques, and as a result, current state-of-the-art solutions consist of numerous hand-crafted modules. In this paper, we show how macromanagement decisions in StarCraft can be learned directly from game replays using deep learning. Neural networks are trained on 789,571 state-action pairs extracted from 2,005 replays of highly skilled players, achieving top-1 and top-3 error rates of 54.6% and 22.9% in predicting the next build action. By integrating the trained network into UAlbertaBot, an open source StarCraft bot, the system can significantly outperform the game's built-in Terran bot, and play competitively against UAlbertaBot with a fixed rush strategy. To our knowledge, this is the first time macromanagement tasks are learned directly from replays in StarCraft. While the best hand-crafted strategies are still the state-of-the-art, the deep network approach is able to express a wide range of different strategies and thus improving the network's performance further with deep reinforcement learning is an immediately promising avenue for future research. Ultimately this approach could lead to strong StarCraft bots that are less reliant on hard-coded strategies. version:1
arxiv-1707-03739 | Conflict Analysis for Pythagorean Fuzzy Information Systems with Group Decision Making | http://arxiv.org/abs/1707.03739 | id:1707.03739 author:Guangming Lang category:cs.AI cs.IT math.IT  published:2017-07-12 summary:Pythagorean fuzzy sets provide stronger ability than intuitionistic fuzzy sets to model uncertainty information and knowledge, but little effort has been paid to conflict analysis of Pythagorean fuzzy information systems. In this paper, we present three types of positive, central, and negative alliances with different thresholds, and employ examples to illustrate how to construct the positive, central, and negative alliances. Then we study conflict analysis of Pythagorean fuzzy information systems based on Bayesian minimum risk theory. Finally, we investigate group conflict analysis of Pythagorean fuzzy information systems based on Bayesian minimum risk theory. version:1
arxiv-1707-02978 | Automatic Construction of Real-World Datasets for 3D Object Localization using Two Cameras | http://arxiv.org/abs/1707.02978 | id:1707.02978 author:Joris Guérin, Olivier Gibaru, Eric Nyiri, Stéphane Thiery category:cs.CV cs.RO  published:2017-07-10 summary:Unlike classification, position labels cannot be assigned manually by humans. For this reason, generating supervision for precise object localization is a hard task. This paper details a method to create large datasets for 3D object localization, with real world images, using an industrial robot to generate position labels. By knowledge of the geometry of the robot, we are able to automatically synchronize the images of the two cameras and the object 3D position. We applied it to generate a screw-driver localization dataset with stereo images, using a KUKA LBR iiwa robot. This dataset could then be used to train a CNN regressor to learn end-to-end stereo object localization from a set of two standard uncalibrated cameras. version:2
arxiv-1706-05086 | Evaluating Noisy Optimisation Algorithms: First Hitting Time is Problematic | http://arxiv.org/abs/1706.05086 | id:1706.05086 author:Simon M. Lucas, Jialin Liu, Diego Pérez-Liébana category:cs.NE cs.AI  published:2017-06-13 summary:A key part of any evolutionary algorithm is fitness evaluation. When fitness evaluations are corrupted by noise, as happens in many real-world problems as a consequence of various types of uncertainty, a strategy is needed in order to cope with this. Resampling is one of the most common strategies, whereby each solution is evaluated many times in order to reduce the variance of the fitness estimates. When evaluating the performance of a noisy optimisation algorithm, a key consideration is the stopping condition for the algorithm. A frequently used stopping condition in runtime analysis, known as "First Hitting Time", is to stop the algorithm as soon as it encounters the optimal solution. However, this is unrealistic for real-world problems, as if the optimal solution were already known, there would be no need to search for it. This paper argues that the use of First Hitting Time, despite being a commonly used approach, is significantly flawed and overestimates the quality of many algorithms in real-world cases, where the optimum is not known in advance and has to be genuinely searched for. A better alternative is to measure the quality of the solution an algorithm returns after a fixed evaluation budget, i.e., to focus on final solution quality. This paper argues that focussing on final solution quality is more realistic and demonstrates cases where the results produced by each algorithm evaluation method lead to very different conclusions regarding the quality of each noisy optimisation algorithm. version:2
arxiv-1707-04151 | The Reach-Avoid Problem for Constant-Rate Multi-Mode Systems | http://arxiv.org/abs/1707.04151 | id:1707.04151 author:Shankara Narayanan Krishna, Aviral Kumar, Fabio Somenzi, Behrouz Touri, Ashutosh Trivedi category:cs.LO cs.FL cs.RO  published:2017-07-12 summary:A constant-rate multi-mode system is a hybrid system that can switch freely among a finite set of modes, and whose dynamics is specified by a finite number of real-valued variables with mode-dependent constant rates. Alur, Wojtczak, and Trivedi have shown that reachability problems for constant-rate multi-mode systems for open and convex safety sets can be solved in polynomial time. In this paper, we study the reachability problem for non-convex state spaces and show that this problem is in general undecidable. We recover decidability by making certain assumptions about the safety set. We present a new algorithm to solve this problem and compare its performance with the popular sampling based algorithm rapidly-exploring random tree (RRT) as implemented in the Open Motion Planning Library (OMPL). version:1
arxiv-1707-03602 | Using RDF Summary Graph For Keyword-based Semantic Searches | http://arxiv.org/abs/1707.03602 | id:1707.03602 author:Serkan Ayvaz, Mehmet Aydar category:cs.AI cs.DB cs.IR  published:2017-07-12 summary:The Semantic Web began to emerge as its standards and technologies developed rapidly in the recent years. The continuing development of Semantic Web technologies has facilitated publishing explicit semantics with data on the Web in RDF data model. This study proposes a semantic search framework to support efficient keyword-based semantic search on RDF data utilizing near neighbor explorations. The framework augments the search results with the resources in close proximity by utilizing the entity type semantics. Along with the search results, the system generates a relevance confidence score measuring the inferred semantic relatedness of returned entities based on the degree of similarity. Furthermore, the evaluations assessing the effectiveness of the framework and the accuracy of the results are presented. version:1
arxiv-1707-03527 | Oseba: Optimization for Selective Bulk Analysis in Big Data Processing | http://arxiv.org/abs/1707.03527 | id:1707.03527 author:Rui Wang, Jun Wang category:cs.DC  published:2017-07-12 summary:Selective bulk analyses, such as statistical learning on temporal/spatial data, are fundamental to a wide range of contemporary data analysis. However, with the increasingly larger data-sets, such as weather data and marketing transactions, the data organization/access becomes more challenging in selective bulk data processing with the use of current big data processing frameworks such as Spark or keyvalue stores. In this paper, we propose a method to optimize selective bulk analysis in big data processing and referred to as Oseba. Oseba maintains a super index for the data organization in memory to support fast lookup through targeting the data involved with each selective analysis program. Oseba is able to save memory as well as computation in comparison to the default data processing frameworks. version:1
arxiv-1707-03515 | Benchmarking Data Analysis and Machine Learning Applications on the Intel KNL Many-Core Processor | http://arxiv.org/abs/1707.03515 | id:1707.03515 author:Chansup Byun, Jeremy Kepner, William Arcand, David Bestor, Bill Bergeron, Vijay Gadepally, Michael Houle, Matthew Hubbell, Michael Jones, Anna Klein, Peter Michaleas, Lauren Milechin, Julie Mullen, Andrew Prout, Antonio Rosa, Siddharth Samsi, Charles Yee, Albert Reuther category:cs.PF astro-ph.IM cs.DC physics.comp-ph  published:2017-07-12 summary:Knights Landing (KNL) is the code name for the second-generation Intel Xeon Phi product family. KNL has generated significant interest in the data analysis and machine learning communities because its new many-core architecture targets both of these workloads. The KNL many-core vector processor design enables it to exploit much higher levels of parallelism. At the Lincoln Laboratory Supercomputing Center (LLSC), the majority of users are running data analysis applications such as MATLAB and Octave. More recently, machine learning applications, such as the UC Berkeley Caffe deep learning framework, have become increasingly important to LLSC users. Thus, the performance of these applications on KNL systems is of high interest to LLSC users and the broader data analysis and machine learning communities. Our data analysis benchmarks of these application on the Intel KNL processor indicate that single-core double-precision generalized matrix multiply (DGEMM) performance on KNL systems has improved by ~3.5x compared to prior Intel Xeon technologies. Our data analysis applications also achieved ~60% of the theoretical peak performance. Also a performance comparison of a machine learning application, Caffe, between the two different Intel CPUs, Xeon E5 v3 and Xeon Phi 7210, demonstrated a 2.7x improvement on a KNL node. version:1
arxiv-1707-00051 | Failing to Learn: Autonomously Identifying Perception Failures for Self-driving Cars | http://arxiv.org/abs/1707.00051 | id:1707.00051 author:Manikandasriram Srin, Cyrus Anderson, Ram Vasudevan, Matthew Johnson-Roberson category:cs.CV cs.RO  published:2017-06-30 summary:One of the major open challenges in self-driving cars is the ability to detect cars and pedestrians to safely navigate in the world. Deep learning-based object detector approaches have enabled great advances in using camera imagery to detect and classify objects. But for a safety critical application such as autonomous driving, the error rates of the current state-of-the-art are still too high to enable safe operation. Moreover, our characterization of object detector performance is primarily limited to testing on prerecorded datasets. Errors that occur on novel data go undetected without additional human labels. In this paper, we propose an automated method to identify mistakes made by object detectors without ground truth labels. We show that inconsistencies in object detector output between a pair of similar images can be used to identify false negatives(e.g. missed detections). In particular, we study two distinct cues - temporal and stereo inconsistencies - using data that is readily available on most autonomous vehicles. Our method can be used with any camera-based object detector and we evaluate the technique on several sets of real world data. The proposed method achieves over 97% precision in automatically identifying missed detections produced by one of the leading state-of-the-art object detectors in the literature. We also release a new tracking dataset with over 100 sequences totaling more than 80,000 labeled images from a game engine to facilitate further research. version:2
arxiv-1707-09849 | A New Classification Approach for Robotic Surgical Tasks Recognition | http://arxiv.org/abs/1707.09849 | id:1707.09849 author:Mehrdad J. Bani, Shoele Jamali category:cs.RO  published:2017-07-12 summary:Automatic recognition and classification of tasks in robotic surgery is an important stepping stone toward automated surgery and surgical training. Recently, technical breakthroughs in gathering data make data-driven model development possible. In this paper, we propose a framework for high-level robotic surgery task recognition using motion data. We present a novel classification technique that is used to classify three important surgical tasks through quantitative analyses of motion: knot tying, needle passing and suturing. The proposed technique integrates state-of-the-art data mining and time series analysis methods. The first step of this framework consists of developing a time series distance-based similarity measure using derivative dynamic time warping (DDTW). The distance-weighted k-nearest neighbor algorithm was then used to classify task instances. The framework was validated using an extensive dataset. Our results demonstrate the strength of the proposed framework in recognizing fundamental robotic surgery tasks. version:1
arxiv-1707-03502 | Deep Learning for Sensor-based Activity Recognition: A Survey | http://arxiv.org/abs/1707.03502 | id:1707.03502 author:Jindong Wang, Yiqiang Chen, Shuji Hao, Xiaohui Peng, Lisha Hu category:cs.CV cs.AI cs.LG cs.NE  published:2017-07-12 summary:Sensor-based activity recognition seeks the profound high-level knowledge about human activity from multitudes of low-level sensor readings. Conventional pattern recognition approaches have made tremendous progress in the past years. However, most of those approaches heavily rely on heuristic hand-crafted feature extraction methods, which dramatically hinder their generalization performance. Additionally, those methods often produce unsatisfactory results for unsupervised and incremental learning tasks. Meanwhile, the recent advancement of deep learning makes it possible to perform automatic high-level feature extraction thus achieves promising performance in many areas. Since then, deep learning based methods have been widely adopted for the sensor-based activity recognition tasks. In this paper, we survey and highlight the recent advancement of deep learning approaches for sensor-based activity recognition. Specifically, we summarize existing literatures from three aspects: sensor modality, deep model and application. We also present a detailed discussion and propose grand challenges for future direction. version:1
arxiv-1707-03501 | NO Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles | http://arxiv.org/abs/1707.03501 | id:1707.03501 author:Jiajun Lu, Hussein Sibai, Evan Fabry, David Forsyth category:cs.CV cs.AI cs.CR  published:2017-07-12 summary:It has been shown that most machine learning algorithms are susceptible to adversarial perturbations. Slightly perturbing an image in a carefully chosen direction in the image space may cause a trained neural network model to misclassify it. Recently, it was shown that physical adversarial examples exist: printing perturbed images then taking pictures of them would still result in misclassification. This raises security and safety concerns. However, these experiments ignore a crucial property of physical objects: the camera can view objects from different distances and at different angles. In this paper, we show experiments that suggest that current constructions of physical adversarial examples do not disrupt object detection from a moving platform. Instead, a trained neural network classifies most of the pictures taken from different distances and angles of a perturbed image correctly. We believe this is because the adversarial property of the perturbation is sensitive to the scale at which the perturbed picture is viewed, so (for example) an autonomous car will misclassify a stop sign only from a small range of distances. Our work raises an important question: can one construct examples that are adversarial for many or most viewing conditions? If so, the construction should offer very significant insights into the internal representation of patterns by deep networks. If not, there is a good prospect that adversarial examples can be reduced to a curiosity with little practical impact. version:1
arxiv-1707-03497 | Value Prediction Network | http://arxiv.org/abs/1707.03497 | id:1707.03497 author:Junhyuk Oh, Satinder Singh, Honglak Lee category:cs.AI cs.LG  published:2017-07-11 summary:This paper proposes a novel deep reinforcement learning (RL) architecture, called Value Prediction Network (VPN), which integrates model-free and model-based RL methods into a single neural network. In contrast to typical model-based RL methods, VPN learns a dynamics model whose abstract states are trained to make option-conditional predictions of future values (discounted sum of rewards) rather than of future observations. Our experimental results show that VPN has several advantages over both model-free and model-based baselines in a stochastic environment where careful planning is required but building an accurate observation-prediction model is difficult. Furthermore, VPN outperforms Deep Q-Network (DQN) on several Atari games even with short-lookahead planning, demonstrating its potential as a new way of learning a good state representation. version:1
arxiv-1707-04245 | Hot-Rodding the Browser Engine: Automatic Configuration of JavaScript Compilers | http://arxiv.org/abs/1707.04245 | id:1707.04245 author:Chris Fawcett, Lars Kotthoff, Holger H. Hoos category:cs.PL cs.AI cs.PF  published:2017-07-11 summary:Modern software systems in many application areas offer to the user a multitude of parameters, switches and other customisation hooks. Humans tend to have difficulties determining the best configurations for particular applications. Modern optimising compilers are an example of such software systems; their many parameters need to be tuned for optimal performance, but are often left at the default values for convenience. In this work, we automatically determine compiler parameter settings that result in optimised performance for particular applications. Specifically, we apply a state-of-the-art automated parameter configuration procedure based on cutting-edge machine learning and optimisation techniques to two prominent JavaScript compilers and demonstrate that significant performance improvements, more than 35% in some cases, can be achieved over the default parameter settings on a diverse set of benchmarks. version:1
arxiv-1707-03492 | Fault-Induced Dynamics of Oblivious Robots on a Line | http://arxiv.org/abs/1707.03492 | id:1707.03492 author:Jean-Lou De Carufel, Paola Flocchini category:cs.DC  published:2017-07-11 summary:The study of computing in presence of faulty robots in the Look-Compute-Move model has been the object of extensive investigation, typically with the goal of designing algorithms tolerant to as many faults as possible. In this paper, we initiate a new line of investigation on the presence of faults, focusing on a rather different issue. We are interested in understanding the dynamics of a group of robots when they execute an algorithm designed for a fault-free environment, in presence of some undetectable crashed robots. We start this investigation focusing on the classic point-convergence algorithm by Ando et al. for robots with limited visibility, in a simple setting (which already presents serious challenges): the robots operate fully synchronously on a line, and at most two of them are faulty. Interestingly, and perhaps surprisingly, the presence of faults induces the robots to perform some form of scattering, rather than point-convergence. In fact, we discover that they arrange themselves inside the segment delimited by the two faults in interleaved sequences of equidistant robots. The structure that they form has a hierarchical nature: robots organize themselves in groups where a group of some level converges to an equidistant distribution only after all groups of lower levels have converged. This is the first study on the unintended dynamics of oblivious robots induced by the presence of faults. version:1
arxiv-1707-03490 | Detecting Policy Preferences and Dynamics in the UN General Debate with Neural Word Embeddings | http://arxiv.org/abs/1707.03490 | id:1707.03490 author:Stefano Gurciullo, Slava Mikhaylov category:cs.CL cs.AI stat.ML  published:2017-07-11 summary:Foreign policy analysis has been struggling to find ways to measure policy preferences and paradigm shifts in international political systems. This paper presents a novel, potential solution to this challenge, through the application of a neural word embedding (Word2vec) model on a dataset featuring speeches by heads of state or government in the United Nations General Debate. The paper provides three key contributions based on the output of the Word2vec model. First, it presents a set of policy attention indices, synthesizing the semantic proximity of political speeches to specific policy themes. Second, it introduces country-specific semantic centrality indices, based on topological analyses of countries' semantic positions with respect to each other. Third, it tests the hypothesis that there exists a statistical relation between the semantic content of political speeches and UN voting behavior, falsifying it and suggesting that political speeches contain information of different nature then the one behind voting outcomes. The paper concludes with a discussion of the practical use of its results and consequences for foreign policy analysis, public accountability, and transparency. version:1
arxiv-1707-03478 | Round Compression for Parallel Matching Algorithms | http://arxiv.org/abs/1707.03478 | id:1707.03478 author:Artur Czumaj, Jakub Łącki, Aleksander Mądry, Slobodan Mitrović, Krzysztof Onak, Piotr Sankowski category:cs.DS cs.DC  published:2017-07-11 summary:The last decade has witnessed the success of a number of \emph{massive parallel computation} (MPC) frameworks, such as MapReduce, Hadoop, Dryad, or Spark. These frameworks allow for much more local memory and computation, compared to the classical distributed or PRAM models. In this context, we investigate the complexity of one of the most fundamental graph problems: \emph{Maximum Matching}. We show that if the memory per machine is $\Omega(n)$ (or even only $n/(\log n)^{O(\log \log n)}$), then for any fixed constant $\epsilon > 0$, one can compute a $(2+\epsilon)$-approximation to Maximum Matching in $O\left((\log \log n)^2\right)$ MPC rounds. This constitutes an exponential improvement over previous work---both the one designed specifically for MPC and the one obtained via connections to PRAM or distributed algorithms---which required $\Theta(\log n)$ rounds to achieve similar approximation guarantees. The starting point of our result is a (distributed) algorithm that computes an $O(1)$-approximation in $O(\log n)$ parallel phases. Its straightforward MPC implementation requires $\Theta(\log n)$ rounds. Our exponential speedup stems from compressing several phases of a modified version of this algorithm into a constant number of MPC rounds. We obtain this via a careful analysis of controlled randomness, which enables the emulation of multiple phases on separate machines without any coordination between them. We leave it as an intriguing open question whether a similar speedup can be obtained for other PRAM and distributed graph algorithms. version:1
arxiv-1707-03471 | Proceedings of the 2017 AdKDD & TargetAd Workshop | http://arxiv.org/abs/1707.03471 | id:1707.03471 author:Abraham Bagherjeiran, Nemanja Djuric, Mihajlo Grbovic, Kuang-Chih Lee, Kun Liu, Vladan Radosavljevic, Suju Rajan category:cs.AI  published:2017-07-11 summary:Proceedings of the 2017 AdKDD and TargetAd Workshop held in conjunction with the 23rd ACM SIGKDD Conference on Knowledge Discovery and Data Mining Halifax, Nova Scotia, Canada. version:1
arxiv-1707-04506 | Reliability Assessment of Distribution System Using Fuzzy Logic for Modelling of Transformer and Line Uncertainties | http://arxiv.org/abs/1707.04506 | id:1707.04506 author:Ahmad Shokrollahi, Hossein Sangrody, Mahdi Motalleb, Mandana Rezaeiahari, Elham Foruzan, Fattah Hassanzadeh category:cs.AI  published:2017-07-11 summary:Reliability assessment of distribution system, based on historical data and probabilistic methods, leads to an unreliable estimation of reliability indices since the data for the distribution components are usually inaccurate or unavailable. Fuzzy logic is an efficient method to deal with the uncertainty in reliability inputs. In this paper, the ENS index along with other commonly used indices in reliability assessment are evaluated for the distribution system using fuzzy logic. Accordingly, the influential variables on the failure rate and outage duration time of the distribution components, which are natural or human-made, are explained using proposed fuzzy membership functions. The reliability indices are calculated and compared for different cases of the system operations by simulation on the IEEE RBTS Bus 2. The results of simulation show how utilities can significantly improve the reliability of their distribution system by considering the risk of the influential variables. version:1
arxiv-1707-01606 | Multimedia Semantic Integrity Assessment Using Joint Embedding Of Images And Text | http://arxiv.org/abs/1707.01606 | id:1707.01606 author:Ayush Jaiswal, Ekraam Sabir, Wael AbdAlmageed, Premkumar Natarajan category:cs.MM cs.AI cs.CV cs.LG  published:2017-07-06 summary:Real world multimedia data is often composed of multiple modalities such as an image or a video with associated text (e.g. captions, user comments, etc.) and metadata. Such multimodal data packages are prone to manipulations, where a subset of these modalities can be altered to misrepresent or repurpose data packages, with possible malicious intent. It is, therefore, important to develop methods to assess or verify the integrity of these multimedia packages. Using computer vision and natural language processing methods to directly compare the image (or video) and the associated caption to verify the integrity of a media package is only possible for a limited set of objects and scenes. In this paper, we present a novel deep learning-based approach for assessing the semantic integrity of multimedia packages containing images and captions, using a reference set of multimedia packages. We construct a joint embedding of images and captions with deep multimodal representation learning on the reference dataset in a framework that also provides image-caption consistency scores (ICCSs). The integrity of query media packages is assessed as the inlierness of the query ICCSs with respect to the reference dataset. We present the MultimodAl Information Manipulation dataset (MAIM), a new dataset of media packages from Flickr, which we make available to the research community. We use both the newly created dataset as well as Flickr30K and MS COCO datasets to quantitatively evaluate our proposed approach. The reference dataset does not contain unmanipulated versions of tampered query packages. Our method is able to achieve F1 scores of 0.75, 0.89 and 0.94 on MAIM, Flickr30K and MS COCO, respectively, for detecting semantically incoherent media packages. version:3
arxiv-1707-03374 | Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation | http://arxiv.org/abs/1707.03374 | id:1707.03374 author:YuXuan Liu, Abhishek Gupta, Pieter Abbeel, Sergey Levine category:cs.LG cs.AI cs.CV cs.NE cs.RO  published:2017-07-11 summary:Imitation learning is an effective approach for autonomous systems to acquire control policies when an explicit reward function is unavailable, using supervision provided as demonstrations from an expert, typically a human operator. However, standard imitation learning methods assume that the agent receives examples of observation-action tuples that could be provided, for instance, to a supervised learning algorithm. This stands in contrast to how humans and animals imitate: we observe another person performing some behavior and then figure out which actions will realize that behavior, compensating for changes in viewpoint, surroundings, and embodiment. We term this kind of imitation learning as imitation-from-observation and propose an imitation learning method based on video prediction with context translation and deep reinforcement learning. This lifts the assumption in imitation learning that the demonstration should consist of observations and actions in the same environment, and enables a variety of interesting applications, including learning robotic skills that involve tool use simply by observing videos of human tool use. Our experimental results show that our approach can perform imitation-from-observation for a variety of real-world robotic tasks modeled on common household chores, acquiring skills such as sweeping from videos of a human demonstrator. Videos can be found at https://sites.google.com/site/imitationfromobservation version:1
arxiv-1707-03336 | CHARDA: Causal Hybrid Automata Recovery via Dynamic Analysis | http://arxiv.org/abs/1707.03336 | id:1707.03336 author:Adam Summerville, Joseph Osborn, Michael Mateas category:cs.AI  published:2017-07-11 summary:We propose and evaluate a new technique for learning hybrid automata automatically by observing the runtime behavior of a dynamical system. Working from a sequence of continuous state values and predicates about the environment, CHARDA recovers the distinct dynamic modes, learns a model for each mode from a given set of templates, and postulates causal guard conditions which trigger transitions between modes. Our main contribution is the use of information-theoretic measures (1)~as a cost function for data segmentation and model selection to penalize over-fitting and (2)~to determine the likely causes of each transition. CHARDA is easily extended with different classes of model templates, fitting methods, or predicates. In our experiments on a complex videogame character, CHARDA successfully discovers a reasonable over-approximation of the character's true behaviors. Our results also compare favorably against recent work in automatically learning probabilistic timed automata in an aircraft domain: CHARDA exactly learns the modes of these simpler automata. version:1
arxiv-1707-03333 | Automated Game Design Learning | http://arxiv.org/abs/1707.03333 | id:1707.03333 author:Joseph C Osborn, Adam Summerville, Michael Mateas category:cs.AI  published:2017-07-11 summary:While general game playing is an active field of research, the learning of game design has tended to be either a secondary goal of such research or it has been solely the domain of humans. We propose a field of research, Automated Game Design Learning (AGDL), with the direct purpose of learning game designs directly through interaction with games in the mode that most people experience games: via play. We detail existing work that touches the edges of this field, describe current successful projects in AGDL and the theoretical foundations that enable them, point to promising applications enabled by AGDL, and discuss next steps for this exciting area of study. The key moves of AGDL are to use game programs as the ultimate source of truth about their own design, and to make these design properties available to other systems and avenues of inquiry. version:1
arxiv-1707-03311 | Similarity Search Over Graphs Using Localized Spectral Analysis | http://arxiv.org/abs/1707.03311 | id:1707.03311 author:Yariv Aizenbud, Amir Averbuch, Gil Shabat, Guy Ziv category:cs.AI cs.LG  published:2017-07-11 summary:This paper provides a new similarity detection algorithm. Given an input set of multi-dimensional data points, where each data point is assumed to be multi-dimensional, and an additional reference data point for similarity finding, the algorithm uses kernel method that embeds the data points into a low dimensional manifold. Unlike other kernel methods, which consider the entire data for the embedding, our method selects a specific set of kernel eigenvectors. The eigenvectors are chosen to separate between the data points and the reference data point so that similar data points can be easily identified as being distinct from most of the members in the dataset. version:1
arxiv-1708-04571 | A Machine Learning Based Intrusion Detection System for Software Defined 5G Network | http://arxiv.org/abs/1708.04571 | id:1708.04571 author:Jiaqi Li, Zhifeng Zhao, Rongpeng Li category:cs.CR cs.AI cs.NI  published:2017-07-10 summary:As an inevitable trend of future 5G networks, Software Defined architecture has many advantages in providing central- ized control and flexible resource management. But it is also confronted with various security challenges and potential threats with emerging services and technologies. As the focus of network security, Intrusion Detection Systems (IDS) are usually deployed separately without collaboration. They are also unable to detect novel attacks with limited intelligent abilities, which are hard to meet the needs of software defined 5G. In this paper, we propose an intelligent intrusion system taking the advances of software defined technology and artificial intelligence based on Software Defined 5G architecture. It flexibly combines security function mod- ules which are adaptively invoked under centralized management and control with a globle view. It can also deal with unknown intrusions by using machine learning algorithms. Evaluation results prove that the intelligent intrusion detection system achieves a better performance. version:1
arxiv-1707-02385 | Evaluating Social Networks Using Task-Focused Network Inference | http://arxiv.org/abs/1707.02385 | id:1707.02385 author:Ivan Brugere, Chris Kanich, Tanya Y. Berger-Wolf category:cs.SI cs.AI  published:2017-07-08 summary:Networks are representations of complex underlying social processes. However, the same given network may be more suitable to model one behavior of individuals than another. In many cases, aggregate population models may be more effective than modeling on the network. We present a general framework for evaluating the suitability of given networks for a set of predictive tasks of interest, compared against alternative, networks inferred from data. We present several interpretable network models and measures for our comparison. We apply this general framework to the case study on collective classification of music preferences in a newly available dataset of the Last.fm social network. version:1
arxiv-1708-09332 | Private Data System Enabling Self-Sovereign Storage Managed by Executable Choreographies | http://arxiv.org/abs/1708.09332 | id:1708.09332 author:Sinica Alboaie, Doina Cosovan category:cs.DC cs.CR cs.DB  published:2017-06-26 summary:With the increased use of Internet, governments and large companies store and share massive amounts of personal data in such a way that leaves no space for transparency. When a user needs to achieve a simple task like applying for college or a driving license, he needs to visit a lot of institutions and organizations, thus leaving a lot of private data in many places. The same happens when using the Internet. These privacy issues raised by the centralized architectures along with the recent developments in the area of serverless applications demand a decentralized private data layer under user control. We introduce the Private Data System (PDS), a distributed approach which enables self-sovereign storage and sharing of private data. The system is composed of nodes spread across the entire Internet managing local key-value databases. The communication between nodes is achieved through executable choreographies, which are capable of preventing information leakage when executing across different organizations with different regulations in place. The user has full control over his private data and is able to share and revoke access to organizations at any time. Even more, the updates are propagated instantly to all the parties which have access to the data thanks to the system design. Specifically, the processing organizations may retrieve and process the shared information, but are not allowed under any circumstances to store it on long term. PDS offers an alternative to systems that aim to ensure self-sovereignty of specific types of data through blockchain inspired techniques but face various problems, such as low performance. Both approaches propose a distributed database, but with different characteristics. While the blockchain-based systems are built to solve consensus problems, PDS's purpose is to solve the self-sovereignty aspects raised by the privacy laws, rules and principles. version:1
