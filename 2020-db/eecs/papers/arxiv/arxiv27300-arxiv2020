arxiv-1704-02971 | A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction | http://arxiv.org/abs/1704.02971 | id:1704.02971 author:Yao Qin, Dongjin Song, Haifeng Cheng, Wei Cheng, Guofei Jiang, Garrison Cottrell category:cs.LG stat.ML  published:2017-04-07 summary:The Nonlinear autoregressive exogenous (NARX) model, which predicts the current value of a time series based upon its previous values as well as the current and past values of multiple driving (exogenous) series, has been studied for decades. Despite the fact that various NARX models have been developed, few of them can capture the long-term temporal dependencies appropriately and select the relevant driving series to make predictions. In this paper, we propose a dual-stage attention based recurrent neural network (DA-RNN) to address these two issues. In the first stage, we introduce an input attention mechanism to adaptively extract relevant driving series (a.k.a., input features) at each timestamp by referring to the previous encoder hidden state. In the second stage, we use a temporal attention mechanism to select relevant encoder hidden states across all the timestamps. With this dual-stage attention scheme, our model can not only make prediction effectively, but can also be easily interpreted. Thorough empirical studies based upon the SML 2010 dataset and the NASDAQ 100 Stock dataset demonstrate that DA-RNN can outperform state-of-the-art methods for time series prediction. version:1
arxiv-1704-02402 | GoDP: Globally optimized dual pathway system for facial landmark localization in-the-wild | http://arxiv.org/abs/1704.02402 | id:1704.02402 author:Yuhang Wu, Shishir K. Shah, Ioannis A. Kakadiaris category:cs.CV  published:2017-04-07 summary:Facial landmark localization is a fundamental module for face recognition. Current common approach for facial landmark detection is cascaded regression, which is composed by two steps: feature extraction and facial shape regression. Recent methods employ deep convolutional networks to extract robust features in each step and the whole system could be regarded as a deep cascaded regression architecture. Unfortunately, this architecture is problematic. First, parameters in the networks are optimized from a greedy stage-wise perspective. Second, the network cannot efficiently merge landmark coordinate vectors with 2D convolutional layers. Third, the facial shape regression relies on a feature vector generated from the bottom layer of the convolutional neural network, which has recently been criticized for lacking spatial resolution to accomplish pixel-wise localization tasks. We propose a globally optimized dual-pathway system (GoDP) to handle the optimization and precision weaknesses of deep cascaded regression without resorting to high-level inference models or complex stacked architecture. This end-to-end system relies on distance-aware softmax functions and dual-pathway proposal-refinement architecture. The proposed system outperforms the state-of-the-art cascaded regression-based methods on multiple in-the-wild face alignment databases. Experiments on face identification demonstrate that GoDP significantly improves the quality of face frontalization in face recognition. version:1
arxiv-1704-02399 | Stein Variational Policy Gradient | http://arxiv.org/abs/1704.02399 | id:1704.02399 author:Yang Liu, Prajit Ramachandran, Qiang Liu, Jian Peng category:cs.LG  published:2017-04-07 summary:Policy gradient methods have been successfully applied to many complex reinforcement learning problems. However, policy gradient methods suffer from high variance, slow convergence, and inefficient exploration. In this work, we introduce a maximum entropy policy optimization framework which explicitly encourages parameter exploration, and show that this framework can be reduced to a Bayesian inference problem. We then propose a novel Stein variational policy gradient method (SVPG) which combines existing policy gradient methods and a repulsive functional to generate a set of diverse but well-behaved policies. SVPG is robust to initialization and can easily be implemented in a parallel manner. On continuous control problems, we find that implementing SVPG on top of REINFORCE and advantage actor-critic algorithms improves both average return and data efficiency. version:1
arxiv-1704-02393 | Learning Where to Look: Data-Driven Viewpoint Set Selection for 3D Scenes | http://arxiv.org/abs/1704.02393 | id:1704.02393 author:Kyle Genova, Manolis Savva, Angel X. Chang, Thomas Funkhouser category:cs.CV  published:2017-04-07 summary:The use of rendered images, whether from completely synthetic datasets or from 3D reconstructions, is increasingly prevalent in vision tasks. However, little attention has been given to how the selection of viewpoints affects the performance of rendered training sets. In this paper, we propose a data-driven approach to view set selection. Given a set of example images, we extract statistics describing their contents and generate a set of views matching the distribution of those statistics. Motivated by semantic segmentation tasks, we model the spatial distribution of each semantic object category within an image view volume. We provide a search algorithm that generates a sampling of likely candidate views according to the example distribution, and a set selection algorithm that chooses a subset of the candidates that jointly cover the example distribution. Results of experiments with these algorithms on SUNCG indicate that they are indeed able to produce view distributions similar to an example set from NYUDv2 according to the earth mover's distance. Furthermore, the selected views improve performance on semantic segmentation compared to alternative view selection algorithms. version:1
arxiv-1704-02386 | Pixelwise Instance Segmentation with a Dynamically Instantiated Network | http://arxiv.org/abs/1704.02386 | id:1704.02386 author:Anurag Arnab, Philip H. S Torr category:cs.CV  published:2017-04-07 summary:Semantic segmentation and object detection research have recently achieved rapid progress. However, the former task has no notion of different instances of the same object, and the latter operates at a coarse, bounding-box level. We propose an Instance Segmentation system that produces a segmentation map where each pixel is assigned an object class and instance identity label. Most approaches adapt object detectors to produce segments instead of boxes. In contrast, our method is based on an initial semantic segmentation module, which feeds into an instance subnetwork. This subnetwork uses the initial category-level segmentation, along with cues from the output of an object detector, within an end-to-end CRF to predict instances. This part of our model is dynamically instantiated to produce a variable number of instances per image. Our end-to-end approach requires no post-processing and considers the image holistically, instead of processing independent proposals. Therefore, unlike some related work, a pixel cannot belong to multiple instances. Furthermore, far more precise segmentations are achieved, as shown by our state-of-the-art results (particularly at high IoU thresholds) on the Pascal VOC and Cityscapes datasets. version:1
arxiv-1704-02385 | A Trolling Hierarchy in Social Media and A Conditional Random Field For Trolling Detection | http://arxiv.org/abs/1704.02385 | id:1704.02385 author:Luis Gerardo Mojica category:cs.CL  published:2017-04-07 summary:An-ever increasing number of social media websites, electronic newspapers and Internet forums allow visitors to leave comments for others to read and interact. This exchange is not free from participants with malicious intentions, which do not contribute with the written conversation. Among different communities users adopt strategies to handle such users. In this paper we present a comprehensive categorization of the trolling phenomena resource, inspired by politeness research and propose a model that jointly predicts four crucial aspects of trolling: intention, interpretation, intention disclosure and response strategy. Finally, we present a new annotated dataset containing excerpts of conversations involving trolls and the interactions with other users that we hope will be a useful resource for the research community. version:1
arxiv-1704-02378 | Uncovering Group Level Insights with Accordant Clustering | http://arxiv.org/abs/1704.02378 | id:1704.02378 author:Amit Dhurandhar, Margareta Ackerman, Xiang Wang category:cs.LG  published:2017-04-07 summary:Clustering is a widely-used data mining tool, which aims to discover partitions of similar items in data. We introduce a new clustering paradigm, \emph{accordant clustering}, which enables the discovery of (predefined) group level insights. Unlike previous clustering paradigms that aim to understand relationships amongst the individual members, the goal of accordant clustering is to uncover insights at the group level through the analysis of their members. Group level insight can often support a call to action that cannot be informed through previous clustering techniques. We propose the first accordant clustering algorithm, and prove that it finds near-optimal solutions when data possesses inherent cluster structure. The insights revealed by accordant clusterings enabled experts in the field of medicine to isolate successful treatments for a neurodegenerative disease, and those in finance to discover patterns of unnecessary spending. version:1
arxiv-1704-02356 | Three-Dimensional Segmentation of Vesicular Networks of Fungal Hyphae in Macroscopic Microscopy Image Stacks | http://arxiv.org/abs/1704.02356 | id:1704.02356 author:P. Saponaro, W. Treible, A. Kolagunda, S. Rhein, J. Caplan, C. Kambhamettu, R. Wisser category:cs.CV  published:2017-04-07 summary:Automating the extraction and quantification of features from three-dimensional (3-D) image stacks is a critical task for advancing computer vision research. The union of 3-D image acquisition and analysis enables the quantification of biological resistance of a plant tissue to fungal infection through the analysis of attributes such as fungal penetration depth, fungal mass, and branching of the fungal network of connected cells. From an image processing perspective, these tasks reduce to segmentation of vessel-like structures and the extraction of features from their skeletonization. In order to sample multiple infection events for analysis, we have developed an approach we refer to as macroscopic microscopy. However, macroscopic microscopy produces high-resolution image stacks that pose challenges to routine approaches and are difficult for a human to annotate to obtain ground truth data. We present a synthetic hyphal network generator, a comparison of several vessel segmentation methods, and a minimum spanning tree method for connecting small gaps resulting from imperfections in imaging or incomplete skeletonization of hyphal networks. Qualitative results are shown for real microscopic data. We believe the comparison of vessel detectors on macroscopic microscopy data, the synthetic vessel generator, and the gap closing technique are beneficial to the image processing community. version:1
arxiv-1704-02348 | Automated Unsupervised Segmentation of Liver Lesions in CT scans via Cahn-Hilliard Phase Separation | http://arxiv.org/abs/1704.02348 | id:1704.02348 author:Jana Lipková, Markus Rempfler, Patrick Christ, John Lowengrub, Bjoern H. Menze category:cs.CV  published:2017-04-07 summary:The segmentation of liver lesions is crucial for detection, diagnosis and monitoring progression of liver cancer. However, design of accurate automated methods remains challenging due to high noise in CT scans, low contrast between liver and lesions, as well as large lesion variability. We propose a 3D automatic, unsupervised method for liver lesions segmentation using a phase separation approach. It is assumed that liver is a mixture of two phases: healthy liver and lesions, represented by different image intensities polluted by noise. The Cahn-Hilliard equation is used to remove the noise and separate the mixture into two distinct phases with well-defined interfaces. This simplifies the lesion detection and segmentation task drastically and enables to segment liver lesions by thresholding the Cahn-Hilliard solution. The method was tested on 3Dircadb and LITS dataset. version:1
arxiv-1704-02346 | Joint Probabilistic Linear Discriminant Analysis | http://arxiv.org/abs/1704.02346 | id:1704.02346 author:Luciana Ferrer category:cs.LG stat.ML  published:2017-04-07 summary:Standard probabilistic discriminant analysis (PLDA) for speaker recognition assumes that the sample's features (usually, i-vectors) are given by a sum of three terms: a term that depends on the speaker identity, a term that models the within-speaker variability and is assumed independent across samples, and a final term that models any remaining variability and is also independent across samples. In this work, we propose a generalization of this model where the within-speaker variability is not necessarily assumed independent across samples but dependent on another discrete variable. This variable, which we call the channel variable as in the standard PLDA approach, could be, for example, a discrete category for the channel characteristics, the language spoken by the speaker, the type of speech in the sample (conversational, monologue, read), etc. The value of this variable is assumed to be known during training but not during testing. Scoring is performed, as in standard PLDA, by computing a likelihood ratio between the null hypothesis that the two sides of a trial belong to the same speaker versus the alternative hypothesis that the two sides belong to different speakers. The two likelihoods are computed by marginalizing over two hypothesis about the channels in both sides of a trial: that they are the same and that they are different. This way, we expect that the new model will be better at coping with same-channel versus different-channel trials than standard PLDA, since knowledge about the channel (or language, or speech style) is used during training and implicitly considered during scoring. version:1
arxiv-1704-02345 | Fast Spectral Clustering Using Autoencoders and Landmarks | http://arxiv.org/abs/1704.02345 | id:1704.02345 author:Ershad Banijamali, Ali Ghodsi category:cs.LG stat.ML  published:2017-04-07 summary:In this paper, we introduce an algorithm for performing spectral clustering efficiently. Spectral clustering is a powerful clustering algorithm that suffers from high computational complexity, due to eigen decomposition. In this work, we first build the adjacency matrix of the corresponding graph of the dataset. To build this matrix, we only consider a limited number of points, called landmarks, and compute the similarity of all data points with the landmarks. Then, we present a definition of the Laplacian matrix of the graph that enable us to perform eigen decomposition efficiently, using a deep autoencoder. The overall complexity of the algorithm for eigen decomposition is $O(np)$, where $n$ is the number of data points and $p$ is the number of landmarks. At last, we evaluate the performance of the algorithm in different experiments. version:1
arxiv-1704-02340 | Evolutionary Many-Objective Optimization Based on Adversarial Decomposition | http://arxiv.org/abs/1704.02340 | id:1704.02340 author:Mengyuan Wu, Ke Li, Sam Kwong, Qingfu Zhang category:cs.NE  published:2017-04-07 summary:The decomposition-based method has been recognized as a major approach for multi-objective optimization. It decomposes a multi-objective optimization problem into several single-objective optimization subproblems, each of which is usually defined as a scalarizing function using a weight vector. Due to the characteristics of the contour line of a particular scalarizing function, the performance of the decomposition-based method strongly depends on the Pareto front's shape by merely using a single scalarizing function, especially when facing a large number of objectives. To improve the flexibility of the decomposition-based method, this paper develops an adversarial decomposition method that leverages the complementary characteristics of two different scalarizing functions within a single paradigm. More specifically, we maintain two co-evolving populations simultaneously by using different scalarizing functions. In order to avoid allocating redundant computational resources to the same region of the Pareto front, we stably match these two co-evolving populations into one-one solution pairs according to their working regions of the Pareto front. Then, each solution pair can at most contribute one mating parent during the mating selection process. Comparing with nine state-of-the-art many-objective optimizers, we have witnessed the competitive performance of our proposed algorithm on 130 many-objective test instances with various characteristics and Pareto front's shapes. version:1
arxiv-1704-02312 | A Constrained Sequence-to-Sequence Neural Model for Sentence Simplification | http://arxiv.org/abs/1704.02312 | id:1704.02312 author:Yaoyuan Zhang, Zhenxu Ye, Yansong Feng, Dongyan Zhao, Rui Yan category:cs.CL cs.AI cs.NE  published:2017-04-07 summary:Sentence simplification reduces semantic complexity to benefit people with language impairments. Previous simplification studies on the sentence level and word level have achieved promising results but also meet great challenges. For sentence-level studies, sentences after simplification are fluent but sometimes are not really simplified. For word-level studies, words are simplified but also have potential grammar errors due to different usages of words before and after simplification. In this paper, we propose a two-step simplification framework by combining both the word-level and the sentence-level simplifications, making use of their corresponding advantages. Based on the two-step framework, we implement a novel constrained neural generation model to simplify sentences given simplified words. The final results on Wikipedia and Simple Wikipedia aligned datasets indicate that our method yields better performance than various baselines. version:1
arxiv-1704-02304 | Adversarial Generator-Encoder Networks | http://arxiv.org/abs/1704.02304 | id:1704.02304 author:Dmitry Ulyanov, Andrea Vedaldi, Victor Lempitsky category:cs.CV cs.LG stat.ML  published:2017-04-07 summary:We present a new autoencoder-type architecture, that is trainable in an unsupervised mode, sustains both generation and inference, and has the quality of conditional and unconditional samples boosted by adversarial learning. Unlike previous hybrids of autoencoders and adversarial networks, the adversarial game in our approach is set up directly between the encoder and the generator, and no external mappings are trained in the process of learning. The game objective compares the divergences of each of the real and the generated data distributions with the canonical distribution in the latent space. We show that direct generator-vs-encoder game leads to a tight coupling of the two components, resulting in samples and reconstructions of a comparable quality to some recently-proposed more complex architectures. version:1
arxiv-1704-02298 | TransNets: Learning to Transform for Recommendation | http://arxiv.org/abs/1704.02298 | id:1704.02298 author:Rose Catherine, William Cohen category:cs.IR cs.CL cs.LG  published:2017-04-07 summary:Recently, deep learning methods have been shown to improve the performance of recommender systems over traditional methods, especially when review text is available. For example, a recent model, DeepCoNN, uses neural nets to learn one latent representation for the text of all reviews written by a target user, and a second latent representation for the text of all reviews for a target item, and then combines these latent representations to obtain state-of-the-art performance on recommendation tasks. We show that (unsurprisingly) much of the predictive value of review text comes from reviews of the target user for the target item. We then introduce a way in which this information can be used in recommendation, even when the target user's review for the target item is not available. Our model, called TransNets, extends the DeepCoNN model by introducing an additional latent layer representing the target user-target item pair. We then regularize this layer, at training time, to be similar to another latent representation of the target user's review of the target item. We show that TransNets and extensions of it improve substantially over the previous state-of-the-art. version:1
arxiv-1704-02293 | Comparison of Global Algorithms in Word Sense Disambiguation | http://arxiv.org/abs/1704.02293 | id:1704.02293 author:Loïc Vial, Andon Tchechmedjiev, Didier Schwab category:cs.CL  published:2017-04-07 summary:This article compares four probabilistic algorithms (global algorithms) for Word Sense Disambiguation (WSD) in terms of the number of scorer calls (local algo- rithm) and the F1 score as determined by a gold-standard scorer. Two algorithms come from the state of the art, a Simulated Annealing Algorithm (SAA) and a Genetic Algorithm (GA) as well as two algorithms that we first adapt from WSD that are state of the art probabilistic search algorithms, namely a Cuckoo search algorithm (CSA) and a Bat Search algorithm (BS). As WSD requires to evaluate exponentially many word sense combinations (with branching factors of up to 6 or more), probabilistic algorithms allow to find approximate solution in a tractable time by sampling the search space. We find that CSA, GA and SA all eventually converge to similar results (0.98 F1 score), but CSA gets there faster (in fewer scorer calls) and reaches up to 0.95 F1 before SA in fewer scorer calls. In BA a strict convergence criterion prevents it from reaching above 0.89 F1. version:1
arxiv-1704-02286 | Threat analysis of IoT networks Using Artificial Neural Network Intrusion Detection System | http://arxiv.org/abs/1704.02286 | id:1704.02286 author:Elike Hodo, Xavier Bellekens, Andrew Hamilton, Pierre-louis Dubouilh, Ephraim Iorkyase, Christos Tachtatzis, Robert Atkinson category:cs.NE cs.CR  published:2017-04-07 summary:The Internet of things (IoT) is still in its infancy and has attracted much interest in many industrial sectors including medical fields, logistics tracking, smart cities and automobiles. However as a paradigm, it is susceptible to a range of significant intrusion threats. This paper presents a threat analysis of the IoT and uses an Artificial Neural Network (ANN) to combat these threats. A multi-level perceptron, a type of supervised ANN, is trained using internet packet traces, then is assessed on its ability to thwart Distributed Denial of Service (DDoS/DoS) attacks. This paper focuses on the classification of normal and threat patterns on an IoT Network. The ANN procedure is validated against a simulated IoT network. The experimental results demonstrate 99.4% accuracy and can successfully detect various DDoS/DoS attacks. version:1
arxiv-1704-02281 | Thresholding Bandits with Augmented UCB | http://arxiv.org/abs/1704.02281 | id:1704.02281 author:Subhojyoti Mukherjee, K. P. Naveen, Nandan Sudarsanam, Balaraman Ravindran category:cs.LG  published:2017-04-07 summary:In this paper we propose the Augmented-UCB (AugUCB) algorithm for a fixed-budget version of the thresholding bandit problem (TBP), where the objective is to identify a set of arms whose quality is above a threshold. A key feature of AugUCB is that it uses both mean and variance estimates to eliminate arms that have been sufficiently explored; to the best of our knowledge this is the first algorithm to employ such an approach for the considered TBP. Theoretically, we obtain an upper bound on the loss (probability of mis-classification) incurred by AugUCB. Although UCBEV in literature provides a better guarantee, it is important to emphasize that UCBEV has access to problem complexity (whose computation requires arms' mean and variances), and hence is not realistic in practice; this is in contrast to AugUCB whose implementation does not require any such complexity inputs. We conduct extensive simulation experiments to validate the performance of AugUCB. Through our simulation work, we establish that AugUCB, owing to its utilization of variance estimates, performs significantly better than the state-of-the-art APT, CSAR and other non variance-based algorithms. version:1
arxiv-1704-02206 | DeepCoder: Semi-parametric Variational Autoencoders for Facial Action Unit Intensity Estimation | http://arxiv.org/abs/1704.02206 | id:1704.02206 author:Dieu Linh Tran, Robert Walecki, Ognjen, Rudovic, Stefanos Eleftheriadis, Bjoern Schuller, Maja Pantic category:cs.CV  published:2017-04-07 summary:Variational (deep) parametric auto-encoders (VAE) have shown a great potential for unsupervised extraction of latent representations from large amounts of data. Human face exhibits an inherent hierarchy in facial representations (encoded in facial action units (AUs) and their intensity). This makes VAE a sophisticated method for learning facial features for AU intensity estimation. Yet, most existing methods apply classifiers learned separately from the encoded features. On the other hand, non-parametric (probabilistic) approaches, such as Gaussian Processes (GPs), typically outperform their parametric counterparts, but cannot deal easily with large amounts of data. In this paper, we propose a novel VAE semi-parametric modeling framework, named DeepCoder, which combines the modeling power of parametric (convolutional) and nonparametric (ordinal GPs) VAEs, for joint learning of (1) latent representations at multiple levels in a task hierarchy, and (2) classification of multiple ordinal outputs (AUs intensities). We show on benchmark datasets for AU intensity estimation that the proposed DeepCoder significantly outperforms state-of-the-art approaches, and related parametric VAEs, deep learning and parametric models. version:1
arxiv-1704-02263 | NILC-USP at SemEval-2017 Task 4: A Multi-view Ensemble for Twitter Sentiment Analysis | http://arxiv.org/abs/1704.02263 | id:1704.02263 author:Edilson A. Corrêa Jr., Vanessa Queiroz Marinho, Leandro Borges dos Santos category:cs.CL cs.LG  published:2017-04-07 summary:This paper describes our multi-view ensemble approach to SemEval-2017 Task 4 on Sentiment Analysis in Twitter, specifically, the Message Polarity Classification subtask for English (subtask A). Our system is a voting ensemble, where each base classifier is trained in a different feature space. The first space is a bag-of-words model and has a Linear SVM as base classifier. The second and third spaces are two different strategies of combining word embeddings to represent sentences and use a Linear SVM and a Logistic Regressor as base classifiers. The proposed system was ranked 18th out of 38 systems considering F1 score and 20th considering recall. version:1
arxiv-1704-02249 | Learned Watershed: End-to-End Learning of Seeded Segmentation | http://arxiv.org/abs/1704.02249 | id:1704.02249 author:Steffen Wolf, Lukas Schott, Ullrich Köthe, Fred Hamprecht category:cs.CV  published:2017-04-07 summary:Learned boundary maps are known to outperform hand- crafted ones as a basis for the watershed algorithm. We show, for the first time, how to train watershed computation jointly with boundary map prediction. The estimator for the merging priorities is cast as a neural network that is con- volutional (over space) and recurrent (over iterations). The latter allows learning of complex shape priors. The method gives the best known seeded segmentation results on the CREMI segmentation challenge. version:1
arxiv-1704-02890 | Opinion Polarization by Learning from Social Feedback | http://arxiv.org/abs/1704.02890 | id:1704.02890 author:Sven Banisch, Eckehard Olbrich category:physics.soc-ph cs.LG cs.SI nlin.AO  published:2017-04-07 summary:We explore a new mechanism to explain polarization phenomena in opinion dynamics. The model is based on the idea that agents evaluate alternative views on the basis of the social feedback obtained on expressing them. A high support of the favored and therefore expressed opinion in the social environment, is treated as a positive social feedback which reinforces the value associated to this opinion. In this paper we concentrate on the model with dyadic communication and encounter probabilities defined by an unweighted, time-homogeneous network. The model captures polarization dynamics more plausibly compared to bounded confidence opinion models and avoids extensive opinion flipping usually present in binary opinion dynamics. We perform systematic simulation experiments to understand the role of network connectivity for the emergence of polarization. version:1
arxiv-1704-02239 | Echantillonnage de signaux sur graphes via des processus déterminantaux | http://arxiv.org/abs/1704.02239 | id:1704.02239 author:Nicolas Tremblay, Simon Barthelme, Pierre-Olivier Amblard category:cs.DS cs.DM cs.LG  published:2017-04-07 summary:We consider the problem of sampling k-bandlimited graph signals, \ie, linear combinations of the first k graph Fourier modes. We know that a set of k nodes embedding all k-bandlimited signals always exists, thereby enabling their perfect reconstruction after sampling. Unfortunately, to exhibit such a set, one needs to partially diagonalize the graph Laplacian, which becomes prohibitive at large scale. We propose a novel strategy based on determinantal point processes that side-steps partial diagonalisation and enables reconstruction with only O(k) samples. While doing so, we exhibit a new general algorithm to sample determinantal process, faster than the state-of-the-art algorithm by an order k. version:1
arxiv-1704-02231 | Clothing and People - A Social Signal Processing Perspective | http://arxiv.org/abs/1704.02231 | id:1704.02231 author:Maedeh Aghaei, Federico Parezzan, Mariella Dimiccoli, Petia Radeva, Marco Cristani category:cs.CV  published:2017-04-07 summary:In our society and century, clothing is not anymore used only as a means for body protection. Our paper builds upon the evidence, studied within the social sciences, that clothing brings a clear communicative message in terms of social signals, influencing the impression and behaviour of others towards a person. In fact, clothing correlates with personality traits, both in terms of self-assessment and assessments that unacquainted people give to an individual. The consequences of these facts are important: the influence of clothing on the decision making of individuals has been investigated in the literature, showing that it represents a discriminative factor to differentiate among diverse groups of people. Unfortunately, this has been observed after cumbersome and expensive manual annotations, on very restricted populations, limiting the scope of the resulting claims. With this position paper, we want to sketch the main steps of the very first systematic analysis, driven by social signal processing techniques, of the relationship between clothing and social signals, both sent and perceived. Thanks to human parsing technologies, which exhibit high robustness owing to deep learning architectures, we are now capable to isolate visual patterns characterising a large types of garments. These algorithms will be used to capture statistical relations on a large corpus of evidence to confirm the sociological findings and to go beyond the state of the art. version:1
arxiv-1704-02224 | Hand3D: Hand Pose Estimation using 3D Neural Network | http://arxiv.org/abs/1704.02224 | id:1704.02224 author:Xiaoming Deng, Shuo Yang, Yinda Zhang, Ping Tan, Liang Chang, Hongan Wang category:cs.CV  published:2017-04-07 summary:We propose a novel 3D neural network architecture for 3D hand pose estimation from a single depth image. Different from previous works that mostly run on 2D depth image domain and require intermediate or post process to bring in the supervision from 3D space, we convert the depth map to a 3D volumetric representation, and feed it into a 3D convolutional neural network(CNN) to directly produce the pose in 3D requiring no further process. Our system does not require the ground truth reference point for initialization, and our network architecture naturally integrates both local feature and global context in 3D space. To increase the coverage of the hand pose space of the training data, we render synthetic depth image by transferring hand pose from existing real image datasets. We evaluation our algorithm on two public benchmarks and achieve the state-of-the-art performance. The synthetic hand pose dataset will be available. version:1
arxiv-1704-02218 | Investigating Natural Image Pleasantness Recognition using Deep Features and Eye Tracking for Loosely Controlled Human-computer Interaction | http://arxiv.org/abs/1704.02218 | id:1704.02218 author:Hamed R. Tavakoli, Jorma Laaksonen, Esa Rahtu category:cs.CV  published:2017-04-07 summary:This paper revisits recognition of natural image pleasantness by employing deep convolutional neural networks and affordable eye trackers. There exist several approaches to recognize image pleasantness: (1) computer vision, and (2) psychophysical signals. For natural images, computer vision approaches have not been as successful as for abstract paintings and is lagging behind the psychophysical signals like eye movements. Despite better results, the scalability of eye movements is adversely affected by the sensor cost. While the introduction of affordable sensors have helped the scalability issue by making the sensors more accessible, the application of such sensors in a loosely controlled human-computer interaction setup is not yet studied for affective image tagging. On the other hand, deep convolutional neural networks have boosted the performance of vision-based techniques significantly in recent years. To investigate the current status in regard to affective image tagging, we (1) introduce a new eye movement dataset using an affordable eye tracker, (2) study the use of deep neural networks for pleasantness recognition, (3) investigate the gap between deep features and eye movements. To meet these ends, we record eye movements in a less controlled setup, akin to daily human-computer interaction. We assess features from eye movements, visual features, and their combination. Our results show that (1) recognizing natural image pleasantness from eye movement under less restricted setup is difficult and previously used techniques are prone to fail, and (2) visual class categories are strong cues for predicting pleasantness, due to their correlation with emotions, necessitating careful study of this phenomenon. This latter finding is alerting as some deep learning approaches may fit to the class category bias. version:1
arxiv-1704-02216 | OBTAIN: Real-Time Beat Tracking in Audio Signals | http://arxiv.org/abs/1704.02216 | id:1704.02216 author:Ali Mottaghi, Kayhan Behdin, Ashkan Esmaeili, Mohammadreza Heydari, Farokh Marvasti category:cs.SD cs.IR cs.LG cs.MM  published:2017-04-07 summary:In this paper, we design a system in order to perform the real-time beat tracking for an audio signal. We use Onset Strength Signal (OSS) to detect the onsets and estimate the tempos. Then, we form Cumulative Beat Strength Signal (CBSS) by taking advantage of OSS and estimated tempos. Next, we perform peak detection by extracting the periodic sequence of beats among all CBSS peaks. In simulations, we can see that our proposed algorithm, Online Beat TrAckINg (OBTAIN), outperforms state-of-art results in terms of prediction accuracy while maintaining comparable and practical computational complexity. The real-time performance is tractable visually as illustrated in the simulations. version:1
arxiv-1704-02205 | High-Quality Correspondence and Segmentation Estimation for Dual-Lens Smart-Phone Portraits | http://arxiv.org/abs/1704.02205 | id:1704.02205 author:Xiaoyong Shen, Hongyun Gao, Xin Tao, Chao Zhou, Jiaya Jia category:cs.CV  published:2017-04-07 summary:Estimating correspondence between two images and extracting the foreground object are two challenges in computer vision. With dual-lens smart phones, such as iPhone 7Plus and Huawei P9, coming into the market, two images of slightly different views provide us new information to unify the two topics. We propose a joint method to tackle them simultaneously via a joint fully connected conditional random field (CRF) framework. The regional correspondence is used to handle textureless regions in matching and make our CRF system computationally efficient. Our method is evaluated over 2,000 new image pairs, and produces promising results on challenging portrait images. version:1
arxiv-1704-02203 | Privacy-Preserving Visual Learning Using Doubly Permuted Homomorphic Encryption | http://arxiv.org/abs/1704.02203 | id:1704.02203 author:Ryo Yonetani, Vishnu Naresh Boddeti, Kris M. Kitani, Yoichi Sato category:cs.CV cs.CR  published:2017-04-07 summary:We propose a privacy-preserving framework for learning visual classifiers by leveraging distributed private image data. This framework is designed to aggregate multiple classifiers updated locally using private data and to ensure that no private information about the data is exposed during its learning procedure. We utilize a homomorphic cryptosystem that can aggregate the local classifiers while they are encrypted and thus kept secret. To overcome the high computational cost of homomorphic encryption of high-dimensional classifiers, we (1) impose sparsity constraints on local classifier updates and (2) propose a novel efficient encryption scheme named doubly-permuted homomorphic encryption (DPHE) which is tailored to sparse high-dimensional data. DPHE (i) decomposes sparse data into its constituent non-zero values and their corresponding support indices, (ii) applies homomorphic encryption only to the non-zero values, and (iii) employs double permutations on the support indices to make them secret. Our experimental evaluation on several public datasets demonstrates that the proposed approach significantly outperforms other privacy-preserving methods and achieves comparable performance against state-of-the-art visual recognition methods without privacy preservation. version:1
arxiv-1704-02201 | Real-time Hand Tracking under Occlusion from an Egocentric RGB-D Sensor | http://arxiv.org/abs/1704.02201 | id:1704.02201 author:Franziska Mueller, Dushyant Mehta, Oleksandr Sotnychenko, Srinath Sridhar, Dan Casas, Christian Theobalt category:cs.CV  published:2017-04-07 summary:We present an approach for real-time, robust and accurate hand pose estimation from moving egocentric RGB-D cameras in cluttered real environments. Existing methods typically fail for hand-object interactions in cluttered scenes imaged from egocentric viewpoints, common for virtual or augmented reality applications. Our approach uses two subsequently applied Convolutional Neural Networks (CNNs) to localize the hand and regress 3D joint locations. Hand localization is achieved by using a CNN to estimate the 2D position of the hand center in the input, even in the presence of clutter and occlusions. The localized hand position, together with the corresponding input depth value, is used to generate a normalized cropped image that is fed into a second CNN to regress relative 3D hand joint locations in real time. For added accuracy, robustness and temporal stability, we refine the pose estimates using a kinematic pose tracking energy. To train the CNNs, we introduce a new photorealistic dataset that uses a merged reality approach to capture and synthesize large amounts of annotated data of natural hand interaction in cluttered scenes. Through quantitative and qualitative evaluation, we show that our method is robust to self-occlusion and occlusions by objects, particularly in moving egocentric perspectives. version:1
arxiv-1704-02199 | Could you guess an interesting movie from the posters?: An evaluation of vision-based features on movie poster database | http://arxiv.org/abs/1704.02199 | id:1704.02199 author:Yuta Matsuzaki, Kazushige Okayasu, Takaaki Imanari, Naomichi Kobayashi, Yoshihiro Kanehara, Ryousuke Takasawa, Akio Nakamura, Hirokatsu Kataoka category:cs.CV  published:2017-04-07 summary:In this paper, we aim to estimate the Winner of world-wide film festival from the exhibited movie poster. The task is an extremely challenging because the estimation must be done with only an exhibited movie poster, without any film ratings and box-office takings. In order to tackle this problem, we have created a new database which is consist of all movie posters included in the four biggest film festivals. The movie poster database (MPDB) contains historic movies over 80 years which are nominated a movie award at each year. We apply a couple of feature types, namely hand-craft, mid-level and deep feature to extract various information from a movie poster. Our experiments showed suggestive knowledge, for example, the Academy award estimation can be better rate with a color feature and a facial emotion feature generally performs good rate on the MPDB. The paper may suggest a possibility of modeling human taste for a movie recommendation. version:1
arxiv-1704-02197 | Variance Based Moving K-Means Algorithm | http://arxiv.org/abs/1704.02197 | id:1704.02197 author:Vibin Vijay, Raghunath Vp, Amarjot Singh, SN Omar category:cs.LG  published:2017-04-07 summary:Clustering is a useful data exploratory method with its wide applicability in multiple fields. However, data clustering greatly relies on initialization of cluster centers that can result in large intra-cluster variance and dead centers, therefore leading to sub-optimal solutions. This paper proposes a novel variance based version of the conventional Moving K-Means (MKM) algorithm called Variance Based Moving K-Means (VMKM) that can partition data into optimal homogeneous clusters, irrespective of cluster initialization. The algorithm utilizes a novel distance metric and a unique data element selection criteria to transfer the selected elements between clusters to achieve low intra-cluster variance and subsequently avoid dead centers. Quantitative and qualitative comparison with various clustering techniques is performed on four datasets selected from image processing, bioinformatics, remote sensing and the stock market respectively. An extensive analysis highlights the superior performance of the proposed method over other techniques. version:1
arxiv-1703-08388 | DeepVisage: Making face recognition simple yet with powerful generalization skills | http://arxiv.org/abs/1703.08388 | id:1703.08388 author:Abul Hasnat, Julien Bohné, Jonathan Milgram, Stéphane Gentric, Liming Chen category:cs.CV  published:2017-03-24 summary:Face recognition (FR) methods report significant performance by adopting the convolutional neural network (CNN) based learning methods. Although CNNs are mostly trained by optimizing the softmax loss, the recent trend shows an improvement of accuracy with different strategies, such as task-specific CNN learning with different loss functions, fine-tuning on target dataset, metric learning and concatenating features from multiple CNNs. Incorporating these tasks obviously requires additional efforts. Moreover, it demotivates the discovery of efficient CNN models for FR which are trained only with identity labels. We focus on this fact and propose an easily trainable and single CNN based FR method. Our CNN model exploits the residual learning framework. Additionally, it uses normalized features to compute the loss. Our extensive experiments show excellent generalization on different datasets. We obtain very competitive and state-of-the-art results on the LFW, IJB-A, YouTube faces and CACD datasets. version:2
arxiv-1704-02191 | The (1+$λ$) Evolutionary Algorithm with Self-Adjusting Mutation Rate | http://arxiv.org/abs/1704.02191 | id:1704.02191 author:Benjamin Doerr, Christian Gießen, Carsten Witt, Jing Yang category:cs.NE  published:2017-04-07 summary:We propose a new way to self-adjust the mutation rate in population-based evolutionary algorithms. Roughly speaking, it consists of creating half the offspring with a mutation rate that is twice the current mutation rate and the other half with half the current rate. The mutation rate is then updated to the rate used in that subpopulation which contains the best offspring. We analyze how the $(1+\lambda)$ evolutionary algorithm with this self-adjusting mutation rate optimizes the OneMax test function. We prove that this dynamic version of the $(1+\lambda)$~EA finds the optimum in an expected optimization time (number of fitness evaluations) of $O(n\lambda/\!\log\lambda+n\log n)$. This time is asymptotically smaller than the optimization time of the classic $(1+\lambda)$ EA. Previous work shows that this performance is best-possible among all $\lambda$-parallel mutation-based unbiased black-box algorithms. This result shows that the new way of adjusting the mutation rate can find optimal dynamic parameter values on the fly. Since our adjustment mechanism is simpler than the ones previously used for adjusting the mutation rate and does not have parameters itself, we are optimistic that it will find other applications. version:1
arxiv-1704-01474 | Convolutional Neural Networks for Page Segmentation of Historical Document Images | http://arxiv.org/abs/1704.01474 | id:1704.01474 author:Kai Chen, Mathias Seuret category:cs.CV cs.LG stat.ML  published:2017-04-05 summary:This paper presents a Convolutional Neural Network (CNN) based page segmentation method for handwritten historical document images. We consider page segmentation as a pixel labeling problem, i.e., each pixel is classified as one of the predefined classes. Traditional methods in this area rely on carefully hand-crafted features or large amounts of prior knowledge. In contrast, we propose to learn features from raw image pixels using a CNN. While many researchers focus on developing deep CNN architectures to solve different problems, we train a simple CNN with only one convolution layer. We show that the simple architecture achieves competitive results against other deep architectures on different public datasets. Experiments also demonstrate the effectiveness and superiority of the proposed method compared to previous methods. version:2
arxiv-1704-02166 | Semi-Latent GAN: Learning to generate and modify facial images from attributes | http://arxiv.org/abs/1704.02166 | id:1704.02166 author:Weidong Yin, Yanwei Fu, Leonid Sigal, Xiangyang Xue category:cs.CV  published:2017-04-07 summary:Generating and manipulating human facial images using high-level attributal controls are important and interesting problems. The models proposed in previous work can solve one of these two problems (generation or manipulation), but not both coherently. This paper proposes a novel model that learns how to both generate and modify the facial image from high-level semantic attributes. Our key idea is to formulate a Semi-Latent Facial Attribute Space (SL-FAS) to systematically learn relationship between user-defined and latent attributes, as well as between those attributes and RGB imagery. As part of this newly formulated space, we propose a new model --- SL-GAN which is a specific form of Generative Adversarial Network. Finally, we present an iterative training algorithm for SL-GAN. The experiments on recent CelebA and CASIA-WebFace datasets validate the effectiveness of our proposed framework. We will also make data, pre-trained models and code available. version:1
arxiv-1704-02163 | Egocentric Video Description based on Temporally-Linked Sequences | http://arxiv.org/abs/1704.02163 | id:1704.02163 author:Marc Bolaños, Álvaro Peris, Francisco Casacuberta, Sergi Soler, Petia Radeva category:cs.CV  published:2017-04-07 summary:Egocentric vision consists in acquiring images along the day from a first person point-of-view using wearable cameras. The automatic analysis of this information allows to discover daily patterns for improving the quality of life of the user. A natural topic that arises in egocentric vision is storytelling, that is, how to understand and tell the story relying behind the pictures. In this paper, we tackle storytelling as an egocentric sequences description problem. We propose a novel methodology that exploits information from temporally neighboring events, matching precisely the nature of egocentric sequences. Furthermore, we present a new method for multimodal data fusion consisting on a multi-input attention recurrent network. We also publish the first dataset for egocentric image sequences description, consisting of 1,339 events with 3,991 descriptions, from 55 days acquired by 11 people. Furthermore, we prove that our proposal outperforms classical attentional encoder-decoder methods for video description. version:1
arxiv-1704-02162 | Locally-adapted convolution-based super-resolution of irregularly-sampled ocean remote sensing data | http://arxiv.org/abs/1704.02162 | id:1704.02162 author:Manuel López-Radcenco, Ronan Fablet, Abdeldjalil Aïssa-El-Bey, Pierre Ailliot category:stat.ML  published:2017-04-07 summary:Super-resolution is a classical problem in image processing, with numerous applications to remote sensing image enhancement. Here, we address the super-resolution of irregularly-sampled remote sensing images. Using an optimal interpolation as the low-resolution reconstruction, we explore locally-adapted multimodal convolutional models and investigate different dictionary-based decompositions, namely based on principal component analysis (PCA), sparse priors and non-negativity constraints. We consider an application to the reconstruction of sea surface height (SSH) fields from two information sources, along-track altimeter data and sea surface temperature (SST) data. The reported experiments demonstrate the relevance of the proposed model, especially locally-adapted parametrizations with non-negativity constraints, to outperform optimally-interpolated reconstructions. version:1
arxiv-1704-02161 | ReLayNet: Retinal Layer and Fluid Segmentation of Macular Optical Coherence Tomography using Fully Convolutional Network | http://arxiv.org/abs/1704.02161 | id:1704.02161 author:Abhijit Guha Roy, Sailesh Conjeti, Sri Phani Krishna Karri, Debdoot Sheet, Amin Katouzian, Christian Wachinger, Nassir Navab category:cs.CV  published:2017-04-07 summary:Optical coherence tomography (OCT) is extensively used for diagnosis of diabetic macular edema due to its non-invasive imaging based assessment of the retinal layers. In this paper, we propose a new fully convolutional deep learning architecture, termed ReLayNet, for segmentation of retinal layers and fluid masses in eye OCT scans. ReLayNet uses a contracting path of convolutional blocks (encoders) to learn a heirarchy of contextual features, followed by an expansive path of convolutional blocks (decoders) for semantic segmentation. Additionally, skip connections relaying encoder outputs to matched decoder inputs are introduced to recover spatial information lost during downsampling. ReLayNet is trained with stochastic gradient descent to optimize a joint loss function comprising of both weighted logistic regression and Dice overlap loss. The framework is validated on a publicly available benchmark dataset with comparisons against five state-of-the-art segmentation methods which includes two deep learning based approaches. Additionally, eight incremental baselines are defined and compared with, to validate the individual contributions of the proposed framework. We demonstrate that ReLayNet can reliably segment the retinal layers and accumulated fluids with improved performance in retinal thickness estimation and contour delineation. With a segmentation time of 5s per volume, it is well suited for clinical applications. version:1
arxiv-1704-02157 | Multi-Scale Continuous CRFs as Sequential Deep Networks for Monocular Depth Estimation | http://arxiv.org/abs/1704.02157 | id:1704.02157 author:Dan Xu, Elisa Ricci, Wanli Ouyang, Xiaogang Wang, Nicu Sebe category:cs.CV  published:2017-04-07 summary:This paper addresses the problem of depth estimation from a single still image. Inspired by recent works on multi- scale convolutional neural networks (CNN), we propose a deep model which fuses complementary information derived from multiple CNN side outputs. Different from previous methods, the integration is obtained by means of continuous Conditional Random Fields (CRFs). In particular, we propose two different variations, one based on a cascade of multiple CRFs, the other on a unified graphical model. By designing a novel CNN implementation of mean-field updates for continuous CRFs, we show that both proposed models can be regarded as sequential deep networks and that training can be performed end-to-end. Through extensive experimental evaluation we demonstrate the effective- ness of the proposed approach and establish new state of the art results on publicly available datasets. version:1
arxiv-1704-02147 | Hierarchical Clustering: Objective Functions and Algorithms | http://arxiv.org/abs/1704.02147 | id:1704.02147 author:Vincent Cohen-Addad, Varun Kanade, Frederik Mallmann-Trenn, Claire Mathieu category:cs.DS cs.LG  published:2017-04-07 summary:Hierarchical clustering is a recursive partitioning of a dataset into clusters at an increasingly finer granularity. Motivated by the fact that most work on hierarchical clustering was based on providing algorithms, rather than optimizing a specific objective, Dasgupta framed similarity-based hierarchical clustering as a combinatorial optimization problem, where a `good' hierarchical clustering is one that minimizes some cost function. He showed that this cost function has certain desirable properties. We take an axiomatic approach to defining `good' objective functions for both similarity and dissimilarity-based hierarchical clustering. We characterize a set of "admissible" objective functions (that includes Dasgupta's one) that have the property that when the input admits a `natural' hierarchical clustering, it has an optimal value. Equipped with a suitable objective function, we analyze the performance of practical algorithms, as well as develop better algorithms. For similarity-based hierarchical clustering, Dasgupta showed that the divisive sparsest-cut approach achieves an $O(\log^{3/2} n)$-approximation. We give a refined analysis of the algorithm and show that it in fact achieves an $O(\sqrt{\log n})$-approx. (Charikar and Chatziafratis independently proved that it is a $O(\sqrt{\log n})$-approx.). This improves upon the LP-based $O(\log n)$-approx. of Roy and Pokutta. For dissimilarity-based hierarchical clustering, we show that the classic average-linkage algorithm gives a factor 2 approx., and provide a simple and better algorithm that gives a factor 3/2 approx.. Finally, we consider `beyond-worst-case' scenario through a generalisation of the stochastic block model for hierarchical clustering. We show that Dasgupta's cost function has desirable properties for these inputs and we provide a simple 1 + o(1)-approximation in this setting. version:1
arxiv-1704-02146 | Quantum ensembles of quantum classifiers | http://arxiv.org/abs/1704.02146 | id:1704.02146 author:Maria Schuld, Francesco Petruccione category:quant-ph cs.LG math.ST stat.TH  published:2017-04-07 summary:Quantum machine learning witnesses an increasing amount of quantum algorithms for data-driven decision making, a problem with potential applications ranging from automated image recognition to medical diagnosis. Many of those algorithms are implementations of quantum classifiers, or models for the classification of data inputs with a quantum computer. Following the success of collective decision making with ensembles in classical machine learning, this paper introduces the concept of quantum ensembles of quantum classifiers. Creating the ensemble corresponds to a state preparation routine, after which the quantum classifiers are evaluated in parallel and their combined decision is accessed by a single-qubit measurement. This framework naturally allows for exponentially large ensembles in which -- similar to Bayesian learning -- the individual classifiers do not have to be trained. As an example, we analyse an exponentially large quantum ensemble in which each classifier is weighed according to its performance in classifying the training data, leading to new results for quantum as well as classical machine learning. version:1
arxiv-1704-02134 | Adposition Supersenses v2 | http://arxiv.org/abs/1704.02134 | id:1704.02134 author:Nathan Schneider, Jena D. Hwang, Archna Bhatia, Na-Rae Han, Vivek Srikumar, Tim O'Gorman, Omri Abend category:cs.CL  published:2017-04-07 summary:This document describes an inventory of 50 semantic labels designed to characterize the use of adpositions and case markers at a somewhat coarse level of granularity. Version 2 is a revision of the supersense inventory proposed for English by Schneider et al. (2015, 2016) and documented in PrepWiki (henceforth "v1"), which in turn was based on previous schemes. The present inventory was developed after extensive review of the v1 corpus annotations for English, as well as consideration of adposition and case phenomena in Hebrew, Hindi, and Korean. Examples in this document are limited to English; a multilingual and more detailed online lexical resource is forthcoming. version:1
arxiv-1704-02124 | Jet Constituents for Deep Neural Network Based Top Quark Tagging | http://arxiv.org/abs/1704.02124 | id:1704.02124 author:Jannicke Pearkes, Wojciech Fedorko, Alison Lister, Colin Gay category:hep-ex cs.LG hep-ph stat.ML 62H30 I.5.1; J.2  published:2017-04-07 summary:Recent literature on deep neural networks for tagging of highly energetic jets resulting from top quark decays has focused on image based techniques or multivariate approaches using high level jet substructure variables. Here a sequential approach to this task is taken by using an ordered sequence of jet constituents as training inputs. Unlike previous approaches, this strategy does not result in a loss of information during pixelisation or the calculation of high level features. New preprocessing methods that do not alter key physical quantities such as the jet mass are developed. The jet classification method achieves background rejection of 45 for 50% efficiency operating point for reconstruction level jets with transverse momentum range of 600 to 2500 GeV and is insensitive to multiple proton-proton interactions at the levels expected throughout LHC Run 2. version:1
arxiv-1704-02117 | Partial Face Detection in the Mobile Domain | http://arxiv.org/abs/1704.02117 | id:1704.02117 author:Upal Mahbub, Sayantan Sarkar, Rama Chellappa category:cs.CV  published:2017-04-07 summary:Generic face detection algorithms do not perform well in the mobile domain due to significant presence of occluded and partially visible faces. One promising technique to handle the challenge of partial faces is to design face detectors based on facial segments. In this paper two different approaches of facial segment-based face detection are discussed, namely, proposal-based detection and detection by end-to-end regression. Methods that follow the first approach rely on generating face proposals that contain facial segment information. The three detectors following this approach, namely Facial Segment-based Face Detector (FSFD), SegFace and DeepSegFace, discussed in this paper, perform binary classification on each proposal based on features learned from facial segments. The process of proposal generation, however, needs to be handled separately, which can be very time consuming, and is not truly necessary given the nature of the active authentication problem. Hence a novel algorithm, Deep Regression-based User Image Detector (DRUID) is proposed, which shifts from the classification to the regression paradigm, thus obviating the need for proposal generation. DRUID has an unique network architecture with customized loss functions, is trained using a relatively small amount of data by utilizing a novel data augmentation scheme and is fast since it outputs the bounding boxes of a face and its segments in a single pass. Being robust to occlusion by design, the facial segment-based face detection methods, especially DRUID show superior performance over other state-of-the-art face detectors in terms of precision-recall and ROC curve on two mobile face datasets. version:1
arxiv-1704-02112 | Generalized Rank Pooling for Activity Recognition | http://arxiv.org/abs/1704.02112 | id:1704.02112 author:Anoop Cherian, Basura Fernando, Mehrtash Harandi, Stephen Gould category:cs.CV  published:2017-04-07 summary:Most popular deep models for action recognition split video sequences into short sub-sequences consisting of a few frames; frame-based features are then pooled for recognizing the activity. Usually, this pooling step discards the temporal order of the frames, which could otherwise be used for better recognition. Towards this end, we propose a novel pooling method, generalized rank pooling (GRP), that takes as input, features from the intermediate layers of a CNN that is trained on tiny sub-sequences, and produces as output the parameters of a subspace which (i) provides a low-rank approximation to the features and (ii) preserves their temporal order. We propose to use these parameters as a compact representation for the video sequence, which is then used in a classification setup. We formulate an objective for computing this subspace as a Riemannian optimization problem on the Grassmann manifold, and propose an efficient conjugate gradient scheme for solving it. Experiments on several activity recognition datasets show that our scheme leads to state-of-the-art performance. version:1
arxiv-1704-02109 | Restricted Isometry Property of Gaussian Random Projection for Finite Set of Subspaces | http://arxiv.org/abs/1704.02109 | id:1704.02109 author:Gen Li, Yuantao Gu category:cs.IT cs.LG math.IT  published:2017-04-07 summary:Dimension reduction plays an essential role when decreasing the complexity of solving large-scale problems. The well-known Johnson-Lindenstrauss (JL) Lemma and Restricted Isometry Property (RIP) admit the use of random projection to reduce the dimension while keeping the Euclidean distance, which leads to the boom of Compressed Sensing and the field of sparsity related signal processing. Recently, successful applications of sparse models in computer vision and machine learning have increasingly hinted that the underlying structure of high dimensional data looks more like a union of subspaces (UoS). In this paper, motivated by JL Lemma and an emerging field of Compressed Subspace Clustering, we study for the first time the RIP of Gaussian random matrix for compressing two subspaces. We theoretically prove that with high probability the affinity or distance between two projected subspaces are concentrated around their estimates. When the ambient dimension after projection is sufficiently large, the affinity and distance between two subspaces almost remain unchanged after random projection. Numerical experiments verify the theoretical work. version:1
arxiv-1704-02107 | When is Network Lasso Accurate? | http://arxiv.org/abs/1704.02107 | id:1704.02107 author:Alexander Jung category:stat.ML  published:2017-04-07 summary:The network Lasso is a recently proposed method for clustering and optimization problems arising from massive network structured datasets, i.e., big data over networks. It is a variant of the well-known least absolute shrinkage and selection operator (Lasso), which is underlying many methods in learning and signal processing involving sparse models. While some work has been devoted to studying efficient and scalable implementations of the network Lasso, only little is known about conditions on the underlying network structure required by network Lasso to be accurate. We address this gap by giving precise conditions on the underlying network topology which guarantee the network lasso to be accurate. version:1
arxiv-1704-02090 | Conceptualization Topic Modeling | http://arxiv.org/abs/1704.02090 | id:1704.02090 author:Yi-Kun Tang, Xian-Ling Mao, Heyan Huang, Guihua Wen category:cs.CL cs.IR  published:2017-04-07 summary:Recently, topic modeling has been widely used to discover the abstract topics in text corpora. Most of the existing topic models are based on the assumption of three-layer hierarchical Bayesian structure, i.e. each document is modeled as a probability distribution over topics, and each topic is a probability distribution over words. However, the assumption is not optimal. Intuitively, it's more reasonable to assume that each topic is a probability distribution over concepts, and then each concept is a probability distribution over words, i.e. adding a latent concept layer between topic layer and word layer in traditional three-layer assumption. In this paper, we verify the proposed assumption by incorporating the new assumption in two representative topic models, and obtain two novel topic models. Extensive experiments were conducted among the proposed models and corresponding baselines, and the results show that the proposed models significantly outperform the baselines in terms of case study and perplexity, which means the new assumption is more reasonable than traditional one. version:1
arxiv-1704-02088 | Supervised Deep Hashing for Hierarchical Labeled Data | http://arxiv.org/abs/1704.02088 | id:1704.02088 author:Dan Wang, Heyan Huang, Chi Lu, Bo-Si Feng, Liqiang Nie, Guihua Wen, Xian-Ling Mao category:cs.CV  published:2017-04-07 summary:Recently, hashing methods have been widely used in large-scale image retrieval. However, most existing hashing methods did not consider the hierarchical relation of labels, which means that they ignored the rich information stored in the hierarchy. Moreover, most of previous works treat each bit in a hash code equally, which does not meet the scenario of hierarchical labeled data. In this paper, we propose a novel deep hashing method, called supervised hierarchical deep hashing (SHDH), to perform hash code learning for hierarchical labeled data. Specifically, we define a novel similarity formula for hierarchical labeled data by weighting each layer, and design a deep convolutional neural network to obtain a hash code for each data point. Extensive experiments on several real-world public datasets show that the proposed method outperforms the state-of-the-art baselines in the image retrieval task. version:1
arxiv-1704-02083 | "RAPID" Regions-of-Interest Detection In Big Histopathological Images | http://arxiv.org/abs/1704.02083 | id:1704.02083 author:Li Sulimowicz, Ishfaq Ahmad category:cs.CV  published:2017-04-07 summary:The sheer volume and size of histopathological images (e.g.,10^6 MPixel) underscores the need for faster and more accurate Regions-of-interest (ROI) detection algorithms. In this paper, we propose such an algorithm, which has four main components that help achieve greater accuracy and faster speed: First, while using coarse-to-fine topology preserving segmentation as the baseline, the proposed algorithm uses a superpixel regularity optimization scheme for avoiding irregular and extremely small superpixels. Second, the proposed technique employs a prediction strategy to focus only on important superpixels at finer image levels. Third, the algorithm reuses the information gained from the coarsest image level at other finer image levels. Both the second and the third components drastically lower the complexity. Fourth, the algorithm employs a highly effective parallelization scheme using adap- tive data partitioning, which gains high speedup. Experimental results, conducted on the BSD500 [1] and 500 whole-slide histological images from the National Lung Screening Trial (NLST)1 dataset, confirm that the proposed algorithm gained 13 times speedup compared with the baseline, and around 160 times compared with SLIC [11], without losing accuracy. version:1
arxiv-1704-02081 | Evolution in Groups: A deeper look at synaptic cluster driven evolution of deep neural networks | http://arxiv.org/abs/1704.02081 | id:1704.02081 author:Mohammad Javad Shafiee, Elnaz Barshan, Alexander Wong category:cs.NE cs.AI cs.CV stat.ML  published:2017-04-07 summary:A promising paradigm for achieving highly efficient deep neural networks is the idea of evolutionary deep intelligence, which mimics biological evolution processes to progressively synthesize more efficient networks. A crucial design factor in evolutionary deep intelligence is the genetic encoding scheme used to simulate heredity and determine the architectures of offspring networks. In this study, we take a deeper look at the notion of synaptic cluster-driven evolution of deep neural networks which guides the evolution process towards the formation of a highly sparse set of synaptic clusters in offspring networks. Utilizing a synaptic cluster-driven genetic encoding, the probabilistic encoding of synaptic traits considers not only individual synaptic properties but also inter-synaptic relationships within a deep neural network. This process results in highly sparse offspring networks which are particularly tailored for parallel computational devices such as GPUs and deep neural network accelerator chips. Comprehensive experimental results using four well-known deep neural network architectures (LeNet-5, AlexNet, ResNet-56, and DetectNet) on two different tasks (object categorization and object detection) demonstrate the efficiency of the proposed method. Cluster-driven genetic encoding scheme synthesizes networks that can achieve state-of-the-art performance with significantly smaller number of synapses than that of the original ancestor network. ($\sim$125-fold decrease in synapses for MNIST). Furthermore, the improved cluster efficiency in the generated offspring networks ($\sim$9.71-fold decrease in clusters for MNIST and a $\sim$8.16-fold decrease in clusters for KITTI) is particularly useful for accelerated performance on parallel computing hardware architectures such as those in GPUs and deep neural network accelerator chips. version:1
arxiv-1704-02080 | Conversation Modeling on Reddit using a Graph-Structured LSTM | http://arxiv.org/abs/1704.02080 | id:1704.02080 author:Vicky Zayats, Mari Ostendorf category:cs.CL  published:2017-04-07 summary:This paper presents a novel approach for modeling threaded discussions on social media using a graph-structured bidirectional LSTM which represents both hierarchical and temporal conversation structure. In experiments with a task of predicting popularity of comments in Reddit discussions, the proposed model outperforms a node-independent architecture for different sets of input features. Analyses show a benefit to the model over the full course of the discussion, improving detection in both early and late stages. Further, the use of language cues with the bidirectional tree state updates helps with identifying controversial comments. version:1
arxiv-1704-02071 | Convolutional Neural Pyramid for Image Processing | http://arxiv.org/abs/1704.02071 | id:1704.02071 author:Xiaoyong Shen, Ying-Cong Chen, Xin Tao, Jiaya Jia category:cs.CV  published:2017-04-07 summary:We propose a principled convolutional neural pyramid (CNP) framework for general low-level vision and image processing tasks. It is based on the essential finding that many applications require large receptive fields for structure understanding. But corresponding neural networks for regression either stack many layers or apply large kernels to achieve it, which is computationally very costly. Our pyramid structure can greatly enlarge the field while not sacrificing computation efficiency. Extra benefit includes adaptive network depth and progressive upsampling for quasi-realtime testing on VGA-size input. Our method profits a broad set of applications, such as depth/RGB image restoration, completion, noise/artifact removal, edge refinement, image filtering, image enhancement and colorization. version:1
arxiv-1704-02060 | Angle-Based Joint and Individual Variation Explained | http://arxiv.org/abs/1704.02060 | id:1704.02060 author:Qing Feng, Jan Hannig, Meilei Jiang, J. S. Marron category:stat.ML  published:2017-04-07 summary:Integrative analysis of disparate data blocks measured on a common set of experimental subjects is a major challenge in modern data analysis. This data structure naturally motivates the simultaneous exploration of the joint and individual variation within each data block resulting in new insights. For instance, there is a strong desire to integrate the multiple genomic data sets in The Cancer Genome Atlas to characterize the common and also the unique aspects of cancer genetics and cell biology for each source. In this paper we introduce Angle-Based Joint and Individual Variation Explained capturing both joint and individual variation within each data block. This is a major improvement over earlier approaches to this challenge in terms of a new conceptual understanding, much better adaption to data heterogeneity and a fast linear algebra computation. Important mathematical contributions are the use of score subspaces as the principal descriptors of variation structure and the use of perturbation theory as the guide for variation segmentation. This leads to an exploratory data analysis method which is insensitive to the heterogeneity among data blocks and does not require separate normalization. An application to cancer data reveals different behaviors of each type of signal in characterizing tumor subtypes. An application to a mortality data set reveals interesting historical lessons. version:1
arxiv-1704-01314 | Character-based Joint Segmentation and POS Tagging for Chinese using Bidirectional RNN-CRF | http://arxiv.org/abs/1704.01314 | id:1704.01314 author:Yan Shao, Christian Hardmeier, Jörg Tiedemann, Joakim Nivre category:cs.CL  published:2017-04-05 summary:We present a character-based model for joint segmentation and POS tagging for Chinese. The bidirectional RNN-CRF architecture for general sequence tagging is adapted and applied with novel vector representations of Chinese characters that capture rich contextual information and lower-than-character level features. The proposed model is extensively evaluated and compared with a state-of-the-art tagger respectively on CTB5, CTB9 and UD Chinese. The experimental results indicate that our model is accurate and robust across datasets in different sizes, genres and annotation schemes. We obtain state-of-the-art performance on CTB5, achieving 94.38 F1-score for joint segmentation and POS tagging. version:2
arxiv-1703-10717 | BEGAN: Boundary Equilibrium Generative Adversarial Networks | http://arxiv.org/abs/1703.10717 | id:1703.10717 author:David Berthelot, Thomas Schumm, Luke Metz category:cs.LG stat.ML  published:2017-03-31 summary:We propose a new equilibrium enforcing method paired with a loss derived from the Wasserstein distance for training auto-encoder based Generative Adversarial Networks. This method balances the generator and discriminator during training. Additionally, it provides a new approximate convergence measure, fast and stable training and high visual quality. We also derive a way of controlling the trade-off between image diversity and visual quality. We focus on the image generation task, setting a new milestone in visual quality, even at higher resolutions. This is achieved while using a relatively simple model architecture and a standard training procedure. version:2
arxiv-1704-02038 | Treatment-Response Models for Counterfactual Reasoning with Continuous-time, Continuous-valued Interventions | http://arxiv.org/abs/1704.02038 | id:1704.02038 author:Hossein Soleimani, Adarsh Subbaswamy, Suchi Saria category:stat.ML cs.AI cs.LG  published:2017-04-06 summary:Treatment effects can be estimated from observational data as the difference in potential outcomes. In this paper, we address the challenge of estimating the potential outcome when treatment-dose levels can vary continuously over time. Further, the outcome variable may not be measured at a regular frequency. Our proposed solution represents the treatment response curves using linear time-invariant dynamical systems---this provides a flexible means for modeling response over time to highly variable dose curves. Moreover, for multivariate data, the proposed method: uncovers shared structure in treatment response and the baseline across multiple markers; and, flexibly models challenging correlation structure both across and within signals over time. For this, we build upon the framework of multiple-output Gaussian Processes. On simulated and a challenging clinical dataset, we show significant gains in accuracy over state-of-the-art models. version:1
arxiv-1703-10135 | Tacotron: Towards End-to-End Speech Synthesis | http://arxiv.org/abs/1703.10135 | id:1703.10135 author:Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J. Weiss, Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, Quoc Le, Yannis Agiomyrgiannakis, Rob Clark, Rif A. Saurous category:cs.CL cs.LG cs.SD  published:2017-03-29 summary:A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module. Building these components often requires extensive domain expertise and may contain brittle design choices. In this paper, we present Tacotron, an end-to-end generative text-to-speech model that synthesizes speech directly from characters. Given <text, audio> pairs, the model can be trained completely from scratch with random initialization. We present several key techniques to make the sequence-to-sequence framework perform well for this challenging task. Tacotron achieves a 3.82 subjective 5-scale mean opinion score on US English, outperforming a production parametric system in terms of naturalness. In addition, since Tacotron generates speech at the frame level, it's substantially faster than sample-level autoregressive methods. version:2
arxiv-1704-02019 | Associative content-addressable networks with exponentially many robust stable states | http://arxiv.org/abs/1704.02019 | id:1704.02019 author:Rishidev Chaudhuri, Ila Fiete category:q-bio.NC cs.NE  published:2017-04-06 summary:The brain must robustly store a large number of memories, corresponding to the many events and scenes a person encounters over a lifetime. However, the number of memory states in existing neural network models either grows weakly with network size or recall performance fails catastrophically with vanishingly little noise. Here we show that it is possible to construct an associative content-addressable memory (ACAM) with exponentially many stable states and robust error-correction. The network possesses expander graph connectivity on a restricted Boltzmann machine architecture. The expansion property allows simple neural network dynamics to perform at par with modern error-correcting codes. Appropriate networks can be constructed with sparse random connections combined with glomerular nodes and a local associative learning rule, using low dynamic-range weights. Thus, sparse quasi-random constraint structures -- characteristic of an important class of modern error-correcting codes -- may provide for high-performance computation in artificial neural networks and the brain. version:1
arxiv-1704-02012 | A Software-equivalent SNN Hardware using RRAM-array for Asynchronous Real-time Learning | http://arxiv.org/abs/1704.02012 | id:1704.02012 author:Aditya Shukla, Vinay Kumar, Udayan Ganguly category:cs.NE  published:2017-04-06 summary:Spiking Neural Network (SNN) naturally inspires hardware implementation as it is based on biology. For learning, spike time dependent plasticity (STDP) may be implemented using an energy efficient waveform superposition on memristor based synapse. However, system level implementation has three challenges. First, a classic dilemma is that recognition requires current reading for short voltage$-$spikes which is disturbed by large voltage$-$waveforms that are simultaneously applied on the same memristor for real$-$time learning i.e. the simultaneous read$-$write dilemma. Second, the hardware needs to exactly replicate software implementation for easy adaptation of algorithm to hardware. Third, the devices used in hardware simulations must be realistic. In this paper, we present an approach to address the above concerns. First, the learning and recognition occurs in separate arrays simultaneously in real$-$time, asynchronously $-$ avoiding non$-$biomimetic clocking based complex signal management. Second, we show that the hardware emulates software at every stage by comparison of SPICE (circuit$-$simulator) with MATLAB (mathematical SNN algorithm implementation in software) implementations. As an example, the hardware shows 97.5 per cent accuracy in classification which is equivalent to software for a Fisher$-$Iris dataset. Third, the STDP is implemented using a model of synaptic device implemented using HfO2 memristor. We show that an increasingly realistic memristor model slightly reduces the hardware performance (85 per cent), which highlights the need to engineer RRAM characteristics specifically for SNN. version:1
arxiv-1704-02007 | DIMM-SC: A Dirichlet mixture model for clustering droplet-based single cell transcriptomic data | http://arxiv.org/abs/1704.02007 | id:1704.02007 author:Zhe Sun, Ting Wang, Ke Deng, Xiao-Feng Wang, Robert Lafyatis, Ying Ding, Ming Hu, Wei Chen category:stat.ML q-bio.QM  published:2017-04-06 summary:Motivation: Single cell transcriptome sequencing (scRNA-Seq) has become a revolutionary tool to study cellular and molecular processes at single cell resolution. Among existing technologies, the recently developed droplet-based platform enables efficient parallel processing of thousands of single cells with direct counting of transcript copies using Unique Molecular Identifier (UMI). Despite the technology advances, statistical methods and computational tools are still lacking for analyzing droplet-based scRNA-Seq data. Particularly, model-based approaches for clustering large-scale single cell transcriptomic data are still under-explored. Methods: We developed DIMM-SC, a Dirichlet Mixture Model for clustering droplet-based Single Cell transcriptomic data. This approach explicitly models UMI count data from scRNA-Seq experiments and characterizes variations across different cell clusters via a Dirichlet mixture prior. An expectation-maximization algorithm is used for parameter inference. Results: We performed comprehensive simulations to evaluate DIMM-SC and compared it with existing clustering methods such as K-means, CellTree and Seurat. In addition, we analyzed public scRNA-Seq datasets with known cluster labels and in-house scRNA-Seq datasets from a study of systemic sclerosis with prior biological knowledge to benchmark and validate DIMM-SC. Both simulation studies and real data applications demonstrated that overall, DIMM-SC achieves substantially improved clustering accuracy and much lower clustering variability compared to other existing clustering methods. More importantly, as a model-based approach, DIMM-SC is able to quantify the clustering uncertainty for each single cell, facilitating rigorous statistical inference and biological interpretations, which are typically unavailable from existing clustering methods. version:1
arxiv-1704-01312 | On Generalization and Regularization in Deep Learning | http://arxiv.org/abs/1704.01312 | id:1704.01312 author:Pirmin Lemberger category:stat.ML cs.LG math.ST stat.TH 62-01  published:2017-04-05 summary:Why do large neural network generalize so well on complex tasks such as image classification or speech recognition? What exactly is the role regularization for them? These are arguably among the most important open questions in machine learning today. In a recent and thought provoking paper [C. Zhang et al.] several authors performed a number of numerical experiments that hint at the need for novel theoretical concepts to account for this phenomenon. The paper stirred quit a lot of excitement among the machine learning community but at the same time it created some confusion as discussions on OpenReview.net testifies. The aim of this pedagogical paper is to make this debate accessible to a wider audience of data scientists without advanced theoretical knowledge in statistical learning. The focus here is on explicit mathematical definitions and on a discussion of relevant concepts, not on proofs for which we provide references. version:2
arxiv-1704-01975 | An Automated Text Categorization Framework based on Hyperparameter Optimization | http://arxiv.org/abs/1704.01975 | id:1704.01975 author:Eric S. Tellez, Daniela Moctezuma, Sabino Miranda-Jímenez, Mario Graff category:cs.CL cs.AI stat.ML  published:2017-04-06 summary:The amount of textual data generated in environments such as social media, blogs, online newspapers, and so on, have attracted the attention of the scientific community in order to automatize and improve several tasks that were manually performed such as sentiment analysis, user profiling, or text categorization, just to mention a few. Fortunately, several of these activities can be posed as a classification problem, i.e., a problem where one is interested in developing a function, from a set of texts with associated labels, capable of predicting a label given an unseen text. In this contribution, we propose a text classifier, named $\mu$TC. $\mu$TC is composed of a number of easy to implement text transformation, text representation and a machine learning algorithm that produce a competitive classifier even over informal written text when these parts are correctly configured. We provide a detailed description of $\mu$TC along with an extensive experimental comparison with the relevant state-of-the-art methods. $\mu$TC was compared on 30 different datasets obtaining the best performance (regarding accuracy) in 18 of them. The different datasets include several problems like topic and polarity classification, spam detection, user profiling and authorship attribution. Furthermore, it is important to comment that our approach allows the usage of the technology even for users without knowledge of machine learning and natural language processing. version:1
arxiv-1704-01942 | ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models | http://arxiv.org/abs/1704.01942 | id:1704.01942 author:Minsuk Kahng, Pierre Andrews, Aditya Kalro, Duen Horng Chau category:cs.HC stat.ML  published:2017-04-06 summary:While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance- and subset-level. ActiVis has been deployed on Facebook's machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models. version:1
arxiv-1704-04428 | Parallel Multi Channel Convolution using General Matrix Multiplication | http://arxiv.org/abs/1704.04428 | id:1704.04428 author:Aravind Vasudevan, Andrew Anderson, David Gregg category:cs.CV cs.PF  published:2017-04-06 summary:Convolutional neural networks (CNNs) have emerged as one of the most successful machine learning technologies for image and video processing. The most computationally intensive parts of CNNs are the convolutional layers, which convolve multi-channel images with multiple kernels. A common approach to implementing convolutional layers is to expand the image into a column matrix (im2col) and perform Multiple Channel Multiple Kernel (MCMK) convolution using an existing parallel General Matrix Multiplication (GEMM) library. This im2col conversion greatly increases the memory footprint of the input matrix and reduces data locality. In this paper we propose a new approach to MCMK convolution that is based on General Matrix Multiplication (GEMM), but not on im2col. Our algorithm eliminates the need for data replication on the input. By splitting a single call to GEMM into several smaller calls, we can eliminate date size increases on either the input or output of the convolution layer. We have implemented several variants of our algorithm on CPU and GPU processors. On CPU, our algorithm uses much less memory than im2col and in most cases is also faster. version:1
arxiv-1704-02227 | Training Triplet Networks with GAN | http://arxiv.org/abs/1704.02227 | id:1704.02227 author:Maciej Zieba, Lei Wang category:cs.LG stat.ML  published:2017-04-06 summary:Triplet networks are widely used models that are characterized by good performance in classification and retrieval tasks. In this work we propose to train a triplet network by putting it as the discriminator in Generative Adversarial Nets (GANs). We make use of the good capability of representation learning of the discriminator to increase the predictive quality of the model. We evaluated our approach on Cifar10 and MNIST datasets and observed significant improvement on the classification performance using the simple k-nn method. version:1
arxiv-1704-01938 | The Interplay of Semantics and Morphology in Word Embeddings | http://arxiv.org/abs/1704.01938 | id:1704.01938 author:Oded Avraham, Yoav Goldberg category:cs.CL  published:2017-04-06 summary:We explore the ability of word embeddings to capture both semantic and morphological similarity, as affected by the different types of linguistic properties (surface form, lemma, morphological tag) used to compose the representation of each word. We train several models, where each uses a different subset of these properties to compose its representations. By evaluating the models on semantic and morphological measures, we reveal some useful insights on the relationship between semantics and morphology. version:1
arxiv-1704-01926 | Semantically-Guided Video Object Segmentation | http://arxiv.org/abs/1704.01926 | id:1704.01926 author:Sergi Caelles, Yuhua Chen, Jordi Pont-Tuset, Luc Van Gool category:cs.CV  published:2017-04-06 summary:This paper tackles the problem of semi-supervised video object segmentation, that is, segmenting an object in a sequence given its mask in the first frame. One of the main challenges in this scenario is the change of appearance of the objects of interest. Their semantics, on the other hand, do not vary. This paper investigates how to take advantage of such invariance via the introduction of a semantic prior that guides the appearance model. Specifically, given the segmentation mask of the first frame of a sequence, we estimate the semantics of the object of interest, and propagate that knowledge throughout the sequence to improve the results based on an appearance model. We present Semantically-Guided Video Object Segmentation (SGV), which improves results over previous state of the art on two different datasets using a variety of evaluation metrics, while running in half a second per frame. version:1
arxiv-1704-01925 | Automated Latent Fingerprint Recognition | http://arxiv.org/abs/1704.01925 | id:1704.01925 author:Kai Cao, Anil K. Jain category:cs.CV  published:2017-04-06 summary:Latent fingerprints are one of the most important and widely used evidence in law enforcement and forensic agencies worldwide. Yet, NIST evaluations show that the performance of state-of-the-art latent recognition systems is far from satisfactory. An automated latent fingerprint recognition system with high accuracy is essential to compare latents found at crime scenes to a large collection of reference prints to generate a candidate list of possible mates. In this paper, we propose an automated latent fingerprint recognition algorithm that utilizes Convolutional Neural Networks (ConvNets) for ridge flow estimation and minutiae descriptor extraction, and extract complementary templates (two minutiae templates and one texture template) to represent the latent. The comparison scores between the latent and a reference print based on the three templates are fused to retrieve a short candidate list from the reference database. Experimental results show that the rank-1 identification accuracies (query latent is matched with its true mate in the reference database) are 64.7% for the NIST SD27 and 75.3% for the WVU latent databases, against a reference database of 100K rolled prints. These results are the best among published papers on latent recognition and competitive with the performance (66.7% and 70.8% rank-1 accuracies on NIST SD27 and WVU DB, respectively) of a leading COTS latent Automated Fingerprint Identification System (AFIS). By score-level (rank-level) fusion of our system with the commercial off-the-shelf (COTS) latent AFIS, the overall rank-1 identification performance can be improved from 64.7% and 75.3% to 73.3% (74.4%) and 76.6% (78.4%) on NIST SD27 and WVU latent databases, respectively. version:1
arxiv-1704-01920 | Encoder Based Lifelong Learning | http://arxiv.org/abs/1704.01920 | id:1704.01920 author:Amal Rannen Triki, Rahaf Aljundi, Mathew B. Blaschko, Tinne Tuytelaars category:cs.CV cs.AI stat.ML  published:2017-04-06 summary:This paper introduces a new lifelong learning solution where a single model is trained for a sequence of tasks. The main challenge that vision systems face in this context is catastrophic forgetting: as they tend to adapt to the most recently seen task, they lose performance on the tasks that were learned previously. Our method aims at preserving the knowledge of the previous tasks while learning a new one by using autoencoders. For each task, an under-complete autoencoder is learned, capturing the features that are crucial for its achievement. When a new task is presented to the system, we prevent the reconstructions of the features with these autoencoders from changing, which has the effect of preserving the information on which the previous tasks are mainly relying. At the same time, the features are given space to adjust to the most recent environment as only their projection into a low dimension submanifold is controlled. The proposed system is evaluated on image classification tasks and shows a reduction of forgetting over the state-of-the-art version:1
arxiv-1704-01918 | Cooperative network localization using hybrid range and angle measurements | http://arxiv.org/abs/1704.01918 | id:1704.01918 author:Hassan Naseri, Visa Koivunen category:cs.IT math.IT stat.ML  published:2017-04-06 summary:A reliable, accurate, and affordable positioning service is highly required in wireless networks. In this paper, a novel distributed message passing algorithm is proposed to solve the problem of cooperative network localization using both distance and angle of arrival estimates. This hybrid approach combines the distance and angle observations to reduce the uncertainty in localizing the network nodes. A statistical problem formulations is employed and approximate minimum mean square error (MMSE) estimates of the node locations are found. Numerical results are presented to show the improvement in localization performance compared to existing distance-only and angle-only localization methods. Moreover, the proposed algorithm improves the identifiability of the localization problem compared to range-only or angle-only localization techniques. That is, it can solve the problem with fewer anchor nodes and fewer connections in the network. version:1
arxiv-1704-01897 | Online Hashing | http://arxiv.org/abs/1704.01897 | id:1704.01897 author:Long-Kai Huang, Qiang Yang, Wei-Shi Zheng category:cs.CV cs.LG  published:2017-04-06 summary:Although hash function learning algorithms have achieved great success in recent years, most existing hash models are off-line, which are not suitable for processing sequential or online data. To address this problem, this work proposes an online hash model to accommodate data coming in stream for online learning. Specifically, a new loss function is proposed to measure the similarity loss between a pair of data samples in hamming space. Then, a structured hash model is derived and optimized in a passive-aggressive way. Theoretical analysis on the upper bound of the cumulative loss for the proposed online hash model is provided. Furthermore, we extend our online hashing from a single-model to a multi-model online hashing that trains multiple models so as to retain diverse online hashing models in order to avoid biased update. The competitive efficiency and effectiveness of the proposed online hash models are verified through extensive experiments on several large-scale datasets as compared to related hashing methods. version:1
arxiv-1704-01896 | Statistical Efficiency of Compositional Nonparametric Prediction | http://arxiv.org/abs/1704.01896 | id:1704.01896 author:Yixi Xu, Jean Honorio, Xiao Wang category:stat.ML cs.LG  published:2017-04-06 summary:In this paper, we propose a compositional nonparametric method in which a model is expressed as a labeled binary tree of $2k+1$ nodes, where each node is either a summation, a multiplication, or the application of one of the $q$ basis functions to one of the $p$ covariates. We show that in order to recover a labeled binary tree from a given dataset, the sufficient number of samples is $O(k\log(pq)+\log(k!))$, and the necessary number of samples is $\Omega(k\log (pq)-\log(k!))$. We implement our method for regression as a greedy search algorithm, and demonstrate its effectiveness with two synthetic data sets and one real-world experiment. version:1
arxiv-1704-01880 | A Convolution Tree with Deconvolution Branches: Exploiting Geometric Relationships for Single Shot Keypoint Detection | http://arxiv.org/abs/1704.01880 | id:1704.01880 author:Amit Kumar, Rama Chellappa category:cs.CV  published:2017-04-06 summary:Recently, Deep Convolution Networks (DCNNs) have been applied to the task of face alignment and have shown potential for learning improved feature representations. Although deeper layers can capture abstract concepts like pose, it is difficult to capture the geometric relationships among the keypoints in DCNNs. In this paper, we propose a novel convolution-deconvolution network for facial keypoint detection. Our model predicts the 2D locations of the keypoints and their individual visibility along with 3D head pose, while exploiting the spatial relationships among different keypoints. Different from existing approaches of modeling these relationships, we propose learnable transform functions which captures the relationships between keypoints at feature level. However, due to extensive variations in pose, not all of these relationships act at once, and hence we propose, a pose-based routing function which implicitly models the active relationships. Both transform functions and the routing function are implemented through convolutions in a multi-task framework. Our approach presents a single-shot keypoint detection method, making it different from many existing cascade regression-based methods. We also show that learning these relationships significantly improve the accuracy of keypoint detections for in-the-wild face images from challenging datasets such as AFW and AFLW. version:1
arxiv-1704-01871 | Massive Data Clustering in Moderate Dimensions from the Dual Spaces of Observation and Attribute Data Clouds | http://arxiv.org/abs/1704.01871 | id:1704.01871 author:Fionn Murtagh category:stat.ML 62H30  91C20 H.3.3; I.5.3  published:2017-04-06 summary:Cluster analysis of very high dimensional data can benefit from the properties of such high dimensionality. Informally expressed, in this work, our focus is on the analogous situation when the dimensionality is moderate to small, relative to a massively sized set of observations. Mathematically expressed, these are the dual spaces of observations and attributes. The point cloud of observations is in attribute space, and the point cloud of attributes is in observation space. In this paper, we begin by summarizing various perspectives related to methodologies that are used in multivariate analytics. We draw on these to establish an efficient clustering processing pipeline, both partitioning and hierarchical clustering. version:1
arxiv-1704-01864 | Robust Causal Estimation in the Large-Sample Limit without Strict Faithfulness | http://arxiv.org/abs/1704.01864 | id:1704.01864 author:Ioan Gabriel Bucur, Tom Claassen, Tom Heskes category:stat.ML cs.AI stat.ME  published:2017-04-06 summary:Causal effect estimation from observational data is an important and much studied research topic. The instrumental variable (IV) and local causal discovery (LCD) patterns are canonical examples of settings where a closed-form expression exists for the causal effect of one variable on another, given the presence of a third variable. Both rely on faithfulness to infer that the latter only influences the target effect via the cause variable. In reality, it is likely that this assumption only holds approximately and that there will be at least some form of weak interaction. This brings about the paradoxical situation that, in the large-sample limit, no predictions are made, as detecting the weak edge invalidates the setting. We introduce an alternative approach by replacing strict faithfulness with a prior that reflects the existence of many 'weak' (irrelevant) and 'strong' interactions. We obtain a posterior distribution over the target causal effect estimator which shows that, in many cases, we can still make good estimates. We demonstrate the approach in an application on a simple linear-Gaussian setting, using the MultiNest sampling algorithm, and compare it with established techniques to show our method is robust even when strict faithfulness is violated. version:1
arxiv-1704-01859 | Tackling Dynamic Vehicle Routing Problem with Time Windows by means of Ant Colony System | http://arxiv.org/abs/1704.01859 | id:1704.01859 author:Raluca Necula, Mihaela Breaban, Madalina Raschip category:cs.NE cs.AI  published:2017-04-06 summary:The Dynamic Vehicle Routing Problem with Time Windows (DVRPTW) is an extension of the well-known Vehicle Routing Problem (VRP), which takes into account the dynamic nature of the problem. This aspect requires the vehicle routes to be updated in an ongoing manner as new customer requests arrive in the system and must be incorporated into an evolving schedule during the working day. Besides the vehicle capacity constraint involved in the classical VRP, DVRPTW considers in addition time windows, which are able to better capture real-world situations. Despite this, so far, few studies have focused on tackling this problem of greater practical importance. To this end, this study devises for the resolution of DVRPTW, an ant colony optimization based algorithm, which resorts to a joint solution construction mechanism, able to construct in parallel the vehicle routes. This method is coupled with a local search procedure, aimed to further improve the solutions built by ants, and with an insertion heuristics, which tries to reduce the number of vehicles used to service the available customers. The experiments indicate that the proposed algorithm is competitive and effective, and on DVRPTW instances with a higher dynamicity level, it is able to yield better results compared to existing ant-based approaches. version:1
arxiv-1704-01858 | An Online Hierarchical Algorithm for Extreme Clustering | http://arxiv.org/abs/1704.01858 | id:1704.01858 author:Ari Kobren, Nicholas Monath, Akshay Krishnamurthy, Andrew McCallum category:cs.LG stat.ML  published:2017-04-06 summary:Many modern clustering methods scale well to a large number of data items, N, but not to a large number of clusters, K. This paper introduces PERCH, a new non-greedy algorithm for online hierarchical clustering that scales to both massive N and K--a problem setting we term extreme clustering. Our algorithm efficiently routes new data points to the leaves of an incrementally-built tree. Motivated by the desire for both accuracy and speed, our approach performs tree rotations for the sake of enhancing subtree purity and encouraging balancedness. We prove that, under a natural separability assumption, our non-greedy algorithm will produce trees with perfect dendrogram purity regardless of online data arrival order. Our experiments demonstrate that PERCH constructs more accurate trees than other tree-building clustering algorithms and scales well with both N and K, achieving a higher quality clustering than the strongest flat clustering competitor in nearly half the time. version:1
arxiv-1703-08653 | Bayesian Optimization for Refining Object Proposals | http://arxiv.org/abs/1703.08653 | id:1703.08653 author:Anthony D. Rhodes, Jordan Witte, Melanie Mitchell, Bruno Jedynak category:cs.CV  published:2017-03-25 summary:We develop a general-purpose algorithm using a Bayesian optimization framework for the efficient refinement of object proposals. While recent research has achieved substantial progress for object localization and related objectives in computer vision, current state-of-the-art object localization procedures are nevertheless encumbered by inefficiency and inaccuracy. We present a novel, computationally efficient method for refining inaccurate bounding-box proposals for a target object using Bayesian optimization. Offline, image features from a convolutional neural network are used to train a model to predict the offset distance of an object proposal from a target object. Online, this model is used in a Bayesian active search to improve inaccurate object proposals. In experiments, we compare our approach to a state-of-the-art bounding-box regression method for localization refinement of pedestrian object proposals. Our method exhibits a substantial improvement for the task of localization refinement over this baseline regression method. version:2
arxiv-1704-01815 | Incremental Transductive Learning Approaches to Schistosomiasis Vector Classification | http://arxiv.org/abs/1704.01815 | id:1704.01815 author:Terence Fusco, Yaxin Bi, Haiying Wang, Fiona Browne category:cs.LG  published:2017-04-06 summary:The key issues pertaining to collection of epidemic disease data for our analysis purposes are that it is a labour intensive, time consuming and expensive process resulting in availability of sparse sample data which we use to develop prediction models. To address this sparse data issue, we present novel Incremental Transductive methods to circumvent the data collection process by applying previously acquired data to provide consistent, confidence-based labelling alternatives to field survey research. We investigated various reasoning approaches for semisupervised machine learning including Bayesian models for labelling data. The results show that using the proposed methods, we can label instances of data with a class of vector density at a high level of confidence. By applying the Liberal and Strict Training Approaches, we provide a labelling and classification alternative to standalone algorithms. The methods in this paper are components in the process of reducing the proliferation of the Schistosomiasis disease and its effects. version:1
arxiv-1704-01811 | Higher-Order Minimum Cost Lifted Multicuts for Motion Segmentation | http://arxiv.org/abs/1704.01811 | id:1704.01811 author:Margret Keuper category:cs.CV  published:2017-04-06 summary:Most state-of-the-art motion segmentation algorithms draw their potential from modeling motion differences of local entities such as point trajectories in terms of pairwise potentials in graphical models. Inference in instances of minimum cost multicut problems defined on such graphs al- lows to optimize the number of the resulting segments along with the segment assignment. However, pairwise potentials limit the discriminative power of the employed motion models to translational differences. More complex models such as Euclidean or affine transformations call for higher-order potentials and a tractable inference in the resulting higher-order graphical models. In this paper, we (1) introduce a generalization of the minimum cost lifted multicut problem to hypergraphs, and (2) propose a simple primal feasible heuristic that allows for a reasonably efficient inference in instances of higher-order lifted multicut problem instances defined on point trajectory hypergraphs for motion segmentation. The resulting motion segmentations improve over the state-of-the-art on the FBMS-59 dataset. version:1
arxiv-1704-01770 | Enabling Smart Data: Noise filtering in Big Data classification | http://arxiv.org/abs/1704.01770 | id:1704.01770 author:Diego García-Gil, Julián Luengo, Salvador García, Francisco Herrera category:cs.DB cs.LG  published:2017-04-06 summary:In any knowledge discovery process the value of extracted knowledge is directly related to the quality of the data used. Big Data problems, generated by massive growth in the scale of data observed in recent years, also follow the same dictate. A common problem affecting data quality is the presence of noise, particularly in classification problems, where label noise refers to the incorrect labeling of training instances, and is known to be a very disruptive feature of data. However, in this Big Data era, the massive growth in the scale of the data poses a challenge to traditional proposals created to tackle noise, as they have difficulties coping with such a large amount of data. New algorithms need to be proposed to treat the noise in Big Data problems, providing high quality and clean data, also known as Smart Data. In this paper, two Big Data preprocessing approaches to remove noisy examples are proposed: an homogeneous ensemble and an heterogeneous ensemble filter, with special emphasis in their scalability and performance traits. The obtained results show that these proposals enable the practitioner to efficiently obtain a Smart Dataset from any Big Data classification problem. version:1
arxiv-1704-01444 | Learning to Generate Reviews and Discovering Sentiment | http://arxiv.org/abs/1704.01444 | id:1704.01444 author:Alec Radford, Rafal Jozefowicz, Ilya Sutskever category:cs.LG cs.CL cs.NE  published:2017-04-05 summary:We explore the properties of byte-level recurrent language models. When given sufficient amounts of capacity, training data, and compute time, the representations learned by these models include disentangled features corresponding to high-level concepts. Specifically, we find a single unit which performs sentiment analysis. These representations, learned in an unsupervised manner, achieve state of the art on the binary subset of the Stanford Sentiment Treebank. They are also very data efficient. When using only a handful of labeled examples, our approach matches the performance of strong baselines trained on full datasets. We also demonstrate the sentiment unit has a direct influence on the generative process of the model. Simply fixing its value to be positive or negative generates samples with the corresponding positive or negative sentiment. version:2
arxiv-1704-02373 | Time-Contrastive Learning Based Unsupervised DNN Feature Extraction for Speaker Verification | http://arxiv.org/abs/1704.02373 | id:1704.02373 author:Achintya Kr. Sarkar, Zheng-Hua Tan category:cs.SD cs.LG  published:2017-04-06 summary:In this paper, we present a time-contrastive learning (TCL)based unsupervised bottleneck (BN) feature extraction method for speech signals with an application to speaker verification. The method exploits the temporal structure of a speech signal and more specifically, it trains deep neural networks (DNNs) to discriminate temporal events obtained by uniformly segmenting the signal without using any label information, in contrast to conventional DNN based BN feature extraction methods that train DNNs using labeled data to discriminate speakers or passphrases or phones or a combination of them. We consider different strategies for TCL and its combination with transfer learning. Experimental results on the RSR2015 database show that the TCL method is superior to the conventional speaker and pass-phrase discriminant BN feature and Mel-frequency cepstral coefficients (MFCCs) feature for text-dependent speaker verification. The unsupervised TCL method further has the advantage of being able to leverage the huge amount of unlabeled data that are often available in real life. version:1
arxiv-1704-01754 | Enhance Feature Discrimination for Unsupervised Hashing | http://arxiv.org/abs/1704.01754 | id:1704.01754 author:Tuan Hoang, Thanh-Toan Do, Dang-Khoa Le Tan, Ngai-Man Cheung category:cs.CV cs.IR  published:2017-04-06 summary:We propose a novel approach to improve unsupervised hashing. Specifically, we propose an embedding method to enhance the discriminative property of features before passing them into hashing. We propose a very efficient embedding method: Gaussian Mixture Model embedding (Gemb). Gemb embeds feature vector into a low-dimensional vector using Gaussian Mixture Model. Our experiment shows that the proposed method boosts the hashing performance of many state-of-the-art, e.g. Binary Autoencoder (BA), Iterative Quantization (ITQ), in standard evaluation metrics for the three main benchmark datasets. version:1
arxiv-1704-01745 | How to Make an Image More Memorable? A Deep Style Transfer Approach | http://arxiv.org/abs/1704.01745 | id:1704.01745 author:Aliaksandr Siarohin, Gloria Zen, Cveta Majtanovic, Xavier Alameda-Pineda, Elisa Ricci, Nicu Sebe category:cs.CV  published:2017-04-06 summary:Recent works have shown that it is possible to automatically predict intrinsic image properties like memorability. In this paper, we take a step forward addressing the question: "Can we make an image more memorable?". Methods for automatically increasing image memorability would have an impact in many application fields like education, gaming or advertising. Our work is inspired by the popular editing-by-applying-filters paradigm adopted in photo editing applications, like Instagram and Prisma. In this context, the problem of increasing image memorability maps to that of retrieving "memorabilizing" filters or style "seeds". Still, users generally have to go through most of the available filters before finding the desired solution, thus turning the editing process into a resource and time consuming task. In this work, we show that it is possible to automatically retrieve the best style seeds for a given image, thus remarkably reducing the number of human attempts needed to find a good match. Our approach leverages from recent advances in the field of image synthesis and adopts a deep architecture for generating a memorable picture from a given input image and a style seed. Importantly, to automatically select the best style a novel learning-based solution, also relying on deep models, is proposed. Our experimental evaluation, conducted on publicly available benchmarks, demonstrates the effectiveness of the proposed approach for generating memorable images through automatic style seed selection version:1
arxiv-1704-01740 | Object-Part Attention Driven Discriminative Localization for Fine-grained Image Classification | http://arxiv.org/abs/1704.01740 | id:1704.01740 author:Yuxin Peng, Xiangteng He, Junjie Zhao category:cs.CV  published:2017-04-06 summary:Fine-grained image classification is to recognize hundreds of subcategories belonging to the same basic-level category, such as 200 subcategories belonging to bird, and highly challenging due to large variance in same subcategory and small variance among different subcategories. Existing methods generally find where the object or its parts are and then discriminate which subcategory the image belongs to. However, they mainly have two limitations: (1) Relying on object or parts annotations which are heavily labor consuming. (2) Ignoring the spatial relationship between the object and its parts as well as among these parts, both of which are significantly helpful for finding discriminative parts. Therefore, this paper proposes the object-part attention driven discriminative localization (OPADDL) approach for weakly supervised fine-grained image classification, and the main novelties are: (1) Object-part attention model integrates two level attentions: object-level attention localizes objects of images, and part-level attention selects discriminative parts of object. Both are jointly employed to learn multi-view and multi-scale features to enhance their mutual promotion. (2) Object-part spatial model combines two spatial constraints: object spatial constraint ensures selected parts highly representative, and part spatial constraint eliminates redundancy and enhances discrimination of selected parts. Both are jointly employed to exploit the subtle and local differences for distinguishing the subcategories. Importantly, neither objects nor parts annotations are used, which avoids the heavy labor consuming of labeling. Comparing with more than 10 state-of-the-art methods on 3 widely used datasets, our OPADDL approach achieves the best performance. version:1
arxiv-1701-02302 | A Homological Theory of Functions | http://arxiv.org/abs/1701.02302 | id:1701.02302 author:Greg Yang category:math.AC cs.CC cs.DM cs.LG math.CO F.1.3; I.2.6; G.1.6  published:2017-01-09 summary:In computational complexity, a complexity class is given by a set of problems or functions, and a basic challenge is to show separations of complexity classes $A \not= B$ especially when $A$ is known to be a subset of $B$. In this paper we introduce a homological theory of functions that can be used to establish complexity separations, while also providing other interesting consequences. We propose to associate a topological space $S_A$ to each class of functions $A$, such that, to separate complexity classes $A \subseteq B'$, it suffices to observe a change in "the number of holes", i.e. homology, in $S_A$ as a subclass $B$ of $B'$ is added to $A$. In other words, if the homologies of $S_A$ and $S_{A \cup B}$ are different, then $A \not= B'$. We develop the underlying theory of functions based on combinatorial and homological commutative algebra and Stanley-Reisner theory, and recover Minsky and Papert's 1969 result that parity cannot be computed by nonmaximal degree polynomial threshold functions. In the process, we derive a "maximal principle" for polynomial threshold functions that is used to extend this result further to arbitrary symmetric functions. A surprising coincidence is demonstrated, where the maximal dimension of "holes" in $S_A$ upper bounds the VC dimension of $A$, with equality for common computational cases such as the class of polynomial threshold functions or the class of linear functionals in $\mathbb F_2$, or common algebraic cases such as when the Stanley-Reisner ring of $S_A$ is Cohen-Macaulay. As another interesting application of our theory, we prove a result that a priori has nothing to do with complexity separation: it characterizes when a vector subspace intersects the positive cone, in terms of homological conditions. By analogy to Farkas' result doing the same with *linear conditions*, we call our theorem the Homological Farkas Lemma. version:3
arxiv-1704-01420 | OEC: Open-Ended Classification for Future-Proof Link-Fraud Detection | http://arxiv.org/abs/1704.01420 | id:1704.01420 author:Neil Shah, Hemank Lamba, Alex Beutel, Christos Faloutsos category:cs.SI cs.LG  published:2017-04-05 summary:When tasked to find fraudulent social network users, what is a practitioner to do? Traditional classification can lead to poor generalization and high misclassification given few and possibly biased labels. We tackle this problem by analyzing fraudulent behavioral patterns, featurizing users to yield strong discriminative performance, and building algorithms to handle new and multimodal fraud types. First, we set up honeypots, or "dummy" social network accounts on which we solicit fake followers (after careful IRB approval). We report the signs of such behaviors, including oddities in local network connectivity, account attributes, and similarities and differences across fraud providers. We discover several types of fraud behaviors, with the possibility of even more. We discuss how to leverage these insights in practice, build strongly performing entropy-based features, and propose OEC (Open-ended Classification), an approach for "future-proofing" existing algorithms to account for the complexities of link fraud. Our contributions are (a) observations: we analyze our honeypot fraudster ecosystem and give insights regarding various fraud behaviors, (b) features: we engineer features which give exceptionally strong (>0.95 precision/recall) discriminative power on ground-truth data, and (c) algorithm: we motivate and discuss OEC, which reduces misclassification rate by >18% over baselines and routes practitioner attention to samples at high-risk of misclassification. version:2
arxiv-1704-01719 | Beyond triplet loss: a deep quadruplet network for person re-identification | http://arxiv.org/abs/1704.01719 | id:1704.01719 author:Weihua Chen, Xiaotang Chen, Jianguo Zhang, Kaiqi Huang category:cs.CV  published:2017-04-06 summary:Person re-identification (ReID) is an important task in wide area video surveillance which focuses on identifying people across different cameras. Recently, deep learning networks with a triplet loss become a common framework for person ReID. However, the triplet loss pays main attentions on obtaining correct orders on the training set. It still suffers from a weaker generalization capability from the training set to the testing set, thus resulting in inferior performance. In this paper, we design a quadruplet loss, which can lead to the model output with a larger inter-class variation and a smaller intra-class variation compared to the triplet loss. As a result, our model has a better generalization ability and can achieve a higher performance on the testing set. In particular, a quadruplet deep network using a margin-based online hard negative mining is proposed based on the quadruplet loss for the person ReID. In extensive experiments, the proposed network outperforms most of the state-of-the-art algorithms on representative datasets which clearly demonstrates the effectiveness of our proposed method. version:1
arxiv-1704-01716 | Action Representation Using Classifier Decision Boundaries | http://arxiv.org/abs/1704.01716 | id:1704.01716 author:Jue Wang, Anoop Cherian, Fatih Porikli, Stephen Gould category:cs.CV  published:2017-04-06 summary:Most popular deep learning based models for action recognition are designed to generate separate predictions within their short temporal windows, which are often aggregated by heuristic means to assign an action label to the full video segment. Given that not all frames from a video characterize the underlying action, pooling schemes that impose equal importance to all frames might be unfavorable. In an attempt towards tackling this challenge, we propose a novel pooling scheme, dubbed SVM pooling, based on the notion that among the bag of features generated by a CNN on all temporal windows, there is at least one feature that characterizes the action. To this end, we learn a decision hyperplane that separates this unknown yet useful feature from the rest. Applying multiple instance learning in an SVM setup, we use the parameters of this separating hyperplane as a descriptor for the video. Since these parameters are directly related to the support vectors in a max-margin framework, they serve as robust representations for pooling of the CNN features. We devise a joint optimization objective and an efficient solver that learns these hyperplanes per video and the corresponding action classifiers over the hyperplanes. Showcased experiments on the standard HMDB and UCF101 datasets demonstrate state-of-the-art performance. version:1
arxiv-1704-02232 | Rapid Mixing Swendsen-Wang Sampler for Stochastic Partitioned Attractive Models | http://arxiv.org/abs/1704.02232 | id:1704.02232 author:Sejun Park, Yunhun Jang, Andreas Galanis, Jinwoo Shin, Daniel Stefankovic, Eric Vigoda category:cs.LG stat.ML  published:2017-04-06 summary:The Gibbs sampler is a particularly popular Markov chain used for learning and inference problems in Graphical Models (GMs). These tasks are computationally intractable in general, and the Gibbs sampler often suffers from slow mixing. In this paper, we study the Swendsen-Wang dynamics which is a more sophisticated Markov chain designed to overcome bottlenecks that impede the Gibbs sampler. We prove O(\log n) mixing time for attractive binary pairwise GMs (i.e., ferromagnetic Ising models) on stochastic partitioned graphs having n vertices, under some mild conditions, including low temperature regions where the Gibbs sampler provably mixes exponentially slow. Our experiments also confirm that the Swendsen-Wang sampler significantly outperforms the Gibbs sampler when they are used for learning parameters of attractive GMs. version:1
arxiv-1704-01705 | Generate To Adapt: Aligning Domains using Generative Adversarial Networks | http://arxiv.org/abs/1704.01705 | id:1704.01705 author:Swami Sankaranarayanan, Yogesh Balaji, Carlos D. Castillo, Rama Chellappa category:cs.CV  published:2017-04-06 summary:Visual Domain adaptation is an actively researched problem in Computer Vision. In this work, we propose an approach that leverages unsupervised data to bring the source and target distributions closer in a learned joint feature space. We accomplish this by inducing a symbiotic relationship between the learned embedding and a generative adversarial framework. This is in contrast to methods which use an adversarial framework for realistic data generation and retraining deep models with such data. We show the strength and generality of our method by performing experiments on three different tasks: (1) Digit classification (MNIST, SVHN and USPS datasets) (2) Object recognition using OFFICE dataset and (3) Face recognition using the Celebrity Frontal Profile (CFP) dataset. version:1
arxiv-1704-01704 | Adequacy of the Gradient-Descent Method for Classifier Evasion Attacks | http://arxiv.org/abs/1704.01704 | id:1704.01704 author:Yi Han, Benjamin I. P. Rubinstein category:cs.CR cs.LG stat.ML  published:2017-04-06 summary:Despite the wide use of machine learning in adversarial settings including computer security, recent studies have demonstrated vulnerabilities to evasion attacks---carefully crafted adversarial samples that closely resemble legitimate instances, but cause misclassification. In this paper, (1) we analyse the effectiveness of the gradient-descent method---the leading approach for generating adversarial samples---against non-linear support vector machines, and conclude that carefully reduced kernel smoothness can significantly increase robustness to the attack; (2) we propose a quantity similar to margin that can efficiently predict potential susceptibility to gradient-descent attack, before the attack is launched; and (3) we design a new adversarial sample construction algorithm based on optimising the multiplicative ratio of class decision functions. Our results demonstrate that the new method not only increases the attack's success rate, but also achieves success with less perturbation. version:1
arxiv-1704-01701 | Learning Certifiably Optimal Rule Lists for Categorical Data | http://arxiv.org/abs/1704.01701 | id:1704.01701 author:Elaine Angelino, Nicholas Larus-Stone, Daniel Alabi, Margo Seltzer, Cynthia Rudin category:stat.ML cs.LG  published:2017-04-06 summary:We present the design and implementation of a custom discrete optimization technique for building rule lists over a categorical feature space. Our algorithm provides the optimal solution, with a certificate of optimality. By leveraging algorithmic bounds, efficient data structures, and computational reuse, we achieve several orders of magnitude speedup in time and a massive reduction of memory consumption. We demonstrate that our approach produces optimal rule lists on practical problems in seconds. This framework is a novel alternative to CART and other decision tree methods. version:1
arxiv-1704-01696 | A Syntactic Neural Model for General-Purpose Code Generation | http://arxiv.org/abs/1704.01696 | id:1704.01696 author:Pengcheng Yin, Graham Neubig category:cs.CL cs.PL cs.SE  published:2017-04-06 summary:We consider the problem of parsing natural language descriptions into source code written in a general-purpose programming language like Python. Existing data-driven methods treat this problem as a language generation task without considering the underlying syntax of the target programming language. Informed by previous work in semantic parsing, in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge. Experiments find this an effective way to scale up to generation of complex programs from natural language descriptions, achieving state-of-the-art results that well outperform previous code generation and semantic parsing approaches. version:1
arxiv-1704-01691 | Multi-space Variational Encoder-Decoders for Semi-supervised Labeled Sequence Transduction | http://arxiv.org/abs/1704.01691 | id:1704.01691 author:Chunting Zhou, Graham Neubig category:cs.CL cs.LG  published:2017-04-06 summary:Labeled sequence transduction is a task of transforming one sequence into another sequence that satisfies desiderata specified by a set of labels. In this paper we propose multi-space variational encoder-decoders, a new model for labeled sequence transduction with semi-supervised learning. The generative model can use neural networks to handle both discrete and continuous latent variables to exploit various features of data. Experiments show that our model provides not only a powerful supervised framework but also can effectively take advantage of the unlabeled data. On the SIGMORPHON morphological inflection benchmark, our model outperforms single-model state-of-art results by a large margin for the majority of languages. version:1
arxiv-1704-01665 | Learning Combinatorial Optimization Algorithms over Graphs | http://arxiv.org/abs/1704.01665 | id:1704.01665 author:Hanjun Dai, Elias B. Khalil, Yuyu Zhang, Bistra Dilkina, Le Song category:cs.LG stat.ML  published:2017-04-05 summary:Many combinatorial optimization problems over graphs are NP-hard, and require significant specialized knowledge and trial-and-error to design good heuristics or approximation algorithms. Can we automate this challenging and tedious process, and learn the algorithms instead? In many real world applications, it is typically the case that the same type of optimization problem is solved again and again on a regular basis, maintaining the same problem structure but differing in the data. This provides an opportunity for learning heuristic algorithms which can exploit the structure of such recurring problems. In this paper, we propose a unique combination of reinforcement learning and graph embedding to address this challenge. The learned greedy policy behaves like a meta-algorithm which incrementally constructs a solution, and the action is determined by the output of a graph embedding network capturing the current state of the solution. We show that our framework can be applied to a diverse range of optimization problems over graphs, and provide evidence that our learning approach can compete with or outperform specialized heuristics or approximation algorithms for the Minimum Vertex Cover, Maximum Cut and Traveling Salesman Problems. version:1
arxiv-1704-01664 | The Relative Performance of Ensemble Methods with Deep Convolutional Neural Networks for Image Classification | http://arxiv.org/abs/1704.01664 | id:1704.01664 author:Cheng Ju, Aurélien Bibaut, Mark J. van der Laan category:stat.ML cs.CV cs.LG stat.ME  published:2017-04-05 summary:Artificial neural networks have been successfully applied to a variety of machine learning tasks, including image recognition, semantic segmentation, and machine translation. However, few studies fully investigated ensembles of artificial neural networks. In this work, we investigated multiple widely used ensemble methods, including unweighted averaging, majority voting, the Bayes Optimal Classifier, and the (discrete) Super Learner, for image recognition tasks, with deep neural networks as candidate algorithms. We designed several experiments, with the candidate algorithms being the same network structure with different model checkpoints within a single training process, networks with same structure but trained multiple times stochastically, and networks with different structure. In addition, we further studied the over-confidence phenomenon of the neural networks, as well as its impact on the ensemble methods. Across all of our experiments, the Super Learner achieved best performance among all the ensemble methods in this study. version:1
arxiv-1704-01653 | Automatic Measurement of Pre-aspiration | http://arxiv.org/abs/1704.01653 | id:1704.01653 author:Yaniv Sheena, Míša Hejná, Yossi Adi, Joseph Keshet category:cs.CL  published:2017-04-05 summary:Pre-aspiration is defined as the period of glottal friction occurring in sequences of vocalic/consonantal sonorants and phonetically voiceless obstruents. In this paper, we propose two machine learning methods for automatic measurement of pre-aspiration duration: feedforward neural network, which works at the frame level; and structured prediction model, which relies on manually designed feature functions, and works at the segment level. The input for both algorithms is a speech signal of an arbitrary length containing a single obstruent, and the output is a pair of times which constitutes the pre-aspiration boundaries. We train both models on a set of manually annotated examples. Results suggest that the structured model is superior to the frame-based model as it yields higher accuracy in predicting the boundaries and generalizes to new speakers and new languages. Finally, we demonstrate the applicability of our structured prediction algorithm by replicating linguistic analysis of pre-aspiration in Aberystwyth English with high correlation. version:1
arxiv-1704-01652 | Greed is Good: Near-Optimal Submodular Maximization via Greedy Optimization | http://arxiv.org/abs/1704.01652 | id:1704.01652 author:Moran Feldman, Christopher Harshaw, Amin Karbasi category:cs.LG cs.DS  published:2017-04-05 summary:It is known that greedy methods perform well for maximizing monotone submodular functions. At the same time, such methods perform poorly in the face of non-monotonicity. In this paper, we show - arguably, surprisingly - that invoking the classical greedy algorithm $O(\sqrt{k})$-times leads to the (currently) fastest deterministic algorithm, called Repeated Greedy, for maximizing a general submodular function subject to $k$-independent system constraints. Repeated Greedy achieves $(1 + O(1/\sqrt{k}))k$ approximation using $O(nr\sqrt{k})$ function evaluations (here, $n$ and $r$ denote the size of the ground set and the maximum size of a feasible solution, respectively). We then show that by a careful sampling procedure, we can run the greedy algorithm only once and obtain the (currently) fastest randomized algorithm, called Sample Greedy, for maximizing a submodular function subject to $k$-extendible system constraints (a subclass of $k$-independent system constrains). Sample Greedy achieves $(k + 3)$-approximation with only $O(nr/k)$ function evaluations. Finally, we derive an almost matching lower bound, and show that no polynomial time algorithm can have an approximation ratio smaller than $ k + 1/2 - \varepsilon$. To further support our theoretical results, we compare the performance of Repeated Greedy and Sample Greedy with prior art in a concrete application (movie recommendation). We consistently observe that while Sample Greedy achieves practically the same utility as the best baseline, it performs at least two orders of magnitude faster. version:1
arxiv-1704-01605 | Nonnegative/binary matrix factorization with a D-Wave quantum annealer | http://arxiv.org/abs/1704.01605 | id:1704.01605 author:Daniel O'Malley, Velimir V. Vesselinov, Boian S. Alexandrov, Ludmil B. Alexandrov category:cs.LG quant-ph stat.ML  published:2017-04-05 summary:D-Wave quantum annealers represent a novel computational architecture and have attracted significant interest, but have been used for few real-world computations. Machine learning has been identified as an area where quantum annealing may be useful. Here, we show that the D-Wave 2X can be effectively used as part of an unsupervised machine learning method. This method can be used to analyze large datasets. The D-Wave only limits the number of features that can be extracted from the dataset. We apply this method to learn the features from a set of facial images. version:1
arxiv-1704-01599 | Rhetorical relations for information retrieval | http://arxiv.org/abs/1704.01599 | id:1704.01599 author:Christina Lioma, Birger Larsen, Wei Lu category:cs.IR cs.CL  published:2017-04-05 summary:Typically, every part in most coherent text has some plausible reason for its presence, some function that it performs to the overall semantics of the text. Rhetorical relations, e.g. contrast, cause, explanation, describe how the parts of a text are linked to each other. Knowledge about this socalled discourse structure has been applied successfully to several natural language processing tasks. This work studies the use of rhetorical relations for Information Retrieval (IR): Is there a correlation between certain rhetorical relations and retrieval performance? Can knowledge about a document's rhetorical relations be useful to IR? We present a language model modification that considers rhetorical relations when estimating the relevance of a document to a query. Empirical evaluation of different versions of our model on TREC settings shows that certain rhetorical relations can benefit retrieval effectiveness notably (> 10% in mean average precision over a state-of-the-art baseline). version:1
arxiv-1704-01568 | Best Practices for Applying Deep Learning to Novel Applications | http://arxiv.org/abs/1704.01568 | id:1704.01568 author:Leslie N. Smith category:cs.SE cs.AI cs.NE  published:2017-04-05 summary:This report is targeted to groups who are subject matter experts in their application but deep learning novices. It contains practical advice for those interested in testing the use of deep neural networks on applications that are novel for deep learning. We suggest making your project more manageable by dividing it into phases. For each phase this report contains numerous recommendations and insights to assist novice practitioners. version:1
arxiv-1704-01547 | Comment on "Biologically inspired protection of deep networks from adversarial attacks" | http://arxiv.org/abs/1704.01547 | id:1704.01547 author:Wieland Brendel, Matthias Bethge category:stat.ML cs.LG q-bio.NC  published:2017-04-05 summary:A recent paper suggests that Deep Neural Networks can be protected from gradient-based adversarial perturbations by driving the network activations into a highly saturated regime. Here we analyse such saturated networks and show that the attacks fail due to numerical limitations in the gradient computations. A simple stabilisation of the gradient estimates enables successful and efficient attacks. Thus, it has yet to be shown that the robustness observed in highly saturated networks is not simply due to numerical limitations. version:1
arxiv-1704-01523 | MIT at SemEval-2017 Task 10: Relation Extraction with Convolutional Neural Networks | http://arxiv.org/abs/1704.01523 | id:1704.01523 author:Ji Young Lee, Franck Dernoncourt, Peter Szolovits category:cs.CL cs.AI cs.NE stat.ML  published:2017-04-05 summary:Over 50 million scholarly articles have been published: they constitute a unique repository of knowledge. In particular, one may infer from them relations between scientific concepts, such as synonyms and hyponyms. Artificial neural networks have been recently explored for relation extraction. In this work, we continue this line of work and present a system based on a convolutional neural network to extract relations. Our model ranked first in the SemEval-2017 task 10 (ScienceIE) for relation extraction in scientific articles (subtask C). version:1
arxiv-1704-01518 | Generating Descriptions with Grounded and Co-Referenced People | http://arxiv.org/abs/1704.01518 | id:1704.01518 author:Anna Rohrbach, Marcus Rohrbach, Siyu Tang, Seong Joon Oh, Bernt Schiele category:cs.CV  published:2017-04-05 summary:Learning how to generate descriptions of images or videos received major interest both in the Computer Vision and Natural Language Processing communities. While a few works have proposed to learn a grounding during the generation process in an unsupervised way (via an attention mechanism), it remains unclear how good the quality of the grounding is and whether it benefits the description quality. In this work we propose a movie description model which learns to generate description and jointly ground (localize) the mentioned characters as well as do visual co-reference resolution between pairs of consecutive sentences/clips. We also propose to use weak localization supervision through character mentions provided in movie descriptions to learn the character grounding. At training time, we first learn how to localize characters by relating their visual appearance to mentions in the descriptions via a semi-supervised approach. We then provide this (noisy) supervision into our description model which greatly improves its performance. Our proposed description model improves over prior work w.r.t. generated description quality and additionally provides grounding and local co-reference resolution. We evaluate it on the MPII Movie Description dataset using automatic and human evaluation measures and using our newly collected grounding and co-reference data for characters. version:1
arxiv-1704-01510 | Isotropic reconstruction of 3D fluorescence microscopy images using convolutional neural networks | http://arxiv.org/abs/1704.01510 | id:1704.01510 author:Martin Weigert, Loic Royer, Florian Jug, Gene Myers category:cs.CV  published:2017-04-05 summary:Fluorescence microscopy images usually show severe anisotropy in axial versus lateral resolution. This hampers downstream processing, i.e. the automatic extraction of quantitative biological data. While deconvolution methods and other techniques to address this problem exist, they are either time consuming to apply or limited in their ability to remove anisotropy. We propose a method to recover isotropic resolution from readily acquired anisotropic data. We achieve this using a convolutional neural network that is trained end-to-end from the same anisotropic body of data we later apply the network to. The network effectively learns to restore the full isotropic resolution by restoring the image under a trained, sample specific image prior. We apply our method to $3$ synthetic and $3$ real datasets and show that our results improve on results from deconvolution and state-of-the-art super-resolution techniques. Finally, we demonstrate that a standard 3D segmentation pipeline performs on the output of our network with comparable accuracy as on the full isotropic data. version:1
arxiv-1704-01502 | Weakly Supervised Dense Video Captioning | http://arxiv.org/abs/1704.01502 | id:1704.01502 author:Zhiqiang Shen, Jianguo Li, Zhou Su, Minjun Li, Yurong Chen, Yu-Gang Jiang, Xiangyang Xue category:cs.CV  published:2017-04-05 summary:This paper focuses on a novel and challenging vision task, dense video captioning, which aims to automatically describe a video clip with multiple informative and diverse caption sentences. The proposed method is trained without explicit annotation of fine-grained sentence to video region-sequence correspondence, but is only based on weak video-level sentence annotations. It differs from existing video captioning systems in three technical aspects. First, we propose lexical fully convolutional neural networks (Lexical-FCN) with weakly supervised multi-instance multi-label learning to weakly link video regions with lexical labels. Second, we introduce a novel submodular maximization scheme to generate multiple informative and diverse region-sequences based on the Lexical-FCN outputs. A winner-takes-all scheme is adopted to weakly associate sentences to region-sequences in the training phase. Third, a sequence-to-sequence learning based language model is trained with the weakly supervised information obtained through the association process. We show that the proposed method can not only produce informative and diverse dense captions, but also outperform state-of-the-art single video captioning methods by a large margin. version:1
arxiv-1704-01460 | Comparison Based Nearest Neighbor Search | http://arxiv.org/abs/1704.01460 | id:1704.01460 author:Siavash Haghiri, Debarghya Ghoshdastidar, Ulrike von Luxburg category:stat.ML cs.DS cs.LG  published:2017-04-05 summary:We consider machine learning in a comparison-based setting where we are given a set of points in a metric space, but we have no access to the actual distances between the points. Instead, we can only ask an oracle whether the distance between two points $i$ and $j$ is smaller than the distance between the points $i$ and $k$. We are concerned with data structures and algorithms to find nearest neighbors based on such comparisons. We focus on a simple yet effective algorithm that recursively splits the space by first selecting two random pivot points and then assigning all other points to the closer of the two (comparison tree). We prove that if the metric space satisfies certain expansion conditions, then with high probability the height of the comparison tree is logarithmic in the number of points, leading to efficient search performance. We also provide an upper bound for the failure probability to return the true nearest neighbor. Experiments show that the comparison tree is competitive with algorithms that have access to the actual distance values, and needs less triplet comparisons than other competitors. version:1
arxiv-1704-01445 | Bayesian Inference of Log Determinants | http://arxiv.org/abs/1704.01445 | id:1704.01445 author:Jack Fitzsimons, Kurt Cutajar, Michael Osborne, Stephen Roberts, Maurizio Filippone category:stat.ML cs.NA stat.CO  published:2017-04-05 summary:The log-determinant of a kernel matrix appears in a variety of machine learning problems, ranging from determinantal point processes and generalized Markov random fields, through to the training of Gaussian processes. Exact calculation of this term is often intractable when the size of the kernel matrix exceeds a few thousand. In the spirit of probabilistic numerics, we reinterpret the problem of computing the log-determinant as a Bayesian inference problem. In particular, we combine prior knowledge in the form of bounds from matrix theory and evidence derived from stochastic trace estimation to obtain probabilistic estimates for the log-determinant and its associated uncertainty within a given computational budget. Beyond its novelty and theoretic appeal, the performance of our proposal is competitive with state-of-the-art approaches to approximating the log-determinant, while also quantifying the uncertainty due to budget-constrained evidence. version:1
arxiv-1704-01430 | Detecting confounding in multivariate linear models via spectral analysis | http://arxiv.org/abs/1704.01430 | id:1704.01430 author:Dominik Janzing, Bernhard Schoelkopf category:stat.ML  published:2017-04-05 summary:We study a model where one target variable Y is correlated with a vector X:=(X_1,...,X_d) of predictor variables being potential causes of Y. We describe a method that infers to what extent the statistical dependences between X and Y are due to the influence of X on Y and to what extent due to a hidden common cause (confounder) of X and Y. The method relies on concentration of measure results for large dimensions d and an independence assumption stating that, in the absence of confounding, the vector of regression coefficients describing the influence of each X on Y typically has `generic orientation' relative to the eigenspaces of the covariance matrix of X. For the special case of a scalar confounder we show that confounding typically spoils this generic orientation in a characteristic way that can be used to quantitatively estimate the amount of confounding. version:1
arxiv-1704-01429 | Non-Convex Weighted Lp Minimization based Group Sparse Representation Framework for Image Denoising | http://arxiv.org/abs/1704.01429 | id:1704.01429 author:Qiong Wang, Xinggan Zhang, Yu Wu, Yechao Bai, Lan Tang, Zhiyuan Zha category:cs.CV  published:2017-04-05 summary:Nonlocal image representation or group sparsity has attracted considerable interest in various low-level vision tasks and has led to several state-of-the-art image denoising techniques, such as BM3D, LSSC. In the past, convex optimization with sparsity-promoting convex regularization was usually regarded as a standard scheme for estimating sparse signals in noise. However, using convex regularization can not still obtain the correct sparsity solution under some practical problems including image inverse problems. In this paper we propose a non-convex weighted $\ell_p$ minimization based group sparse representation (GSR) framework for image denoising. To make the proposed scheme tractable and robust, the generalized soft-thresholding (GST) algorithm is adopted to solve the non-convex $\ell_p$ minimization problem. In addition, to improve the accuracy of the nonlocal similar patches selection, an adaptive patch search (APS) scheme is proposed. Experimental results have demonstrated that the proposed approach not only outperforms many state-of-the-art denoising methods such as BM3D and WNNM, but also results in a competitive speed. version:1
arxiv-1704-01426 | The UMCD Dataset | http://arxiv.org/abs/1704.01426 | id:1704.01426 author:Danilo Avola, Gian Luca Foresti, Niki Martinel, Daniele Pannone, Claudio Piciarelli category:cs.CV  published:2017-04-05 summary:In recent years, the technological improvements of low-cost small-scale Unmanned Aerial Vehicles (UAVs) are promoting an ever-increasing use of them in different tasks. In particular, the use of small-scale UAVs is useful in all these low-altitude tasks in which common UAVs cannot be adopted, such as recurrent comprehensive view of wide environments, frequent monitoring of military areas, real-time classification of static and moving entities (e.g., people, cars, etc.). These tasks can be supported by mosaicking and change detection algorithms achieved at low-altitude. Currently, public datasets for testing these algorithms are not available. This paper presents the UMCD dataset, the first collection of geo-referenced video sequences acquired at low-altitude for mosaicking and change detection purposes. Five reference scenarios are also reported. version:1
arxiv-1704-01419 | Linear Ensembles of Word Embedding Models | http://arxiv.org/abs/1704.01419 | id:1704.01419 author:Avo Muromägi, Kairit Sirts, Sven Laur category:cs.CL  published:2017-04-05 summary:This paper explores linear methods for combining several word embedding models into an ensemble. We construct the combined models using an iterative method based on either ordinary least squares regression or the solution to the orthogonal Procrustes problem. We evaluate the proposed approaches on Estonian---a morphologically complex language, for which the available corpora for training word embeddings are relatively small. We compare both combined models with each other and with the input word embedding models using synonym and analogy tests. The results show that while using the ordinary least squares regression performs poorly in our experiments, using orthogonal Procrustes to combine several word embedding models into an ensemble model leads to 7-10% relative improvements over the mean result of the initial models in synonym tests and 19-47% in analogy tests. version:1
arxiv-1704-01407 | Embodied Artificial Intelligence through Distributed Adaptive Control: An Integrated Framework | http://arxiv.org/abs/1704.01407 | id:1704.01407 author:Clément Moulin-Frier, Jordi-Ysard Puigbò, Xerxes D. Arsiwalla, Martì Sanchez-Fibla, Paul F. M. J. Verschure category:cs.AI cs.LG cs.MA  published:2017-04-05 summary:In this paper, we argue that the future of Artificial Intelligence research resides in two keywords: integration and embodiment. We support this claim by analyzing the recent advances of the field. Regarding integration, we note that the most impactful recent contributions have been made possible through the integration of recent Machine Learning methods (based in particular on Deep Learning and Recurrent Neural Networks) with more traditional ones (e.g. Monte-Carlo tree search, goal babbling exploration or addressable memory systems). Regarding embodiment, we note that the traditional benchmark tasks (e.g. visual classification or board games) are becoming obsolete as state-of-the-art learning algorithms approach or even surpass human performance in most of them, having recently encouraged the development of first-person 3D game platforms embedding realistic physics. Building upon this analysis, we first propose an embodied cognitive architecture integrating heterogenous sub-fields of Artificial Intelligence into a unified framework. We demonstrate the utility of our approach by showing how major contributions of the field can be expressed within the proposed framework. We then claim that benchmarking environments need to reproduce ecologically-valid conditions for bootstrapping the acquisition of increasingly complex cognitive skills through the concept of a cognitive arms race between embodied agents. version:1
arxiv-1704-01382 | On the construction of probabilistic Newton-type algorithms | http://arxiv.org/abs/1704.01382 | id:1704.01382 author:Adrian G. Wills, Thomas B. Schön category:stat.ML  published:2017-04-05 summary:It has recently been shown that many of the existing quasi-Newton algorithms can be formulated as learning algorithms, capable of learning local models of the cost functions. Importantly, this understanding allows us to safely start assembling probabilistic Newton-type algorithms, applicable in situations where we only have access to noisy observations of the cost function and its derivatives. This is where our interest lies. We make contributions to the use of the non-parametric and probabilistic Gaussian process models in solving these stochastic optimisation problems. Specifically, we present a new algorithm that unites these approximations together with recent probabilistic line search routines to deliver a probabilistic quasi-Newton approach. We also show that the probabilistic optimisation algorithms deliver promising results on challenging nonlinear system identification problems where the very nature of the problem is such that we can only access the cost function and its derivative via noisy observations, since there are no closed-form expressions available. version:1
arxiv-1703-10480 | A deep learning classification scheme based on augmented-enhanced features to segment organs at risk on the optic region in brain cancer patients | http://arxiv.org/abs/1703.10480 | id:1703.10480 author:Jose Dolz, Nicolas Reyns, Nacim Betrouni, Dris Kharroubi, Mathilde Quidet, Laurent Massoptier, Maximilien Vermandel category:cs.CV  published:2017-03-30 summary:Radiation therapy has emerged as one of the preferred techniques to treat brain cancer patients. During treatment, a very high dose of radiation is delivered to a very narrow area. Prescribed radiation therapy for brain cancer requires precisely defining the target treatment area, as well as delineating vital brain structures which must be spared from radiotoxicity. Nevertheless, delineation task is usually still manually performed, which is inefficient and operator-dependent. Several attempts of automatizing this process have reported. however, marginal results when analyzing organs in the optic region. In this work we present a deep learning classification scheme based on augmented-enhanced features to automatically segment organs at risk (OARs) in the optic region -optic nerves, optic chiasm, pituitary gland and pituitary stalk-. Fifteen MR images with various types of brain tumors were retrospectively collected to undergo manual and automatic segmentation. Mean Dice Similarity coefficients around 0.80 were reported. Incorporation of proposed features yielded to improvements on the segmentation. Compared with support vector machines, our method achieved better performance with less variation on the results, as well as a considerably reduction on the classification time. Performance of the proposed approach was also evaluated with respect to manual contours. In this case, results obtained from the automatic contours mostly lie on the variability of the observers, showing no significant differences with respect to them. These results suggest therefore that the proposed system is more accurate than other presented approaches, up to date, to segment these structures. The speed, reproducibility, and robustness of the process make the proposed deep learning-based classification system a valuable tool for assisting in the delineation task of small OARs in brain cancer. version:2
arxiv-1704-01372 | On the Relation between Color Image Denoising and Classification | http://arxiv.org/abs/1704.01372 | id:1704.01372 author:Jiqing Wu, Radu Timofte, Zhiwu Huang, Luc Van Gool category:cs.CV  published:2017-04-05 summary:Large amount of image denoising literature focuses on single channel images and often experimentally validates the proposed methods on tens of images at most. In this paper, we investigate the interaction between denoising and classification on large scale dataset. Inspired by classification models, we propose a novel deep learning architecture for color (multichannel) image denoising and report on thousands of images from ImageNet dataset as well as commonly used imagery. We study the importance of (sufficient) training data, how semantic class information can be traded for improved denoising results. As a result, our method greatly improves PSNR performance by 0.34 - 0.51 dB on average over state-of-the art methods on large scale dataset. We conclude that it is beneficial to incorporate in classification models. On the other hand, we also study how noise affect classification performance. In the end, we come to a number of interesting conclusions, some being counter-intuitive. version:1
arxiv-1704-01358 | Incremental Tube Construction for Human Action Detection | http://arxiv.org/abs/1704.01358 | id:1704.01358 author:Harkirat S. Behl, Michael Sapienza, Gurkirt Singh, Suman Saha, Fabio Cuzzolin, Philip H. S. Torr category:cs.CV  published:2017-04-05 summary:Current state-of-the-art action detection systems are tailored for offline batch-processing applications. However, for online applications like human-robot interaction, current systems fall short, either because they only detect one action per video, or because they assume that the entire video is available ahead of time. In this work, we introduce a real-time and online joint-labelling and association algorithm for action detection that can incrementally construct space-time action tubes on the most challenging action videos in which different action categories occur concurrently. In contrast to previous methods, we solve the detection-window association and action labelling problems jointly in a single pass. We demonstrate superior online association accuracy and speed (2.2ms per frame) as compared to the current state-of-the-art offline systems. We further demonstrate that the entire action detection pipeline can easily be made to work effectively in real-time using our action tube construction algorithm. version:1
arxiv-1704-01346 | CompiLIG at SemEval-2017 Task 1: Cross-Language Plagiarism Detection Methods for Semantic Textual Similarity | http://arxiv.org/abs/1704.01346 | id:1704.01346 author:Jeremy Ferrero, Frederic Agnes, Laurent Besacier, Didier Schwab category:cs.CL  published:2017-04-05 summary:We present our submitted systems for Semantic Textual Similarity (STS) Track 4 at SemEval-2017. Given a pair of Spanish-English sentences, each system must estimate their semantic similarity by a score between 0 and 5. In our submission, we use syntax-based, dictionary-based, context-based, and MT-based methods. We also combine these methods in unsupervised and supervised way. Our best run ranked 1st on track 4a with a correlation of 83.02% with human annotations. version:1
arxiv-1704-01344 | Not All Pixels Are Equal: Difficulty-aware Semantic Segmentation via Deep Layer Cascade | http://arxiv.org/abs/1704.01344 | id:1704.01344 author:Xiaoxiao Li, Ziwei Liu, Ping Luo, Chen Change Loy, Xiaoou Tang category:cs.CV cs.LG  published:2017-04-05 summary:We propose a novel deep layer cascade (LC) method to improve the accuracy and speed of semantic segmentation. Unlike the conventional model cascade (MC) that is composed of multiple independent models, LC treats a single deep model as a cascade of several sub-models. Earlier sub-models are trained to handle easy and confident regions, and they progressively feed-forward harder regions to the next sub-model for processing. Convolutions are only calculated on these regions to reduce computations. The proposed method possesses several advantages. First, LC classifies most of the easy regions in the shallow stage and makes deeper stage focuses on a few hard regions. Such an adaptive and 'difficulty-aware' learning improves segmentation performance. Second, LC accelerates both training and testing of deep network thanks to early decisions in the shallow stage. Third, in comparison to MC, LC is an end-to-end trainable framework, allowing joint learning of all sub-models. We evaluate our method on PASCAL VOC and Cityscapes datasets, achieving state-of-the-art performance and fast speed. version:1
arxiv-1704-01297 | Automated Diagnosis of Epilepsy Employing Multifractal Detrended Fluctuation Analysis Based Features | http://arxiv.org/abs/1704.01297 | id:1704.01297 author:S Pratiher, S Chatterjee, R Bose category:cs.CV nlin.AO nlin.CD q-bio.QM stat.OT 92B25 92F99  published:2017-04-05 summary:This contribution reports an application of MultiFractal Detrended Fluctuation Analysis, MFDFA based novel feature extraction technique for automated detection of epilepsy. In fractal geometry, Multifractal Detrended Fluctuation Analysis MFDFA is a popular technique to examine the self-similarity of a nonlinear, chaotic and noisy time series. In the present research work, EEG signals representing healthy, interictal (seizure free) and ictal activities (seizure) are acquired from an existing available database. The acquired EEG signals of different states are at first analyzed using MFDFA. To requisite the time series singularity quantification at local and global scales, a novel set of fourteen different features. Suitable feature ranking employing students t-test has been done to select the most statistically significant features which are henceforth being used as inputs to a support vector machines (SVM) classifier for the classification of different EEG signals. Eight different classification problems have been presented in this paper and it has been observed that the overall classification accuracy using MFDFA based features are reasonably satisfactory for all classification problems. The performance of the proposed method are also found to be quite commensurable and in some cases even better when compared with the results published in existing literature studied on the similar data set. version:1
arxiv-1703-09928 | Bundle Optimization for Multi-aspect Embedding | http://arxiv.org/abs/1703.09928 | id:1703.09928 author:Qiong Zeng, Wenzheng Chen, Zhuo Han, Mingyi Shi, Yanir Kleiman, Daniel Cohen-Or, Baoquan Chen, Yangyan Li category:cs.CV  published:2017-03-29 summary:Understanding semantic similarity among images is the core of a wide range of computer vision applications. An important step towards this goal is to collect and learn human perceptions. Interestingly, the semantic context of images is often ambiguous as images can be perceived with emphasis on different aspects, which may be contradictory to each other. In this paper, we present a method for learning the semantic similarity among images, inferring their latent aspects and embedding them into multi-spaces corresponding to their semantic aspects. We consider the multi-embedding problem as an optimization function that evaluates the embedded distances with respect to the qualitative clustering queries. The key idea of our approach is to collect and embed qualitative measures that share the same aspects in bundles. To ensure similarity aspect sharing among multiple measures, image classification queries are presented to, and solved by users. The collected image clusters are then converted into bundles of tuples, which are fed into our bundle optimization algorithm that jointly infers the aspect similarity and multi-aspect embedding. Extensive experimental results show that our approach significantly outperforms state-of-the-art multi-embedding approaches on various datasets, and scales well for large multi-aspect similarity measures. version:2
arxiv-1704-01285 | Smart Mining for Deep Metric Learning | http://arxiv.org/abs/1704.01285 | id:1704.01285 author:Vijay B G Kumar, Ben Harwood, Gustavo Carneiro, Ian Reid, Tom Drummond category:cs.CV  published:2017-04-05 summary:To solve deep metric learning problems and producing feature embeddings, current methodologies will commonly use a triplet model to minimise the relative distance between samples from the same class and maximise the relative distance between samples from different classes. Though successful, the training convergence of this triplet model can be compromised by the fact that the vast majority of the training samples will produce gradients with magnitudes that are close to zero. This issue has motivated the development of methods that explore the global structure of the embedding and other methods that explore hard negative/positive mining. The effectiveness of such mining methods is often associated with intractable computational requirements. In this paper, we propose a novel deep metric learning method that combines the triplet model and the global structure of the embedding space. We rely on a smart mining procedure that produces effective training samples for a low computational cost. In addition, we propose an adaptive controller that automatically adjusts the smart mining hyper-parameters and speeds up the convergence of the training process. We show empirically that our proposed method allows for fast and more accurate training of triplet ConvNets than other competing mining methods. Additionally, we show that our method achieves new state-of-the-art embedding results for CUB-200-2011 and Cars196 datasets. version:1
arxiv-1704-01280 | Revisiting the problem of audio-based hit song prediction using convolutional neural networks | http://arxiv.org/abs/1704.01280 | id:1704.01280 author:Li-Chia Yang, Szu-Yu Chou, Jen-Yu Liu, Yi-Hsuan Yang, Yi-An Chen category:cs.SD cs.LG stat.ML  published:2017-04-05 summary:Being able to predict whether a song can be a hit has impor- tant applications in the music industry. Although it is true that the popularity of a song can be greatly affected by exter- nal factors such as social and commercial influences, to which degree audio features computed from musical signals (whom we regard as internal factors) can predict song popularity is an interesting research question on its own. Motivated by the recent success of deep learning techniques, we attempt to ex- tend previous work on hit song prediction by jointly learning the audio features and prediction models using deep learning. Specifically, we experiment with a convolutional neural net- work model that takes the primitive mel-spectrogram as the input for feature learning, a more advanced JYnet model that uses an external song dataset for supervised pre-training and auto-tagging, and the combination of these two models. We also consider the inception model to characterize audio infor- mation in different scales. Our experiments suggest that deep structures are indeed more accurate than shallow structures in predicting the popularity of either Chinese or Western Pop songs in Taiwan. We also use the tags predicted by JYnet to gain insights into the result of different models. version:1
arxiv-1704-01279 | Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders | http://arxiv.org/abs/1704.01279 | id:1704.01279 author:Jesse Engel, Cinjon Resnick, Adam Roberts, Sander Dieleman, Douglas Eck, Karen Simonyan, Mohammad Norouzi category:cs.LG cs.AI cs.SD  published:2017-04-05 summary:Generative models in vision have seen rapid progress due to algorithmic improvements and the availability of high-quality image datasets. In this paper, we offer contributions in both these areas to enable similar progress in audio modeling. First, we detail a powerful new WaveNet-style autoencoder model that conditions an autoregressive decoder on temporal codes learned from the raw audio waveform. Second, we introduce NSynth, a large-scale and high-quality dataset of musical notes that is an order of magnitude larger than comparable public datasets. Using NSynth, we demonstrate improved qualitative and quantitative performance of the WaveNet autoencoder over a well-tuned spectral autoencoder baseline. Finally, we show that the model learns a manifold of embeddings that allows for morphing between instruments, meaningfully interpolating in timbre to create new types of sounds that are realistic and expressive. version:1
arxiv-1704-01266 | Supporting Navigation of Outdoor Shopping Complexes for Visually-impaired Users through Multi-modal Data Fusion | http://arxiv.org/abs/1704.01266 | id:1704.01266 author:Archana Paladugu, Parag S. Chandakkar, Peng Zhang, Baoxin Li category:cs.CV cs.CY cs.HC  published:2017-04-05 summary:Outdoor shopping complexes (OSC) are extremely difficult for people with visual impairment to navigate. Existing GPS devices are mostly designed for roadside navigation and seldom transition well into an OSC-like setting. We report our study on the challenges faced by a blind person in navigating OSC through developing a new mobile application named iExplore. We first report an exploratory study aiming at deriving specific design principles for building this system by learning the unique challenges of the problem. Then we present a methodology that can be used to derive the necessary information for the development of iExplore, followed by experimental validation of the technology by a group of visually impaired users in a local outdoor shopping center. User feedback and other experiments suggest that iExplore, while at its very initial phase, has the potential of filling a practical gap in existing assistive technologies for the visually impaired. version:1
arxiv-1704-01265 | Geometry of Factored Nuclear Norm Regularization | http://arxiv.org/abs/1704.01265 | id:1704.01265 author:Qiuwei Li, Zhihui Zhu, Gongguo Tang category:cs.NA cs.IT cs.LG math.IT math.OC  published:2017-04-05 summary:This work investigates the geometry of a nonconvex reformulation of minimizing a general convex loss function $f(X)$ regularized by the matrix nuclear norm $\ X\ _*$. Nuclear-norm regularized matrix inverse problems are at the heart of many applications in machine learning, signal processing, and control. The statistical performance of nuclear norm regularization has been studied extensively in literature using convex analysis techniques. Despite its optimal performance, the resulting optimization has high computational complexity when solved using standard or even tailored fast convex solvers. To develop faster and more scalable algorithms, we follow the proposal of Burer-Monteiro to factor the matrix variable $X$ into the product of two smaller rectangular matrices $X=UV^T$ and also replace the nuclear norm $\ X\ _*$ with $(\ U\ _F^2+\ V\ _F^2)/2$. In spite of the nonconvexity of the factored formulation, we prove that when the convex loss function $f(X)$ is $(2r,4r)$-restricted well-conditioned, each critical point of the factored problem either corresponds to the optimal solution $X^\star$ of the original convex optimization or is a strict saddle point where the Hessian matrix has a strictly negative eigenvalue. Such a geometric structure of the factored formulation allows many local search algorithms to converge to the global optimum with random initializations. version:1
arxiv-1704-01264 | Classification of Diabetic Retinopathy Images Using Multi-Class Multiple-Instance Learning Based on Color Correlogram Features | http://arxiv.org/abs/1704.01264 | id:1704.01264 author:Ragav Venkatesan, Parag S. Chandakkar, Baoxin Li category:cs.CV  published:2017-04-05 summary:All people with diabetes have the risk of developing diabetic retinopathy (DR), a vision-threatening complication. Early detection and timely treatment can reduce the occurrence of blindness due to DR. Computer-aided diagnosis has the potential benefit of improving the accuracy and speed in DR detection. This study is concerned with automatic classification of images with microaneurysm (MA) and neovascularization (NV), two important DR clinical findings. Together with normal images, this presents a 3-class classification problem. We propose a modified color auto-correlogram feature (AutoCC) with low dimensionality that is spectrally tuned towards DR images. Recognizing the fact that the images with or without MA or NV are generally different only in small, localized regions, we propose to employ a multi-class, multiple-instance learning framework for performing the classification task using the proposed feature. Extensive experiments including comparison with a few state-of-art image classification approaches have been performed and the results suggest that the proposed approach is promising as it outperforms other methods by a large margin. version:1
arxiv-1704-01262 | Investigating Human Factors in Image Forgery Detection | http://arxiv.org/abs/1704.01262 | id:1704.01262 author:Parag S. Chandakkar, Baoxin Li category:cs.CV  published:2017-04-05 summary:In today's age of internet and social media, one can find an enormous volume of forged images on-line. These images have been used in the past to convey falsified information and achieve harmful intentions. The spread and the effect of the social media only makes this problem more severe. While creating forged images has become easier due to software advancements, there is no automated algorithm which can reliably detect forgery. Image forgery detection can be seen as a subset of image understanding problem. Human performance is still the gold-standard for these type of problems when compared to existing state-of-art automated algorithms. We conduct a subjective evaluation test with the aid of eye-tracker to investigate into human factors associated with this problem. We compare the performance of an automated algorithm and humans for forgery detection problem. We also develop an algorithm which uses the data from the evaluation test to predict the difficulty-level of an image (the difficulty-level of an image here denotes how difficult it is for humans to detect forgery in an image. Terms such as "Easy/difficult image" will be used in the same context). The experimental results presented in this paper should facilitate development of better algorithms in the future. version:1
arxiv-1704-01256 | Improving Vision-based Self-positioning in Intelligent Transportation Systems via Integrated Lane and Vehicle Detection | http://arxiv.org/abs/1704.01256 | id:1704.01256 author:Parag S. Chandakkar, Yilin Wang, Baoxin Li category:cs.CV  published:2017-04-05 summary:Traffic congestion is a widespread problem. Dynamic traffic routing systems and congestion pricing are getting importance in recent research. Lane prediction and vehicle density estimation is an important component of such systems. We introduce a novel problem of vehicle self-positioning which involves predicting the number of lanes on the road and vehicle's position in those lanes using videos captured by a dashboard camera. We propose an integrated closed-loop approach where we use the presence of vehicles to aid the task of self-positioning and vice-versa. To incorporate multiple factors and high-level semantic knowledge into the solution, we formulate this problem as a Bayesian framework. In the framework, the number of lanes, the vehicle's position in those lanes and the presence of other vehicles are considered as parameters. We also propose a bounding box selection scheme to reduce the number of false detections and increase the computational efficiency. We show that the number of box proposals decreases by a factor of 6 using the selection approach. It also results in large reduction in the number of false detections. The entire approach is tested on real-world videos and is found to give acceptable results. version:1
arxiv-1704-01255 | Linear Additive Markov Processes | http://arxiv.org/abs/1704.01255 | id:1704.01255 author:Ravi Kumar, Maithra Raghu, Tamas Sarlos, Andrew Tomkins category:cs.LG stat.ML  published:2017-04-05 summary:We introduce LAMP: the Linear Additive Markov Process. Transitions in LAMP may be influenced by states visited in the distant history of the process, but unlike higher-order Markov processes, LAMP retains an efficient parametrization. LAMP also allows the specific dependence on history to be learned efficiently from data. We characterize some theoretical properties of LAMP, including its steady-state and mixing time. We then give an algorithm based on alternating minimization to learn LAMP models from data. Finally, we perform a series of real-world experiments to show that LAMP is more powerful than first-order Markov processes, and even holds its own against deep sequential models (LSTMs) with a negligible increase in parameter complexity. version:1
arxiv-1704-01250 | Relative Learning from Web Images for Content-adaptive Enhancement | http://arxiv.org/abs/1704.01250 | id:1704.01250 author:Parag S. Chandakkar, Qiongjie Tian, Baoxin Li category:cs.CV  published:2017-04-05 summary:Personalized and content-adaptive image enhancement can find many applications in the age of social media and mobile computing. This paper presents a relative-learning-based approach, which, unlike previous methods, does not require matching original and enhanced images for training. This allows the use of massive online photo collections to train a ranking model for improved enhancement. We first propose a multi-level ranking model, which is learned from only relatively-labeled inputs that are automatically crawled. Then we design a novel parameter sampling scheme under this model to generate the desired enhancement parameters for a new image. For evaluation, we first verify the effectiveness and the generalization abilities of our approach, using images that have been enhanced/labeled by experts. Then we carry out subjective tests, which show that users prefer images enhanced by our approach over other existing methods. version:1
arxiv-1704-01249 | A Structured Approach to Predicting Image Enhancement Parameters | http://arxiv.org/abs/1704.01249 | id:1704.01249 author:Parag S. Chandakkar, Baoxin Li category:cs.CV  published:2017-04-05 summary:Social networking on mobile devices has become a commonplace of everyday life. In addition, photo capturing process has become trivial due to the advances in mobile imaging. Hence people capture a lot of photos everyday and they want them to be visually-attractive. This has given rise to automated, one-touch enhancement tools. However, the inability of those tools to provide personalized and content-adaptive enhancement has paved way for machine-learned methods to do the same. The existing typical machine-learned methods heuristically (e.g. kNN-search) predict the enhancement parameters for a new image by relating the image to a set of similar training images. These heuristic methods need constant interaction with the training images which makes the parameter prediction sub-optimal and computationally expensive at test time which is undesired. This paper presents a novel approach to predicting the enhancement parameters given a new image using only its features, without using any training images. We propose to model the interaction between the image features and its corresponding enhancement parameters using the matrix factorization (MF) principles. We also propose a way to integrate the image features in the MF formulation. We show that our approach outperforms heuristic approaches as well as recent approaches in MF and structured prediction on synthetic as well as real-world data of image enhancement. version:1
arxiv-1704-01248 | A Computational Approach to Relative Aesthetics | http://arxiv.org/abs/1704.01248 | id:1704.01248 author:Parag S. Chandakkar, Vijetha Gattupalli, Baoxin Li category:cs.CV  published:2017-04-05 summary:Computational visual aesthetics has recently become an active research area. Existing state-of-art methods formulate this as a binary classification task where a given image is predicted to be beautiful or not. In many applications such as image retrieval and enhancement, it is more important to rank images based on their aesthetic quality instead of binary-categorizing them. Furthermore, in such applications, it may be possible that all images belong to the same category. Hence determining the aesthetic ranking of the images is more appropriate. To this end, we formulate a novel problem of ranking images with respect to their aesthetic quality. We construct a new dataset of image pairs with relative labels by carefully selecting images from the popular AVA dataset. Unlike in aesthetics classification, there is no single threshold which would determine the ranking order of the images across our entire dataset. We propose a deep neural network based approach that is trained on image pairs by incorporating principles from relative learning. Results show that such relative training procedure allows our network to rank the images with a higher accuracy than a state-of-art network trained on the same set of images using binary labels. version:1
arxiv-1704-01246 | Estimation of Tissue Microstructure Using a Deep Network Inspired by a Sparse Reconstruction Framework | http://arxiv.org/abs/1704.01246 | id:1704.01246 author:Chuyang Ye category:cs.CV  published:2017-04-05 summary:Diffusion magnetic resonance imaging (dMRI) provides a unique tool for noninvasively probing the microstructure of the neuronal tissue. The NODDI model has been a popular approach to the estimation of tissue microstructure in many neuroscience studies. It represents the diffusion signals with three types of diffusion in tissue: intra-cellular, extra-cellular, and cerebrospinal fluid compartments. However, the original NODDI method uses a computationally expensive procedure to fit the model and could require a large number of diffusion gradients for accurate microstructure estimation, which may be impractical for clinical use. Therefore, efforts have been devoted to efficient and accurate NODDI microstructure estimation with a reduced number of diffusion gradients. In this work, we propose a deep network based approach to the NODDI microstructure estimation, which is named Microstructure Estimation using a Deep Network (MEDN). Motivated by the AMICO algorithm which accelerates the computation of NODDI parameters, we formulate the microstructure estimation problem in a dictionary-based framework. The proposed network comprises two cascaded stages. The first stage resembles the solution to a dictionary-based sparse reconstruction problem and the second stage computes the final microstructure using the output of the first stage. The weights in the two stages are jointly learned from training data, which is obtained from training dMRI scans with diffusion gradients that densely sample the q-space. The proposed method was applied to brain dMRI scans, where two shells each with 30 gradient directions (60 diffusion gradients in total) were used. Estimation accuracy with respect to the gold standard was measured and the results demonstrate that MEDN outperforms the competing algorithms. version:1
arxiv-1704-01235 | Joint Regression and Ranking for Image Enhancement | http://arxiv.org/abs/1704.01235 | id:1704.01235 author:Parag S. Chandakkar, Baoxin Li category:cs.CV  published:2017-04-05 summary:Research on automated image enhancement has gained momentum in recent years, partially due to the need for easy-to-use tools for enhancing pictures captured by ubiquitous cameras on mobile devices. Many of the existing leading methods employ machine-learning-based techniques, by which some enhancement parameters for a given image are found by relating the image to the training images with known enhancement parameters. While knowing the structure of the parameter space can facilitate search for the optimal solution, none of the existing methods has explicitly modeled and learned that structure. This paper presents an end-to-end, novel joint regression and ranking approach to model the interaction between desired enhancement parameters and images to be processed, employing a Gaussian process (GP). GP allows searching for ideal parameters using only the image features. The model naturally leads to a ranking technique for comparing images in the induced feature space. Comparative evaluation using the ground-truth based on the MIT-Adobe FiveK dataset plus subjective tests on an additional data-set were used to demonstrate the effectiveness of the proposed approach. version:1
arxiv-1704-01223 | Greedy Sampling of Graph Signals | http://arxiv.org/abs/1704.01223 | id:1704.01223 author:Luiz F. O. Chamon, Alejandro Ribeiro category:cs.IT cs.SI math.IT stat.ML  published:2017-04-05 summary:Sampling is a fundamental topic in graph signal processing, having found applications in estimation, clustering, and video compression. In contrast to traditional signal processing, the irregularity of the signal domain makes selecting a sampling set non-trivial and hard to analyze. Indeed, though conditions for graph signal interpolation from noiseless samples exist, they do not lead to a unique sampling set. Thus, the presence of noise makes sampling set selection a hard combinatorial problem. Although greedy sampling schemes have become ubiquitous in practice, they have no performance guarantee. This work takes a twofold approach to address this issue. First, universal performance bounds are derived for the interpolation of stochastic graph signals from noisy samples. In contrast to currently available bounds, they are not restricted to specific sampling schemes and hold for any sampling sets. Second, this paper provides near-optimal guarantees for greedy sampling by introducing the concept of approximate submodularity and updating the classical greedy bound. It then provides explicit bounds on the approximate supermodularity of the interpolation mean-square error showing that it can be optimized with worst-case guarantees using greedy search even though it is not supermodular. Simulations illustrate the derived bound for different graph models and show an application of graph signal sampling to reduce the complexity of kernel principal component analysis. version:1
arxiv-1704-01222 | Escape from Cells: Deep Kd-Networks for The Recognition of 3D Point Cloud Models | http://arxiv.org/abs/1704.01222 | id:1704.01222 author:Roman Klokov, Victor Lempitsky category:cs.CV  published:2017-04-04 summary:We present a new deep learning architecture (called Kd-network) that is designed for 3D model recognition tasks and works with unstructured point clouds. The new architecture performs multiplicative transformations and share parameters of these transformations according to the subdivisions of the point clouds imposed onto them by Kd-trees. Unlike the currently dominant convolutional architectures that usually require rasterization on uniform two-dimensional or three-dimensional grids, Kd-networks do not rely on such grids in any way and therefore avoid poor scaling behaviour. In a series of experiments with popular shape recognition benchmarks, Kd-networks demonstrate competitive performance in a number of shape recognition tasks such as shape classification, shape retrieval and shape part segmentation. version:1
arxiv-1704-00207 | A Brownian Motion Model and Extreme Belief Machine for Modeling Sensor Data Measurements | http://arxiv.org/abs/1704.00207 | id:1704.00207 author:Robert A. Murphy category:cs.NE 60J70  published:2017-04-01 summary:As the title suggests, we will describe (and justify through the presentation of some of the relevant mathematics) prediction methodologies for sensor measurements. This exposition will mainly be concerned with the mathematics related to modeling the sensor measurements. version:2
arxiv-1704-01212 | Neural Message Passing for Quantum Chemistry | http://arxiv.org/abs/1704.01212 | id:1704.01212 author:Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, George E. Dahl category:cs.LG I.2.6  published:2017-04-04 summary:Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation function to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark, results we believe are strong enough to justify retiring this benchmark. version:1
arxiv-1704-01194 | Two Stream LSTM: A Deep Fusion Framework for Human Action Recognition | http://arxiv.org/abs/1704.01194 | id:1704.01194 author:Harshala Gammulle, Simon Denman, Sridha Sridharan, Clinton Fookes category:cs.CV  published:2017-04-04 summary:In this paper we address the problem of human action recognition from video sequences. Inspired by the exemplary results obtained via automatic feature learning and deep learning approaches in computer vision, we focus our attention towards learning salient spatial features via a convolutional neural network (CNN) and then map their temporal relationship with the aid of Long-Short-Term-Memory (LSTM) networks. Our contribution in this paper is a deep fusion framework that more effectively exploits spatial features from CNNs with temporal features from LSTM models. We also extensively evaluate their strengths and weaknesses. We find that by combining both the sets of features, the fully connected features effectively act as an attention mechanism to direct the LSTM to interesting parts of the convolutional feature sequence. The significance of our fusion method is its simplicity and effectiveness compared to other state-of-the-art methods. The evaluation results demonstrate that this hierarchical multi stream fusion method has higher performance compared to single stream mapping methods allowing it to achieve high accuracy outperforming current state-of-the-art methods in three widely used databases: UCF11, UCFSports, jHMDB. version:1
arxiv-1704-01155 | Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks | http://arxiv.org/abs/1704.01155 | id:1704.01155 author:Weilin Xu, David Evans, Yanjun Qi category:cs.CV cs.CR cs.LG  published:2017-04-04 summary:Although deep neural networks (DNNs) have achieved great success in many computer vision tasks, recent studies have shown they are vulnerable to adversarial examples. Such examples, typically generated by adding small but purposeful distortions, can frequently fool DNN models. Previous studies to defend against adversarial examples mostly focused on refining the DNN models. They have either shown limited success or suffer from the expensive computation. We propose a new strategy, \emph{feature squeezing}, that can be used to harden DNN models by detecting adversarial examples. Feature squeezing reduces the search space available to an adversary by coalescing samples that correspond to many different feature vectors in the original space into a single sample. By comparing a DNN model's prediction on the original input with that on the squeezed input, feature squeezing detects adversarial examples with high accuracy and few false positives. This paper explores two instances of feature squeezing: reducing the color bit depth of each pixel and smoothing using a spatial filter. These strategies are straightforward, inexpensive, and complementary to defensive methods that operate on the underlying model, such as adversarial training. version:1
arxiv-1704-01152 | Pose2Instance: Harnessing Keypoints for Person Instance Segmentation | http://arxiv.org/abs/1704.01152 | id:1704.01152 author:Subarna Tripathi, Maxwell Collins, Matthew Brown, Serge Belongie category:cs.CV  published:2017-04-04 summary:Human keypoints are a well-studied representation of people.We explore how to use keypoint models to improve instance-level person segmentation. The main idea is to harness the notion of a distance transform of oracle provided keypoints or estimated keypoint heatmaps as a prior for person instance segmentation task within a deep neural network. For training and evaluation, we consider all those images from COCO where both instance segmentation and human keypoints annotations are available. We first show how oracle keypoints can boost the performance of existing human segmentation model during inference without any training. Next, we propose a framework to directly learn a deep instance segmentation model conditioned on human pose. Experimental results show that at various Intersection Over Union (IOU) thresholds, in a constrained environment with oracle keypoints, the instance segmentation accuracy achieves 10% to 12% relative improvements over a strong baseline of oracle bounding boxes. In a more realistic environment, without the oracle keypoints, the proposed deep person instance segmentation model conditioned on human pose achieves 3.8% to 10.5% relative improvements comparing with its strongest baseline of a deep network trained only for segmentation. version:1
arxiv-1703-08769 | Open Vocabulary Scene Parsing | http://arxiv.org/abs/1703.08769 | id:1703.08769 author:Hang Zhao, Xavier Puig, Bolei Zhou, Sanja Fidler, Antonio Torralba category:cs.CV cs.AI  published:2017-03-26 summary:Recognizing arbitrary objects in the wild has been a challenging problem due to the limitations of existing classification models and datasets. In this paper, we propose a new task that aims at parsing scenes with a large and open vocabulary, and several evaluation metrics are explored for this problem. Our proposed approach to this problem is a joint image pixel and word concept embeddings framework, where word concepts are connected by semantic relations. We validate the open vocabulary prediction ability of our framework on ADE20K dataset which covers a wide variety of scenes and objects. We further explore the trained joint embedding space to show its interpretability. version:2
arxiv-1704-01137 | DyVEDeep: Dynamic Variable Effort Deep Neural Networks | http://arxiv.org/abs/1704.01137 | id:1704.01137 author:Sanjay Ganapathy, Swagath Venkataramani, Balaraman Ravindran, Anand Raghunathan category:cs.NE cs.CV cs.LG  published:2017-04-04 summary:Deep Neural Networks (DNNs) have advanced the state-of-the-art in a variety of machine learning tasks and are deployed in increasing numbers of products and services. However, the computational requirements of training and evaluating large-scale DNNs are growing at a much faster pace than the capabilities of the underlying hardware platforms that they are executed upon. In this work, we propose Dynamic Variable Effort Deep Neural Networks (DyVEDeep) to reduce the computational requirements of DNNs during inference. Previous efforts propose specialized hardware implementations for DNNs, statically prune the network, or compress the weights. Complementary to these approaches, DyVEDeep is a dynamic approach that exploits the heterogeneity in the inputs to DNNs to improve their compute efficiency with comparable classification accuracy. DyVEDeep equips DNNs with dynamic effort mechanisms that, in the course of processing an input, identify how critical a group of computations are to classify the input. DyVEDeep dynamically focuses its compute effort only on the critical computa- tions, while skipping or approximating the rest. We propose 3 effort knobs that operate at different levels of granularity viz. neuron, feature and layer levels. We build DyVEDeep versions for 5 popular image recognition benchmarks - one for CIFAR-10 and four for ImageNet (AlexNet, OverFeat and VGG-16, weight-compressed AlexNet). Across all benchmarks, DyVEDeep achieves 2.1x-2.6x reduction in the number of scalar operations, which translates to 1.8x-2.3x performance improvement over a Caffe-based implementation, with < 0.5% loss in accuracy. version:1
arxiv-1704-01133 | Satellite Image-based Localization via Learned Embeddings | http://arxiv.org/abs/1704.01133 | id:1704.01133 author:Dong-Ki Kim, Matthew R. Walter category:cs.RO cs.CV cs.LG  published:2017-04-04 summary:We propose a vision-based method that localizes a ground vehicle using publicly available satellite imagery as the only prior knowledge of the environment. Our approach takes as input a sequence of ground-level images acquired by the vehicle as it navigates, and outputs an estimate of the vehicle's pose relative to a georeferenced satellite image. We overcome the significant viewpoint and appearance variations between the images through a neural multi-view model that learns location-discriminative embeddings in which ground-level images are matched with their corresponding satellite view of the scene. We use this learned function as an observation model in a filtering framework to maintain a distribution over the vehicle's pose. We evaluate our method on different benchmark datasets and demonstrate its ability localize ground-level images in environments novel relative to training, despite the challenges of significant viewpoint and appearance variations. version:1
arxiv-1704-01087 | Probabilistic Search for Structured Data via Probabilistic Programming and Nonparametric Bayes | http://arxiv.org/abs/1704.01087 | id:1704.01087 author:Feras Saad, Leonardo Casarsa, Vikash Mansinghka category:cs.AI cs.DB cs.LG stat.ML  published:2017-04-04 summary:Databases are widespread, yet extracting relevant data can be difficult. Without substantial domain knowledge, multivariate search queries often return sparse or uninformative results. This paper introduces an approach for searching structured data based on probabilistic programming and nonparametric Bayes. Users specify queries in a probabilistic language that combines standard SQL database search operators with an information theoretic ranking function called predictive relevance. Predictive relevance can be calculated by a fast sparse matrix algorithm based on posterior samples from CrossCat, a nonparametric Bayesian model for high-dimensional, heterogeneously-typed data tables. The result is a flexible search technique that applies to a broad class of information retrieval problems, which we integrate into BayesDB, a probabilistic programming platform for probabilistic data analysis. This paper demonstrates applications to databases of US colleges, global macroeconomic indicators of public health, and classic cars. We found that human evaluators often prefer the results from probabilistic search to results from a standard baseline. version:1
arxiv-1704-01085 | Deep Depth From Focus | http://arxiv.org/abs/1704.01085 | id:1704.01085 author:Caner Hazirbas, Laura Leal-Taixé, Daniel Cremers category:cs.CV  published:2017-04-04 summary:Depth from Focus (DFF) is one of the classical ill-posed inverse problems in computer vision. Most approaches recover the depth at each pixel based on the focal setting which exhibits maximal sharpness. Yet, it is not obvious how to reliably estimate the sharpness level, particularly in low-textured areas. In this paper, we propose 'Deep Depth From Focus (DDFF)' as the first end-to-end learning approach to this problem. Towards this goal, we create a novel real-scene indoor benchmark composed of 4D light-field images obtained from a plenoptic camera and ground truth depth obtained from a registered RGB-D sensor. Compared to existing benchmarks our dataset is 30 times larger, enabling the use of machine learning for this inverse problem. We compare our results with state-of-the-art DFF methods and we also analyze the effect of several key deep architectural components. These experiments show that DDFFNet achieves state-of-the-art performance in all scenes, reducing depth error by more than 70% wrt classic DFF methods. version:1
arxiv-1704-01079 | Homotopy Parametric Simplex Method for Sparse Learning | http://arxiv.org/abs/1704.01079 | id:1704.01079 author:Haotian Pang, Tuo Zhao, Robert Vanderbei, Han Liu category:cs.LG math.OC stat.ML  published:2017-04-04 summary:High dimensional sparse learning has imposed a great computational challenge to large scale data analysis. In this paper, we are interested in a broad class of sparse learning approaches formulated as linear programs parametrized by a {\em regularization factor}, and solve them by the parametric simplex method (PSM). Our parametric simplex method offers significant advantages over other competing methods: (1) PSM naturally obtains the complete solution path for all values of the regularization parameter; (2) PSM provides a high precision dual certificate stopping criterion; (3) PSM yields sparse solutions through very few iterations, and the solution sparsity significantly reduces the computational cost per iteration. Particularly, we demonstrate the superiority of PSM over various sparse learning approaches, including Dantzig selector for sparse linear regression, LAD-Lasso for sparse robust linear regression, CLIME for sparse precision matrix estimation, sparse differential network estimation, and sparse Linear Programming Discriminant (LPD) analysis. We then provide sufficient conditions under which PSM always outputs sparse solutions such that its computational performance can be significantly boosted. Thorough numerical experiments are provided to demonstrate the outstanding performance of the PSM method. version:1
arxiv-1704-01069 | ME R-CNN: Multi-Expert Region-based CNN for Object Detection | http://arxiv.org/abs/1704.01069 | id:1704.01069 author:Hyungtae Lee, Sungmin Eum, Heesung Kwon category:cs.CV  published:2017-04-04 summary:Recent CNN-based object detection methods have drastically improved their performances but still use a single classifier as opposed to "multiple experts" in categorizing objects. The main motivation of introducing multi-experts is twofold: i) to allow different experts to specialize in different fundamental object shape priors and ii) to better capture the appearance variations caused by different poses and viewing angles. The proposed approach, referred to as multi-expert Region-based CNN (ME R-CNN), consists of three experts each responsible for objects with particular shapes: horizontally elongated, square-like, and vertically elongated. Each expert is a network with multiple fully connected layers and all the experts are preceded by a shared network which consists of multiple convolutional layers. On top of using selective search which provides a compact, yet effective set of region of interests (RoIs) for object detection, we augmented the set by also employing the exhaustive search for training. Incorporating the exhaustive search can provide complementary advantages: i) it captures the multitude of neighboring RoIs missed by the selective search, and thus ii) provide significantly larger amount of training examples to achieve the enhanced accuracy. version:1
arxiv-1704-01047 | OctNetFusion: Learning Depth Fusion from Data | http://arxiv.org/abs/1704.01047 | id:1704.01047 author:Gernot Riegler, Ali Osman Ulusoy, Horst Bischof, Andreas Geiger category:cs.CV  published:2017-04-04 summary:In this paper, we present a learning based approach to depth fusion, i.e., dense 3D reconstruction from multiple depth images. The most common approach to depth fusion is based on averaging truncated signed distance functions, which was originally proposed by Curless and Levoy in 1996. While this method achieves great results, it can not reconstruct surfaces occluded in the input views and requires a large number frames to filter out sensor noise and outliers. Motivated by large 3D model databases and recent advances in deep learning, we present a novel 3D convolutional network architecture that learns to predict an implicit surface representation from the input depth maps. Our learning based fusion approach significantly outperforms the traditional volumetric fusion approach in terms of noise reduction and outlier suppression. By learning the structure of real world 3D objects and scenes, our approach is further able to reconstruct occluded regions and to fill gaps in the reconstruction. We evaluate our approach extensively on both synthetic and real-world datasets for volumetric fusion. Further, we apply our approach to the problem of 3D shape completion from a single view where our approach achieves state-of-the-art results. version:1
arxiv-1704-01046 | Using Echo State Networks for Cryptography | http://arxiv.org/abs/1704.01046 | id:1704.01046 author:Rajkumar Ramamurthy, Christian Bauckhage, Krisztian Buza, Stefan Wrobel category:cs.CR cs.NE  published:2017-04-04 summary:Echo state networks are simple recurrent neural networks that are easy to implement and train. Despite their simplicity, they show a form of memory and can predict or regenerate sequences of data. We make use of this property to realize a novel neural cryptography scheme. The key idea is to assume that Alice and Bob share a copy of an echo state network. If Alice trains her copy to memorize a message, she can communicate the trained part of the network to Bob who plugs it into his copy to regenerate the message. Considering a byte-level representation of in- and output, the technique applies to arbitrary types of data (texts, images, audio files, etc.) and practical experiments reveal it to satisfy the fundamental cryptographic properties of diffusion and confusion. version:1
arxiv-1703-10127 | Priv'IT: Private and Sample Efficient Identity Testing | http://arxiv.org/abs/1703.10127 | id:1703.10127 author:Bryan Cai, Constantinos Daskalakis, Gautam Kamath category:cs.DS cs.CR cs.IT cs.LG math.IT math.ST stat.TH  published:2017-03-29 summary:We develop differentially private hypothesis testing methods for the small sample regime. Given a sample $\cal D$ from a categorical distribution $p$ over some domain $\Sigma$, an explicitly described distribution $q$ over $\Sigma$, some privacy parameter $\varepsilon$, accuracy parameter $\alpha$, and requirements $\beta_{\rm I}$ and $\beta_{\rm II}$ for the type I and type II errors of our test, the goal is to distinguish between $p=q$ and $d_{\rm{TV}}(p,q) \geq \alpha$. We provide theoretical bounds for the sample size $ {\cal D} $ so that our method both satisfies $(\varepsilon,0)$-differential privacy, and guarantees $\beta_{\rm I}$ and $\beta_{\rm II}$ type I and type II errors. We show that differential privacy may come for free in some regimes of parameters, and we always beat the sample complexity resulting from running the $\chi^2$-test with noisy counts, or standard approaches such as repetition for endowing non-private $\chi^2$-style statistics with differential privacy guarantees. We experimentally compare the sample complexity of our method to that of recently proposed methods for private hypothesis testing. version:2
arxiv-1704-01041 | Polynomial Time and Sample Complexity for Non-Gaussian Component Analysis: Spectral Methods | http://arxiv.org/abs/1704.01041 | id:1704.01041 author:Yan Shuo Tan, Roman Vershynin category:cs.LG math.PR stat.ML 68Q87  published:2017-04-04 summary:The problem of Non-Gaussian Component Analysis (NGCA) is about finding a maximal low-dimensional subspace $E$ in $\mathbb{R}^n$ so that data points projected onto $E$ follow a non-gaussian distribution. Although this is an appropriate model for some real world data analysis problems, there has been little progress on this problem over the last decade. In this paper, we attempt to address this state of affairs in two ways. First, we give a new characterization of standard gaussian distributions in high-dimensions, which lead to effective tests for non-gaussianness. Second, we propose a simple algorithm, \emph{Reweighted PCA}, as a method for solving the NGCA problem. We prove that for a general unknown non-gaussian distribution, this algorithm recovers at least one direction in $E$, with sample and time complexity depending polynomially on the dimension of the ambient space. We conjecture that the algorithm actually recovers the entire $E$. version:1
arxiv-1704-01472 | Automatic Breast Ultrasound Image Segmentation: A Survey | http://arxiv.org/abs/1704.01472 | id:1704.01472 author:Min Xian, Yingtao Zhang, H. D. Cheng, Fei Xu, Boyu Zhang, Jianrui Ding category:cs.CV cs.LG  published:2017-04-04 summary:Breast cancer is one of the leading causes of cancer death among women worldwide. In clinical routine, automatic breast ultrasound (BUS) image segmentation is very challenging and essential for cancer diagnosis and treatment planning. Many BUS segmentation approaches have been studied in the last two decades, and have been proved to be effective on private datasets. Currently, the advancement of BUS image segmentation seems to meet its bottleneck. The improvement of the performance is increasingly challenging, and only few new approaches were published in the last several years. It is the time to look at the field by reviewing previous approaches comprehensively and to investigate the future directions. In this paper, we study the basic ideas, theories, pros and cons of the approaches, group them into categories, and extensively review each category in depth by discussing the principles, application issues, and advantages/disadvantages. version:1
arxiv-1704-01415 | Multi-Label Learning with Global and Local Label Correlation | http://arxiv.org/abs/1704.01415 | id:1704.01415 author:Yue Zhu, James T. Kwok, Zhi-Hua Zhou category:cs.LG cs.AI  published:2017-04-04 summary:It is well-known that exploiting label correlations is important to multi-label learning. Existing approaches either assume that the label correlations are global and shared by all instances; or that the label correlations are local and shared only by a data subset. In fact, in the real-world applications, both cases may occur that some label correlations are globally applicable and some are shared only in a local group of instances. Moreover, it is also a usual case that only partial labels are observed, which makes the exploitation of the label correlations much more difficult. That is, it is hard to estimate the label correlations when many labels are absent. In this paper, we propose a new multi-label approach GLOCAL dealing with both the full-label and the missing-label cases, exploiting global and local label correlations simultaneously, through learning a latent label representation and optimizing label manifolds. The extensive experimental studies validate the effectiveness of our approach on both full-label and missing-label data. version:1
arxiv-1704-00979 | Optic Disc and Cup Segmentation Methods for Glaucoma Detection with Modification of U-Net Convolutional Neural Network | http://arxiv.org/abs/1704.00979 | id:1704.00979 author:Artem Sevastopolsky category:cs.CV stat.ML  published:2017-04-04 summary:Glaucoma is the second leading cause of blindness all over the world, with approximately 60 million cases reported worldwide in 2010. If undiagnosed in time, glaucoma causes irreversible damage to the optic nerve leading to blindness. The optic nerve head examination, which involves measurement of cup-to-disc ratio, is considered one of the most valuable methods of structural diagnosis of the disease. Estimation of cup-to-disc ratio requires segmentation of optic disc and optic cup on eye fundus images and can be performed by modern computer vision algorithms. This work presents universal approach for automatic optic disc and cup segmentation, which is based on deep learning, namely, modification of U-Net convolutional neural network. Our experiments include comparison with the best known methods on publicly available databases DRIONS-DB, RIM-ONE v.3, DRISHTI-GS. For both optic disc and cup segmentation, our method achieves quality comparable to current state-of-the-art methods, outperforming them in terms of the prediction time. version:1
arxiv-1704-02841 | From Modal to Multimodal Ambiguities: a Classification Approach | http://arxiv.org/abs/1704.02841 | id:1704.02841 author:Maria Chiara Caschera, Fernando Ferri, Patrizia Grifoni category:cs.HC cs.CL I.2.1; I.2.7  published:2017-04-04 summary:This paper deals with classifying ambiguities for Multimodal Languages. It evolves the classifications and the methods of the literature on ambiguities for Natural Language and Visual Language, empirically defining an original classification of ambiguities for multimodal interaction using a linguistic perspective. This classification distinguishes between Semantic and Syntactic multimodal ambiguities and their subclasses, which are intercepted using a rule-based method implemented in a software module. The experimental results have achieved an accuracy of the obtained classification compared to the expected one, which are defined by the human judgment, of 94.6% for the semantic ambiguities classes, and 92.1% for the syntactic ambiguities classes. version:1
arxiv-1704-01427 | AMIDST: a Java Toolbox for Scalable Probabilistic Machine Learning | http://arxiv.org/abs/1704.01427 | id:1704.01427 author:Andrés R. Masegosa, Ana M. Martínez, Darío Ramos-López, Rafael Cabañas, Antonio Salmerón, Thomas D. Nielsen, Helge Langseth, Anders L. Madsen category:cs.LG I.2.6  published:2017-04-04 summary:The AMIDST Toolbox is a software for scalable probabilistic machine learning with a spe- cial focus on (massive) streaming data. The toolbox supports a flexible modeling language based on probabilistic graphical models with latent variables and temporal dependencies. The specified models can be learnt from large data sets using parallel or distributed implementa- tions of Bayesian learning algorithms for either streaming or batch data. These algorithms are based on a flexible variational message passing scheme, which supports discrete and continu- ous variables from a wide range of probability distributions. AMIDST also leverages existing functionality and algorithms by interfacing to software tools such as Flink, Spark, MOA, Weka, R and HUGIN. AMIDST is an open source toolbox written in Java and available at http://www.amidsttoolbox.com under the Apache Software License version 2.0. version:1
arxiv-1704-00963 | Bayesian optimization with virtual derivative sign observations | http://arxiv.org/abs/1704.00963 | id:1704.00963 author:Eero Siivola, Aki Vehtari, Jarno Vanhatalo, Javier González category:stat.ML stat.CO stat.ME  published:2017-04-04 summary:Bayesian optimization (BO) is a global optimization strategy designed to find the minimum of expensive black-box functions $g$ typically defined on a continuous sets of $\mathcal{R}^d$. Using a Gaussian process (GP) as a surrogate model for the objective and an acquisition function to systematically search its domain, BO strategies aim to minimize the amount of samples required to find the minimum of $g$. Although currently available acquisition functions address this goal with different degree of success, an over-exploration effect of the contour of $g$ is typically observed. This is due to the myopic nature of most acquisitions that greedily try to over-reduce uncertainty in the border of the search domain. In most real problems, however, like the configuration of machine learning algorithms, the function domain is conservatively large and with a high probability the global minimum is not at the boundary. We propose a method to incorporate this knowledge into the searching process by adding virtual derivative observations at the borders of the search space. We use the properties of GP models that allow us to easily impose conditions on the partial derivatives of the objective. The method is applicable with any acquisition function, it is easy to use and consistently reduces the number of evaluations required to find the minimum of $g$ irrespective of the acquisition used. We illustrate the benefits our approach in a simulation study with a battery of objective functions. version:1
arxiv-1704-00552 | A Transition-Based Directed Acyclic Graph Parser for UCCA | http://arxiv.org/abs/1704.00552 | id:1704.00552 author:Daniel Hershcovich, Omri Abend, Ari Rappoport category:cs.CL  published:2017-04-03 summary:We present the first parser for UCCA, a cross-linguistically applicable framework for semantic representation, which builds on extensive typological work and supports rapid annotation. UCCA poses a challenge for existing parsing techniques, as it exhibits reentrancy (resulting in DAG structures), discontinuous structures and non-terminal nodes corresponding to complex semantic units. To our knowledge, the conjunction of these formal properties is not supported by any existing parser. Our transition-based parser, which uses a novel transition set and features based on bidirectional LSTMs, has value not just for UCCA parsing: its ability to handle more general graph structures can inform the development of parsers for other semantic DAG structures, and in languages that frequently use discontinuous structures. version:2
arxiv-1704-00939 | Fortia-FBK at SemEval-2017 Task 5: Bullish or Bearish? Inferring Sentiment towards Brands from Financial News Headlines | http://arxiv.org/abs/1704.00939 | id:1704.00939 author:Youness Mansar, Lorenzo Gatti, Sira Ferradans, Marco Guerini, Jacopo Staiano category:cs.CL cs.CY  published:2017-04-04 summary:In this paper, we describe a methodology to infer Bullish or Bearish sentiment towards companies/brands. More specifically, our approach leverages affective lexica and word embeddings in combination with convolutional neural networks to infer the sentiment of financial news headlines towards a target company. Such architecture was used and evaluated in the context of the SemEval 2017 challenge (task 5, subtask 2), in which it obtained the best performance. version:1
arxiv-1704-00924 | Japanese Sentiment Classification using a Tree-Structured Long Short-Term Memory with Attention | http://arxiv.org/abs/1704.00924 | id:1704.00924 author:Ryosuke Miyazaki, Mamoru Komachi category:cs.CL  published:2017-04-04 summary:Previous approaches to training syntax-based sentiment classification models required phrase-level annotated corpora, which are not readily available in many languages other than English. Thus, we propose the use of tree-structured Long Short-Term Memory with an attention mechanism that pays attention to each subtree of the parse tree. Experimental results indicate that our model achieves the state-of-the-art performance in a Japanese sentiment classification task. version:1
arxiv-1704-01466 | A Unified Multi-Faceted Video Summarization System | http://arxiv.org/abs/1704.01466 | id:1704.01466 author:Anurag Sahoo, Vishal Kaushal, Khoshrav Doctor, Suyash Shetty, Rishabh Iyer, Ganesh Ramakrishnan category:cs.CV cs.DM  published:2017-04-04 summary:This paper addresses automatic summarization and search in visual data comprising of videos, live streams and image collections in a unified manner. In particular, we propose a framework for multi-faceted summarization which extracts key-frames (image summaries), skims (video summaries) and entity summaries (summarization at the level of entities like objects, scenes, humans and faces in the video). The user can either view these as extractive summarization, or query focused summarization. Our approach first pre-processes the video or image collection once, to extract all important visual features, following which we provide an interactive mechanism to the user to summarize the video based on their choice. We investigate several diversity, coverage and representation models for all these problems, and argue the utility of these different mod- els depending on the application. While most of the prior work on submodular summarization approaches has focused on combining several models and learning weighted mixtures, we focus on the explain-ability of different the diversity, coverage and representation models and their scalability. Most importantly, we also show that we can summarize hours of video data in a few seconds, and our system allows the user to generate summaries of various lengths and types interactively on the fly. version:1
arxiv-1704-00898 | Interpretation of Semantic Tweet Representations | http://arxiv.org/abs/1704.00898 | id:1704.00898 author:J Ganesh, Manish Gupta, Vasudeva Varma category:cs.CL  published:2017-04-04 summary:Research in analysis of microblogging platforms is experiencing a renewed surge with a large number of works applying representation learning models for applications like sentiment analysis, semantic textual similarity computation, hashtag prediction, etc. Although the performance of the representation learning models has been better than the traditional baselines for such tasks, little is known about the elementary properties of a tweet encoded within these representations, or why particular representations work better for certain tasks. Our work presented here constitutes the first step in opening the black-box of vector embeddings for tweets. Traditional feature engineering methods for high-level applications have exploited various elementary properties of tweets. We believe that a tweet representation is effective for an application because it meticulously encodes the application-specific elementary properties of tweets. To understand the elementary properties encoded in a tweet representation, we evaluate the representations on the accuracy to which they can model each of those properties such as tweet length, presence of particular words, hashtags, mentions, capitalization, etc. Our systematic extensive study of nine supervised and four unsupervised tweet representations against most popular eight textual and five social elementary properties reveal that Bi-directional LSTMs (BLSTMs) and Skip-Thought Vectors (STV) best encode the textual and social properties of tweets respectively. FastText is the best model for low resource settings, providing very little degradation with reduction in embedding size. Finally, we draw interesting insights by correlating the model performance obtained for elementary property prediction tasks with the high-level downstream applications. version:1
arxiv-1704-00887 | A Branch-and-Bound Algorithm for Checkerboard Extraction in Camera-Laser Calibration | http://arxiv.org/abs/1704.00887 | id:1704.00887 author:Alireza Khosravian, Tat-Jun Chin, Ian Reid category:cs.RO cs.CV  published:2017-04-04 summary:We address the problem of camera-to-laser-scanner calibration using a checkerboard and multiple image-laser scan pairs. Distinguishing which laser points measure the checkerboard and which lie on the background is essential to any such system. We formulate the checkerboard extraction as a combinatorial optimization problem with a clear cut objective function. We propose a branch-and-bound technique that deterministically and globally optimizes the objective. Unlike what is available in the literature, the proposed method is not heuristic and does not require assumptions such as constraints on the background or relying on discontinuity of the range measurements to partition the data into line segments. The proposed approach is generic and can be applied to both 3D or 2D laser scanners as well as the cases where multiple checkerboards are present. We demonstrate the effectiveness of the proposed approach by providing numerical simulations as well as experimental results. version:1
arxiv-1703-08961 | Scaling the Scattering Transform: Deep Hybrid Networks | http://arxiv.org/abs/1703.08961 | id:1703.08961 author:Edouard Oyallon, Eugene Belilovsky, Sergey Zagoruyko category:cs.CV cs.LG  published:2017-03-27 summary:We use the scattering network as a generic and fixed ini-tialization of the first layers of a supervised hybrid deep network. We show that early layers do not necessarily need to be learned, providing the best results to-date with pre-defined representations while being competitive with Deep CNNs. Using a shallow cascade of 1 x 1 convolutions, which encodes scattering coefficients that correspond to spatial windows of very small sizes, permits to obtain AlexNet accuracy on the imagenet ILSVRC2012. We demonstrate that this local encoding explicitly learns invariance w.r.t. rotations. Combining scattering networks with a modern ResNet, we achieve a single-crop top 5 error of 11.4% on imagenet ILSVRC2012, comparable to the Resnet-18 architecture, while utilizing only 10 layers. We also find that hybrid architectures can yield excellent performance in the small sample regime, exceeding their end-to-end counterparts, through their ability to incorporate geometrical priors. We demonstrate this on subsets of the CIFAR-10 dataset and on the STL-10 dataset. version:2
arxiv-1703-09938 | Grouped Convolutional Neural Networks for Multivariate Time Series | http://arxiv.org/abs/1703.09938 | id:1703.09938 author:Subin Yi, Janghoon Ju, Man-Ki Yoon, Jaesik Choi category:cs.LG  published:2017-03-29 summary:Analyzing multivariate time series data is important for many applications such as automated control, fault diagnosis and anomaly detection. One of the key challenges is to learn latent features automatically from dynamically changing multivariate input. In visual recognition tasks, convolutional neural networks (CNNs) have been successful to learn generalized feature extractors with shared parameters over the spatial domain. However, when high-dimensional multivariate time series is given, designing an appropriate CNN model structure becomes challenging because the kernels may need to be extended through the full dimension of the input volume. To address this issue, we present two structure learning algorithms for deep CNN models. Our algorithms exploit the covariance structure over multiple time series to partition input volume into groups. The first algorithm learns the group CNN structures explicitly by clustering individual input sequences. The second algorithm learns the group CNN structures implicitly from the error backpropagation. In experiments with two real-world datasets, we demonstrate that our group CNNs outperform existing CNN based regression methods. version:3
arxiv-1704-00860 | Simultaneous Feature Aggregating and Hashing for Large-scale Image Search | http://arxiv.org/abs/1704.00860 | id:1704.00860 author:Thanh-Toan Do, Dang-Khoa Le Tan, Trung T. Pham, Ngai-Man Cheung category:cs.CV  published:2017-04-04 summary:In most state-of-the-art hashing-based visual search systems, local image descriptors of an image are first aggregated as a single feature vector. This feature vector is then subjected to a hashing function that produces a binary hash code. In previous work, the aggregating and the hashing processes are designed independently. In this paper, we propose a novel framework where feature aggregating and hashing are designed simultaneously and optimized jointly. Specifically, our joint optimization produces aggregated representations that can be better reconstructed by some binary codes. This leads to more discriminative binary hash codes and improved retrieval accuracy. In addition, we also propose a fast version of the recently-proposed Binary Autoencoder to be used in our proposed framework. We perform extensive retrieval experiments on several benchmark datasets with both SIFT and convolutional features. Our results suggest that the proposed framework achieves significant improvements over the state of the art. version:1
arxiv-1704-04422 | Learning a collaborative multiscale dictionary based on robust empirical mode decomposition | http://arxiv.org/abs/1704.04422 | id:1704.04422 author:Rui Chen, Huizhu Jia, Xiaodong Xie, Wen Gao category:cs.CV cs.LG  published:2017-04-04 summary:Dictionary learning is a challenge topic in many image processing areas. The basic goal is to learn a sparse representation from an overcomplete basis set. Due to combining the advantages of generic multiscale representations with learning based adaptivity, multiscale dictionary representation approaches have the power in capturing structural characteristics of natural images. However, existing multiscale learning approaches still suffer from three main weaknesses: inadaptability to diverse scales of image data, sensitivity to noise and outliers, difficulty to determine optimal dictionary structure. In this paper, we present a novel multiscale dictionary learning paradigm for sparse image representations based on an improved empirical mode decomposition. This powerful data-driven analysis tool for multi-dimensional signal can fully adaptively decompose the image into multiscale oscillating components according to intrinsic modes of data self. This treatment can obtain a robust and effective sparse representation, and meanwhile generates a raw base dictionary at multiple geometric scales and spatial frequency bands. This dictionary is refined by selecting optimal oscillating atoms based on frequency clustering. In order to further enhance sparsity and generalization, a tolerance dictionary is learned using a coherence regularized model. A fast proximal scheme is developed to optimize this model. The multiscale dictionary is considered as the product of oscillating dictionary and tolerance dictionary. Experimental results demonstrate that the proposed learning approach has the superior performance in sparse image representations as compared with several competing methods. We also show the promising results in image denoising application. version:1
arxiv-1704-00016 | Opinion Mining on Non-English Short Text | http://arxiv.org/abs/1704.00016 | id:1704.00016 author:Esra Akbas category:cs.CL cs.IR  published:2017-03-31 summary:As the type and the number of such venues increase, automated analysis of sentiment on textual resources has become an essential data mining task. In this paper, we investigate the problem of mining opinions on the collection of informal short texts. Both positive and negative sentiment strength of texts are detected. We focus on a non-English language that has few resources for text mining. This approach would help enhance the sentiment analysis in languages where a list of opinionated words does not exist. We propose a new method projects the text into dense and low dimensional feature vectors according to the sentiment strength of the words. We detect the mixture of positive and negative sentiments on a multi-variant scale. Empirical evaluation of the proposed framework on Turkish tweets shows that our approach gets good results for opinion mining. version:2
arxiv-1704-00848 | Guided Proofreading of Automatic Segmentations for Connectomics | http://arxiv.org/abs/1704.00848 | id:1704.00848 author:Daniel Haehn, Verena Kaynig, James Tompkin, Jeff W. Lichtman, Hanspeter Pfister category:cs.CV  published:2017-04-04 summary:Automatic cell image segmentation methods in connectomics produce merge and split errors, which require correction through proofreading. Previous research has identified the visual search for these errors as the bottleneck in interactive proofreading. To aid error correction, we develop two classifiers that automatically recommend candidate merges and splits to the user. These classifiers use a convolutional neural network (CNN) that has been trained with errors in automatic segmentations against expert-labeled ground truth. Our classifiers detect potentially-erroneous regions by considering a large context region around a segmentation boundary. Corrections can then be performed by a user with yes/no decisions, which reduces variation of information 7.5x faster than previous proofreading methods. We also present a fully-automatic mode that uses a probability threshold to make merge/split decisions. Extensive experiments using the automatic approach and comparing performance of novice and expert users demonstrate that our method performs favorably against state-of-the-art proofreading methods on different connectomics datasets. version:1
arxiv-1703-10664 | Tube Convolutional Neural Network (T-CNN) for Action Detection in Videos | http://arxiv.org/abs/1703.10664 | id:1703.10664 author:Rui Hou, Chen Chen, Mubarak Shah category:cs.CV  published:2017-03-30 summary:Deep learning has been demonstrated to achieve excellent results for image classification and object detection. However, the impact of deep learning on video analysis (e.g. action detection and recognition) has been limited due to complexity of video data and lack of annotations. Previous convolutional neural networks (CNN) based video action detection approaches usually consist of two major steps: frame-level action proposal detection and association of proposals across frames. Also, these methods employ two-stream CNN framework to handle spatial and temporal feature separately. In this paper, we propose an end-to-end deep network called Tube Convolutional Neural Network (T-CNN) for action detection in videos. The proposed architecture is a unified network that is able to recognize and localize action based on 3D convolution features. A video is first divided into equal length clips and for each clip a set of tube proposals are generated next based on 3D Convolutional Network (ConvNet) features. Finally, the tube proposals of different clips are linked together employing network flow and spatio-temporal action detection is performed using these linked video proposals. Extensive experiments on several video datasets demonstrate the superior performance of T-CNN for classifying and localizing actions in both trimmed and untrimmed videos compared to state-of-the-arts. version:2
arxiv-1704-00112 | Configurable, Photorealistic Image Rendering and Ground Truth Synthesis by Sampling Stochastic Grammars Representing Indoor Scenes | http://arxiv.org/abs/1704.00112 | id:1704.00112 author:Chenfanfu Jiang, Yixin Zhu, Siyuan Qi, Siyuan Huang, Jenny Lin, Xingwen Guo, Lap-Fai Yu, Demetri Terzopoulos, Song-Chun Zhu category:cs.CV stat.ML  published:2017-04-01 summary:We propose the configurable rendering of massive quantities of photorealistic images with ground truth for the purposes of training, benchmarking, and diagnosing computer vision models. In contrast to the conventional (crowd-sourced) manual labeling of ground truth for a relatively modest number of RGB-D images captured by Kinect-like sensors, we devise a non-trivial configurable pipeline of algorithms capable of generating a potentially infinite variety of indoor scenes using a stochastic grammar, specifically, one represented by an attributed spatial And-Or graph. We employ physics-based rendering to synthesize photorealistic RGB images while automatically synthesizing detailed, per-pixel ground truth data, including visible surface depth and normal, object identity and material information, as well as illumination. Our pipeline is configurable inasmuch as it enables the precise customization and control of important attributes of the generated scenes. We demonstrate that our generated scenes achieve a performance similar to the NYU v2 Dataset on pre-trained deep learning models. By modifying pipeline components in a controllable manner, we furthermore provide diagnostics on common scene understanding tasks; eg., depth and surface normal prediction, semantic segmentation, etc. version:2
arxiv-1704-00834 | Cascaded Segmentation-Detection Networks for Word-Level Text Spotting | http://arxiv.org/abs/1704.00834 | id:1704.00834 author:Siyang Qin, Roberto Manduchi category:cs.CV  published:2017-04-03 summary:We introduce an algorithm for word-level text spotting that is able to accurately and reliably determine the bounding regions of individual words of text "in the wild". Our system is formed by the cascade of two convolutional neural networks. The first network is fully convolutional and is in charge of detecting areas containing text. This results in a very reliable but possibly inaccurate segmentation of the input image. The second network (inspired by the popular YOLO architecture) analyzes each segment produced in the first stage, and predicts oriented rectangular regions containing individual words. No post-processing (e.g. text line grouping) is necessary. With execution time of 450 ms for a 1000-by-560 image on a Titan X GPU, our system achieves the highest score to date among published algorithms on the ICDAR 2015 Incidental Scene Text dataset benchmark. version:1
arxiv-1704-00829 | Online deforestation detection | http://arxiv.org/abs/1704.00829 | id:1704.00829 author:Emiliano Diaz category:stat.AP cs.CV  published:2017-04-03 summary:Deforestation detection using satellite images can make an important contribution to forest management. Current approaches can be broadly divided into those that compare two images taken at similar periods of the year and those that monitor changes by using multiple images taken during the growing season. The CMFDA algorithm described in Zhu et al. (2012) is an algorithm that builds on the latter category by implementing a year-long, continuous, time-series based approach to monitoring images. This algorithm was developed for 30m resolution, 16-day frequency reflectance data from the Landsat satellite. In this work we adapt the algorithm to 1km, 16-day frequency reflectance data from the modis sensor aboard the Terra satellite. The CMFDA algorithm is composed of two submodels which are fitted on a pixel-by-pixel basis. The first estimates the amount of surface reflectance as a function of the day of the year. The second estimates the occurrence of a deforestation event by comparing the last few predicted and real reflectance values. For this comparison, the reflectance observations for six different bands are first combined into a forest index. Real and predicted values of the forest index are then compared and high absolute differences for consecutive observation dates are flagged as deforestation events. Our adapted algorithm also uses the two model framework. However, since the modis 13A2 dataset used, includes reflectance data for different spectral bands than those included in the Landsat dataset, we cannot construct the forest index. Instead we propose two contrasting approaches: a multivariate and an index approach similar to that of CMFDA. version:1
arxiv-1704-00828 | A Probabilistic Linear Genetic Programming with Stochastic Context-Free Grammar for solving Symbolic Regression problems | http://arxiv.org/abs/1704.00828 | id:1704.00828 author:Léo Françoso Dal Piccol Sotto, Vinícius Veloso de Melo category:cs.NE math.PR stat.ML  published:2017-04-03 summary:Traditional Linear Genetic Programming (LGP) algorithms are based only on the selection mechanism to guide the search. Genetic operators combine or mutate random portions of the individuals, without knowing if the result will lead to a fitter individual. Probabilistic Model Building Genetic Programming (PMB-GP) methods were proposed to overcome this issue through a probability model that captures the structure of the fit individuals and use it to sample new individuals. This work proposes the use of LGP with a Stochastic Context-Free Grammar (SCFG), that has a probability distribution that is updated according to selected individuals. We proposed a method for adapting the grammar into the linear representation of LGP. Tests performed with the proposed probabilistic method, and with two hybrid approaches, on several symbolic regression benchmark problems show that the results are statistically better than the obtained by the traditional LGP. version:1
arxiv-1704-00794 | Time Series Cluster Kernel for Learning Similarities between Multivariate Time Series with Missing Data | http://arxiv.org/abs/1704.00794 | id:1704.00794 author:Karl Øyvind Mikalsen, Filippo Maria Bianchi, Cristina Soguero-Ruiz, Robert Jenssen category:stat.ML cs.LG  published:2017-04-03 summary:Similarity-based approaches represent a promising direction for time series analysis. However, many such methods rely on parameter tuning and have shortcomings if the time series are multivariate (MTS) and contain missing data. In this paper, we address these challenges within the powerful context of kernel methods by proposing the robust \emph{time series cluster kernel} (TCK). The approach taken is to leverage the missing data handling properties of Gaussian mixture models (GMM) augmented with informative prior distributions. An ensemble learning approach is exploited to ensure robustness to parameters by combining the clustering results of many GMM to form the final kernel. We evaluate the TCK on synthetic and real data and compare to other state-of-the-art techniques. The experimental results demonstrate that the TCK is robust to parameter choices, provides competitive results for MTS without missing data and outstanding results for missing data. version:1
arxiv-1704-00784 | Online and Linear-Time Attention by Enforcing Monotonic Alignments | http://arxiv.org/abs/1704.00784 | id:1704.00784 author:Colin Raffel, Thang Luong, Peter J. Liu, Ron J. Weiss, Douglas Eck category:cs.LG cs.CL  published:2017-04-03 summary:Recurrent neural network models with an attention mechanism have proven to be extremely effective on a wide variety of sequence-to-sequence problems. However, the fact that soft attention mechanisms perform a pass over the entire input sequence when producing each element in the output sequence precludes their use in online settings and results in a quadratic time complexity. Based on the insight that the alignment between input and output sequence elements is monotonic in many problems of interest, we propose an end-to-end differentiable method for learning monotonic alignments which, at test time, enables computing attention online and in linear time. We validate our approach on sentence summarization, machine translation, and online speech recognition problems and achieve results competitive with existing sequence-to-sequence models. version:1
arxiv-1704-00783 | Brief Notes on Hard Takeoff, Value Alignment, and Coherent Extrapolated Volition | http://arxiv.org/abs/1704.00783 | id:1704.00783 author:Gopal P. Sarma category:cs.AI cs.CY cs.LG  published:2017-04-03 summary:I make some basic observations about hard takeoff, value alignment, and coherent extrapolated volition, concepts which have been central in analyses of superintelligent AI systems. version:1
arxiv-1704-00773 | A comparative study of counterfactual estimators | http://arxiv.org/abs/1704.00773 | id:1704.00773 author:Thomas Nedelec, Nicolas Le Roux, Vianney Perchet category:stat.ML cs.LG  published:2017-04-03 summary:We provide a comparative study of several widely used off-policy estimators (Empirical Average, Basic Importance Sampling and Normalized Importance Sampling), detailing the different regimes where they are individually suboptimal. We then exhibit properties optimal estimators should possess. In the case where examples have been gathered using multiple policies, we show that fused estimators dominate basic ones but can still be improved. version:1
arxiv-1704-00767 | Geometric Insights into Support Vector Machine Behavior using the KKT Conditions | http://arxiv.org/abs/1704.00767 | id:1704.00767 author:Iain Carmichael, J. S. Marron category:stat.ML cs.LG  published:2017-04-03 summary:The Support Vector Machine (SVM) is a powerful and widely used classification algorithm. Its performance is well known to be impacted by a tuning parameter which is frequently selected by cross-validation. This paper uses the Karush-Kuhn-Tucker conditions to provide rigorous mathematical proof for new insights into the behavior of SVM in the large and small tuning parameter regimes. These insights provide perhaps unexpected relationships between SVM and naive Bayes and maximal data piling directions. We explore how characteristics of the training data affect the behavior of SVM in many cases including: balanced vs. unbalanced classes, low vs. high dimension, separable vs. non-separable data. These results present a simple explanation of SVM's behavior as a function of the tuning parameter. We also elaborate on the geometry of complete data piling directions in high dimensional space. The results proved in this paper suggest important implications for tuning SVM with cross-validation. version:1
arxiv-1704-00764 | A Genetic Programming Approach to Designing Convolutional Neural Network Architectures | http://arxiv.org/abs/1704.00764 | id:1704.00764 author:Masanori Suganuma, Shinichi Shirakawa, Tomoharu Nagao category:cs.NE  published:2017-04-03 summary:The convolutional neural network (CNN), which is one of the deep learning models, has seen much success in a variety of computer vision tasks. However, designing CNN architectures still requires expert knowledge and a lot of trial and error. In this paper, we attempt to automatically construct CNN architectures for an image classification task based on Cartesian genetic programming (CGP). In our method, we adopt highly functional modules, such as convolutional blocks and tensor concatenation, as the node functions in CGP. The CNN structure and connectivity represented by the CGP encoding method are optimized to maximize the validation accuracy. To evaluate the proposed method, we constructed a CNN architecture for the image classification task with the CIFAR-10 dataset. The experimental result shows that the proposed method can be used to automatically find the competitive CNN architecture compared with state-of-the-art models. version:1
arxiv-1704-00763 | AMC: Attention guided Multi-modal Correlation Learning for Image Search | http://arxiv.org/abs/1704.00763 | id:1704.00763 author:Kan Chen, Trung Bui, Fang Chen, Zhaowen Wang, Ram Nevatia category:cs.CV  published:2017-04-03 summary:Given a user's query, traditional image search systems rank images according to its relevance to a single modality (e.g., image content or surrounding text). Nowadays, an increasing number of images on the Internet are available with associated meta data in rich modalities (e.g., titles, keywords, tags, etc.), which can be exploited for better similarity measure with queries. In this paper, we leverage visual and textual modalities for image search by learning their correlation with input query. According to the intent of query, attention mechanism can be introduced to adaptively balance the importance of different modalities. We propose a novel Attention guided Multi-modal Correlation (AMC) learning method which consists of a jointly learned hierarchy of intra and inter-attention networks. Conditioned on query's intent, intra-attention networks (i.e., visual intra-attention network and language intra-attention network) attend on informative parts within each modality; a multi-modal inter-attention network promotes the importance of the most query-relevant modalities. In experiments, we evaluate AMC models on the search logs from two real world image search engines and show a significant boost on the ranking of user-clicked images in search results. Additionally, we extend AMC models to caption ranking task on COCO dataset and achieve competitive results compared with recent state-of-the-arts. version:1
arxiv-1704-00758 | Unsupervised Action Proposal Ranking through Proposal Recombination | http://arxiv.org/abs/1704.00758 | id:1704.00758 author:Waqas Sultani, Dong Zhang, Mubarak Shah category:cs.CV  published:2017-04-03 summary:Recently, action proposal methods have played an important role in action recognition tasks, as they reduce the search space dramatically. Most unsupervised action proposal methods tend to generate hundreds of action proposals which include many noisy, inconsistent, and unranked action proposals, while supervised action proposal methods take advantage of predefined object detectors (e.g., human detector) to refine and score the action proposals, but they require thousands of manual annotations to train. Given the action proposals in a video, the goal of the proposed work is to generate a few better action proposals that are ranked properly. In our approach, we first divide action proposal into sub-proposal and then use Dynamic Programming based graph optimization scheme to select the optimal combinations of sub-proposals from different proposals and assign each new proposal a score. We propose a new unsupervised image-based actioness detector that leverages web images and employs it as one of the node scores in our graph formulation. Moreover, we capture motion information by estimating the number of motion contours within each action proposal patch. The proposed method is an unsupervised method that neither needs bounding box annotations nor video level labels, which is desirable with the current explosion of large-scale action datasets. Our approach is generic and does not depend on a specific action proposal method. We evaluate our approach on several publicly available trimmed and un-trimmed datasets and obtain better performance compared to several proposal ranking methods. In addition, we demonstrate that properly ranked proposals produce significantly better action detection as compared to state-of-the-art proposal based methods. version:1
arxiv-1704-00756 | Multi-Advisor Reinforcement Learning | http://arxiv.org/abs/1704.00756 | id:1704.00756 author:Romain Laroche, Mehdi Fatemi, Joshua Romoff, Harm van Seijen category:cs.LG cs.AI stat.ML  published:2017-04-03 summary:This article deals with a novel branch of Separation of Concerns, called Multi-Advisor Reinforcement Learning (MAd-RL), where a single-agent RL problem is distributed to $n$ learners, called advisors. Each advisor tries to solve the problem with a different focus. Their advice is then communicated to an aggregator, which is in control of the system. For the local training, three off-policy bootstrapping methods are proposed and analysed: local-max bootstraps with the local greedy action, rand-policy bootstraps with respect to the random policy, and agg-policy bootstraps with respect to the aggregator's greedy policy. MAd-RL is positioned as a generalisation of Reinforcement Learning with Ensemble methods. An experiment is held on a simplified version of the Ms. Pac-Man Atari game. The results confirm the theoretical relative strengths and weaknesses of each method. version:1
arxiv-1704-00717 | It Takes Two to Tango: Towards Theory of AI's Mind | http://arxiv.org/abs/1704.00717 | id:1704.00717 author:Arjun Chandrasekaran, Deshraj Yadav, Prithvijit Chattopadhyay, Viraj Prabhu, Devi Parikh category:cs.CV cs.AI cs.CL  published:2017-04-03 summary:Theory of Mind is the ability to attribute mental states (beliefs, intents, knowledge, perspectives, etc.) to others and recognize that these mental states may differ from one's own. Theory of Mind is critical to effective communication and to teams demonstrating higher collective performance. To effectively leverage the progress in Artificial Intelligence (AI) to make our lives more productive, it is important for humans and AI to work well together in a team. Traditionally, there has been much emphasis on research to make AI more accurate, and (to a lesser extent) on having it better understand human intentions, tendencies, beliefs, and contexts. The latter involves making AI more human-like and having it develop a theory of our minds. In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind - get to know its strengths, weaknesses, beliefs, and quirks. We instantiate these ideas within the domain of Visual Question Answering (VQA). We find that using just a few examples(50), lay people can be trained to better predict responses and oncoming failures of a complex VQA model. Surprisingly, we find that having access to the model's internal states - its confidence in its top-k predictions, explicit or implicit attention maps which highlight regions in the image (and words in the question) the model is looking at (and listening to) while answering a question about an image - do not help people better predict its behavior version:1
arxiv-1704-00710 | Hierarchical Surface Prediction for 3D Object Reconstruction | http://arxiv.org/abs/1704.00710 | id:1704.00710 author:Christian Häne, Shubham Tulsiani, Jitendra Malik category:cs.CV  published:2017-04-03 summary:Recently, Convolutional Neural Networks have shown promising results for 3D geometry prediction. They can make predictions from very little input data such as for example a single color image, depth map or a partial 3D volume. A major limitation of such approaches is that they only predict a coarse resolution voxel grid, which does not capture the surface of the objects well. We propose a general framework, called hierarchical surface prediction (HSP), which facilitates prediction of high resolution voxel grids. The main insight is that it is sufficient to predict high resolution voxels around the predicted surfaces. The exterior and interior of the objects can be represented with coarse resolution voxels. This allows us to predict significantly higher resolution voxel grids around the surface, from which triangle meshes can be extracted. Our approach is general and not dependent on a specific input type. In our experiments, we show results for geometry prediction from color images, depth images and shape completion from partial voxel grids. Our analysis shows that the network is able to predict the surface more accurately than a low resolution prediction. version:1
arxiv-1704-00708 | No Spurious Local Minima in Nonconvex Low Rank Problems: A Unified Geometric Analysis | http://arxiv.org/abs/1704.00708 | id:1704.00708 author:Rong Ge, Chi Jin, Yi Zheng category:cs.LG math.OC stat.ML  published:2017-04-03 summary:In this paper we develop a new framework that captures the common landscape underlying the common non-convex low-rank matrix problems including matrix sensing, matrix completion and robust PCA. In particular, we show for all above problems (including asymmetric cases): 1) all local minima are also globally optimal; 2) no high-order saddle points exists. These results explain why simple algorithms such as stochastic gradient descent have global converge, and efficiently optimize these non-convex objective functions in practice. Our framework connects and simplifies the existing analyses on optimization landscapes for matrix sensing and symmetric matrix completion. The framework naturally leads to new results for asymmetric matrix completion and robust PCA. version:1
arxiv-1704-00705 | Graph Partitioning with Acyclicity Constraints | http://arxiv.org/abs/1704.00705 | id:1704.00705 author:Orlando Moreira, Merten Popp, Christian Schulz category:cs.DS cs.CV cs.DC  published:2017-04-03 summary:Graphs are widely used to model execution dependencies in applications. In particular, the NP-complete problem of partitioning a graph under constraints receives enormous attention by researchers because of its applicability in multiprocessor scheduling. We identified the additional constraint of acyclic dependencies between blocks when mapping computer vision and imaging applications to a heterogeneous embedded multiprocessor. Existing algorithms and heuristics do not address this requirement and deliver results that are not applicable for our use-case. In this work, we show that this more constrained version of the graph partitioning problem is NP-complete and present heuristics that achieve a close approximation of the optimal solution found by an exhaustive search for small problem instances and much better scalability for larger instances. In addition, we can show a positive impact on the schedule of a real imaging application that improves communication volume and execution time. version:1
arxiv-1704-00702 | Multi-rendezvous Spacecraft Trajectory Optimization with Beam P-ACO | http://arxiv.org/abs/1704.00702 | id:1704.00702 author:Luís F. Simões, Dario Izzo, Evert Haasdijk, A. E. Eiben category:cs.NE physics.space-ph I.2.8  published:2017-04-03 summary:The design of spacecraft trajectories for missions visiting multiple celestial bodies is here framed as a multi-objective bilevel optimization problem. A comparative study is performed to assess the performance of different Beam Search algorithms at tackling the combinatorial problem of finding the ideal sequence of bodies. Special focus is placed on the development of a new hybridization between Beam Search and the Population-based Ant Colony Optimization algorithm. An experimental evaluation shows all algorithms achieving exceptional performance on a hard benchmark problem. It is found that a properly tuned deterministic Beam Search always outperforms the remaining variants. Beam P-ACO, however, demonstrates lower parameter sensitivity, while offering superior worst-case performance. Being an anytime algorithm, it is then found to be the preferable choice for certain practical applications. version:1
arxiv-1704-00675 | The 2017 DAVIS Challenge on Video Object Segmentation | http://arxiv.org/abs/1704.00675 | id:1704.00675 author:Jordi Pont-Tuset, Federico Perazzi, Sergi Caelles, Pablo Arbeláez, Alex Sorkine-Hornung, Luc Van Gool category:cs.CV  published:2017-04-03 summary:We present the 2017 DAVIS Challenge, a public competition specifically designed for the task of video object segmentation. Following the footsteps of other successful initiatives, such as ILSVRC and PASCAL VOC, which established the avenue of research in the fields of scene classification and semantic segmentation, the DAVIS Challenge comprises a dataset, an evaluation methodology, and a public competition with a dedicated workshop co-located with CVPR 2017. The DAVIS Challenge follows up on the recent publication of DAVIS (Densely-Annotated VIdeo Segmentation), which has fostered the development of several novel state-of-the-art video object segmentation techniques. In this paper we describe the scope of the benchmark, highlight the main characteristics of the dataset and define the evaluation metrics of the competition. version:1
arxiv-1703-10757 | Diabetic Retinopathy Detection via Deep Convolutional Networks for Discriminative Localization and Visual Explanation | http://arxiv.org/abs/1703.10757 | id:1703.10757 author:Zhiguang Wang, Jianbo Yang category:cs.CV cs.LG cs.NE  published:2017-03-31 summary:We proposed a deep learning method for interpretable diabetic retinopathy (DR) detection. The visual-interpretable feature of the proposed method is achieved by adding the regression activation map (RAM) after the global averaging pooling layer of the convolutional networks (CNN). With RAM, the proposed model can localize the discriminative regions of an retina image to show the specific region of interest in terms of its severity level. We believe this advantage of the proposed deep learning model is highly desired for DR detection because in practice, users are not only interested with high prediction performance, but also keen to understand the insights of DR detection and why the adopted learning model works. In the experiments conducted on a large scale of retina image dataset, we show that the proposed CNN model can achieve high performance on DR detection compared with the state-of-the-art while achieving the merits of providing the RAM to highlight the salient regions of the input image. version:2
arxiv-1704-00656 | Detection and Resolution of Rumours in Social Media: A Survey | http://arxiv.org/abs/1704.00656 | id:1704.00656 author:Arkaitz Zubiaga, Ahmet Aker, Kalina Bontcheva, Maria Liakata, Rob Procter category:cs.CL cs.HC cs.IR cs.SI  published:2017-04-03 summary:Despite the increasing use of social media platforms for information and news gathering, its unmoderated nature often leads to the emergence and spread of rumours, i.e. pieces of information that are unverified at the time of posting. At the same time, the openness of social media platforms provides opportunities to study how users share and discuss rumours, and to explore how natural language processing and data mining techniques may be used to find ways of determining their veracity. In this survey we introduce and discuss two types of rumours that circulate on social media; long-standing rumours that circulate for long periods of time, and newly-emerging rumours spawned during fast-paced events such as breaking news, where reports are released piecemeal and often with an unverified status in their early stages. We provide an overview of research into social media rumours with the ultimate goal of developing a rumour classification system that consists of four components: rumour detection, rumour tracking, rumour stance classification and rumour veracity classification. We delve into the approaches presented in the scientific literature for the development of each of these four components. We summarise the efforts and achievements so far towards the development of rumour classification systems and conclude with suggestions for avenues for future research in social media mining for detection and resolution of rumours. version:1
arxiv-1704-00648 | Soft-to-Hard Vector Quantization for End-to-End Learned Compression of Images and Neural Networks | http://arxiv.org/abs/1704.00648 | id:1704.00648 author:Eirikur Agustsson, Fabian Mentzer, Michael Tschannen, Lukas Cavigelli, Radu Timofte, Luca Benini, Luc Van Gool category:cs.LG cs.CV  published:2017-04-03 summary:In this work we present a new approach to learn compressible representations in deep architectures with an end-to-end training strategy. Our method is based on a soft relaxation of quantization and entropy, which we anneal to their discrete counterparts throughout training. We showcase this method for two challenging applications: Image compression and neural network compression. While these tasks have typically been approached with different methods, our soft-to-hard quantization approach gives state-of-the-art results for both. version:1
arxiv-1704-00646 | A correlation game for unsupervised learning yields computational interpretations of Hebbian excitation, anti-Hebbian inhibition, and synapse elimination | http://arxiv.org/abs/1704.00646 | id:1704.00646 author:H. Sebastian Seung, Jonathan Zung category:cs.NE q-bio.NC  published:2017-04-03 summary:Much has been learned about plasticity of biological synapses from empirical studies. Hebbian plasticity is driven by correlated activity of presynaptic and postsynaptic neurons. Synapses that converge onto the same neuron often behave as if they compete for a fixed resource; some survive the competition while others are eliminated. To provide computational interpretations of these aspects of synaptic plasticity, we formulate unsupervised learning as a zero-sum game between Hebbian excitation and anti-Hebbian inhibition in a neural network model. The game formalizes the intuition that Hebbian excitation tries to maximize correlations of neurons with their inputs, while anti-Hebbian inhibition tries to decorrelate neurons from each other. We further include a model of synaptic competition, which enables a neuron to eliminate all connections except those from its most strongly correlated inputs. Through empirical studies, we show that this facilitates the learning of sensory features that resemble parts of objects. version:1
arxiv-1704-00642 | Local nearest neighbour classification with applications to semi-supervised learning | http://arxiv.org/abs/1704.00642 | id:1704.00642 author:Timothy I. Cannings, Thomas B. Berrett, Richard J. Samworth category:math.ST cs.CV cs.LG stat.ME stat.TH 62G20  published:2017-04-03 summary:We derive a new asymptotic expansion for the global excess risk of a local $k$-nearest neighbour classifier, where the choice of $k$ may depend upon the test point. This expansion elucidates conditions under which the dominant contribution to the excess risk comes from the locus of points at which each class label is equally likely to occur, but we also show that if these conditions are not satisfied, the dominant contribution may arise from the tails of the marginal distribution of the features. Moreover, we prove that, provided the $d$-dimensional marginal distribution of the features has a finite $\rho$th moment for some $\rho > 4$ (as well as other regularity conditions), a local choice of $k$ can yield a rate of convergence of the excess risk of $O(n^{-4/(d+4)})$, where $n$ is the sample size, whereas for the standard $k$-nearest neighbour classifier, our theory would require $d \geq 5$ and $\rho > 4d/(d-4)$ finite moments to achieve this rate. Our results motivate a new $k$-nearest neighbour classifier for semi-supervised learning problems, where the unlabelled data are used to obtain an estimate of the marginal feature density, and fewer neighbours are used for classification when this density estimate is small. The potential improvements over the standard $k$-nearest neighbour classifier are illustrated both through our theory and via a simulation study. version:1
arxiv-1704-01184 | On the Unreported-Profile-is-Negative Assumption for Predictive Cheminformatics | http://arxiv.org/abs/1704.01184 | id:1704.01184 author:Chao Lan, Sai Nivedita Chandrasekaran, Jun Huan category:cs.LG physics.chem-ph stat.ML  published:2017-04-03 summary:The study of compound-target binding profiles has been a central theme in cheminformatics. For data repositories that only provide positive binding profiles, a popular assumption is that all unreported profiles are negative. In this paper, we caution audience not to take such assumptions for granted. Under a problem setting where binding profiles are used as features to train predictive models, we present empirical evidence that (1) predictive performance degrades when the assumption fails and (2) explicit recovery of unreported profiles improves predictive performance. In particular, we propose a joint framework of profile recovery and supervised learning, which shows further performance improvement. Our study not only calls for more careful treatment of unreported profiles in cheminformatics, but also initiates a new machine learning problem which we called Learning with Positive and Unknown Features. version:1
arxiv-1704-00637 | Semi-Supervised Generation with Cluster-aware Generative Models | http://arxiv.org/abs/1704.00637 | id:1704.00637 author:Lars Maaløe, Marco Fraccaro, Ole Winther category:stat.ML cs.AI cs.LG  published:2017-04-03 summary:Deep generative models trained with large amounts of unlabelled data have proven to be powerful within the domain of unsupervised learning. Many real life data sets contain a small amount of labelled data points, that are typically disregarded when training generative models. We propose the Cluster-aware Generative Model, that uses unlabelled information to infer a latent representation that models the natural clustering of the data, and additional labelled data points to refine this clustering. The generative performances of the model significantly improve when labelled information is exploited, obtaining a log-likelihood of -79.38 nats on permutation invariant MNIST, while also achieving competitive semi-supervised classification accuracies. The model can also be trained fully unsupervised, and still improve the log-likelihood performance with respect to related methods. version:1
arxiv-1704-00616 | Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection | http://arxiv.org/abs/1704.00616 | id:1704.00616 author:Mohammadreza Zolfaghari, Gabriel L. Oliveira, Nima Sedaghat, Thomas Brox category:cs.CV cs.AI cs.HC cs.MM cs.NE  published:2017-04-03 summary:General human action recognition requires understanding of various visual cues. In this paper, we propose a network architecture that computes and integrates the most important visual cues for action recognition: pose, motion, and the raw images. For the integration, we introduce a Markov chain model which adds cues successively. The resulting approach is efficient and applicable to action classification as well as to spatial and temporal action localization. The two contributions clearly improve the performance over respective baselines. The overall approach achieves state-of-the-art action classification performance on HMDB51, J-HMDB and NTU RGB+D datasets. Moreover, it yields state-of-the-art spatio-temporal action localization results on UCF101 and J-HMDB. version:1
arxiv-1704-00559 | Neural Lattice-to-Sequence Models for Uncertain Inputs | http://arxiv.org/abs/1704.00559 | id:1704.00559 author:Matthias Sperber, Graham Neubig, Jan Niehues, Alex Waibel category:cs.CL  published:2017-04-03 summary:The input to a neural sequence-to-sequence model is often determined by an up-stream system, e.g. a word segmenter, part of speech tagger, or speech recognizer. These up-stream models are potentially error-prone. Representing inputs through word lattices allows making this uncertainty explicit by capturing alternative sequences and their posterior probabilities in a compact form. In this work, we extend the TreeLSTM (Tai et al., 2015) into a LatticeLSTM that is able to consume word lattices, and can be used as encoder in an attentional encoder-decoder model. We integrate lattice posterior scores into this architecture by extending the TreeLSTM's child-sum and forget gates and introducing a bias term into the attention mechanism. We experiment with speech translation lattices and report consistent improvements over baselines that translate either the 1-best hypothesis or the lattice without posterior scores. version:1
arxiv-1703-08987 | LIDAR-based Driving Path Generation Using Fully Convolutional Neural Networks | http://arxiv.org/abs/1703.08987 | id:1703.08987 author:Luca Caltagirone, Mauro Bellone, Lennart Svensson, Mattias Wahde category:cs.CV  published:2017-03-27 summary:In this work, a novel learning-based approach has been developed to generate driving paths by integrating LIDAR point clouds, GPS-IMU information, and Google driving directions. The system is based on a fully convolutional neural network that jointly learns to carry out perception and path generation from real-world driving sequences and that is trained using automatically generated training examples. Several combinations of input data were tested in order to assess the performance gain provided by specific information modalities. The fully convolutional neural network trained using all the available sensors together with driving directions achieved the best MaxF score of 88.13% when considering a region of interest of 60x60 meters. By considering a smaller region of interest, the agreement between predicted paths and ground-truth increased to 92.60%. The positive results obtained in this work indicate that the proposed system may help fill the gap between low-level scene parsing and behavior-reflex approaches by generating outputs that are close to vehicle control and at the same time human-interpretable. version:2
arxiv-1704-00541 | Dictionary-based Tensor Canonical Polyadic Decomposition | http://arxiv.org/abs/1704.00541 | id:1704.00541 author:Jérémy E. Cohen, Nicolas Gillis category:stat.ML  published:2017-04-03 summary:To ensure interpretability of extracted sources in tensor decomposition, we introduce in this paper a dictionary-based tensor canonical polyadic decomposition which enforces one factor to belong exactly to a known dictionary. A new formulation of sparse coding is proposed which enables high dimensional tensors dictionary-based canonical polyadic decomposition. The benefits of using a dictionary in tensor decomposition models are explored both in terms of parameter identifiability and estimation accuracy. This is illustrated on the decomposition of simulated data and on the unmixing of hyperspectral images. version:1
arxiv-1704-00529 | 3D Object Reconstruction from Hand-Object Interactions | http://arxiv.org/abs/1704.00529 | id:1704.00529 author:Dimitrios Tzionas, Juergen Gall category:cs.CV  published:2017-04-03 summary:Recent advances have enabled 3d object reconstruction approaches using a single off-the-shelf RGB-D camera. Although these approaches are successful for a wide range of object classes, they rely on stable and distinctive geometric or texture features. Many objects like mechanical parts, toys, household or decorative articles, however, are textureless and characterized by minimalistic shapes that are simple and symmetric. Existing in-hand scanning systems and 3d reconstruction techniques fail for such symmetric objects in the absence of highly distinctive features. In this work, we show that extracting 3d hand motion for in-hand scanning effectively facilitates the reconstruction of even featureless and highly symmetric objects and we present an approach that fuses the rich additional information of hands into a 3d reconstruction pipeline, significantly contributing to the state-of-the-art of in-hand scanning. version:1
arxiv-1704-00524 | Block-Matching Convolutional Neural Network for Image Denoising | http://arxiv.org/abs/1704.00524 | id:1704.00524 author:Byeongyong Ahn, Nam Ik Cho category:cs.CV  published:2017-04-03 summary:There are two main streams in up-to-date image denoising algorithms: non-local self similarity (NSS) prior based methods and convolutional neural network (CNN) based methods. The NSS based methods are favorable on images with regular and repetitive patterns while the CNN based methods perform better on irregular structures. In this paper, we propose a block-matching convolutional neural network (BMCNN) method that combines NSS prior and CNN. Initially, similar local patches in the input image are integrated into a 3D block. In order to prevent the noise from messing up the block matching, we first apply an existing denoising algorithm on the noisy image. The denoised image is employed as a pilot signal for the block matching, and then denoising function for the block is learned by a CNN structure. Experimental results show that the proposed BMCNN algorithm achieves state-of-the-art performance. In detail, BMCNN can restore both repetitive and irregular structures. version:1
arxiv-1704-00520 | Efficient acquisition rules for model-based approximate Bayesian computation | http://arxiv.org/abs/1704.00520 | id:1704.00520 author:Marko Järvenpää, Michael U. Gutmann, Aki Vehtari, Pekka Marttinen category:stat.ML stat.CO stat.ME  published:2017-04-03 summary:Approximate Bayesian computation (ABC) is a method for Bayesian inference when the likelihood is unavailable but simulating from the model is possible. However, many ABC algorithms require a large number of simulations, which can be costly. To reduce the computational cost, surrogate models and Bayesian optimisation (BO) have been proposed. Bayesian optimisation enables one to intelligently decide where to evaluate the model next, but standard BO strategies are designed for optimisation and not specifically for ABC inference. Our paper addresses this gap in the literature. We propose a new acquisition rule that selects the next evaluation where the uncertainty in the posterior distribution is largest. Experiments show that the proposed method often produces the most accurate approximations, especially in high-dimensional cases or in the presence of strong prior information, compared to common alternatives. version:1
arxiv-1704-00515 | Capturing Hand Motion with an RGB-D Sensor, Fusing a Generative Model with Salient Points | http://arxiv.org/abs/1704.00515 | id:1704.00515 author:Dimitrios Tzionas, Abhilash Srikantha, Pablo Aponte, Juergen Gall category:cs.CV  published:2017-04-03 summary:Hand motion capture has been an active research topic in recent years, following the success of full-body pose tracking. Despite similarities, hand tracking proves to be more challenging, characterized by a higher dimensionality, severe occlusions and self-similarity between fingers. For this reason, most approaches rely on strong assumptions, like hands in isolation or expensive multi-camera systems, that limit the practical use. In this work, we propose a framework for hand tracking that can capture the motion of two interacting hands using only a single, inexpensive RGB-D camera. Our approach combines a generative model with collision detection and discriminatively learned salient points. We quantitatively evaluate our approach on 14 new sequences with challenging interactions. version:1
arxiv-1704-00514 | Multi-Task Learning of Keyphrase Boundary Classification | http://arxiv.org/abs/1704.00514 | id:1704.00514 author:Isabelle Augenstein, Anders Søgaard category:cs.CL cs.AI stat.ML  published:2017-04-03 summary:Keyphrase boundary classification (KBC) is the task of detecting keyphrases in scientific articles and labelling them with respect to predefined types. Although important in practice, this task is so far underexplored, partly due to the lack of labelled data. To overcome this, we explore several auxiliary tasks, including semantic super-sense tagging and identification of multi-word expressions, and cast the task as a multi-task learning problem with deep recurrent neural networks. Our multi-task models perform significantly better than previous state of the art approaches on two scientific KBC datasets, particularly for long keyphrases. version:1
arxiv-1704-00509 | Truncating Wide Networks using Binary Tree Architectures | http://arxiv.org/abs/1704.00509 | id:1704.00509 author:Yan Zhang, Mete Ozay, Shuohao Li, Takayuki Okatani category:cs.CV  published:2017-04-03 summary:Recent study shows that a wide deep network can obtain accuracy comparable to a deeper but narrower network. Compared to narrower and deeper networks, wide networks employ relatively less number of layers and have various important benefits, such that they have less running time on parallel computing devices, and they are less affected by gradient vanishing problems. However, the parameter size of a wide network can be very large due to use of large width of each layer in the network. In order to keep the benefits of wide networks meanwhile improve the parameter size and accuracy trade-off of wide networks, we propose a binary tree architecture to truncate architecture of wide networks by reducing the width of the networks. More precisely, in the proposed architecture, the width is continuously reduced from lower layers to higher layers in order to increase the expressive capacity of network with a less increase on parameter size. Also, to ease the gradient vanishing problem, features obtained at different layers are concatenated to form the output of our architecture. By employing the proposed architecture on a baseline wide network, we can construct and train a new network with same depth but considerably less number of parameters. In our experimental analyses, we observe that the proposed architecture enables us to obtain better parameter size and accuracy trade-off compared to baseline networks using various benchmark image classification datasets. The results show that our model can decrease the classification error of baseline from 20.43% to 19.22% on Cifar-100 using only 28% of parameters that baseline has. Code is available at https://github.com/ZhangVision/bitnet. version:1
arxiv-1704-00498 | Convolutional neural networks for segmentation and object detection of human semen | http://arxiv.org/abs/1704.00498 | id:1704.00498 author:Malte Stær Nissen, Oswin Krause, Kristian Almstrup, Søren Kjærulff, Torben Trindkær Nielsen, Mads Nielsen category:cs.CV  published:2017-04-03 summary:We compare a set of convolutional neural network (CNN) architectures for the task of segmenting and detecting human sperm cells in an image taken from a semen sample. In contrast to previous work, samples are not stained or washed to allow for full sperm quality analysis, making analysis harder due to clutter. Our results indicate that training on full images is superior to training on patches when class-skew is properly handled. Full image training including up-sampling during training proves to be beneficial in deep CNNs for pixel wise accuracy and detection performance. Predicted sperm cells are found by using connected components on the CNN predictions. We investigate optimization of a threshold parameter on the size of detected components. Our best network achieves 93.87% precision and 91.89% recall on our test dataset after thresholding outperforming a classical mage analysis approach. version:1
arxiv-1704-00492 | A Comparison of Directional Distances for Hand Pose Estimation | http://arxiv.org/abs/1704.00492 | id:1704.00492 author:Dimitrios Tzionas, Juergen Gall category:cs.CV  published:2017-04-03 summary:Benchmarking methods for 3d hand tracking is still an open problem due to the difficulty of acquiring ground truth data. We introduce a new dataset and benchmarking protocol that is insensitive to the accumulative error of other protocols. To this end, we create testing frame pairs of increasing difficulty and measure the pose estimation error separately for each of them. This approach gives new insights and allows to accurately study the performance of each feature or method without employing a full tracking pipeline. Following this protocol, we evaluate various directional distances in the context of silhouette-based 3d hand tracking, expressed as special cases of a generalized Chamfer distance form. An appropriate parameter setup is proposed for each of them, and a comparative study reveals the best performing method in this context. version:1
arxiv-1703-08991 | Multilabel Classification with R Package mlr | http://arxiv.org/abs/1703.08991 | id:1703.08991 author:Philipp Probst, Quay Au, Giuseppe Casalicchio, Clemens Stachl, Bernd Bischl category:stat.ML  published:2017-03-27 summary:We implemented several multilabel classification algorithms in the machine learning package mlr. The implemented methods are binary relevance, classifier chains, nested stacking, dependent binary relevance and stacking, which can be used with any base learner that is accessible in mlr. Moreover, there is access to the multilabel classification versions of randomForestSRC and rFerns. All these methods can be easily compared by different implemented multilabel performance measures and resampling methods in the standardized mlr framework. In a benchmark experiment with several multilabel datasets, the performance of the different methods is evaluated. version:2
arxiv-1704-00454 | Clustering in Hilbert simplex geometry | http://arxiv.org/abs/1704.00454 | id:1704.00454 author:Frank Nielsen, Ke Sun category:cs.LG cs.CV  published:2017-04-03 summary:Clustering categorical distributions in the probability simplex is a fundamental primitive often met in applications dealing with histograms or mixtures of multinomials. Traditionally, the differential-geometric structure of the probability simplex has been used either by (i) setting the Riemannian metric tensor to the Fisher information matrix of the categorical distributions, or (ii) defining the information-geometric structure induced by a smooth dissimilarity measure, called a divergence. In this paper, we introduce a novel computationally-friendly non-Riemannian framework for modeling the probability simplex: Hilbert simplex geometry. We discuss the pros and cons of those three statistical modelings, and compare them experimentally for clustering tasks. version:1
arxiv-1704-00447 | Learning a Variational Network for Reconstruction of Accelerated MRI Data | http://arxiv.org/abs/1704.00447 | id:1704.00447 author:Kerstin Hammernik, Teresa Klatzer, Erich Kobler, Michael P Recht, Daniel K Sodickson, Thomas Pock, Florian Knoll category:cs.CV  published:2017-04-03 summary:Purpose: To allow fast and high-quality reconstruction of clinical accelerated multi-coil MR data by learning a variational network that combines the mathematical structure of variational models with deep learning. Theory and Methods: Generalized compressed sensing reconstruction formulated as a variational model is embedded in an unrolled gradient descent scheme. All parameters of this formulation, including the prior model defined by filter kernels and activation functions as well as the data term weights, are learned during an offline training procedure. The learned model can then be applied online to previously unseen data. Results: The variational network approach is evaluated on a clinical knee imaging protocol. The variational network reconstructions outperform standard reconstruction algorithms in terms of image quality and residual artifacts for all tested acceleration factors and sampling patterns. Conclusion: Variational network reconstructions preserve the natural appearance of MR images as well as pathologies that were not included in the training data set. Due to its high computational performance, i.e., reconstruction time of 193 ms on a single graphics card, and the omission of parameter tuning once the network is trained, this new approach to image reconstruction can easily be integrated into clinical workflow. version:1
arxiv-1704-00445 | On Kernelized Multi-armed Bandits | http://arxiv.org/abs/1704.00445 | id:1704.00445 author:Sayak Ray Chowdhury, Aditya Gopalan category:cs.LG  published:2017-04-03 summary:We consider the stochastic bandit problem with a continuous set of arms, with the expected reward function over the arms assumed to be fixed but unknown. We provide two new Gaussian process-based algorithms for continuous bandit optimization-Improved GP-UCB (IGP-UCB) and GP-Thomson sampling (GP-TS), and derive corresponding regret bounds. Specifically, the bounds hold when the expected reward function belongs to the reproducing kernel Hilbert space (RKHS) that naturally corresponds to a Gaussian process kernel used as input by the algorithms. Along the way, we derive a new self-normalized concentration inequality for vector- valued martingales of arbitrary, possibly infinite, dimension. Finally, experimental evaluation and comparisons to existing algorithms on synthetic and real-world environments are carried out that highlight the favorable gains of the proposed strategies in many cases. version:1
arxiv-1704-00440 | Combining Lexical and Syntactic Features for Detecting Content-dense Texts in News | http://arxiv.org/abs/1704.00440 | id:1704.00440 author:Yinfei Yang, Ani Nenkova category:cs.CL  published:2017-04-03 summary:Content-dense news report important factual information about an event in direct, succinct manner. Information seeking applications such as information extraction, question answering and summarization normally assume all text they deal with is content-dense. Here we empirically test this assumption on news articles from the business, U.S. international relations, sports and science journalism domains. Our findings clearly indicate that about half of the news texts in our study are in fact not content-dense and motivate the development of a supervised content-density detector. We heuristically label a large training corpus for the task and train a two-layer classifying model based on lexical and unlexicalized syntactic features. On manually annotated data, we compare the performance of domain-specific classifiers, trained on data only from a given news domain and a general classifier in which data from all four domains is pooled together. Our annotation and prediction experiments demonstrate that the concept of content density varies depending on the domain and that naive annotators provide judgement biased toward the stereotypical domain label. Domain-specific classifiers are more accurate for domains in which content-dense texts are typically fewer. Domain independent classifiers reproduce better naive crowdsourced judgements. Classification prediction is high across all conditions, around 80%. version:1
arxiv-1704-00438 | A Good Practice Towards Top Performance of Face Recognition: Transferred Deep Feature Fusion | http://arxiv.org/abs/1704.00438 | id:1704.00438 author:Lin Xiong, Jayashree Karlekar, Jian Zhao, Jiashi Feng, Sugiri Pranata, Shengmei Shen category:cs.CV  published:2017-04-03 summary:Unconstrained face recognition performance evaluations have traditionally focused on Labeled Faces in the Wild (LFW) dataset for imagery and the YouTubeFaces (YTF) dataset for videos in the last couple of years. Spectacular progress in this field has resulted in a saturation on verification and identification accuracies for those benchmark datasets. In this paper, we propose a unified learning framework named transferred deep feature fusion targeting at the new IARPA Janus Bechmark A (IJB-A) face recognition dataset released by NIST face challenge. The IJB-A dataset includes real-world unconstrained faces from 500 subjects with full pose and illumination variations which are much harder than the LFW and YTF datasets. Inspired by transfer learning, we train two advanced deep convolutional neural networks (DCNN) with two different large datasets in source domain, respectively. By exploring the complementarity of two distinct DCNNs, deep feature fusion is utilized after feature extraction in target domain. Then, template specific linear SVMs is adopted to enhance the discrimination of framework. Finally, multiple matching scores corresponding different templates are merged as the final results. This simple unified framework outperforms the state-of-the-art by a wide margin on IJB-A dataset. Based on the proposed approach, we have submitted our IJB-A results to National Institute of Standards and Technology (NIST) for official evaluation. version:1
arxiv-1703-10798 | Semantic-driven Generation of Hyperlapse from $360^\circ$ Video | http://arxiv.org/abs/1703.10798 | id:1703.10798 author:Wei-Sheng Lai, Yujia Huang, Neel Joshi, Chris Buehler, Ming-Hsuan Yang, Sing Bing Kang category:cs.CV  published:2017-03-31 summary:We present a system for converting a fully panoramic ($360^\circ$) video into a normal field-of-view (NFOV) hyperlapse for an optimal viewing experience. Our system exploits visual saliency and semantics to non-uniformly sample in space and time for generating hyperlapses. In addition, users can optionally choose objects of interest for customizing the hyperlapses. We first stabilize an input $360^\circ$ video by smoothing the rotation between adjacent frames and then compute regions of interest and saliency scores. An initial hyperlapse is generated by optimizing the saliency and motion smoothness followed by the saliency-aware frame selection. We further smooth the result using an efficient 2D video stabilization approach that adaptively selects the motion model to generate the final hyperlapse. We validate the design of our system by showing results for a variety of scenes and comparing against the state-of-the-art method through a user study. version:2
arxiv-1703-10730 | Unsupervised Holistic Image Generation from Key Local Patches | http://arxiv.org/abs/1703.10730 | id:1703.10730 author:Donghoon Lee, Sangdoo Yun, Sungjoon Choi, Hwiyeon Yoo, Ming-Hsuan Yang, Songhwai Oh category:cs.CV  published:2017-03-31 summary:We introduce a new problem of generating an image based on a small number of key local patches without any geometric prior. In this work, key local patches are defined as informative regions of the target object or scene. This is a challenging problem since it requires generating realistic images and predicting locations of parts at the same time. We construct adversarial networks to tackle this problem. A generator network generates a fake image as well as a mask based on the encoder-decoder framework. On the other hand, a discriminator network aims to detect fake images. The network is trained with three losses to consider spatial, appearance, and adversarial information. The spatial loss determines whether the locations of predicted parts are correct. Input patches are restored in the output image without much modification due to the appearance loss. The adversarial loss ensures output images are realistic. The proposed network is trained without supervisory signals since no labels of key parts are required. Experimental results on six datasets demonstrate that the proposed algorithm performs favorably on challenging objects and scenes. version:2
arxiv-1703-10754 | On Self-Adaptive Mutation Restarts for Evolutionary Robotics with Real Rotorcraft | http://arxiv.org/abs/1703.10754 | id:1703.10754 author:Gerard David Howard category:cs.NE cs.RO  published:2017-03-31 summary:Self-adaptive parameters are increasingly used in the field of Evolutionary Robotics, as they allow key evolutionary rates to vary autonomously in a context-sensitive manner throughout the optimisation process. A significant limitation to self-adaptive mutation is that rates can be set unfavourably, which hinders convergence. Rate restarts are typically employed to remedy this, but thus far have only been applied in Evolutionary Robotics for mutation-only algorithms. This paper focuses on the level at which evolutionary rate restarts are applied in population-based algorithms with more than 1 evolutionary operator. After testing on a real hexacopter hovering task, we conclude that individual-level restarting results in higher fitness solutions without fitness stagnation, and population restarts provide a more stable rate evolution. Without restarts, experiments can become stuck in suboptimal controller/rate combinations which can be difficult to escape from. version:2
arxiv-1704-00390 | Geometric loss functions for camera pose regression with deep learning | http://arxiv.org/abs/1704.00390 | id:1704.00390 author:Alex Kendall, Roberto Cipolla category:cs.CV  published:2017-04-02 summary:Deep learning has shown to be effective for robust and real-time monocular image relocalisation. In particular, PoseNet is a deep convolutional neural network which learns to regress the 6-DOF camera pose from a single image. It learns to localize using high level features and is robust to difficult lighting, motion blur and unknown camera intrinsics, where point based SIFT registration fails. However, it was trained using a naive loss function, with hyper-parameters which require expensive tuning. In this paper, we give the problem a more fundamental theoretical treatment. We explore a number of novel loss functions for learning camera pose which are based on geometry and scene reprojection error. Additionally we show how to automatically learn an optimal weighting to simultaneously regress position and orientation. By leveraging geometry, we demonstrate that our technique significantly improves PoseNet's performance across datasets ranging from indoor rooms to a small city. version:1
arxiv-1704-00389 | Hidden Two-Stream Convolutional Networks for Action Recognition | http://arxiv.org/abs/1704.00389 | id:1704.00389 author:Yi Zhu, Zhenzhong Lan, Shawn Newsam, Alexander G. Hauptmann category:cs.CV cs.LG cs.MM  published:2017-04-02 summary:Analyzing videos of human actions involves understanding the temporal relationships among video frames. CNNs are the current state-of-the-art methods for action recognition in videos. However, the CNN architectures currently being used have difficulty in capturing these relationships. State-of-the-art action recognition approaches rely on traditional local optical flow estimation methods to pre-compute the motion information for CNNs. Such a two-stage approach is computationally expensive, storage demanding, and not end-to-end trainable. In this paper, we present a novel CNN architecture that implicitly captures motion information. Our method is 10x faster than a two-stage approach, does not need to cache flow information, and is end-to-end trainable. Experimental results on UCF101 and HMDB51 show that it achieves competitive accuracy with the two-stage approaches. version:1
arxiv-1704-00387 | Identifying networks with common organizational principles | http://arxiv.org/abs/1704.00387 | id:1704.00387 author:Anatol E. Wegner, Luis Ospina-Forero, Robert E. Gaunt, Charlotte M. Deane, Gesine Reinert category:stat.ML cs.SI physics.soc-ph  published:2017-04-02 summary:Many complex systems can be represented as networks, and the problem of network comparison is becoming increasingly relevant. There are many techniques for network comparison, from simply comparing network summary statistics to sophisticated but computationally costly alignment-based approaches. Yet it remains challenging to accurately cluster networks that are of a different size and density, but hypothesized to be structurally similar. In this paper, we address this problem by introducing a new network comparison methodology that is aimed at identifying common organizational principles in networks. The methodology is simple, intuitive and applicable in a wide variety of settings ranging from the functional classification of proteins to tracking the evolution of a world trade network. version:1
arxiv-1612-05974 | An IoT Endpoint System-on-Chip for Secure and Energy-Efficient Near-Sensor Analytics | http://arxiv.org/abs/1612.05974 | id:1612.05974 author:Francesco Conti, Robert Schilling, Pasquale Davide Schiavone, Antonio Pullini, Davide Rossi, Frank Kagan Gürkaynak, Michael Muehlberghuber, Michael Gautschi, Igor Loi, Germain Haugou, Stefan Mangard, Luca Benini category:cs.AR cs.LG  published:2016-12-18 summary:Near-sensor data analytics is a promising direction for IoT endpoints, as it minimizes energy spent on communication and reduces network load - but it also poses security concerns, as valuable data is stored or sent over the network at various stages of the analytics pipeline. Using encryption to protect sensitive data at the boundary of the on-chip analytics engine is a way to address data security issues. To cope with the combined workload of analytics and encryption in a tight power envelope, we propose Fulmine, a System-on-Chip based on a tightly-coupled multi-core cluster augmented with specialized blocks for compute-intensive data processing and encryption functions, supporting software programmability for regular computing tasks. The Fulmine SoC, fabricated in 65nm technology, consumes less than 20mW on average at 0.8V achieving an efficiency of up to 70pJ/B in encryption, 50pJ/px in convolution, or up to 25MIPS/mW in software. As a strong argument for real-life flexible application of our platform, we show experimental results for three secure analytics use cases: secure autonomous aerial surveillance with a state-of-the-art deep CNN consuming 3.16pJ per equivalent RISC op; local CNN-based face detection with secured remote recognition in 5.74pJ/op; and seizure detection with encrypted data collection from EEG within 12.7pJ/op. version:2
arxiv-1704-00380 | Word-Alignment-Based Segment-Level Machine Translation Evaluation using Word Embeddings | http://arxiv.org/abs/1704.00380 | id:1704.00380 author:Junki Matsuo, Mamoru Komachi, Katsuhito Sudoh category:cs.CL  published:2017-04-02 summary:One of the most important problems in machine translation (MT) evaluation is to evaluate the similarity between translation hypotheses with different surface forms from the reference, especially at the segment level. We propose to use word embeddings to perform word alignment for segment-level MT evaluation. We performed experiments with three types of alignment methods using word embeddings. We evaluated our proposed methods with various translation datasets. Experimental results show that our proposed methods outperform previous word embeddings-based methods. version:1
arxiv-1704-00367 | Provable Inductive Robust PCA via Iterative Hard Thresholding | http://arxiv.org/abs/1704.00367 | id:1704.00367 author:U. N. Niranjan, Arun Rajkumar, Theja Tulabandhula category:cs.LG cs.IT math.IT stat.ML  published:2017-04-02 summary:The robust PCA problem, wherein, given an input data matrix that is the superposition of a low-rank matrix and a sparse matrix, we aim to separate out the low-rank and sparse components, is a well-studied problem in machine learning. One natural question that arises is that, as in the inductive setting, if features are provided as input as well, can we hope to do better? Answering this in the affirmative, the main goal of this paper is to study the robust PCA problem while incorporating feature information. In contrast to previous works in which recovery guarantees are based on the convex relaxation of the problem, we propose a simple iterative algorithm based on hard-thresholding of appropriate residuals. Under weaker assumptions than previous works, we prove the global convergence of our iterative procedure; moreover, it admits a much faster convergence rate and lesser computational complexity per iteration. In practice, through systematic synthetic and real data simulations, we confirm our theoretical findings regarding improvements obtained by using feature information. version:1
arxiv-1704-00362 | Understanding Concept Drift | http://arxiv.org/abs/1704.00362 | id:1704.00362 author:Geoffrey I. Webb, Loong Kuan Lee, François Petitjean, Bart Goethals category:cs.LG  published:2017-04-02 summary:Concept drift is a major issue that greatly affects the accuracy and reliability of many real-world applications of machine learning. We argue that to tackle concept drift it is important to develop the capacity to describe and analyze it. We propose tools for this purpose, arguing for the importance of quantitative descriptions of drift in marginal distributions. We present quantitative drift analysis techniques along with methods for communicating their results. We demonstrate their effectiveness by application to three real-world learning tasks. version:1
arxiv-1704-00337 | Dense Multi-view 3D-reconstruction Without Dense Correspondences | http://arxiv.org/abs/1704.00337 | id:1704.00337 author:Yvain Quéau, Jean Mélou, Jean-Denis Durou, Daniel Cremers category:cs.CV  published:2017-04-02 summary:We introduce a variational method for multi-view shape-from-shading under natural illumination. The key idea is to couple PDE-based solutions for single-image based shape-from-shading problems across multiple images and multiple color channels by means of a variational formulation. Rather than alternatingly solving the individual SFS problems and optimizing the consistency across images and channels which is known to lead to suboptimal results, we propose an efficient solution of the coupled problem by means of an ADMM algorithm. In numerous experiments on both simulated and real imagery, we demonstrate that the proposed fusion of multiple-view reconstruction and shape-from-shading provides highly accurate dense reconstructions without the need to compute dense correspondences. With the proposed variational integration across multiple views shape-from-shading techniques become applicable to challenging real-world reconstruction problems, giving rise to highly detailed geometry even in areas of smooth brightness variation and lacking texture. version:1
arxiv-1704-00331 | Restoration of Images with Wavefront Aberrations | http://arxiv.org/abs/1704.00331 | id:1704.00331 author:Claudius Zelenka, Reinhard Koch category:astro-ph.IM cs.CV  published:2017-04-02 summary:This contribution deals with image restoration in optical systems with coherent illumination, which is an important topic in astronomy, coherent microscopy and radar imaging. Such optical systems suffer from wavefront distortions, which are caused by imperfect imaging components and conditions. Known image restoration algorithms work well for incoherent imaging, they fail in case of coherent images. In this paper a novel wavefront correction algorithm is presented, which allows image restoration under coherent conditions. In most coherent imaging systems, especially in astronomy, the wavefront deformation is known. Using this information, the proposed algorithm allows a high quality restoration even in case of severe wavefront distortions. We present two versions of this algorithm, which are an evolution of the Gerchberg-Saxton and the Hybrid-Input-Output algorithm. The algorithm is verified on simulated and real microscopic images. version:1
arxiv-1704-00330 | Understanding Deep Representations through Random Weights | http://arxiv.org/abs/1704.00330 | id:1704.00330 author:Yao Shu, Man Zhu, Kun He, John Hopcroft, Pan Zhou category:cs.CV  published:2017-04-02 summary:We systematically study the deep representation of random weight CNN (convolutional neural network) using the DeCNN (deconvolutional neural network) architecture. We first fix the weights of an untrained CNN, and for each layer of its feature representation, we train a corresponding DeCNN to reconstruct the input image. As compared with the pre-trained CNN, the DeCNN trained on a random weight CNN can reconstruct images more quickly and accurately, no matter which type of random distribution for the CNN's weights. It reveals that every layer of the random CNN can retain photographically accurate information about the image. We then let the DeCNN be untrained, i.e. the overall CNN-DeCNN architecture uses only random weights. Strikingly, we can reconstruct all position information of the image for low layer representations but the colors change. For high layer representations, we can still capture the rough contours of the image. We also change the number of feature maps and the shape of the feature maps and gain more insight on the random function of the CNN-DeCNN structure. Our work reveals that the purely random CNN-DeCNN architecture substantially contributes to the geometric and photometric invariance due to the intrinsic symmetry and invertible structure, but it discards the colormetric information due to the random projection. version:1
arxiv-1704-00326 | People Counting in Crowded and Outdoor Scenes using an Hybrid Multi-Camera Approach | http://arxiv.org/abs/1704.00326 | id:1704.00326 author:Fabio Dittrich, Luiz E. S. de Oliveira, Alceu S. Britto Jr., Alessandro L. Koerich category:cs.CV  published:2017-04-02 summary:This paper presents two novel approaches for people counting in crowded and open environments that combine the information gathered by multiple views. Multiple camera are used to expand the field of view as well as to mitigate the problem of occlusion that commonly affects the performance of counting methods using single cameras. The first approach is regarded as a direct approach and it attempts to segment and count each individual in the crowd. For such an aim, two head detectors trained with head images are employed: one based on support vector machines and another based on Adaboost perceptron. The second approach, regarded as an indirect approach employs learning algorithms and statistical analysis on the whole crowd to achieve counting. For such an aim, corner points are extracted from groups of people in a foreground image and computed by a learning algorithm which estimates the number of people in the scene. Both approaches count the number of people on the scene and not only on a given image or video frame of the scene. The experimental results obtained on the benchmark PETS2009 video dataset show that proposed indirect method surpasses other methods with improvements of up to 46.7% and provides accurate counting results for the crowded scenes. On the other hand, the direct method shows high error rates due to the fact that the latter has much more complex problems to solve, such as segmentation of heads. version:1
arxiv-1704-00299 | Efficient Version-Space Reduction for Visual Tracking | http://arxiv.org/abs/1704.00299 | id:1704.00299 author:Kourosh Meshgi, Shigeyuki Oba, Shin Ishii category:cs.CV  published:2017-04-02 summary:Discrminative trackers, employ a classification approach to separate the target from its background. To cope with variations of the target shape and appearance, the classifier is updated online with different samples of the target and the background. Sample selection, labeling and updating the classifier is prone to various sources of errors that drift the tracker. We introduce the use of an efficient version space shrinking strategy to reduce the labeling errors and enhance its sampling strategy by measuring the uncertainty of the tracker about the samples. The proposed tracker, utilize an ensemble of classifiers that represents different hypotheses about the target, diversify them using boosting to provide a larger and more consistent coverage of the version-space and tune the classifiers' weights in voting. The proposed system adjusts the model update rate by promoting the co-training of the short-memory ensemble with a long-memory oracle. The proposed tracker outperformed state-of-the-art trackers on different sequences bearing various tracking challenges. version:1
arxiv-1704-00280 | The Stixel world: A medium-level representation of traffic scenes | http://arxiv.org/abs/1704.00280 | id:1704.00280 author:Marius Cordts, Timo Rehfeld, Lukas Schneider, David Pfeiffer, Markus Enzweiler, Stefan Roth, Marc Pollefeys, Uwe Franke category:cs.CV  published:2017-04-02 summary:Recent progress in advanced driver assistance systems and the race towards autonomous vehicles is mainly driven by two factors: (1) increasingly sophisticated algorithms that interpret the environment around the vehicle and react accordingly, and (2) the continuous improvements of sensor technology itself. In terms of cameras, these improvements typically include higher spatial resolution, which as a consequence requires more data to be processed. The trend to add multiple cameras to cover the entire surrounding of the vehicle is not conducive in that matter. At the same time, an increasing number of special purpose algorithms need access to the sensor input data to correctly interpret the various complex situations that can occur, particularly in urban traffic. By observing those trends, it becomes clear that a key challenge for vision architectures in intelligent vehicles is to share computational resources. We believe this challenge should be faced by introducing a representation of the sensory data that provides compressed and structured access to all relevant visual content of the scene. The Stixel World discussed in this paper is such a representation. It is a medium-level model of the environment that is specifically designed to compress information about obstacles by leveraging the typical layout of outdoor traffic scenes. It has proven useful for a multitude of automotive vision applications, including object detection, tracking, segmentation, and mapping. In this paper, we summarize the ideas behind the model and generalize it to take into account multiple dense input streams: the image itself, stereo depth maps, and semantic class probability maps that can be generated, e.g., by CNNs. Our generalization is embedded into a novel mathematical formulation for the Stixel model. We further sketch how the free parameters of the model can be learned using structured SVMs. version:1
arxiv-1704-00275 | SAR image despeckling through convolutional neural networks | http://arxiv.org/abs/1704.00275 | id:1704.00275 author:G. Chierchia, D. Cozzolino, G. Poggi, L. Verdoliva category:cs.CV  published:2017-04-02 summary:In this paper we investigate the use of discriminative model learning through Convolutional Neural Networks (CNNs) for SAR image despeckling. The network uses a residual learning strategy, hence it does not recover the filtered image, but the speckle component, which is then subtracted from the noisy one. Training is carried out by considering a large multitemporal SAR image properly despeckled through 3D filtering, in order to approximate a {\em clean} image. Experimental results, both on synthetic and real SAR data, show the method to achieve performance that improve with respect to state-of-the-art techniques. version:1
arxiv-1704-00260 | Aligned Image-Word Representations Improve Inductive Transfer Across Vision-Language Tasks | http://arxiv.org/abs/1704.00260 | id:1704.00260 author:Tanmay Gupta, Kevin Shih, Saurabh Singh, Derek Hoiem category:cs.CV cs.AI cs.LG cs.NE stat.ML  published:2017-04-02 summary:A grand goal of computer vision is to build systems that learn visual representations over time that can be applied to many tasks. In this paper, we investigate a vision-language embedding as a core representation and show that it leads to better cross-task transfer than standard multi-task learning. In particular, the task of visual recognition is aligned to the task of visual question answering by forcing each to use the same word-region embeddings. We show this leads to greater inductive transfer from recognition to VQA than standard multitask learning. Visual recognition also improves, especially for categories that have relatively few recognition training labels but appear often in the VQA setting. Thus, our paper takes a small step towards creating more general vision systems by showing the benefit of interpretable, flexible, and trainable core representations. version:1
arxiv-1704-00248 | A-Lamp: Adaptive Layout-Aware Multi-Patch Deep Convolutional Neural Network for Photo Aesthetic Assessment | http://arxiv.org/abs/1704.00248 | id:1704.00248 author:Shuang Ma, Jing Liu, Chang Wen Chen category:cs.CV  published:2017-04-02 summary:Deep convolutional neural networks (CNN) have recently been shown to generate promising results for aesthetics assessment. However, the performance of these deep CNN methods is often compromised by the constraint that the neural network only takes the fixed-size input. To accommodate this requirement, input images need to be transformed via cropping, warping, or padding, which often alter image composition, reduce image resolution, or cause image distortion. Thus the aesthetics of the original images is impaired because of potential loss of fine grained details and holistic image layout. However, such fine grained details and holistic image layout is critical for evaluating an image's aesthetics. In this paper, we present an Adaptive Layout-Aware Multi-Patch Convolutional Neural Network (A-Lamp CNN) architecture for photo aesthetic assessment. This novel scheme is able to accept arbitrary sized images, and learn from both fined grained details and holistic image layout simultaneously. To enable training on these hybrid inputs, we extend the method by developing a dedicated double-subnet neural network structure, i.e. a Multi-Patch subnet and a Layout-Aware subnet. We further construct an aggregation layer to effectively combine the hybrid features from these two subnets. Extensive experiments on the large-scale aesthetics assessment benchmark (AVA) demonstrate significant performance improvement over the state-of-the-art in photo aesthetic assessment. version:1
arxiv-1703-08603 | Adversarial Examples for Semantic Segmentation and Object Detection | http://arxiv.org/abs/1703.08603 | id:1703.08603 author:Cihang Xie, Jianyu Wang, Zhishuai Zhang, Yuyin Zhou, Lingxi Xie, Alan Yuille category:cs.CV  published:2017-03-24 summary:It has been well demonstrated that adversarial examples, i.e., natural images with visually imperceptible perturbations added, generally exist for deep networks to fail on image classification. In this paper, we extend adversarial examples to semantic segmentation and object detection which are much more difficult. Our observation is that both segmentation and detection are based on classifying multiple targets on an image (e.g., the basic target is a pixel or a receptive field in segmentation, and an object proposal in detection), which inspires us to optimize a loss function over a set of pixels/proposals for generating adversarial perturbations. Based on this idea, we propose a novel algorithm named Dense Adversary Generation (DAG), which generates a large family of adversarial examples, and applies to a wide range of state-of-the-art deep networks for segmentation and detection. We also find that the adversarial perturbations can be transferred across networks with different training data, based on different architectures, and even for different recognition tasks. In particular, the transferability across networks with the same architecture is more significant than in other cases. Besides, summing up heterogeneous perturbations often leads to better transfer performance, which provides an effective method of black-box adversarial attack. version:2
arxiv-1704-00227 | Sequential Learning of Analysis Operators | http://arxiv.org/abs/1704.00227 | id:1704.00227 author:Michael Sandbichler, Karin Schnass category:cs.LG math.NA  published:2017-04-01 summary:In this paper two sequential algorithms for learning analysis operators are presented, which are built upon the same optimisation principle underlying both Analysis K-SVD and Analysis SimCO and use a stochastic gradient descent approach similar to ASimCO. The sequential analysis operator learning (SAOL) algorithm is based on projected gradient descent with an appropriately chosen step size while the implicit SAOL (ISAOL) algorithm avoids choosing a step size altogether by using a strategy inspired by the implicit Euler scheme for solving ordinary differential equations. Both algorithms are tested on synthetic and image data in comparison to Analysis SimCO and found to give slightly better recovery rates resp. decay of the objective function. In a final denoising experiment the presented algorithms are again shown to perform well in comparison to the state of the art algorithm ASimCO. version:1
arxiv-1704-00217 | Adversarial Connective-exploiting Networks for Implicit Discourse Relation Classification | http://arxiv.org/abs/1704.00217 | id:1704.00217 author:Lianhui Qin, Zhisong Zhang, Hai Zhao, Zhiting Hu, Eric P. Xing category:cs.CL cs.AI cs.LG stat.ML  published:2017-04-01 summary:Implicit discourse relation classification is of great challenge due to the lack of connectives as strong linguistic cues, which motivates the use of annotated implicit connectives to improve the recognition. We propose a feature imitation framework in which an implicit relation network is driven to learn from another neural network with access to connectives, and thus encouraged to extract similarly salient features for accurate classification. We develop an adversarial model to enable an adaptive imitation scheme through competition between the implicit network and a rival feature discriminator. Our method effectively transfers discriminability of connectives to the implicit features, and achieves state-of-the-art performance on the PDTB benchmark. version:1
arxiv-1704-00200 | Multimodal Dialogs (MMD): A large-scale dataset for studying multimodal domain-aware conversations | http://arxiv.org/abs/1704.00200 | id:1704.00200 author:Amrita Saha, Mitesh Khapra, Karthik Sankaranarayanan category:cs.CL  published:2017-04-01 summary:Owing to the success of deep learning techniques for tasks such as Q/A and text-based dialog, there is an increasing demand for AI agents in several domains such as retail, travel, entertainment, etc. that can carry on multimodal conversations with humans employing both text and images within a dialog seamlessly. However, deep learning research is this area has been limited primarily due to the lack of availability of large-scale, open conversation datasets. To overcome this bottleneck, in this paper we introduce the task of multi-modal, domain-aware conversations, and propose the MMD benchmark dataset to- wards this task. This dataset was gathered by working in close coordination with large number of domain experts in the retail domain and consists of over 150K conversation sessions between shoppers and sales agents. With this dataset, we propose 5 new sub-tasks for multimodal conversations along with their evaluation methodology. We also propose two novel multi-modal deep learning models in the encode- attend-decode paradigm and demonstrate their performance on two of the sub-tasks, namely text response generation and best image response selection. These experiments serve to establish baseline performance numbers and open new directions of research for each of these sub-tasks. version:1
arxiv-1704-00180 | Complexity-Aware Assignment of Latent Values in Discriminative Models for Accurate Gesture Recognition | http://arxiv.org/abs/1704.00180 | id:1704.00180 author:Manoel Horta Ribeiro, Bruno Teixeira, Antônio Otávio Fernandes, Wagner Meira Jr., Erickson R. Nascimento category:cs.CV  published:2017-04-01 summary:Many of the state-of-the-art algorithms for gesture recognition are based on Conditional Random Fields (CRFs). Successful approaches, such as the Latent-Dynamic CRFs, extend the CRF by incorporating latent variables, whose values are mapped to the values of the labels. In this paper we propose a novel methodology to set the latent values according to the gesture complexity. We use an heuristic that iterates through the samples associated with each label value, stimating their complexity. We then use it to assign the latent values to the label values. We evaluate our method on the task of recognizing human gestures from video streams. The experiments were performed in binary datasets, generated by grouping different labels. Our results demonstrate that our approach outperforms the arbitrary one in many cases, increasing the accuracy by up to 10%. version:1
arxiv-1704-00177 | Sentiment Analysis of Citations Using Word2vec | http://arxiv.org/abs/1704.00177 | id:1704.00177 author:Haixia Liu category:cs.CL  published:2017-04-01 summary:Citation sentiment analysis is an important task in scientific paper analysis. Existing machine learning techniques for citation sentiment analysis are focusing on labor-intensive feature engineering, which requires large annotated corpus. As an automatic feature extraction tool, word2vec has been successfully applied to sentiment analysis of short texts. In this work, I conducted empirical research with the question: how well does word2vec work on the sentiment analysis of citations? The proposed method constructed sentence vectors (sent2vec) by averaging the word embeddings, which were learned from Anthology Collections (ACL-Embeddings). I also investigated polarity-specific word embeddings (PS-Embeddings) for classifying positive and negative citations. The sentence vectors formed a feature space, to which the examined citation sentence was mapped to. Those features were input into classifiers (support vector machines) for supervised classification. Using 10-cross-validation scheme, evaluation was conducted on a set of annotated citations. The results showed that word embeddings are effective on classifying positive and negative citations. However, hand-crafted features performed better for the overall classification. version:1
arxiv-1704-00159 | Compositional Human Pose Regression | http://arxiv.org/abs/1704.00159 | id:1704.00159 author:Xiao Sun, Jiaxiang Shang, Shuang Liang, Yichen Wei category:cs.CV  published:2017-04-01 summary:Regression based methods are widely used for 3D and 2D human pose estimation, but the performance is not satisfactory. One problem is that the structural information of the pose is not well exploited in the existing methods. In this work, we propose a structure-aware regression approach. It adopts a reparameterized pose representation using bones instead of joints. It exploits the joint connection structure and proposes a compositional loss function that encodes the long range interactions in the pose. It is simple, effective, and general. Comprehensive evaluation validates the effectiveness of our approach. It significantly advances the state-of-the-art on Human3.6M and achieves state-of-the-art results on MPII, in a unified framework for 3D and 2D pose regression. version:1
arxiv-1704-00158 | Clustering-based Source-aware Assessment of True Robustness for Learning Models | http://arxiv.org/abs/1704.00158 | id:1704.00158 author:Ozsel Kilinc, Ismail Uysal category:cs.LG  published:2017-04-01 summary:We introduce a novel validation framework to measure the true robustness of learning models for real-world applications by creating source-inclusive and source-exclusive partitions in a dataset via clustering. We develop a robustness metric derived from source-aware lower and upper bounds of model accuracy even when data source labels are not readily available. We clearly demonstrate that even on a well-explored dataset like MNIST, challenging training scenarios can be constructed under the proposed assessment framework for two separate yet equally important applications: i) more rigorous learning model comparison and ii) dataset adequacy evaluation. In addition, our findings not only promise a more complete identification of trade-offs between model complexity, accuracy and robustness but can also help researchers optimize their efforts in data collection by identifying the less robust and more challenging class labels. version:1
arxiv-1704-00138 | Multiple Instance Detection Network with Online Instance Classifier Refinement | http://arxiv.org/abs/1704.00138 | id:1704.00138 author:Peng Tang, Xinggang Wang, Xiang Bai, Wenyu Liu category:cs.CV  published:2017-04-01 summary:Of late, weakly supervised object detection is with great importance in object recognition. Based on deep learning, weakly supervised detectors have achieved many promising results. However, compared with fully supervised detection, it is more challenging to train deep network based detectors in a weakly supervised manner. Here we formulate weakly supervised detection as a Multiple Instance Learning (MIL) problem, where instance classifiers (object detectors) are put into the network as hidden nodes. We propose a novel online instance classifier refinement algorithm to integrate MIL and the instance classifier refinement procedure into a single deep network, and train the network end-to-end with only image-level supervision, i.e., without object location information. More precisely, instance labels inferred from weak supervision are propagated to their spatially overlapped instances to refine instance classifier online. The iterative instance classifier refinement procedure is implemented using multiple streams in deep network, where each stream supervises its latter stream. Weakly supervised object detection experiments are carried out on the challenging PASCAL VOC 2007 and 2012 benchmarks. We obtain 47% mAP on VOC 2007 that significantly outperforms the previous state-of-the-art. version:1
arxiv-1704-00135 | Topic modeling of public repositories at scale using names in source code | http://arxiv.org/abs/1704.00135 | id:1704.00135 author:Vadim Markovtsev, Eiso Kant category:cs.PL cs.CL  published:2017-04-01 summary:Programming languages themselves have a limited number of reserved keywords and character based tokens that define the language specification. However, programmers have a rich use of natural language within their code through comments, text literals and naming entities. The programmer defined names that can be found in source code are a rich source of information to build a high level understanding of the project. The goal of this paper is to apply topic modeling to names used in over 13.6 million repositories and perceive the inferred topics. One of the problems in such a study is the occurrence of duplicate repositories not officially marked as forks (obscure forks). We show how to address it using the same identifiers which are extracted for topic modeling. We open with a discussion on naming in source code, we then elaborate on our approach to remove exact duplicate and fuzzy duplicate repositories using Locality Sensitive Hashing on the bag-of-words model and then discuss our work on topic modeling; and finally present the results from our data analysis together with open-access to the source code, tools and datasets. version:1
arxiv-1704-01088 | sWSI: A Low-cost and Commercial-quality Whole Slide Imaging System on Android and iOS Smartphones | http://arxiv.org/abs/1704.01088 | id:1704.01088 author:Shuoxin Ma, Tan Wang category:physics.bio-ph cs.CV  published:2017-04-01 summary:In this paper, scalable Whole Slide Imaging (sWSI), a novel high-throughput, cost-effective and robust whole slide imaging system on both Android and iOS platforms is introduced and analyzed. With sWSI, most mainstream smartphone connected to a optical eyepiece of any manually controlled microscope can be automatically controlled to capture sequences of mega-pixel fields of views that are synthesized into giga-pixel virtual slides. Remote servers carry out the majority of computation asynchronously to support clients running at satisfying frame rates without sacrificing image quality nor robustness. A typical 15x15mm sample can be digitized in 30 seconds with 4X or in 3 minutes with 10X object magnification, costing under $1. The virtual slide quality is considered comparable to existing high-end scanners thus satisfying for clinical usage by surveyed pathologies. The scan procedure with features such as supporting magnification up to 100x, recoding z-stacks, specimen-type-neutral and giving real-time feedback, is deemed work-flow-friendly and reliable. version:1
arxiv-1704-00119 | Psychological and Personality Profiles of Political Extremists | http://arxiv.org/abs/1704.00119 | id:1704.00119 author:Meysam Alizadeh, Ingmar Weber, Claudio Cioffi-Revilla, Santo Fortunato, Michael Macy category:cs.CL cs.CY cs.SI physics.soc-ph  published:2017-04-01 summary:Global recruitment into radical Islamic movements has spurred renewed interest in the appeal of political extremism. Is the appeal a rational response to material conditions or is it the expression of psychological and personality disorders associated with aggressive behavior, intolerance, conspiratorial imagination, and paranoia? Empirical answers using surveys have been limited by lack of access to extremist groups, while field studies have lacked psychological measures and failed to compare extremists with contrast groups. We revisit the debate over the appeal of extremism in the U.S. context by comparing publicly available Twitter messages written by over 355,000 political extremist followers with messages written by non-extremist U.S. users. Analysis of text-based psychological indicators supports the moral foundation theory which identifies emotion as a critical factor in determining political orientation of individuals. Extremist followers also differ from others in four of the Big Five personality traits. version:1
arxiv-1704-00116 | Stochastic L-BFGS Revisited: Improved Convergence Rates and Practical Acceleration Strategies | http://arxiv.org/abs/1704.00116 | id:1704.00116 author:Renbo Zhao, William B. Haskell, Vincent Y. F. Tan category:math.OC cs.IT math.IT stat.ML  published:2017-04-01 summary:We revisit the stochastic limited-memory BFGS (L-BFGS) algorithm. By proposing a new framework for analyzing convergence, we theoretically improve the (linear) convergence rates and computational complexities of the stochastic L-BFGS algorithms in previous works. In addition, we propose several practical acceleration strategies to speed up the empirical performance of such algorithms. We also provide theoretical analyses for most of the strategies. Experiments on large-scale logistic and ridge regression problems demonstrate that our proposed strategies yield significant improvements via-\`a-vis competing state-of-the-art algorithms. version:1
arxiv-1704-00109 | Snapshot Ensembles: Train 1, get M for free | http://arxiv.org/abs/1704.00109 | id:1704.00109 author:Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E. Hopcroft, Kilian Q. Weinberger category:cs.LG  published:2017-04-01 summary:Ensembles of neural networks are known to be much more robust and accurate than individual networks. However, training multiple deep networks for model averaging is computationally expensive. In this paper, we propose a method to obtain the seemingly contradictory goal of ensembling multiple neural networks at no additional training cost. We achieve this goal by training a single neural network, converging to several local minima along its optimization path and saving the model parameters. To obtain repeated rapid convergence, we leverage recent work on cyclic learning rate schedules. The resulting technique, which we refer to as Snapshot Ensembling, is simple, yet surprisingly effective. We show in a series of experiments that our approach is compatible with diverse network architectures and learning tasks. It consistently yields lower error rates than state-of-the-art single models at no additional training cost, and compares favorably with traditional network ensembles. On CIFAR-10 and CIFAR-100 our DenseNet Snapshot Ensembles obtain error rates of 3.4% and 17.4% respectively. version:1
arxiv-1704-00108 | Assortment Optimization under Unknown MultiNomial Logit Choice Models | http://arxiv.org/abs/1704.00108 | id:1704.00108 author:Wang Chi Cheung, David Simchi-Levi category:cs.LG  published:2017-04-01 summary:Motivated by e-commerce, we study the online assortment optimization problem. The seller offers an assortment, i.e. a subset of products, to each arriving customer, who then purchases one or no product from her offered assortment. A customer's purchase decision is governed by the underlying MultiNomial Logit (MNL) choice model. The seller aims to maximize the total revenue in a finite sales horizon, subject to resource constraints and uncertainty in the MNL choice model. We first propose an efficient online policy which incurs a regret $\tilde{O}(T^{2/3})$, where $T$ is the number of customers in the sales horizon. Then, we propose a UCB policy that achieves a regret $\tilde{O}(T^{1/2})$. Both regret bounds are sublinear in the number of assortments. version:1
arxiv-1704-00103 | SafetyNet: Detecting and Rejecting Adversarial Examples Robustly | http://arxiv.org/abs/1704.00103 | id:1704.00103 author:Jiajun Lu, Theerasit Issaranon, David Forsyth category:cs.CV cs.LG  published:2017-04-01 summary:We describe a method to produce a network where current methods such as DeepFool have great difficulty producing adversarial samples. Our construction suggests some insights into how deep networks work. We provide a reasonable analyses that our construction is difficult to defeat, and show experimentally that our method is hard to defeat using several standard networks and datasets. We use our method to produce a system that can reliably detect whether an image is a picture of a real scene or not. Our system applies to images captured with depth maps (RGBD images) and checks if a pair of image and depth map is consistent. It relies on the relative difficulty of producing naturalistic depth maps for images in post processing. We demonstrate that our system is robust to adversarial examples built from currently known attacking approaches. version:1
arxiv-1704-00098 | Customizing First Person Image Through Desired Actions | http://arxiv.org/abs/1704.00098 | id:1704.00098 author:Shan Su, Jianbo Shi, Hyun Soo Park category:cs.CV  published:2017-04-01 summary:This paper studies a problem of inverse visual path planning: creating a visual scene from a first person action. Our conjecture is that the spatial arrangement of a first person visual scene is deployed to afford an action, and therefore, the action can be inversely used to synthesize a new scene such that the action is feasible. As a proof-of-concept, we focus on linking visual experiences induced by walking. A key innovation of this paper is a concept of ActionTunnel---a 3D virtual tunnel along the future trajectory encoding what the wearer will visually experience as moving into the scene. This connects two distinctive first person images through similar walking paths. Our method takes a first person image with a user defined future trajectory and outputs a new image that can afford the future motion. The image is created by combining present and future ActionTunnels in 3D where the missing pixels in adjoining area are computed by a generative adversarial network. Our work can provide a travel across different first person experiences in diverse real world scenes. version:1
arxiv-1704-00090 | Learning to Predict Indoor Illumination from a Single Image | http://arxiv.org/abs/1704.00090 | id:1704.00090 author:Marc-André Gardner, Kalyan Sunkavalli, Ersin Yumer, Xiaohui Shen, Emiliano Gambaretto, Christian Gagné, Jean-François Lalonde category:cs.CV  published:2017-04-01 summary:In this work, we propose a method to infer high dynamic range illumination from a single, limited field-of-view, low dynamic range photograph of an indoor scene. Inferring scene illumination from a single photograph is a challenging problem. The pixel intensities observed in a photograph are a complex function of scene geometry, reflectance properties, and illumination. We introduce an end-to-end solution to this problem and propose a deep neural network that takes the limited field-of-view photo as input and produces an environment map as a panorama and a light mask prediction over the panorama as the output. Our technique does not require special image capture or user input. We preprocess standard low dynamic range panoramas by introducing novel light source detection and warping methods on the panorama, and use the results with corresponding limited field-of-view crops as training data. Our method does not rely on any assumptions on scene appearance, geometry, material properties, or lighting. This allows us to automatically recover high-quality illumination estimates that significantly outperform previous state-of-the-art methods. Consequently, using our illumination estimates for applications like 3D object insertion lead to results that are photo-realistic, which we demonstrate over a large set of examples and via a user study. version:1
arxiv-1704-00085 | Optimal Reconstruction with a Small Number of Views | http://arxiv.org/abs/1704.00085 | id:1704.00085 author:Cheng Peng, Volkan Isler category:cs.CV  published:2017-03-31 summary:Estimating positions of world points from features observed in images is a key problem in 3D reconstruction, image mosaicking, simultaneous localization and mapping and structure from motion. We consider a special instance in which there is a dominant ground plane $\mathcal{G}$ viewed from a parallel viewing plane $\mathcal{S}$ above it. Such instances commonly arise, for example, in aerial photography. Consider a world point $g \in \mathcal{G}$ and its worst case reconstruction uncertainty $\varepsilon(g,\mathcal{S})$ obtained by merging \emph{all} possible views of $g$ chosen from $\mathcal{S}$. We first show that one can pick two views $s_p$ and $s_q$ such that the uncertainty $\varepsilon(g,\{s_p,s_q\})$ obtained using only these two views is almost as good as (i.e. within a small constant factor of) $\varepsilon(g,\mathcal{S})$. Next, we extend the result to the entire ground plane $\mathcal{G}$ and show that one can pick a small subset of $\mathcal{S'} \subseteq \mathcal{S}$ (which grows only linearly with the area of $\mathcal{G}$) and still obtain a constant factor approximation, for every point $g \in \mathcal{G}$, to the minimum worst case estimate obtained by merging all views in $\mathcal{S}$. Our results provide a view selection mechanism with provable performance guarantees which can drastically increase the speed of scene reconstruction algorithms. In addition to theoretical results, we demonstrate their effectiveness in an application where aerial imagery is used for monitoring farms and orchards. version:1
arxiv-1704-00083 | Efficient Asymmetric Co-Tracking using Uncertainty Sampling | http://arxiv.org/abs/1704.00083 | id:1704.00083 author:Kourosh Meshgi, Maryam Sadat Mirzaei, Shigeyuki Oba, Shin Ishii category:cs.CV  published:2017-03-31 summary:Adaptive tracking-by-detection approaches are popular for tracking arbitrary objects. They treat the tracking problem as a classification task and use online learning techniques to update the object model. However, these approaches are heavily invested in the efficiency and effectiveness of their detectors. Evaluating a massive number of samples for each frame (e.g., obtained by a sliding window) forces the detector to trade the accuracy in favor of speed. Furthermore, misclassification of borderline samples in the detector introduce accumulating errors in tracking. In this study, we propose a co-tracking based on the efficient cooperation of two detectors: a rapid adaptive exemplar-based detector and another more sophisticated but slower detector with a long-term memory. The sampling labeling and co-learning of the detectors are conducted by an uncertainty sampling unit, which improves the speed and accuracy of the system. We also introduce a budgeting mechanism which prevents the unbounded growth in the number of examples in the first detector to maintain its rapid response. Experiments demonstrate the efficiency and effectiveness of the proposed tracker against its baselines and its superior performance against state-of-the-art trackers on various benchmark videos. version:1
arxiv-1704-00077 | Geodesic Distance Histogram Feature for Video Segmentation | http://arxiv.org/abs/1704.00077 | id:1704.00077 author:Hieu Le, Vu Nguyen, Chen-Ping Yu, Dimitris Samaras category:cs.CV  published:2017-03-31 summary:This paper proposes a geodesic-distance-based feature that encodes global information for improved video segmentation algorithms. The feature is a joint histogram of intensity and geodesic distances, where the geodesic distances are computed as the shortest paths between superpixels via their boundaries. We also incorporate adaptive voting weights and spatial pyramid configurations to include spatial information into the geodesic histogram feature and show that this further improves results. The feature is generic and can be used as part of various algorithms. In experiments, we test the geodesic histogram feature by incorporating it into two existing video segmentation frameworks. This leads to significantly better performance in 3D video segmentation benchmarks on two datasets. version:1
arxiv-1704-00060 | Exploiting gradients and Hessians in Bayesian optimization and Bayesian quadrature | http://arxiv.org/abs/1704.00060 | id:1704.00060 author:Anqi Wu, Mikio C. Aoi, Jonathan W. Pillow category:stat.ML  published:2017-03-31 summary:An exciting branch of machine learning research focuses on methods for learning, optimizing, and integrating unknown functions that are difficult or costly to evaluate. A popular Bayesian approach to this problem uses a Gaussian process (GP) to construct a posterior distribution over the function of interest given a set of observed measurements, and selects new points to evaluate using the statistics of this posterior. Here we extend these methods to exploit derivative information from the unknown function. We describe methods for Bayesian optimization (BO) and Bayesian quadrature (BQ) in settings where first and second derivatives may be evaluated along with the function itself. We perform sampling-based inference in order to incorporate uncertainty over hyperparameters, and show that both hyperparameter and function uncertainty decrease much more rapidly when using derivative information. Moreover, we introduce techniques for overcoming ill-conditioning issues that have plagued earlier methods for gradient-enhanced Gaussian processes and kriging. We illustrate the efficacy of these methods using applications to real and simulated Bayesian optimization and quadrature problems, and show that exploting derivatives can provide substantial gains over standard methods. version:1
arxiv-1704-00052 | One-Shot Neural Cross-Lingual Transfer for Paradigm Completion | http://arxiv.org/abs/1704.00052 | id:1704.00052 author:Katharina Kann, Ryan Cotterell, Hinrich Schütze category:cs.CL  published:2017-03-31 summary:We present a novel cross-lingual transfer method for paradigm completion, the task of mapping a lemma to its inflected forms, using a neural encoder-decoder model, the state of the art for the monolingual task. We use labeled data from a high-resource language to increase performance on a low-resource language. In experiments on 21 language pairs from four different language families, we obtain up to 58% higher accuracy than without transfer and show that even zero-shot and one-shot learning are possible. We further find that the degree of language relatedness strongly influences the ability to transfer morphological knowledge. version:1
arxiv-1704-00051 | Reading Wikipedia to Answer Open-Domain Questions | http://arxiv.org/abs/1704.00051 | id:1704.00051 author:Danqi Chen, Adam Fisch, Jason Weston, Antoine Bordes category:cs.CL  published:2017-03-31 summary:This paper proposes to tackle open-domain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval - finding the relevant articles - with that of machine comprehension of text - identifying the answer spans from those articles. Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task. version:1
arxiv-1704-00036 | Efficient Registration of Pathological Images: A Joint PCA/Image-Reconstruction Approach | http://arxiv.org/abs/1704.00036 | id:1704.00036 author:Xu Han, Xiao Yang, Stephen Aylward, Roland Kwitt, Marc Niethammer category:cs.CV  published:2017-03-31 summary:Registration involving one or more images containing pathologies is challenging, as standard image similarity measures and spatial transforms cannot account for common changes due to pathologies. Low-rank/Sparse (LRS) decomposition removes pathologies prior to registration; however, LRS is memory-demanding and slow, which limits its use on larger data sets. Additionally, LRS blurs normal tissue regions, which may degrade registration performance. This paper proposes an efficient alternative to LRS: (1) normal tissue appearance is captured by principal component analysis (PCA) and (2) blurring is avoided by an integrated model for pathology removal and image reconstruction. Results on synthetic and BRATS 2015 data demonstrate its utility. version:1
arxiv-1704-00033 | Transfer of View-manifold Learning to Similarity Perception of Novel Objects | http://arxiv.org/abs/1704.00033 | id:1704.00033 author:Xingyu Lin, Hao Wang, Zhihao Li, Yimeng Zhang, Alan Yuille, Tai Sing Lee category:cs.CV  published:2017-03-31 summary:We develop a model of perceptual similarity judgment based on re-training a deep convolution neural network (DCNN) that learns to associate different views of each 3D object to capture the notion of object persistence and continuity in our visual experience. The re-training process effectively performs distance metric learning under the object persistency constraints, to modify the view-manifold of object representations. It reduces the effective distance between the representations of different views of the same object without compromising the distance between those of the views of different objects, resulting in the untangling of the view-manifolds between individual objects within the same category and across categories. This untangling enables the model to discriminate and recognize objects within the same category, independent of viewpoints. We found that this ability is not limited to the trained objects, but transfers to novel objects in both trained and untrained categories, as well as to a variety of completely novel artificial synthetic objects. This transfer in learning suggests the modification of distance metrics in view- manifolds is more general and abstract, likely at the levels of parts, and independent of the specific objects or categories experienced during training. Interestingly, the resulting transformation of feature representation in the deep networks is found to significantly better match human perceptual similarity judgment than AlexNet, suggesting that object persistence could be an important constraint in the development of perceptual similarity judgment in biological neural networks. version:1
arxiv-1704-00028 | Improved Training of Wasserstein GANs | http://arxiv.org/abs/1704.00028 | id:1704.00028 author:Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, Aaron Courville category:cs.LG stat.ML  published:2017-03-31 summary:Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes significant progress toward stable training of GANs, but can still generate low-quality samples or fail to converge in some settings. We find that these training failures are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to pathological behavior. We propose an alternative method for enforcing the Lipschitz constraint: instead of clipping weights, penalize the norm of the gradient of the critic with respect to its input. Our proposed method converges faster and generates higher-quality samples than WGAN with weight clipping. Finally, our method enables very stable GAN training: for the first time, we can train a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. version:1
arxiv-1704-00026 | Upper Bounds on the Runtime of the Univariate Marginal Distribution Algorithm on OneMax | http://arxiv.org/abs/1704.00026 | id:1704.00026 author:Carsten Witt category:cs.NE  published:2017-03-31 summary:A runtime analysis of the Univariate Marginal Distribution Algorithm (UMDA) is presented on the OneMax function for wide ranges of its parameters $\mu$ and $\lambda$. If $\mu\ge c\log n$ for some constant $c>0$ and $\lambda=(1+\Theta(1))\mu$, a general bound $O(\mu n)$ on the expected runtime is obtained. This bound crucially assumes that all marginal probabilities of the algorithm are confined to the interval $[1/n,1-1/n]$. If $\mu\ge c' \sqrt{n}\log n$ for a constant $c'>0$ and $\lambda=(1+\Theta(1))\mu$, the behavior of the algorithm changes and the bound on the expected runtime becomes $O(\mu\sqrt{n})$, which typically even holds if the borders on the marginal probabilities are omitted. The results supplement the recently derived lower bound $\Omega(\mu\sqrt{n}+n\log n)$ by Krejca and Witt (FOGA 2017) and turn out as tight for the two very different values $\mu=c\log n$ and $\mu=c'\sqrt{n}\log n$. They also improve the previously best known upper bound $O(n\log n\log\log n)$ by Dang and Lehre (GECCO 2015). version:1
arxiv-1704-00023 | On the Reliable Detection of Concept Drift from Streaming Unlabeled Data | http://arxiv.org/abs/1704.00023 | id:1704.00023 author:Tegjyot Singh Sethi, Mehmed Kantardzic category:stat.ML cs.AI cs.LG  published:2017-03-31 summary:Classifiers deployed in the real world operate in a dynamic environment, where the data distribution can change over time. These changes, referred to as concept drift, can cause the predictive performance of the classifier to drop over time, thereby making it obsolete. To be of any real use, these classifiers need to detect drifts and be able to adapt to them, over time. Detecting drifts has traditionally been approached as a supervised task, with labeled data constantly being used for validating the learned model. Although effective in detecting drifts, these techniques are impractical, as labeling is a difficult, costly and time consuming activity. On the other hand, unsupervised change detection techniques are unreliable, as they produce a large number of false alarms. The inefficacy of the unsupervised techniques stems from the exclusion of the characteristics of the learned classifier, from the detection process. In this paper, we propose the Margin Density Drift Detection (MD3) algorithm, which tracks the number of samples in the uncertainty region of a classifier, as a metric to detect drift. The MD3 algorithm is a distribution independent, application independent, model independent, unsupervised and incremental algorithm for reliably detecting drifts from data streams. Experimental evaluation on 6 drift induced datasets and 4 additional datasets from the cybersecurity domain demonstrates that the MD3 approach can reliably detect drifts, with significantly fewer false alarms compared to unsupervised feature based drift detectors. The reduced false alarms enables the signaling of drifts only when they are most likely to affect classification performance. As such, the MD3 approach leads to a detection scheme which is credible, label efficient and general in its applicability. version:1
arxiv-1703-11008 | Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural Networks with Many More Parameters than Training Data | http://arxiv.org/abs/1703.11008 | id:1703.11008 author:Gintare Karolina Dziugaite, Daniel M. Roy category:cs.LG  published:2017-03-31 summary:One of the defining properties of deep learning is that models are chosen to have many more parameters than available training data. In light of this capacity for overfitting, it is remarkable that simple algorithms like SGD reliably return solutions with low test error. One roadblock to explaining these phenomena in terms of implicit regularization, structural properties of the solution, and/or easiness of the data is that many learning bounds are quantitatively vacuous in this "deep learning" regime. In order to explain generalization, we need nonvacuous bounds. We return to an idea by Langford and Caruana (2001), who used PAC-Bayes bounds to compute nonvacuous numerical bounds on generalization error for stochastic two-layer two-hidden-unit neural networks via a sensitivity analysis. By optimizing the PAC-Bayes bound directly, we are able to extend their approach and obtain nonvacuous generalization bounds for deep stochastic neural network classifiers with millions of parameters trained on only tens of thousands of examples. We connect our findings to recent and old work on flat minima and MDL-based explanations of generalization. version:1
arxiv-1703-11000 | Learning Visual Servoing with Deep Features and Fitted Q-Iteration | http://arxiv.org/abs/1703.11000 | id:1703.11000 author:Alex X. Lee, Sergey Levine, Pieter Abbeel category:cs.LG cs.AI cs.RO  published:2017-03-31 summary:Visual servoing involves choosing actions that move a robot in response to observations from a camera, in order to reach a goal configuration in the world. Standard visual servoing approaches typically rely on manually designed features and analytical dynamics models, which limits their generalization capability and often requires extensive application-specific feature and model engineering. In this work, we study how learned visual features, learned predictive dynamics models, and reinforcement learning can be combined to learn visual servoing mechanisms. We focus on target following, with the goal of designing algorithms that can learn a visual servo using low amounts of data of the target in question, to enable quick adaptation to new targets. Our approach is based on servoing the camera in the space of learned visual features, rather than image pixels or manually-designed keypoints. We demonstrate that standard deep features, in our case taken from a model trained for object classification, can be used together with a bilinear predictive model to learn an effective visual servo that is robust to visual variation, changes in viewing angle and appearance, and occlusions. A key component of our approach is to use a sample-efficient fitted Q-iteration algorithm to learn which features are best suited for the task at hand. We show that we can learn an effective visual servo on a complex synthetic car following benchmark using just 20 training trajectory samples for reinforcement learning. We demonstrate substantial improvement over a conventional approach based on image pixels or hand-designed keypoints, and we show an improvement in sample-efficiency of more than two orders of magnitude over standard model-free deep reinforcement learning algorithms. Videos are available at \url{http://rll.berkeley.edu/visual_servoing}. version:1
arxiv-1703-10993 | Catalyst Acceleration for Gradient-Based Non-Convex Optimization | http://arxiv.org/abs/1703.10993 | id:1703.10993 author:Courtney Paquette, Hongzhou Lin, Dmitriy Drusvyatskiy, Julien Mairal, Zaid Harchaoui category:stat.ML math.OC  published:2017-03-31 summary:We introduce a generic acceleration scheme to accelerate gradient-based convex optimization algorithms to solve possibly nonconvex optimization problems. The proposed approach extends the Catalyst acceleration for convex problems and allows one to venture into possibly nonconvex optimization problems without sacrificing the rate of convergence to stationary points. We present promising experimental results for sparse matrix factorization and for learning neural networks. version:1
arxiv-1703-10960 | Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders | http://arxiv.org/abs/1703.10960 | id:1703.10960 author:Tiancheng Zhao, Ran Zhao, Maxine Eskenazi category:cs.CL cs.AI  published:2017-03-31 summary:While recent neural encoder-decoder models have shown great promise in modeling open-domain conversations, they often generate dull and generic responses. Unlike past work that has focused on diversifying the output of the decoder at word-level to alleviate this problem, we present a novel framework based on conditional variational autoencoders that captures the discourse-level diversity in the encoder. Our model uses latent variables to learn a distribution over potential conversational intents and generates diverse responses using only greedy decoders. We have further developed a novel variant that is integrated with linguistic prior knowledge for better performance. Finally, the training procedure is improved by introducing a bag-of-word loss. Our proposed models have been validated to generate significantly more diverse responses than baseline approaches and exhibit competence in discourse-level decision-making. version:1
arxiv-1703-10956 | InverseFaceNet: Deep Single-Shot Inverse Face Rendering From A Single Image | http://arxiv.org/abs/1703.10956 | id:1703.10956 author:Hyeongwoo Kim, Michael Zollhöfer, Ayush Tewari, Justus Thies, Christian Richardt, Christian Theobalt category:cs.CV  published:2017-03-31 summary:We introduce InverseFaceNet, a deep convolutional inverse rendering framework for faces that jointly estimates facial pose, shape, expression, reflectance and illumination from a single input image in a single shot. By estimating all these parameters from just a single image, advanced editing possibilities on a single face image, such as appearance editing and relighting, become feasible. Previous learning-based face reconstruction approaches do not jointly recover all dimensions, or are severely limited in terms of visual quality. In contrast, we propose to recover high-quality facial pose, shape, expression, reflectance and illumination using a deep neural network that is trained using a large, synthetically created dataset. Our approach builds on a novel loss function that measures model-space similarity directly in parameter space and significantly improves reconstruction accuracy. In addition, we propose an analysis-by-synthesis breeding approach which iteratively updates the synthetic training corpus based on the distribution of real-world images, and we demonstrate that this strategy outperforms completely synthetically trained networks. Finally, we show high-quality reconstructions and compare our approach to several state-of-the-art approaches. version:1
arxiv-1703-10951 | Comparison of multi-task convolutional neural network (MT-CNN) and a few other methods for toxicity prediction | http://arxiv.org/abs/1703.10951 | id:1703.10951 author:Kedi Wu, Guo-Wei Wei category:q-bio.QM cs.LG stat.ML  published:2017-03-31 summary:Toxicity analysis and prediction are of paramount importance to human health and environmental protection. Existing computational methods are built from a wide variety of descriptors and regressors, which makes their performance analysis difficult. For example, deep neural network (DNN), a successful approach in many occasions, acts like a black box and offers little conceptual elegance or physical understanding. The present work constructs a common set of microscopic descriptors based on established physical models for charges, surface areas and free energies to assess the performance of multi-task convolutional neural network (MT-CNN) architectures and a few other approaches, including random forest (RF) and gradient boosting decision tree (GBDT), on an equal footing. Comparison is also given to convolutional neural network (CNN) and non-convolutional deep neural network (DNN) algorithms. Four benchmark toxicity data sets (i.e., endpoints) are used to evaluate various approaches. Extensive numerical studies indicate that the present MT-CNN architecture is able to outperform the state-of-the-art methods. version:1
arxiv-1703-10936 | Prediction of infectious disease epidemics via weighted density ensembles | http://arxiv.org/abs/1703.10936 | id:1703.10936 author:Evan L. Ray, Nicholas G. Reich category:stat.ML  published:2017-03-31 summary:Accurate and reliable predictions of infectious disease dynamics can be valuable to public health organizations that plan interventions to decrease or prevent disease transmission. A great variety of models have been developed for this task, using different model structures, covariates, and targets for prediction. Experience has shown that the performance of these models varies; some tend to do better or worse in different seasons or at different points within a season. Ensemble methods combine multiple models to obtain a single prediction that leverages the strengths of each model. We considered a range of ensemble methods that each form a predictive density for a target of interest as a weighted sum of the predictive densities from component models. In the simplest case, equal weight is assigned to each component model; in the most complex case, the weights vary with the region, prediction target, week of the season when the predictions are made, a measure of component model uncertainty, and recent observations of disease incidence. We applied these methods to predict measures of influenza season timing and severity in the United States, both at the national and regional levels, using three component models. We trained the models on retrospective predictions from 14 seasons (1997/1998 - 2010/2011) and evaluated each model's prospective, out-of-sample performance in the five subsequent influenza seasons. In this test phase, the ensemble methods showed overall performance that was similar to the best of the component models, but offered more consistent performance across seasons than the component models. Ensemble methods offer the potential to deliver more reliable predictions to public health decision makers. version:1
arxiv-1703-10935 | The Risk of Machine Learning | http://arxiv.org/abs/1703.10935 | id:1703.10935 author:Alberto Abadie, Maximilian Kasy category:stat.ML  published:2017-03-31 summary:Many applied settings in empirical economics involve simultaneous estimation of a large number of parameters. In particular, applied economists are often interested in estimating the effects of many-valued treatments (like teacher effects or location effects), treatment effects for many groups, and prediction models with many regressors. In these settings, machine learning methods that combine regularized estimation and data-driven choices of regularization parameters are useful to avoid over-fitting. In this article, we analyze the performance of a class of machine learning estimators that includes ridge, lasso and pretest in contexts that require simultaneous estimation of many parameters. Our analysis aims to provide guidance to applied researchers on (i) the choice between regularized estimators in practice and (ii) data-driven selection of regularization parameters. To address (i), we characterize the risk (mean squared error) of regularized estimators and derive their relative performance as a function of simple features of the data generating process. To address (ii), we show that data-driven choices of regularization parameters, based on Stein's unbiased risk estimate or on cross-validation, yield estimators with risk uniformly close to the risk attained under the optimal (unfeasible) choice of regularization parameters. We use data from recent examples in the empirical economics literature to illustrate the practical applicability of our results. version:1
arxiv-1703-10931 | Sentence Simplification with Deep Reinforcement Learning | http://arxiv.org/abs/1703.10931 | id:1703.10931 author:Xingxing Zhang, Mirella Lapata category:cs.CL cs.LG  published:2017-03-31 summary:Sentence simplification aims to make sentences easier to read and understand. Most recent approaches draw on insights from machine translation to learn simplification rewrites from monolingual corpora of complex and simple sentences. We address the simplification problem with an encoder-decoder model coupled with a deep reinforcement learning framework. Our model explores the space of possible simplifications while learning to optimize a reward function that encourages outputs which are simple, fluent, and preserve the meaning of the input. Experiments on three datasets demonstrate that our model brings significant improvements over the state of the art. version:1
arxiv-1703-10927 | Feature functional theory - binding predictor (FFT-BP) for the blind prediction of binding free energies | http://arxiv.org/abs/1703.10927 | id:1703.10927 author:Bao Wang, Zhixiong Zhao, Duc D. Nguyen, Guo-Wei Wei category:q-bio.QM cs.LG physics.chem-ph  published:2017-03-31 summary:We present a feature functional theory - binding predictor (FFT-BP) for the protein-ligand binding affinity prediction. The underpinning assumptions of FFT-BP are as follows: i) representability: there exists a microscopic feature vector that can uniquely characterize and distinguish one protein-ligand complex from another; ii) feature-function relationship: the macroscopic features, including binding free energy, of a complex is a functional of microscopic feature vectors; and iii) similarity: molecules with similar microscopic features have similar macroscopic features, such as binding affinity. Physical models, such as implicit solvent models and quantum theory, are utilized to extract microscopic features, while machine learning algorithms are employed to rank the similarity among protein-ligand complexes. A large variety of numerical validations and tests confirms the accuracy and robustness of the proposed FFT-BP model. The root mean square errors (RMSEs) of FFT-BP blind predictions of a benchmark set of 100 complexes, the PDBBind v2007 core set of 195 complexes and the PDBBind v2015 core set of 195 complexes are 1.99, 2.02 and 1.92 kcal/mol, respectively. Their corresponding Pearson correlation coefficients are 0.75, 0.80, and 0.78, respectively. version:1
arxiv-1703-10908 | Quicksilver: Fast Predictive Image Registration - a Deep Learning Approach | http://arxiv.org/abs/1703.10908 | id:1703.10908 author:Xiao Yang, Roland Kwitt, Marc Niethammer category:cs.CV  published:2017-03-31 summary:This paper introduces Quicksilver, a fast deformable image registration method. Quicksilver registration for image-pairs works by patch-wise prediction of a deformation model based directly on image appearance. A deep encoder-decoder network is used as the prediction model. While the prediction strategy is general, we focus on predictions for the Large Deformation Diffeomorphic Metric Mapping (LDDMM) model. Specifically, we predict the momentum-parameterization of LDDMM, which facilitates a patch-wise prediction strategy while maintaining the theoretical properties of LDDMM, such as guaranteed diffeomorphic mappings for sufficiently strong regularization. We also provide a probabilistic version of our prediction network which can be sampled during test time to calculate uncertainties in the predicted deformations. Finally, we introduce a new correction network which greatly increases the prediction accuracy of an already existing prediction network. Experiments are conducted for both atlas-to-image and image-to-image registrations. These experiments show that our method accurately predicts registrations obtained by numerical optimization, is very fast, and achieves state-of-the-art registration results on four standard validation datasets. Quicksilver is freely available as open-source software. version:1
arxiv-1703-10902 | Fast Predictive Multimodal Image Registration | http://arxiv.org/abs/1703.10902 | id:1703.10902 author:Xiao Yang, Roland Kwitt, Martin Styner, Marc Niethammer category:cs.CV  published:2017-03-31 summary:We introduce a deep encoder-decoder architecture for image deformation prediction from multimodal images. Specifically, we design an image-patch-based deep network that jointly (i) learns an image similarity measure and (ii) the relationship between image patches and deformation parameters. While our method can be applied to general image registration formulations, we focus on the Large Deformation Diffeomorphic Metric Mapping (LDDMM) registration model. By predicting the initial momentum of the shooting formulation of LDDMM, we preserve its mathematical properties and drastically reduce the computation time, compared to optimization-based approaches. Furthermore, we create a Bayesian probabilistic version of the network that allows evaluation of registration uncertainty via sampling of the network at test time. We evaluate our method on a 3D brain MRI dataset using both T1- and T2-weighted images. Our experiments show that our method generates accurate predictions and that learning the similarity measure leads to more consistent registrations than relying on generic multimodal image similarity measures, such as mutual information. Our approach is an order of magnitude faster than optimization-based LDDMM. version:1
arxiv-1703-10901 | Unsupervised learning from video to detect foreground objects in single images | http://arxiv.org/abs/1703.10901 | id:1703.10901 author:Ioana Croitoru, Simion-Vlad Bogolin, Marius Leordeanu category:cs.CV  published:2017-03-31 summary:Unsupervised learning from visual data is one of the most difficult challenges in computer vision, being a fundamental task for understanding how visual recognition works. From a practical point of view, learning from unsupervised visual input has an immense practical value, as very large quantities of unlabeled videos can be collected at low cost. In this paper, we address the task of unsupervised learning to detect and segment foreground objects in single images. We achieve our goal by training a student pathway, consisting of a deep neural network. It learns to predict from a single input image (a video frame) the output for that particular frame, of a teacher pathway that performs unsupervised object discovery in video. Our approach is different from the published literature that performs unsupervised discovery in videos or in collections of images at test time. We move the unsupervised discovery phase during the training stage, while at test time we apply the standard feed-forward processing along the student pathway. This has a dual benefit: firstly, it allows in principle unlimited possibilities of learning and generalization during training, while remaining very fast at testing. Secondly, the student not only becomes able to detect in single images significantly better than its unsupervised video discovery teacher, but it also achieves state of the art results on two important current benchmarks, YouTube Objects and Object Discovery datasets. Moreover, at test time, our system is at least two orders of magnitude faster than other previous methods. version:1
arxiv-1703-10898 | Thin-Slicing Network: A Deep Structured Model for Pose Estimation in Videos | http://arxiv.org/abs/1703.10898 | id:1703.10898 author:Jie Song, Limin Wang, Luc Van Gool, Otmar Hilliges category:cs.CV  published:2017-03-31 summary:Deep ConvNets have been shown to be effective for the task of human pose estimation from single images. However, several challenging issues arise in the video-based case such as self-occlusion, motion blur, and uncommon poses with few or no examples in training data sets. Temporal information can provide additional cues about the location of body joints and help to alleviate these issues. In this paper, we propose a deep structured model to estimate a sequence of human poses in unconstrained videos. This model can be efficiently trained in an end-to-end manner and is capable of representing appearance of body joints and their spatio-temporal relationships simultaneously. Domain knowledge about the human body is explicitly incorporated into the network providing effective priors to regularize the skeletal structure and to enforce temporal consistency. The proposed end-to-end architecture is evaluated on two widely used benchmarks (Penn Action dataset and JHMDB dataset) for video-based pose estimation. Our approach significantly outperforms the existing state-of-the-art methods. version:1
arxiv-1703-10896 | BB8: A Scalable, Accurate, Robust to Partial Occlusion Method for Predicting the 3D Poses of Challenging Objects without Using Depth | http://arxiv.org/abs/1703.10896 | id:1703.10896 author:Mahdi Rad, Vincent Lepetit category:cs.CV  published:2017-03-31 summary:We introduce a novel method for 3D object detection and pose estimation from color images only. We first use segmentation to detect the objects of interest in 2D even in presence of partial occlusions and cluttered background. By contrast with recent patch-based methods, we rely on a "holistic" approach: We apply to the detected objects a Convolutional Neural Network (CNN) trained to predict their 3D poses in the form of 2D projections of the corners of their 3D bounding boxes for the pose of objects' parts. This, however, is not sufficient for handling objects from the recent T-LESS dataset: These objects exhibit an axis of rotational symmetry, and the similarity of two images of such an object under two different poses makes training the CNN challenging. We solve this problem by restricting the range of poses used for training, and by introducing a classifier to identify the range of a pose at run-time before estimating it. We also use an optional additional step that refines the predicted poses for hand pose estimation. We improve the state-of-the-art on the LINEMOD dataset from 73.7% to 89.3% of correctly registered RGB frames. We are also the first to report results on the Occlusion dataset using color images only. We obtain 54% of frames passing the Pose 6D criterion on average on several sequences of the T-LESS dataset, compared to the 67% of the state-of-the-art on the same sequences which uses both color and depth. The full approach is also scalable, as a single network can be trained for multiple objects simultaneously. version:1
arxiv-1703-10889 | Single Image Super Resolution - When Model Adaptation Matters | http://arxiv.org/abs/1703.10889 | id:1703.10889 author:Yudong Liang, Radu Timofte, Jinjun Wang, Yihong Gong, Nanning Zheng category:cs.CV  published:2017-03-31 summary:In the recent years impressive advances were made for single image super-resolution. Deep learning is behind a big part of this success. Deep(er) architecture design and external priors modeling are the key ingredients. The internal contents of the low resolution input image is neglected with deep modeling despite the earlier works showing the power of using such internal priors. In this paper we propose a novel deep convolutional neural network carefully designed for robustness and efficiency at both learning and testing. Moreover, we propose a couple of model adaptation strategies to the internal contents of the low resolution input image and analyze their strong points and weaknesses. By trading runtime and using internal priors we achieve 0.1 up to 0.3dB PSNR improvements over best reported results on standard datasets. Our adaptation especially favors images with repetitive structures or under large resolutions. Moreover, it can be combined with other simple techniques, such as back-projection or enhanced prediction, for further improvements. version:1
arxiv-1703-10887 | Bi-class classification of humpback whale sound units against complex background noise with Deep Convolution Neural Network | http://arxiv.org/abs/1703.10887 | id:1703.10887 author:Cazau Dorian, Riwal Lefort, Julien Bonnel, Jean-Luc Zarader, Olivier Adam category:stat.ML cs.LG cs.SD  published:2017-03-31 summary:Automatically detecting sound units of humpback whales in complex time-varying background noises is a current challenge for scientists. In this paper, we explore the applicability of Convolution Neural Network (CNN) method for this task. In the evaluation stage, we present 6 bi-class classification experimentations of whale sound detection against different background noise types (e.g., rain, wind). In comparison to classical FFT-based representation like spectrograms, we showed that the use of image-based pretrained CNN features brought higher performance to classify whale sounds and background noise. version:1
arxiv-1703-10881 | (DE)^2 CO: Deep Depth Colorization | http://arxiv.org/abs/1703.10881 | id:1703.10881 author:F. M. Carlucci, P. Russo, S. M. Baharlou, B. Caputo category:cs.CV  published:2017-03-31 summary:Object recognition on depth images using convolutional neural networks requires mapping the data collected with depth sensors into three dimensional channels. This makes them processable by deep architectures, pre-trained over large scale RGB databases like ImageNet. Current mappings are based on heuristic assumptions over what depth properties should be most preserved, resulting often in cumbersome data visualizations, and likely in sub-optimal recognition results. Here we take an alternative route and we attempt instead to \emph{learn} an optimal colorization mapping for any given pre-trained architecture, using as training data a reference RGB-D database. We propose a deep network architecture, exploiting the residual paradigm, that learns how to map depth data to three channel images from a reference database. A qualitative analysis of the images obtained with this approach clearly indicates that learning the optimal mapping for depth data preserves the richness of depth information much better than hand-crafted approaches currently in use. Experiments on the Washington, JHUIT-50 and BigBIRD public benchmark databases, using AlexNet, VGG-16, GoogleNet, ResNet and SqueezeNet, clearly showcase the power of our approach, with gains in performance of up to $17\%$ compared to the state of the art. version:1
arxiv-1703-10827 | Intraoperative margin assessment of human breast tissue in optical coherence tomography images using deep neural networks | http://arxiv.org/abs/1703.10827 | id:1703.10827 author:Amal Rannen Triki, Matthew B. Blaschko, Yoon Mo Jung, Seungri Song, Hyun Ju Han, Seung Il Kim, Chulmin Joo category:stat.ML  published:2017-03-31 summary:Objective: In this work, we perform margin assessment of human breast tissue from optical coherence tomography (OCT) images using deep neural networks (DNNs). This work simulates an intraoperative setting for breast cancer lumpectomy. Methods: To train the DNNs, we use both the state-of-the-art methods (Weight Decay and DropOut) and a newly introduced regularization method based on function norms. Commonly used methods can fail when only a small database is available. The use of a function norm introduces a direct control over the complexity of the function with the aim of diminishing the risk of overfitting. Results: As neither the code nor the data of previous results are publicly available, the obtained results are compared with reported results in the literature for a conservative comparison. Moreover, our method is applied to locally collected data on several data configurations. The reported results are the average over the different trials. Conclusion: The experimental results show that the use of DNNs yields significantly better results than other techniques when evaluated in terms of sensitivity, specificity, F1 score, G-mean and Matthews correlation coefficient. Function norm regularization yielded higher and more robust results than competing methods. Significance: We have demonstrated a system that shows high promise for (partially) automated margin assessment of human breast tissue, Equal error rate (EER) is reduced from approximately 12\% (the lowest reported in the literature) to 5\%\,--\,a 58\% reduction. The method is computationally feasible for intraoperative application (less than 2 seconds per image). version:1
arxiv-1703-10818 | End-To-End Face Detection and Recognition | http://arxiv.org/abs/1703.10818 | id:1703.10818 author:Liying Chi, Hongxin Zhang, Mingxiu Chen category:cs.CV  published:2017-03-31 summary:Plenty of face detection and recognition methods have been proposed and got delightful results in decades. Common face recognition pipeline consists of: 1) face detection, 2) face alignment, 3) feature extraction, 4) similarity calculation, which are separated and independent from each other. The separated face analyzing stages lead the model redundant calculation and are hard for end-to-end training. In this paper, we proposed a novel end-to-end trainable convolutional network framework for face detection and recognition, in which a geometric transformation matrix was directly learned to align the faces, instead of predicting the facial landmarks. In training stage, our single CNN model is supervised only by face bounding boxes and personal identities, which are publicly available from WIDER FACE \cite{Yang2016} dataset and CASIA-WebFace \cite{Yi2014} dataset. Tested on Face Detection Dataset and Benchmark (FDDB) \cite{Jain2010} dataset and Labeled Face in the Wild (LFW) \cite{Huang2007} dataset, we have achieved 89.24\% recall for face detection task and 98.63\% verification accuracy for face recognition task simultaneously, which are comparable to state-of-the-art results. version:1
arxiv-1703-09778 | INTEL-TUT Dataset for Camera Invariant Color Constancy Research | http://arxiv.org/abs/1703.09778 | id:1703.09778 author:Caglar Aytekin, Jarno Nikkanen, Moncef Gabbouj category:cs.CV  published:2017-03-21 summary:In this paper, we provide a novel dataset designed for camera invariant color constancy research. Camera invariance corresponds to the robustness of an algorithm's performance when run on images of the same scene taken by different cameras. Accordingly, images in the database correspond to several lab and field scenes each of which are captured by three different cameras with minimal registration errors. The lab scenes are also captured under five different illuminations. The spectral responses of cameras and the spectral power distributions of the lab light sources are also provided, as they may prove beneficial for training future algorithms to achieve color constancy. For a fair evaluation of future methods, we provide guidelines for supervised methods with indicated training, validation and testing partitions. Accordingly, we evaluate a recently proposed convolutional neural network based color constancy algorithm as a baseline for future research. As a side contribution, this dataset also includes images taken by a mobile camera with color shading corrected and uncorrected results. This allows research on the effect of color shading as well. version:2
arxiv-1703-10772 | Joining Hands: Exploiting Monolingual Treebanks for Parsing of Code-mixing Data | http://arxiv.org/abs/1703.10772 | id:1703.10772 author:Irshad Ahmad Bhat, Riyaz Ahmad Bhat, Manish Shrivastava, Dipti Misra Sharma category:cs.CL  published:2017-03-31 summary:In this paper, we propose efficient and less resource-intensive strategies for parsing of code-mixed data. These strategies are not constrained by in-domain annotations, rather they leverage pre-existing monolingual annotated resources for training. We show that these methods can produce significantly better results as compared to an informed baseline. Besides, we also present a data set of 450 Hindi and English code-mixed tweets of Hindi multilingual speakers for evaluation. The data set is manually annotated with Universal Dependencies. version:1
arxiv-1704-00607 | A New Measure of Conditional Dependence for Causal Structural Learning | http://arxiv.org/abs/1704.00607 | id:1704.00607 author:Jalal Etesami, Kun Zhang, Negar Kiyavash category:stat.ML cs.LG  published:2017-03-31 summary:Measuring the dependencies among the variables of a network is of great interest to many disciplines. This paper studies the limitations of the existing dependencies measures such as their shortcomings in detecting direct influences or their lack of ability for group selection in order to have effective interventions and introduces a new statistical influence measure to overcome them. This measure is inspired by Dobrushin's coefficients and has been developed based on the paradigm that the conditional distribution of the variable of interest given all the direct causes will not change by intervening on other variables in the system. We show the advantageous of this measure over the related measures in the literature. Moreover, we establish the connection between our measure and the integral probability metric (IPM) that helps to develop estimators for our measure with lower complexity compared to the other relevant information theoretic based measures. At the end, we show the performance of this measure through a numerical simulation. version:1
arxiv-1703-10764 | A Hybrid Data Association Framework for Robust Online Multi-Object Tracking | http://arxiv.org/abs/1703.10764 | id:1703.10764 author:Min Yang, Yuwei Wu, Yunde Jia category:cs.CV  published:2017-03-31 summary:Global optimization algorithms have shown impressive performance in data-association based multi-object tracking, but handling online data remains a difficult hurdle to overcome. In this paper, we present a hybrid data association framework with a min-cost multi-commodity network flow for robust online multi-object tracking. We build local target-specific models interleaved with global optimization of the optimal data association over multiple video frames. More specifically, in the min-cost multi-commodity network flow, the target-specific similarities are online learned to enforce the local consistency for reducing the complexity of the global data association. Meanwhile, the global data association taking multiple video frames into account alleviates irrecoverable errors caused by the local data association between adjacent frames. To ensure the efficiency of online tracking, we give an efficient near-optimal solution to the proposed min-cost multi-commodity flow problem, and provide the empirical proof of its sub-optimality. The comprehensive experiments on real data demonstrate the superior tracking performance of our approach in various challenging situations. version:1
arxiv-1703-10761 | Universal Scalable Robust Solvers from Computational Information Games and fast eigenspace adapted Multiresolution Analysis | http://arxiv.org/abs/1703.10761 | id:1703.10761 author:Houman Owhadi, Clint Scovel category:math.NA math.AP stat.ML  published:2017-03-31 summary:We show how the discovery of robust scalable numerical solvers for arbitrary bounded linear operators can be automated as a Game Theory problem by reformulating the process of computing with partial information and limited resources as that of playing underlying hierarchies of adversarial information games. When the solution space is a Banach space $B$ endowed with a quadratic norm $\ \cdot\ $, the optimal measure (mixed strategy) for such games (e.g. the adversarial recovery of $u\in B$, given partial measurements $[\phi_i, u]$ with $\phi_i\in B^*$, using relative error in $\ \cdot\ $-norm as a loss) is a centered Gaussian field $\xi$ solely determined by the norm $\ \cdot\ $, whose conditioning (on measurements) produces optimal bets. When measurements are hierarchical, the process of conditioning this Gaussian field produces a hierarchy of elementary bets (gamblets). These gamblets generalize the notion of Wavelets and Wannier functions in the sense that they are adapted to the norm $\ \cdot\ $ and induce a multi-resolution decomposition of $B$ that is adapted to the eigensubspaces of the operator defining the norm $\ \cdot\ $. When the operator is localized, we show that the resulting gamblets are localized both in space and frequency and introduce the Fast Gamblet Transform (FGT) with rigorous accuracy and (near-linear) complexity estimates. As the FFT can be used to solve and diagonalize arbitrary PDEs with constant coefficients, the FGT can be used to decompose a wide range of continuous linear operators (including arbitrary continuous linear bijections from $H^s_0$ to $H^{-s}$ or to $L^2$) into a sequence of independent linear systems with uniformly bounded condition numbers and leads to $\mathcal{O}(N \operatorname{polylog} N)$ solvers and eigenspace adapted Multiresolution Analysis (resulting in near linear complexity approximation of all eigensubspaces). version:1
arxiv-1703-09793 | Deceiving Google's Cloud Video Intelligence API Built for Summarizing Videos | http://arxiv.org/abs/1703.09793 | id:1703.09793 author:Hossein Hosseini, Baicen Xiao, Radha Poovendran category:cs.CV cs.LG  published:2017-03-26 summary:Despite the rapid progress of the techniques for image classification, video annotation has remained a challenging task. Automated video annotation would be a breakthrough technology, enabling users to search within the videos. Recently, Google introduced the Cloud Video Intelligence API for video analysis. As per the website, the system can be used to "separate signal from noise, by retrieving relevant information at the video, shot or per frame" level. A demonstration website has been also launched, which allows anyone to select a video for annotation. The API then detects the video labels (objects within the video) as well as shot labels (description of the video events over time). In this paper, we examine the usability of the Google's Cloud Video Intelligence API in adversarial environments. In particular, we investigate whether an adversary can subtly manipulate a video in such a way that the API will return only the adversary-desired labels. For this, we select an image, which is different from the video content, and insert it, periodically and at a very low rate, into the video. We found that if we insert one image every two seconds, the API is deceived into annotating the video as if it only contained the inserted image. Note that the modification to the video is hardly noticeable as, for instance, for a typical frame rate of 25, we insert only one image per 50 video frames. We also found that, by inserting one image per second, all the shot labels returned by the API are related to the inserted image. We perform the experiments on the sample videos provided by the API demonstration website and show that our attack is successful with different videos and images. version:2
arxiv-1704-00003 | Spectral Methods for Nonparametric Models | http://arxiv.org/abs/1704.00003 | id:1704.00003 author:Hsiao-Yu Fish Tung, Chao-Yuan Wu, Manzil Zaheer, Alexander J. Smola category:cs.LG stat.ML  published:2017-03-31 summary:Nonparametric models are versatile, albeit computationally expensive, tool for modeling mixture models. In this paper, we introduce spectral methods for the two most popular nonparametric models: the Indian Buffet Process (IBP) and the Hierarchical Dirichlet Process (HDP). We show that using spectral methods for the inference of nonparametric models are computationally and statistically efficient. In particular, we derive the lower-order moments of the IBP and the HDP, propose spectral algorithms for both models, and provide reconstruction guarantees for the algorithms. For the HDP, we further show that applying hierarchical models on dataset with hierarchical structure, which can be solved with the generalized spectral HDP, produces better solutions to that of flat models regarding likelihood performance. version:1
arxiv-1703-10740 | Fundamental Conditions for Low-CP-Rank Tensor Completion | http://arxiv.org/abs/1703.10740 | id:1703.10740 author:Morteza Ashraphijuo, Xiaodong Wang category:cs.LG cs.NA math.NA stat.ML  published:2017-03-31 summary:We consider the problem of low canonical polyadic (CP) rank tensor completion. A completion is a tensor whose entries agree with the observed entries and its rank matches the given CP rank. We analyze the manifold structure corresponding to the tensors with the given rank and define a set of polynomials based on the sampling pattern and CP decomposition. Then, we show that finite completability of the sampled tensor is equivalent to having a certain number of algebraically independent polynomials among the defined polynomials. Our proposed approach results in characterizing the maximum number of algebraically independent polynomials in terms of a simple geometric structure of the sampling pattern, and therefore we obtain the deterministic necessary and sufficient condition on the sampling pattern for finite completability of the sampled tensor. Moreover, assuming that the entries of the tensor are sampled independently with probability $p$ and using the mentioned deterministic analysis, we propose a combinatorial method to derive a lower bound on the sampling probability $p$, or equivalently, the number of sampled entries that guarantees finite completability with high probability. We also show that the existing result for the matrix completion problem can be used to obtain a loose lower bound on the sampling probability $p$. In addition, we obtain deterministic and probabilistic conditions for unique completability. It is seen that the number of samples required for finite or unique completability obtained by the proposed analysis on the CP manifold is orders-of-magnitude lower than that is obtained by the existing analysis on the Grassmannian manifold. version:1
arxiv-1703-10729 | Deep Domain Adaptation Based Video Smoke Detection using Synthetic Smoke Images | http://arxiv.org/abs/1703.10729 | id:1703.10729 author:Gao Xu, Yongming Zhang, Qixing Zhang, Gaohua Lin, Jinjun Wang category:cs.CV 68T45  published:2017-03-31 summary:In this paper, a deep domain adaptation based method for video smoke detection is proposed to extract a powerful feature representation of smoke. Due to the smoke image samples limited in scale and diversity for deep CNN training, we systematically produced adequate synthetic smoke images with a wide variation in the smoke shape, background and lighting conditions. Considering that the appearance gap (dataset bias) between synthetic and real smoke images degrades significantly the performance of the trained model on the test set composed fully of real images, we build deep architectures based on domain adaptation to confuse the distributions of features extracted from synthetic and real smoke images. This approach expands the domain-invariant feature space for smoke image samples. With their approximate feature distribution off non-smoke images, the recognition rate of the trained model is improved significantly compared to the model trained directly on mixed dataset of synthetic and real images. Experimentally, several deep architectures with different design choices are applied to the smoke detector. The ultimate framework can get a satisfactory result on the test set. We believe that our approach is a start in the direction of utilizing deep neural networks enhanced with synthetic smoke images for video smoke detection. version:1
arxiv-1703-10724 | N-gram Language Modeling using Recurrent Neural Network Estimation | http://arxiv.org/abs/1703.10724 | id:1703.10724 author:Ciprian Chelba, Mohammad Norouzi, Samy Bengio category:cs.CL  published:2017-03-31 summary:We investigate the effective memory depth of RNN models by using them for n-gram language model (LM) smoothing. Experiments on a small corpus (UPenn Treebank, one million words of training data and 10k vocabulary) have found the LSTM cell with dropout to be the best model for encoding the n-gram state when compared with feed-forward and vanilla RNN models. When preserving the sentence independence assumption the LSTM n-gram matches the LSTM LM performance for n=9 and slightly outperforms it for n=13. When allowing dependencies across sentence boundaries, the LSTM 13-gram almost matches the perplexity of the unlimited history LSTM LM. LSTM n-gram smoothing also has the desirable property of improving with increasing n-gram order, unlike the Katz or Kneser-Ney back-off estimators. Using multinomial distributions as targets in training instead of the usual one-hot target is only slightly beneficial for low n-gram orders. Experiments on the One Billion Words benchmark show that the results hold at larger scale. Building LSTM n-gram LMs may be appealing for some practical situations: the state in a n-gram LM can be succinctly represented with (n-1)*4 bytes storing the identity of the words in the context and batches of n-gram contexts can be processed in parallel. On the downside, the n-gram context encoding computed by the LSTM is discarded, making the model more expensive than a regular recurrent LSTM LM. version:1
arxiv-1703-10722 | Factorization tricks for LSTM networks | http://arxiv.org/abs/1703.10722 | id:1703.10722 author:Oleksii Kuchaiev, Boris Ginsburg category:cs.CL cs.NE stat.ML  published:2017-03-31 summary:We present two simple ways of reducing the number of parameters and accelerating the training of large Long Short-Term Memory (LSTM) networks: the first one is "matrix factorization by design" of LSTM matrix into the product of two smaller matrices, and the second one is partitioning of LSTM matrix, its inputs and states into the independent groups. Both approaches allow us to train large LSTM networks significantly faster to the state-of the art perplexity. On the One Billion Word Benchmark we improve single model perplexity down to 24.29. version:1
arxiv-1703-10714 | Deep 3D Face Identification | http://arxiv.org/abs/1703.10714 | id:1703.10714 author:Donghyun Kim, Matthias Hernandez, Jongmoo Choi, Gerard Medioni category:cs.CV  published:2017-03-30 summary:We propose a novel 3D face recognition algorithm using a deep convolutional neural network (DCNN) and a 3D augmentation technique. The performance of 2D face recognition algorithms has significantly increased by leveraging the representational power of deep neural networks and the use of large-scale labeled training data. As opposed to 2D face recognition, training discriminative deep features for 3D face recognition is very difficult due to the lack of large-scale 3D face datasets. In this paper, we show that transfer learning from a CNN trained on 2D face images can effectively work for 3D face recognition by fine-tuning the CNN with a relatively small number of 3D facial scans. We also propose a 3D face augmentation technique which synthesizes a number of different facial expressions from a single 3D face scan. Our proposed method shows excellent recognition results on Bosphorus, BU-3DFE, and 3D-TEC datasets, without using hand-crafted features. The 3D identification using our deep features also scales well for large databases. version:1
