arxiv-1706-00377 | Morph-fitting: Fine-Tuning Word Vector Spaces with Simple Language-Specific Rules | http://arxiv.org/abs/1706.00377 | id:1706.00377 author:Ivan Vulić, Nikola Mrkšić, Roi Reichart, Diarmuid Ó Séaghdha, Steve Young, Anna Korhonen category:cs.CL  published:2017-06-01 summary:Morphologically rich languages accentuate two properties of distributional vector space models: 1) the difficulty of inducing accurate representations for low-frequency word forms; and 2) insensitivity to distinct lexical relations that have similar distributional signatures. These effects are detrimental for language understanding systems, which may infer that 'inexpensive' is a rephrasing for 'expensive' or may not associate 'acquire' with 'acquires'. In this work, we propose a novel morph-fitting procedure which moves past the use of curated semantic lexicons for improving distributional vector spaces. Instead, our method injects morphological constraints generated using simple language-specific rules, pulling inflectional forms of the same word close together and pushing derivational antonyms far apart. In intrinsic evaluation over four languages, we show that our approach: 1) improves low-frequency word estimates; and 2) boosts the semantic quality of the entire word vector collection. Finally, we show that morph-fitted vectors yield large gains in the downstream task of dialogue state tracking, highlighting the importance of morphology for tackling long-tail phenomena in language understanding tasks. version:1
arxiv-1706-00374 | Semantic Specialisation of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints | http://arxiv.org/abs/1706.00374 | id:1706.00374 author:Nikola Mrkšić, Ivan Vulić, Diarmuid Ó Séaghdha, Ira Leviant, Roi Reichart, Milica Gašić, Anna Korhonen, Steve Young category:cs.CL cs.AI cs.LG  published:2017-06-01 summary:We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. Attract-Repel facilitates the use of constraints from mono- and cross-lingual resources, yielding semantically specialised cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct high-quality vector spaces for a plethora of different languages, facilitating semantic transfer from high- to lower-resource ones. The effectiveness of our approach is demonstrated with state-of-the-art results on semantic similarity datasets in six languages. We next show that Attract-Repel-specialised vectors boost performance in the downstream task of dialogue state tracking (DST) across multiple languages. Finally, we show that cross-lingual vector spaces produced by our algorithm facilitate the training of multilingual DST models, which brings further performance improvements. version:1
arxiv-1706-00359 | Discovering Discrete Latent Topics with Neural Variational Inference | http://arxiv.org/abs/1706.00359 | id:1706.00359 author:Yishu Miao, Edward Grefenstette, Phil Blunsom category:cs.CL cs.AI cs.IR cs.LG  published:2017-06-01 summary:Topic models have been widely explored as probabilistic generative models of documents. Traditional inference methods have sought closed-form derivations for updating the models, however as the expressiveness of these models grows, so does the difficulty of performing fast and accurate inference over their parameters. This paper presents alternative neural approaches to topic modelling by providing parameterisable distributions over topics which permit training by backpropagation in the framework of neural variational inference. In addition, with the help of a stick-breaking construction, we propose a recurrent network that is able to discover a notionally unbounded number of topics, analogous to Bayesian non-parametric topic models. Experimental results on the MXM Song Lyrics, 20NewsGroups and Reuters News datasets demonstrate the effectiveness and efficiency of these neural topic models. version:1
arxiv-1706-00348 | Approximating first-passage time distributions via sequential Bayesian computation | http://arxiv.org/abs/1706.00348 | id:1706.00348 author:David Schnoerr, Botond Cseke, Ramon Grima, Guido Sanguinetti category:physics.comp-ph physics.bio-ph q-bio.QM stat.CO stat.ML  published:2017-06-01 summary:We show that computing first-passage time distributions for stochastic processes is equivalent to a sequential Bayesian inference problem for an auxiliary observation process. The solution can be approximated efficiently by solving a closed set of coupled ordinary differential equations. The method is accurate and orders of magnitude faster than existing approaches, enabling hitherto computationally prohibitive tasks such as sensitivity analysis. We apply it to an epidemic model, an entrained oscillator and a trimerisation process, and show good agreement with exact stochastic simulations. version:1
arxiv-1706-00326 | Discriminative k-shot learning using probabilistic models | http://arxiv.org/abs/1706.00326 | id:1706.00326 author:Matthias Bauer, Mateo Rojas-Carulla, Jakub Bartłomiej Świątkowski, Bernhard Schölkopf, Richard E. Turner category:stat.ML cs.LG  published:2017-06-01 summary:This paper introduces a probabilistic framework for k-shot image classification. The goal is to generalise from an initial large-scale classification task to a separate task comprising new classes and small numbers of examples. The new approach not only leverages the feature-based representation learned by a neural network from the initial task (representational transfer), but also information about the form of the classes (concept transfer). The concept information is encapsulated in a probabilistic model for the final layer weights of the neural network which then acts as a prior when probabilistic k-shot learning is performed. Surprisingly, simple probabilistic models and inference schemes outperform many existing k-shot learning approaches and compare favourably with the state-of-the-art method in terms of error-rate. The new probabilistic methods are also able to accurately model uncertainty, leading to well calibrated classifiers, and they are easily extensible and flexible, unlike many recent approaches to k-shot learning. version:1
arxiv-1706-00321 | Using of heterogeneous corpora for training of an ASR system | http://arxiv.org/abs/1706.00321 | id:1706.00321 author:Jan Trmal, Gaurav Kumar, Vimal Manohar, Sanjeev Khudanpur, Matt Post, Paul McNamee category:cs.CL  published:2017-06-01 summary:The paper summarizes the development of the LVCSR system built as a part of the Pashto speech-translation system at the SCALE (Summer Camp for Applied Language Exploration) 2015 workshop on "Speech-to-text-translation for low-resource languages". The Pashto language was chosen as a good "proxy" low-resource language, exhibiting multiple phenomena which make the speech-recognition and and speech-to-text-translation systems development hard. Even when the amount of data is seemingly sufficient, given the fact that the data originates from multiple sources, the preliminary experiments reveal that there is little to no benefit in merging (concatenating) the corpora and more elaborate ways of making use of all of the data must be worked out. This paper concentrates only on the LVCSR part and presents a range of different techniques that were found to be useful in order to benefit from multiple different corpora version:1
arxiv-1705-08500 | Selective Classification for Deep Neural Networks | http://arxiv.org/abs/1705.08500 | id:1705.08500 author:Yonatan Geifman, Ran El-Yaniv category:cs.LG cs.AI  published:2017-05-23 summary:Selective classification techniques (also known as reject option) have not yet been considered in the context of deep neural networks (DNNs). These techniques can potentially significantly improve DNNs prediction performance by trading-off coverage. In this paper we propose a method to construct a selective classifier given a trained neural network. Our method allows a user to set a desired risk level. At test time, the classifier rejects instances as needed, to grant the desired risk (with high probability). Empirical results over CIFAR and ImageNet convincingly demonstrate the viability of our method, which opens up possibilities to operate DNNs in mission-critical applications. For example, using our method an unprecedented 2% error in top-5 ImageNet classification can be guaranteed with probability 99.9%, and almost 60% test coverage. version:2
arxiv-1706-00292 | Sinkhorn-AutoDiff: Tractable Wasserstein Learning of Generative Models | http://arxiv.org/abs/1706.00292 | id:1706.00292 author:Aude Genevay, Gabriel Peyré, Marco Cuturi category:stat.ML  published:2017-06-01 summary:The ability to compare two degenerate probability distributions (i.e. two probability distributions supported on two distinct low-dimensional manifolds living in a much higher-dimensional space) is a crucial problem arising in the estimation of generative models for high-dimensional observations such as those arising in computer vision or natural language. It is known that optimal transport metrics can represent a cure for this problem, since they were specifically designed as an alternative to information divergences to handle such problematic scenarios. Unfortunately, training generative machines using OT raises formidable computational and statistical challenges, because of (i) the computational burden of evaluating OT losses, (ii) the instability and lack of smoothness of these losses, (iii) the difficulty to estimate robustly these losses and their gradients in high dimension. This paper presents the first tractable computational method to train large scale generative models using an optimal transport loss, and tackles both these issues by relying on two key ideas: (a) entropic smoothing, which turns the original OT loss into one that can be computed using Sinkhorn fixed point iterations; (b) algorithmic (automatic) differentiation of these iterations. These two approximations result in a robust and differentiable approximation of the OT loss with streamlined GPU execution. The resulting computational architecture complements nicely standard deep network generative models by a stack of extra layers implementing the loss function. version:1
arxiv-1706-00290 | Transfer Learning for Speech Recognition on a Budget | http://arxiv.org/abs/1706.00290 | id:1706.00290 author:Julius Kunze, Louis Kirsch, Ilia Kurenkov, Andreas Krug, Jens Johannsmeier, Sebastian Stober category:cs.LG cs.CL cs.NE stat.ML  published:2017-06-01 summary:End-to-end training of automated speech recognition (ASR) systems requires massive data and compute resources. We explore transfer learning based on model adaptation as an approach for training ASR models under constrained GPU memory, throughput and training data. We conduct several systematic experiments adapting a Wav2Letter convolutional neural network originally trained for English ASR to the German language. We show that this technique allows faster training on consumer-grade resources while requiring less training data in order to achieve the same accuracy, thereby lowering the cost of training ASR models in other languages. Model introspection revealed that small adaptations to the network's weights were sufficient for good performance, especially for inner layers. version:1
arxiv-1705-07109 | Deep adversarial neural decoding | http://arxiv.org/abs/1705.07109 | id:1705.07109 author:Yağmur Güçlütürk, Umut Güçlü, Katja Seeliger, Sander Bosch, Rob van Lier, Marcel van Gerven category:q-bio.NC cs.LG stat.ML  published:2017-05-19 summary:Here, we present a novel approach to solve the problem of reconstructing perceived stimuli from brain responses by combining probabilistic inference with deep learning. Our approach first inverts the linear transformation from latent features to brain responses with maximum a posteriori estimation and then inverts the nonlinear transformation from perceived stimuli to latent features with adversarial training of convolutional neural networks. We test our approach with a functional magnetic resonance imaging experiment and show that it can generate state-of-the-art reconstructions of perceived faces from brain activations. version:2
arxiv-1706-00280 | Integer Echo State Networks: Hyperdimensional Reservoir Computing | http://arxiv.org/abs/1706.00280 | id:1706.00280 author:Denis Kleyko, Edward Paxon Frady, Evgeny Osipov category:cs.NE  published:2017-06-01 summary:We propose an integer approximation of Echo State Networks (ESN) based on the mathematics of hyperdimensional computing. The reservoir of the proposed Integer Echo State Network (intESN) contains only n-bits integers and replaces the recurrent matrix multiply with an efficient cyclic shift operation. Such an architecture results in dramatic improvements in memory footprint and computational efficiency, with minimal performance loss. Our architecture naturally supports the usage of the trained reservoir in symbolic processing tasks of analogy making and logical inference. version:1
arxiv-1705-09368 | Pose Guided Person Image Generation | http://arxiv.org/abs/1705.09368 | id:1705.09368 author:Liqian Ma, Xu Jia, Qianru Sun, Bernt Schiele, Tinne Tuytelaars, Luc Van Gool category:cs.CV  published:2017-05-25 summary:This paper proposes the novel Pose Guided Person Generation Network (PG$^2$) that allows to synthesize person images in arbitrary poses, based on an image of that person and a novel pose. Our generation framework PG$^2$ utilizes the pose information explicitly and consists of two key stages: pose integration and image refinement. In the first stage the condition image and the target pose are fed into a U-Net-like network to generate an initial but coarse image of the person with the target pose. The second stage then refines the initial and blurry result by training a U-Net-like generator in an adversarial way. Extensive experimental results on both 128$\times$64 re-identification images and 256$\times$256 fashion photos show that our model generates high-quality person images with convincing details. version:2
arxiv-1705-02402 | Face Detection, Bounding Box Aggregation and Pose Estimation for Robust Facial Landmark Localisation in the Wild | http://arxiv.org/abs/1705.02402 | id:1705.02402 author:Zhen-Hua Feng, Josef Kittler, Muhammad Awais, Patrik Huber, Xiao-Jun Wu category:cs.CV  published:2017-05-05 summary:We present a framework for robust face detection and landmark localisation of faces in the wild, which has been evaluated as part of `the 2nd Facial Landmark Localisation Competition'. The framework has four stages: face detection, bounding box aggregation, pose estimation and landmark localisation. To achieve a high detection rate, we use two publicly available CNN-based face detectors and two proprietary detectors. We aggregate the detected face bounding boxes of each input image to reduce false positives and improve face detection accuracy. A cascaded shape regressor, trained using faces with a variety of pose variations, is then employed for pose estimation and image pre-processing. Last, we train the final cascaded shape regressor for fine-grained landmark localisation, using a large number of training samples with limited pose variations. The experimental results obtained on the 300W and Menpo benchmarks demonstrate the superiority of our framework over state-of-the-art methods. version:2
arxiv-1706-00245 | Polish Read Speech Corpus for Speech Tools and Services | http://arxiv.org/abs/1706.00245 | id:1706.00245 author:Danijel Koržinek, Krzysztof Marasek, Łukasz Brocki, Krzysztof Wołk category:cs.CL  published:2017-06-01 summary:This paper describes the speech processing activities conducted at the Polish consortium of the CLARIN project. The purpose of this segment of the project was to develop specific tools that would allow for automatic and semi-automatic processing of large quantities of acoustic speech data. The tools include the following: grapheme-to-phoneme conversion, speech-to-text alignment, voice activity detection, speaker diarization, keyword spotting and automatic speech transcription. Furthermore, in order to develop these tools, a large high-quality studio speech corpus was recorded and released under an open license, to encourage development in the area of Polish speech research. Another purpose of the corpus was to serve as a reference for studies in phonetics and pronunciation. All the tools and resources were released on the the Polish CLARIN website. This paper discusses the current status and future plans for the project. version:1
arxiv-1706-00244 | Supervised Quantile Normalisation | http://arxiv.org/abs/1706.00244 | id:1706.00244 author:Marine Le Morvan, Jean-Philippe Vert category:stat.ML cs.LG q-bio.QM  published:2017-06-01 summary:Quantile normalisation is a popular normalisation method for data subject to unwanted variations such as images, speech, or genomic data. It applies a monotonic transformation to the feature values of each sample to ensure that after normalisation, they follow the same target distribution for each sample. Choosing a "good" target distribution remains however largely empirical and heuristic, and is usually done independently of the subsequent analysis of normalised data. We propose instead to couple the quantile normalisation step with the subsequent analysis, and to optimise the target distribution jointly with the other parameters in the analysis. We illustrate this principle on the problem of estimating a linear model over normalised data, and show that it leads to a particular low-rank matrix regression problem that can be solved efficiently. We illustrate the potential of our method, which we term SUQUAN, on simulated data, images and genomic data, where it outperforms standard quantile normalisation. version:1
arxiv-1706-00241 | Krylov Subspace Recycling for Fast Iterative Least-Squares in Machine Learning | http://arxiv.org/abs/1706.00241 | id:1706.00241 author:Filip de Roos, Philipp Hennig category:cs.LG math.NA stat.ML  published:2017-06-01 summary:Solving symmetric positive definite linear problems is a fundamental computational task in machine learning. The exact solution, famously, is cubicly expensive in the size of the matrix. To alleviate this problem, several linear-time approximations, such as spectral and inducing-point methods, have been suggested and are now in wide use. These are low-rank approximations that choose the low-rank space a priori and do not refine it over time. While this allows linear cost in the data-set size, it also causes a finite, uncorrected approximation error. Authors from numerical linear algebra have explored ways to iteratively refine such low-rank approximations, at a cost of a small number of matrix-vector multiplications. This idea is particularly interesting in the many situations in machine learning where one has to solve a sequence of related symmetric positive definite linear problems. From the machine learning perspective, such deflation methods can be interpreted as transfer learning of a low-rank approximation across a time-series of numerical tasks. We study the use of such methods for our field. Our empirical results show that, on regression and classification problems of intermediate size, this approach can interpolate between low computational cost and numerical precision. version:1
arxiv-1706-00227 | An Effective Approach for Point Clouds Registration Based on the Hard and Soft Assignments | http://arxiv.org/abs/1706.00227 | id:1706.00227 author:Congcong Jin, Jihua Zhu, Yaochen Li, Shaoyi Du, Zhongyu Li, Huimin Lu category:cs.CV  published:2017-06-01 summary:For the registration of partially overlapping point clouds, this paper proposes an effective approach based on both the hard and soft assignments. Given two initially posed clouds, it firstly establishes the forward correspondence for each point in the data shape and calculates the value of binary variable, which can indicate whether this point correspondence is located in the overlapping areas or not. Then, it establishes the bilateral correspondence and computes bidirectional distances for each point in the overlapping areas. Based on the ratio of bidirectional distances, the exponential function is selected and utilized to calculate the probability value, which can indicate the reliability of the point correspondence. Subsequently, both the values of hard and soft assignments are embedded into the proposed objective function for registration of partially overlapping point clouds and a novel variant of ICP algorithm is proposed to obtain the optimal rigid transformation. The proposed approach can achieve good registration of point clouds, even when their overlap percentage is low. Experimental results tested on public data sets illustrate its superiority over previous approaches on accuracy and robustness. version:1
arxiv-1706-00212 | Depth Structure Preserving Scene Image Generation | http://arxiv.org/abs/1706.00212 | id:1706.00212 author:Wendong Zhang, Bingbing Ni, Yichao Yan, Jingwei Xu, Xiaokang Yang category:cs.CV  published:2017-06-01 summary:Key to automatically generate natural scene images is to properly arrange among various spatial elements, especially in the depth direction. To this end, we introduce a novel depth structure preserving scene image generation network (DSP-GAN), which favors a hierarchical and heterogeneous architecture, for the purpose of depth structure preserving scene generation. The main trunk of the proposedinfrastructureisbuiltonaHawkespointprocessthat models the spatial dependency between different depth layers. Within each layer generative adversarial sub-networks are trained collaboratively to generate realistic scene components, conditioned on the layer information produced by the point process. We experiment our model on a sub-set of SUNdataset with annotated scene images and demonstrate that our models are capable of generating depth-realistic natural scene image. version:1
arxiv-1706-00188 | Deep Learning for Hate Speech Detection in Tweets | http://arxiv.org/abs/1706.00188 | id:1706.00188 author:Pinkesh Badjatiya, Shashank Gupta, Manish Gupta, Vasudeva Varma category:cs.CL cs.IR  published:2017-06-01 summary:Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging. We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity. Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by ~18 F1 points. version:1
arxiv-1706-00182 | Efficient learning with robust gradient descent | http://arxiv.org/abs/1706.00182 | id:1706.00182 author:Matthew J. Holland, Kazushi Ikeda category:stat.ML  published:2017-06-01 summary:Minimizing the empirical risk is a popular training strategy, but for learning tasks where the data may be noisy or heavy-tailed, one may require many observations in order to generalize well. To achieve better performance under less stringent requirements, we introduce a procedure which constructs a robust approximation of the risk gradient for use in an iterative learning routine. We provide high-probability bounds on the excess risk of this algorithm, by showing that it does not deviate far from the ideal gradient-based update. Empirical tests show that in diverse settings, the proposed procedure can learn more efficiently, using less resources (iterations and observations) while generalizing better. version:1
arxiv-1705-10021 | Data Driven Coded Aperture Design for Depth Recovery | http://arxiv.org/abs/1705.10021 | id:1705.10021 author:Prasan A Shedligeri, Sreyas Mohan, Kaushik Mitra category:cs.CV  published:2017-05-29 summary:Inserting a patterned occluder at the aperture of a camera lens has been shown to improve the recovery of depth map and all-focus image compared to a fully open aperture. However, design of the aperture pattern plays a very critical role. Previous approaches for designing aperture codes make simple assumptions on image distributions to obtain metrics for evaluating aperture codes. However, real images may not follow those assumptions and hence the designed code may not be optimal for them. To address this drawback we propose a data driven approach for learning the optimal aperture pattern to recover depth map from a single coded image. We propose a two stage architecture where, in the first stage we simulate coded aperture images from a training dataset of all-focus images and depth maps and in the second stage we recover the depth map using a deep neural network. We demonstrate that our learned aperture code performs better than previously designed codes even on code design metrics proposed by previous approaches. version:2
arxiv-1706-00153 | Cross-modal Common Representation Learning by Hybrid Transfer Network | http://arxiv.org/abs/1706.00153 | id:1706.00153 author:Xin Huang, Yuxin Peng, Mingkuan Yuan category:cs.MM cs.CV cs.LG  published:2017-06-01 summary:DNN-based cross-modal retrieval is a research hotspot to retrieve across different modalities as image and text, but existing methods often face the challenge of insufficient cross-modal training data. In single-modal scenario, similar problem is usually relieved by transferring knowledge from large-scale auxiliary datasets (as ImageNet). Knowledge from such single-modal datasets is also very useful for cross-modal retrieval, which can provide rich general semantic information that can be shared across different modalities. However, it is challenging to transfer useful knowledge from single-modal (as image) source domain to cross-modal (as image/text) target domain. Knowledge in source domain cannot be directly transferred to both two different modalities in target domain, and the inherent cross-modal correlation contained in target domain provides key hints for cross-modal retrieval which should be preserved during transfer process. This paper proposes Cross-modal Hybrid Transfer Network (CHTN) with two subnetworks: Modal-sharing transfer subnetwork utilizes the modality in both source and target domains as a bridge, for transferring knowledge to both two modalities simultaneously; Layer-sharing correlation subnetwork preserves the inherent cross-modal semantic correlation to further adapt to cross-modal retrieval task. Cross-modal data can be converted to common representation by CHTN for retrieval, and comprehensive experiment on 3 datasets shows its effectiveness. version:1
arxiv-1706-00150 | Shape and Positional Geometry of Multi-Object Configurations | http://arxiv.org/abs/1706.00150 | id:1706.00150 author:James Damon, Ellen Gasparovic category:cs.CV 68  published:2017-06-01 summary:In previous work, we introduced a method for modeling a configuration of objects in 2D and 3D images using a mathematical "medial/skeletal linking structure." In this paper, we show how these structures allow us to capture positional properties of a multi-object configuration in addition to the shape properties of the individual objects. In particular, we introduce numerical invariants for positional properties which measure the closeness of neighboring objects, including identifying the parts of the objects which are close, and the "relative significance" of objects compared with the other objects in the configuration. Using these numerical measures, we introduce a hierarchical ordering and relations between the individual objects, and quantitative criteria for identifying subconfigurations. In addition, the invariants provide a "proximity matrix" which yields a unique set of weightings measuring overall proximity of objects in the configuration. Furthermore, we show that these invariants, which are volumetrically defined and involve external regions, may be computed via integral formulas in terms of "skeletal linking integrals" defined on the internal skeletal structures of the objects. version:1
arxiv-1706-00140 | Faster Spatially Regularized Correlation Filters for Visual Tracking | http://arxiv.org/abs/1706.00140 | id:1706.00140 author:Xiaoxiang Hu, Yujiu Yang category:cs.CV  published:2017-06-01 summary:Discriminatively learned correlation filters (DCF) have been widely used in online visual tracking filed due to its simplicity and efficiency. These methods utilize a periodic assumption of the training samples to construct a circulant data matrix, which implicitly increases the training samples and reduces both storage and computational complexity.The periodic assumption also introduces unwanted boundary effects. Recently, Spatially Regularized Correlation Filters (SRDCF) solved this issue by introducing penalization on correlation filter coefficients depending on their spatial location. However, SRDCF's efficiency dramatically decreased due to the breaking of circulant structure. We propose Faster Spatially Regularized Discriminative Correlation Filters (FSRDCF) for tracking. The FSRDCF is constructed from Ridge Regression, the circulant structure of training samples in the spatial domain is fully used, more importantly, we further exploit the circulant structure of regularization function in the Fourier domain, which allows our problem to be solved more directly and efficiently. Experiments are conducted on three benchmark datasets: OTB-2013, OTB-2015 and VOT2016. Our approach achieves equivalent performance to the baseline tracker SRDCF on all three datasets. On OTB-2013 and OTB-2015 datasets, our approach obtains a more than twice faster running speed and a more than third times shorter start-up time than the SRDCF. For state-of-the-art comparison, our approach demonstrates superior performance compared to other non-spatial-regularization trackers. version:1
arxiv-1706-00139 | Natural Language Generation for Spoken Dialogue System using RNN Encoder-Decoder Networks | http://arxiv.org/abs/1706.00139 | id:1706.00139 author:Van-Khanh Tran, Le-Minh Nguyen category:cs.CL  published:2017-06-01 summary:Natural language generation (NLG) is a critical component in a spoken dialogue system. This paper presents a Recurrent Neural Network based Encoder-Decoder architecture, in which an LSTM-based decoder is introduced to select, aggregate semantic elements produced by an attention mechanism over the input elements, and to produce the required utterances. The proposed generator can be jointly trained both sentence planning and surface realization to produce natural language sentences. The proposed model was extensively evaluated on four different NLG datasets. The experimental results showed that the proposed generators not only consistently outperform the previous methods across all the NLG domains but also show an ability to generalize from a new, unseen domain and learn from multi-domain datasets. version:1
arxiv-1706-00136 | Scalable Generalized Linear Bandits: Online Computation and Hashing | http://arxiv.org/abs/1706.00136 | id:1706.00136 author:Kwang-Sung Jun, Aniruddha Bhargava, Robert Nowak, Rebecca Willett category:stat.ML cs.LG  published:2017-06-01 summary:Generalized Linear Bandits (GLBs), a natural extension of the stochastic linear bandits, has been popular and successful in recent years. However, existing GLBs scale poorly with the number of rounds and the number of arms, limiting their utility in practice. This paper proposes new, scalable solutions to the GLB problem in two respects. First, unlike existing GLBs, whose per-time-step space and time complexity grow at least linearly with time $t$, we propose a new algorithm that performs online computations to enjoy a constant space and time complexity. At its heart is a novel Generalized Linear extension of the Online-to-confidence-set Conversion (GLOC method) that takes \emph{any} online learning algorithm and turns it into a GLB algorithm. As a special case, we apply GLOC to the online Newton step algorithm, which results in a low-regret GLB algorithm with much lower time and memory complexity than prior work. Second, for the case where the number $N$ of arms is very large, we propose new algorithms in which each next arm is selected via an inner product search. Such methods can be implemented via hashing algorithms (i.e., "hash-amenable") and result in a time complexity sublinear in $N$. While a Thompson sampling extension of GLOC is hash-amenable, its regret bound for $d$-dimensional arm sets scales with $d^{3/2}$, whereas GLOC's regret bound is linear in $d$. Towards closing this gap, we propose a new hash-amenable algorithm whose regret bound scales with $d^{5/4}$. Finally, we propose a fast approximate hash-key computation (inner product) that has a better accuracy than the state-of-the-art, which can be of independent interest. We conclude the paper with preliminary experimental results confirming the merits of our methods. version:1
arxiv-1706-00120 | Superhuman Accuracy on the SNEMI3D Connectomics Challenge | http://arxiv.org/abs/1706.00120 | id:1706.00120 author:Kisuk Lee, Jonathan Zung, Peter Li, Viren Jain, H. Sebastian Seung category:cs.CV  published:2017-05-31 summary:For the past decade, convolutional networks have been used for 3D reconstruction of neurons from electron microscopic (EM) brain images. Recent years have seen great improvements in accuracy, as evidenced by submissions to the SNEMI3D benchmark challenge. Here we report the first submission to surpass the estimate of human accuracy provided by the SNEMI3D leaderboard. A variant of 3D U-Net is trained on a primary task of predicting affinities between nearest neighbor voxels, and an auxiliary task of predicting long-range affinities. The training data is augmented by simulated image defects. The nearest neighbor affinities are used to create an oversegmentation, and then supervoxels are greedily agglomerated based on mean affinity. The resulting SNEMI3D score exceeds the estimate of human accuracy by a large margin. While one should be cautious about extrapolating from the SNEMI3D benchmark to real-world accuracy of large-scale neural circuit reconstruction, our result inspires optimism that the goal of full automation may be realizable in the future. version:1
arxiv-1706-00119 | Subjective fairness: Fairness is in the eye of the beholder | http://arxiv.org/abs/1706.00119 | id:1706.00119 author:Christos Dimitrakakis, Yang Liu, David Parkes, Goran Radanovic category:cs.LG stat.ML  published:2017-05-31 summary:We analyze different notions of fairness in decision making when the underlying model is not known with certainty. We argue that recent notions of fairness in machine learning need to be modified to incorporate uncertainties about model parameters. We introduce the notion of {\em subjective fairness} as a suitable candidate for fair Bayesian decision making rules, relate this definition with existing ones, and experimentally demonstrate the inherent accuracy-fairness tradeoff under this definition. version:1
arxiv-1705-10715 | Multi-View Task-Driven Recognition in Visual Sensor Networks | http://arxiv.org/abs/1705.10715 | id:1705.10715 author:Ali Taalimi, Alireza Rahimpour, Liu Liu, Hairong Qi category:cs.CV  published:2017-05-30 summary:Nowadays, distributed smart cameras are deployed for a wide set of tasks in several application scenarios, ranging from object recognition, image retrieval, and forensic applications. Due to limited bandwidth in distributed systems, efficient coding of local visual features has in fact been an active topic of research. In this paper, we propose a novel approach to obtain a compact representation of high-dimensional visual data using sensor fusion techniques. We convert the problem of visual analysis in resource-limited scenarios to a multi-view representation learning, and we show that the key to finding properly compressed representation is to exploit the position of cameras with respect to each other as a norm-based regularization in the particular signal representation of sparse coding. Learning the representation of each camera is viewed as an individual task and a multi-task learning with joint sparsity for all nodes is employed. The proposed representation learning scheme is referred to as the multi-view task-driven learning for visual sensor network (MT-VSN). We demonstrate that MT-VSN outperforms state-of-the-art in various surveillance recognition tasks. version:2
arxiv-1706-00098 | Bayesian $l_0$ Regularized Least Squares | http://arxiv.org/abs/1706.00098 | id:1706.00098 author:Nicholas G. Polson, Lei Sun category:stat.ML stat.CO 62-04  published:2017-05-31 summary:Bayesian $l_0$-regularized least squares provides a variable selection technique for high dimensional predictors. The challenge in $l_0$ regularization is optimizing a non-convex objective function via search over model space consisting of all possible predictor combinations, a NP-hard task. Spike-and-slab (a.k.a. Bernoulli-Gaussian, BG) priors are the gold standard for Bayesian variable selection, with a caveat of computational speed and scalability. We show that a Single Best Replacement (SBR) algorithm is a fast scalable alternative. Although SBR calculates a sparse posterior mode, we show that it possesses a number of equivalences and optimality properties of a posterior mean. To illustrate our methodology, we provide simulation evidence and a real data example on the statistical properties and computational efficiency of SBR versus direct posterior sampling using spike-and-slab priors. Finally, we conclude with directions for future research. version:1
arxiv-1706-00095 | Using GPI-2 for Distributed Memory Paralleliziation of the Caffe Toolbox to Speed up Deep Neural Network Training | http://arxiv.org/abs/1706.00095 | id:1706.00095 author:Martin Kuehn, Janis Keuper, Franz-Josef Pfreundt category:cs.LG cs.DC  published:2017-05-31 summary:Deep Neural Network (DNN) are currently of great inter- est in research and application. The training of these net- works is a compute intensive and time consuming task. To reduce training times to a bearable amount at reasonable cost we extend the popular Caffe toolbox for DNN with an efficient distributed memory communication pattern. To achieve good scalability we emphasize the overlap of computation and communication and prefer fine granu- lar synchronization patterns over global barriers. To im- plement these communication patterns we rely on the the Global address space Programming Interface version 2 (GPI-2) communication library. This interface provides a light-weight set of asynchronous one-sided communica- tion primitives supplemented by non-blocking fine gran- ular data synchronization mechanisms. Therefore, Caf- feGPI is the name of our parallel version of Caffe. First benchmarks demonstrate better scaling behavior com- pared with other extensions, e.g., the Intel TM Caffe. Even within a single symmetric multiprocessing machine with four graphics processing units, the CaffeGPI scales bet- ter than the standard Caffe toolbox. These first results demonstrate that the use of standard High Performance Computing (HPC) hardware is a valid cost saving ap- proach to train large DDNs. I/O is an other bottleneck to work with DDNs in a standard parallel HPC setting, which we will consider in more detail in a forthcoming paper. version:1
arxiv-1706-00090 | Lower Bounds on Regret for Noisy Gaussian Process Bandit Optimization | http://arxiv.org/abs/1706.00090 | id:1706.00090 author:Jonathan Scarlett, Ilijia Bogunovic, Volkan Cevher category:stat.ML cs.IT cs.LG math.IT  published:2017-05-31 summary:In this paper, we consider the problem of sequentially optimizing a black-box function $f$ based on noisy samples and bandit feedback. We assume that $f$ is smooth in the sense of having a bounded norm in some reproducing kernel Hilbert space (RKHS), yielding a commonly-considered non-Bayesian form of Gaussian process bandit optimization. We provide algorithm-independent lower bounds on the simple regret, measuring the suboptimality of a single point reported after $T$ rounds, and on the cumulative regret, measuring the sum of regrets over the $T$ chosen points. For the isotropic squared-exponential kernel in $d$ dimensions, we find that an average simple regret of $\epsilon$ requires $T = \Omega\big(\frac{1}{\epsilon^2} (\log\frac{1}{\epsilon})^{d/2}\big)$, and the average cumulative regret is at least $\Omega\big( \sqrt{T(\log T)^d} \big)$, thus matching existing upper bounds up to the replacement of $d/2$ by $d+O(1)$ in both cases. For the Mat\'ern-$\nu$ kernel, we give analogous bounds of the form $\Omega\big( (\frac{1}{\epsilon})^{2+d/\nu}\big)$ and $\Omega\big( T^{\frac{\nu + d}{2\nu + d}} \big)$, and discuss the resulting gaps to the existing upper bounds. version:1
arxiv-1706-00083 | Blood capillaries and vessels segmentation in optical coherence tomography angiogram using fuzzy C-means and Curvelet transform | http://arxiv.org/abs/1706.00083 | id:1706.00083 author:Fariborz Taherkhani category:cs.CV  published:2017-05-31 summary:This paper has been removed from arXiv as the submitter did not have ownership of the data presented in this work. version:1
arxiv-1706-00082 | Megapixel Size Image Creation using Generative Adversarial Networks | http://arxiv.org/abs/1706.00082 | id:1706.00082 author:Marco Marchesi category:cs.CV cs.GR cs.LG I.5.1  published:2017-05-31 summary:Since its appearance, Generative Adversarial Networks (GANs) have received a lot of interest in the AI community. In image generation several projects showed how GANs are able to generate photorealistic images but the results so far did not look adequate for the quality standard of visual media production industry. We present an optimized image generation process based on a Deep Convolutional Generative Adversarial Networks (DCGANs), in order to create photorealistic high-resolution images (up to 1024x1024 pixels). Furthermore, the system was fed with a limited dataset of images, less than two thousand images. All these results give more clue about future exploitation of GANs in Computer Graphics and Visual Effects. version:1
arxiv-1706-00079 | Putting a Face to the Voice: Fusing Audio and Visual Signals Across a Video to Determine Speakers | http://arxiv.org/abs/1706.00079 | id:1706.00079 author:Ken Hoover, Sourish Chaudhuri, Caroline Pantofaru, Malcolm Slaney, Ian Sturdy category:cs.MM cs.CV cs.SD  published:2017-05-31 summary:In this paper, we present a system that associates faces with voices in a video by fusing information from the audio and visual signals. The thesis underlying our work is that an extremely simple approach to generating (weak) speech clusters can be combined with visual signals to effectively associate faces and voices by aggregating statistics across a video. This approach does not need any training data specific to this task and leverages the natural coherence of information in the audio and visual streams. It is particularly applicable to tracking speakers in videos on the web where a priori information about the environment (e.g., number of speakers, spatial signals for beamforming) is not available. We performed experiments on a real-world dataset using this analysis framework to determine the speaker in a video. Given a ground truth labeling determined by human rater consensus, our approach had ~71% accuracy. version:1
arxiv-1706-00078 | Low-Rank Matrix Approximation in the Infinity Norm | http://arxiv.org/abs/1706.00078 | id:1706.00078 author:Nicolas Gillis, Yaroslav Shitov category:cs.CC cs.LG math.NA math.OC  published:2017-05-31 summary:The low-rank matrix approximation problem with respect to the entry-wise $\ell_{\infty}$-norm is the following: given a matrix $M$ and a factorization rank $r$, find a matrix $X$ whose rank is at most $r$ and that minimizes $\max_{i,j} M_{ij} - X_{ij} $. In this paper, we prove that the decision variant of this problem for $r=1$ is NP-complete using a reduction from the problem `not all equal 3SAT'. We also analyze several cases when the problem can be solved in polynomial time, and propose a simple practical heuristic algorithm which we apply on the problem of the recovery of a quantized low-rank matrix. version:1
arxiv-1705-00316 | A Conditional Variational Framework for Dialog Generation | http://arxiv.org/abs/1705.00316 | id:1705.00316 author:Xiaoyu Shen, Hui Su, Yanran Li, Wenjie Li, Shuzi Niu, Yang Zhao, Akiko Aizawa, Guoping Long category:cs.CL  published:2017-04-30 summary:Deep latent variable models have been shown to facilitate the response generation for open-domain dialog systems. However, these latent variables are highly randomized, leading to uncontrollable generated responses. In this paper, we propose a framework allowing conditional response generation based on specific attributes. These attributes can be either manually assigned or automatically detected. Moreover, the dialog states for both speakers are modeled separately in order to reflect personal features. We validate this framework on two different scenarios, where the attribute refers to genericness and sentiment states respectively. The experiment result testified the potential of our model, where meaningful responses can be generated in accordance with the specified attributes. version:3
arxiv-1705-05633 | Social Media-based Substance Use Prediction | http://arxiv.org/abs/1705.05633 | id:1705.05633 author:Tao Ding, Warren K. Bickel, Shimei Pan category:cs.CL cs.LG cs.SI  published:2017-05-16 summary:In this paper, we demonstrate how the state-of-the-art machine learning and text mining techniques can be used to build effective social media-based substance use detection systems. Since a substance use ground truth is difficult to obtain on a large scale, to maximize system performance, we explore different feature learning methods to take advantage of a large amount of unsupervised social media data. We also demonstrate the benefit of using multi-view unsupervised feature learning to combine heterogeneous user information such as Facebook `"likes" and "status updates" to enhance system performance. Based on our evaluation, our best models achieved 86% AUC for predicting tobacco use, 81% for alcohol use and 84% for drug use, all of which significantly outperformed existing methods. Our investigation has also uncovered interesting relations between a user's social media behavior (e.g., word usage) and substance use. version:2
arxiv-1706-00061 | The Sample Complexity of Online One-Class Collaborative Filtering | http://arxiv.org/abs/1706.00061 | id:1706.00061 author:Reinhard Heckel, Kannan Ramchandran category:cs.LG cs.AI cs.IT math.IT stat.ML  published:2017-05-31 summary:We consider the online one-class collaborative filtering (CF) problem that consists of recommending items to users over time in an online fashion based on positive ratings only. This problem arises when users respond only occasionally to a recommendation with a positive rating, and never with a negative one. We study the impact of the probability of a user responding to a recommendation, p_f, on the sample complexity, i.e., the number of ratings required to make `good' recommendations, and ask whether receiving positive and negative ratings, instead of positive ratings only, improves the sample complexity. Both questions arise in the design of recommender systems. We introduce a simple probabilistic user model, and analyze the performance of an online user-based CF algorithm. We prove that after an initial cold start phase, where recommendations are invested in exploring the user's preferences, this algorithm makes---up to a fraction of the recommendations required for updating the user's preferences---perfect recommendations. The number of ratings required for the cold start phase is nearly proportional to 1/p_f, and that for updating the user's preferences is essentially independent of p_f. As a consequence we find that, receiving positive and negative ratings instead of only positive ones improves the number of ratings required for initial exploration by a factor of 1/p_f, which can be significant. version:1
arxiv-1706-00051 | Deep Generative Adversarial Networks for Compressed Sensing Automates MRI | http://arxiv.org/abs/1706.00051 | id:1706.00051 author:Morteza Mardani, Enhao Gong, Joseph Y. Cheng, Shreyas Vasanawala, Greg Zaharchuk, Marcus Alley, Neil Thakur, Song Han, William Dally, John M. Pauly, Lei Xing category:cs.CV cs.LG stat.ML  published:2017-05-31 summary:Magnetic resonance image (MRI) reconstruction is a severely ill-posed linear inverse task demanding time and resource intensive computations that can substantially trade off {\it accuracy} for {\it speed} in real-time imaging. In addition, state-of-the-art compressed sensing (CS) analytics are not cognizant of the image {\it diagnostic quality}. To cope with these challenges we put forth a novel CS framework that permeates benefits from generative adversarial networks (GAN) to train a (low-dimensional) manifold of diagnostic-quality MR images from historical patients. Leveraging a mixture of least-squares (LS) GANs and pixel-wise $\ell_1$ cost, a deep residual network with skip connections is trained as the generator that learns to remove the {\it aliasing} artifacts by projecting onto the manifold. LSGAN learns the texture details, while $\ell_1$ controls the high-frequency noise. A multilayer convolutional neural network is then jointly trained based on diagnostic quality images to discriminate the projection quality. The test phase performs feed-forward propagation over the generator network that demands a very low computational overhead. Extensive evaluations are performed on a large contrast-enhanced MR dataset of pediatric patients. In particular, images rated based on expert radiologists corroborate that GANCS retrieves high contrast images with detailed texture relative to conventional CS, and pixel-wise schemes. In addition, it offers reconstruction under a few milliseconds, two orders of magnitude faster than state-of-the-art CS-MRI schemes. version:1
arxiv-1705-10768 | Reflection Invariant and Symmetry Detection | http://arxiv.org/abs/1705.10768 | id:1705.10768 author:Erbo Li, Hua Li category:cs.CV  published:2017-05-30 summary:Symmetry detection and discrimination are of fundamental meaning in science, technology, and engineering. This paper introduces reflection invariants and defines the directional moment to detect symmetry for shape analysis and object recognition. And it demonstrates that detection of reflection symmetry can be done in a simple way by solving a trigonometric system derived from the directional moment, and discrimination of reflection symmetry can be achieved by application of the reflection invariants in 2D and 3D. Rotation symmetry can also be determined based on that.The experiments in 2D and 3D, including the regular triangle, the square, and the five Platonic objects, show that all the reflection lines or planes can be deterministically found using directional moments up to order six. This result can be used to simplify the efforts of symmetry detection in research areas, such as protein structure, model retrieval, inverse engineering, and machine vision etc. version:2
arxiv-1706-00046 | Learning Time-Efficient Deep Architectures with Budgeted Super Networks | http://arxiv.org/abs/1706.00046 | id:1706.00046 author:Tom Veniat, Ludovic Denoyer category:cs.LG  published:2017-05-31 summary:Learning neural network architectures is a way to discover new highly predictive models. We propose to focus on this problem from a different perspective where the goal is to discover architectures efficient in terms of both prediction quality and computation cost, e.g time in milliseconds, number of operations... For instance, our approach is able to solve the following task: find the best neural network architecture (in a very large set of possible architectures) able to predict well in less than 100 milliseconds on my mobile phone. Our contribution is based on a new family of models called Budgeted Super Networks that are learned using reinforcement-learning inspired techniques applied to a budgeted learning objective function which includes the computation cost during disk/memory operations at inference. We present a set of experiments on computer vision problems and show the ability of our method to discover efficient architectures in terms of both predictive quality and computation time. version:1
arxiv-1706-00043 | Biased Importance Sampling for Deep Neural Network Training | http://arxiv.org/abs/1706.00043 | id:1706.00043 author:Angelos Katharopoulos, François Fleuret category:cs.LG  published:2017-05-31 summary:Importance sampling has been successfully used to accelerate stochastic optimization in many convex problems. However, the lack of an efficient way to calculate the importance still hinders its application to Deep Learning. In this paper, we show that the loss value can be used as an alternative importance metric, and propose a way to efficiently approximate it for a deep model, using a small model trained for that purpose in parallel. This method allows in particular to utilize a biased gradient estimate that implicitly optimizes a soft max-loss, and leads to better generalization performance. While such method suffers from a prohibitively high variance of the gradient estimate when using a standard stochastic optimizer, we show that when it is combined with our sampling mechanism, it results in a reliable procedure. We showcase the generality of our method by testing it on both image classification and language modeling tasks using deep convolutional and recurrent neural networks. In particular, in case of CIFAR10 we reach 10% classification error 50 epochs faster than when using uniform sampling. version:1
arxiv-1706-00038 | Toward Robustness against Label Noise in Training Deep Discriminative Neural Networks | http://arxiv.org/abs/1706.00038 | id:1706.00038 author:Arash Vahdat category:cs.LG stat.ML  published:2017-05-31 summary:Collecting large training datasets, annotated with high quality labels, is a costly process. This paper proposes a novel framework for training deep convolutional neural networks from noisy labeled datasets. The problem is formulated using an undirected graphical model that represents the relationship between noisy and clean labels, trained in a semi-supervised setting. In the proposed structure, the inference over latent clean labels is tractable and is regularized during training using auxiliary sources of information. The proposed model is applied to the image labeling problem and is shown to be effective in labeling unseen images as well as reducing label noise in training on CIFAR-10 and MS COCO datasets. version:1
arxiv-1706-00672 | Development of a N-type GM-PHD Filter for Multiple Target, Multiple Type Visual Tracking | http://arxiv.org/abs/1706.00672 | id:1706.00672 author:Nathanael L. Baisa, Andrew Wallace category:cs.CV  published:2017-05-31 summary:We propose a new framework that extends the standard Probability Hypothesis Density (PHD) filter for multiple targets having $N$ different types where $N\geq2$ based on Random Finite Set (RFS) theory, taking into account not only background false positives (clutter), but also confusions among detections of different target types, which are in general different in character from background clutter. Under the assumptions of Gaussianity and linearity, our framework extends the existing Gaussian mixture (GM) implementation of the standard PHD filter to create a N-type GM-PHD filter. The methodology is applied to real video sequences by integrating object detectors' information into this filter for two scenarios. In the first scenario, a tri-GM-PHD filter ($N=3$) is applied to real video sequences containing three types of multiple targets in the same scene, two football teams and a referee, using separate but confused detections. In the second scenario, we use a dual GM-PHD filter ($N=2$) for tracking pedestrians and vehicles in the same scene handling their detectors' confusions. For both cases, Munkres's variant of the Hungarian assignment algorithm is used to associate tracked target identities between frames. This approach is evaluated and compared to both raw detection and independent GM-PHD filters using the Optimal Sub-pattern Assignment (OSPA) metric and the discrimination rate. This shows the improved performance of our strategy on real video sequences. version:1
arxiv-1705-11192 | Emergence of Language with Multi-agent Games: Learning to Communicate with Sequences of Symbols | http://arxiv.org/abs/1705.11192 | id:1705.11192 author:Serhii Havrylov, Ivan Titov category:cs.LG cs.CL cs.CV cs.MA  published:2017-05-31 summary:Learning to communicate through interaction, rather than relying on explicit supervision, is often considered a prerequisite for developing a general AI. We study a setting where two agents engage in playing a referential game and, from scratch, develop a communication protocol necessary to succeed in this game. Unlike previous work, we require that messages they exchange, both at train and test time, are in the form of a language (i.e. sequences of discrete symbols). We compare a reinforcement learning approach and one using a differentiable relaxation (straight-through Gumbel-softmax estimator) and observe that the latter is much faster to converge and it results in more effective protocols. Interestingly, we also observe that the protocol we induce by optimizing the communication success exhibits a degree of compositionality and variability (i.e. the same information can be phrased in different ways), both properties characteristic of natural languages. As the ultimate goal is to ensure that communication is accomplished in natural language, we also perform experiments where we inject prior information about natural language into our model and study properties of the resulting protocol. version:1
arxiv-1705-06366 | Automatic Goal Generation for Reinforcement Learning Agents | http://arxiv.org/abs/1705.06366 | id:1705.06366 author:David Held, Xinyang Geng, Carlos Florensa, Pieter Abbeel category:cs.LG cs.AI cs.RO  published:2017-05-17 summary:Reinforcement learning is a powerful technique to train an agent to perform a task. However, an agent that is trained using reinforcement learning is only capable of achieving the single task that is specified via its reward function. Such an approach does not scale well to settings in which an agent needs to perform a diverse set of tasks, such as navigating to varying positions in a room or moving objects to varying locations. Instead, we propose a method that allows an agent to automatically discover the range of tasks that it is capable of performing. We use a generator network to propose tasks for the agent to try to achieve, specified as goal states. The generator network is optimized using adversarial training to produce tasks that are always at the appropriate level of difficulty for the agent. Our method thus automatically produces a curriculum of tasks for the agent to learn. We show that, by using this framework, an agent can efficiently and automatically learn to perform a wide set of tasks without requiring any prior knowledge of its environment. Our method can also learn to achieve tasks with sparse rewards, which traditionally pose significant challenges. version:2
arxiv-1705-11187 | U-Phylogeny: Undirected Provenance Graph Construction in the Wild | http://arxiv.org/abs/1705.11187 | id:1705.11187 author:Aparna Bharati, Daniel Moreira, Allan Pinto, Joel Brogan, Kevin Bowyer, Patrick Flynn, Walter Scheirer, Anderson Rocha category:cs.CV  published:2017-05-31 summary:Deriving relationships between images and tracing back their history of modifications are at the core of Multimedia Phylogeny solutions, which aim to combat misinformation through doctored visual media. Nonetheless, most recent image phylogeny solutions cannot properly address cases of forged composite images with multiple donors, an area known as multiple parenting phylogeny (MPP). This paper presents a preliminary undirected graph construction solution for MPP, without any strict assumptions. The algorithm is underpinned by robust image representative keypoints and different geometric consistency checks among matching regions in both images to provide regions of interest for direct comparison. The paper introduces a novel technique to geometrically filter the most promising matches as well as to aid in the shared region localization task. The strength of the approach is corroborated by experiments with real-world cases, with and without image distractors (unrelated cases). version:1
arxiv-1705-11168 | Are distributional representations ready for the real world? Evaluating word vectors for grounded perceptual meaning | http://arxiv.org/abs/1705.11168 | id:1705.11168 author:Li Lucy, Jon Gauthier category:cs.CL  published:2017-05-31 summary:Distributional word representation methods exploit word co-occurrences to build compact vector encodings of words. While these representations enjoy widespread use in modern natural language processing, it is unclear whether they accurately encode all necessary facets of conceptual meaning. In this paper, we evaluate how well these representations can predict perceptual and conceptual features of concrete concepts, drawing on two semantic norm datasets sourced from human participants. We find that several standard word representations fail to encode many salient perceptual features of concepts, and show that these deficits correlate with word-word similarity prediction errors. Our analyses provide motivation for grounded and embodied language learning approaches, which may help to remedy these deficits. version:1
arxiv-1705-11166 | Adversarial Inversion: Inverse Graphics with Adversarial Priors | http://arxiv.org/abs/1705.11166 | id:1705.11166 author:Hsiao-Yu Fish Tung, Adam Harley, William Seto, Katerina Fragkiadaki category:cs.CV  published:2017-05-31 summary:We propose adversarial inversion, a weakly supervised neural network model that combines inverse rendering with adversarial networks. Given a set of images, our inverse rendering encoder predicts a set of latent factors (e.g., depth, camera pose), which a renderer then projects to reconstruct (part of) the visual input. Inversion is often ambiguous, e.g., many compositions of 3D shape and camera pose give rise to the same 2D projection. To address this ambiguity, we impose priors on the predicted latent factors, through an adversarial discriminator network trained to discriminate between predicted factors and ground-truth ones. Training adversarial inversion does not require input-output paired annotations, but merely a collection of ground-truth factors, unrelated (unpaired) to the current input. Our model can thus be self-supervised by unlabelled image data, by minimizing a joint reconstruction and adversarial loss, complementing any direct supervision provided by paired annotations. We apply adversarial inversion to 3D human pose estimation and 3D structure and egomotion estimation, and outperform models supervised by only paired annotations, and/or reconstruction losses, that do not use adversarial priors. Applying adversarial inversion to super-resolution and inpainting results in automated "visual plastic surgery". In adversarial super-resolution, when the discriminator is provided with young, old, female, male, or Tom Cruise faces as ground-truth, our model renders the input face image towards its young, old, feminine, masculine or Tom Cruise-like equivalent. In adversarial inpainting, when the discriminator is provided with faces with big lips or big noses as ground-truth, it creates visual lip or nose augmentations. version:1
arxiv-1706-00005 | Machine Learning Based Crackle Detection in Lung Sounds | http://arxiv.org/abs/1706.00005 | id:1706.00005 author:Morten Grønnesby, Juan Carlos Aviles Solis, Einar Holsbø, Hasse Melbye, Lars Ailo Bongo category:cs.SD cs.LG  published:2017-05-31 summary:The stethoscope is a well-known and widely available diagnostic instrument. In recent years, many innovative solutions for recording and viewing sounds from a stethoscope have become available. However, to fully utilize such devices, there is a need for an automated approach for detecting abnormal lung sounds, which is better than the existing methods that typically have been developed and evaluated using a small and non-diverse dataset. We propose a machine learning based approach for detecting crackles in lung sounds recorded using a stethoscope in a large health survey. Our method is trained and evaluated using 209 files with crackles classified by expert listeners. Our analysis pipeline is based on features extracted from small windows in audio files. We evaluated several feature extraction methods and classifiers. We evaluated the pipeline using a training set of 175 crackle windows and 208 normal windows. We found and evaluated a 5-dimenstional vector with four features from the time domain and one from the spectrum domain. We evaluated several classifiers and found SVM with a Radial Basis Function Kernel to perform best for our 5-dimensional feature vector. Our approach had a precision of 86% and recall of 84% for classifying a crackle in a window, which is more accurate than found in studies of health personnel. The low-dimensional feature vector makes the SVM very fast. The model can be trained on a regular computer in 1.44 seconds, and 319 crackles can be classified in 1.08 seconds. Our approach detects and visualizes individual crackles in recorded audio files. It is accurate, fast, and has low resource requirements. The approach is therefore well suited for deployment on smart devices and phones or as a web application. It can be used to train health personnel or as part of a smartphone application for Bluetooth stethoscopes. version:1
arxiv-1705-10748 | A Kernel Redundancy Removing Policy for Convolutional Neural Network | http://arxiv.org/abs/1705.10748 | id:1705.10748 author:Chih-Ting Liu, Yi-Heng Wu, Yu-Sheng Lin, Shao-Yi Chien category:cs.CV  published:2017-05-30 summary:Deep Convolutional Neural Networks (CNN) have won a significant place in the computer vision recently, which repeatedly convolving an image to extract the knowledge behind it. However, with the depth of convolutional layers getting deeper and deeper in recent years, the computational complexity also increases significantly, which make it difficult to be deployed on embedded systems with limited hardware resources. In this paper we propose a method to reduce the redundant convolution kernels during the computation of CNN and apply it to a network for super resolution (SR). Using PSNR drop compared to the original network as performance criterion, our method can get the optimal PSNR under a certain computation budget constraint. On the other hand, our method is also capable of minimizing the computation required under a given PSNR drop. version:2
arxiv-1705-11160 | Learning When to Attend for Neural Machine Translation | http://arxiv.org/abs/1705.11160 | id:1705.11160 author:Junhui Li, Muhua Zhu category:cs.CL  published:2017-05-31 summary:In the past few years, attention mechanisms have become an indispensable component of end-to-end neural machine translation models. However, previous attention models always refer to some source words when predicting a target word, which contradicts with the fact that some target words have no corresponding source words. Motivated by this observation, we propose a novel attention model that has the capability of determining when a decoder should attend to source words and when it should not. Experimental results on NIST Chinese-English translation tasks show that the new model achieves an improvement of 0.8 BLEU score over a state-of-the-art baseline. version:1
arxiv-1705-11159 | Reinforcement Learning for Learning Rate Control | http://arxiv.org/abs/1705.11159 | id:1705.11159 author:Chang Xu, Tao Qin, Gang Wang, Tie-Yan Liu category:cs.LG  published:2017-05-31 summary:Stochastic gradient descent (SGD), which updates the model parameters by adding a local gradient times a learning rate at each step, is widely used in model training of machine learning algorithms such as neural networks. It is observed that the models trained by SGD are sensitive to learning rates and good learning rates are problem specific. We propose an algorithm to automatically learn learning rates using neural network based actor-critic methods from deep reinforcement learning (RL).In particular, we train a policy network called actor to decide the learning rate at each step during training, and a value network called critic to give feedback about quality of the decision (e.g., the goodness of the learning rate outputted by the actor) that the actor made. The introduction of auxiliary actor and critic networks helps the main network achieve better performance. Experiments on different datasets and network architectures show that our approach leads to better convergence of SGD than human-designed competitors. version:1
arxiv-1705-11146 | SuperSpike: Supervised learning in multi-layer spiking neural networks | http://arxiv.org/abs/1705.11146 | id:1705.11146 author:Friedemann Zenke, Surya Ganguli category:q-bio.NC cs.LG cs.NE stat.ML  published:2017-05-31 summary:A vast majority of computation in the brain is performed by spiking neural networks. Despite the ubiquity of such spiking, we currently lack an understanding of how biological spiking neural circuits learn and compute in-vivo, as well as how we can instantiate such capabilities in artificial spiking circuits in-silico. Here we revisit the problem of supervised learning in temporally coding multi-layer spiking neural networks. First, by using a surrogate gradient approach, we derive SuperSpike, a nonlinear voltage-based three factor learning rule capable of training multi-layer networks of deterministic integrate-and-fire neurons to perform nonlinear computations on spatiotemporal spike patterns. Second, inspired by recent results on feedback alignment, we compare the performance of our learning rule under different credit assignment strategies for propagating output errors to hidden units. Specifically, we test uniform, symmetric and random feedback, finding that simpler tasks can be solved with any type of feedback, while more complex tasks require symmetric feedback. In summary, our results open the door to obtaining a better scientific understanding of learning and computation in spiking neural networks by advancing our ability to train them to solve nonlinear problems involving transformations between different spatiotemporal spike-time patterns. version:1
arxiv-1705-11140 | Variational Sequential Monte Carlo | http://arxiv.org/abs/1705.11140 | id:1705.11140 author:Christian A. Naesseth, Scott W. Linderman, Rajesh Ranganath, David M. Blei category:stat.ML stat.CO stat.ME  published:2017-05-31 summary:Variational inference underlies many recent advances in large scale probabilistic modeling. The success of variational approaches depends on (i) formulating a flexible parametric family of distributions; and (ii) optimizing the parameters to find the member of this family that most closely approximates the exact posterior. In this paper we present a new approximating family of distributions, variational sequential Monte Carlo (VSMC), and show how to optimize it in variational inference. VSMC melds variational inference (VI) and sequential Monte Carlo (SMC), providing practitioners with flexible, accurate, and powerful Bayesian inference. VSMC is a variational family that can approximate the posterior arbitrarily well, while still allowing for efficient optimization of its parameters. version:1
arxiv-1705-11136 | Representation Learning by Rotating Your Faces | http://arxiv.org/abs/1705.11136 | id:1705.11136 author:Luan Tran, Xi Yin, Xiaoming Liu category:cs.CV  published:2017-05-31 summary:The large pose discrepancy between two face images is one of the fundamental challenges in automatic face recognition. Conventional approaches to pose-invariant face recognition either perform face frontalization on, or learn a pose-invariant representation from, a non-frontal face image. We argue that it is more desirable to perform both tasks jointly to allow them to leverage each other. To this end, this paper proposes a Disentangled Representation learning-Generative Adversarial Network (DR-GAN) with three distinct novelties. First, the encoder-decoder structure of the generator enables DR-GAN to learn a representation that is both generative and discriminative, which can be used for face image synthesis and pose-invariant face recognition. Second, this representation is explicitly disentangled from other face variations such as pose, through the pose code provided to the decoder and pose estimation in the discriminator. Third, DR-GAN can take one or multiple images as the input, and generate one unified identity representation along with an arbitrary number of synthetic face images. Extensive quantitative and qualitative evaluation on a number of controlled and in-the-wild databases demonstrate the superiority of DR-GAN over the state of the art in both learning representations and rotating large-pose face images. version:1
arxiv-1705-11122 | Controllable Invariance through Adversarial Feature Learning | http://arxiv.org/abs/1705.11122 | id:1705.11122 author:Qizhe Xie, Zihang Dai, Yulun Du, Eduard Hovy, Graham Neubig category:cs.LG cs.AI cs.CL  published:2017-05-31 summary:Learning meaningful representations that maintain the content necessary for a particular task while filtering away detrimental variations is a problem of great interest in machine learning. In this paper, we tackle the problem of learning representations invariant to a specific factor or trait of data, leading to better generalization. The representation learning process is formulated as an adversarial minimax game. We analyze the optimal equilibrium of such a game and find that it amounts to maximizing the uncertainty of inferring the detrimental factor given the representation while maximizing the certainty of making task-specific predictions. On three benchmark tasks, namely fair and bias-free classification, language-independent generation, and lighting-independent image classification, we show that the proposed framework induces an invariant representation, and leads to better generalization evidenced by the improved test performance. version:1
arxiv-1705-11107 | Information Theoretic Properties of Markov Random Fields, and their Algorithmic Applications | http://arxiv.org/abs/1705.11107 | id:1705.11107 author:Linus Hamilton, Frederic Koehler, Ankur Moitra category:cs.LG cs.DS cs.IT math.IT math.ST stat.TH  published:2017-05-31 summary:Markov random fields area popular model for high-dimensional probability distributions. Over the years, many mathematical, statistical and algorithmic problems on them have been studied. Until recently, the only known algorithms for provably learning them relied on exhaustive search, correlation decay or various incoherence assumptions. Bresler gave an algorithm for learning general Ising models on bounded degree graphs. His approach was based on a structural result about mutual information in Ising models. Here we take a more conceptual approach to proving lower bounds on the mutual information through setting up an appropriate zero-sum game. Our proof generalizes well beyond Ising models, to arbitrary Markov random fields with higher order interactions. As an application, we obtain algorithms for learning Markov random fields on bounded degree graphs on $n$ nodes with $r$-order interactions in $n^r$ time and $\log n$ sample complexity. The sample complexity is information theoretically optimal up to the dependence on the maximum degree. The running time is nearly optimal under standard conjectures about the hardness of learning parity with noise. version:1
arxiv-1705-11105 | HiNet: Hierarchical Classification with Neural Network | http://arxiv.org/abs/1705.11105 | id:1705.11105 author:Zhenzhou Wu, Sean Saito category:cs.LG  published:2017-05-31 summary:Traditionally, classifying large hierarchical labels with more than 10000 distinct traces can only be achieved with flatten labels. Although flatten labels is feasible, it misses the hierarchical information in the labels. Hierarchical models like HSVM by \cite{vural2004hierarchical} becomes impossible to train because of the sheer number of SVMs in the whole architecture. We developed a hierarchical architecture based on neural networks that is simple to train. Also, we derived an inference algorithm that can efficiently infer the MAP (maximum a posteriori) trace guaranteed by our theorems. Furthermore, the complexity of the model is only $O(n^2)$ compared to $O(n^h)$ in a flatten model, where $h$ is the height of the hierarchy. version:1
arxiv-1705-11077 | EvaluationNet: Can Human Skill be Evaluated by Deep Networks? | http://arxiv.org/abs/1705.11077 | id:1705.11077 author:Seong Tae Kim, Yong Man Ro category:cs.CV  published:2017-05-31 summary:With the recent substantial growth of media such as YouTube, a considerable number of instructional videos covering a wide variety of tasks are available online. Therefore, online instructional videos have become a rich resource for humans to learn everyday skills. In order to improve the effectiveness of the learning with instructional video, observation and evaluation of the activity are required. However, it is difficult to observe and evaluate every activity steps by expert. In this study, a novel deep learning framework which targets human activity evaluation for learning from instructional video has been proposed. In order to deal with the inherent variability of activities, we propose to model activity as a structured process. First, action units are encoded from dense trajectories with LSTM network. The variable-length action unit features are then evaluated by a Siamese LSTM network. By the comparative experiments on public dataset, the effectiveness of the proposed method has been demonstrated. version:1
arxiv-1705-07099 | Machine learning for classification and quantification of monoclonal antibody preparations for cancer therapy | http://arxiv.org/abs/1705.07099 | id:1705.07099 author:Laetitia Le, Camille Marini, Alexandre Gramfort, David Nguyen, Mehdi Cherti, Sana Tfaili, Ali Tfayli, Arlette Baillet-Guffroy, Patrice Prognon, Pierre Chaminade, Eric Caudron, Balázs Kégl category:q-bio.QM cs.LG  published:2017-05-19 summary:Monoclonal antibodies constitute one of the most important strategies to treat patients suffering from cancers such as hematological malignancies and solid tumors. In order to guarantee the quality of those preparations prepared at hospital, quality control has to be developed. The aim of this study was to explore a noninvasive, nondestructive, and rapid analytical method to ensure the quality of the final preparation without causing any delay in the process. We analyzed four mAbs (Inlfiximab, Bevacizumab, Ramucirumab and Rituximab) diluted at therapeutic concentration in chloride sodium 0.9% using Raman spectroscopy. To reduce the prediction errors obtained with traditional chemometric data analysis, we explored a data-driven approach using statistical machine learning methods where preprocessing and predictive models are jointly optimized. We prepared a data analytics workflow and submitted the problem to a collaborative data challenge platform called Rapid Analytics and Model Prototyping (RAMP). This allowed to use solutions from about 300 data scientists during five days of collaborative work. The prediction of the four mAbs samples was considerably improved with a misclassification rate and the mean error rate of 0.8% and 4%, respectively. version:2
arxiv-1705-11053 | Neuron Segmentation Using Deep Complete Bipartite Networks | http://arxiv.org/abs/1705.11053 | id:1705.11053 author:Jianxu Chen, Sreya Banerjee, Abhinav Grama, Walter J. Scheirer, Danny Z. Chen category:cs.CV  published:2017-05-31 summary:In this paper, we consider the problem of automatically segmenting neuronal cells in dual-color confocal microscopy images. This problem is a key task in various quantitative analysis applications in neuroscience, such as tracing cell genesis in Danio rerio (zebrafish) brains. Deep learning, especially using fully convolutional networks (FCN), has profoundly changed segmentation research in biomedical imaging. We face two major challenges in this problem. First, neuronal cells may form dense clusters, making it difficult to correctly identify all individual cells (even to human experts). Consequently, segmentation results of the known FCN-type models are not accurate enough. Second, pixel-wise ground truth is difficult to obtain. Only a limited amount of approximate instance-wise annotation can be collected, which makes the training of FCN models quite cumbersome. We propose a new FCN-type deep learning model, called deep complete bipartite networks (CB-Net), and a new scheme for leveraging approximate instance-wise annotation to train our pixel-wise prediction model. Evaluated using seven real datasets, our proposed new CB-Net model outperforms the state-of-the-art FCN models and produces neuron segmentation results of remarkable quality version:1
arxiv-1705-11041 | Greedy Algorithms for Cone Constrained Optimization with Convergence Guarantees | http://arxiv.org/abs/1705.11041 | id:1705.11041 author:Francesco Locatello, Michael Tschannen, Gunnar Rätsch, Martin Jaggi category:cs.LG stat.ML  published:2017-05-31 summary:Greedy optimization methods such as Matching Pursuit (MP) and Frank-Wolfe (FW) algorithms regained popularity in recent years due to their simplicity, effectiveness and theoretical guarantees. MP and FW address optimization over the linear span and the convex hull of a set of atoms, respectively. In this paper, we consider the intermediate case of optimization over the convex cone, parametrized as the conic hull of a generic atom set, leading to the first principled definitions of non-negative MP algorithms for which we give explicit convergence rates and demonstrate excellent empirical performance. In particular, we derive sublinear ($\mathcal{O}(1/t)$) convergence on general smooth and convex objectives, and linear convergence ($\mathcal{O}(e^{-t})$) on strongly convex objectives, in both cases for general sets of atoms. Furthermore, we establish a clear correspondence of our algorithms to known algorithms from the MP and FW literature. Our novel algorithms and analyses target general atom sets and general objective functions, and hence are directly applicable to a large variety of learning settings. version:1
arxiv-1705-11040 | End-to-end Differentiable Proving | http://arxiv.org/abs/1705.11040 | id:1705.11040 author:Tim Rocktäschel, Sebastian Riedel category:cs.NE cs.AI cs.LG cs.LO  published:2017-05-31 summary:We introduce neural networks for end-to-end differentiable theorem proving that operate on dense vector representations of symbols. These neural networks are constructed recursively by taking inspiration from the backward chaining algorithm as used in Prolog. Specifically, we replace symbolic unification with a differentiable computation on vector representations of symbols using a radial basis function kernel, thereby combining symbolic reasoning with learning subsymbolic vector representations. By using gradient descent, the resulting neural network can be trained to infer facts from a given incomplete knowledge base. It learns to (i) place representations of similar symbols in close proximity in a vector space, (ii) make use of such similarities to prove facts, (iii) induce logical rules, and (iv) use provided and induced logical rules for complex multi-hop reasoning. We demonstrate that this architecture outperforms ComplEx, a state-of-the-art neural link prediction model, on four benchmark knowledge bases while at the same time inducing interpretable function-free first-order logic rules. version:1
arxiv-1705-11023 | Criticality & Deep Learning II: Momentum Renormalisation Group | http://arxiv.org/abs/1705.11023 | id:1705.11023 author:Dan Oprisa, Peter Toth category:cond-mat.stat-mech cs.LG  published:2017-05-31 summary:Guided by critical systems found in nature we develop a novel mechanism consisting of inhomogeneous polynomial regularisation via which we can induce scale invariance in deep learning systems. Technically, we map our deep learning (DL) setup to a genuine field theory, on which we act with the Renormalisation Group (RG) in momentum space and produce the flow equations of the couplings; those are translated to constraints and consequently interpreted as "critical regularisation" conditions in the optimiser; the resulting equations hence prove to be sufficient conditions for - and serve as an elegant and simple mechanism to induce scale invariance in any deep learning setup. version:1
arxiv-1706-00342 | Stable recovery of the factors from a deep matrix product and application to convolutional networks. Focus on sparsity constraints | http://arxiv.org/abs/1706.00342 | id:1706.00342 author:Francois Malgouyres, Joseph Landsberg category:math.OC cs.LG math.ST stat.TH  published:2017-05-31 summary:We study a deep matrix factorization problem. It takes as input a matrix X obtained by multiplying K matrices (called factors). Each factor is obtained by applying a fixed linear operator to a vector of parameters satisfying a sparsity constraint. We provide sharp conditions on the structure of the model that guarantee the stable recovery of the factors from the knowledge of X and the model for the factors. This is crucial in order to interpret the factors and the intermediate features obtained when applying a few factors to a datum. When K = 1: the paper provides compressed sensing statements; K = 2 covers (for instance) Non-negative Matrix Factorization, Dictionary learning, low rank approximation, phase recovery. The particularity of this paper is to extend the study to deep problems. As an illustration, we detail the analysis and provide (entirely computable) guarantees for the stable recovery of a (non-neural) sparse convolutional network. version:1
arxiv-1705-11001 | Adversarial Ranking for Language Generation | http://arxiv.org/abs/1705.11001 | id:1705.11001 author:Kevin Lin, Dianqi Li, Xiaodong He, Zhengyou Zhang, Ming-Ting Sun category:cs.CL cs.LG  published:2017-05-31 summary:Generative adversarial networks (GANs) have great successes on synthesizing data. However, the existing GANs restrict the discriminator to be a binary classifier, and thus limit their learning capacity for tasks that need to synthesize output with rich structures such as natural language descriptions. In this paper, we propose a novel generative adversarial network, RankGAN, for generating high-quality language descriptions. Rather than train the discriminator to learn and assign absolute binary predicate for individual data sample, the proposed RankGAN is able to analyze and rank a collection of human-written and machine-written sentences by giving a reference group. By viewing a set of data samples collectively and evaluating their quality through relative ranking scores, the discriminator is able to make better assessment which in turn helps to learn a better generator. The proposed RankGAN is optimized through the policy gradient technique. Experimental results on multiple public datasets clearly demonstrate the effectiveness of the proposed approach. version:1
arxiv-1705-10999 | Deep Supervised Discrete Hashing | http://arxiv.org/abs/1705.10999 | id:1705.10999 author:Qi Li, Zhenan Sun, Ran He, Tieniu Tan category:cs.CV  published:2017-05-31 summary:With the rapid growth of image and video data on the web, hashing has been extensively studied for image or video search in recent years. Benefit from recent advances in deep learning, deep hashing methods have achieved promising results for image retrieval. However, there are some limitations of previous deep hashing methods (e.g., the semantic information is not fully exploited). In this paper, we develop a deep supervised discrete hashing algorithm based on the assumption that the learned binary codes should be ideal for classification. Both the pairwise label information and the classification information are used to learn the hash codes within one stream framework. We constrain the outputs of the last layer to be binary codes directly, which is rarely investigated in deep hashing algorithm. Because of the discrete nature of hash codes, an alternating minimization method is used to optimize the objective function. Experimental results have shown that our method outperforms current state-of-the-art methods on benchmark datasets. version:1
arxiv-1705-10993 | Non-Markovian Control with Gated End-to-End Memory Policy Networks | http://arxiv.org/abs/1705.10993 | id:1705.10993 author:Julien Perez, Tomi Silander category:stat.ML cs.AI cs.LG cs.NE  published:2017-05-31 summary:Partially observable environments present an important open challenge in the domain of sequential control learning with delayed rewards. Despite numerous attempts during the two last decades, the majority of reinforcement learning algorithms and associated approximate models, applied to this context, still assume Markovian state transitions. In this paper, we explore the use of a recently proposed attention-based model, the Gated End-to-End Memory Network, for sequential control. We call the resulting model the Gated End-to-End Memory Policy Network. More precisely, we use a model-free value-based algorithm to learn policies for partially observed domains using this memory-enhanced neural network. This model is end-to-end learnable and it features unbounded memory. Indeed, because of its attention mechanism and associated non-parametric memory, the proposed model allows us to define an attention mechanism over the observation stream unlike recurrent models. We show encouraging results that illustrate the capability of our attention-based model in the context of the continuous-state non-stationary control problem of stock trading. We also present an OpenAI Gym environment for simulated stock exchange and explain its relevance as a benchmark for the field of non-Markovian decision process learning. version:1
arxiv-1705-10142 | Kronecker Recurrent Units | http://arxiv.org/abs/1705.10142 | id:1705.10142 author:Cijo Jose, Moustpaha Cisse, Francois Fleuret category:cs.LG  published:2017-05-29 summary:Our work addresses two important issues with recurrent neural networks: (1) they are over-parameterized, and (2) the recurrence matrix is ill-conditioned. The former increases the sample complexity of learning and the training time. The latter causes the vanishing and exploding gradient problem. We present a flexible recurrent neural network model called Kronecker Recurrent Units (KRU). KRU achieves parameter efficiency in RNNs through a Kronecker factored recurrent matrix. It overcomes the ill-conditioning of the recurrent matrix by enforcing soft unitary constraints on the factors. Thanks to the small dimensionality of the factors, maintaining these constraints is computationally efficient. Our experimental results on five standard data-sets reveal that KRU can reduce the number of parameters by three orders of magnitude in the recurrent weight matrix compared to the existing recurrent models, without trading the statistical performance. These results in particular show that while there are advantages in having a high dimensional recurrent space, the capacity of the recurrent part of the model can be dramatically reduced. version:3
arxiv-1705-10986 | Class Specific Feature Selection for Interval Valued Data Through Interval K-Means Clustering | http://arxiv.org/abs/1705.10986 | id:1705.10986 author:D. S. Guru, N. Vinay Kumar category:cs.CV 68T10 I.5.2; I.5.3  published:2017-05-31 summary:In this paper, a novel feature selection approach for supervised interval valued features is proposed. The proposed approach takes care of selecting the class specific features through interval K-Means clustering. The kernel of K-Means clustering algorithm is modified to adapt interval valued data. During training, a set of samples corresponding to a class is fed into the interval K-Means clustering algorithm, which clusters features into K distinct clusters. Hence, there are K number of features corresponding to each class. Subsequently, corresponding to each class, the cluster representatives are chosen. This procedure is repeated for all the samples of remaining classes. During testing the feature indices correspond to each class are used for validating the given dataset through classification using suitable symbolic classifiers. For experimentation, four standard supervised interval datasets are used. The results show the superiority of the proposed model when compared with the other existing state-of-the-art feature selection methods. version:1
arxiv-1705-10962 | Analysis of the Effect of Dependency Information on Predicate-Argument Structure Analysis and Zero Anaphora Resolution | http://arxiv.org/abs/1705.10962 | id:1705.10962 author:Koichiro Yoshino, Shinsuke Mori, Satoshi Nakamura category:cs.CL  published:2017-05-31 summary:This paper investigates and analyzes the effect of dependency information on predicate-argument structure analysis (PASA) and zero anaphora resolution (ZAR) for Japanese, and shows that a straightforward approach of PASA and ZAR works effectively even if dependency information was not available. We constructed an analyzer that directly predicts relationships of predicates and arguments with their semantic roles from a POS-tagged corpus. The features of the system are designed to compensate for the absence of syntactic information by using features used in dependency parsing as a reference. We also constructed analyzers that use the oracle dependency and the real dependency parsing results, and compared with the system that does not use any syntactic information to verify that the improvement provided by dependencies is not crucial. version:1
arxiv-1705-10499 | Online to Offline Conversions, Universality and Adaptive Minibatch Sizes | http://arxiv.org/abs/1705.10499 | id:1705.10499 author:Kfir Y. Levy category:cs.LG math.OC stat.ML  published:2017-05-30 summary:We present an approach towards convex optimization that relies on a novel scheme which converts online adaptive algorithms into offline methods. In the offline optimization setting, our derived methods are shown to obtain favourable adaptive guarantees which depend on the harmonic sum of the queried gradients. We further show that our methods implicitly adapt to the objective's structure: in the smooth case fast convergence rates are ensured without any prior knowledge of the smoothness parameter, while still maintaining guarantees in the non-smooth setting. Our approach has a natural extension to the stochastic setting, resulting in a lazy version of SGD (stochastic GD), where minibathces are chosen \emph{adaptively} depending on the magnitude of the gradients. Thus providing a principled approach towards choosing minibatch sizes. version:2
arxiv-1705-10958 | FALKON: An Optimal Large Scale Kernel Method | http://arxiv.org/abs/1705.10958 | id:1705.10958 author:Alessandro Rudi, Luigi Carratino, Lorenzo Rosasco category:stat.ML cs.LG  published:2017-05-31 summary:Kernel methods provide a principled way to perform non linear, nonparametric learning. They rely on solid functional analytic foundations and enjoy optimal statistical properties. However, at least in their basic form, they have limited applicability in large scale scenarios because of stringent computational requirements in terms of time and especially memory. In this paper, we take a substantial step in scaling up kernel methods, proposing FALKON, a novel algorithm that allows to efficiently process millions of points. FALKON is derived combining several algorithmic principles, namely stochastic projections, iterative solvers and preconditioning. Our theoretical analysis shows that optimal statistical accuracy is achieved requiring essentially $O(n)$ memory and $O(n\sqrt{n})$ time. Extensive experiments show that state of the art results on available large scale datasets can be achieved even on a single machine. version:1
arxiv-1705-07284 | Gaze Distribution Analysis and Saliency Prediction Across Age Groups | http://arxiv.org/abs/1705.07284 | id:1705.07284 author:Onkar Krishna, Kiyoharu Aizawa, Andrea Helo, Rama Pia category:cs.CV  published:2017-05-20 summary:Knowledge of the human visual system helps to develop better computational models of visual attention. State-of-the-art models have been developed to mimic the visual attention system of young adults that, however, largely ignore the variations that occur with age. In this paper, we investigated how visual scene processing changes with age and we propose an age-adapted framework that helps to develop a computational model that can predict saliency across different age groups. Our analysis uncovers how the explorativeness of an observer varies with age, how well saliency maps of an age group agree with fixation points of observers from the same or different age groups, and how age influences the center bias. We analyzed the eye movement behavior of 82 observers belonging to four age groups while they explored visual scenes. Explorativeness was quantified in terms of the entropy of a saliency map, and area under the curve (AUC) metrics was used to quantify the agreement analysis and the center bias. These results were used to develop age adapted saliency models. Our results suggest that the proposed age-adapted saliency model outperforms existing saliency models in predicting the regions of interest across age groups. version:2
arxiv-1705-10732 | Deep manifold-to-manifold transforming network for action recognition | http://arxiv.org/abs/1705.10732 | id:1705.10732 author:Tong Zhang, Wenming Zheng, Zhen Cui, Chaolong Li category:cs.CV  published:2017-05-30 summary:In this paper, a novel deep manifold-to-manifold transforming network (DMT-Net) is proposed for action recognition, in which symmetric positive definite (SPD) matrix is adopted to describe the spatial-temporal information of action feature vectors. Since each SPD matrix is a point of the Riemannian manifold space, the proposed DMT-Net aims to learn more discriminative feature by hierarchically transforming the data points from one Riemannian manifold to another more discriminative one. To this end, several novel layers are proposed in DMT-Net, including SPD convolutional layer, channel convolution layer, diagonalizing layer and kernel regression layer. Specifically, SPD convolutional layer enables multi-channel convolution to be well applied to Riemannian manifold, and the kernel regression layer enables the distance metric computation between two SPD points in Riemannian manifold to be done in the Euclidean space, in which a novel reference set dynamically generated during the network training is also introduced to relieve the computational burden of the kernel method. To evaluate the effectiveness of the proposed method, three action recognition databases are respectively used to testify our method and the experimental results show that our algorithm outperforms the state-of-the-art methods. version:2
arxiv-1705-10943 | Bridge Simulation and Metric Estimation on Landmark Manifolds | http://arxiv.org/abs/1705.10943 | id:1705.10943 author:Stefan Sommer, Alexis Arnaudon, Line Kuhnel, Sarang Joshi category:cs.CV  published:2017-05-31 summary:We present an inference algorithm and connected Monte Carlo based estimation procedures for metric estimation from landmark configurations distributed according to the transition distribution of a Riemannian Brownian motion arising from the Large Deformation Diffeomorphic Metric Mapping (LDDMM) metric. The distribution possesses properties similar to the regular Euclidean normal distribution but its transition density is governed by a high-dimensional PDE with no closed-form solution in the nonlinear case. We show how the density can be numerically approximated by Monte Carlo sampling of conditioned Brownian bridges, and we use this to estimate parameters of the LDDMM kernel and thus the metric structure by maximum likelihood. version:1
arxiv-1705-10941 | Spectral Norm Regularization for Improving the Generalizability of Deep Learning | http://arxiv.org/abs/1705.10941 | id:1705.10941 author:Yuichi Yoshida, Takeru Miyato category:stat.ML cs.LG  published:2017-05-31 summary:We investigate the generalizability of deep learning based on the sensitivity to input perturbation. We hypothesize that the high sensitivity to the perturbation of data degrades the performance on it. To reduce the sensitivity to perturbation, we propose a simple and effective regularization method, referred to as spectral norm regularization, which penalizes the high spectral norm of weight matrices in neural networks. We provide supportive evidence for the abovementioned hypothesis by experimentally confirming that the models trained using spectral norm regularization exhibit better generalizability than other baseline methods. version:1
arxiv-1705-10934 | Learning Graphs with Monotone Topology Properties and Multiple Connected Components | http://arxiv.org/abs/1705.10934 | id:1705.10934 author:Eduardo Pavez, Hilmi E. Egilmez, Antonio Ortega category:stat.ML  published:2017-05-31 summary:Learning graphs with structural properties is in general a non-convex optimization problem. We consider graph families closed under edge removal operations, and graphs with multiple connected components. We propose a tractable algorithm that finds the generalized Laplacian matrix of a graph with the desired type of structure. Our algorithm has two steps, first it solves a combinatorial optimization problem to find a graph topology that satisfies the desired structural property. Second, it estimates a generalized Laplacian matrix by solving a sparsity constrained log-determinant divergence minimization problem. Our results are based on the analysis of a convex relaxation via weighted $\ell_1$-regularization. We derive specific instances of our algorithm to learn tree structured graphs, sparse connected graphs and bipartite graphs. We evaluate the performance of our graph learning method via numerical experiments with synthetic and image data. version:1
arxiv-1705-10930 | Micro Fourier Transform Profilometry ($μ$FTP): 3D shape measurement at 10,000 frames per second | http://arxiv.org/abs/1705.10930 | id:1705.10930 author:Chao Zuo, Tianyang Tao, Shijie Feng, Lei Huang, Anand Asundi, Qian Chen category:physics.ins-det cs.CV physics.optics  published:2017-05-31 summary:Recent advances in imaging sensors and digital light projection technology have facilitated a rapid progress in 3D optical sensing, enabling 3D surfaces of complex-shaped objects to be captured with improved resolution and accuracy. However, due to the large number of projection patterns required for phase recovery and disambiguation, the maximum fame rates of current 3D shape measurement techniques are still limited to the range of hundreds of frames per second (fps). Here, we demonstrate a new 3D dynamic imaging technique, Micro Fourier Transform Profilometry ($\mu$FTP), which can capture 3D surfaces of transient events at up to 10,000 fps based on our newly developed high-speed fringe projection system. Compared with existing techniques, $\mu$FTP has the prominent advantage of recovering an accurate, unambiguous, and dense 3D point cloud with only two projected patterns. Furthermore, the phase information is encoded within a single high-frequency fringe image, thereby allowing motion-artifact-free reconstruction of transient events with temporal resolution of 50 microseconds. To show $\mu$FTP's broad utility, we use it to reconstruct 3D videos of 4 transient scenes: vibrating cantilevers, rotating fan blades, bullet fired from a toy gun, and balloon's explosion triggered by a flying dart, which were previously difficult or even unable to be captured with conventional approaches. version:1
arxiv-1705-10929 | Adversarial Generation of Natural Language | http://arxiv.org/abs/1705.10929 | id:1705.10929 author:Sai Rajeswar, Sandeep Subramanian, Francis Dutil, Christopher Pal, Aaron Courville category:cs.CL cs.AI cs.NE stat.ML  published:2017-05-31 summary:Generative Adversarial Networks (GANs) have gathered a lot of attention from the computer vision community, yielding impressive results for image generation. Advances in the adversarial generation of natural language from noise however are not commensurate with the progress made in generating images, and still lag far behind likelihood based methods. In this paper, we take a step towards generating natural language with a GAN objective alone. We introduce a simple baseline that addresses the discrete output space problem without relying on gradient estimators and show that it is able to achieve state-of-the-art results on a Chinese poem generation dataset. We present quantitative results on generating sentences from context-free and probabilistic context-free grammars, and qualitative language modeling results. A conditional version is also described that can generate sequences conditioned on sentence characteristics. version:1
arxiv-1705-10928 | Naturally Combined Shape-Color Moment Invariants under Affine Transformations | http://arxiv.org/abs/1705.10928 | id:1705.10928 author:Ming Gong, You Hao, Hanlin Mo, Hua Li category:cs.CV  published:2017-05-31 summary:We proposed a kind of naturally combined shape-color affine moment invariants (SCAMI), which consider both shape and color affine transformations simultaneously in one single system. In the real scene, color and shape deformations always exist in images simultaneously. Simple shape invariants or color invariants can not be qualified for this situation. The conventional method is just to make a simple linear combination of the two factors. Meanwhile, the manual selection of weights is a complex issue. Our construction method is based on the multiple integration framework. The integral kernel is assigned as the continued product of the shape and color invariant cores. It is the first time to directly derive an invariant to dual affine transformations of shape and color. The manual selection of weights is no longer necessary, and both the shape and color transformations are extended to affine transformation group. With the various of invariant cores, a set of lower-order invariants are constructed and the completeness and independence are discussed detailedly. A set of SCAMIs, which called SCAMI24, are recommended, and the effectiveness and robustness have been evaluated on both synthetic and real datasets. version:1
arxiv-1705-10924 | Sequential Dynamic Decision Making with Deep Neural Nets on a Test-Time Budget | http://arxiv.org/abs/1705.10924 | id:1705.10924 author:Henghui Zhu, Feng Nan, Ioannis Paschalidis, Venkatesh Saligrama category:stat.ML cs.LG  published:2017-05-31 summary:Deep neural network (DNN) based approaches hold significant potential for reinforcement learning (RL) and have already shown remarkable gains over state-of-art methods in a number of applications. The effectiveness of DNN methods can be attributed to leveraging the abundance of supervised data to learn value functions, Q-functions, and policy function approximations without the need for feature engineering. Nevertheless, the deployment of DNN-based predictors with very deep architectures can pose an issue due to computational and other resource constraints at test-time in a number of applications. We propose a novel approach for reducing the average latency by learning a computationally efficient gating function that is capable of recognizing states in a sequential decision process for which policy prescriptions of a shallow network suffices and deeper layers of the DNN have little marginal utility. The overall system is adaptive in that it dynamically switches control actions based on state-estimates in order to reduce average latency without sacrificing terminal performance. We experiment with a number of alternative loss-functions to train gating functions and shallow policies and show that in a number of applications a speed-up of up to almost 5X can be obtained with little loss in performance. version:1
arxiv-1705-10918 | The ALAMO approach to machine learning | http://arxiv.org/abs/1705.10918 | id:1705.10918 author:Zachary T. Wilson, Nikolaos V. Sahinidis category:cs.LG stat.ML  published:2017-05-31 summary:ALAMO is a computational methodology for leaning algebraic functions from data. Given a data set, the approach begins by building a low-complexity, linear model composed of explicit non-linear transformations of the independent variables. Linear combinations of these non-linear transformations allow a linear model to better approximate complex behavior observed in real processes. The model is refined, as additional data are obtained in an adaptive fashion through error maximization sampling using derivative-free optimization. Models built using ALAMO can enforce constraints on the response variables to incorporate first-principles knowledge. The ability of ALAMO to generate simple and accurate models for a number of reaction problems is demonstrated. The error maximization sampling is compared with Latin hypercube designs to demonstrate its sampling efficiency. ALAMO's constrained regression methodology is used to further refine concentration models, resulting in models that perform better on validation data and satisfy upper and lower bounds placed on model outputs. version:1
arxiv-1705-10915 | Unsupervised Learning of Disentangled Representations from Video | http://arxiv.org/abs/1705.10915 | id:1705.10915 author:Emily Denton, Vighnesh Birodkar category:cs.LG cs.AI cs.CV stat.ML  published:2017-05-31 summary:We present a new model DrNET that learns disentangled image representations from video. Our approach leverages the temporal coherence of video and a novel adversarial loss to learn a representation that factorizes each frame into a stationary part and a temporally varying component. The disentangled representation can be used for a range of tasks. For example, applying a standard LSTM to the time-vary components enables prediction of future frames. We evaluate our approach on a range of synthetic and real videos, demonstrating the ability to coherently generate hundreds of steps into the future. version:1
arxiv-1705-10694 | Deep Learning is Robust to Massive Label Noise | http://arxiv.org/abs/1705.10694 | id:1705.10694 author:David Rolnick, Andreas Veit, Serge Belongie, Nir Shavit category:cs.LG cs.AI cs.CV cs.NE  published:2017-05-30 summary:Deep neural networks trained on large supervised datasets have led to impressive results in recent years. However, since well-annotated datasets can be prohibitively expensive and time-consuming to collect, recent work has explored the use of larger but noisy datasets that can be more easily obtained. In this paper, we investigate the behavior of deep neural networks on training sets with massively noisy labels. We show that successful learning is possible even with an essentially arbitrary amount of noise. For example, on MNIST we find that accuracy of above 90 percent is still attainable even when the dataset has been diluted with 100 noisy examples for each clean example. Such behavior holds across multiple patterns of label noise, even when noisy labels are biased towards confusing classes. Further, we show how the required dataset size for successful training increases with higher label noise. Finally, we present simple actionable techniques for improving learning in the regime of high label noise. version:2
arxiv-1705-10904 | Weakly Supervised Generative Adversarial Networks for 3D Reconstruction | http://arxiv.org/abs/1705.10904 | id:1705.10904 author:JunYoung Gwak, Christopher B. Choy, Animesh Garg, Manmohan Chandraker, Silvio Savarese category:cs.CV  published:2017-05-31 summary:Volumetric 3D reconstruction has witnessed a significant progress in performance through the use of deep neural network based methods that address some of the limitations of traditional reconstruction algorithms. However, this increase in performance requires large scale annotations of 2D/3D data. This paper introduces a novel generative model for volumetric 3D reconstruction, Weakly supervised Generative Adversarial Network (WS-GAN) which reduces reliance on expensive 3D supervision. WS-GAN takes an input image, a sparse set of 2D object masks with respective camera parameters, and an unmatched 3D model as inputs during training. WS-GAN uses a learned encoding as input to a conditional 3D-model generator trained alongside a discriminator, which is constrained to the manifold of realistic 3D shapes. We bridge the representation gap between 2D masks and 3D volumes through a perspective raytrace pooling layer, that enables perspective projection and allows backpropagation. We evaluate WS-GAN on ShapeNet, ObjectNet and Stanford Online Product dataset for reconstruction with single-view and multi-view cases in both synthetic and real images. We compare our method to voxel carving and prior work with full 3D supervision. Additionally, we also demonstrate that the learned feature representation is semantically meaningful through interpolation and manipulation in input space. version:1
arxiv-1705-10900 | Does the Geometry of Word Embeddings Help Document Classification? A Case Study on Persistent Homology Based Representations | http://arxiv.org/abs/1705.10900 | id:1705.10900 author:Paul Michel, Abhilasha Ravichander, Shruti Rijhwani category:cs.CL  published:2017-05-31 summary:We investigate the pertinence of methods from algebraic topology for text data analysis. These methods enable the development of mathematically-principled isometric-invariant mappings from a set of vectors to a document embedding, which is stable with respect to the geometry of the document in the selected metric space. In this work, we evaluate the utility of these topology-based document representations in traditional NLP tasks, specifically document clustering and sentiment classification. We find that the embeddings do not benefit text analysis. In fact, performance is worse than simple techniques like $\textit{tf-idf}$, indicating that the geometry of the document does not provide enough variability for classification on the basis of topic or sentiment in the chosen datasets. version:1
arxiv-1705-10888 | Identification of Gaussian Process State Space Models | http://arxiv.org/abs/1705.10888 | id:1705.10888 author:Stefanos Eleftheriadis, Thomas F. W. Nicholson, Marc Peter Deisenroth, James Hensman category:stat.ML  published:2017-05-30 summary:The Gaussian process state space model (GPSSM) is a non-linear dynamical system, where unknown transition and/or measurement mappings are described by GPs. Most research in GPSSMs has focussed on the state estimation problem. However, the key challenge in GPSSMs has not been satisfactorily addressed yet: system identification. To address this challenge, we impose a structured Gaussian variational posterior distribution over the latent states, which is parameterised by a recognition model in the form of a bi-directional recurrent neural network. Inference with this structure allows us to recover a posterior smoothed over the entire sequence(s) of data. We provide a practical algorithm for efficiently computing a lower bound on the marginal likelihood using the reparameterisation trick. This additionally allows arbitrary kernels to be used within the GPSSM. We demonstrate that we can efficiently generate plausible future trajectories of the system we seek to model with the GPSSM, requiring only a small number of interactions with the true system. version:1
arxiv-1705-10887 | Sparse and low-rank approximations of large symmetric matrices using biharmonic interpolation | http://arxiv.org/abs/1705.10887 | id:1705.10887 author:Javier S. Turek, Alexander Huth category:stat.ML cs.LG cs.NA 65D05  68T99  65F50 I.2.6; G.1  published:2017-05-30 summary:Symmetric matrices are widely used in machine learning problems such as kernel machines and manifold learning. Using large datasets often requires computing low-rank approximations of these symmetric matrices so that they fit in memory. In this paper, we present a novel method based on biharmonic interpolation for low-rank matrix approximation. The method exploits knowledge of the data manifold to learn an interpolation operator that approximates values using a subset of randomly selected landmark points. This operator is readily sparsified, reducing memory requirements by at least two orders of magnitude without significant loss in accuracy. We show that our method can approximate very large datasets using twenty times more landmarks than other methods. Further, numerical results suggest that our method is stable even when numerical difficulties arise for other methods. version:1
arxiv-1705-10886 | High Dimensional Structured Superposition Models | http://arxiv.org/abs/1705.10886 | id:1705.10886 author:Qilong Gu, Arindam Banerjee category:cs.LG stat.ML  published:2017-05-30 summary:High dimensional superposition models characterize observations using parameters which can be written as a sum of multiple component parameters, each with its own structure, e.g., sum of low rank and sparse matrices, sum of sparse and rotated sparse vectors, etc. In this paper, we consider general superposition models which allow sum of any number of component parameters, and each component structure can be characterized by any norm. We present a simple estimator for such models, give a geometric condition under which the components can be accurately estimated, characterize sample complexity of the estimator, and give high probability non-asymptotic bounds on the componentwise estimation error. We use tools from empirical processes and generic chaining for the statistical analysis, and our results, which substantially generalize prior work on superposition models, are in terms of Gaussian widths of suitable sets. version:1
arxiv-1705-10883 | Optimization of Tree Ensembles | http://arxiv.org/abs/1705.10883 | id:1705.10883 author:Velibor V. Mišić category:math.OC cs.LG stat.ML  published:2017-05-30 summary:Tree ensemble models such as random forests and boosted trees are among the most widely used and practically successful predictive models in applied machine learning and business analytics. Although such models have been used to make predictions based on exogenous, uncontrollable independent variables, they are increasingly being used to make predictions where the independent variables are controllable and are also decision variables. In this paper, we study the problem of tree ensemble optimization: given a tree ensemble that predicts some dependent variable using controllable independent variables, how should we set these variables so as to maximize the predicted value? We formulate the problem as a mixed-integer optimization problem. We theoretically examine the strength of our formulation, provide a hierarchy of approximate formulations with bounds on approximation quality and exploit the structure of the problem to develop two large-scale solution methods, one based on Benders decomposition and one based on iteratively generating tree split constraints. We test our methodology on real data sets, including two case studies in drug design and customized pricing, and show that our methodology can efficiently solve large-scale instances to near or full optimality, and outperforms solutions obtained by heuristic approaches. In our drug design case, we show how our approach can identify compounds that efficiently trade-off predicted performance and novelty with respect to existing, known compounds. In our customized pricing case, we show how our approach can efficiently determine optimal store-level prices under a random forest model that delivers excellent predictive accuracy. version:1
arxiv-1705-10882 | Morphological Error Detection in 3D Segmentations | http://arxiv.org/abs/1705.10882 | id:1705.10882 author:David Rolnick, Yaron Meirovitch, Toufiq Parag, Hanspeter Pfister, Viren Jain, Jeff W. Lichtman, Edward S. Boyden, Nir Shavit category:cs.CV cs.AI q-bio.NC stat.ML  published:2017-05-30 summary:Deep learning algorithms for connectomics rely upon localized classification, rather than overall morphology. This leads to a high incidence of erroneously merged objects. Humans, by contrast, can easily detect such errors by acquiring intuition for the correct morphology of objects. Biological neurons have complicated and variable shapes, which are challenging to learn, and merge errors take a multitude of different forms. We present an algorithm, MergeNet, that shows 3D ConvNets can, in fact, detect merge errors from high-level neuronal morphology. MergeNet follows unsupervised training and operates across datasets. We demonstrate the performance of MergeNet both on a variety of connectomics data and on a dataset created from merged MNIST images. version:1
arxiv-1705-10874 | Deep Learning for Environmentally Robust Speech Recognition: An Overview of Recent Developments | http://arxiv.org/abs/1705.10874 | id:1705.10874 author:Zixing Zhang, Jürgen Geiger, Jouni Pohjalainen, Amr El-Desoky Mousa, Björn Schuller category:cs.SD cs.CL cs.LG  published:2017-05-30 summary:Eliminating the negative effect of highly non-stationary environmental noise is a long-standing research topic for speech recognition but remains an important challenge nowadays. To address this issue, traditional unsupervised signal processing methods seem to have touched the ceiling. However, data-driven based supervised approaches, particularly the ones designed with deep learning, have recently emerged as potential alternatives. In this light, we are going to comprehensively summarise the recently developed and most representative deep learning approaches to deal with the raised problem in this article, with the aim of providing guidelines for those who are going deeply into the field of environmentally robust speech recognition. To better introduce these approaches, we categorise them into single- and multi-channel techniques, each of which is specifically described at the front-end, the back-end, and the joint framework of speech recognition systems. In the meanwhile, we describe the pros and cons of these approaches as well as the relationships among them, which can probably benefit future research. version:1
arxiv-1705-10872 | Working hard to know your neighbor's margins:Local descriptor learning loss | http://arxiv.org/abs/1705.10872 | id:1705.10872 author:Anastasiya Mishchuk, Dmytro Mishkin, Filip Radenovic, Jiri Matas category:cs.CV  published:2017-05-30 summary:We introduce a novel loss for learning local feature descriptors that is inspired by the SIFT matching scheme. We show that the proposed loss that relies on the maximization of the distance between the closest positive and closest negative patches can replace more complex regularization methods which have been used in local descriptor learning; it works well for both shallow and deep convolution network architectures. The resulting descriptor is compact -- it has the same dimensionality as SIFT (128), it shows state-of-art performance on matching, patch verification and retrieval benchmarks and it is fast to compute on a GPU. version:1
arxiv-1705-10861 | Generic Tubelet Proposals for Action Localization | http://arxiv.org/abs/1705.10861 | id:1705.10861 author:Jiawei He, Mostafa S. Ibrahim, Zhiwei Deng, Greg Mori category:cs.CV  published:2017-05-30 summary:We develop a novel framework for action localization in videos. We propose the Tube Proposal Network (TPN), which can generate generic, class-independent, video-level tubelet proposals in videos. The generated tubelet proposals can be utilized in various video analysis tasks, including recognizing and localizing actions in videos. In particular, we integrate these generic tubelet proposals into a unified temporal deep network for action classification. Compared with other methods, our generic tubelet proposal method is accurate, general, and is fully differentiable under a smoothL1 loss function. We demonstrate the performance of our algorithm on the standard UCF-Sports, J-HMDB21, and UCF-101 datasets. Our class-independent TPN outperforms other tubelet generation methods, and our unified temporal deep network achieves state-of-the-art localization results on all three datasets. version:1
arxiv-1705-10854 | A Tale of Two Animats: What does it take to have goals? | http://arxiv.org/abs/1705.10854 | id:1705.10854 author:Larissa Albantakis category:q-bio.NC cs.NE  published:2017-05-30 summary:What does it take for a system, biological or not, to have goals? Here, this question is approached in the context of in silico artificial evolution. By examining the informational and causal properties of artificial organisms ('animats') controlled by small, adaptive neural networks (Markov Brains), this essay discusses necessary requirements for intrinsic information, autonomy, and meaning. The focus lies on comparing two types of Markov Brains that evolved in the same simple environment: one with purely feedforward connections between its elements, the other with an integrated set of elements that causally constrain each other. While both types of brains 'process' information about their environment and are equally fit, only the integrated one forms a causally autonomous entity above a background of external influences. This suggests that to assess whether goals are meaningful for a system itself, it is important to understand what the system is, rather than what it does. version:1
arxiv-1705-10843 | Objective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models | http://arxiv.org/abs/1705.10843 | id:1705.10843 author:Gabriel Lima Guimaraes, Benjamin Sanchez-Lengeling, Pedro Luis Cunha Farias, Alán Aspuru-Guzik category:stat.ML cs.LG  published:2017-05-30 summary:In unsupervised data generation tasks, besides the generation of a sample based on previous observations, one would often like to give hints to the model in order to bias the generation towards desirable metrics. We propose a method that combines Generative Adversarial Networks (GANs) and reinforcement learning (RL) in order to accomplish exactly that. While RL biases the data generation process towards arbitrary metrics, the GAN component of the reward function ensures that the model still remembers information learned from data. We build upon previous results that incorporated GANs and RL in order to generate sequence data and test this model in several settings for the generation of molecules encoded as text sequences (SMILES) and in the context of music generation, showing for each case that we can effectively bias the generation process towards desired metrics. version:1
arxiv-1705-10829 | Accuracy First: Selecting a Differential Privacy Level for Accuracy-Constrained ERM | http://arxiv.org/abs/1705.10829 | id:1705.10829 author:Katrina Ligett, Seth Neel, Aaron Roth, Bo Waggoner, Z. Steven Wu category:cs.LG  published:2017-05-30 summary:Traditional approaches to differential privacy assume a fixed privacy requirement $\epsilon$ for a computation, and attempt to maximize the accuracy of the computation subject to the privacy constraint. As differential privacy is increasingly deployed in practical settings, it may often be that there is instead a fixed accuracy requirement for a given computation and the data analyst would like to maximize the privacy of the computation subject to the accuracy constraint. This raises the question of how to find and run a maximally private empirical risk minimizer subject to a given accuracy requirement. We propose a general "noise reduction" framework that can apply to a variety of private empirical risk minimization (ERM) algorithms, using them to "search" the space of privacy levels to find the empirically strongest one that meets the accuracy constraint, incurring only logarithmic overhead in the number of privacy levels searched. The privacy analysis of our algorithm leads naturally to a version of differential privacy where the privacy parameters are dependent on the data, which we term ex-post privacy, and which is related to the recently introduced notion of privacy odometers. We also give an ex-post privacy analysis of the classical AboveThreshold privacy tool, modifying it to allow for queries chosen depending on the database. Finally, we apply our approach to two common objectives, regularized linear and logistic regression, and empirically compare our noise reduction methods to (i) inverting the theoretical utility guarantees of standard private ERM algorithms and (ii) a stronger, empirical baseline based on binary search. version:1
arxiv-1705-10823 | Practical Neural Network Performance Prediction for Early Stopping | http://arxiv.org/abs/1705.10823 | id:1705.10823 author:Bowen Baker, Otkrist Gupta, Ramesh Raskar, Nikhil Naik category:cs.LG cs.CV cs.NE  published:2017-05-30 summary:In the neural network domain, methods for hyperparameter optimization and meta-modeling are computationally expensive due to the need to train a large number of neural network configurations. In this paper, we show that a simple regression model, based on support vector machines, can predict the final performance of partially trained neural network configurations using features based on network architectures, hyperparameters, and time-series validation performance data. We use this regression model to develop an early stopping strategy for neural network configurations. With this early stopping strategy, we obtain significant speedups in both hyperparameter optimization and meta-modeling. Particularly in the context of meta-modeling, our method can learn to predict the performance of drastically different architectures and is seamlessly incorporated into reinforcement learning-based architecture selection algorithms. Finally, we show that our method is simpler, faster, and more accurate than Bayesian methods for learning curve prediction. version:1
arxiv-1705-10819 | Surface Networks | http://arxiv.org/abs/1705.10819 | id:1705.10819 author:Ilya Kostrikov, Joan Bruna, Daniele Panozzo, Denis Zorin category:stat.ML cs.GR cs.LG  published:2017-05-30 summary:We study data-driven representations for three-dimensional triangle meshes, which are one of the prevalent objects used to represent 3D geometry. Recent works have developed models that exploit the intrinsic geometry of manifolds and graphs, namely the Graph Neural Networks (GNNs) and its spectral variants, which learn from the local metric tensor via the Laplacian operator. Despite offering excellent sample complexity and built-in invariances, intrinsic geometry alone is invariant to isometric deformations, making it unsuitable for many applications. To overcome this limitation, we propose several upgrades to GNNs to leverage extrinsic differential geometry properties of three-dimensional surfaces, increasing its modeling power. In particular, we propose to exploit the Dirac operator, whose spectrum detects principal curvature directions --- this is in stark contrast with the classical Laplace operator, which directly measures mean curvature. We coin the resulting model the \emph{Surface Network (SN)}. We demonstrate the efficiency and versatility of SNs on two challenging tasks: temporal prediction of mesh deformations under non-linear dynamics and generative models using a variational autoencoder framework with encoders/decoders given by SNs. version:1
arxiv-1705-10817 | Dynamics Based Features For Graph Classification | http://arxiv.org/abs/1705.10817 | id:1705.10817 author:Leonardo Gutierrez Gomez, Benjamin Chiem, Jean-Charles Delvenne category:stat.ML  published:2017-05-30 summary:Numerous social, medical, engineering and biological challenges can be framed as graph-based learning tasks. Here, we propose a new feature based approach to network classification. We show how dynamics on a network can be useful to reveal patterns about the organization of the components of the underlying graph where the process takes place. We define generalized assortativities on networks and use them as generalized features across multiple time scales. These features turn out to be suitable signatures for discriminating between different classes of networks. Our method is evaluated empirically on established network benchmarks. We also introduce a new dataset of human brain networks (connectomes) and use it to evaluate our method. Results reveal that our dynamics based features are competitive and often outperform state of the art accuracies. version:1
arxiv-1705-10814 | Character Composition Model with Convolutional Neural Networks for Dependency Parsing on Morphologically Rich Languages | http://arxiv.org/abs/1705.10814 | id:1705.10814 author:Xiang Yu, Ngoc Thang Vu category:cs.CL  published:2017-05-30 summary:We present a transition-based dependency parser that uses a convolutional neural network to compose word representations from characters. The character composition model shows great improvement over the word-lookup model, especially for parsing agglutinative languages. These improvements are even better than using pre-trained word embeddings from extra data. On the SPMRL data sets, our system outperforms the previous best greedy parser (Ballesteros et al., 2015) by a margin of 3% on average. version:1
arxiv-1705-10813 | Large Linear Multi-output Gaussian Process Learning for Time Series | http://arxiv.org/abs/1705.10813 | id:1705.10813 author:Vladimir Feinberg, Li-Fang Cheng, Kai Li, Barbara E Engelhardt category:stat.ML  published:2017-05-30 summary:Gaussian processes, or distributions over arbitrary functions in a continuous domain, can be generalized to the multi-output case: a linear model of coregionalization (LMC) is one approach. LMCs estimate and exploit correlations across the multiple outputs. While model estimation can be performed efficiently for single-output GPs, these assume stationarity, but in the multi-output case the cross-covariance interaction is not stationary. We propose Large Linear GPs (LLGPs), which circumvent the need for stationarity by using LMC's structure, enabling optimization of GP hyperparameters for multi-dimensional outputs and one-dimensional inputs. When applied to real time series data, we find our theoretical improvement relative to the current state of the art is realized with LLGP being generally an order of magnitude faster while improving or maintaining predictive accuracy. version:1
arxiv-1705-10770 | Forward-Backward Selection with Early Dropping | http://arxiv.org/abs/1705.10770 | id:1705.10770 author:Giorgos Borboudakis, Ioannis Tsamardinos category:cs.LG stat.ML  published:2017-05-30 summary:Forward-backward selection is one of the most basic and commonly-used feature selection algorithms available. It is also general and conceptually applicable to many different types of data. In this paper, we propose a heuristic that significantly improves its running time, while preserving predictive accuracy. The idea is to temporarily discard the variables that are conditionally independent with the outcome given the selected variable set. Depending on how those variables are reconsidered and reintroduced, this heuristic gives rise to a family of algorithms with increasingly stronger theoretical guarantees. In distributions that can be faithfully represented by Bayesian networks or maximal ancestral graphs, members of this algorithmic family are able to correctly identify the Markov blanket in the sample limit. In experiments we show that the proposed heuristic increases computational efficiency by about two orders of magnitude in high-dimensional problems, while selecting fewer variables and retaining predictive performance. Furthermore, we show that the proposed algorithm and feature selection with LASSO perform similarly when restricted to select the same number of variables, making the proposed algorithm an attractive alternative for problems where no (efficient) algorithm for LASSO exists. version:1
arxiv-1705-10762 | Generative Models of Visually Grounded Imagination | http://arxiv.org/abs/1705.10762 | id:1705.10762 author:Ramakrishna Vedantam, Ian Fischer, Jonathan Huang, Kevin Murphy category:cs.LG cs.CV stat.ML  published:2017-05-30 summary:Consider how easy it is for people to imagine what a "purple hippo" would look like, even though they do not exist. If we instead said "purple hippo with wings", they could just as easily create a different internal mental representation, to represent this more specific concept. To assess whether the person has correctly understood the concept, we can ask them to draw a few sketches, to illustrate their thoughts. We call the ability to map text descriptions of concepts to latent representations and then to images (or vice versa) visually grounded semantic imagination. We propose a latent variable model for images and attributes, based on variational auto-encoders, which can perform this task. Our method uses a novel training objective, and a novel product-of-experts inference network, which can handle partially specified (abstract) concepts in a principled and efficient way. We also propose a set of easy-to-compute evaluation metrics that capture our intuitive notions of what it means to have good imagination, namely correctness, coverage, and compositionality (the 3 C's). Finally, we perform a detailed comparison (in terms of the 3 C's) of our method with two existing joint image-attribute VAE methods (the JMVAE method of (Suzuki et al., 2017) and the bi-VCCA method of (Wang et al., 2016)) by applying them to two simple datasets based on MNIST, where it is easy to objectively evaluate performance in a controlled way. version:1
arxiv-1705-07795 | Backprop without Learning Rates Through Coin Betting | http://arxiv.org/abs/1705.07795 | id:1705.07795 author:Francesco Orabona, Tatiana Tommasi category:cs.LG math.OC stat.ML  published:2017-05-22 summary:Deep learning methods achieve state-of-the-art performance in many application scenarios. Yet, these methods require a significant amount of hyperparameters tuning in order to achieve the best results. In particular, tuning the learning rates in the stochastic optimization process is still one of the main bottlenecks. In this paper, we propose a new stochastic gradient descent procedure for deep networks that does not require any learning rate setting. Contrary to previous methods, we do not adapt the learning rates nor we make use of the assumed curvature of the objective function. Instead, we reduce the optimization process to a game of betting on a coin and propose a learning rate free optimal algorithm for this scenario. Theoretical convergence is proven for convex and quasi-convex functions and empirical evidence shows the advantage of our algorithm over popular stochastic gradient algorithms. version:2
arxiv-1705-10757 | A Multi-Layer K-means Approach for Multi-Sensor Data Pattern Recognition in Multi-Target Localization | http://arxiv.org/abs/1705.10757 | id:1705.10757 author:Samuel Silva, Rengan Suresh, Feng Tao, Johnathan Votion, Yongcan Cao category:cs.SY stat.ML  published:2017-05-30 summary:Data-target association is an important step in multi-target localization for the intelligent operation of un- manned systems in numerous applications such as search and rescue, traffic management and surveillance. The objective of this paper is to present an innovative data association learning approach named multi-layer K-means (MLKM) based on leveraging the advantages of some existing machine learning approaches, including K-means, K-means++, and deep neural networks. To enable the accurate data association from different sensors for efficient target localization, MLKM relies on the clustering capabilities of K-means++ structured in a multi-layer framework with the error correction feature that is motivated by the backpropogation that is well-known in deep learning research. To show the effectiveness of the MLKM method, numerous simulation examples are conducted to compare its performance with K-means, K-means++, and deep neural networks. version:1
arxiv-1705-01462 | Ternary Neural Networks with Fine-Grained Quantization | http://arxiv.org/abs/1705.01462 | id:1705.01462 author:Naveen Mellempudi, Abhisek Kundu, Dheevatsa Mudigere, Dipankar Das, Bharat Kaul, Pradeep Dubey category:cs.LG cs.NE  published:2017-05-02 summary:We propose a novel fine-grained quantization (FGQ) method to ternarize pre-trained full precision models, while also constraining activations to 8 and 4-bits. Using this method, we demonstrate a minimal loss in classification accuracy on state-of-the-art topologies without additional training. We provide an improved theoretical formulation that forms the basis for a higher quality solution using FGQ. Our method involves ternarizing the original weight tensor in groups of $N$ weights. Using $N=4$, we achieve Top-1 accuracy within $3.7\%$ and $4.2\%$ of the baseline full precision result for Resnet-101 and Resnet-50 respectively, while eliminating $75\%$ of all multiplications. These results enable a full 8/4-bit inference pipeline, with best-reported accuracy using ternary weights on ImageNet dataset, with a potential of $9\times$ improvement in performance. Also, for smaller networks like AlexNet, FGQ achieves state-of-the-art results. We further study the impact of group size on both performance and accuracy. With a group size of $N=64$, we eliminate $\approx99\%$ of the multiplications; however, this introduces a noticeable drop in accuracy, which necessitates fine tuning the parameters at lower precision. We address this by fine-tuning Resnet-50 with 8-bit activations and ternary weights at $N=64$, improving the Top-1 accuracy to within $4\%$ of the full precision result with $<30\%$ additional training overhead. Our final quantized model can run on a full 8-bit compute pipeline using 2-bit weights and has the potential of up to $15\times$ improvement in performance compared to baseline full-precision models. version:3
arxiv-1705-10754 | A Low Dimensionality Representation for Language Variety Identification | http://arxiv.org/abs/1705.10754 | id:1705.10754 author:Francisco Rangel, Marc Franco-Salvador, Paolo Rosso category:cs.CL  published:2017-05-30 summary:Language variety identification aims at labelling texts in a native language (e.g. Spanish, Portuguese, English) with its specific variation (e.g. Argentina, Chile, Mexico, Peru, Spain; Brazil, Portugal; UK, US). In this work we propose a low dimensionality representation (LDR) to address this task with five different varieties of Spanish: Argentina, Chile, Mexico, Peru and Spain. We compare our LDR method with common state-of-the-art representations and show an increase in accuracy of ~35%. Furthermore, we compare LDR with two reference distributed representation models. Experimental results show competitive performance while dramatically reducing the dimensionality --and increasing the big data suitability-- to only 6 features per variety. Additionally, we analyse the behaviour of the employed machine learning algorithms and the most discriminating features. Finally, we employ an alternative dataset to test the robustness of our low dimensionality representation with another set of similar languages. version:1
arxiv-1705-10750 | Recurrent Estimation of Distributions | http://arxiv.org/abs/1705.10750 | id:1705.10750 author:Junier B. Oliva, Kumar Avinava Dubey, Barnabas Poczos, Eric Xing, Jeff Schneider category:cs.LG stat.ML  published:2017-05-30 summary:This paper presents the recurrent estimation of distributions (RED) for modeling real-valued data in a semiparametric fashion. RED models make two novel uses of recurrent neural networks (RNNs) for density estimation of general real-valued data. First, RNNs are used to transform input covariates into a latent space to better capture conditional dependencies in inputs. After, an RNN is used to compute the conditional distributions of the latent covariates. The resulting model is efficient to train, compute, and sample from, whilst producing normalized pdfs. The effectiveness of RED is shown via several real-world data experiments. Our results show that RED models achieve a lower held-out negative log-likelihood than other neural network approaches across multiple dataset sizes and dimensionalities. Further context of the efficacy of RED is provided by considering anomaly detection tasks, where we also observe better performance over alternative models. version:1
arxiv-1705-07204 | Ensemble Adversarial Training: Attacks and Defenses | http://arxiv.org/abs/1705.07204 | id:1705.07204 author:Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Dan Boneh, Patrick McDaniel category:stat.ML cs.CR cs.LG  published:2017-05-19 summary:Machine learning models are vulnerable to adversarial examples, inputs maliciously perturbed to mislead the model. These inputs transfer between models, thus enabling black-box attacks against deployed models. Adversarial training increases robustness to attacks by injecting adversarial examples into training data. Surprisingly, we find that although adversarially trained models exhibit strong robustness to some white-box attacks (i.e., with knowledge of the model parameters), they remain highly vulnerable to transferred adversarial examples crafted on other models. We show that the reason for this vulnerability is the model's decision surface exhibiting sharp curvature in the vicinity of the data points, thus hindering attacks based on first-order approximations of the model's loss, but permitting black-box attacks that use adversarial examples transferred from another model. We harness this observation in two ways: First, we propose a simple yet powerful novel attack that first applies a small random perturbation to an input, before finding the optimal perturbation under a first-order approximation. Our attack outperforms prior "single-step" attacks on models trained with or without adversarial training. Second, we propose Ensemble Adversarial Training, an extension of adversarial training that additionally augments training data with perturbed inputs transferred from a number of fixed pre-trained models. On MNIST and ImageNet, ensemble adversarial training vastly improves robustness to black-box attacks. version:2
arxiv-1705-10744 | Knowledge Base Completion: Baselines Strike Back | http://arxiv.org/abs/1705.10744 | id:1705.10744 author:Rudolf Kadlec, Ondrej Bajgar, Jan Kleindienst category:cs.LG cs.AI  published:2017-05-30 summary:Many papers have been published on the knowledge base completion task in the past few years. Most of these introduce novel architectures for relation learning that are evaluated on standard datasets such as FB15k and WN18. This paper shows that the accuracy of almost all models published on the FB15k can be outperformed by an appropriately tuned baseline - our reimplementation of the DistMult model. Our findings cast doubt on the claim that the performance improvements of recent models are due to architectural changes as opposed to hyper-parameter tuning or different training objectives. This should prompt future research to re-consider how the performance of models is evaluated and reported. version:1
arxiv-1705-10743 | The Cramer Distance as a Solution to Biased Wasserstein Gradients | http://arxiv.org/abs/1705.10743 | id:1705.10743 author:Marc G. Bellemare, Ivo Danihelka, Will Dabney, Shakir Mohamed, Balaji Lakshminarayanan, Stephan Hoyer, Rémi Munos category:cs.LG stat.ML  published:2017-05-30 summary:The Wasserstein probability metric has received much attention from the machine learning community. Unlike the Kullback-Leibler divergence, which strictly measures change in probability, the Wasserstein metric reflects the underlying geometry between outcomes. The value of being sensitive to this geometry has been demonstrated, among others, in ordinal regression and generative modelling. In this paper we describe three natural properties of probability divergences that reflect requirements from machine learning: sum invariance, scale sensitivity, and unbiased sample gradients. The Wasserstein metric possesses the first two properties but, unlike the Kullback-Leibler divergence, does not possess the third. We provide empirical evidence suggesting that this is a serious issue in practice. Leveraging insights from probabilistic forecasting we propose an alternative to the Wasserstein metric, the Cram\'er distance. We show that the Cram\'er distance possesses all three desired properties, combining the best of the Wasserstein and Kullback-Leibler divergences. To illustrate the relevance of the Cram\'er distance in practice we design a new algorithm, the Cram\'er Generative Adversarial Network (GAN), and show that it performs significantly better than the related Wasserstein GAN. version:1
arxiv-1705-10739 | Efficient Decentralized Visual Place Recognition From Full-Image Descriptors | http://arxiv.org/abs/1705.10739 | id:1705.10739 author:Titus Cieslewski, Davide Scaramuzza category:cs.RO cs.CV  published:2017-05-30 summary:In this paper, we discuss the adaptation of our decentralized place recognition method described in [1] to full image descriptors. As we had shown, the key to making a scalable decentralized visual place recognition lies in exploting deterministic key assignment in a distributed key-value map. Through this, it is possible to reduce bandwidth by up to a factor of n, the robot count, by casting visual place recognition to a key-value lookup problem. In [1], we exploited this for the bag-of-words method [3], [4]. Our method of casting bag-of-words, however, results in a complex decentralized system, which has inherently worse recall than its centralized counterpart. In this paper, we instead start from the recent full-image description method NetVLAD [5]. As we show, casting this to a key-value lookup problem can be achieved with k-means clustering, and results in a much simpler system than [1]. The resulting system still has some flaws, albeit of a completely different nature: it suffers when the environment seen during deployment lies in a different distribution in feature space than the environment seen during training. version:1
arxiv-1705-10723 | Fast Regression with an $\ell_\infty$ Guarantee | http://arxiv.org/abs/1705.10723 | id:1705.10723 author:Eric Price, Zhao Song, David P. Woodruff category:cs.DS cs.LG  published:2017-05-30 summary:Sketching has emerged as a powerful technique for speeding up problems in numerical linear algebra, such as regression. In the overconstrained regression problem, one is given an $n \times d$ matrix $A$, with $n \gg d$, as well as an $n \times 1$ vector $b$, and one wants to find a vector $\hat{x}$ so as to minimize the residual error $\ Ax-b\ _2$. Using the sketch and solve paradigm, one first computes $S \cdot A$ and $S \cdot b$ for a randomly chosen matrix $S$, then outputs $x' = (SA)^{\dagger} Sb$ so as to minimize $\ SAx' - Sb\ _2$. The sketch-and-solve paradigm gives a bound on $\ x'-x^*\ _2$ when $A$ is well-conditioned. Our main result is that, when $S$ is the subsampled randomized Fourier/Hadamard transform, the error $x' - x^*$ behaves as if it lies in a "random" direction within this bound: for any fixed direction $a\in \mathbb{R}^d$, we have with $1 - d^{-c}$ probability that \[ \langle a, x'-x^*\rangle \lesssim \frac{\ a\ _2\ x'-x^*\ _2}{d^{\frac{1}{2}-\gamma}}, \quad (1) \] where $c, \gamma > 0$ are arbitrary constants. This implies $\ x'-x^*\ _{\infty}$ is a factor $d^{\frac{1}{2}-\gamma}$ smaller than $\ x'-x^*\ _2$. It also gives a better bound on the generalization of $x'$ to new examples: if rows of $A$ correspond to examples and columns to features, then our result gives a better bound for the error introduced by sketch-and-solve when classifying fresh examples. We show that not all oblivious subspace embeddings $S$ satisfy these properties. In particular, we give counterexamples showing that matrices based on Count-Sketch or leverage score sampling do not satisfy these properties. We also provide lower bounds, both on how small $\ x'-x^*\ _2$ can be, and for our new guarantee (1), showing that the subsampled randomized Fourier/Hadamard transform is nearly optimal. version:1
arxiv-1705-10716 | Addressing Ambiguity in Multi-target Tracking by Hierarchical Strategy | http://arxiv.org/abs/1705.10716 | id:1705.10716 author:Ali Taalimi, Liu Liu, Hairong Qi category:cs.CV  published:2017-05-30 summary:This paper presents a novel hierarchical approach for the simultaneous tracking of multiple targets in a video. We use a network flow approach to link detections in low-level and tracklets in high-level. At each step of the hierarchy, the confidence of candidates is measured by using a new scoring system, ConfRank, that considers the quality and the quantity of its neighborhood. The output of the first stage is a collection of safe tracklets and unlinked high-confidence detections. For each individual detection, we determine if it belongs to an existing or is a new tracklet. We show the effect of our framework to recover missed detections and reduce switch identity. The proposed tracker is referred to as TVOD for multi-target tracking using the visual tracker and generic object detector. We achieve competitive results with lower identity switches on several datasets comparing to state-of-the-art. version:1
arxiv-1705-10701 | Multi-Labelled Value Networks for Computer Go | http://arxiv.org/abs/1705.10701 | id:1705.10701 author:Ti-Rong Wu, I-Chen Wu, Guan-Wun Chen, Ting-han Wei, Tung-Yi Lai, Hung-Chun Wu, Li-Cheng Lan category:cs.AI cs.LG  published:2017-05-30 summary:This paper proposes a new approach to a novel value network architecture for the game Go, called a multi-labelled (ML) value network. In the ML value network, different values (win rates) are trained simultaneously for different settings of komi, a compensation given to balance the initiative of playing first. The ML value network has three advantages, (a) it outputs values for different komi, (b) it supports dynamic komi, and (c) it lowers the mean squared error (MSE). This paper also proposes a new dynamic komi method to improve game-playing strength. This paper also performs experiments to demonstrate the merits of the architecture. First, the MSE of the ML value network is generally lower than the value network alone. Second, the program based on the ML value network wins by a rate of 67.6% against the program based on the value network alone. Third, the program with the proposed dynamic komi method significantly improves the playing strength over the baseline that does not use dynamic komi, especially for handicap games. To our knowledge, up to date, no handicap games have been played openly by programs using value networks. This paper provides these programs with a useful approach to playing handicap games. version:1
arxiv-1705-10698 | ResnetCrowd: A Residual Deep Learning Architecture for Crowd Counting, Violent Behaviour Detection and Crowd Density Level Classification | http://arxiv.org/abs/1705.10698 | id:1705.10698 author:Mark Marsden, Kevin McGuinness, Suzanne Little, Noel E. O'Connor category:cs.CV  published:2017-05-30 summary:In this paper we propose ResnetCrowd, a deep residual architecture for simultaneous crowd counting, violent behaviour detection and crowd density level classification. To train and evaluate the proposed multi-objective technique, a new 100 image dataset referred to as Multi Task Crowd is constructed. This new dataset is the first computer vision dataset fully annotated for crowd counting, violent behaviour detection and density level classification. Our experiments show that a multi-task approach boosts individual task performance for all tasks and most notably for violent behaviour detection which receives a 9\% boost in ROC curve AUC (Area under the curve). The trained ResnetCrowd model is also evaluated on several additional benchmarks highlighting the superior generalisation of crowd analysis models trained for multiple objectives. version:1
arxiv-1705-10686 | Feature Squeezing Mitigates and Detects Carlini/Wagner Adversarial Examples | http://arxiv.org/abs/1705.10686 | id:1705.10686 author:Weilin Xu, David Evans, Yanjun Qi category:cs.CR cs.LG  published:2017-05-30 summary:Feature squeezing is a recently-introduced framework for mitigating and detecting adversarial examples. In previous work, we showed that it is effective against several earlier methods for generating adversarial examples. In this short note, we report on recent results showing that simple feature squeezing techniques also make deep learning models significantly more robust against the Carlini/Wagner attacks, which are the best known adversarial methods discovered to date. version:1
arxiv-1705-10659 | Discovering Visual Concept Structure with Sparse and Incomplete Tags | http://arxiv.org/abs/1705.10659 | id:1705.10659 author:Jingya Wang, Xiatian Zhu, Shaogang Gong category:cs.CV  published:2017-05-30 summary:Discovering automatically the semantic structure of tagged visual data (e.g. web videos and images) is important for visual data analysis and interpretation, enabling the machine intelligence for effectively processing the fast-growing amount of multi-media data. However, this is non-trivial due to the need for jointly learning underlying correlations between heterogeneous visual and tag data. The task is made more challenging by inherently sparse and incomplete tags. In this work, we develop a method for modelling the inherent visual data concept structures based on a novel Hierarchical-Multi-Label Random Forest model capable of correlating structured visual and tag information so as to more accurately interpret the visual semantics, e.g. disclosing meaningful visual groups with similar high-level concepts, and recovering missing tags for individual visual data samples. Specifically, our model exploits hierarchically structured tags of different semantic abstractness and multiple tag statistical correlations in addition to modelling visual and tag interactions. As a result, our model is able to discover more accurate semantic correlation between textual tags and visual features, and finally providing favourable visual semantics interpretation even with highly sparse and incomplete tags. We demonstrate the advantages of our proposed approach in two fundamental applications, visual data clustering and missing tag completion, on benchmarking video (i.e. TRECVID MED 2011) and image (i.e. NUS-WIDE) datasets. version:1
arxiv-1705-10639 | Grammatical Inference as a Satisfiability Modulo Theories Problem | http://arxiv.org/abs/1705.10639 | id:1705.10639 author:Rick Smetsers category:cs.FL cs.LG cs.LO  published:2017-05-30 summary:The problem of learning a minimal consistent model from a set of labeled sequences of symbols is addressed from a satisfiability modulo theories perspective. We present two encodings for deterministic finite automata and extend one of these for Moore and Mealy machines. Our experimental results show that these encodings improve upon the state-of-the-art, and are useful in practice for learning small models. version:1
arxiv-1705-10134 | On Residual CNN in text-dependent speaker verification task | http://arxiv.org/abs/1705.10134 | id:1705.10134 author:Egor Malykh, Sergey Novoselov, Oleg Kudashev category:cs.SD cs.LG  published:2017-05-29 summary:Deep learning approaches are still not very common in the speaker verification field. We investigate the possibility of using deep residual convolutional neural network with spectrograms as an input features in the text-dependent speaker verification task. Despite the fact that we were not able to surpass the baseline system in quality, we achieved a quite good results for such a new approach getting an 5.23% ERR on the RSR2015 evaluation part. Fusion of the baseline and proposed systems outperformed the best individual system by 18% relatively. version:2
arxiv-1705-10583 | Nighttime sky/cloud image segmentation | http://arxiv.org/abs/1705.10583 | id:1705.10583 author:Soumyabrata Dev, Florian M. Savoy, Yee Hui Lee, Stefan Winkler category:cs.CV  published:2017-05-30 summary:Imaging the atmosphere using ground-based sky cameras is a popular approach to study various atmospheric phenomena. However, it usually focuses on the daytime. Nighttime sky/cloud images are darker and noisier, and thus harder to analyze. An accurate segmentation of sky/cloud images is already challenging because of the clouds' non-rigid structure and size, and the lower and less stable illumination of the night sky increases the difficulty. Nonetheless, nighttime cloud imaging is essential in certain applications, such as continuous weather analysis and satellite communication. In this paper, we propose a superpixel-based method to segment nighttime sky/cloud images. We also release the first nighttime sky/cloud image segmentation database to the research community. The experimental results show the efficacy of our proposed algorithm for nighttime images. version:1
arxiv-1705-10574 | Multi-Focus Image Fusion Via Coupled Sparse Representation and Dictionary Learning | http://arxiv.org/abs/1705.10574 | id:1705.10574 author:Rui Gao, Sergiy A. Vorobyov category:cs.CV cs.LG  published:2017-05-30 summary:We address the multi-focus image fusion problem, where multiple images captured with different focal settings are to be fused into an all-in-focus image of higher quality. Algorithms for this problem necessarily admit the source image characteristics along with focused and blurred feature. However, most sparsity-based approaches use a single dictionary in focused feature space to describe multi-focus images, and ignore the representations in blurred feature space. Here, we propose a multi-focus image fusion approach based on coupled sparse representation. The approach exploits the facts that (i) the patches in given training set can be sparsely represented by a couple of overcomplete dictionaries related to the focused and blurred categories of images; and (ii) merging such representations leads to a more flexible and therefore better fusion strategy than the one based on just selecting the sparsest representation in the original image estimate. By jointly learning the coupled dictionary, we enforce the similarity of sparse representations in the focused and blurred feature spaces, and then introduce a fusion approach to combine these representations for generating an all-in-focus image. We also discuss the advantages of the fusion approach based on coupled sparse representation and present an efficient algorithm for learning the coupled dictionary. Extensive experimental comparisons with state-of-the-art multi-focus image fusion algorithms validate the effectiveness of the proposed approach. version:1
arxiv-1705-10561 | End-to-end Active Object Tracking via Reinforcement Learning | http://arxiv.org/abs/1705.10561 | id:1705.10561 author:Wenhan Luo, Peng Sun, Yadong Mu, Wei Liu category:cs.CV  published:2017-05-30 summary:In this paper we propose an active object tracking approach, which provides a tracking solution simultaneously addressing tracking and camera control. Crucially, these two tasks are tackled in an end-to-end manner via reinforcement learning. Specifically, a ConvNet-LSTM function approximator is adopted, which takes as input only visual observations (i.e., frame sequences) and directly outputs camera motions (e.g., move forward, turn left, etc.). The tracker, regarded as an agent, is trained with the A3C algorithm, where we harness an environment augmentation technique and a customized rewarding function to encourage robust object tracking. We carry out experiments on the AI research platform ViZDoom. The yielded tracker can automatically pay attention to the most likely object in the initial frame and perform tracking subsequently, not requiring a manual bounding box as initialization. Moreover, our approach shows a good generalization ability when performing tracking in case of unseen object moving path, object appearance, background and distracting object. The tracker can even restore tracking once it occasionally loses the target. version:1
arxiv-1705-10552 | Interpreting and Extending The Guided Filter Via Cyclic Coordinate Descent | http://arxiv.org/abs/1705.10552 | id:1705.10552 author:Longquan Dai category:cs.CV  published:2017-05-30 summary:In this paper, we will disclose that the Guided Filter (GF) can be interpreted as the Cyclic Coordinate Descent (CCD) solver of a Least Square (LS) objective function. This discovery implies a possible way to extend GF because we can alter the objective function of GF and define new filters as the first pass iteration of the CCD solver of modified objective functions. Moreover, referring to the iterative minimizing procedure of CCD, we can derive new rolling filtering schemes. Hence, under the guidance of this discovery, we not only propose new GF-like filters adapting to the specific requirements of applications but also offer thoroughly explanations for two rolling filtering schemes of GF as well as the way to extend them. Experiments show that our new filters and extensions produce state-of-the-art results. version:1
arxiv-1705-09899 | Understanding Abuse: A Typology of Abusive Language Detection Subtasks | http://arxiv.org/abs/1705.09899 | id:1705.09899 author:Zeerak Waseem, Thomas Davidson, Dana Warmsley, Ingmar Weber category:cs.CL  published:2017-05-28 summary:As the body of research on abusive language detection and analysis grows, there is a need for critical consideration of the relationships between different subtasks that have been grouped under this label. Based on work on hate speech, cyberbullying, and online abuse we propose a typology that captures central similarities and differences between subtasks and we discuss its implications for data annotation and feature construction. We emphasize the practical actions that can be taken by researchers to best approach their abusive language detection subtask of interest. version:2
arxiv-1705-10546 | Saliency Revisited: Analysis of Mouse Movements versus Fixations | http://arxiv.org/abs/1705.10546 | id:1705.10546 author:Hamed R. Tavakoli, Fawad Ahmed, Ali Borji, Jorma Laaksonen category:cs.CV  published:2017-05-30 summary:This paper revisits visual saliency prediction by evaluating the recent advancements in this field such as crowd-sourced mouse tracking-based databases and contextual annotations. We pursue a critical and quantitative approach towards some of the new challenges including the quality of mouse tracking versus eye tracking for model training and evaluation. We extend quantitative evaluation of models in order to incorporate contextual information by proposing an evaluation methodology that allows accounting for contextual factors such as text, faces, and object attributes. The proposed contextual evaluation scheme facilitates detailed analysis of models and helps identify their pros and cons. Through several experiments, we find that (1) mouse tracking data has lower inter-participant visual congruency and higher dispersion, compared to the eye tracking data, (2) mouse tracking data does not totally agree with eye tracking in general and in terms of different contextual regions in specific, and (3) mouse tracking data leads to acceptable results in training current existing models, and (4) mouse tracking data is less reliable for model selection and evaluation. The contextual evaluation also reveals that, among the studied models, there is no single model that performs best on all the tested annotations. version:1
arxiv-1705-10545 | Parcellation of Visual Cortex on high-resolution histological Brain Sections using Convolutional Neural Networks | http://arxiv.org/abs/1705.10545 | id:1705.10545 author:Hannah Spitzer, Katrin Amunts, Stefan Harmeling, Timo Dickscheid category:cs.CV  published:2017-05-30 summary:Microscopic analysis of histological sections is considered the "gold standard" to verify structural parcellations in the human brain. Its high resolution allows the study of laminar and columnar patterns of cell distributions, which build an important basis for the simulation of cortical areas and networks. However, such cytoarchitectonic mapping is a semiautomatic, time consuming process that does not scale with high throughput imaging. We present an automatic approach for parcellating histological sections at 2um resolution. It is based on a convolutional neural network that combines topological information from probabilistic atlases with the texture features learned from high-resolution cell-body stained images. The model is applied to visual areas and trained on a sparse set of partial annotations. We show how predictions are transferable to new brains and spatially consistent across sections. version:1
arxiv-1705-10528 | Constrained Policy Optimization | http://arxiv.org/abs/1705.10528 | id:1705.10528 author:Joshua Achiam, David Held, Aviv Tamar, Pieter Abbeel category:cs.LG  published:2017-05-30 summary:For many applications of reinforcement learning it can be more convenient to specify both a reward function and constraints, rather than trying to design behavior through the reward function. For example, systems that physically interact with or around humans should satisfy safety constraints. Recent advances in policy search algorithms (Mnih et al., 2016, Schulman et al., 2015, Lillicrap et al., 2016, Levine et al., 2016) have enabled new capabilities in high-dimensional control, but do not consider the constrained setting. We propose Constrained Policy Optimization (CPO), the first general-purpose policy search algorithm for constrained reinforcement learning with guarantees for near-constraint satisfaction at each iteration. Our method allows us to train neural network policies for high-dimensional control while making guarantees about policy behavior all throughout training. Our guarantees are based on a new theoretical result, which is of independent interest: we prove a bound relating the expected returns of two policies to an average divergence between them. We demonstrate the effectiveness of our approach on simulated robot locomotion tasks where the agent must satisfy constraints motivated by safety. version:1
arxiv-1705-10524 | Decorrelation of Neutral Vector Variables: Theory and Applications | http://arxiv.org/abs/1705.10524 | id:1705.10524 author:Zhanyu Ma, Jing-Hao Xue, Arne Leijon, Zheng-Hua Tan, Zhen Yang, Jun Guo category:cs.CV stat.ML  published:2017-05-30 summary:In this paper, we propose novel strategies for neutral vector variable decorrelation. Two fundamental invertible transformations, namely serial nonlinear transformation and parallel nonlinear transformation, are proposed to carry out the decorrelation. For a neutral vector variable, which is not multivariate Gaussian distributed, the conventional principal component analysis (PCA) cannot yield mutually independent scalar variables. With the two proposed transformations, a highly negatively correlated neutral vector can be transformed to a set of mutually independent scalar variables with the same degrees of freedom. We also evaluate the decorrelation performances for the vectors generated from a single Dirichlet distribution and a mixture of Dirichlet distributions. The mutual independence is verified with the distance correlation measurement. The advantages of the proposed decorrelation strategies are intensively studied and demonstrated with synthesized data and practical application evaluations. version:1
arxiv-1705-00664 | Bayesian Image Quality Transfer with CNNs: Exploring Uncertainty in dMRI Super-Resolution | http://arxiv.org/abs/1705.00664 | id:1705.00664 author:Ryutaro Tanno, Daniel E. Worrall, Aurobrata Ghosh, Enrico Kaden, Stamatios N. Sotiropoulos, Antonio Criminisi, Daniel C. Alexander category:cs.CV  published:2017-05-01 summary:In this work, we investigate the value of uncertainty modeling in 3D super-resolution with convolutional neural networks (CNNs). Deep learning has shown success in a plethora of medical image transformation problems, such as super-resolution (SR) and image synthesis. However, the highly ill-posed nature of such problems results in inevitable ambiguity in the learning of networks. We propose to account for intrinsic uncertainty through a per-patch heteroscedastic noise model and for parameter uncertainty through approximate Bayesian inference in the form of variational dropout. We show that the combined benefits of both lead to the state-of-the-art performance SR of diffusion MR brain images in terms of errors compared to ground truth. We further show that the reduced error scores produce tangible benefits in downstream tractography. In addition, the probabilistic nature of the methods naturally confers a mechanism to quantify uncertainty over the super-resolved output. We demonstrate through experiments on both healthy and pathological brains the potential utility of such an uncertainty measure in the risk assessment of the super-resolved images for subsequent clinical use. version:2
arxiv-1705-10513 | IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models | http://arxiv.org/abs/1705.10513 | id:1705.10513 author:Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, Peng Zhang, Dell Zhang category:cs.IR cs.LG  published:2017-05-30 summary:This paper provides a unified account of two schools of thinking in information retrieval modelling: the generative retrieval focusing on predicting relevant documents given a query, and the discriminative retrieval focusing on predicting relevancy given a query-document pair. We propose a game theoretical minimax game to iteratively optimise both models. On one hand, the discriminative model, aiming to mine signals from labelled and unlabelled data, provides guidance to train the generative model towards fitting the underlying relevance distribution over documents given the query. On the other hand, the generative model, acting as an attacker to the current discriminative model, generates difficult examples for the discriminative model in an adversarial way by minimising its discrimination objective. With the competition between these two models, we show that the unified framework takes advantage of both schools of thinking: (i) the generative model learns to fit the relevance distribution over documents via the signals from the discriminative model, and (ii) the discriminative model is able to exploit the unlabelled data selected by the generative model to achieve a better estimation for document ranking. Our experimental results have demonstrated significant performance gains as much as 23.96% on Precision@5 and 15.50% on MAP over strong baselines in a variety of applications including web search, item recommendation, and question answering. version:1
arxiv-1705-10508 | Implications of Decentralized Q-learning Resource Allocation in Wireless Networks | http://arxiv.org/abs/1705.10508 | id:1705.10508 author:Francesc Wilhelmi, Boris Bellalta, Cristina Cano, Anders Jonsson category:cs.NI cs.LG  published:2017-05-30 summary:Reinforcement Learning is gaining attention by the wireless networking community due to its potential to learn good-performing configurations only from the observed results. In this work we propose a stateless variation of Q-learning, which we apply to exploit spatial reuse in a wireless network. In particular, we allow networks to modify both their transmission power and the channel used solely based on the experienced throughput. We concentrate in a completely decentralized scenario in which no information about neighbouring nodes is available to the learners. Our results show that although the algorithm is able to find the best-performing actions to enhance aggregate throughput, there is high variability in the throughput experienced by the individual networks. We identify the cause of this variability as the adversarial setting of our setup, in which the most played actions provide intermittent good/poor performance depending on the neighbouring decisions. We also evaluate the effect of the intrinsic learning parameters of the algorithm on this variability. version:1
arxiv-1705-09792 | Deep Complex Networks | http://arxiv.org/abs/1705.09792 | id:1705.09792 author:Chiheb Trabelsi, Olexa Bilaniuk, Dmitriy Serdyuk, Sandeep Subramanian, João Felipe Santos, Soroush Mehri, Negar Rostamzadeh, Yoshua Bengio, Christopher J Pal category:cs.NE cs.LG  published:2017-05-27 summary:At present, the vast majority of building blocks, techniques, and architectures for deep learning are based on real-valued operations and representations. However, recent work on recurrent neural networks and older fundamental theoretical analysis suggests that complex numbers could have a richer representational capacity and could also facilitate noise-robust memory retrieval mechanisms. Despite their attractive properties and potential for opening up entirely new neural architectures, complex-valued deep neural networks have been marginalized due to the absence of the building blocks required to design such models. In this work, we provide the key atomic components for complex-valued deep neural networks and apply them to convolutional feed-forward networks. More precisely, we rely on complex convolutions and present algorithms for complex batch-normalization, complex weight initialization strategies for complex-valued neural nets and we use them in experiments with end-to-end training schemes. We demonstrate that such complex-valued models are able to achieve comparable or better performance than their real-valued counterparts. We test deep complex models on several computer vision tasks and on music transcription using the MusicNet dataset where we achieve state of the art performance. version:2
arxiv-1705-10503 | Quantum Low Entropy based Associative Reasoning or QLEAR Learning | http://arxiv.org/abs/1705.10503 | id:1705.10503 author:Marko V. Jankovic category:cs.LG cs.IT math.IT  published:2017-05-30 summary:In this paper, we propose the classification method based on a learning paradigm we are going to call Quantum Low Entropy based Associative Reasoning or QLEAR learning. The approach is based on the idea that classification can be understood as supervised clustering, where a quantum entropy in the context of the quantum probabilistic model, will be used as a "capturer" (measure, or external index), of the "natural structure" of the data. By using quantum entropy we do not make any assumption about linear separability of the data that are going to be classified. The basic idea is to find close neighbors to a query sample and then use relative change in the quantum entropy as a measure of similarity of the newly arrived sample with the representatives of interest. In other words, method is based on calculation of quantum entropy of the referent system and its relative change with the addition of the newly arrived sample. Referent system consists of vectors that represent individual classes and that are the most similar, in Euclidean distance sense, to the vector that is analyzed. Here, we analyze the classification problem in the context of measuring similarities to prototype examples of categories. While nearest neighbor classifiers are natural in this setting, they suffer from the problem of high variance (in bias-variance decomposition) in the case of limited sampling. Alternatively, one could use machine learning techniques (like support vector machines) but they involve time-consuming optimization. Here we propose a hybrid of nearest neighbor and machine learning technique which deals naturally with the multi-class setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice. version:1
arxiv-1705-10500 | Exploiting Restricted Boltzmann Machines and Deep Belief Networks in Compressed Sensing | http://arxiv.org/abs/1705.10500 | id:1705.10500 author:Luisa F. Polania, Kenneth E. Barner category:cs.LG  published:2017-05-30 summary:This paper proposes a CS scheme that exploits the representational power of restricted Boltzmann machines and deep learning architectures to model the prior distribution of the sparsity pattern of signals belonging to the same class. The determined probability distribution is then used in a maximum a posteriori (MAP) approach for the reconstruction. The parameters of the prior distribution are learned from training data. The motivation behind this approach is to model the higher-order statistical dependencies between the coefficients of the sparse representation, with the final goal of improving the reconstruction. The performance of the proposed method is validated on the Berkeley Segmentation Dataset and the MNIST Database of handwritten digits. version:1
arxiv-1705-10498 | Zonotope hit-and-run for efficient sampling from projection DPPs | http://arxiv.org/abs/1705.10498 | id:1705.10498 author:Guillaume Gautier, Rémi Bardenet, Michal Valko category:stat.ML cs.LG stat.CO  published:2017-05-30 summary:Determinantal point processes (DPPs) are distributions over sets of items that model diversity using kernels. Their applications in machine learning include summary extraction and recommendation systems. Yet, the cost of sampling from a DPP is prohibitive in large-scale applications, which has triggered an effort towards efficient approximate samplers. We build a novel MCMC sampler that combines ideas from combinatorial geometry, linear programming, and Monte Carlo methods to sample from DPPs with a fixed sample cardinality, also called projection DPPs. Our sampler leverages the ability of the hit-and-run MCMC kernel to efficiently move across convex bodies. Previous theoretical results yield a fast mixing time of our chain when targeting a distribution that is close to a projection DPP, but not a DPP in general. Our empirical results demonstrate that this extends to sampling projection DPPs, i.e., our sampler is more sample-efficient than previous approaches. version:1
arxiv-1705-10494 | Joint auto-encoders: a flexible multi-task learning framework | http://arxiv.org/abs/1705.10494 | id:1705.10494 author:Baruch Epstein. Ron Meir, Tomer Michaeli category:stat.ML cs.LG  published:2017-05-30 summary:The incorporation of prior knowledge into learning is essential in achieving good performance based on small noisy samples. Such knowledge is often incorporated through the availability of related data arising from domains and tasks similar to the one of current interest. Ideally one would like to allow both the data for the current task and for previous related tasks to self-organize the learning system in such a way that commonalities and differences between the tasks are learned in a data-driven fashion. We develop a framework for learning multiple tasks simultaneously, based on sharing features that are common to all tasks, achieved through the use of a modular deep feedforward neural network consisting of shared branches, dealing with the common features of all tasks, and private branches, learning the specific unique aspects of each task. Once an appropriate weight sharing architecture has been established, learning takes place through standard algorithms for feedforward networks, e.g., stochastic gradient descent and its variations. The method deals with domain adaptation and multi-task learning in a unified fashion, and can easily deal with data arising from different types of sources. Numerical experiments demonstrate the effectiveness of learning in domain adaptation and transfer learning setups, and provide evidence for the flexible and task-oriented representations arising in the network. version:1
arxiv-1705-10479 | Multi-Modal Imitation Learning from Unstructured Demonstrations using Generative Adversarial Nets | http://arxiv.org/abs/1705.10479 | id:1705.10479 author:Karol Hausman, Yevgen Chebotar, Stefan Schaal, Gaurav Sukhatme, Joseph Lim category:cs.RO cs.LG  published:2017-05-30 summary:Imitation learning has traditionally been applied to learn a single task from demonstrations thereof. The requirement of structured and isolated demonstrations limits the scalability of imitation learning approaches as they are difficult to apply to real-world scenarios, where robots have to be able to execute a multitude of tasks. In this paper, we propose a multi-modal imitation learning framework that is able to segment and imitate skills from unlabelled and unstructured demonstrations by learning skill segmentation and imitation learning jointly. The extensive simulation results indicate that our method can efficiently separate the demonstrations into individual skills and learn to imitate them using a single multi-modal policy. The video of our experiments is available at http://sites.google.com/view/nips17intentiongan version:1
arxiv-1705-10470 | Iterative Machine Teaching | http://arxiv.org/abs/1705.10470 | id:1705.10470 author:Weiyang Liu, Bo Dai, James M. Rehg, Le Song category:stat.ML cs.LG  published:2017-05-30 summary:In this paper, we consider the problem of machine teaching, the inverse problem of machine learning. Different from traditional machine teaching which views the learners as batch algorithms, we study a new paradigm where the learner uses an iterative algorithm and a teacher can feed examples sequentially and intelligently based on the current performance of the learner. We show that the teaching complexity in the iterative case is very different from that in the batch case. Instead of constructing a minimal training set for learners, our iterative machine teaching focuses on achieving fast convergence in the learner model. Depending on the level of information the teacher has from the learner model, we design teaching algorithms which can provably reduce the number of teaching examples and achieve faster convergence than learning without teachers. We also validate our theoretical findings with extensive experiments on different data distribution and real image datasets. version:1
arxiv-1705-10467 | Federated Multi-Task Learning | http://arxiv.org/abs/1705.10467 | id:1705.10467 author:Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, Ameet Talwalkar category:cs.LG stat.ML  published:2017-05-30 summary:Federated learning poses new statistical and systems challenges in training machine learning models over distributed networks of devices. In this work, we show that multi-task learning is naturally suited to handle the statistical challenges of this setting, and propose a novel systems-aware optimization method, MOCHA, that is robust to practical systems issues. Our method and theory for the first time consider issues of high communication cost, stragglers, and fault tolerance for distributed multi-task learning. The resulting method achieves significant speedups compared to alternatives in the federated setting, as we demonstrate through simulations on real-world federated datasets. version:1
arxiv-1705-10461 | The Numerics of GANs | http://arxiv.org/abs/1705.10461 | id:1705.10461 author:Lars Mescheder, Sebastian Nowozin, Andreas Geiger category:cs.LG  published:2017-05-30 summary:In this paper, we analyze the numerics of common algorithms for training Generative Adversarial Networks (GANs). Using the formalism of smooth two-player games we analyze the associated gradient vector field of GAN training objectives. Our findings suggest that the convergence of current algorithms suffers due to two factors: i) presence of eigenvalues of the Jacobian of the gradient vector field with zero real-part, and ii) eigenvalues with big imaginary part. Using these findings, we design a new algorithm that overcomes some of these limitations and has better convergence properties. Experimentally, we demonstrate its superiority on training common GAN architectures and show convergence on GAN architectures that are known to be notoriously hard to train. version:1
arxiv-1705-10786 | Semi-Supervised Learning for Detecting Human Trafficking | http://arxiv.org/abs/1705.10786 | id:1705.10786 author:Hamidreza Alvari, Paulo Shakarian, J. E. Kelly Snyder category:cs.LG cs.AI  published:2017-05-30 summary:Human trafficking is one of the most atrocious crimes and among the challenging problems facing law enforcement which demands attention of global magnitude. In this study, we leverage textual data from the website "Backpage"- used for classified advertisement- to discern potential patterns of human trafficking activities which manifest online and identify advertisements of high interest to law enforcement. Due to the lack of ground truth, we rely on a human analyst from law enforcement, for hand-labeling a small portion of the crawled data. We extend the existing Laplacian SVM and present S3VM-R, by adding a regularization term to exploit exogenous information embedded in our feature space in favor of the task at hand. We train the proposed method using labeled and unlabeled data and evaluate it on a fraction of the unlabeled data, herein referred to as unseen data, with our expert's further verification. Results from comparisons between our method and other semi-supervised and supervised approaches on the labeled data demonstrate that our learner is effective in identifying advertisements of high interest to law enforcement version:1
arxiv-1704-07352 | A Saddle Point Approach to Structured Low-rank Matrix Learning | http://arxiv.org/abs/1704.07352 | id:1704.07352 author:Pratik Jawanpuria, Bamdev Mishra category:stat.ML cs.LG  published:2017-04-24 summary:We propose a novel optimization approach for learning a low-rank matrix which is also constrained to be in a given linear subspace. Low-rank constraints are regularly employed in applications such as recommender systems and multi-task learning. In addition, several system identification problems require a learning matrix with both low-rank and linear subspace constraints. We model the classical nuclear norm regularized formulation as an equivalent saddle point minimax problem. This decouples the low-rank and the linear subspace constraints onto separate factors. Motivated by large-scale problems, we reformulate the minimax problem via a rank constrained non-convex surrogate. This translates into an optimization problem on the Riemannian spectrahedron manifold. We exploit the Riemannian structure to propose efficient first- and second-order algorithms. The duality theory allows to compute the duality gap for a candidate solution and our approach easily accommodates popular non-smooth loss functions, e.g., the absolute-value loss. We effortlessly scale on the Netflix data set on both matrix completion and robust matrix completion problems, obtaining state-of-the-art generalization performance. Additionally, we demonstrate the efficacy of our approach in Hankel matrix learning and multi-task learning problems. version:2
arxiv-1705-10450 | RSI-CB: A Large Scale Remote Sensing Image Classification Benchmark via Crowdsource Data | http://arxiv.org/abs/1705.10450 | id:1705.10450 author:Haifeng Li, Chao Tao, Zhixiang Wu, Jie Chen, Jianya Gong, Min Deng category:cs.CV  published:2017-05-30 summary:Remote sensing image classification is a fundamental task in remote sensing image processing. Remote sensing field still lacks of such a large-scale benchmark compared to ImageNet, Place2. We propose a remote sensing image classification benchmark (RSI-CB) based on crowd-source data which is massive, scalable, and diversity. Using crowdsource data, we can efficiently annotate ground objects in remotes sensing image by point of interests, vectors data from OSM or other crowd-source data. Based on this method, we construct a worldwide large-scale benchmark for remote sensing image classification. In this benchmark, there are two sub datasets with 256 * 256 and 128 * 128 size respectively since different convolution neural networks requirement different image size. The former sub dataset contains 6 categories with 35 subclasses with total of more than 24,000 images; the later one contains 6 categories with 45 subclasses with total of more than 36,000 images. The six categories are agricultural land, construction land and facilities, transportation and facilities, water and water conservancy facilities, woodland and other land, and each category has several subclasses. This classification system is defined according to the national standard of land use classification in China, and is inspired by the hierarchy mechanism of ImageNet. Finally, we have done a large number of experiments to compare RSI-CB with SAT-4, UC-Merced datasets on handcrafted features, such as such as SIFT, and classical CNN models, such as AlexNet, VGG, GoogleNet, and ResNet. We also show CNN models trained by RSI-CB have good performance when transfer to other dataset, i.e. UC-Merced, and good generalization ability. The experiments show that RSI-CB is more suitable as a benchmark for remote sensing image classification task than other ones in big data era, and can be potentially used in practical applications. version:1
arxiv-1705-10447 | Robust Tracking Using Region Proposal Networks | http://arxiv.org/abs/1705.10447 | id:1705.10447 author:Jimmy Ren, Zhiyang Yu, Jianbo Liu, Rui Zhang, Wenxiu Sun, Jiahao Pang, Xiaohao Chen, Qiong Yan category:cs.CV  published:2017-05-30 summary:Recent advances in visual tracking showed that deep Convolutional Neural Networks (CNN) trained for image classification can be strong feature extractors for discriminative trackers. However, due to the drastic difference between image classification and tracking, extra treatments such as model ensemble and feature engineering must be carried out to bridge the two domains. Such procedures are either time consuming or hard to generalize well across datasets. In this paper we discovered that the internal structure of Region Proposal Network (RPN)'s top layer feature can be utilized for robust visual tracking. We showed that such property has to be unleashed by a novel loss function which simultaneously considers classification accuracy and bounding box quality. Without ensemble and any extra treatment on feature maps, our proposed method achieved state-of-the-art results on several large scale benchmarks including OTB50, OTB100 and VOT2016. We will make our code publicly available. version:1
arxiv-1705-10444 | Unsupervised Person Re-identification: Clustering and Fine-tuning | http://arxiv.org/abs/1705.10444 | id:1705.10444 author:Hehe Fan, Liang Zheng, Yi Yang category:cs.CV  published:2017-05-30 summary:The superiority of deeply learned pedestrian representations has been reported in very recent literature of person re-identification (re-ID). In this paper, we consider the more pragmatic issue of learning a deep feature with only a few or no labels. We propose a progressive unsupervised learning (PUL) method to transfer pretrained deep representations to unseen domains. Our method is easy to implement and can be viewed as an effective baseline for unsupervised feature learning. Specifically, PUL iterates between 1) pedestrian clustering and 2) fine-tuning of the convolutional neural network (CNN) to improve the original model trained on the irrelevant labeled dataset. At the beginning when the model is weak, CNN is fine-tuned on a small amount of reliable examples which locate near to cluster centroids in the feature space. As the model becomes stronger in subsequent iterations, more images are being selected as CNN training samples. Progressively, pedestrian clustering and the CNN model are improved simultaneously until algorithm convergence. We then point out promising directions that may lead to further improvement. version:1
arxiv-1705-06839 | Deep-LK for Efficient Adaptive Object Tracking | http://arxiv.org/abs/1705.06839 | id:1705.06839 author:Chaoyang Wang, Hamed Kiani Galoogahi, Chen-Hsuan Lin, Simon Lucey category:cs.CV  published:2017-05-19 summary:In this paper we present a new approach for efficient regression based object tracking which we refer to as Deep- LK. Our approach is closely related to the Generic Object Tracking Using Regression Networks (GOTURN) framework of Held et al. We make the following contributions. First, we demonstrate that there is a theoretical relationship between siamese regression networks like GOTURN and the classical Inverse-Compositional Lucas & Kanade (IC-LK) algorithm. Further, we demonstrate that unlike GOTURN IC-LK adapts its regressor to the appearance of the currently tracked frame. We argue that this missing property in GOTURN can be attributed to its poor performance on unseen objects and/or viewpoints. Second, we propose a novel framework for object tracking - which we refer to as Deep-LK - that is inspired by the IC-LK framework. Finally, we show impressive results demonstrating that Deep-LK substantially outperforms GOTURN. Additionally, we demonstrate comparable tracking performance to current state of the art deep-trackers whilst being an order of magnitude (i.e. 100 FPS) computationally efficient. version:2
arxiv-1705-07349 | Stability of cross-validation and minmax-optimal number of folds | http://arxiv.org/abs/1705.07349 | id:1705.07349 author:Ning Xu, Jian Hong, Timothy C. G. Fisher category:stat.ML cs.LG math.ST stat.TH  published:2017-05-20 summary:In this paper, we analyze the properties of cross-validation from the perspective of the stability, that is, the probablistic maximal difference between the training error and the test error of the cross-validated model. In both the i.i.d.\ and non-i.i.d.\ cases, we derive the probablistic upper bounds of the one-round and average test error, referred to as the one-round/convoluted Rademacher-bounds, as the measure of cross-validation stability. We show that the convoluted Rademacher-bounds quantify the stability of the out-of-sample performance of the cross-validated model in terms of its training error, the sample sizes, number of folds $K$, the `heaviness' in the tails of the loss distribution (encoded as Orlicz-$\Psi_\nu$ norms) and the Rademacher complexity of the model class $\Lambda$. Using the convoluted Rademacher-bounds, we also define the minmax-optimal number of folds, at which the performance of the cross-validated model on new-coming samples is most stable, for cross-validation. The minmax-optimal number of folds also reveals that, given sample size, stability maximization (or upper bound minimization) may help to quantify optimality in hyper-parameter tuning or other learning tasks with large variation. version:3
arxiv-1705-10422 | Learning End-to-end Multimodal Sensor Policies for Autonomous Navigation | http://arxiv.org/abs/1705.10422 | id:1705.10422 author:Guan-Horng Liu, Avinash Siravuru, Sai Prabhakar, Manuela Veloso, George Kantor category:cs.RO cs.AI cs.LG  published:2017-05-30 summary:Sensor fusion is indispensable to improve accuracy and robustness in an autonomous navigation setting. However, in the space of end-to-end sensorimotor control, this multimodal outlook has received limited attention. In this work, we propose a novel stochastic regularization technique, called Sensor Dropout, to robustify multimodal sensor policy learning outcomes. We also introduce an auxiliary loss on policy network along with the standard DRL loss that help reduce the action variations of the multimodal sensor policy. Through empirical testing we demonstrate that our proposed policy can 1) operate with minimal performance drop in noisy environments, 2) remain functional even in the face of a sensor subset failure. Finally, through the visualization of gradients, we show that the learned policies are conditioned on the same latent input distribution despite having multiple sensory observations spaces - a hallmark of true sensor-fusion. This efficacy of a multimodal policy is shown through simulations on TORCS, a popular open-source racing car game. A demo video can be seen here: https://youtu.be/HC3TcJjXf3Q version:1
arxiv-1705-10420 | Discriminatively Learned Hierarchical Rank Pooling Networks | http://arxiv.org/abs/1705.10420 | id:1705.10420 author:Basura Fernando, Stephen Gould category:cs.CV  published:2017-05-30 summary:In this work, we present novel temporal encoding methods for action and activity classification by extending the unsupervised rank pooling temporal encoding method in two ways. First, we present "discriminative rank pooling" in which the shared weights of our video representation and the parameters of the action classifiers are estimated jointly for a given training dataset of labelled vector sequences using a bilevel optimization formulation of the learning problem. When the frame level features vectors are obtained from a convolutional neural network (CNN), we rank pool the network activations and jointly estimate all parameters of the model, including CNN filters and fully-connected weights, in an end-to-end manner which we coined as "end-to-end trainable rank pooled CNN". Importantly, this model can make use of any existing convolutional neural network architecture (e.g., AlexNet or VGG) without modification or introduction of additional parameters. Then, we extend rank pooling to a high capacity video representation, called "hierarchical rank pooling". Hierarchical rank pooling consists of a network of rank pooling functions, which encode temporal semantics over arbitrary long video clips based on rich frame level features. By stacking non-linear feature functions and temporal sub-sequence encoders one on top of the other, we build a high capacity encoding network of the dynamic behaviour of the video. The resulting video representation is a fixed-length feature vector describing the entire video clip that can be used as input to standard machine learning classifiers. We demonstrate our approach on the task of action and activity recognition. Obtained results are comparable to state-of-the-art methods on three important activity recognition benchmarks with classification performance of 76.7% mAP on Hollywood2, 69.4% on HMDB51, and 93.6% on UCF101. version:1
arxiv-1705-10417 | Solving the Conjugacy Decision Problem via Machine Learning | http://arxiv.org/abs/1705.10417 | id:1705.10417 author:Jonathan Gryak, Robert M. Haralick, Delaram Kahrobaei category:math.GR cs.LG 20-04  68T10  published:2017-05-30 summary:Machine learning and pattern recognition techniques have been successfully applied to algorithmic problems in free groups. In this paper, we seek to extend these techniques to finitely presented non-free groups, with a particular emphasis on polycyclic and metabelian groups that are of interest to non-commutative cryptography. As a prototypical example, we utilize supervised learning methods to construct classifiers that can solve the conjugacy decision problem, i.e., determine whether or not a pair of elements from a specified group are conjugate. The accuracies of classifiers created using decision trees, random forests, and N-tuple neural network models are evaluated for several non-free groups. The very high accuracy of these classifiers suggests an underlying mathematical relationship with respect to conjugacy in the tested groups. version:1
arxiv-1705-10415 | On the "Calligraphy" of Books | http://arxiv.org/abs/1705.10415 | id:1705.10415 author:Vanessa Q. Marinho, Henrique F. de Arruda, Thales S. Lima, Luciano F. Costa, Diego R. Amancio category:cs.CL  published:2017-05-29 summary:Authorship attribution is a natural language processing task that has been widely studied, often by considering small order statistics. In this paper, we explore a complex network approach to assign the authorship of texts based on their mesoscopic representation, in an attempt to capture the flow of the narrative. Indeed, as reported in this work, such an approach allowed the identification of the dominant narrative structure of the studied authors. This has been achieved due to the ability of the mesoscopic approach to take into account relationships between different, not necessarily adjacent, parts of the text, which is able to capture the story flow. The potential of the proposed approach has been illustrated through principal component analysis, a comparison with the chance baseline method, and network visualization. Such visualizations reveal individual characteristics of the authors, which can be understood as a kind of calligraphy. version:1
arxiv-1705-10413 | Learning to Generate Chairs with Generative Adversarial Nets | http://arxiv.org/abs/1705.10413 | id:1705.10413 author:Evgeny Zamyatin, Andrey Filchenkov category:cs.CV  published:2017-05-29 summary:Generative adversarial networks (GANs) has gained tremendous popularity lately due to an ability to reinforce quality of its predictive model with generated objects and the quality of the generative model with and supervised feedback. GANs allow to synthesize images with a high degree of realism. However, the learning process of such models is a very complicated optimization problem and certain limitation for such models were found. It affects the choice of certain layers and nonlinearities when designing architectures. In particular, it does not allow to train convolutional GAN models with fully-connected hidden layers. In our work, we propose a modification of the previously described set of rules, as well as new approaches to designing architectures that will allow us to train more powerful GAN models. We show the effectiveness of our methods on the problem of synthesizing projections of 3D objects with the possibility of interpolation by class and view point. version:1
arxiv-1705-10412 | Gradient Descent Can Take Exponential Time to Escape Saddle Points | http://arxiv.org/abs/1705.10412 | id:1705.10412 author:Simon S. Du, Chi Jin, Jason D. Lee, Michael I. Jordan, Barnabas Poczos, Aarti Singh category:math.OC cs.LG stat.ML  published:2017-05-29 summary:Although gradient descent (GD) almost always escapes saddle points asymptotically [Lee et al., 2016], this paper shows that even with fairly natural random initialization schemes and non-pathological functions, GD can be significantly slowed down by saddle points, taking exponential time to escape. On the other hand, gradient descent with perturbations [Ge et al., 2015, Jin et al., 2017] is not slowed down by saddle points - it can find an approximate local minimizer in polynomial time. This result implies that GD is inherently slower than perturbed GD, and justifies the importance of adding perturbations for efficient non-convex optimization. While our focus is theoretical, we also present experiments that illustrate our theoretical findings. version:1
arxiv-1705-10784 | PCM-TV-TFV: A Novel Two Stage Framework for Image Reconstruction from Fourier Data | http://arxiv.org/abs/1705.10784 | id:1705.10784 author:Weihong Guo, Guohui Song, Yue Zhang category:cs.CV  published:2017-05-29 summary:We propose in this paper a novel two-stage Projection Correction Modeling (PCM) framework for image reconstruction from (non-uniform) Fourier measurements. PCM consists of a projection stage (P-stage) motivated by the multi-scale Galerkin method and a correction stage (C-stage) with an edge guided regularity fusing together the advantages of total variation (TV) and total fractional variation (TFV). The P-stage allows for continuous modeling of the underlying image of interest. The given measurements are projected onto a space in which the image is well represented. We then enhance the reconstruction result at the C-stage that minimizes an energy functional consisting of a fidelity in the transformed domain and a novel edge guided regularity. We further develop efficient proximal algorithms to solve the corresponding optimization problem. Various numerical results in both 1D signals and 2D images have also been presented to demonstrate the superior performance of the proposed two-stage method to other classical one-stage methods. version:1
arxiv-1705-10407 | Solving Almost all Systems of Random Quadratic Equations | http://arxiv.org/abs/1705.10407 | id:1705.10407 author:Gang Wang, Georgios B. Giannakis, Yousef Saad, Jie Chen category:math.OC cs.IT math.IT stat.ML  published:2017-05-29 summary:This paper deals with finding an $n$-dimensional solution $x$ to a system of quadratic equations of the form $y_i= \langle{a}_i,x\rangle ^2$ for $1\le i \le m$, which is also known as phase retrieval and is NP-hard in general. We put forth a novel procedure for minimizing the amplitude-based least-squares empirical loss, that starts with a weighted maximal correlation initialization obtainable with a few power or Lanczos iterations, followed by successive refinements based upon a sequence of iteratively reweighted (generalized) gradient iterations. The two (both the initialization and gradient flow) stages distinguish themselves from prior contributions by the inclusion of a fresh (re)weighting regularization technique. The overall algorithm is conceptually simple, numerically scalable, and easy-to-implement. For certain random measurement models, the novel procedure is shown capable of finding the true solution $x$ in time proportional to reading the data $\{(a_i;y_i)\}_{1\le i \le m}$. This holds with high probability and without extra assumption on the signal $x$ to be recovered, provided that the number $m$ of equations is some constant $c>0$ times the number $n$ of unknowns in the signal vector, namely, $m>cn$. Empirically, the upshots of this contribution are: i) (almost) $100\%$ perfect signal recovery in the high-dimensional (say e.g., $n\ge 2,000$) regime given only an information-theoretic limit number of noiseless equations, namely, $m=2n-1$ in the real-valued Gaussian case; and, ii) (nearly) optimal statistical accuracy in the presence of additive noise of bounded support. Finally, substantial numerical tests using both synthetic data and real images corroborate markedly improved signal recovery performance and computational efficiency of our novel procedure relative to state-of-the-art approaches. version:1
arxiv-1705-10405 | Distributed SAGA: Maintaining linear convergence rate with limited communication | http://arxiv.org/abs/1705.10405 | id:1705.10405 author:Clément Calauzènes, Nicolas Le Roux category:math.OC cs.LG  published:2017-05-29 summary:In recent years, variance-reducing stochastic methods have shown great practical performance, exhibiting linear convergence rate when other stochastic methods offered a sub-linear rate. However, as datasets grow ever bigger and clusters become widespread, the need for fast distribution methods is pressing. We propose here a distribution scheme for SAGA which maintains a linear convergence rate, even when communication between nodes is limited. version:1
arxiv-1705-10388 | Model Selection in Bayesian Neural Networks via Horseshoe Priors | http://arxiv.org/abs/1705.10388 | id:1705.10388 author:Soumya Ghosh, Finale Doshi-Velez category:stat.ML  published:2017-05-29 summary:Bayesian Neural Networks (BNNs) have recently received increasing attention for their ability to provide well-calibrated posterior uncertainties. However, model selection---even choosing the number of nodes---remains an open question. In this work, we apply a horseshoe prior over node pre-activations of a Bayesian neural network, which effectively turns off nodes that do not help explain the data. We demonstrate that our prior prevents the BNN from under-fitting even when the number of nodes required is grossly over-estimated. Moreover, this model selection over the number of nodes doesn't come at the expense of predictive or computational performance; in fact, we learn smaller networks with comparable predictive performance to current approaches. version:1
arxiv-1705-10385 | Collaborative Deep Learning for Speech Enhancement: A Run-Time Model Selection Method Using Autoencoders | http://arxiv.org/abs/1705.10385 | id:1705.10385 author:Minje Kim category:cs.SD cs.LG  published:2017-05-29 summary:We show that a Modular Neural Network (MNN) can combine various speech enhancement modules, each of which is a Deep Neural Network (DNN) specialized on a particular enhancement job. Differently from an ordinary ensemble technique that averages variations in models, the propose MNN selects the best module for the unseen test signal to produce a greedy ensemble. We see this as Collaborative Deep Learning (CDL), because it can reuse various already-trained DNN models without any further refining. In the proposed MNN selecting the best module during run time is challenging. To this end, we employ a speech AutoEncoder (AE) as an arbitrator, whose input and output are trained to be as similar as possible if its input is clean speech. Therefore, the AE can gauge the quality of the module-specific denoised result by seeing its AE reconstruction error, e.g. low error means that the module output is similar to clean speech. We propose an MNN structure with various modules that are specialized on dealing with a specific noise type, gender, and input Signal-to-Noise Ratio (SNR) value, and empirically prove that it almost always works better than an arbitrarily chosen DNN module and sometimes as good as an oracle result. version:1
arxiv-1705-10378 | Fair Inference On Outcomes | http://arxiv.org/abs/1705.10378 | id:1705.10378 author:Razieh Nabi, Ilya Shpitser category:stat.ML  published:2017-05-29 summary:Many data analysis tasks, such as solving prediction problems or inferring cause effect relationships, can be framed as statistical inference on models with outcome variables. This type of inference has been very successful in a variety of applications, including image and video analysis, speech recognition, machine translation, autonomous vehicle control, game playing, and validating hypotheses in the empirical sciences. As statistical and machine learning models become an increasingly ubiquitous part of our lives, policymakers, regulators, and advocates have expressed fears about the harmful impact of deployment of such models that encode harmful and discriminatory biases of their creators. A growing community is now addressing issues of fairness and transparency in data analysis in part by defining, analyzing, and mitigating harmful effects of algorithmic bias from a variety of perspectives and frameworks [3, 4, 6, 7, 8, 18]. In this paper, we consider the problem of fair statistical inference involving outcome variables. Examples include classification and regression problems, and estimating treatment effects in randomized trials or observational data. The issue of fairness arises in such problems where some covariates or treatments are "sensitive", in the sense of having potential of creating discrimination. In this paper, we argue that the presence of discrimination in our setting can be formalized in a sensible way as the presence of an effect of a sensitive covariate on the outcome along certain causal pathways, a view which generalizes [16]. We discuss a number of complications that arise in classical statistical inference due to this view, and suggest workarounds, based on recent work in causal and semi-parametric inference. version:1
arxiv-1705-10369 | Emergent Language in a Multi-Modal, Multi-Step Referential Game | http://arxiv.org/abs/1705.10369 | id:1705.10369 author:Katrina Evtimova, Andrew Drozdov, Douwe Kiela, Kyunghyun Cho category:cs.LG cs.CL cs.CV cs.IT cs.MA math.IT  published:2017-05-29 summary:Inspired by previous work on emergent language in referential games, we propose a novel multi-modal, multi-step referential game, where the sender and receiver have access to distinct modalities of an object, and their information exchange is bidirectional and of arbitrary duration. The multi-modal multi-step setting allows agents to develop an internal language significantly closer to natural language, in that they share a single set of messages, and that the length of the conversation may vary according to the difficulty of the task. We examine these properties empirically using a dataset consisting of images and textual descriptions of mammals, where the agents are tasked with identifying the correct object. Our experiments indicate that a robust and efficient communication protocol emerges, where gradual information exchange informs better predictions and higher communication bandwidth improves generalization. version:1
arxiv-1705-10368 | DNN-based uncertainty estimation for weighted DNN-HMM ASR | http://arxiv.org/abs/1705.10368 | id:1705.10368 author:José Novoa, Josué Fredes, Néstor Becerra Yoma category:cs.SD cs.NE  published:2017-05-29 summary:In this paper, the uncertainty is defined as the mean square error between a given enhanced noisy observation vector and the corresponding clean one. Then, a DNN is trained by using enhanced noisy observation vectors as input and the uncertainty as output with a training database. In testing, the DNN receives an enhanced noisy observation vector and delivers the estimated uncertainty. This uncertainty in employed in combination with a weighted DNN-HMM based speech recognition system and compared with an existing estimation of the noise cancelling uncertainty variance based on an additive noise model. Experiments were carried out with Aurora-4 task. Results with clean, multi-noise and multi-condition training are presented. version:1
arxiv-1706-00074 | Free energy-based reinforcement learning using a quantum processor | http://arxiv.org/abs/1706.00074 | id:1706.00074 author:Anna Levit, Daniel Crawford, Navid Ghadermarzy, Jaspreet S. Oberoi, Ehsan Zahedinejad, Pooya Ronagh category:cs.LG cs.AI cs.NE math.OC quant-ph  published:2017-05-29 summary:Recent theoretical and experimental results suggest the possibility of using current and near-future quantum hardware in challenging sampling tasks. In this paper, we introduce free energy-based reinforcement learning (FERL) as an application of quantum hardware. We propose a method for processing a quantum annealer's measured qubit spin configurations in approximating the free energy of a quantum Boltzmann machine (QBM). We then apply this method to perform reinforcement learning on the grid-world problem using the D-Wave 2000Q quantum annealer. The experimental results show that our technique is a promising method for harnessing the power of quantum sampling in reinforcement learning tasks. version:1
arxiv-1705-10359 | Neural Embeddings of Graphs in Hyperbolic Space | http://arxiv.org/abs/1705.10359 | id:1705.10359 author:Benjamin Paul Chamberlain, James Clough, Marc Peter Deisenroth category:stat.ML cs.LG  published:2017-05-29 summary:Neural embeddings have been used with great success in Natural Language Processing (NLP). They provide compact representations that encapsulate word similarity and attain state-of-the-art performance in a range of linguistic tasks. The success of neural embeddings has prompted significant amounts of research into applications in domains other than language. One such domain is graph-structured data, where embeddings of vertices can be learned that encapsulate vertex similarity and improve performance on tasks including edge prediction and vertex labelling. For both NLP and graph based tasks, embeddings have been learned in high-dimensional Euclidean spaces. However, recent work has shown that the appropriate isometric space for embedding complex networks is not the flat Euclidean space, but negatively curved, hyperbolic space. We present a new concept that exploits these recent insights and propose learning neural embeddings of graphs in hyperbolic space. We provide experimental evidence that embedding graphs in their natural geometry significantly improves performance on downstream tasks for several real-world public datasets. version:1
arxiv-1705-10342 | Deep Learning for Ontology Reasoning | http://arxiv.org/abs/1705.10342 | id:1705.10342 author:Patrick Hohenecker, Thomas Lukasiewicz category:cs.AI cs.LG  published:2017-05-29 summary:In this work, we present a novel approach to ontology reasoning that is based on deep learning rather than logic-based formal reasoning. To this end, we introduce a new model for statistical relational learning that is built upon deep recursive neural networks, and give experimental evidence that it can easily compete with, or even outperform, existing logic-based reasoners on the task of ontology reasoning. More precisely, we compared our implemented system with one of the best logic-based ontology reasoners at present, RDFox, on a number of large standard benchmark datasets, and found that our system attained high reasoning quality, while being up to two orders of magnitude faster. version:1
arxiv-1705-10306 | Auto-Encoding Sequential Monte Carlo | http://arxiv.org/abs/1705.10306 | id:1705.10306 author:Tuan Anh Le, Maximilian Igl, Tom Jin, Tom Rainforth, Frank Wood category:stat.ML  published:2017-05-29 summary:We introduce AESMC: a method for using deep neural networks for simultaneous model learning and inference amortization in a broad family of structured probabilistic models. Starting with an unlabeled dataset and a partially specified underlying generative model, AESMC refines the generative model and learns efficient proposal distributions for SMC for performing inference in this model. Our approach relies on 1) efficiency of SMC in performing inference in structured probabilistic models and 2) flexibility of deep neural networks to model complex conditional probability distributions. We demonstrate that our approach provides a fast, accurate, easy-to-implement, and scalable means for carrying out parameter estimation in high-dimensional statistical models as well as simultaneous model learning and proposal amortization in neural network based models. version:1
arxiv-1705-10301 | Contextual Explanation Networks | http://arxiv.org/abs/1705.10301 | id:1705.10301 author:Maruan Al-Shedivat, Avinava Dubey, Eric P. Xing category:cs.LG cs.AI stat.ML  published:2017-05-29 summary:We introduce contextual explanation networks (CENs)---a class of models that learn to predict by generating and leveraging intermediate explanations. CENs combine deep networks with context-specific probabilistic models and construct explanations in the form of locally-correct hypotheses. Contrary to the existing post-hoc model-explanation tools, CENs learn to predict and to explain jointly. Our approach offers two major advantages: (i) for each prediction, valid instance-specific explanations are generated with no computational overhead and (ii) prediction via explanation acts as a regularization and boosts performance in low-resource settings. We prove that local approximations to the decision boundary of our networks are consistent with the generated explanations. Our results on image and text classification and survival analysis tasks demonstrate that CENs can easily match or outperform the state-of-the-art while offering additional insights behind each prediction, valuable for decision support. version:1
arxiv-1705-08921 | Consistent Kernel Density Estimation with Non-Vanishing Bandwidth | http://arxiv.org/abs/1705.08921 | id:1705.08921 author:Efrén Cruz Cortés, Clayton Scott category:stat.ML cs.LG  published:2017-05-24 summary:Consistency of the kernel density estimator requires that the kernel bandwidth tends to zero as the sample size grows. In this paper we investigate the question of whether consistency is possible when the bandwidth is fixed, if we consider a more general class of weighted KDEs. To answer this question in the affirmative, we introduce the fixed-bandwidth KDE (fbKDE), obtained by solving a quadratic program, and prove that it consistently estimates any continuous square-integrable density. We also establish rates of convergence for the fbKDE with radial kernels and the box kernel under appropriate smoothness assumptions. Furthermore, in an experimental study we demonstrate that the fbKDE compares favorably to the standard KDE and the previously proposed variable bandwidth KDE. version:2
arxiv-1705-10284 | Feature Incay for Representation Regularization | http://arxiv.org/abs/1705.10284 | id:1705.10284 author:Yuhui Yuan, Kuiyuan Yang, Chao Zhang category:cs.CV  published:2017-05-29 summary:Softmax loss is widely used in deep neural networks for multi-class classification, where each class is represented by a weight vector, a sample is represented as a feature vector, and the feature vector has the largest projection on the weight vector of the correct category when the model correctly classifies a sample. To ensure generalization, weight decay that shrinks the weight norm is often used as regularizer. Different from traditional learning algorithms where features are fixed and only weights are tunable, features are also tunable as representation learning in deep learning. Thus, we propose feature incay to also regularize representation learning, which favors feature vectors with large norm when the samples can be correctly classified. With the feature incay, feature vectors are further pushed away from the origin along the direction of their corresponding weight vectors, which achieves better inter-class separability. In addition, the proposed feature incay encourages intra-class compactness along the directions of weight vectors by increasing the small feature norm faster than the large ones. Empirical results on MNIST, CIFAR10 and CIFAR100 demonstrate feature incay can improve the generalization ability. version:1
arxiv-1705-10279 | Towards Visual Ego-motion Learning in Robots | http://arxiv.org/abs/1705.10279 | id:1705.10279 author:Sudeep Pillai, John J. Leonard category:cs.RO cs.AI cs.CV  published:2017-05-29 summary:Many model-based Visual Odometry (VO) algorithms have been proposed in the past decade, often restricted to the type of camera optics, or the underlying motion manifold observed. We envision robots to be able to learn and perform these tasks, in a minimally supervised setting, as they gain more experience. To this end, we propose a fully trainable solution to visual ego-motion estimation for varied camera optics. We propose a visual ego-motion learning architecture that maps observed optical flow vectors to an ego-motion density estimate via a Mixture Density Network (MDN). By modeling the architecture as a Conditional Variational Autoencoder (C-VAE), our model is able to provide introspective reasoning and prediction for ego-motion induced scene-flow. Additionally, our proposed model is especially amenable to bootstrapped ego-motion learning in robots where the supervision in ego-motion estimation for a particular camera sensor can be obtained from standard navigation-based sensor fusion strategies (GPS/INS and wheel-odometry fusion). Through experiments, we show the utility of our proposed approach in enabling the concept of self-supervised learning for visual ego-motion estimation in autonomous robots. version:1
arxiv-1705-10272 | Who's to say what's funny? A computer using Language Models and Deep Learning, That's Who! | http://arxiv.org/abs/1705.10272 | id:1705.10272 author:Xinru Yan, Ted Pedersen category:cs.CL  published:2017-05-29 summary:Humor is a defining characteristic of human beings. Our goal is to develop methods that automatically detect humorous statements and rank them on a continuous scale. In this paper we report on results using a Language Model approach, and outline our plans for using methods from Deep Learning. version:1
arxiv-1705-10586 | Character-Based Text Classification using Top Down Semantic Model for Sentence Representation | http://arxiv.org/abs/1705.10586 | id:1705.10586 author:Zhenzhou Wu, Xin Zheng, Daniel Dahlmeier category:cs.CL cs.LG  published:2017-05-29 summary:Despite the success of deep learning on many fronts especially image and speech, its application in text classification often is still not as good as a simple linear SVM on n-gram TF-IDF representation especially for smaller datasets. Deep learning tends to emphasize on sentence level semantics when learning a representation with models like recurrent neural network or recursive neural network, however from the success of TF-IDF representation, it seems a bag-of-words type of representation has its strength. Taking advantage of both representions, we present a model known as TDSM (Top Down Semantic Model) for extracting a sentence representation that considers both the word-level semantics by linearly combining the words with attention weights and the sentence-level semantics with BiLSTM and use it on text classification. We apply the model on characters and our results show that our model is better than all the other character-based and word-based convolutional neural network models by \cite{zhang15} across seven different datasets with only 1\% of their parameters. We also demonstrate that this model beats traditional linear models on TF-IDF vectors on small and polished datasets like news article in which typically deep learning models surrender. version:1
arxiv-1705-10257 | Boltzmann Exploration Done Right | http://arxiv.org/abs/1705.10257 | id:1705.10257 author:Nicolò Cesa-Bianchi, Claudio Gentile, Gábor Lugosi, Gergely Neu category:cs.LG stat.ML  published:2017-05-29 summary:Boltzmann exploration is a classic strategy for sequential decision-making under uncertainty, and is one of the most standard tools in Reinforcement Learning (RL). Despite its widespread use, there is virtually no theoretical understanding about the limitations or the actual benefits of this exploration scheme. Does it drive exploration in a meaningful way? Is it prone to misidentifying the optimal actions or spending too much time exploring the suboptimal ones? What is the right tuning for the learning rate? In this paper, we address several of these questions in the classic setup of stochastic multi-armed bandits. One of our main results is showing that the Boltzmann exploration strategy with any monotone learning-rate sequence will induce suboptimal behavior. As a remedy, we offer a simple non-monotone schedule that guarantees near-optimal performance, albeit only when given prior access to key problem parameters that are typically not available in practical situations (like the time horizon $T$ and the suboptimality gap $\Delta$). More importantly, we propose a novel variant that uses different learning rates for different arms, and achieves a distribution-dependent regret bound of order $\frac{K\log^2 T}{\Delta}$ and a distribution-independent bound of order $\sqrt{KT}\log K$ without requiring such prior knowledge. To demonstrate the flexibility of our technique, we also propose a variant that guarantees the same performance bounds even if the rewards are heavy-tailed. version:1
arxiv-1705-10246 | Fast Single-Class Classification and the Principle of Logit Separation | http://arxiv.org/abs/1705.10246 | id:1705.10246 author:Gil Keren, Sivan Sabato, Björn Schuller category:stat.ML cs.LG  published:2017-05-29 summary:We consider neural network training, in applications in which there are many possible classes, but at test time the task is to identify whether the example belongs to one specific class, e.g., when searching for photos of a specific person. We focus on reducing the computational burden at test-time in such applications. We define the Single Logit Classification (SLC) task: training the network so that at test time, it would be possible to accurately identify if the example belongs to a given class, based only on the output logit of the trained model for this class. We propose a natural principle, the Principle of Logit Separation (PoLS), as a guideline for choosing and designing losses suitable for the SLC. We study previously suggested losses and their alignment with the PoLS. We further derive new batch versions of known losses, and show that unlike the standard versions, these new versions satisfy the PoLS. Our experiments show that the losses aligned with the PoLS overwhelmingly outperform the other losses on the SLC task. Tensorflow code for optimizing the new batch losses is publicly available in https://github.com/cruvadom/Logit_Separation. version:1
arxiv-1705-10245 | Deep Learning for Patient-Specific Kidney Graft Survival Analysis | http://arxiv.org/abs/1705.10245 | id:1705.10245 author:Margaux Luck, Tristan Sylvain, Héloïse Cardinal, Andrea Lodi, Yoshua Bengio category:cs.LG stat.ML  published:2017-05-29 summary:An accurate model of patient-specific kidney graft survival distributions can help to improve shared-decision making in the treatment and care of patients. In this paper, we propose a deep learning method that directly models the survival function instead of estimating the hazard function to predict survival times for graft patients based on the principle of multi-task learning. By learning to jointly predict the time of the event, and its rank in the cox partial log likelihood framework, our deep learning approach outperforms, in terms of survival time prediction quality and concordance index, other common methods for survival analysis, including the Cox Proportional Hazards model and a network trained on the cox partial log-likelihood. version:1
arxiv-1705-10229 | Latent Intention Dialogue Models | http://arxiv.org/abs/1705.10229 | id:1705.10229 author:Tsung-Hsien Wen, Yishu Miao, Phil Blunsom, Steve Young category:cs.CL cs.LG cs.NE stat.ML  published:2017-05-29 summary:Developing a dialogue agent that is capable of making autonomous decisions and communicating by natural language is one of the long-term goals of machine learning research. Traditional approaches either rely on hand-crafting a small state-action set for applying reinforcement learning that is not scalable or constructing deterministic models for learning dialogue sentences that fail to capture natural conversational variability. In this paper, we propose a Latent Intention Dialogue Model (LIDM) that employs a discrete latent variable to learn underlying dialogue intentions in the framework of neural variational inference. In a goal-oriented dialogue scenario, these latent intentions can be interpreted as actions guiding the generation of machine responses, which can be further refined autonomously by reinforcement learning. The experimental evaluation of LIDM shows that the model out-performs published benchmarks for both corpus-based and human evaluation, demonstrating the effectiveness of discrete latent variable models for learning goal-oriented dialogues. version:1
arxiv-1705-10225 | Bayesian stochastic blockmodeling | http://arxiv.org/abs/1705.10225 | id:1705.10225 author:Tiago P. Peixoto category:stat.ML cond-mat.stat-mech physics.data-an  published:2017-05-29 summary:This chapter provides a self-contained introduction to the use of Bayesian inference to extract large-scale modular structures from network data, based on the stochastic block model (SBM), as well as its degree-corrected and overlapping generalizations. We focus on nonparametric formulations that allow their inference in a manner that prevents overfitting, and enables model selection. We discuss aspects on the choice of priors, in particular how to avoid underfitting via increased Bayesian hierarchies, and we contrast the task of sampling network partitions from the posterior distribution with finding the single point estimate that maximizes it, while describing efficient algorithms to perform either one. We also show how inferring the SBM can be used to predict missing and spurious links, and shed light on the fundamental limitations of the detectability of modular structures in networks. version:1
arxiv-1705-10591 | Optimizing Memory Efficiency for Convolution Kernels on Kepler GPUs | http://arxiv.org/abs/1705.10591 | id:1705.10591 author:Xiaoming Chen, Jianxu Chen, Danny Z. Chen, Xiaobo Sharon Hu category:cs.DC cs.LG  published:2017-05-29 summary:Convolution is a fundamental operation in many applications, such as computer vision, natural language processing, image processing, etc. Recent successes of convolutional neural networks in various deep learning applications put even higher demand on fast convolution. The high computation throughput and memory bandwidth of graphics processing units (GPUs) make GPUs a natural choice for accelerating convolution operations. However, maximally exploiting the available memory bandwidth of GPUs for convolution is a challenging task. This paper introduces a general model to address the mismatch between the memory bank width of GPUs and computation data width of threads. Based on this model, we develop two convolution kernels, one for the general case and the other for a special case with one input channel. By carefully optimizing memory access patterns and computation patterns, we design a communication-optimized kernel for the special case and a communication-reduced kernel for the general case. Experimental data based on implementations on Kepler GPUs show that our kernels achieve 5.16X and 35.5% average performance improvement over the latest cuDNN library, for the special case and the general case, respectively. version:1
arxiv-1705-10209 | On Multilingual Training of Neural Dependency Parsers | http://arxiv.org/abs/1705.10209 | id:1705.10209 author:Michał Zapotoczny, Paweł Rychlikowski, Jan Chorowski category:cs.CL cs.LG cs.NE  published:2017-05-29 summary:We show that a recently proposed neural dependency parser can be improved by joint training on multiple languages from the same family. The parser is implemented as a deep neural network whose only input is orthographic representations of words. In order to successfully parse, the network has to discover how linguistically relevant concepts can be inferred from word spellings. We analyze the representations of characters and words that are learned by the network to establish which properties of languages were accounted for. In particular we show that the parser has approximately learned to associate Latin characters with their Cyrillic counterparts and that it can group Polish and Russian words that have a similar grammatical function. Finally, we evaluate the parser on selected languages from the Universal Dependencies dataset and show that it is competitive with other recently proposed state-of-the art methods, while having a simple structure. version:1
arxiv-1705-10182 | Fast learning rate of deep learning via a kernel perspective | http://arxiv.org/abs/1705.10182 | id:1705.10182 author:Taiji Suzuki category:math.ST cs.LG stat.ML stat.TH  published:2017-05-29 summary:We develop a new theoretical framework to analyze the generalization error of deep learning, and derive a new fast learning rate for two representative algorithms: empirical risk minimization and Bayesian deep learning. The series of theoretical analyses of deep learning has revealed its high expressive power and universal approximation capability. Although these analyses are highly nonparametric, existing generalization error analyses have been developed mainly in a fixed dimensional parametric model. To compensate this gap, we develop an infinite dimensional model that is based on an integral form as performed in the analysis of the universal approximation capability. This allows us to define a reproducing kernel Hilbert space corresponding to each layer. Our point of view is to deal with the ordinary finite dimensional deep neural network as a finite approximation of the infinite dimensional one. The approximation error is evaluated by the degree of freedom of the reproducing kernel Hilbert space in each layer. To estimate a good finite dimensional model, we consider both of empirical risk minimization and Bayesian deep learning. We derive its generalization error bound and it is shown that there appears bias-variance trade-off in terms of the number of parameters of the finite dimensional approximation. We show that the optimal width of the internal layers can be determined through the degree of freedom and the convergence rate can be faster than $O(1/\sqrt{n})$ rate which has been shown in the existing studies. version:1
arxiv-1705-08111 | A Multi-Armed Bandit to Smartly Select a Training Set from Big Medical Data | http://arxiv.org/abs/1705.08111 | id:1705.08111 author:Benjamín Gutiérrez, Loïc Peter, Tassilo Klein, Christian Wachinger category:cs.CV  published:2017-05-23 summary:With the availability of big medical image data, the selection of an adequate training set is becoming more important to address the heterogeneity of different datasets. Simply including all the data does not only incur high processing costs but can even harm the prediction. We formulate the smart and efficient selection of a training dataset from big medical image data as a multi-armed bandit problem, solved by Thompson sampling. Our method assumes that image features are not available at the time of the selection of the samples, and therefore relies only on meta information associated with the images. Our strategy simultaneously exploits data sources with high chances of yielding useful samples and explores new data regions. For our evaluation, we focus on the application of estimating the age from a brain MRI. Our results on 7,250 subjects from 10 datasets show that our approach leads to higher accuracy while only requiring a fraction of the training data. version:2
arxiv-1705-10152 | Tangent Cones to TT Varieties | http://arxiv.org/abs/1705.10152 | id:1705.10152 author:Benjamin Kutschan category:math.OC cs.LG math.AG math.NA 15A69  65K10  62Fxx  published:2017-05-29 summary:As already done for the matrix case for example in [Joe Harris, Algebraic Geometry - A first course, p.256] we give a parametrization of the Bouligand tangent cone of the variety of tensors of bounded TT rank. We discuss how the proof generalizes to any binary hierarchical format. The parametrization can be rewritten as an orthogonal sum of TT tensors. Its retraction onto the variety is particularly easy to compose. We also give an implicit description of the tangent cone as the solution of a system of polynomial equations. version:1
arxiv-1705-05615 | Learning Edge Representations via Low-Rank Asymmetric Projections | http://arxiv.org/abs/1705.05615 | id:1705.05615 author:Sami Abu-El-Haija, Bryan Perozzi, Rami Al-Rfou category:cs.LG cs.SI stat.ML  published:2017-05-16 summary:We propose a method for learning continuous-space vector representation of graphs, which preserves directed edge information. Unlike previous works that utilize random walks to learn structure-preserving graph embeddings, we (1) explicitly model an edge as a function of node embeddings that we jointly learn with the node embeddings, and we (2) propose a novel objective which we call \emph{graph likelihood}, defined in terms of the random walk statistics. Individually, both of these contributions improve the learned representations, especially when there are memory constraints on the total size of the embeddings. When combined, our contributions enable us to significantly improve the state-of-the-art by learning more concise representations that better preserve the graph structure. We evaluate our method on a variety of link-prediction task including social networks, collaboration networks, and protein interactions, showing that our proposed method learn representations with error reductions of up to 76% and 55%, respectively, on directed and undirected graphs. In addition, we show that the representations learned by our method more effectively utilize their provided space -- on several datasets, they outperform all baseline methods while using \emph{16 times less} space to represent each node. version:3
arxiv-1704-08803 | Neural Ranking Models with Weak Supervision | http://arxiv.org/abs/1704.08803 | id:1704.08803 author:Mostafa Dehghani, Hamed Zamani, Aliaksei Severyn, Jaap Kamps, W. Bruce Croft category:cs.IR cs.CL cs.LG  published:2017-04-28 summary:Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. The reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet effective ranking models based on feed-forward neural networks. We study their effectiveness under various learning scenarios (point-wise and pair-wise models) and using different input representations (i.e., from encoding query-document pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection(Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and letting the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our findings also suggest that supervised neural ranking models can greatly benefit from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models. version:2
arxiv-1705-10130 | An Automatic Contextual Analysis and Clustering Classifiers Ensemble approach to Sentiment Analysis | http://arxiv.org/abs/1705.10130 | id:1705.10130 author:Murtadha Talib AL-Sharuee, Fei Liu, Mahardhika Pratama category:cs.CL  published:2017-05-29 summary:Products reviews are one of the major resources to determine the public sentiment. The existing literature on reviews sentiment analysis mainly utilizes supervised paradigm, which needs labeled data to be trained on and suffers from domain-dependency. This article addresses these issues by describes a completely automatic approach for sentiment analysis based on unsupervised ensemble learning. The method consists of two phases. The first phase is contextual analysis, which has five processes, namely (1) data preparation; (2) spelling correction; (3) intensifier handling; (4) negation handling and (5) contrast handling. The second phase comprises the unsupervised learning approach, which is an ensemble of clustering classifiers using a majority voting mechanism with different weight schemes. The base classifier of the ensemble method is a modified k-means algorithm. The base classifier is modified by extracting initial centroids from the feature set via using SentWordNet (SWN). We also introduce new sentiment analysis problems of Australian airlines and home builders which offer potential benchmark problems in the sentiment analysis field. Our experiments on datasets from different domains show that contextual analysis and the ensemble phases improve the clustering performance in term of accuracy, stability and generalization ability. version:1
arxiv-1705-10120 | Pose-Aware Person Recognition | http://arxiv.org/abs/1705.10120 | id:1705.10120 author:Vijay Kumar, Anoop Namboodiri, Manohar Paluri, C V Jawahar category:cs.CV  published:2017-05-29 summary:Person recognition methods that use multiple body regions have shown significant improvements over traditional face-based recognition. One of the primary challenges in full-body person recognition is the extreme variation in pose and view point. In this work, (i) we present an approach that tackles pose variations utilizing multiple models that are trained on specific poses, and combined using pose-aware weights during testing. (ii) For learning a person representation, we propose a network that jointly optimizes a single loss over multiple body regions. (iii) Finally, we introduce new benchmarks to evaluate person recognition in diverse scenarios and show significant improvements over previously proposed approaches on all the benchmarks including the photo album setting of PIPA. version:1
arxiv-1705-10119 | Implicit Variational Inference with Kernel Density Ratio Fitting | http://arxiv.org/abs/1705.10119 | id:1705.10119 author:Jiaxin Shi, Shengyang Sun, Jun Zhu category:stat.ML cs.AI cs.LG cs.NE  published:2017-05-29 summary:Recent progress in variational inference has paid much attention to the flexibility of variational posteriors. Work has been done to use implicit distributions, i.e., distributions without tractable likelihoods as the variational posterior. However, existing methods on implicit posteriors still face challenges of noisy estimation and can hardly scale to high-dimensional latent variable models. In this paper, we present an implicit variational inference approach with kernel density ratio fitting that addresses these challenges. As far as we know, for the first time implicit variational inference is successfully applied to Bayesian neural networks, which shows promising results on both regression and classification tasks. version:1
arxiv-1705-10118 | Beyond Counting: Comparisons of Density Maps for Crowd Analysis Tasks - Counting, Detection, and Tracking | http://arxiv.org/abs/1705.10118 | id:1705.10118 author:Di Kang, Zheng Ma, Antoni B. Chan category:cs.CV  published:2017-05-29 summary:For crowded scenes, the accuracy of object-based computer vision methods declines when the images are low-resolution and objects have severe occlusions. Taking counting methods for example, almost all the recent state-of-the-art counting methods bypass explicit detection and adopt regression-based methods to directly count the objects of interest. Among regression-based methods, density map estimation, where the number of objects inside a subregion is the integral of the density map over that subregion, is especially promising because it preserves spatial information, which makes it useful for both counting and localization (detection and tracking). With the power of deep convolutional neural networks (CNNs) the counting performance has improved steadily. The goal of this paper is to evaluate density maps generated by density estimation methods on a variety of crowd analysis tasks, including counting, detection, and tracking. Most existing CNN methods produce density maps with resolution that is smaller than the original images, due to the downsample strides in the convolution/pooling operations. To produce an original-resolution density map, we also evaluate a classical CNN that uses a sliding window regressor to predict the density for every pixel in the image. We also consider a fully convolutional (FCNN) adaptation, with skip connections from lower convolutional layers to compensate for loss in spatial information during upsampling. In our experiments, we found that the lower-resolution density maps sometimes have better counting performance. In contrast, the original-resolution density maps improved localization tasks, such as detection and tracking, compared to bilinear upsampling the lower-resolution density maps. Finally, we also propose several metrics for measuring the quality of a density map, and relate them to experiment results on counting and localization. version:1
arxiv-1705-10112 | Dynamics of core of language vocabulary | http://arxiv.org/abs/1705.10112 | id:1705.10112 author:Valery D. Solovyev, Vladimir V. Bochkarev, Anna V. Shevlyakova category:cs.CL 91F20 I.2.7; J.5  published:2017-05-29 summary:Studies of the overall structure of vocabulary and its dynamics became possible due to creation of diachronic text corpora, especially Google Books Ngram. This article discusses the question of core change rate and the degree to which the core words cover the texts. Different periods of the last three centuries and six main European languages presented in Google Books Ngram are compared. The main result is high stability of core change rate, which is analogous to stability of the Swadesh list. version:1
arxiv-1705-10102 | Coreset Construction via Randomized Matrix Multiplication | http://arxiv.org/abs/1705.10102 | id:1705.10102 author:Jiasen Yang, Agniva Chowdhury, Petros Drineas category:stat.ML cs.LG  published:2017-05-29 summary:Coresets are small sets of points that approximate the properties of a larger point-set. For example, given a compact set $\mathcal{S} \subseteq \mathbb{R}^d$, a coreset could be defined as a (weighted) subset of $\mathcal{S}$ that approximates the sum of squared distances from $\mathcal{S}$ to every linear subspace of $\mathbb{R}^d$. As such, coresets can be used as a proxy to the full dataset and provide an important technique to speed up algorithms for solving problems including principal component analysis, latent semantic indexing, etc. In this paper, we provide a structural result that connects the construction of such coresets to approximating matrix products. This structural result implies a simple, randomized algorithm that constructs coresets whose sizes are independent of the number and dimensionality of the input points. The expected size of the resulting coresets yields an improvement over the state-of-the-art deterministic approach. Finally, we evaluate the proposed randomized algorithm on synthetic and real data, and demonstrate its effective performance relative to its deterministic counterpart. version:1
arxiv-1705-10087 | Distributed Convolutional Sparse Coding | http://arxiv.org/abs/1705.10087 | id:1705.10087 author:Thomas Moreau, Laurent Oudre, Nicolas Vayatis category:cs.LG stat.ML  published:2017-05-29 summary:We consider the problem of building shift-invariant representations for long signals in the context of distributed processing. We propose an asynchronous algorithm based on coordinate descent called DICOD to efficiently solve the $\ell_1$-minimization problems involved in convolutional sparse coding. This algorithm leverages the weak temporal dependency of the convolution to reduce the interprocess communication to a few local messages. We prove that this algorithm converges to the optimal solution and that it scales with superlinear speedup, up to a certain limit. These properties are illustrated with numerical experiments and our algorithm is compared to the state-of-the-art methods used for convolutional sparse coding. version:1
arxiv-1705-10085 | Temporal anomaly detection: calibrating the surprise | http://arxiv.org/abs/1705.10085 | id:1705.10085 author:Eyal Gutflaish, Aryeh Kontorovich, Sivan Sabato, Ofer Biller, Oded Sofer category:cs.CR cs.LG  published:2017-05-29 summary:We propose a hybrid approach to temporal anomaly detection in user-database access data -- or more generally, any kind of subject-object co-occurrence data. Our methodology allows identifying anomalies based on a single stationary model, instead of requiring a full temporal one, which would be prohibitive in our setting. We learn our low-rank stationary model from the high-dimensional training data, and then fit a regression model for predicting the expected likelihood score of normal access patterns in the future. The disparity between the predicted and the observed likelihood scores is used to assess the "surprise". This approach enables calibration of the anomaly score so that time-varying normal behavior patterns are not considered anomalous. We provide a detailed description of the algorithm, including a convergence analysis, and report encouraging empirical results. One of the datasets we tested is new for the public domain. It consists of two months' worth of database access records from a live system. This dataset will be made publicly available, and is provided in the supplementary material. version:1
arxiv-1705-09558 | Bayesian GAN | http://arxiv.org/abs/1705.09558 | id:1705.09558 author:Yunus Saatchi, Andrew Gordon Wilson category:stat.ML cs.AI cs.CV cs.LG  published:2017-05-26 summary:Generative adversarial networks (GANs) can implicitly learn rich distributions over images, audio, and data which are hard to model with an explicit likelihood. We present a practical Bayesian formulation for unsupervised and semi-supervised learning with GANs. Within this framework, we use stochastic gradient Hamiltonian Monte Carlo to marginalize the weights of the generator and discriminator networks. The resulting approach is straightforward and obtains good performance without any standard interventions such as feature matching, or mini-batch discrimination. By exploring an expressive posterior over the parameters of the generator, the Bayesian GAN avoids mode-collapse, produces interpretable and diverse candidate samples, and provides state-of-the-art quantitative results for semi-supervised learning on benchmarks including SVHN, CelebA, and CIFAR-10, outperforming DCGAN, Wasserstein GANs, and DCGAN ensembles. version:2
arxiv-1705-10060 | On the Power Spectral Density Applied to the Analysis of Old Canvases | http://arxiv.org/abs/1705.10060 | id:1705.10060 author:Francisco J. Simois, Juan J. Murillo-Fuentes category:cs.CV math.SP  published:2017-05-29 summary:A routine task for art historians is painting diagnostics, such as dating or attribution. Signal processing of the X-ray image of a canvas provides useful information about its fabric. However, previous methods may fail when very old and deteriorated artworks or simply canvases of small size are studied. We present a new framework to analyze and further characterize the paintings from their radiographs. First, we start from a general analysis of lattices and provide new unifying results about the theoretical spectra of weaves. Then, we use these results to infer the main structure of the fabric, like the type of weave and the thread densities. We propose a practical estimation of these theoretical results from paintings with the averaged power spectral density (PSD), which provides a more robust tool. Furthermore, we found that the PSD provides a fingerprint that characterizes the whole canvas. We search and discuss some distinctive features we may find in that fingerprint. We apply these results to several masterpieces of the 17th and 18th centuries from the Museo Nacional del Prado to show that this approach yields accurate results in thread counting and is very useful for paintings comparison, even in situations where previous methods fail. version:1
arxiv-1705-01921 | Recurrent Soft Attention Model for Common Object Recognition | http://arxiv.org/abs/1705.01921 | id:1705.01921 author:Liliang Ren category:cs.CV  published:2017-05-04 summary:We propose the Recurrent Soft Attention Model, which integrates the visual attention from the original image to a LSTM memory cell through a down-sample network. The model recurrently transmits visual attention to the memory cells for glimpse mask generation, which is a more natural way for attention integration and exploitation in general object detection and recognition problem. We test our model under the metric of the top-1 accuracy on the CIFAR-10 dataset. The experiment shows that our down-sample network and feedback mechanism plays an effective role among the whole network structure. version:2
arxiv-1705-10051 | Learning Network Structures from Contagion | http://arxiv.org/abs/1705.10051 | id:1705.10051 author:Adisak Supeesun, Jittat Fakcharoenphol category:cs.LG cs.SI  published:2017-05-29 summary:In 2014, Amin, Heidari, and Kearns proved that tree networks can be learned by observing only the infected set of vertices of the contagion process under the independent cascade model, in both the active and passive query models. They also showed empirically that simple extensions of their algorithms work on sparse networks. In this work, we focus on the active model. We prove that a simple modification of Amin et al.'s algorithm works on more general classes of networks, namely (i) networks with large girth and low path growth rate, and (ii) networks with bounded degree. This also provides partial theoretical explanation for Amin et al.'s experiments on sparse networks. version:1
arxiv-1705-10041 | Towards Metamerism via Foveated Style Transfer | http://arxiv.org/abs/1705.10041 | id:1705.10041 author:Arturo Deza, Aditya Jonnalagadda, Miguel Eckstein category:cs.CV cs.GR  published:2017-05-29 summary:Given the recent successes of deep learning applied to style transfer and texture synthesis, we propose a new theoretical framework to construct visual metamers: \textit{a family of perceptually identical, yet physically different images}. We review work both in neuroscience related to metameric stimuli, as well as computer vision research in style transfer. We propose our NeuroFovea metamer model that is based on a mixture of peripheral representations and style transfer forward-pass algorithms for \emph{any} image from the recent work of Adaptive Instance Normalization (Huang~\&~Belongie). Our model is parametrized by a VGG-Net versus a set of joint statistics of complex wavelet coefficients which allows us to encode images in high dimensional space and interpolate between the content and texture information. We empirically show that human observers discriminate our metamers at a similar rate as the metamers of Freeman~\&~Simoncelli (FS) In addition, our NeuroFovea metamer model gives us the benefit of near real-time generation which presents a $\times1000$ speed-up compared to previous work. Critically, psychophysical studies show that both the FS and NeuroFovea metamers are discriminable from the original images highlighting an important limitation of current metamer generation methods. version:1
arxiv-1705-08665 | Bayesian Compression for Deep Learning | http://arxiv.org/abs/1705.08665 | id:1705.08665 author:Christos Louizos, Karen Ullrich, Max Welling category:stat.ML cs.LG  published:2017-05-24 summary:Compression and computational efficiency in deep learning have become a problem of great significance. In this work, we argue that the most principled and effective way to attack this problem is by taking a Bayesian point of view, where through sparsity inducing priors we prune large parts of the network. We introduce two novelties in this paper: 1) we use hierarchical priors to prune nodes instead of individual weights, and 2) we use the posterior uncertainties to determine the optimal fixed point precision to encode the weights. Both factors significantly contribute to achieving the state of the art in terms of compression rates, while still staying competitive with methods designed to optimize for speed or energy efficiency. version:2
arxiv-1705-10034 | Ensemble of Part Detectors for Simultaneous Classification and Localization | http://arxiv.org/abs/1705.10034 | id:1705.10034 author:Xiaopeng Zhang, Hongkai Xiong, Weiyao Lin, Qi Tian category:cs.CV  published:2017-05-29 summary:Part-based representation has been proven to be effective for a variety of visual applications. However, automatic discovery of discriminative parts without object/part-level annotations is challenging. This paper proposes a discriminative mid-level representation paradigm based on the responses of a collection of part detectors, which only requires the image-level labels. Towards this goal, we first develop a detector-based spectral clustering method to mine the representative and discriminative mid-level patterns for detector initialization. The advantage of the proposed pattern mining technology is that the distance metric based on detectors only focuses on discriminative details, and a set of such grouped detectors offer an effective way for consistent pattern mining. Relying on the discovered patterns, we further formulate the detector learning process as a confidence-loss sparse Multiple Instance Learning (cls-MIL) task, which considers the diversity of the positive samples, while avoid drifting away the well localized ones by assigning a confidence value to each positive sample. The responses of the learned detectors can form an effective mid-level image representation for both image classification and object localization. Experiments conducted on benchmark datasets demonstrate the superiority of our method over existing approaches. version:1
arxiv-1705-10033 | Improving the Expected Improvement Algorithm | http://arxiv.org/abs/1705.10033 | id:1705.10033 author:Chao Qin, Diego Klabjan, Daniel Russo category:cs.LG stat.ML  published:2017-05-29 summary:The expected improvement (EI) algorithm is a popular strategy for information collection in optimization under uncertainty. The algorithm is widely known to be too greedy, but nevertheless enjoys wide use due to its simplicity and ability to handle uncertainty and noise in a coherent decision theoretic framework. To provide rigorous insight into EI, we study its properties in a simple setting of Bayesian optimization where the domain consists of a finite grid of points. This is the so-called best-arm identification problem, where the goal is to allocate measurement effort wisely to confidently identify the best arm using a small number of measurements. In this framework, one can show formally that EI is far from optimal. To overcome this shortcoming, we introduce a simple modification of the expected improvement algorithm. Surprisingly, this simple change results in an algorithm that is asymptotically optimal for Gaussian best-arm identification problems, and provably outperforms standard EI by an order of magnitude. version:1
arxiv-1705-10030 | Supervised Complementary Entity Recognition with Augmented Key-value Pairs of Knowledge | http://arxiv.org/abs/1705.10030 | id:1705.10030 author:Hu Xu, Lei Shu, Philip S. Yu category:cs.CL  published:2017-05-29 summary:Extracting opinion targets is an important task in sentiment analysis on product reviews and complementary entities (products) are one important type of opinion targets that may work together with the reviewed product. In this paper, we address the problem of Complementary Entity Recognition (CER) as a supervised sequence labeling with the capability of expanding domain knowledge as key-value pairs from unlabeled reviews, by automatically learning and enhancing knowledge-based features. We use Conditional Random Field (CRF) as the base learner and augment CRF with knowledge-based features (called the Knowledge-based CRF or KCRF for short). We conduct experiments to show that KCRF effectively improves the performance of supervised CER task. version:1
arxiv-1705-10015 | Learning the Sparse and Low Rank PARAFAC Decomposition via the Elastic Net | http://arxiv.org/abs/1705.10015 | id:1705.10015 author:Songting Shi, Xiang Li, Arkadiusz Sitek, Quanzheng Li category:math.NA math.OC stat.ML  published:2017-05-29 summary:In this article, we derive a Bayesian model to learning the sparse and low rank PARAFAC decomposition for the observed tensor with missing values via the elastic net, with property to find the true rank and sparse factor matrix which is robust to the noise. We formulate efficient block coordinate descent algorithm and admax stochastic block coordinate descent algorithm to solve it, which can be used to solve the large scale problem. To choose the appropriate rank and sparsity in PARAFAC decomposition, we will give a solution path by gradually increasing the regularization to increase the sparsity and decrease the rank. When we find the sparse structure of the factor matrix, we can fixed the sparse structure, using a small to regularization to decreasing the recovery error, and one can choose the proper decomposition from the solution path with sufficient sparse factor matrix with low recovery error. We test the power of our algorithm on the simulation data and real data, which show it is powerful. version:1
arxiv-1705-10000 | Robust Online Matrix Factorization for Dynamic Background Subtraction | http://arxiv.org/abs/1705.10000 | id:1705.10000 author:Hongwei Yong, Deyu Meng, Wangmeng Zuo, Lei Zhang category:cs.CV  published:2017-05-28 summary:We propose an effective online background subtraction method, which can be robustly applied to practical videos that have variations in both foreground and background. Different from previous methods which often model the foreground as Gaussian or Laplacian distributions, we model the foreground for each frame with a specific mixture of Gaussians (MoG) distribution, which is updated online frame by frame. Particularly, our MoG model in each frame is regularized by the learned foreground/background knowledge in previous frames. This makes our online MoG model highly robust, stable and adaptive to practical foreground and background variations. The proposed model can be formulated as a concise probabilistic MAP model, which can be readily solved by EM algorithm. We further embed an affine transformation operator into the proposed model, which can be automatically adjusted to fit a wide range of video background transformations and make the method more robust to camera movements. With using the sub-sampling technique, the proposed method can be accelerated to execute more than 250 frames per second on average, meeting the requirement of real-time background subtraction for practical video processing tasks. The superiority of the proposed method is substantiated by extensive experiments implemented on synthetic and real videos, as compared with state-of-the-art online and offline background subtraction methods. version:1
arxiv-1705-09995 | Subject Specific Stream Classification Preprocessing Algorithm for Twitter Data Stream | http://arxiv.org/abs/1705.09995 | id:1705.09995 author:Nisansa de Silva, Danaja Maldeniya, Chamilka Wijeratne category:cs.CL  published:2017-05-28 summary:Micro-blogging service Twitter is a lucrative source for data mining applications on global sentiment. But due to the omnifariousness of the subjects mentioned in each data item; it is inefficient to run a data mining algorithm on the raw data. This paper discusses an algorithm to accurately classify the entire stream in to a given number of mutually exclusive collectively exhaustive streams upon each of which the data mining algorithm can be run separately yielding more relevant results with a high efficiency. version:1
arxiv-1705-09993 | Deep Learning for User Comment Moderation | http://arxiv.org/abs/1705.09993 | id:1705.09993 author:John Pavlopoulos, Prodromos Malakasiotis, Ion Androutsopoulos category:cs.CL cs.LG  published:2017-05-28 summary:Experimenting with a new dataset of 1.6M user comments from a Greek news portal and existing datasets of English Wikipedia comments, we show that an RNN outperforms the previous state of the art in moderation. A deep, classification-specific attention mechanism improves further the overall performance of the RNN. We also compare against a CNN and a word-list baseline, considering both fully automatic and semi-automatic moderation. version:1
arxiv-1705-09992 | LAP: a Linearize and Project Method for Solving Inverse Problems with Coupled Variables | http://arxiv.org/abs/1705.09992 | id:1705.09992 author:James Herring, James Nagy, Lars Ruthotto category:math.NA cs.CV cs.NA math.OC 65F10  65F22  65M32  published:2017-05-28 summary:Many inverse problems involve two or more sets of variables that represent different physical quantities but are tightly coupled with each other. For example, image super-resolution requires joint estimation of image and motion parameters from noisy measurements. Exploiting this structure is key for efficiently solving large-scale problems to avoid, e.g., ill-conditioned optimization problems. In this paper, we present a new method called Linearize And Project (LAP) that offers a flexible framework for solving inverse problems with coupled variables. LAP is most promising for cases when the subproblem corresponding to one of the variables is considerably easier to solve than the other. LAP is based on a Gauss-Newton method, and thus after linearizing the residual, it eliminates one block of variables through projection. Due to the linearization, the block can be chosen freely and can represent quadratic as well as nonlinear variables. Further, LAP supports direct, iterative, and hybrid regularization as well as constraints. Therefore LAP is attractive, e.g., for ill-posed imaging problems. These traits differentiate LAP from common alternatives for this type of problems such as variable projection (VarPro) and block coordinate descent (BCD). Our numerical experiments compare the performance of LAP to BCD and VarPro using four coupled problems with one quadratic and one nonlinear set of variables. version:1
arxiv-1705-09980 | Neural Semantic Parsing by Character-based Translation: Experiments with Abstract Meaning Representations | http://arxiv.org/abs/1705.09980 | id:1705.09980 author:Rik van Noord, Johan Bos category:cs.CL  published:2017-05-28 summary:We evaluate the character-level translation method for neural semantic parsing on a large corpus of sentences annotated with Abstract Meaning Representations (AMRs). Using a seq2seq model, and some trivial preprocessing and postprocessing of AMRs, we obtain a baseline accuracy of 53.1 (F-score on AMR-triples). We examine four different approaches to improve this baseline result: (i) reordering AMR branches to match the word order of the input sentence increases performance to 58.3; (ii) adding part-of-speech tags (automatically produced) to the input shows improvement as well (57.2); (iii) So does the introduction of super characters (conflating frequent sequences of characters to a single character), reaching 57.4; (iv) adding silver-standard training data obtained by an off-the-shelf parser yields the biggest improvement, resulting in an F-score of 64.0. Combining all four techniques leads to an F-score of 69.0, which is state-of-the-art in AMR parsing. This is remarkable because of the relatively simplicity of the approach: the only explicit linguistic knowledge that we use are part-of-speech tags. version:1
arxiv-1705-09975 | A Deep Multi-View Learning Framework for City Event Extraction from Twitter Data Streams | http://arxiv.org/abs/1705.09975 | id:1705.09975 author:Nazli Farajidavar, Sefki Kolozali, Payam Barnaghi category:cs.SI cs.CL  published:2017-05-28 summary:Cities have been a thriving place for citizens over the centuries due to their complex infrastructure. The emergence of the Cyber-Physical-Social Systems (CPSS) and context-aware technologies boost a growing interest in analysing, extracting and eventually understanding city events which subsequently can be utilised to leverage the citizen observations of their cities. In this paper, we investigate the feasibility of using Twitter textual streams for extracting city events. We propose a hierarchical multi-view deep learning approach to contextualise citizen observations of various city systems and services. Our goal has been to build a flexible architecture that can learn representations useful for tasks, thus avoiding excessive task-specific feature engineering. We apply our approach on a real-world dataset consisting of event reports and tweets of over four months from San Francisco Bay Area dataset and additional datasets collected from London. The results of our evaluations show that our proposed solution outperforms the existing models and can be used for extracting city related events with an averaged accuracy of 81% over all classes. To further evaluate the impact of our Twitter event extraction model, we have used two sources of authorised reports through collecting road traffic disruptions data from Transport for London API, and parsing the Time Out London website for sociocultural events. The analysis showed that 49.5% of the Twitter traffic comments are reported approximately five hours prior to the authorities official records. Moreover, we discovered that amongst the scheduled sociocultural event topics; tweets reporting transportation, cultural and social events are 31.75% more likely to influence the distribution of the Twitter comments than sport, weather and crime topics. version:1
arxiv-1705-09966 | Conditional CycleGAN for Attribute Guided Face Image Generation | http://arxiv.org/abs/1705.09966 | id:1705.09966 author:Yongyi Lu, Yu-Wing Tai, Chi-Keung Tang category:cs.CV cs.LG stat.ML  published:2017-05-28 summary:State-of-the-art techniques in Generative Adversarial Networks (GANs) such as cycleGAN is able to learn the mapping of one image domain $X$ to another image domain $Y$ using unpaired image data. We extend the cycleGAN to ${\it Conditional}$ cycleGAN such that the mapping from $X$ to $Y$ is subjected to attribute condition $Z$. Using face image generation as an application example, where $X$ is a low resolution face image, $Y$ is a high resolution face image, and $Z$ is a set of attributes related to facial appearance (e.g. gender, hair color, smile), we present our method to incorporate $Z$ into the network, such that the hallucinated high resolution face image $Y'$ not only satisfies the low resolution constrain inherent in $X$, but also the attribute condition prescribed by $Z$. Using face feature vector extracted from face verification network as $Z$, we demonstrate the efficacy of our approach on identity-preserving face image super-resolution. Our approach is general and applicable to high-quality face image generation where specific facial attributes can be controlled easily in the automatically generated results. version:1
arxiv-1705-09954 | L1-norm Error Function Robustness and Outlier Regularization | http://arxiv.org/abs/1705.09954 | id:1705.09954 author:Chris Ding, Bo Jiang category:cs.CV  published:2017-05-28 summary:In many real-world applications, data come with corruptions, large errors or outliers. One popular approach is to use L1-norm function. However, the robustness of L1-norm function is not well understood so far. In this paper, we present a new outlier regularization framework to understand and analyze the robustness of L1-norm function. There are two main features for the proposed outlier regularization. (1) A key property of outlier regularization is that how far an outlier lies away from its theoretically predicted value does not affect the final regularization and analysis results. (2) Another important feature of outlier regularization is that it has an equivalent continuous representation that closely relates to L1 function. This provides a new way to understand and analyze the robustness of L1 function. We apply our outlier regularization framework to PCA and propose an outlier regularized PCA (ORPCA) model. Comparing to the trace-normbased robust PCA, ORPCA has several benefits: (1) It does not suffer singular value suppression. (2) It can retain small high rank components which help retain fine details of data. (3) ORPCA can be computed more efficiently. version:1
arxiv-1705-09952 | Optimal dynamic treatment allocation | http://arxiv.org/abs/1705.09952 | id:1705.09952 author:Anders Bredahl Kock, Martin Thyrsgaard category:stat.ML  published:2017-05-28 summary:In a treatment problem the individuals to be treated often arrive gradually. Initially, when the first treatments are made, little is known about the effect of the treatments but as more treatments are assigned the policy maker gradually learns about their effects by observing the outcomes. Thus, one faces a tradeoff between exploring the available treatments and exploiting the best treatment, i.e. administering it as often as possible, in order to maximize the cumulative welfare of all the assignments made. Furthermore, a policy maker may not only be interested in the expected effect of the treatment but also its riskiness. Thus, we allow for the welfare function to depend on the first and second moments of the distribution of each of the treatments. We propose a dynamic treatment policy which attains the minimax optimal regret relative to the unknown best treatment in this dynamic setting. We allow for the data to arrive in batches as, say, unemployment programs only start once a month or blood samples are only send to the laboratory for investigation in batches. Furthermore, we show that the minimax optimality does not come at the price of overly aggressive experimentation in the beginning of the treatment period as we provide upper bounds on the expected number of times any suboptimal treatment is assigned. Next, we consider the case where the outcome of a treatment is only observed with delay as it may take time for the treatment to work. Thus, a doctor faces a tradeoff between getting imprecise information quickly by making the measurement soon after the treatment is given or getting precise information later at the expense of less information for the individuals who are treated in the meantime. version:1
arxiv-1705-09944 | Learning Data Manifolds with a Cutting Plane Method | http://arxiv.org/abs/1705.09944 | id:1705.09944 author:SueYeon Chung, Uri Cohen, Haim Sompolinsky, Daniel D. Lee category:cs.LG stat.ML  published:2017-05-28 summary:We consider the problem of classifying data manifolds where each manifold represents invariances that are parameterized by continuous degrees of freedom. Conventional data augmentation methods rely upon sampling large numbers of training examples from these manifolds; instead, we propose an iterative algorithm called M_{CP} based upon a cutting-plane approach that efficiently solves a quadratic semi-infinite programming problem to find the maximum margin solution. We provide a proof of convergence as well as a polynomial bound on the number of iterations required for a desired tolerance in the objective function. The efficiency and performance of M_{CP} are demonstrated in high-dimensional simulations and on image manifolds generated from the ImageNet dataset. Our results indicate that M_{CP} is able to rapidly learn good classifiers and shows superior generalization performance compared with conventional maximum margin methods using data augmentation methods. version:1
arxiv-1705-09046 | Expectation Propagation for t-Exponential Family Using Q-Algebra | http://arxiv.org/abs/1705.09046 | id:1705.09046 author:Futoshi Futami, Issei Sato, Masashi Sugiyama category:stat.ML  published:2017-05-25 summary:Exponential family distributions are highly useful in machine learning since their calculation can be performed efficiently through natural parameters. The exponential family has recently been extended to the t-exponential family, which contains Student-t distributions as family members and thus allows us to handle noisy data well. However, since the t-exponential family is denied by the deformed exponential, we cannot derive an efficient learning algorithm for the t-exponential family such as expectation propagation (EP). In this paper, we borrow the mathematical tools of q-algebra from statistical physics and show that the pseudo additivity of distributions allows us to perform calculation of t-exponential family distributions through natural parameters. We then develop an expectation propagation (EP) algorithm for the t-exponential family, which provides a deterministic approximation to the posterior or predictive distribution with simple moment matching. We finally apply the proposed EP algorithm to the Bayes point machine and Student-t process classication, and demonstrate their performance numerically. version:2
arxiv-1705-09932 | The placement of the head that maximizes predictability. An information theoretic approach | http://arxiv.org/abs/1705.09932 | id:1705.09932 author:Ramon Ferrer-i-Cancho category:cs.CL nlin.AO physics.soc-ph q-bio.NC  published:2017-05-28 summary:The minimization of the length of syntactic dependencies is a well-stablished principle of word order and the basis of a mathematical theory of word order. Here we complete that theory from the perspective of information theory, adding a competing word order principle: the maximization of predictability of a target element. These two principles are in conflict: to maximize the predictability of the head, the head should appear last, which maximizes the costs with respect to dependency length minimization. The implications of such a broad theoretical framework to understand the optimality, diversity and evolution of the six possible orderings of subject, object and verb are reviewed. version:1
arxiv-1705-09922 | Bayesian Unification of Gradient and Bandit-based Learning for Accelerated Global Optimisation | http://arxiv.org/abs/1705.09922 | id:1705.09922 author:Ole-Christoffer Granmo category:cs.AI cs.LG  published:2017-05-28 summary:Bandit based optimisation has a remarkable advantage over gradient based approaches due to their global perspective, which eliminates the danger of getting stuck at local optima. However, for continuous optimisation problems or problems with a large number of actions, bandit based approaches can be hindered by slow learning. Gradient based approaches, on the other hand, navigate quickly in high-dimensional continuous spaces through local optimisation, following the gradient in fine grained steps. Yet, apart from being susceptible to local optima, these schemes are less suited for online learning due to their reliance on extensive trial-and-error before the optimum can be identified. In this paper, we propose a Bayesian approach that unifies the above two paradigms in one single framework, with the aim of combining their advantages. At the heart of our approach we find a stochastic linear approximation of the function to be optimised, where both the gradient and values of the function are explicitly captured. This allows us to learn from both noisy function and gradient observations, and predict these properties across the action space to support optimisation. We further propose an accompanying bandit driven exploration scheme that uses Bayesian credible bounds to trade off exploration against exploitation. Our empirical results demonstrate that by unifying bandit and gradient based learning, one obtains consistently improved performance across a wide spectrum of problem environments. Furthermore, even when gradient feedback is unavailable, the flexibility of our model, including gradient prediction, still allows us outperform competing approaches, although with a smaller margin. Due to the pervasiveness of bandit based optimisation, our scheme opens up for improved performance both in meta-optimisation and in applications where gradient related information is readily available. version:1
arxiv-1705-09919 | Direct Mapping Hidden Excited State Interaction Patterns from ab initio Dynamics and Its Implications on Force Field Development | http://arxiv.org/abs/1705.09919 | id:1705.09919 author:Fang Liu, Likai Du, Dongju Zhang, Jun Gao category:physics.chem-ph stat.ML  published:2017-05-28 summary:The excited states of polyatomic systems are rather complex, and often exhibit meta-stable dynamical behaviors. Static analysis of reaction pathway often fails to sufficiently characterize excited state motions due to their highly non-equilibrium nature. Here, we proposed a time series guided clustering algorithm to generate most relevant meta-stable patterns directly from ab initio dynamic trajectories. Based on the knowledge of these meta-stable patterns, we suggested an interpolation scheme with only a concrete and finite set of known patterns to accurately predict the ground and excited state properties of the entire dynamics trajectories. As illustrated with the example of sinapic acids, the estimation error for both ground and excited state is very close, which indicates one could predict the ground and excited state molecular properties with similar accuracy. These results may provide us some insights to construct an excited state force field with compatible energy terms as traditional ones. version:1
arxiv-1705-09914 | Dilated Residual Networks | http://arxiv.org/abs/1705.09914 | id:1705.09914 author:Fisher Yu, Vladlen Koltun, Thomas Funkhouser category:cs.CV  published:2017-05-28 summary:Convolutional networks for image classification progressively reduce resolution until the image is represented by tiny feature maps in which the spatial structure of the scene is no longer discernible. Such loss of spatial acuity can limit image classification accuracy and complicate the transfer of the model to downstream applications that require detailed scene understanding. These problems can be alleviated by dilation, which increases the resolution of output feature maps without reducing the receptive field of individual neurons. We show that dilated residual networks (DRNs) outperform their non-dilated counterparts in image classification without increasing the model's depth or complexity. We then study gridding artifacts introduced by dilation, develop an approach to removing these artifacts (`degridding'), and show that this further increases the performance of DRNs. In addition, we show that the accuracy advantage of DRNs is further magnified in downstream applications such as object localization and semantic segmentation. version:1
arxiv-1705-09912 | Multi-channel Weighted Nuclear Norm Minimization for Real Color Image Denoising | http://arxiv.org/abs/1705.09912 | id:1705.09912 author:Jun Xu, Lei Zhang, David Zhang, Xiangchu Feng category:cs.CV  published:2017-05-28 summary:Most of the existing denoising algorithms are developed for grayscale images, while it is not a trivial work to extend them for color image denoising because the noise statistics in R, G, B channels can be very different for real noisy images. In this paper, we propose a multi-channel (MC) optimization model for real color image denoising under the weighted nuclear norm minimization (WNNM) framework. We concatenate the RGB patches to make use of the channel redundancy, and introduce a weight matrix to balance the data fidelity of the three channels in consideration of their different noise statistics. The proposed MC-WNNM model does not have an analytical solution. We reformulate it into a linear equality-constrained problem and solve it with the alternating direction method of multipliers. Each alternative updating step has closed-form solution and the convergence can be guaranteed. Extensive experiments on both synthetic and real noisy image datasets demonstrate the superiority of the proposed MC-WNNM over state-of-the-art denoising methods. version:1
arxiv-1705-09906 | Listen, Interact and Talk: Learning to Speak via Interaction | http://arxiv.org/abs/1705.09906 | id:1705.09906 author:Haichao Zhang, Haonan Yu, Wei Xu category:cs.CL  published:2017-05-28 summary:One of the long-term goals of artificial intelligence is to build an agent that can communicate intelligently with human in natural language. Most existing work on natural language learning relies heavily on training over a pre-collected dataset with annotated labels, leading to an agent that essentially captures the statistics of the fixed external training data. As the training data is essentially a static snapshot representation of the knowledge from the annotator, the agent trained this way is limited in adaptiveness and generalization of its behavior. Moreover, this is very different from the language learning process of humans, where language is acquired during communication by taking speaking action and learning from the consequences of speaking action in an interactive manner. This paper presents an interactive setting for grounded natural language learning, where an agent learns natural language by interacting with a teacher and learning from feedback, thus learning and improving language skills while taking part in the conversation. To achieve this goal, we propose a model which incorporates both imitation and reinforcement by leveraging jointly sentence and reward feedbacks from the teacher. Experiments are conducted to validate the effectiveness of the proposed approach. version:1
arxiv-1705-09894 | Continuous Video to Simple Signals for Swimming Stroke Detection with Convolutional Neural Networks | http://arxiv.org/abs/1705.09894 | id:1705.09894 author:Brandon Victor, Zhen He, Stuart Morgan, Dino Miniutti category:cs.CV  published:2017-05-28 summary:In many sports, it is useful to analyse video of an athlete in competition for training purposes. In swimming, stroke rate is a common metric used by coaches; requiring a laborious labelling of each individual stroke. We show that using a Convolutional Neural Network (CNN) we can automatically detect discrete events in continuous video (in this case, swimming strokes). We create a CNN that learns a mapping from a window of frames to a point on a smooth 1D target signal, with peaks denoting the location of a stroke, evaluated as a sliding window. To our knowledge this process of training and utilizing a CNN has not been investigated before; either in sports or fundamental computer vision research. Most research has been focused on action recognition and using it to classify many clips in continuous video for action localisation. In this paper we demonstrate our process works well on the task of detecting swimming strokes in the wild. However, without modifying the model architecture or training method, the process is also shown to work equally well on detecting tennis strokes, implying that this is a general process. The outputs of our system are surprisingly smooth signals that predict an arbitrary event at least as accurately as humans (manually evaluated from a sample of negative results). A number of different architectures are evaluated, pertaining to slightly different problem formulations and signal targets. version:1
arxiv-1705-09892 | Care about you: towards large-scale human-centric visual relationship detection | http://arxiv.org/abs/1705.09892 | id:1705.09892 author:Bohan Zhuang, Qi Wu, Chunhua Shen, Ian Reid, Anton van den Hengel category:cs.CV  published:2017-05-28 summary:Visual relationship detection aims to capture interactions between pairs of objects in images. Relationships between objects and humans represent a particularly important subset of this problem, with implications for challenges such as understanding human behaviour, and identifying affordances, amongst others. In addressing this problem we first construct a large-scale human-centric visual relationship detection dataset (HCVRD), which provides many more types of relationship annotation (nearly 10K categories) than the previous released datasets. This large label space better reflects the reality of human-object interactions, but gives rise to a long-tail distribution problem, which in turn demands a zero-shot approach to labels appearing only in the test set. This is the first time this issue has been addressed. We propose a webly-supervised approach to these problems and demonstrate that the proposed model provides a strong baseline on our HCVRD dataset. version:1
arxiv-1705-09888 | Cross-modal Subspace Learning for Fine-grained Sketch-based Image Retrieval | http://arxiv.org/abs/1705.09888 | id:1705.09888 author:Peng Xu, Qiyue Yin, Yongye Huang, Yi-Zhe Song, Zhanyu Ma, Liang Wang, Tao Xiang, W. Bastiaan Kleijn, Jun Guo category:cs.CV  published:2017-05-28 summary:Sketch-based image retrieval (SBIR) is challenging due to the inherent domain-gap between sketch and photo. Compared with pixel-perfect depictions of photos, sketches are iconic renderings of the real world with highly abstract. Therefore, matching sketch and photo directly using low-level visual clues are unsufficient, since a common low-level subspace that traverses semantically across the two modalities is non-trivial to establish. Most existing SBIR studies do not directly tackle this cross-modal problem. This naturally motivates us to explore the effectiveness of cross-modal retrieval methods in SBIR, which have been applied in the image-text matching successfully. In this paper, we introduce and compare a series of state-of-the-art cross-modal subspace learning methods and benchmark them on two recently released fine-grained SBIR datasets. Through thorough examination of the experimental results, we have demonstrated that the subspace learning can effectively model the sketch-photo domain-gap. In addition we draw a few key insights to drive future research. version:1
arxiv-1705-09887 | Vocabulary-informed Extreme Value Learning | http://arxiv.org/abs/1705.09887 | id:1705.09887 author:Yanwei Fu, HanZe Dong, Yu-feng Ma, Zhengjun Zhang, Xiangyang Xue category:cs.CV math.ST stat.ML stat.TH  published:2017-05-28 summary:The novel unseen classes can be formulated as the extreme values of known classes. This inspired the recent works on open-set recognition \cite{Scheirer_2013_TPAMI,Scheirer_2014_TPAMIb,EVM}, which however can have no way of naming the novel unseen classes. To solve this problem, we propose the Extreme Value Learning (EVL) formulation to learn the mapping from visual feature to semantic space. To model the margin and coverage distributions of each class, the Vocabulary-informed Learning (ViL) is adopted by using vast open vocabulary in the semantic space. Essentially, by incorporating the EVL and ViL, we for the first time propose a novel semantic embedding paradigm -- Vocabulary-informed Extreme Value Learning (ViEVL), which embeds the visual features into semantic space in a probabilistic way. The learned embedding can be directly used to solve supervised learning, zero-shot and open set recognition simultaneously. Experiments on two benchmark datasets demonstrate the effectiveness of proposed frameworks. version:1
arxiv-1705-09886 | Convergence Analysis of Two-layer Neural Networks with ReLU Activation | http://arxiv.org/abs/1705.09886 | id:1705.09886 author:Yuanzhi Li, Yang Yuan category:cs.LG  published:2017-05-28 summary:In recent years, stochastic gradient descent (SGD) based techniques has become the standard tools for training neural networks. However, formal theoretical understanding of why SGD can train neural networks in practice is largely missing. In this paper, we make progress on understanding this mystery by providing a convergence analysis for SGD on a rich subset of two-layer feedforward networks with ReLU activations. This subset is characterized by a special structure called "identity mapping". We prove that, if input follows from Gaussian distribution, with standard $O(1/\sqrt{d})$ initialization of the weights, SGD converges to the global minimum in polynomial number of steps. Unlike normal vanilla networks, the "identity mapping" makes our network asymmetric and thus the global minimum is unique. To complement our theory, we are also able to show experimentally that multi-layer networks with this mapping have better performance compared with normal vanilla networks. Our convergence theorem differs from traditional non-convex optimization techniques. We show that SGD converges to optimal in "two phases": In phase I, the gradient points to the wrong direction, however, a potential function $g$ gradually decreases. Then in phase II, SGD enters a nice one point convex region and converges. We also show that the identity mapping is necessary for convergence, as it moves the initial point to a better place for optimization. Experiment verifies our claims. version:1
arxiv-1705-09882 | Person Depth ReID: Robust Person Re-identification with Commodity Depth Sensors | http://arxiv.org/abs/1705.09882 | id:1705.09882 author:Nikolaos Karianakis, Zicheng Liu, Yinpeng Chen, Stefano Soatto category:cs.CV  published:2017-05-28 summary:This work targets person re-identification (ReID) from depth sensors such as Kinect. Since depth is invariant to illumination and less sensitive than color to day-by-day appearance changes, a natural question is whether depth is an effective modality for Person ReID, especially in scenarios where individuals wear different colored clothes or over a period of several months. We explore the use of recurrent Deep Neural Networks for learning high-level shape information from low-resolution depth images. In order to tackle the small sample size problem, we introduce regularization and a hard temporal attention unit. The whole model can be trained end to end with a hybrid supervised loss. We carry out a thorough experimental evaluation of the proposed method on three person re-identification datasets, which include side views, views from the top and sequences with varying degree of partial occlusion, pose and viewpoint variations. To that end, we introduce a new dataset with RGB-D and skeleton data. In a scenario where subjects are recorded after three months with new clothes, we demonstrate large performance gains attained using Depth ReID compared to a state-of-the-art Color ReID. Finally, we show further improvements using the temporal attention unit in multi-shot setting. version:1
arxiv-1705-09874 | Targeted Learning with Daily EHR Data | http://arxiv.org/abs/1705.09874 | id:1705.09874 author:Oleg Sofrygin, Zheng Zhu, Julie A Schmittdiel, Alyce S. Adams, Richard W. Grant, Mark J. van der Laan, Romain Neugebauer category:stat.AP stat.CO stat.ML  published:2017-05-27 summary:Electronic health records (EHR) data provide a cost and time-effective opportunity to conduct cohort studies of the effects of multiple time-point interventions in the diverse patient population found in real-world clinical settings. Because the computational cost of analyzing EHR data at daily (or more granular) scale can be quite high, a pragmatic approach has been to partition the follow-up into coarser intervals of pre-specified length. Current guidelines suggest employing a 'small' interval, but the feasibility and practical impact of this recommendation has not been evaluated and no formal methodology to inform this choice has been developed. We start filling these gaps by leveraging large-scale EHR data from a diabetes study to develop and illustrate a fast and scalable targeted learning approach that allows to follow the current recommendation and study its practical impact on inference. More specifically, we map daily EHR data into four analytic datasets using 90, 30, 15 and 5-day intervals. We apply a semi-parametric and doubly robust estimation approach, the longitudinal TMLE, to estimate the causal effects of four dynamic treatment rules with each dataset, and compare the resulting inferences. To overcome the computational challenges presented by the size of these data, we propose a novel TMLE implementation, the 'long-format TMLE', and rely on the latest advances in scalable data-adaptive machine-learning software, xgboost and h2o, for estimation of the TMLE nuisance parameters. version:1
arxiv-1705-09869 | Dimensionality reduction for acoustic vehicle classification with spectral clustering | http://arxiv.org/abs/1705.09869 | id:1705.09869 author:Justin Sunu, Allon G. Percus category:stat.ML cs.LG physics.data-an  published:2017-05-27 summary:Classification of vehicles has broad applications, ranging from traffic flow management to military target recognition. We propose a method for automated identification of moving vehicles from roadside audio sensors. We use a short-time Fourier transform to decompose audio signals, and treat the frequency signature at each time window as an individual data point to be classified. Using spectral clustering, we then decrease the dimensionality of the data sufficiently for K-nearest neighbors to provide accurate vehicle identification. version:1
arxiv-1705-09866 | Machine learning for graph-based representations of three-dimensional discrete fracture networks | http://arxiv.org/abs/1705.09866 | id:1705.09866 author:Manuel Valera, Zhengyang Guo, Priscilla Kelly, Sean Matz, Adrian Cantu, Allon G. Percus, Jeffrey D. Hyman, Gowri Srinivasan, Hari S. Viswanathan category:physics.geo-ph cs.SI physics.data-an stat.ML  published:2017-05-27 summary:Structural and topological information play a key role in modeling of flow through fractured rock. Discrete fracture network (DFN) computational suites such as dfnWorks are designed to simulate flow and transport in such media. Transport calculations that use a particle tracking method reveal that a small backbone of fractures exists where most transport occurs providing a significant reduction in the effective size of the flowing fracture network. However, the simulations needed for particle tracking are computationally intensive, and may not be scalable to large systems or for robust uncertainty quantification of fracture networks where thousands of forward simulations are needed to bound system behavior. In this paper, we combine machine learning and graph theoretical methods to develop an emulator of dfnWorks for quick estimates of transport that can mimic the high fidelity discrete fracture networks. We introduce a machine learning approach to characterizing transport in DFNs. We consider a graph representation where nodes signify fractures and edges denote their intersections. Using supervised learning techniques, random forest and support vector machines, that train on particle-tracking backbone paths found by dfnWorks, we predict whether or not fractures conduct significant flow, based primarily on node centrality features in the graph. Our methods run in negligible time compared to particle-tracking simulations. We find that our predicted backbone can reduce the network to approximately 20% of its original size, while still generating breakthrough curves resembling those of the full network. version:1
arxiv-1705-09864 | BMXNet: An Open-Source Binary Neural Network Implementation Based on MXNet | http://arxiv.org/abs/1705.09864 | id:1705.09864 author:Haojin Yang, Martin Fritzsche, Christian Bartz, Christoph Meinel category:cs.LG cs.CV cs.NE  published:2017-05-27 summary:Binary Neural Networks (BNNs) can drastically reduce memory size and accesses by applying bit-wise operations instead of standard arithmetic operations. Therefore it could significantly improve the efficiency and lower the energy consumption at runtime, which enables the application of state-of-the-art deep learning models on low power devices. BMXNet is an open-source BNN library based on MXNet, which supports both XNOR-Networks and Quantized Neural Networks. The developed BNN layers can be seamlessly applied with other standard library components and work in both GPU and CPU mode. BMXNet is maintained and developed by the multimedia research group at Hasso Plattner Institute and released under Apache license. Extensive experiments validate the efficiency and effectiveness of our implementation. The BMXNet library, several sample projects, and a collection of pre-trained binary deep models are available for download at https://github.com/hpi-xnor version:1
arxiv-1705-09862 | Efficient Modeling of Latent Information in Supervised Learning using Gaussian Processes | http://arxiv.org/abs/1705.09862 | id:1705.09862 author:Zhenwen Dai, Mauricio A. Álvarez, Neil D. Lawrence category:stat.ML cs.LG  published:2017-05-27 summary:Often in machine learning, data are collected as a combination of multiple conditions, e.g., the voice recordings of multiple persons, each labeled with an ID. How could we build a model that captures the latent information related to these conditions and generalize to a new one with few data? We present a new model called Latent Variable Multiple Output Gaussian Processes (LVMOGP) and that allows to jointly model multiple conditions for regression and generalize to a new condition with a few data points at test time. LVMOGP infers the posteriors of Gaussian processes together with a latent space representing the information about different conditions. We derive an efficient variational inference method for LVMOGP, of which the computational complexity is as low as sparse Gaussian processes. We show that LVMOGP significantly outperforms related Gaussian process methods on various tasks with both synthetic and real data. version:1
arxiv-1705-09860 | Probabilistic Global Scale Estimation for MonoSLAM Based on Generic Object Detection | http://arxiv.org/abs/1705.09860 | id:1705.09860 author:Edgar Sucar, Jean-Bernard Hayet category:cs.CV  published:2017-05-27 summary:This paper proposes a novel method to estimate the global scale of a 3D reconstructed model within a Kalman filtering-based monocular SLAM algorithm. Our Bayesian framework integrates height priors over the detected objects belonging to a set of broad predefined classes, based on recent advances in fast generic object detection. Each observation is produced on single frames, so that we do not need a data association process along video frames. This is because we associate the height priors with the image region sizes at image places where map features projections fall within the object detection regions. We present very promising results of this approach obtained on several experiments with different object classes. version:1
arxiv-1705-09851 | Deep Learning for Spatio-Temporal Modeling: Dynamic Traffic Flows and High Frequency Trading | http://arxiv.org/abs/1705.09851 | id:1705.09851 author:Matthew F. Dixon, Nicholas G. Polson, Vadim O. Sokolov category:stat.ML  published:2017-05-27 summary:Deep learning applies hierarchical layers of hidden variables to construct nonlinear high dimensional predictors. Our goal is to develop and train deep learning architectures for spatio-temporal modeling. Training a deep architecture is achieved by stochastic gradient descent (SGD) and drop-out (DO) for parameter regularization with a goal of minimizing out-of-sample predictive mean squared error. To illustrate our methodology, we predict the sharp discontinuities in traffic flow data, and secondly, we develop a classification rule to predict short-term futures market prices as a function of the order book depth. Finally, we conclude with directions for future research. version:1
arxiv-1705-09850 | Abnormality Detection and Localization in Chest X-Rays using Deep Convolutional Neural Networks | http://arxiv.org/abs/1705.09850 | id:1705.09850 author:Mohammad Tariqul Islam, Md Abdul Aowal, Ahmed Tahseen Minhaz, Khalid Ashraf category:cs.CV  published:2017-05-27 summary:Chest X-Rays are widely used for diagnosing abnormalities in the heart and lung area. Automatically detecting these abnormalities with high accuracy could greatly enhance real world diagnosis processes. Lack of standard publicly available dataset and benchmark studies, however, makes it difficult to compare various detection methods. In order to overcome these difficulties, we have used a publicly available Indiana chest X-Ray dataset and studied the performance of known deep convolutional network (DCN) architectures on different abnormalities. We find that the same DCN architecture doesn't perform well across all abnormalities. Shallow features or earlier layers consistently provide higher detection accuracy compared to deep features. We have also found ensemble models to improve classification significantly compared to single model. Combining these insight, we report the highest accuracy on chest X-Ray abnormality detection on this dataset. Our localization experiments using these trained classifiers show that for spatially spread out abnormalities like cardiomegaly and pulmonary edema, the network can localize the abnormalities successfully most of the time. We find that in the cardiomegaly classification task, the deep learning method improves the accuracy by a staggering 17 percentage point compared to rule based methods. One remarkable result of the cardiomegaly localization is that the heart and its surrounding region is most responsible for cardiomegaly detection, in contrast to the rule based models where the ratio of heart and lung area is used as the measure. We believe that through deep learning based classification and localization, we will discover many more interesting features in medical image diagnosis that are not considered traditionally. version:1
arxiv-1704-06194 | Improved Neural Relation Detection for Knowledge Base Question Answering | http://arxiv.org/abs/1704.06194 | id:1704.06194 author:Mo Yu, Wenpeng Yin, Kazi Saidul Hasan, Cicero dos Santos, Bing Xiang, Bowen Zhou category:cs.CL cs.AI cs.NE  published:2017-04-20 summary:Relation detection is a core component for many NLP applications including Knowledge Base Question Answering (KBQA). In this paper, we propose a hierarchical recurrent neural network enhanced by residual learning that detects KB relations given an input question. Our method uses deep residual bidirectional LSTMs to compare questions and relation names via different hierarchies of abstraction. Additionally, we propose a simple KBQA system that integrates entity linking and our proposed relation detector to enable one enhance another. Experimental results evidence that our approach achieves not only outstanding relation detection performance, but more importantly, it helps our KBQA system to achieve state-of-the-art accuracy for both single-relation (SimpleQuestions) and multi-relation (WebQSP) QA benchmarks. version:2
arxiv-1705-09847 | Lifelong Generative Modeling | http://arxiv.org/abs/1705.09847 | id:1705.09847 author:Jason Ramapuram, Magda Gregorova, Alexandros Kalousis category:stat.ML cs.LG  published:2017-05-27 summary:Lifelong learning is the problem of learning multiple consecutive tasks in an online manner and is essential towards the development of intelligent machines that can adapt to their surroundings. In this work we focus on learning a lifelong approach to generative modeling whereby we continuously incorporate newly observed distributions into our model representation. We utilize two models, aptly named the student and the teacher, in order to aggregate information about all past distributions without the preservation of any of the past data or previous models. The teacher is utilized as a form of compressed memory in order to allow for the student model to learn over the past as well as present data. We demonstrate why a naive approach to lifelong generative modeling fails and introduce a regularizer with which we demonstrate learning across a long range of distributions. version:1
arxiv-1704-08883 | Traffic Light Control Using Deep Policy-Gradient and Value-Function Based Reinforcement Learning | http://arxiv.org/abs/1704.08883 | id:1704.08883 author:Seyed Sajad Mousavi, Michael Schukat, Enda Howley category:cs.LG  published:2017-04-28 summary:Recent advances in combining deep neural network architectures with reinforcement learning techniques have shown promising potential results in solving complex control problems with high dimensional state and action spaces. Inspired by these successes, in this paper, we build two kinds of reinforcement learning algorithms: deep policy-gradient and value-function based agents which can predict the best possible traffic signal for a traffic intersection. At each time step, these adaptive traffic light control agents receive a snapshot of the current state of a graphical traffic simulator and produce control signals. The policy-gradient based agent maps its observation directly to the control signal, however the value-function based agent first estimates values for all legal control signals. The agent then selects the optimal control action with the highest value. Our methods show promising results in a traffic network simulated in the SUMO traffic simulator, without suffering from instability issues during the training process. version:2
arxiv-1705-08415 | Community Detection with Graph Neural Networks | http://arxiv.org/abs/1705.08415 | id:1705.08415 author:Joan Bruna, Xiang Li category:stat.ML  published:2017-05-23 summary:We study data-driven methods for community detection in graphs. This estimation problem is typically formulated in terms of the spectrum of certain operators, as well as via posterior inference under certain probabilistic graphical models. Focusing on random graph families such as the Stochastic Block Model, recent research has unified these two approaches, and identified both statistical and computational signal-to-noise detection thresholds. We embed the resulting class of algorithms within a generic family of graph neural networks and show that they can reach those detection thresholds in a purely data-driven manner, without access to the underlying generative models and with no parameter assumptions. The resulting model is also tested on real datasets, requiring less computational steps and performing significantly better than rigid parametric models. version:2
arxiv-1705-09816 | Global hard thresholding algorithms for joint sparse image representation and denoising | http://arxiv.org/abs/1705.09816 | id:1705.09816 author:Reza Borhani, Jeremy Watt, Aggelos Katsaggelos category:cs.CV cs.LG  published:2017-05-27 summary:Sparse coding of images is traditionally done by cutting them into small patches and representing each patch individually over some dictionary given a pre-determined number of nonzero coefficients to use for each patch. In lack of a way to effectively distribute a total number (or global budget) of nonzero coefficients across all patches, current sparse recovery algorithms distribute the global budget equally across all patches despite the wide range of differences in structural complexity among them. In this work we propose a new framework for joint sparse representation and recovery of all image patches simultaneously. We also present two novel global hard thresholding algorithms, based on the notion of variable splitting, for solving the joint sparse model. Experimentation using both synthetic and real data shows effectiveness of the proposed framework for sparse image representation and denoising tasks. Additionally, time complexity analysis of the proposed algorithms indicate high scalability of both algorithms, making them favorable to use on large megapixel images. version:1
arxiv-1705-09805 | PVEs: Position-Velocity Encoders for Unsupervised Learning of Structured State Representations | http://arxiv.org/abs/1705.09805 | id:1705.09805 author:Rico Jonschkowski, Roland Hafner, Jonathan Scholz, Martin Riedmiller category:cs.RO cs.CV cs.LG  published:2017-05-27 summary:We propose position-velocity encoders (PVEs) which learn---without supervision---to encode images to positions and velocities of task-relevant objects. PVEs encode a single image into a low-dimensional position state and compute the velocity state from finite differences in position. In contrast to autoencoders, position-velocity encoders are not trained by image reconstruction, but by making the position-velocity representation consistent with priors about interacting with the physical world. We applied PVEs to several simulated control tasks from pixels and achieved promising preliminary results. version:1
arxiv-1705-09800 | Growth-Optimal Portfolio Selection under CVaR Constraints | http://arxiv.org/abs/1705.09800 | id:1705.09800 author:Guy Uziel, Ran El-Yaniv category:q-fin.MF cs.LG  published:2017-05-27 summary:Online portfolio selection research has so far focused mainly on minimizing regret defined in terms of wealth growth. Practical financial decision making, however, is deeply concerned with both wealth and risk. We consider online learning of portfolios of stocks whose prices are governed by arbitrary (unknown) stationary and ergodic processes, where the goal is to maximize wealth while keeping the conditional value at risk (CVaR) below a desired threshold. We characterize the asymptomatically optimal risk-adjusted performance and present an investment strategy whose portfolios are guaranteed to achieve the asymptotic optimal solution while fulfilling the desired risk constraint. We also numerically demonstrate and validate the viability of our method on standard datasets. version:1
arxiv-1705-09786 | AMPNet: Asynchronous Model-Parallel Training for Dynamic Neural Networks | http://arxiv.org/abs/1705.09786 | id:1705.09786 author:Alex Gaunt, Matthew Johnson, Maik Riechert, Daniel Tarlow, Ryota Tomioka, Dimitrios Vytiniotis, Sam Webster category:cs.LG cs.AI cs.DC stat.ML  published:2017-05-27 summary:New types of machine learning hardware in development and entering the market hold the promise of revolutionizing deep learning in a manner as profound as GPUs. However, existing software frameworks and training algorithms for deep learning have yet to evolve to fully leverage the capability of the new wave of silicon. We already see the limitations of existing algorithms for models that exploit structured input via complex and instance-dependent control flow, which prohibits minibatching. We present an {\em asynchronous model-parallel} (AMP) training algorithm that is specifically motivated by training on networks of interconnected devices. Through an implementation on multi-core CPUs, we show that AMP training converges to the same accuracy as conventional synchronous training algorithms in a similar number of epochs, but utilizes the available hardware more efficiently even for small minibatch sizes, resulting in significantly shorter overall training times. Our framework opens the door for scaling up a new class of deep learning models that cannot be efficiently trained today. version:1
arxiv-1705-09785 | LiDAR-Camera Calibration using 3D-3D Point correspondences | http://arxiv.org/abs/1705.09785 | id:1705.09785 author:Ankit Dhall, Kunal Chelani, Vishnu Radhakrishnan, K. M. Krishna category:cs.RO cs.CV  published:2017-05-27 summary:With the advent of autonomous vehicles, LiDAR and cameras have become an indispensable combination of sensors. They both provide rich and complementary data which can be used by various algorithms and machine learning to sense and make vital inferences about the surroundings. We propose a novel pipeline and experimental setup to find accurate rigid-body transformation for extrinsically calibrating a LiDAR and a camera. The pipeling uses 3D-3D point correspondences in LiDAR and camera frame and gives a closed form solution. We further show the accuracy of the estimate by fusing point clouds from two stereo cameras which align perfectly with the rotation and translation estimated by our method, confirming the accuracy of our method's estimates both mathematically and visually. Taking our idea of extrinsic LiDAR-camera calibration forward, we demonstrate how two cameras with no overlapping field-of-view can also be calibrated extrinsically using 3D point correspondences. The code has been made available as open-source software in the form of a ROS package, more information about which can be sought here: https://github.com/ankitdhall/lidar_camera_calibration . version:1
arxiv-1705-09783 | Good Semi-supervised Learning that Requires a Bad GAN | http://arxiv.org/abs/1705.09783 | id:1705.09783 author:Zihang Dai, Zhilin Yang, Fan Yang, William W. Cohen, Ruslan Salakhutdinov category:cs.LG cs.AI  published:2017-05-27 summary:Semi-supervised learning methods based on generative adversarial networks (GANs) obtained strong empirical results, but it is not clear 1) how the discriminator benefits from joint training with a generator, and 2) why good semi-supervised classification performance and a good generator cannot be obtained at the same time. Theoretically, we show that given the discriminator objective, good semisupervised learning indeed requires a bad generator, and propose the definition of a preferred generator. Empirically, we derive a novel formulation based on our analysis that substantially improves over feature matching GANs, obtaining state-of-the-art results on multiple benchmark datasets. version:1
arxiv-1705-09780 | Nearest Neighbour Radial Basis Function Solvers for Deep Neural Networks | http://arxiv.org/abs/1705.09780 | id:1705.09780 author:Benjamin J. Meyer, Ben Harwood, Tom Drummond category:cs.CV  published:2017-05-27 summary:We present a radial basis function solver for convolutional neural networks that can be directly applied to both image classification and distance metric learning problems. Our method treats all training features from a deep neural network as radial basis function centres and computes loss by summing the influence of a feature's nearby centres in the embedding space. Having a radial basis function centred on each training feature is made scalable by treating it as an approximate nearest neighbour search problem. End-to-end learning of the network and solver is carried out, mapping high dimensional features into clusters of the same class. This results in a well formed embedding space, where semantically related instances are likely to be located near one another, regardless of whether or not the network was trained on those classes. The same loss function is used for both the metric learning and classification problems. We show that our radial basis function solver sets state-of-the-art embedding results on the Stanford Cars196 and CUB-200-2011 datasets. Additionally, we show that when used as a classifier, our method outperforms a conventional softmax classifier on the Caltech-256 object recognition dataset and the fine-grained recognition dataset CUB-200-2011. version:1
arxiv-1705-09778 | Heteroscedastic Concomitant Lasso for sparse multimodal electromagnetic brain imaging | http://arxiv.org/abs/1705.09778 | id:1705.09778 author:Mathurin Massias, Olivier Fercoq, Alexandre Gramfort, Joseph Salmon category:stat.ML math.OC stat.AP  published:2017-05-27 summary:In high dimension, it is customary to consider $\ell_1$-penalty regularized estimators to enforce sparsity, the Lasso being a canonical example. For statistical efficiency, they rely on tuning a parameter trading data fitting versus sparsity. For the Lasso theory to hold, this tuning parameter should be proportional to the noise level, yet the latter is often unknown in practice. A possible remedy is to consider estimators, such as the Scaled Lasso or the Concomitant Lasso, that jointly optimize over the regression parameter as well as over the noise level, making the choice of the regularization independent from the noise level. However, when data from different sources with varying noise levels are observed, as it is common with multimodal datasets, new dedicated estimators are necessary. In this work we provide statistical and computational solutions to deal with such heteroscedastic regression model, with a special emphasis on functional brain imaging with combined MEG and EEG signals. Adopting the formulation of Concomitant/Scaled Lasso-type estimators, we propose a jointly convex formulation leading to an efficient algorithm whose computational cost is no more expensive than the one for the Lasso. Empirical results on simulations and real M/EEG datasets demonstrate that our model successfully estimates the different noise levels and provides a stable estimation of the support as the noise levels vary. version:1
arxiv-1705-09765 | Deep Matching and Validation Network -- An End-to-End Solution to Constrained Image Splicing Localization and Detection | http://arxiv.org/abs/1705.09765 | id:1705.09765 author:Yue Wu, Wael AbdAlmageed, Prem Natarajan category:cs.CV cs.CR  published:2017-05-27 summary:Image splicing is a very common image manipulation technique that is sometimes used for malicious purposes. A splicing detec- tion and localization algorithm usually takes an input image and produces a binary decision indicating whether the input image has been manipulated, and also a segmentation mask that corre- sponds to the spliced region. Most existing splicing detection and localization pipelines suffer from two main shortcomings: 1) they use handcrafted features that are not robust against subsequent processing (e.g., compression), and 2) each stage of the pipeline is usually optimized independently. In this paper we extend the formulation of the underlying splicing problem to consider two input images, a query image and a potential donor image. Here the task is to estimate the probability that the donor image has been used to splice the query image, and obtain the splicing masks for both the query and donor images. We introduce a novel deep convolutional neural network architecture, called Deep Matching and Validation Network (DMVN), which simultaneously localizes and detects image splicing. The proposed approach does not depend on handcrafted features and uses raw input images to create deep learned representations. Furthermore, the DMVN is end-to-end op- timized to produce the probability estimates and the segmentation masks. Our extensive experiments demonstrate that this approach outperforms state-of-the-art splicing detection methods by a large margin in terms of both AUC score and speed. version:1
arxiv-1705-09764 | A Multi-strength Adversarial Training Method to Mitigate Adversarial Attacks | http://arxiv.org/abs/1705.09764 | id:1705.09764 author:Chang Song, Hsin-Pai Cheng, Chunpeng Wu, Hai Li, Yiran Chen, Qing Wu category:cs.LG cs.CV  published:2017-05-27 summary:Some recent works revealed that deep neural networks (DNNs) are vulnerable to so-called adversarial attacks where input examples are intentionally perturbed to fool DNNs. In this work, we revisit the DNN training process that includes adversarial examples into the training dataset so as to improve DNN's resilience to adversarial attacks, namely, adversarial training. Our experiments show that different adversarial strengths, i.e., perturbation levels of adversarial examples, have different working zones to resist the attack. Based on the observation, we propose a multi-strength adversarial training method (MAT) that combines the adversarial training examples with different adversarial strengths to defend adversarial attacks. Two training structures - mixed MAT and parallel MAT - are developed to facilitate the tradeoffs between training time and memory occupation. Our results show that MAT can substantially minimize the accuracy degradation of deep learning systems to adversarial attacks on MNIST, CIFAR-10, CIFAR-100, and SVHN. version:1
arxiv-1705-09761 | Stochastic Feedback Control of Systems with Unknown Nonlinear Dynamics | http://arxiv.org/abs/1705.09761 | id:1705.09761 author:Dan Yu, Mohammadhussein Rafieisakhaei, Suman Chakravorty category:cs.SY cs.LG  published:2017-05-27 summary:This paper studies the stochastic optimal control problem for systems with unknown dynamics. First, an open-loop deterministic trajectory optimization problem is solved without knowing the explicit form of the dynamical system. Next, a Linear Quadratic Gaussian (LQG) controller is designed for the nominal trajectory-dependent linearized system, such that under a small noise assumption, the actual states remain close to the optimal trajectory. The trajectory-dependent linearized system is identified using input-output experimental data consisting of the impulse responses of the nominal system. A computational example is given to illustrate the performance of the proposed approach. version:1
arxiv-1705-09759 | CASENet: Deep Category-Aware Semantic Edge Detection | http://arxiv.org/abs/1705.09759 | id:1705.09759 author:Zhiding Yu, Chen Feng, Ming-Yu Liu, Srikumar Ramalingam category:cs.CV  published:2017-05-27 summary:Boundary and edge cues are highly beneficial in improving a wide variety of vision tasks such as semantic segmentation, object recognition, stereo, and object proposal generation. Recently, the problem of edge detection has been revisited and significant progress has been made with deep learning. While classical edge detection is a challenging binary problem in itself, the category-aware semantic edge detection by nature is an even more challenging multi-label problem. We model the problem such that each edge pixel can be associated with more than one class as they appear in contours or junctions belonging to two or more semantic classes. To this end, we propose a novel end-to-end deep semantic edge learning architecture based on ResNet and a new skip-layer architecture where category-wise edge activations at the top convolution layer share and are fused with the same set of bottom layer features. We then propose a multi-label loss function to supervise the fused activations. We show that our proposed architecture benefits this problem with better performance, and we outperform the current state-of-the-art semantic edge detection methods by a large margin on standard data sets such as SBD and Cityscapes. version:1
arxiv-1705-09755 | word2vec Skip-Gram with Negative Sampling is a Weighted Logistic PCA | http://arxiv.org/abs/1705.09755 | id:1705.09755 author:Andrew J. Landgraf, Jeremy Bellay category:cs.CL stat.ML  published:2017-05-27 summary:We show that the skip-gram formulation of word2vec trained with negative sampling is equivalent to a weighted logistic PCA. This connection allows us to better understand the objective, compare it to other word embedding methods, and extend it to higher dimensional models. version:1
arxiv-1705-09731 | Multiplex model of mental lexicon reveals explosive learning in humans | http://arxiv.org/abs/1705.09731 | id:1705.09731 author:Massimo Stella, Nicole M. Beckage, Markus Brede, Manlio De Domenico category:physics.soc-ph cs.CL cs.SI nlin.AO  published:2017-05-26 summary:Similarities among words affect language acquisition and processing in a multi-relational way barely accounted for in the literature. We propose a multiplex network representation of word similarities in a mental lexicon as a natural framework for investigating large-scale cognitive patterns. Our model accounts for semantic, taxonomic, and phonological interactions and identifies a cluster of words of higher frequency, easier to identify, memorise and learn and with more meanings than expected at random. This cluster emerges around age 7 yr through an explosive transition not reproduced by null models. We relate this phenomenon to polysemy, i.e. redundancy in word meanings. We show that the word cluster acts as a core for the lexicon, increasing both its navigability and robustness to degradation in cognitive impairments. Our findings provide quantitative confirmation of existing psycholinguistic conjectures about core structure in the mental lexicon and the importance of integrating multi-relational word-word interactions in suitable frameworks. version:1
arxiv-1705-09728 | Direct Estimation of Regional Wall Thicknesses via Residual Recurrent Neural Network | http://arxiv.org/abs/1705.09728 | id:1705.09728 author:Wufeng Xue, Ilanit Ben Nachum, Sachin Pandey, James Warrington, Stephanie Leung, Shuo Li category:cs.CV  published:2017-05-26 summary:Accurate estimation of regional wall thicknesses (RWT) of left ventricular (LV) myocardium from cardiac MR sequences is of significant importance for identification and diagnosis of cardiac disease. Existing RWT estimation still relies on segmentation of LV myocardium, which requires strong prior information and user interaction. No work has been devoted into direct estimation of RWT from cardiac MR images due to the diverse shapes and structures for various subjects and cardiac diseases, as well as the complex regional deformation of LV myocardium during the systole and diastole phases of the cardiac cycle. In this paper, we present a newly proposed Residual Recurrent Neural Network (ResRNN) that fully leverages the spatial and temporal dynamics of LV myocardium to achieve accurate frame-wise RWT estimation. Our ResRNN comprises two paths: 1) a feed forward convolution neural network (CNN) for effective and robust CNN embedding learning of various cardiac images and preliminary estimation of RWT from each frame itself independently, and 2) a recurrent neural network (RNN) for further improving the estimation by modeling spatial and temporal dynamics of LV myocardium. For the RNN path, we design for cardiac sequences a Circle-RNN to eliminate the effect of null hidden input for the first time-step. Our ResRNN is capable of obtaining accurate estimation of cardiac RWT with Mean Absolute Error of 1.44mm (less than 1-pixel error) when validated on cardiac MR sequences of 145 subjects, evidencing its great potential in clinical cardiac function assessment. version:1
arxiv-1705-03387 | Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN | http://arxiv.org/abs/1705.03387 | id:1705.03387 author:Hyeungill Lee, Sungyeob Han, Jungwoo Lee category:cs.LG stat.ML  published:2017-05-09 summary:We propose a novel technique to make neural network robust to adversarial examples using a generative adversarial network. We alternately train both classifier and generator networks. The generator network generates an adversarial perturbation that can easily fool the classifier network by using a gradient of each image. Simultaneously, the classifier network is trained to classify correctly both original and adversarial images generated by the generator. These procedures help the classifier network to become more robust to adversarial perturbations. Furthermore, our adversarial training framework efficiently reduces overfitting and outperforms other regularization methods such as Dropout. We applied our method to supervised learning for CIFAR datasets, and experimantal results show that our method significantly lowers the generalization error of the network. To the best of our knowledge, this is the first method which uses GAN to improve supervised learning. version:2
arxiv-1705-09724 | Semi-Supervised Model Training for Unbounded Conversational Speech Recognition | http://arxiv.org/abs/1705.09724 | id:1705.09724 author:Shane Walker, Morten Pedersen, Iroro Orife, Jason Flaks category:cs.CL  published:2017-05-26 summary:For conversational large-vocabulary continuous speech recognition (LVCSR) tasks, up to about two thousand hours of audio is commonly used to train state of the art models. Collection of labeled conversational audio however, is prohibitively expensive, laborious and error-prone. Furthermore, academic corpora like Fisher English (2004) or Switchboard (1992) are inadequate to train models with sufficient accuracy in the unbounded space of conversational speech. These corpora are also timeworn due to dated acoustic telephony features and the rapid advancement of colloquial vocabulary and idiomatic speech over the last decades. Utilizing the colossal scale of our unlabeled telephony dataset, we propose a technique to construct a modern, high quality conversational speech training corpus on the order of hundreds of millions of utterances (or tens of thousands of hours) for both acoustic and language model training. We describe the data collection, selection and training, evaluating the results of our updated speech recognition system on a test corpus of 7K manually transcribed utterances. We show relative word error rate (WER) reductions of {35%, 19%} on {agent, caller} utterances over our seed model and 5% absolute WER improvements over IBM Watson STT on this conversational speech task. version:1
arxiv-1705-08499 | The Prediction Advantage: A Universally Meaningful Performance Measure for Classification and Regression | http://arxiv.org/abs/1705.08499 | id:1705.08499 author:Ran El-Yaniv, Yonatan Geifman, Yair Wiener category:cs.LG  published:2017-05-23 summary:We introduce the Prediction Advantage (PA), a novel performance measure for prediction functions under any loss function (e.g., classification or regression). The PA is defined as the performance advantage relative to the Bayesian risk restricted to knowing only the distribution of the labels. We derive the PA for well-known loss functions, including 0/1 loss, cross-entropy loss, absolute loss, and squared loss. In the latter case, the PA is identical to the well-known R-squared measure, widely used in statistics. The use of the PA ensures meaningful quantification of prediction performance, which is not guaranteed, for example, when dealing with noisy imbalanced classification problems. We argue that among several known alternative performance measures, PA is the best (and only) quantity ensuring meaningfulness for all noise and imbalance levels. version:2
arxiv-1705-09700 | Online Auctions and Multi-scale Online Learning | http://arxiv.org/abs/1705.09700 | id:1705.09700 author:Sébastien Bubeck, Nikhil R. Devanur, Zhiyi Huang, Rad Niazadeh category:cs.GT cs.DS cs.LG stat.ML  published:2017-05-26 summary:We consider revenue maximization in online auctions and pricing. A seller sells an identical item in each period to a new buyer, or a new set of buyers. For the online posted pricing problem, we show regret bounds that scale with the best fixed price, rather than the range of the values. We also show regret bounds that are almost scale free, and match the offline sample complexity, when comparing to a benchmark that requires a lower bound on the market share. These results are obtained by generalizing the classical learning from experts and multi-armed bandit problems to their multi-scale versions. In this version, the reward of each action is in a different range, and the regret w.r.t. a given action scales with its own range, rather than the maximum range. version:1
arxiv-1705-09684 | Multiple Source Domain Adaptation with Adversarial Training of Neural Networks | http://arxiv.org/abs/1705.09684 | id:1705.09684 author:Han Zhao, Shanghang Zhang, Guanhang Wu, João P. Costeira, José M. F. Moura, Geoffrey J. Gordon category:cs.LG cs.AI stat.ML  published:2017-05-26 summary:We propose a new generalization bound for domain adaptation when there are multiple source domains with labeled instances and one target domain with unlabeled instances. The new bound has an interesting interpretation and reduces to an existing bound when there is only one source domain. Compared with existing bounds, the new bound does not require expert knowledge about the target distribution, nor the optimal combination rule for multisource domains. Interestingly, our theory also leads to an efficient implementation using adversarial neural networks: we show how to interpret it as learning feature representations that are invariant to the multiple domain shifts while still being discriminative for the learning task. To this end, we propose two models, both of which we call multisource domain adversarial networks (MDANs): the first model optimizes directly our bound, while the second model is a smoothed approximation of the first one, leading to a more data-efficient and task-adaptive model. The optimization tasks of both models are minimax saddle point problems that can be optimized by adversarial training. To demonstrate the effectiveness of MDANs, we conduct extensive experiments showing superior adaptation performance on three real-world datasets: sentiment analysis, digit classification, and vehicle counting. version:1
arxiv-1705-09675 | Fisher GAN | http://arxiv.org/abs/1705.09675 | id:1705.09675 author:Youssef Mroueh, Tom Sercu category:cs.LG stat.ML  published:2017-05-26 summary:Generative Adversarial Networks (GANs) are powerful models for learning complex distributions. Stable training of GANs has been addressed in many recent works which explore different metrics between distributions. In this paper we introduce Fisher GAN which fits within the Integral Probability Metrics (IPM) framework for training GANs. Fisher GAN defines a critic with a data dependent constraint on its second order moments. We show in this paper that Fisher GAN allows for stable and time efficient training that does not compromise the capacity of the critic, and does not need data independent constraints such as weight clipping. We analyze our Fisher IPM theoretically and provide an algorithm based on Augmented Lagrangian for Fisher GAN. We validate our claims on both image sample generation and semi-supervised classification using Fisher GAN. version:1
arxiv-1705-09665 | Community Identity and User Engagement in a Multi-Community Landscape | http://arxiv.org/abs/1705.09665 | id:1705.09665 author:Justine Zhang, William L. Hamilton, Cristian Danescu-Niculescu-Mizil, Dan Jurafsky, Jure Leskovec category:cs.SI cs.CL cs.CY physics.soc-ph  published:2017-05-26 summary:A community's identity defines and shapes its internal dynamics. Our current understanding of this interplay is mostly limited to glimpses gathered from isolated studies of individual communities. In this work we provide a systematic exploration of the nature of this relation across a wide variety of online communities. To this end we introduce a quantitative, language-based typology reflecting two key aspects of a community's identity: how distinctive, and how temporally dynamic it is. By mapping almost 300 Reddit communities into the landscape induced by this typology, we reveal regularities in how patterns of user engagement vary with the characteristics of a community. Our results suggest that the way new and existing users engage with a community depends strongly and systematically on the nature of the collective identity it fosters, in ways that are highly consequential to community maintainers. For example, communities with distinctive and highly dynamic identities are more likely to retain their users. However, such niche communities also exhibit much larger acculturation gaps between existing users and newcomers, which potentially hinder the integration of the latter. More generally, our methodology reveals differences in how various social phenomena manifest across communities, and shows that structuring the multi-community landscape can lead to a better understanding of the systematic nature of this diversity. version:1
arxiv-1705-09656 | Helping News Editors Write Better Headlines: A Recommender to Improve the Keyword Contents & Shareability of News Headlines | http://arxiv.org/abs/1705.09656 | id:1705.09656 author:Terrence Szymanski, Claudia Orellana-Rodriguez, Mark T. Keane category:cs.CL cs.HC cs.IR  published:2017-05-26 summary:We present a software tool that employs state-of-the-art natural language processing (NLP) and machine learning techniques to help newspaper editors compose effective headlines for online publication. The system identifies the most salient keywords in a news article and ranks them based on both their overall popularity and their direct relevance to the article. The system also uses a supervised regression model to identify headlines that are likely to be widely shared on social media. The user interface is designed to simplify and speed the editor's decision process on the composition of the headline. As such, the tool provides an efficient way to combine the benefits of automated predictors of engagement and search-engine optimization (SEO) with human judgments of overall headline quality. version:1
arxiv-1705-08039 | Poincaré Embeddings for Learning Hierarchical Representations | http://arxiv.org/abs/1705.08039 | id:1705.08039 author:Maximilian Nickel, Douwe Kiela category:cs.AI cs.LG stat.ML  published:2017-05-22 summary:Representation learning has become an invaluable approach for learning from symbolic data such as text and graphs. However, while complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space -- or more precisely into an n-dimensional Poincar\'e ball. Due to the underlying hyperbolic geometry, this allows us to learn parsimonious representations of symbolic data by simultaneously capturing hierarchy and similarity. We introduce an efficient algorithm to learn the embeddings based on Riemannian optimization and show experimentally that Poincar\'e embeddings outperform Euclidean embeddings significantly on data with latent hierarchies, both in terms of representation capacity and in terms of generalization ability. version:2
arxiv-1705-09655 | Style Transfer from Non-Parallel Text by Cross-Alignment | http://arxiv.org/abs/1705.09655 | id:1705.09655 author:Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakkola category:cs.CL cs.LG  published:2017-05-26 summary:This paper focuses on style transfer on the basis of non-parallel text. This is an instance of a broader family of problems including machine translation, decipherment, and sentiment modification. The key technical challenge is to separate the content from desired text characteristics such as sentiment. We leverage refined alignment of latent representations across mono-lingual text corpora with different characteristics. We deliberately modify encoded examples according to their characteristics, requiring the reproduced instances to match available examples with the altered characteristics as a population. We demonstrate the effectiveness of this cross-alignment method on three tasks: sentiment modification, decipherment of word substitution ciphers, and recovery of word order. version:1
arxiv-1706-01380 | Automatic Response Assessment in Regions of Language Cortex in Epilepsy Patients Using ECoG-based Functional Mapping and Machine Learning | http://arxiv.org/abs/1706.01380 | id:1706.01380 author:Harish RaviPrakash, Milena Korostenskaja, Eduardo Castillo, Ki Lee, James Baumgartner, Ulas Bagci category:q-bio.NC cs.CV cs.LG  published:2017-05-26 summary:Accurate localization of brain regions responsible for language and cognitive functions in Epilepsy patients should be carefully determined prior to surgery. Electrocorticography (ECoG)-based Real Time Functional Mapping (RTFM) has been shown to be a safer alternative to electrical cortical stimulation mapping (ESM), which is currently the clinical/gold standard. Conventional methods for analyzing RTFM signals are based on statistical comparison of signal power at certain frequency bands with limited response assessment accuracies. This inherently leads to low accuracies of functional mapping results when compared with gold standard. In this study, we address the limitation of the current RTFM signal estimation methods by analyzing the full frequency spectrum of the signal and applying machine learning algorithms, specifically random forest (RF). We train RF with power spectral density of the time-series RTFM signal in supervised learning framework where ground truth labels are obtained from the ESM. Experimental results obtained from RTFM of six adult patients in a strictly controlled experimental setup reveal the state of the art detection accuracy of $\approx 78\%$ for the language comprehension task, an improvement of $23\%$ over the conventional RTFM estimation method. To the best of our knowledge, this is the first study exploring the use of machine learning approaches for determining RTFM signal characteristics, and using the whole-frequency band for better region localization. Our results demonstrate the feasibility of machine learning based RTFM signal analysis method over the full spectrum to be a clinical routine in the near future. version:1
arxiv-1705-09644 | Learning Causal Structures Using Regression Invariance | http://arxiv.org/abs/1705.09644 | id:1705.09644 author:AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, Kun Zhang category:cs.LG cs.AI stat.ML  published:2017-05-26 summary:We study causal inference in a multi-environment setting, in which the functional relations for producing the variables from their direct causes remain the same across environments, while the distribution of exogenous noises may vary. We introduce the idea of using the invariance of the functional relations of the variables to their causes across a set of environments. We define a notion of completeness for a causal inference algorithm in this setting and prove the existence of such algorithm by proposing the baseline algorithm. Additionally, we present an alternate algorithm that has significantly improved computational and sample complexity compared to the baseline algorithm. The experiment results show that the proposed algorithm outperforms the other existing algorithms. version:1
arxiv-1705-09634 | Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration | http://arxiv.org/abs/1705.09634 | id:1705.09634 author:Jason Altschuler, Jonathan Weed, Philippe Rigollet category:cs.DS stat.ML  published:2017-05-26 summary:Computing optimal transport distances such as the earth mover's distance is a fundamental problem in machine learning, statistics, and computer vision. Despite the recent introduction of several algorithms with good empirical performance, it is unknown whether general optimal transport distances can be approximated in near-linear time. This paper demonstrates that this ambitious goal is in fact achieved by Cuturi's Sinkhorn Distances, and provides guidance towards parameter tuning for this algorithm. This result relies on a new analysis of Sinkhorn iterations that also directly suggests a new algorithm Greenkhorn with the same theoretical guarantees. Numerical simulations illustrate that Greenkhorn significantly outperforms the classical Sinkhorn algorithm in practice. version:1
arxiv-1705-09606 | End-to-end Global to Local CNN Learning for Hand Pose Recovery in Depth data | http://arxiv.org/abs/1705.09606 | id:1705.09606 author:Meysam Madadi, Sergio Escalera, Xavier Baro, Jordi Gonzalez category:cs.CV  published:2017-05-26 summary:Despite recent advances in 3D pose estimation of human hands, especially thanks to the advent of CNNs and depth cameras, this task is still far from being solved. This is mainly due to the highly non-linear dynamics of fingers, which makes hand model training a challenging task. In this paper, we exploit a novel hierarchical tree-like structured CNN, in which branches are trained to become specialized in predefined subsets of hand joints, called local poses. We further fuse local pose features, extracted from hierarchical CNN branches, to learn higher order dependencies among joints in the final pose by end-to-end training. Lastly, the loss function used is also defined to incorporate appearance and physical constraints about doable hand motion and deformation. Experimental results suggest that feeding a tree-shaped CNN, specialized in local poses, into a fusion network for modeling joints correlations, helps to increase the precision of final estimations, outperforming state-of-the-art results on NYU and MSRA datasets. version:1
arxiv-1705-09605 | Combinatorial Multi-Armed Bandits with Filtered Feedback | http://arxiv.org/abs/1705.09605 | id:1705.09605 author:James A. Grant, David S. Leslie, Kevin Glazebrook, Roberto Szechtman category:cs.LG stat.ML  published:2017-05-26 summary:Motivated by problems in search and detection we present a solution to a Combinatorial Multi-Armed Bandit (CMAB) problem with both heavy-tailed reward distributions and a new class of feedback, filtered semibandit feedback. In a CMAB problem an agent pulls a combination of arms from a set $\{1,...,k\}$ in each round, generating random outcomes from probability distributions associated with these arms and receiving an overall reward. Under semibandit feedback it is assumed that the random outcomes generated are all observed. Filtered semibandit feedback allows the outcomes that are observed to be sampled from a second distribution conditioned on the initial random outcomes. This feedback mechanism is valuable as it allows CMAB methods to be applied to sequential search and detection problems where combinatorial actions are made, but the true rewards (number of objects of interest appearing in the round) are not observed, rather a filtered reward (the number of objects the searcher successfully finds, which must by definition be less than the number that appear). We present an upper confidence bound type algorithm, Robust-F-CUCB, and associated regret bound of order $\mathcal{O}(\ln(n))$ to balance exploration and exploitation in the face of both filtering of reward and heavy tailed reward distributions. version:1
arxiv-1705-09602 | Learning a Robust Society of Tracking Parts | http://arxiv.org/abs/1705.09602 | id:1705.09602 author:Elena Burceanu, Marius Leordeanu category:cs.CV  published:2017-05-26 summary:Object tracking is an essential task in computer vision that has been studied since the early days of the field. Being able to follow objects that undergo different transformations in the video sequence, including changes in scale, illumination, shape and occlusions, makes the problem extremely difficult. One of the real challenges is to keep track of the changes in objects appearance and not drift towards the background clutter. Different from previous approaches, we obtain robustness against background with a tracker model that is composed of many different parts. They are classifiers that respond at different scales and locations. The tracker system functions as a society of parts, each having its own role and level of credibility. Reliable classifiers decide the tracker's next move, while newcomers are first monitored before gaining the necessary level of reliability to participate in the decision process. Some parts that loose their consistency are rejected, while others that show consistency for a sufficiently long time are promoted to permanent roles. The tracker system, as a whole, could also go through different phases, from the usual, normal functioning to states of weak agreement and even crisis. The tracker system has different governing rules in each state. What truly distinguishes our work from others is not necessarily the strength of individual tracking parts, but the way in which they work together and build a strong and robust organization. We also propose an efficient way to learn simultaneously many tracking parts, with a single closed-form formulation. We obtain a fast and robust tracker with state of the art performance on the challenging OTB50 dataset. version:1
arxiv-1704-07626 | Taxonomy Induction using Hypernym Subsequences | http://arxiv.org/abs/1704.07626 | id:1704.07626 author:Amit Gupta, Rémi Lebret, Hamza Harkous, Karl Aberer category:cs.AI cs.CL cs.IR  published:2017-04-25 summary:We propose a novel, semi-supervised approach towards domain taxonomy induction from an input vocabulary of seed terms. Unlike all previous approaches, which typically extract direct hypernym edges for terms, our approach utilizes a novel probabilistic framework to extract hypernym subsequences. Taxonomy induction from extracted subsequences is cast as an instance of the minimumcost flow problem on a carefully designed directed graph. Through experiments, we demonstrate that our approach outperforms stateof- the-art taxonomy induction approaches across four languages. Importantly, we also show that our approach is robust to the presence of noise in the input vocabulary. To the best of our knowledge, no previous approaches have been empirically proven to manifest noise-robustness in the input vocabulary. version:3
arxiv-1705-09597 | Extracting 3D Vascular Structures from Microscopy Images using Convolutional Recurrent Networks | http://arxiv.org/abs/1705.09597 | id:1705.09597 author:Russell Bates, Benjamin Irving, Bostjan Markelc, Jakob Kaeppler, Ruth Muschel, Vicente Grau, Julia A. Schnabel category:cs.CV  published:2017-05-26 summary:Vasculature is known to be of key biological significance, especially in the study of cancer. As such, considerable effort has been focused on the automated measurement and analysis of vasculature in medical and pre-clinical images. In tumors in particular, the vascular networks may be extremely irregular and the appearance of the individual vessels may not conform to classical descriptions of vascular appearance. Typically, vessels are extracted by either a segmentation and thinning pipeline, or by direct tracking. Neither of these methods are well suited to microscopy images of tumor vasculature. In order to address this we propose a method to directly extract a medial representation of the vessels using Convolutional Neural Networks. We then show that these two-dimensional centerlines can be meaningfully extended into 3D in anisotropic and complex microscopy images using the recently popularized Convolutional Long Short-Term Memory units (ConvLSTM). We demonstrate the effectiveness of this hybrid convolutional-recurrent architecture over both 2D and 3D convolutional comparators. version:1
arxiv-1705-07844 | DepthCut: Improved Depth Edge Estimation Using Multiple Unreliable Channels | http://arxiv.org/abs/1705.07844 | id:1705.07844 author:Paul Guerrero, Holger Winnemöller, Wilmot Li, Niloy J. Mitra category:cs.CV  published:2017-05-22 summary:In the context of scene understanding, a variety of methods exists to estimate different information channels from mono or stereo images, including disparity, depth, and normals. Although several advances have been reported in the recent years for these tasks, the estimated information is often imprecise particularly near depth discontinuities or creases. Studies have however shown that precisely such depth edges carry critical cues for the perception of shape, and play important roles in tasks like depth-based segmentation or foreground selection. Unfortunately, the currently extracted channels often carry conflicting signals, making it difficult for subsequent applications to effectively use them. In this paper, we focus on the problem of obtaining high-precision depth edges (i.e., depth contours and creases) by jointly analyzing such unreliable information channels. We propose DepthCut, a data-driven fusion of the channels using a convolutional neural network trained on a large dataset with known depth. The resulting depth edges can be used for segmentation, decomposing a scene into depth layers with relatively flat depth, or improving the accuracy of the depth estimate near depth edges by constraining its gradients to agree with these edges. Quantitatively, we compare against 15 variants of baselines and demonstrate that our depth edges result in an improved segmentation performance and an improved depth estimate near depth edges compared to data-agnostic channel fusion. Qualitatively, we demonstrate that the depth edges result in superior segmentation and depth orderings. version:2
arxiv-1705-09587 | Enhancement of SSD by concatenating feature maps for object detection | http://arxiv.org/abs/1705.09587 | id:1705.09587 author:Jisoo Jeong, Hyojin Park, Nojun Kwak category:cs.CV  published:2017-05-26 summary:We propose an object detection method that improves the accuracy of the conventional SSD (Single Shot Multibox Detector), which is one of the top object detection algorithms in both aspects of accuracy and speed. The performance of a deep network is known to be improved as the number of feature maps increases. However, it is difficult to improve the performance by simply raising the number of feature maps. In this paper, we propose and analyze how to use feature maps effectively to improve the performance of the conventional SSD. The enhanced performance was obtained by changing the structure close to the classifier network, rather than growing layers close to the input data, e.g., by replacing VGGNet with ResNet. The proposed network is suitable for sharing the weights in the classifier networks, by which property, the training can be faster with better generalization power. For the Pascal VOC 2007 test set trained with VOC 2007 and VOC 2012 training sets, the proposed network with the input size of 300 x 300 achieved 78.5% mAP (mean average precision) at the speed of 35.0 FPS (frame per second), while the network with a 512 x 512 sized input achieved 80.8% mAP at 16.6 FPS using Nvidia Titan X GPU. The proposed network shows state-of-the-art mAP, which is better than those of the conventional SSD, YOLO, Faster-RCNN and RFCN. Also, it is faster than Faster-RCNN and RFCN. version:1
arxiv-1705-09585 | Detecting and Explaining Crisis | http://arxiv.org/abs/1705.09585 | id:1705.09585 author:Rohan Kshirsagar, Robert Morris, Sam Bowman category:cs.CL  published:2017-05-26 summary:Individuals on social media may reveal themselves to be in various states of crisis (e.g. suicide, self-harm, abuse, or eating disorders). Detecting crisis from social media text automatically and accurately can have profound consequences. However, detecting a general state of crisis without explaining why has limited applications. An explanation in this context is a coherent, concise subset of the text that rationalizes the crisis detection. We explore several methods to detect and explain crisis using a combination of neural and non-neural techniques. We evaluate these techniques on a unique data set obtained from Koko, an anonymous emotional support network available through various messaging applications. We annotate a small subset of the samples labeled with crisis with corresponding explanations. Our best technique significantly outperforms the baseline for detection and explanation. version:1
arxiv-1705-09580 | Risk-Sensitive Cooperative Games for Human-Machine Systems | http://arxiv.org/abs/1705.09580 | id:1705.09580 author:Agostino Capponi, Reza Ghanadan, Matt Stern category:stat.ML cs.AI 97R40  published:2017-05-26 summary:Autonomous systems can substantially enhance a human's efficiency and effectiveness in complex environments. Machines, however, are often unable to observe the preferences of the humans that they serve. Despite the fact that the human's and machine's objectives are aligned, asymmetric information, along with heterogeneous sensitivities to risk by the human and machine, make their joint optimization process a game with strategic interactions. We propose a framework based on risk-sensitive dynamic games; the human seeks to optimize her risk-sensitive criterion according to her true preferences, while the machine seeks to adaptively learn the human's preferences and at the same time provide a good service to the human. We develop a class of performance measures for the proposed framework based on the concept of regret. We then evaluate their dependence on the risk-sensitivity and the degree of uncertainty. We present applications of our framework to self-driving taxis, and robo-financial advising. version:1
arxiv-1705-06168 | Two-Sample Tests for Large Random Graphs Using Network Statistics | http://arxiv.org/abs/1705.06168 | id:1705.06168 author:Debarghya Ghoshdastidar, Maurilio Gutzeit, Alexandra Carpentier, Ulrike von Luxburg category:stat.ME stat.ML  published:2017-05-17 summary:We consider a two-sample hypothesis testing problem, where the distributions are defined on the space of undirected graphs, and one has access to only one observation from each model. A motivating example for this problem is comparing the friendship networks on Facebook and LinkedIn. The practical approach to such problems is to compare the networks based on certain network statistics. In this paper, we present a general principle for two-sample hypothesis testing in such scenarios without making any assumption about the network generation process. The main contribution of the paper is a general formulation of the problem based on concentration of network statistics, and consequently, a consistent two-sample test that arises as the natural solution for this problem. We also show that the proposed test is minimax optimal for certain network statistics. version:2
arxiv-1705-03451 | Proceedings of the Workshop on Data Mining for Oil and Gas | http://arxiv.org/abs/1705.03451 | id:1705.03451 author:Alipio Jorge, German Larrazabal, Pablo Guillen, Rui L. Lopes category:cs.AI stat.ML  published:2017-05-09 summary:The process of exploring and exploiting Oil and Gas (O&G) generates a lot of data that can bring more efficiency to the industry. The opportunities for using data mining techniques in the "digital oil-field" remain largely unexplored or uncharted. With the high rate of data expansion, companies are scrambling to develop ways to develop near-real-time predictive analytics, data mining and machine learning capabilities, and are expanding their data storage infrastructure and resources. With these new goals, come the challenges of managing data growth, integrating intelligence tools, and analyzing the data to glean useful insights. Oil and Gas companies need data solutions to economically extract value from very large volumes of a wide variety of data generated from exploration, well drilling and production devices and sensors. Data mining for oil and gas industry throughout the lifecycle of the reservoir includes the following roles: locating hydrocarbons, managing geological data, drilling and formation evaluation, well construction, well completion, and optimizing production through the life of the oil field. For each of these phases during the lifecycle of oil field, data mining play a significant role. Based on which phase were talking about, knowledge creation through scientific models, data analytics and machine learning, a effective, productive, and on demand data insight is critical for decision making within the organization. The significant challenges posed by this complex and economically vital field justify a meeting of data scientists that are willing to share their experience and knowledge. Thus, the Worskhop on Data Mining for Oil and Gas (DM4OG) aims to provide a quality forum for researchers that work on the significant challenges arising from the synergy between data science, machine learning, and the modeling and optimization problems in the O&G industry. version:2
arxiv-1705-09554 | Analysis of universal adversarial perturbations | http://arxiv.org/abs/1705.09554 | id:1705.09554 author:Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, Pascal Frossard, Stefano Soatto category:cs.CV cs.AI cs.LG stat.ML  published:2017-05-26 summary:Deep networks have recently been shown to be vulnerable to universal perturbations: there exist very small image-agnostic perturbations that cause most natural images to be misclassified by such classifiers. In this paper, we propose the first quantitative analysis of the robustness of classifiers to universal perturbations, and draw a formal link between the robustness to universal perturbations, and the geometry of the decision boundary. Specifically, we establish theoretical bounds on the robustness of classifiers under two decision boundary models (flat and curved models). We show in particular that the robustness of deep networks to universal perturbations is driven by a key property of their curvature: there exists shared directions along which the decision boundary of deep networks is systematically positively curved. Under such conditions, we prove the existence of small universal perturbations. Our analysis further provides a novel geometric method for computing universal perturbations, in addition to explaining their properties. version:1
arxiv-1705-09552 | Classification regions of deep neural networks | http://arxiv.org/abs/1705.09552 | id:1705.09552 author:Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard, Stefano Soatto category:cs.CV cs.AI cs.LG stat.ML  published:2017-05-26 summary:The goal of this paper is to analyze the geometric properties of deep neural network classifiers in the input space. We specifically study the topology of classification regions created by deep networks, as well as their associated decision boundary. Through a systematic empirical investigation, we show that state-of-the-art deep nets learn connected classification regions, and that the decision boundary in the vicinity of datapoints is flat along most directions. We further draw an essential connection between two seemingly unrelated properties of deep networks: their sensitivity to additive perturbations in the inputs, and the curvature of their decision boundary. The directions where the decision boundary is curved in fact remarkably characterize the directions to which the classifier is the most vulnerable. We finally leverage a fundamental asymmetry in the curvature of the decision boundary of deep nets, and propose a method to discriminate between original images, and images perturbed with small adversarial examples. We show the effectiveness of this purely geometric approach for detecting small adversarial perturbations in images, and for recovering the labels of perturbed images. version:1
arxiv-1705-10194 | Adaptive Classification for Prediction Under a Budget | http://arxiv.org/abs/1705.10194 | id:1705.10194 author:Feng Nan, Venkatesh Saligrama category:stat.ML cs.LG  published:2017-05-26 summary:We propose a novel adaptive approximation approach for test-time resource-constrained prediction. Given an input instance at test-time, a gating function identifies a prediction model for the input among a collection of models. Our objective is to minimize overall average cost without sacrificing accuracy. We learn gating and prediction models on fully labeled training data by means of a bottom-up strategy. Our novel bottom-up method first trains a high-accuracy complex model. Then a low-complexity gating and prediction model are subsequently learned to adaptively approximate the high-accuracy model in regions where low-cost models are capable of making highly accurate predictions. We pose an empirical loss minimization problem with cost constraints to jointly train gating and prediction models. On a number of benchmark datasets our method outperforms state-of-the-art achieving higher accuracy for the same cost. version:1
arxiv-1705-09549 | Residual Expansion Algorithm: Fast and Effective Optimization for Nonconvex Least Squares Problems | http://arxiv.org/abs/1705.09549 | id:1705.09549 author:Daiki Ikami, Toshihiko Yamasaki, Kiyoharu Aizawa category:cs.CV  published:2017-05-26 summary:We propose the residual expansion (RE) algorithm: a global (or near-global) optimization method for nonconvex least squares problems. Unlike most existing nonconvex optimization techniques, the RE algorithm is not based on either stochastic or multi-point searches; therefore, it can achieve fast global optimization. Moreover, the RE algorithm is easy to implement and successful in high-dimensional optimization. The RE algorithm exhibits excellent empirical performance in terms of k-means clustering, point-set registration, optimized product quantization, and blind image deblurring. version:1
arxiv-1705-08302 | Anatomically Constrained Neural Networks (ACNN): Application to Cardiac Image Enhancement and Segmentation | http://arxiv.org/abs/1705.08302 | id:1705.08302 author:Ozan Oktay, Enzo Ferrante, Konstantinos Kamnitsas, Mattias Heinrich, Wenjia Bai, Jose Caballero, Ricardo Guerrero, Stuart Cook, Antonio de Marvao, Timothy Dawes, Declan O'Regan, Bernhard Kainz, Ben Glocker, Daniel Rueckert category:cs.CV  published:2017-05-22 summary:Incorporation of prior knowledge about organ shape and location is key to improve performance of image analysis approaches. In particular, priors can be useful in cases where images are corrupted and contain artefacts due to limitations in image acquisition. The highly constrained nature of anatomical objects can be well captured with learning based techniques. However, in most recent and promising techniques such as CNN based segmentation it is not obvious how to incorporate such prior knowledge. State-of-the-art methods operate as pixel-wise classifiers where the training objectives do not incorporate the structure and inter-dependencies of the output. To overcome this limitation, we propose a generic training strategy that incorporates anatomical prior knowledge into CNNs through a new regularisation model, which is trained end-to-end. The new framework encourages models to follow the global anatomical properties of the underlying anatomy (e.g. shape, label structure) via learned non-linear representations of the shape. We show that the proposed approach can be easily adapted to different analysis tasks (e.g. image enhancement, segmentation) and improve the prediction accuracy of the state-of-the-art models. The applicability of our approach is shown on multi-modal cardiac datasets and public benchmarks. Additionally, we demonstrate how the learned deep models of 3D shapes can be interpreted and used as biomarkers for classification of cardiac pathologies. version:2
arxiv-1705-09529 | Fully Automatic Segmentation and Objective Assessment of Atrial Scars for Longstanding Persistent Atrial Fibrillation Patients Using Late Gadolinium-Enhanced MRI | http://arxiv.org/abs/1705.09529 | id:1705.09529 author:Guang Yang, Xiahai Zhuang, Habib Khan, Shouvik Haldar, Eva Nyktari, Lei Li, Rick Wage, Xujiong Ye, Greg Slabaugh, Raad Mohiaddin, Tom Wong, Jennifer Keegan, David Firmin category:cs.CV  published:2017-05-26 summary:Purpose: Atrial fibrillation (AF) is the most common cardiac arrhythmia and is correlated with increased morbidity and mortality. It is associated with atrial fibrosis, which may be assessed non-invasively using late gadolinium-enhanced (LGE) magnetic resonance imaging (MRI) where scar tissue is visualised as a region of signal enhancement. In this study, we proposed a novel fully automatic pipeline to achieve an accurate and objective atrial scarring segmentation and assessment of LGE MRI scans for the AF patients. Methods: Our fully automatic pipeline uniquely combined: (1) a multi-atlas based whole heart segmentation (MA-WHS) to determine the cardiac anatomy from an MRI Roadmap acquisition which is then mapped to LGE MRI, and (2) a super-pixel and supervised learning based approach to delineate the distribution and extent of atrial scarring in LGE MRI. Results: Both our MA-WHS and atrial scarring segmentation showed accurate delineations of cardiac anatomy (mean Dice = 89%) and atrial scarring (mean Dice =79%) respectively compared to the established ground truth from manual segmentation. Compared with previously studied methods with manual interventions, our innovative pipeline demonstrated comparable results, but was computed fully automatically. Conclusion: The proposed segmentation methods allow LGE MRI to be used as an objective assessment tool for localisation, visualisation and quantification of atrial scarring. version:1
arxiv-1705-09524 | Towards meaningful physics from generative models | http://arxiv.org/abs/1705.09524 | id:1705.09524 author:Marco Cristoforetti, Giuseppe Jurman, Andrea I. Nardelli, Cesare Furlanello category:hep-lat cond-mat.stat-mech cs.LG  published:2017-05-26 summary:In several physical systems, important properties characterizing the system itself are theoretically related with specific degrees of freedom. Although standard Monte Carlo simulations provide an effective tool to accurately reconstruct the physical configurations of the system, they are unable to isolate the different contributions corresponding to different degrees of freedom. Here we show that unsupervised deep learning can become a valid support to MC simulation, coupling useful insights in the phases detection task with good reconstruction performance. As a testbed we consider the 2D XY model, showing that a deep neural network based on variational autoencoders can detect the continuous Kosterlitz-Thouless (KT) transitions, and that, if endowed with the appropriate constrains, they generate configurations with meaningful physical content. version:1
arxiv-1705-09518 | A Sampling Theory Perspective of Graph-based Semi-supervised Learning | http://arxiv.org/abs/1705.09518 | id:1705.09518 author:Aamir Anis, Aly El Gamal, Salman Avestimehr, Antonio Ortega category:cs.LG  published:2017-05-26 summary:Graph-based methods have been quite successful in solving unsupervised and semi-supervised learning problems, as they provide a means to capture the underlying geometry of the dataset. It is often desirable for the constructed graph to satisfy two properties: first, data points that are similar in the feature space should be strongly connected on the graph, and second, the class label information should vary smoothly with respect to the graph, where smoothness is measured using the spectral properties of the graph Laplacian matrix. Recent works have justified some of these smoothness conditions by showing that they are strongly linked to the semi-supervised smoothness assumption and its variants. In this work, we reinforce this connection by viewing the problem from a graph sampling theoretic perspective, where class indicator functions are treated as bandlimited graph signals (in the eigenvector basis of the graph Laplacian) and label prediction as a bandlimited reconstruction problem. Our approach involves analyzing the bandwidth of class indicator signals generated from statistical data models with separable and nonseparable classes. These models are quite general and mimic the nature of most real-world datasets. Our results show that in the asymptotic limit, the bandwidth of any class indicator is also closely related to the geometry of the dataset. This allows one to theoretically justify the assumption of bandlimitedness of class indicator signals, thereby providing a sampling theoretic interpretation of graph-based semi-supervised classification. version:1
arxiv-1705-09516 | Biomedical Event Trigger Identification Using Bidirectional Recurrent Neural Network Based Models | http://arxiv.org/abs/1705.09516 | id:1705.09516 author:Patchigolla V S S Rahul, Sunil Kumar Sahu, Ashish Anand category:cs.CL  published:2017-05-26 summary:Biomedical events describe complex interactions between various biomedical entities. Event trigger is a word or a phrase which typically signifies the occurrence of an event. Event trigger identification is an important first step in all event extraction methods. However many of the current approaches either rely on complex hand-crafted features or consider features only within a window. In this paper we propose a method that takes the advantage of recurrent neural network (RNN) to extract higher level features present across the sentence. Thus hidden state representation of RNN along with word and entity type embedding as features avoid relying on the complex hand-crafted features generated using various NLP toolkits. Our experiments have shown to achieve state-of-art F1-score on Multi Level Event Extraction (MLEE) corpus. We have also performed category-wise analysis of the result and discussed the importance of various features in trigger identification task. version:1
arxiv-1705-09515 | ASR error management for improving spoken language understanding | http://arxiv.org/abs/1705.09515 | id:1705.09515 author:Edwin Simonnet, Sahar Ghannay, Nathalie Camelin, Yannick Estève, Renato De Mori category:cs.CL cs.AI cs.NE  published:2017-05-26 summary:This paper addresses the problem of automatic speech recognition (ASR) error detection and their use for improving spoken language understanding (SLU) systems. In this study, the SLU task consists in automatically extracting, from ASR transcriptions , semantic concepts and concept/values pairs in a e.g touristic information system. An approach is proposed for enriching the set of semantic labels with error specific labels and by using a recently proposed neural approach based on word embeddings to compute well calibrated ASR confidence measures. Experimental results are reported showing that it is possible to decrease significantly the Concept/Value Error Rate with a state of the art system, outperforming previously published results performance on the same experimental data. It also shown that combining an SLU approach based on conditional random fields with a neural encoder/decoder attention based architecture , it is possible to effectively identifying confidence islands and uncertain semantic output segments useful for deciding appropriate error handling actions by the dialogue manager strategy . version:1
arxiv-1705-09479 | PL-SLAM: a Stereo SLAM System through the Combination of Points and Line Segments | http://arxiv.org/abs/1705.09479 | id:1705.09479 author:Ruben Gomez-Ojeda, Francisco-Angel Moreno, Davide Scaramuzza, Javier Gonzalez-Jimenez category:cs.CV  published:2017-05-26 summary:Traditional approaches to stereo visual SLAM rely on point features to estimate the camera trajectory and build a map of the environment. In low-textured environments, though, it is often difficult to find a sufficient number of reliable point features and, as a consequence, the performance of such algorithms degrades. This paper proposes PL-SLAM, a stereo visual SLAM system that combines both points and line segments to work robustly in a wider variety of scenarios, particularly in those where point features are scarce or not well-distributed in the image. PL-SLAM leverages both points and segments at all the instances of the process: visual odometry, keyframe selection, bundle adjustment, etc. We contribute also with a loop closure procedure through a novel bag-of-words approach that exploits the combined descriptive power of the two kinds of features. Additionally, the resulting map is richer and more diverse in 3D elements, which can be exploited to infer valuable, high-level scene structures like planes, empty spaces, ground plane, etc. (not addressed in this work). Our proposal has been tested with several popular datasets (such as KITTI and EuRoC), and is compared to state of the art methods like ORB-SLAM, revealing superior performance in most of the experiments, while still running in real-time. An open source version of the PL-SLAM C++ code will be released for the benefit of the community. version:1
arxiv-1705-09476 | Learning Robust Features with Incremental Auto-Encoders | http://arxiv.org/abs/1705.09476 | id:1705.09476 author:Yanan Li, Donghui Wang category:cs.LG cs.CV  published:2017-05-26 summary:Automatically learning features, especially robust features, has attracted much attention in the machine learning community. In this paper, we propose a new method to learn non-linear robust features by taking advantage of the data manifold structure. We first follow the commonly used trick of the trade, that is learning robust features with artificially corrupted data, which are training samples with manually injected noise. Following the idea of the auto-encoder, we first assume features should contain much information to well reconstruct the input from its corrupted copies. However, merely reconstructing clean input from its noisy copies could make data manifold in the feature space noisy. To address this problem, we propose a new method, called Incremental Auto-Encoders, to iteratively denoise the extracted features. We assume the noisy manifold structure is caused by a diffusion process. Consequently, we reverse this specific diffusion process to further contract this noisy manifold, which results in an incremental optimization of model parameters . Furthermore, we show these learned non-linear features can be stacked into a hierarchy of features. Experimental results on real-world datasets demonstrate the proposed method can achieve better classification performances. version:1
arxiv-1705-09474 | Zero-Shot Learning with Generative Latent Prototype Model | http://arxiv.org/abs/1705.09474 | id:1705.09474 author:Yanan Li, Donghui Wang category:cs.CV  published:2017-05-26 summary:Zero-shot learning, which studies the problem of object classification for categories for which we have no training examples, is gaining increasing attention from community. Most existing ZSL methods exploit deterministic transfer learning via an in-between semantic embedding space. In this paper, we try to attack this problem from a generative probabilistic modelling perspective. We assume for any category, the observed representation, e.g. images or texts, is developed from a unique prototype in a latent space, in which the semantic relationship among prototypes is encoded via linear reconstruction. Taking advantage of this assumption, virtual instances of unseen classes can be generated from the corresponding prototype, giving rise to a novel ZSL model which can alleviate the domain shift problem existing in the way of direct transfer learning. Extensive experiments on three benchmark datasets show our proposed model can achieve state-of-the-art results. version:1
arxiv-1705-08386 | Better Text Understanding Through Image-To-Text Transfer | http://arxiv.org/abs/1705.08386 | id:1705.08386 author:Karol Kurach, Sylvain Gelly, Michal Jastrzebski, Philip Haeusser, Olivier Teytaud, Damien Vincent, Olivier Bousquet category:cs.CL cs.CV cs.LG  published:2017-05-23 summary:Generic text embeddings are successfully used in a variety of tasks. However, they are often learnt by capturing the co-occurrence structure from pure text corpora, resulting in limitations of their ability to generalize. In this paper, we explore models that incorporate visual information into the text representation. Based on comprehensive ablation studies, we propose a conceptually simple, yet well performing architecture. It outperforms previous multimodal approaches on a set of well established benchmarks. We also improve the state-of-the-art results for image-related text datasets, using orders of magnitude less data. version:2
arxiv-1705-09467 | Predicting Human Interaction via Relative Attention Model | http://arxiv.org/abs/1705.09467 | id:1705.09467 author:Yichao Yan, Bingbing Ni, Xiaokang Yang category:cs.CV  published:2017-05-26 summary:Predicting human interaction is challenging as the on-going activity has to be inferred based on a partially observed video. Essentially, a good algorithm should effectively model the mutual influence between the two interacting subjects. Also, only a small region in the scene is discriminative for identifying the on-going interaction. In this work, we propose a relative attention model to explicitly address these difficulties. Built on a tri-coupled deep recurrent structure representing both interacting subjects and global interaction status, the proposed network collects spatio-temporal information from each subject, rectified with global interaction information, yielding effective interaction representation. Moreover, the proposed network also unifies an attention module to assign higher importance to the regions which are relevant to the on-going action. Extensive experiments have been conducted on two public datasets, and the results demonstrate that the proposed relative attention network successfully predicts informative regions between interacting subjects, which in turn yields superior human interaction prediction accuracy. version:1
arxiv-1706-01758 | A WL-SPPIM Semantic Model for Document Classification | http://arxiv.org/abs/1706.01758 | id:1706.01758 author:Ming Li, Peilun Xiao, Ju Zhang category:cs.CL cs.AI  published:2017-05-26 summary:In this paper, we explore SPPIM-based text classification method, and the experiment reveals that the SPPIM method is equal to or even superior than SGNS method in text classification task on three international and standard text datasets, namely 20newsgroups, Reuters52 and WebKB. Comparing to SGNS, although SPPMI provides a better solution, it is not necessarily better than SGNS in text classification tasks. Based on our analysis, SGNS takes into the consideration of weight calculation during decomposition process, so it has better performance than SPPIM in some standard datasets. Inspired by this, we propose a WL-SPPIM semantic model based on SPPIM model, and experiment shows that WL-SPPIM approach has better classification and higher scalability in the text classification task compared with LDA, SGNS and SPPIM approaches. version:1
arxiv-1705-09451 | Algorithmic clothing: hybrid recommendation, from street-style-to-shop | http://arxiv.org/abs/1705.09451 | id:1705.09451 author:Y Qian, P Giaccone, M Sasdelli, E Vasquez, B Sengupta category:cs.CV  published:2017-05-26 summary:In this paper we detail Cortexica's (https://www.cortexica.com) recommendation framework -- particularly, we describe how a hybrid visual recommender system can be created by combining conditional random fields for segmentation and deep neural networks for object localisation and feature representation. The recommendation system that is built after localisation, segmentation and classification has two properties -- first, it is knowledge based in the sense that it learns pairwise preference/occurrence matrix by utilising knowledge from experts (images from fashion blogs) and second, it is content-based as it utilises a deep learning based framework for learning feature representation. Such a construct is especially useful when there is a scarcity of user preference data, that forms the foundation of many collaborative recommendation algorithms. version:1
arxiv-1705-09439 | Taste or Addiction?: Using Play Logs to Infer Song Selection Motivation | http://arxiv.org/abs/1705.09439 | id:1705.09439 author:Kosetsu Tsukuda, Masataka Goto category:cs.AI cs.LG  published:2017-05-26 summary:Online music services are increasing in popularity. They enable us to analyze people's music listening behavior based on play logs. Although it is known that people listen to music based on topic (e.g., rock or jazz), we assume that when a user is addicted to an artist, s/he chooses the artist's songs regardless of topic. Based on this assumption, in this paper, we propose a probabilistic model to analyze people's music listening behavior. Our main contributions are three-fold. First, to the best of our knowledge, this is the first study modeling music listening behavior by taking into account the influence of addiction to artists. Second, by using real-world datasets of play logs, we showed the effectiveness of our proposed model. Third, we carried out qualitative experiments and showed that taking addiction into account enables us to analyze music listening behavior from a new viewpoint in terms of how people listen to music according to the time of day, how an artist's songs are listened to by people, etc. We also discuss the possibility of applying the analysis results to applications such as artist similarity computation and song recommendation. version:1
arxiv-1705-09437 | Effective Sampling: Fast Segmentation Using Robust Geometric Model Fitting | http://arxiv.org/abs/1705.09437 | id:1705.09437 author:Ruwan Tennakoon, Alireza Sadri, Reza Hoseinnezhad, Alireza Bab-Hadiashar category:cs.CV  published:2017-05-26 summary:Identifying the underlying models in a set of data points contaminated by noise and outliers, leads to a highly complex multi-model fitting problem. This problem can be posed as a clustering problem by the projection of higher order affinities between data points into a graph, which can then be clustered using spectral clustering. Calculating all possible higher order affinities is computationally expensive. Hence in most cases only a subset is used. In this paper, we propose an effective sampling method to obtain a highly accurate approximation of the full graph required to solve multi-structural model fitting problems in computer vision. The proposed method is based on the observation that the usefulness of a graph for segmentation improves as the distribution of hypotheses (used to build the graph) approaches the distribution of actual parameters for the given data. In this paper, we approximate this actual parameter distribution using a k-th order statistics based cost function and the samples are generated using a greedy algorithm coupled with a data sub-sampling strategy. The experimental analysis shows that the proposed method is both accurate and computationally efficient compared to the state-of-the-art robust multi-model fitting techniques. The code is publicly available from https://github.com/RuwanT/model-fitting-cbs. version:1
arxiv-1705-09436 | Human Trajectory Prediction using Spatially aware Deep Attention Models | http://arxiv.org/abs/1705.09436 | id:1705.09436 author:Daksh Varshneya, G. Srinivasaraghavan category:cs.LG cs.AI  published:2017-05-26 summary:Trajectory Prediction of dynamic objects is a widely studied topic in the field of artificial intelligence. Thanks to a large number of applications like predicting abnormal events, navigation system for the blind, etc. there have been many approaches to attempt learning patterns of motion directly from data using a wide variety of techniques ranging from hand-crafted features to sophisticated deep learning models for unsupervised feature learning. All these approaches have been limited by problems like inefficient features in the case of hand crafted features, large error propagation across the predicted trajectory and no information of static artefacts around the dynamic moving objects. We propose an end to end deep learning model to learn the motion patterns of humans using different navigational modes directly from data using the much popular sequence to sequence model coupled with a soft attention mechanism. We also propose a novel approach to model the static artefacts in a scene and using these to predict the dynamic trajectories. The proposed method, tested on trajectories of pedestrians, consistently outperforms previously proposed state of the art approaches on a variety of large scale data sets. We also show how our architecture can be naturally extended to handle multiple modes of movement (say pedestrians, skaters, bikers and buses) simultaneously. version:1
