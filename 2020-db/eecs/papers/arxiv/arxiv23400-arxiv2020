arxiv-1611-10305 | Influential Node Detection in Implicit Social Networks using Multi-task Gaussian Copula Models | http://arxiv.org/abs/1611.10305 | id:1611.10305 author:Qunwei Li, Bhavya Kailkhura, Jayaraman J. Thiagarajan, Zhenliang Zhang, Pramod K. Varshney category:cs.SI cs.LG stat.ML  published:2016-11-30 summary:Influential node detection is a central research topic in social network analysis. Many existing methods rely on the assumption that the network structure is completely known \textit{a priori}. However, in many applications, network structure is unavailable to explain the underlying information diffusion phenomenon. To address the challenge of information diffusion analysis with incomplete knowledge of network structure, we develop a multi-task low rank linear influence model. By exploiting the relationships between contagions, our approach can simultaneously predict the volume (i.e. time series prediction) for each contagion (or topic) and automatically identify the most influential nodes for each contagion. The proposed model is validated using synthetic data and an ISIS twitter dataset. In addition to improving the volume prediction performance significantly, we show that the proposed approach can reliably infer the most influential users for specific contagions. version:1
arxiv-1611-08657 | Deep Constrained Local Models for Facial Landmark Detection | http://arxiv.org/abs/1611.08657 | id:1611.08657 author:Amir Zadeh, Tadas Baltru≈°aitis, Louis-Philippe Morency category:cs.CV cs.AI  published:2016-11-26 summary:Among the well-established methods for facial landmark detection is the family of Constrained Local Models (CLMs). An important part of CLM landmark alignment pipeline are the local detectors that estimate the alignment probability of each individual landmark over the facial region. In this paper we present Deep Constrained Local Model (DCLM) algorithm and the novel Dense-Projection Network (DPN) as a local detector. DPN is a deep neural network that consists of two important layers: Template Projection layer and Dense Aggregate layer. In Template Projection layer, patches of facial region are mapped to a higher dimensional space allowing the pose and rotation variations to be captured accurately. In Dense Aggregate layer an ensemble of experts is simulated within one network to make the landmark localization task more robust. In our extensive set of experiments we show that DPNs outperform previously proposed local detectors. Furthermore, we demonstrate that our proposed DCLM algorithm is state-of-the-art in facial landmark detection. We significantly outperform competitive baselines, that use both CLM-based and cascaded regression approaches, by a large margin on three publicly-available datasets for image and video landmark detection. version:3
arxiv-1611-10283 | Weighted bandits or: How bandits learn distorted values that are not expected | http://arxiv.org/abs/1611.10283 | id:1611.10283 author:Aditya Gopalan, L. A. Prashanth, Michael Fu, Steve Marcus category:cs.LG stat.ML  published:2016-11-30 summary:Motivated by models of human decision making proposed to explain commonly observed deviations from conventional expected value preferences, we formulate two stochastic multi-armed bandit problems with distorted probabilities on the cost distributions: the classic $K$-armed bandit and the linearly parameterized bandit. In both settings, we propose algorithms that are inspired by Upper Confidence Bound (UCB), incorporate cost distortions, and exhibit sublinear regret assuming \holder continuous weight distortion functions. For the $K$-armed setting, we show that the algorithm, called W-UCB, achieves problem-dependent regret $O(L^2 M^2 \log n/ \Delta^{\frac{2}{\alpha}-1})$, where $n$ is the number of plays, $\Delta$ is the gap in distorted expected value between the best and next best arm, $L$ and $\alpha$ are the H\"{o}lder constants for the distortion function, and $M$ is an upper bound on costs, and a problem-independent regret bound of $O((KL^2M^2)^{\alpha/2}n^{(2-\alpha)/2})$. We also present a matching lower bound on the regret, showing that the regret of W-UCB is essentially unimprovable over the class of H\"{o}lder-continuous weight distortions. For the linearly parameterized setting, we develop a new algorithm, a variant of the Optimism in the Face of Uncertainty Linear bandit (OFUL) algorithm called WOFUL (Weight-distorted OFUL), and show that it has regret $O(d\sqrt{n} \; \mbox{polylog}(n))$ with high probability, for sub-Gaussian cost distributions. Finally, numerical examples demonstrate the advantages resulting from using distortion-aware learning algorithms. version:1
arxiv-1611-10277 | Anchored Correlation Explanation: Topic Modeling with Minimal Domain Knowledge | http://arxiv.org/abs/1611.10277 | id:1611.10277 author:Ryan J. Gallagher, Kyle Reing, David Kale, Greg Ver Steeg category:cs.CL cs.IR cs.IT math.IT stat.ML  published:2016-11-30 summary:Popular approaches to topic modeling often invoke the use of probabilistic generative models, such as Latent Dirichlet Allocation (LDA). While such models have enjoyed widespread use and proven fruitful, these models or generalizing them to incorporate human input requires detailed and often unrealistic assumptions about the data generating process. We introduce a new approach to topic modeling via Correlation Explanation (CorEx), which leverages an information-theoretic framework to bypass typical topic modeling assumptions. Using two challenging, real-world datasets, we demonstrate that CorEx yields results that are comparable to LDA in terms of semantic coherence and document classification. We then devise a flexible methodology for incorporating word-level domain knowledge into CorEx by introducing anchor words in a manner reminiscent of the information bottleneck. Augmenting CorEx with anchor words allows the topic model to be guided with minimal human intervention towards topics that do not naturally emerge. Furthermore, we show that these new topics are often highly coherent and act as better predictors in document classification. version:1
arxiv-1611-10258 | Reliably Learning the ReLU in Polynomial Time | http://arxiv.org/abs/1611.10258 | id:1611.10258 author:Surbhi Goel, Varun Kanade, Adam Klivans, Justin Thaler category:cs.LG stat.ML  published:2016-11-30 summary:We give the first dimension-efficient algorithms for learning Rectified Linear Units (ReLUs), which are functions of the form $\mathbf{x} \mapsto \max(0, \mathbf{w} \cdot \mathbf{x})$ with $\mathbf{w} \in \mathbb{S}^{n-1}$. Our algorithm works in the challenging Reliable Agnostic learning model of Kalai, Kanade, and Mansour (2009) where the learner is given access to a distribution $\cal{D}$ on labeled examples but the labeling may be arbitrary. We construct a hypothesis that simultaneously minimizes the false-positive rate and the loss on inputs given positive labels by $\cal{D}$, for any convex, bounded, and Lipschitz loss function. The algorithm runs in polynomial-time (in $n$) with respect to any distribution on $\mathbb{S}^{n-1}$ (the unit sphere in $n$ dimensions) and for any error parameter $\epsilon = \Omega(1/\log n)$ (this yields a PTAS for a question raised by F. Bach on the complexity of maximizing ReLUs). These results are in contrast to known efficient algorithms for reliably learning linear threshold functions, where $\epsilon$ must be $\Omega(1)$ and strong assumptions are required on the marginal distribution. We can compose our results to obtain the first set of efficient algorithms for learning constant-depth networks of ReLUs. Our techniques combine kernel methods and polynomial approximations with a "dual-loss" approach to convex programming. As a byproduct we obtain a number of applications including the first set of efficient algorithms for "convex piecewise-linear fitting" and the first efficient algorithms for noisy polynomial reconstruction of low-weight polynomials on the unit sphere. version:1
arxiv-1611-10242 | Likelihood-free inference by penalised logistic regression | http://arxiv.org/abs/1611.10242 | id:1611.10242 author:Ritabrata Dutta, Jukka Corander, Samuel Kaski, Michael U. Gutmann category:stat.ML stat.CO stat.ME  published:2016-11-30 summary:We consider the problem of parametric statistical inference when likelihood computations are prohibitively expensive but sampling from the model is possible. Several so-called likelihood-free methods have been developed to perform inference in the absence of a likelihood function. The popular synthetic likelihood approach infers the parameters by modelling summary statistics of the data by a Gaussian probability distribution. In another popular approach called approximate Bayesian computation, the inference is performed by identifying parameter values for which the summary statistics of the simulated data are close to the observed data. Synthetic likelihood is easier to use as no measure of "closeness" is required but the Gaussianity assumption is often limiting. Moreover, both approaches require judiciously chosen summary statistics. We here present an alternative inference approach that is as easy to use as synthetic likelihood but not as restricted in its assumptions, and that naturally enables automatic selection of relevant summary statistic from a large set of candidates. The basic idea is to frame the problem of estimating the posterior as a problem of estimating the ratio between the data generating distribution and the marginal distribution. This problem can be solved by logistic regression and including regularizing penalty terms enables automatic selection of the summary statistics relevant to the inference task. We illustrate the general theory on toy problems and use it to perform inference for stochastic nonlinear dynamical systems. version:1
arxiv-1611-10229 | End-to-End Training of Hybrid CNN-CRF Models for Stereo | http://arxiv.org/abs/1611.10229 | id:1611.10229 author:Patrick Kn√∂belreiter, Christian Reinbacher, Alexander Shekhovtsov, Thomas Pock category:cs.CV  published:2016-11-30 summary:We propose a novel method for stereo estimation, combining advantages of convolutional neural networks (CNNs) and optimization-based approaches. The optimization, posed as a conditional random field (CRF), takes local matching costs and consistency-enforcing (smoothness) costs as inputs, both estimated by CNN blocks. To perform the inference in the CRF we use an approach based on linear programming relaxation with a fixed number of iterations. We address the challenging problem of training this hybrid model end-to-end. We show that in the discriminative formulation (structured support vector machine) the training is practically feasible. The trained hybrid model with shallow CNNs is comparable to state-of-the-art deep models in both time and performance. The optimization part efficiently replaces sophisticated and not jointly trainable (but commonly applied) post-processing steps by a trainable, well-understood model. version:1
arxiv-1611-10228 | Behavior-Based Machine-Learning: A Hybrid Approach for Predicting Human Decision Making | http://arxiv.org/abs/1611.10228 | id:1611.10228 author:Gali Noti, Effi Levi, Yoav Kolumbus, Amit Daniely category:cs.LG cs.GT J.4; I.2.6; H.1.2  published:2016-11-30 summary:A large body of work in behavioral fields attempts to develop models that describe the way people, as opposed to rational agents, make decisions. A recent Choice Prediction Competition (2015) challenged researchers to suggest a model that captures 14 classic choice biases and can predict human decisions under risk and ambiguity. The competition focused on simple decision problems, in which human subjects were asked to repeatedly choose between two gamble options. In this paper we present our approach for predicting human decision behavior: we suggest to use machine learning algorithms with features that are based on well-established behavioral theories. The basic idea is that these psychological features are essential for the representation of the data and are important for the success of the learning process. We implement a vanilla model in which we train SVM models using behavioral features that rely on the psychological properties underlying the competition baseline model. We show that this basic model captures the 14 choice biases and outperforms all the other learning-based models in the competition. The preliminary results suggest that such hybrid models can significantly improve the prediction of human decision making, and are a promising direction for future research. version:1
arxiv-1611-10215 | Unit Commitment using Nearest Neighbor as a Short-Term Proxy | http://arxiv.org/abs/1611.10215 | id:1611.10215 author:Gal Dalal, Elad Gilboa, Shie Mannor, Louis Wehenkel category:cs.LG cs.AI  published:2016-11-30 summary:We devise the Unit Commitment Nearest Neighbor (UCNN) algorithm to be used as a proxy for quickly approximating outcomes of short-term decisions, to make tractable hierarchical long-term assessment and planning for large power systems. Experimental results on an updated version of IEEE-RTS96 show high accuracy measured on operational cost, achieved in run-times that are lower in several orders of magnitude than the traditional approach. version:1
arxiv-1611-10195 | POSEidon: Face-from-Depth for Driver Pose Estimation | http://arxiv.org/abs/1611.10195 | id:1611.10195 author:Guido Borghi, Marco Venturelli, Roberto Vezzani, Rita Cucchiara category:cs.CV  published:2016-11-30 summary:Fast and accurate upper-body and head pose estimation is a key task for automatic monitoring of driver attention, a challenging context characterized by severe illumination changes, occlusions and extreme poses. In this work, we present a new deep learning framework for head localization and pose estimation on depth images. The core of the proposal is a regression neural network, called POSEidon, which is composed of three independent convolutional nets followed by a fusion layer, specially conceived for understanding the pose by depth. In addition, to recover the intrinsic value of face appearance for understanding head position and orientation, we propose a new Face-from-Depth approach for learning image faces from depth. Results in face reconstruction are qualitatively impressive. We test the proposed framework on two public datasets, namely Biwi Kinect Head Pose and ICT-3DHP, and on Pandora, a new challenging dataset mainly inspired by the automotive setup. Results show that our method overcomes all recent state-of-art works, running in real time at more than 30 frames per second. version:1
arxiv-1611-10176 | Effective Quantization Methods for Recurrent Neural Networks | http://arxiv.org/abs/1611.10176 | id:1611.10176 author:Qinyao He, He Wen, Shuchang Zhou, Yuxin Wu, Cong Yao, Xinyu Zhou, Yuheng Zou category:cs.LG cs.CV  published:2016-11-30 summary:Reducing bit-widths of weights, activations, and gradients of a Neural Network can shrink its storage size and memory usage, and also allow for faster training and inference by exploiting bitwise operations. However, previous attempts for quantization of RNNs show considerable performance degradation when using low bit-width weights and activations. In this paper, we propose methods to quantize the structure of gates and interlinks in LSTM and GRU cells. In addition, we propose balanced quantization methods for weights to further reduce performance degradation. Experiments on PTB and IMDB datasets confirm effectiveness of our methods as performances of our models match or surpass the previous state-of-the-art of quantized RNN. version:1
arxiv-1611-10171 | Stability selection for component-wise gradient boosting in multiple dimensions | http://arxiv.org/abs/1611.10171 | id:1611.10171 author:Janek Thomas, Andreas Mayr, Bernd Bischl, Matthias Schmid, Adam Smith, Benjamin Hofner category:stat.CO stat.ML  published:2016-11-30 summary:We present a new algorithm for boosting generalized additive models for location, scale and shape (GAMLSS) that allows to incorporate stability selection, an increasingly popular way to obtain stable sets of covariates while controlling the per-family error rate (PFER). The model is fitted repeatedly to subsampled data and variables with high selection frequencies are extracted. To apply stability selection to boosted GAMLSS, we develop a new "noncyclical" fitting algorithm that incorporates an additional selection step of the best-fitting distribution parameter in each iteration. This new algorithms has the additional advantage that optimizing the tuning parameters of boosting is reduced from a multi-dimensional to a one-dimensional problem with vastly decreased complexity. The performance of the novel algorithm is evaluated in an extensive simulation study. We apply this new algorithm to a study to estimate abundance of common eider in Massachusetts, USA, featuring excess zeros, overdispersion, non-linearity and spatio-temporal structures. Eider abundance is estimated via boosted GAMLSS, allowing both mean and overdispersion to be regressed on covariates. Stability selection is used to obtain a sparse set of stable predictors. version:1
arxiv-1611-10152 | Combining Data-driven and Model-driven Methods for Robust Facial Landmark Detection | http://arxiv.org/abs/1611.10152 | id:1611.10152 author:Hongwen Zhang, Qi Li, Zhenan Sun category:cs.CV  published:2016-11-30 summary:Facial landmark detection is an important but challenging task for real-world computer vision applications. This paper proposes an accurate and robust approach for facial landmark detection by combining data-driven and model-driven methods. Firstly, a fully convolutional network (FCN) is trained to generate response maps of all facial landmark points. Such a data-driven method can make full use of holistic information in a facial image for global estimation of facial landmarks. Secondly, the maximum points in the response maps are fitted with a pre-trained point distribution model (PDM) to generate initial facial landmark shape. Such a model-driven method can correct the location errors of outliers by considering shape prior information. Thirdly, a weighted version of Regularized Landmark Mean-Shift (RLMS) is proposed to fine-tune facial landmark shapes iteratively. The weighting strategy is based on the confidence of convolutional response maps so that FCN is integrated into the framework of Constrained Local Model (CLM). Such an Estimation-Correction-Tuning process perfectly combines the global robustness advantage of data-driven method (FCN), outlier correction advantage of model-driven method (PDM) and non-parametric optimization advantage of RLMS. The experimental results demonstrate that the proposed approach outperforms state-of-the-art solutions on the 300-W dataset. Our approach is well-suited for face images with large poses, exaggerated expression, and occlusions. version:1
arxiv-1612-00312 | Classifiers for centrality determination in proton-nucleus and nucleus-nucleus collisions | http://arxiv.org/abs/1612.00312 | id:1612.00312 author:Igor Altsybeev, Vladimir Kovalenko category:physics.data-an nucl-ex stat.ML  published:2016-11-30 summary:Centrality, as a geometrical property of the collision, is crucial for the physical interpretation of nucleus-nucleus and proton-nucleus experimental data. However, it cannot be directly accessed in event-by-event data analysis. Common methods for centrality estimation in A-A and p-A collisions usually rely on a single detector (either on the signal in zero-degree calorimeters or on the multiplicity in some semi-central rapidity range). In the present work, we made an attempt to develop an approach for centrality determination that is based on machine-learning techniques and utilizes information from several detector subsystems simultaneously. Different event classifiers are suggested and evaluated for their selectivity power in terms of the number of nucleons-participants and the impact parameter of the collision. Finer centrality resolution may allow to reduce impact from so-called volume fluctuations on physical observables being studied in heavy-ion experiments like ALICE at the LHC and fixed target experiment NA61/SHINE on SPS. version:1
arxiv-1611-10122 | Deep encoding of etymological information in TEI | http://arxiv.org/abs/1611.10122 | id:1611.10122 author:Jack Bowers, Laurent Romary category:cs.CL  published:2016-11-30 summary:This paper aims to provide a comprehensive modeling and representation of etymological data in digital dictionaries. The purpose is to integrate in one coherent framework both digital representations of legacy dictionaries, and also born-digital lexical databases that are constructed manually or semi-automatically. We want to propose a systematic and coherent set of modeling principles for a variety of etymological phenomena that may contribute to the creation of a continuum between existing and future lexical constructs, where anyone interested in tracing the history of words and their meanings will be able to seamlessly query lexical resources.Instead of designing an ad hoc model and representation language for digital etymological data, we will focus on identifying all the possibilities offered by the TEI guidelines for the representation of lexical information. version:1
arxiv-1611-10104 | User Dependent Features in Online Signature Verification | http://arxiv.org/abs/1611.10104 | id:1611.10104 author:D. S. Guru, K. S. Manjunatha, S. Manjunath category:cs.CV  published:2016-11-30 summary:In this paper, we propose a novel approach for verification of on-line signatures based on user dependent feature selection and symbolic representation. Unlike other signature verification methods, which work with same features for all users, the proposed approach introduces the concept of user dependent features. It exploits the typicality of each and every user to select different features for different users. Initially all possible features are extracted for all users and a method of feature selection is employed for selecting user dependent features. The selected features are clustered using Fuzzy C means algorithm. In order to preserve the intra-class variation within each user, we recommend to represent each cluster in the form of an interval valued symbolic feature vector. A method of signature verification based on the proposed cluster based symbolic representation is also presented. Extensive experimentations are conducted on MCYT-100 User (DB1) and MCYT-330 User (DB2) online signature data sets to demonstrate the effectiveness of the proposed novel approach. version:1
arxiv-1611-09803 | InterpoNet, A brain inspired neural network for optical flow dense interpolation | http://arxiv.org/abs/1611.09803 | id:1611.09803 author:Shay Zweig, Lior Wolf category:cs.CV  published:2016-11-29 summary:Sparse-to-dense interpolation for optical flow is a fundamental phase in the pipeline of most of the leading optical flow estimation algorithms. The current state-of-the-art method for interpolation, EpicFlow, is a local average method based on an edge aware geodesic distance. We propose a new data-driven sparse-to-dense interpolation algorithm based on a fully convolutional network. We draw inspiration from the filling-in process in the visual cortex and introduce lateral dependencies between neurons and multi-layer supervision into our learning process. We also show the importance of the image contour to the learning process. Our method is robust and outperforms EpicFlow on competitive optical flow benchmarks with several underlying matching algorithms. This leads to state-of-the-art performance on the Sintel and KITTI 2012 benchmarks. version:2
arxiv-1611-10080 | Wider or Deeper: Revisiting the ResNet Model for Visual Recognition | http://arxiv.org/abs/1611.10080 | id:1611.10080 author:Zifeng Wu, Chunhua Shen, Anton van den Hengel category:cs.CV  published:2016-11-30 summary:The trend towards increasingly deep neural networks has been driven by a general observation that increasing depth increases the performance of a network. Recently, however, evidence has been amassing that simply increasing depth may not be the best way to increase performance, particularly given other limitations. Investigations into deep residual networks have also suggested that they may not in fact be operating as a single deep network, but rather as an ensemble of many relatively shallow networks. We examine these issues, and in doing so arrive at a new interpretation of the unravelled view of deep residual networks which explains some of the behaviours that have been observed experimentally. As a result, we are able to derive a new, shallower, architecture of residual networks which significantly outperforms much deeper models such as ResNet-200 on the ImageNet classification dataset. We also show that this performance is transferable to other problem domains by developing a semantic segmentation approach which outperforms the state-of-the-art by a remarkable margin on datasets including PASCAL VOC, PASCAL Context, and Cityscapes. The architecture that we propose thus outperforms its comparators, including very deep ResNets, and yet is more efficient in memory use and sometimes also in training time. The code and models are available at https://github.com/itijyou/ademxapp version:1
arxiv-1611-10073 | Complex-valued Gaussian Process Regression for Time Series Analysis | http://arxiv.org/abs/1611.10073 | id:1611.10073 author:Luca Ambrogioni, Eric Maris category:stat.ML  published:2016-11-30 summary:The construction of a complex-valued signal is an important step in many time series analysis techniques. In this paper, we model the observable real-valued signal as the real part of a latent complex-valued Gaussian process. To construct a meaningful imaginary part, we impose the constraint that, in expectation, the real and the imaginary part of the covariance function are in quadrature relation. Through an analysis of simulated chirplets and stochastic oscillations, we show that the Gaussian process complex-valued signal provides a much better estimate of the instantaneous amplitude and frequency than the established approaches. Furthermore, the complex-valued Gaussian process regression allows to incorporate prior information about the structure in signal and noise and thereby to tailor the analysis to the features of the signal. As a example, we analyze the non-stationary dynamics of brain oscillations in the alpha band, as measured using magneto-encephalography version:1
arxiv-1611-10052 | Performance Tuning of Hadoop MapReduce: A Noisy Gradient Approach | http://arxiv.org/abs/1611.10052 | id:1611.10052 author:Sandeep Kumar, Sindhu Padakandla, Chandrashekar L, Priyank Parihar, K Gopinath, Shalabh Bhatnagar category:cs.DC cs.LG  published:2016-11-30 summary:Hadoop MapReduce is a framework for distributed storage and processing of large datasets that is quite popular in big data analytics. It has various configuration parameters (knobs) which play an important role in deciding the performance i.e., the execution time of a given big data processing job. Default values of these parameters do not always result in good performance and hence it is important to tune them. However, there is inherent difficulty in tuning the parameters due to two important reasons - firstly, the parameter search space is large and secondly, there are cross-parameter interactions. Hence, there is a need for a dimensionality-free method which can automatically tune the configuration parameters by taking into account the cross-parameter dependencies. In this paper, we propose a novel Hadoop parameter tuning methodology, based on a noisy gradient algorithm known as the simultaneous perturbation stochastic approximation (SPSA). The SPSA algorithm tunes the parameters by directly observing the performance of the Hadoop MapReduce system. The approach followed is independent of parameter dimensions and requires only $2$ observations per iteration while tuning. We demonstrate the effectiveness of our methodology in achieving good performance on popular Hadoop benchmarks namely \emph{Grep}, \emph{Bigram}, \emph{Inverted Index}, \emph{Word Co-occurrence} and \emph{Terasort}. Our method, when tested on a 25 node Hadoop cluster shows 66\% decrease in execution time of Hadoop jobs on an average, when compared to the default configuration. Further, we also observe a reduction of 45\% in execution times, when compared to prior methods. version:1
arxiv-1611-10041 | Subsampled online matrix factorization with convergence guarantees | http://arxiv.org/abs/1611.10041 | id:1611.10041 author:Arthur Mensch, Julien Mairal, Ga√´l Varoquaux, Bertrand Thirion category:math.OC stat.ML  published:2016-11-30 summary:We present a matrix factorization algorithm that scales to input matrices that are large in both dimensions (i.e., that contains morethan 1TB of data). The algorithm streams the matrix columns while subsampling them, resulting in low complexity per iteration andreasonable memory footprint. In contrast to previous online matrix factorization methods, our approach relies on low-dimensional statistics from past iterates to control the extra variance introduced by subsampling. We present a convergence analysis that guarantees us to reach a stationary point of the problem. Large speed-ups can be obtained compared to previous online algorithms that do not perform subsampling, thanks to the feature redundancy that often exists in high-dimensional settings. version:1
arxiv-1611-10038 | Towards Accurate Word Segmentation for Chinese Patents | http://arxiv.org/abs/1611.10038 | id:1611.10038 author:Si Li, Nianwen Xue category:cs.CL  published:2016-11-30 summary:A patent is a property right for an invention granted by the government to the inventor. An invention is a solution to a specific technological problem. So patents often have a high concentration of scientific and technical terms that are rare in everyday language. The Chinese word segmentation model trained on currently available everyday language data sets performs poorly because it cannot effectively recognize these scientific and technical terms. In this paper we describe a pragmatic approach to Chinese word segmentation on patents where we train a character-based semi-supervised sequence labeling model by extracting features from a manually segmented corpus of 142 patents, enhanced with information extracted from the Chinese TreeBank. Experiments show that the accuracy of our model reached 95.08% (F1 score) on a held-out test set and 96.59% on development set, compared with an F1 score of 91.48% on development set if the model is trained on the Chinese TreeBank. We also experimented with some existing domain adaptation techniques, the results show that the amount of target domain data and the selected features impact the performance of the domain adaptation techniques. version:1
arxiv-1611-10031 | Active Deep Learning for Classification of Hyperspectral Images | http://arxiv.org/abs/1611.10031 | id:1611.10031 author:Peng Liu, Hui Zhang, Kie B. Eom category:cs.LG  published:2016-11-30 summary:Active deep learning classification of hyperspectral images is considered in this paper. Deep learning has achieved success in many applications, but good-quality labeled samples are needed to construct a deep learning network. It is expensive getting good labeled samples in hyperspectral images for remote sensing applications. An active learning algorithm based on a weighted incremental dictionary learning is proposed for such applications. The proposed algorithm selects training samples that maximize two selection criteria, namely representative and uncertainty. This algorithm trains a deep network efficiently by actively selecting training samples at each iteration. The proposed algorithm is applied for the classification of hyperspectral images, and compared with other classification algorithms employing active learning. It is shown that the proposed algorithm is efficient and effective in classifying hyperspectral images. version:1
arxiv-1611-10017 | Fast Supervised Discrete Hashing and its Analysis | http://arxiv.org/abs/1611.10017 | id:1611.10017 author:Gou Koutaki, Keiichiro Shirai, Mitsuru Ambai category:cs.CV cs.LG cs.MM  published:2016-11-30 summary:In this paper, we propose a learning-based supervised discrete hashing method. Binary hashing is widely used for large-scale image retrieval as well as video and document searches because the compact representation of binary code is essential for data storage and reasonable for query searches using bit-operations. The recently proposed Supervised Discrete Hashing (SDH) efficiently solves mixed-integer programming problems by alternating optimization and the Discrete Cyclic Coordinate descent (DCC) method. We show that the SDH model can be simplified without performance degradation based on some preliminary experiments; we call the approximate model for this the "Fast SDH" (FSDH) model. We analyze the FSDH model and provide a mathematically exact solution for it. In contrast to SDH, our model does not require an alternating optimization algorithm and does not depend on initial values. FSDH is also easier to implement than Iterative Quantization (ITQ). Experimental results involving a large-scale database showed that FSDH outperforms conventional SDH in terms of precision, recall, and computation time. version:1
arxiv-1611-10012 | Speed/accuracy trade-offs for modern convolutional object detectors | http://arxiv.org/abs/1611.10012 | id:1611.10012 author:Jonathan Huang, Vivek Rathod, Chen Sun, Menglong Zhu, Anoop Korattikara, Alireza Fathi, Ian Fischer, Zbigniew Wojna, Yang Song, Sergio Guadarrama, Kevin Murphy category:cs.CV  published:2016-11-30 summary:In this paper, we study the trade-off between accuracy and speed when building an object detection system based on convolutional neural networks. We consider three main families of detectors --- Faster R-CNN, R-FCN and SSD --- which we view as "meta-architectures". Each of these can be combined with different kinds of feature extractors, such as VGG, Inception or ResNet. In addition, we can vary other parameters, such as the image resolution, and the number of box proposals. We develop a unified framework (in Tensorflow) that enables us to perform a fair comparison between all of these variants. We analyze the performance of many different previously published model combinations, as well as some novel ones, and thus identify a set of models which achieve different points on the speed-accuracy tradeoff curve, ranging from fast models, suitable for use on a mobile phone, to a much slower model that achieves a new state of the art on the COCO detection challenge. version:1
arxiv-1611-10010 | Deep Cuboid Detection: Beyond 2D Bounding Boxes | http://arxiv.org/abs/1611.10010 | id:1611.10010 author:Debidatta Dwibedi, Tomasz Malisiewicz, Vijay Badrinarayanan, Andrew Rabinovich category:cs.CV  published:2016-11-30 summary:We present a Deep Cuboid Detector which takes a consumer-quality RGB image of a cluttered scene and localizes all 3D cuboids (box-like objects). Contrary to classical approaches which fit a 3D model from low-level cues like corners, edges, and vanishing points, we propose an end-to-end deep learning system to detect cuboids across many semantic categories (e.g., ovens, shipping boxes, and furniture). We localize cuboids with a 2D bounding box, and simultaneously localize the cuboid's corners, effectively producing a 3D interpretation of box-like objects. We refine keypoints by pooling convolutional features iteratively, improving the baseline method significantly. Our deep learning cuboid detector is trained in an end-to-end fashion and is suitable for real-time applications in augmented reality (AR) and robotics. version:1
arxiv-1611-08664 | Semi-supervised Learning using Denoising Autoencoders for Brain Lesion Detection and Segmentation | http://arxiv.org/abs/1611.08664 | id:1611.08664 author:Varghese Alex, Kiran Vaidhya, Subramaniam Thirunavukkarasu, Chandrasekharan Kesavdas, Ganapathy Krishnamurthi category:cs.CV  published:2016-11-26 summary:The work presented explores the use of denoising autoencoders (DAE) for brain lesion detection, segmentation and false positive reduction. Stacked denoising autoencoders (SDAE) were pre-trained using a large number of unlabeled patient volumes and fine tuned with patches drawn from a limited number of patients (n=20, 40, 65). The results show negligible loss in performance even when SDAE was fine tuned using 20 patients. Low grade glioma (LGG) segmentation was achieved using a transfer learning approach wherein a network pre-trained with High Grade Glioma (HGG) data was fine tuned using LGG image patches. The weakly supervised SDAE (for HGG) and transfer learning based LGG network were also shown to generalize well and provide good segmentation on unseen BraTS 2013 & BraTS 2015 test data. An unique contribution includes a single layer DAE, referred to as novelty detector(ND). ND was trained to accurately reconstruct non-lesion patches using a mean squared error loss function. The reconstruction error maps of test data were used to identify regions containing lesions. The error maps were shown to assign unique error distributions to various constituents of the glioma, enabling localization. The ND learns the non-lesion brain accurately as it was also shown to provide good segmentation performance on ischemic brain lesions in images from a different database. version:3
arxiv-1611-09978 | Modeling Relationships in Referential Expressions with Compositional Modular Networks | http://arxiv.org/abs/1611.09978 | id:1611.09978 author:Ronghang Hu, Marcus Rohrbach, Jacob Andreas, Trevor Darrell, Kate Saenko category:cs.CV  published:2016-11-30 summary:People often refer to entities in an image in terms of their relationships with other entities. For example, "the black cat sitting under the table" refers to both a "black cat" entity and its relationship with another "table" entity. Understanding these relationships is essential for interpreting and grounding such natural language expressions. Most prior work focuses on either grounding entire referential expressions holistically to one region, or localizing relationships based on a fixed set of categories. In this paper we instead present a modular deep architecture capable of analyzing referential expressions into their component parts, identifying entities and relationships mentioned in the input expression and grounding them all in the scene. We call this approach Compositional Modular Networks (CMNs): a novel architecture that learns linguistic analysis and visual inference end-to-end. Our approach is built around two types of neural modules that inspect local regions and pairwise interactions between regions. We evaluate CMNs on multiple referential expression datasets, outperforming state-of-the-art approaches on all tasks. version:1
arxiv-1611-09972 | Nonparametric Regression with Adaptive Truncation via a Convex Hierarchical Penalty | http://arxiv.org/abs/1611.09972 | id:1611.09972 author:Asad Haris, Ali Shojaie, Noah Simon category:stat.ME math.ST stat.ML stat.TH  published:2016-11-30 summary:We consider the problem of non-parametric regression with a potentially large number of covariates. We propose a convex, penalized estimation framework that is particularly well-suited for high-dimensional sparse additive models. The proposed approach combines appealing features of finite basis representation and smoothing penalties for non-parametric estimation. In particular, in the case of additive models, a finite basis representation provides a parsimonious representation for fitted functions but is not adaptive when component functions posses different levels of complexity. On the other hand, a smoothing spline type penalty on the component functions is adaptive but does not offer a parsimonious representation of the estimated function. The proposed approach simultaneously achieves parsimony and adaptivity in a computationally efficient framework. We demonstrate these properties through empirical studies on both real and simulated datasets. We show that our estimator converges at the minimax rate for functions within a hierarchical class. We further establish minimax rates for a large class of sparse additive models. The proposed algorithm is implemented using an efficient algorithm that scales similarly to the Lasso with the number of covariates and samples size. version:1
arxiv-1611-09448 | The Upper Bound on Knots in Neural Networks | http://arxiv.org/abs/1611.09448 | id:1611.09448 author:Kevin K. Chen category:stat.ML cs.LG  published:2016-11-29 summary:Neural networks with rectified linear unit activations are essentially multivariate linear splines. As such, one of many ways to measure the "complexity" or "expressivity" of a neural network is to count the number of knots in the spline model. We study the number of knots in fully-connected feedforward neural networks with rectified linear unit activation functions. We intentionally keep the neural networks very simple, so as to make theoretical analyses more approachable. An induction on the number of layers $l$ reveals a tight upper bound on the number of knots in $\mathbb{R} \to \mathbb{R}^p$ deep neural networks. With $n_i \gg 1$ neurons in layer $i = 1, \dots, l$, the upper bound is approximately $n_1 \dots n_l$. We then show that the exact upper bound is tight, and we demonstrate the upper bound with an example. The purpose of these analyses is to pave a path for understanding the behavior of general $\mathbb{R}^q \to \mathbb{R}^p$ neural networks. version:2
arxiv-1611-09969 | High-Resolution Image Inpainting using Multi-Scale Neural Patch Synthesis | http://arxiv.org/abs/1611.09969 | id:1611.09969 author:Chao Yang, Xin Lu, Zhe Lin, Eli Shechtman, Oliver Wang, Hao Li category:cs.CV  published:2016-11-30 summary:Recent advances in deep learning have shown exciting promise in filling large holes in natural images with semantically plausible and context aware details, impacting fundamental image manipulation tasks such as object removal. While these learning-based methods are significantly more effective in capturing high-level features than prior techniques, they can only handle very low-resolution inputs due to memory limitations and difficulty in training. Even for slightly larger images, the inpainted regions would appear blurry and unpleasant boundaries become visible. We propose a multi-scale neural patch synthesis approach based on joint optimization of image content and texture constraints, which not only preserves contextual structures but also produces high-frequency details by matching and adapting patches with the most similar mid-layer feature correlations of a deep classification network. We evaluate our method on the ImageNet and Paris Streetview datasets and achieved state-of-the-art inpainting accuracy. We show our approach produces sharper and more coherent results than prior methods, especially for high-resolution images. version:1
arxiv-1611-09967 | Sequential Person Recognition in Photo Albums with a Recurrent Network | http://arxiv.org/abs/1611.09967 | id:1611.09967 author:Yao Li, Guosheng Lin, Bohan Zhuang, Lingqiao Liu, Chunhua Shen, Anton van den Hengel category:cs.CV  published:2016-11-30 summary:Recognizing the identities of people in everyday photos is still a very challenging problem for machine vision, due to non-frontal faces, changes in clothing, location, lighting and similar. Recent studies have shown that rich relational information between people in the same photo can help in recognizing their identities. In this work, we propose to model the relational information between people as a sequence prediction task. At the core of our work is a novel recurrent network architecture, in which relational information between instances' labels and appearance are modeled jointly. In addition to relational cues, scene context is incorporated in our sequence prediction model with no additional cost. In this sense, our approach is a unified framework for modeling both contextual cues and visual appearance of person instances. Our model is trained end-to-end with a sequence of annotated instances in a photo as inputs, and a sequence of corresponding labels as targets. We demonstrate that this simple but elegant formulation achieves state-of-the-art performance on the newly released People In Photo Albums (PIPA) dataset. version:1
arxiv-1611-09961 | Semantic Facial Expression Editing using Autoencoded Flow | http://arxiv.org/abs/1611.09961 | id:1611.09961 author:Raymond Yeh, Ziwei Liu, Dan B Goldman, Aseem Agarwala category:cs.CV  published:2016-11-30 summary:High-level manipulation of facial expressions in images --- such as changing a smile to a neutral expression --- is challenging because facial expression changes are highly non-linear, and vary depending on the appearance of the face. We present a fully automatic approach to editing faces that combines the advantages of flow-based face manipulation with the more recent generative capabilities of Variational Autoencoders (VAEs). During training, our model learns to encode the flow from one expression to another over a low-dimensional latent space. At test time, expression editing can be done simply using latent vector arithmetic. We evaluate our methods on two applications: 1) single-image facial expression editing, and 2) facial expression interpolation between two images. We demonstrate that our method generates images of higher perceptual quality than previous VAE and flow-based methods. version:1
arxiv-1611-09960 | Attend in groups: a weakly-supervised deep learning framework for learning from web data | http://arxiv.org/abs/1611.09960 | id:1611.09960 author:Bohan Zhuang, Lingqiao Liu, Yao Li, Chunhua Shen, Ian Reid category:cs.CV  published:2016-11-30 summary:Large-scale datasets have driven the rapid development of deep neural networks for visual recognition. However, annotating a massive dataset is expensive and time-consuming. Web images and their labels are, in comparison, much easier to obtain, but direct training on such automatically harvested images can lead to unsatisfactory performance, because the noisy labels of Web images adversely affect the learned recognition models. To address this drawback we propose an end-to-end weakly-supervised deep learning framework which is robust to the label noise in Web images. The proposed framework relies on two unified strategies -- random grouping and attention -- to effectively reduce the negative impact of noisy web image annotations. Specifically, random grouping stacks multiple images into a single training instance and thus increases the labeling accuracy at the instance level. Attention, on the other hand, suppresses the noisy signals from both incorrectly labeled images and less discriminative image regions. By conducting intensive experiments on two challenging datasets, including a newly collected fine-grained dataset with Web images of different car models, the superior performance of the proposed methods over competitive baselines is clearly demonstrated. version:1
arxiv-1611-09958 | Machine Learning for Dental Image Analysis | http://arxiv.org/abs/1611.09958 | id:1611.09958 author:Young-jun Yu category:stat.ML cs.CV cs.LG  published:2016-11-30 summary:In order to study the application of artificial intelligence (AI) to dental imaging, we applied AI technology to classify a set of panoramic radiographs using (a) a convolutional neural network (CNN) which is a form of an artificial neural network (ANN), (b) representative image cognition algorithms that implement scale-invariant feature transform (SIFT), and (c) histogram of oriented gradients (HOG). version:1
arxiv-1611-09956 | Efficient Likelihood Bayesian Constrained Local Model | http://arxiv.org/abs/1611.09956 | id:1611.09956 author:Hailiang Li, Kin-Man Lam, Man-Yau Chiu, Kangheng Wu, Zhibin Lei category:cs.CV  published:2016-11-30 summary:The constrained local model (CLM) proposes a paradigm that the locations of a set of local landmark detectors are constrained to lie in a subspace, spanned by a shape point distribution model (PDM). Fitting the model to an object involves two steps. A response map, which represents the likelihood of the location of a landmark, is first computed for each landmark using local-texture detectors. Then, an optimal PDM is determined by jointly maximizing all the response maps simultaneously, with a global shape constraint. This global optimization can be considered as a Bayesian inference problem, where the posterior distribution of the shape parameters, as well as the pose parameters, can be inferred using maximum a posteriori (MAP). In this paper, we present a cascaded face-alignment approach, which employs random-forest regressors to estimate the positions of each landmark, as a likelihood term, efficiently in the CLM model. Interpretation from CLM framework, this algorithm is named as an efficient likelihood Bayesian constrained local model (elBCLM). Furthermore, in each stage of the regressors, the PDM non-rigid parameters of previous stage can work as shape clues for training each stage regressors. Experimental results on benchmarks show our approach achieve about 3 to 5 times speed-up compared with CLM models and improve around 10% on fitting quality compare with the same setting regression models. version:1
arxiv-1611-09942 | Photographic home styles in Congress: a computer vision approach | http://arxiv.org/abs/1611.09942 | id:1611.09942 author:L. Jason Anastasopoulos, Dhruvil Badani, Crystal Lee, Shiry Ginosar, Jake Williams category:cs.SI cs.CV  published:2016-11-29 summary:While members of Congress now routinely communicate with constituents using images on a variety of internet platforms, little is known about how images are used as a means of strategic political communication. This is due primarily to computational limitations which have prevented large-scale, systematic analyses of image features. New developments in computer vision, however, are bringing the systematic study of images within reach. Here, we develop a framework for understanding visual political communication by extending Fenno's analysis of home style (Fenno 1978) to images and introduce "photographic" home styles. Using approximately 192,000 photographs collected from MCs Facebook profiles, we build machine learning software with convolutional neural networks and conduct an image manipulation experiment to explore how the race of people that MCs pose with shape photographic home styles. We find evidence that electoral pressures shape photographic home styles and demonstrate that Democratic and Republican members of Congress use images in very different ways. version:1
arxiv-1611-09940 | Neural Combinatorial Optimization with Reinforcement Learning | http://arxiv.org/abs/1611.09940 | id:1611.09940 author:Irwan Bello, Hieu Pham, Quoc V. Le, Mohammad Norouzi, Samy Bengio category:cs.AI cs.LG stat.ML  published:2016-11-29 summary:This paper presents a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning. We focus on the traveling salesman problem (TSP) and train a recurrent network that, given a set of city coordinates, predicts a distribution over different city permutations. Using negative tour length as the reward signal, we optimize the parameters of the recurrent network using a policy gradient method. We compare learning the network parameters on a set of training graphs against learning them on individual test graphs. The best results are obtained when the network is first optimized on a training set and then refined on individual test graphs. Without any supervision and with minimal engineering, Neural Combinatorial Optimization achieves close to optimal results on 2D Euclidean graphs with up to 100 nodes. version:1
arxiv-1611-09932 | Weakly-supervised Discriminative Patch Learning via CNN for Fine-grained Recognition | http://arxiv.org/abs/1611.09932 | id:1611.09932 author:Yaming Wang, Vlad I. Morariu, Larry S. Davis category:cs.CV  published:2016-11-29 summary:Trending research on fine-grained recognition gradually shifts from traditional multistage frameworks to an end-to-end fashion with convolutional neural network (CNN). Many previous end-to-end deep approaches typically consist of a recognition network and an auxiliary localization network trained with additional part annotations to detect semantic parts shared across classes. In this paper, without the cost of extra semantic part annotations, we advance by learning class-specific discriminative patches within the CNN framework. We achieve this by designing a novel asymmetric two-stream network architecture with supervision on convolutional filters and a non-random way of layer initialization. Experimental results show that our approach is able to find high-quality discriminative patches as expected and gets comparable results to state-of-the-art on two publicly available fine-grained recognition datasets. version:1
arxiv-1611-09913 | Capacity and Trainability in Recurrent Neural Networks | http://arxiv.org/abs/1611.09913 | id:1611.09913 author:Jasmine Collins, Jascha Sohl-Dickstein, David Sussillo category:stat.ML cs.AI cs.LG  published:2016-11-29 summary:Two potential bottlenecks on the expressiveness of recurrent neural networks (RNNs) are their ability to store information about the task in their parameters, and to store information about the input history in their units. We show experimentally that all common RNN architectures achieve nearly the same per-task and per-unit capacity bounds with careful training, for a variety of tasks and stacking depths. They can store an amount of task information which is linear in the number of parameters, and is approximately 5 bits per parameter. They can additionally store approximately one real number from their input history per hidden unit. We further find that for several tasks it is the per-task parameter capacity bound that determines performance. These results suggest that many previous results comparing RNN architectures are driven primarily by differences in training effectiveness, rather than differences in capacity. Supporting this observation, we compare training difficulty for several architectures, and show that vanilla RNNs are far more difficult to train, yet have higher capacity. Finally, we propose two novel RNN architectures, one of which is easier to train than the LSTM or GRU. version:1
arxiv-1611-09904 | C-RNN-GAN: Continuous recurrent neural networks with adversarial training | http://arxiv.org/abs/1611.09904 | id:1611.09904 author:Olof Mogren category:cs.AI cs.LG  published:2016-11-29 summary:Generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks. We propose a generative adversarial model that works on continuous sequential data, and apply it by training it on a collection of classical music. We conclude that it generates music that sounds better and better as the model is trained, report statistics on generated music, and let the reader judge the quality by downloading the generated songs. version:1
arxiv-1611-09900 | Context-aware Natural Language Generation with Recurrent Neural Networks | http://arxiv.org/abs/1611.09900 | id:1611.09900 author:Jian Tang, Yifan Yang, Sam Carton, Ming Zhang, Qiaozhu Mei category:cs.CL  published:2016-11-29 summary:This paper studied generating natural languages at particular contexts or situations. We proposed two novel approaches which encode the contexts into a continuous semantic representation and then decode the semantic representation into text sequences with recurrent neural networks. During decoding, the context information are attended through a gating mechanism, addressing the problem of long-range dependency caused by lengthy sequences. We evaluate the effectiveness of the proposed approaches on user review data, in which rich contexts are available and two informative contexts, sentiments and products, are selected for evaluation. Experiments show that the fake reviews generated by our approaches are very natural. Results of fake review detection with human judges show that more than 50\% of the fake reviews are misclassified as the real reviews, and more than 90\% are misclassified by existing state-of-the-art fake review detection algorithm. version:1
arxiv-1611-09897 | Autism Spectrum Disorder Classification using Graph Kernels on Multidimensional Time Series | http://arxiv.org/abs/1611.09897 | id:1611.09897 author:Rushil Anirudh, Jayaraman J. Thiagarajan, Irene Kim, Wolfgang Polonik category:stat.ML  published:2016-11-29 summary:We present an approach to model time series data from resting state fMRI for autism spectrum disorder (ASD) severity classification. We propose to adopt kernel machines and employ graph kernels that define a kernel dot product between two graphs. This enables us to take advantage of spatio-temporal information to capture the dynamics of the brain network, as opposed to aggregating them in the spatial or temporal dimension. In addition to the conventional similarity graphs, we explore the use of L1 graph using sparse coding, and the persistent homology of time delay embeddings, in the proposed pipeline for ASD classification. In our experiments on two datasets from the ABIDE collection, we demonstrate a consistent and significant advantage in using graph kernels over traditional linear or non linear kernels for a variety of time series features. version:1
arxiv-1611-09894 | Exploration for Multi-task Reinforcement Learning with Deep Generative Models | http://arxiv.org/abs/1611.09894 | id:1611.09894 author:Sai Praveen Bangaru, JS Suhas, Balaraman Ravindran category:cs.AI cs.LG I.2; I.5  published:2016-11-29 summary:Exploration in multi-task reinforcement learning is critical in training agents to deduce the underlying MDP. Many of the existing exploration frameworks such as $E^3$, $R_{max}$, Thompson sampling assume a single stationary MDP and are not suitable for system identification in the multi-task setting. We present a novel method to facilitate exploration in multi-task reinforcement learning using deep generative models. We supplement our method with a low dimensional energy model to learn the underlying MDP distribution and provide a resilient and adaptive exploration signal to the agent. We evaluate our method on a new set of environments and provide intuitive interpretation of our results. version:1
arxiv-1611-09891 | Using Brain Connectivity Measure of EEG Synchrostates for Discriminating Typical and Autism Spectrum Disorder | http://arxiv.org/abs/1611.09891 | id:1611.09891 author:Wasifa Jamal, Saptarshi Das, Koushik Maharatna, Doga Kuyucu, Federico Sicca, Lucia Billeci, Fabio Apicella, Filippo Muratori category:physics.med-ph stat.AP stat.ML  published:2016-11-29 summary:In this paper we utilized the concept of stable phase synchronization topography - synchrostates - over the scalp derived from EEG recording for formulating brain connectivity network in Autism Spectrum Disorder (ASD) and typically-growing children. A synchronization index is adapted for forming the edges of the connectivity graph capturing the stability of each of the synchrostates. Such network is formed for 11 ASD and 12 control group children. Comparative analyses of these networks using graph theoretic measures show that children with autism have a different modularity of such networks from typical children. This result could pave the way to a new modality for possible identification of ASD from non-invasively recorded EEG data. version:1
arxiv-1611-09888 | Existence of Millisecond-order Stable States in Time-Varying Phase Synchronization Measure in EEG Signals | http://arxiv.org/abs/1611.09888 | id:1611.09888 author:Wasifa Jamal, Saptarshi Das, Koushik Maharatna category:physics.med-ph stat.AP stat.ML  published:2016-11-29 summary:In this paper, we have developed a new measure of understanding the temporal evolution of phase synchronization for EEG signals using cross-electrode information. From this measure it is found that there exists a small number of well-defined phase-synchronized states, each of which is stable for few milliseconds during the execution of a face perception task. We termed these quasi-stable states as synchrostates. We used k-means clustering algorithms to estimate the optimal number of synchrostates from 100 trials of EEG signals over 128 channels. Our results show that these synchrostates exist consistently in all the different trials. It is also found that from the onset of the stimulus, switching between these synchrostates results in well-behaved temporal sequence with repeatability which may be indicative of the dynamics of the cognitive process underlying that task. Therefore these synchrostates and their temporal switching sequences may be used as a new measure of the stability of phase synchrony and information exchange between different regions of a human brain. version:1
arxiv-1611-09878 | Identity-sensitive Word Embedding through Heterogeneous Networks | http://arxiv.org/abs/1611.09878 | id:1611.09878 author:Jian Tang, Meng Qu, Qiaozhu Mei category:cs.CL cs.LG  published:2016-11-29 summary:Most existing word embedding approaches do not distinguish the same words in different contexts, therefore ignoring their contextual meanings. As a result, the learned embeddings of these words are usually a mixture of multiple meanings. In this paper, we acknowledge multiple identities of the same word in different contexts and learn the \textbf{identity-sensitive} word embeddings. Based on an identity-labeled text corpora, a heterogeneous network of words and word identities is constructed to model different-levels of word co-occurrences. The heterogeneous network is further embedded into a low-dimensional space through a principled network embedding approach, through which we are able to obtain the embeddings of words and the embeddings of word identities. We study three different types of word identities including topics, sentiments and categories. Experimental results on real-world data sets show that the identity-sensitive word embeddings learned by our approach indeed capture different meanings of words and outperforms competitive methods on tasks including text classification and word similarity computation. version:1
arxiv-1611-09842 | Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction | http://arxiv.org/abs/1611.09842 | id:1611.09842 author:Richard Zhang, Phillip Isola, Alexei A. Efros category:cs.CV  published:2016-11-29 summary:We propose split-brain autoencoders, a straightforward modification of the traditional autoencoder architecture, for unsupervised representation learning. The method adds a split to the network, resulting in two disjoint sub-networks. Each sub-network is trained to perform a difficult task -- predicting one subset of the data channels from another. Together, the sub-networks extract features from the entire input signal. By forcing the network to solve cross-channel prediction tasks, we induce a representation within the network which transfers well to other, unseen tasks. This method achieves state-of-the-art performance on several large-scale transfer learning benchmarks. version:1
arxiv-1611-09835 | Multi-objective Active Control Policy Design for Commensurate and Incommensurate Fractional Order Chaotic Financial Systems | http://arxiv.org/abs/1611.09835 | id:1611.09835 author:Indranil Pan, Saptarshi Das, Shantanu Das category:math.OC cs.CE cs.NE cs.SY nlin.CD  published:2016-11-29 summary:In this paper, an active control policy design for a fractional order (FO) financial system is attempted, considering multiple conflicting objectives. An active control template as a nonlinear state feedback mechanism is developed and the controller gains are chosen within a multi-objective optimization (MOO) framework to satisfy the conditions of asymptotic stability, derived analytically. The MOO gives a set of solutions on the Pareto optimal front for the multiple conflicting objectives that are considered. It is shown that there is a trade-off between the multiple design objectives and a better performance in one objective can only be obtained at the cost of performance deterioration in the other objectives. The multi-objective controller design has been compared using three different MOO techniques viz. Non Dominated Sorting Genetic Algorithm-II (NSGA-II), epsilon variable Multi-Objective Genetic Algorithm (ev-MOGA), and Multi Objective Evolutionary Algorithm with Decomposition (MOEA/D). The robustness of the same control policy designed with the nominal system settings have been investigated also for gradual decrease in the commensurate and incommensurate fractional orders of the financial system. version:1
arxiv-1611-09830 | NewsQA: A Machine Comprehension Dataset | http://arxiv.org/abs/1611.09830 | id:1611.09830 author:Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, Kaheer Suleman category:cs.CL cs.AI  published:2016-11-29 summary:We present NewsQA, a challenging machine comprehension dataset of over 100,000 question-answer pairs. Crowdworkers supply questions and answers based on a set of over 10,000 news articles from CNN, with answers consisting in spans of text from the corresponding articles. We collect this dataset through a four-stage process designed to solicit exploratory questions that require reasoning. A thorough analysis confirms that NewsQA demands abilities beyond simple word matching and recognizing entailment. We measure human performance on the dataset and compare it to several strong neural models. The performance gap between humans and machines (25.3% F1) indicates that significant progress can be made on NewsQA through future research. The dataset is freely available at datasets.maluuba.com/NewsQA. version:1
arxiv-1611-09827 | Learning Features of Music from Scratch | http://arxiv.org/abs/1611.09827 | id:1611.09827 author:John Thickstun, Zaid Harchaoui, Sham Kakade category:stat.ML cs.LG cs.SD  published:2016-11-29 summary:We introduce a new large-scale music dataset, MusicNet, to serve as a source of supervision and evaluation of machine learning methods for music research. MusicNet consists of hundreds of freely-licensed classical music recordings by 10 composers, written for 11 instruments, together with instrument/note annotations resulting in over 1 million temporal labels on 34 hours of chamber music performances under various studio and microphone conditions. We define a multi-label classification task to predict notes in musical recordings, along with an evaluation protocol. We benchmark several machine learning architectures for this task: i) learning from "hand-crafted" spectrogram features; ii) end-to-end learning with a neural net; iii) end-to-end learning with a convolutional neural net. We show that several end-to-end learning proposals outperform approaches based on learning from hand-crafted audio features. version:1
arxiv-1611-09823 | Dialogue Learning With Human-In-The-Loop | http://arxiv.org/abs/1611.09823 | id:1611.09823 author:Jiwei Li, Alexander H. Miller, Sumit Chopra, Marc'Aurelio Ranzato, Jason Weston category:cs.AI cs.CL  published:2016-11-29 summary:An important aspect of developing conversational agents is to give a bot the ability to improve through communicating with humans and to learn from the mistakes that it makes. Most research has focused on learning from fixed training sets of labeled data rather than interacting with a dialogue partner in an online fashion. In this paper we explore this direction in a reinforcement learning setting where the bot improves its question-answering ability from feedback a teacher gives following its generated responses. We build a simulator that tests various aspects of such learning in a synthetic environment, and introduce models that work in this regime. Finally, real experiments with Mechanical Turk validate the approach. version:1
arxiv-1611-09820 | Exploring Strategies for Classification of External Stimuli Using Statistical Features of the Plant Electrical Response | http://arxiv.org/abs/1611.09820 | id:1611.09820 author:Shre Kumar Chatterjee, Saptarshi Das, Koushik Maharatna, Elisa Masi, Luisa Santopolo, Stefano Mancuso, Andrea Vitaletti category:physics.bio-ph q-bio.QM stat.AP stat.ML  published:2016-11-29 summary:Plants sense their environment by producing electrical signals which in essence represent changes in underlying physiological processes. These electrical signals, when monitored, show both stochastic and deterministic dynamics. In this paper, we compute 11 statistical features from the raw non-stationary plant electrical signal time series to classify the stimulus applied (causing the electrical signal). By using different discriminant analysis based classification techniques, we successfully establish that there is enough information in the raw electrical signal to classify the stimuli. In the process, we also propose two standard features which consistently give good classification results for three types of stimuli - Sodium Chloride (NaCl), Sulphuric Acid (H2SO4) and Ozone (O3). This may facilitate reduction in the complexity involved in computing all the features for online classification of similar external stimuli in future. version:1
arxiv-1611-09819 | Measuring and modeling the perception of natural and unconstrained gaze in humans and machines | http://arxiv.org/abs/1611.09819 | id:1611.09819 author:Daniel Harari, Tao Gao, Nancy Kanwisher, Joshua Tenenbaum, Shimon Ullman category:q-bio.NC cs.AI cs.CV cs.LG  published:2016-11-29 summary:Humans are remarkably adept at interpreting the gaze direction of other individuals in their surroundings. This skill is at the core of the ability to engage in joint visual attention, which is essential for establishing social interactions. How accurate are humans in determining the gaze direction of others in lifelike scenes, when they can move their heads and eyes freely, and what are the sources of information for the underlying perceptual processes? These questions pose a challenge from both empirical and computational perspectives, due to the complexity of the visual input in real-life situations. Here we measure empirically human accuracy in perceiving the gaze direction of others in lifelike scenes, and study computationally the sources of information and representations underlying this cognitive capacity. We show that humans perform better in face-to-face conditions compared with recorded conditions, and that this advantage is not due to the availability of input dynamics. We further show that humans are still performing well when only the eyes-region is visible, rather than the whole face. We develop a computational model, which replicates the pattern of human performance, including the finding that the eyes-region contains on its own, the required information for estimating both head orientation and direction of gaze. Consistent with neurophysiological findings on task-specific face regions in the brain, the learned computational representations reproduce perceptual effects such as the Wollaston illusion, when trained to estimate direction of gaze, but not when trained to recognize objects or faces. version:1
arxiv-1611-09813 | Monocular 3D Human Pose Estimation Using Transfer Learning and Improved CNN Supervision | http://arxiv.org/abs/1611.09813 | id:1611.09813 author:Dushyant Mehta, Helge Rhodin, Dan Casas, Oleksandr Sotnychenko, Weipeng Xu, Christian Theobalt category:cs.CV  published:2016-11-29 summary:We propose a new CNN-based method for regressing 3D human body pose from a single image that improves over the state-of-the-art on standard benchmarks by more than 25%. Our approach addresses the limited generalizability of models trained solely on the starkly limited publicly available 3D body pose data. Improved CNN supervision leverages first and second order parent relationships along the skeletal kinematic tree, and improved multi-level skip connections to learn better representations through implicit modification of the loss landscape. Further, transfer learning from 2D human pose prediction significantly improves accuracy and generalizability to unseen poses and camera views. Additionally, we contribute a new benchmark and training set for human body pose estimation from monocular images of real humans, that has ground truth captured with marker-less motion capture. It complements existing corpora with greater diversity in pose, human appearance, clothing, occlusion, and viewpoints, and enables increased scope of augmentation. The benchmark covers outdoors and indoor scenes. version:1
arxiv-1611-09811 | 3D Ultrasound image segmentation: A Survey | http://arxiv.org/abs/1611.09811 | id:1611.09811 author:Mohammad Hamed Mozaffari, WonSook Lee category:cs.CV  published:2016-11-29 summary:Three-dimensional Ultrasound image segmentation methods are surveyed in this paper. The focus of this report is to investigate applications of these techniques and a review of the original ideas and concepts. Although many two-dimensional image segmentation in the literature have been considered as a three-dimensional approach by mistake but we review them as a three-dimensional technique. We select the studies that have addressed the problem of medical three-dimensional Ultrasound image segmentation utilizing their proposed techniques. The evaluation methods and comparison between them are presented and tabulated in terms of evaluation techniques, interactivity, and robustness. version:1
arxiv-1611-09805 | A Primal-dual Three-operator Splitting Scheme | http://arxiv.org/abs/1611.09805 | id:1611.09805 author:Ming Yan category:math.OC math.NA stat.ML  published:2016-11-29 summary:In this paper, we propose a new primal-dual algorithm for minimizing $f(x)+g(x)+h(Ax)$, where $f$, $g$, and $h$ are convex functions, $f$ is differentiable with a Lipschitz continuous gradient, and $A$ is a bounded linear operator. It has some famous primal-dual algorithms for minimizing the sum of two functions as special cases. For example, it reduces to the Chambolle-Pock algorithm when $f=0$ and a primal-dual fixed-point algorithm in [P. Chen, J. Huang, and X. Zhang, A primal-dual fixed-point algorithm for convex separable minimization with applications to image restoration, Inverse Problems, 29 (2013), p.025011] when $g=0$. In addition, it recovers the three-operator splitting scheme in [D. Davis and W. Yin, A three-operator splitting scheme and its optimization applications, arXiv:1504.01032, (2015)] when $A$ is the identity operator. We prove the convergence of this new algorithm for the general case by showing that the iteration is a nonexpansive operator and derive the linear convergence rate with additional assumptions. Comparing to other primal-dual algorithms for solving the same problem, this algorithm extends the range of acceptable parameters to ensure the convergence and has a smaller per-iteration cost. The numerical experiments show the efficiency of this new algorithm by comparing to other primal-dual algorithms. version:1
arxiv-1611-09802 | Fractional Order Load-Frequency Control of Interconnected Power Systems Using Chaotic Multi-objective Optimization | http://arxiv.org/abs/1611.09802 | id:1611.09802 author:Indranil Pan, Saptarshi Das category:math.OC cs.NE cs.SY  published:2016-11-29 summary:Fractional order proportional-integral-derivative (FOPID) controllers are designed for load frequency control (LFC) of two interconnected power systems. Conflicting time domain design objectives are considered in a multi objective optimization (MOO) based design framework to design the gains and the fractional differ-integral orders of the FOPID controllers in the two areas. Here, we explore the effect of augmenting two different chaotic maps along with the uniform random number generator (RNG) in the popular MOO algorithm - the Non-dominated Sorting Genetic Algorithm-II (NSGA-II). Different measures of quality for MOO e.g. hypervolume indicator, moment of inertia based diversity metric, total Pareto spread, spacing metric are adopted to select the best set of controller parameters from multiple runs of all the NSGA-II variants (i.e. nominal and chaotic versions). The chaotic versions of the NSGA-II algorithm are compared with the standard NSGA-II in terms of solution quality and computational time. In addition, the Pareto optimal fronts showing the trade-off between the two conflicting time domain design objectives are compared to show the advantage of using the FOPID controller over that with simple PID controller. The nature of fast/slow and high/low noise amplification effects of the FOPID structure or the four quadrant operation in the two inter-connected areas of the power system is also explored. A fuzzy logic based method has been adopted next to select the best compromise solution from the best Pareto fronts corresponding to each MOO comparison criteria. The time domain system responses are shown for the fuzzy best compromise solutions under nominal operating conditions. Comparative analysis on the merits and de-merits of each controller structure is reported then. A robustness analysis is also done for the PID and the FOPID controllers. version:1
arxiv-1611-09799 | Geometry of Compositionality | http://arxiv.org/abs/1611.09799 | id:1611.09799 author:Hongyu Gong, Suma Bhat, Pramod Viswanath category:cs.CL  published:2016-11-29 summary:This paper proposes a simple test for compositionality (i.e., literal usage) of a word or phrase in a context-specific way. The test is computationally simple, relying on no external resources and only uses a set of trained word vectors. Experiments show that the proposed method is competitive with state of the art and displays high accuracy in context-specific compositionality detection of a variety of natural language phenomena (idiomaticity, sarcasm, metaphor) for different datasets in multiple languages. The key insight is to connect compositionality to a curious geometric property of word embeddings, which is of independent interest. version:1
arxiv-1611-09791 | On the Existence of Synchrostates in Multichannel EEG Signals during Face-perception Tasks | http://arxiv.org/abs/1611.09791 | id:1611.09791 author:Wasifa Jamal, Saptarshi Das, Koushik Maharatna, Fabio Apicella, Georgia Chronaki, Federico Sicca, David Cohen, Filippo Muratori category:physics.med-ph cs.CV stat.AP stat.ML  published:2016-11-29 summary:Phase synchronisation in multichannel EEG is known as the manifestation of functional brain connectivity. Traditional phase synchronisation studies are mostly based on time average synchrony measures hence do not preserve the temporal evolution of the phase difference. Here we propose a new method to show the existence of a small set of unique phase synchronised patterns or "states" in multi-channel EEG recordings, each "state" being stable of the order of ms, from typical and pathological subjects during face perception tasks. The proposed methodology bridges the concepts of EEG microstates and phase synchronisation in time and frequency domain respectively. The analysis is reported for four groups of children including typical, Autism Spectrum Disorder (ASD), low and high anxiety subjects - a total of 44 subjects. In all cases, we observe consistent existence of these states - termed as synchrostates - within specific cognition related frequency bands (beta and gamma bands), though the topographies of these synchrostates differ for different subject groups with different pathological conditions. The inter-synchrostate switching follows a well-defined sequence capturing the underlying inter-electrode phase relation dynamics in stimulus- and person-centric manner. Our study is motivated from the well-known EEG microstate exhibiting stable potential maps over the scalp. However, here we report a similar observation of quasi-stable phase synchronised states in multichannel EEG. The existence of the synchrostates coupled with their unique switching sequence characteristics could be considered as a potentially new field over contemporary EEG phase synchronisation studies. version:1
arxiv-1611-09769 | Computer Aided Detection of Oral Lesions on CT Images | http://arxiv.org/abs/1611.09769 | id:1611.09769 author:Shaikat Galib, Fahima Islam, Muhammad Abir, Hyoung-Koo Lee category:cs.CV  published:2016-11-29 summary:Oral lesions are important findings on computed tomography (CT) images. In this study, a fully automatic method to detect oral lesions in mandibular region from dental CT images is proposed. Two methods were developed to recognize two types of lesions namely (1) Close border (CB) lesions and (2) Open border (OB) lesions, which cover most of the lesion types that can be found on CT images. For the detection of CB lesions, fifteen features were extracted from each initial lesion candidates and multi layer perceptron (MLP) neural network was used to classify suspicious regions. Moreover, OB lesions were detected using a rule based image processing method, where no feature extraction or classification algorithm were used. The results were validated using a CT dataset of 52 patients, where 22 patients had abnormalities and 30 patients were normal. Using non-training dataset, CB detection algorithm yielded 71% sensitivity with 0.31 false positives per patient. Furthermore, OB detection algorithm achieved 100% sensitivity with 0.13 false positives per patient. Results suggest that, the proposed framework, which consists of two methods, has the potential to be used in clinical context, and assist radiologists for better diagnosis. version:1
arxiv-1611-10252 | SeDMiD for Confusion Detection: Uncovering Mind State from Time Series Brain Wave Data | http://arxiv.org/abs/1611.10252 | id:1611.10252 author:Jingkang Yang, Haohan Wang, Jun Zhu, Eric P. Xing category:q-bio.NC cs.AI cs.LG  published:2016-11-29 summary:Understanding how brain functions has been an intriguing topic for years. With the recent progress on collecting massive data and developing advanced technology, people have become interested in addressing the challenge of decoding brain wave data into meaningful mind states, with many machine learning models and algorithms being revisited and developed, especially the ones that handle time series data because of the nature of brain waves. However, many of these time series models, like HMM with hidden state in discrete space or State Space Model with hidden state in continuous space, only work with one source of data and cannot handle different sources of information simultaneously. In this paper, we propose an extension of State Space Model to work with different sources of information together with its learning and inference algorithms. We apply this model to decode the mind state of students during lectures based on their brain waves and reach a significant better results compared to traditional methods. version:1
arxiv-1611-09755 | Fractional Order AGC for Distributed Energy Resources Using Robust Optimization | http://arxiv.org/abs/1611.09755 | id:1611.09755 author:Indranil Pan, Saptarshi Das category:cs.SY cs.AI cs.NE math.OC  published:2016-11-29 summary:The applicability of fractional order (FO) automatic generation control (AGC) for power system frequency oscillation damping is investigated in this paper, employing distributed energy generation. The hybrid power system employs various autonomous generation systems like wind turbine, solar photovoltaic, diesel engine, fuel-cell and aqua electrolyzer along with other energy storage devices like the battery and flywheel. The controller is placed in a remote location while receiving and sending signals over an unreliable communication network with stochastic delay. The controller parameters are tuned using robust optimization techniques employing different variants of Particle Swarm Optimization (PSO) and are compared with the corresponding optimal solutions. An archival based strategy is used for reducing the number of function evaluations for the robust optimization methods. The solutions obtained through the robust optimization are able to handle higher variation in the controller gains and orders without significant decrease in the system performance. This is desirable from the FO controller implementation point of view, as the design is able to accommodate variations in the system parameter which may result due to the approximation of FO operators, using different realization methods and order of accuracy. Also a comparison is made between the FO and the integer order (IO) controllers to highlight the merits and demerits of each scheme. version:1
arxiv-1611-09726 | Gossip training for deep learning | http://arxiv.org/abs/1611.09726 | id:1611.09726 author:Michael Blot, David Picard, Matthieu Cord, Nicolas Thome category:cs.CV cs.LG stat.ML  published:2016-11-29 summary:We address the issue of speeding up the training of convolutional networks. Here we study a distributed method adapted to stochastic gradient descent (SGD). The parallel optimization setup uses several threads, each applying individual gradient descents on a local variable. We propose a new way to share information between different threads inspired by gossip algorithms and showing good consensus convergence properties. Our method called GoSGD has the advantage to be fully asynchronous and decentralized. We compared our method to the recent EASGD in \cite{elastic} on CIFAR-10 show encouraging results. version:1
arxiv-1611-09718 | Efficient Linear Programming for Dense CRFs | http://arxiv.org/abs/1611.09718 | id:1611.09718 author:Thalaiyasingam Ajanthan, Alban Desmaison, Rudy Bunel, Mathieu Salzmann, Philip H. S. Torr, M. Pawan Kumar category:cs.CV G.1.6; I.4.6  published:2016-11-29 summary:The fully connected conditional random field (CRF) with Gaussian pairwise potentials has proven popular and effective for multi-class semantic segmentation. While the energy of a dense CRF can be minimized accurately using a linear programming (LP) relaxation, the state-of-the-art algorithm is too slow to be useful in practice. To alleviate this deficiency, we introduce an efficient LP minimization algorithm for dense CRFs. To this end, we develop a proximal minimization framework, where the dual of each proximal problem is optimized via block coordinate descent. We show that each block of variables can be efficiently optimized. Specifically, for one block, the problem decomposes into significantly smaller subproblems, each of which is defined over a single pixel. For the other block, the problem is optimized via conditional gradient descent. This has two advantages: 1) the conditional gradient can be computed in a time linear in the number of pixels and labels; and 2) the optimal step size can be computed analytically. Our experiments on standard datasets provide compelling evidence that our approach outperforms all existing baselines including the previous LP based approach for dense CRFs. version:1
arxiv-1611-09706 | Probabilistic map-matching using particle filters | http://arxiv.org/abs/1611.09706 | id:1611.09706 author:Kira Kempinska, Toby Davies, John Shawe-Taylor category:stat.ML  published:2016-11-29 summary:Increasing availability of vehicle GPS data has created potentially transformative opportunities for traffic management, route planning and other location-based services. Critical to the utility of the data is their accuracy. Map-matching is the process of improving the accuracy by aligning GPS data with the road network. In this paper, we propose a purely probabilistic approach to map-matching based on a sequential Monte Carlo algorithm known as particle filters. The approach performs map-matching by producing a range of candidate solutions, each with an associated probability score. We outline implementation details and thoroughly validate the technique on GPS data of varied quality. version:1
arxiv-1611-09703 | Semantic Parsing of Mathematics by Context-based Learning from Aligned Corpora and Theorem Proving | http://arxiv.org/abs/1611.09703 | id:1611.09703 author:Cezary Kaliszyk, Josef Urban, Ji≈ô√≠ Vyskoƒçil category:cs.CL cs.AI  published:2016-11-29 summary:We study methods for automated parsing of informal mathematical expressions into formal ones, a main prerequisite for deep computer understanding of informal mathematical texts. We propose a context-based parsing approach that combines efficient statistical learning of deep parse trees with their semantic pruning by type checking and large-theory automated theorem proving. We show that the methods very significantly improve on previous results in parsing theorems from the Flyspeck corpus. version:1
arxiv-1611-09630 | Improving Variational Auto-Encoders using Householder Flow | http://arxiv.org/abs/1611.09630 | id:1611.09630 author:Jakub M. Tomczak, Max Welling category:cs.LG stat.ML  published:2016-11-29 summary:Variational auto-encoders (VAE) are scalable and powerful generative models. However, the choice of the variational posterior determines tractability and flexibility of the VAE. Commonly, latent variables are modeled using the normal distribution with a diagonal covariance matrix. This results in computational efficiency but typically it is not flexible enough to match the true posterior distribution. One fashion of enriching the variational posterior distribution is application of normalizing flows, i.e., a series of invertible transformations to latent variables with a simple posterior. In this paper, we follow this line of thinking and propose a volume-preserving flow that uses a series of Householder transformations. We show empirically on MNIST dataset and histopathology data that the proposed flow allows to obtain more flexible variational posterior and highly competitive results comparing to other normalizing flows. version:1
arxiv-1611-09621 | Associative Memory using Dictionary Learning and Expander Decoding | http://arxiv.org/abs/1611.09621 | id:1611.09621 author:Arya Mazumdar, Ankit Singh Rawat category:stat.ML cs.IT cs.LG math.IT  published:2016-11-29 summary:An associative memory is a framework of content-addressable memory that stores a collection of message vectors (or a dataset) over a neural network while enabling a neurally feasible mechanism to recover any message in the dataset from its noisy version. Designing an associative memory requires addressing two main tasks: 1) learning phase: given a dataset, learn a concise representation of the dataset in the form of a graphical model (or a neural network), 2) recall phase: given a noisy version of a message vector from the dataset, output the correct message vector via a neurally feasible algorithm over the network learnt during the learning phase. This paper studies the problem of designing a class of neural associative memories which learns a network representation for a large dataset that ensures correction against a large number of adversarial errors during the recall phase. Specifically, the associative memories designed in this paper can store dataset containing $\exp(n)$ $n$-length message vectors over a network with $O(n)$ nodes and can tolerate $\Omega(\frac{n}{{\rm polylog} n})$ adversarial errors. This paper carries out this memory design by mapping the learning phase and recall phase to the tasks of dictionary learning with a square dictionary and iterative error correction in an expander code, respectively. version:1
arxiv-1611-09130 | Generalizing the Kelly strategy | http://arxiv.org/abs/1611.09130 | id:1611.09130 author:Arjun Viswanathan category:stat.ML cs.GT  published:2016-11-28 summary:Prompted by a recent experiment by Victor Haghani and Richard Dewey, this note generalises the Kelly strategy (optimal for simple investment games with log utility) to a large class of practical utility functions and including the effect of extraneous wealth. A counterintuitive result is proved : for any continuous, concave, differentiable utility function, the optimal choice at every point depends only on the probability of reaching that point. The practical calculation of the optimal action at every stage is made possible through use of the binomial expansion, reducing the problem size from exponential to quadratic. Applications include (better) automatic investing and risk taking under uncertainty. version:2
arxiv-1611-07727 | Pose-Track: Joint Multi-Person Pose Estimation and Tracking | http://arxiv.org/abs/1611.07727 | id:1611.07727 author:Umar Iqbal, Anton Milan, Juergen Gall category:cs.CV  published:2016-11-23 summary:In this work, we introduce the challenging problem of joint multi-person pose estimation and tracking of an unknown number of persons in unconstrained videos. Existing methods for multi-person pose estimation in images cannot be applied directly to this problem, since it also requires to solve the problem of person association over time in addition to the pose estimation for each person. We therefore propose a novel method that jointly models multi-person pose estimation and tracking in a single formulation. To this end, we represent body joint detections in a video by a spatio-temporal graph and solve an integer linear program to partition the graph into sub-graphs that correspond to plausible body pose trajectories for each person. The proposed approach implicitly handles occlusions and truncations of persons. Since the problem has not been addressed quantitatively in the literature, we introduce a challenging "Multi-Person Pose-Track" dataset, and also propose a completely unconstrained evaluation protocol that does not make any assumptions on the scale, size, location or the number of persons. Finally, we evaluate the proposed approach and several baseline methods on our new dataset. version:2
arxiv-1611-09194 | Times series averaging and denoising from a probabilistic perspective on time-elastic kernels | http://arxiv.org/abs/1611.09194 | id:1611.09194 author:Pierre-Fran√ßois Marteau category:cs.LG cs.IR  published:2016-11-28 summary:In the light of regularized dynamic time warping kernels, this paper re-considers the concept of time elastic centroid for a setof time series. We derive a new algorithm based on a probabilistic interpretation of kernel alignment matrices. This algorithm expressesthe averaging process in terms of a stochastic alignment automata. It uses an iterative agglomerative heuristic method for averagingthe aligned samples, while also averaging the times of occurrence of the aligned samples. By comparing classification accuracies for45 heterogeneous time series datasets obtained by first nearest centroid/medoid classifiers we show that: i) centroid-basedapproaches significantly outperform medoid-based approaches, ii) for the considered datasets, our algorithm that combines averagingin the sample space and along the time axes, emerges as the most significantly robust model for time-elastic averaging with apromising noise reduction capability. We also demonstrate its benefit in an isolated gesture recognition experiment and its ability tosignificantly reduce the size of training instance sets. Finally we highlight its denoising capability using demonstrative synthetic data:we show that it is possible to retrieve, from few noisy instances, a signal whose components are scattered in a wide spectral band. version:2
arxiv-1611-09587 | Surveillance Video Parsing with Single Frame Supervision | http://arxiv.org/abs/1611.09587 | id:1611.09587 author:Si Liu, Changhu Wang, Ruihe Qian, Han Yu, Renda Bao category:cs.CV  published:2016-11-29 summary:Surveillance video parsing, which segments the video frames into several labels, e.g., face, pants, left-leg, has wide applications. However,pixel-wisely annotating all frames is tedious and inefficient. In this paper, we develop a Single frame Video Parsing (SVP) method which requires only one labeled frame per video in training stage. To parse one particular frame, the video segment preceding the frame is jointly considered. SVP (1) roughly parses the frames within the video segment, (2) estimates the optical flow between frames and (3) fuses the rough parsing results warped by optical flow to produce the refined parsing result. The three components of SVP, namely frame parsing, optical flow estimation and temporal fusion are integrated in an end-to-end manner. Experimental results on two surveillance video datasets show the superiority of SVP over state-of-the-arts. version:1
arxiv-1611-09580 | A Large-scale Distributed Video Parsing and Evaluation Platform | http://arxiv.org/abs/1611.09580 | id:1611.09580 author:Kai Yu, Yang Zhou, Da Li, Zhang Zhang, Kaiqi Huang category:cs.CV  published:2016-11-29 summary:Visual surveillance systems have become one of the largest data sources of Big Visual Data in real world. However, existing systems for video analysis still lack the ability to handle the problems of scalability, expansibility and error-prone, though great advances have been achieved in a number of visual recognition tasks and surveillance applications, e.g., pedestrian/vehicle detection, people/vehicle counting. Moreover, few algorithms explore the specific values/characteristics in large-scale surveillance videos. To address these problems in large-scale video analysis, we develop a scalable video parsing and evaluation platform through combining some advanced techniques for Big Data processing, including Spark Streaming, Kafka and Hadoop Distributed Filesystem (HDFS). Also, a Web User Interface is designed in the system, to collect users' degrees of satisfaction on the recognition tasks so as to evaluate the performance of the whole system. Furthermore, the highly extensible platform running on the long-term surveillance videos makes it possible to develop more intelligent incremental algorithms to enhance the performance of various visual recognition tasks. version:1
arxiv-1611-09577 | Fast Face-swap Using Convolutional Neural Networks | http://arxiv.org/abs/1611.09577 | id:1611.09577 author:Iryna Korshunova, Wenzhe Shi, Joni Dambre, Lucas Theis category:cs.CV  published:2016-11-29 summary:We consider the problem of face swapping in images, where an input identity is transformed into a target identity while preserving pose, facial expression, and lighting. To perform this mapping, we use convolutional neural networks trained to capture the appearance of the target identity from an unstructured collection of his/her photographs.This approach is enabled by framing the face swapping problem in terms of style transfer, where the goal is to render an image in the style of another one. Building on recent advances in this area, we devise a new loss function that enables the network to produce highly photorealistic results. By combining neural networks with simple pre- and post-processing steps, we aim at making face swap work in real-time with no input from the user. version:1
arxiv-1611-09573 | Learning Concept Hierarchies through Probabilistic Topic Modeling | http://arxiv.org/abs/1611.09573 | id:1611.09573 author:V. S. Anoop, S. Asharaf, P. Deepak category:cs.AI cs.CL cs.IR  published:2016-11-29 summary:With the advent of semantic web, various tools and techniques have been introduced for presenting and organizing knowledge. Concept hierarchies are one such technique which gained significant attention due to its usefulness in creating domain ontologies that are considered as an integral part of semantic web. Automated concept hierarchy learning algorithms focus on extracting relevant concepts from unstructured text corpus and connect them together by identifying some potential relations exist between them. In this paper, we propose a novel approach for identifying relevant concepts from plain text and then learns hierarchy of concepts by exploiting subsumption relation between them. To start with, we model topics using a probabilistic topic model and then make use of some lightweight linguistic process to extract semantically rich concepts. Then we connect concepts by identifying an "is-a" relationship between pair of concepts. The proposed method is completely unsupervised and there is no need for a domain specific training corpus for concept extraction and learning. Experiments on large and real-world text corpora such as BBC News dataset and Reuters News corpus shows that the proposed method outperforms some of the existing methods for concept extraction and efficient concept hierarchy learning is possible if the overall task is guided by a probabilistic topic modeling algorithm. version:1
arxiv-1611-09572 | Occlusion-Aware Video Deblurring with a New Layered Blur Model | http://arxiv.org/abs/1611.09572 | id:1611.09572 author:Byeongjoo Ahn, Tae Hyun Kim, Wonsik Kim, Kyoung Mu Lee category:cs.CV  published:2016-11-29 summary:We present a deblurring method for scenes with occluding objects using a carefully designed layered blur model. Layered blur model is frequently used in the motion deblurring problem to handle locally varying blurs, which is caused by object motions or depth variations in a scene. However, conventional models have a limitation in representing the layer interactions occurring at occlusion boundaries. In this paper, we address this limitation in both theoretical and experimental ways, and propose a new layered blur model reflecting actual blur generation process. Based on this model, we develop an occlusion-aware deblurring method that can estimate not only the clear foreground and background, but also the object motion more accurately. We also provide a novel analysis on the blur kernel at object boundaries, which shows the distinctive characteristics of the blur kernel that cannot be captured by conventional blur models. Experimental results on synthetic and real blurred videos demonstrate that the proposed method yields superior results, especially at object boundaries. version:1
arxiv-1611-09571 | Predicting Human Eye Fixations via an LSTM-based Saliency Attentive Model | http://arxiv.org/abs/1611.09571 | id:1611.09571 author:Marcella Cornia, Lorenzo Baraldi, Giuseppe Serra, Rita Cucchiara category:cs.CV  published:2016-11-29 summary:Data-driven saliency has recently gained a lot of attention thanks to the use of Convolutional Neural Networks. In this paper we go beyond the standard approach to saliency prediction, in which gaze maps are computed with a feed-forward network, and we present a novel Saliency Attentive Model which can predict accurate saliency maps by incorporating attentive mechanisms. Our solution is composed of a Convolutional LSTM, that iteratively focuses on the most salient regions of the input, and a Residual Architecture designed to preserve spatial resolution. Additionally, to tackle the center bias present in human eye fixations, our model incorporates prior maps generated by learned Gaussian functions. We show, through an extensive evaluation, that the proposed architecture overcomes the current state of the art on three public saliency prediction datasets: SALICON, MIT300 and CAT2000. We further study the contribution of each key components to demonstrate their robustness on different scenarios. version:1
arxiv-1611-09559 | Lens Distortion Rectification using Triangulation based Interpolation | http://arxiv.org/abs/1611.09559 | id:1611.09559 author:Burak Benligiray, Cihan Topal category:cs.CV  published:2016-11-29 summary:Nonlinear lens distortion rectification is a common first step in image processing applications where the assumption of a linear camera model is essential. For rectifying the lens distortion, forward distortion model needs to be known. However, many self-calibration methods estimate the inverse distortion model. In the literature, the inverse of the estimated model is approximated for image rectification, which introduces additional error to the system. We propose a novel distortion rectification method that uses the inverse distortion model directly. The method starts by mapping the distorted pixels to the rectified image using the inverse distortion model. The resulting set of points with subpixel locations are triangulated. The pixel values of the rectified image are linearly interpolated based on this triangulation. The method is applicable to all camera calibration methods that estimate the inverse distortion model and performs well across a large range of parameters. version:1
arxiv-1611-09534 | Is a picture worth a thousand words? A Deep Multi-Modal Fusion Architecture for Product Classification in e-commerce | http://arxiv.org/abs/1611.09534 | id:1611.09534 author:Tom Zahavy, Alessandro Magnani, Abhinandan Krishnan, Shie Mannor category:cs.CV cs.CL  published:2016-11-29 summary:Classifying products into categories precisely and efficiently is a major challenge in modern e-commerce. The high traffic of new products uploaded daily and the dynamic nature of the categories raise the need for machine learning models that can reduce the cost and time of human editors. In this paper, we propose a decision level fusion approach for multi-modal product classification using text and image inputs. We train input specific state-of-the-art deep neural networks for each input source, show the potential of forging them together into a multi-modal architecture and train a novel policy network that learns to choose between them. Finally, we demonstrate that our multi-modal network improves the top-1 accuracy % over both networks on a real-world large-scale product classification dataset that we collected fromWalmart.com. While we focus on image-text fusion that characterizes e-commerce domains, our algorithms can be easily applied to other modalities such as audio, video, physical sensors, etc. version:1
arxiv-1611-09510 | Graph-Based Manifold Frequency Analysis for Denoising | http://arxiv.org/abs/1611.09510 | id:1611.09510 author:Shay Deutsch, Antonio Ortega, Gerard Medioni category:cs.LG stat.ML  published:2016-11-29 summary:We propose a new framework for manifold denoising based on processing in the graph Fourier frequency domain, derived from the spectral decomposition of the discrete graph Laplacian. Our approach uses the Spectral Graph Wavelet transform in order to per- form non-iterative denoising directly in the graph frequency domain, an approach inspired by conventional wavelet-based signal denoising methods. We theoretically justify our approach, based on the fact that for smooth manifolds the coordinate information energy is localized in the low spectral graph wavelet sub-bands, while the noise affects all frequency bands in a similar way. Experimental results show that our proposed manifold frequency denoising (MFD) approach significantly outperforms the state of the art denoising meth- ods, and is robust to a wide range of parameter selections, e.g., the choice of k nearest neighbor connectivity of the graph. version:1
arxiv-1611-08987 | Exploiting Unlabeled Data for Neural Grammatical Error Detection | http://arxiv.org/abs/1611.08987 | id:1611.08987 author:Zhuoran Liu, Yang Liu category:cs.CL  published:2016-11-28 summary:Identifying and correcting grammatical errors in the text written by non-native writers has received increasing attention in recent years. Although a number of annotated corpora have been established to facilitate data-driven grammatical error detection and correction approaches, they are still limited in terms of quantity and coverage because human annotation is labor-intensive, time-consuming, and expensive. In this work, we propose to utilize unlabeled data to train neural network based grammatical error detection models. The basic idea is to cast error detection as a binary classification problem and derive positive and negative training examples from unlabeled data. We introduce an attention-based neural network to capture long-distance dependencies that influence the word being detected. Experiments show that the proposed approach significantly outperforms SVMs and convolutional networks with fixed-size context window. version:2
arxiv-1611-09502 | Deep Quantization: Encoding Convolutional Activations with Deep Generative Model | http://arxiv.org/abs/1611.09502 | id:1611.09502 author:Zhaofan Qiu, Ting Yao, Tao Mei category:cs.CV  published:2016-11-29 summary:Deep convolutional neural networks (CNNs) have proven highly effective for visual recognition, where learning a universal representation from activations of convolutional layer plays a fundamental problem. In this paper, we present Fisher Vector encoding with Variational Auto-Encoder (FV-VAE), a novel deep architecture that quantizes the local activations of convolutional layer in a deep generative model, by training them in an end-to-end manner. To incorporate FV encoding strategy into deep generative models, we introduce Variational Auto-Encoder model, which steers a variational inference and learning in a neural network which can be straightforwardly optimized using standard stochastic gradient method. Different from the FV characterized by conventional generative models (e.g., Gaussian Mixture Model) which parsimoniously fit a discrete mixture model to data distribution, the proposed FV-VAE is more flexible to represent the natural property of data for better generalization. Extensive experiments are conducted on three public datasets, i.e., UCF101, ActivityNet, and CUB-200-2011 in the context of video action recognition and fine-grained image classification, respectively. Superior results are reported when compared to state-of-the-art representations. Most remarkably, our proposed FV-VAE achieves to-date the best published accuracy of 94.2% on UCF101. version:1
arxiv-1611-09498 | Inertial-Based Scale Estimation for Structure from Motion on Mobile Devices | http://arxiv.org/abs/1611.09498 | id:1611.09498 author:Janne Mustaniemi, Juho Kannala, Simo S√§rkk√§, Jiri Matas, Janne Heikkil√§ category:cs.CV  published:2016-11-29 summary:Structure from motion algorithms have an inherent limitation that the reconstruction can only be determined up to the unknown scale factor. Modern mobile devices are equipped with an inertial measurement unit (IMU), which can be used for estimating the scale of the reconstruction. We propose a method that recovers the metric scale given inertial measurements and camera poses. In the process, we also perform a temporal and spatial alignment of the camera and the IMU. Therefore, our solution can be easily combined with any existing visual reconstruction software. The method can cope with noisy camera pose estimates, typically caused by motion blur or rolling shutter artifacts, via utilizing a Rauch-Tung-Striebel (RTS) smoother. Furthermore, the scale estimation is performed in the frequency domain, which provides more robustness to inaccurate sensor time stamps and noisy IMU samples than the previously used time domain representation. In contrast to previous methods, our approach has no parameters that need to be tuned for achieving a good performance. In the experiments, we show that the algorithm outperforms the state-of-the-art in both accuracy and convergence speed of the scale estimate. The accuracy of the scale is around $1\%$ from the ground truth depending on the recording. We also demonstrate that our method can improve the scale accuracy of the Project Tango's build-in motion tracking. version:1
arxiv-1611-08991 | Object Detection Free Instance Segmentation With Labeling Transformations | http://arxiv.org/abs/1611.08991 | id:1611.08991 author:Long Jin, Zeyu Chen, Zhuowen Tu category:cs.CV  published:2016-11-28 summary:Instance segmentation has attracted recent attention in computer vision and existing methods in this domain mostly have an object detection stage. In this paper, we study the intrinsic challenge of the instance segmentation problem, the presence of a quotient space (swapping the labels of different instances leads to the same result), and propose new methods that are object proposal- and object detection- free. We propose three alternative methods, namely pixel-based affinity mapping, superpixel-based affinity learning, and boundary-based component segmentation, all focusing on performing labeling transformations to cope with the quotient space problem. By adopting fully convolutional neural networks (FCN) like models, our framework attains competitive results on both the PASCAL dataset (object-centric) and the Gland dataset (texture-centric), which the existing methods are not able to do. Our work also has the advantages in its transparency, simplicity, and being all segmentation based. version:2
arxiv-1611-09482 | Fast Wavenet Generation Algorithm | http://arxiv.org/abs/1611.09482 | id:1611.09482 author:Tom Le Paine, Pooya Khorrami, Shiyu Chang, Yang Zhang, Prajit Ramachandran, Mark A. Hasegawa-Johnson, Thomas S. Huang category:cs.SD cs.DS cs.LG  published:2016-11-29 summary:This paper presents an efficient implementation of the Wavenet generation process called Fast Wavenet. Compared to a naive implementation that has complexity O(2^L) (L denotes the number of layers in the network), our proposed approach removes redundant convolution operations by caching previous calculations, thereby reducing the complexity to O(L) time. Timing experiments show significant advantages of our fast implementation over a naive one. While this method is presented for Wavenet, the same scheme can be applied anytime one wants to perform autoregressive generation or online prediction using a model with dilated convolution layers. The code for our method is publicly available. version:1
arxiv-1611-09464 | Social Behavior Prediction from First Person Videos | http://arxiv.org/abs/1611.09464 | id:1611.09464 author:Shan Su, Jung Pyo Hong, Jianbo Shi, Hyun Soo Park category:cs.CV  published:2016-11-29 summary:This paper presents a method to predict the future movements (location and gaze direction) of basketball players as a whole from their first person videos. The predicted behaviors reflect an individual physical space that affords to take the next actions while conforming to social behaviors by engaging to joint attention. Our key innovation is to use the 3D reconstruction of multiple first person cameras to automatically annotate each other's the visual semantics of social configurations. We leverage two learning signals uniquely embedded in first person videos. Individually, a first person video records the visual semantics of a spatial and social layout around a person that allows associating with past similar situations. Collectively, first person videos follow joint attention that can link the individuals to a group. We learn the egocentric visual semantics of group movements using a Siamese neural network to retrieve future trajectories. We consolidate the retrieved trajectories from all players by maximizing a measure of social compatibility---the gaze alignment towards joint attention predicted by their social formation, where the dynamics of joint attention is learned by a long-term recurrent convolutional network. This allows us to characterize which social configuration is more plausible and predict future group trajectories. version:1
arxiv-1611-09461 | Cost-Sensitive Random Pair Encoding for Multi-Label Classification | http://arxiv.org/abs/1611.09461 | id:1611.09461 author:Yao-Yuan Yang, Chih-Wei Chang, Hsuan-Tien Lin category:cs.LG  published:2016-11-29 summary:We propose a novel cost-sensitive multi-label classification algorithm called cost-sensitive random pair encoding (CSRPE). CSRPE reduces the cost-sensitive multi-label classification problem to many cost-sensitive binary classification problems through the label powerset approach followed by the classic one-versus-one decomposition. While such a naive reduction results in exponentially-many classifiers, we resolve the training challenge of building the many classifiers by random sampling, and the prediction challenge of voting from the many classifiers by nearest-neighbor decoding through casting the one-versus-one decomposition as a special case of error-correcting code. Extensive experimental results demonstrate that CSRPE achieves stable convergence and reaches better performance than other ensemble-learning and error-correcting-coding algorithms for multi-label classification. The results also justify that CSRPE is competitive with state-of-the-art cost-sensitive multi-label classification algorithms for cost-sensitive multi-label classification. version:1
arxiv-1611-09268 | MS MARCO: A Human Generated MAchine Reading COmprehension Dataset | http://arxiv.org/abs/1611.09268 | id:1611.09268 author:Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng category:cs.CL cs.IR  published:2016-11-28 summary:This paper presents our recent work on the design and development of a new, large scale dataset, which we name MS MARCO, for MAchine Reading COmprehension.This new dataset is aimed to overcome a number of well-known weaknesses of previous publicly available datasets for the same task of reading comprehension and question answering. In MS MARCO, all questions are sampled from real anonymized user queries. The context passages, from which answers in the dataset are derived, are extracted from real web documents using the most advanced version of the Bing search engine. The answers to the queries are human generated. Finally, a subset of these queries has multiple answers. We aim to release one million queries and the corresponding answers in the dataset, which, to the best of our knowledge, is the most comprehensive real-world dataset of its kind in both quantity and quality. We are currently releasing 100,000 queries with their corresponding answers to inspire work in reading comprehension and question answering along with gathering feedback from the research community. version:2
arxiv-1611-09444 | The empirical size of trained neural networks | http://arxiv.org/abs/1611.09444 | id:1611.09444 author:Kevin K. Chen, Anthony Gamst, Alden Walker category:stat.ML cs.LG  published:2016-11-29 summary:ReLU neural networks define piecewise linear functions of their inputs. However, initializing and training a neural network is very different from fitting a linear spline. In this paper, we expand empirically upon previous theoretical work to demonstrate features of trained neural networks. Standard network initialization and training produce networks vastly simpler than a naive parameter count would suggest and can impart odd features to the trained network. However, we also show the forced simplicity is beneficial and, indeed, critical for the wide success of these networks. version:1
arxiv-1611-09441 | Sentiment Analysis for Twitter : Going Beyond Tweet Text | http://arxiv.org/abs/1611.09441 | id:1611.09441 author:Lahari Poddar, Kishaloy Halder, Xianyan Jia category:cs.CL cs.SI  published:2016-11-29 summary:Analysing sentiment of tweets is important as it helps to determine the users' opinion. Knowing people's opinion is crucial for several purposes starting from gathering knowledge about customer base, e-governance, campaigning and many more. In this report, we aim to develop a system to detect the sentiment from tweets. We employ several linguistic features along with some other external sources of information to detect the sentiment of a tweet. We show that augmenting the 140 character-long tweet with information harvested from external urls shared in the tweet as well as Social Media features enhances the sentiment prediction accuracy significantly. version:1
arxiv-1611-09434 | Intelligible Language Modeling with Input Switched Affine Networks | http://arxiv.org/abs/1611.09434 | id:1611.09434 author:Jakob N. Foerster, Justin Gilmer, Jan Chorowski, Jascha Sohl-Dickstein, David Sussillo category:cs.AI cs.CL cs.LG cs.NE  published:2016-11-28 summary:The computational mechanisms by which nonlinear recurrent neural networks (RNNs) achieve their goals remains an open question. There exist many problem domains where intelligibility of the network model is crucial for deployment. Here we introduce a recurrent architecture composed of input-switched affine transformations, in other words an RNN without any nonlinearity and with one set of weights per input. We show that this architecture achieves near identical performance to traditional architectures on language modeling of Wikipedia text, for the same number of model parameters. It can obtain this performance with the potential for computational speedup compared to existing methods, by precomputing the composed affine transformations corresponding to longer input sequences. As our architecture is affine, we are able to understand the mechanisms by which it functions using linear methods. For example, we show how the network linearly combines contributions from the past to make predictions at the current time step. We show how representations for words can be combined in order to understand how context is transferred across word boundaries. Finally, we demonstrate how the system can be executed and analyzed in arbitrary bases to aid understanding. version:1
arxiv-1611-09430 | Emergence of foveal image sampling from learning to attend in visual scenes | http://arxiv.org/abs/1611.09430 | id:1611.09430 author:Brian Cheung, Eric Weiss, Bruno Olshausen category:cs.NE cs.AI cs.LG  published:2016-11-28 summary:We describe a neural attention model with a learnable retinal sampling lattice. The model is trained on a visual search task requiring the classification of an object embedded in a visual scene amidst background distractors using the smallest number of fixations. We explore the tiling properties that emerge in the model's retinal sampling lattice after training. Specifically, we show that this lattice resembles the eccentricity dependent sampling lattice of the primate retina, with a high resolution region in the fovea surrounded by a low resolution periphery. Furthermore, we find conditions where these emergent properties are amplified or eliminated providing clues to their function. version:1
arxiv-1611-09427 | Easy-setup eye movement recording system for human-computer interaction | http://arxiv.org/abs/1611.09427 | id:1611.09427 author:Manh Duong Phung, Quang Vinh Tran, Kenji Hara, Hirohito Inagaki, Masanobu Abe category:cs.HC cs.CV  published:2016-11-28 summary:Tracking the movement of human eyes is expected to yield natural and convenient applications based on human-computer interaction (HCI). To implement an effective eye-tracking system, eye movements must be recorded without placing any restriction on the user's behavior or user discomfort. This paper describes an eye movement recording system that offers free-head, simple configuration. It does not require the user to wear anything on her head, and she can move her head freely. Instead of using a computer, the system uses a visual digital signal processor (DSP) camera to detect the position of eye corner, the center of pupil and then calculate the eye movement. Evaluation tests show that the sampling rate of the system can be 300 Hz and the accuracy is about 1.8 degree/s. version:1
arxiv-1611-09405 | An End-to-End Architecture for Keyword Spotting and Voice Activity Detection | http://arxiv.org/abs/1611.09405 | id:1611.09405 author:Chris Lengerich, Awni Hannun category:cs.CL  published:2016-11-28 summary:We propose a single neural network architecture for two tasks: on-line keyword spotting and voice activity detection. We develop novel inference algorithms for an end-to-end Recurrent Neural Network trained with the Connectionist Temporal Classification loss function which allow our model to achieve high accuracy on both keyword spotting and voice activity detection without retraining. In contrast to prior voice activity detection models, our architecture does not require aligned training data and uses the same parameters as the keyword spotting model. This allows us to deploy a high quality voice activity detector with no additional memory or maintenance requirements. version:1
arxiv-1611-09394 | Material Recognition from Local Appearance in Global Context | http://arxiv.org/abs/1611.09394 | id:1611.09394 author:Gabriel Schwartz, Ko Nishino category:cs.CV  published:2016-11-28 summary:Recognition of materials has proven to be a challenging problem due to the wide variation in appearance within and between categories. Many recent material recognition methods treat materials as yet another set of labels like objects. Materials are, however, fundamentally different from objects as they have no inherent shape or defined spatial extent. This makes local material recognition particularly hard. Global image context, such as where the material is or what object it makes up, can be crucial to recognizing the material. Existing methods, however, operate on an implicit fusion of materials and context by using large receptive fields as input (i.e., large image patches). Such an approach can only take advantage of limited context as it appears during training, and will be bounded by the combinations seen in the training data. We instead show that recognizing materials purely from their local appearance and integrating separately recognized global contextual cues including objects and places leads to superior dense, per-pixel, material recognition. We achieve this by training a fully-convolutional material recognition network end-to-end with only material category supervision. We integrate object and place estimates to this network from independent CNNs. This approach avoids the necessity of preparing an infeasible amount of training data that covers the product space of materials, objects, and scenes, while fully leveraging contextual cues for dense material recognition. Experimental results validate the effectiveness of our approach and show that our method outperforms past methods that build on inseparable material and contextual information. version:1
arxiv-1611-09392 | Generating Holistic 3D Scene Abstractions for Text-based Image Retrieval | http://arxiv.org/abs/1611.09392 | id:1611.09392 author:Ang Li, Jin Sun, Joe Yue-Hei Ng, Ruichi Yu, Vlad I. Morariu, Larry S. Davis category:cs.CV cs.CG cs.IR  published:2016-11-28 summary:Spatial relationships between objects provide important information for text-based image retrieval. As users are more likely to describe a scene from a real world perspective, using 3D spatial relationships rather than 2D relationships that assume a particular viewing direction, one of the main challenges is to infer the 3D structure that bridges images with users' text descriptions. However, direct inference of 3D structure from images requires learning from large scale annotated data. Since interactions between objects can be reduced to a limited set of atomic spatial relations in 3D, we study the possibility of inferring 3D structure from a text description rather than an image, applying physical relation models to synthesize holistic 3D abstract object layouts satisfying the spatial constraints present in a textual description. We present a generic framework for retrieving images from a textual description of a scene by matching images with these generated abstract object layouts. Images are ranked by matching object detection outputs (bounding boxes) to 2D layout candidates (also represented by bounding boxes) which are obtained by projecting the 3D scenes with sampled camera directions. We validate our approach using public indoor scene datasets and show that our method outperforms an object occurrence based and a learned 2D pairwise relation based baselines. version:1
arxiv-1611-09391 | Simultaneous Clustering and Estimation of Heterogeneous Graphical Models | http://arxiv.org/abs/1611.09391 | id:1611.09391 author:Will Wei Sun, Botao Hao, Yufeng Liu, Guang Cheng category:stat.ML math.ST stat.TH  published:2016-11-28 summary:We consider joint estimation of multiple graphical models arising from heterogeneous and high-dimensional observations. Unlike most previous approaches which assume that the cluster structure is given in advance, an appealing feature of our method is to learn cluster structure while estimating heterogeneous graphical models. This is achieved via a high dimensional version of Expectation Conditional Maximization (ECM) algorithm (Meng and Rubin, 1993). A joint graphical lasso penalty is imposed in the conditional maximization step to extract both homogeneity and heterogeneity components across all clusters. Our algorithm is computationally efficient due to fast sparse learning routines and can be implemented without unsupervised learning knowledge. The superior performance of our method is demonstrated by extensive experiments and its application to a Glioblastoma cancer dataset reveals some new insights in understanding the Glioblastoma cancer. In theory, a non-asymptotic error bound is established for the output directly from our high dimensional ECM algorithm, and it consists of two quantities: statistical error (statistical accuracy) and optimization error (computational complexity). Such a result gives a theoretical guideline in terminating our ECM iterations. version:1
arxiv-1611-09384 | The Emergence of Organizing Structure in Conceptual Representation | http://arxiv.org/abs/1611.09384 | id:1611.09384 author:Brenden M. Lake, Neil D. Lawrence, Joshua B. Tenenbaum category:cs.LG stat.ML  published:2016-11-28 summary:Both scientists and children make important structural discoveries, yet their computational underpinnings are not well understood. Structure discovery has previously been formalized as probabilistic inference about the right structural form --- where form could be a tree, ring, chain, grid, etc. [Kemp & Tenenbaum (2008). The discovery of structural form. PNAS, 105(3), 10687-10692]. While this approach can learn intuitive organizations, including a tree for animals and a ring for the color circle, it assumes a strong inductive bias that considers only these particular forms, and each form is explicitly provided as initial knowledge. Here we introduce a new computational model of how organizing structure can be discovered, utilizing a broad hypothesis space with a preference for sparse connectivity. Given that the inductive bias is more general, the model's initial knowledge shows little qualitative resemblance to some of the discoveries it supports. As a consequence, the model can also learn complex structures for domains that lack intuitive description, as well as predict human property induction judgments without explicit structural forms. By allowing form to emerge from sparsity, our approach clarifies how both the richness and flexibility of human conceptual organization can coexist. version:1
arxiv-1611-09347 | Quantum Machine Learning | http://arxiv.org/abs/1611.09347 | id:1611.09347 author:Jacob Biamonte, Peter Wittek, Nicola Pancotti, Patrick Rebentrost, Nathan Wiebe, Seth Lloyd category:quant-ph cond-mat.str-el stat.ML  published:2016-11-28 summary:Recent progress implies that a crossover between machine learning and quantum information processing benefits both fields. Traditional machine learning has dramatically improved the benchmarking and control of experimental quantum computing systems, including adaptive quantum phase estimation and designing quantum computing gates. On the other hand, quantum mechanics offers tantalizing prospects to enhance machine learning, ranging from reduced computational complexity to improved generalization performance. The most notable examples include quantum enhanced algorithms for principal component analysis, quantum support vector machines, and quantum Boltzmann machines. Progress has been rapid, fostered by demonstrations of midsized quantum optimizers which are predicted to soon outperform their classical counterparts. Further, we are witnessing the emergence of a physical theory pinpointing the fundamental and natural limitations of learning. Here we survey the cutting edge of this merger and list several open problems. version:1
arxiv-1611-09345 | Unifying Multi-Domain Multi-Task Learning: Tensor and Neural Network Perspectives | http://arxiv.org/abs/1611.09345 | id:1611.09345 author:Yongxin Yang, Timothy M. Hospedales category:cs.LG  published:2016-11-28 summary:Multi-domain learning aims to benefit from simultaneously learning across several different but related domains. In this chapter, we propose a single framework that unifies multi-domain learning (MDL) and the related but better studied area of multi-task learning (MTL). By exploiting the concept of a \emph{semantic descriptor} we show how our framework encompasses various classic and recent MDL/MTL algorithms as special cases with different semantic descriptor encodings. As a second contribution, we present a higher order generalisation of this framework, capable of simultaneous multi-task-multi-domain learning. This generalisation has two mathematically equivalent views in multi-linear algebra and gated neural networks respectively. Moreover, by exploiting the semantic descriptor, it provides neural networks the capability of zero-shot learning (ZSL), where a classifier is generated for an unseen class without any training data; as well as zero-shot domain adaptation (ZSDA), where a model is generated for an unseen domain without any training data. In practice, this framework provides a powerful yet easy to implement method that can be flexibly applied to MTL, MDL, ZSL and ZSDA. version:1
arxiv-1611-09340 | Diet Networks: Thin Parameters for Fat Genomic | http://arxiv.org/abs/1611.09340 | id:1611.09340 author:Adriana Romero, Pierre Luc Carrier, Akram Erraqabi, Tristan Sylvain, Alex Auvolat, Etienne Dejoie, Marc-Andr√© Legault, Marie-Pierre Dub√©, Julie G. Hussin, Yoshua Bengio category:cs.LG  published:2016-11-28 summary:Learning tasks such as those involving genomic data often poses a serious challenge: the number of input features can be orders of magnitude larger than the number of training examples, making it difficult to avoid overfitting, even when using the known regularization techniques. We focus here on tasks in which the input is a description of the genetic variation specific to a patient, the single nucleotide polymorphisms (SNPs), yielding millions of ternary inputs. Improving the ability of deep learning to handle such datasets could have an important impact in precision medicine, where high-dimensional data regarding a particular patient is used to make predictions of interest. Even though the amount of data for such tasks is increasing, this mismatch between the number of examples and the number of inputs remains a concern. Naive implementations of classifier neural networks involve a huge number of free parameters in their first layer: each input feature is associated with as many parameters as there are hidden units. We propose a novel neural network parametrization which considerably reduces the number of free parameters. It is based on the idea that we can first learn or provide a distributed representation for each input feature (e.g. for each position in the genome where variations are observed), and then learn (with another neural network called the parameter prediction network) how to map a feature's distributed representation to the vector of parameters specific to that feature in the classifier neural network (the weights which link the value of the feature to each of the hidden units). We show experimentally on a population stratification task of interest to medical studies that the proposed approach can significantly reduce both the number of parameters and the error rate of the classifier. version:1
arxiv-1611-09333 | Dictionary Learning with Equiprobable Matching Pursuit | http://arxiv.org/abs/1611.09333 | id:1611.09333 author:Fredrik Sandin, Sergio Martin-del-Campo category:cs.LG  published:2016-11-28 summary:Sparse signal representations based on linear combinations of learned atoms have been used to obtain state-of-the-art results in several practical signal processing applications. Approximation methods are needed to process high-dimensional signals in this way because the problem to calculate optimal atoms for sparse coding is NP-hard. Here we study greedy algorithms for unsupervised learning of dictionaries of shift-invariant atoms and propose a new method where each atom is selected with the same probability on average, which corresponds to the homeostatic regulation of a recurrent convolutional neural network. Equiprobable selection can be used with several greedy algorithms for dictionary learning to ensure that all atoms adapt during training and that no particular atom is more likely to take part in the linear combination on average. We demonstrate via simulation experiments that dictionary learning with equiprobable selection results in higher entropy of the sparse representation and lower reconstruction and denoising errors, both in the case of ordinary matching pursuit and orthogonal matching pursuit with shift-invariant dictionaries. Furthermore, we show that the computational costs of the matching pursuits are lower with equiprobable selection, leading to faster and more accurate dictionary learning algorithms. version:1
arxiv-1611-09328 | Accelerated Gradient Temporal Difference Learning | http://arxiv.org/abs/1611.09328 | id:1611.09328 author:Yangchen Pan, Adam White, Martha White category:cs.AI cs.LG stat.ML  published:2016-11-28 summary:The family of temporal difference (TD) methods span a spectrum from computationally frugal linear methods like TD({\lambda}) to data efficient least squares methods. Least square methods make the best use of available data directly computing the TD solution and thus do not require tuning a typically highly sensitive learning rate parameter, but require quadratic computation and storage. Recent algorithmic developments have yielded several sub-quadratic methods that use an approximation to the least squares TD solution, but incur bias. In this paper, we propose a new family of accelerated gradient TD (ATD) methods that (1) provide similar data efficiency benefits to least-squares methods, at a fraction of the computation and storage (2) significantly reduce parameter sensitivity compared to linear TD methods, and (3) are asymptotically unbiased. We illustrate these claims with a proof of convergence in expectation and experiments on several benchmark domains and a large-scale industrial energy allocation domain. version:1
arxiv-1611-09326 | The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation | http://arxiv.org/abs/1611.09326 | id:1611.09326 author:Simon J√©gou, Michal Drozdzal, David Vazquez, Adriana Romero, Yoshua Bengio category:cs.CV  published:2016-11-28 summary:State-of-the-art approaches for semantic image segmentation are built on Convolutional Neural Networks (CNNs). The typical segmentation architecture is composed of (a) a downsampling path responsible for extracting coarse semantic features, followed by (b) an upsampling path trained to recover the input image resolution at the output of the model and, optionally, (c) a post-processing module (e.g. Conditional Random Fields) to refine the model predictions. Recently, a new CNN architecture, Densely Connected Convolutional Networks (DenseNets), has shown excellent results on image classification tasks. The idea of DenseNets is based on the observation that if each layer is directly connected to every other layer in a feed-forward fashion then the network will be more accurate and easier to train. In this paper, we extend DenseNets to deal with the problem of semantic segmentation. We achieve state-of-the-art results on urban scene benchmark datasets such as CamVid and Gatech, without any further post-processing module nor pretraining. Moreover, due to smart construction of the model, our approach has much less parameters than currently published best entries for these datasets. version:1
arxiv-1611-09325 | Natural Illumination from Multiple Materials Using Deep Learning | http://arxiv.org/abs/1611.09325 | id:1611.09325 author:Stamatios Georgoulis, Konstantinos Rematas, Tobias Ritschel, Mario Fritz, Tinne Tuytelaars, Luc Van Gool category:cs.CV  published:2016-11-28 summary:Recovering natural illumination from a single Low-Dynamic Range (LDR) image is a challenging task. To remedy this situation we exploit two properties often found in everyday images. First, images rarely show a single material, but rather multiple ones that all reflect the same illumination. However, the appearance of each material is observed only for some surface orientations, not all. Second, parts of the illumination are often directly observed in the background, without being affected by reflection. Typically, this directly observed part of the illumination is even smaller. We propose a deep Convolutional Neural Network (CNN) that combines prior knowledge about the statistics of illumination and reflectance with an input that makes explicit use of these two observations. Our approach maps multiple partial LDR material observations represented as reflectance maps and a background image to a spherical High-Dynamic Range (HDR) illumination map. For training and testing we propose a new data set comprising of synthetic and real images with multiple materials observed under the same illumination. Qualitative and quantitative evidence shows how both multi-material and using a background are essential to improve illumination estimations. version:1
arxiv-1611-09321 | Improving Policy Gradient by Exploring Under-appreciated Rewards | http://arxiv.org/abs/1611.09321 | id:1611.09321 author:Ofir Nachum, Mohammad Norouzi, Dale Schuurmans category:cs.LG cs.AI  published:2016-11-28 summary:This paper presents a novel form of policy gradient for model-free reinforcement learning (RL) with improved exploration properties. Current policy-based methods use entropy regularization to encourage undirected exploration of the reward landscape, which is ineffective in high dimensional spaces with sparse rewards. We propose a more directed exploration strategy that promotes exploration of {\em under-appreciated reward} regions. An action sequence is considered under-appreciated if its log-probability under the current policy under-estimates its \mbox{resulting} reward. The proposed exploration strategy is easy to implement, requiring small modifications to an implementation of the REINFORCE algorithm. We evaluate the approach on a set of algorithmic tasks that have long challenged RL methods. Our approach reduces hyper-parameter sensitivity and demonstrates significant improvements over baseline methods. Our algorithm successfully solves a benchmark multi-digit addition task and generalizes to long sequences. This is, to our knowledge, the first time that a pure RL method has solved addition using only reward feedback. version:1
arxiv-1611-09312 | Hierarchical Boundary-Aware Neural Encoder for Video Captioning | http://arxiv.org/abs/1611.09312 | id:1611.09312 author:Lorenzo Baraldi, Costantino Grana, Rita Cucchiara category:cs.CV  published:2016-11-28 summary:The use of Recurrent Neural Networks for video captioning has recently gained a lot of attention, since they can be used both to encode the input video and to generate the corresponding description. In this paper, we present a recurrent video encoding scheme which can discover and leverage the hierarchical structure of the video. Unlike the classical encoder-decoder approach, in which a video is encoded continuously by a recurrent layer, we propose a novel LSTM cell, which can identify discontinuity points between frames or segments and modify the temporal connections of the encoding layer accordingly. We evaluate our approach on three large-scale datasets: the Montreal Video Annotation dataset, the MPII Movie Description dataset and the Microsoft Video Description Corpus. Experiments show that our approach can discover appropriate hierarchical representations of input videos and improve the state of the art results on movie description datasets. version:1
arxiv-1611-09309 | Gaze Embeddings for Zero-Shot Image Classification | http://arxiv.org/abs/1611.09309 | id:1611.09309 author:Nour Karessli, Zeynep Akata, Andreas Bulling, Bernt Schiele category:cs.CV  published:2016-11-28 summary:Zero-shot image classification using auxiliary information, such as attributes describing discriminative object properties, requires time-consuming annotation by domain experts. We instead propose a method that relies on human gaze as auxiliary information, exploiting that even non-expert users have a natural ability to judge class membership. We present a data collection paradigm that involves a discrimination task to increase the information content obtained from gaze data. Our method extracts discriminative descriptors from the data and learns a compatibility function between image and gaze using three novel gaze embeddings: Gaze Histograms (GH), Gaze Features with Grid (GFG) and Gaze Features with Sequence (GFS). We introduce two new gaze-annotated datasets for fine-grained image classification and show that human gaze data is indeed class discriminative, provides a competitive alternative to expert-annotated attributes, and outperforms other baselines for zero-shot image classification. version:1
arxiv-1611-09288 | Dense Prediction on Sequences with Time-Dilated Convolutions for Speech Recognition | http://arxiv.org/abs/1611.09288 | id:1611.09288 author:Tom Sercu, Vaibhava Goel category:cs.CL cs.LG cs.NE  published:2016-11-28 summary:In computer vision pixelwise dense prediction is the task of predicting a label for each pixel in the image. Convolutional neural networks achieve good performance on this task, while being computationally efficient. In this paper we carry these ideas over to the problem of assigning a sequence of labels to a set of speech frames, a task commonly known as framewise classification. We show that dense prediction view of framewise classification offers several advantages and insights, including computational efficiency and the ability to apply batch normalization. When doing dense prediction we pay specific attention to strided pooling in time and introduce an asymmetric dilated convolution, called time-dilated convolution, that allows for efficient and elegant implementation of pooling in time. We show that by using time-dilated convolutions with a very deep VGG-style CNN with batch normalization, we achieve best published single model accuracy result on the switchboard-2000 benchmark dataset. version:1
arxiv-1611-09238 | Improving Multi-Document Summarization via Text Classification | http://arxiv.org/abs/1611.09238 | id:1611.09238 author:Ziqiang Cao, Wenjie Li, Sujian Li, Furu Wei category:cs.CL cs.IR  published:2016-11-28 summary:Developed so far, multi-document summarization has reached its bottleneck due to the lack of sufficient training data and diverse categories of documents. Text classification just makes up for these deficiencies. In this paper, we propose a novel summarization system called TCSum, which leverages plentiful text classification data to improve the performance of multi-document summarization. TCSum projects documents onto distributed representations which act as a bridge between text classification and summarization. It also utilizes the classification results to produce summaries of different styles. Extensive experiments on DUC generic multi-document summarization datasets show that, TCSum can achieve the state-of-the-art performance without using any hand-crafted features and has the capability to catch the variations of summary styles with respect to different text categories. version:1
arxiv-1611-09235 | Joint Copying and Restricted Generation for Paraphrase | http://arxiv.org/abs/1611.09235 | id:1611.09235 author:Ziqiang Cao, Chuwei Luo, Wenjie Li, Sujian Li category:cs.CL cs.IR  published:2016-11-28 summary:Many natural language generation tasks, such as abstractive summarization and text simplification, are paraphrase-orientated. In these tasks, copying and rewriting are two main writing modes. Most previous sequence-to-sequence (Seq2Seq) models use a single decoder and neglect this fact. In this paper, we develop a novel Seq2Seq model to fuse a copying decoder and a restricted generative decoder. The copying decoder finds the position to be copied based on a typical attention model. The generative decoder produces words limited in the source-specific vocabulary. To combine the two decoders and determine the final output, we develop a predictor to predict the mode of copying or rewriting. This predictor can be guided by the actual writing mode in the training data. We conduct extensive experiments on two different paraphrase datasets. The result shows that our model outperforms the state-of-the-art approaches in terms of both informativeness and language quality. version:1
arxiv-1611-09232 | Efficient Convolutional Auto-Encoding via Random Convexification and Frequency-Domain Minimization | http://arxiv.org/abs/1611.09232 | id:1611.09232 author:Meshia C√©dric Oveneke, Mitchel Aliosha-Perez, Yong Zhao, Dongmei Jiang, Hichem Sahli category:stat.ML cs.LG cs.NE  published:2016-11-28 summary:The omnipresence of deep learning architectures such as deep convolutional neural networks (CNN)s is fueled by the synergistic combination of ever-increasing labeled datasets and specialized hardware. Despite the indisputable success, the reliance on huge amounts of labeled data and specialized hardware can be a limiting factor when approaching new applications. To help alleviating these limitations, we propose an efficient learning strategy for layer-wise unsupervised training of deep CNNs on conventional hardware in acceptable time. Our proposed strategy consists of randomly convexifying the reconstruction contractive auto-encoding (RCAE) learning objective and solving the resulting large-scale convex minimization problem in the frequency domain via coordinate descent (CD). The main advantages of our proposed learning strategy are: (1) single tunable optimization parameter; (2) fast and guaranteed convergence; (3) possibilities for full parallelization. Numerical experiments show that our proposed learning strategy scales (in the worst case) linearly with image size, number of filters and filter size. version:1
arxiv-1611-09226 | Robust Variational Inference | http://arxiv.org/abs/1611.09226 | id:1611.09226 author:Michael Figurnov, Kirill Struminsky, Dmitry Vetrov category:cs.LG  published:2016-11-28 summary:Variational inference is a powerful tool for approximate inference. However, it mainly focuses on the evidence lower bound as variational objective and the development of other measures for variational inference is a promising area of research. This paper proposes a robust modification of evidence and a lower bound for the evidence, which is applicable when the majority of the training set samples are random noise objects. We provide experiments for variational autoencoders to show advantage of the objective over the evidence lower bound on synthetic datasets obtained by adding uninformative noise objects to MNIST and OMNIGLOT. Additionally, for the original MNIST and OMNIGLOT datasets we observe a small improvement over the non-robust evidence lower bound. version:1
arxiv-1611-09224 | ECO: Efficient Convolution Operators for Tracking | http://arxiv.org/abs/1611.09224 | id:1611.09224 author:Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, Michael Felsberg category:cs.CV  published:2016-11-28 summary:In recent years, Discriminative Correlation Filter (DCF) based methods have significantly advanced the state-of-the-art in tracking. However, in the pursuit of ever increasing tracking performance, their characteristic speed and real-time capability have gradually faded. Further, the increasingly complex models, with massive number of trainable parameters, have introduced the risk of severe over-fitting. In this work, we tackle the key causes behind the problems of computational complexity and over-fitting, with the aim of simultaneously improving both speed and performance. We revisit the core DCF formulation and introduce: (i) a factorized convolution operator, which drastically reduces the number of parameters in the model; (ii) a compact generative model of the training sample distribution, that significantly reduces memory and time complexity, while providing better diversity of samples; (iii) a conservative model update strategy with improved robustness and reduced complexity. We perform comprehensive experiments on four benchmarks: VOT2016, UAV123, OTB-2015, and TempleColor. When using expensive deep features, our tracker provides a 20-fold speedup and achieves a 13.3% relative gain in Expected Average Overlap compared to the top ranked method in the VOT2016 challenge. Moreover, our fast variant, using hand-crafted features, operates at 60 Hz on a single CPU, while obtaining 64.8% AUC on OTB-2015. version:1
arxiv-1611-09207 | AutoMOS: Learning a non-intrusive assessor of naturalness-of-speech | http://arxiv.org/abs/1611.09207 | id:1611.09207 author:Brian Patton, Yannis Agiomyrgiannakis, Michael Terry, Kevin Wilson, Rif A. Saurous, D. Sculley category:cs.CL cs.LG stat.ML  published:2016-11-28 summary:Developers of text-to-speech synthesizers (TTS) often make use of human raters to assess the quality of synthesized speech. We demonstrate that we can model human raters' mean opinion scores (MOS) of synthesized speech using a deep recurrent neural network whose inputs consist solely of a raw waveform. Our best models provide utterance-level estimates of MOS only moderately inferior to sampled human ratings, as shown by Pearson and Spearman correlations. When multiple utterances are scored and averaged, a scenario common in synthesizer quality assessment, AutoMOS achieves correlations approaching those of human raters. The AutoMOS model has a number of applications, such as the ability to explore the parameter space of a speech synthesizer without requiring a human-in-the-loop. version:1
arxiv-1611-09203 | Computational Mapping of the Ground Reflectivity with Laser Scanners | http://arxiv.org/abs/1611.09203 | id:1611.09203 author:Juan Castorena category:cs.CV  published:2016-11-28 summary:In this investigation we focus on the problem of mapping the ground reflectivity with multiple laser scanners mounted on mobile robots/vehicles. The problem originates because regions of the ground become populated with a varying number of reflectivity measurements whose value depends on the observer and its corresponding perspective. Here, we propose a novel automatic, data-driven computational mapping framework specifically aimed at preserving edge sharpness in the map reconstruction process and that considers the sources of measurement variation. Our new formulation generates map-perspective gradients and applies sub-set selection fusion and de-noising operators to these through iterative algorithms that minimize an $\ell_1$ sparse regularized least squares formulation. Reconstruction of the ground reflectivity is then carried out based on Poisson's formulation posed as an $\ell_2$ term promoting consistency with the fused gradient of map-perspectives and a term that ensures equality constraints with reference measurement data. We demonstrate our new framework outperforms the capabilities of existing ones with experiments realized on Ford's fleet of autonomous vehicles. For example, we show we can achieve map enhancement (i.e., contrast enhancement), artifact removal, de-noising and map-stitching without requiring an additional reflectivity adjustment to calibrate sensors to the specific mounting and robot/vehicle motion. version:1
arxiv-1611-09180 | Image Based Appraisal of Real Estate Properties | http://arxiv.org/abs/1611.09180 | id:1611.09180 author:Quanzeng You, Ran Pang, Jiebo Luo category:cs.CV cs.LG  published:2016-11-28 summary:Real estate appraisal, which is the process of estimating the price for real estate properties, is crucial for both buys and sellers as the basis for negotiation and transaction. Traditionally, the repeat sales model has been widely adopted to estimate real estate price. However, it depends the design and calculation of a complex economic related index, which is challenging to estimate accurately. Today, real estate brokers provide easy access to detailed online information on real estate properties to their clients. We are interested in estimating the real estate price from these large amounts of easily accessed data. In particular, we analyze the prediction power of online house pictures, which is one of the key factors for online users to make a potential visiting decision. The development of robust computer vision algorithms makes the analysis of visual content possible. In this work, we employ a Recurrent Neural Network (RNN) to predict real estate price using the state-of-the-art visual features. The experimental results indicate that our model outperforms several of other state-of-the-art baseline algorithms in terms of both mean absolute error (MAE) and mean absolute percentage error (MAPE). version:1
arxiv-1611-09162 | Who's that Actor? Automatic Labelling of Actors in TV series starting from IMDB Images | http://arxiv.org/abs/1611.09162 | id:1611.09162 author:Rahaf Aljundi, Punarjay Chakravarty, Tinne Tuytelaars category:cs.CV  published:2016-11-28 summary:In this work, we aim at automatically labeling actors in a TV series. Rather than relying on transcripts and subtitles, as has been demonstrated in the past, we show how to achieve this goal starting from a set of example images of each of the main actors involved, collected from the Internet Movie Database (IMDB). The problem then becomes one of domain adaptation: actors' IMDB photos are typically taken at awards ceremonies and are quite different from their appearances in TV series. In each series as well, there is considerable change in actor appearance due to makeup, lighting, ageing, etc. To bridge this gap, we propose a graph-matching based self-labelling algorithm, which we coin HSL (Hungarian Self Labeling). Further, we propose a new edge cost to be used in this context, as well as an extension that is more robust to outliers, where prototypical faces for each of the actors are selected based on a hierarchical clustering procedure. We conduct experiments with 15 episodes from 3 different TV series and demonstrate automatic annotation with an accuracy of 90% and up. version:1
arxiv-1611-09159 | Sparse 3D Convolutional Neural Networks for Large-Scale Shape Retrieval | http://arxiv.org/abs/1611.09159 | id:1611.09159 author:Alexandr Notchenko, Ermek Kapushev, Evgeny Burnaev category:cs.CV  published:2016-11-28 summary:In this paper we present preliminary results of performance evaluation of S3DCNN - a Sparse 3D Convolutional Neural Network - on a large-scale 3D Shape benchmark ModelNet40, and measure how it is impacted by voxel resolution of input shape. We demonstrate comparable classification and retrieval performance to state-of-the-art models, but with much less computational costs in training and inference phases. We also notice that benefits of higher input resolution can be limited by an ability of a neural network to generalize high level features. version:1
arxiv-1611-09149 | Dynamic landscape models of coevolutionary games | http://arxiv.org/abs/1611.09149 | id:1611.09149 author:Hendrik Richter category:q-bio.PE cs.NE physics.bio-ph  published:2016-11-28 summary:Players of coevolutionary games may update not only their strategies but also their networks of interaction. Based on interpreting the payoff of players as fitness, dynamic landscape models are proposed. The modeling procedure is carried out for Prisoner's Dilemma (PD) and Snowdrift (SD) games that both use either birth-death (BD) or death-birth (DB) strategy updating. With the main focus on using dynamic fitness landscapes as an alternative tool for analyzing coevolutionary games, landscape measures such as modality, ruggedness and information content are computed and analyzed. In addition, fixation properties of the games and quantifiers characterizing the network of interaction are calculated numerically. Relations are established between landscape properties expressed by landscape measures and quantifiers of coevolutionary game dynamics such as fixation probabilities, fixation times and network properties version:1
arxiv-1611-09139 | Proceedings of NIPS 2016 Workshop on Interpretable Machine Learning for Complex Systems | http://arxiv.org/abs/1611.09139 | id:1611.09139 author:Andrew Gordon Wilson, Been Kim, William Herlands category:stat.ML  published:2016-11-28 summary:This is the Proceedings of NIPS 2016 Workshop on Interpretable Machine Learning for Complex Systems, held in Barcelona, Spain on December 9, 2016 version:1
arxiv-1611-09119 | Unsupervised Feature Learning With Symmetrically Connected Convolutional Denoising Auto-encoders | http://arxiv.org/abs/1611.09119 | id:1611.09119 author:Jianfeng Dong, Xiao-Jiao Mao, Chunhua Shen, Yu-Bin Yang category:cs.CV  published:2016-11-28 summary:Convolutional neural networks (CNNs) have shown their power on many computer vision tasks.However, there are still some limitations, including their dependency to large scale labeled training data and sensitivity to weight initialization.In this paper, we try to address these two problems by proposing a simple yet powerful CNN based denoising auto-encoder which can be trained end-to-end in an unsupervised manner.The network architecture we employ is a fully convolutional auto-encoder with symmetric encoder-decoder connections.The proposed method can not only reconstruct clean images from corrupted ones, but also learn image representation through the reconstruction training.It can further be adapted to find data driven network initialization without using extra training data.Experimental results show that our network can learn good feature from unlabeled data, which can be easily transferred to different high level vision tasks such as image classification and semantic segmentation.The data driven initialization method based on the convolutional auto-encoder is also competitive. version:1
arxiv-1611-09100 | Learning to Compose Words into Sentences with Reinforcement Learning | http://arxiv.org/abs/1611.09100 | id:1611.09100 author:Dani Yogatama, Phil Blunsom, Chris Dyer, Edward Grefenstette, Wang Ling category:cs.CL  published:2016-11-28 summary:We use reinforcement learning to learn tree-structured neural networks for computing representations of natural language sentences. In contrast with prior work on tree-structured models in which the trees are either provided as input or predicted using supervision from explicit treebank annotations, the tree structures in this work are optimized to improve performance on a downstream task. Experiments demonstrate the benefit of learning task-specific composition orders, outperforming both sequential encoders and recursive encoders based on treebank annotations. We analyze the induced trees and show that while they discover some linguistically intuitive structures (e.g., noun phrases, simple verb phrases), they are different than conventional English syntactic structures. version:1
arxiv-1611-09099 | On the Role and the Importance of Features for Background Modeling and Foreground Detection | http://arxiv.org/abs/1611.09099 | id:1611.09099 author:Thierry Bouwmans, Caroline Silva, Cristina Marghes, Mohammed Sami Zitouni, Harish Bhaskar, Carl Frelicot category:cs.CV  published:2016-11-28 summary:Background modeling has emerged as a popular foreground detection technique for various applications in video surveillance. Background modeling methods have become increasing efficient in robustly modeling the background and hence detecting moving objects in any visual scene. Although several background subtraction and foreground detection have been proposed recently, no traditional algorithm today still seem to be able to simultaneously address all the key challenges of illumination variation, dynamic camera motion, cluttered background and occlusion. This limitation can be attributed to the lack of systematic investigation concerning the role and importance of features within background modeling and foreground detection. With the availability of a rather large set of invariant features, the challenge is in determining the best combination of features that would improve accuracy and robustness in detection. The purpose of this study is to initiate a rigorous and comprehensive survey of features used within background modeling and foreground detection. Further, this paper presents a systematic experimental and statistical analysis of techniques that provide valuable insight on the trends in background modeling and use it to draw meaningful recommendations for practitioners. In this paper, a preliminary review of the key characteristics of features based on the types and sizes is provided in addition to investigating their intrinsic spectral, spatial and temporal properties. Furthermore, improvements using statistical and fuzzy tools are examined and techniques based on multiple features are benchmarked against reliability and selection criterion. Finally, a description of the different resources available such as datasets and codes is provided. version:1
arxiv-1611-09083 | Prediction of Video Popularity in the Absence of Reliable Data from Video Hosting Services: Utility of Traces Left by Users on the Web | http://arxiv.org/abs/1611.09083 | id:1611.09083 author:Alexey Drutsa, Gleb Gusev, Pavel Serdyukov category:cs.IR cs.HC cs.MM stat.ML 68T05  62F07  published:2016-11-28 summary:With the growth of user-generated content, we observe the constant rise of the number of companies, such as search engines, content aggregators, etc., that operate with tremendous amounts of web content not being the services hosting it. Thus, aiming to locate the most important content and promote it to the users, they face the need of estimating the current and predicting the future content popularity. In this paper, we approach the problem of video popularity prediction not from the side of a video hosting service, as done in all previous studies, but from the side of an operating company, which provides a popular video search service that aggregates content from different video hosting websites. We investigate video popularity prediction based on features from three primary sources available for a typical operating company: first, the content hosting provider may deliver its data via its API, second, the operating company makes use of its own search and browsing logs, third, the company crawls information about embeds of a video and links to a video page from publicly available resources on the Web. We show that video popularity prediction based on the embed and link data coupled with the internal search and browsing data significantly improves video popularity prediction based only on the data provided by the video hosting and can even adequately replace the API data in the cases when it is partly or completely unavailable. version:1
arxiv-1611-09078 | Social Scene Understanding: End-to-End Multi-Person Action Localization and Collective Activity Recognition | http://arxiv.org/abs/1611.09078 | id:1611.09078 author:Timur Bagautdinov, Alexandre Alahi, Fran√ßois Fleuret, Pascal Fua, Silvio Savarese category:cs.CV  published:2016-11-28 summary:We present a unified framework for understanding human social behaviors in raw image sequences. Our model jointly detects multiple individuals, infers their social actions, and estimates the collective actions with a single feed-forward pass through a neural network. We propose a single architecture that does not rely on external detection algorithms but rather is trained end-to-end to generate dense proposal maps that are refined via a novel inference scheme. The temporal consistency is handled via a person-level matching Recurrent Neural Network. The complete model takes as input a sequence of frames and outputs detections along with the estimates of individual actions and collective activities. We demonstrate state-of-the-art performance of our algorithm on multiple publicly available benchmarks. version:1
arxiv-1611-09053 | Bidirectional Multirate Reconstruction for Temporal Modeling in Videos | http://arxiv.org/abs/1611.09053 | id:1611.09053 author:Linchao Zhu, Zhongwen Xu, Yi Yang category:cs.CV  published:2016-11-28 summary:Despite the recent success of neural networks in image feature learning, a major problem in the video domain is the lack of sufficient labeled data for learning to model temporal information. In this paper, we propose an unsupervised temporal modeling method that learns from untrimmed videos. The speed of motion varies constantly, e.g., a man may run quickly or slowly. We therefore train a Multirate Visual Recurrent Model (MVRM) by encoding frames of a clip with different intervals. This learning process makes the learned model more capable of dealing with motion speed variance. Given a clip sampled from a video, we use its past and future neighboring clips as the temporal context, and reconstruct the two temporal transitions, i.e., present$\rightarrow$past transition and present$\rightarrow$future transition, reflecting the temporal information in different views. The proposed method exploits the two transitions simultaneously by incorporating a bidirectional reconstruction which consists of a backward reconstruction and a forward reconstruction. We apply the proposed method to two challenging video tasks, i.e., complex event detection and video captioning, in which it achieves state-of-the-art performance. Notably, our method generates the best single feature for event detection with a relative improvement of 10.4% on the MEDTest-13 dataset and achieves the best performance in video captioning across all evaluation metrics on the YouTube2Text dataset. version:1
arxiv-1611-09051 | Deep, Dense, and Low-Rank Gaussian Conditional Random Fields | http://arxiv.org/abs/1611.09051 | id:1611.09051 author:Siddhartha Chandra, Iasonas Kokkinos category:cs.CV  published:2016-11-28 summary:In this work we introduce a fully-connected graph structure in the Deep Gaussian Conditional Random Field (G-CRF) model. For this we express the pairwise interactions between pixels as the inner-products of low-dimensional embeddings, delivered by a new subnetwork of a deep architecture. We efficiently minimize the resulting energy by solving the resulting low-rank linear system with conjugate gradients, and derive an analytic expression for the gradient of our embeddings which allows us to train them end-to-end with backpropagation. We demonstrate the merit of our approach by achieving state of the art results on three challenging Computer Vision benchmarks, namely semantic segmentation, human parts segmentation, and saliency estimation. Our implementation is fully GPU based, built on top of the Caffe library, and will be made publicly available. version:1
arxiv-1611-08402 | Geometric deep learning on graphs and manifolds using mixture model CNNs | http://arxiv.org/abs/1611.08402 | id:1611.08402 author:Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodol√†, Jan Svoboda, Michael M. Bronstein category:cs.CV  published:2016-11-25 summary:Deep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclidean-structured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graph- and 3D shape analysis and show that it consistently outperforms previous approaches. version:2
arxiv-1611-08512 | Person Re-Identification by Unsupervised Video Matching | http://arxiv.org/abs/1611.08512 | id:1611.08512 author:Xiaolong Ma, Xiatian Zhu, Shaogang Gong, Xudong Xie, Jianming Hu, Kin-Man Lam, Yisheng Zhong category:cs.CV  published:2016-11-25 summary:Most existing person re-identification (ReID) methods rely only on the spatial appearance information from either one or multiple person images, whilst ignore the space-time cues readily available in video or image-sequence data. Moreover, they often assume the availability of exhaustively labelled cross-view pairwise data for every camera pair, making them non-scalable to ReID applications in real-world large scale camera networks. In this work, we introduce a novel video based person ReID method capable of accurately matching people across views from arbitrary unaligned image-sequences without any labelled pairwise data. Specifically, we introduce a new space-time person representation by encoding multiple granularities of spatio-temporal dynamics in form of time series. Moreover, a Time Shift Dynamic Time Warping (TS-DTW) model is derived for performing automatically alignment whilst achieving data selection and matching between inherently inaccurate and incomplete sequences in a unified way. We further extend the TS-DTW model for accommodating multiple feature-sequences of an image-sequence in order to fuse information from different descriptions. Crucially, this model does not require pairwise labelled training data (i.e. unsupervised) therefore readily scalable to large scale camera networks of arbitrary camera pairs without the need for exhaustive data annotation for every camera pair. We show the effectiveness and advantages of the proposed method by extensive comparisons with related state-of-the-art approaches using two benchmarking ReID datasets, PRID2011 and iLIDS-VID. version:2
arxiv-1611-09028 | Analyzing Features for the Detection of Happy Endings in German Novels | http://arxiv.org/abs/1611.09028 | id:1611.09028 author:Fotis Jannidis, Isabella Reger, Albin Zehe, Martin Becker, Lena Hettinger, Andreas Hotho category:cs.IR cs.AI cs.CL  published:2016-11-28 summary:With regard to a computational representation of literary plot, this paper looks at the use of sentiment analysis for happy ending detection in German novels. Its focus lies on the investigation of previously proposed sentiment features in order to gain insight about the relevance of specific features on the one hand and the implications of their performance on the other hand. Therefore, we study various partitionings of novels, considering the highly variable concept of "ending". We also show that our approach, even though still rather simple, can potentially lead to substantial findings relevant to literary studies. version:1
arxiv-1611-09026 | Awesome Typography: Statistics-Based Text Effects Transfer | http://arxiv.org/abs/1611.09026 | id:1611.09026 author:Shuai Yang, Jiaying Liu, Zhouhui Lian, Zongming Guo category:cs.CV  published:2016-11-28 summary:In this work, we explore the problem of generating fantastic special-effects for the typography. It is quite challenging due to the model diversities to illustrate varied text effects for different characters. To address this issue, our key idea is to exploit the analytics on the high regularity of the spatial distribution for text effects to guide the synthesis process. Specifically, we characterize the stylized patches by their normalized positions and the optimal scales to depict their style elements. Our method first estimates these two features and derives their correlation statistically. They are then converted into soft constraints for texture transfer to accomplish adaptive multi-scale texture synthesis and to make style element distribution uniform. It allows our algorithm to produce artistic typography that fits for both local texture patterns and the global spatial distribution in the example. Experimental results demonstrate the superiority of our method for various text effects over conventional style transfer methods. In addition, we validate the effectiveness of our algorithm with extensive artistic typography library generation. version:1
arxiv-1611-09020 | Developing a cardiovascular disease risk-factors annotated corpus of Chinese electronic medical records | http://arxiv.org/abs/1611.09020 | id:1611.09020 author:Jia Su, Bin He, Yi Guan, Jingchi Jiang, Jinfeng Yang category:cs.CL I.2.7  published:2016-11-28 summary:Objective The goal of this study was to build a corpus of cardiovascular disease (CVD) risk-factor annotations based on Chinese electronic medical records (CEMRs). This corpus is intended to be used to develop a risk-factor information extraction system that, in turn, can be applied as a foundation for the further study of the progress of risk-factors and CVD. Materials and Methods We designed a light-annotation-task to capture CVD-risk-factors with indicators, temporal attributes and assertions explicitly displayed in the records. The task included: 1) preparing data; 2) creating guidelines for capturing annotations (these were created with the help of clinicians); 3) proposing annotation method including building the guidelines draft, training the annotators and updating the guidelines, and corpus construction. Results The outcome of this study was a risk-factor-annotated corpus based on de-identified discharge summaries and progress notes from 600 patients. Built with the help of specialists, this corpus has an inter-annotator agreement (IAA) F1-measure of 0.968, indicating a high reliability. Discussion Our annotations included 12 CVD-risk-factors such as Hypertension and Diabetes. The annotations can be applied as a powerful tool to the management of these chronic diseases and the prediction of CVD. Conclusion Guidelines for capturing CVD-risk-factor annotations from CEMRs were proposed and an annotated corpus was established. The obtained document-level annotations can be applied in future studies to monitor risk-factors and CVD over the long term. version:1
arxiv-1611-09010 | 3D Human Pose Estimation from a Single Image via Distance Matrix Regression | http://arxiv.org/abs/1611.09010 | id:1611.09010 author:Francesc Moreno-Noguer category:cs.CV  published:2016-11-28 summary:This paper addresses the problem of 3D human pose estimation from a single image. We follow a standard two-step pipeline by first detecting the 2D position of the $N$ body joints, and then using these observations to infer 3D pose. For the first step, we use a recent CNN-based detector. For the second step, most existing approaches perform 2$N$-to-3$N$ regression of the Cartesian joint coordinates. We show that more precise pose estimates can be obtained by representing both the 2D and 3D human poses using $N\times N$ distance matrices, and formulating the problem as a 2D-to-3D distance matrix regression. For learning such a regressor we leverage on simple Neural Network architectures, which by construction, enforce positivity and symmetry of the predicted matrices. The approach has also the advantage to naturally handle missing observations and allowing to hypothesize the position of non-observed joints. Quantitative results on Humaneva and Human3.6M datasets demonstrate consistent performance gains over state-of-the-art. Qualitative evaluation on the images in-the-wild of the LSP dataset, using the regressor learned on Human3.6M, reveals very promising generalization results. version:1
arxiv-1611-09007 | Hyperspectral CNN Classification with Limited Training Samples | http://arxiv.org/abs/1611.09007 | id:1611.09007 author:Lloyd Windrim, Rishi Ramakrishnan, Arman Melkumyan, Richard Murphy category:cs.CV  published:2016-11-28 summary:Hyperspectral imaging sensors are becoming increasingly popular in robotics applications such as agriculture and mining, and allow per-pixel thematic classification of materials in a scene based on their unique spectral signatures. Recently, convolutional neural networks have shown remarkable performance for classification tasks, but require substantial amounts of labelled training data. This data must sufficiently cover the variability expected to be encountered in the environment. For hyperspectral data, one of the main variations encountered outdoors is due to incident illumination, which can change in spectral shape and intensity depending on the scene geometry. For example, regions occluded from the sun have a lower intensity and their incident irradiance skewed towards shorter wavelengths. In this work, a data augmentation strategy based on relighting is used during training of a hyperspectral convolutional neural network. It allows training to occur in the outdoor environment given only a small labelled region, which does not need to sufficiently represent the geometric variability of the entire scene. This is important for applications where obtaining large amounts of training data is labourious, hazardous or difficult, such as labelling pixels within shadows. Radiometric normalisation approaches for pre-processing the hyperspectral data are analysed and it is shown that methods based on the raw pixel data are sufficient to be used as input for the classifier. This removes the need for external hardware such as calibration boards, which can restrict the application of hyperspectral sensors in robotics applications. Experiments to evaluate the classification system are carried out on two datasets captured from a field-based platform. version:1
arxiv-1611-08998 | DeepSetNet: Predicting Sets with Deep Neural Networks | http://arxiv.org/abs/1611.08998 | id:1611.08998 author:Seyed Hamid Rezatofighi, Vijay Kumar B G, Anton Milan, Ehsan Abbasnejad, Anthony Dick, Ian Reid category:cs.CV cs.AI cs.LG  published:2016-11-28 summary:This paper addresses the task of set prediction using deep learning. This is important because the output of many computer vision tasks, including image tagging and object detection, are naturally expressed as sets of entities rather than vectors. As opposed to a vector, the size of a set is not fixed in advance, and it is invariant to the ordering of entities within it. We define a likelihood for a set distribution and learn its parameters using a deep neural network. We also derive a loss for predicting a discrete distribution corresponding to set cardinality. Set prediction is demonstrated on the problems of multi-class image classification and pedestrian detection. Our approach yields state-of-the-art results in both cases on standard datasets. version:1
arxiv-1611-08986 | Improving Fully Convolution Network for Semantic Segmentation | http://arxiv.org/abs/1611.08986 | id:1611.08986 author:Bing Shuai, Ting Liu, Gang Wang category:cs.CV  published:2016-11-28 summary:Fully Convolution Networks (FCN) have achieved great success in dense prediction tasks including semantic segmentation. In this paper, we start from discussing FCN by understanding its architecture limitations in building a strong segmentation network. Next, we present our Improved Fully Convolution Network (IFCN). In contrast to FCN, IFCN introduces a context network that progressively expands the receptive fields of feature maps. In addition, dense skip connections are added so that the context network can be effectively optimized. More importantly, these dense skip connections enable IFCN to fuse rich-scale context to make reliable predictions. Empirically, those architecture modifications are proven to be significant to enhance the segmentation performance. Without engaging any contextual post-processing, IFCN significantly advances the state-of-the-arts on ADE20K (ImageNet scene parsing), Pascal Context, Pascal VOC 2012 and SUN-RGBD segmentation datasets. version:1
arxiv-1611-08983 | Analyzing the group sparsity based on the rank minimization methods | http://arxiv.org/abs/1611.08983 | id:1611.08983 author:Zhiyuan Zha, Xin Liu, Xiaohua Huang, Xiaopeng Hong, Henglin Shi, Yingyue Xu, Qiong Wang, Lan Tang, Xinggan Zhang category:cs.CV  published:2016-11-28 summary:Sparse coding has achieved a great success in various image processing studies. However, there is not any benchmark to measure the sparsity of image patch/group because sparse discriminant conditions cannot keep unchanged. This paper analyzes the sparsity of group based on the strategy of the rank minimization. Firstly, an adaptive dictionary for each group is designed. Then, we prove that group-based sparse coding is equivalent to the rank minimization problem, and thus the sparse coefficient of each group is measured by estimating the singular values of each group. Based on that measurement, the weighted Schatten $p$-norm minimization (WSNM) has been found to be the closest solution to the real singular values of each group. Thus, WSNM can be equivalently transformed into a non-convex $\ell_p$-norm minimization problem in group-based sparse coding. To make the proposed scheme tractable and robust, the alternating direction method of multipliers (ADMM) is used to solve the $\ell_p$-norm minimization problem. Experimental results on two applications: image inpainting and image compressive sensing (CS) recovery have shown that the proposed scheme outperforms many state-of-the-art methods. version:1
arxiv-1611-08976 | Range Loss for Deep Face Recognition with Long-tail | http://arxiv.org/abs/1611.08976 | id:1611.08976 author:Xiao Zhang, Zhiyuan Fang, Yandong Wen, Zhifeng Li, Yu Qiao category:cs.CV  published:2016-11-28 summary:Convolutional neural networks have achieved great improvement on face recognition in recent years because of its extraordinary ability in learning discriminative features of people with different identities. To train such a well-designed deep network, tremendous amounts of data is indispensable. Long tail distribution specifically refers to the fact that a small number of generic entities appear frequently while other objects far less existing. Considering the existence of long tail distribution of the real world data, large but uniform distributed data are usually hard to retrieve. Empirical experiences and analysis show that classes with more samples will pose greater impact on the feature learning process and inversely cripple the whole models feature extracting ability on tail part data. Contrary to most of the existing works that alleviate this problem by simply cutting the tailed data for uniform distributions across the classes, this paper proposes a new loss function called range loss to effectively utilize the whole long tailed data in training process. More specifically, range loss is designed to reduce overall intra-personal variations while enlarging inter-personal differences within one mini-batch simultaneously when facing even extremely unbalanced data. The optimization objective of range loss is the $k$ greatest range's harmonic mean values in one class and the shortest inter-class distance within one batch. Extensive experiments on two famous and challenging face recognition benchmarks (Labeled Faces in the Wild (LFW) and YouTube Faces (YTF) not only demonstrate the effectiveness of the proposed approach in overcoming the long tail effect but also show the good generalization ability of the proposed approach. version:1
arxiv-1611-08974 | Semantic Scene Completion from a Single Depth Image | http://arxiv.org/abs/1611.08974 | id:1611.08974 author:Shuran Song, Fisher Yu, Andy Zeng, Angel X. Chang, Manolis Savva, Thomas Funkhouser category:cs.CV  published:2016-11-28 summary:This paper focuses on semantic scene completion, a task for producing a complete 3D voxel representation of volumetric occupancy and semantic labels for a scene from a single-view depth map observation. Previous work has considered scene completion and semantic labeling of depth maps separately. However, we observe that these two problems are tightly intertwined. To leverage the coupled nature of these two tasks, we introduce the semantic scene completion network (SSCNet), an end-to-end 3D convolutional network that takes a single depth image as input and simultaneously outputs occupancy and semantic labels for all voxels in the camera view frustum. Our network uses a dilation-based 3D context module to efficiently expand the receptive field and enable 3D context learning. To train our network, we construct SUNCG - a manually created large-scale dataset of synthetic 3D scenes with dense volumetric annotations. Our experiments demonstrate that the joint model outperforms methods addressing each task in isolation and outperforms alternative approaches on the semantic scene completion task. version:1
arxiv-1611-08280 | Two-Level Structural Sparsity Regularization for Finding Lattice Locations and Defects in Noisy Image Data | http://arxiv.org/abs/1611.08280 | id:1611.08280 author:Xin Li, Alex Belianinov, Stephen Jesse, Chiwoo Park category:stat.AP cs.CV 62P35 G.3; I.4.6  published:2016-11-24 summary:This paper presents a regularized regression model with two-level structural sparsity penalties and applies it for locating individual atoms in a noisy electron microscope image. For crystalline materials, the locations of atoms have spatial symmetries, forming a few regular lattice groups. Therefore, by simply identifying a few underlying lattice groups seen in an image, one can locate most atoms in the image accurately. Identifying the few underlying lattice groups is formulated as a sparse group selection problem. On the other hand, some positions on the lattice groups can be vacant due to atomic defects, so simply finding the lattice groups may result in many false detections on the vacant positions. To minimize such false detections, the proposed model includes an individual sparsity regularization in addition to the group sparsity for a within-group selection, which results in a regularization regression model with two-level sparsities. We propose a modification of the group orthogonal matching pursuit (gOMP) algorithm with a thresholding step to solve the problem. The convergence analysis and statistical analysis of the proposed algorithm are presented. The proposed algorithm is also evaluated through numerical experiments with two simulated images and three real images. version:2
arxiv-1611-08945 | Learning a Natural Language Interface with Neural Programmer | http://arxiv.org/abs/1611.08945 | id:1611.08945 author:Arvind Neelakantan, Quoc V. Le, Martin Abadi, Andrew McCallum, Dario Amodei category:cs.CL cs.LG stat.ML  published:2016-11-28 summary:Learning a natural language interface for database tables is a challenging task that involves deep language understanding and multi-step reasoning. The task is often approached by mapping natural language queries to logical forms or programs that provide the desired response when executed on the database. To our knowledge, this paper presents the first weakly supervised, end-to-end neural network model to induce such programs on a real-world dataset. We enhance the objective function of Neural Programmer, a neural network with built-in discrete operations, and apply it on WikiTableQuestions, a natural language question-answering dataset. The model is trained end-to-end with weak supervision of question-answer pairs, and does not require domain-specific grammars, rules, or annotations that are key elements in previous approaches to program induction. The main experimental result in this paper is that a single Neural Programmer model achieves 34.2% accuracy using only 10,000 examples with weak supervision. An ensemble of 15 models, with a trivial combination technique, achieves 37.2% accuracy, which is competitive to the current state-of-the-art accuracy of 37.1% obtained by a traditional natural language semantic parser. version:1
arxiv-1611-08930 | Deep attractor network for single-microphone speaker separation | http://arxiv.org/abs/1611.08930 | id:1611.08930 author:Zhuo Chen, Yi Luo, Nima Mesgarani category:cs.SD cs.LG  published:2016-11-27 summary:Despite the overwhelming success of deep learning in various speech processing tasks, the problem of separating simultaneous speakers in a mixture remains challenging. Two major difficulties in such systems are the arbitrary source permutation and unknown number of sources in the mixture. We propose a novel deep learning framework for single channel speech separation by creating attractor points in high dimensional embedding space of the acoustic signals which pull together the time-frequency bins corresponding to each source. Attractor points in this study are created by finding the centroids of the sources in the embedding space, which are subsequently used to determine the similarity of each bin in the mixture to each source. The network is then trained to minimize the reconstruction error of each source by optimizing the embeddings. The proposed model is different from prior works in that it implements an end-to-end training, and it does not depend on the number of sources in the mixture. Two strategies are explored in the test time, K-means and fixed attractor points, where the latter requires no post-processing and can be implemented in real-time. We evaluated our system on Wall Street Journal dataset and show 5.49\% improvement over the previous state-of-the-art methods. version:1
arxiv-1611-08906 | Voronoi-based compact image descriptors: Efficient Region-of-Interest retrieval with VLAD and deep-learning-based descriptors | http://arxiv.org/abs/1611.08906 | id:1611.08906 author:Aaron Chadha, Yiannis Andreopoulos category:cs.CV  published:2016-11-27 summary:We investigate the problem of image retrieval based on visual queries when the latter comprise arbitrary regions-of-interest (ROI) rather than entire images. Our proposal is a compact image descriptor that combines the state-of-the-art in content-based descriptor extraction with a multi-level, Voronoi-based spatial partitioning of each dataset image. The proposed multi-level Voronoi-based encoding uses a spatial hierarchical K-means over interest-point locations, and computes a content-based descriptor over each cell. In order to reduce the matching complexity with minimal or no sacrifice in retrieval performance: (i) we utilize the tree structure of the spatial hierarchical K-means to perform a top-to-bottom pruning for local similarity maxima; (ii) we propose a new image similarity score that combines relevant information from all partition levels into a single measure for similarity; (iii) we combine our proposal with a novel and efficient approach for optimal bit allocation within quantized descriptor representations. By deriving both a Voronoi-based VLAD descriptor (termed as Fast-VVLAD) and a Voronoi-based deep convolutional neural network (CNN) descriptor (termed as Fast-VDCNN), we demonstrate that our Voronoi-based framework is agnostic to the descriptor basis, and can easily be slotted into existing frameworks. Via a range of ROI queries in two standard datasets, it is shown that the Voronoi-based descriptors achieve comparable or higher mean Average Precision against conventional grid-based spatial search, while offering more than two-fold reduction in complexity. Finally, beyond ROI queries, we show that Voronoi partitioning improves the geometric invariance of compact CNN descriptors, thereby resulting in competitive performance to the current state-of-the-art on whole image retrieval. version:1
arxiv-1611-08903 | Should I use TensorFlow | http://arxiv.org/abs/1611.08903 | id:1611.08903 author:Martin Schrimpf category:cs.LG  published:2016-11-27 summary:Google's Machine Learning framework TensorFlow was open-sourced in November 2015 [1] and has since built a growing community around it. TensorFlow is supposed to be flexible for research purposes while also allowing its models to be deployed productively. This work is aimed towards people with experience in Machine Learning considering whether they should use TensorFlow in their environment. Several aspects of the framework important for such a decision are examined, such as the heterogenity, extensibility and its computation graph. A pure Python implementation of linear classification is compared with an implementation utilizing TensorFlow. I also contrast TensorFlow to other popular frameworks with respect to modeling capability, deployment and performance and give a brief description of the current adaption of the framework. version:1
arxiv-1611-08896 | Uniform Information Segmentation | http://arxiv.org/abs/1611.08896 | id:1611.08896 author:Radhakrishna Achanta, Pablo M√°rquez-Neila, Pascal Fua, Sabine S√ºsstrunk category:cs.CV  published:2016-11-27 summary:Size uniformity is one of the main criteria of superpixel methods. But size uniformity rarely conforms to the varying content of an image. The chosen size of the superpixels therefore represents a compromise - how to obtain the fewest superpixels without losing too much important detail. We propose that a more appropriate criterion for creating image segments is information uniformity. We introduce a novel method for segmenting an image based on this criterion. Since information is a natural way of measuring image complexity, our proposed algorithm leads to image segments that are smaller and denser in areas of high complexity and larger in homogeneous regions, thus simplifying the image while preserving its details. Our algorithm is simple and requires just one input parameter - a threshold on the information content. On segmentation comparison benchmarks it proves to be superior to the state-of-the-art. In addition, our method is computationally very efficient, approaching real-time performance, and is easily extensible to three-dimensional image stacks and video volumes. version:1
arxiv-1611-08860 | It's Written All Over Your Face: Full-Face Appearance-Based Gaze Estimation | http://arxiv.org/abs/1611.08860 | id:1611.08860 author:Xucong Zhang, Yusuke Sugano, Mario Fritz, Andreas Bulling category:cs.CV cs.HC  published:2016-11-27 summary:While appearance-based gaze estimation methods have traditionally exploited information encoded solely from the eyes, recent results from a multi-region method indicated that using the full face image can benefit performance. Pushing this idea further, we propose an appearance-based method that, in contrast to a long-standing line of work in computer vision, only takes the full face image as input. Our method encodes the face image using a convolutional neural network with spatial weights applied on the feature maps to flexibly suppress or enhance information in different facial regions. Through evaluation on the recent MPIIGaze and EYEDIAP gaze estimation datasets, we show that our full-face method significantly outperforms the state of the art for both 2D and 3D gaze estimation, achieving improvements of up to 14.3% on MPIIGaze and 27.7% on EYEDIAP for person-independent 3D gaze estimation. We further show that this improvement is consistent across different illumination conditions and gaze directions and particularly pronounced for the most challenging extreme head poses. version:1
arxiv-1611-08844 | A neuro-mathematical model for geometrical optical illusions | http://arxiv.org/abs/1611.08844 | id:1611.08844 author:B. Franceschiello, A. Sarti, G. Citti category:cs.CV  published:2016-11-27 summary:Geometrical optical illusions have been object of many studies due to the possibility they offer to understand the behaviour of low-level visual processing. They consist in situations in which the perceived geometrical properties of an object differ from those of the object in the visual stimulus. Starting from the geometrical model introduced by Citti and Sarti in [3], we provide a mathematical model and a computational algorithm which allows to interpret these phenomena and to qualitatively reproduce the perceived misperception. version:1
arxiv-1611-08841 | Long-Term Image Boundary Extrapolation | http://arxiv.org/abs/1611.08841 | id:1611.08841 author:Apratim Bhattacharyya, Mateusz Malinowski, Bernt Schiele, Mario Fritz category:cs.CV cs.GR  published:2016-11-27 summary:Boundary prediction in images and videos has been a very active topic of research and organizing visual information into boundaries and segments is believed to be a corner stone of visual perception. While prior work has focused on predicting boundaries for observed frames, our work aims at predicting boundaries of future unobserved frames. This requires our model to learn about the fate of boundaries and extrapolate motion patterns. We experiment on established real-world video segmentation dataset, which provides a testbed for this new task. We show for the first time spatio-temporal boundary extrapolation, that in contrast to prior work on RGB extrapolation maintains a crisp result. Furthermore, we show long-term prediction of boundaries in situations where the motion is governed by the laws of physics. We argue that our model has with minimalistic model assumptions derived a notion of "intuitive physics". version:1
arxiv-1611-08815 | Did Evolution get it right? An evaluation of Near-Infrared imaging in semantic scene segmentation using deep learning | http://arxiv.org/abs/1611.08815 | id:1611.08815 author:J. Rafid Siddiqui category:cs.CV  published:2016-11-27 summary:Animals have evolved to restrict their sensing capabilities to certain region of electromagnetic spectrum. This is surprisingly a very narrow band on a vast scale which makes one think if there is a systematic bias underlying such selective filtration. The situation becomes even more intriguing when we find a sharp cutoff point at Near-infrared point whereby almost all animal vision systems seem to have a lower bound. This brings us to an interesting question: did evolution "intentionally" performed such a restriction in order to evolve higher visual cognition? In this work this question is addressed by experimenting with Near-infrared images for their potential applicability in higher visual processing such as semantic segmentation. A modified version of Fully Convolutional Networks are trained on NIR images and RGB images respectively and compared for their respective effectiveness in the wake of semantic segmentation. The results from the experiments show that visible part of the spectrum alone is sufficient for the robust semantic segmentation of the indoor as well as outdoor scenes. version:1
arxiv-1611-08813 | Semi Supervised Preposition-Sense Disambiguation using Multilingual Data | http://arxiv.org/abs/1611.08813 | id:1611.08813 author:Hila Gonen, Yoav Goldberg category:cs.CL  published:2016-11-27 summary:Prepositions are very common and very ambiguous, and understanding their sense is critical for understanding the meaning of the sentence. Supervised corpora for the preposition-sense disambiguation task are small, suggesting a semi-supervised approach to the task. We show that signals from unannotated multilingual data can be used to improve supervised preposition-sense disambiguation. Our approach pre-trains an LSTM encoder for predicting the translation of a preposition, and then incorporates the pre-trained encoder as a component in a supervised classification system, and fine-tunes it for the task. The multilingual signals consistently improve results on two preposition-sense datasets. version:1
arxiv-1611-08812 | Kernel classification of connectomes based on earth mover's distance between graph spectra | http://arxiv.org/abs/1611.08812 | id:1611.08812 author:Yulia Dodonova, Mikhail Belyaev, Anna Tkachev, Dmitry Petrov, Leonid Zhukov category:cs.CV cs.NE  published:2016-11-27 summary:In this paper, we tackle a problem of predicting phenotypes from structural connectomes. We propose that normalized Laplacian spectra can capture structural properties of brain networks, and hence graph spectral distributions are useful for a task of connectome-based classification. We introduce a kernel that is based on earth mover's distance (EMD) between spectral distributions of brain networks. We access performance of an SVM classifier with the proposed kernel for a task of classification of autism spectrum disorder versus typical development based on a publicly available dataset. Classification quality (area under the ROC-curve) obtained with the EMD-based kernel on spectral distributions is 0.71, which is higher than that based on simpler graph embedding methods. version:1
arxiv-1611-08807 | The polysemy of the words that children learn over time | http://arxiv.org/abs/1611.08807 | id:1611.08807 author:Bernardino Casas, Neus Catal√†, Ramon Ferrer-i-Cancho, Antoni Hern√°ndez-Fern√°ndez, Jaume Baixeries category:cs.CL physics.soc-ph  published:2016-11-27 summary:Here we study polysemy as a potential learning bias in vocabulary learning in children. We employ a massive set of transcriptions of conversations between children and adults in English, to analyze the evolution of mean polysemy in the words produced by children whose ages range between 10 and 60 months. Our results show that mean polysemy in children increases over time in two phases, i.e. a fast growth till the 31st month followed by a slower tendency towards adult speech. In contrast, no dependency with time is found in adults. This suggests that children have a preference for non-polysemous words in their early stages of vocabulary acquisition. Our hypothesis is twofold: (a) polysemy is a standalone bias or (b) polysemy is a side-effect of other biases. Interestingly, the bias for low polysemy described above weakens when controlling for syntactic category (noun, verb, adjective or adverb). The pattern of the evolution of polysemy suggests that both hypotheses may apply to some extent, and that (b) would originate from a combination of the well-known preference for nouns and the lower polysemy of nouns with respect to other syntactic categories. version:1
arxiv-1611-10162 | Predicting the Category and Attributes of Mental Pictures Using Deep Gaze Pooling | http://arxiv.org/abs/1611.10162 | id:1611.10162 author:Hosnieh Sattar, Andreas Bulling, Mario Fritz category:q-bio.NC cs.CV  published:2016-11-27 summary:Previous work focused on predicting visual search targets from human fixations but, in the real world, a specific target is often not known, e.g. when searching for a present for a friend. In this work we instead study the problem of predicting the mental picture, i.e. only an abstract idea instead of a specific target. This task is significantly more challenging given that mental pictures of the same target category can vary widely depending on personal biases, and given that characteristic target attributes can often not be verbalised explicitly. We instead propose to use gaze information as implicit information on users' mental picture and present a novel gaze pooling layer to seamlessly integrate semantic and localized fixation information into a deep image representation. We show that we can robustly predict both the mental picture's category as well as attributes on a novel dataset containing fixation data of 14 users searching for targets on a subset of the DeepFahion dataset. Our results have important implications for future search interfaces and suggest deep gaze pooling as a general-purpose approach for gaze-supported computer vision systems. version:1
arxiv-1611-08796 | Deep Deformable Registration: Enhancing Accuracy by Fully Convolutional Neural Net | http://arxiv.org/abs/1611.08796 | id:1611.08796 author:Sayan Ghosal, Nilanjan Ray category:cs.CV  published:2016-11-27 summary:Deformable registration is ubiquitous in medical image analysis. Many deformable registration methods minimize sum of squared difference (SSD) as the registration cost with respect to deformable model parameters. In this work, we construct a tight upper bound of the SSD registration cost by using a fully convolutional neural network (FCNN) in the registration pipeline. The upper bound SSD (UB-SSD) enhances the original deformable model parameter space by adding a heatmap output from FCNN. Next, we minimize this UB-SSD by adjusting both the parameters of the FCNN and the parameters of the deformable model in coordinate descent. Our coordinate descent framework is end-to-end and can work with any deformable registration method that uses SSD. We demonstrate experimentally that our method enhances the accuracy of deformable registration algorithms significantly on two publicly available 3D brain MRI data sets. version:1
arxiv-1611-08791 | Learning without recall in directed circles and rooted trees | http://arxiv.org/abs/1611.08791 | id:1611.08791 author:M. Amin Rahimian, Ali Jadbabaie category:stat.AP cs.IT cs.SI math.IT math.PR stat.ML  published:2016-11-27 summary:This work investigates the case of a network of agents that attempt to learn some unknown state of the world amongst the finitely many possibilities. At each time step, agents all receive random, independently distributed private signals whose distributions are dependent on the unknown state of the world. However, it may be the case that some or any of the agents cannot distinguish between two or more of the possible states based only on their private observations, as when several states result in the same distribution of the private signals. In our model, the agents form some initial belief (probability distribution) about the unknown state and then refine their beliefs in accordance with their private observations, as well as the beliefs of their neighbors. An agent learns the unknown state when her belief converges to a point mass that is concentrated at the true state. A rational agent would use the Bayes' rule to incorporate her neighbors' beliefs and own private signals over time. While such repeated applications of the Bayes' rule in networks can become computationally intractable, in this paper, we show that in the canonical cases of directed star, circle or path networks and their combinations, one can derive a class of memoryless update rules that replicate that of a single Bayesian agent but replace the self beliefs with the beliefs of the neighbors. This way, one can realize an exponentially fast rate of learning similar to the case of Bayesian (fully rational) agents. The proposed rules are a special case of the Learning without Recall. version:1
arxiv-1611-08789 | Handwriting Profiling using Generative Adversarial Networks | http://arxiv.org/abs/1611.08789 | id:1611.08789 author:Arna Ghosh, Biswarup Bhattacharya, Somnath Basu Roy Chowdhury category:cs.CV cs.AI  published:2016-11-27 summary:Handwriting is a skill learned by humans from a very early age. The ability to develop one's own unique handwriting as well as mimic another person's handwriting is a task learned by the brain with practice. This paper deals with this very problem where an intelligent system tries to learn the handwriting of an entity using Generative Adversarial Networks (GANs). We propose a modified architecture of DCGAN (Radford, Metz, and Chintala 2015) to achieve this. We also discuss about applying reinforcement learning techniques to achieve faster learning. Our algorithm hopes to give new insights in this area and its uses include identification of forged documents, signature verification, computer generated art, digitization of documents among others. Our early implementation of the algorithm illustrates a good performance with MNIST datasets. version:1
arxiv-1611-08788 | SAD-GAN: Synthetic Autonomous Driving using Generative Adversarial Networks | http://arxiv.org/abs/1611.08788 | id:1611.08788 author:Arna Ghosh, Biswarup Bhattacharya, Somnath Basu Roy Chowdhury category:cs.CV cs.AI  published:2016-11-27 summary:Autonomous driving is one of the most recent topics of interest which is aimed at replicating human driving behavior keeping in mind the safety issues. We approach the problem of learning synthetic driving using generative neural networks. The main idea is to make a controller trainer network using images plus key press data to mimic human learning. We used the architecture of a stable GAN to make predictions between driving scenes using key presses. We train our model on one video game (Road Rash) and tested the accuracy and compared it by running the model on other maps in Road Rash to determine the extent of learning. version:1
arxiv-1611-08780 | Real-Time Video Highlights for Yahoo Esports | http://arxiv.org/abs/1611.08780 | id:1611.08780 author:Yale Song category:cs.CV  published:2016-11-27 summary:Esports has gained global popularity in recent years and several companies have started offering live streaming videos of esports games and events. This creates opportunities to develop large scale video understanding systems for new product features and services. We present a technique for detecting highlights from live streaming videos of esports game matches. Most video games use pronounced visual effects to emphasize highlight moments; we use CNNs to learn convolution filters of those visual effects for detecting highlights. We propose a cascaded prediction approach that allows us to deal with several challenges arise in a production environment. We demonstrate our technique on our new dataset of three popular game titles, Heroes of the Storm, League of Legends, and Dota 2. Our technique achieves 18 FPS on a single CPU with an average precision of up to 83.18%. Part of our technique is currently deployed in production on Yahoo Esports. version:1
arxiv-1611-08765 | Fill it up: Exploiting partial dependency annotations in a minimum spanning tree parser | http://arxiv.org/abs/1611.08765 | id:1611.08765 author:Liang Sun, Jason Mielens, Jason Baldridge category:cs.CL  published:2016-11-26 summary:Unsupervised models of dependency parsing typically require large amounts of clean, unlabeled data plus gold-standard part-of-speech tags. Adding indirect supervision (e.g. language universals and rules) can help, but we show that obtaining small amounts of direct supervision - here, partial dependency annotations - provides a strong balance between zero and full supervision. We adapt the unsupervised ConvexMST dependency parser to learn from partial dependencies expressed in the Graph Fragment Language. With less than 24 hours of total annotation, we obtain 7% and 17% absolute improvement in unlabeled dependency scores for English and Spanish, respectively, compared to the same parser using only universal grammar constraints. version:1
arxiv-1611-08754 | What Can Be Predicted from Six Seconds of Driver Glances? | http://arxiv.org/abs/1611.08754 | id:1611.08754 author:Lex Fridman, Heishiro Toyoda, Sean Seaman, Bobbie Seppelt, Linda Angell, Joonbum Lee, Bruce Mehler, Bryan Reimer category:cs.CV cs.HC cs.LG  published:2016-11-26 summary:We consider a large dataset of real-world, on-road driving from a 100-car naturalistic study to explore the predictive power of driver glances and, specifically, to answer the following question: what can be predicted about the state of the driver and the state of the driving environment from a 6-second sequence of macro-glances? The context-based nature of such glances allows for application of supervised learning to the problem of vision-based gaze estimation, making it robust, accurate, and reliable in messy, real-world conditions. So, it's valuable to ask whether such macro-glances can be used to infer behavioral, environmental, and demographic variables? We analyze 27 binary classification problems based on these variables. The takeaway is that glance can be used as part of a multi-sensor real-time system to predict radio-tuning, fatigue state, failure to signal, talking, and several environment variables. version:1
arxiv-1611-08737 | Structural Correspondence Learning for Cross-lingual Sentiment Classification with One-to-many Mappings | http://arxiv.org/abs/1611.08737 | id:1611.08737 author:Nana Li, Shuangfei Zhai, Zhongfei Zhang, Boying Liu category:cs.LG cs.CL  published:2016-11-26 summary:Structural correspondence learning (SCL) is an effective method for cross-lingual sentiment classification. This approach uses unlabeled documents along with a word translation oracle to automatically induce task specific, cross-lingual correspondences. It transfers knowledge through identifying important features, i.e., pivot features. For simplicity, however, it assumes that the word translation oracle maps each pivot feature in source language to exactly only one word in target language. This one-to-one mapping between words in different languages is too strict. Also the context is not considered at all. In this paper, we propose a cross-lingual SCL based on distributed representation of words; it can learn meaningful one-to-many mappings for pivot words using large amounts of monolingual data and a small dictionary. We conduct experiments on NLP\&CC 2013 cross-lingual sentiment analysis dataset, employing English as source language, and Chinese as target language. Our method does not rely on the parallel corpora and the experimental results show that our approach is more competitive than the state-of-the-art methods in cross-lingual sentiment classification. version:1
arxiv-1611-08699 | Machine Learning on Human Connectome Data from MRI | http://arxiv.org/abs/1611.08699 | id:1611.08699 author:Colin J Brown, Ghassan Hamarneh category:cs.LG  published:2016-11-26 summary:Functional MRI (fMRI) and diffusion MRI (dMRI) are non-invasive imaging modalities that allow in-vivo analysis of a patient's brain network (known as a connectome). Use of these technologies has enabled faster and better diagnoses and treatments of neurological disorders and a deeper understanding of the human brain. Recently, researchers have been exploring the application of machine learning models to connectome data in order to predict clinical outcomes and analyze the importance of subnetworks in the brain. Connectome data has unique properties, which present both special challenges and opportunities when used for machine learning. The purpose of this work is to review the literature on the topic of applying machine learning models to MRI-based connectome data. This field is growing rapidly and now encompasses a large body of research. To summarize the research done to date, we provide a comparative, structured summary of 77 relevant works, tabulated according to different criteria, that represent the majority of the literature on this topic. (We also published a living version of this table online at http://connectomelearning.cs.sfu.ca that the community can continue to contribute to.) After giving an overview of how connectomes are constructed from dMRI and fMRI data, we discuss the variety of machine learning tasks that have been explored with connectome data. We then compare the advantages and drawbacks of different machine learning approaches that have been employed, discussing different feature selection and feature extraction schemes, as well as the learning models and regularization penalties themselves. Throughout this discussion, we focus particularly on how the methods are adapted to the unique nature of graphical connectome data. Finally, we conclude by summarizing the current state of the art and by outlining what we believe are strategic directions for future research. version:1
arxiv-1611-08675 | Deep Reinforcement Learning for Multi-Domain Dialogue Systems | http://arxiv.org/abs/1611.08675 | id:1611.08675 author:Heriberto Cuay√°huitl, Seunghak Yu, Ashley Williamson, Jacob Carse category:cs.AI cs.CL  published:2016-11-26 summary:Standard deep reinforcement learning methods such as Deep Q-Networks (DQN) for multiple tasks (domains) face scalability problems. We propose a method for multi-domain dialogue policy learning---termed NDQN, and apply it to an information-seeking spoken dialogue system in the domains of restaurants and hotels. Experimental results comparing DQN (baseline) versus NDQN (proposed) using simulations report that our proposed method exhibits better scalability and is promising for optimising the behaviour of multi-domain dialogue systems. version:1
arxiv-1611-08669 | Visual Dialog | http://arxiv.org/abs/1611.08669 | id:1611.08669 author:Abhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav, Jos√© M. F. Moura, Devi Parikh, Dhruv Batra category:cs.CV cs.AI cs.CL cs.LG  published:2016-11-26 summary:We introduce the task of Visual Dialog, which requires an AI agent to hold a meaningful dialog with humans in natural, conversational language about visual content. Specifically, given an image, a dialog history, and a question about the image, the agent has to ground the question in image, infer context from history, and answer the question accurately. Visual Dialog is disentangled enough from a specific downstream task so as to serve as a general test of machine intelligence, while being grounded in vision enough to allow objective evaluation of individual responses and benchmark progress. We develop a novel two-person chat data-collection protocol to curate a large-scale Visual Dialog dataset (VisDial). Data collection is underway and on completion, VisDial will contain 1 dialog with 10 question-answer pairs on all ~200k images from COCO, with a total of 2M dialog question-answer pairs. We introduce a family of neural encoder-decoder models for Visual Dialog with 3 encoders -- Late Fusion, Hierarchical Recurrent Encoder and Memory Network -- and 2 decoders (generative and discriminative), which outperform a number of sophisticated baselines. We propose a retrieval-based evaluation protocol for Visual Dialog where the AI agent is asked to sort a set of candidate answers and evaluated on metrics such as mean-reciprocal-rank of human response. We quantify gap between machine and human performance on the Visual Dialog task via human studies. Our dataset, code, and trained models will be released publicly. Putting it all together, we demonstrate the first 'visual chatbot'! version:1
arxiv-1611-08666 | Training an Interactive Humanoid Robot Using Multimodal Deep Reinforcement Learning | http://arxiv.org/abs/1611.08666 | id:1611.08666 author:Heriberto Cuay√°huitl, Guillaume Couly, Cl√©ment Olalainty category:cs.LG cs.AI cs.RO  published:2016-11-26 summary:Training robots to perceive, act and communicate using multiple modalities still represents a challenging problem, particularly if robots are expected to learn efficiently from small sets of example interactions. We describe a learning approach as a step in this direction, where we teach a humanoid robot how to play the game of noughts and crosses. Given that multiple multimodal skills can be trained to play this game, we focus our attention to training the robot to perceive the game, and to interact in this game. Our multimodal deep reinforcement learning agent perceives multimodal features and exhibits verbal and non-verbal actions while playing. Experimental results using simulations show that the robot can learn to win or draw up to 98% of the games. A pilot test of the proposed multimodal system for the targeted game---integrating speech, vision and gestures---reports that reasonable and fluent interactions can be achieved using the proposed approach. version:1
arxiv-1611-08663 | Multi-Task Zero-Shot Action Recognition with Prioritised Data Augmentation | http://arxiv.org/abs/1611.08663 | id:1611.08663 author:Xun Xu, Timothy M. Hospedales, Shaogang Gong category:cs.CV  published:2016-11-26 summary:Zero-Shot Learning (ZSL) promises to scale visual recognition by bypassing the conventional model training requirement of annotated examples for every category. This is achieved by establishing a mapping connecting low-level features and a semantic description of the label space, referred as visual-semantic mapping, on auxiliary data. Reusing the learned mapping to project target videos into an embedding space thus allows novel-classes to be recognised by nearest neighbour inference. However, existing ZSL methods suffer from auxiliary-target domain shift intrinsically induced by assuming the same mapping for the disjoint auxiliary and target classes. This compromises the generalisation accuracy of ZSL recognition on the target data. In this work, we improve the ability of ZSL to generalise across this domain shift in both model- and data-centric ways by formulating a visual-semantic mapping with better generalisation properties and a dynamic data re-weighting method to prioritise auxiliary data that are relevant to the target classes. Specifically: (1) We introduce a multi-task visual-semantic mapping to improve generalisation by constraining the semantic mapping parameters to lie on a low-dimensional manifold, (2) We explore prioritised data augmentation by expanding the pool of auxiliary data with additional instances weighted by relevance to the target domain. The proposed new model is applied to the challenging zero-shot action recognition problem to demonstrate its advantages over existing ZSL models. version:1
arxiv-1611-08661 | Knowledge Graph Representation with Jointly Structural and Textual Encoding | http://arxiv.org/abs/1611.08661 | id:1611.08661 author:Jiacheng Xu, Kan Chen, Xipeng Qiu, Xuanjing Huang category:cs.CL  published:2016-11-26 summary:The objective of knowledge graph embedding is to encode both entities and relations of knowledge graphs into continuous low-dimensional vector spaces. Previously, most works focused on symbolic representation of knowledge graph with structure information, which can not handle new entities or entities with few facts well. In this paper, we propose a novel deep architecture to utilize both structural and textual information of entities. Specifically, we introduce three neural models to encode the valuable information from text description of entity, among which an attentive model can select related information as needed. Then, a gating mechanism is applied to integrate representations of structure and text into a unified architecture. Experiments show that our models outperform baseline by margin on link prediction and triplet classification tasks. Source codes of this paper will be available on Github. version:1
arxiv-1611-08656 | Attention-based Memory Selection Recurrent Network for Language Modeling | http://arxiv.org/abs/1611.08656 | id:1611.08656 author:Da-Rong Liu, Shun-Po Chuang, Hung-yi Lee category:cs.CL  published:2016-11-26 summary:Recurrent neural networks (RNNs) have achieved great success in language modeling. However, since the RNNs have fixed size of memory, their memory cannot store all the information about the words it have seen before in the sentence, and thus the useful long-term information may be ignored when predicting the next words. In this paper, we propose Attention-based Memory Selection Recurrent Network (AMSRN), in which the model can review the information stored in the memory at each previous time step and select the relevant information to help generate the outputs. In AMSRN, the attention mechanism finds the time steps storing the relevant information in the memory, and memory selection determines which dimensions of the memory are involved in computing the attention weights and from which the information is extracted.In the experiments, AMSRN outperformed long short-term memory (LSTM) based language models on both English and Chinese corpora. Moreover, we investigate using entropy as a regularizer for attention weights and visualize how the attention mechanism helps language modeling. version:1
arxiv-1611-08655 | A Deep Neural Network to identify foreshocks in real time | http://arxiv.org/abs/1611.08655 | id:1611.08655 author:K. Vikraman category:physics.geo-ph cs.LG  published:2016-11-26 summary:Foreshock events provide valuable insight to predict imminent major earthquakes. However, it is difficult to identify them in real time. In this paper, I propose an algorithm based on deep learning to instantaneously classify a seismic waveform as a foreshock, mainshock or an aftershock event achieving a high accuracy of 99% in classification. As a result, this is by far the most reliable method to predict major earthquakes that are preceded by foreshocks. In addition, I discuss methods to create an earthquake dataset that is compatible with deep networks. version:1
arxiv-1611-07909 | Image Segmentation Using Overlapping Group Sparsity | http://arxiv.org/abs/1611.07909 | id:1611.07909 author:Shervin Minaee, Yao Wang category:cs.CV  published:2016-11-23 summary:Sparse decomposition has been widely used for different applications, such as source separation, image classification and image denoising. This paper presents a new algorithm for segmentation of an image into background and foreground text and graphics using sparse decomposition. First, the background is represented using a suitable smooth model, which is a linear combination of a few smoothly varying basis functions, and the foreground text and graphics are modeled as a sparse component overlaid on the smooth background. Then the background and foreground are separated using a sparse decomposition framework and imposing some prior information, which promote the smoothness of background, and the sparsity and connectivity of foreground pixels. This algorithm has been tested on a dataset of images extracted from HEVC standard test sequences for screen content coding, and is shown to outperform prior methods, including least absolute deviation fitting, k-means clustering based segmentation in DjVu, and shape primitive extraction and coding algorithm. version:2
arxiv-1611-08648 | Patient-Driven Privacy Control through Generalized Distillation | http://arxiv.org/abs/1611.08648 | id:1611.08648 author:Z. Berkay Celik, David Lopez-Paz, Patrick McDaniel category:cs.CR cs.CY cs.LG stat.ML  published:2016-11-26 summary:The introduction of data analytics into medicine has changed the nature of treatment. In this, patients are asked to disclose personal information such as genetic markers, lifestyle habits, and clinical history. This data is then used by statistical models to predict personalized treatments. However, due to privacy concerns, patients often desire to withhold sensitive information. This self-censorship can impede proper diagnosis and treatment, which may lead to serious health complications and even death. In this paper, we present privacy distillation, a mechanism which allows patients to control the type and amount of information they wish to disclose to the healthcare providers for use in statistical models. Meanwhile, it retains the accuracy of models that have access to all patient data under a sufficient but not full set of privacy-relevant information. We validate privacy distillation using a corpus of patients prescribed to warfarin for a personalized dosage. We use a deep neural network to implement privacy distillation for training and making dose predictions. We find that privacy distillation with sufficient privacy-relevant information i) retains accuracy almost as good as having all patient data (only 3% worse), and ii) is effective at preventing errors that introduce health-related risks (yielding on average 3.9% of under- or over-prescriptions). version:1
arxiv-1611-08629 | Texture analysis using deterministic partially self-avoiding walk with thresholds | http://arxiv.org/abs/1611.08629 | id:1611.08629 author:Lucas Correia Ribas, Wesley Nunes Gon√ßalves, Odemir Martinez Bruno category:cs.CV  published:2016-11-25 summary:In this paper, we propose a new texture analysis method using the deterministic partially self-avoiding walk performed on maps modified with thresholds. In this method, two pixels of the map are neighbors if the Euclidean distance between them is less than $\sqrt{2}$ and the weight (difference between its intensities) is less than a given threshold. The maps obtained by using different thresholds highlight several properties of the image that are extracted by the deterministic walk. To compose the feature vector, deterministic walks are performed with different thresholds and its statistics are concatenated. Thus, this approach can be considered as a multi-scale analysis. We validate our method on the Brodatz database, which is very well known public image database and widely used by texture analysis methods. Experimental results indicate that the proposed method presents a good texture discrimination, overcoming traditional texture methods. version:1
arxiv-1611-08625 | Directional Mean Curvature for Textured Image Demixing | http://arxiv.org/abs/1611.08625 | id:1611.08625 author:Duy Hoang Thai, David Banks category:cs.CV  published:2016-11-25 summary:Approximation theory plays an important role in image processing, especially image deconvolution and decomposition. For piecewise smooth images, there are many methods that have been developed over the past thirty years. The goal of this study is to devise similar and practical methodology for handling textured images. This problem is motivated by forensic imaging, since fingerprints, shoeprints and bullet ballistic evidence are textured images. In particular, it is known that texture information is almost destroyed by a blur operator, such as a blurred ballistic image captured from a low-cost microscope. The contribution of this work is twofold: first, we propose a mathematical model for textured image deconvolution and decomposition into four meaningful components, using a high-order partial differential equation approach based on the directional mean curvature. Second, we uncover a link between functional analysis and multiscale sampling theory, e.g., harmonic analysis and filter banks. Both theoretical results and examples with natural images are provided to illustrate the performance of the proposed model. version:1
arxiv-1611-08624 | Fast deterministic tourist walk for texture analysis | http://arxiv.org/abs/1611.08624 | id:1611.08624 author:Lucas Correia Ribas, Odemir Martinez Bruno category:cs.CV  published:2016-11-25 summary:Deterministic tourist walk (DTW) has attracted increasing interest in computer vision. In the last years, different methods for analysis of dynamic and static textures were proposed. So far, all works based on the DTW for texture analysis use all image pixels as initial point of a walk. However, this requires much runtime. In this paper, we conducted a study to verify the performance of the DTW method according to the number of initial points to start a walk. The proposed method assigns a unique code to each image pixel, then, the pixels whose code is not divisible by a given $k$ value are ignored as initial points of walks. Feature vectors were extracted and a classification process was performed for different percentages of initial points. Experimental results on the Brodatz and Vistex datasets indicate that to use fewer pixels as initial points significantly improves the runtime compared to use all image pixels. In addition, the correct classification rate decreases very little. version:1
arxiv-1611-08618 | A Benchmark and Comparison of Active Learning for Logistic Regression | http://arxiv.org/abs/1611.08618 | id:1611.08618 author:Yazhou Yang, Marco Loog category:stat.ML  published:2016-11-25 summary:Various active learning methods based on logistic regression have been proposed. In this paper, we investigate seven state-of-the-art strategies, present an extensive benchmark, and provide a better understanding of their underlying characteristics. Experiments are carried out both on 3 synthetic datasets and 43 real-world datasets, providing insights into the behaviour of these active learning methods with respect to classification accuracy and their computational cost. version:1
arxiv-1611-08583 | Learning from Maps: Visual Common Sense for Autonomous Driving | http://arxiv.org/abs/1611.08583 | id:1611.08583 author:Ari Seff, Jianxiong Xiao category:cs.CV  published:2016-11-25 summary:Today's autonomous vehicles rely extensively on high-definition 3D maps to navigate the environment. While this approach works well when these maps are completely up-to-date, safe autonomous vehicles must be able to corroborate the map's information via a real time sensor-based system. Our goal in this work is to develop a model for road layout inference given imagery from on-board cameras, without any reliance on high-definition maps. However, no sufficient dataset for training such a model exists. Here, we leverage the availability of standard navigation maps and corresponding street view images to construct an automatically labeled, large-scale dataset for this complex scene understanding problem. By matching road vectors and metadata from navigation maps with Google Street View images, we can assign ground truth road layout attributes (e.g., distance to an intersection, one-way vs. two-way street) to the images. We then train deep convolutional networks to predict these road layout attributes given a single monocular RGB image. Experimental evaluation demonstrates that our model learns to correctly infer the road attributes using only panoramas captured by car-mounted cameras as input. Additionally, our results indicate that this method may be suitable to the novel application of recommending safety improvements to infrastructure (e.g., suggesting an alternative speed limit for a street). version:1
arxiv-1611-08568 | Bottleneck Conditional Density Estimation | http://arxiv.org/abs/1611.08568 | id:1611.08568 author:Rui Shu, Hung H. Bui, Mohammad Ghavamzadeh category:stat.ML cs.LG  published:2016-11-25 summary:We propose a neural network framework for high-dimensional conditional density estimation. The Bottleneck Conditional Density Estimator (BCDE) is a variant of the conditional variational autoencoder (CVAE) that employs layer(s) of stochastic variables as the bottleneck between the input x and target y, where both are high-dimensional. The key to effectively train BCDEs is the hybrid blending of the conditional generative model with a joint generative model that leverages unlabeled data to regularize the conditional model. We show that the BCDE significantly outperforms the CVAE in MNIST quadrant prediction benchmarks in the fully supervised case and establishes new benchmarks in the semi-supervised case. version:1
arxiv-1611-08563 | Online Real time Multiple Spatiotemporal Action Localisation and Prediction on a Single Platform | http://arxiv.org/abs/1611.08563 | id:1611.08563 author:Gurkirt Singh, Suman Saha, Fabio Cuzzolin category:cs.CV  published:2016-11-25 summary:We present a method for multiple spatiotemporal (S/T) action localisation, classification and early prediction based on a single deep learning platform, able to perform in an online fashion and in real time. Our online action detection pipeline comprises of three main steps. In step one, two end-to-end trainable SSD (Single Shot MultiBox Detector) convolutional neural networks are employed to regress and classify detection boxes in each video frame potentially containing an action of interest, one from optical flow and one from RBG images. In step two, appearance and motion cues are combined by merging the detection boxes and classification scores generated by the two networks. In step three, sequences of detection boxes most likely to be associated with a single action instance, called `action tubes', are constructed incrementally and efficiently in an online fashion, allowing the system to perform early action class prediction and spatial localisation in real time. Empirical results on the challenging UCF101 and J-HMDB-21 datasets demonstrate new state-of-the-art results in S/T action localisation on UCF101, even when compared to offline competitors, and superior results on early action label prediction across the board. To the best of our knowledge, ours is the first platform able to perform online spatial and temporal action localisation. The system works in real time (30fps) when computing optical flow incrementally, perform better than real time (52fps) when processing only RBG images. version:1
arxiv-1611-08562 | A Simple, Fast Diverse Decoding Algorithm for Neural Generation | http://arxiv.org/abs/1611.08562 | id:1611.08562 author:Jiwei Li, Will Monroe, Dan Jurafsky category:cs.CL  published:2016-11-25 summary:In this paper, we propose a simple, fast decoding algorithm that fosters diversity in neural generation. The algorithm modifies the standard beam search algorithm by adding an inter-sibling ranking penalty, favoring choosing hypotheses from diverse parents. We evaluate the proposed model on the tasks of dialogue response generation, abstractive summarization and machine translation. We find that diverse decoding helps across all tasks, especially those for which reranking is needed. We further propose a variation that is capable of automatically adjusting its diversity decoding rates for different inputs using reinforcement learning (RL). We observe a further performance boost from this RL technique. This paper includes material from the unpublished script "Mutual Information and Diverse Decoding Improve Neural Machine Translation" (Li and Jurafsky, 2016). version:1
arxiv-1611-07588 | A Neural Network Model to Classify Liver Cancer Patients Using Data Expansion and Compression | http://arxiv.org/abs/1611.07588 | id:1611.07588 author:Ashkan Zeinalzadeh, Tom Wenska, Gordon Okimoto category:stat.ML cs.LG q-bio.QM  published:2016-11-23 summary:We develop a neural network model to classify liver cancer patients into high-risk and low-risk groups using genomic data. Our approach provides a novel technique to classify big data sets using neural network models. We preprocess the data before training the neural network models. We first expand the data using wavelet analysis. We then compress the wavelet coefficients by mapping them onto a new scaled orthonormal coordinate system. Then the data is used to train a neural network model that enables us to classify cancer patients into two different classes of high-risk and low-risk patients. We use the leave-one-out approach to build a neural network model. This neural network model enables us to classify a patient using genomic data as a high-risk or low-risk patient without any information about the survival time of the patient. The results from genomic data analysis are compared with survival time analysis. It is shown that the expansion and compression of data using wavelet analysis and singular value decomposition (SVD) is essential to train the neural network model. version:2
arxiv-1611-08527 | Clickstream analysis for crowd-based object segmentation with confidence | http://arxiv.org/abs/1611.08527 | id:1611.08527 author:Eric Heim, Alexander Seitel, Christian Stock, Fabian Isensee, Lena Maier-Hein category:cs.CV  published:2016-11-25 summary:With the rapidly increasing interest in machine learning based solutions for automatic image annotation, the availability of reference image annotations for algorithm training is one of the major bottlenecks in the field. Crowdsourcing has evolved as a valuable option for low-cost and large-scale data annotation; however, quality control remains a major issue which needs to be addressed. To our knowledge, we are the first to investigate the analysis of clickstreams to improve crowd-based image segmentation. Our method involves training a regressor to estimate a worker's segmentation performance from the clickstream data, where the performance is represented by the DICE similarity coefficient (DSC) comparing the worker's annotation and the reference segmentation. The DSC prediction can be used to identify spammers and weight individual workers by their (estimated) skill when merging multiple segmentations of one image. Using a total of 20,000 crowd annotations performed on publicly available data of cars and cats, we show that (1) our method is highly accurate in predicting the DSC based on clickstream data and thus outperforms state-of-the-art methods for merging multiple annotations and that (2) the regressor does not need to be trained on the object class (e.g. cars) that it is applied to (e.g. cats). In contrast to previously proposed methods, our approach does not rely on additional sanity tasks and can thus be regarded as a low-cost option for spam control and confidence analysis in the context of crowd-based image annotation. version:1
arxiv-1611-08483 | On the Exponentially Weighted Aggregate with the Laplace Prior | http://arxiv.org/abs/1611.08483 | id:1611.08483 author:Arnak S. Dalalyan, Edwin Grappin, Quentin Paris category:math.ST cs.LG stat.TH  published:2016-11-25 summary:In this paper, we study the statistical behaviour of the Exponentially Weighted Aggregate (EWA) in the problem of high-dimensional regression with fixed design. Under the assumption that the underlying regression vector is sparse, it is reasonable to use the Laplace distribution as a prior. The resulting estimator and, specifically, a particular instance of it referred to as the Bayesian lasso, was already used in the statistical literature because of its computational convenience, even though no thorough mathematical analysis of its statistical properties was carried out. The present work fills this gap by establishing sharp oracle inequalities for the EWA with the Laplace prior. These inequalities show that if the temperature parameter is small, the EWA with the Laplace prior satisfies the same type of oracle inequality as the lasso estimator does, as long as the quality of estimation is measured by the prediction loss. Extensions of the proposed methodology to the problem of prediction with low-rank matrices are considered. version:1
arxiv-1611-08480 | Distributed Optimization of Multi-Class SVMs | http://arxiv.org/abs/1611.08480 | id:1611.08480 author:Maximilian Alber, Julian Zimmert, Urun Dogan, Marius Kloft category:stat.ML cs.LG  published:2016-11-25 summary:Training of one-vs.-rest SVMs can be parallelized over the number of classes in a straight forward way. Given enough computational resources, one-vs.-rest SVMs can thus be trained on data involving a large number of classes. The same cannot be stated, however, for the so-called all-in-one SVMs, which require solving a quadratic program of size quadratically in the number of classes. We develop distributed algorithms for two all-in-one SVM formulations (Lee et al. and Weston and Watkins) that parallelize the computation evenly over the number of classes. This allows us to compare these models to one-vs.-rest SVMs on unprecedented scale. The results indicate superior accuracy on text classification data. version:1
arxiv-1611-08472 | Multimodal Latent Variable Analysis | http://arxiv.org/abs/1611.08472 | id:1611.08472 author:Vardan Papyan, Ronen Talmon category:cs.CV  published:2016-11-25 summary:Consider a set of multiple, multimodal sensors capturing a complex system or a physical phenomenon of interest. Our primary goal is to distinguish the underlying sources of variability manifested in the measured data. The first step in our analysis is to find the common source of variability present in all sensor measurements. We base our work on a recent paper, which tackles this problem with alternating diffusion (AD). In this work, we suggest to further the analysis by extracting the sensor-specific variables in addition to the common source. We propose an algorithm, which we analyze theoretically, and then demonstrate on three different applications: a synthetic example, a toy problem, and the task of fetal ECG extraction. version:1
arxiv-1611-08461 | Discriminative Correlation Filter with Channel and Spatial Reliability | http://arxiv.org/abs/1611.08461 | id:1611.08461 author:Alan Luke≈æiƒç, Tom√°≈° Voj√≠≈ô, Luka ƒåehovin, Ji≈ô√≠ Matas, Matej Kristan category:cs.CV  published:2016-11-25 summary:Short-term tracking is an open and challenging problem for which discriminative correlation filters (DCF) have shown excellent performance. We introduce the channel and spatial reliability concepts to DCF tracking and provide a novel learning algorithm for its efficient and seamless integration in the filter update and the tracking process. The spatial reliability map adjusts the filter support to the part of the object suitable for tracking. This both allows to enlarge the search region and improves tracking of non-rectangular objects. Reliability scores reflect channel-wise quality of the learned filters and are used as feature weighting coefficients in localization. Experimentally, with only two simple standard features, HoGs and Colornames, the novel CSR-DCF method -- DCF with Channel and Spatial Reliability -- achieves state-of-the-art results on VOT 2016, VOT 2015 and OTB100. The CSR-DCF runs in real-time on a CPU. version:1
arxiv-1611-08459 | Neural Machine Translation with Latent Semantic of Image and Text | http://arxiv.org/abs/1611.08459 | id:1611.08459 author:Joji Toyama, Masanori Misono, Masahiro Suzuki, Kotaro Nakayama, Yutaka Matsuo category:cs.CL  published:2016-11-25 summary:Although attention-based Neural Machine Translation have achieved great success, attention-mechanism cannot capture the entire meaning of the source sentence because the attention mechanism generates a target word depending heavily on the relevant parts of the source sentence. The report of earlier studies has introduced a latent variable to capture the entire meaning of sentence and achieved improvement on attention-based Neural Machine Translation. We follow this approach and we believe that the capturing meaning of sentence benefits from image information because human beings understand the meaning of language not only from textual information but also from perceptual information such as that gained from vision. As described herein, we propose a neural machine translation model that introduces a continuous latent variable containing an underlying semantic extracted from texts and images. Our model, which can be trained end-to-end, requires image information only when training. Experiments conducted with an English--German translation task show that our model outperforms over the baseline. version:1
arxiv-1611-08408 | Semantic Segmentation using Adversarial Networks | http://arxiv.org/abs/1611.08408 | id:1611.08408 author:Pauline Luc, Camille Couprie, Soumith Chintala, Jakob Verbeek category:cs.CV  published:2016-11-25 summary:Adversarial training has been shown to produce state of the art results for generative image modeling. In this paper we propose an adversarial training approach to train semantic segmentation models. We train a convolutional semantic segmentation network along with an adversarial network that discriminates segmentation maps coming either from the ground truth or from the segmentation network. The motivation for our approach is that it can detect and correct higher-order inconsistencies between ground truth segmentation maps and the ones produced by the segmentation net. Our experiments show that our adversarial training approach leads to improved accuracy on the Stanford Background and PASCAL VOC 2012 datasets. version:1
arxiv-1611-08389 | Color Constancy with Derivative Colors | http://arxiv.org/abs/1611.08389 | id:1611.08389 author:Huan Lei, Guang Jiang, Long Quan category:cs.CV  published:2016-11-25 summary:Information about the illuminant color is well contained in both achromatic regions and the specular components of highlight regions. In this paper, we propose a novel way to achieve color constancy by exploiting such clues. The key to our approach lies in the use of suitably extracted derivative colors, which are able to compute the illuminant color robustly with kernel density estimation. While extracting derivative colors from achromatic regions to approximate the illuminant color well is basically straightforward, the success of our extraction in highlight regions is attributed to the different rates of variation of the diffuse and specular magnitudes in the dichromatic reflection model. The proposed approach requires no training phase and is simple to implement. More significantly, it performs quite satisfactorily under inter-database parameter settings. Our experiments on three standard databases demonstrate its effectiveness and fine performance in comparison to state-of-the-art methods. version:1
arxiv-1611-08387 | Deep Video Deblurring | http://arxiv.org/abs/1611.08387 | id:1611.08387 author:Shuochen Su, Mauricio Delbracio, Jue Wang, Guillermo Sapiro, Wolfgang Heidrich, Oliver Wang category:cs.CV  published:2016-11-25 summary:Motion blur from camera shake is a major problem in videos captured by hand-held devices. Unlike single-image deblurring, video-based approaches can take advantage of the abundant information that exists across neighboring frames. As a result the best performing methods rely on aligning nearby frames. However, aligning images is a computationally expensive and fragile procedure, and methods that aggregate information must therefore be able to identify which regions have been accurately aligned and which have not, a task which requires high level scene understanding. In this work, we introduce a deep learning solution to video deblurring, where a CNN is trained end-to-end to learn how to accumulate information across frames. To train this network, we collected a dataset of real videos recorded with a high framerate camera, which we use to generate synthetic motion blur for supervision. We show that the features learned from this dataset extend to deblurring motion blur that arises due to camera shake in a wide range of videos, and compare the quality of results to a number of other baselines. version:1
arxiv-1611-08373 | Bidirectional LSTM-CRF for Clinical Concept Extraction | http://arxiv.org/abs/1611.08373 | id:1611.08373 author:Raghavendra Chalapathy, Ehsan Zare Borzeshi, Massimo Piccardi category:stat.ML cs.CL cs.LG  published:2016-11-25 summary:Automated extraction of concepts from patient clinical records is an essential facilitator of clinical research. For this reason, the 2010 i2b2/VA Natural Language Processing Challenges for Clinical Records introduced a concept extraction task aimed at identifying and classifying concepts into predefined categories (i.e., treatments, tests and problems). State-of-the-art concept extraction approaches heavily rely on handcrafted features and domain-specific resources which are hard to collect and define. For this reason, this paper proposes an alternative, streamlined approach: a recurrent neural network (the bidirectional LSTM with CRF decoding) initialized with general-purpose, off-the-shelf word embeddings. The experimental results achieved on the 2010 i2b2/VA reference corpora using the proposed framework outperform all recent methods and ranks closely to the best submission from the original 2010 i2b2/VA challenge. version:1
arxiv-1611-08372 | A Unified Convex Surrogate for the Schatten-$p$ Norm | http://arxiv.org/abs/1611.08372 | id:1611.08372 author:Chen Xu, Zhouchen Lin, Hongbin Zha category:stat.ML cs.LG math.NA math.OC  published:2016-11-25 summary:The Schatten-$p$ norm ($0<p<1$) has been widely used to replace the nuclear norm for better approximating the rank function. However, existing methods are either 1) not scalable for large scale problems due to relying on singular value decomposition (SVD) in every iteration, or 2) specific to some $p$ values, e.g., $1/2$, and $2/3$. In this paper, we show that for any $p$, $p_1$, and $p_2 >0$ satisfying $1/p=1/p_1+1/p_2$, there is an equivalence between the Schatten-$p$ norm of one matrix and the Schatten-$p_1$ and the Schatten-$p_2$ norms of its two factor matrices. We further extend the equivalence to multiple factor matrices and show that all the factor norms can be convex and smooth for any $p>0$. In contrast, the original Schatten-$p$ norm for $0<p<1$ is non-convex and non-smooth. As an example we conduct experiments on matrix completion. To utilize the convexity of the factor matrix norms, we adopt the accelerated proximal alternating linearized minimization algorithm and establish its sequence convergence. Experiments on both synthetic and real datasets exhibit its superior performance over the state-of-the-art methods. Its speed is also highly competitive. version:1
arxiv-1611-08366 | Local Discriminant Hyperalignment for multi-subject fMRI data alignment | http://arxiv.org/abs/1611.08366 | id:1611.08366 author:Muhammad Yousefnezhad, Daoqiang Zhang category:stat.ML cs.AI cs.LG  published:2016-11-25 summary:Multivariate Pattern (MVP) classification can map different cognitive states to the brain tasks. One of the main challenges in MVP analysis is validating the generated results across subjects. However, analyzing multi-subject fMRI data requires accurate functional alignments between neuronal activities of different subjects, which can rapidly increase the performance and robustness of the final results. Hyperalignment (HA) is one of the most effective functional alignment methods, which can be mathematically formulated by the Canonical Correlation Analysis (CCA) methods. Since HA mostly uses the unsupervised CCA techniques, its solution may not be optimized for MVP analysis. By incorporating the idea of Local Discriminant Analysis (LDA) into CCA, this paper proposes Local Discriminant Hyperalignment (LDHA) as a novel supervised HA method, which can provide better functional alignment for MVP analysis. Indeed, the locality is defined based on the stimuli categories in the train-set, where the correlation between all stimuli in the same category will be maximized and the correlation between distinct categories of stimuli approaches to near zero. Experimental studies on multi-subject MVP analysis confirm that the LDHA method achieves superior performance to other state-of-the-art HA algorithms. version:1
arxiv-1611-08358 | Kannada Spell Checker with Sandhi Splitter | http://arxiv.org/abs/1611.08358 | id:1611.08358 author:A N Akshatha, Chandana G Upadhyaya, Rajashekara S Murthy category:cs.CL  published:2016-11-25 summary:Spelling errors are introduced in text either during typing, or when the user does not know the correct phoneme or grapheme. If a language contains complex words like sandhi where two or more morphemes join based on some rules, spell checking becomes very tedious. In such situations, having a spell checker with sandhi splitter which alerts the user by flagging the errors and providing suggestions is very useful. A novel algorithm of sandhi splitting is proposed in this paper. The sandhi splitter can split about 7000 most common sandhi words in Kannada language used as test samples. The sandhi splitter was integrated with a Kannada spell checker and a mechanism for generating suggestions was added. A comprehensive, platform independent, standalone spell checker with sandhi splitter application software was thus developed and tested extensively for its efficiency and correctness. A comparative analysis of this spell checker with sandhi splitter was made and results concluded that the Kannada spell checker with sandhi splitter has an improved performance. It is twice as fast, 200 times more space efficient, and it is 90% accurate in case of complex nouns and 50% accurate for complex verbs. Such a spell checker with sandhi splitter will be of foremost significance in machine translation systems, voice processing, etc. This is the first sandhi splitter in Kannada and the advantage of the novel algorithm is that, it can be extended to all Indian languages. version:1
arxiv-1611-08350 | Learning an Invariant Hilbert Space for Domain Adaptation | http://arxiv.org/abs/1611.08350 | id:1611.08350 author:Samitha Herath, Mehrtash Harandi, Fatih Porikli category:cs.CV  published:2016-11-25 summary:This paper introduces a learning scheme to construct a Hilbert space (i.e., a vector space along its inner product) to address both unsupervised and semi-supervised domain adaptation problems. This is achieved by learning projections from each domain to a latent space along the Mahalanobis metric of the latent space to simultaneously minimizing a notion of domain variance while maximizing a measure of discriminatory power. In particular, we make use of the Riemannian optimization techniques to match statistical properties (e.g., first and second order statistics) between samples projected into the latent space from different domains. Upon availability of class labels, we further deem samples sharing the same label to form more compact clusters while pulling away samples coming from different classes.We extensively evaluate and contrast our proposal against state-of-the-art methods for the task of visual domain adaptation using both handcrafted and deep-net features. Our experiments show that even with a simple nearest neighbor classifier, the proposed method can outperform several state-of-the-art methods benefitting from more involved classification schemes. version:1
arxiv-1611-08331 | An Overview on Data Representation Learning: From Traditional Feature Learning to Recent Deep Learning | http://arxiv.org/abs/1611.08331 | id:1611.08331 author:Guoqiang Zhong, Li-Na Wang, Junyu Dong category:cs.LG stat.ML 68T05  published:2016-11-25 summary:Since about 100 years ago, to learn the intrinsic structure of data, many representation learning approaches have been proposed, including both linear ones and nonlinear ones, supervised ones and unsupervised ones. Particularly, deep architectures are widely applied for representation learning in recent years, and have delivered top results in many tasks, such as image classification, object detection and speech recognition. In this paper, we review the development of data representation learning methods. Specifically, we investigate both traditional feature learning algorithms and state-of-the-art deep learning models. The history of data representation learning is introduced, while available resources (e.g. online course, tutorial and book information) and toolboxes are provided. Finally, we conclude this paper with remarks and some interesting research directions on data representation learning. version:1
arxiv-1611-08323 | Full-Resolution Residual Networks for Semantic Segmentation in Street Scenes | http://arxiv.org/abs/1611.08323 | id:1611.08323 author:Tobias Pohlen, Alexander Hermans, Markus Mathias, Bastian Leibe category:cs.CV  published:2016-11-24 summary:Semantic image segmentation is an essential component of modern autonomous driving systems, as an accurate understanding of the surrounding scene is crucial to navigation and action planning. Current state-of-the-art approaches in semantic image segmentation rely on pre-trained networks that were initially developed for classifying images as a whole. While these networks exhibit outstanding recognition performance (i.e., what is visible?), they lack localization accuracy (i.e., where precisely is something located?). Therefore, additional processing steps have to be performed in order to obtain pixel-accurate segmentation masks at the full image resolution. To alleviate this problem we propose a novel ResNet-like architecture that exhibits strong localization and recognition performance. We combine multi-scale context with pixel-level accuracy by using two processing streams within our network: One stream carries information at the full image resolution, enabling precise adherence to segment boundaries. The other stream undergoes a sequence of pooling operations to obtain robust features for recognition. The two streams are coupled at the full image resolution using residuals. Without additional processing steps and without pre-training, our approach achieves an intersection-over-union score of 71.8% on the Cityscapes dataset. version:1
arxiv-1611-08321 | Training and Evaluating Multimodal Word Embeddings with Large-scale Web Annotated Images | http://arxiv.org/abs/1611.08321 | id:1611.08321 author:Junhua Mao, Jiajing Xu, Yushi Jing, Alan Yuille category:cs.LG cs.CL cs.CV  published:2016-11-24 summary:In this paper, we focus on training and evaluating effective word embeddings with both text and visual information. More specifically, we introduce a large-scale dataset with 300 million sentences describing over 40 million images crawled and downloaded from publicly available Pins (i.e. an image with sentence descriptions uploaded by users) on Pinterest. This dataset is more than 200 times larger than MS COCO, the standard large-scale image dataset with sentence descriptions. In addition, we construct an evaluation dataset to directly assess the effectiveness of word embeddings in terms of finding semantically similar or related words and phrases. The word/phrase pairs in this evaluation dataset are collected from the click data with millions of users in an image search system, thus contain rich semantic relationships. Based on these datasets, we propose and compare several Recurrent Neural Networks (RNNs) based multimodal (text and image) models. Experiments show that our model benefits from incorporating the visual information into the word embeddings, and a weight sharing strategy is crucial for learning such multimodal embeddings. The project page is: http://www.stat.ucla.edu/~junhua.mao/multimodal_embedding.html version:1
arxiv-1611-08309 | On Human Intellect and Machine Failures: Troubleshooting Integrative Machine Learning Systems | http://arxiv.org/abs/1611.08309 | id:1611.08309 author:Besmira Nushi, Ece Kamar, Eric Horvitz, Donald Kossmann category:cs.LG  published:2016-11-24 summary:We study the problem of troubleshooting machine learning systems that rely on analytical pipelines of distinct components. Understanding and fixing errors that arise in such integrative systems is difficult as failures can occur at multiple points in the execution workflow. Moreover, errors can propagate, become amplified or be suppressed, making blame assignment difficult. We propose a human-in-the-loop methodology which leverages human intellect for troubleshooting system failures. The approach simulates potential component fixes through human computation tasks and measures the expected improvements in the holistic behavior of the system. The method provides guidance to designers about how they can best improve the system. We demonstrate the effectiveness of the approach on an automated image captioning system that has been pressed into real-world use. version:1
arxiv-1611-08307 | Learning Python Code Suggestion with a Sparse Pointer Network | http://arxiv.org/abs/1611.08307 | id:1611.08307 author:Avishkar Bhoopchand, Tim Rockt√§schel, Earl Barr, Sebastian Riedel category:cs.NE cs.AI cs.CL cs.SE  published:2016-11-24 summary:To enhance developer productivity, all modern integrated development environments (IDEs) include code suggestion functionality that proposes likely next tokens at the cursor. While current IDEs work well for statically-typed languages, their reliance on type annotations means that they do not provide the same level of support for dynamic programming languages as for statically-typed languages. Moreover, suggestion engines in modern IDEs do not propose expressions or multi-statement idiomatic code. Recent work has shown that language models can improve code suggestion systems by learning from software repositories. This paper introduces a neural language model with a sparse pointer network aimed at capturing very long-range dependencies. We release a large-scale code suggestion corpus of 41M lines of Python code crawled from GitHub. On this corpus, we found standard neural language models to perform well at suggesting local phenomena, but struggle to refer to identifiers that are introduced many tokens in the past. By augmenting a neural language model with a pointer network specialized in referring to predefined classes of identifiers, we obtain a much lower perplexity and a 5 percentage points increase in accuracy for code suggestion compared to an LSTM baseline. In fact, this increase in code suggestion accuracy is due to a 13 times more accurate prediction of identifiers. Furthermore, a qualitative analysis shows this model indeed captures interesting long-range dependencies, like referring to a class member defined over 60 tokens in the past. version:1
arxiv-1611-08303 | Deep Watershed Transform for Instance Segmentation | http://arxiv.org/abs/1611.08303 | id:1611.08303 author:Min Bai, Raquel Urtasun category:cs.CV  published:2016-11-24 summary:Most contemporary approaches to instance segmentation use complex pipelines involving conditional random fields, recurrent neural networks, object proposals, or template matching schemes. In our paper, we present a simple yet powerful end-to-end convolutional neural network to tackle this task. Our approach combines intuitions from the classical watershed transform and modern deep learning to produce an energy map of the image where object instances are unambiguously represented as basins in the energy map. We then perform a cut at a single energy level to directly yield connected components corresponding to object instances. Our model achieves an increase of 75% in performance on the challenging Cityscapes Instance Level Segmentation task over the state-of-the-art. version:1
arxiv-1611-08292 | Identifying Significant Predictive Bias in Classifiers | http://arxiv.org/abs/1611.08292 | id:1611.08292 author:Zhe Zhang, Daniel B. Neill category:stat.ML cs.LG  published:2016-11-24 summary:We present a novel subset scan method to detect if a probabilistic binary classifier has statistically significant bias -- over or under predicting the risk -- for some subgroup, and identify the characteristics of this subgroup. This form of model checking and goodness-of-fit test provides a way to interpretably detect the presence of classifier bias and poor classifier fit, not just in one or two dimensions of features of a priori interest, but in the space of all possible feature subgroups. We use subset scan and parametric bootstrap methods to efficiently address the difficulty of assessing the exponentially many possible subgroups. We also suggest several useful extensions of this method for increasing interpretability of predictive models and prediction performance. version:1
arxiv-0905-1424 | Concept Stability for Constructing Taxonomies of Web-site Users | http://arxiv.org/abs/0905.1424 | id:0905.1424 author:Sergei O. Kuznetsov, Dmitry I. Ignatov category:cs.CY cs.AI cs.SI stat.ML H.2.8; J.4  published:2009-05-09 summary:Owners of a web-site are often interested in analysis of groups of users of their site. Information on these groups can help optimizing the structure and contents of the site. In this paper we use an approach based on formal concepts for constructing taxonomies of user groups. For decreasing the huge amount of concepts that arise in applications, we employ stability index of a concept, which describes how a group given by a concept extent differs from other such groups. We analyze resulting taxonomies of user groups for three target websites. version:2
arxiv-1611-08272 | InstanceCut: from Edges to Instances with MultiCut | http://arxiv.org/abs/1611.08272 | id:1611.08272 author:Alexander Kirillov, Evgeny Levinkov, Bjoern Andres, Bogdan Savchynskyy, Carsten Rother category:cs.CV  published:2016-11-24 summary:This work addresses the task of instance-aware semantic segmentation. Our key motivation is to design a simple method with a new modelling-paradigm, which therefore has a different trade-off between advantages and disadvantages compared to known approaches. Our approach, we term InstanceCut, represents the problem by two output modalities: (i) an instance-agnostic semantic segmentation and (ii) all instance-boundaries. The former is computed from a standard convolutional neural network for semantic segmentation, and the latter is derived from a new instance-aware edge detection model. To reason globally about the optimal partitioning of an image into instances, we combine these two modalities into a novel MultiCut formulation. We evaluate our approach on the challenging CityScapes dataset. Despite the conceptual simplicity of our approach, we achieve the best result among all published methods, and perform particularly well for rare object classes. version:1
arxiv-1611-08258 | Weakly Supervised Cascaded Convolutional Networks | http://arxiv.org/abs/1611.08258 | id:1611.08258 author:Ali Diba, Vivek Sharma, Ali Pazandeh, Hamed Pirsiavash, Luc Van Gool category:cs.CV  published:2016-11-24 summary:Object detection is a challenging task in visual understanding domain, and even more so if the supervision is to be weak. Recently, few efforts to handle the task without expensive human annotations is established by promising deep neural network. A new architecture of cascaded networks is proposed to learn a convolutional neural network (CNN) under such conditions. We introduce two such architectures, with either two cascade stages or three which are trained in an end-to-end pipeline. The first stage of both architectures extracts best candidate of class specific region proposals by training a fully convolutional network. In the case of the three stage architecture, the middle stage provides object segmentation, using the output of the activation maps of first stage. The final stage of both architectures is a part of a convolutional neural network that performs multiple instance learning on proposals extracted in the previous stage(s). Our experiments on the PASCAL VOC 2007, 2010, 2012 and large scale object datasets, ILSVRC 2013, 2014 datasets show improvements in the areas of weakly-supervised object detection, classification and localization. version:1
arxiv-1611-08256 | The Inverse Bagging Algorithm: Anomaly Detection by Inverse Bootstrap Aggregating | http://arxiv.org/abs/1611.08256 | id:1611.08256 author:Pietro Vischia, Tommaso Dorigo category:stat.ML hep-ex physics.data-an  published:2016-11-24 summary:For data sets populated by a very well modeled process and by another process of unknown probability density function (PDF), a desired feature when manipulating the fraction of the unknown process (either for enhancing it or suppressing it) consists in avoiding to modify the kinematic distributions of the well modeled one. A bootstrap technique is used to identify sub-samples rich in the well modeled process, and classify each event according to the frequency of it being part of such sub-samples. Comparisons with general MVA algorithms will be shown, as well as a study of the asymptotic properties of the method, making use of a public domain data set that models a typical search for new physics as performed at hadronic colliders such as the Large Hadron Collider (LHC). version:1
arxiv-1611-08230 | Learning Fast Sparsifying Transforms | http://arxiv.org/abs/1611.08230 | id:1611.08230 author:Cristian Rusu, John Thompson category:cs.LG  published:2016-11-24 summary:Given a dataset, the task of learning a transform that allows sparse representations of the data bears the name of dictionary learning. In many applications, these learned dictionaries represent the data much better than the static well-known transforms (Fourier, Hadamard etc.). The main downside of learned transforms is that they lack structure and therefore they are not computationally efficient, unlike their classical counterparts. This posses several difficulties especially when using power limited hardware such as mobile devices, therefore discouraging the application of sparsity techniques in such scenarios. In this paper we construct orthonormal and non-orthonormal dictionaries that are factorized as a product of a few basic transformations. In the orthonormal case, we solve exactly the dictionary update problem for one basic transformation, which can be viewed as a generalized Givens rotation, and then propose to construct orthonormal dictionaries that are a product of these transformations, guaranteeing their fast manipulation. We also propose a method to construct fast square but non-orthonormal dictionaries that are factorized as a product of few transforms that can be viewed as a further generalization of Givens rotations to the non-orthonormal setting. We show how the proposed transforms can balance very well data representation performance and computational complexity. We also compare with classical fast and learned general and orthonormal transforms. version:1
arxiv-1611-08229 | Fast Orthonormal Sparsifying Transforms Based on Householder Reflectors | http://arxiv.org/abs/1611.08229 | id:1611.08229 author:Cristian Rusu, Nuria Gonzalez-Prelcic, Robert Heath category:cs.LG stat.ML  published:2016-11-24 summary:Dictionary learning is the task of determining a data-dependent transform that yields a sparse representation of some observed data. The dictionary learning problem is non-convex, and usually solved via computationally complex iterative algorithms. Furthermore, the resulting transforms obtained generally lack structure that permits their fast application to data. To address this issue, this paper develops a framework for learning orthonormal dictionaries which are built from products of a few Householder reflectors. Two algorithms are proposed to learn the reflector coefficients: one that considers a sequential update of the reflectors and one with a simultaneous update of all reflectors that imposes an additional internal orthogonal constraint. The proposed methods have low computational complexity and are shown to converge to local minimum points which can be described in terms of the spectral properties of the matrices involved. The resulting dictionaries balance between the computational complexity and the quality of the sparse representations by controlling the number of Householder reflectors in their product. Simulations of the proposed algorithms are shown in the image processing setting where well-known fast transforms are available for comparisons. The proposed algorithms have favorable reconstruction error and the advantage of a fast implementation relative to the classical, unstructured, dictionaries. version:1
arxiv-1611-08215 | Where Should You Attend While Driving? | http://arxiv.org/abs/1611.08215 | id:1611.08215 author:Andrea Palazzi, Francesco Solera, Simone Calderara, Stefano Alletto, Rita Cucchiara category:cs.CV cs.HC  published:2016-11-24 summary:Despite the advent of autonomous cars, it's likely - at least in the near future - that human attention will still maintain a central role as a guarantee in terms of legal responsibility during the driving task. In this paper we study the dynamics of the driver's gaze and use it as a proxy to understand related attentional mechanisms. First, we build our analysis upon two questions: where and what the driver is looking at? Second, we model the driver's gaze by training a coarse-to-fine convolutional network on short sequences extracted from the DR(eye)VE dataset. Experimental comparison against different baselines reveal that the driver's gaze can indeed be learnt to some extent, despite i) being highly subjective and ii) having only one driver's gaze available for each sequence due to the irreproducibility of the scene. Eventually, we advocate for a new assisted driving paradigm which suggests to the driver, with no intervention, where she should focus her attention. version:1
arxiv-1611-08195 | Domain Adaptation by Mixture of Alignments of Second- or Higher-Order Scatter Tensors | http://arxiv.org/abs/1611.08195 | id:1611.08195 author:Piotr Koniusz, Yusuf Tas, Fatih Porikli category:cs.CV  published:2016-11-24 summary:In this paper, we propose an approach to the domain adaptation, dubbed Second- or Higher-order Transfer of Knowledge (So-HoT), based on the mixture of alignments of second- or higher-order scatter statistics between the source and target domains. The human ability to learn from few labeled samples is a recurring motivation in the literature for domain adaptation. Towards this end, we investigate the supervised target scenario for which few labeled target training samples per category exist. Specifically, we utilize two CNN streams: the source and target networks fused at the classifier level. Features from the fully connected layers fc7 of each network are used to compute second- or even higher-order scatter tensors; one per network stream per class. As the source and target distributions are somewhat different despite being related, we align the scatters of the two network streams of the same class (within-class scatters) to a desired degree with our bespoke loss while maintaining good separation of the between-class scatters. We train the entire network in end-to-end fashion. We provide evaluations on the standard Office benchmark (visual domains), RGB-D combined with Caltech256 (depth-to-rgb transfer) and Pascal VOC2007 combined with the TU Berlin dataset (image-to-sketch transfer). We attain state-of-the-art results. version:1
arxiv-1611-08194 | Interferences in match kernels | http://arxiv.org/abs/1611.08194 | id:1611.08194 author:Naila Murray, Herv√© J√©gou, Florent Perronnin, Andrew Zisserman category:cs.CV  published:2016-11-24 summary:We consider the design of an image representation that embeds and aggregates a set of local descriptors into a single vector. Popular representations of this kind include the bag-of-visual-words, the Fisher vector and the VLAD. When two such image representations are compared with the dot-product, the image-to-image similarity can be interpreted as a match kernel. In match kernels, one has to deal with interference, i.e. with the fact that even if two descriptors are unrelated, their matching score may contribute to the overall similarity. We formalise this problem and propose two related solutions, both aimed at equalising the individual contributions of the local descriptors in the final representation. These methods modify the aggregation stage by including a set of per-descriptor weights. They differ by the objective function that is optimised to compute those weights. The first is a "democratisation" strategy that aims at equalising the relative importance of each descriptor in the set comparison metric. The second one involves equalising the match of a single descriptor to the aggregated vector. These concurrent methods give a substantial performance boost over the state of the art in image search with short or mid-size vectors, as demonstrated by our experiments on standard public image retrieval benchmarks. version:1
arxiv-1611-08191 | Interpreting the Predictions of Complex ML Models by Layer-wise Relevance Propagation | http://arxiv.org/abs/1611.08191 | id:1611.08191 author:Wojciech Samek, Gr√©goire Montavon, Alexander Binder, Sebastian Lapuschkin, Klaus-Robert M√ºller category:stat.ML cs.LG  published:2016-11-24 summary:Complex nonlinear models such as deep neural network (DNNs) have become an important tool for image classification, speech recognition, natural language processing, and many other fields of application. These models however lack transparency due to their complex nonlinear structure and to the complex data distributions to which they typically apply. As a result, it is difficult to fully characterize what makes these models reach a particular decision for a given input. This lack of transparency can be a drawback, especially in the context of sensitive applications such as medical analysis or security. In this short paper, we summarize a recent technique introduced by Bach et al. [1] that explains predictions by decomposing the classification decision of DNN models in terms of input variables. version:1
arxiv-1611-07703 | 'Part'ly first among equals: Semantic part-based benchmarking for state-of-the-art object recognition systems | http://arxiv.org/abs/1611.07703 | id:1611.07703 author:Ravi Kiran Sarvadevabhatla, Shanthakumar Venkatraman, R. Venkatesh Babu category:cs.CV  published:2016-11-23 summary:An examination of object recognition challenge leaderboards (ILSVRC, PASCAL-VOC) reveals that the top-performing classifiers typically exhibit small differences amongst themselves in terms of error rate/mAP. To better differentiate the top performers, additional criteria are required. Moreover, the (test) images, on which the performance scores are based, predominantly contain fully visible objects. Therefore, `harder' test images, mimicking the challenging conditions (e.g. occlusion) in which humans routinely recognize objects, need to be utilized for benchmarking. To address the concerns mentioned above, we make two contributions. First, we systematically vary the level of local object-part content, global detail and spatial context in images from PASCAL VOC 2010 to create a new benchmarking dataset dubbed PPSS-12. Second, we propose an object-part based benchmarking procedure which quantifies classifiers' robustness to a range of visibility and contextual settings. The benchmarking procedure relies on a semantic similarity measure that naturally addresses potential semantic granularity differences between the category labels in training and test datasets, thus eliminating manual mapping. We use our procedure on the PPSS-12 dataset to benchmark top-performing classifiers trained on the ILSVRC-2012 dataset. Our results show that the proposed benchmarking procedure enables additional differentiation among state-of-the-art object classifiers in terms of their ability to handle missing content and insufficient object detail. Given this capability for additional differentiation, our approach can potentially supplement existing benchmarking procedures used in object recognition challenge leaderboards. version:2
arxiv-1611-07583 | Alternating Direction Graph Matching | http://arxiv.org/abs/1611.07583 | id:1611.07583 author:D. Khu√™ L√™-Huu, Nikos Paragios category:cs.CV  published:2016-11-22 summary:In this paper, we introduce a graph matching method that can account for constraints of arbitrary order, with arbitrary potential functions. Unlike previous decomposition approaches that rely on the graph structures, we introduce a decomposition of the matching constraints. Graph matching is then reformulated as a non-convex non-separable optimization problem that can be split into smaller and much-easier-to-solve subproblems, by means of the alternating direction method of multipliers. The proposed framework is modular, scalable, and can be instantiated into different variants. Two instantiations are studied exploring pairwise and higher-order constraints. Experimental results on widely adopted benchmarks involving synthetic and real examples demonstrate that the proposed solutions outperform existing pairwise graph matching methods, and competitive with the state of the art in higher-order settings. version:2
arxiv-1611-08135 | Question Retrieval for Community-based Question Answering via Heterogeneous Network Integration Learning | http://arxiv.org/abs/1611.08135 | id:1611.08135 author:Zheqian Chen, Chi Zhang, Zhou Zhao, Deng Cai category:cs.IR cs.CL  published:2016-11-24 summary:Community based question answering platforms have attracted substantial users to share knowledge and learn from each other. As the rapid enlargement of CQA platforms, quantities of overlapped questions emerge, which makes users confounded to select a proper reference. It is urgent for us to take effective automated algorithms to reuse historical questions with corresponding answers. In this paper we focus on the problem with question retrieval, which aims to match historical questions that are relevant or semantically equivalent to resolve one s query directly. The challenges in this task are the lexical gaps between questions for the word ambiguity and word mismatch problem. Furthermore, limited words in queried sentences cause sparsity of word features. To alleviate these challenges, we propose a novel framework named HNIL which encodes not only the question contents but also the askers social interactions to enhance the question embedding performance. More specifically, we apply random walk based learning method with recurrent neural network to match the similarities between askers question and historical questions proposed by other users. Extensive experiments on a large scale dataset from a real world CQA site show that employing the heterogeneous social network information outperforms the other state of the art solutions in this task. version:1
arxiv-1611-08134 | Comparative study of histogram distance measures for re-identification | http://arxiv.org/abs/1611.08134 | id:1611.08134 author:Pedro A. Mar√≠n-Reyes, Javier Lorenzo-Navarro, Modesto Castrill√≥n-Santana category:cs.CV  published:2016-11-24 summary:Color based re-identification methods usually rely on a distance function to measure the similarity between individuals. In this paper we study the behavior of several histogram distance measures in different color spaces. We wonder whether there is a particular histogram distance measure better than others, likewise also, if there is a color space that present better discrimination features. Several experiments are designed and evaluated in several images to obtain measures against various color spaces. We test in several image databases. A measure ranking is generated to calculate the area under the CMC, this area is the indicator used to evaluate which distance measure and color space present the best performance for the considered databases. Also, other parameters such as the image division in horizontal stripes and number of histogram bins, have been studied. version:1
arxiv-1611-08131 | Extraction of airway trees using multiple hypothesis tracking and template matching | http://arxiv.org/abs/1611.08131 | id:1611.08131 author:Raghavendra Selvan, Jens Petersen, Jesper H. Pedersen, Marleen de Bruijne category:cs.CV  published:2016-11-24 summary:Knowledge of airway tree morphology has important clinical applications in diagnosis of chronic obstructive pulmonary disease. We present an automatic tree extraction method based on multiple hypothesis tracking and template matching for this purpose and evaluate its performance on chest CT images. The method is adapted from a semi-automatic method devised for vessel segmentation. Idealized tubular templates are constructed that match airway probability obtained from a trained classifier and ranked based on their relative significance. Several such regularly spaced templates form the local hypotheses used in constructing a multiple hypothesis tree, which is then traversed to reach decisions. The proposed modifications remove the need for local thresholding of hypotheses as decisions are made entirely based on statistical comparisons involving the hypothesis tree. The results show improvements in performance when compared to the original method and region growing on intensity images. We also compare the method with region growing on the probability images, where the presented method does not show substantial improvement, but we expect it to be less sensitive to local anomalies in the data. version:1
arxiv-1611-08108 | Dynamic Key-Value Memory Network for Knowledge Tracing | http://arxiv.org/abs/1611.08108 | id:1611.08108 author:Jiani Zhang, Xingjian Shi, Irwin King, Dit-Yan Yeung category:cs.AI cs.LG  published:2016-11-24 summary:The goal of knowledge tracing is to model students' mastering levels of underlying knowledge concepts, termed knowledge state, based on students' exercise performance data. However, existing methods, such as Bayesian Knowledge Tracing (BKT) or Deep Knowledge Tracing (DKT), either require costly human-labeled concept annotations or fail to exactly pinpoint which concepts a student is good at or unfamiliar with. To solve these problems, in this paper we introduce a new model called Dynamic Key-Value Memory Network (DKVMN) that can learn representations using nonlinear transformations and directly output a student's mastering level of each concept. Unlike standard Memory-Augmented Neural Networks (MANNs) that facilitate a single memory matrix or two static memory matrices, our model has one static matrix called key that stores the knowledge concepts and the other dynamic matrix called value that stores and updates corresponding concepts' mastery levels. Experiments show that our DKVMN model, which is trained end-to-end, consistently outperforms the state-of-the-art model on a range of knowledge tracing data-sets. We also illustrate that the learned DKVMN can automatically discover underlying concepts of the exercises which are typically performed by human annotations, and depict a student's changing knowledge state. version:1
arxiv-1611-08107 | Automatically Building Face Datasets of New Domains from Weakly Labeled Data with Pretrained Models | http://arxiv.org/abs/1611.08107 | id:1611.08107 author:Shengyong Ding, Junyu Wu, Wei Xu, Hongyang Chao category:cs.CV  published:2016-11-24 summary:Training data are critical in face recognition systems. However, labeling a large scale face data for a particular domain is very tedious. In this paper, we propose a method to automatically and incrementally construct datasets from massive weakly labeled data of the target domain which are readily available on the Internet under the help of a pretrained face model. More specifically, given a large scale weakly labeled dataset in which each face image is associated with a label, i.e. the name of an identity, we create a graph for each identity with edges linking matched faces verified by the existing model under a tight threshold. Then we use the maximal subgraph as the cleaned data for that identity. With the cleaned dataset, we update the existing face model and use the new model to filter the original dataset to get a larger cleaned dataset. We collect a large weakly labeled dataset containing 530,560 Asian face images of 7,962 identities from the Internet, which will be published for the study of face recognition. By running the filtering process, we obtain a cleaned datasets (99.7+% purity) of size 223,767 (recall 70.9%). On our testing dataset of Asian faces, the model trained by the cleaned dataset achieves recognition rate 93.1%, which obviously outperforms the model trained by the public dataset CASIA whose recognition rate is 85.9%. version:1
arxiv-1611-08104 | Quantum Enhanced Inference in Markov Logic Networks | http://arxiv.org/abs/1611.08104 | id:1611.08104 author:Peter Wittek, Christian Gogolin category:stat.ML cs.AI quant-ph  published:2016-11-24 summary:Markov logic networks (MLNs) reconcile two opposing schools in machine learning and artificial intelligence: causal networks, which account for uncertainty extremely well, and first-order logic, which allows for formal deduction. An MLN is essentially a first-order logic template to generate Markov networks. Inference in MLNs is probabilistic and it is often performed by approximate methods such as Markov chain Monte Carlo (MCMC) Gibbs sampling. An MLN has many regular, symmetric structures that can be exploited at both first-order level and in the generated Markov network. We analyze the graph structures that are produced by various lifting methods and investigate the extent to which quantum protocols can be used to speed up Gibbs sampling with state preparation and measurement schemes. We review different such approaches, discuss their advantages, theoretical limitations, and their appeal to implementations. We find that a straightforward application of a recent result yields exponential speedup compared to classical heuristics in approximate probabilistic inference, thereby demonstrating another example where advanced quantum resources can potentially prove useful in machine learning. version:1
arxiv-1611-08097 | Geometric deep learning: going beyond Euclidean data | http://arxiv.org/abs/1611.08097 | id:1611.08097 author:Michael M. Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, Pierre Vandergheynst category:cs.CV  published:2016-11-24 summary:Many signal processing problems involve data whose underlying structure is non-Euclidean, but may be modeled as a manifold or (combinatorial) graph. For instance, in social networks, the characteristics of users can be modeled as signals on the vertices of the social graph. Sensor networks are graph models of distributed interconnected sensors, whose readings are modelled as time-dependent signals on the vertices. In genetics, gene expression data are modeled as signals defined on the regulatory network. In neuroscience, graph models are used to represent anatomical and functional structures of the brain. Modeling data given as points in a high-dimensional Euclidean space using nearest neighbor graphs is an increasingly popular trend in data science, allowing practitioners access to the intrinsic structure of the data. In computer graphics and vision, 3D objects are modeled as Riemannian manifolds (surfaces) endowed with properties such as color texture. Even more complex examples include networks of operators, e.g., functional correspondences or difference operators in a collection of 3D shapes, or orientations of overlapping cameras in multi-view vision ("structure from motion") problems. The complexity of geometric data and the availability of very large datasets (in the case of social networks, on the scale of billions) suggest the use of machine learning techniques. In particular, deep learning has recently proven to be a powerful tool for problems with large datasets with underlying Euclidean structure. The purpose of this paper is to overview the problems arising in relation to geometric deep learning and present solutions existing today for this class of problems, as well as key difficulties and future research directions. version:1
arxiv-1611-08096 | User Personalized Satisfaction Prediction via Multiple Instance Deep Learning | http://arxiv.org/abs/1611.08096 | id:1611.08096 author:Zheqian Chen, Ben Gao, Huimin Zhang, Zhou Zhao, Deng Cai category:cs.IR cs.CL  published:2016-11-24 summary:Community based question answering services have arisen as a popular knowledge sharing pattern for netizens. With abundant interactions among users, individuals are capable of obtaining satisfactory information. However, it is not effective for users to attain answers within minutes. Users have to check the progress over time until the satisfying answers submitted. We address this problem as a user personalized satisfaction prediction task. Existing methods usually exploit manual feature selection. It is not desirable as it requires careful design and is labor intensive. In this paper, we settle this issue by developing a new multiple instance deep learning framework. Specifically, in our settings, each question follows a weakly supervised learning multiple instance learning assumption, where its obtained answers can be regarded as instance sets and we define the question resolved with at least one satisfactory answer. We thus design an efficient framework exploiting multiple instance learning property with deep learning to model the question answer pairs. Extensive experiments on large scale datasets from Stack Exchange demonstrate the feasibility of our proposed framework in predicting askers personalized satisfaction. Our framework can be extended to numerous applications such as UI satisfaction Prediction, multi armed bandit problem, expert finding and so on. version:1
arxiv-1611-08091 | Deep Joint Face Hallucination and Recognition | http://arxiv.org/abs/1611.08091 | id:1611.08091 author:Junyu Wu, Shengyong Ding, Wei Xu, Hongyang Chao category:cs.CV  published:2016-11-24 summary:Deep models have achieved impressive performance for face hallucination tasks. However, we observe that directly feeding the hallucinated facial images into recog- nition models can even degrade the recognition performance despite the much better visualization quality. In this paper, we address this problem by jointly learning a deep model for two tasks, i.e. face hallucination and recognition. In particular, we design an end-to-end deep convolution network with hallucination sub-network cascaded by recognition sub-network. The recognition sub- network are responsible for producing discriminative feature representations using the hallucinated images as inputs generated by hallucination sub-network. During training, we feed LR facial images into the network and optimize the parameters by minimizing two loss items, i.e. 1) face hallucination loss measured by the pixel wise difference between the ground truth HR images and network-generated images; and 2) verification loss which is measured by the classification error and intra-class distance. We extensively evaluate our method on LFW and YTF datasets. The experimental results show that our method can achieve recognition accuracy 97.95% on 4x down-sampled LFW testing set, outperforming the accuracy 96.35% of conventional face recognition model. And on the more challenging YTF dataset, we achieve recognition accuracy 90.65%, a margin over the recognition accuracy 89.45% obtained by conventional face recognition model on the 4x down-sampled version. version:1
arxiv-1611-08083 | Survey of Expressivity in Deep Neural Networks | http://arxiv.org/abs/1611.08083 | id:1611.08083 author:Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, Jascha Sohl-Dickstein category:stat.ML cs.LG cs.NE  published:2016-11-24 summary:We survey results on neural network expressivity described in "On the Expressive Power of Deep Neural Networks". The paper motivates and develops three natural measures of expressiveness, which all display an exponential dependence on the depth of the network. In fact, all of these measures are related to a fourth quantity, trajectory length. This quantity grows exponentially in the depth of the network, and is responsible for the depth sensitivity observed. These results translate to consequences for networks during and after training. They suggest that parameters earlier in a network have greater influence on its expressive power -- in particular, given a layer, its influence on expressivity is determined by the remaining depth of the network after that layer. This is verified with experiments on MNIST and CIFAR-10. We also explore the effect of training on the input-output map, and find that it trades off between the stability and expressivity. version:1
arxiv-1611-08070 | Multiscale Inverse Reinforcement Learning using Diffusion Wavelets | http://arxiv.org/abs/1611.08070 | id:1611.08070 author:Jung-Su Ha, Han-Lim Choi category:cs.LG cs.AI  published:2016-11-24 summary:This work presents a multiscale framework to solve an inverse reinforcement learning (IRL) problem for continuous-time/state stochastic systems. We take advantage of a diffusion wavelet representation of the associated Markov chain to abstract the state space. This not only allows for effectively handling the large (and geometrically complex) decision space but also provides more interpretable representations of the demonstrated state trajectories and also of the resulting policy of IRL. In the proposed framework, the problem is divided into the global and local IRL, where the global approximation of the optimal value functions are obtained using coarse features and the local details are quantified using fine local features. An illustrative numerical example on robot path control in a complex environment is presented to verify the proposed method. version:1
arxiv-1611-08069 | 3D Fully Convolutional Network for Vehicle Detection in Point Cloud | http://arxiv.org/abs/1611.08069 | id:1611.08069 author:Bo Li category:cs.CV cs.RO  published:2016-11-24 summary:2D fully convolutional network has been recently successfully applied to object detection from images. In this paper, we extend the fully convolutional network based detection techniques to 3D and apply it to point cloud data. The proposed approach is verified on the task of vehicle detection from lidar point cloud for autonomous driving. Experiments on the KITTI dataset shows a significant performance improvement over the previous point cloud based detection approaches. version:1
arxiv-1611-08061 | Recalling Holistic Information for Semantic Segmentation | http://arxiv.org/abs/1611.08061 | id:1611.08061 author:Hexiang Hu, Zhiwei Deng, Guang-tong Zhou, Fei Sha, Greg Mori category:cs.CV  published:2016-11-24 summary:Semantic segmentation requires a detailed labeling of image pixels by object category. Information derived from local image patches is necessary to describe the detailed shape of individual objects. However, this information is ambiguous and can result in noisy labels. Global inference of image content can instead capture the general semantic concepts present. We advocate that high-recall holistic inference of image concepts provides valuable information for detailed pixel labeling. We build a two-stream neural network architecture that facilitates information flow from holistic information to local pixels, while keeping common image features shared among the low-level layers of both the holistic analysis and segmentation branches. We empirically evaluate our network on four standard semantic segmentation datasets. Our network obtains state-of-the-art performance on PASCAL-Context and NYUDv2, and ablation studies verify its effectiveness on ADE20K and SIFT-Flow. version:1
arxiv-1611-08050 | Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields | http://arxiv.org/abs/1611.08050 | id:1611.08050 author:Zhe Cao, Tomas Simon, Shih-En Wei, Yaser Sheikh category:cs.CV  published:2016-11-24 summary:We present a realtime approach for multi-person 2D pose estimation that predicts vector fields, which we refer to as Part Affinity Fields (PAFs), that directly expose the association between anatomical parts in an image. The architecture is designed to jointly learn part locations and their association, via two branches of the same sequential prediction process. The sequential prediction enables the part confidence maps and the association fields to encode global context, while allowing an efficient bottom-up parsing step that maintains tractable runtime complexity. Our method has set the state-of-the-art performance on the inaugural MSCOCO 2016 keypoints challenge, and significantly exceeds the previous state-of-the-art result on the MPII Multi-Person benchmark, both in performance and efficiency. version:1
arxiv-1611-07800 | Infinite Variational Autoencoder for Semi-Supervised Learning | http://arxiv.org/abs/1611.07800 | id:1611.07800 author:Ehsan Abbasnejad, Anthony Dick, Anton van den Hengel category:cs.LG stat.ML  published:2016-11-23 summary:This paper presents an infinite variational autoencoder (VAE) whose capacity adapts to suit the input data. This is achieved using a mixture model where the mixing coefficients are modeled by a Dirichlet process, allowing us to integrate over the coefficients when performing inference. Critically, this then allows us to automatically vary the number of autoencoders in the mixture based on the data. Experiments show the flexibility of our method, particularly for semi-supervised learning, where only a small number of training samples are available. version:2
arxiv-1611-08036 | Robotic Grasp Detection using Deep Convolutional Neural Networks | http://arxiv.org/abs/1611.08036 | id:1611.08036 author:Sulabh Kumra, Christopher Kanan category:cs.RO cs.CV  published:2016-11-24 summary:Deep learning has significantly advanced computer vision and natural language processing. While there have been some successes in robotics using deep learning, deep learning has not been widely adopted. In this paper, we present a novel robotic grasp detection system that predicts the best grasping pose of a parallel-plate robotic gripper for novel objects using the RGB-D image of the scene. The proposed model uses a deep convolutional neural network to extract features from the scene and then uses a shallow convolutional neural network to predict the graspability of the object of interest for a specific position and orientation. Our multi-modal model achieved an accuracy of 88.96% and runs at real-time speeds. This redefines the state-ofthe- art for robotic grasp detection. version:1
arxiv-1611-08034 | Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling | http://arxiv.org/abs/1611.08034 | id:1611.08034 author:Zhe Gan, Chunyuan Li, Changyou Chen, Yunchen Pu, Qinliang Su, Lawrence Carin category:cs.CL cs.LG  published:2016-11-23 summary:Recurrent neural networks (RNNs) have shown promising performance for language modeling. However, traditional training of RNNs using back-propagation through time often suffers from overfitting. One reason for this is that stochastic optimization (used for large training sets) does not provide good estimates of model uncertainty. This paper leverages recent advances in stochastic gradient Markov Chain Monte Carlo (also appropriate for large training sets) to learn weight uncertainty in RNNs. It yields a principled Bayesian learning algorithm, adding gradient noise during training (enhancing exploration of the model-parameter space) and model averaging when testing. Extensive experiments on various RNN models and across a broad range of applications demonstrate the superiority of the proposed approach over stochastic optimization. version:1
arxiv-1611-08024 | EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces | http://arxiv.org/abs/1611.08024 | id:1611.08024 author:Vernon J. Lawhern, Amelia J. Solon, Nicholas R. Waytowich, Stephen M. Gordon, Chou P. Hung, Brent J. Lance category:cs.LG q-bio.NC stat.ML  published:2016-11-23 summary:Objective: Brain-Computer Interface technologies (BCI) enable the direct communication between humans and computers by analyzing brain measurements, such as electroencephalography (EEG). These technologies have been applied to a variety of domains, including neuroprosthetic control and the monitoring of epileptic seizures. Existing BCI systems primarily use a priori knowledge of EEG features of interest to build machine learning models. Recently, convolutional networks have been used for automatic feature extraction of large image databases, where they have obtained state-of-the-art results. In this work we introduce EEGNet, a compact fully convolutional network for EEG-based BCIs developed using Deep Learning approaches. Methods: EEGNet is a 4-layer convolutional network that uses filter factorization for learning a compact representation of EEG time series. EEGNet is one of the smallest convolutional networks to date, having less than 2200 parameters for a binary classification. Results: We show state-of-the-art classification performance across four different BCI paradigms: P300 event-related potential, error-related negativity, movement-related cortical potential, and sensory motor rhythm, with as few as 500 EEG trials. We also show that adding more trials reduces the error variance of prediction rather than improving classification performance. Conclusion: We provide preliminary evidence suggesting that our model can be used with small EEG databases while improving upon the state-of-the-art performance across several tasks and across subjects. Significance: The EEGNet neural network architecture provides state-of-the-art performance across several tasks and across subjects, challenging the notion that large datasets are required to obtain optimal performance. version:1
arxiv-1611-08002 | Semantic Compositional Networks for Visual Captioning | http://arxiv.org/abs/1611.08002 | id:1611.08002 author:Zhe Gan, Chuang Gan, Xiaodong He, Yunchen Pu, Kenneth Tran, Jianfeng Gao, Lawrence Carin, Li Deng category:cs.CV cs.CL cs.LG  published:2016-11-23 summary:A Semantic Compositional Network (SCN) is developed for image captioning, in which semantic concepts (i.e., tags) are detected from the image, and the probability of each tag is used to compose the parameters in a long short-term memory (LSTM) network. The SCN extends each weight matrix of the LSTM to an ensemble of tag-dependent weight matrices. The degree to which each member of the ensemble is used to generate an image caption is tied to the image-dependent probability of the corresponding tag. In addition to captioning images, we also extend the SCN to generate captions for video clips. We qualitatively analyze semantic composition in SCNs, and quantitatively evaluate the algorithm on three benchmark datasets: COCO, Flickr30k, and Youtube2Text. Experimental results show that the proposed method significantly outperforms prior state-of-the-art approaches, across multiple evaluation metrics. version:1
arxiv-1611-08481 | GuessWhat?! Visual object discovery through multi-modal dialogue | http://arxiv.org/abs/1611.08481 | id:1611.08481 author:Harm de Vries, Florian Strub, Sarath Chandar, Olivier Pietquin, Hugo Larochelle, Aaron Courville category:cs.AI cs.CV  published:2016-11-23 summary:We introduce GuessWhat?!, a two-player guessing game as a testbed for research on the interplay of computer vision and dialogue systems. The goal of the game is to locate an unknown object in a rich image scene by asking a sequence of questions. Higher-level image understanding, like spatial reasoning and language grounding, is required to solve the proposed task. Our key contribution is the collection of a large-scale dataset consisting of 150K human-played games with a total of 800K visual question-answer pairs on 66K images. We explain our design decisions in collecting the dataset and introduce the oracle and questioner tasks that are associated with the two players of the game. We prototyped deep learning models to establish initial baselines of the introduced tasks. version:1
arxiv-1611-07954 | Emergent Logical Structure in Vector Representations of Neural Readers | http://arxiv.org/abs/1611.07954 | id:1611.07954 author:Hai Wang, Takeshi Onishi, Kevin Gimpel, David McAllester category:cs.CL  published:2016-11-23 summary:Reading comprehension is a question answering task where the answer is to be found in a given passage about entities and events not mentioned in general knowledge sources. A significant number of neural architectures for this task (neural readers) have recently been developed and evaluated on large cloze-style datasets. We present experiments supporting the existence of logical structure in the hidden state vectors of "aggregation readers" such as the Attentive Reader and Stanford Reader. The logical structure of aggregation readers reflects the architecture of "explicit reference readers" such as the Attention-Sum Reader, the Gated Attention Reader and the Attention-over-Attention Reader. This relationship between aggregation readers and explicit reference readers presents a case study in emergent logical structure. In an independent contribution, we show that the addition of linguistics features to the input to existing neural readers significantly boosts performance yielding the best results to date on the Who-did-What datasets. version:1
arxiv-1611-06972 | Measuring Sample Quality with Diffusions | http://arxiv.org/abs/1611.06972 | id:1611.06972 author:Jack Gorham, Andrew B. Duncan, Sebastian J. Vollmer, Lester Mackey category:stat.ML cs.LG math.PR  published:2016-11-21 summary:Standard Markov chain Monte Carlo diagnostics, like effective sample size, are ineffective for biased sampling procedures that sacrifice asymptotic correctness for computational speed. Recent work addresses this issue for a class of strongly log-concave target distributions by constructing a computable discrepancy measure based on Stein's method that provably determines convergence to the target. We generalize this approach to cover any target with a fast-coupling Ito diffusion by bounding the derivatives of Stein equation solutions in terms of Markov process coupling rates. As example applications, we develop computable and convergence-determining diffusion Stein discrepancies for log-concave, heavy-tailed, and multimodal targets and use these quality measures to select the hyperparameters of biased samplers, compare random and deterministic quadrature rules, and quantify bias-variance tradeoffs in approximate Markov chain Monte Carlo. Our explicit multivariate Stein factor bounds may be of independent interest. version:2
arxiv-1611-07941 | Multi-Modal Mean-Fields via Cardinality-Based Clamping | http://arxiv.org/abs/1611.07941 | id:1611.07941 author:Pierre Baqu√©, Fran√ßois Fleuret, Pascal Fua category:cs.CV cs.AI  published:2016-11-23 summary:Mean Field inference is central to statistical physics. It has attracted much interest in the Computer Vision community to efficiently solve problems expressible in terms of large Conditional Random Fields. However, since it models the posterior probability distribution as a product of marginal probabilities, it may fail to properly account for important dependencies between variables. We therefore replace the fully factorized distribution of Mean Field by a weighted mixture of such distributions, that similarly minimizes the KL-Divergence to the true posterior. By introducing two new ideas, namely, conditioning on groups of variables instead of single ones and using a parameter of the conditional random field potentials, that we identify to the temperature in the sense of statistical physics to select such groups, we can perform this minimization efficiently. Our extension of the clamping method proposed in previous works allows us to both produce a more descriptive approximation of the true posterior and, inspired by the diverse MAP paradigms, fit a mixture of Mean Field approximations. We demonstrate that this positively impacts real-world algorithms that initially relied on mean fields. version:1
arxiv-1611-07932 | Straight to Shapes: Real-time Detection of Encoded Shapes | http://arxiv.org/abs/1611.07932 | id:1611.07932 author:Saumya Jetley, Michael Sapienza, Stuart Golodetz, Philip H. S. Torr category:cs.CV  published:2016-11-23 summary:Current object detection approaches predict bounding boxes, but these provide little instance-specific information beyond location, scale and aspect ratio. In this work, we propose to directly regress to objects' shapes in addition to their bounding boxes and categories. It is crucial to find an appropriate shape representation that is compact and decodable, and in which objects can be compared for higher-order concepts such as view similarity, pose variation and occlusion. To achieve this, we use a denoising convolutional auto-encoder to establish an embedding space, and place the decoder after a fast end-to-end network trained to regress directly to the encoded shape vectors. This yields what to the best of our knowledge is the first real-time shape prediction network, running at ~35 FPS on a high-end desktop. With higher-order shape reasoning well-integrated into the network pipeline, the network shows the useful practical quality of generalising to unseen categories that are similar to the ones in the training set, something that most existing approaches fail to handle. version:1
arxiv-1611-08588 | PVANet: Lightweight Deep Neural Networks for Real-time Object Detection | http://arxiv.org/abs/1611.08588 | id:1611.08588 author:Sanghoon Hong, Byungseok Roh, Kye-Hyeon Kim, Yeongjae Cheon, Minje Park category:cs.CV  published:2016-11-23 summary:In object detection, reducing computational cost is as important as improving accuracy for most practical usages. This paper proposes a novel network structure, which is an order of magnitude lighter than other state-of-the-art networks while maintaining the accuracy. Based on the basic principle of more layers with less channels, this new deep neural network minimizes its redundancy by adopting recent innovations including C.ReLU and Inception structure. We also show that this network can be trained efficiently to achieve solid results on well-known object detection benchmarks: 84.9% and 84.2% mAP on VOC2007 and VOC2012 while the required compute is less than 10% of the recent ResNet-101. version:1
arxiv-1611-07897 | Unsupervised Learning of Sentence Representations using Convolutional Neural Networks | http://arxiv.org/abs/1611.07897 | id:1611.07897 author:Zhe Gan, Yunchen Pu, Ricardo Henao, Chunyuan Li, Xiaodong He, Lawrence Carin category:cs.CL cs.LG  published:2016-11-23 summary:We propose a new encoder-decoder approach to learn distributed sentence representations from unlabeled sentences. The word-to-vector representation is used, and convolutional neural networks are employed as sentence encoders, mapping an input sentence into a fixed-length vector. This representation is decoded using long short-term memory recurrent neural networks, considering several tasks, such as reconstructing the input sentence, or predicting the future sentence. We further describe a hierarchical encoder-decoder model to encode a sentence to predict multiple future sentences. By training our models on a large collection of novels, we obtain a highly generic convolutional sentence encoder that performs well in practice. Experimental results on several benchmark datasets, and across a broad range of applications, demonstrate the superiority of the proposed model over competing methods. version:1
arxiv-1611-07890 | Image-based Localization with Spatial LSTMs | http://arxiv.org/abs/1611.07890 | id:1611.07890 author:Florian Walch, Caner Hazirbas, Laura Leal-Taix√©, Torsten Sattler, Sebastian Hilsenbeck, Daniel Cremers category:cs.CV  published:2016-11-23 summary:In this work we propose a new CNN+LSTM architecture for camera pose regression for indoor and outdoor scenes. CNNs allow us to learn suitable feature representations for localization that are robust against motion blur and illumination changes. We make use of LSTM units on the CNN output in spatial coordinates in order to capture contextual information. This substantially enlarges the receptive field of each pixel leading to drastic improvements in localization performance. We provide extensive quantitative comparison of CNN-based vs SIFT-based localization methods, showing the weaknesses and strengths of each. Furthermore, we present a new large-scale indoor dataset with accurate ground truth from a laser scanner. Experimental results on both indoor and outdoor public datasets show our method outperforms existing deep architectures, and can localize images in hard conditions, e.g., in the presence of mostly textureless surfaces. version:1
arxiv-1611-07889 | The World of Fast Moving Objects | http://arxiv.org/abs/1611.07889 | id:1611.07889 author:Denys Rozumnyi, Jan Kotera, Filip Sroubek, Lukas Novotny, Jiri Matas category:cs.CV  published:2016-11-23 summary:The notion of a Fast Moving Object (FMO), i.e. an object that moves over a distance exceeding its size within the exposure time, is introduced. FMOs may, and typically do, rotate with high angular speed. FMOs are very common in sports videos, but are not rare elsewhere. In a single frame, such objects are often barely visible and appear as semi-transparent streaks. A method for the detection and tracking of FMOs is proposed. The method consists of three distinct algorithms, which form an efficient localization pipeline that operates successfully in a broad range of conditions. We show that it is possible to recover the appearance of the object and its axis of rotation, despite its blurred appearance. The proposed method is evaluated on a new annotated dataset. The results show that existing trackers are inadequate for the problem of FMO localization and a new approach is required. Two applications of localization, temporal super-resolution and highlighting, are presented. version:1
arxiv-1611-07873 | Piecewise Deterministic Markov Processes for Continuous-Time Monte Carlo | http://arxiv.org/abs/1611.07873 | id:1611.07873 author:Paul Fearnhead, Joris Bierkens, Murray Pollock, Gareth O Roberts category:stat.CO math.ST stat.ME stat.ML stat.TH  published:2016-11-23 summary:Recently there have been exciting developments in Monte Carlo methods, with the development of new MCMC and sequential Monte Carlo (SMC) algorithms which are based on continuous-time, rather than discrete-time, Markov processes. This has led to some fundamentally new Monte Carlo algorithms which can be used to sample from, say, a posterior distribution. Interestingly, continuous-time algorithms seem particularly well suited to Bayesian analysis in big-data settings as they need only access a small sub-set of data points at each iteration, and yet are still guaranteed to target the true posterior distribution. Whilst continuous-time MCMC and SMC methods have been developed independently we show here that they are related by the fact that both involve simulating a piecewise deterministic Markov process. Furthermore we show that the methods developed to date are just specific cases of a potentially much wider class of continuous-time Monte Carlo algorithms. We give an informal introduction to piecewise deterministic Markov processes, covering the aspects relevant to these new Monte Carlo algorithms, with a view to making the development of new continuous-time Monte Carlo more accessible. We focus on how and why sub-sampling ideas can be used with these algorithms, and aim to give insight into how these new algorithms can be implemented, and what are some of the issues that affect their efficiency. version:1
arxiv-1611-07865 | Controlling Perceptual Factors in Neural Style Transfer | http://arxiv.org/abs/1611.07865 | id:1611.07865 author:Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, Aaron Hertzmann, Eli Shechtman category:cs.CV  published:2016-11-23 summary:Neural Style Transfer has shown very exciting results enabling new forms of image manipulation. Here we extend the existing method beyond the paradigm of transferring global style information between pairs of images. In particular, we introduce control over spatial location, colour information and across spatial scale. We demonstrate how this enhances the method by allowing high-resolution controlled stylisation and helps to alleviate common failure cases such as applying ground textures to sky regions. Furthermore, by decomposing style into these perceptual factors we enable the combination of style information from multiple sources to generate new, perceptually appealing styles from existing ones. Finally we show how the introduced control measures can be applied in recent methods for Fast Neural Style Transfer. version:1
arxiv-1611-07850 | Robust Unsupervised Transient Detection With Invariant Representation based on the Scattering Network | http://arxiv.org/abs/1611.07850 | id:1611.07850 author:Randall Balestriero, Behnaam Aazhang category:stat.ML stat.AP  published:2016-11-23 summary:We present a sparse and invariant representation with low asymptotic complexity for robust unsupervised transient and onset zone detection in noisy environments. This unsupervised approach is based on wavelet transforms and leverages the scattering network from Mallat et al. by deriving frequency invariance. This frequency invariance is a key concept to enforce robust representations of transients in presence of possible frequency shifts and perturbations occurring in the original signal. Implementation details as well as complexity analysis are provided in addition of the theoretical framework and the invariance properties. In this work, our primary application consists of predicting the onset of seizure in epileptic patients from subdural recordings as well as detecting inter-ictal spikes. version:1
arxiv-1611-07837 | Adaptive Feature Abstraction for Translating Video to Language | http://arxiv.org/abs/1611.07837 | id:1611.07837 author:Yunchen Pu, Martin Renqiang Min, Zhe Gan, Lawrence Carin category:cs.CV cs.CL  published:2016-11-23 summary:A new model for video captioning is developed, using a deep three-dimensional Convolutional Neural Network (C3D) as an encoder for videos and a Recurrent Neural Network (RNN) as a decoder for captions. We consider both "hard" and "soft" attention mechanisms, to adaptively and sequentially focus on different layers of features (levels of feature "abstraction"), as well as local spatiotemporal regions of the feature maps at each layer. The proposed approach is evaluated on three benchmark datasets: YouTube2Text, M-VAD and MSR-VTT. Along with visualizing the results and how the model works, these experiments quantitatively demonstrate the effectiveness of the proposed adaptive spatiotemporal feature abstraction for translating videos to sentences with rich semantics. version:1
arxiv-1611-07828 | Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose | http://arxiv.org/abs/1611.07828 | id:1611.07828 author:Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, Kostas Daniilidis category:cs.CV  published:2016-11-23 summary:This paper addresses the challenge of 3D human pose estimation from a single color image. Despite the general success of the end-to-end learning paradigm, top performing approaches employ a two-step solution consisting of a Convolutional Network (ConvNet) for 2D joint localization only and recover 3D pose by a subsequent optimization step. In this paper, we identify the representation of 3D pose as a critical issue with current ConvNet approaches and make two important contributions towards validating the value of end-to-end learning for this task. First, we propose a fine discretization of the 3D space around the subject and train a ConvNet to predict per voxel likelihoods for each joint. This creates a natural representation for 3D pose and greatly improves performance over the direct regression of joint coordinates. Second, to further improve upon initial estimates, we employ a coarse-to-fine prediction scheme. This step addresses the large dimensionality increase and enables iterative refinement and repeated processing of the image features. The proposed approach allows us to train a ConvNet that outperforms all state-of-the-art approaches on standard benchmarks achieving relative error reduction greater than 35% on average. Additionally, we investigate using our volumetric representation in a related architecture which is suboptimal compared to our end-to-end approach, but is of practical interest, since it enables training when no image with corresponding 3D groundtruth is available, and allows us to present compelling results for in-the-wild images. version:1
arxiv-1611-07810 | A dataset and exploration of models for understanding video data through fill-in-the-blank question-answering | http://arxiv.org/abs/1611.07810 | id:1611.07810 author:Tegan Maharaj, Nicolas Ballas, Aaron Courville, Christopher Pal category:cs.CV  published:2016-11-23 summary:While deep convolutional neural networks frequently approach or exceed human-level performance at benchmark tasks involving static images, extending this success to moving images is not straightforward. Having models which can learn to understand video is of interest for many applications, including content recommendation, prediction, summarization, event/object detection and understanding human visual perception, but many domains lack sufficient data to explore and perfect video models. In order to address the need for a simple, quantitative benchmark for developing and understanding video, we present MovieFIB, a fill-in-the-blank question-answering dataset with over 300,000 examples, based on descriptive video annotations for the visually impaired. In addition to presenting statistics and a description of the dataset, we perform a detailed analysis of 5 different models' predictions, and compare these with human performance. We investigate the relative importance of language, static (2D) visual features, and moving (3D) visual features; the effects of increasing dataset size, the number of frames sampled; and of vocabulary size. We illustrate that: this task is not solvable by a language model alone; our model combining 2D and 3D visual information indeed provides the best result; all models perform significantly worse than human-level. We provide human evaluations for responses given by different models and find that accuracy on the MovieFIB evaluation corresponds well with human judgement. We suggest avenues for improving video models, and hope that the proposed dataset can be useful for measuring and encouraging progress in this very interesting field. version:1
arxiv-1611-07807 | Learning Invariant Representations Of Planar Curves | http://arxiv.org/abs/1611.07807 | id:1611.07807 author:Gautam Pai, Aaron Wetzler, Ron Kimmel category:cs.CV  published:2016-11-23 summary:We propose a metric learning framework for the construction of invariant geometric functions of planar curves for the Eucledian and Similarity group of transformations. We leverage on the representational power of convolutional neural networks to compute these geometric quantities. In comparison with axiomatic constructions, we show that the invariants approximated by the learning architectures have better numerical qualities such as robustness to noise, resiliency to sampling, as well as the ability to adapt to occlusion and partiality. Finally, we develop a novel multi-scale representation in a similarity metric learning paradigm. version:1
arxiv-1611-07804 | ATR4S: Toolkit with State-of-the-art Automatic Terms Recognition Methods in Scala | http://arxiv.org/abs/1611.07804 | id:1611.07804 author:N. Astrakhantsev category:cs.CL  published:2016-11-23 summary:Automatically recognized terminology is widely used for various domain-specific texts processing tasks, such as machine translation, information retrieval or sentiment analysis. However, there is still no agreement on which methods are best suited for particular settings and, moreover, there is no reliable comparison of already developed methods. We believe that one of the main reasons is the lack of state-of-the-art methods implementations, which are usually non-trivial to recreate. In order to address these issues, we present ATR4S, an open-source software written in Scala that comprises more than 15 methods for automatic terminology recognition (ATR) and implements the whole pipeline from text document preprocessing, to term candidates collection, term candidates scoring, and finally, term candidates ranking. It is highly scalable, modular and configurable tool with support of automatic caching. We also compare 10 state-of-the-art methods on 7 open datasets by average precision and processing time. Experimental comparison reveals that no single method demonstrates best average precision for all datasets and that other available tools for ATR do not contain the best methods. version:1
arxiv-1611-07791 | Object Detection using Image Processing | http://arxiv.org/abs/1611.07791 | id:1611.07791 author:Fares Jalled, Ilia Voronkov category:cs.CV  published:2016-11-23 summary:An Unmanned Ariel vehicle (UAV) has greater importance in the army for border security. The main objective of this article is to develop an OpenCV-Python code using Haar Cascade algorithm for object and face detection. Currently, UAVs are used for detecting and attacking the infiltrated ground targets. The main drawback for this type of UAVs is that sometimes the object are not properly detected, which thereby causes the object to hit the UAV. This project aims to avoid such unwanted collisions and damages of UAV. UAV is also used for surveillance that uses Voila-jones algorithm to detect and track humans. This algorithm uses cascade object detector function and vision. train function to train the algorithm. The main advantage of this code is the reduced processing time. The Python code was tested with the help of available database of video and image, the output was verified. version:1
arxiv-1611-07781 | Adaptive Down-Sampling and Dimension Reduction in Time Elastic Kernel Machines for Efficient Recognition of Isolated Gestures | http://arxiv.org/abs/1611.07781 | id:1611.07781 author:Pierre-Fran√ßois Marteau, Sylvie Gibet, Cl√©ment Reverdy category:cs.CV cs.LG  published:2016-11-23 summary:In the scope of gestural action recognition, the size of the feature vector representing movements is in general quite large especially when full body movements are considered. Furthermore, this feature vector evolves during the movement performance so that a complete movement is fully represented by a matrix M of size DxT , whose element M i, j represents the value of feature i at timestamps j. Many studies have addressed dimensionality reduction considering only the size of the feature vector lying in R D to reduce both the variability of gestural sequences expressed in the reduced space, and the computational complexity of their processing. In return, very few of these methods have explicitly addressed the dimensionality reduction along the time axis. Yet this is a major issue when considering the use of elastic distances which are characterized by a quadratic complexity along the time axis. We present in this paper an evaluation of straightforward approaches aiming at reducing the dimensionality of the matrix M for each movement, leading to consider both the dimensionality reduction of the feature vector as well as its reduction along the time axis. The dimensionality reduction of the feature vector is achieved by selecting remarkable joints in the skeleton performing the movement, basically the extremities of the articulatory chains composing the skeleton. The temporal dimen-sionality reduction is achieved using either a regular or adaptive down-sampling that seeks to minimize the reconstruction error of the movements. Elastic and Euclidean kernels are then compared through support vector machine learning. Two data sets 1 that are widely referenced in the domain of human gesture recognition, and quite distinctive in terms of quality of motion capture, are used for the experimental assessment of the proposed approaches. On these data sets we experimentally show that it is feasible, and possibly desirable, to significantly reduce simultaneously the size of the feature vector and the number of skeleton frames to represent body movements while maintaining a very good recognition rate. The method proves to give satisfactory results at a level currently reached by state-of-the-art methods on these data sets. We experimentally show that the computational complexity reduction that is obtained makes this approach eligible for real-time applications. version:1
arxiv-1611-07767 | Multiframe Motion Coupling via Infimal Convolution Regularization for Video Super Resolution | http://arxiv.org/abs/1611.07767 | id:1611.07767 author:Hendrik Dirks, Jonas Geiping, Daniel Cremers, Michael Moeller category:cs.CV math.OC I.4; G.1.6; G.4  published:2016-11-23 summary:The idea of video super resolution is to use the temporal information of seeing a scene from many slightly different viewpoints in the successive frames of a video to enhance the overall resolution and quality of each frame. Classical energy minimization approaches first establish a correspondence of the current video frame to several of its neighbors and then use this temporal information to enhance it. In this paper we propose the first variational super resolution approach that computes several super resolved frames in one joint optimization procedure by incorporating motion information between the high resolution image frames themselves. As a consequence, the number of motion estimation problems grows linearly in the number of frames, opposed to a quadratic growth of classical methods. In addition, we use infimal convolution regularization to automatically determine the reliability of the motion information and reweight the regularization locally. We demonstrate that our approach yields state-of-the-art results and even is competitive with learning based approaches that require a significant amount of training data. version:1
arxiv-1611-07759 | Multi-View 3D Object Detection Network for Autonomous Driving | http://arxiv.org/abs/1611.07759 | id:1611.07759 author:Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, Tian Xia category:cs.CV  published:2016-11-23 summary:This paper aims at high-accuracy 3D object detection in autonomous driving scenario. We propose Multi-View 3D networks (MV3D), a sensory-fusion framework that takes both LIDAR point cloud and RGB images as input and predicts oriented 3D bounding boxes. We encode the sparse 3D point cloud with a compact multi-view representation. The network is composed of two subnetworks: one for 3D object proposal generation and another for multi-view feature fusion. The proposal network generates 3D candidate boxes efficiently from the bird's eye view representation of 3D point cloud. We design a deep fusion scheme to combine region-wise features from multiple views and enable interactions between intermediate layers of different paths. Experiments on the challenging KITTI benchmark show that our approach outperforms the state-of-the-art by around 25% and 30% AP on the tasks of 3D localization and 3D detection. In addition, for 2D detection, our approach obtains 14.9% higher AP than the state-of-the-art on the hard data among the LIDAR-based methods. version:1
arxiv-1611-07752 | Convergence Analysis of MAP based Blur Kernel Estimation | http://arxiv.org/abs/1611.07752 | id:1611.07752 author:Sunghyun Cho, Seungyong Lee category:cs.CV  published:2016-11-23 summary:One popular approach for blind deconvolution is to formulate a maximum a posteriori (MAP) problem with sparsity priors on the gradients of the latent image, and then alternatingly estimate the blur kernel and the latent image. While several successful MAP based methods have been proposed, there has been much controversy and confusion about their convergence, because sparsity priors have been shown to prefer blurry images to sharp natural images. In this paper, we revisit this problem and provide an analysis on the convergence of MAP based approaches. We first introduce a slight modification to a conventional joint energy function for blind deconvolution. The reformulated energy function yields the same alternating estimation process, but more clearly reveals how blind deconvolution works. We then show the global optimum of the energy function can actually be the right solution instead of the no-blur solution under certain conditions, which explains the success of previous MAP based approaches. The reformulated energy function and our conditions for the convergence also provide a way to compare the qualities of different blur kernels, and we demonstrate its applicability to automatic blur kernel size selection, blur kernel estimation using light streaks, and defocus estimation. version:1
arxiv-1611-07743 | Tunable Sensitivity to Large Errors in Neural Network Training | http://arxiv.org/abs/1611.07743 | id:1611.07743 author:Gil Keren, Sivan Sabato, Bj√∂rn Schuller category:stat.ML cs.LG cs.NE  published:2016-11-23 summary:When humans learn a new concept, they might ignore examples that they cannot make sense of at first, and only later focus on such examples, when they are more useful for learning. We propose incorporating this idea of tunable sensitivity for hard examples in neural network learning, using a new generalization of the cross-entropy gradient step, which can be used in place of the gradient in any gradient-based training method. The generalized gradient is parameterized by a value that controls the sensitivity of the training process to harder training examples. We tested our method on several benchmark datasets. We propose, and corroborate in our experiments, that the optimal level of sensitivity to hard example is positively correlated with the depth of the network. Moreover, the test prediction error obtained by our method is generally lower than that of the vanilla cross-entropy gradient learner. We therefore conclude that tunable sensitivity can be helpful for neural network learning. version:1
arxiv-1611-07725 | iCaRL: Incremental Classifier and Representation Learning | http://arxiv.org/abs/1611.07725 | id:1611.07725 author:Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Christoph H. Lampert category:cs.CV cs.LG stat.ML  published:2016-11-23 summary:A major open problem on the road to artificial intelligence is the development of incrementally learning systems that learn about more and more concepts over time from a stream of data. In this work, we introduce a new training strategy, iCaRL, that allows learning in such a class-incremental way: only the training data for a small number of classes has to be present at the same time and new classes can be added progressively. iCaRL learns strong classifiers and a data representation simultaneously. This distinguishes it from earlier works that were fundamentally limited to fixed data representations and therefore incompatible with deep learning architectures. We show by experiments on the CIFAR-100 and ImageNet ILSVRC 2012 datasets that iCaRL can learn many classes incrementally over a long period of time where other strategies quickly fail. version:1
arxiv-1611-07718 | On the Connection of Deep Fusion to Ensembling | http://arxiv.org/abs/1611.07718 | id:1611.07718 author:Liming Zhao, Jingdong Wang, Xi Li, Zhuowen Tu, Wenjun Zeng category:cs.CV  published:2016-11-23 summary:In this paper, we provide a systematic study to the prevailing ResNet architecture by showing a connection from a general deeply-fused net view to ensembling. We start by empirically demonstrating the resemblance between the expanded form of the deeply-fused net and an ensemble of neural networks. Our empirical results uncover that the deepest network among the ensemble components does not contribute the most significantly to the overall performance and instead it provides a manner to introduce many layers and thus guarantee the ensemble size. Guided by the above study and observation, we develop a new deeply-fused network that combines two networks in a \emph{merge-and-run} fusion manner. It is less deep than a ResNet with the same number of parameters but yields an ensemble of the same number of more-capable component networks, thus improving the classification accuracy. We evaluate the proposed network on the standard recognition tasks. Our approach demonstrates consistent improvements over the ResNet with the comparable setup, and achieves the state-of-the-art results (e.g., $3.57\%$ testing error on CIFAR-$10$, $19.00\%$ on CIFAR-$100$, $1.51\%$ on SVHN). version:1
arxiv-1611-07715 | Deep Feature Flow for Video Recognition | http://arxiv.org/abs/1611.07715 | id:1611.07715 author:Xizhou Zhu, Yuwen Xiong, Jifeng Dai, Lu Yuan, Yichen Wei category:cs.CV  published:2016-11-23 summary:Deep convolutional neutral networks have achieved great success on image recognition tasks. Yet, it is non-trivial to transfer the state-of-the-art image recognition networks to videos as per-frame evaluation is too slow and unaffordable. We present deep feature flow, a fast and accurate framework for video recognition. It runs the expensive convolutional sub-network only on sparse key frames and propagates their deep feature maps to other frames via a flow field. It achieves significant speedup as flow computation is relatively fast. The end-to-end training of the whole architecture significantly boosts the recognition accuracy. Deep feature flow is flexible and general. It is validated on two recent large scale video datasets. It makes a large step towards practical video recognition. version:1
arxiv-1611-07710 | Spatio-Temporal Modeling of Check-ins in Location-Based Social Networks | http://arxiv.org/abs/1611.07710 | id:1611.07710 author:Ali Zarezade, Sina Jafarzadeh, Hamid R. Rabiee category:cs.SI stat.ML  published:2016-11-23 summary:Social networks are getting closer to our real physical world. People share the exact location and time of their check-ins and are influenced by their friends. Modeling the spatio-temporal behavior of users in social networks is of great importance for predicting the future behavior of users, controlling the users' movements, and finding the latent influence network. It is observed that users have periodic patterns in their movements. Also, they are influenced by the locations that their close friends recently visited. Leveraging these two observations, we propose a probabilistic model based on a doubly stochastic point process with a periodic decaying kernel for the time of check-ins and a time-varying multinomial distribution for the location of check-ins of users in the location-based social networks. We learn the model parameters by using an efficient EM algorithm, which distributes over the users. Experiments on synthetic and real data gathered from Foursquare show that the proposed inference algorithm learns the parameters efficiently and our method models the real data better than other alternatives. version:1
arxiv-1611-07709 | Fully Convolutional Instance-aware Semantic Segmentation | http://arxiv.org/abs/1611.07709 | id:1611.07709 author:Yi Li, Haozhi Qi, Jifeng Dai, Xiangyang Ji, Yichen Wei category:cs.CV  published:2016-11-23 summary:We present the first fully convolutional end-to-end solution for instance-aware semantic segmentation task. It inherits all the merits of FCNs for semantic segmentation and instance mask proposal. It performs instance mask prediction and classification jointly. The underlying convolutional representation is fully shared between the two sub-tasks, as well as between all regions of interest. The proposed network is highly integrated and achieves state-of-the-art performance in both accuracy and efficiency. It wins the COCO 2016 segmentation competition by a large margin. The code would be released at \url{https://github.com/daijifeng001/TA-FCN}. version:1
arxiv-1611-07700 | 3D Menagerie: Modeling the 3D shape and pose of animals | http://arxiv.org/abs/1611.07700 | id:1611.07700 author:Silvia Zuffi, Angjoo Kanazawa, David Jacobs, Michael J. Black category:cs.CV  published:2016-11-23 summary:There has been significant prior work on learning realistic, articulated, 3D statistical shape models of the human body. In contrast, there are few such models for animals, despite their many applications. The main challenge is that animals are much less cooperative subjects than humans. The best human body models are learned from thousands of 3D scans of people in specific poses, which is infeasible with live animals. Consequently, here we extend a state-of-the-art articulated 3D human body model to animals and learn it from a limited set of 3D scans of toy figurines in arbitrary poses. We employ a novel part-based shape model to compute an initial registration to the scans. We then normalize their pose, learn a statistical shape model, and refine the alignments and the model together. In this way, we accurately align animal scans from different quadruped families with very different shapes and poses. With the alignment to a common template we learn a shape space representing animals including lions, cats, dogs, horses, cows and hippos. Animal shapes can be sampled from the model, posed, animated, and fitted to data. In particular, we demonstrate the generalization of the model by fitting it to images of real animals, and show that it captures realistic animal shapes, even for new species not seen in training. We make our model available for research, enabling the extension of methods for human shape and pose estimation to animals. version:1
arxiv-1611-07688 | UniMiB SHAR: a new dataset for human activity recognition using acceleration data from smartphones | http://arxiv.org/abs/1611.07688 | id:1611.07688 author:Daniela Micucci, Marco Mobilio, Paolo Napoletano category:cs.CV  published:2016-11-23 summary:Smartphones, smartwatches, fitness trackers, and ad-hoc wearable devices are being increasingly used to monitor human activities. Usually, machine-learning-based algorithms process data acquired by their sensors to classify human activities. The success of those algorithms mostly depends on the availability of training (labeled) data. In this letter we present a new smartphone accelerometer dataset designed for activity recognition. The dataset includes 7,013 activities performed by 30 subjects, mostly females, of ages ranging from 18 to 60 years. Activities are divided in 17 fine grained classes grouped in two coarse grained classes: 9 types of activities of daily living (ADL) and 8 types of falls. The dataset, benchmarked with two different classifiers, thanks to its unique features will be of interest to the scientific community. version:1
arxiv-1612-00056 | Generalized Fourier-Bessel operator and almost-periodic interpolation and approximation | http://arxiv.org/abs/1612.00056 | id:1612.00056 author:Jean-Paul Gauthier, Dario Prandi category:math.NA cs.CV math.GR  published:2016-11-23 summary:We consider functions $f$ of two real variables, given as trigonometric functions over a finite set $F$ of frequencies. This set is assumed to be closed under rotations in the frequency plane of angle $\frac{2k\pi}{M}$ for some integer $M$. Firstly, we address the problem of evaluating these functions over a similar finite set $E$ in the space plane and, secondly, we address the problems of interpolating or approximating a function $g$ of two variables by such an $f$ over the grid $E.$ In particular, for this aim, we establish an abstract factorization theorem for the evaluation function, which is a key point for an efficient numerical solution to these problems. This result is based on the very special structure of the group $SE(2,N)$, subgroup of the group $SE(2)$ of motions of the plane corresponding to discrete rotations, which is a maximally almost periodic group. Although the motivation of this paper comes from our previous works on biomimetic image reconstruction and pattern recognition, where these questions appear naturally, this topic is related with several classical problems: the FFT in polar coordinates, the Non Uniform FFT, the evaluation of general trigonometric polynomials, and so on. version:1
arxiv-1611-07675 | Video Captioning with Transferred Semantic Attributes | http://arxiv.org/abs/1611.07675 | id:1611.07675 author:Yingwei Pan, Ting Yao, Houqiang Li, Tao Mei category:cs.CV  published:2016-11-23 summary:Automatically generating natural language descriptions of videos plays a fundamental challenge for computer vision community. Most recent progress in this problem has been achieved through employing 2-D and/or 3-D Convolutional Neural Networks (CNN) to encode video content and Recurrent Neural Networks (RNN) to decode a sentence. In this paper, we present Long Short-Term Memory with Transferred Semantic Attributes (LSTM-TSA)---a novel deep architecture that incorporates the transferred semantic attributes learnt from images and videos into the CNN plus RNN framework, by training them in an end-to-end manner. The design of LSTM-TSA is highly inspired by the facts that 1) semantic attributes play a significant contribution to captioning, and 2) images and videos carry complementary semantics and thus can reinforce each other for captioning. To boost video captioning, we propose a novel transfer unit to model the mutually correlated attributes learnt from images and videos. Extensive experiments are conducted on three public datasets, i.e., MSVD, M-VAD and MPII-MD. Our proposed LSTM-TSA achieves to-date the best published performance in sentence generation on MSVD: 52.8% and 74.0% in terms of BLEU@4 and CIDEr-D. Superior results when compared to state-of-the-art methods are also reported on M-VAD and MPII-MD. version:1
arxiv-1611-07663 | Learning Cost-Effective and Interpretable Regimes for Treatment Recommendation | http://arxiv.org/abs/1611.07663 | id:1611.07663 author:Himabindu Lakkaraju, Cynthia Rudin category:stat.ML  published:2016-11-23 summary:Decision makers, such as doctors and judges, make crucial decisions such as recommending treatments to patients, and granting bails to defendants on a daily basis. Such decisions typically involve weighting the potential benefits of taking an action against the costs involved. In this work, we aim to automate this task of learning {cost-effective, interpretable and actionable treatment regimes. We formulate this as a problem of learning a decision list -- a sequence of if-then-else rules -- which maps characteristics of subjects (eg., diagnostic test results of patients) to treatments. We propose a novel objective to construct a decision list which maximizes outcomes for the population, and minimizes overall costs. We model the problem of learning such a list as a Markov Decision Process (MDP) and employ a variant of the Upper Confidence Bound for Trees (UCT) strategy which leverages customized checks for pruning the search space effectively. Experimental results on real world observational data capturing treatment recommendations for asthma patients demonstrate the effectiveness of our approach. version:1
arxiv-1611-07661 | Neural Multigrid | http://arxiv.org/abs/1611.07661 | id:1611.07661 author:Tsung-Wei Ke, Michael Maire, Stella X. Yu category:cs.CV cs.LG cs.NE  published:2016-11-23 summary:We propose a multigrid extension of convolutional neural networks (CNNs). Rather than manipulating representations living on a single spatial grid, our network layers operate across scale space, on a pyramid of tensors. They consume multigrid inputs and produce multigrid outputs; convolutional filters themselves have both within-scale and cross-scale extent. This aspect is distinct from simple multiscale designs, which only process the input at different scales. Viewed in terms of information flow, a multigrid network passes messages across a spatial pyramid. As a consequence, receptive field size grows exponentially with depth, facilitating rapid integration of context. Most critically, multigrid structure enables networks to learn internal attention and dynamic routing mechanisms, and use them to accomplish tasks on which modern CNNs fail. Experiments demonstrate wide-ranging performance advantages of multigrid. On CIFAR image classification, flipping from single to multigrid within standard CNN architectures improves accuracy at modest compute and parameter increase. Multigrid is independent of other architectural choices; we show synergistic results in combination with residual connections. On tasks demanding per-pixel output, gains can be substantial. We show dramatic improvement on a synthetic semantic segmentation dataset. Strikingly, we show that relatively shallow multigrid networks can learn to directly perform spatial transformation tasks, where, in contrast, current CNNs fail. Together, our results suggest that continuous evolution of features on a multigrid pyramid could replace virtually all existing CNN designs. version:1
arxiv-1611-07659 | Improving Efficiency of SVM k-fold Cross-validation by Alpha Seeding | http://arxiv.org/abs/1611.07659 | id:1611.07659 author:Zeyi Wen, Bin Li, Rao Kotagiri, Jian Chen, Yawen Chen, Rui Zhang category:cs.LG  published:2016-11-23 summary:The k-fold cross-validation is commonly used to evaluate the effectiveness of SVMs with the selected hyper-parameters. It is known that the SVM k-fold cross-validation is expensive, since it requires training k SVMs. However, little work has explored reusing the h-th SVM for training the (h+1)-th SVM for improving the efficiency of k-fold cross-validation. In this paper, we propose three algorithms that reuse the h-th SVM for improving the efficiency of training the (h+1)-th SVM. Our key idea is to efficiently identify the support vectors and to accurately estimate their associated weights (also called alpha values) of the next SVM by using the previous SVM. Our experimental results show that our algorithms are several times faster than the k-fold cross-validation which does not make use of the previously trained SVM. Moreover, our algorithms produce the same results (hence same accuracy) as the k-fold cross-validation which does not make use of the previously trained SVM. version:1
arxiv-1611-07635 | T-CONV: A Convolutional Neural Network For Multi-scale Taxi Trajectory Prediction | http://arxiv.org/abs/1611.07635 | id:1611.07635 author:Jianming Lv, Qing Li, Xintong Wang category:cs.CV  published:2016-11-23 summary:Precise destination prediction of taxi trajectories can benefit efficient scheduling of taxies and accurate advertisement. Traditional prediction algorithms treat trajectories as sequences of spatial points and process them in one single predefined spatial scale. In this paper, we show that taxi trajectories can exhibit different patterns in different spatial scales, and the combination of multi-scale patterns can improve the accuracy of prediction. Based on this, we propose T-CONV to achieve higher accuracy, which models trajectories as images and adopts multi-layer convolutional neural networks to combine multi-scale trajectory patterns. Furthermore, in order to solve the sparsity problem of trajectories, we integrate multiple local convolutional fields in T-CONV to capture important specific areas of trajectories. Comprehensive experiments based on real trajectory data show that T-CONV can achieve much better results than state-of-the-art methods. version:1
arxiv-1611-07634 | Interpretation of Prediction Models Using the Input Gradient | http://arxiv.org/abs/1611.07634 | id:1611.07634 author:Yotam Hechtlinger category:stat.ML cs.LG  published:2016-11-23 summary:State of the art machine learning algorithms are highly optimized to provide the optimal prediction possible, naturally resulting in complex models. While these models often outperform simpler more interpretable models by order of magnitudes, in terms of understanding the way the model functions, we are often facing a "black box". In this paper we suggest a simple method to interpret the behavior of any predictive model, both for regression and classification. Given a particular model, the information required to interpret it can be obtained by studying the partial derivatives of the model with respect to the input. We exemplify this insight by interpreting convolutional and multi-layer neural networks in the field of natural language processing. version:1
arxiv-1611-07627 | SyGuS-Comp 2016: Results and Analysis | http://arxiv.org/abs/1611.07627 | id:1611.07627 author:Rajeev Alur, Dana Fisman, Rishabh Singh, Armando Solar-Lezama category:cs.SE cs.LG cs.LO  published:2016-11-23 summary:Syntax-Guided Synthesis (SyGuS) is the computational problem of finding an implementation f that meets both a semantic constraint given by a logical formula $\varphi$ in a background theory T, and a syntactic constraint given by a grammar G, which specifies the allowed set of candidate implementations. Such a synthesis problem can be formally defined in SyGuS-IF, a language that is built on top of SMT-LIB. The Syntax-Guided Synthesis Competition (SyGuS-Comp) is an effort to facilitate, bring together and accelerate research and development of efficient solvers for SyGuS by providing a platform for evaluating different synthesis techniques on a comprehensive set of benchmarks. In this year's competition we added a new track devoted to programming by examples. This track consisted of two categories, one using the theory of bit-vectors and one using the theory of strings. This paper presents and analyses the results of SyGuS-Comp'16. version:1
arxiv-1611-07609 | Adaptive Accelerated Gradient Converging Methods under Holderian Error Bound Condition | http://arxiv.org/abs/1611.07609 | id:1611.07609 author:Tianbao Yang category:math.OC stat.ML  published:2016-11-23 summary:In this paper, we focus our study on the convergence of (proximal) gradient methods and accelerated (proximal) gradient methods for smooth (composite) optimization under a H\"{o}lderian error bound (HEB) condition. We first show that proximal gradient (PG) method is automatically adaptive to HEB while accelerated proximal gradient (APG) method can be adaptive to HEB by restart with an improved iteration complexity. However, the number of iterations to restart APG hinges on a possibly unknown parameter. To address this issue, we propose to develop adaptive gradient converging methods, i.e., using the magnitude of gradient as a criterion for restart and termination. We develop adaptive accelerated gradient converging (adaAGC) methods for solving smooth (composite) optimization under the HEB condition with an explicit exponent $\theta$, and establish an better iteration complexity than PG. Furthermore, we demonstrate that these results have important implication and applications in machine learning: (i) if the considered objective function is coercive and semi-algebraic, PG's convergence speed is essentially $o(\frac{1}{t})$, where $t$ is the total number of iterations; (ii) if the objective function consists of an $\ell_1$, $\ell_\infty$, $\ell_{1,\infty}$, or huber norm regularization and a convex smooth piecewise quadratic loss, which includes least-squares loss, smoothed hinge loss and huber loss, the proposed adaAGC is parameter-free and enjoys a faster linear convergence than PG without any other assumptions (e.g., restricted eigen-value condition). It is notable that for all aforementioned problems, our linear convergence results are global instead of local. To the best of our knowledge, these improved results are the first shown in this work. version:1
arxiv-1611-06962 | Sampled Image Tagging and Retrieval Methods on User Generated Content | http://arxiv.org/abs/1611.06962 | id:1611.06962 author:Karl Ni, Kyle Zaragoza, Carmen Carrano, Barry Chen, Yonas Tesfaye, Alex Gude category:cs.CV  published:2016-11-21 summary:Traditional image tagging and retrieval algorithms have limited value as a result of being trained with heavily curated datasets. These limitations are most evident when arbitrary search words are used that do not intersect with training set labels. Weak labels from user generated content (UGC) found in the wild (e.g., Google Photos, FlickR, etc.) have an almost unlimited number of unique words in the metadata tags. Prior work on word embeddings successfully leveraged unstructured text with large vocabularies, and our proposed method seeks to apply similar cost functions to open source imagery. Specifically, we train a deep learning image tagging and retrieval system on large scale, user generated content (UGC) using sampling methods and joint optimization of word embeddings. By using the Yahoo! FlickR Creative Commons (YFCC100M) dataset, such an approach builds robustness to common unstructured data issues that include but are not limited to irrelevant tags, misspellings, multiple languages, polysemy, and tag imbalance. As a result, the final proposed algorithm will not only yield comparable results to state of the art in conventional image tagging, but will enable new capability to train algorithms on large, scale unstructured text in the YFCC100M dataset and outperform cited work in zero-shot capability. version:2
arxiv-1611-07596 | Fast Fourier Color Constancy | http://arxiv.org/abs/1611.07596 | id:1611.07596 author:Jonathan T. Barron, Yun-Ta Tsai category:cs.CV  published:2016-11-23 summary:We present Fast Fourier Color Constancy (FFCC), a color constancy algorithm which solves illuminant estimation by reducing it to a spatial localization task on a torus. By operating in the frequency domain, FFCC produces lower error rates than the previous state-of-the-art by 10-13% while being 250-3000 times faster. This unconventional approach introduces challenges regarding aliasing, directional statistics, and preconditioning, which we address. By producing a complete posterior distribution over illuminants instead of a single illuminant estimate, FFCC enables better training techniques, an effective temporal smoothing technique, and richer methods for error analysis. Our implementation of FFCC runs at ~700 frames per second on a mobile device, allowing it to be used as an accurate, real-time, temporally-coherent automatic white balance algorithm. version:1
arxiv-1611-07593 | Learning Joint Feature Adaptation for Zero-Shot Recognition | http://arxiv.org/abs/1611.07593 | id:1611.07593 author:Ziming Zhang, Venkatesh Saligrama category:cs.CV  published:2016-11-23 summary:Zero-shot recognition (ZSR) aims to recognize target-domain data instances of unseen classes based on the models learned from associated pairs of seen-class source and target domain data. One of the key challenges in ZSR is the relative scarcity of source-domain features (e.g. one feature vector per class), which do not fully account for wide variability in target-domain instances. In this paper we propose a novel framework of learning data-dependent feature transforms for scoring similarity between an arbitrary pair of source and target data instances to account for the wide variability in target domain. Our proposed approach is based on optimizing over a parameterized family of local feature displacements that maximize the source-target adaptive similarity functions. Accordingly we propose formulating zero-shot learning (ZSL) using latent structural SVMs to learn our similarity functions from training data. As demonstration we design a specific algorithm under the proposed framework involving bilinear similarity functions and regularized least squares as penalties for feature displacement. We test our approach on several benchmark datasets for ZSR and show significant improvement over the state-of-the-art. For instance, on aP&Y dataset we can achieve 80.89% in terms of recognition accuracy, outperforming the state-of-the-art by 11.15%. version:1
arxiv-1611-07579 | Programs as Black-Box Explanations | http://arxiv.org/abs/1611.07579 | id:1611.07579 author:Sameer Singh, Marco Tulio Ribeiro, Carlos Guestrin category:stat.ML cs.AI cs.LG  published:2016-11-22 summary:Recent work in model-agnostic explanations of black-box machine learning has demonstrated that interpretability of complex models does not have to come at the cost of accuracy or model flexibility. However, it is not clear what kind of explanations, such as linear models, decision trees, and rule lists, are the appropriate family to consider, and different tasks and models may benefit from different kinds of explanations. Instead of picking a single family of representations, in this work we propose to use "programs" as model-agnostic explanations. We show that small programs can be expressive yet intuitive as explanations, and generalize over a number of existing interpretable families. We propose a prototype program induction method based on simulated annealing that approximates the local behavior of black-box classifiers around a specific prediction using random perturbations. Finally, we present preliminary application on small datasets and show that the generated explanations are intuitive and accurate for a number of classifiers. version:1
arxiv-1611-07573 | Relaxed Earth Mover's Distances for Chain- and Tree-connected Spaces and their use as a Loss Function in Deep Learning | http://arxiv.org/abs/1611.07573 | id:1611.07573 author:Manuel Martinez, Monica Haurilet, Ziad Al-Halah, Makarand Tapaswi, Rainer Stiefelhagen category:cs.CV  published:2016-11-22 summary:The Earth Mover's Distance (EMD) computes the optimal cost of transforming one distribution into another, given a known transport metric between them. In deep learning, the EMD loss allows us to embed information during training about the output space structure like hierarchical or semantic relations. This helps in achieving better output smoothness and generalization. However EMD is computationally expensive.Moreover, solving EMD optimization problems usually require complex techniques like lasso. These properties limit the applicability of EMD-based approaches in large scale machine learning. We address in this work the difficulties facing incorporation of EMD-based loss in deep learning frameworks. Additionally, we provide insight and novel solutions on how to integrate such loss function in training deep neural networks. Specifically, we make three main contributions: (i) we provide an in-depth analysis of the fastest state-of-the-art EMD algorithm (Sinkhorn Distance) and discuss its limitations in deep learning scenarios. (ii) we derive fast and numerically stable closed-form solutions for the EMD gradient in output spaces with chain- and tree- connectivity; and (iii) we propose a relaxed form of the EMD gradient with equivalent computational complexity but faster convergence rate. We support our claims with experiments on real datasets. In a restricted data setting on the ImageNet dataset, we train a model to classify 1000 categories using 50K images, and demonstrate that our relaxed EMD loss achieves better Top-1 accuracy than the cross entropy loss. Overall, we show that our relaxed EMD loss criterion is a powerful asset for deep learning in the small data regime. version:1
arxiv-1611-07571 | Quad-networks: unsupervised learning to rank for interest point detection | http://arxiv.org/abs/1611.07571 | id:1611.07571 author:Nikolay Savinov, Akihito Seki, Lubor Ladicky, Torsten Sattler, Marc Pollefeys category:cs.CV cs.LG cs.NE  published:2016-11-22 summary:Several machine learning tasks require to represent the data using only a sparse set of interest points. An ideal detector is able to find the corresponding interest points even if the data undergo a transformation typical for a given domain. Since the task is of high practical interest in computer vision, many hand-crafted solutions were proposed. In this paper, we ask a fundamental question: can we learn such detectors from scratch? Since it is often unclear, what points are "interesting", human labelling cannot be used to find a truly unbiased solution. Therefore, the task requires an unsupervised formulation. We are the first to propose such a formulation: training a neural network to rank points in a transformation-invariant manner. Interest points are then extracted from the top/bottom quantiles of this ranking. We validate our approach on two tasks: standard RGB image interest point detection and challenging cross-modal interest point detection between RGB and depth images. We quantitatively show that our unsupervised method performs better or on-par with baselines. version:1
arxiv-1611-07567 | Feature Importance Measure for Non-linear Learning Algorithms | http://arxiv.org/abs/1611.07567 | id:1611.07567 author:Marina M. -C. Vidovic, Nico G√∂rnitz, Klaus-Robert M√ºller, Marius Kloft category:cs.AI cs.LG stat.ML  published:2016-11-22 summary:Complex problems may require sophisticated, non-linear learning methods such as kernel machines or deep neural networks to achieve state of the art prediction accuracies. However, high prediction accuracies are not the only objective to consider when solving problems using machine learning. Instead, particular scientific applications require some explanation of the learned prediction function. Unfortunately, most methods do not come with out of the box straight forward interpretation. Even linear prediction functions are not straight forward to explain if features exhibit complex correlation structure. In this paper, we propose the Measure of Feature Importance (MFI). MFI is general and can be applied to any arbitrary learning machine (including kernel machines and deep learning). MFI is intrinsically non-linear and can detect features that by itself are inconspicuous and only impact the prediction function through their interaction with other features. Lastly, MFI can be used for both --- model-based feature importance and instance-based feature importance (i.e, measuring the importance of a feature for a particular data point). version:1
arxiv-1611-07559 | Sar image despeckling based on nonlocal similarity sparse decomposition | http://arxiv.org/abs/1611.07559 | id:1611.07559 author:Chengwei Sang, Hong Sun, Quisong Xia category:cs.CV  published:2016-11-22 summary:This letter presents a method of synthetic aperture radar (SAR) image despeckling aimed to preserve the detail information while suppressing speckle noise. This method combines the nonlocal self-similarity partition and a proposed modified sparse decomposition. The nonlocal partition method groups a series of structure-similarity data sets. Each data set has a good sparsity for learning an over-complete dictionary in sparse representation. In the sparse decomposition, we propose a novel method to identify principal atoms from over-complete dictionary to form a principal dictionary. Despeckling is performed on each data set over the principal dictionary with principal atoms. Experimental results demonstrate that the proposed method can achieve high performances in terms of both speckle noise reduction and structure details preservation. version:1
arxiv-1611-07555 | Randomized Distributed Mean Estimation: Accuracy vs Communication | http://arxiv.org/abs/1611.07555 | id:1611.07555 author:Jakub Koneƒçn√Ω, Peter Richt√°rik category:cs.DC math.NA stat.ML  published:2016-11-22 summary:We consider the problem of estimating the arithmetic average of a finite collection of real vectors stored in a distributed fashion across several compute nodes subject to a communication budget constraint. Our analysis does not rely on any statistical assumptions about the source of the vectors. This problem arises as a subproblem in many applications, including reduce-all operations within algorithms for distributed and federated optimization and learning. We propose a flexible family of randomized algorithms exploring the trade-off between expected communication cost and estimation error. Our family contains the full-communication and zero-error method on one extreme, and an $\epsilon$-bit communication and ${\cal O}\left(1/(\epsilon n)\right)$ error method on the opposite extreme. In the special case where we communicate, in expectation, a single bit per coordinate of each vector, we improve upon existing results by obtaining $\mathcal{O}(r/n)$ error, where $r$ is the number of bits used to represent a floating point value. version:1
arxiv-1611-06459 | Gendered Conversation in a Social Game-Streaming Platform | http://arxiv.org/abs/1611.06459 | id:1611.06459 author:Supun Nakandala, Giovanni Luca Ciampaglia, Norman Makoto Su, Yong-Yeol Ahn category:cs.SI cs.CL cs.CY  published:2016-11-20 summary:Online social media and games are increasingly replacing offline social activities. Social media is now an indispensable mode of communication; online gaming is not only a genuine social activity but also a popular spectator sport. With support for anonymity and larger audiences, online interaction shrinks social and geographical barriers. Despite such benefits, social disparities such as gender inequality persist in online social media. In particular, online gaming communities have been criticized for persistent gender disparities and objectification. As gaming evolves into a social platform, persistence of gender disparity is a pressing question. Yet, there are few large-scale, systematic studies of gender inequality and objectification in social gaming platforms. Here we analyze more than one billion chat messages from Twitch, a social game-streaming platform, to study how the gender of streamers is associated with the nature of conversation. Using a combination of computational text analysis methods, we show that gendered conversation and objectification is prevalent in chats. Female streamers receive significantly more objectifying comments while male streamers receive more game-related comments. This difference is more pronounced for popular streamers. There also exists a large number of users who post only on female or male streams. Employing a neural vector-space embedding (paragraph vector) method, we analyze gendered chat messages and create prediction models that (i) identify the gender of streamers based on messages posted in the channel and (ii) identify the gender a viewer prefers to watch based on their chat messages. Our findings suggest that disparities in social game-streaming platforms is a nuanced phenomenon that involves the gender of streamers as well as those who produce gendered and game-related conversation. version:2
arxiv-1611-07544 | Self-learning Scene-specific Pedestrian Detectors using a Progressive Latent Model | http://arxiv.org/abs/1611.07544 | id:1611.07544 author:Qixiang Ye, Tianliang Zhang, Qiang Qiu, Baochang Zhang, Jie Chen, Guillermo Sapiro category:cs.CV  published:2016-11-22 summary:In this paper, a self-learning approach is proposed towards solving scene-specific pedestrian detection problem without any human' annotation involved. The self-learning approach is deployed as progressive steps of object discovery, object enforcement, and label propagation. In the learning procedure, object locations in each frame are treated as latent variables that are solved with a progressive latent model (PLM). Compared with conventional latent models, the proposed PLM incorporates a spatial regularization term to reduce ambiguities in object proposals and to enforce object localization, and also a graph-based label propagation to discover harder instances in adjacent frames. With the difference of convex (DC) objective functions, PLM can be efficiently optimized with a concave-convex programming and thus guaranteeing the stability of self-learning. Extensive experiments demonstrate that even without annotation the proposed self-learning approach outperforms weakly supervised learning approaches, while achieving comparable performance with transfer learning and fully supervised approaches. version:1
arxiv-1611-07509 | A causal framework for discovering and removing direct and indirect discrimination | http://arxiv.org/abs/1611.07509 | id:1611.07509 author:Lu Zhang, Yongkai Wu, Xintao Wu category:cs.LG  published:2016-11-22 summary:Anti-discrimination is an increasingly important task in data science. In this paper, we investigate the problem of discovering both direct and indirect discrimination from the historical data, and removing the discriminatory effects before the data is used for predictive analysis (e.g., building classifiers). We make use of the causal network to capture the causal structure of the data. Then we model direct and indirect discrimination as the path-specific effects, which explicitly distinguish the two types of discrimination as the causal effects transmitted along different paths in the network. Based on that, we propose an effective algorithm for discovering direct and indirect discrimination, as well as an algorithm for precisely removing both types of discrimination while retaining good data utility. Different from previous works, our approaches can ensure that the predictive models built from the modified data will not incur discrimination in decision making. Experiments using real datasets show the effectiveness of our approaches. version:1
arxiv-1611-07507 | Variational Intrinsic Control | http://arxiv.org/abs/1611.07507 | id:1611.07507 author:Karol Gregor, Danilo Jimenez Rezende, Daan Wierstra category:cs.LG cs.AI  published:2016-11-22 summary:In this paper we introduce a new unsupervised reinforcement learning method for discovering the set of intrinsic options available to an agent. This set is learned by maximizing the number of different states an agent can reliably reach, as measured by the mutual information between the set of options and option termination states. To this end, we instantiate two policy gradient based algorithms, one that creates an explicit embedding space of options and one that represents options implicitly. The algorithms also provide an explicit measure of empowerment in a given state that can be used by an empowerment maximizing agent. The algorithm scales well with function approximation and we demonstrate the applicability of the algorithm on a range of tasks. version:1
arxiv-1611-07492 | Inducing Interpretable Representations with Variational Autoencoders | http://arxiv.org/abs/1611.07492 | id:1611.07492 author:N. Siddharth, Brooks Paige, Alban Desmaison, Jan-Willem Van de Meent, Frank Wood, Noah D. Goodman, Pushmeet Kohli, Philip H. S. Torr category:stat.ML cs.CV cs.LG  published:2016-11-22 summary:We develop a framework for incorporating structured graphical models in the \emph{encoders} of variational autoencoders (VAEs) that allows us to induce interpretable representations through approximate variational inference. This allows us to both perform reasoning (e.g. classification) under the structural constraints of a given graphical model, and use deep generative models to deal with messy, high-dimensional domains where it is often difficult to model all the variation. Learning in this framework is carried out end-to-end with a variational objective, applying to both unsupervised and semi-supervised schemes. version:1
arxiv-1611-07490 | Can Co-robots Learn to Teach? | http://arxiv.org/abs/1611.07490 | id:1611.07490 author:Harshal Maske, Emily Kieson, Girish Chowdhary, Charles Abramson category:cs.RO cs.LG  published:2016-11-22 summary:We explore beyond existing work on learning from demonstration by asking the question: Can robots learn to teach?, that is, can a robot autonomously learn an instructional policy from expert demonstration and use it to instruct or collaborate with humans in executing complex tasks in uncertain environments? In this paper we pursue a solution to this problem by leveraging the idea that humans often implicitly decompose a higher level task into several subgoals whose execution brings the task closer to completion. We propose Dirichlet process based non-parametric Inverse Reinforcement Learning (DPMIRL) approach for reward based unsupervised clustering of task space into subgoals. This approach is shown to capture the latent subgoals that a human teacher would have utilized to train a novice. The notion of action primitive is introduced as the means to communicate instruction policy to humans in the least complicated manner, and as a computationally efficient tool to segment demonstration data. We evaluate our approach through experiments on hydraulic actuated scaled model of an excavator and evaluate and compare different teaching strategies utilized by the robot. version:1
arxiv-1611-07485 | Scene Labeling using Recurrent Neural Networks with Explicit Long Range Contextual Dependency | http://arxiv.org/abs/1611.07485 | id:1611.07485 author:Qiangui Huang, Weiyue Wang, Kevin Zhou, Suya You, Ulrich Neumann category:cs.CV  published:2016-11-22 summary:Spatial contextual dependencies are crucial for scene labeling problems. Recurrent neural network (RNN) is one of state-of-the-art methods for modeling contextual dependencies. However, RNNs are fundamentally designed for sequential data, not spatial data. This work shows that directly applying traditional RNN architectures, which unfold a 2D lattice grid into a sequence, is not sufficient to model structure dependencies in images due to the "impact vanishing" problem. A new RNN unit with Explicit Long-range Conditioning (RNN-ELC) is designed to overcome this problem. Based on this new RNN-ELC unit, a novel neural network architecture is built for scene labeling tasks. This architecture achieves state-of-the-art performances on several standard scene labeling datasets. Comprehensive experiments demonstrate that scene labeling tasks benefit a lot from the explicit long range contextual dependencies encoded in our algorithm. version:1
arxiv-1611-07476 | Singularity of the Hessian in Deep Learning | http://arxiv.org/abs/1611.07476 | id:1611.07476 author:Levent Sagun, Leon Bottou, Yann LeCun category:cs.LG  published:2016-11-22 summary:We look at the eigenvalues of the Hessian of a loss function before and after training. The eigenvalue distribution is seen to be composed of two parts, the bulk which is concentrated around zero, and the edges which are scattered away from zero. We present empirical evidence for the bulk indicating how over-parametrized the system is, and for the edges indicating the complexity of the input data. version:1
arxiv-1611-07460 | Poisson Random Fields for Dynamic Feature Models | http://arxiv.org/abs/1611.07460 | id:1611.07460 author:Valerio Perrone, Paul A. Jenkins, Dario Spano, Yee Whye Teh category:stat.ML  published:2016-11-22 summary:We present the Wright-Fisher Indian buffet process (WF-IBP), a probabilistic model for time-dependent data assumed to have been generated by an unknown number of latent features. This model is suitable as a prior in Bayesian nonparametric feature allocation models in which the features underlying the observed data exhibit a dependency structure over time. More specifically, we establish a new framework for generating dependent Indian buffet processes, where the Poisson random field model from population genetics is used as a way of constructing dependent beta processes. Inference in the model is complex, and we describe a sophisticated Markov Chain Monte Carlo algorithm for exact posterior simulation. We apply our construction to develop a nonparametric focused topic model for collections of time-stamped text documents and test it on the full corpus of NIPS papers published from 1987 to 2015. version:1
arxiv-1611-06284 | Understanding Anatomy Classification Through Visualization | http://arxiv.org/abs/1611.06284 | id:1611.06284 author:Devinder Kumar, Vlado Menkovski category:cs.CV  published:2016-11-19 summary:One of the main challenges for broad adoption of deep convolutional neural network (DCNN) models is the lack of understanding of their decision process. In many applications a simpler less capable model that can be easily understood is favorable to a black-box model that has superior performance. In this paper, we present an approach for designing DCNN models based on visualization of the internal activations of the model. We visualize the model's response using fractional stride convolution technique and compare the results with known imaging landmarks from the medical literature. We show that sufficiently deep and capable models can be successfully trained to use the same medical landmarks a human expert would use. The presented approach allows for communicating the model decision process well, but also offers insight towards detecting biases. version:2
arxiv-1611-07450 | Grad-CAM: Why did you say that? | http://arxiv.org/abs/1611.07450 | id:1611.07450 author:Ramprasaath R Selvaraju, Abhishek Das, Ramakrishna Vedantam, Michael Cogswell, Devi Parikh, Dhruv Batra category:stat.ML cs.CV cs.LG  published:2016-11-22 summary:We propose a technique for making Convolutional Neural Network (CNN)-based models more transparent by visualizing input regions that are 'important' for predictions -- or visual explanations. Our approach, called Gradient-weighted Class Activation Mapping (Grad-CAM), uses class-specific gradient information to localize important regions. These localizations are combined with existing pixel-space visualizations to create a novel high-resolution and class-discriminative visualization called Guided Grad-CAM. These methods help better understand CNN-based models, including image captioning and visual question answering (VQA) models. We evaluate our visual explanations by measuring their ability to discriminate between classes, to inspire trust in humans, and their correlation with occlusion maps. Grad-CAM provides a new way to understand CNN-based models. We have released code, an online demo hosted on CloudCV, and a full version of this extended abstract. version:1
arxiv-1611-07443 | Mapping chemical performance on molecular structures using locally interpretable explanations | http://arxiv.org/abs/1611.07443 | id:1611.07443 author:Leanne S. Whitmore, Anthe George, Corey M. Hudson category:stat.ML physics.chem-ph  published:2016-11-22 summary:In this work, we present an application of Locally Interpretable Machine-Agnostic Explanations to 2-D chemical structures. Using this framework we are able to provide a structural interpretation for an existing black-box model for classifying biologically produced fuel compounds with regard to Research Octane Number. This method of "painting" locally interpretable explanations onto 2-D chemical structures replicates the chemical intuition of synthetic chemists, allowing researchers in the field to directly accept, reject, inform and evaluate decisions underlying inscrutably complex quantitative structure-activity relationship models. version:1
arxiv-1611-07438 | Achieving non-discrimination in data release | http://arxiv.org/abs/1611.07438 | id:1611.07438 author:Lu Zhang, Yongkai Wu, Xintao Wu category:cs.LG  published:2016-11-22 summary:Discrimination discovery and prevention/removal are increasingly important tasks in data mining. Discrimination discovery aims to unveil discriminatory practices on the protected attribute (e.g., gender) by analyzing the dataset of historical decision records, and discrimination prevention aims to remove discrimination by modifying the biased data before conducting predictive analysis. In this paper, we show that the key to discrimination discovery and prevention is to find the meaningful partitions that can be used to provide quantitative evidences for the judgment of discrimination. With the support of the causal graph, we present a graphical condition for identifying a meaningful partition. Based on that, we develop a simple criterion for the claim of non-discrimination, and propose discrimination removal algorithms which accurately remove discrimination while retaining good data utility. Experiments using real datasets show the effectiveness of our approaches. version:1
arxiv-1611-07429 | TreeView: Peeking into Deep Neural Networks Via Feature-Space Partitioning | http://arxiv.org/abs/1611.07429 | id:1611.07429 author:Jayaraman J. Thiagarajan, Bhavya Kailkhura, Prasanna Sattigeri, Karthikeyan Natesan Ramamurthy category:stat.ML cs.LG  published:2016-11-22 summary:With the advent of highly predictive but opaque deep learning models, it has become more important than ever to understand and explain the predictions of such models. Existing approaches define interpretability as the inverse of complexity and achieve interpretability at the cost of accuracy. This introduces a risk of producing interpretable but misleading explanations. As humans, we are prone to engage in this kind of behavior \cite{mythos}. In this paper, we take a step in the direction of tackling the problem of interpretability without compromising the model accuracy. We propose to build a Treeview representation of the complex model via hierarchical partitioning of the feature space, which reveals the iterative rejection of unlikely class labels until the correct association is predicted. version:1
arxiv-1611-07390 | 3D Image Reconstruction from X-Ray Measurements with Overlap | http://arxiv.org/abs/1611.07390 | id:1611.07390 author:Maria Klodt, Raphael Hauser category:physics.med-ph cs.CV  published:2016-11-22 summary:3D image reconstruction from a set of X-ray projections is an important image reconstruction problem, with applications in medical imaging, industrial inspection and airport security. The innovation of X-ray emitter arrays allows for a novel type of X-ray scanners with multiple simultaneously emitting sources. However, two or more sources emitting at the same time can yield measurements from overlapping rays, imposing a new type of image reconstruction problem based on nonlinear constraints. Using traditional linear reconstruction methods, respective scanner geometries have to be implemented such that no rays overlap, which severely restricts the scanner design. We derive a new type of 3D image reconstruction model with nonlinear constraints, based on measurements with overlapping X-rays. Further, we show that the arising optimization problem is partially convex, and present an algorithm to solve it. Experiments show highly improved image reconstruction results from both simulated and real-world measurements. version:1
arxiv-1611-07385 | Smart Library: Identifying Books in a Library using Richly Supervised Deep Scene Text Reading | http://arxiv.org/abs/1611.07385 | id:1611.07385 author:Xiao Yang, Dafang He, Wenyi Huang, Zihan Zhou, Alex Ororbia, Dan Kifer, C. Lee Giles category:cs.CV  published:2016-11-22 summary:Physical library collections are valuable and long standing resources for knowledge and learning. However, managing books in a large bookshelf and finding books on it often leads to tedious manual work, especially for large book collections where books might be missing or misplaced. Recently, deep neural models, such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) have achieved great success for scene text detection and recognition. Motivated by these recent successes, we aim to investigate their viability in facilitating book management, a task that introduces further challenges including large amounts of cluttered scene text, distortion, and varied lighting conditions. In this paper, we present a library inventory building and retrieval system based on scene text reading methods. We specifically design our scene text recognition model using rich supervision to accelerate training and achieve state-of-the-art performance on several benchmark datasets. Our proposed system has the potential to greatly reduce the amount of human labor required in managing book inventories as well as the space needed to store book information. version:1
arxiv-1612-00369 | New Ideas for Brain Modelling 3 | http://arxiv.org/abs/1612.00369 | id:1612.00369 author:Kieran Greer category:cs.NE  published:2016-11-22 summary:This paper considers a process for the creation and subsequent firing of sequences of neuronal patterns, as might be found in the human brain. The scale is one of larger patterns emerging from an ensemble mass, possibly through some type of energy equation and a reduction procedure. The links between the patterns can be formed naturally, as a residual effect of the pattern creation itself. If the process is valid, then the pattern creation can be relatively simplistic and automatic, where the neuron does not have to do anything particularly intelligent. The pattern interfaces become slightly abstract without firm boundaries and exact structure is determined more by averages or ratios. This paper follows-on closely from the earlier research, including two earlier papers in the series and uses the ideas of entropy and cohesion. With a small addition, it is possible to show how the inter-pattern links can be determined. A new compact grid form of an earlier Counting Mechanism is also demonstrated. version:1
arxiv-1611-09122 | Statistical Properties of European Languages and Voynich Manuscript Analysis | http://arxiv.org/abs/1611.09122 | id:1611.09122 author:Andronik Arutyunov, Leonid Borisov, Sergey Fedorov, Anastasiya Ivchenko, Elizabeth Kirina-Lilinskaya, Yurii Orlov, Konstantin Osminin, Sergey Shilin, Dmitriy Zeniuk category:stat.AP cs.CL  published:2016-11-18 summary:The statistical properties of letters frequencies in European literature texts are investigated. The determination of logarithmic dependence of letters sequence for one-language and two-language texts are examined. The pare of languages is suggested for Voynich Manuscript. The internal structure of Manuscript is considered. The spectral portraits of two-letters distribution are constructed. version:1
