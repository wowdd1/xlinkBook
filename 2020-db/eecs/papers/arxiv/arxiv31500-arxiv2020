arxiv-1607-00291 | High-Performance Tensor Contraction without Transposition | http://arxiv.org/abs/1607.00291 | id:1607.00291 author:Devin A. Matthews category:cs.MS cs.DC cs.PF 15A69 G.4  published:2016-07-01 summary:Tensor computations--in particular tensor contraction (TC)--are important kernels in many scientific computing applications. Due to the fundamental similarity of TC to matrix multiplication (MM) and to the availability of optimized implementations such as the BLAS, tensor operations have traditionally been implemented in terms of BLAS operations, incurring both a performance and a storage overhead. Instead, we implement TC using the flexible BLIS framework, which allows for transposition (reshaping) of the tensor to be fused with internal partitioning and packing operations, requiring no explicit transposition operations or additional workspace. This implementation, TBLIS, achieves performance approaching that of MM, and in some cases considerably higher than that of traditional TC. Our implementation supports multithreading using an approach identical to that used for MM in BLIS, with similar performance characteristics. The complexity of managing tensor-to-matrix transformations is also handled automatically in our approach, greatly simplifying its use in scientific applications. version:4
arxiv-1707-03300 | The Intentional Unintentional Agent: Learning to Solve Many Continuous Control Tasks Simultaneously | http://arxiv.org/abs/1707.03300 | id:1707.03300 author:Serkan Cabi, Sergio GÃ³mez Colmenarejo, Matthew W. Hoffman, Misha Denil, Ziyu Wang, Nando de Freitas category:cs.AI  published:2017-07-11 summary:This paper introduces the Intentional Unintentional (IU) agent. This agent endows the deep deterministic policy gradients (DDPG) agent for continuous control with the ability to solve several tasks simultaneously. Learning to solve many tasks simultaneously has been a long-standing, core goal of artificial intelligence, inspired by infant development and motivated by the desire to build flexible robot manipulators capable of many diverse behaviours. We show that the IU agent not only learns to solve many tasks simultaneously but it also learns faster than agents that target a single task at-a-time. In some cases, where the single task DDPG method completely fails, the IU agent successfully solves the task. To demonstrate this, we build a playroom environment using the MuJoCo physics engine, and introduce a grounded formal language to automatically generate tasks. version:1
arxiv-1704-06131 | Learning to Acquire Information | http://arxiv.org/abs/1704.06131 | id:1704.06131 author:Yewen Pu, Leslie P Kaelbling, Armando Solar-Lezama category:cs.AI cs.LG stat.ML  published:2017-04-20 summary:We consider the problem of diagnosis where a set of simple observations are used to infer a potentially complex hidden hypothesis. Finding the optimal subset of observations is intractable in general, thus we focus on the problem of active diagnosis, where the agent selects the next most-informative observation based on the results of previous observations. We show that under the assumption of uniform observation entropy, one can build an implication model which directly predicts the outcome of the potential next observation conditioned on the results of past observations, and selects the observation with the maximum entropy. This approach enjoys reduced computation complexity by bypassing the complicated hypothesis space, and can be trained on observation data alone, learning how to query without knowledge of the hidden hypothesis. version:2
arxiv-1707-03232 | Deductive and Analogical Reasoning on a Semantically Embedded Knowledge Graph | http://arxiv.org/abs/1707.03232 | id:1707.03232 author:Douglas Summers-Stay category:cs.AI  published:2017-07-11 summary:Representing knowledge as high-dimensional vectors in a continuous semantic vector space can help overcome the brittleness and incompleteness of traditional knowledge bases. We present a method for performing deductive reasoning directly in such a vector space, combining analogy, association, and deduction in a straightforward way at each step in a chain of reasoning, drawing on knowledge from diverse sources and ontologies. version:1
arxiv-1707-03198 | The swiss army knife of job submission tools: grid-control | http://arxiv.org/abs/1707.03198 | id:1707.03198 author:F. Stober, M. Fischer, P. Schleper, H. Stadie, C. Garbers, J. Lange, N. Kovalchuk category:cs.DC hep-ex  published:2017-07-11 summary:Grid-control is a lightweight and highly portable open source submission tool that supports virtually all workflows in high energy physics (HEP). Since 2007 it has been used by a sizeable number of HEP analyses to process tasks that sometimes consist of up 100k jobs. grid-control is built around a powerful plugin and configuration system, that allows users to easily specify all aspects of the desired workflow. Job submission to a wide range of local or remote batch systems or grid middleware is supported. Tasks can be conveniently specified through the parameter space that will be processed, which can consist of any number of variables and data sources with complex dependencies on each other. Dataset information is processed through a configurable pipeline of dataset filters, partition plugins and partition filters. The partition plugins can take the number of files, size of the work units, metadata or combinations thereof into account. All changes to the input datasets or variables are propagated through the processing pipeline and can transparently trigger adjustments to the parameter space and the job submission. While the core functionality is completely experiment independent, integration with the CMS computing environment is provided by a small set of plugins. version:1
arxiv-1707-03191 | Towards an automated method based on Iterated Local Search optimization for tuning the parameters of Support Vector Machines | http://arxiv.org/abs/1707.03191 | id:1707.03191 author:Sergio Consoli, Jacek Kustra, Pieter Vos, Monique Hendriks, Dimitrios Mavroeidis category:cs.AI cs.LG  published:2017-07-11 summary:We provide preliminary details and formulation of an optimization strategy under current development that is able to automatically tune the parameters of a Support Vector Machine over new datasets. The optimization strategy is a heuristic based on Iterated Local Search, a modification of classic hill climbing which iterates calls to a local search routine. version:1
arxiv-1707-03184 | A Survey on Resilient Machine Learning | http://arxiv.org/abs/1707.03184 | id:1707.03184 author:Atul Kumar, Sameep Mehta category:cs.AI cs.CR cs.LG  published:2017-07-11 summary:Machine learning based system are increasingly being used for sensitive tasks such as security surveillance, guiding autonomous vehicle, taking investment decisions, detecting and blocking network intrusion and malware etc. However, recent research has shown that machine learning models are venerable to attacks by adversaries at all phases of machine learning (eg, training data collection, training, operation). All model classes of machine learning systems can be misled by providing carefully crafted inputs making them wrongly classify inputs. Maliciously created input samples can affect the learning process of a ML system by either slowing down the learning process, or affecting the performance of the learned mode, or causing the system make error(s) only in attacker's planned scenario. Because of these developments, understanding security of machine learning algorithms and systems is emerging as an important research area among computer security and machine learning researchers and practitioners. We present a survey of this emerging area in machine learning. version:1
arxiv-1707-03167 | RegNet: Multimodal Sensor Registration Using Deep Neural Networks | http://arxiv.org/abs/1707.03167 | id:1707.03167 author:Nick Schneider, Florian Piewak, Christoph Stiller, Uwe Franke category:cs.CV cs.AI cs.LG cs.RO  published:2017-07-11 summary:In this paper, we present RegNet, the first deep convolutional neural network (CNN) to infer a 6 degrees of freedom (DOF) extrinsic calibration between multimodal sensors, exemplified using a scanning LiDAR and a monocular camera. Compared to existing approaches, RegNet casts all three conventional calibration steps (feature extraction, feature matching and global regression) into a single real-time capable CNN. Our method does not require any human interaction and bridges the gap between classical offline and target-less online calibration approaches as it provides both a stable initial estimation as well as a continuous online correction of the extrinsic parameters. During training we randomly decalibrate our system in order to train RegNet to infer the correspondence between projected depth measurements and RGB image and finally regress the extrinsic calibration. Additionally, with an iterative execution of multiple CNNs, that are trained on different magnitudes of decalibration, our approach compares favorably to state-of-the-art methods in terms of a mean calibration error of 0.28 degrees for the rotational and 6 cm for the translation components even for large decalibrations up to 1.5 m and 20 degrees. version:1
arxiv-1707-03141 | Meta-Learning with Temporal Convolutions | http://arxiv.org/abs/1707.03141 | id:1707.03141 author:Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, Pieter Abbeel category:cs.AI cs.LG cs.NE stat.ML  published:2017-07-11 summary:Deep neural networks excel in regimes with large amounts of data, but tend to struggle when data is scarce or when they need to adapt quickly to changes in the task. Recent work in meta-learning seeks to overcome this shortcoming by training a meta-learner on a distribution of similar tasks; the goal is for the meta-learner to generalize to novel but related tasks by learning a high-level strategy that captures the essence of the problem it is asked to solve. However, most recent approaches to meta-learning are extensively hand-designed, either using architectures that are specialized to a particular application, or hard-coding algorithmic components that tell the meta-learner how to solve the task. We propose a class of simple and generic meta-learner architectures, based on temporal convolutions, that is domain- agnostic and has no particular strategy or algorithm encoded into it. We validate our temporal-convolution-based meta-learner (TCML) through experiments pertaining to both supervised and reinforcement learning, and demonstrate that it outperforms state-of-the-art methods that are less general and more complex. version:1
arxiv-1704-07575 | Sharing deep generative representation for perceived image reconstruction from human brain activity | http://arxiv.org/abs/1704.07575 | id:1704.07575 author:Changde Du, Changying Du, Huiguang He category:cs.AI cs.CV q-bio.NC  published:2017-04-25 summary:Decoding human brain activities via functional magnetic resonance imaging (fMRI) has gained increasing attention in recent years. While encouraging results have been reported in brain states classification tasks, reconstructing the details of human visual experience still remains difficult. Two main challenges that hinder the development of effective models are the perplexing fMRI measurement noise and the high dimensionality of limited data instances. Existing methods generally suffer from one or both of these issues and yield dissatisfactory results. In this paper, we tackle this problem by casting the reconstruction of visual stimulus as the Bayesian inference of missing view in a multiview latent variable model. Sharing a common latent representation, our joint generative model of external stimulus and brain response is not only "deep" in extracting nonlinear features from visual images, but also powerful in capturing correlations among voxel activities of fMRI recordings. The nonlinearity and deep structure endow our model with strong representation ability, while the correlations of voxel activities are critical for suppressing noise and improving prediction. We devise an efficient variational Bayesian method to infer the latent variables and the model parameters. To further improve the reconstruction accuracy, the latent representations of testing instances are enforced to be close to that of their neighbours from the training set via posterior regularization. Experiments on three fMRI recording datasets demonstrate that our approach can more accurately reconstruct visual stimuli. version:3
arxiv-1707-03098 | An Optimal Bayesian Network Based Solution Scheme for the Constrained Stochastic On-line Equi-Partitioning Problem | http://arxiv.org/abs/1707.03098 | id:1707.03098 author:Sondre Glimsdal, Ole-Christoffer Granmo category:cs.AI  published:2017-07-11 summary:A number of intriguing decision scenarios revolve around partitioning a collection of objects to optimize some application specific objective function. This problem is generally referred to as the Object Partitioning Problem (OPP) and is known to be NP-hard. We here consider a particularly challenging version of OPP, namely, the Stochastic On-line Equi-Partitioning Problem (SO-EPP). In SO-EPP, the target partitioning is unknown and has to be inferred purely from observing an on-line sequence of object pairs. The paired objects belong to the same partition with probability $p$ and to different partitions with probability $1-p$, with $p$ also being unknown. As an additional complication, the partitions are required to be of equal cardinality. Previously, only sub-optimal solution strategies have been proposed for SO- EPP. In this paper, we propose the first optimal solution strategy. In brief, the scheme that we propose, BN-EPP, is founded on a Bayesian network representation of SO-EPP problems. Based on probabilistic reasoning, we are not only able to infer the underlying object partitioning with optimal accuracy. We are also able to simultaneously infer $p$, allowing us to accelerate learning as object pairs arrive. Furthermore, our scheme is the first to support arbitrary constraints on the partitioning (Constrained SO-EPP). Being optimal, BN-EPP provides superior performance compared to existing solution schemes. We additionally introduce Walk-BN-EPP, a novel WalkSAT inspired algorithm for solving large scale BN-EPP problems. Finally, we provide a BN-EPP based solution to the problem of order picking, a representative real-life application of BN-EPP. version:1
arxiv-1707-03092 | A Separation-Based Design to Data-Driven Control for Large-Scale Partially Observed Systems | http://arxiv.org/abs/1707.03092 | id:1707.03092 author:Dan Yu, Mohammadhussein Rafieisakhaei, Suman Chakravorty category:cs.SY cs.LG cs.RO  published:2017-07-11 summary:This paper studies the partially observed stochastic optimal control problem for systems with state dynamics governed by Partial Differential Equations (PDEs) that leads to an extremely large problem. First, an open-loop deterministic trajectory optimization problem is solved using a black box simulation model of the dynamical system. Next, a Linear Quadratic Gaussian (LQG) controller is designed for the nominal trajectory-dependent linearized system, which is identified using input-output experimental data consisting of the impulse responses of the optimized nominal system. A computational nonlinear heat example is used to illustrate the performance of the approach. version:1
arxiv-1707-03080 | Robot Autonomy for Surgery | http://arxiv.org/abs/1707.03080 | id:1707.03080 author:Michael Yip, Nikhil Das category:cs.RO  published:2017-07-10 summary:Autonomous surgery involves having surgical tasks performed by a robot operating under its own will, with partial or no human involvement. There are several important advantages of automation in surgery, which include increasing precision of care due to sub-millimeter robot control, real-time utilization of biosignals for interventional care, improvements to surgical efficiency and execution, and computer-aided guidance under various medical imaging and sensing modalities. While these methods may displace some tasks of surgical teams and individual surgeons, they also present new capabilities in interventions that are too difficult or go beyond the skills of a human. In this chapter, we provide an overview of robot autonomy in commercial use and in research, and present some of the challenges faced in developing autonomous surgical robots. version:1
arxiv-1707-03069 | Lexicographic choice functions | http://arxiv.org/abs/1707.03069 | id:1707.03069 author:Arthur Van Camp, Gert de Cooman, Enrique Miranda category:cs.AI  published:2017-07-10 summary:We investigate a generalisation of the coherent choice functions considered by Seidenfeld et al. (2010), by sticking to the convexity axiom but imposing no Archimedeanity condition. We define our choice functions on vector spaces of options, which allows us to incorporate as special cases both Seidenfeld et al.'s (2010) choice functions on horse lotteries and sets of desirable gambles (Quaeghebeur, 2014), and to investigate their connections. We show that choice functions based on sets of desirable options (gambles) satisfy Seidenfeld's convexity axiom only for very particular types of sets of desirable options, which are in a one-to-one relationship with the lexicographic probabilities. We call them lexicographic choice functions. Finally, we prove that these choice functions can be used to determine the most conservative convex choice function associated with a given binary relation. version:1
arxiv-1707-03034 | Learning Heuristic Search via Imitation | http://arxiv.org/abs/1707.03034 | id:1707.03034 author:Mohak Bhardwaj, Sanjiban Choudhury, Sebastian Scherer category:cs.RO cs.AI cs.LG  published:2017-07-10 summary:Robotic motion planning problems are typically solved by constructing a search tree of valid maneuvers from a start to a goal configuration. Limited onboard computation and real-time planning constraints impose a limit on how large this search tree can grow. Heuristics play a crucial role in such situations by guiding the search towards potentially good directions and consequently minimizing search effort. Moreover, it must infer such directions in an efficient manner using only the information uncovered by the search up until that time. However, state of the art methods do not address the problem of computing a heuristic that explicitly minimizes search effort. In this paper, we do so by training a heuristic policy that maps the partial information from the search to decide which node of the search tree to expand. Unfortunately, naively training such policies leads to slow convergence and poor local minima. We present SaIL, an efficient algorithm that trains heuristic policies by imitating "clairvoyant oracles" - oracles that have full information about the world and demonstrate decisions that minimize search effort. We leverage the fact that such oracles can be efficiently computed using dynamic programming and derive performance guarantees for the learnt heuristic. We validate the approach on a spectrum of environments which show that SaIL consistently outperforms state of the art algorithms. Our approach paves the way forward for learning heuristics that demonstrate an anytime nature - finding feasible solutions quickly and incrementally refining it over time. version:1
arxiv-1612-00916 | A Matrix Splitting Perspective on Planning with Options | http://arxiv.org/abs/1612.00916 | id:1612.00916 author:Pierre-Luc Bacon, Doina Precup category:cs.AI  published:2016-12-03 summary:We show that the Bellman operator underlying the options framework leads to a matrix splitting, an approach traditionally used to speed up convergence of iterative solvers for large linear systems of equations. Based on standard comparison theorems for matrix splittings, we then show how the asymptotic rate of convergence varies as a function of the inherent timescales of the options. This new perspective highlights a trade-off between asymptotic performance and the cost of computation associated with building a good set of options. version:2
arxiv-1707-02286 | Emergence of Locomotion Behaviours in Rich Environments | http://arxiv.org/abs/1707.02286 | id:1707.02286 author:Nicolas Heess, Dhruva TB, Srinivasan Sriram, Jay Lemmon, Josh Merel, Greg Wayne, Yuval Tassa, Tom Erez, Ziyu Wang, S. M. Ali Eslami, Martin Riedmiller, David Silver category:cs.AI  published:2017-07-07 summary:The reinforcement learning paradigm allows, in principle, for complex behaviours to be learned directly from simple reward signals. In practice, however, it is common to carefully hand-design the reward function to encourage a particular solution, or to derive it from demonstration data. In this paper explore how a rich environment can help to promote the learning of complex behavior. Specifically, we train agents in diverse environmental contexts, and find that this encourages the emergence of robust behaviours that perform well across a suite of tasks. We demonstrate this principle for locomotion -- behaviours that are known for their sensitivity to the choice of reward. We train several simulated bodies on a diverse set of challenging terrains and obstacles, using a simple reward function based on forward progress. Using a novel scalable variant of policy gradient reinforcement learning, our agents learn to run, jump, crouch and turn as required by the environment without explicit reward-based guidance. A visual depiction of highlights of the learned behavior can be viewed following https://youtu.be/hx_bgoTF7bs . version:2
arxiv-1707-01495 | Hindsight Experience Replay | http://arxiv.org/abs/1707.01495 | id:1707.01495 author:Marcin Andrychowicz, Filip Wolski, Alex Ray, Jonas Schneider, Rachel Fong, Peter Welinder, Bob McGrew, Josh Tobin, Pieter Abbeel, Wojciech Zaremba category:cs.LG cs.AI cs.NE cs.RO  published:2017-07-05 summary:Dealing with sparse rewards is one of the biggest challenges in Reinforcement Learning (RL). We present a novel technique called Hindsight Experience Replay which allows sample-efficient learning from rewards which are sparse and binary and therefore avoid the need for complicated reward engineering. It can be combined with an arbitrary off-policy RL algorithm and may be seen as a form of implicit curriculum. We demonstrate our approach on the task of manipulating objects with a robotic arm. In particular, we run experiments on three different tasks: pushing, sliding, and pick-and-place, in each case using only binary rewards indicating whether or not the task is completed. Our ablation studies show that Hindsight Experience Replay is a crucial ingredient which makes training possible in these challenging environments. We show that our policies trained on a physics simulation can be deployed on a physical robot and successfully complete the task. version:2
arxiv-1707-02968 | Revisiting Unreasonable Effectiveness of Data in Deep Learning Era | http://arxiv.org/abs/1707.02968 | id:1707.02968 author:Chen Sun, Abhinav Shrivastava, Saurabh Singh, Abhinav Gupta category:cs.CV cs.AI  published:2017-07-10 summary:The success of deep learning in vision can be attributed to: (a) models with high capacity; (b) increased computational power; and (c) availability of large-scale labeled data. Since 2012, there have been significant advances in representation capabilities of the models and computational capabilities of GPUs. But the size of the biggest dataset has surprisingly remained constant. What will happen if we increase the dataset size by 10x or 100x? This paper takes a step towards clearing the clouds of mystery surrounding the relationship between `enormous data' and deep learning. By exploiting the JFT-300M dataset which has more than 375M noisy labels for 300M images, we investigate how the performance of current vision tasks would change if this data was used for representation learning. Our paper delivers some surprising (and some expected) findings. First, we find that the performance on vision tasks still increases linearly with orders of magnitude of training data size. Second, we show that representation learning (or pre-training) still holds a lot of promise. One can improve performance on any vision tasks by just training a better base model. Finally, as expected, we present new state-of-the-art results for different vision tasks including image classification, object detection, semantic segmentation and human pose estimation. Our sincere hope is that this inspires vision community to not undervalue the data and develop collective efforts in building larger datasets. version:1
arxiv-1606-03742 | Application-Driven Near-Data Processing for Similarity Search | http://arxiv.org/abs/1606.03742 | id:1606.03742 author:Vincent T. Lee, Amrita Mazumdar, Carlo C. del Mundo, Armin Alaghi, Luis Ceze, Mark Oskin category:cs.DC cs.AR  published:2016-06-12 summary:Similarity search is a key to a variety of applications including content-based search for images and video, recommendation systems, data deduplication, natural language processing, computer vision, databases, computational biology, and computer graphics. At its core, similarity search manifests as k-nearest neighbors (kNN), a computationally simple primitive consisting of highly parallel distance calculations and a global top-k sort. However, kNN is poorly supported by today's architectures because of its high memory bandwidth requirements. This paper proposes an application-driven near-data processing accelerator for similarity search: the Similarity Search Associative Memory (SSAM). By instantiating compute units close to memory, SSAM benefits from the higher memory bandwidth and density exposed by emerging memory technologies. We evaluate the SSAM design down to layout on top of the Micron hybrid memory cube (HMC), and show that SSAM can achieve up to two orders of magnitude area-normalized throughput and energy efficiency improvement over multicore CPUs; we also show SSAM is faster and more energy efficient than competing GPUs and FPGAs. Finally, we show that SSAM is also useful for other data intensive tasks like kNN index construction, and can be generalized to semantically function as a high capacity content addressable memory. version:2
arxiv-1707-02920 | Vision-Based Multi-Task Manipulation for Inexpensive Robots Using End-To-End Learning from Demonstration | http://arxiv.org/abs/1707.02920 | id:1707.02920 author:Rouhollah Rahmatizadeh, Pooya Abolghasemi, Ladislau BÃ¶lÃ¶ni, Sergey Levine category:cs.LG cs.AI cs.RO  published:2017-07-10 summary:In this paper, we propose a multi-task learning from demonstration method that works using raw images as input to autonomously accomplish a wide variety of tasks in the real world using a low-cost robotic arm. The controller is a single recurrent neural network that can generate robot arm trajectories to perform different manipulation tasks. In order to learn complex skills from relatively few demonstrations, we share parameters across different tasks. Our network also combines VAE-GAN-based reconstruction with autoregressive multimodal action prediction for improved data efficiency. Our results show that weight sharing and reconstruction substantially improve generalization and robustness, and that training on multiple tasks simultaneously greatly improves the success rate on all of the tasks. Our experiments, performed on a real-world low-cost Lynxmotion arm, illustrate a variety of picking and placing tasks, as well as non-prehensile manipulation. version:1
arxiv-1707-02895 | Entanglement verification protocols for distributed systems based on the Quantum Recursive Network Architecture | http://arxiv.org/abs/1707.02895 | id:1707.02895 author:Michele Amoretti, Stefano Carretta category:quant-ph cs.CR cs.DC  published:2017-07-10 summary:In distributed systems based on the quantum recursive network architecture, quantum channels are used to establish entangled quantum states between node pairs. Such systems are robust against attackers that interact with the quantum channels. Conversely, weaknesses emerge when an attacker takes full control of a node and alters the configuration of the local quantum memory, either to make a denial-of-service attack or to reprogram the node. In such a scenario, entanglement verification over quantum memories is a means for detecting the intruder. In this paper, we thoroughly analyze an entanglement verification protocol previously proposed by Nagy and Akl, denoted as NA2010. Then, we introduce two novel entanglement verification protocols and we prove that they are even more efficient in terms of intrusion detection probability versus sacrificed quantum resources. Remarkably, all these protocols require only classical channels and local quantum operations to work. version:1
arxiv-1707-02201 | Learning human behaviors from motion capture by adversarial imitation | http://arxiv.org/abs/1707.02201 | id:1707.02201 author:Josh Merel, Yuval Tassa, Dhruva TB, Sriram Srinivasan, Jay Lemmon, Ziyu Wang, Greg Wayne, Nicolas Heess category:cs.RO cs.LG cs.SY  published:2017-07-07 summary:Rapid progress in deep reinforcement learning has made it increasingly feasible to train controllers for high-dimensional humanoid bodies. However, methods that use pure reinforcement learning with simple reward functions tend to produce non-humanlike and overly stereotyped movement behaviors. In this work, we extend generative adversarial imitation learning to enable training of generic neural network policies to produce humanlike movement patterns from limited demonstrations consisting only of partially observed state features, without access to actions, even when the demonstrations come from a body with different and unknown physical parameters. We leverage this approach to build sub-skill policies from motion capture data and show that they can be reused to solve tasks when controlled by a higher level controller. version:2
arxiv-1701-07495 | Two-Party Function Computation on the Reconciled Data | http://arxiv.org/abs/1701.07495 | id:1701.07495 author:Ivo Kubjas, Vitaly Skachek category:cs.IT cs.DC math.IT  published:2017-01-25 summary:In this paper, we initiate a study of a new problem termed function computation on the reconciled data, which generalizes a set reconciliation problem in the literature. Assume a distributed data storage system with two users $A$ and $B$. The users possess a collection of binary vectors $S_{A}$ and $S_{B}$, respectively. They are interested in computing a function $\phi$ of the reconciled data $S_{A} \cup S_{B}$. It is shown that any deterministic protocol, which computes a sum and a product of reconciled sets of binary vectors represented as nonnegative integers, has to communicate at least $2^n + n - 1$ and $2^n + n - 2$ bits in the worst-case scenario, respectively, where $n$ is the length of the binary vectors. Connections to other problems in computer science, such as set disjointness and finding the intersection, are established, yielding a variety of additional upper and lower bounds on the communication complexity. A protocol for computation of a sum function, which is based on use of a family of hash functions, is presented, and its characteristics are analyzed. version:2
arxiv-1604-03687 | Democratic, Existential, and Consensus-Based Output Conventions in Stable Computation by Chemical Reaction Networks | http://arxiv.org/abs/1604.03687 | id:1604.03687 author:Robert Brijder, David Doty, David Soloveichik category:cs.ET cs.DC cs.LO q-bio.MN  published:2016-04-13 summary:We show that some natural output conventions for error-free computation in chemical reaction networks (CRN) lead to a common level of computational expressivity. Our main results are that the standard consensus-based output convention have equivalent computational power to (1) existence-based and (2) democracy-based output conventions. The CRNs using the former output convention have only "yes" voters, with the interpretation that the CRN's output is yes if any voters are present and no otherwise. The CRNs using the latter output convention define output by majority vote among "yes" and "no" voters. Both results are proven via a generalized framework that simultaneously captures several definitions, directly inspired by a Petri net result of Esparza, Ganty, Leroux, and Majumder [CONCUR 2015]. These results support the thesis that the computational expressivity of error-free CRNs is intrinsic, not sensitive to arbitrary definitional choices. version:2
arxiv-1707-02812 | Towards Crafting Text Adversarial Samples | http://arxiv.org/abs/1707.02812 | id:1707.02812 author:Suranjana Samanta, Sameep Mehta category:cs.LG cs.AI cs.CL cs.CV  published:2017-07-10 summary:Adversarial samples are strategically modified samples, which are crafted with the purpose of fooling a classifier at hand. An attacker introduces specially crafted adversarial samples to a deployed classifier, which are being mis-classified by the classifier. However, the samples are perceived to be drawn from entirely different classes and thus it becomes hard to detect the adversarial samples. Most of the prior works have been focused on synthesizing adversarial samples in the image domain. In this paper, we propose a new method of crafting adversarial text samples by modification of the original samples. Modifications of the original text samples are done by deleting or replacing the important or salient words in the text or by introducing new words in the text sample. Our algorithm works best for the datasets which have sub-categories within each of the classes of examples. While crafting adversarial samples, one of the key constraint is to generate meaningful sentences which can at pass off as legitimate from language (English) viewpoint. Experimental results on IMDB movie review dataset for sentiment analysis and Twitter dataset for gender detection show the efficiency of our proposed method. version:1
arxiv-1707-02796 | Semi-Supervised Haptic Material Recognition for Robots using Generative Adversarial Networks | http://arxiv.org/abs/1707.02796 | id:1707.02796 author:Zackory Erickson, Sonia Chernova, Charles C. Kemp category:cs.RO cs.LG stat.ML  published:2017-07-10 summary:Material recognition enables robots to incorporate knowledge of material properties into their interactions with everyday objects. For instance, material recognition opens up opportunities for clearer communication with a robot, such as "bring me the metal coffee mug", and having the ability to recognize plastic versus metal is crucial when using a microwave or oven. However, collecting labeled training data can be difficult with a robot, whereas many forms of unlabeled data could be collected relatively easily during a robot's interactions. We present a semi-supervised learning approach for material recognition that uses generative adversarial networks (GANs) with haptic features such as force, temperature, and vibration. Our approach achieves state-of-the-art results and enables a robot to estimate the material class of household objects with ~90% accuracy when 92% of the training data are unlabeled. We explore how well this generative approach can recognize the material of new objects and we discuss challenges facing this generalization. In addition, we have released the dataset used for this work which consists of time-series haptic measurements from a robot that conducted thousands of interactions with 72 household objects. version:1
arxiv-1707-02789 | Exploiting Parallelism in Optical Network Systems: A Case Study of Random Linear Network Coding (RLNC) in Ethernet-over-Optical Networks | http://arxiv.org/abs/1707.02789 | id:1707.02789 author:Anna Engelmann, Wolfgang Bziuk, Admela Jukan, Muriel Medard category:cs.PF cs.DC  published:2017-07-10 summary:As parallelism becomes critically important in the semiconductor technology, high-performance computing, and cloud applications, parallel network systems will increasingly follow suit. Today, parallelism is an essential architectural feature of 40/100/400 Gigabit Ethernet standards, whereby high speed Ethernet systems are equipped with multiple parallel network interfaces. This creates new network topology abstractions and new technology requirements: instead of a single high capacity network link, multiple Ethernet end-points and interfaces need to be considered together with multiple links in form of discrete parallel paths. This new paradigm is enabling implementations of various new features to improve overall system performance. In this paper, we analyze the performance of parallel network systems with network coding. In particular, by using random LNC (RLNC), - a code without the need for decoding, we can make use of the fact that we have codes that are both distributed (removing the need for coordination or optimization of resources) and composable (without the need to exchange code information), leading to a fully stateless operation. We propose a novel theoretical modeling framework, including derivation of the upper and lower bounds as well as an expected value of the differential delay of parallel paths, and the resulting queue size at the receiver. The results show a great promise of network system parallelism in combination with RLNC: with a proper set of design parameters, the differential delay and the buffer size at the Ethernet receiver can be reduced significantly, while the cross-layer design and routing can be greatly simplified. version:1
arxiv-1705-09415 | Near-Optimal Belief Space Planning via T-LQG | http://arxiv.org/abs/1705.09415 | id:1705.09415 author:Mohammadhussein Rafieisakhaei, Suman Chakravorty, P. R. Kumar category:cs.RO cs.SY  published:2017-05-26 summary:We consider the problem of planning under observation and motion uncertainty for nonlinear robotics systems. Determining the optimal solution to this problem, generally formulated as a Partially Observed Markov Decision Process (POMDP), is computationally intractable. We propose a Trajectory-optimized Linear Quadratic Gaussian (T-LQG) approach that leads to quantifiably near-optimal solutions for the POMDP problem. We provide a novel "separation principle" for the design of an optimal nominal open-loop trajectory followed by an optimal feedback control law, which provides a near-optimal feedback control policy for belief space planning problems involving a polynomial order of calculations of minimum order. version:2
arxiv-1707-02774 | Understanding State Preferences With Text As Data: Introducing the UN General Debate Corpus | http://arxiv.org/abs/1707.02774 | id:1707.02774 author:Alexander Baturo, Niheer Dasandi, Slava J. Mikhaylov category:cs.CL cs.AI stat.ML  published:2017-07-10 summary:Every year at the United Nations, member states deliver statements during the General Debate discussing major issues in world politics. These speeches provide invaluable information on governments' perspectives and preferences on a wide range of issues, but have largely been overlooked in the study of international politics. This paper introduces a new dataset consisting of over 7,701 English-language country statements from 1970-2016. We demonstrate how the UN General Debate Corpus (UNGDC) can be used to derive country positions on different policy dimensions using text analytic methods. The paper provides applications of these estimates, demonstrating the contribution the UNGDC can make to the study of international politics. version:1
arxiv-1707-02767 | Model Identification and Controller Parameter Optimization for an Autopilot Design for Autonomous Underwater Vehicles | http://arxiv.org/abs/1707.02767 | id:1707.02767 author:Ralf Taubert, Mike Eichhorn, Christoph Ament, Marco Jacobi, Divas Karimanzira, Torsten Pfuetzenreuter category:cs.RO  published:2017-07-10 summary:Nowadays an accurate modeling of the system to be controlled is essential for reliable autopilot. This paper presents a non-linear model of the autonomous underwater vehicle 'CWolf'. Matrices and the corresponding coefficients generate a parameterized representation for added mass, Coriolis and centripetal forces, damping, gravity and buoyancy, using the equations of motion, for all six degrees of freedom. The determination of actuator behaviour by surge tests allows the conversion of propeller revolutions to the respective forces and moments. Based on geometric approximations, the coefficients of the model can be specified by optimization algorithms in 'open loop' sea trials. The realistic model is the basis for the subsequent design of the autopilot. The reference variables used in the four decoupled adaptive PID controllers for surge, heading, pitch and heave are provided a 'Line of Sight' - guidance system. A constraint criteria optimization determines the required controller parameters. The verification by 'closed loop' sea trials ensures the results. version:1
arxiv-1707-02745 | Object Handover Prediction using Gaussian Processes clustered with Trajectory Classification | http://arxiv.org/abs/1707.02745 | id:1707.02745 author:Muriel Lang, Satoshi Endo, Oliver Dunkley, Sandra Hirche category:cs.RO  published:2017-07-10 summary:A robotic system which approximates the user intention and appropriate complimentary motion is critical for successful human-robot interaction. %While the existing wearable sensors can monitor human movements in real-time, prediction of human movement is a significant challenge due to its highly non-linear motions optimised through the redundancy in the degrees of freedom. Here, we demonstrate robustness of the Gaussian Process (GP) clustered with a stochastic classification technique for trajectory prediction using an object handover scenario. By parametrising real 6D hand movements during human-human object handover using dual quaternions, variations of handover configurations were classified in real-time and then the remaining hand trajectory was predicted using the GP. The results highlights that our method can classify the handover configuration at an average of $43.4\%$ of the trajectory and the final hand configuration can be predicted within the normal variation of human movement. In conclusion, we demonstrate that GPs combined with a stochastic classification technique is a robust tool for proactively estimating human motions for human-robot interaction. version:1
arxiv-1707-02729 | Best-Effort Inductive Logic Programming via Fine-grained Cost-based Hypothesis Generation | http://arxiv.org/abs/1707.02729 | id:1707.02729 author:Peter SchÃ¼ller, Mishal Kazmi category:cs.AI cs.LG cs.LO  published:2017-07-10 summary:We describe the Inspire system which participated in the first competition on Inductive Logic Programming (ILP). Inspire is based on Answer Set Programming (ASP), its most important feature is an ASP encoding for hypothesis space generation: given a set of facts representing the mode bias, and a set of cost configuration parameters, each answer set of this encoding represents a single rule that is considered for finding a hypothesis that entails the given examples. Compared with state-of-the-art methods that use the length of the rule body as a metric for rule complexity, our approach permits a much more fine-grained specification of the shape of hypothesis candidate rules. Similar to the ILASP system, our system iteratively increases the rule cost limit until it finds a suitable hypothesis. Different from ILASP, our approach generates a new search space for each cost limit. The Inspire system searches for a hypothesis that entails a single example at a time, utilizing a simplification of the ASP encoding used in the XHAIL system. To evaluate ASP we use Clingo. We perform experiments with the development and test set of the ILP competition. For comparison we also adapted the ILASP system to process competition instances. Experimental results show, that Inspire performs better than ILASP, and that cost parameters for the hypothesis search space are an important factor for finding suitable hypotheses efficiently. version:1
arxiv-1706-03416 | Learning Large-Scale Topological Maps Using Sum-Product Networks | http://arxiv.org/abs/1706.03416 | id:1706.03416 author:Kaiyu Zheng category:cs.RO cs.AI  published:2017-06-11 summary:In order to perform complex actions in human environments, an autonomous robot needs the ability to understand the environment, that is, to gather and maintain spatial knowledge. Topological map is commonly used for representing large scale, global maps such as floor plans. Although much work has been done in topological map extraction, we have found little previous work on the problem of learning the topological map using a probabilistic model. Learning a topological map means learning the structure of the large-scale space and dependency between places, for example, how the evidence of a group of places influence the attributes of other places. This is an important step towards planning complex actions in the environment. In this thesis, we consider the problem of using probabilistic deep learning model to learn the topological map, which is essentially a sparse undirected graph where nodes represent places annotated with their semantic attributes (e.g. place category). We propose to use a novel probabilistic deep model, Sum-Product Networks (SPNs), due to their unique properties. We present two methods for learning topological maps using SPNs: the place grid method and the template-based method. We contribute an algorithm that builds SPNs for graphs using template models. Our experiments evaluate the ability of our models to enable robots to infer semantic attributes and detect maps with novel semantic attribute arrangements. Our results demonstrate their understanding of the topological map structure and spatial relations between places. version:2
arxiv-1707-02657 | PELESent: Cross-domain polarity classification using distant supervision | http://arxiv.org/abs/1707.02657 | id:1707.02657 author:Edilson A. CorrÃªa Jr, Vanessa Q. Marinho, Leandro B. dos Santos, Thales F. C. Bertaglia, Marcos V. Treviso, Henrico B. Brum category:cs.CL cs.AI cs.LG  published:2017-07-09 summary:The enormous amount of texts published daily by Internet users has fostered the development of methods to analyze this content in several natural language processing areas, such as sentiment analysis. The main goal of this task is to classify the polarity of a message. Even though many approaches have been proposed for sentiment analysis, some of the most successful ones rely on the availability of large annotated corpus, which is an expensive and time-consuming process. In recent years, distant supervision has been used to obtain larger datasets. So, inspired by these techniques, in this paper we extend such approaches to incorporate popular graphic symbols used in electronic messages, the emojis, in order to create a large sentiment corpus for Portuguese. Trained on almost one million tweets, several models were tested in both same domain and cross-domain corpora. Our methods obtained very competitive results in five annotated corpora from mixed domains (Twitter and product reviews), which proves the domain-independent property of such approach. In addition, our results suggest that the combination of emoticons and emojis is able to properly capture the sentiment of a message. version:1
arxiv-1707-02647 | Cappuccino: Efficient Inference Software Synthesis for Mobile System-on-Chips | http://arxiv.org/abs/1707.02647 | id:1707.02647 author:Mohammad Motamedi, Daniel Fong, Soheil Ghiasi category:cs.DC  published:2017-07-09 summary:Convolutional Neural Networks (CNNs) exhibit remarkable performance in various machine learning tasks. As sensor-equipped Internet of Things (IoT) devices permeate into every aspect of modern life, the ability to execute CNN inference, a computationally intensive application, on resource constrained devices has become increasingly important. In this context, we present Cappuccino, a framework for synthesis of efficient inference software targeting mobile System-on-Chips (SoCs). We propose techniques for efficient parallelization of CNN inference targeting mobile SoCs, and explore the underlying tradeoffs. Experiments with different CNNs on three mobile devices demonstrate the effectiveness of our approach. version:1
arxiv-1707-02639 | Towards a Comprehensive Framework for Telemetry Data in HPC Environments | http://arxiv.org/abs/1707.02639 | id:1707.02639 author:Ole Weidner, Malcolm Atkinson, Adam Barker category:cs.DC  published:2017-07-09 summary:Current HPC platforms do not provide the infrastructure, interfaces and conceptual models to collect, store, analyze, and access such data. Today, applications depend on application and platform specific techniques for collecting telemetry data; introducing significant development overheads that inhibit portability and mobility. The development and adoption of adaptive, context-aware strategies is thereby impaired. To facilitate 2nd generation applications, more efficient application development, and swift adoption of adaptive applications in production, a comprehensive framework for telemetry data management must be provided by future HPC systems and services. We introduce a conceptual model and a software framework to collect, store, analyze, and exploit streams of telemetry data generated by HPC systems and their applications. We show how this framework can be integrated with HPC platform architectures and how it enables common application execution strategies. version:1
arxiv-1707-02600 | Event Stream Processing with Multiple Threads | http://arxiv.org/abs/1707.02600 | id:1707.02600 author:Sylvain HallÃ©, RaphaÃ«l Khoury, SÃ©bastien Gaboury category:cs.DC  published:2017-07-09 summary:Current runtime verification tools seldom make use of multi-threading to speed up the evaluation of a property on a large event trace. In this paper, we present an extension to the BeepBeep 3 event stream engine that allows the use of multiple threads during the evaluation of a query. Various parallelization strategies are presented and described on simple examples. The implementation of these strategies is then evaluated empirically on a sample of problems. Compared to the previous, single-threaded version of the BeepBeep engine, the allocation of just a few threads to specific portions of a query provides dramatic improvement in terms of running time. version:1
arxiv-1707-02591 | Flexible human-robot cooperation models for assisted shop-floor tasks | http://arxiv.org/abs/1707.02591 | id:1707.02591 author:Kourosh Darwish, Francesco Wanderlingh, Barbara Bruno, Enrico Simetti, Fulvio Mastrogiovanni, Giuseppe Casalino category:cs.RO 68T40  published:2017-07-09 summary:The Industry 4.0 paradigm emphasizes the crucial benefits that collaborative robots, i.e., robots able to work alongside and together with humans, could bring to the whole production process. In this context, an enabling technology yet unreached is the design of flexible robots able to deal at all levels with humans' intrinsic variability, which is not only a necessary element for a comfortable working experience for the person but also a precious capability for efficiently dealing with unexpected events. In this paper, a sensing, representation, planning and control architecture for flexible human-robot cooperation, referred to as FlexHRC, is proposed. FlexHRC relies on wearable sensors for human action recognition, AND/OR graphs for the representation of and reasoning upon cooperation models, and a Task Priority framework to decouple action planning from robot motion planning and control. version:1
arxiv-1707-02589 | Exploiting the Tradeoff between Program Accuracy and Soft-error Resiliency Overhead for Machine Learning Workloads | http://arxiv.org/abs/1707.02589 | id:1707.02589 author:Qingchuan Shi, Hamza Omar, Omer Khan category:cs.DC  published:2017-07-09 summary:To protect multicores from soft-error perturbations, resiliency schemes have been developed with high coverage but high power and performance overheads. Emerging safety-critical machine learning applications are increasingly being deployed on these platforms. Moreover, these systems are exposed to harsh environments, such as unmanned aerial vehicles (UAVs) and self-driving cars. Due to the unique structure and computational behavior of such applications, research has been done on relaxing their accuracy for performance benefits. We observe that not all transient errors affect program correctness, some errors only affect program accuracy, i.e., the program completes with certain acceptable deviations from error free outcome. This paper illustrates the idea of cross-layer soft-error resilience using machine learning workloads, where program accuracy is introduced as a tradeoff to deliver resilient yet efficient execution on futuristic large-scale multicores. version:1
arxiv-1707-02586 | Mathematical Models of Adaptation in Human-Robot Collaboration | http://arxiv.org/abs/1707.02586 | id:1707.02586 author:Stefanos Nikolaidis, Jodi Forlizzi, David Hsu, Julie Shah, Siddhartha Srinivasa category:cs.RO  published:2017-07-09 summary:A robot operating in isolation needs to reason over the uncertainty in its model of the world and adapt its own actions to account for this uncertainty. Similarly, a robot interacting with people needs to reason over its uncertainty over the human internal state, as well as over how this state may change, as humans adapt to the robot. This paper summarizes our own work in this area, which depicts the different ways that probabilistic planning and game-theoretic algorithms can enable such reasoning in robotic systems that collaborate with people. We start with a general formulation of the problem as a two-player game with incomplete information. We then articulate the different assumptions within this general formulation, and we explain how these lead to exciting and diverse robot behaviors in real-time interactions with actual human subjects, in a variety of manufacturing, personal robotics and assistive care settings. version:1
arxiv-1707-02353 | Evaluating race and sex diversity in the world's largest companies using deep neural networks | http://arxiv.org/abs/1707.02353 | id:1707.02353 author:Konstantin Chekanov, Polina Mamoshina, Roman V. Yampolskiy, Radu Timofte, Morten Scheibye-Knudsen, Alex Zhavoronkov category:cs.CY cs.AI cs.LG  published:2017-07-09 summary:Diversity is one of the fundamental properties for the survival of species, populations, and organizations. Recent advances in deep learning allow for the rapid and automatic assessment of organizational diversity and possible discrimination by race, sex, age and other parameters. Automating the process of assessing the organizational diversity using the deep neural networks and eliminating the human factor may provide a set of real-time unbiased reports to all stakeholders. In this pilot study we applied the deep-learned predictors of race and sex to the executive management and board member profiles of the 500 largest companies from the 2016 Forbes Global 2000 list and compared the predicted ratios to the ratios within each company's country of origin and ranked them by the sex-, age- and race- diversity index (DI). While the study has many limitations and no claims are being made concerning the individual companies, it demonstrates a method for the rapid and impartial assessment of organizational diversity using deep neural networks. version:1
arxiv-1707-02557 | GraphMP: An Efficient Semi-External-Memory Big Graph Processing System on a Single Machine | http://arxiv.org/abs/1707.02557 | id:1707.02557 author:Peng Sun, Yonggang Wen, Ta Nguyen Binh Duong, Xiaokui Xiao category:cs.DC  published:2017-07-09 summary:Recent studies showed that single-machine graph processing systems can be as highly competitive as cluster-based approaches on large-scale problems. While several out-of-core graph processing systems and computation models have been proposed, the high disk I/O overhead could significantly reduce performance in many practical cases. In this paper, we propose GraphMP to tackle big graph analytics on a single machine. GraphMP achieves low disk I/O overhead with three techniques. First, we design a vertex-centric sliding window (VSW) computation model to avoid reading and writing vertices on disk. Second, we propose a selective scheduling method to skip loading and processing unnecessary edge shards on disk. Third, we use a compressed edge cache mechanism to fully utilize the available memory of a machine to reduce the amount of disk accesses for edges. Extensive evaluations have shown that GraphMP could outperform state-of-the-art systems such as GraphChi, X-Stream and GridGraph by 31.6x, 54.5x and 23.1x respectively, when running popular graph applications on a billion-vertex graph. version:1
arxiv-1707-02515 | A Fast Integrated Planning and Control Framework for Autonomous Driving via Imitation Learning | http://arxiv.org/abs/1707.02515 | id:1707.02515 author:Liting Sun, Cheng Peng, Wei Zhan, Masayoshi Tomizuka category:cs.AI cs.LG cs.SY  published:2017-07-09 summary:For safe and efficient planning and control in autonomous driving, we need a driving policy which can achieve desirable driving quality in long-term horizon with guaranteed safety and feasibility. Optimization-based approaches, such as Model Predictive Control (MPC), can provide such optimal policies, but their computational complexity is generally unacceptable for real-time implementation. To address this problem, we propose a fast integrated planning and control framework that combines learning- and optimization-based approaches in a two-layer hierarchical structure. The first layer, defined as the "policy layer", is established by a neural network which learns the long-term optimal driving policy generated by MPC. The second layer, called the "execution layer", is a short-term optimization-based controller that tracks the reference trajecotries given by the "policy layer" with guaranteed short-term safety and feasibility. Moreover, with efficient and highly-representative features, a small-size neural network is sufficient in the "policy layer" to handle many complicated driving scenarios. This renders online imitation learning with Dataset Aggregation (DAgger) so that the performance of the "policy layer" can be improved rapidly and continuously online. Several exampled driving scenarios are demonstrated to verify the effectiveness and efficiency of the proposed framework. version:1
arxiv-1707-02973 | A Reconfigurable Streaming Deep Convolutional Neural Network Accelerator for Internet of Things | http://arxiv.org/abs/1707.02973 | id:1707.02973 author:Li Du, Yuan Du, Yilei Li, Mau-Chung Frank Chang category:cs.CV cs.AR  published:2017-07-08 summary:Convolutional neural network (CNN) offers significant accuracy in image detection. To implement image detection using CNN in the internet of things (IoT) devices, a streaming hardware accelerator is proposed. The proposed accelerator optimizes the energy efficiency by avoiding unnecessary data movement. With unique filter decomposition technique, the accelerator can support arbitrary convolution window size. In addition, max pooling function can be computed in parallel with convolution by using separate pooling unit, thus achieving throughput improvement. A prototype accelerator was implemented in TSMC 65nm technology with a core size of 5mm2. The accelerator can support major CNNs and achieve 152GOPS peak throughput and 434GOPS/W energy efficiency at 350mW, making it a promising hardware accelerator for intelligent IoT devices. version:1
arxiv-1611-08743 | Eliminating Tight Coupling using Subscriptions Subgrouping in Structured Overlays | http://arxiv.org/abs/1611.08743 | id:1611.08743 author:Muhammad Shafique category:cs.DC  published:2016-11-26 summary:Advertisements and subscriptions are tightly coupled to generate publication routing paths in content--based publish/subscribe systems. Tight coupling requires instantaneous updates in routing tables to generate alternative paths which prevents offering scalable and robust dynamic routing in cyclic overlays when link congestion is detected. We propose, OctopiA, first distributed publish/subscribe system for content--based inter--cluster dynamic routing using purpose--built structured cyclic overlays. OctopiA uses a novel concept of subscription subgrouping, which divides subscriptions into disjoint sets called subscription subgroups. The purpose--built structured cyclic overlay is divided into identical clusters where subscriptions in each subgroup are broadcast to an exclusive cluster. Our advertisement and subscription forwarding algorithms use subscription subgrouping to eliminate tight coupling to offer inter--cluster dynamic routing without requiring updates in routing tables. Experiments on a cluster testbed with real world data show that OctopiA reduces the number of saved advertisements in routing tables by 93%, subscription broadcast delay by 33%, static and dynamic publication delivery delays by 25% and 54%, respectively. version:4
arxiv-1707-02423 | A Similarity Measure for GPU Kernel Subgraph Matching | http://arxiv.org/abs/1707.02423 | id:1707.02423 author:Robert V. Lim, Boyana Norris, Allen D. Malony category:cs.DC  published:2017-07-08 summary:Accelerator architectures specialize in executing SIMD (single instruction, multiple data) in lockstep. Because the majority of CUDA applications are parallelized loops, control flow information can provide an in-depth characterization of a kernel. CUDAflow is a tool that statically separates CUDA binaries into basic block regions and dynamically measures instruction and basic block frequencies. CUDAflow captures this information in a control flow graph (CFG) and performs subgraph matching across various kernel's CFGs to gain insights to an application's resource requirements, based on the shape and traversal of the graph, instruction operations executed and registers allocated, among other information. The utility of CUDAflow is demonstrated with SHOC and Rodinia application case studies on a variety of GPU architectures, revealing novel thread divergence characteristics that facilitates end users, autotuners and compilers in generating high performing code. version:1
arxiv-1705-03455 | Sequential Dialogue Context Modeling for Spoken Language Understanding | http://arxiv.org/abs/1705.03455 | id:1705.03455 author:Ankur Bapna, Gokhan Tur, Dilek Hakkani-Tur, Larry Heck category:cs.CL cs.AI cs.LG  published:2017-05-08 summary:Spoken Language Understanding (SLU) is a key component of goal oriented dialogue systems that would parse user utterances into semantic frame representations. Traditionally SLU does not utilize the dialogue history beyond the previous system turn and contextual ambiguities are resolved by the downstream components. In this paper, we explore novel approaches for modeling dialogue context in a recurrent neural network (RNN) based language understanding system. We propose the Sequential Dialogue Encoder Network, that allows encoding context from the dialogue history in chronological order. We compare the performance of our proposed architecture with two context models, one that uses just the previous turn context and another that encodes dialogue context in a memory network, but loses the order of utterances in the dialogue history. Experiments with a multi-domain dialogue dataset demonstrate that the proposed architecture results in reduced semantic frame error rates. version:3
arxiv-1707-02363 | Towards Zero-Shot Frame Semantic Parsing for Domain Scaling | http://arxiv.org/abs/1707.02363 | id:1707.02363 author:Ankur Bapna, Gokhan Tur, Dilek Hakkani-Tur, Larry Heck category:cs.AI cs.CL  published:2017-07-07 summary:State-of-the-art slot filling models for goal-oriented human/machine conversational language understanding systems rely on deep learning methods. While multi-task training of such models alleviates the need for large in-domain annotated datasets, bootstrapping a semantic parsing model for a new domain using only the semantic frame, such as the back-end API or knowledge graph schema, is still one of the holy grail tasks of language understanding for dialogue systems. This paper proposes a deep learning based approach that can utilize only the slot description in context without the need for any labeled or unlabeled in-domain examples, to quickly bootstrap a new domain. The main idea of this paper is to leverage the encoding of the slot names and descriptions within a multi-task deep learned slot filling model, to implicitly align slots across domains. The proposed approach is promising for solving the domain scaling problem and eliminating the need for any manually annotated data or explicit schema alignment. Furthermore, our experiments on multiple domains show that this approach results in significantly better slot-filling performance when compared to using only in-domain data, especially in the low data regime. version:1
arxiv-1707-02342 | Information Theoretic Model Predictive Control: Theory and Applications to Autonomous Driving | http://arxiv.org/abs/1707.02342 | id:1707.02342 author:Grady Williams, Paul Drews, Brian Goldfain, James M. Rehg, Evangelos A. Theodorou category:cs.RO  published:2017-07-07 summary:We present an information theoretic approach to stochastic optimal control problems that can be used to derive general sampling based optimization schemes. This new mathematical method is used to develop a sampling based model predictive control algorithm. We apply this information theoretic model predictive control (IT-MPC) scheme to the task of aggressive autonomous driving around a dirt test track, and compare its performance to a model predictive control version of the cross-entropy method. version:1
arxiv-1707-02275 | A parallel corpus of Python functions and documentation strings for automated code documentation and code generation | http://arxiv.org/abs/1707.02275 | id:1707.02275 author:Antonio Valerio Miceli Barone, Rico Sennrich category:cs.CL cs.AI  published:2017-07-07 summary:Automated documentation of programming source code and automated code generation from natural language are challenging tasks of both practical and scientific interest. Progress in these areas has been limited by the low availability of parallel corpora of code and natural language descriptions, which tend to be small and constrained to specific domains. In this work we introduce a large and diverse parallel corpus of a hundred thousands Python functions with their documentation strings ("docstrings") generated by scraping open source repositories on GitHub. We describe baseline results for the code documentation and code generation tasks obtained by neural machine translation. We also experiment with data augmentation techniques to further increase the amount of training data. We release our datasets and processing scripts in order to stimulate research in these areas. version:1
arxiv-1707-02267 | Transferring End-to-End Visuomotor Control from Simulation to Real World for a Multi-Stage Task | http://arxiv.org/abs/1707.02267 | id:1707.02267 author:Stephen James, Andrew J. Davison, Edward Johns category:cs.RO cs.LG  published:2017-07-07 summary:End-to-end control for robot manipulation and grasping is emerging as an attractive alternative to traditional pipelined approaches. However, end-to-end methods tend to be either slow to train, exhibit little or no generalisability, or lack the ability to accomplish long-horizon or multi-stage tasks. In this paper, we show how two simple techniques can lead to end-to-end (image to velocity) execution of a multi-stage task that is analogous to a simple tidying routine, without having seen a single real image. This involves locating, reaching for, and grasping a cube, then locating a basket to drop the cube in. The first technique is to utilise the full state from a simulator to collect a series of control velocities which accomplish the task. The second technique is to utilise domain randomisation to allow the controller to generalise to the real world. Our results show that we are able to successfully accomplish the task in the real world with the ability to generalise to novel environments, including those with novel lighting conditions and distractor objects, and the ability to deal with moving objects, including the basket itself. We believe our approach to be simple, highly scalable and capable of learning long-horizon tasks that have so far not been shown with the state-of-the-art in end-to-end robot control. version:1
arxiv-1702-07312 | Self-synchronization and Self-stabilization of 3D Bipedal Walking Gaits | http://arxiv.org/abs/1702.07312 | id:1702.07312 author:Christine Chevallereau, Hamed Razavi, Damien Six, Yannick Aoustin, Jessy Grizzle category:cs.RO  published:2017-02-23 summary:This paper seeks insight into stabilization mechanisms for periodic walking gaits in 3D bipedal robots. Based on this insight, a control strategy based on virtual constraints, which imposes coordination between joints rather than a temporal evolution, will be proposed for achieving asymptotic convergence toward a periodic motion. For planar bipeds with one degree of underactuation, it is known that a vertical displacement of the center of mass---with downward velocity at the step transition---induces stability of a walking gait. This paper concerns the qualitative extension of this type of property to 3D walking with two degrees of underactuation. It is shown that a condition on the position of the center of mass in the horizontal plane at the transition between steps induces synchronization between the motions in the sagittal and frontal planes. A combination of the conditions for self-synchronization and vertical oscillations leads to stable gaits. The algorithm for self-stabilization of 3D walking gaits is first developed for a simplified model of a walking robot (an inverted pendulum with variable length legs), and then it is extended to a complex model of the humanoid robot Romeo using the notion of Hybrid Zero Dynamics. Simulations of the model of the robot illustrate the efficacy of the method and its robustness. version:2
arxiv-1707-02244 | GPU-Accelerated Algorithms for Compressed Signals Recovery with Application to Astronomical Imagery Deblurring | http://arxiv.org/abs/1707.02244 | id:1707.02244 author:Attilio Fiandrotti, Sophie M. Fosson, Chiara Ravazzi, Enrico Magli category:cs.DC astro-ph.IM cs.CV  published:2017-07-07 summary:Compressive sensing promises to enable bandwidth-efficient on-board compression of astronomical data by lifting the encoding complexity from the source to the receiver. The signal is recovered off-line, exploiting GPUs parallel computation capabilities to speedup the reconstruction process. However, inherent GPU hardware constraints limit the size of the recoverable signal and the speedup practically achievable. In this work, we design parallel algorithms that exploit the properties of circulant matrices for efficient GPU-accelerated sparse signals recovery. Our approach reduces the memory requirements, allowing us to recover very large signals with limited memory. In addition, it achieves a tenfold signal recovery speedup thanks to ad-hoc parallelization of matrix-vector multiplications and matrix inversions. Finally, we practically demonstrate our algorithms in a typical application of circulant matrices: deblurring a sparse astronomical image in the compressed domain. version:1
arxiv-1707-02229 | A Lower Bound Technique for Communication in BSP | http://arxiv.org/abs/1707.02229 | id:1707.02229 author:Gianfranco Bilardi, Michele Scquizzato, Francesco Silvestri category:cs.DC cs.DS  published:2017-07-07 summary:Communication is a major factor determining the performance of algorithms on current computing systems; it is therefore valuable to provide tight lower bounds on the communication complexity of computations. This paper presents a lower bound technique for the communication complexity in the bulk-synchronous parallel (BSP) model of a given class of DAG computations. The derived bound is expressed in terms of the switching potential of a DAG, that is, the number of permutations that the DAG can realize when viewed as a switching network. The proposed technique yields tight lower bounds for the fast Fourier transform (FFT), and for any sorting and permutation network. A stronger bound is also derived for the periodic balanced sorting network, by applying this technique to suitable subnetworks. Finally, we demonstrate that the switching potential captures communication requirements even in computational models different from BSP, such as the I/O model and the LPRAM. version:1
arxiv-1707-02174 | Methods for finding leader--follower equilibria with multiple followers | http://arxiv.org/abs/1707.02174 | id:1707.02174 author:Nicola Basilico, Stefano Coniglio, Nicola Gatti category:cs.GT cs.AI  published:2017-07-07 summary:The concept of leader--follower (or Stackelberg) equilibrium plays a central role in a number of real--world applications of game theory. While the case with a single follower has been thoroughly investigated, results with multiple followers are only sporadic and the problem of designing and evaluating computationally tractable equilibrium-finding algorithms is still largely open. In this work, we focus on the fundamental case where multiple followers play a Nash equilibrium once the leader has committed to a strategy---as we illustrate, the corresponding equilibrium finding problem can be easily shown to be $\mathcal{FNP}$--hard and not in Poly--$\mathcal{APX}$ unless $\mathcal{P} = \mathcal{NP}$ and therefore it is one among the hardest problems to solve and approximate. We propose nonconvex mathematical programming formulations and global optimization methods to find both exact and approximate equilibria, as well as a heuristic black box algorithm. All the methods and formulations that we introduce are thoroughly evaluated computationally. version:1
arxiv-1703-08144 | Note Value Recognition for Piano Transcription Using Markov Random Fields | http://arxiv.org/abs/1703.08144 | id:1703.08144 author:Eita Nakamura, Kazuyoshi Yoshii, Simon Dixon category:cs.AI cs.SD  published:2017-03-23 summary:This paper presents a statistical method for use in music transcription that can estimate score times of note onsets and offsets from polyphonic MIDI performance signals. Because performed note durations can deviate largely from score-indicated values, previous methods had the problem of not being able to accurately estimate offset score times (or note values) and thus could only output incomplete musical scores. Based on observations that the pitch context and onset score times are influential on the configuration of note values, we construct a context-tree model that provides prior distributions of note values using these features and combine it with a performance model in the framework of Markov random fields. Evaluation results show that our method reduces the average error rate by around 40 percent compared to existing/simple methods. We also confirmed that, in our model, the score model plays a more important role than the performance model, and it automatically captures the voice structure by unsupervised learning. version:3
arxiv-1609-01995 | Unifying task specification in reinforcement learning | http://arxiv.org/abs/1609.01995 | id:1609.01995 author:Martha White category:cs.AI  published:2016-09-07 summary:Reinforcement learning tasks are typically specified as Markov decision processes. This formalism has been highly successful, though specifications often couple the dynamics of the environment and the learning objective. This lack of modularity can complicate generalization of the task specification, as well as obfuscate connections between different task settings, such as episodic and continuing. In this work, we introduce the RL task formalism, that provides a unification through simple constructs including a generalization to transition-based discounting. Through a series of examples, we demonstrate the generality and utility of this formalism. Finally, we extend standard learning constructs, including Bellman operators, and extend some seminal theoretical results, including approximation errors bounds. Overall, we provide a well-understood and sound formalism on which to build theoretical results and simplify algorithm use and development. version:3
arxiv-1707-02292 | Measuring Relations Between Concepts In Conceptual Spaces | http://arxiv.org/abs/1707.02292 | id:1707.02292 author:Lucas Bechberger, Kai-Uwe KÃ¼hnberger category:cs.AI  published:2017-07-07 summary:The highly influential framework of conceptual spaces provides a geometric way of representing knowledge. Instances are represented by points in a high-dimensional space and concepts are represented by regions in this space. Our recent mathematical formalization of this framework is capable of representing correlations between different domains in a geometric way. In this paper, we extend our formalization by providing quantitative mathematical definitions for the notions of concept size, subsethood, implication, similarity, and betweenness. This considerably increases the representational power of our formalization by introducing measurable ways of describing relations between concepts. version:1
arxiv-1707-01873 | Blockchain Consensus Protocols in the Wild | http://arxiv.org/abs/1707.01873 | id:1707.01873 author:Christian Cachin, Marko VukoliÄ category:cs.DC  published:2017-07-06 summary:A blockchain is a distributed ledger for recording transactions, maintained by many nodes without central authority through a distributed cryptographic protocol. All nodes validate the information to be appended to the blockchain, and a consensus protocol ensures that the nodes agree on a unique order in which entries are appended. Consensus protocols for tolerating Byzantine faults have received renewed attention because they also address blockchain systems. This work discusses the process of assessing and gaining confidence in the resilience of a consensus protocols exposed to faults and adversarial nodes. We advocate to follow the established practice in cryptography and computer security, relying on public reviews, detailed models, and formal proofs; the designers of several practical systems appear to be unaware of this. Moreover, we review the consensus protocols in some prominent permissioned blockchain platforms with respect to their fault models and resilience against attacks. The protocol comparison covers Hyperledger Fabric, Tendermint, Symbiont, R3~Corda, Iroha, Kadena, Chain, Quorum, MultiChain, Sawtooth Lake, Ripple, Stellar, and IOTA. version:2
arxiv-1707-02033 | Networked Fairness in Cake Cutting | http://arxiv.org/abs/1707.02033 | id:1707.02033 author:Xiaohui Bei, Youming Qiao, Shengyu Zhang category:cs.DS cs.AI cs.GT  published:2017-07-07 summary:We introduce a graphical framework for fair division in cake cutting, where comparisons between agents are limited by an underlying network structure. We generalize the classical fairness notions of envy-freeness and proportionality to this graphical setting. Given a simple undirected graph G, an allocation is envy-free on G if no agent envies any of her neighbor's share, and is proportional on G if every agent values her own share no less than the average among her neighbors, with respect to her own measure. These generalizations open new research directions in developing simple and efficient algorithms that can produce fair allocations under specific graph structures. On the algorithmic frontier, we first propose a moving-knife algorithm that outputs an envy-free allocation on trees. The algorithm is significantly simpler than the discrete and bounded envy-free algorithm recently designed by Aziz and Mackenzie for complete graphs. Next, we give a discrete and bounded algorithm for computing a proportional allocation on descendant graphs, a class of graphs by taking a rooted tree and connecting all its ancestor-descendant pairs. version:1
arxiv-1707-02032 | Matrix-Based Characterization of the Motion and Wrench Uncertainties in Robotic Manipulators | http://arxiv.org/abs/1707.02032 | id:1707.02032 author:Javad Sovizi, Sonjoy Das, Venkat Krovi category:stat.AP cs.RO  published:2017-07-07 summary:Characterization of the uncertainty in robotic manipulators is the focus of this paper. Based on the random matrix theory (RMT), we propose uncertainty characterization schemes in which the uncertainty is modeled at the macro (system) level. This is different from the traditional approaches that model the uncertainty in the parametric space of micro (state) level. We show that perturbing the system matrices rather than the state of the system provides unique advantages especially for robotic manipulators. First, it requires only limited statistical information that becomes effective when dealing with complex systems where detailed information on their variability is not available. Second, the RMT-based models are aware of the system state and configuration that are significant factors affecting the level of uncertainty in system behavior. In this study, in addition to the motion uncertainty analysis that was first proposed in our earlier work, we also develop an RMT-based model for the quantification of the static wrench uncertainty in multi-agent cooperative systems. This model is aimed to be an alternative to the elaborate parametric formulation when only rough bounds are available on the system parameters. We discuss that how RMT-based model becomes advantageous when the complexity of the system increases. We perform experimental studies on a KUKA youBot arm to demonstrate the superiority of the RMT-based motion uncertainty models. We show that how these models outperform the traditional models built upon Gaussianity assumption in capturing real-system uncertainty and providing accurate bounds on the state estimation errors. In addition, to experimentally support our wrench uncertainty quantification model, we study the behavior of a cooperative system of mobile robots. It is shown that one can rely on less demanding RMT-based formulation and yet meets the acceptable accuracy. version:1
arxiv-1704-03647 | A Component-Based Dual Decomposition Method for the OPF Problem | http://arxiv.org/abs/1704.03647 | id:1704.03647 author:Sleiman Mhanna, Gregor Verbic, Archie Chapman category:cs.DC math.OC  published:2017-04-12 summary:This paper proposes a component-based dual decomposition of the nonconvex AC optimal power flow (OPF) problem, where the modified dual function is solved in a distributed fashion. The main contribution of this work is that is demonstrates that a distributed method with carefully tuned parameters can converge to globally optimal solutions despite the inherent nonconvexity of the problem and the absence of theoretical guarantees of convergence. This paper is the first to conduct extensive numerical analysis resulting in the identification and tabulation of the algorithmic parameter settings that are crucial for the convergence of the method on 72 AC OPF test instances. Moreover, this work provides a deeper insight into the geometry of the modified Lagrange dual function of the OPF problem and highlights the conditions that make this function differentiable. This numerical demonstration of convergence coupled with the scalability and the privacy preserving nature of the proposed method makes it well suited for smart grid applications such as multi-period OPF with demand response (DR) and security constrained unit commitment (SCUC) with contingency constraints and multiple transmission system operators (TSOs). version:7
arxiv-1707-02000 | Shared-memory Graph Truss Decomposition | http://arxiv.org/abs/1707.02000 | id:1707.02000 author:Humayun Kabir, Kamesh Madduri category:cs.DC cs.DS cs.SI  published:2017-07-07 summary:We present PKT, a new shared-memory parallel algorithm and OpenMP implementation for the truss decomposition of large sparse graphs. A k-truss is a dense subgraph definition that can be considered a relaxation of a clique. Truss decomposition refers to a partitioning of all the edges in the graph based on their k-truss membership. The truss decomposition of a graph has many applications. We show that our new approach PKT consistently outperforms other truss decomposition approaches for a collection of large sparse graphs and on a 24-core shared-memory server. PKT is based on a recently proposed algorithm for k-core decomposition. version:1
arxiv-1706-07568 | Predictable Cache Coherence for Multi-Core Real-Time Systems | http://arxiv.org/abs/1706.07568 | id:1706.07568 author:Mohamed Hassan, Anirudh M. Kaushik, Hiren Patel category:cs.AR  published:2017-06-23 summary:This work addresses the challenge of allowing simultaneous and predictable accesses to shared data on multi-core systems. We accomplish this by proposing a predictable cache coherence protocol, which mandates the use of certain invariants to ensure predictability. In particular, we enforce these invariants by augmenting the classic modify-share-invalid (MSI) protocol with transient coherence states, and minimal architectural changes. This allows us to derive worst-case latency bounds on predictable MSI (PMSI) protocol. Our analysis shows that while the arbitration latency scales linearly, the coherence latency scales quadratically with the number of cores. We implement PMSI in gem5, and execute SPLASH-2 and synthetic multi-threaded workloads. Our empirical results show that our approach is always within the analytical worst-case latency bounds, and that PMSI improves average-case performance by up to 4x over the next best predictable alternative. PMSI has average slowdowns of 1.45x and 1.46x compared to conventional MSI and MESI protocols, respectively. version:2
arxiv-1707-01961 | Long-Term Memory Networks for Question Answering | http://arxiv.org/abs/1707.01961 | id:1707.01961 author:Fenglong Ma, Radha Chitta, Saurabh Kataria, Jing Zhou, Palghat Ramesh, Tong Sun, Jing Gao category:cs.CL cs.AI  published:2017-07-06 summary:Question answering is an important and difficult task in the natural language processing domain, because many basic natural language processing tasks can be cast into a question answering task. Several deep neural network architectures have been developed recently, which employ memory and inference components to memorize and reason over text information, and generate answers to questions. However, a major drawback of many such models is that they are capable of only generating single-word answers. In addition, they require large amount of training data to generate accurate answers. In this paper, we introduce the Long-Term Memory Network (LTMN), which incorporates both an external memory module and a Long Short-Term Memory (LSTM) module to comprehend the input data and generate multi-word answers. The LTMN model can be trained end-to-end using back-propagation and requires minimal supervision. We test our model on two synthetic data sets (based on Facebook's bAbI data set) and the real-world Stanford question answering data set, and show that it can achieve state-of-the-art performance. version:1
arxiv-1707-01952 | Significance of Disk Failure Prediction in Datacenters | http://arxiv.org/abs/1707.01952 | id:1707.01952 author:Jayanta Basak, Randy H. Katz category:cs.DC  published:2017-07-06 summary:Modern datacenters assemble a very large number of disk drives under a single roof. Even if economic and technical factors where to make individual drives more reliable (which is not at all clear, given the commoditization of the technology), their sheer numbers combined with their ever increasing utilization in a well-balanced design makes achieving storage reliability a major challenge. In this paper, we assess the challenge of storage system reliability in the modern datacenter, and demonstrate how good disk failure prediction models can significantly improve the reliability of such systems. version:1
arxiv-1707-01891 | Trust-PCL: An Off-Policy Trust Region Method for Continuous Control | http://arxiv.org/abs/1707.01891 | id:1707.01891 author:Ofir Nachum, Mohammad Norouzi, Kelvin Xu, Dale Schuurmans category:cs.AI  published:2017-07-06 summary:Trust region methods, such as TRPO, are often used to stabilize policy optimization algorithms in reinforcement learning (RL). While current trust region strategies are effective for continuous control, they typically require a prohibitively large amount of on-policy interaction with the environment. To address this problem, we propose an off-policy trust region method, Trust-PCL. The algorithm is the result of observing that the optimal policy and state values of a maximum reward objective with a relative-entropy regularizer satisfy a set of multi-step pathwise consistencies along any path. Thus, Trust-PCL is able to maintain optimization stability while exploiting off-policy data to improve sample efficiency. When evaluated on a number of continuous control tasks, Trust-PCL improves the solution quality and sample efficiency of TRPO. version:1
arxiv-1707-01888 | Informed Asymptotically Optimal Anytime Search | http://arxiv.org/abs/1707.01888 | id:1707.01888 author:Jonathan D. Gammell, Timothy D. Barfoot, Siddhartha S. Srinivasa category:cs.RO  published:2017-07-06 summary:Path planning in robotics often requires finding high-quality solutions to continuously valued and/or high-dimensional problems. These problems are challenging and most planning algorithms instead solve simplified approximations. Popular approximations include graphs and random samples, as respectively used by informed graph-based searches and anytime sampling-based planners. Informed graph-based searches, such as A*, traditionally use heuristics to search a priori graphs in order of potential solution quality. This makes their search efficient but leaves their performance dependent on the chosen approximation. If its resolution is too low, they may not find a (suitable) solution but if it is too high, they may take a prohibitively long time to do so. Anytime sampling-based planners, such as RRT*, traditionally use random sampling to approximate the problem domain incrementally. This allows them to increase resolution until a suitable solution is found but makes their search dependent on the random samples. This arbitrary sequence fills the problem domain by expanding the search in every direction and may be prohibitively inefficient at finding a solution. This paper unifies and extends these two approaches to develop Batch Informed Trees (BIT*), an informed, anytime sampling-based planner. BIT* solves continuous planning problems efficiently by using sampling and heuristics to alternately approximate and search the problem domain. Its search is ordered by potential solution quality, as in A*, and its approximation improves indefinitely with additional computational time, as in RRT*. It is shown analytically to be almost-surely asymptotically optimal and experimentally to outperform existing sampling-based planners, especially on high-dimensional planning problems. version:1
arxiv-1706-08439 | Optimal choice: new machine learning problem and its solution | http://arxiv.org/abs/1706.08439 | id:1706.08439 author:Marina Sapir category:cs.AI  published:2017-06-26 summary:The task of learning to pick a single preferred example out a finite set of examples, an "optimal choice problem", is a supervised machine learning problem with complex, structured input. Problems of optimal choice emerge often in various practical applications. We formalize the problem, show that it does not satisfy the assumptions of statistical learning theory, yet it can be solved efficiently in some cases. We propose two approaches to solve the problem. Both of them reach good solutions on real life data from a signal processing application. version:2
arxiv-1707-01869 | A Survey on Geographically Distributed Big-Data Processing using MapReduce | http://arxiv.org/abs/1707.01869 | id:1707.01869 author:Shlomi Dolev, Patricia Florissi, Ehud Gudes, Shantanu Sharma, Ido Singer category:cs.DB cs.DC  published:2017-07-06 summary:Hadoop and Spark are widely used distributed processing frameworks for large-scale data processing in an efficient and fault-tolerant manner on private or public clouds. These big-data processing systems are extensively used by many industries, e.g., Google, Facebook, and Amazon, for solving a large class of problems, e.g., search, clustering, log analysis, different types of join operations, matrix multiplication, pattern matching, and social network analysis. However, all these popular systems have a major drawback in terms of locally distributed computations, which prevent them in implementing geographically distributed data processing. The increasing amount of geographically distributed massive data is pushing industries and academia to rethink the current big-data processing systems. The novel frameworks, which will be beyond state-of-the-art architectures and technologies involved in the current system, are expected to process geographically distributed data at their locations without moving entire raw datasets to a single location. In this paper, we investigate and discuss challenges and requirements in designing geographically distributed data processing frameworks and protocols. We classify and study batch processing (MapReduce-based systems), stream processing (Spark-based systems), and SQL-style processing geo-distributed frameworks, models, and algorithms with their overhead issues. version:1
arxiv-1705-02426 | Analogical Inference for Multi-Relational Embeddings | http://arxiv.org/abs/1705.02426 | id:1705.02426 author:Hanxiao Liu, Yuexin Wu, Yiming Yang category:cs.LG cs.AI cs.CL  published:2017-05-06 summary:Large-scale multi-relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs. An effective and scalable solution for this problem is crucial for the true success of knowledge-based inference in a broad range of applications. This paper proposes a novel framework for optimizing the latent representations with respect to the \textit{analogical} properties of the embedded entities and relations. By formulating the learning objective in a differentiable fashion, our model enjoys both theoretical power and computational scalability, and significantly outperformed a large number of representative baseline methods on benchmark datasets. Furthermore, the model offers an elegant unification of several well-known methods in multi-relational embedding, which can be proven to be special instantiations of our framework. version:2
arxiv-1703-03512 | Real-time Perception meets Reactive Motion Generation | http://arxiv.org/abs/1703.03512 | id:1703.03512 author:Daniel Kappler, Franziska Meier, Jan Issac, Jim Mainprice, Cristina Garcia Cifuentes, Manuel WÃ¼thrich, Vincent Berenz, Stefan Schaal, Nathan Ratliff, Jeannette Bohg category:cs.RO  published:2017-03-10 summary:We address the challenging problem of robotic grasping and manipulation in the presence of uncertainty. This uncertainty is due to noisy sensing, inaccurate models and hard-to-predict environment dynamics. Our approach emphasizes the importance of continuous, real-time perception and its tight integration with reactive motion generation methods. We present a fully integrated system where real-time object and robot tracking as well as ambient world modeling provides the necessary input to feedback controllers and continuous motion optimizers. Specifically, they provide attractive and repulsive potentials based on which the controllers and motion optimizer can online compute movement policies over different time horizons. We extensively evaluate the proposed system on a real robotic platform in four scenarios that exhibit either challenging workspace geometry or a dynamic environment. We compare the proposed integrated system with a more traditional sense-plan-act approach that is still widely used and to a myopic controller that only reacts to local environment dynamics. In 333 experiments, we show the robustness and accuracy of the proposed system as compared to alternative system architectures. version:2
arxiv-1707-01788 | Embodied Flight with a Drone | http://arxiv.org/abs/1707.01788 | id:1707.01788 author:Alexandre Cherpillod, Stefano Mintchev, Dario Floreano category:cs.RO  published:2017-07-06 summary:Most human-robot interfaces, such as joysticks and keyboards, require training and constant cognitive effort and provide a limited degree of awareness of the robots state and its environment. Embodied interactions, instead of interfaces, could bridge the gap between humans and robots, allowing humans to naturally perceive and act through a distal robotic body. Establishing an embodied interaction and mapping human movements and a non-anthropomorphic robot is particularly challenging. In this paper, we describe a natural and immersive embodied interaction that allows users to control and experience drone flight with their own bodies. The setup uses a commercial flight simulator that tracks hand movements and provides haptic and visual feedback. The paper discusses how to integrate the simulator with a real drone, how to map body movement with drone motion, and how the resulting embodied interaction provides a more natural and immersive flight experience to unskilled users with respect to a conventional RC remote controller. version:1
arxiv-1701-05463 | Proving Linearizability Using Partial Orders (Extended Version) | http://arxiv.org/abs/1701.05463 | id:1701.05463 author:Artem Khyzha, Mike Dodds, Alexey Gotsman, Matthew Parkinson category:cs.PL cs.DC cs.LO  published:2017-01-19 summary:Linearizability is the commonly accepted notion of correctness for concurrent data structures. It requires that any execution of the data structure is justified by a linearization --- a linear order on operations satisfying the data structure's sequential specification. Proving linearizability is often challenging because an operation's position in the linearization order may depend on future operations. This makes it very difficult to incrementally construct the linearization in a proof. We propose a new proof method that can handle data structures with such future-dependent linearizations. Our key idea is to incrementally construct not a single linear order of operations, but a partial order that describes multiple linearizations satisfying the sequential specification. This allows decisions about the ordering of operations to be delayed, mirroring the behaviour of data structure implementations. We formalise our method as a program logic based on rely-guarantee reasoning, and demonstrate its effectiveness by verifying several challenging data structures: the Herlihy-Wing queue, the TS queue and the Optimistic set. version:4
arxiv-1707-01736 | Cross-linguistic differences and similarities in image descriptions | http://arxiv.org/abs/1707.01736 | id:1707.01736 author:Emiel van Miltenburg, Desmond Elliott, Piek Vossen category:cs.CL cs.AI cs.CV  published:2017-07-06 summary:Automatic image description systems are commonly trained and evaluated on large image description datasets. Recently, researchers have started to collect such datasets for languages other than English. An unexplored question is how different these datasets are from English and, if there are any differences, what causes them to differ. This paper provides a cross-linguistic comparison of Dutch, English, and German image descriptions. We find that these descriptions are similar in many respects, but the familiarity of crowd workers with the subjects of the images has a noticeable influence on the specificity of the descriptions. version:1
arxiv-1707-01727 | Application of Fuzzy Assessing for Reliability Decision Making | http://arxiv.org/abs/1707.01727 | id:1707.01727 author:Shoele Jamali, Mehrdad J. Bani category:cs.AI  published:2017-07-06 summary:This paper proposes a new fuzzy assessing procedure with application in management decision making. The proposed fuzzy approach build the membership functions for system characteristics of a standby repairable system. This method is used to extract a family of conventional crisp intervals from the fuzzy repairable system for the desired system characteristics. This can be determined with a set of nonlinear parametric programing using the membership functions. When system characteristics are governed by the membership functions, more information is provided for use by management, and because the redundant system is extended to the fuzzy environment, general repairable systems are represented more accurately and the analytic results are more useful for designers and practitioners. Also beside standby, active redundancy systems are used in many cases so this article has many practical instances. Different from other studies, our model provides, a good estimated value based on uncertain environments, a comparison discussion of using fuzzy theory and conventional method and also a comparison between parallel (active redundancy) and series system in fuzzy world when we have standby redundancy. When the membership function intervals cannot be inverted explicitly, system management or designers can specify the system characteristics of interest, perform numerical calculations, examine the corresponding {\alpha}-cuts, and use this information to develop or improve system processes. version:1
arxiv-1707-01700 | CNN features are also great at unsupervised classification | http://arxiv.org/abs/1707.01700 | id:1707.01700 author:Joris GuÃ©rin, Olivier Gibaru, StÃ©phane Thiery, Eric Nyiri category:cs.CV cs.AI cs.LG  published:2017-07-06 summary:This paper aims at providing insight on the transferability of deep CNN features to unsupervised problems. We study the impact of different pretrained CNN feature extractors on the problem of image set clustering for object classification as well as fine-grained classification. We propose a rather straightforward pipeline combining deep-feature extraction using a CNN pretrained on ImageNet and a classic clustering algorithm to classify sets of images. This approach is compared to state-of-the-art algorithms in image-clustering and provides better results. These results strengthen the belief that supervised training of deep CNN on large datasets, with a large variability of classes, extracts better features than most carefully designed engineering approaches, even for unsupervised tasks. We also validate our approach on a robotic application, consisting in sorting and storing objects smartly based on clustering. version:1
arxiv-1707-01697 | Pipelined Parallel FFT Architecture | http://arxiv.org/abs/1707.01697 | id:1707.01697 author:Tanaji U. Kamble, B. G. Patil, Rakhee S. Bhojakar category:cs.AR math.OC  published:2017-07-06 summary:In this paper, an optimized efficient VLSI architecture of a pipeline Fast Fourier transform (FFT) processor capable of producing the reverse output order sequence is presented. Paper presents Radix-2 multipath delay architecture for FFT calculation. The implementation of FFT in hardware is very critical because for calculation of FFT number of butterfly operations i.e. number of multipliers requires due to which hardware gets increased means indirectly cost of hardware is automatically gets increased. Also multiplier operations are slow that's why it limits the speed of operation of architecture. The optimized VLSI implementation of FFT algorithm is presented in this paper. Here architecture is pipelined to optimize it and to increase the speed of operation. Also to increase the speed of operation 2 levels parallel processing is used. version:1
arxiv-1707-01696 | Generalized Task-Parameterized Movement Primitives | http://arxiv.org/abs/1707.01696 | id:1707.01696 author:Yanlong Huang, JoÃ£o SilvÃ©rio, Leonel Rozo, Darwin G. Caldwell category:cs.RO  published:2017-07-06 summary:Programming by demonstrations has recently gained much attention due to its user-friendly and natural way to transfer human skills to robots. In order to facilitate the learning of multiple demonstrations and meanwhile generalize to new situations, a task-parameterized movement learning has been recently developed [4], which has achieved reliable performance in areas such as human-robot collaboration and robot bimanual operation. However, the crucial task frames and associated task parameters in this learning framework are often set based on human experience, which renders three problems that have not been addressed yet: (i) task frames are treated equally without considering the task priorities; (ii) task parameters are defined without considering additional task constraints, e.g., robot joint limits and motion smoothness; (iii) a fixed number of task frames are pre-defined regardless some of them are redundant or even irrelevant for the task at hand. In this paper, we generalize the task-parameterized learning by addressing the aforementioned problems. Moreover, we provide an alternative way to refine and adapt previously learned robot skills, which allows us to work on a low dimensional space. Several examples are studied in simulated and real robotic systems, showing the applicability of our approach. version:1
arxiv-1707-01655 | Online Job Scheduling with Redundancy and Opportunistic Checkpointing: A Speedup-Function-Based Analysis | http://arxiv.org/abs/1707.01655 | id:1707.01655 author:Huanle Xu, Gustavo de Veciana, Wing Cheong Lau, Kunxiao Zhou category:cs.DC  published:2017-07-06 summary:In a large-scale computing cluster, the job completions can be substantially delayed due to two sources of variability, namely, variability in the job size and that in the machine service capacity. To tackle this issue, existing works have proposed various scheduling algorithms which exploit redundancy wherein a job runs on multiple servers until the first completes. In this paper, we explore the impact of variability in the machine service capacity and adopt a rigorous analytical approach to design scheduling algorithms using redundancy and checkpointing. We design several online scheduling algorithms which can dynamically vary the number of redundant copies for jobs. We also provide new theoretical performance bounds for these algorithms in terms of the overall job flowtime by introducing the notion of a speedup function, based on which a novel potential function can be defined to enable the corresponding competitive ratio analysis. In particular, by adopting the online primal-dual fitting approach, we prove that our SRPT+R Algorithm in a non-multitasking cluster is $(1+\epsilon)$-speed, $\ O(\frac{1}{\epsilon})$-competitive. We also show that our proposed Fair+R and LAPS+R($\beta$) Algorithms for a multitasking cluster are $(4+\epsilon)$-speed, $\ O(\frac{1}{\epsilon})$-competitive and {($2 + 2\beta + 2\epsilon)$-speed $O(\frac{1}{\beta \epsilon})$-competitive} respectively. We demonstrate via extensive simulations that our proposed algorithms can significantly reduce job flowtime under both the non-multitasking and multitasking modes. version:1
arxiv-1707-01647 | Convergence Analysis of Optimization Algorithms | http://arxiv.org/abs/1707.01647 | id:1707.01647 author:HyoungSeok Kim, JiHoon Kang, WooMyoung Park, SukHyun Ko, YoonHo Cho, DaeSung Yu, YoungSook Song, JungWon Choi category:stat.ML cs.AI cs.LG math.OC  published:2017-07-06 summary:The regret bound of an optimization algorithms is one of the basic criteria for evaluating the performance of the given algorithm. By inspecting the differences between the regret bounds of traditional algorithms and adaptive one, we provide a guide for choosing an optimizer with respect to the given data set and the loss function. For analysis, we assume that the loss function is convex and its gradient is Lipschitz continuous. version:1
arxiv-1703-06680 | Parallel Sort-Based Matching for Data Distribution Management on Shared-Memory Multiprocessors | http://arxiv.org/abs/1703.06680 | id:1703.06680 author:Moreno Marzolla, Gabriele D'Angelo category:cs.DC cs.DS cs.MA  published:2017-03-20 summary:In this paper we consider the problem of identifying intersections between two sets of d-dimensional axis-parallel rectangles. This is a common problem that arises in many agent-based simulation studies, and is of central importance in the context of High Level Architecture (HLA), where it is at the core of the Data Distribution Management (DDM) service. Several realizations of the DDM service have been proposed; however, many of them are either inefficient or inherently sequential. These are serious limitations since multicore processors are now ubiquitous, and DDM algorithms -- being CPU-intensive -- could benefit from additional computing power. We propose a parallel version of the Sort-Based Matching algorithm for shared-memory multiprocessors. Sort-Based Matching is one of the most efficient serial algorithms for the DDM problem, but is quite difficult to parallelize due to data dependencies. We describe the algorithm and compute its asymptotic running time; we complete the analysis by assessing its performance and scalability through extensive experiments on two commodity multicore systems based on a dual socket Intel Xeon processor, and a single socket Intel Core i7 processor. version:2
arxiv-1707-01625 | Optimal Vehicle Dispatching Schemes via Dynamic Pricing | http://arxiv.org/abs/1707.01625 | id:1707.01625 author:Mengjing Chen, Weiran Shen, Pingzhong Tang, Song Zuo category:cs.SY cs.AI cs.GT  published:2017-07-06 summary:Recently, shared mobility has been proven to be an effective way to relieve urban traffic congestion and reduce energy consumption. Despite the emergence of several nationwide platforms, the pricing schemes and the vehicle dispatching problem of such platforms are optimized in an ad hoc manner. In this paper, we introduce a general framework that incorporates geographic information and time-sensitive dynamic environment parameters (such as the dynamically changing demand) and models the pricing and dispatching problem as a Markov Decision Process with continuous state and action spaces. Despite of the PSPACE-hardness of general MDPs, we provide efficient algorithms finding the exact revenue (or welfare) optimal (potentially randomized) pricing schemes. We also characterize the optimal solution via primal-dual analysis of a convex program. Finally, we also discuss generalizing our model by showing how to reduce a wide range of general settings in practice to our model. version:1
arxiv-1706-08627 | SUNNY-CP and the MiniZinc Challenge | http://arxiv.org/abs/1706.08627 | id:1706.08627 author:Roberto Amadini, Maurizio Gabbrielli, Jacopo Mauro category:cs.AI  published:2017-06-26 summary:In Constraint Programming (CP) a portfolio solver combines a variety of different constraint solvers for solving a given problem. This fairly recent approach enables to significantly boost the performance of single solvers, especially when multicore architectures are exploited. In this work we give a brief overview of the portfolio solver sunny-cp, and we discuss its performance in the MiniZinc Challenge---the annual international competition for CP solvers---where it won two gold medals in 2015 and 2016. Under consideration in Theory and Practice of Logic Programming (TPLP) version:3
arxiv-1703-02920 | Multi-GPU maximum entropy image synthesis for radio astronomy | http://arxiv.org/abs/1703.02920 | id:1703.02920 author:M. CÃ¡rcamo, P. RomÃ¡n, S. Casassus, V. Moral, F. R. Rannou category:astro-ph.IM cs.DC  published:2017-03-08 summary:The maximum entropy method (MEM) is a well known deconvolution technique in radio-interferometry. This method solves a non-linear optimization problem with an entropy regularization term. Other heuristics such as CLEAN are faster but highly user dependent. Nevertheless, MEM has the following advantages: it is unsupervised, it has an statistical basis, it has a better resolution and better image quality under certain conditions. This work presents a high performance GPU version of non-gridded MEM, which is tested using interferometric and simulated data. We propose a single-GPU and a multi-GPU implementation for single and multi-spectral data, respectively. We also make use of the Peer-to-Peer and Unified Virtual Addressing features of newer GPUs which allows to exploit transparently and efficiently multiple GPUs. Several ALMA data sets are used to demonstrate the effectiveness in imaging and to evaluate GPU performance. The results show that a speedup from 1000 to 5000 times faster than a sequential version can be achieved, depending on data and image size. This has allowed us to reconstruct the HD142527 CO(6-5) short baseline data set in 2.1 minutes, instead of the 2.5 days that takes on CPU. version:2
arxiv-1707-01555 | A Deep Network with Visual Text Composition Behavior | http://arxiv.org/abs/1707.01555 | id:1707.01555 author:Hongyu Guo category:cs.CL cs.AI cs.NE  published:2017-07-05 summary:While natural languages are compositional, how state-of-the-art neural models achieve compositionality is still unclear. We propose a deep network, which not only achieves competitive accuracy for text classification, but also exhibits compositional behavior. That is, while creating hierarchical representations of a piece of text, such as a sentence, the lower layers of the network distribute their layer-specific attention weights to individual words. In contrast, the higher layers compose meaningful phrases and clauses, whose lengths increase as the networks get deeper until fully composing the sentence. version:1
arxiv-1707-01550 | Information-gain computation | http://arxiv.org/abs/1707.01550 | id:1707.01550 author:Anthony Di Franco category:cs.PL cs.AI cs.IT math.IT  published:2017-07-05 summary:Despite large incentives, correctness in software remains an elusive goal. Declarative programming techniques, where algorithms are derived from a specification of the desired behavior, offer hope to address this problem, since there is a combinatorial reduction in complexity in programming in terms of specifications instead of algorithms, and arbitrary desired properties can be expressed and enforced in specifications directly. However, limitations on performance have prevented programming with declarative specifications from becoming a mainstream technique for general-purpose programming. To address the performance bottleneck in deriving an algorithm from a specification, I propose information-gain computation, a framework where an adaptive evaluation strategy is used to efficiently perform a search which derives algorithms that provide information about a query most directly. Within this framework, opportunities to compress the search space present themselves, which suggest that information-theoretic bounds on the performance of such a system might be articulated and a system designed to achieve them. In a preliminary empirical study of adaptive evaluation for a simple test program, the evaluation strategy adapts successfully to evaluate a query efficiently. version:1
arxiv-1707-00724 | Efficient Probabilistic Performance Bounds for Inverse Reinforcement Learning | http://arxiv.org/abs/1707.00724 | id:1707.00724 author:Daniel S. Brown, Scott Niekum category:cs.AI cs.LG stat.ML  published:2017-07-03 summary:In the field of reinforcement learning there has been recent progress towards safety and high-confidence bounds on policy performance. However, to our knowledge, no methods exist for determining high-confidence safety bounds for a given evaluation policy in the inverse reinforcement learning setting---where the true reward function is unknown and only samples of expert behavior are given. We propose a method based on Bayesian Inverse Reinforcement Learning that uses demonstrations to determine practical high-confidence bounds on the difference in expected return between any evaluation policy and the expert's underlying policy. A sampling-based approach is used to obtain probabilistic confidence bounds using the financial Value at Risk metric. We empirically evaluate our proposed bound on a standard navigation task for a wide variety of ground truth reward functions. Empirical results demonstrate that our proposed bound provides significant improvements over a standard feature count-based approach: providing accurate, tight bounds even for small numbers of noisy demonstrations. version:2
arxiv-1707-01532 | Gaussian Processes Semantic Map Representation | http://arxiv.org/abs/1707.01532 | id:1707.01532 author:Maani Ghaffari Jadidi, Lu Gan, Steven A. Parkison, Jie Li, Ryan M. Eustice category:cs.RO  published:2017-07-05 summary:In this paper, we develop a high-dimensional map building technique that incorporates raw pixelated semantic measurements into the map representation. The proposed technique uses Gaussian Processes (GPs) multi-class classification for map inference and is the natural extension of GP occupancy maps from binary to multi-class form. The technique exploits the continuous property of GPs and, as a result, the map can be inferred with any resolution. In addition, the proposed GP Semantic Map (GPSM) learns the structural and semantic correlation from measurements rather than resorting to assumptions, and can flexibly learn the spatial correlation as well as any additional non-spatial correlation between map points. We extend the OctoMap to Semantic OctoMap representation and compare with the GPSM mapping performance using NYU Depth V2 dataset. Evaluations of the proposed technique on multiple partially labeled RGBD scans and labels from noisy image segmentation show that the GP semantic map can handle sparse measurements, missing labels in the point cloud, as well as noise corrupted labels. version:1
arxiv-1707-01489 | Creative Robot Dance with Variational Encoder | http://arxiv.org/abs/1707.01489 | id:1707.01489 author:Agnese Augello, Emanuele Cipolla, Ignazio Infantino, Adriano Manfre, Giovanni Pilato, Filippo Vella category:cs.AI  published:2017-07-05 summary:What we appreciate in dance is the ability of people to sponta- neously improvise new movements and choreographies, sur- rendering to the music rhythm, being inspired by the cur- rent perceptions and sensations and by previous experiences, deeply stored in their memory. Like other human abilities, this, of course, is challenging to reproduce in an artificial entity such as a robot. Recent generations of anthropomor- phic robots, the so-called humanoids, however, exhibit more and more sophisticated skills and raised the interest in robotic communities to design and experiment systems devoted to automatic dance generation. In this work, we highlight the importance to model a computational creativity behavior in dancing robots to avoid a mere execution of preprogrammed dances. In particular, we exploit a deep learning approach that allows a robot to generate in real time new dancing move- ments according to to the listened music. version:1
arxiv-1707-01450 | The Complex Negotiation Dialogue Game | http://arxiv.org/abs/1707.01450 | id:1707.01450 author:Romain Laroche category:cs.AI cs.CL  published:2017-07-05 summary:This position paper formalises an abstract model for complex negotiation dialogue. This model is to be used for the benchmark of optimisation algorithms ranging from Reinforcement Learning to Stochastic Games, through Transfer Learning, One-Shot Learning or others. version:1
arxiv-1707-01428 | SHADHO: Massively Scalable Hardware-Aware Distributed Hyperparameter Optimization | http://arxiv.org/abs/1707.01428 | id:1707.01428 author:Jeff Kinnison, Nathaniel Kremer-Herman, Douglas Thain, Walter Scheirer category:cs.LG cs.DC  published:2017-07-05 summary:Computer science is experiencing an AI renaissance, in which machine learning models are expediting important breakthroughs in academic research and commercial applications. Effective training of these models, however, is not trivial due in part to hyperparameters: user-configured values that parametrize learning models and control their ability to learn from data. Existing hyperparameter optimization methods are highly parallel but make no effort to balance the search across heterogeneous hardware or to prioritize searching high-impact spaces. In this paper, we introduce a framework for massively Scalable Hardware-Aware Distributed Hyperparameter Optimization (SHADHO). Our framework calculates the relative complexity of each search space and monitors performance on the learning task over all trials. These metrics are then used as heuristics to assign hyperparameters to distributed workers based on their hardware. We demonstrate that our framework scales to 1400 heterogeneous cores and that it achieves a factor of 1.6 speedup in the necessary time to find an optimal set of hyperparameters over a standard distributed hyperparameter optimization framework. version:1
arxiv-1707-01423 | Model enumeration in propositional circumscription via unsatisfiable core analysis | http://arxiv.org/abs/1707.01423 | id:1707.01423 author:Mario Alviano category:cs.AI 68T30 F.4.1  published:2017-07-05 summary:Many practical problems are characterized by a preference relation over admissible solutions, where preferred solutions are minimal in some sense. For example, a preferred diagnosis usually comprises a minimal set of reasons that is sufficient to cause the observed anomaly. Alternatively, a minimal correction subset comprises a minimal set of reasons whose deletion is sufficient to eliminate the observed anomaly. Circumscription formalizes such preference relations by associating propositional theories with minimal models. The resulting enumeration problem is addressed here by means of a new algorithm taking advantage of unsatisfiable core analysis. Empirical evidence of the efficiency of the algorithm is given by comparing the performance of the resulting solver, CIRCUMSCRIPTINO, with HCLASP, CAMUS MCS, LBX and MCSLS on the enumeration of minimal models for problems originating from practical applications. This paper is under consideration for acceptance in TPLP. version:1
arxiv-1707-01415 | Machine Learning, Deepest Learning: Statistical Data Assimilation Problems | http://arxiv.org/abs/1707.01415 | id:1707.01415 author:Henry Abarbanel, Paul Rozdeba, Sasha Shirman category:cs.AI  published:2017-07-05 summary:We formulate a strong equivalence between machine learning, artificial intelligence methods and the formulation of statistical data assimilation as used widely in physical and biological sciences. The correspondence is that layer number in the artificial network setting is the analog of time in the data assimilation setting. Within the discussion of this equivalence we show that adding more layers (making the network deeper) is analogous to adding temporal resolution in a data assimilation framework. How one can find a candidate for the global minimum of the cost functions in the machine learning context using a method from data assimilation is discussed. Calculations on simple models from each side of the equivalence are reported. Also discussed is a framework in which the time or layer label is taken to be continuous, providing a differential equation, the Euler-Lagrange equation, which shows that the problem being solved is a two point boundary value problem familiar in the discussion of variational methods. The use of continuous layers is denoted "deepest learning". These problems respect a symplectic symmetry in continuous time/layer phase space. Both Lagrangian versions and Hamiltonian versions of these problems are presented. Their well-studied implementation in a discrete time/layer, while respected the symplectic structure, is addressed. The Hamiltonian version provides a direct rationale for back propagation as a solution method for the canonical momentum. version:1
arxiv-1707-01357 | Improving Content-Invariance in Gated Autoencoders for 2D and 3D Object Rotation | http://arxiv.org/abs/1707.01357 | id:1707.01357 author:Stefan Lattner, Maarten Grachten category:cs.CV cs.AI cs.LG cs.NE  published:2017-07-05 summary:Content-invariance in mapping codes learned by GAEs is a useful feature for various relation learning tasks. In this paper we show that the content-invariance of mapping codes for images of 2D and 3D rotated objects can be substantially improved by extending the standard GAE loss (symmetric reconstruction error) with a regularization term that penalizes the symmetric cross-reconstruction error. This error term involves reconstruction of pairs with mapping codes obtained from other pairs exhibiting similar transformations. Although this would principally require knowledge of the transformations exhibited by training pairs, our experiments show that a bootstrapping approach can sidestep this issue, and that the regularization term can effectively be used in an unsupervised setting. version:1
arxiv-1705-01040 | Maximum Resilience of Artificial Neural Networks | http://arxiv.org/abs/1705.01040 | id:1705.01040 author:Chih-Hong Cheng, Georg NÃ¼hrenberg, Harald Ruess category:cs.LG cs.AI cs.LO cs.SE  published:2017-04-28 summary:The deployment of Artificial Neural Networks (ANNs) in safety-critical applications poses a number of new verification and certification challenges. In particular, for ANN-enabled self-driving vehicles it is important to establish properties about the resilience of ANNs to noisy or even maliciously manipulated sensory input. We are addressing these challenges by defining resilience properties of ANN-based classifiers as the maximal amount of input or sensor perturbation which is still tolerated. This problem of computing maximal perturbation bounds for ANNs is then reduced to solving mixed integer optimization problems (MIP). A number of MIP encoding heuristics are developed for drastically reducing MIP-solver runtimes, and using parallelization of MIP-solvers results in an almost linear speed-up in the number (up to a certain limit) of computing cores in our experiments. We demonstrate the effectiveness and scalability of our approach by means of computing maximal resilience bounds for a number of ANN benchmark sets ranging from typical image recognition scenarios to the autonomous maneuvering of robots. version:2
arxiv-1707-01310 | Learning to Design Games: Strategic Environments in Deep Reinforcement Learning | http://arxiv.org/abs/1707.01310 | id:1707.01310 author:Haifeng Zhang, Jun Wang, Zhiming Zhou, Weinan Zhang, Ying Wen, Yong Yu, Wenxin Li category:cs.AI  published:2017-07-05 summary:In typical reinforcement learning (RL), the environment is assumed given and the goal of the learning is to identify an optimal policy for the agent taking actions through its interactions with the environment. In this paper, we extend this setting by considering the environment is not given, but controllable and learnable through its interaction with the agent at the same time. Theoretically, we find a dual Markov decision process (MDP) w.r.t. the environment to that w.r.t. the agent, and solving the dual MDP-policy pair yields a policy gradient solution to optimizing the parametrized environment. Furthermore, environments with non-differentiable parameters are addressed by a proposed general generative framework. Experiments on a Maze generation task show the effectiveness of generating diverse and challenging Mazes against agents with various settings. version:1
arxiv-1707-01283 | SADA: A General Framework to Support Robust Causation Discovery with Theoretical Guarantee | http://arxiv.org/abs/1707.01283 | id:1707.01283 author:Ruichu Cai, Zhenjie Zhang, Zhifeng Hao category:cs.AI  published:2017-07-05 summary:Causation discovery without manipulation is considered a crucial problem to a variety of applications. The state-of-the-art solutions are applicable only when large numbers of samples are available or the problem domain is sufficiently small. Motivated by the observations of the local sparsity properties on causal structures, we propose a general Split-and-Merge framework, named SADA, to enhance the scalability of a wide class of causation discovery algorithms. In SADA, the variables are partitioned into subsets, by finding causal cut on the sparse causal structure over the variables. By running mainstream causation discovery algorithms as basic causal solvers on the subproblems, complete causal structure can be reconstructed by combining the partial results. SADA benefits from the recursive division technique, since each small subproblem generates more accurate result under the same number of samples. We theoretically prove that SADA always reduces the scales of problems without sacrifice on accuracy, under the condition of local causal sparsity and reliable conditional independence tests. We also present sufficient condition to accuracy enhancement by SADA, even when the conditional independence tests are vulnerable. Extensive experiments on both simulated and real-world datasets verify the improvements on scalability and accuracy by applying SADA together with existing causation discovery algorithms. version:1
arxiv-1706-09520 | Neural SLAM | http://arxiv.org/abs/1706.09520 | id:1706.09520 author:Jingwei Zhang, Lei Tai, Joschka Boedecker, Wolfram Burgard, Ming Liu category:cs.LG cs.AI cs.RO  published:2017-06-29 summary:We present an approach for agents to learn representations of a global map from sensor data, to aid their exploration in new environments. To achieve this, we embed procedures mimicking that of traditional Simultaneous Localization and Mapping (SLAM) into the soft attention based addressing of external memory architectures, in which the external memory acts as an internal representation of the environment. This structure encourages the evolution of SLAM-like behaviors inside a completely differentiable deep neural network. We show that this approach can help reinforcement learning agents to successfully explore new environments where long-term memory is essential. We validate our approach in both challenging grid-world environments and preliminary Gazebo experiments. A video of our experiments can be found at: https://goo.gl/RfiSxo. version:4
arxiv-1707-01941 | MPG - A Framework for Reasoning on 6 DOF Pose Uncertainty | http://arxiv.org/abs/1707.01941 | id:1707.01941 author:Wendelin Feiten, Muriel Lang category:cs.RO  published:2017-07-05 summary:Reasoning about the pose, i.e. position and orientation of objects is one of the cornerstones of robotic manipulation under uncertainty. In a number of joint research projects our group is developing a robotic perception system that perceives and models an unprepared kitchen scenario with many objects. Since no single sensor or measurement provides sufficient information, a technique is needed to fuse a number of uncertain estimates of the pose, i.e. estimates with a widely stretched probability density function ($pdf$). The most frequently used approaches to describe the $pdfs$ are sample based description and multivariate normal (Gaussian) distributions. Sample based descriptions in 6D can describe basically any type of $pdfs$, but they require a large number of samples and there are no analytic formulae to fuse several $pdfs$. For Gaussian distributions these formulae exist, but the Gaussian distributions are unimodal and don't model widely spread distributions well. In this paper we present a framework for probabilistic modeling of 6D poses that combines the expressive power of the sample based description with the conciseness and algorithmic power of the Gaussian models. As parameterization of the 6D poses we select the dual quaternions, i.e. any pose is represented by two quaternions. The orientation part of a pose is described by a unit quaternion. The translation part is described by a purely imaginary quaternion. A basic probability density function over the poses is constructed by selecting a tangent point on the 3D sphere representing unit quaternions and taking the Cartesian set product of the tangent space with the 3D space of translations. In this 6D Euclidean space a 6D Gaussian distribution is defined. Projecting this Gaussian back to the unit sphere and renormalizing induces a distribution over 6D poses, called a Projected Gaussian. version:1
arxiv-1707-00130 | Sample-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management | http://arxiv.org/abs/1707.00130 | id:1707.00130 author:Pei-Hao Su, Pawel Budzianowski, Stefan Ultes, Milica Gasic, Steve Young category:cs.CL cs.AI cs.LG  published:2017-07-01 summary:Deep reinforcement learning (RL) methods have significant potential for dialogue policy optimisation. However, they suffer from a poor performance in the early stages of learning. This is especially problematic for on-line learning with real users. Two approaches are introduced to tackle this problem. Firstly, to speed up the learning process, two sample-efficient neural networks algorithms: trust region actor-critic with experience replay (TRACER) and episodic natural actor-critic with experience replay (eNACER) are presented. For TRACER, the trust region helps to control the learning step size and avoid catastrophic model changes. For eNACER, the natural gradient identifies the steepest ascent direction in policy space to speed up the convergence. Both models employ off-policy learning with experience replay to improve sample-efficiency. Secondly, to mitigate the cold start issue, a corpus of demonstration data is utilised to pre-train the models prior to on-line reinforcement learning. Combining these two approaches, we demonstrate a practical approach to learn deep RL-based dialogue policies and demonstrate their effectiveness in a task-oriented information seeking domain. version:2
arxiv-1707-01250 | Graph Based Recommendations: From Data Representation to Feature Extraction and Application | http://arxiv.org/abs/1707.01250 | id:1707.01250 author:Amit Tiroshi, Tsvi Kuflik, Shlomo Berkovsky, Mohamed Ali Kaafar category:cs.IR cs.AI cs.LG  published:2017-07-05 summary:Modeling users for the purpose of identifying their preferences and then personalizing services on the basis of these models is a complex task, primarily due to the need to take into consideration various explicit and implicit signals, missing or uncertain information, contextual aspects, and more. In this study, a novel generic approach for uncovering latent preference patterns from user data is proposed and evaluated. The approach relies on representing the data using graphs, and then systematically extracting graph-based features and using them to enrich the original user models. The extracted features encapsulate complex relationships between users, items, and metadata. The enhanced user models can then serve as an input to any recommendation algorithm. The proposed approach is domain-independent (demonstrated on data from movies, music, and business recommender systems), and is evaluated using several state-of-the-art machine learning methods, on different recommendation tasks, and using different evaluation metrics. The results show a unanimous improvement in the recommendation accuracy across tasks and domains. In addition, the evaluation provides a deeper analysis regarding the performance of the approach in special scenarios, including high sparsity and variability of ratings. version:1
arxiv-1706-03930 | Item Difficulty-Based Label Aggregation Models for Crowdsourcing | http://arxiv.org/abs/1706.03930 | id:1706.03930 author:Chi Hong category:cs.AI cs.HC cs.LG  published:2017-06-13 summary:A large amount of labeled data is required for supervised learning. However, labeling by domain experts is expensive and time-consuming. A low cost and high efficiency way to obtain large training datasets is to aggregate noisy labels collected from non-professional crowds. Prior works have proposed confusion matrices to evaluate the reliability of workers. In this paper, we redefine the structure of the confusion matrices and propose generative probabilistic models which utilize item difficulty in label aggregation. We assume that labels are generated by a probability distribution over confusion matrices, item difficulties, labels and true labels. We use Markov chain Monte Carlo method to perform the parameter estimation. We also derive a novel variational inference algorithm to perform the posterior inference. To avoid bad local optima, we design a method to preliminarily predict the true label and difficulty of each item and initialize the model parameters. Empirical results show that our methods consistently outperform state-of-the-art methods. version:2
arxiv-1707-03350 | MovePattern: Interactive Framework to Provide Scalable Visualization of Movement Patterns | http://arxiv.org/abs/1707.03350 | id:1707.03350 author:Kiumars Soltani, Anand Padmanabhan, Shaowen Wang category:cs.DC cs.DB cs.SI  published:2017-07-05 summary:The rapid growth of movement data sources such as GPS traces, traffic networks and social media have provided analysts with the opportunity to explore collective patterns of geographical movements in a nearly real-time fashion. A fast and interactive visualization framework can help analysts to understand these massive and dynamically changing datasets. However, previous studies on movement visualization either ignore the unique properties of geographical movement or are unable to handle today's massive data. In this paper, we develop MovePattern, a novel framework to 1) efficiently construct a concise multi-level view of movements using a scalable and spatially-aware MapReduce-based approach and 2) present a fast and highly interactive webbased environment which engages vector-based visualization to include on-the-fly customization and the ability to enhance analytical functions by storing metadata for both places and movements. We evaluate the framework using the movements of Twitter users captured from geo-tagged tweets. The experiments confirmed that our framework is able to aggregate close to 180 million movements in a few minutes. In addition, we run series of stress tests on the front-end of the framework to ensure that simultaneous user queries do not lead to long latency in the user response. version:1
arxiv-1707-01195 | A note on the impossibility of "fairness" | http://arxiv.org/abs/1707.01195 | id:1707.01195 author:Thomas Miconi category:stat.AP cs.AI stat.ML  published:2017-07-05 summary:Predictions of people's behavior or status can be affected by biases and prejudice, especially when various groups differ in prevalence of the predicted condition. Various measures can be used to determine bias or unfairness in a predictor. Previous work has already established that some of these measures are incompatible with each other. Here we show that, when groups differ in prevalence of the predicted event, several intuitive measures of fairness (ratio of positive predictions to event occurrence, probability of positive prediction given actual occurrence or non-occurrence, and probability of occurrence given positive or negative prediction) are all mutually exclusive: if one of them is equal among groups, the other two must differ. The only exceptions are for perfect, or trivial (always-positive or always-negative) predictors. As a consequence, any non-perfect, non-trivial predictor can always be portrayed as biased or unfair under a certain perspective. The result applies to all predictors, algorithmic or human. We conclude with possible ways to handle this effect when assessing and designing prediction methods. version:1
arxiv-1706-06197 | meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting | http://arxiv.org/abs/1706.06197 | id:1706.06197 author:Xu Sun, Xuancheng Ren, Shuming Ma, Houfeng Wang category:cs.LG cs.AI cs.CL cs.CV  published:2017-06-19 summary:We propose a simple yet effective technique for neural network learning. The forward propagation is computed as usual. In back propagation, only a small subset of the full gradient is computed to update the model parameters. The gradient vectors are sparsified in such a way that only the top-$k$ elements (in terms of magnitude) are kept. As a result, only $k$ rows or columns (depending on the layout) of the weight matrix are modified, leading to a linear reduction ($k$ divided by the vector dimension) in the computational cost. Surprisingly, experimental results demonstrate that we can update only 1--4\% of the weights at each back propagation pass. This does not result in a larger number of training iterations. More interestingly, the accuracy of the resulting models is actually improved rather than degraded, and a detailed analysis is given. version:2
arxiv-1510-05189 | Causal Falling Rule Lists | http://arxiv.org/abs/1510.05189 | id:1510.05189 author:Fulton Wang, Cynthia Rudin category:cs.AI stat.ME  published:2015-10-18 summary:A causal falling rule list (CFRL) is a sequence of if-then rules that specifies heterogeneous treatment effects, where (i) the order of rules determines the treatment effect subgroup a subject belongs to, and (ii) the treatment effect decreases monotonically down the list. A given CFRL parameterizes a hierarchical bayesian regression model in which the treatment effects are incorporated as parameters, and assumed constant within model-specific subgroups. We formulate the search for the CFRL best supported by the data as a Bayesian model selection problem, where we perform a search over the space of CFRL models, and approximate the evidence for a given CFRL model using standard variational techniques. We apply CFRL to a census wage dataset to identify subgroups of differing wage inequalities between men and women. version:2
arxiv-1707-01184 | Sentiment Identification in Code-Mixed Social Media Text | http://arxiv.org/abs/1707.01184 | id:1707.01184 author:Souvick Ghosh, Satanu Ghosh, Dipankar Das category:cs.CL cs.AI cs.SI  published:2017-07-04 summary:Sentiment analysis is the Natural Language Processing (NLP) task dealing with the detection and classification of sentiments in texts. While some tasks deal with identifying the presence of sentiment in the text (Subjectivity analysis), other tasks aim at determining the polarity of the text categorizing them as positive, negative and neutral. Whenever there is a presence of sentiment in the text, it has a source (people, group of people or any entity) and the sentiment is directed towards some entity, object, event or person. Sentiment analysis tasks aim to determine the subject, the target and the polarity or valence of the sentiment. In our work, we try to automatically extract sentiment (positive or negative) from Facebook posts using a machine learning approach.While some works have been done in code-mixed social media data and in sentiment analysis separately, our work is the first attempt (as of now) which aims at performing sentiment analysis of code-mixed social media text. We have used extensive pre-processing to remove noise from raw text. Multilayer Perceptron model has been used to determine the polarity of the sentiment. We have also developed the corpus for this task by manually labeling Facebook posts with their associated sentiments. version:1
arxiv-1707-01166 | Unsupervised Submodular Rank Aggregation on Score-based Permutations | http://arxiv.org/abs/1707.01166 | id:1707.01166 author:Jun Qi, Javier Tejedor category:cs.LG cs.AI  published:2017-07-04 summary:Unsupervised rank aggregation on score-based permutations, which is widely used in many applications, has not been deeply explored yet. This work studies the use of submodular optimization for rank aggregation on score-based permutations in an unsupervised way. Specifically, we propose an unsupervised approach based on the Lovasz Bregman divergence for setting up linear structured convex and nested structured concave objective functions. In addition, stochastic optimization meth- ods are applied in the training process and efficient algorithms for inference can be guaranteed. The experimental results from Information Retrieval, Combining Distributed Neural Networks, and Influencers in Social Networks tasks demonstrate the effectiveness of the proposed methods. version:1
arxiv-1707-01164 | Kernel Feature Selection via Conditional Covariance Minimization | http://arxiv.org/abs/1707.01164 | id:1707.01164 author:Jianbo Chen, Mitchell Stern, Martin J. Wainwright, Michael I. Jordan category:stat.ML cs.AI cs.LG stat.ME  published:2017-07-04 summary:We propose a framework for feature selection that employs kernel-based measures of independence to find a subset of covariates that is maximally predictive of the response. Building on past work in kernel dimension reduction, we formulate our approach as a constrained optimization problem involving the trace of the conditional covariance operator, and additionally provide some consistency results. We then demonstrate on a variety of synthetic and real data sets that our method compares favorably with other state-of-the-art algorithms. version:1
arxiv-1707-01154 | Interpretable & Explorable Approximations of Black Box Models | http://arxiv.org/abs/1707.01154 | id:1707.01154 author:Himabindu Lakkaraju, Ece Kamar, Rich Caruana, Jure Leskovec category:cs.AI  published:2017-07-04 summary:We propose Black Box Explanations through Transparent Approximations (BETA), a novel model agnostic framework for explaining the behavior of any black-box classifier by simultaneously optimizing for fidelity to the original model and interpretability of the explanation. To this end, we develop a novel objective function which allows us to learn (with optimality guarantees), a small number of compact decision sets each of which explains the behavior of the black box model in unambiguous, well-defined regions of feature space. Furthermore, our framework also is capable of accepting user input when generating these approximations, thus allowing users to interactively explore how the black-box model behaves in different subspaces that are of interest to the user. To the best of our knowledge, this is the first approach which can produce global explanations of the behavior of any given black box model through joint optimization of unambiguity, fidelity, and interpretability, while also allowing users to explore model behavior based on their preferences. Experimental evaluation with real-world datasets and user studies demonstrates that our approach can generate highly compact, easy-to-understand, yet accurate approximations of various kinds of predictive models compared to state-of-the-art baselines. version:1
arxiv-1707-01152 | Improving Foot-Mounted Inertial Navigation Through Real-Time Motion Classification | http://arxiv.org/abs/1707.01152 | id:1707.01152 author:Brandon Wagstaff, Valentin Peretroukhin, Jonathan Kelly category:cs.RO cs.HC  published:2017-07-04 summary:We present a method to improve the accuracy of a foot-mounted, zero-velocity-aided inertial navigation system (INS) by varying estimator parameters based on a real-time classification of motion type. We train a support vector machine (SVM) classifier using inertial data recorded by a single foot-mounted sensor to differentiate between six motion types (walking, jogging, running, sprinting, crouch-walking, and ladder-climbing) and report mean test classification accuracy of over 90% on a dataset with five different subjects. From these motion types, we select two of the most common (walking and running), and describe a method to compute optimal zero-velocity detection parameters tailored to both a specific user and motion type by maximizing the detector F-score. By combining the motion classifier with a set of optimal detection parameters, we show how we can reduce INS position error during mixed walking and running motion. We evaluate our adaptive system on a total of 5.9 km of indoor pedestrian navigation performed by five different subjects moving along a 130 m path with surveyed ground truth markers. version:1
arxiv-1705-02408 | Perception-Aware Motion Planning via Multiobjective Search on GPUs | http://arxiv.org/abs/1705.02408 | id:1705.02408 author:Brian Ichter, Benoit Landry, Edward Schmerling, Marco Pavone category:cs.RO  published:2017-05-05 summary:In this paper we describe a framework towards computing well-localized, robust motion plans through the perception-aware motion planning problem, whereby we seek a low-cost motion plan subject to a separate constraint on perception localization quality. To solve this problem we introduce the Multiobjective Perception-Aware Planning (MPAP) algorithm which explores the state space via a multiobjective search, considering both cost and a perception heuristic. This framework can accommodate a large range of heuristics, allowing those that capture the history dependence of localization drift and represent complex modern perception methods. We present two such heuristics, one derived from a simplified model of robot perception and a second learned from ground-truth sensor error, which we show to be capable of predicting the performance of a state-of-the-art perception system. The solution trajectory from this heuristic-based search is then certified via Monte Carlo methods to be well-localized and robust. The additional computational burden of perception-aware planning is offset by GPU massive parallelization. Through numerical experiments the algorithm is shown to find well-localized, robust solutions in about a second. Finally, we demonstrate MPAP on a quadrotor flying perception-aware and perception-agnostic plans using Google Tango for localization, finding the quadrotor safely executes the perception-aware plan every time, while crashing in over 20% of the perception-agnostic runs due to loss of localization. version:2
arxiv-1707-05189 | The Normalized Singular Value Decomposition of Non-Symmetric Matrices Using Givens fast Rotations | http://arxiv.org/abs/1707.05189 | id:1707.05189 author:Ehsan Rohani, Gwan Choi, Mi Lu category:cs.NA cs.AR  published:2017-07-04 summary:In this paper we introduce the algorithm and the fixed point hardware to calculate the normalized singular value decomposition of a non-symmetric matrices using Givens fast (approximate) rotations. This algorithm only uses the basic combinational logic modules such as adders, multiplexers, encoders, Barrel shifters (B-shifters), and comparators and does not use any lookup table. This method in fact combines the iterative properties of singular value decomposition method and CORDIC method in one single iteration. The introduced architecture is a systolic architecture that uses two different types of processors, diagonal and non-diagonal processors. The diagonal processor calculates, transmits and applies the horizontal and vertical rotations, while the non-diagonal processor uses a fully combinational architecture to receive, and apply the rotations. The diagonal processor uses priority encoders, Barrel shifters, and comparators to calculate the rotation angles. Both processors use a series of adders to apply the rotation angles. The design presented in this work provides $2.83\sim649$ times better energy per matrix performance compared to the state of the art designs. This performance achieved without the employment of pipelining; a better performance advantage is expected to be achieved employing pipelining. version:1
arxiv-1707-01068 | Maintaining cooperation in complex social dilemmas using deep reinforcement learning | http://arxiv.org/abs/1707.01068 | id:1707.01068 author:Adam Lerer, Alexander Peysakhovich category:cs.AI cs.GT cs.MA  published:2017-07-04 summary:In social dilemmas individuals face a temptation to increase their payoffs in the short run at a cost to the long run total welfare. Much is known about how cooperation can be stabilized in the simplest of such settings: repeated Prisoner's Dilemma games. However, there is relatively little work on generalizing these insights to more complex situations. We start to fill this gap by showing how to use modern reinforcement learning methods to generalize a highly successful Prisoner's Dilemma strategy: tit-for-tat. We construct artificial agents that act in ways that are simple to understand, nice (begin by cooperating), provokable (try to avoid being exploited), and forgiving (following a bad turn try to return to mutual cooperation). We show both theoretically and experimentally that generalized tit-for-tat agents can maintain cooperation in more complex environments. In contrast, we show that employing purely reactive training techniques can lead to agents whose behavior results in socially inefficient outcomes. version:1
arxiv-1707-01067 | ELF: An Extensive, Lightweight and Flexible Research Platform for Real-time Strategy Games | http://arxiv.org/abs/1707.01067 | id:1707.01067 author:Yuandong Tian, Qucheng Gong, Wenling Shang, Yuxin Wu, Larry Zitnick category:cs.AI  published:2017-07-04 summary:In this paper, we propose ELF, an Extensive, Lightweight and Flexible platform for fundamental reinforcement learning research. Using ELF, we implement a highly customizable real-time strategy (RTS) engine with three game environments (Mini-RTS, Capture the Flag and Tower Defense). Mini-RTS, as a miniature version of StarCraft, captures key game dynamics and runs at 40K frame-per-second (FPS) per core on a Macbook Pro notebook. When coupled with modern reinforcement learning methods, the system can train a full-game bot against built-in AIs end-to-end in one day with 6 CPUs and 1 GPU. In addition, our platform is flexible in terms of environment-agent communication topologies, choices of RL methods, changes in game parameters, and can host existing C/C++-based game environments like Arcade Learning Environment. Using ELF, we thoroughly explore training parameters and show that a network with Leaky ReLU and Batch Normalization coupled with long-horizon training and progressive curriculum beats the rule-based built-in AI more than $70\%$ of the time in the full game of Mini-RTS. Strong performance is also achieved on the other two games. In game replays, we show our agents learn interesting strategies. ELF, along with its RL platform, will be open-sourced. version:1
arxiv-1707-00936 | Window-of-interest based Multi-objective Evolutionary Search for Satisficing Concepts | http://arxiv.org/abs/1707.00936 | id:1707.00936 author:Eliran Farhi, Amiram Moshaiov category:cs.AI  published:2017-07-04 summary:The set-based concept approach has been suggested as a means to simultaneously explore different design concepts, which are meaningful sub-sets of the entire set of solutions. Previous efforts concerning the suggested approach focused on either revealing the global front (s-Pareto front), of all the concepts, or on finding the concepts' fronts, within a relaxation zone. In contrast, here the aim is to reveal which of the concepts have at least one solution with a performance vector within a pre-defined window-of-interest (WOI). This paper provides the rational for this new concept-based exploration problem, and suggests a WOI-based rather than Pareto-based multi-objective evolutionary algorithm. The proposed algorithm, which simultaneously explores different concepts, is tested using a recently suggested concept-based benchmarking approach. The numerical study of this paper shows that the algorithm can cope with various numerical difficulties in a simultaneous way, which outperforms a sequential exploration approach. version:1
arxiv-1610-09018 | Optimal Belief Approximation | http://arxiv.org/abs/1610.09018 | id:1610.09018 author:Reimar H. Leike, Torsten A. EnÃlin category:math.ST cs.AI physics.data-an stat.TH  published:2016-10-27 summary:In Bayesian statistics probability distributions express beliefs. However, for many problems the beliefs cannot be computed analytically and approximations of beliefs are needed. We seek a loss function that quantifies how "embarrassing" it is to communicate a given approximation. We reproduce and discuss an old proof showing that there is only one ranking under the requirements that (1) the best ranked approximation is the non-approximated belief and (2) that the ranking judges approximations only by their predictions for actual outcomes. The ranking that is obtained in the derivation is equivalent to the Kullback-Leibler divergence that is frequently used in the literature. However, there seems to be confusion about the correct order in which its functional arguments, the approximated and non-approximated beliefs, should be used. The correct order ensures that the recipient of a communication is only deprived of the minimal amount of information. We hope that the elementary derivation settles the apparent confusion. For example when approximating beliefs with Gaussian distributions the optimal approximation is given by moment matching. This is in contrast to many suggested computational schemes. version:5
arxiv-1707-00904 | Sequential Checking: Reallocation-Free Data-Distribution Algorithm for Scale-out Storage | http://arxiv.org/abs/1707.00904 | id:1707.00904 author:Ken-ichiro Ishikawa category:cs.DC cs.DB cs.DS E.1  published:2017-07-04 summary:Using tape or optical devices for scale-out storage is one option for storing a vast amount of data. However, it is impossible or almost impossible to rewrite data with such devices. Thus, scale-out storage using such devices cannot use standard data-distribution algorithms because they rewrite data for moving between servers constituting the scale-out storage when the server configuration is changed. Although using rewritable devices for scale-out storage, when server capacity is huge, rewriting data is very hard when server constitution is changed. In this paper, a data-distribution algorithm called Sequential Checking is proposed, which can be used for scale-out storage composed of devices that are hardly able to rewrite data. Sequential Checking 1) does not need to move data between servers when the server configuration is changed, 2) distribute data, the amount of which depends on the server's volume, 3) select a unique server when datum is written, and 4) select servers when datum is read (there are few such server(s) in most cases) and find out a unique server that stores the newest datum from them. These basic characteristics were confirmed through proofs and simulations. Data can be read by accessing 1.98 servers on average from a storage comprising 256 servers under a realistic condition. And it is confirmed by evaluations in real environment that access time is acceptable. Sequential Checking makes selecting scale-out storage using tape or optical devices or using huge capacity servers realistic. version:1
arxiv-1309-7720 | ASURA: Scalable and Uniform Data Distribution Algorithm for Storage Clusters | http://arxiv.org/abs/1309.7720 | id:1309.7720 author:Ken-ichiro Ishikawa category:cs.DC E.1  published:2013-09-30 summary:Large-scale storage cluster systems need to manage a vast amount of data locations. A naive data locations management maintains pairs of data ID and nodes storing the data in tables. However, it is not practical when the number of pairs is too large. To solve this problem, management using data distribution algorithms, rather than management using tables, has been proposed in recent research. It can distribute data by determining the node for storing the data based on the datum ID. Such data distribution algorithms require the ability to handle the addition or removal of nodes, short calculation time and uniform data distribution in the capacity of each node. This paper proposes a data distribution algorithm called ASURA (Advanced Scalable and Uniform storage by Random number Algorithm) that satisfies these requirements. It achieves following four characteristics: 1) minimum data movement to maintain data distribution according to node capacity when nodes are added or removed, even if data are replicated, 2) roughly sub-micro-seconds calculation time, 3) much lower than 1% maximum variability between nodes in data distribution, and 4) data distribution according to the capacity of each node. The evaluation results show that ASURA is qualitatively and quantitatively competitive against major data distribution algorithms such as Consistent Hashing, Weighted Rendezvous Hashing and Random Slicing. The comparison results show benefits of each algorithm; they show that ASURA has advantage in large scale-out storage clusters. version:2
arxiv-1707-00893 | Optimization Beyond the Convolution: Generalizing Spatial Relations with End-to-End Metric Learning | http://arxiv.org/abs/1707.00893 | id:1707.00893 author:Philipp Jund, Andreas Eitel, Nichola Abdo, Wolfram Burgard category:cs.RO cs.CV cs.LG  published:2017-07-04 summary:To operate intelligently in domestic environments, robots require the ability to understand arbitrary spatial relations between objects and to generalize them to objects of varying sizes and shapes. In this work, we present a novel end-to-end approach utilizing neural networks to generalize spatial relations based on distance metric learning. Our network transforms spatial relations to a feature space that captures their similarities based on 3D point clouds of the objects and without prior semantic knowledge of the relations. It employs gradient-based optimization to compute object poses in order to imitate an arbitrary target relation by reducing the distance to it under the learned metric. version:1
arxiv-1707-00889 | ECHO: An Adaptive Orchestration Platform for Hybrid Dataflows across Cloud and Edge | http://arxiv.org/abs/1707.00889 | id:1707.00889 author:Pushkara Ravindra, Aakash Khochare, Siva Prakash Reddy, Sarthak Sharma, Prateeksha Varshney, Yogesh Simmhan category:cs.DC  published:2017-07-04 summary:The Internet of Things (IoT) is offering unprecedented observational data that are used for managing Smart City utilities. Edge and Fog gateway devices are an integral part of IoT deployments to acquire real-time data and enact controls. Recently, Edge-computing is emerging as first-class paradigm to complement Cloud-centric analytics. But a key limitation is the lack of a platform-as-a-service for applications spanning Edge and Cloud. Here, we propose ECHO, an orchestration platform for dataflows across distributed resources. ECHO's hybrid dataflow composition can operate on diverse data models -- streams, micro-batches and files, and interface with native runtime engines like TensorFlow and Storm to execute them. It manages the application's lifecycle, including container-based deployment and a registry for state management. ECHO can schedule the dataflow on different Edge, Fog and Cloud resources, and also perform dynamic task migration between resources. We validate the ECHO platform for executing video analytics and sensor streams for Smart Traffic and Smart Utility applications on Raspberry Pi, NVidia TX1, ARM64 and Azure Cloud VM resources, and present our results. version:1
arxiv-1707-00836 | DeepStory: Video Story QA by Deep Embedded Memory Networks | http://arxiv.org/abs/1707.00836 | id:1707.00836 author:Kyung-Min Kim, Min-Oh Heo, Seong-Ho Choi, Byoung-Tak Zhang category:cs.CV cs.AI cs.CL  published:2017-07-04 summary:Question-answering (QA) on video contents is a significant challenge for achieving human-level intelligence as it involves both vision and language in real-world settings. Here we demonstrate the possibility of an AI agent performing video story QA by learning from a large amount of cartoon videos. We develop a video-story learning model, i.e. Deep Embedded Memory Networks (DEMN), to reconstruct stories from a joint scene-dialogue video stream using a latent embedding space of observed data. The video stories are stored in a long-term memory component. For a given question, an LSTM-based attention model uses the long-term memory to recall the best question-story-answer triplet by focusing on specific words containing key information. We trained the DEMN on a novel QA dataset of children's cartoon video series, Pororo. The dataset contains 16,066 scene-dialogue pairs of 20.5-hour videos, 27,328 fine-grained sentences for scene description, and 8,913 story-related QA pairs. Our experimental results show that the DEMN outperforms other QA models. This is mainly due to 1) the reconstruction of video stories in a scene-dialogue combined form that utilize the latent embedding and 2) attention. DEMN also achieved state-of-the-art results on the MovieQA benchmark. version:1
arxiv-1707-00832 | Modeling the Internet of Things: a simulation perspective | http://arxiv.org/abs/1707.00832 | id:1707.00832 author:Gabriele D'Angelo, Stefano Ferretti, Vittorio Ghini category:cs.DC cs.MA cs.NI cs.PF  published:2017-07-04 summary:This paper deals with the problem of properly simulating the Internet of Things (IoT). Simulating an IoT allows evaluating strategies that can be employed to deploy smart services over different kinds of territories. However, the heterogeneity of scenarios seriously complicates this task. This imposes the use of sophisticated modeling and simulation techniques. We discuss novel approaches for the provision of scalable simulation scenarios, that enable the real-time execution of massively populated IoT environments. Attention is given to novel hybrid and multi-level simulation techniques that, when combined with agent-based, adaptive Parallel and Distributed Simulation (PADS) approaches, can provide means to perform highly detailed simulations on demand. To support this claim, we detail a use case concerned with the simulation of vehicular transportation systems. version:1
arxiv-1707-00819 | Causal Consistency of Structural Equation Models | http://arxiv.org/abs/1707.00819 | id:1707.00819 author:Paul K. Rubenstein, Sebastian Weichwald, Stephan Bongers, Joris M. Mooij, Dominik Janzing, Moritz Grosse-Wentrup, Bernhard SchÃ¶lkopf category:stat.ML cs.AI cs.LG stat.ME  published:2017-07-04 summary:Complex systems can be modelled at various levels of detail. Ideally, causal models of the same system should be consistent with one another in the sense that they agree in their predictions of the effects of interventions. We formalise this notion of consistency in the case of Structural Equation Models (SEMs) by introducing exact transformations between SEMs. This provides a general language to consider, for instance, the different levels of description in the following three scenarios: (a) models with large numbers of variables versus models in which the `irrelevant' or unobservable variables have been marginalised out; (b) micro-level models versus macro-level models in which the macro-variables are aggregate features of the micro-variables; (c) dynamical time series models versus models of their stationary behaviour. Our analysis stresses the importance of well specified interventions in the causal modelling process and sheds light on the interpretation of cyclic SEMs. version:1
arxiv-1705-04226 | Robot Planning with Mathematical Models of Human State and Action | http://arxiv.org/abs/1705.04226 | id:1705.04226 author:Anca D. Dragan category:cs.RO  published:2017-05-11 summary:Robots interacting with the physical world plan with models of physics. We advocate that robots interacting with people need to plan with models of cognition. This writeup summarizes the insights we have gained in integrating computational cognitive models of people into robotics planning and control. It starts from a general game-theoretic formulation of interaction, and analyzes how different approximations result in different useful coordination behaviors for the robot during its interaction with people. version:2
arxiv-1707-00791 | Visualizing the Consequences of Evidence in Bayesian Networks | http://arxiv.org/abs/1707.00791 | id:1707.00791 author:Clifford Champion, Charles Elkan category:cs.AI  published:2017-07-04 summary:This paper addresses the challenge of viewing and navigating Bayesian networks as their structural size and complexity grow. Starting with a review of the state of the art of visualizing Bayesian networks, an area which has largely been passed over, we improve upon existing visualizations in three ways. First, we apply a disciplined approach to the graphic design of the basic elements of the Bayesian network. Second, we propose a technique for direct, visual comparison of posterior distributions resulting from alternative evidence sets. Third, we leverage a central mathematical tool in information theory, to assist the user in finding variables of interest in the network, and to reduce visual complexity where unimportant. We present our methods applied to two modestly large Bayesian networks constructed from real-world data sets. Results suggest the new techniques can be a useful tool for discovering information flow phenomena, and also for qualitative comparisons of different evidence configurations, especially in large probabilistic networks. version:1
arxiv-1707-00790 | OPEB: Open Physical Environment Benchmark for Artificial Intelligence | http://arxiv.org/abs/1707.00790 | id:1707.00790 author:Hamid Mirzaei, Mona Fathollahi, Tony Givargis category:cs.AI  published:2017-07-04 summary:Artificial Intelligence methods to solve continuous- control tasks have made significant progress in recent years. However, these algorithms have important limitations and still need significant improvement to be used in industry and real- world applications. This means that this area is still in an active research phase. To involve a large number of research groups, standard benchmarks are needed to evaluate and compare proposed algorithms. In this paper, we propose a physical environment benchmark framework to facilitate collaborative research in this area by enabling different research groups to integrate their designed benchmarks in a unified cloud-based repository and also share their actual implemented benchmarks via the cloud. We demonstrate the proposed framework using an actual implementation of the classical mountain-car example and present the results obtained using a Reinforcement Learning algorithm. version:1
arxiv-1707-00788 | Lifeguard : SWIM-ing with Situational Awareness | http://arxiv.org/abs/1707.00788 | id:1707.00788 author:Armon Dadgar, James Phillips, Jon Currey category:cs.DC  published:2017-07-04 summary:SWIM is a peer-to-peer group membership protocol that uses randomized probing and gossip to obtain attractive scaling and robustness properties. Sensitivity to slow message processing, due to factors such as CPU exhaustion, network delay or loss, can lead SWIM to declare healthy members faulty. To counter this, SWIM adds a Suspicion mechanism, that trades increased failure detection latency for a lower false positive failure detection rate. However, relatively short lived periods of slow message processing commonly experienced in data centers can still lead to healthy members being marked as failed. We observe that the Suspicion mechanism still assumes timely processing of some messages. In particular, refutation of a suspicion can only succeed if it is processed by the suspecting member in a timely manner. However, missing expected responses could indicate a member is experiencing slow message processing, and an episode of slow message processing at a given group member is likely to impact multiple of its interactions with other members in a short period of time. Based on these insights, we define a set of extensions to SWIM that allow a member to dynamically adjust its timeouts to mitigate timeliness issues. We call these extensions Lifeguard. We analyze the effect of Lifeguard using synthetic benchmarks that vary message processing delays in a controlled manner. Across the wide range of cases tested, Lifeguard is able to reduce the false positive rate by a factor of more than 50x, while modestly increasing failure detection latency and message load. Furthermore, by modifying tuning parameters, Life- guard allows users to reduce median detection latency by 45% while still reducing false positives at healthy members by 3x compared to without Lifeguard. The tuning parameters allow users to choose a suitable trade-off between lower false positives and lower detection latency. version:1
arxiv-1704-00079 | Algorithms for Routing of Unmanned Aerial Vehicles with Mobile Recharging Stations and for Package Delivery | http://arxiv.org/abs/1704.00079 | id:1704.00079 author:Kevin Yu, Ashish Kumar Budhiraja, Pratap Tokekar category:cs.RO cs.MA  published:2017-03-31 summary:We study the problem of planning tours for an Unmanned Aerial Vehicle (UAV) to visit a given set of sites in the least amount of time. This is the classic Traveling Salesperson Problem (TSP). UAVs have limited battery life and as a result may not be able to visit all the points on a single charge. We envision scenarios where the UAVs can be recharged along the way either by landing on stationary recharging stations or on Unmanned Ground Vehicles (UGVs) acting as mobile recharging stations. We present an algorithm to find the optimal tours to determine not only the order in which to visit the sites but also when and where to land on the UGV to recharge. Our algorithm plans tours for the UGVs as well as determines best locations to place stationary charging stations. While the problem we study is NP-Hard, we present a practical solution using Generalized TSP that finds the optimal solution (albeit in possibly exponential worst-case running time). Our simulation results show that the running time is acceptable for reasonably sized instances in practice. We also show how to modify our algorithms to plan for package delivery with UAVs using UGVs as mobile warehouses. version:2
arxiv-1706-09932 | Scalable Asymptotically-Optimal Multi-Robot Motion Planning | http://arxiv.org/abs/1706.09932 | id:1706.09932 author:Andrew Dobson, Kiril Solovey, Rahul Shome, Dan Halperin, Kostas E. Bekris category:cs.MA cs.RO  published:2017-06-29 summary:Finding asymptotically-optimal paths in multi-robot motion planning problems could be achieved, in principle, using sampling-based planners in the composite configuration space of all of the robots in the space. The dimensionality of this space increases with the number of robots, rendering this approach impractical. This work focuses on a scalable sampling-based planner for coupled multi-robot problems that provides asymptotic optimality. It extends the dRRT approach, which proposed building roadmaps for each robot and searching an implicit roadmap in the composite configuration space. This work presents a new method, dRRT* , and develops theory for scalable convergence to optimal paths in multi-robot problems. Simulated experiments indicate dRRT* converges to high-quality paths while scaling to higher numbers of robots where the naive approach fails. Furthermore, dRRT* is applicable to high-dimensional problems, such as planning for robot manipulators version:2
arxiv-1707-00703 | Automated Problem Identification: Regression vs Classification via Evolutionary Deep Networks | http://arxiv.org/abs/1707.00703 | id:1707.00703 author:Emmanuel Dufourq, Bruce A. Bassett category:cs.NE cs.AI cs.LG stat.ML  published:2017-07-03 summary:Regression or classification? This is perhaps the most basic question faced when tackling a new supervised learning problem. We present an Evolutionary Deep Learning (EDL) algorithm that automatically solves this by identifying the question type with high accuracy, along with a proposed deep architecture. Typically, a significant amount of human insight and preparation is required prior to executing machine learning algorithms. For example, when creating deep neural networks, the number of parameters must be selected in advance and furthermore, a lot of these choices are made based upon pre-existing knowledge of the data such as the use of a categorical cross entropy loss function. Humans are able to study a dataset and decide whether it represents a classification or a regression problem, and consequently make decisions which will be applied to the execution of the neural network. We propose the Automated Problem Identification (API) algorithm, which uses an evolutionary algorithm interface to TensorFlow to manipulate a deep neural network to decide if a dataset represents a classification or a regression problem. We test API on 16 different classification, regression and sentiment analysis datasets with up to 10,000 features and up to 17,000 unique target values. API achieves an average accuracy of $96.3\%$ in identifying the problem type without hardcoding any insights about the general characteristics of regression or classification problems. For example, API successfully identifies classification problems even with 1000 target values. Furthermore, the algorithm recommends which loss function to use and also recommends a neural network architecture. Our work is therefore a step towards fully automated machine learning. version:1
arxiv-1707-00524 | Hashing Over Predicted Future Frames for Informed Exploration of Deep Reinforcement Learning | http://arxiv.org/abs/1707.00524 | id:1707.00524 author:Haiyan Yin, Sinno Jialin Pan category:cs.LG cs.AI stat.ML  published:2017-07-03 summary:In reinforcement learning (RL) tasks, an efficient exploration mechanism should be able to encourage an agent to take actions that lead to less frequent states which may yield higher accumulative future return. However, both knowing about the future and evaluating the frequentness of states are non-trivial tasks, especially for deep RL domains, where a state is represented by high-dimensional image frames. In this paper, we propose a novel informed exploration framework for deep RL tasks, where we build the capability for a RL agent to predict over the future transitions and evaluate the frequentness for the predicted future frames in a meaningful manner. To this end, we train a deep prediction model to generate future frames given a state-action pair, and a convolutional autoencoder model to generate deep features for conducting hashing over the seen frames. In addition, to utilize the counts derived from the seen frames to evaluate the frequentness for the predicted frames, we tackle the challenge of making the hash codes for the predicted future frames to match with their corresponding seen frames. In this way, we could derive a reliable metric for evaluating the novelty of the future direction pointed by each action, and hence inform the agent to explore the least frequent one. We use Atari 2600 games as the testing environment and demonstrate that the proposed framework achieves significant performance gain over a state-of-the-art informed exploration approach in most of the domains. version:1
arxiv-1701-08546 | Survey on Models and Techniques for Root-Cause Analysis | http://arxiv.org/abs/1701.08546 | id:1701.08546 author:Marc SolÃ©, Victor MuntÃ©s-Mulero, Annie Ibrahim Rana, Giovani Estrada category:cs.AI  published:2017-01-30 summary:Automation and computer intelligence to support complex human decisions becomes essential to manage large and distributed systems in the Cloud and IoT era. Understanding the root cause of an observed symptom in a complex system has been a major problem for decades. As industry dives into the IoT world and the amount of data generated per year grows at an amazing speed, an important question is how to find appropriate mechanisms to determine root causes that can handle huge amounts of data or may provide valuable feedback in real-time. While many survey papers aim at summarizing the landscape of techniques for modelling system behavior and infering the root cause of a problem based in the resulting models, none of those focuses on analyzing how the different techniques in the literature fit growing requirements in terms of performance and scalability. In this survey, we provide a review of root-cause analysis, focusing on these particular aspects. We also provide guidance to choose the best root-cause analysis strategy depending on the requirements of a particular system and application. version:2
arxiv-1707-00484 | A Projected Inverse Dynamics Approach for Dual-arm Cartesian Impedance Control | http://arxiv.org/abs/1707.00484 | id:1707.00484 author:Hsiu-Chin Lin, Joshua Smith, Keyhan Kouhkiloui Babarahmati, Niels Dehio, Michael Mistry category:cs.RO  published:2017-07-03 summary:We propose a method for dual-arm manipulation of rigid objects, subject to external disturbance. The problem is formulated as a Cartesian impedance controller within a projected inverse dynamics framework. We use the constrained component of the controller to enforce contact and the unconstrained controller to accomplish the task with a desired 6-DOF impedance behaviour. Furthermore, the proposed method optimises the torque required to maintain contact, subject to unknown disturbances, and can do so without direct measurement of external force. The techniques are evaluated on a single-arm wiping a table and a dual-arm platform manipulating a rigid object of unknown mass and with human interaction. version:1
arxiv-1707-00424 | Parle: parallelizing stochastic gradient descent | http://arxiv.org/abs/1707.00424 | id:1707.00424 author:Pratik Chaudhari, Carlo Baldassi, Riccardo Zecchina, Stefano Soatto, Ameet Talwalkar category:cs.LG cs.DC stat.ML  published:2017-07-03 summary:We propose a new algorithm called Parle for parallel training of deep networks that converges 2-4x faster than a data-parallel implementation of SGD, while achieving significantly improved error rates that are nearly state-of-the-art on several benchmarks including CIFAR-10 and CIFAR-100, without introducing any additional hyper-parameters. We exploit the phenomenon of flat minima that has been shown to lead to improved generalization error for deep networks. Parle requires very infrequent communication with the parameter server and instead performs more computation on each client, which makes it well-suited to both single-machine, multi-GPU settings and distributed implementations. version:1
arxiv-1707-00355 | Ising Processing Units: Potential and Challenges for Discrete Optimization | http://arxiv.org/abs/1707.00355 | id:1707.00355 author:Carleton Coffrin, Harsha Nagarajan, Russell Bent category:math.OC cs.AI  published:2017-07-02 summary:The recent emergence of novel computational devices, such as adiabatic quantum computers, CMOS annealers, and optical parametric oscillators, presents new opportunities for hybrid-optimization algorithms that leverage these kinds of specialized hardware. In this work, we propose the idea of an Ising processing unit as a computational abstraction for these emerging tools. Challenges involved in using and benchmarking these devices are presented, and open-source software tools are proposed to address some of these challenges. The proposed benchmarking tools and methodology are demonstrated by conducting a baseline study of established solution methods to a D-Wave 2X adiabatic quantum computer, one example of a commercially available Ising processing unit. version:1
arxiv-1707-00318 | Sampling-based Planning of In-Hand Manipulation with External Pushes | http://arxiv.org/abs/1707.00318 | id:1707.00318 author:Nikhil Chavan-Dafle, Alberto Rodriguez category:cs.RO  published:2017-07-02 summary:This paper presents a sampling-based planning algorithm for in-hand manipulation of a grasped object using a series of external pushes. A high-level optimal sampling-based planning framework, in tandem with a low-level inverse contact dynamics solver, effectively explores the space of continuous pushes with discrete pusher contact switch-overs. We model the frictional interaction between gripper, grasped object, and pusher, by discretizing complex surface/line contacts into arrays of hard frictional point contacts. The inverse dynamics problem of finding an instantaneous pusher motion that yields a desired instantaneous object motion takes the form of a mixed nonlinear complementarity problem. Building upon this dynamics solver, our planner generates a sequence of long pushes that steers the object to a goal grasp.We evaluate the performance of the planner for the case of a parallel-jaw gripper manipulating different objects, both in simulation and with real experiments. Through these examples, we highlight the important properties of the planner: respecting and exploiting the hybrid dynamics of contact sticking/sliding/rolling and a sense of efficiency with respect to contact switch-overs. version:1
arxiv-1704-01161 | Finite Sample Analysis for TD(0) with Linear Function Approximation | http://arxiv.org/abs/1704.01161 | id:1704.01161 author:Gal Dalal, BalÃ¡zs SzÃ¶rÃ©nyi, Gugan Thoppe, Shie Mannor category:cs.AI  published:2017-04-04 summary:TD(0) is one of the most commonly used algorithms in reinforcement learning. Despite this, there is no existing finite sample analysis for TD(0) with function approximation, even for the linear case. Our work is the first to provide such a result. Works that managed to obtain concentration bounds for online Temporal Difference (TD) methods analyzed modified versions of them, carefully crafted for the analyses to hold. These modifications include projections and step-sizes dependent on unknown problem parameters. Our analysis obviates these artificial alterations by exploiting strong properties of TD(0) and tailor-made stochastic approximation tools. version:2
arxiv-1705-01522 | A Fast Causal Profiler for Task Parallel Programs | http://arxiv.org/abs/1705.01522 | id:1705.01522 author:Adarsh Yoga, Santosh Nagarakatte category:cs.PL cs.DC  published:2017-05-03 summary:This paper proposes TASKPROF, a profiler that identifies parallelism bottlenecks in task parallel programs. It leverages the structure of a task parallel execution to perform fine-grained attribution of work to various parts of the program. TASKPROF's use of hardware performance counters to perform fine-grained measurements minimizes perturbation. TASKPROF's profile execution runs in parallel using multi-cores. TASKPROF's causal profile enables users to estimate improvements in parallelism when a region of code is optimized even when concrete optimizations are not yet known. We have used TASKPROF to isolate parallelism bottlenecks in twenty three applications that use the Intel Threading Building Blocks library. We have designed parallelization techniques in five applications to in- crease parallelism by an order of magnitude using TASKPROF. Our user study indicates that developers are able to isolate performance bottlenecks with ease using TASKPROF. version:3
arxiv-1611-08037 | A Spatio-Temporal Representation for the Orienteering Problem with Time-Varying Profits | http://arxiv.org/abs/1611.08037 | id:1611.08037 author:Zhibei Ma, Kai Yin, Lantao Liu, Gaurav S. Sukhatme category:cs.AI  published:2016-11-24 summary:We consider an orienteering problem (OP) where an agent needs to visit a series (possibly a subset) of depots, from which the maximal accumulated profits are desired within given limited time budget. Different from most existing works where the profits are assumed to be static, in this work we investigate a variant that has arbitrary time-dependent profits. Specifically, the profits to be collected change over time and they follow different (e.g., independent) time-varying functions. The problem is of inherent nonlinearity and difficult to solve by existing methods. To tackle the challenge, we present a simple and effective framework that incorporates time-variations into the fundamental planning process. Specifically, we propose a deterministic spatio-temporal representation where both spatial description and temporal logic are unified into one routing topology. By employing existing basic sorting and searching algorithms, the routing solutions can be computed in an extremely efficient way. The proposed method is easy to implement and extensive numerical results show that our approach is time efficient and generates near-optimal solutions. version:2
arxiv-1707-00228 | Modifying Optimal SAT-based Approach to Multi-agent Path-finding Problem to Suboptimal Variants | http://arxiv.org/abs/1707.00228 | id:1707.00228 author:Pavel Surynek, Ariel Felner, Roni Stern, Eli Boyarski category:cs.AI  published:2017-07-02 summary:In multi-agent path finding (MAPF) the task is to find non-conflicting paths for multiple agents. In this paper we focus on finding suboptimal solutions for MAPF for the sum-of-costs variant. Recently, a SAT-based approached was developed to solve this problem and proved beneficial in many cases when compared to other search-based solvers. In this paper, we present SAT-based unbounded- and bounded-suboptimal algorithms and compare them to relevant algorithms. Experimental results show that in many case the SAT-based solver significantly outperforms the search-based solvers. version:1
arxiv-1705-00720 | Computing Tropical Prevarieties in Parallel | http://arxiv.org/abs/1705.00720 | id:1705.00720 author:Anders Jensen, Jeff Sommars, Jan Verschelde category:cs.MS cs.CG cs.DC math.AG math.CO  published:2017-05-01 summary:The computation of the tropical prevariety is the first step in the application of polyhedral methods to compute positive dimensional solution sets of polynomial systems. In particular, pretropisms are candidate leading exponents for the power series developments of the solutions. The computation of the power series may start as soon as one pretropism is available, so our parallel computation of the tropical prevariety has an application in a pipelined solver. We present a parallel implementation of dynamic enumeration. Our first distributed memory implementation with forked processes achieved good speedups, but quite often resulted in large variations in the execution times of the processes. The shared memory multithreaded version applies work stealing to reduce the variability of the run time. Our implementation applies the thread safe Parma Polyhedral Library (PPL), in exact arithmetic with the GNU Multiprecision Arithmetic Library (GMP), aided by the fast memory allocations of TCMalloc. Our parallel implementation is capable of computing the tropical prevariety of the cyclic 16-roots problem. We also report on computational experiments on the $n$-body and $n$-vortex problems; our computational results compare favorably with Gfan. version:2
arxiv-1707-00183 | Teacher-Student Curriculum Learning | http://arxiv.org/abs/1707.00183 | id:1707.00183 author:Tambet Matiisen, Avital Oliver, Taco Cohen, John Schulman category:cs.LG cs.AI  published:2017-07-01 summary:We propose Teacher-Student Curriculum Learning (TSCL), a framework for automatic curriculum learning, where the Student tries to learn a complex task and the Teacher automatically chooses subtasks from a given set for the Student to train on. We describe a family of Teacher algorithms that rely on the intuition that the Student should practice more those tasks on which it makes the fastest progress, i.e. where the slope of the learning curve is highest. In addition, the Teacher algorithms address the problem of forgetting by also choosing tasks where the Student's performance is getting worse. We demonstrate that TSCL matches or surpasses the results of carefully hand-crafted curricula in two tasks: addition of decimal numbers with LSTM and navigation in Minecraft. Using our automatically generated curriculum enabled to solve a Minecraft maze that could not be solved at all when training directly on solving the maze, and the learning was an order of magnitude faster than uniform sampling of subtasks. version:1
arxiv-1707-00112 | A study of existing Ontologies in the IoT-domain | http://arxiv.org/abs/1707.00112 | id:1707.00112 author:Garvita Bajaj, Rachit Agarwal, Pushpendra Singh, Nikolaos Georgantas, Valerie Issarny category:cs.AI  published:2017-07-01 summary:Several domains have adopted the increasing use of IoT-based devices to collect sensor data for generating abstractions and perceptions of the real world. This sensor data is multi-modal and heterogeneous in nature. This heterogeneity induces interoperability issues while developing cross-domain applications, thereby restricting the possibility of reusing sensor data to develop new applications. As a solution to this, semantic approaches have been proposed in the literature to tackle problems related to interoperability of sensor data. Several ontologies have been proposed to handle different aspects of IoT-based sensor data collection, ranging from discovering the IoT sensors for data collection to applying reasoning on the collected sensor data for drawing inferences. In this paper, we survey these existing semantic ontologies to provide an overview of the recent developments in this field. We highlight the fundamental ontological concepts (e.g., sensor-capabilities and context-awareness) required for an IoT-based application, and survey the existing ontologies which include these concepts. Based on our study, we also identify the shortcomings of currently available ontologies, which serves as a stepping stone to state the need for a common unified ontology for the IoT domain. version:1
arxiv-1706-04803 | A Policy-Aware Model for Intelligent Transportation Systems | http://arxiv.org/abs/1706.04803 | id:1706.04803 author:Zacharenia Garofalaki, Dimitrios Kallergis, Georgios Katsikogiannis, Christos Douligeris category:cs.DC cs.CR  published:2017-06-15 summary:Recent advancements in the field of smart machine-to-machine (M2M) communications impose the necessity to improve the service delivery by enforcing appropriate security rules. Due to the large number of connected devices, the criticality of the M2M applications, and the network stability weaknesses, we need to consider and analyse the security aspects and establish a flexible policy-aware architecture. This paper explores the relevant architectural challenges in this environment and proposes a Policy-Aware smart M2M Architecture (PAArc) based on ETSI M2M communications functional architecture. We explore the policy-based management aspects to improve the security of the M2M components and services and to mitigate the security concerns that arise by evaluating an Intelligent Transportation System use case. It is shown that the policy enforcement enables enhanced security management capabilities, increased agility, and better service levels in the field of smart M2M communications. version:2
arxiv-1707-00081 | Synthesizing Deep Neural Network Architectures using Biological Synaptic Strength Distributions | http://arxiv.org/abs/1707.00081 | id:1707.00081 author:A. H. Karimi, M. J. Shafiee, A. Ghodsi, A. Wong category:cs.NE cs.AI cs.CV stat.ML  published:2017-07-01 summary:In this work, we perform an exploratory study on synthesizing deep neural networks using biological synaptic strength distributions, and the potential influence of different distributions on modelling performance particularly for the scenario associated with small data sets. Surprisingly, a CNN with convolutional layer synaptic strengths drawn from biologically-inspired distributions such as log-normal or correlated center-surround distributions performed relatively well suggesting a possibility for designing deep neural network architectures that do not require many data samples to learn, and can sidestep current training procedures while maintaining or boosting modelling performance. version:1
arxiv-1605-00686 | Adaptive Candidate Generation for Scalable Edge-discovery Tasks on Data Graphs | http://arxiv.org/abs/1605.00686 | id:1605.00686 author:Mayank Kejriwal category:cs.AI cs.DB  published:2016-05-02 summary:Several `edge-discovery' applications over graph-based data models are known to have worst-case quadratic time complexity in the nodes, even if the discovered edges are sparse. One example is the generic link discovery problem between two graphs, which has invited research interest in several communities. Specific versions of this problem include link prediction in social networks, ontology alignment between metadata-rich RDF data, approximate joins, and entity resolution between instance-rich data. As large datasets continue to proliferate, reducing quadratic complexity to make the task practical is an important research problem. Within the entity resolution community, the problem is commonly referred to as blocking. A particular class of learnable blocking schemes is known as Disjunctive Normal Form (DNF) blocking schemes, and has emerged as state-of-the art for homogeneous (i.e. same-schema) tabular data. Despite the promise of these schemes, a formalism or learning framework has not been developed for them when input data instances are generic, attributed graphs possessing both node and edge heterogeneity. With such a development, the complexity-reducing scope of DNF schemes becomes applicable to a variety of problems, including entity resolution and type alignment between heterogeneous graphs, and link prediction in networks represented as attributed graphs. This paper presents a graph-theoretic formalism for DNF schemes, and investigates their learnability in an optimization framework. We also briefly describe an empirical case study encapsulating some of the principles in this paper. version:2
arxiv-1706-04652 | Learning a visuomotor controller for real world robotic grasping using simulated depth images | http://arxiv.org/abs/1706.04652 | id:1706.04652 author:Ulrich Viereck, Andreas ten Pas, Kate Saenko, Robert Platt category:cs.RO cs.AI  published:2017-06-14 summary:We want to build robots that are useful in unstructured real world applications, such as doing work in the household. Grasping in particular is an important skill in this domain, yet it remains a challenge. One of the key hurdles is handling unexpected changes or motion in the objects being grasped and kinematic noise or other errors in the robot. This paper proposes an approach to learning a closed-loop controller for robotic grasping that dynamically guides the gripper to the object. We use a wrist-mounted sensor to acquire depth images in front of the gripper and train a convolutional neural network to learn a distance function to true grasps for grasp configurations over an image. The training sensor data is generated in simulation, a major advantage over previous work that uses real robot experience, which is costly to obtain. Despite being trained in simulation, our approach works well on real noisy sensor images. We compare our controller in simulated and real robot experiments to a strong baseline for grasp pose detection, and find that our approach significantly outperforms the baseline in the presence of kinematic noise, perceptual errors and disturbances of the object during grasping. version:2
arxiv-1703-06815 | Foundations for a Probabilistic Event Calculus | http://arxiv.org/abs/1703.06815 | id:1703.06815 author:Fabio Aurelio D'Asaro, Antonis Bikakis, Luke Dickens, Rob Miller category:cs.AI  published:2017-03-20 summary:We present PEC, an Event Calculus (EC) style action language for reasoning about probabilistic causal and narrative information. It has an action language style syntax similar to that of the EC variant Modular-E. Its semantics is given in terms of possible worlds which constitute possible evolutions of the domain, and builds on that of EFEC, an epistemic extension of EC. We also describe an ASP implementation of PEC and show the sense in which this is sound and complete. version:2
arxiv-1706-10240 | Bridging the Gap between Probabilistic and Deterministic Models: A Simulation Study on a Variational Bayes Predictive Coding Recurrent Neural Network Model | http://arxiv.org/abs/1706.10240 | id:1706.10240 author:Ahmadreza Ahmadi, Jun Tani category:cs.AI cs.LG  published:2017-06-30 summary:The current paper proposes a novel variational Bayes predictive coding RNN model, which can learn to generate fluctuated temporal patterns from exemplars. The model learns to maximize the lower bound of the weighted sum of the regularization and reconstruction error terms. We examined how this weighting can affect development of different types of information processing while learning fluctuated temporal patterns. Simulation results show that strong weighting of the reconstruction term causes the development of deterministic chaos for imitating the randomness observed in target sequences, while strong weighting of the regularization term causes the development of stochastic dynamics imitating probabilistic processes observed in targets. Moreover, results indicate that the most generalized learning emerges between these two extremes. The paper concludes with implications in terms of the underlying neuronal mechanisms for autism spectrum disorder and for free action. version:1
arxiv-1706-10239 | Towards Understanding Generalization of Deep Learning: Perspective of Loss Landscapes | http://arxiv.org/abs/1706.10239 | id:1706.10239 author:Lei Wu, Zhanxing Zhu, Weinan E category:cs.LG cs.AI stat.ML  published:2017-06-30 summary:It is widely observed that deep learning models with learned parameters generalize well, even with much more model parameters than the number of training samples. We systematically investigate the underlying reasons why deep neural networks often generalize well, and reveal the difference between the minima (with the same training error) that generalize well and those they don't. We show that it is the characteristics the landscape of the loss function that explains the good generalization capability. For the landscape of loss function for deep networks, the volume of basin of attraction of good minima dominates over that of poor minima, which guarantees optimization methods with random initialization to converge to good minima. We theoretically justify our findings through analyzing 2-layer neural networks; and show that the low-complexity solutions have a small norm of Hessian matrix with respect to model parameters. For deeper networks, extensive numerical evidence helps to support our arguments. version:1
arxiv-1706-10234 | Probabilistic Active Learning of Functions in Structural Causal Models | http://arxiv.org/abs/1706.10234 | id:1706.10234 author:Paul K. Rubenstein, Ilya Tolstikhin, Philipp Hennig, Bernhard Schoelkopf category:stat.ML cs.AI cs.LG  published:2017-06-30 summary:We consider the problem of learning the functions computing children from parents in a Structural Causal Model once the underlying causal graph has been identified. This is in some sense the second step after causal discovery. Taking a probabilistic approach to estimating these functions, we derive a natural myopic active learning scheme that identifies the intervention which is optimally informative about all of the unknown functions jointly, given previously observed data. We test the derived algorithms on simple examples, to demonstrate that they produce a structured exploration policy that significantly improves on unstructured base-lines. version:1
arxiv-1706-10209 | Storage, Communication, and Load Balancing Trade-off in Distributed Cache Networks | http://arxiv.org/abs/1706.10209 | id:1706.10209 author:Mahdi Jafari Siavoshani, Ali Pourmiri, Seyed Pooya Shariatpanahi category:cs.IT cs.DC cs.DS cs.NI math.IT  published:2017-06-30 summary:We consider load balancing in a network of caching servers delivering contents to end users. Randomized load balancing via the so-called power of two choices is a well-known approach in parallel and distributed systems. In this framework, we investigate the tension between storage resources, communication cost, and load balancing performance. To this end, we propose a randomized load balancing scheme which simultaneously considers cache size limitation and proximity in the server redirection process. In contrast to the classical power of two choices setup, since the memory limitation and the proximity constraint cause correlation in the server selection process, we may not benefit from the power of two choices. However, we prove that in certain regimes of problem parameters, our scheme results in the maximum load of order $\Theta(\log\log n)$ (here $n$ is the network size). This is an exponential improvement compared to the scheme which assigns each request to the nearest available replica. Interestingly, the extra communication cost incurred by our proposed scheme, compared to the nearest replica strategy, is small. Furthermore, our extensive simulations show that the trade-off trend does not depend on the network topology and library popularity profile details. version:1
arxiv-0812-0885 | Elementary epistemological features of machine intelligence | http://arxiv.org/abs/0812.0885 | id:0812.0885 author:Marko Horvat category:cs.AI  published:2008-12-04 summary:Theoretical analysis of machine intelligence (MI) is useful for defining a common platform in both theoretical and applied artificial intelligence (AI). The goal of this paper is to set canonical definitions that can assist pragmatic research in both strong and weak AI. Described epistemological features of machine intelligence include relationship between intelligent behavior, intelligent and unintelligent machine characteristics, observable and unobservable entities and classification of intelligence. The paper also establishes algebraic definitions of efficiency and accuracy of MI tests as their quality measure. The last part of the paper addresses the learning process with respect to the traditional epistemology and the epistemology of MI described here. The proposed views on MI positively correlate to the Hegelian monistic epistemology and contribute towards amalgamating idealistic deliberations with the AI theory, particularly in a local frame of reference. version:4
arxiv-1706-10188 | A reliability-based approach for influence maximization using the evidence theory | http://arxiv.org/abs/1706.10188 | id:1706.10188 author:Siwar Jendoubi, Arnaud Martin category:cs.SI cs.AI  published:2017-06-30 summary:The influence maximization is the problem of finding a set of social network users, called influencers, that can trigger a large cascade of propagation. Influencers are very beneficial to make a marketing campaign goes viral through social networks for example. In this paper, we propose an influence measure that combines many influence indicators. Besides, we consider the reliability of each influence indicator and we present a distance-based process that allows to estimate the reliability of each indicator. The proposed measure is defined under the framework of the theory of belief functions. Furthermore, the reliability-based influence measure is used with an influence maximization model to select a set of users that are able to maximize the influence in the network. Finally, we present a set of experiments on a dataset collected from Twitter. These experiments show the performance of the proposed solution in detecting social influencers with good quality. version:1
arxiv-1706-10177 | Statistical Analysis of Dice CAPTCHA Usability | http://arxiv.org/abs/1706.10177 | id:1706.10177 author:Darko BrodiÄ, Alessia Amelio, Ivo R. Draganov category:cs.HC cs.AI cs.CR cs.DM  published:2017-06-30 summary:In this paper the elements of the CAPTCHA usability are analyzed. CAPTCHA, as a time progressive element in computer science, has been under constant interest of ordinary, professional as well as the scientific users of the Internet. The analysis is given based on the usability elements of CAPTCHA which are abbreviated as user-centric approach to the CAPTCHA. To demonstrate it, the specific type of Dice CAPTCHA is used in the experiment. The experiment is conducted on 190 Internet users with different demographic characteristics on laptop and tablet computers. The obtained results are statistically processed. At the end, the results are compared and conclusion of their use is drawn. version:1
arxiv-1706-10151 | A ROS multi-ontology references services: OWL reasoners and application prototyping issues | http://arxiv.org/abs/1706.10151 | id:1706.10151 author:Luca Buoncompagni, Alessio Capitanelli, Fulvio Mastrogiovanni category:cs.RO cs.AI cs.HC 68T40  published:2017-06-30 summary:The challenge of sharing and communicating information is crucial in complex human-robot interaction (HRI) scenarios. Ontologies and symbolic reasoning are the state-of-the-art approaches for a natural representation of knowledge, especially within the Semantic Web domain. In such a context, scripted paradigms have been adopted to achieve high expressiveness. Nevertheless, since symbolic reasoning is a high complexity problem, optimizing its performance requires a careful design of the knowledge. Specifically, a robot architecture requires the integration of several components implementing different behaviors and generating a series of beliefs. Most of the components are expected to access, manipulate, and reason upon a run-time generated semantic representation of knowledge grounding robot behaviors and perceptions through formal axioms, with soft real-time requirements. version:1
arxiv-1706-10117 | Restricted Causal Inference Algorithm | http://arxiv.org/abs/1706.10117 | id:1706.10117 author:MieczysÅaw A. KÅopotek category:cs.AI  published:2017-06-30 summary:This paper proposes a new algorithm for recovery of belief network structure from data handling hidden variables. It consists essentially in an extension of the CI algorithm of Spirtes et al. by restricting the number of conditional dependencies checked up to k variables and in an extension of the original CI by additional steps transforming so called partial including path graph into a belief network. Its correctness is demonstrated. version:1
arxiv-1706-10098 | From Big Data to Big Displays: High-Performance Visualization at Blue Brain | http://arxiv.org/abs/1706.10098 | id:1706.10098 author:Stefan Eilemann, Marwan Abdellah, Nicolas Antille, Ahmet Bilgili, Grigory Chevtchenko, Raphael Dumusc, Cyrille Favreau, Juan Hernando, Daniel Nachbaur, Pawel Podhajski, Jafet Villafranca, Felix SchÃ¼rmann category:cs.GR cs.DC  published:2017-06-30 summary:Blue Brain has pushed high-performance visualization (HPV) to complement its HPC strategy since its inception in 2007. In 2011, this strategy has been accelerated to develop innovative visualization solutions through increased funding and strategic partnerships with other research institutions. We present the key elements of this HPV ecosystem, which integrates C++ visualization applications with novel collaborative display systems. We motivate how our strategy of transforming visualization engines into services enables a variety of use cases, not only for the integration with high-fidelity displays, but also to build service oriented architectures, to link into web applications and to provide remote services to Python applications. version:1
arxiv-1706-10086 | Tuning and optimization for a variety of many-core architectures without changing a single line of implementation code using the Alpaka library | http://arxiv.org/abs/1706.10086 | id:1706.10086 author:Alexander Matthes, RenÃ© Widera, Erik Zenker, Benjamin Worpitz, Axel Huebl, Michael Bussmann category:cs.DC  published:2017-06-30 summary:We present an analysis on optimizing performance of a single C++11 source code using the Alpaka hardware abstraction library. For this we use the general matrix multiplication (GEMM) algorithm in order to show that compilers can optimize Alpaka code effectively when tuning key parameters of the algorithm. We do not intend to rival existing, highly optimized DGEMM versions, but merely choose this example to prove that Alpaka allows for platform-specific tuning with a single source code. In addition we analyze the optimization potential available with vendor-specific compilers when confronted with the heavily templated abstractions of Alpaka. We specifically test the code for bleeding edge architectures such as Nvidia's Tesla P100, Intel's Knights Landing (KNL) and Haswell architecture as well as IBM's Power8 system. On some of these we are able to reach almost 50\% of the peak floating point operation performance using the aforementioned means. When adding compiler-specific #pragmas we are able to reach 5 TFLOPS/s on a P100 and over 1 TFLOPS/s on a KNL system. version:1
arxiv-1706-10036 | Providing Effective Real-time Feedback in Simulation-based Surgical Training | http://arxiv.org/abs/1706.10036 | id:1706.10036 author:Xingjun Ma, Sudanthi Wijewickrema, Yun Zhou, Shuo Zhou, Stephen O'Leary, James Bailey category:cs.AI cs.LG  published:2017-06-30 summary:Virtual reality simulation is becoming popular as a training platform in surgical education. However, one important aspect of simulation-based surgical training that has not received much attention is the provision of automated real-time performance feedback to support the learning process. Performance feedback is actionable advice that improves novice behaviour. In simulation, automated feedback is typically extracted from prediction models trained using data mining techniques. Existing techniques suffer from either low effectiveness or low efficiency resulting in their inability to be used in real-time. In this paper, we propose a random forest based method that finds a balance between effectiveness and efficiency. Experimental results in a temporal bone surgery simulation show that the proposed method is able to extract highly effective feedback at a high level of efficiency. version:1
arxiv-1704-05816 | Analytical study of the "master-worker" framework scalability on multiprocessors with distributed memory | http://arxiv.org/abs/1704.05816 | id:1704.05816 author:L. B. Sokolinsky category:cs.DC  published:2017-04-19 summary:The paper is devoted to an analytical study of the "master-worker" framework scalability on multiprocessors with distributed memory. A new model of parallel computations called BSF is proposed. The BSF model is based on BSP and SPMD models. The scope of BSF model is the compute-intensive applications. The architecture of BSF-computer is defined. The structure of BSF-program is described. The Using this metric, the upper scalability bounds of BSF programs on distributed memory multiprocessors are evaluated. The formulas for estimating the parallel efficiency of BSF programs also proposed. version:7
arxiv-1706-09997 | Tight Load Balancing via Randomized Local Search | http://arxiv.org/abs/1706.09997 | id:1706.09997 author:Petra Berenbrink, Peter Kling, Christopher Liaw, Abbas Mehrabian category:cs.DC math.PR  published:2017-06-30 summary:We consider the following balls-into-bins process with $n$ bins and $m$ balls: each ball is equipped with a mutually independent exponential clock of rate 1. Whenever a ball's clock rings, the ball samples a random bin and moves there if the number of balls in the sampled bin is smaller than in its current bin. This simple process models a typical load balancing problem where users (balls) seek a selfish improvement of their assignment to resources (bins). From a game theoretic perspective, this is a randomized approach to the well-known Koutsoupias-Papadimitriou model, while it is known as randomized local search (RLS) in load balancing literature. Up to now, the best bound on the expected time to reach perfect balance was $O\left({(\ln n)}^2+\ln(n)\cdot n^2/m\right)$ due to Ganesh, Lilienthal, Manjunath, Proutiere, and Simatos (Load balancing via random local search in closed and open systems, Queueing Systems, 2012). We improve this to an asymptotically tight $O\left(\ln(n)+n^2/m\right)$. Our analysis is based on the crucial observation that performing "destructive moves" (reversals of RLS moves) cannot decrease the balancing time. This allows us to simplify problem instances and to ignore "inconvenient moves" in the analysis. version:1
arxiv-1706-09953 | Fast Processing of Large Graph Applications Using Asynchronous Architecture | http://arxiv.org/abs/1706.09953 | id:1706.09953 author:Michel A. Kinsy, Rashmi S. Agrawal, Hien D. Nguyen category:cs.AR  published:2017-06-29 summary:Graph algorithms and techniques are increasingly being used in scientific and commercial applications to express relations and explore large data sets. Although conventional or commodity computer architectures, like CPU or GPU, can compute fairly well dense graph algorithms, they are often inadequate in processing large sparse graph applications. Memory access patterns, memory bandwidth requirements and on-chip network communications in these applications do not fit in the conventional program execution flow. In this work, we propose and design a new architecture for fast processing of large graph applications. To leverage the lack of the spatial and temporal localities in these applications and to support scalable computational models, we design the architecture around two key concepts. (1) The architecture is a multicore processor of independently clocked processing elements. These elements communicate in a self-timed manner and use handshaking to perform synchronization, communication, and sequencing of operations. By being asynchronous, the operating speed at each processing element is determined by actual local latencies rather than global worst-case latencies. We create a specialized ISA to support these operations. (2) The application compilation and mapping process uses a graph clustering algorithm to optimize parallel computing of graph operations and load balancing. Through the clustering process, we make scalability an inherent property of the architecture where task-to-element mapping can be done at the graph node level or at node cluster level. A prototyped version of the architecture outperforms a comparable CPU by 10~20x across all benchmarks and provides 2~5x better power efficiency when compared to a GPU. version:1
arxiv-1706-09949 | Efficient, High-Quality Stack Rearrangement | http://arxiv.org/abs/1706.09949 | id:1706.09949 author:Shuai D. Han, Nicholas M. Stiffler, Kostas E. Bekris, Jingjin Yu category:cs.RO  published:2017-06-29 summary:This work studies rearrangement problems involving the sorting of robots or objects in stack-like containers, which can be accessed only from one side. Two scenarios are considered: one where every robot or object needs to reach a particular stack, and a setting in which each robot has a distinct position within a stack. In both cases, the goal is to minimize the number of stack removals that need to be performed. Stack rearrangement is shown to be intimately connected to pebble motion problems, a useful abstraction in multi-robot path planning. Through this connection, feasibility of stack rearrangement can be readily addressed. The paper continues to establish lower and upper bounds on optimality, which differ only by a logarithmic factor, in terms of stack removals. An algorithmic solution is then developed that produces suboptimal paths much quicker than a pebble motion solver. Furthermore, informed search-based methods are proposed for finding high-quality solutions. The efficiency and desirable scalability of the methods is demonstrated in simulation. version:1
arxiv-1706-09937 | Robust Detection in Leak-Prone Population Protocols | http://arxiv.org/abs/1706.09937 | id:1706.09937 author:Dan Alistarh, BartÅomiej Dudek, Adrian Kosowski, David Soloveichik, PrzemysÅaw UznaÅski category:cs.DS cs.DC  published:2017-06-29 summary:In contrast to electronic computation, chemical computation is noisy and susceptible to a variety of sources of error, which has prevented the construction of robust complex systems. To be effective, chemical algorithms must be designed with an appropriate error model in mind. Here we consider the model of chemical reaction networks that preserve molecular count (population protocols), and ask whether computation can be made robust to a natural model of unintended "leak" reactions. Our definition of leak is motivated by both the particular spurious behavior seen when implementing chemical reaction networks with DNA strand displacement cascades, as well as the unavoidable side reactions in any implementation due to the basic laws of chemistry. We develop a new "Robust Detection" algorithm for the problem of fast (logarithmic time) single molecule detection, and prove that it is robust to this general model of leaks. Besides potential applications in single molecule detection, the error-correction ideas developed here might enable a new class of robust-by-design chemical algorithms. Our analysis is based on a non-standard hybrid argument, combining ideas from discrete analysis of population protocols with classic Markov chain techniques. version:1
arxiv-1704-00917 | Deriving Probability Density Functions from Probabilistic Functional Programs | http://arxiv.org/abs/1704.00917 | id:1704.00917 author:Sooraj Bhat, Johannes BorgstrÃ¶m, Andrew D. Gordon, Claudio Russo category:cs.PL cs.AI F.3.2; G.3; I.2.5  published:2017-04-04 summary:The probability density function of a probability distribution is a fundamental concept in probability theory and a key ingredient in various widely used machine learning methods. However, the necessary framework for compiling probabilistic functional programs to density functions has only recently been developed. In this work, we present a density compiler for a probabilistic language with failure and both discrete and continuous distributions, and provide a proof of its soundness. The compiler greatly reduces the development effort of domain experts, which we demonstrate by solving inference problems from various scientific applications, such as modelling the global carbon cycle, using a standard Markov chain Monte Carlo framework. version:2
arxiv-1705-02257 | In-place Parallel Super Scalar Samplesort (IPS$^4$o) | http://arxiv.org/abs/1705.02257 | id:1705.02257 author:Michael Axtmann, Sascha Witt, Daniel Ferizovic, Peter Sanders category:cs.DC F.2.2  published:2017-05-05 summary:We present a sorting algorithm that works in-place, executes in parallel, is cache-efficient, avoids branch-mispredictions, and performs work O(n log n) for arbitrary inputs with high probability. The main algorithmic contributions are new ways to make distribution-based algorithms in-place: On the practical side, by using coarse-grained block-based permutations, and on the theoretical side, we show how to eliminate the recursion stack. Extensive experiments show that our algorithm IPS$^4$o scales well on a variety of multi-core machines. We outperform our closest in-place competitor by a factor of up to 3. Even as a sequential algorithm, we are up to 1.5 times faster than the closest sequential competitor, BlockQuicksort. version:2
arxiv-1706-09911 | Grasp Pose Detection in Point Clouds | http://arxiv.org/abs/1706.09911 | id:1706.09911 author:Andreas ten Pas, Marcus Gualtieri, Kate Saenko, Robert Platt category:cs.RO  published:2017-06-29 summary:Recently, a number of grasp detection methods have been proposed that can be used to localize robotic grasp configurations directly from sensor data without estimating object pose. The underlying idea is to treat grasp perception analogously to object detection in computer vision. These methods take as input a noisy and partially occluded RGBD image or point cloud and produce as output pose estimates of viable grasps, without assuming a known CAD model of the object. Although these methods generalize grasp knowledge to new objects well, they have not yet been demonstrated to be reliable enough for wide use. Many grasp detection methods achieve grasp success rates (grasp successes as a fraction of the total number of grasp attempts) between 75% and 95% for novel objects presented in isolation or in light clutter. Not only are these success rates too low for practical grasping applications, but the light clutter scenarios that are evaluated often do not reflect the realities of real world grasping. This paper proposes a number of innovations that together result in a significant improvement in grasp detection performance. The specific improvement in performance due to each of our contributions is quantitatively measured either in simulation or on robotic hardware. Ultimately, we report a series of robotic experiments that average a 93% end-to-end grasp success rate for novel objects presented in dense clutter. version:1
arxiv-1706-09838 | New Fairness Metrics for Recommendation that Embrace Differences | http://arxiv.org/abs/1706.09838 | id:1706.09838 author:Sirui Yao, Bert Huang category:cs.CY cs.AI  published:2017-06-29 summary:We study fairness in collaborative-filtering recommender systems, which are sensitive to discrimination that exists in historical data. Biased data can lead collaborative filtering methods to make unfair predictions against minority groups of users. We identify the insufficiency of existing fairness metrics and propose four new metrics that address different forms of unfairness. These fairness metrics can be optimized by adding fairness terms to the learning objective. Experiments on synthetic and real data show that our new metrics can better measure fairness than the baseline, and that the fairness objectives effectively help reduce unfairness. version:1
arxiv-1706-09829 | Towards Monocular Vision based Obstacle Avoidance through Deep Reinforcement Learning | http://arxiv.org/abs/1706.09829 | id:1706.09829 author:Linhai Xie, Sen Wang, Andrew Markham, Niki Trigoni category:cs.RO  published:2017-06-29 summary:Obstacle avoidance is a fundamental requirement for autonomous robots which operate in, and interact with, the real world. When perception is limited to monocular vision avoiding collision becomes significantly more challenging due to the lack of 3D information. Conventional path planners for obstacle avoidance require tuning a number of parameters and do not have the ability to directly benefit from large datasets and continuous use. In this paper, a dueling architecture based deep double-Q network (D3QN) is proposed for obstacle avoidance, using only monocular RGB vision. Based on the dueling and double-Q mechanisms, D3QN can efficiently learn how to avoid obstacles in a simulator even with very noisy depth information predicted from RGB image. Extensive experiments show that D3QN enables twofold acceleration on learning compared with a normal deep Q network and the models trained solely in virtual environments can be directly transferred to real robots, generalizing well to various new environments with previously unseen dynamic objects. version:1
arxiv-1706-09767 | Speaker Identification in each of the Neutral and Shouted Talking Environments based on Gender-Dependent Approach Using SPHMMs | http://arxiv.org/abs/1706.09767 | id:1706.09767 author:Ismail Shahin category:cs.AI cs.SD  published:2017-06-29 summary:It is well known that speaker identification performs extremely well in the neutral talking environments; however, the identification performance is declined sharply in the shouted talking environments. This work aims at proposing, implementing and testing a new approach to enhance the declined performance in the shouted talking environments. The new proposed approach is based on gender-dependent speaker identification using Suprasegmental Hidden Markov Models (SPHMMs) as classifiers. This proposed approach has been tested on two different and separate speech databases: our collected database and the Speech Under Simulated and Actual Stress (SUSAS) database. The results of this work show that gender-dependent speaker identification based on SPHMMs outperforms gender-independent speaker identification based on the same models and gender-dependent speaker identification based on Hidden Markov Models (HMMs) by about 6% and 8%, respectively. The results obtained based on the proposed approach are close to those obtained in subjective evaluation by human judges. version:1
arxiv-1706-09737 | Indoor UAV scheduling with Restful Task Assignment Algorithm | http://arxiv.org/abs/1706.09737 | id:1706.09737 author:Yohanes Khosiawan, Izabela Nielsen category:cs.AI  published:2017-06-29 summary:Research in UAV scheduling has obtained an emerging interest from scientists in the optimization field. When the scheduling itself has established a strong root since the 19th century, works on UAV scheduling in indoor environment has come forth in the latest decade. Several works on scheduling UAV operations in indoor (two and three dimensional) and outdoor environments are reported. In this paper, a further study on UAV scheduling in three dimensional indoor environment is investigated. Dealing with indoor environment\textemdash where humans, UAVs, and other elements or infrastructures are likely to coexist in the same space\textemdash draws attention towards the safety of the operations. In relation to the battery level, a preserved battery level leads to safer operations, promoting the UAV to have a decent remaining power level. A methodology which consists of a heuristic approach based on Restful Task Assignment Algorithm, incorporated with Particle Swarm Optimization Algorithm, is proposed. The motivation is to preserve the battery level throughout the operations, which promotes less possibility in having failed UAVs on duty. This methodology is tested with 54 benchmark datasets stressing on 4 different aspects: geographical distance, number of tasks, number of predecessors, and slack time. The test results and their characteristics in regard to the proposed methodology are discussed and presented. version:1
arxiv-1701-08547 | Autotuning GPU Kernels via Static and Predictive Analysis | http://arxiv.org/abs/1701.08547 | id:1701.08547 author:Robert V. Lim, Boyana Norris, Allen D. Malony category:cs.DC cs.PF  published:2017-01-30 summary:Optimizing the performance of GPU kernels is challenging for both human programmers and code generators. For example, CUDA programmers must set thread and block parameters for a kernel, but might not have the intuition to make a good choice. Similarly, compilers can generate working code, but may miss tuning opportunities by not targeting GPU models or performing code transformations. Although empirical autotuning addresses some of these challenges, it requires extensive experimentation and search for optimal code variants. This research presents an approach for tuning CUDA kernels based on static analysis that considers fine-grained code structure and the specific GPU architecture features. Notably, our approach does not require any program runs in order to discover near-optimal parameter settings. We demonstrate the applicability of our approach in enabling code autotuners such as Orio to produce competitive code variants comparable with empirical-based methods, without the high cost of experiments. version:3
arxiv-1706-09597 | Path Integral Networks: End-to-End Differentiable Optimal Control | http://arxiv.org/abs/1706.09597 | id:1706.09597 author:Masashi Okada, Luca Rigazio, Takenobu Aoshima category:cs.AI cs.SY  published:2017-06-29 summary:In this paper, we introduce Path Integral Networks (PI-Net), a recurrent network representation of the Path Integral optimal control algorithm. The network includes both system dynamics and cost models, used for optimal control based planning. PI-Net is fully differentiable, learning both dynamics and cost models end-to-end by back-propagation and stochastic gradient descent. Because of this, PI-Net can learn to plan. PI-Net has several advantages: it can generalize to unseen states thanks to planning, it can be applied to continuous control tasks, and it allows for a wide variety learning schemes, including imitation and reinforcement learning. Preliminary experiment results show that PI-Net, trained by imitation learning, can mimic control demonstrations for two simulated problems; a linear system and a pendulum swing-up problem. We also show that PI-Net is able to learn dynamics and cost models latent in the demonstrations. version:1
arxiv-1706-09393 | Default Logic and Bounded Treewidth | http://arxiv.org/abs/1706.09393 | id:1706.09393 author:Johannes K. Fichte, Markus Hecher, Irina Schindler category:cs.AI cs.CC cs.LO  published:2017-06-28 summary:In this paper, we study Reiter's propositional default logic when the treewidth of a certain graph representation (semi-incidence graph) of the input theory is bounded. We establish a dynamic programming algorithm on tree decompositions that decides whether a theory has a consistent stable extension or can even be used to enumerate all generating defaults that lead to stable extensions. We show that, for input theories whose semi-incidence graph has bounded treewidth, our algorithm decides whether a theory has a stable extension in linear time and enumerates all characteristic generating defaults with linear delay. version:1
arxiv-1706-09370 | DynASP2.5: Dynamic Programming on Tree Decompositions in Action | http://arxiv.org/abs/1706.09370 | id:1706.09370 author:Johannes K. Fichte, Markus Hecher, Michael Morak, Stefan Woltran category:cs.LO cs.AI cs.CC  published:2017-06-28 summary:A vibrant theoretical research area are efficient exact parameterized algorithms. Very recent solving competitions such as the PACE challenge show that there is also increasing practical interest in the parameterized algorithms community. An important research question is whether dedicated parameterized exact algorithms exhibit certain practical relevance and one can even beat well-established problem solvers. We consider the logic-based declarative modeling language and problem solving framework Answer Set Programming (ASP). State-of-the-art ASP solvers rely considerably on Sat-based algorithms. An ASP solver (DynASP2), which is based on a classical dynamic programming on tree decompositions, has been published very recently. Unfortunately, DynASP2 can outperform modern ASP solvers on programs of small treewidth only if the question of interest is to count the number of solutions. In this paper, we describe underlying concepts of our new implementation (DynASP2.5) that shows competitive behavior to state-of-the-art ASP solvers even for finding just one solution when solving problems as the Steiner tree problem that have been modeled in ASP on graphs with low treewidth. Our implementation is based on a novel approach that we call multi-pass dynamic programming (M-DPSINC). version:1
arxiv-1412-4972 | Max-Product Belief Propagation for Linear Programming: Applications to Combinatorial Optimization | http://arxiv.org/abs/1412.4972 | id:1412.4972 author:Sejun Park, Jinwoo Shin category:cs.AI  published:2014-12-16 summary:The max-product {belief propagation} (BP) is a popular message-passing heuristic for approximating a maximum-a-posteriori (MAP) assignment in a joint distribution represented by a graphical model (GM). In the past years, it has been shown that BP can solve a few classes of linear programming (LP) formulations to combinatorial optimization problems including maximum weight matching, shortest path and network flow, i.e., BP can be used as a message-passing solver for certain combinatorial optimizations. However, those LPs and corresponding BP analysis are very sensitive to underlying problem setups, and it has been not clear what extent these results can be generalized to. In this paper, we obtain a generic criteria that BP converges to the optimal solution of given LP, and show that it is satisfied in LP formulations associated to many classical combinatorial optimization problems including maximum weight perfect matching, shortest path, traveling salesman, cycle packing, vertex/edge cover and network flow. version:5
arxiv-1706-09351 | Near-Optimal Edge Evaluation in Explicit Generalized Binomial Graphs | http://arxiv.org/abs/1706.09351 | id:1706.09351 author:Sanjiban Choudhury, Shervin Javdani, Siddhartha Srinivasa, Sebastian Scherer category:cs.RO  published:2017-06-28 summary:Robotic motion-planning problems, such as a UAV flying fast in a partially-known environment or a robot arm moving around cluttered objects, require finding collision-free paths quickly. Typically, this is solved by constructing a graph, where vertices represent robot configurations and edges represent potentially valid movements of the robot between these configurations. The main computational bottlenecks are expensive edge evaluations to check for collisions. State of the art planning methods do not reason about the optimal sequence of edges to evaluate in order to find a collision free path quickly. In this paper, we do so by drawing a novel equivalence between motion planning and the Bayesian active learning paradigm of decision region determination (DRD). Unfortunately, a straight application of existing methods requires computation exponential in the number of edges in a graph. We present BISECT, an efficient and near-optimal algorithm to solve the DRD problem when edges are independent Bernoulli random variables. By leveraging this property, we are able to significantly reduce computational complexity from exponential to linear in the number of edges. We show that BISECT outperforms several state of the art algorithms on a spectrum of planning problems for mobile robots, manipulators, and real flight data collected from a full scale helicopter. version:1
arxiv-1706-09347 | Path planning for Robotic Mobile Fulfillment Systems | http://arxiv.org/abs/1706.09347 | id:1706.09347 author:Marius Merschformann, Lin Xie, Daniel Erdmann category:cs.AI cs.RO  published:2017-06-28 summary:This paper presents a collection of path planning algorithms for real-time movement of multiple robots across a Robotic Mobile Fulfillment System (RMFS). Robots are assigned to move storage units to pickers at working stations instead of requiring pickers to go to the storage area. Path planning algorithms aim to find paths for the robots to fulfill the requests without collisions or deadlocks. The state-of-the-art path planning algorithms, including WHCA*, FAR, BCP, OD&ID and CBS, were adapted to suit path planning in RMFS and integrated within a simulation tool to guide the robots from their starting points to their destinations during the storage and retrieval processes. Ten different layouts with a variety of numbers of robots, floors, pods, stations and the sizes of storage areas were considered in the simulation study. Performance metrics of throughput, path length and search time were monitored. Simulation results demonstrate the best algorithm based on each performance metric. version:1
arxiv-1706-09305 | Exposing Non-Atomic Methods of Concurrent Objects | http://arxiv.org/abs/1706.09305 | id:1706.09305 author:Michael Emmi, Constantin Enea category:cs.SE cs.DC  published:2017-06-28 summary:Multithreaded software is typically built with specialized concurrent objects like atomic integers, queues, and maps. These objects' methods are designed to behave according to certain consistency criteria like atomicity, despite being optimized to avoid blocking and exploit parallelism, e.g., by using atomic machine instructions like compare and exchange (cmpxchg). Exposing atomicity violations is important since they generally lead to elusive bugs that are difficult to identify, reproduce, and ultimately repair. In this work we expose atomicity violations in concurrent object implementations from the most widely-used software development kit: The Java Development Kit (JDK). We witness atomicity violations via simple test harnesses containing few concurrent method invocations. While stress testing is effective at exposing violations given catalytic test harnesses and lightweight means of falsifying atomicity, divining effectual catalysts can be difficult, and atomicity checks are generally cumbersome. We overcome these problems by automating test-harness search, and establishing atomicity via membership in precomputed sets of acceptable return-value outcomes. Our approach enables testing millions of executions of each harness each second (per processor core). This scale is important since atomicity violations are observed in very few executions (tens to hundreds out of millions) of very few harnesses (one out of hundreds to thousands). Our implementation is open source and publicly available. version:1
arxiv-1706-09278 | Learning Knowledge Graph Embeddings with Type Regularizer | http://arxiv.org/abs/1706.09278 | id:1706.09278 author:Bhushan Kotnis, Vivi Nastase category:cs.AI  published:2017-06-28 summary:Learning relations based on evidence from knowledge bases relies on processing the available relation instances. Many relations, however, have clear domain and range, which we hypothesize could help learn a better, more generalizing, model. We include such information in the RESCAL model in the form of a regularization factor added to the loss function that takes into account the types (categories) of the entities that appear as arguments to relations in the knowledge base. We note increased performance compared to the baseline model in terms of mean reciprocal rank and hits@N, N = 1, 3, 10. Furthermore, we discover scenarios that significantly impact the effectiveness of the type regularizer. version:1
arxiv-1704-08065 | Systematizing Decentralization and Privacy: Lessons from 15 Years of Research and Deployments | http://arxiv.org/abs/1704.08065 | id:1704.08065 author:Carmela Troncoso, Marios Isaakidis, George Danezis, Harry Halpin category:cs.CR cs.DC  published:2017-04-26 summary:Decentralized systems are a subset of distributed systems where multiple authorities control different components and no authority is fully trusted by all. This implies that any component in a decentralized system is potentially adversarial. We revise fifteen years of research on decentralization and privacy, and provide an overview of key systems, as well as key insights for designers of future systems. We show that decentralized designs can enhance privacy, integrity, and availability but also require careful trade-offs in terms of system complexity, properties provided, and degree of decentralization. These trade-offs need to be understood and navigated by designers. We argue that a combination of insights from cryptography, distributed systems, and mechanism design, aligned with the development of adequate incentives, are necessary to build scalable and successful privacy-preserving decentralized systems. version:3
arxiv-1706-09262 | Hierarchical Attentive Recurrent Tracking | http://arxiv.org/abs/1706.09262 | id:1706.09262 author:Adam R. Kosiorek, Alex Bewley, Ingmar Posner category:cs.CV cs.AI cs.NE  published:2017-06-28 summary:Class-agnostic object tracking is particularly difficult in cluttered environments as target specific discriminative models cannot be learned a priori. Inspired by how the human visual cortex employs spatial attention and separate "where" and "what" processing pathways to actively suppress irrelevant visual features, this work develops a hierarchical attentive recurrent model for single object tracking in videos. The first layer of attention discards the majority of background by selecting a region containing the object of interest, while the subsequent layers tune in on visual features particular to the tracked object. This framework is fully differentiable and can be trained in a purely data driven fashion by gradient methods. To improve training convergence, we augment the loss function with terms for a number of auxiliary tasks relevant for tracking. Evaluation of the proposed model is performed on two datasets of increasing difficulty: pedestrian tracking on the KTH activity recognition dataset and the KITTI object tracking dataset. version:1
arxiv-1707-00614 | Development of the SP machine | http://arxiv.org/abs/1707.00614 | id:1707.00614 author:J Gerard Wolff category:cs.AI  published:2017-06-28 summary:This paper describes the main things that need to be done to develop the "SP machine", based on the "SP theory of intelligence" and its realisation in the "SP computer model". The SP machine may be developed initially as a software virtual machine with high levels of parallel processing, hosted on a high-performance computer, or driven by high-parallel search processes in any of the leading search engines. An easy-to-use user interface is needed with facilities for visualisation of knowledge structures and processing. The system needs to be generalised to work with patterns in two dimensions, including the display of multiple alignments with 2D patterns. Research is needed into how the system may discover low-level features in speech and visual images. Existing strengths of the SP system in the processing of natural language may be developed towards the understanding of natural language and its production from meanings. This may be done most effectively in conjunction with the development of existing strengths of the SP system in unsupervised learning. Existing strengths of the SP system in pattern recognition may be developed for computer vision. Further work is needed on the representation of numbers and the performance of arithmetic processes in the SP system. A computer model is needed of SP-neural drawing on the existing conceptual model. When the SP machine is relatively mature, new hardware may be developed to exploit opportunities to increase the efficiency of computations. There is potential for the SP machine to be applied on relatively short timescales in such areas as information storage and retrieval, with intelligence, software engineering with or without automation or semi-automation, and information compression. version:1
arxiv-1704-07434 | Can Saliency Information Benefit Image Captioning Models? | http://arxiv.org/abs/1704.07434 | id:1704.07434 author:Hamed R. Tavakoli, Rakshith Shetty, Ali Borji, Jorma Laaksonen category:cs.CV cs.AI  published:2017-04-24 summary:To bridge the gap between humans and machines in image understanding and describing, we need further insight into how people describe a perceived scene. In this paper, we study the agreement between bottom-up saliency-based visual attention and object referrals in scene description constructs. We investigate the properties of human-written descriptions and machine-generated ones. We then propose a saliency-boosted image captioning model in order to investigate benefits from low-level cues in language models. We learn that (1) humans mention more salient objects earlier than less salient ones in their descriptions, (2) the better a captioning model performs, the better attention agreement it has with human descriptions, (3) the proposed saliency-boosted model, compared to its baseline form, does not improve significantly on the MS COCO database, indicating explicit bottom-up boosting does not help when the task is well learnt and tuned on a data, (4) a better generalization ability is, however, observed for the saliency-boosted model on unseen data. version:2
arxiv-1706-09153 | Drawbacks and alternatives to the numerical calculation of the base inertial parameters expressions for low mobility mechanisms | http://arxiv.org/abs/1706.09153 | id:1706.09153 author:Xabier Iriarte, Javier Ros, Aitor Plaza, Jokin Aginaga, Vicente Mata category:cs.RO 70E55  published:2017-06-28 summary:Base inertial parameters constitute a minimal inertial parametrization of mechanical systems that is of interest, for example, in parameter estimation and model reduction. Numerical and symbolic methods are available to determine their expressions. In this paper the problems associated with the numerical determination of the base inertial parameters expressions in the context of low mobility mechanisms are analyzed and discussed through and example. To circumvent these problems two alternatives are proposed: a variable precision arithmetic implementation of the customary numerical algorithm and the application of a general symbolic method. Finally, the advantages of both approaches compared to the numerical one are discussed in the context of the proposed low mobility example. version:1
arxiv-1706-09152 | Neural Sequence Prediction by Coaching | http://arxiv.org/abs/1706.09152 | id:1706.09152 author:Wenhu Chen, Guanlin Li, Shujie Liu, Zhirui Zhang, Mu Li, Ming Zhou category:cs.AI cs.LG stat.ML  published:2017-06-28 summary:In sequence prediction task, there mainly exist two types of learning algorithms. One genre based on maximum likelihood estimation (MLE) supervises the training in every time step via a surrogate loss function but leads to train-test discrepancy and hard-to-train problem. The other genre based on Reinforcement Learning gives the model freedom to generate samples and guides the training by feeding back task-level reward but suffers from high variance and instability problem. In general, these two frameworks both have their own trade-offs and complement each other. In this paper, we introduce a hybrid-coach framework to combine these two existing algorithms so that the supervision from MLE can stabilize RL training while RL can incorporate task-level loss into MLE training. To augment more easy-to-learn samples for MLE training and denser reward for RL training, the coach is encouraged to be close to both the data and model distribution. During training, the coach acts as a proxy target and pulls the model distribution to the data distribution, as the model makes progress it correspondingly upgrades itself to become harsher and finally anneal to the ultimate target distribution. With the coordination of the coach system, our hybrid-coach framework can efficiently resolve RL's reward sparsity problem and MLE's data sparsity problem. We apply our algorithm on two Machine Translation Task and show significant improvements over the state-of-art systems. version:1
arxiv-1706-08870 | Using ECC DRAM to Adaptively Increase Memory Capacity | http://arxiv.org/abs/1706.08870 | id:1706.08870 author:Yixin Luo, Saugata Ghose, Tianshi Li, Sriram Govindan, Bikash Sharma, Bryan Kelly, Amirali Boroumand, Onur Mutlu category:cs.AR  published:2017-06-27 summary:Modern DRAM modules are often equipped with hardware error correction capabilities, especially for DRAM deployed in large-scale data centers, as process technology scaling has increased the susceptibility of these devices to errors. To provide fast error detection and correction, error-correcting codes (ECC) are placed on an additional DRAM chip in a DRAM module. This additional chip expands the raw capacity of a DRAM module by 12.5%, but the applications are unable to use any of this extra capacity, as it is used exclusively to provide reliability for all data. In reality, there are a number of applications that do not need such strong reliability for all their data regions (e.g., some user batch jobs executing on a public cloud), and can instead benefit from using additional DRAM capacity to store extra data. Our goal in this work is to provide the additional capacity within an ECC DRAM module to applications when they do not need the high reliability of error correction. In this paper, we propose Capacity- and Reliability-Adaptive Memory (CREAM), a hardware mechanism that adapts error correcting DRAM modules to offer multiple levels of error protection, and provides the capacity saved from using weaker protection to applications. For regions of memory that do not require strong error correction, we either provide no ECC protection or provide error detection using multibit parity. We evaluate several layouts for arranging the data within ECC DRAM in these reduced-protection modes, taking into account the various trade-offs exposed from exploiting the extra chip. Our experiments show that the increased capacity provided by CREAM improves performance by 23.0% for a memory caching workload, and by 37.3% for a commercial web search workload executing production query traces. In addition, CREAM can increase bank-level parallelism within DRAM, offering further performance improvements. version:2
arxiv-1707-00617 | Submodular Function Maximization for Group Elevator Scheduling | http://arxiv.org/abs/1707.00617 | id:1707.00617 author:Srikumar Ramalingam, Arvind U. Raghunathan, Daniel Nikovski category:cs.AI math.CO 05B35 F.2.2; I.2.8  published:2017-06-28 summary:We propose a novel approach for group elevator scheduling by formulating it as the maximization of submodular function under a matroid constraint. In particular, we propose to model the total waiting time of passengers using a quadratic Boolean function. The unary and pairwise terms in the function denote the waiting time for single and pairwise allocation of passengers to elevators, respectively. We show that this objective function is submodular. The matroid constraints ensure that every passenger is allocated to exactly one elevator. We use a greedy algorithm to maximize the submodular objective function, and derive provable guarantees on the optimality of the solution. We tested our algorithm using Elevate 8, a commercial-grade elevator simulator that allows simulation with a wide range of elevator settings. We achieve significant improvement over the existing algorithms. version:1
arxiv-1706-09076 | A Pig, an Angel and a Cactus Walk Into a Blender: A Descriptive Approach to Visual Blending | http://arxiv.org/abs/1706.09076 | id:1706.09076 author:JoÃ£o M. Cunha, JoÃ£o GonÃ§alves, Pedro Martins, Penousal Machado, AmÃ­lcar Cardoso category:cs.AI cs.GR  published:2017-06-27 summary:A descriptive approach for automatic generation of visual blends is presented. The implemented system, the Blender, is composed of two components: the Mapper and the Visual Blender. The approach uses structured visual representations along with sets of visual relations which describe how the elements (in which the visual representation can be decomposed) relate among each other. Our system is a hybrid blender, as the blending process starts at the Mapper (conceptual level) and ends at the Visual Blender (visual representation level). The experimental results show that the Blender is able to create analogies from input mental spaces and produce well-composed blends, which follow the rules imposed by its base-analogy and its relations. The resulting blends are visually interesting and some can be considered as unexpected. version:1
arxiv-1706-09068 | ROS Navigation Tuning Guide | http://arxiv.org/abs/1706.09068 | id:1706.09068 author:Kaiyu Zheng category:cs.RO  published:2017-06-27 summary:The ROS navigation stack is powerful for mobile robots to move from place to place reliably. The job of navigation stack is to produce a safe path for the robot to execute, by processing data from odometry, sensors and environment map. Maximizing the performance of this navigation stack requires some fine tuning of parameters, and this is not as simple as it looks. One who is sophomoric about the concepts and reasoning may try things randomly, and wastes a lot of time. This article intends to guide the reader through the process of fine tuning navigation parameters. It is the reference when someone need to know the "how" and "why" when setting the value of key parameters. This guide assumes that the reader has already set up the navigation stack and ready to optimize it. This is also a summary of my work with the ROS navigation stack. version:1
arxiv-1706-09007 | Strategyproof Mechanisms for Additively Separable Hedonic Games and Fractional Hedonic Games | http://arxiv.org/abs/1706.09007 | id:1706.09007 author:Michele Flammini, Gianpiero Monaco, Qiang Zhang category:cs.AI cs.GT  published:2017-06-27 summary:Additively separable hedonic games and fractional hedonic games have received considerable attention. They are coalition forming games of selfish agents based on their mutual preferences. Most of the work in the literature characterizes the existence and structure of stable outcomes (i.e., partitions in coalitions), assuming that preferences are given. However, there is little discussion on this assumption. In fact, agents receive different utilities if they belong to different partitions, and thus it is natural for them to declare their preferences strategically in order to maximize their benefit. In this paper we consider strategyproof mechanisms for additively separable hedonic games and fractional hedonic games, that is, partitioning methods without payments such that utility maximizing agents have no incentive to lie about their true preferences. We focus on social welfare maximization and provide several lower and upper bounds on the performance achievable by strategyproof mechanisms for general and specific additive functions. In most of the cases we provide tight or asymptotically tight results. All our mechanisms are simple and can be computed in polynomial time. Moreover, all the lower bounds are unconditional, that is, they do not rely on any computational or complexity assumptions. version:1
arxiv-1706-08948 | Training a Fully Convolutional Neural Network to Route Integrated Circuits | http://arxiv.org/abs/1706.08948 | id:1706.08948 author:Sambhav R. Jain, Kye Okabe category:cs.CV cs.AI cs.LG  published:2017-06-27 summary:We present a deep, fully convolutional neural network that learns to route a circuit layout net with appropriate choice of metal tracks and wire class combinations. Inputs to the network are the encoded layouts containing spatial location of pins to be routed. After 15 fully convolutional stages followed by a score comparator, the network outputs 8 layout layers (corresponding to 4 route layers, 3 via layers and an identity-mapped pin layer) which are then decoded to obtain the routed layouts. We formulate this as a binary segmentation problem on a per-pixel per-layer basis, where the network is trained to correctly classify pixels in each layout layer to be 'on' or 'off'. To demonstrate learnability of layout design rules, we train the network on a dataset of 50,000 train and 10,000 validation samples that we generate based on certain pre-defined layout constraints. Precision, recall and $F_1$ score metrics are used to track the training progress. Our network achieves $F_1\approx97\%$ on the train set and $F_1\approx92\%$ on the validation set. We use PyTorch for implementing our model. version:1
arxiv-1706-08932 | Iterative Sequential Action Control for Stable, Model-Based Control of Nonlinear Systems | http://arxiv.org/abs/1706.08932 | id:1706.08932 author:Emmanouil Tzorakoleftherakis, Todd Murphey category:cs.RO cs.SY  published:2017-06-27 summary:This paper presents iterative Sequential Action Control (iSAC), a receding horizon approach for control of nonlinear systems. The iSAC method has a closed-form open-loop solution, which is iteratively updated between time steps by introducing constant control values applied for short duration. Application of a contractive constraint on the cost is shown to lead to closed-loop asymptotic stability under mild assumptions. The effect of asymptotically decaying disturbances on system trajectories is also examined. To demonstrate the applicability of iSAC to a variety of systems and conditions, we employ five different systems, including a 13-dimensional quaternion-based quadrotor. Each system is tested in different scenarios, ranging from feasible and infeasible trajectory tracking, to setpoint stabilization, with or without the presence of external disturbances. Finally, limitations of this work are discussed. version:1
arxiv-1706-08931 | Managing a Fleet of Autonomous Mobile Robots (AMR) using Cloud Robotics Platform | http://arxiv.org/abs/1706.08931 | id:1706.08931 author:Aniruddha Singhal, Nishant Kejriwal, Prasun Pallav, Soumyadeep Choudhury, Rajesh Sinha, Swagat Kumar category:cs.RO  published:2017-06-27 summary:In this paper, we provide details of implementing a system for managing a fleet of autonomous mobile robots (AMR) operating in a factory or a warehouse premise. While the robots are themselves autonomous in its motion and obstacle avoidance capability, the target destination for each robot is provided by a global planner. The global planner and the ground vehicles (robots) constitute a multi agent system (MAS) which communicate with each other over a wireless network. Three different approaches are explored for implementation. The first two approaches make use of the distributed computing based Networked Robotics architecture and communication framework of Robot Operating System (ROS) itself while the third approach uses Rapyuta Cloud Robotics framework for this implementation. The comparative performance of these approaches are analyzed through simulation as well as real world experiment with actual robots. These analyses provide an in-depth understanding of the inner working of the Cloud Robotics Platform in contrast to the usual ROS framework. The insight gained through this exercise will be valuable for students as well as practicing engineers interested in implementing similar systems else where. In the process, we also identify few critical limitations of the current Rapyuta platform and provide suggestions to overcome them. version:1
arxiv-1705-04524 | Learning to Predict Blood Pressure with Deep Bidirectional LSTM Network | http://arxiv.org/abs/1705.04524 | id:1705.04524 author:Peng Su, Xiaorong Ding, Yuanting Zhang, Fen Miao, Ni Zhao category:cs.LG cs.AI math.DS stat.ML  published:2017-05-12 summary:Blood pressure (BP) has been a difficult vascular risk factor to measure precisely and continuously due to its multiscale temporal dependencies. However, both pulse transit time (PTT) model and regression model fail to learn such dependencies and thus suffer from accuracy decay over time. In this work, we addressed the limitation of existing BP prediction models by formulating BP extraction as a sequence prediction problem in which both the input and target are temporal sequence. By incorporating both a bidirectional layer structure and a deep architecture in a standard long short term-memory (LSTM), we established a deep bidirectional LSTM (DB-LSTM) network that can adaptively discover the latent structures of different timescales in BP sequences and automatically learn such multiscale dependencies. We evaluated our proposed model on a static and follow-up continuous BP dataset, and the results show that DB-LSTM network can effectively learn different timescale dependencies in the BP sequences and advances the state-of-the-art by achieving superior accuracy performance than other leading methods on both datasets. To the best of our knowledge, this is the first study to validate the ability of recurrent neural networks to learn the multiscale dependencies of long-term continuous BP sequence. version:2
arxiv-1706-08884 | When Neurons Fail | http://arxiv.org/abs/1706.08884 | id:1706.08884 author:El Mahdi El Mhamdi, Rachid Guerraoui category:stat.ML cs.DC cs.NE q-bio.NC  published:2017-06-27 summary:We view a neural network as a distributed system of which neurons can fail independently, and we evaluate its robustness in the absence of any (recovery) learning phase. We give tight bounds on the number of neurons that can fail without harming the result of a computation. To determine our bounds, we leverage the fact that neural activation functions are Lipschitz-continuous. Our bound is on a quantity, we call the \textit{Forward Error Propagation}, capturing how much error is propagated by a neural network when a given number of components is failing, computing this quantity only requires looking at the topology of the network, while experimentally assessing the robustness of a network requires the costly experiment of looking at all the possible inputs and testing all the possible configurations of the network corresponding to different failure situations, facing a discouraging combinatorial explosion. We distinguish the case of neurons that can fail and stop their activity (crashed neurons) from the case of neurons that can fail by transmitting arbitrary values (Byzantine neurons). Interestingly, as we show in the paper, our bound can easily be extended to the case where synapses can fail. We show how our bound can be leveraged to quantify the effect of memory cost reduction on the accuracy of a neural network, to estimate the amount of information any neuron needs from its preceding layer, enabling thereby a boosting scheme that prevents neurons from waiting for unnecessary signals. We finally discuss the trade-off between neural networks robustness and learning cost. version:1
arxiv-1706-08775 | Topometric Localization with Deep Learning | http://arxiv.org/abs/1706.08775 | id:1706.08775 author:Gabriel L. Oliveira, Noha Radwan, Wolfram Burgard, Thomas Brox category:cs.CV cs.RO  published:2017-06-27 summary:Compared to LiDAR-based localization methods, which provide high accuracy but rely on expensive sensors, visual localization approaches only require a camera and thus are more cost-effective while their accuracy and reliability typically is inferior to LiDAR-based methods. In this work, we propose a vision-based localization approach that learns from LiDAR-based localization methods by using their output as training data, thus combining a cheap, passive sensor with an accuracy that is on-par with LiDAR-based localization. The approach consists of two deep networks trained on visual odometry and topological localization, respectively, and a successive optimization to combine the predictions of these two networks. We evaluate the approach on a new challenging pedestrian-based dataset captured over the course of six months in varying weather conditions with a high degree of noise. The experiments demonstrate that the localization errors are up to 10 times smaller than with traditional vision-based localization methods. version:1
arxiv-1703-09312 | Dex-Net 2.0: Deep Learning to Plan Robust Grasps with Synthetic Point Clouds and Analytic Grasp Metrics | http://arxiv.org/abs/1703.09312 | id:1703.09312 author:Jeffrey Mahler, Jacky Liang, Sherdil Niyaz, Michael Laskey, Richard Doan, Xinyu Liu, Juan Aparicio Ojea, Ken Goldberg category:cs.RO  published:2017-03-27 summary:To reduce data collection time for deep learning of robust robotic grasp plans, we explore training from a synthetic dataset of 6.7 million point clouds, grasps, and analytic grasp metrics generated from thousands of 3D models from Dex-Net 1.0 in randomized poses on a table. We use the resulting dataset, Dex-Net 2.0, to train a Grasp Quality Convolutional Neural Network (GQ-CNN) model that rapidly predicts the probability of success of grasps from depth images, where grasps are specified as the planar position, angle, and depth of a gripper relative to an RGB-D sensor. Experiments with over 1,000 trials on an ABB YuMi comparing grasp planning methods on singulated objects suggest that a GQ-CNN trained with only synthetic data from Dex-Net 2.0 can be used to plan grasps in 0.8sec with a success rate of 93% on eight known objects with adversarial geometry and is 3x faster than registering point clouds to a precomputed dataset of objects and indexing grasps. The Dex-Net 2.0 grasp planner also has the highest success rate on a dataset of 10 novel rigid objects and achieves 99% precision (one false positive out of 69 grasps classified as robust) on a dataset of 40 novel household objects, some of which are articulated or deformable. Code, datasets, videos, and supplementary material are available at http://berkeleyautomation.github.io/dex-net. version:2
arxiv-1706-08700 | PasMoQAP: A Parallel Asynchronous Memetic Algorithm for solving the Multi-Objective Quadratic Assignment Problem | http://arxiv.org/abs/1706.08700 | id:1706.08700 author:Claudio Sanhueza, Francia Jimenez, Regina Berretta, Pablo Moscato category:cs.NE cs.DC  published:2017-06-27 summary:Multi-Objective Optimization Problems (MOPs) have attracted growing attention during the last decades. Multi-Objective Evolutionary Algorithms (MOEAs) have been extensively used to address MOPs because are able to approximate a set of non-dominated high-quality solutions. The Multi-Objective Quadratic Assignment Problem (mQAP) is a MOP. The mQAP is a generalization of the classical QAP which has been extensively studied, and used in several real-life applications. The mQAP is defined as having as input several flows between the facilities which generate multiple cost functions that must be optimized simultaneously. In this study, we propose PasMoQAP, a parallel asynchronous memetic algorithm to solve the Multi-Objective Quadratic Assignment Problem. PasMoQAP is based on an island model that structures the population by creating sub-populations. The memetic algorithm on each island individually evolve a reduced population of solutions, and they asynchronously cooperate by sending selected solutions to the neighboring islands. The experimental results show that our approach significatively outperforms all the island-based variants of the multi-objective evolutionary algorithm NSGA-II. We show that PasMoQAP is a suitable alternative to solve the Multi-Objective Quadratic Assignment Problem. version:1
arxiv-1706-08697 | Controlled Tactile Exploration and Haptic Object Recognition | http://arxiv.org/abs/1706.08697 | id:1706.08697 author:Massimo Regoli, Nawid Jamali, Giorgio Metta, Lorenzo Natale category:cs.RO cs.LG  published:2017-06-27 summary:In this paper we propose a novel method for in-hand object recognition. The method is composed of a grasp stabilization controller and two exploratory behaviours to capture the shape and the softness of an object. Grasp stabilization plays an important role in recognizing objects. First, it prevents the object from slipping and facilitates the exploration of the object. Second, reaching a stable and repeatable position adds robustness to the learning algorithm and increases invariance with respect to the way in which the robot grasps the object. The stable poses are estimated using a Gaussian mixture model (GMM). We present experimental results showing that using our method the classifier can successfully distinguish 30 objects.We also compare our method with a benchmark experiment, in which the grasp stabilization is disabled. We show, with statistical significance, that our method outperforms the benchmark method. version:1
arxiv-1706-08685 | Material Recognition CNNs and Hierarchical Planning for Biped Robot Locomotion on Slippery Terrain | http://arxiv.org/abs/1706.08685 | id:1706.08685 author:Martim Brandao, Yukitoshi Minami Shiguematsu, Kenji Hashimoto, Atsuo Takanishi category:cs.RO cs.CV  published:2017-06-27 summary:In this paper we tackle the problem of visually predicting surface friction for environments with diverse surfaces, and integrating this knowledge into biped robot locomotion planning. The problem is essential for autonomous robot locomotion since diverse surfaces with varying friction abound in the real world, from wood to ceramic tiles, grass or ice, which may cause difficulties or huge energy costs for robot locomotion if not considered. We propose to estimate friction and its uncertainty from visual estimation of material classes using convolutional neural networks, together with probability distribution functions of friction associated with each material. We then robustly integrate the friction predictions into a hierarchical (footstep and full-body) planning method using chance constraints, and optimize the same trajectory costs at both levels of the planning method for consistency. Our solution achieves fully autonomous perception and locomotion on slippery terrain, which considers not only friction and its uncertainty, but also collision, stability and trajectory cost. We show promising friction prediction results in real pictures of outdoor scenarios, and planning experiments on a real robot facing surfaces with different friction. version:1
arxiv-1706-08642 | Error Characterization, Mitigation, and Recovery in Flash Memory Based Solid-State Drives | http://arxiv.org/abs/1706.08642 | id:1706.08642 author:Yu Cai, Saugata Ghose, Erich F. Haratsch, Yixin Luo, Onur Mutlu category:cs.AR  published:2017-06-27 summary:NAND flash memory is ubiquitous in everyday life today because its capacity has continuously increased and cost has continuously decreased over decades. This positive growth is a result of two key trends: (1) effective process technology scaling, and (2) multi-level (e.g., MLC, TLC) cell data coding. Unfortunately, the reliability of raw data stored in flash memory has also continued to become more difficult to ensure, because these two trends lead to (1) fewer electrons in the flash memory cell (floating gate) to represent the data and (2) larger cell-to-cell interference and disturbance effects. Without mitigation, worsening reliability can reduce the lifetime of NAND flash memory. As a result, flash memory controllers in solid-state drives (SSDs) have become much more sophisticated: they incorporate many effective techniques to ensure the correct interpretation of noisy data stored in flash memory cells. In this article, we review recent advances in SSD error characterization, mitigation, and data recovery techniques for reliability and lifetime improvement. We provide rigorous experimental data from state-of-the-art MLC and TLC NAND flash devices on various types of flash memory errors, to motivate the need for such techniques. Based on the understanding developed by the experimental characterization, we describe several mitigation and recovery techniques, including (1) cell-to-cell interference mitigation, (2) optimal multi-level cell sensing, (3) error correction using state-of-the-art algorithms and methods, and (4) data recovery when error correction fails. We quantify the reliability improvement provided by each of these techniques. Looking forward, we briefly discuss how flash memory and these techniques could evolve into the future. version:1
arxiv-1706-08611 | Relating Complexity-theoretic Parameters with SAT Solver Performance | http://arxiv.org/abs/1706.08611 | id:1706.08611 author:Edward Zulkoski, Ruben Martins, Christoph Wintersteiger, Robert Robere, Jia Liang, Krzysztof Czarnecki, Vijay Ganesh category:cs.AI  published:2017-06-26 summary:Over the years complexity theorists have proposed many structural parameters to explain the surprising efficiency of conflict-driven clause-learning (CDCL) SAT solvers on a wide variety of large industrial Boolean instances. While some of these parameters have been studied empirically, until now there has not been a unified comparative study of their explanatory power on a comprehensive benchmark. We correct this state of affairs by conducting a large-scale empirical evaluation of CDCL SAT solver performance on nearly 7000 industrial and crafted formulas against several structural parameters such as backdoors, treewidth, backbones, and community structure. Our study led us to several results. First, we show that while such parameters only weakly correlate with CDCL solving time, certain combinations of them yield much better regression models. Second, we show how some parameters can be used as a "lens" to better understand the efficiency of different solving heuristics. Finally, we propose a new complexity-theoretic parameter, which we call learning-sensitive with restarts (LSR) backdoors, that extends the notion of learning-sensitive (LS) backdoors to incorporate restarts and discuss algorithms to compute them. We mathematically prove that for certain class of instances minimal LSR-backdoors are exponentially smaller than minimal-LS backdoors. version:1
arxiv-1706-08605 | Developing Bug-Free Machine Learning Systems With Formal Mathematics | http://arxiv.org/abs/1706.08605 | id:1706.08605 author:Daniel Selsam, Percy Liang, David L. Dill category:cs.SE cs.AI  published:2017-06-26 summary:Noisy data, non-convex objectives, model misspecification, and numerical instability can all cause undesired behaviors in machine learning systems. As a result, detecting actual implementation errors can be extremely difficult. We demonstrate a methodology in which developers use an interactive proof assistant to both implement their system and to state a formal theorem defining what it means for their system to be correct. The process of proving this theorem interactively in the proof assistant exposes all implementation errors since any error in the program would cause the proof to fail. As a case study, we implement a new system, Certigrad, for optimizing over stochastic computation graphs, and we generate a formal (i.e. machine-checkable) proof that the gradients sampled by the system are unbiased estimates of the true mathematical gradients. We train a variational autoencoder using Certigrad and find the performance comparable to training the same model in TensorFlow. version:1
arxiv-1706-08569 | Parareal Algorithm Implementation and Simulation in Julia | http://arxiv.org/abs/1706.08569 | id:1706.08569 author:Tyler M. Masthay, Saverio Perugini category:cs.MS cs.DC cs.NA  published:2017-06-26 summary:We present a full implementation of the parareal algorithm---an integration technique to solve differential equations in parallel---in the Julia programming language for a fully general, first-order, initial-value problem. Our implementation accepts both coarse and fine integrators as functional arguments. We use Euler's method and another Runge-Kutta integration technique as the integrators in our experiments. We also present a simulation of the algorithm for purposes of pedagogy. version:1
arxiv-1706-08568 | Neural Question Answering at BioASQ 5B | http://arxiv.org/abs/1706.08568 | id:1706.08568 author:Georg Wiese, Dirk Weissenborn, Mariana Neves category:cs.CL cs.AI cs.NE  published:2017-06-26 summary:This paper describes our submission to the 2017 BioASQ challenge. We participated in Task B, Phase B which is concerned with biomedical question answering (QA). We focus on factoid and list question, using an extractive QA model, that is, we restrict our system to output substrings of the provided text snippets. At the core of our system, we use FastQA, a state-of-the-art neural QA system. We extended it with biomedical word embeddings and changed its answer layer to be able to answer list questions in addition to factoid questions. We pre-trained the model on a large-scale open-domain QA dataset, SQuAD, and then fine-tuned the parameters on the BioASQ training set. With our approach, we achieve state-of-the-art results on factoid questions and competitive results on list questions. version:1
arxiv-1706-08560 | Skill Learning by Autonomous Robotic Playing using Active Learning and Creativity | http://arxiv.org/abs/1706.08560 | id:1706.08560 author:Simon Hangl, Vedran Dunjko, Hans J. Briegel, Justus Piater category:cs.RO  published:2017-06-26 summary:We treat the problem of autonomous acquisition of manipulation skills where problem-solving strategies are initially available only for a narrow range of situations. We propose to extend the range of solvable situations by autonomous playing with the object. By applying previously-trained skills and behaviours, the robot learns how to prepare situations for which a successful strategy is already known. The information gathered during autonomous play is additionally used to learn an environment model. This model is exploited for active learning and the creative generation of novel preparatory behaviours. We apply our approach on a wide range of different manipulation tasks, e.g. book grasping, grasping of objects of different sizes by selecting different grasping strategies, placement on shelves, and tower disassembly. We show that the creative behaviour generation mechanism enables the robot to solve previously-unsolvable tasks, e.g. tower disassembly. We use success statistics gained during real-world experiments to simulate the convergence behaviour of our system. Experiments show that active improves the learning speed by around 9 percent in the book grasping scenario. version:1
arxiv-1706-08502 | Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog | http://arxiv.org/abs/1706.08502 | id:1706.08502 author:Satwik Kottur, JosÃ© M. F. Moura, Stefan Lee, Dhruv Batra category:cs.CL cs.AI cs.CV  published:2017-06-26 summary:A number of recent works have proposed techniques for end-to-end learning of communication protocols among cooperative multi-agent populations, and have simultaneously found the emergence of grounded human-interpretable language in the protocols developed by the agents, all learned without any human supervision! In this paper, using a Task and Tell reference game between two agents as a testbed, we present a sequence of 'negative' results culminating in a 'positive' one -- showing that while most agent-invented languages are effective (i.e. achieve near-perfect task rewards), they are decidedly not interpretable or compositional. In essence, we find that natural language does not emerge 'naturally', despite the semblance of ease of natural-language-emergence that one may gather from recent literature. We discuss how it is possible to coax the invented languages to become more and more human-like and compositional by increasing restrictions on how two agents may communicate. version:1
arxiv-1706-08493 | Towards the Evolution of Multi-Layered Neural Networks: A Dynamic Structured Grammatical Evolution Approach | http://arxiv.org/abs/1706.08493 | id:1706.08493 author:Filipe AssunÃ§Ã£o, Nuno LourenÃ§o, Penousal Machado, Bernardete Ribeiro category:cs.NE cs.AI  published:2017-06-26 summary:Current grammar-based NeuroEvolution approaches have several shortcomings. On the one hand, they do not allow the generation of Artificial Neural Networks (ANNs composed of more than one hidden-layer. On the other, there is no way to evolve networks with more than one output neuron. To properly evolve ANNs with more than one hidden-layer and multiple output nodes there is the need to know the number of neurons available in previous layers. In this paper we introduce Dynamic Structured Grammatical Evolution (DSGE): a new genotypic representation that overcomes the aforementioned limitations. By enabling the creation of dynamic rules that specify the connection possibilities of each neuron, the methodology enables the evolution of multi-layered ANNs with more than one output neuron. Results in different classification problems show that DSGE evolves effective single and multi-layered ANNs, with a varying number of output neurons. version:1
arxiv-1704-05136 | The Causality/Repair Connection in Databases: Causality-Programs | http://arxiv.org/abs/1704.05136 | id:1704.05136 author:Leopoldo Bertossi category:cs.DB cs.AI  published:2017-04-17 summary:In this work, answer-set programs that specify repairs of databases are used as a basis for solving computational and reasoning problems about causes for query answers from databases. version:2
arxiv-1706-08476 | Generative Encoder-Decoder Models for Task-Oriented Spoken Dialog Systems with Chatting Capability | http://arxiv.org/abs/1706.08476 | id:1706.08476 author:Tiancheng Zhao, Allen Lu, Kyusong Lee, Maxine Eskenazi category:cs.CL cs.AI  published:2017-06-26 summary:Generative encoder-decoder models offer great promise in developing domain-general dialog systems. However, they have mainly been applied to open-domain conversations. This paper presents a practical and novel framework for building task-oriented dialog systems based on encoder-decoder models. This framework enables encoder-decoder models to accomplish slot-value independent decision-making and interact with external databases. Moreover, this paper shows the flexibility of the proposed method by interleaving chatting capability with a slot-filling system for better out-of-domain recovery. The models were trained on both real-user data from a bus information system and human-human chat data. Results show that the proposed framework achieves good performance in both offline evaluation metrics and in task success rate with human users. version:1
arxiv-1704-00693 | Loop Tiling in Large-Scale Stencil Codes at Run-time with OPS | http://arxiv.org/abs/1704.00693 | id:1704.00693 author:Istvan Z Reguly, Gihan R Mudalige, Mike B Giles category:cs.PF cs.DC cs.DS  published:2017-04-03 summary:The key common bottleneck in most stencil codes is data movement, and prior research has shown that improving data locality through optimisations that schedule across loops do particularly well. However, in many large PDE applications it is not possible to apply such optimisations through compilers because there are many options, execution paths and data per grid point, many dependent on run-time parameters, and the code is distributed across different compilation units. In this paper, we adapt the data locality improving optimisation called iteration space slicing for use in large OPS applications both in shared-memory and distributed-memory systems, relying on run-time analysis and delayed execution. We evaluate our approach on a number of applications, observing speedups of 2$\times$ on the Cloverleaf 2D/3D proxy application, which contain 83/141 loops respectively, $3.5\times$ on the linear solver TeaLeaf, and $1.7\times$ on the compressible Navier-Stokes solver OpenSBLI. We demonstrate strong and weak scalability up to 4608 cores of CINECA's Marconi supercomputer. We also evaluate our algorithms on Intel's Knights Landing, demonstrating maintained throughput as the problem size grows beyond 16GB, and we do scaling studies up to 8704 cores. The approach is generally applicable to any stencil DSL that provides per loop data access information. version:2
arxiv-1706-08420 | StreamLearner: Distributed Incremental Machine Learning on Event Streams: Grand Challenge | http://arxiv.org/abs/1706.08420 | id:1706.08420 author:Christian Mayer, Ruben Mayer, Majd Abdo category:cs.DC  published:2017-06-26 summary:Today, massive amounts of streaming data from smart devices need to be analyzed automatically to realize the Internet of Things. The Complex Event Processing (CEP) paradigm promises low-latency pattern detection on event streams. However, CEP systems need to be extended with Machine Learning (ML) capabilities such as online training and inference in order to be able to detect fuzzy patterns (e.g., outliers) and to improve pattern recognition accuracy during runtime using incremental model training. In this paper, we propose a distributed CEP system denoted as StreamLearner for ML-enabled complex event detection. The proposed programming model and data-parallel system architecture enable a wide range of real-world applications and allow for dynamically scaling up and out system resources for low-latency, high-throughput event processing. We show that the DEBS Grand Challenge 2017 case study (i.e., anomaly detection in smart factories) integrates seamlessly into the StreamLearner API. Our experiments verify scalability and high event throughput of StreamLearner. version:1
arxiv-1702-04866 | Proust: A Design Space for Highly-Concurrent Transactional Data Structures | http://arxiv.org/abs/1702.04866 | id:1702.04866 author:Thomas D. Dickerson, Paul Gazzillo, Maurice Herlihy, Eric Koskinen category:cs.DC cs.DS  published:2017-02-16 summary:Most STM systems are poorly equipped to support libraries of concurrent data structures. One reason is that they typically detect conflicts by tracking transactions' read sets and write sets, an approach that often leads to false conflicts. A second is that existing data structures and libraries often need to be rewritten from scratch to support transactional conflict detection and rollback. This paper introduces Proust, a framework for the design and implementation of transactional data structures. Proust is designed to maximize re-use of existing well-engineered by providing transactional "wrappers" to make existing thread-safe concurrent data structures transactional. Proustian objects are also integrated with an underling STM system, allowing them to take advantage of well-engineered STM conflict detection mechanisms. Proust generalizes and unifies prior approaches such as boosting and predication. version:2
arxiv-1706-08366 | Ordered and Delayed Adversaries and How to Work against Them on Shared Channel | http://arxiv.org/abs/1706.08366 | id:1706.08366 author:Marek Klonowski, Dariusz R. Kowalski, Jaroslaw Mirek category:cs.DC  published:2017-06-26 summary:Performance of a distributed algorithm depends on environment in which the algorithm is executed. This is often modeled as a game between the algorithm and a conceptual adversary causing specific distractions. In this work we define a class of ordered adversaries, which cause distractions according to some partial order fixed by the adversary before the execution, and study how they affect performance of algorithms. For this purpose, we focus on well-known Do-All problem of performing t tasks on a shared channel consisting of p crash-prone stations. The channel restricts communication by the fact that no message is delivered to the alive stations if more than one station transmits at the same time. The most popular and meaningful performance measure for Do-All type of problems considered in the literature is work, defined as the total number of available processor steps during the whole execution. The question addressed in this work is how the ordered adversaries controlling crashes of stations influence work performance of Do-All algorithms. We provide two randomized distributed algorithms. The first solves Do-All with work O(t+p\sqrt{t}\log p) against the Linearly-Ordered adversary, restricted by some pre-defined linear order of crashing stations. Another algorithm is developed against the Weakly-Adaptive adversary, restricted by some pre-defined set of crash-prone stations, it can be seen as an ordered adversary with the order being an anti-chain consisting of crashing stations. The work done by this algorithm is O(t+p\sqrt{t}+p\min{p/(p-f),t}\log p). Both results are close to the corresponding lower bounds from [CKL]. We generalize this result to the class of adversaries restricted by partial order of f stations with maximum anti-chain of size k and complementary lower bound. We also consider a class of delayed adaptive adversaries, that is, who could see random choices with some delay. We give an algorithm that works efficiently against the 1-RD adversary, which could see random choices of stations with one round delay, achieving close to optimal O(t+p\sqrt{t}\log^2 p) work complexity. This shows that restricting adversary by even 1 round delay results in (almost) optimal work on a shared channel. version:1
arxiv-1706-08362 | Dynamic Load Balancing for PIC code using Eulerian/Lagrangian partitioning | http://arxiv.org/abs/1706.08362 | id:1706.08362 author:Marc Sauget, Guillaume Latu category:cs.DC  published:2017-06-26 summary:This document presents an analysis of different load balance strategies for a Plasma physics code that models high energy particle beams with PIC method. A comparison of different load balancing algorithms is given: static or dynamic ones. Lagrangian and Eulerian partitioning techniques have been investigated. version:1
arxiv-1706-08359 | GPU-acceleration for Large-scale Tree Boosting | http://arxiv.org/abs/1706.08359 | id:1706.08359 author:Huan Zhang, Si Si, Cho-Jui Hsieh category:stat.ML cs.DC cs.LG  published:2017-06-26 summary:In this paper, we present a novel massively parallel algorithm for accelerating the decision tree building procedure on GPUs (Graphics Processing Units), which is a crucial step in Gradient Boosted Decision Tree (GBDT) and random forests training. Previous GPU based tree building algorithms are based on parallel multi-scan or radix sort to find the exact tree split, and thus suffer from scalability and performance issues. We show that using a histogram based algorithm to approximately find the best split is more efficient and scalable on GPU. By identifying the difference between classical GPU-based image histogram construction and the feature histogram construction in decision tree training, we develop a fast feature histogram building kernel on GPU with carefully designed computational and memory access sequence to reduce atomic update conflict and maximize GPU utilization. Our algorithm can be used as a drop-in replacement for histogram construction in popular tree boosting systems to improve their scalability. As an example, to train GBDT on epsilon dataset, our method using a main-stream GPU is 7-8 times faster than histogram based algorithm on CPU in LightGBM and 25 times faster than the exact-split finding algorithm in XGBoost on a dual-socket 28-core Xeon server, while achieving similar prediction accuracy. version:1
arxiv-1706-08355 | Deep Semantic Classification for 3D LiDAR Data | http://arxiv.org/abs/1706.08355 | id:1706.08355 author:Ayush Dewan, Gabriel L. Oliveira, Wolfram Burgard category:cs.RO cs.CV  published:2017-06-26 summary:Robots are expected to operate autonomously in dynamic environments. Understanding the underlying dynamic characteristics of objects is a key enabler for achieving this goal. In this paper, we propose a method for pointwise semantic classification of 3D LiDAR data into three classes: non-movable, movable and dynamic. We concentrate on understanding these specific semantics because they characterize important information required for an autonomous system. Non-movable points in the scene belong to unchanging segments of the environment, whereas the remaining classes corresponds to the changing parts of the scene. The difference between the movable and dynamic class is their motion state. The dynamic points can be perceived as moving, whereas movable objects can move, but are perceived as static. To learn the distinction between movable and non-movable points in the environment, we introduce an approach based on deep neural network and for detecting the dynamic points, we estimate pointwise motion. We propose a Bayes filter framework for combining the learned semantic cues with the motion cues to infer the required semantic classification. In extensive experiments, we compare our approach with other methods on a standard benchmark dataset and report competitive results in comparison to the existing state-of-the-art. Furthermore, we show an improvement in the classification of points by combining the semantic cues retrieved from the neural network with the motion cues. version:1
arxiv-1706-08329 | The Boolean Solution Problem from the Perspective of Predicate Logic - Extended Version | http://arxiv.org/abs/1706.08329 | id:1706.08329 author:Christoph Wernhard category:cs.LO cs.AI  published:2017-06-26 summary:Finding solution values for unknowns in Boolean equations was a principal reasoning mode in the Algebra of Logic of the 19th century. Schr\"oder investigated it as "Aufl\"osungsproblem" ("solution problem"). It is closely related to the modern notion of Boolean unification. Today it is commonly presented in an algebraic setting, but seems potentially useful also in knowledge representation based on predicate logic. We show that it can be modeled on the basis of first-order logic extended by second-order quantification. A wealth of classical results transfers, foundations for algorithms unfold, and connections with second-order quantifier elimination and Craig interpolation show up. Although for first-order inputs the set of solutions is recursively enumerable, the development of constructive methods remains a challenge. We identify some cases that allow constructions, most of them based on Craig interpolation, and show a method to take vocabulary restrictions on solution components into account. version:1
arxiv-1706-08325 | An adaptive prefix-assignment technique for symmetry reduction | http://arxiv.org/abs/1706.08325 | id:1706.08325 author:Tommi Junttila, Matti Karppa, Petteri Kaski, Jukka Kohonen category:cs.LO cs.AI cs.DS F.4.1; F.2.2; G.2.1  published:2017-06-26 summary:This paper presents a technique for symmetry reduction that adaptively assigns a prefix of variables in a system of constraints so that the generated prefix-assignments are pairwise nonisomorphic under the action of the symmetry group of the system. The technique is based on McKay's canonical extension framework [J. Algorithms 26 (1998), no. 2, 306-324]. Among key features of the technique are (i) adaptability - the prefix sequence can be user-prescribed and truncated for compatibility with the group of symmetries; (ii) parallelisability - prefix-assignments can be processed in parallel independently of each other; (iii) versatility - the method is applicable whenever the group of symmetries can be concisely represented as the automorphism group of a vertex-colored graph; and (iv) implementability - the method can be implemented relying on a canonical labeling map for vertex-colored graphs as the only nontrivial subroutine. To demonstrate the tentative practical applicability of our technique we have prepared a preliminary implementation and report on a limited set of experiments that demonstrate ability to reduce symmetry on hard instances. version:1
arxiv-1706-08317 | Handling PDDL3.0 State Trajectory Constraints with Temporal Landmarks | http://arxiv.org/abs/1706.08317 | id:1706.08317 author:Eliseo Marzal, Mohannad Babli, Eva Onaindia, Laura Sebastia category:cs.AI  published:2017-06-26 summary:Temporal landmarks have been proved to be a helpful mechanism to deal with temporal planning problems, specifically to improve planners performance and handle problems with deadline constraints. In this paper, we show the strength of using temporal landmarks to handle the state trajectory constraints of PDDL3.0. We analyze the formalism of TempLM, a temporal planner particularly aimed at solving planning problems with deadlines, and we present a detailed study that exploits the underlying temporal landmark-based mechanism of TempLM for representing and reasoning with trajectory constraints. version:1
arxiv-1706-08302 | A Publish/Subscribe System Using Causal Broadcast Over Dynamically Built Spanning Trees | http://arxiv.org/abs/1706.08302 | id:1706.08302 author:JoÃ£o Paulo de Araujo, Luciana Arantes, Elias P. Duarte Jr., Luiz A. Rodrigues, Pierre Sens category:cs.DC C.2.4  published:2017-06-26 summary:In this paper we present VCube-PS, a topic-based Publish/Subscribe system built on the top of a virtual hypercube-like topology. Membership information and published messages to subscribers (members) of a topic group are broadcast over dynamically built spanning trees rooted at the message's source. For a given topic, delivery of published messages respects causal order. Performance results of experiments conducted on the PeerSim simulator confirm the efficiency of VCube-PS in terms of scalability, latency, number, and size of messages when compared to a single rooted, not dynamically, tree built approach. version:1
arxiv-1706-02274 | Can Computers overcome Humans? Consciousness interaction and its implications | http://arxiv.org/abs/1706.02274 | id:1706.02274 author:Camilo Miguel Signorelli category:cs.AI q-bio.NC  published:2017-06-07 summary:Can computers overcome human capabilities? This is a paradoxical and controversial question, particularly because there are many hidden assumptions. This article focuses on that issue putting on evidence some misconception related with future generations of machines and the understanding of the brain. It will be discussed to what extent computers might reach human capabilities, and how it could be possible only if the computer is a conscious machine. However, it will be shown that if the computer is conscious, an interference process due to consciousness would affect the information processing of the system. Therefore, it might be possible to make conscious machines to overcome human capabilities, which will have limitations as well as humans. In other words, trying to overcome human capabilities with computers implies the paradoxical conclusion that a computer will never overcome human capabilities at all, or if the computer does, it should not be considered as a computer anymore. version:2
arxiv-1706-08210 | IS-ASGD: Importance Sampling Accelerated Asynchronous SGD on Multi-Core Systems | http://arxiv.org/abs/1706.08210 | id:1706.08210 author:Fei Wang, Xiaofeng Gao, Guihai Chen, Weichen Li, Jun Ye category:cs.DC  published:2017-06-26 summary:Parallel SGD (PSGD) algorithm has been broadly used to accelerate the stochastic optimization tasks. However its scalability is severely limited by the synchronization between threads. Asynchronous SGD (ASGD) algorithm is then proposed to increase PSGD's scalability by allowing non-synchronized model updates. In practical, lock-free ASGD is preferable since it requires no lock operations on the concurrent update of the global model and thus achieves optimal scalability. It also maintains almost the same convergence bound if certain conditions (convexity, continuity and sparsity) are met. With the success of lock-free ASGD, researchers developed its variance reduction (VR) variants, i.e., VR-integrated lock-free ASGD to achieve superior convergence bound. We noted that the VR techniques that have been studied in lock-free ASGD context are all variance-reduced-gradient based such as SVRG, SAGA, etc. Unfortunately, the estimation of variance-reduced-gradient needs to calculate the full gradient periodically and doubles the computation cost at each iteration which decreases the scalability of ASGD to a very large extent. On the other hand, importance sampling (IS) as another elegant and practical VR technique has not been studied nor implemented in conjunction with lock-free ASGD. One important advantage of IS is that, not like variance-reduced-gradient VR algorithms, IS algorithm achieves the goal of VR through weighted sampling which does not introduce any extra on-line computation and thus preserves the original scalability of ASGD. We are thus motivated to study the application of IS in lock-free ASGD and propose our IS-ASGD algorithm to achieve a superior convergence bound while maintaining the original high scalability of ASGD. We also conduct experimental evaluations that verify the effectiveness of IS-ASGD algorithm with datasets that are popularly adopted in relative researches. version:1
arxiv-1706-04972 | Device Placement Optimization with Reinforcement Learning | http://arxiv.org/abs/1706.04972 | id:1706.04972 author:Azalia Mirhoseini, Hieu Pham, Quoc V. Le, Benoit Steiner, Rasmus Larsen, Yuefeng Zhou, Naveen Kumar, Mohammad Norouzi, Samy Bengio, Jeff Dean category:cs.LG cs.AI  published:2017-06-13 summary:The past few years have witnessed a growth in size and computational requirements for training and inference with neural networks. Currently, a common approach to address these requirements is to use a heterogeneous distributed environment with a mixture of hardware devices such as CPUs and GPUs. Importantly, the decision of placing parts of the neural models on devices is often made by human experts based on simple heuristics and intuitions. In this paper, we propose a method which learns to optimize device placement for TensorFlow computational graphs. Key to our method is the use of a sequence-to-sequence model to predict which subsets of operations in a TensorFlow graph should run on which of the available devices. The execution time of the predicted placements is then used as the reward signal to optimize the parameters of the sequence-to-sequence model. Our main result is that on Inception-V3 for ImageNet classification, and on RNN LSTM, for language modeling and neural machine translation, our model finds non-trivial device placements that outperform hand-crafted heuristics and traditional algorithmic methods. version:2
arxiv-1706-08146 | There and Back Again: A General Approach to Learning Sparse Models | http://arxiv.org/abs/1706.08146 | id:1706.08146 author:Vatsal Sharan, Kai Sheng Tai, Peter Bailis, Gregory Valiant category:cs.LG cs.AI stat.ML  published:2017-06-25 summary:We propose a simple and efficient approach to learning sparse models. Our approach consists of (1) projecting the data into a lower dimensional space, (2) learning a dense model in the lower dimensional space, and then (3) recovering the sparse model in the original space via compressive sensing. We apply this approach to Non-negative Matrix Factorization (NMF), tensor decomposition and linear classification---showing that it obtains $10\times$ compression with negligible loss in accuracy on real data, and obtains up to $5\times$ speedups. Our main theoretical contribution is to show the following result for NMF: if the original factors are sparse, then their projections are the sparsest solutions to the projected NMF problem. This explains why our method works for NMF and shows an interesting new property of random projections: they can preserve the solutions of non-convex optimization problems such as NMF. version:1
arxiv-1706-08133 | A Security Framework for Wireless Sensor Networks: Theory and Practice | http://arxiv.org/abs/1706.08133 | id:1706.08133 author:Christophe Guyeux, Abdallah Makhoul, Jacques M. Bahi category:cs.DC  published:2017-06-25 summary:Wireless sensor networks are often deployed in public or otherwise untrusted and even hostile environments, which prompts a number of security issues. Although security is a necessity in other types of networks, it is much more so in sensor networks due to the resource-constraint, susceptibility to physical capture, and wireless nature. In this work we emphasize two security issues: (1) secure communication infrastructure and (2) secure nodes scheduling algorithm. Due to resource constraints, specific strategies are often necessary to preserve the network's lifetime and its quality of service. For instance, to reduce communication costs nodes can go to sleep mode periodically (nodes scheduling). These strategies must be proven as secure, but protocols used to guarantee this security must be compatible with the resource preservation requirement. To achieve this goal, secure communications in such networks will be defined, together with the notions of secure scheduling. Finally, some of these security properties will be evaluated in concrete case studies. version:1
arxiv-1706-08514 | Well-supported phylogenies using largest subsets of core-genes by discrete particle swarm optimization | http://arxiv.org/abs/1706.08514 | id:1706.08514 author:Reem Alsrraj, Bassam AlKindy, Christophe Guyeux, Laurent Philippe, Jean-FranÃ§ois Couchot category:q-bio.PE cs.AI q-bio.QM  published:2017-06-25 summary:The number of complete chloroplastic genomes increases day after day, making it possible to rethink plants phylogeny at the biomolecular era. Given a set of close plants sharing in the order of one hundred of core chloroplastic genes, this article focuses on how to extract the largest subset of sequences in order to obtain the most supported species tree. Due to computational complexity, a discrete and distributed Particle Swarm Optimization (DPSO) is proposed. It is finally applied to the core genes of Rosales order. version:1
arxiv-1706-08106 | Random Forests for Industrial Device Functioning Diagnostics Using Wireless Sensor Networks | http://arxiv.org/abs/1706.08106 | id:1706.08106 author:Wiem Elghazel, Kamal Medjaher, Nourredine Zerhouni, Jacques Bahi, Ahamd Farhat, Christophe Guyeux, Mourad Hakem category:cs.AI  published:2017-06-25 summary:In this paper, random forests are proposed for operating devices diagnostics in the presence of a variable number of features. In various contexts, like large or difficult-to-access monitored areas, wired sensor networks providing features to achieve diagnostics are either very costly to use or totally impossible to spread out. Using a wireless sensor network can solve this problem, but this latter is more subjected to flaws. Furthermore, the networks' topology often changes, leading to a variability in quality of coverage in the targeted area. Diagnostics at the sink level must take into consideration that both the number and the quality of the provided features are not constant, and that some politics like scheduling or data aggregation may be developed across the network. The aim of this article is ($1$) to show that random forests are relevant in this context, due to their flexibility and robustness, and ($2$) to provide first examples of use of this method for diagnostics based on data provided by a wireless sensor network. version:1
arxiv-1706-08100 | Specifying Non-Markovian Rewards in MDPs Using LDL on Finite Traces (Preliminary Version) | http://arxiv.org/abs/1706.08100 | id:1706.08100 author:Ronen Brafman, Giuseppe De Giacomo, Fabio Patrizi category:cs.AI  published:2017-06-25 summary:In Markov Decision Processes (MDPs), the reward obtained in a state depends on the properties of the last state and action. This state dependency makes it difficult to reward more interesting long-term behaviors, such as always closing a door after it has been opened, or providing coffee only following a request. Extending MDPs to handle such non-Markovian reward function was the subject of two previous lines of work, both using variants of LTL to specify the reward function and then compiling the new model back into a Markovian model. Building upon recent progress in the theories of temporal logics over finite traces, we adopt LDLf for specifying non-Markovian rewards and provide an elegant automata construction for building a Markovian model, which extends that of previous work and offers strong minimality and compositionality guarantees. version:1
arxiv-1706-08093 | One random jump and one permutation: sufficient conditions to chaotic, statistically faultless, and large throughput PRNG for FPGA | http://arxiv.org/abs/1706.08093 | id:1706.08093 author:Mohammed Bakiri, Jean-FranÃ§ois Couchot, Christophe Guyeux category:cs.CR cs.DC  published:2017-06-25 summary:Sub-categories of mathematical topology, like the mathematical theory of chaos, offer interesting applications devoted to information security. In this research work, we have introduced a new chaos-based pseudorandom number generator implemented in FPGA, which is mainly based on the deletion of a Hamilton cycle within the $n$-cube (or on the vectorial negation), plus one single permutation. By doing so, we produce a kind of post-treatment on hardware pseudorandom generators, but the obtained generator has usually a better statistical profile than its input, while running at a similar speed. We tested 6 combinations of Boolean functions and strategies that all achieve to pass the most stringent TestU01 battery of tests. This generation can reach a throughput/latency ratio equal to 6.7 Gbps, being thus the second fastest FPGA generator that can pass TestU01. version:1
arxiv-1706-08090 | Count-Based Exploration in Feature Space for Reinforcement Learning | http://arxiv.org/abs/1706.08090 | id:1706.08090 author:Jarryd Martin, Suraj Narayanan Sasikumar, Tom Everitt, Marcus Hutter category:cs.AI I.2.6  published:2017-06-25 summary:We introduce a new count-based optimistic exploration algorithm for Reinforcement Learning (RL) that is feasible in environments with high-dimensional state-action spaces. The success of RL algorithms in these domains depends crucially on generalisation from limited training experience. Function approximation techniques enable RL agents to generalise in order to estimate the value of unvisited states, but at present few methods enable generalisation regarding uncertainty. This has prevented the combination of scalable RL algorithms with efficient exploration strategies that drive the agent to reduce its uncertainty. We present a new method for computing a generalised state visit-count, which allows the agent to estimate the uncertainty associated with any state. Our \phi-pseudocount achieves generalisation by exploiting same feature representation of the state space that is used for value function approximation. States that have less frequently observed features are deemed more uncertain. The \phi-Exploration-Bonus algorithm rewards the agent for exploring in feature space rather than in the untransformed state space. The method is simpler and less computationally expensive than some previous proposals, and achieves near state-of-the-art results on high-dimensional RL benchmarks. version:1
arxiv-1706-08089 | Finding optimal finite biological sequences over finite alphabets: the OptiFin toolbox | http://arxiv.org/abs/1706.08089 | id:1706.08089 author:RÃ©gis Garnier, Christophe Guyeux, StÃ©phane ChrÃ©tien category:cs.AI q-bio.QM  published:2017-06-25 summary:In this paper, we present a toolbox for a specific optimization problem that frequently arises in bioinformatics or genomics. In this specific optimisation problem, the state space is a set of words of specified length over a finite alphabet. To each word is associated a score. The overall objective is to find the words which have the lowest possible score. This type of general optimization problem is encountered in e.g 3D conformation optimisation for protein structure prediction, or largest core genes subset discovery based on best supported phylogenetic tree for a set of species. In order to solve this problem, we propose a toolbox that can be easily launched using MPI and embeds 3 well-known metaheuristics. The toolbox is fully parametrized and well documented. It has been specifically designed to be easy modified and possibly improved by the user depending on the application, and does not require to be a computer scientist. We show that the toolbox performs very well on two difficult practical problems. version:1
arxiv-1707-03435 | Obstacle detection test in real-word traffic contexts for the purposes of motorcycle autonomous emergency braking (MAEB) | http://arxiv.org/abs/1707.03435 | id:1707.03435 author:Giovanni Savino, Simone Piantini, Gustavo Gil, Marco Pierini category:cs.CV cs.RO  published:2017-06-25 summary:Research suggests that a Motorcycle Autonomous Emergency Braking system (MAEB) could influence 25% of the crashes involving powered two wheelers (PTWs). By automatically slowing down a host PTW of up to 10 km/h in inevitable collision scenarios, MAEB could potentially mitigate the crash severity for the riders. The feasibility of automatic decelerations of motorcycles was shown via field trials in controlled environment. However, the feasibility of correct MAEB triggering in the real traffic context is still unclear. In particular, MAEB requires an accurate obstacle detection, the feasibility of which from a single track vehicle has not been confirmed yet. To address this issue, our study presents obstacle detection tests in a real-world MAEB-sensitive crash scenario. version:1
arxiv-1706-08046 | An Algorithm for Supervised Driving of Cooperative Semi-Autonomous Vehicles (Extended) | http://arxiv.org/abs/1706.08046 | id:1706.08046 author:Florent Altche, Xiangjun Qian, Arnaud de La Fortelle category:cs.MA cs.RO  published:2017-06-25 summary:Before reaching full autonomy, vehicles will gradually be equipped with more and more advanced driver assistance systems (ADAS), effectively rendering them semi-autonomous. However, current ADAS technologies seem unable to handle complex traffic situations, notably when dealing with vehicles arriving from the sides, either at intersections or when merging on highways. The high rate of accidents in these settings prove that they constitute difficult driving situations. Moreover, intersections and merging lanes are often the source of important traffic congestion and, sometimes, deadlocks. In this article, we propose a cooperative framework to safely coordinate semi-autonomous vehicles in such settings, removing the risk of collision or deadlocks while remaining compatible with human driving. More specifically, we present a supervised coordination scheme that overrides control inputs from human drivers when they would result in an unsafe or blocked situation. To avoid unnecessary intervention and remain compatible with human driving, overriding only occurs when collisions or deadlocks are imminent. In this case, safe overriding controls are chosen while ensuring they deviate minimally from those originally requested by the drivers. Simulation results based on a realistic physics simulator show that our approach is scalable to real-world scenarios, and computations can be performed in real-time on a standard computer for up to a dozen simultaneous vehicles. version:1
arxiv-1706-08018 | FAIR: A Hadoop-based Hybrid Model for Faculty Information Retrieval System | http://arxiv.org/abs/1706.08018 | id:1706.08018 author:Noopur Gupta, Rakesh K. Lenka, Rabindra K. Barik, Harishchandra Dubey category:cs.DC  published:2017-06-25 summary:In era of ever-expanding data and knowledge, we lack a centralized system that maps all the faculties to their research works. This problem has not been addressed in the past and it becomes challenging for students to connect with the right faculty of their domain. Since we have so many colleges and faculties this lies in the category of big data problem. In this paper, we present a model which works on the distributed computing environment to tackle big data. The proposed model uses apache spark as an execution engine and hive as database. The results are visualized with the help of Tableau that is connected to Apache Hive to achieve distributed computing. version:1
arxiv-1608-00695 | The blockchain: a new framework for robotic swarm systems | http://arxiv.org/abs/1608.00695 | id:1608.00695 author:Eduardo CastellÃ³ Ferrer category:cs.RO cs.DC cs.ET cs.MA  published:2016-08-02 summary:Swarms of robots will revolutionize many industrial applications, from targeted material delivery to precision farming. However, several of the heterogeneous characteristics that make them ideal for certain future applications --- robot autonomy, decentralized control, collective emergent behavior, etc. --- hinder the evolution of the technology from academic institutions to real-world problems. Blockchain, an emerging technology originated in the Bitcoin field, demonstrates that by combining peer-to-peer networks with cryptographic algorithms a group of agents can reach an agreement on a particular state of affairs and record that agreement without the need for a controlling authority. The combination of blockchain with other distributed systems, such as robotic swarm systems, can provide the necessary capabilities to make robotic swarm operations more secure, autonomous, flexible and even profitable. This work explains how blockchain technology can provide innovative solutions to four emergent issues in the swarm robotics research field. New security, decision making, behavior differentiation and business models for swarm robotic systems are described by providing case scenarios and examples. Finally, limitations and possible future problems that arise from the combination of these two technologies are described. version:4
arxiv-1704-08393 | A wearable general-purpose solution for Human-Swarm Interaction | http://arxiv.org/abs/1704.08393 | id:1704.08393 author:Eduardo CastellÃ³ Ferrer category:cs.RO cs.HC cs.MA  published:2017-04-27 summary:Swarms of robots will revolutionize many industrial applications, from targeted material delivery to precision farming. Controlling the motion and behavior of these swarms presents unique challenges for human operators, who cannot yet effectively convey their high-level intentions to a group of robots in application. This work proposes a new human-swarm interface based on novel wearable gesture-control and haptic-feedback devices. This work seeks to combine a wearable gesture recognition device that can detect high-level intentions, a portable device that can detect Cartesian information and finger movements, and a wearable advanced haptic device that can provide real-time feedback. This project is the first to envisage a wearable Human-Swarm Interaction (HSI) interface that separates the input and feedback components of the classical control loop (input, output, feedback), as well as being the first of its kind suitable for both indoor and outdoor environments. version:2
arxiv-1706-05104 | Personal Food Computer: A new device for controlled-environment agriculture | http://arxiv.org/abs/1706.05104 | id:1706.05104 author:Eduardo CastellÃ³ Ferrer, Jake Rye, Gordon Brander, Tim Savas, Douglas Chambers, Hildreth England, Caleb Harper category:cs.RO cs.ET cs.SY  published:2017-06-15 summary:Due to their interdisciplinary nature, devices for controlled-environment agriculture have the possibility to turn into ideal tools not only to conduct research on plant phenology but also to create curricula in a wide range of disciplines. Controlled-environment devices are increasing their functionalities as well as improving their accessibility. Traditionally, building one of these devices from scratch implies knowledge in fields such as mechanical engineering, digital electronics, programming, and energy management. However, the requirements of an effective controlled environment device for personal use brings new constraints and challenges. This paper presents the OpenAg Personal Food Computer (PFC); a low cost desktop size platform, which not only targets plant phenology researchers but also hobbyists, makers, and teachers from elementary to high-school levels (K-12). The PFC is completely open-source and it is intended to become a tool that can be used for collective data sharing and plant growth analysis. Thanks to its modular design, the PFC can be used in a large spectrum of activities. version:2
arxiv-1706-08012 | Fog Computing in Medical Internet-of-Things: Architecture, Implementation, and Applications | http://arxiv.org/abs/1706.08012 | id:1706.08012 author:Harishchandra Dubey, Admir Monteiro, Nicholas Constant, Mohammadreza Abtahi, Debanjan Borthakur, Leslie Mahler, Yan Sun, Qing Yang, Umer Akbar, Kunal Mankodiya category:cs.DC  published:2017-06-24 summary:In the era when the market segment of Internet of Things (IoT) tops the chart in various business reports, it is apparently envisioned that the field of medicine expects to gain a large benefit from the explosion of wearables and internet-connected sensors that surround us to acquire and communicate unprecedented data on symptoms, medication, food intake, and daily-life activities impacting one's health and wellness. However, IoT-driven healthcare would have to overcome many barriers, such as: 1) There is an increasing demand for data storage on cloud servers where the analysis of the medical big data becomes increasingly complex, 2) The data, when communicated, are vulnerable to security and privacy issues, 3) The communication of the continuously collected data is not only costly but also energy hungry, 4) Operating and maintaining the sensors directly from the cloud servers are non-trial tasks. This book chapter defined Fog Computing in the context of medical IoT. Conceptually, Fog Computing is a service-oriented intermediate layer in IoT, providing the interfaces between the sensors and cloud servers for facilitating connectivity, data transfer, and queryable local database. The centerpiece of Fog computing is a low-power, intelligent, wireless, embedded computing node that carries out signal conditioning and data analytics on raw data collected from wearables or other medical sensors and offers efficient means to serve telehealth interventions. We implemented and tested an fog computing system using the Intel Edison and Raspberry Pi that allows acquisition, computing, storage and communication of the various medical data such as pathological speech data of individuals with speech disorders, Phonocardiogram (PCG) signal for heart rate estimation, and Electrocardiogram (ECG)-based Q, R, S detection. version:1
arxiv-1706-08001 | Temporal-related Convolutional-Restricted-Boltzmann-Machine capable of learning relational order via reinforcement learning procedure? | http://arxiv.org/abs/1706.08001 | id:1706.08001 author:Zizhuang Wang category:cs.AI cs.LG stat.ML  published:2017-06-24 summary:In this article, we extend the conventional framework of convolutional-Restricted-Boltzmann-Machine to learn highly abstract features among abitrary number of time related input maps by constructing a layer of multiplicative units, which capture the relations among inputs. In many cases, more than two maps are strongly related, so it is wise to make multiplicative unit learn relations among more input maps, in other words, to find the optimal relational-order of each unit. In order to enable our machine to learn relational order, we developed a reinforcement-learning method whose optimality is proven to train the network. version:1
arxiv-1706-07946 | Justifications in Constraint Handling Rules for Logical Retraction in Dynamic Algorithms | http://arxiv.org/abs/1706.07946 | id:1706.07946 author:Thom Fruehwirth category:cs.AI cs.LO cs.PL  published:2017-06-24 summary:We present a straightforward source-to-source transformation that introduces justifications for user-defined constraints into the CHR programming language. Then a scheme of two rules suffices to allow for logical retraction (deletion, removal) of constraints during computation. Without the need to recompute from scratch, these rules remove not only the constraint but also undo all consequences of the rule applications that involved the constraint. We prove a confluence result concerning the rule scheme and show its correctness. When algorithms are written in CHR, constraints represent both data and operations. CHR is already incremental by nature, i.e. constraints can be added at runtime. Logical retraction adds decrementality. Hence any algorithm written in CHR with justifications will become fully dynamic. Operations can be undone and data can be removed at any point in the computation without compromising the correctness of the result. We present two classical examples of dynamic algorithms, written in our prototype implementation of CHR with justifications that is available online: maintaining the minimum of a changing set of numbers and shortest paths in a graph whose edges change. version:1
arxiv-1606-08905 | knor: A NUMA-Optimized In-Memory, Distributed and Semi-External-Memory k-means Library | http://arxiv.org/abs/1606.08905 | id:1606.08905 author:Disa Mhembere, Da Zheng, Carey E. Priebe, Joshua T. Vogelstein, Randal Burns category:cs.DC  published:2016-06-28 summary:k-means is one of the most influential and utilized machine learning algorithms. Its computation limits the performance and scalability of many statistical analysis and machine learning tasks. We rethink and optimize k-means in terms of modern NUMA architectures to develop a novel parallelization scheme that delays and minimizes synchronization barriers. The \textit{k-means NUMA Optimized Routine} (\textsf{knor}) library has (i) in-memory (\textsf{knori}), (ii) distributed memory (\textsf{knord}), and (iii) semi-external memory (\textsf{knors}) modules that radically improve the performance of k-means for varying memory and hardware budgets. \textsf{knori} boosts performance for single machine datasets by an order of magnitude or more. \textsf{knors} improves the scalability of k-means on a memory budget using SSDs. \textsf{knors} scales to billions of points on a single machine, using a fraction of the resources that distributed in-memory systems require. \textsf{knord} retains \textsf{knori}'s performance characteristics, while scaling in-memory through distributed computation in the cloud. \textsf{knor} modifies Elkan's triangle inequality pruning algorithm such that we utilize it on billion-point datasets without the significant memory overhead of the original algorithm. We demonstrate \textsf{knor} outperforms distributed commercial products like H$_2$O, Turi (formerly Dato, GraphLab) and Spark's MLlib by more than an order of magnitude for datasets of $10^7$ to $10^9$ points. version:6
arxiv-1706-07853 | Loom: Exploiting Weight and Activation Precisions to Accelerate Convolutional Neural Networks | http://arxiv.org/abs/1706.07853 | id:1706.07853 author:Sayeh Sharify, Alberto Delmas Lascorz, Patrick Judd, Andreas Moshovos category:cs.DC cs.AR cs.LG  published:2017-06-23 summary:Loom (LM), a hardware inference accelerator for Convolutional Neural Networks (CNNs) is presented. In LM every bit of data precision that can be saved translates to proportional performance gains. Specifically, for convolutional layers LM's execution time scales inversely proportionally with the precisions of both weights and activations. For fully-connected layers LM's performance scales inversely proportionally with the precision of the weights. The LM accelerator targets area constrained System-on-a-Chip designs such as those found on mobile devices that cannot afford the multi-megabyte buffers that would be needed to store each layer on-chip during processing. Experiments on image classification CNNs show that on average across all networks studied and assuming that weights are supplied via a High Bandwidth Memory v2 (HBM2) interface, a configuration of LM outperforms a state-of-the-art bit-parallel accelerator [1] by 2.34x without any loss in accuracy while being 2.23x more energy efficient. Moreover, LM can trade-off accuracy for additional improvements in execution performance and energy efficiency. version:1
arxiv-1706-07831 | Synchronization in Dynamic Networks | http://arxiv.org/abs/1706.07831 | id:1706.07831 author:Bernadette Charron-Bost, Shlomo Moran category:cs.DC F.2.2; G.2.2  published:2017-06-23 summary:In this article, we study algorithms for dynamic networks with asynchronous start, i.e., each node may start running the algorithm in a different round. Inactive nodes transmit only heartbeats, which contain no information but can be detected by active nodes. We make no assumption on the way the nodes are awakened, except that for each node u there is a time $s_u$ in which it is awakened and starts to run the algorithm. The identities of the nodes are not mutually known, and the network size is unknown as well. We present synchronization algorithms, which guarantee that after a finite number of rounds, all nodes hold the same round number, which is incremented by one each round thereafter. We study the time complexity and message size required for synchronization, and specifically for simultaneous synchronization, in which all nodes synchronize their round numbers at exactly the same round. We show that there is a strong relation between the complexity of simultaneous synchronization and the connectivity of the dynamic graphs: With high connectivity which guarantees that messages can be broadcasted in a constant number of rounds, simultaneous synchronization by all nodes can be obtained by a deterministic algorithm within a constant number of rounds, and with messages of constant size. With a weaker connectivity, which only guarantees that the broadcast time is proportional to the network size, our algorithms still achieve simultaneous synchronization, but within linear time and long messages. We also discuss how information on the network size and randomization may improve synchronization algorithms, and show related impossibility results. version:1
arxiv-1706-07830 | Formation Maneuvering Control of Multiple Nonholonomic Robotic Vehicles: Theory and Experimentation | http://arxiv.org/abs/1706.07830 | id:1706.07830 author:Milad Khaledyan, Marcio de Queiroz category:cs.RO math.OC  published:2017-06-23 summary:In this paper, we present a new leader-follower type solution to the formation maneuvering problem for multiple, nonholonomic wheeled mobile robots. The solution is based on the graph that models the coordination among the robots being a spanning tree. Our decentralized control law ensures, in the least squares sense, that the robots globally acquire a given planar formation while the formation as a whole globally tracks a desired trajectory. The control law is first designed at the kinematic level and then extended to the dynamic level. In the latter, we consider that parametric uncertainty exists in the equations of motion. These uncertainties are accounted for by employing an adaptive control scheme. The proposed formation maneuvering controls are demonstrated experimentally and numerically. version:1
arxiv-1706-07772 | Optimizing the Performance of Reactive Molecular Dynamics Simulations for Multi-Core Architectures | http://arxiv.org/abs/1706.07772 | id:1706.07772 author:Hasan Metin Aktulga, Christopher Knight, Paul Coffman, Kurt A. O'Hearn, Tzu-Ray Shan, Wei Jiang category:cs.DC cs.PF  published:2017-06-23 summary:Reactive molecular dynamics simulations are computationally demanding. Reaching spatial and temporal scales where interesting scientific phenomena can be observed requires efficient and scalable implementations on modern hardware. In this paper, we focus on optimizing the performance of the widely used LAMMPS/ReaxC package for multi-core architectures. As hybrid parallelism allows better leverage of the increasing on-node parallelism, we adopt thread parallelism in the construction of bonded and nonbonded lists, and in the computation of complex ReaxFF interactions. To mitigate the I/O overheads due to large volumes of trajectory data produced and to save users the burden of post-processing, we also develop a novel in-situ tool for molecular species analysis. We analyze the performance of the resulting ReaxC-OMP package on Mira, an IBM Blue Gene/Q supercomputer. For PETN systems of sizes ranging from 32 thousand to 16.6 million particles, we observe speedups in the range of 1.5-4.5x. We observe sustained performance improvements for up to 262,144 cores (1,048,576 processes) of Mira and a weak scaling efficiency of 91.5% in large simulations containing 16.6 million particles. The in-situ molecular species analysis tool incurs only insignificant overheads across various system sizes and run configurations. version:1
arxiv-1611-04810 | The NOESIS Network-Oriented Exploration, Simulation, and Induction System | http://arxiv.org/abs/1611.04810 | id:1611.04810 author:VÃ­ctor MartÃ­nez, Fernando Berzal, Juan-Carlos Cubero category:cs.SI cs.AI  published:2016-11-15 summary:Network data mining has become an important area of study due to the large number of problems it can be applied to. This paper presents NOESIS, an open source framework for network data mining that provides a large collection of network analysis techniques, including the analysis of network structural properties, community detection methods, link scoring, and link prediction, as well as network visualization algorithms. It also features a complete stand-alone graphical user interface that facilitates the use of all these techniques. The NOESIS framework has been designed using solid object-oriented design principles and structured parallel programming. As a lightweight library with minimal external dependencies and a permissive software license, NOESIS can be incorporated into other software projects. Released under a BSD license, it is available from http://noesis.ikor.org. version:2
arxiv-1706-07429 | Heterogeneous MPSoCs for Mixed Criticality Systems: Challenges and Opportunities | http://arxiv.org/abs/1706.07429 | id:1706.07429 author:Mohamed Hassan category:cs.DC  published:2017-06-23 summary:Due to their cost, performance, area, and energy efficiency, MPSoCs offer appealing architecture for emerging mixed criticality systems (MCS) such as driverless cars, smart power grids, and healthcare devices. Furthermore, heterogeneity of MPSoCs presents exceptional opportunities to satisfy the conflicting requirements of MCS. Seizing these opportunities is unattainable without addressing the associated challenges. We focus on four aspects of MCS that we believe are of most importance upon adopting MPSoCs: theoretical model, interference, data sharing, and security. We outline existing solutions, highlight the necessary considerations for MPSoCs including both opportunities they create and research directions yet to be explored. version:1
arxiv-1706-07561 | A-NICE-MC: Adversarial Training for MCMC | http://arxiv.org/abs/1706.07561 | id:1706.07561 author:Jiaming Song, Shengjia Zhao, Stefano Ermon category:stat.ML cs.AI cs.LG  published:2017-06-23 summary:Existing Markov Chain Monte Carlo (MCMC) methods are either based on general-purpose and domain-agnostic schemes which can lead to slow convergence, or hand-crafting of problem-specific proposals by an expert. We propose A-NICE-MC, a novel method to train flexible parametric Markov chain kernels to produce samples with desired properties. First, we propose an efficient likelihood-free adversarial training method to train a Markov chain and mimic a given data distribution. Then, we leverage flexible volume preserving flows to obtain parametric kernels for MCMC. Using a bootstrap approach, we show how to train efficient Markov chains to sample from a prescribed posterior distribution by iteratively improving the quality of both the model and the samples. A-NICE-MC provides the first framework to automatically design efficient domain-specific MCMC proposals. Empirical results demonstrate that A-NICE-MC combines the strong guarantees of MCMC with the expressiveness of deep neural networks, and is able to significantly outperform competing methods such as Hamiltonian Monte Carlo. version:1
arxiv-1706-07527 | Model Selection with Nonlinear Embedding for Unsupervised Domain Adaptation | http://arxiv.org/abs/1706.07527 | id:1706.07527 author:Hemanth Venkateswara, Shayok Chakraborty, Troy McDaniel, Sethuraman Panchanathan category:cs.AI  published:2017-06-23 summary:Domain adaptation deals with adapting classifiers trained on data from a source distribution, to work effectively on data from a target distribution. In this paper, we introduce the Nonlinear Embedding Transform (NET) for unsupervised domain adaptation. The NET reduces cross-domain disparity through nonlinear domain alignment. It also embeds the domain-aligned data such that similar data points are clustered together. This results in enhanced classification. To determine the parameters in the NET model (and in other unsupervised domain adaptation models), we introduce a validation procedure by sampling source data points that are similar in distribution to the target data. We test the NET and the validation procedure using popular image datasets and compare the classification results across competitive procedures for unsupervised domain adaptation. version:1
arxiv-1706-07519 | Interoperable Convergence of Storage, Networking and Computation | http://arxiv.org/abs/1706.07519 | id:1706.07519 author:Micah Beck, Terry Moore, Piotr Luszczek category:cs.DC  published:2017-06-22 summary:In every form of digital store-and-forward communication, intermediate forwarding nodes are computers, with attendant memory and processing resources. This has inevitably given rise to efforts to create a wide area infrastructure that goes beyond simple store and forward, a facility that makes more general and varied use of the potential of this collection of increasingly powerful nodes. Historically, efforts in this direction predate the advent of globally routed packet networking. The desire for a converged infrastructure of this kind has only intensified over the last 30 years, as memory, storage and processing resources have both increased in density and speed and decreased in cost. Although there seems to be a general consensus that it should be possible to define and deploy such a dramatically more capable wide area facility, a great deal of investment in research prototypes has yet to produce a credible candidate architecture. Drawing on technical analysis, historical examples, and case studies, we present a argument for the hypothesis that in order to realize a distributed system with the kind of convergent generality and deployment scalability that might qualify as "future-defining," we must build it up from a small set of simple, generic, and limited abstractions of the low level processing, storage and network resources of its intermediate nodes. version:1
arxiv-1706-07506 | Inter-Session Modeling for Session-Based Recommendation | http://arxiv.org/abs/1706.07506 | id:1706.07506 author:Massimiliano Ruocco, Ole Steinar LillestÃ¸l Skrede, Helge Langseth category:cs.IR cs.AI  published:2017-06-22 summary:In recent years, research has been done on applying Recurrent Neural Networks (RNNs) as recommender systems. Results have been promising, especially in the session-based setting where RNNs have been shown to outperform state-of-the-art models. In many of these experiments, the RNN could potentially improve the recommendations by utilizing information about the user's past sessions, in addition to its own interactions in the current session. A problem for session-based recommendation, is how to produce accurate recommendations at the start of a session, before the system has learned much about the user's current interests. We propose a novel approach that extends a RNN recommender to be able to process the user's recent sessions, in order to improve recommendations. This is done by using a second RNN to learn from recent sessions, and predict the user's interest in the current session. By feeding this information to the original RNN, it is able to improve its recommendations. Our experiments on two different datasets show that the proposed approach can significantly improve recommendations throughout the sessions, compared to a single RNN working only on the current session. The proposed model especially improves recommendations at the start of sessions, and is therefore able to deal with the cold start problem within sessions. version:1
arxiv-1610-03383 | Deterministic parallel algorithms for fooling polylogarithmic juntas and the Lovasz Local Lemma | http://arxiv.org/abs/1610.03383 | id:1610.03383 author:David G. Harris category:cs.DS cs.DC math.PR  published:2016-10-11 summary:Many randomized algorithms can be derandomized efficiently using either the method of conditional expectations or probability spaces with low (almost-) independence. A series of papers, beginning with Luby (1988) and continuing with Berger & Rompel (1991) and Chari et al. (1994), showed that these techniques can be combined to give deterministic parallel algorithms for combinatorial optimization problems involving sums of $w$-juntas. We improve these algorithms through derandomized variable partitioning and a new code construction for fooling Fourier characters over $GF(2)$. This reduces the processor complexity to essentially independent of $w$ while the running time is reduced from exponential in $w$ to linear in $w$. As a key subroutine, we give a new algorithm to generate a probability space which can fool a given set of neighborhoods, each of size at most $w$. Schulman (1992) gave an NC algorithm to do so for $w \leq O(\log n)$. Our new algorithm is NC1, with essentially optimal time and processor complexity, when $w = O(\log n)$; it remains NC up to $w = \text{polylog}(n)$. This answers an open problem of Schulman. One major application of these algorithms is an NC algorithm for the Lov\'{a}sz Local Lemma. Previous NC algorithms, including the seminal algorithm of Moser & Tardos (2010) and the work of Chandrasekaran et. al (2013), required that (essentially) the bad-events could span only $O(\log n)$ variables; we relax this to $\text{polylog}(n)$ variables. We use this to give algorithms for defective vertex coloring and domatic graph partition in graphs of maximum degree $\text{polylog}(n)$. version:5
arxiv-1603-01564 | High precision grasp pose detection in dense clutter | http://arxiv.org/abs/1603.01564 | id:1603.01564 author:Marcus Gualtieri, Andreas ten Pas, Kate Saenko, Robert Platt category:cs.RO  published:2016-03-04 summary:This paper considers the problem of grasp pose detection in point clouds. We follow a general algorithmic structure that first generates a large set of 6-DOF grasp candidates and then classifies each of them as a good or a bad grasp. Our focus in this paper is on improving the second step by using depth sensor scans from large online datasets to train a convolutional neural network. We propose two new representations of grasp candidates, and we quantify the effect of using prior knowledge of two forms: instance or category knowledge of the object to be grasped, and pretraining the network on simulated depth data obtained from idealized CAD models. Our analysis shows that a more informative grasp candidate representation as well as pretraining and prior knowledge significantly improve grasp detection. We evaluate our approach on a Baxter Research Robot and demonstrate an average grasp success rate of 93% in dense clutter. This is a 20% improvement compared to our prior work. version:2
arxiv-1706-07412 | Rational coordination with no communication or conventions | http://arxiv.org/abs/1706.07412 | id:1706.07412 author:Valentin Goranko, Antti Kuusisto, Raine Raine RÃ¶nnholm category:cs.MA cs.AI cs.GT cs.SI I.2.11  published:2017-06-22 summary:We study pure coordination games where in every outcome, all players have identical payoffs, 'win' or 'lose'. We identify and discuss a range of 'purely rational principles' guiding the reasoning of rational players in such games and analyze which classes of coordination games can be solved by such players with no preplay communication or conventions. We observe that it is highly nontrivial to delineate a boundary between purely rational principles and other decision methods, such as conventions, for solving such coordination games. version:1
arxiv-1603-04068 | A Signaling Game Approach to Databases Querying and Interaction | http://arxiv.org/abs/1603.04068 | id:1603.04068 author:Ben McCamish, Arash Termehchy, Behrouz Touri category:cs.DB cs.AI  published:2016-03-13 summary:As most database users cannot precisely express their information needs, it is challenging for database management systems to understand them. We propose a novel formal framework for representing and understanding information needs in database querying and exploration. Our framework considers querying as a collaboration between the user and the database management system to establish a it mutual language for representing information needs. We formalize this collaboration as a signaling game, where each mutual language is an equilibrium for the game. A query interface is more effective if it establishes a less ambiguous mutual language faster. We discuss some equilibria, strategies, and the convergence in this game. In particular, we propose a reinforcement learning mechanism and analyze it within our framework. We prove that this adaptation mechanism for the query interface improves the effectiveness of answering queries stochastically speaking, and converges almost surely. We extend out results for the cases that the user also modifies her strategy during the interaction. version:4
arxiv-1706-05452 | A General Optimal Control Model of Human Movement Patterns I: Walking Gait | http://arxiv.org/abs/1706.05452 | id:1706.05452 author:Stuart Hagler category:q-bio.QM cs.RO  published:2017-06-16 summary:The biomechanics of the human body gives subjects a high degree of freedom in how they can execute movement. Nevertheless, subjects exhibit regularity in their movement patterns. One way to account for this regularity is to suppose that subjects select movement trajectories that are optimal in some sense. We adopt the principle that human movements are optimal and develop a general model for human movement patters that uses variational methods in the form of optimal control theory to calculate trajectories of movement trajectories of the body. We find that in this approach a constant of the motion that arises from the model and which plays a role in the optimal control model that is analogous to the role that the mechanical energy plays in classical physics. We illustrate how this approach works in practice by using it to develop a model of walking gait, making all the derivations and calculations in detail. We finally show that this optimal control model of walking gait recovers in an appropriate limit an existing model of walking gait which has been shown to provide good estimates of many observed characteristics of walking gait. version:3
arxiv-1706-07351 | An approach to reachability analysis for feed-forward ReLU neural networks | http://arxiv.org/abs/1706.07351 | id:1706.07351 author:Alessio Lomuscio, Lalit Maganti category:cs.AI cs.LG cs.LO  published:2017-06-22 summary:We study the reachability problem for systems implemented as feed-forward neural networks whose activation function is implemented via ReLU functions. We draw a correspondence between establishing whether some arbitrary output can ever be outputed by a neural system and linear problems characterising a neural system of interest. We present a methodology to solve cases of practical interest by means of a state-of-the-art linear programs solver. We evaluate the technique presented by discussing the experimental results obtained by analysing reachability properties for a number of benchmarks in the literature. version:1
arxiv-1706-07296 | A Minimal Developmental Model Can Increase Evolvability in Soft Robots | http://arxiv.org/abs/1706.07296 | id:1706.07296 author:Sam Kriegman, Nick Cheney, Francesco Corucci, Josh C. Bongard category:cs.NE cs.RO q-bio.PE  published:2017-06-22 summary:Different subsystems of organisms adapt over many time scales, such as rapid changes in the nervous system (learning), slower morphological and neurological change over the lifetime of the organism (postnatal development), and change over many generations (evolution). Much work has focused on instantiating learning or evolution in robots, but relatively little on development. Although many theories have been forwarded as to how development can aid evolution, it is difficult to isolate each such proposed mechanism. Thus, here we introduce a minimal yet embodied model of development: the body of the robot changes over its lifetime, yet growth is not influenced by the environment. We show that even this simple developmental model confers evolvability because it allows evolution to sweep over a larger range of body plans than an equivalent non-developmental system, and subsequent heterochronic mutations 'lock in' this body plan in more morphologically-static descendants. Future work will involve gradually complexifying the developmental model to determine when and how such added complexity increases evolvability. version:1
arxiv-1706-07269 | Explanation in Artificial Intelligence: Insights from the Social Sciences | http://arxiv.org/abs/1706.07269 | id:1706.07269 author:Tim Miller category:cs.AI  published:2017-06-22 summary:There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to provide more transparency to their algorithms. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that, if these techniques are to succeed, the explanations they generate should have a structure that humans accept. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers' intuition of what constitutes a `good' explanation. There exists vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations. This paper argues that the field of explainable artificial intelligence should build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence. version:1
arxiv-1706-07255 | Constant Factor Optimal Multi-Robot Path Planning in Well-Connected Environments | http://arxiv.org/abs/1706.07255 | id:1706.07255 author:Jingjin Yu category:cs.RO  published:2017-06-22 summary:Fast algorithms for optimal multi-robot path planning are sought after in many real-world applications. Known methods, however, generally do not simultaneously guarantee good solution optimality and fast run time (e.g., polynomial). In this work, we develop a low-polynomial running time algorithm, called SplitAndGroup, that solves the multi-robot path planning problem on grids and grid-like environments and produces constant factor time- and distance-optimal solutions, in expectation. In particular, SplitAndGroup computes solutions with sub-linear makespan. SplitAndGroup is capable of handling cases when the density of robot is extremely high - in a graph-theoretic setting, the algorithm supports cases where all vertices of the underlying graph are occupied by robots. SplitAndGroup attains its desirable properties through a careful combination of divide-and-conquer technique and network flow based methods for routing the robots. version:1
arxiv-1706-07230 | Gated-Attention Architectures for Task-Oriented Language Grounding | http://arxiv.org/abs/1706.07230 | id:1706.07230 author:Devendra Singh Chaplot, Kanthashree Mysore Sathyendra, Rama Kumar Pasumarthi, Dheeraj Rajagopal, Ruslan Salakhutdinov category:cs.LG cs.AI cs.CL cs.RO  published:2017-06-22 summary:To perform tasks specified by natural language instructions, autonomous agents need to extract semantically meaningful representations of language and map it to visual elements and actions in the environment. This problem is called task-oriented language grounding. We propose an end-to-end trainable neural architecture for task-oriented language grounding in 3D environments which assumes no prior linguistic or perceptual knowledge and requires only raw pixels from the environment and the natural language instruction as input. The proposed model combines the image and text representations using a Gated-Attention mechanism and learns a policy to execute the natural language instruction using standard reinforcement and imitation learning methods. We show the effectiveness of the proposed model on unseen instructions as well as unseen maps, both quantitatively and qualitatively. We also introduce a novel environment based on a 3D game engine to simulate the challenges of task-oriented language grounding over a rich set of instructions and environment states. version:1
arxiv-1706-07221 | GraphHP: A Hybrid Platform for Iterative Graph Processing | http://arxiv.org/abs/1706.07221 | id:1706.07221 author:Qun Chen, Song Bai, Zhanhuai Li, Zhiying Gou, Bo Suo, Wei Pan category:cs.DC  published:2017-06-22 summary:The Bulk Synchronous Parallel(BSP) computational model has emerged as the dominant distributed framework to build large-scale iterative graph processing systems. While its implementations(e.g., Pregel, Giraph, and Hama) achieve high scalability, frequent synchronization and communication among the workers can cause substantial parallel inefficiency. To help address this critical concern, this paper introduces the GraphHP(Graph Hybrid Processing) platform which inherits the friendly vertex-centric BSP programming interface and optimizes its synchronization and communication overhead. To achieve the goal, we first propose a hybrid execution model which differentiates between the computations within a graph partition and across the partitions, and decouples the computations within a partition from distributed synchronization and communication. By implementing the computations within a partition by pseudo-superstep iteration in memory, the hybrid execution model can effectively reduce synchronization and communication overhead while not requiring heavy scheduling overhead or graph-centric sequential algorithms. We then demonstrate how the hybrid execution model can be easily implemented within the BSP abstraction to preserve its simple programming interface. Finally, we evaluate our implementation of the GraphHP platform on classical BSP applications and show that it performs significantly better than the state-of-the-art BSP implementations. Our GraphHP implementation is based on Hama, but can easily generalize to other BSP platforms. version:1
arxiv-1706-07206 | Explaining Recurrent Neural Network Predictions in Sentiment Analysis | http://arxiv.org/abs/1706.07206 | id:1706.07206 author:Leila Arras, GrÃ©goire Montavon, Klaus-Robert MÃ¼ller, Wojciech Samek category:cs.CL cs.AI cs.NE stat.ML  published:2017-06-22 summary:Recently, a technique called Layer-wise Relevance Propagation (LRP) was shown to deliver insightful explanations in the form of input space relevances for understanding feed-forward neural network classification decisions. In the present work, we extend the usage of LRP to recurrent neural networks. We propose a specific propagation rule applicable to multiplicative connections as they arise in recurrent network architectures such as LSTMs and GRUs. We apply our technique to a word-based bi-directional LSTM model on a five-class sentiment prediction task, and evaluate the resulting LRP relevances both qualitatively and quantitatively, obtaining better results than a gradient-based related method which was used in previous work. version:1
arxiv-1706-07204 | Context Reasoning in Underwater Robots Using MEBN | http://arxiv.org/abs/1706.07204 | id:1706.07204 author:Xin Li, JosÃ©-FernÃ¡n MartÃ­nez, Gregorio Rubio, David GÃ³mez category:cs.RO  published:2017-06-22 summary:This paper presents ongoing research in the SWARMs project towards facilitating context awareness in underwater robots. In particular, the focus of this paper is put on the context reasoning part. The underwater environment introduces uncertainties in context data which lead to difficulties in the context reasoning phase. As probability is the best well-known formalism for computational scientific reasoning under uncertainties, the emerging and effective probabilistic reasoning method, namely, Multi-Entity Bayesian Network (MEBN), is explored for its feasibility to reason under uncertainties in the SWARMs project. A simple use case for oil spill monitoring is used to verify the usefulness of MEBN. The results show that the MEBN is a promising approach to reason about context in the presence of uncertainties in the underwater robot field. version:1
arxiv-1704-04451 | Optimizing Differentiable Relaxations of Coreference Evaluation Metrics | http://arxiv.org/abs/1704.04451 | id:1704.04451 author:Phong Le, Ivan Titov category:cs.CL cs.AI cs.LG  published:2017-04-14 summary:Coreference evaluation metrics are hard to optimize directly as they are non-differentiable functions, not easily decomposable into elementary decisions. Consequently, most approaches optimize objectives only indirectly related to the end goal, resulting in suboptimal performance. Instead, we propose a differentiable relaxation that lends itself to gradient-based optimisation, thus bypassing the need for reinforcement learning or heuristic modification of cross-entropy. We show that by modifying the training objective of a competitive neural coreference system, we obtain a substantial gain in performance. This suggests that our approach can be regarded as a viable alternative to using reinforcement learning or more computationally expensive imitation learning. version:3
arxiv-1706-07191 | High-Performance Out-of-core Block Randomized Singular Value Decomposition on GPU | http://arxiv.org/abs/1706.07191 | id:1706.07191 author:Yuechao Lu, Fumihiko Ino, Yasuyuki Matsushita category:cs.DC  published:2017-06-22 summary:Fast computation of singular value decomposition (SVD) is of great interest in various machine learning tasks. Recently, SVD methods based on randomized linear algebra have shown significant speedup in this regime. This paper attempts to further accelerate the computation by harnessing a modern computing architecture, namely graphics processing unit (GPU), with the goal of processing large-scale data that may not fit in the GPU memory. It leads to a new block randomized algorithm that fully utilizes the power of GPUs and efficiently processes large-scale data in an out-of- core fashion. Our experiment shows that the proposed block randomized SVD (BRSVD) method outperforms existing randomized SVD methods in terms of speed with retaining the same accuracy. We also show its application to convex robust principal component analysis, which shows significant speedup in computer vision applications. version:1
arxiv-1706-01991 | Unsupervised Neural-Symbolic Integration | http://arxiv.org/abs/1706.01991 | id:1706.01991 author:Son N. Tran category:cs.AI  published:2017-06-06 summary:Symbolic has been long considered as a language of human intelligence while neural networks have advantages of robust computation and dealing with noisy data. The integration of neural-symbolic can offer better learning and reasoning while providing a means for interpretability through the representation of symbolic knowledge. Although previous works focus intensively on supervised feedforward neural networks, little has been done for the unsupervised counterparts. In this paper we show how to integrate symbolic knowledge into unsupervised neural networks. We exemplify our approach with knowledge in different forms, including propositional logic for DNA promoter prediction and first-order logic for understanding family relationship. version:2
arxiv-1706-07160 | MAGIX: Model Agnostic Globally Interpretable Explanations | http://arxiv.org/abs/1706.07160 | id:1706.07160 author:Nikaash Puri, Piyush Gupta, Pratiksha Agarwal, Sukriti Verma, Balaji Krishnamurthy category:cs.AI  published:2017-06-22 summary:Explaining the behavior of a black box machine learning model at the instance level is useful for building trust. However, what is also important is understanding how the model behaves globally. Such an understanding provides insight into both the data on which the model was trained and the generalization power of the rules it learned. We present here an approach that learns rules to explain globally the behavior of black box machine learning models. Collectively these rules represent the logic learned by the model and are hence useful for gaining insight into its behavior. We demonstrate the power of the approach on three publicly available data sets. version:1
arxiv-1706-07147 | A Useful Motif for Flexible Task Learning in an Embodied Two-Dimensional Visual Environment | http://arxiv.org/abs/1706.07147 | id:1706.07147 author:Kevin T. Feigelis, Daniel L. K. Yamins category:cs.LG cs.AI q-bio.NC stat.ML  published:2017-06-22 summary:Animals (especially humans) have an amazing ability to learn new tasks quickly, and switch between them flexibly. How brains support this ability is largely unknown, both neuroscientifically and algorithmically. One reasonable supposition is that modules drawing on an underlying general-purpose sensory representation are dynamically allocated on a per-task basis. Recent results from neuroscience and artificial intelligence suggest the role of the general purpose visual representation may be played by a deep convolutional neural network, and give some clues how task modules based on such a representation might be discovered and constructed. In this work, we investigate module architectures in an embodied two-dimensional touchscreen environment, in which an agent's learning must occur via interactions with an environment that emits images and rewards, and accepts touches as input. This environment is designed to capture the physical structure of the task environments that are commonly deployed in visual neuroscience and psychophysics. We show that in this context, very simple changes in the nonlinear activations used by such a module can significantly influence how fast it is at learning visual tasks and how suitable it is for switching to new tasks. version:1
arxiv-1706-07144 | Improving Condition- and Environment-Invariant Place Recognition with Semantic Place Categorization | http://arxiv.org/abs/1706.07144 | id:1706.07144 author:Sourav Garg, Adam Jacobson, Swagat Kumar, Michael Milford category:cs.RO  published:2017-06-22 summary:The place recognition problem comprises two distinct subproblems; recognizing a specific location in the world ("specific" or "ordinary" place recognition) and recognizing the type of place (place categorization). Both are important competencies for mobile robots and have each received significant attention in the robotics and computer vision community, but usually as separate areas of investigation. In this paper, we leverage the powerful complementary nature of place recognition and place categorization processes to create a new hybrid place recognition system that uses place context to inform place recognition. We show that semantic place categorization creates an informative natural segmenting of physical space that in turn enables significantly better place recognition performance in comparison to existing techniques. In particular, this new semantically informed approach adds robustness to significant local changes within the environment, such as transitioning between indoor and outdoor environments or between dark and light rooms in a house, complementing the capabilities of current condition-invariant techniques that are robust to globally consistent change (such as day to night cycles). We perform experiments using 4 benchmark and new datasets and show that semantically-informed place recognition outperforms the previous state-of-the-art systems. Like it does for object recognition [1], we believe that semantics can play a key role in boosting conventional place recognition and navigation performance for robotic systems. version:1
arxiv-1706-07098 | Distributed Least-Squares Iterative Methods in Networks: A Survey | http://arxiv.org/abs/1706.07098 | id:1706.07098 author:Lei Shi, Liang Zhao, Wen-Zhan Song, Goutham Kamath, Yuan Wu, Xuefeng Liu category:cs.DC  published:2017-06-21 summary:Many science and engineering applications involve solving a linear least-squares system formed from some field measurements. In the distributed cyber-physical systems (CPS), often each sensor node used for measurement only knows partial independent rows of the least-squares system. To compute the least-squares solution they need to gather all these measurement at a centralized location and then compute the solution. These data collection and computation are inefficient because of bandwidth and time constraints and sometimes are infeasible because of data privacy concerns. Thus distributed computations are strongly preferred or demanded in many of the real world applications e.g.: smart-grid, target tracking etc. To compute least squares for the large sparse system of linear equation iterative methods are natural candidates and there are a lot of studies regarding this, however, most of them are related to the efficiency of centralized/parallel computations while and only a few are explicitly about distributed computation or have the potential to apply in distributed networks. This paper surveys the representative iterative methods from several research communities. Some of them were not originally designed for this need, so we slightly modified them to suit our requirement and maintain the consistency. In this survey, we sketch the skeleton of the algorithm first and then analyze its time-to-completion and communication cost. To our best knowledge, this is the first survey of distributed least-squares in distributed networks. version:1
arxiv-1609-05253 | Open World Assistive Grasping Using Laser Selection | http://arxiv.org/abs/1609.05253 | id:1609.05253 author:Marcus Gualtieri, James Kuczynski, Abraham M. Shultz, Andreas ten Pas, Holly Yanco, Robert Platt category:cs.RO  published:2016-09-16 summary:Many people with motor disabilities are unable to complete activities of daily living (ADLs) without assistance. This paper describes a complete robotic system developed to provide mobile grasping assistance for ADLs. The system is comprised of a robot arm from a Rethink Robotics Baxter robot mounted to an assistive mobility device, a control system for that arm, and a user interface with a variety of access methods for selecting desired objects. The system uses grasp detection to allow previously unseen objects to be picked up by the system. The grasp detection algorithms also allow for objects to be grasped in cluttered environments. We evaluate our system in a number of experiments on a large variety of objects. Overall, we achieve an object selection success rate of 88% and a grasp detection success rate of 90% in a non-mobile scenario, and success rates of 89% and 72% in a mobile scenario. version:2
arxiv-1706-07068 | CAN: Creative Adversarial Networks, Generating "Art" by Learning About Styles and Deviating from Style Norms | http://arxiv.org/abs/1706.07068 | id:1706.07068 author:Ahmed Elgammal, Bingchen Liu, Mohamed Elhoseiny, Marian Mazzone category:cs.AI  published:2017-06-21 summary:We propose a new system for generating art. The system generates art by looking at art and learning about style; and becomes creative by increasing the arousal potential of the generated art by deviating from the learned styles. We build over Generative Adversarial Networks (GAN), which have shown the ability to learn to generate novel images simulating a given distribution. We argue that such networks are limited in their ability to generate creative products in their original design. We propose modifications to its objective to make it capable of generating creative art by maximizing deviation from established styles and minimizing deviation from art distribution. We conducted experiments to compare the response of human subjects to the generated art with their response to art created by artists. The results show that human subjects could not distinguish art generated by the proposed system from art generated by contemporary artists and shown in top art fairs. Human subjects even rated the generated images higher on various scales. version:1
arxiv-1706-07035 | The Capacity of Cache Aided Private Information Retrieval | http://arxiv.org/abs/1706.07035 | id:1706.07035 author:Ravi Tandon category:cs.IT cs.CR cs.DC math.IT  published:2017-06-21 summary:The problem of cache enabled private information retrieval (PIR) is considered in which a user wishes to privately retrieve one out of $K$ messages, each of size $L$ bits from $N$ distributed databases. The user has a local cache of storage $SL$ bits which can be used to store any function of the $K$ messages. The main contribution of this work is the exact characterization of the capacity of cache aided PIR as a function of the storage parameter $S$. In particular, for a given cache storage parameter $S$, the information-theoretically optimal download cost $D^{*}(S)/L$ (or the inverse of capacity) is shown to be equal to $(1- \frac{S}{K})\left(1+ \frac{1}{N}+ \ldots + \frac{1}{N^{K-1}}\right)$. Special cases of this result correspond to the settings when $S=0$, for which the optimal download cost was shown by Sun and Jafar to be $\left(1+ \frac{1}{N}+ \ldots + \frac{1}{N^{K-1}}\right)$, and the case when $S=K$, i.e., cache size is large enough to store all messages locally, for which the optimal download cost is $0$. The intermediate points $S\in (0, K)$ can be readily achieved through a simple memory-sharing based PIR scheme. The key technical contribution of this work is the converse, i.e., a lower bound on the download cost as a function of storage $S$ which shows that memory sharing is information-theoretically optimal. version:1
arxiv-1706-06952 | Ensemble Framework for Real-time Decision Making | http://arxiv.org/abs/1706.06952 | id:1706.06952 author:Philip Rodgers, John Levine category:cs.AI  published:2017-06-21 summary:This paper introduces a new framework for real-time decision making in video games. An Ensemble agent is a compound agent composed of multiple agents, each with its own tasks or goals to achieve. Usually when dealing with real-time decision making, reactive agents are used; that is agents that return a decision based on the current state. While reactive agents are very fast, most games require more than just a rule-based agent to achieve good results. Deliberative agents---agents that use a forward model to search future states---are very useful in games with no hard time limit, such as Go or Backgammon, but generally take too long for real-time games. The Ensemble framework addresses this issue by allowing the agent to be both deliberative and reactive at the same time. This is achieved by breaking up the game-play into logical roles and having highly focused components for each role, with each component disregarding anything outwith its own role. Reactive agents can be used where a reactive agent is suited to the role, and where a deliberative approach is required, branching is kept to a minimum by the removal of all extraneous factors, enabling an informed decision to be made within a much smaller time-frame. An Arbiter is used to combine the component results, allowing high performing agents to be created from simple, efficient components. version:1
arxiv-1706-06927 | Combined Task and Motion Planning as Classical AI Planning | http://arxiv.org/abs/1706.06927 | id:1706.06927 author:Jonathan Ferrer-Mestres, Guillem FrancÃ¨s, Hector Geffner category:cs.RO cs.AI  published:2017-06-21 summary:Planning in robotics is often split into task and motion planning. The high-level, symbolic task planner decides what needs to be done, while the motion planner checks feasibility and fills up geometric detail. It is known however that such a decomposition is not effective in general as the symbolic and geometrical components are not independent. In this work, we show that it is possible to compile task and motion planning problems into classical AI planning problems; i.e., planning problems over finite and discrete state spaces with a known initial state, deterministic actions, and goal states to be reached. The compilation is sound, meaning that classical plans are valid robot plans, and probabilistically complete, meaning that valid robot plans are classical plans when a sufficient number of configurations is sampled. In this approach, motion planners and collision checkers are used for the compilation, but not at planning time. The key elements that make the approach effective are 1) expressive classical AI planning languages for representing the compiled problems in compact form, that unlike PDDL make use of functions and state constraints, and 2) general width-based search algorithms capable of finding plans over huge combinatorial spaces using weak heuristics only. Empirical results are presented for a PR2 robot manipulating tens of objects, for which long plans are required. version:1
arxiv-1706-06906 | Expert and Non-Expert Opinion about Technological Unemployment | http://arxiv.org/abs/1706.06906 | id:1706.06906 author:Toby Walsh category:cs.AI  published:2017-06-21 summary:There is significant concern that technological advances, especially in Robotics and Artificial Intelligence (AI), could lead to high levels of unemployment in the coming decades. Studies have estimated that around half of all current jobs are at risk of automation. To look into this issue in more depth, we surveyed experts in Robotics and AI about the risk, and compared their views with those of non-experts. Whilst the experts predicted a significant number of occupations were at risk of automation in the next two decades, they were more cautious than people outside the field in predicting occupations at risk. Their predictions were consistent with their estimates for when computers might be expected to reach human level performance across a wide range of skills. These estimates were typically decades later than those of the non-experts. Technological barriers may therefore provide society with more time to prepare for an automated future than the public fear. In addition, public expectations may need to be dampened about the speed of progress to be expected in Robotics and AI. version:1
arxiv-1612-01650 | Closed-Chain Manipulation of Large Objects by Multi-Arm Robotic Systems | http://arxiv.org/abs/1612.01650 | id:1612.01650 author:Xian Zhou, Puttichai Lertkultanon, Quang-Cuong Pham category:cs.RO  published:2016-12-06 summary:Closed kinematic chains are created whenever multiple robot arms concurrently manipulate a single object. The closed-chain constraint, when coupled with robot joint limits, dramatically changes the connectivity of the configuration space. We propose a regrasping move, termed "IK-switch", which allows efficiently bridging components of the configuration space that are otherwise mutually disconnected. This move, combined with several other developments, such as a method to stabilize the manipulated object using the environment, a new tree structure, and a compliant control scheme, enables us to address complex closed-chain manipulation tasks, such as flipping a chair frame, which is otherwise impossible to realize using existing multi-arm planning methods. version:3
arxiv-1706-06814 | Dynamic Analytical Initialization Method for Spacecraft Attitude Estimators | http://arxiv.org/abs/1706.06814 | id:1706.06814 author:Lubin Chang, Fangjun Qin category:cs.RO  published:2017-06-21 summary:This paper proposes a dynamic analytical initialization method for spacecraft attitude estimators. In the proposed method, the desired attitude matrix is decomposed into two parts: one is the constant attitude matrix at the very start and the other encodes the attitude changes of the body frame from its initial state. The latter one can be calculated recursively using the gyroscope outputs and the constant attitude matrix can be determined using constructed vector observations at different time. Compared with traditional initialization methods, the proposed method does not necessitate the spacecraft being static or more than two non-collinear vector observations at the same time. Therefore, the proposed method can promote increased spacecraft autonomy by autonomous initialization of attitude estimators. The effectiveness and prospect of the proposed method in spacecraft attitude estimation applications have been validated through numerical simulations. version:1
arxiv-1706-06789 | Agreement Protocols on an Arbitrary Network in the Presence of a Mobile Adversary | http://arxiv.org/abs/1706.06789 | id:1706.06789 author:Chris Dowden category:cs.DC  published:2017-06-21 summary:We investigate the problem of obtaining agreement protocols in the presence of a mobile adversary, who can control an ever-changing selection of processors. We make improvements to previous results for the case when the communications network forms a complete graph, and also adapt these to the general case when the network is not complete. version:1
arxiv-1706-06783 | NPGLM: A Non-Parametric Method for Temporal Link Prediction | http://arxiv.org/abs/1706.06783 | id:1706.06783 author:Sina Sajadmanesh, Jiawei Zhang, Hamid R. Rabiee category:cs.LG cs.AI cs.SI  published:2017-06-21 summary:In this paper, we try to solve the problem of temporal link prediction in information networks. This implies predicting the time it takes for a link to appear in the future, given its features that have been extracted at the current network snapshot. To this end, we introduce a probabilistic non-parametric approach, called "Non-Parametric Generalized Linear Model" (NP-GLM), which infers the hidden underlying probability distribution of the link advent time given its features. We then present a learning algorithm for NP-GLM and an inference method to answer time-related queries. Extensive experiments conducted on both synthetic data and real-world Sina Weibo social network demonstrate the effectiveness of NP-GLM in solving temporal link prediction problem vis-a-vis competitive baselines. version:1
arxiv-1705-05742 | Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs | http://arxiv.org/abs/1705.05742 | id:1705.05742 author:Rakshit Trivedi, Hanjun Dai, Yichen Wang, Le Song category:cs.AI cs.CL cs.LG  published:2017-05-16 summary:The availability of large scale event data with time stamps has given rise to dynamically evolving knowledge graphs that contain temporal information for each edge. Reasoning over time in such dynamic knowledge graphs is not yet well understood. To this end, we present Know-Evolve, a novel deep evolutionary knowledge network that learns non-linearly evolving entity representations over time. The occurrence of a fact (edge) is modeled as a multivariate point process whose intensity function is modulated by the score for that fact computed based on the learned entity embeddings. We demonstrate significantly improved performance over various relational learning approaches on two large scale real-world datasets. Further, our method effectively predicts occurrence or recurrence time of a fact which is novel compared to prior reasoning approaches in multi-relational setting. version:3
arxiv-1706-06718 | Multi-Modal Trip Hazard Affordance Detection On Construction Sites | http://arxiv.org/abs/1706.06718 | id:1706.06718 author:Sean McMahon, Niko SÃ¼nderhauf, Ben Upcroft, Michael Milford category:cs.RO cs.CV  published:2017-06-21 summary:Trip hazards are a significant contributor to accidents on construction and manufacturing sites, where over a third of Australian workplace injuries occur [1]. Current safety inspections are labour intensive and limited by human fallibility,making automation of trip hazard detection appealing from both a safety and economic perspective. Trip hazards present an interesting challenge to modern learning techniques because they are defined as much by affordance as by object type; for example wires on a table are not a trip hazard, but can be if lying on the ground. To address these challenges, we conduct a comprehensive investigation into the performance characteristics of 11 different colour and depth fusion approaches, including 4 fusion and one non fusion approach; using colour and two types of depth images. Trained and tested on over 600 labelled trip hazards over 4 floors and 2000m$\mathrm{^{2}}$ in an active construction site,this approach was able to differentiate between identical objects in different physical configurations (see Figure 1). Outperforming a colour-only detector, our multi-modal trip detector fuses colour and depth information to achieve a 4% absolute improvement in F1-score. These investigative results and the extensive publicly available dataset moves us one step closer to assistive or fully automated safety inspection systems on construction sites. version:1
arxiv-1706-06696 | The NAO Backpack: An Open-hardware Add-on for Fast Software Development with the NAO Robot | http://arxiv.org/abs/1706.06696 | id:1706.06696 author:MatÃ­as Mattamala, Gonzalo Olave, Clayder GonzÃ¡lez, NicolÃ¡s HasbÃºn, Javier Ruiz-del-Solar category:cs.RO  published:2017-06-20 summary:We present an open-source accessory for the NAO robot, which enables to test computationally demanding algorithms in an external platform while preserving robot's autonomy and mobility. The platform has the form of a backpack, which can be 3D printed and replicated, and holds an ODROID XU4 board to process algorithms externally with ROS compatibility. We provide also a software bridge between the B-Human's framework and ROS to have access to the robot's sensors close to real-time. We tested the platform in several robotics applications such as data logging, visual SLAM, and robot vision with deep learning techniques. The CAD model, hardware specifications and software are available online for the benefit of the community: https://github.com/uchile-robotics/nao-backpack version:1
arxiv-1706-06695 | Toward Real-Time Decentralized Reinforcement Learning using Finite Support Basis Functions | http://arxiv.org/abs/1706.06695 | id:1706.06695 author:Kenzo Lobos-Tsunekawa, David L. Leottau, Javier Ruiz-del-Solar category:cs.RO cs.AI  published:2017-06-20 summary:This paper addresses the design and implementation of complex Reinforcement Learning (RL) behaviors where multi-dimensional action spaces are involved, as well as the need to execute the behaviors in real-time using robotic platforms with limited computational resources and training times. For this purpose, we propose the use of decentralized RL, in combination with finite support basis functions as alternatives to Gaussian RBF, in order to alleviate the effects of the curse of dimensionality on the action and state spaces respectively, and to reduce the computation time. As testbed, a RL based controller for the in-walk kick in NAO robots, a challenging and critical problem for soccer robotics, is used. The reported experiments show empirically that our solution saves up to 99.94% of execution time and 98.82% of memory consumption during execution, without diminishing performance compared to classical approaches. version:1
arxiv-1706-06694 | Recognition of Grasp Points for Clothes Manipulation under unconstrained Conditions | http://arxiv.org/abs/1706.06694 | id:1706.06694 author:Luz MarÃ­a MartÃ­nez, Javier Ruiz-del-Solar category:cs.CV cs.RO  published:2017-06-20 summary:In this work a system for recognizing grasp points in RGB-D images is proposed. This system is intended to be used by a domestic robot when deploying clothes lying at a random position on a table. By taking into consideration that the grasp points are usually near key parts of clothing, such as the waist of pants or the neck of a shirt. The proposed system attempts to detect these key parts first, using a local multivariate contour that adapts its shape accordingly. Then, the proposed system applies the Vessel Enhancement filter to identify wrinkles in the clothes, allowing to compute a roughness index for the clothes. Finally, by mixing (i) the key part contours and (ii) the roughness information obtained by the vessel filter, the system is able to recognize grasp points for unfolding a piece of clothing. The recognition system is validated using realistic RGB-D images of different cloth types. version:1
arxiv-1706-06687 | Reputation blackboard systems | http://arxiv.org/abs/1706.06687 | id:1706.06687 author:JosÃ© F. Fontanari category:cs.DC cs.MA  published:2017-06-20 summary:Blackboard systems are motivated by the popular view of task forces as brainstorming groups in which specialists write promising ideas to solve a problem in a central blackboard. Here we study a minimal model of blackboard system designed to solve cryptarithmetic puzzles, where hints are posted anonymously on a public display (standard blackboard) or are posted together with information about the reputations of the agents that posted them (reputation blackboard). We find that the reputation blackboard always outperforms the standard blackboard, which, in turn, always outperforms the independent search. The asymptotic distribution of the computational cost of the search, which is proportional to the total number of agent updates required to find the solution of the puzzle, is an exponential distribution for those three search heuristics. Only for the reputation blackboard we find a nontrivial dependence of the mean computational cost on the system size and, in that case, the optimal performance is achieved by a single agent working alone, indicating that, though the blackboard organization can produce impressive performance gains when compared with the independent search, it is not very supportive of cooperative work. version:1
arxiv-1705-09180 | High-Quality Tabletop Rearrangement with Overhand Grasps: Hardness Results and Fast Methods | http://arxiv.org/abs/1705.09180 | id:1705.09180 author:Shuai D. Han, Nicholas M. Stiffler, Athansios Krontiris, Kostas E. Bekris, Jingjin Yu category:cs.RO  published:2017-05-25 summary:This paper studies the underlying combinatorial structure of a class of object rearrangement problems, which appear frequently in applications. The problems involve multiple, similar-geometry objects placed on a flat, horizontal surface, where a robot can approach them from above and perform pick-and-place operations to rearrange them. The paper considers both the case where the start and goal object poses overlap, and where they do not. For overlapping poses, the primary objective is to minimize the number of pick-and-place actions and then to minimize the distance traveled by the end-effector. For the non-overlapping case, the objective is solely to minimize the end-effector distance. While such problems do not involve all the complexities of general rearrangement, they remain computationally hard challenges in both cases. This is shown through two-way reductions between well-understood, hard combinatorial challenges and these rearrangement problems. The benefit of the reduction is that there are well studied algorithms for solving these well-established combinatorial challenges. These algorithms can be very efficient in practice despite the hardness results. The paper builds on these reduction results to propose an algorithmic pipeline for dealing with the rearrangement problems. Experimental evaluation shows that the proposed pipeline achieves high-quality paths with regards to the optimization objectives. Furthermore, it exhibits highly desirable scalability as the number of objects increases in both the overlapping and non-overlapping setups. version:3
arxiv-1706-06646 | Multi-objective, Decentralized Dynamic Virtual Machine Consolidation using ACO Metaheuristic in Computing Clouds | http://arxiv.org/abs/1706.06646 | id:1706.06646 author:Md Hasanul Ferdaus, Manzur Murshed, Rodrigo N. Calheiros, Rajkumar Buyya category:cs.DC  published:2017-06-20 summary:Underutilization of computing resources and high power consumption are two primary challenges in the domain of Cloud resource management. This paper deals with these challenges through offline, migration impact-aware, multi-objective dynamic Virtual Machine (VM) consolidation in the context of large-scale virtualized data center environments. The problem is formulated as an NP-hard discrete combinatorial optimization problem with simultaneous objectives of minimizing resource wastage, power consumption, and the associated VM migration overhead. Since dynamic VM consolidation through VM live migrations have negative impacts on hosted applications performance and data center components, a VM live migration overhead estimation technique is proposed, which takes into account pragmatic migration parameters and overhead factors. In order to tackle scalability issues, a hierarchical, decentralized dynamic VM consolidation framework is presented that helps to localize migration-related network traffic and reduce network cost. Moreover, a multi-objective, dynamic VM consolidation algorithm is proposed by utilizing the Ant Colony Optimization (ACO) metaheuristic, with integration of the proposed VM migration overhead estimation technique. Comprehensive performance evaluation makes it evident that the proposed dynamic VM consolidation approach outpaces the state-of-the-art offline, migration-aware dynamic VM consolidation algorithm across all performance metrics by reducing the overall power consumption by up to 47%, resource wastage by up to 64%, and migration overhead by up to 83%. version:1
arxiv-1706-06643 | Policy Gradient Methods for Reinforcement Learning with Function Approximation and Action-Dependent Baselines | http://arxiv.org/abs/1706.06643 | id:1706.06643 author:Philip S. Thomas, Emma Brunskill category:cs.AI cs.LG  published:2017-06-20 summary:We show how an action-dependent baseline can be used by the policy gradient theorem using function approximation, originally presented with action-independent baselines by (Sutton et al. 2000). version:1
arxiv-1706-06636 | Word-Entity Duet Representations for Document Ranking | http://arxiv.org/abs/1706.06636 | id:1706.06636 author:Chenyan Xiong, Jamie Callan, Tie-Yan Liu category:cs.IR cs.AI  published:2017-06-20 summary:This paper presents a word-entity duet framework for utilizing knowledge bases in ad-hoc retrieval. In this work, the query and documents are modeled by word-based representations and entity-based representations. Ranking features are generated by the interactions between the two representations, incorporating information from the word space, the entity space, and the cross-space connections through the knowledge graph. To handle the uncertainties from the automatically constructed entity representations, an attention-based ranking model AttR-Duet is developed. With back-propagation from ranking labels, the model learns simultaneously how to demote noisy entities and how to rank documents with the word-entity duet. Evaluation results on TREC Web Track ad-hoc task demonstrate that all of the four-way interactions in the duet are useful, the attention mechanism successfully steers the model away from noisy entities, and together they significantly outperform both word-based and entity-based learning to rank systems. version:1
arxiv-1706-06617 | Observational Learning by Reinforcement Learning | http://arxiv.org/abs/1706.06617 | id:1706.06617 author:Diana Borsa, Bilal Piot, RÃ©mi Munos, Olivier Pietquin category:cs.LG cs.AI stat.ML  published:2017-06-20 summary:Observational learning is a type of learning that occurs as a function of observing, retaining and possibly replicating or imitating the behaviour of another agent. It is a core mechanism appearing in various instances of social learning and has been found to be employed in several intelligent species, including humans. In this paper, we investigate to what extent the explicit modelling of other agents is necessary to achieve observational learning through machine learning. Especially, we argue that observational learning can emerge from pure Reinforcement Learning (RL), potentially coupled with memory. Through simple scenarios, we demonstrate that an RL agent can leverage the information provided by the observations of an other agent performing a task in a shared environment. The other agent is only observed through the effect of its actions on the environment and never explicitly modeled. Two key aspects are borrowed from observational learning: i) the observer behaviour needs to change as a result of viewing a 'teacher' (another agent) and ii) the observer needs to be motivated somehow to engage in making use of the other agent's behaviour. The later is naturally modeled by RL, by correlating the learning agent's reward with the teacher agent's behaviour. version:1
arxiv-1706-06563 | Technical Report for Real-Time Certified Probabilistic Pedestrian Forecasting | http://arxiv.org/abs/1706.06563 | id:1706.06563 author:Henry O. Jacobs, Owen K. Hughes, Matthew Johnson-Roberson, Ram Vasudevan category:cs.RO math.OC  published:2017-06-20 summary:The success of autonomous systems will depend upon their ability to safely navigate human-centric environments. This motivates the need for a real-time, probabilistic forecasting algorithm for pedestrians, cyclists, and other agents since these predictions will form a necessary step in assessing the risk of any action. This paper presents a novel approach to probabilistic forecasting for pedestrians based on weighted sums of ordinary differential equations that are learned from historical trajectory information within a fixed scene. The resulting algorithm is embarrassingly parallel and is able to work at real-time speeds using a naive Python implementation. The quality of predicted locations of agents generated by the proposed algorithm is validated on a variety of examples and considerably higher than existing state of the art approaches over long time horizons. version:1
arxiv-1706-06544 | Robust and Efficient Transfer Learning with Hidden-Parameter Markov Decision Processes | http://arxiv.org/abs/1706.06544 | id:1706.06544 author:Taylor Killian, Samuel Daulton, George Konidaris, Finale Doshi-Velez category:stat.ML cs.AI cs.LG  published:2017-06-20 summary:We introduce a new formulation of the Hidden Parameter Markov Decision Process (HiP-MDP), a framework for modeling families of related tasks using low-dimensional latent embeddings. We replace the original Gaussian Process-based model with a Bayesian Neural Network. Our new framework correctly models the joint uncertainty in the latent parameters and the state space and has more scalable inference, thus expanding the scope the HiP-MDP to applications with higher dimensions and more complex dynamics. version:1
