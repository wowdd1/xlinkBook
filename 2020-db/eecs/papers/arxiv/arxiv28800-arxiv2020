arxiv-1707-07804 | Exploring the Effectiveness of Convolutional Neural Networks for Answer Selection in End-to-End Question Answering | http://arxiv.org/abs/1707.07804 | id:1707.07804 author:Royal Sequiera, Gaurav Baruah, Zhucheng Tu, Salman Mohammed, Jinfeng Rao, Haotian Zhang, Jimmy Lin category:cs.IR cs.CL  published:2017-07-25 summary:Most work on natural language question answering today focuses on answer selection: given a candidate list of sentences, determine which contains the answer. Although important, answer selection is only one stage in a standard end-to-end question answering pipeline. This paper explores the effectiveness of convolutional neural networks (CNNs) for answer selection in an end-to-end context using the standard TrecQA dataset. We observe that a simple idf-weighted word overlap algorithm forms a very strong baseline, and that despite substantial efforts by the community in applying deep learning to tackle answer selection, the gains are modest at best on this dataset. Furthermore, it is unclear if a CNN is more effective than the baseline in an end-to-end context based on standard retrieval metrics. To further explore this finding, we conducted a manual user evaluation, which confirms that answers from the CNN are detectably better than those from idf-weighted word overlap. This result suggests that users are sensitive to relatively small differences in answer selection quality. version:1
arxiv-1707-07792 | Integrating Lexical and Temporal Signals in Neural Ranking Models for Searching Social Media Streams | http://arxiv.org/abs/1707.07792 | id:1707.07792 author:Jinfeng Rao, Hua He, Haotian Zhang, Ferhan Ture, Royal Sequiera, Salman Mohammed, Jimmy Lin category:cs.IR cs.CL  published:2017-07-25 summary:Time is an important relevance signal when searching streams of social media posts. The distribution of document timestamps from the results of an initial query can be leveraged to infer the distribution of relevant documents, which can then be used to rerank the initial results. Previous experiments have shown that kernel density estimation is a simple yet effective implementation of this idea. This paper explores an alternative approach to mining temporal signals with recurrent neural networks. Our intuition is that neural networks provide a more expressive framework to capture the temporal coherence of neighboring documents in time. To our knowledge, we are the first to integrate lexical and temporal signals in an end-to-end neural network architecture, in which existing neural ranking models are used to generate query-document similarity vectors that feed into a bidirectional LSTM layer for temporal modeling. Our results are mixed: existing neural models for document ranking alone yield limited improvements over simple baselines, but the integration of lexical and temporal signals yield significant improvements over competitive temporal baselines. version:1
arxiv-1707-07791 | Deep Feature Learning via Structured Graph Laplacian Embedding for Person Re-Identification | http://arxiv.org/abs/1707.07791 | id:1707.07791 author:De Cheng, Yihong Gong, Zhihui Li, Weiwei Shi, Alexander G. Hauptmann, Nanning Zheng category:cs.CV  published:2017-07-25 summary:Learning the distance metric between pairs of examples is of great importance for visual recognition, especially for person re-identification (Re-Id). Recently, the contrastive and triplet loss are proposed to enhance the discriminative power of the deeply learned features, and have achieved remarkable success. As can be seen, either the contrastive or triplet loss is just one special case of the Euclidean distance relationships among these training samples. Therefore, we propose a structured graph Laplacian embedding algorithm, which can formulate all these structured distance relationships into the graph Laplacian form. The proposed method can take full advantages of the structured distance relationships among these training samples, with the constructed complete graph. Besides, this formulation makes our method easy-to-implement and super-effective. When embedding the proposed algorithm with the softmax loss for the CNN training, our method can obtain much more robust and discriminative deep features with inter-personal dispersion and intra-personal compactness, which is essential to person Re-Id. We illustrate the effectiveness of our proposed method on top of three popular networks, namely AlexNet, DGDNet and ResNet50, on recent four widely used Re-Id benchmark datasets. Our proposed method achieves state-of-the-art performances. version:1
arxiv-1707-07409 | Big Data Regression Using Tree Based Segmentation | http://arxiv.org/abs/1707.07409 | id:1707.07409 author:Rajiv Sambasivan, Sourish Das category:stat.ML cs.LG  published:2017-07-24 summary:Scaling regression to large datasets is a common problem in many application areas. We propose a two step approach to scaling regression to large datasets. Using a regression tree (CART) to segment the large dataset constitutes the first step of this approach. The second step of this approach is to develop a suitable regression model for each segment. Since segment sizes are not very large, we have the ability to apply sophisticated regression techniques if required. A nice feature of this two step approach is that it can yield models that have good explanatory power as well as good predictive performance. Ensemble methods like Gradient Boosted Trees can offer excellent predictive performance but may not provide interpretable models. In the experiments reported in this study, we found that the predictive performance of the proposed approach matched the predictive performance of Gradient Boosted Trees. version:2
arxiv-1705-03122 | Convolutional Sequence to Sequence Learning | http://arxiv.org/abs/1705.03122 | id:1705.03122 author:Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, Yann N. Dauphin category:cs.CL  published:2017-05-08 summary:The prevalent approach to sequence to sequence learning maps an input sequence to a variable length output sequence via recurrent neural networks. We introduce an architecture based entirely on convolutional neural networks. Compared to recurrent models, computations over all elements can be fully parallelized during training and optimization is easier since the number of non-linearities is fixed and independent of the input length. Our use of gated linear units eases gradient propagation and we equip each decoder layer with a separate attention module. We outperform the accuracy of the deep LSTM setup of Wu et al. (2016) on both WMT'14 English-German and WMT'14 English-French translation at an order of magnitude faster speed, both on GPU and CPU. version:3
arxiv-1707-07785 | Comparing Aggregators for Relational Probabilistic Models | http://arxiv.org/abs/1707.07785 | id:1707.07785 author:Seyed Mehran Kazemi, Bahare Fatemi, Alexandra Kim, Zilun Peng, Moumita Roy Tora, Xing Zeng, Matthew Dirks, David Poole category:stat.ML cs.LG  published:2017-07-25 summary:Relational probabilistic models have the challenge of aggregation, where one variable depends on a population of other variables. Consider the problem of predicting gender from movie ratings; this is challenging because the number of movies per user and users per movie can vary greatly. Surprisingly, aggregation is not well understood. In this paper, we show that existing relational models (implicitly or explicitly) either use simple numerical aggregators that lose great amounts of information, or correspond to naive Bayes, logistic regression, or noisy-OR that suffer from overconfidence. We propose new simple aggregators and simple modifications of existing models that empirically outperform the existing ones. The intuition we provide on different (existing or new) models and their shortcomings plus our empirical findings promise to form the foundation for future representations. version:1
arxiv-1707-07240 | Language modeling with Neural trans-dimensional random fields | http://arxiv.org/abs/1707.07240 | id:1707.07240 author:Bin Wang, Zhijian Ou category:cs.CL cs.LG stat.ML  published:2017-07-23 summary:Trans-dimensional random field language models (TRF LMs) have recently been introduced, where sentences are modeled as a collection of random fields. The TRF approach has been shown to have the advantages of being computationally more efficient in inference than LSTM LMs with close performance and being able to flexibly integrating rich features. In this paper we propose neural TRFs, beyond of the previous discrete TRFs that only use linear potentials with discrete features. The idea is to use nonlinear potentials with continuous features, implemented by neural networks (NNs), in the TRF framework. Neural TRFs combine the advantages of both NNs and TRFs. The benefits of word embedding, nonlinear feature learning and larger context modeling are inherited from the use of NNs. At the same time, the strength of efficient inference by avoiding expensive softmax is preserved. A number of technical contributions, including employing deep convolutional neural networks (CNNs) to define the potentials and incorporating the joint stochastic approximation (JSA) strategy in the training algorithm, are developed in this work, which enable us to successfully train neural TRF LMs. Various LMs are evaluated in terms of speech recognition WERs by rescoring the 1000-best lists of WSJ'92 test data. The results show that neural TRF LMs not only improve over discrete TRF LMs, but also perform slightly better than LSTM LMs with only one fifth of parameters and 16x faster inference efficiency. version:2
arxiv-1707-07139 | Clinical Patient Tracking in the Presence of Transient and Permanent Occlusions via Geodesic Feature | http://arxiv.org/abs/1707.07139 | id:1707.07139 author:Kun Li, Joel W. Burdick category:cs.RO cs.CV  published:2017-07-22 summary:This paper develops a method to use RGB-D cameras to track the motions of a human spinal cord injury patient undergoing spinal stimulation and physical rehabilitation. Because clinicians must remain close to the patient during training sessions, the patient is usually under permanent and transient occlusions due to the training equipment and the movements of the attending clinicians. These occlusions can significantly degrade the accuracy of existing human tracking methods. To improve the data association problem in these circumstances, we present a new global feature based on the geodesic distances of surface mesh points to a set of anchor points. Transient occlusions are handled via a multi-hypothesis tracking framework. To evaluate the method, we simulated different occlusion sizes on a data set captured from a human in varying movement patterns, and compared the proposed feature with other tracking methods. The results show that the proposed method achieves robustness to both surface deformations and transient occlusions. version:2
arxiv-1707-07770 | Desensitized RDCA Subspaces for Compressive Privacy in Machine Learning | http://arxiv.org/abs/1707.07770 | id:1707.07770 author:Artur Filipowicz, Thee Chanyaswad, S. Y. Kung category:cs.CR cs.LG  published:2017-07-24 summary:The quest for better data analysis and artificial intelligence has lead to more and more data being collected and stored. As a consequence, more data are exposed to malicious entities. This paper examines the problem of privacy in machine learning for classification. We utilize the Ridge Discriminant Component Analysis (RDCA) to desensitize data with respect to a privacy label. Based on five experiments, we show that desensitization by RDCA can effectively protect privacy (i.e. low accuracy on the privacy label) with small loss in utility. On HAR and CMU Faces datasets, the use of desensitized data results in random guess level accuracies for privacy at a cost of 5.14% and 0.04%, on average, drop in the utility accuracies. For Semeion Handwritten Digit dataset, accuracies of the privacy-sensitive digits are almost zero, while the accuracies for the utility-relevant digits drop by 7.53% on average. This presents a promising solution to the problem of privacy in machine learning for classification. version:1
arxiv-1707-07769 | Exact Identification of a Quantum Change Point | http://arxiv.org/abs/1707.07769 | id:1707.07769 author:Gael Sentís, John Calsamiglia, Ramon Munoz-Tapia category:quant-ph cs.LG  published:2017-07-24 summary:The detection of change points is a pivotal task in statistical analysis. In the quantum realm, it is a new primitive where one aims at identifying the point where a source that supposedly prepares a sequence of particles in identical quantum states starts preparing a mutated one. We obtain the optimal procedure to identify the change point with certainty ---naturally at the price of having a certain probability of getting an inconclusive answer. We obtain the analytical form of the optimal probability of successful identification for any length of the particle sequence. We show that the conditional success probabilities of identifying each possible change point show an unexpected oscillatory behaviour. We also discuss local (online) protocols and compare them with the optimal procedure. version:1
arxiv-1707-07767 | Bellman Gradient Iteration for Inverse Reinforcement Learning | http://arxiv.org/abs/1707.07767 | id:1707.07767 author:Kun Li, Yanan Sui, Joel W. Burdick category:cs.LG cs.RO  published:2017-07-24 summary:This paper develops an inverse reinforcement learning algorithm aimed at recovering a reward function from the observed actions of an agent. We introduce a strategy to flexibly handle different types of actions with two approximations of the Bellman Optimality Equation, and a Bellman Gradient Iteration method to compute the gradient of the Q-value with respect to the reward function. These methods allow us to build a differentiable relation between the Q-value and the reward function and learn an approximately optimal reward function with gradient methods. We test the proposed method in two simulated environments by evaluating the accuracy of different approximations and comparing the proposed method with existing solutions. The results show that even with a linear reward function, the proposed method has a comparable accuracy with the state-of-the-art method adopting a non-linear reward function, and the proposed method is more flexible because it is defined on observed actions instead of trajectories. version:1
arxiv-1704-05021 | Sparse Communication for Distributed Gradient Descent | http://arxiv.org/abs/1704.05021 | id:1704.05021 author:Alham Fikri Aji, Kenneth Heafield category:cs.CL cs.DC cs.LG  published:2017-04-17 summary:We make distributed stochastic gradient descent faster by exchanging sparse updates instead of dense updates. Gradient updates are positively skewed as most updates are near zero, so we map the 99% smallest updates (by absolute value) to zero then exchange sparse matrices. This method can be combined with quantization to further improve the compression. We explore different configurations and apply them to neural machine translation and MNIST image classification tasks. Most configurations work on MNIST, whereas different configurations reduce convergence rate on the more complex translation task. Our experiments show that we can achieve up to 49% speed up on MNIST and 22% on NMT without damaging the final accuracy or BLEU. version:2
arxiv-1707-07755 | AMR Parsing using Stack-LSTMs | http://arxiv.org/abs/1707.07755 | id:1707.07755 author:Miguel Ballesteros, Yaser Al-Onaizan category:cs.CL  published:2017-07-24 summary:We present a transition-based AMR parser that directly generates AMR parses from plain text. We use Stack-LSTMs to represent our parser state and make decisions greedily. In our experiments, we show that our parser achieves very competitive scores on English using only AMR training data. Adding additional information, such as POS tags and dependency trees, improves the results further. version:1
arxiv-1707-07747 | Detection of curved lines with B-COSFIRE filters: A case study on crack delineation | http://arxiv.org/abs/1707.07747 | id:1707.07747 author:Nicola Strisciuglio, George Azzopardi, Nicolai Petkov category:cs.CV  published:2017-07-24 summary:The detection of curvilinear structures is an important step for various computer vision applications, ranging from medical image analysis for segmentation of blood vessels, to remote sensing for the identification of roads and rivers, and to biometrics and robotics, among others. %The visual system of the brain has remarkable abilities to detect curvilinear structures in noisy images. This is a nontrivial task especially for the detection of thin or incomplete curvilinear structures surrounded with noise. We propose a general purpose curvilinear structure detector that uses the brain-inspired trainable B-COSFIRE filters. It consists of four main steps, namely nonlinear filtering with B-COSFIRE, thinning with non-maximum suppression, hysteresis thresholding and morphological closing. We demonstrate its effectiveness on a data set of noisy images with cracked pavements, where we achieve state-of-the-art results (F-measure=0.865). The proposed method can be employed in any computer vision methodology that requires the delineation of curvilinear and elongated structures. version:1
arxiv-1707-07734 | Liver lesion segmentation informed by joint liver segmentation | http://arxiv.org/abs/1707.07734 | id:1707.07734 author:Eugene Vorontsov, Gabriel Chartrand, An Tang, Chris Pal, Samuel Kadoury category:cs.CV  published:2017-07-24 summary:We propose a model for the joint segmentation of the liver and liver lesions in computed tomography (CT) volumes. We build the model from two fully convolutional networks connected in tandem and trained together end-to-end. The first network is trained to produce a representation that is used for liver segmentation. This representation is passed to every layer in the second network, the output of which is used to produce a lesion segmentation. We evaluate the approach on the 2017 ISBI Liver Tumour Segmentation Challenge and place second with a per-volume average Dice score of 0.65. version:1
arxiv-1707-07719 | Global Normalization of Convolutional Neural Networks for Joint Entity and Relation Classification | http://arxiv.org/abs/1707.07719 | id:1707.07719 author:Heike Adel, Hinrich Schütze category:cs.CL  published:2017-07-24 summary:We introduce globally normalized convolutional neural networks for joint entity classification and relation extraction. In particular, we propose a way to utilize a linear-chain conditional random field output layer for predicting entity types and relations between entities at the same time. Our experiments show that global normalization outperforms a locally normalized softmax layer on a benchmark dataset. version:1
arxiv-1704-05974 | Cross-domain Semantic Parsing via Paraphrasing | http://arxiv.org/abs/1704.05974 | id:1704.05974 author:Yu Su, Xifeng Yan category:cs.CL  published:2017-04-20 summary:Existing studies on semantic parsing mainly focus on the in-domain setting. We formulate cross-domain semantic parsing as a domain adaptation problem: train a semantic parser on some source domains and then adapt it to the target domain. Due to the diversity of logical forms in different domains, this problem presents unique and intriguing challenges. By converting logical forms into canonical utterances in natural language, we reduce semantic parsing to paraphrasing, and develop an attentive sequence-to-sequence paraphrase model that is general and flexible to adapt to different domains. We discover two problems, small micro variance and large macro variance, of pre-trained word embeddings that hinder their direct use in neural networks, and propose standardization techniques as a remedy. On the popular Overnight dataset, which contains eight domains, we show that both cross-domain training and standardized pre-trained word embeddings can bring significant improvement. version:2
arxiv-1707-07716 | Stochastic Gradient Descent for Relational Logistic Regression via Partial Network Crawls | http://arxiv.org/abs/1707.07716 | id:1707.07716 author:Jiasen Yang, Bruno Ribeiro, Jennifer Neville category:stat.ML cs.LG  published:2017-07-24 summary:Research in statistical relational learning has produced a number of methods for learning relational models from large-scale network data. While these methods have been successfully applied in various domains, they have been developed under the unrealistic assumption of full data access. In practice, however, the data are often collected by crawling the network, due to proprietary access, limited resources, and privacy concerns. Recently, we showed that the parameter estimates for relational Bayes classifiers computed from network samples collected by existing network crawlers can be quite inaccurate, and developed a crawl-aware estimation method for such models (Yang, Ribeiro, and Neville, 2017). In this work, we extend the methodology to learning relational logistic regression models via stochastic gradient descent from partial network crawls, and show that the proposed method yields accurate parameter estimates and confidence intervals. version:1
arxiv-1707-08110 | Deep Forecast: Deep Learning-based Spatio-Temporal Forecasting | http://arxiv.org/abs/1707.08110 | id:1707.08110 author:Amir Ghaderi, Borhan M. Sanandaji, Faezeh Ghaderi category:cs.LG  published:2017-07-24 summary:The paper presents a spatio-temporal wind speed forecasting algorithm using Deep Learning (DL)and in particular, Recurrent Neural Networks(RNNs). Motivated by recent advances in renewable energy integration and smart grids, we apply our proposed algorithm for wind speed forecasting. Renewable energy resources (wind and solar)are random in nature and, thus, their integration is facilitated with accurate short-term forecasts. In our proposed framework, we model the spatiotemporal information by a graph whose nodes are data generating entities and its edges basically model how these nodes are interacting with each other. One of the main contributions of our work is the fact that we obtain forecasts of all nodes of the graph at the same time based on one framework. Results of a case study on recorded time series data from a collection of wind mills in the north-east of the U.S. show that the proposed DL-based forecasting algorithm significantly improves the short-term forecasts compared to a set of widely-used benchmarks models. version:1
arxiv-1707-07708 | Per-instance Differential Privacy and the Adaptivity of Posterior Sampling in Linear and Ridge regression | http://arxiv.org/abs/1707.07708 | id:1707.07708 author:Yu-Xiang Wang category:stat.ML cs.LG  published:2017-07-24 summary:Differential privacy (DP), ever since its advent, has been a controversial object. On the one hand, it provides strong provable protection of individuals in a data set; on the other hand, it has been heavily criticized for being not practical, partially due to its complete independence to the actual data set it tries to protect. In this paper, we address this issue by a new and more fine-grained notion of differential privacy --- per instance differential privacy (pDP), which captures the privacy of a specific individual with respect to a fixed data set. We show that this is a strict generalization of the standard DP and inherits all its desirable properties, e.g., composition, invariance to side information and closedness to postprocessing, except that they all hold for every instance separately. When the data is drawn from a distribution, we show that per-instance DP implies generalization. Moreover, we provide explicit calculations of the per-instance DP for the output perturbation on a class of smooth learning problems. The result reveals an interesting and intuitive fact that an individual has stronger privacy if he/she has small "leverage score" with respect to the data set and if he/she can be predicted more accurately using the leave-one-out data set. Using the developed techniques, we provide a novel analysis of the One-Posterior-Sample (OPS) estimator and show that it achieves $(\epsilon,\delta)$-DP for any constant $\epsilon$ and match the exact lower bound up to a $1+O(n^{-1/3})$ multiplicative factor for any data and when the data is well-conditioned it achieves $(O(n^{-1/3}),\delta)$-pDP for any target individual. Simulation shows several orders-of-magnitude more favorable privacy and utility trade-off when we consider the privacy of only the users in the data set. version:1
arxiv-1707-07657 | Engineering multilevel support vector machines | http://arxiv.org/abs/1707.07657 | id:1707.07657 author:E. Sadrfaridpour, T. Razzaghi, I. Safro category:cs.LG cs.DS stat.CO stat.ML  published:2017-07-24 summary:The computational complexity of solving nonlinear support vector machine (SVM) is prohibitive on large-scale data. In particular, this issue becomes very sensitive when the data represents additional difficulties such as highly imbalanced class sizes. Typically, nonlinear kernels produce significantly higher classification quality to linear kernels but introduce extra kernel and model parameters. Thus, the parameter fitting is required to increase the quality but it reduces the performance dramatically. We introduce a generalized fast multilevel framework for SVM and discuss several versions of its algorithmic components that lead to a good trade-off between quality and time. Our framework is implemented using PETSc which allows integration with scientific computing tasks. The experimental results demonstrate significant speed up compared to the state-of-the-art SVM libraries. version:1
arxiv-1707-07637 | Copy the dynamics using a learning machine | http://arxiv.org/abs/1707.07637 | id:1707.07637 author:Hong Zhao category:stat.ML math.ST nlin.CD stat.TH  published:2017-07-24 summary:Is it possible to generally construct a dynamical system to simulate a black system without recovering the equations of motion of the latter? Here we show that this goal can be approached by a learning machine. Trained by a set of input-output responses or a segment of time series of a black system, a learning machine can be served as a copy system to mimic the dynamics of various black systems. It can not only behave as the black system at the parameter set that the training data are made, but also recur the evolution history of the black system. As a result, the learning machine provides an effective way for prediction, and enables one to probe the global dynamics of a black system. These findings have significance for practical systems whose equations of motion cannot be approached accurately. Examples of copying the dynamics of an artificial neural network, the Lorenz system, and a variable star are given. Our idea paves a possible way towards copy a living brain. version:1
arxiv-1707-01176 | CharManteau: Character Embedding Models For Portmanteau Creation | http://arxiv.org/abs/1707.01176 | id:1707.01176 author:Varun Gangal, Harsh Jhamtani, Graham Neubig, Eduard Hovy, Eric Nyberg category:cs.CL  published:2017-07-04 summary:Portmanteaus are a word formation phenomenon where two words are combined to form a new word. We propose character-level neural sequence-to-sequence (S2S) methods for the task of portmanteau generation that are end-to-end-trainable, language independent, and do not explicitly use additional phonetic information. We propose a noisy-channel-style model, which allows for the incorporation of unsupervised word lists, improving performance over a standard source-to-target model. This model is made possible by an exhaustive candidate generation strategy specifically enabled by the features of the portmanteau task. Experiments find our approach superior to a state-of-the-art FST-based baseline with respect to ground truth accuracy and human evaluation. version:2
arxiv-1707-07631 | Deep Architectures for Neural Machine Translation | http://arxiv.org/abs/1707.07631 | id:1707.07631 author:Antonio Valerio Miceli Barone, Jindřich Helcl, Rico Sennrich, Barry Haddow, Alexandra Birch category:cs.CL  published:2017-07-24 summary:It has been shown that increasing model depth improves the quality of neural machine translation. However, different architectural variants to increase model depth have been proposed, and so far, there has been no thorough comparative study. In this work, we describe and evaluate several existing approaches to introduce depth in neural machine translation. Additionally, we explore novel architectural variants, including deep transition RNNs, and we vary how attention is used in the deep decoder. We introduce a novel "BiDeep" RNN architecture that combines deep transition RNNs and stacked RNNs. Our evaluation is carried out on the English to German WMT news translation dataset, using a single-GPU machine for both training and inference. We find that several of our proposed architectures improve upon existing approaches in terms of speed and translation quality. We obtain best improvements with a BiDeep RNN of combined depth 8, obtaining an average improvement of 1.5 BLEU over a strong shallow baseline. We release our code for ease of adoption. version:1
arxiv-1707-07628 | Improve Lexicon-based Word Embeddings By Word Sense Disambiguation | http://arxiv.org/abs/1707.07628 | id:1707.07628 author:Yuanzhi Ke, Masafumi Hagiwara category:cs.CL  published:2017-07-24 summary:There have been some works that learn a lexicon together with the corpus to improve the word embeddings. However, they either model the lexicon separately but update the neural networks for both the corpus and the lexicon by the same likelihood, or minimize the distance between all of the synonym pairs in the lexicon. Such methods do not consider the relatedness and difference of the corpus and the lexicon, and may not be the best optimized. In this paper, we propose a novel method that considers the relatedness and difference of the corpus and the lexicon. It trains word embeddings by learning the corpus to predicate a word and its corresponding synonym under the context at the same time. For polysemous words, we use a word sense disambiguation filter to eliminate the synonyms that have different meanings for the context. To evaluate the proposed method, we compare the performance of the word embeddings trained by our proposed model, the control groups without the filter or the lexicon, and the prior works in the word similarity tasks and text classification task. The experimental results show that the proposed model provides better embeddings for polysemous words and improves the performance for text classification. version:1
arxiv-1706-08746 | DE-PACRR: Exploring Layers Inside the PACRR Model | http://arxiv.org/abs/1706.08746 | id:1706.08746 author:Andrew Yates, Kai Hui category:cs.IR cs.CL  published:2017-06-27 summary:Recent neural IR models have demonstrated deep learning's utility in ad-hoc information retrieval. However, deep models have a reputation for being black boxes, and the roles of a neural IR model's components may not be obvious at first glance. In this work, we attempt to shed light on the inner workings of a recently proposed neural IR model, namely the PACRR model, by visualizing the output of intermediate layers and by investigating the relationship between intermediate weights and the ultimate relevance score produced. We highlight several insights, hoping that such insights will be generally applicable. version:2
arxiv-1707-07609 | A Deep Learning Approach to Digitally Stain Optical Coherence Tomography Images of the Optic Nerve Head | http://arxiv.org/abs/1707.07609 | id:1707.07609 author:Sripad Krishna Devalla, Jean-Martial Mari, Tin A. Tun, Nicholas G. Strouthidis, Tin Aung, Alexandre H. Thiery, Michael J. A. Girard category:cs.LG  published:2017-07-24 summary:Purpose: To develop a deep learning approach to digitally-stain optical coherence tomography (OCT) images of the optic nerve head (ONH). Methods: A horizontal B-scan was acquired through the center of the ONH using OCT (Spectralis) for 1 eye of each of 100 subjects (40 normal & 60 glaucoma). All images were enhanced using adaptive compensation. A custom deep learning network was then designed and trained with the compensated images to digitally stain (i.e. highlight) 6 tissue layers of the ONH. The accuracy of our algorithm was assessed (against manual segmentations) using the Dice coefficient, sensitivity, and specificity. We further studied how compensation and the number of training images affected the performance of our algorithm. Results: For images it had not yet assessed, our algorithm was able to digitally stain the retinal nerve fiber layer + prelamina, the retinal pigment epithelium, all other retinal layers, the choroid, and the peripapillary sclera and lamina cribrosa. For all tissues, the mean dice coefficient was $0.84 \pm 0.03$, the mean sensitivity $0.92 \pm 0.03$, and the mean specificity $0.99 \pm 0.00$. Our algorithm performed significantly better when compensated images were used for training. Increasing the number of images (from 10 to 40) to train our algorithm did not significantly improve performance, except for the RPE. Conclusion. Our deep learning algorithm can simultaneously stain neural and connective tissues in ONH images. Our approach offers a framework to automatically measure multiple key structural parameters of the ONH that may be critical to improve glaucoma management. version:1
arxiv-1707-07608 | Vision-Based Fallen Person Detection for the Elderly | http://arxiv.org/abs/1707.07608 | id:1707.07608 author:Markus D. Solbach, John K. Tsotsos category:cs.CV  published:2017-07-24 summary:Falls are serious and costly for elderly people. The Centers for Disease Control and Prevention of the US reports that millions of older people, 65 and older, fall each year at least once. Serious injuries such as; hip fractures, broken bones or head injury, are caused by 20% of the falls. The time it takes to respond and treat a fallen person is crucial. With this paper we present a new , non-invasive system for fallen people detection. Our approach uses only stereo camera data for passively sensing the environment. The key novelty is a human fall detector which uses a CNN based human pose estimator in combination with stereo data to reconstruct the human pose in 3D and estimate the ground plane in 3D. We have tested our approach in different scenarios covering most activities elderly people might encounter living at home. Based on our extensive evaluations, our system shows high accuracy and almost no miss-classification. To reproduce our results, the implementation will be made publicly available to the scientific community. version:1
arxiv-1707-07605 | Share your Model instead of your Data: Privacy Preserving Mimic Learning for Ranking | http://arxiv.org/abs/1707.07605 | id:1707.07605 author:Mostafa Dehghani, Hosein Azarbonyad, Jaap Kamps, Maarten de Rijke category:cs.IR cs.AI cs.CL cs.LG  published:2017-07-24 summary:Deep neural networks have become a primary tool for solving problems in many fields. They are also used for addressing information retrieval problems and show strong performance in several tasks. Training these models requires large, representative datasets and for most IR tasks, such data contains sensitive information from users. Privacy and confidentiality concerns prevent many data owners from sharing the data, thus today the research community can only benefit from research on large-scale datasets in a limited manner. In this paper, we discuss privacy preserving mimic learning, i.e., using predictions from a privacy preserving trained model instead of labels from the original sensitive training data as a supervision signal. We present the results of preliminary experiments in which we apply the idea of mimic learning and privacy preserving mimic learning for the task of document re-ranking as one of the core IR tasks. This research is a step toward laying the ground for enabling researchers from data-rich environments to share knowledge learned from actual users' data, which should facilitate research collaborations. version:1
arxiv-1707-07678 | Extracting Core Claims from Scientific Articles | http://arxiv.org/abs/1707.07678 | id:1707.07678 author:Tom Jansen, Tobias Kuhn category:cs.IR cs.CL cs.DL  published:2017-07-24 summary:The number of scientific articles has grown rapidly over the years and there are no signs that this growth will slow down in the near future. Because of this, it becomes increasingly difficult to keep up with the latest developments in a scientific field. To address this problem, we present here an approach to help researchers learn about the latest developments and findings by extracting in a normalized form core claims from scientific articles. This normalized representation is a controlled natural language of English sentences called AIDA, which has been proposed in previous work as a method to formally structure and organize scientific findings and discourse. We show how such AIDA sentences can be automatically extracted by detecting the core claim of an article, checking for AIDA compliance, and - if necessary - transforming it into a compliant sentence. While our algorithm is still far from perfect, our results indicate that the different steps are feasible and they support the claim that AIDA sentences might be a promising approach to improve scientific communication in the future. version:1
arxiv-1707-07601 | Image Pivoting for Learning Multilingual Multimodal Representations | http://arxiv.org/abs/1707.07601 | id:1707.07601 author:Spandana Gella, Rico Sennrich, Frank Keller, Mirella Lapata category:cs.CL cs.CV  published:2017-07-24 summary:In this paper we propose a model to learn multimodal multilingual representations for matching images and sentences in different languages, with the aim of advancing multilingual versions of image search and image understanding. Our model learns a common representation for images and their descriptions in two different languages (which need not be parallel) by considering the image as a pivot between two languages. We introduce a new pairwise ranking loss function which can handle both symmetric and asymmetric similarity between the two modalities. We evaluate our models on image-description ranking for German and English, and on semantic textual similarity of image descriptions in English. In both cases we achieve state-of-the-art performance. version:1
arxiv-1707-07591 | Transition-Based Generation from Abstract Meaning Representations | http://arxiv.org/abs/1707.07591 | id:1707.07591 author:Timo Schick category:cs.CL  published:2017-07-24 summary:This work addresses the task of generating English sentences from Abstract Meaning Representation (AMR) graphs. To cope with this task, we transform each input AMR graph into a structure similar to a dependency tree and annotate it with syntactic information by applying various predefined actions to it. Subsequently, a sentence is obtained from this tree structure by visiting its nodes in a specific order. We train maximum entropy models to estimate the probability of each individual action and devise an algorithm that efficiently approximates the best sequence of actions to be applied. Using a substandard language model, our generator achieves a Bleu score of 27.4 on the LDC2014T12 test set, the best result reported so far without using silver standard annotations from another corpus as additional training data. version:1
arxiv-1707-07584 | Joint Background Reconstruction and Foreground Segmentation via A Two-stage Convolutional Neural Network | http://arxiv.org/abs/1707.07584 | id:1707.07584 author:Xu Zhao, Yingying Chen, Ming Tang, Jinqiao Wang category:cs.CV  published:2017-07-24 summary:Foreground segmentation in video sequences is a classic topic in computer vision. Due to the lack of semantic and prior knowledge, it is difficult for existing methods to deal with sophisticated scenes well. Therefore, in this paper, we propose an end-to-end two-stage deep convolutional neural network (CNN) framework for foreground segmentation in video sequences. In the first stage, a convolutional encoder-decoder sub-network is employed to reconstruct the background images and encode rich prior knowledge of background scenes. In the second stage, the reconstructed background and current frame are input into a multi-channel fully-convolutional sub-network (MCFCN) for accurate foreground segmentation. In the two-stage CNN, the reconstruction loss and segmentation loss are jointly optimized. The background images and foreground objects are output simultaneously in an end-to-end way. Moreover, by incorporating the prior semantic knowledge of foreground and background in the pre-training process, our method could restrain the background noise and keep the integrity of foreground objects at the same time. Experiments on CDNet 2014 show that our method outperforms the state-of-the-art by 4.9%. version:1
arxiv-1707-07576 | Interpreting Classifiers through Attribute Interactions in Datasets | http://arxiv.org/abs/1707.07576 | id:1707.07576 author:Andreas Henelius, Kai Puolamäki, Antti Ukkonen category:stat.ML cs.LG  published:2017-07-24 summary:In this work we present the novel ASTRID method for investigating which attribute interactions classifiers exploit when making predictions. Attribute interactions in classification tasks mean that two or more attributes together provide stronger evidence for a particular class label. Knowledge of such interactions makes models more interpretable by revealing associations between attributes. This has applications, e.g., in pharmacovigilance to identify interactions between drugs or in bioinformatics to investigate associations between single nucleotide polymorphisms. We also show how the found attribute partitioning is related to a factorisation of the data generating distribution and empirically demonstrate the utility of the proposed method. version:1
arxiv-1707-07568 | CAp 2017 challenge: Twitter Named Entity Recognition | http://arxiv.org/abs/1707.07568 | id:1707.07568 author:Cédric Lopez, Ioannis Partalas, Georgios Balikas, Nadia Derbas, Amélie Martin, Coralie Reutenauer, Frédérique Segond, Massih-Reza Amini category:cs.CL  published:2017-07-24 summary:The paper describes the CAp 2017 challenge. The challenge concerns the problem of Named Entity Recognition (NER) for tweets written in French. We first present the data preparation steps we followed for constructing the dataset released in the framework of the challenge. We begin by demonstrating why NER for tweets is a challenging problem especially when the number of entities increases. We detail the annotation process and the necessary decisions we made. We provide statistics on the inter-annotator agreement, and we conclude the data description part with examples and statistics for the data. We, then, describe the participation in the challenge, where 8 teams participated, with a focus on the methods employed by the challenge participants and the scores achieved in terms of F$_1$ measure. Importantly, the constructed dataset comprising $\sim$6,000 tweets annotated for 13 types of entities, which to the best of our knowledge is the first such dataset in French, is publicly available at \url{http://cap2017.imag.fr/competition.html} . version:1
arxiv-1705-07120 | VAE with a VampPrior | http://arxiv.org/abs/1705.07120 | id:1705.07120 author:Jakub M. Tomczak, Max Welling category:cs.LG cs.AI stat.ML  published:2017-05-19 summary:Many different methods to train deep generative models have been introduced in the past. In this paper, we propose to extend the variational auto-encoder (VAE) framework with a new type of prior which we call "Variational Mixture of Posteriors" prior, or VampPrior for short. The VampPrior consists of a mixture distribution (\textit{e.g.}, a mixture of Gaussians) with components given by variational posteriors conditioned on learnable pseudo-inputs. We further extend this prior to a two layer hierarchical model and show that this architecture where prior and posterior are coupled, learns significantly better models. The model also avoids the usual local optima issues that plague VAEs related to useless latent dimensions. We provide empirical studies on three benchmark datasets, namely, MNIST, OMNIGLOT and Caltech 101 Silhouettes, and show that applying the hierarchical VampPrior delivers state-of-the-art results on all three datasets in the unsupervised permutation invariant setting and the best results or comparable to SOTA methods for the approach with convolutional networks. version:2
arxiv-1705-01389 | Learning to Estimate 3D Hand Pose from Single RGB Images | http://arxiv.org/abs/1705.01389 | id:1705.01389 author:Christian Zimmermann, Thomas Brox category:cs.CV  published:2017-05-03 summary:Low-cost consumer depth cameras and deep learning have enabled reasonable 3D hand pose estimation from single depth images. In this paper, we present an approach that estimates 3D hand pose from regular RGB images. This task has far more ambiguities due to the missing depth information. To this end, we propose a deep network that learns a network-implicit 3D articulation prior. Together with detected keypoints in the images, this network yields good estimates of the 3D pose. We introduce a large scale 3D hand pose dataset based on synthetic hand models for training the involved networks. Experiments on a variety of test sets, including one on sign language recognition, demonstrate the feasibility of 3D hand pose estimation on single color images. version:2
arxiv-1707-07565 | Automatic breast cancer grading in lymph nodes using a deep neural network | http://arxiv.org/abs/1707.07565 | id:1707.07565 author:Thomas Wollmann, Karl Rohr category:cs.CV cs.LG  published:2017-07-24 summary:The progression of breast cancer can be quantified in lymph node whole-slide images (WSIs). We describe a novel method for effectively performing classification of whole-slide images and patient level breast cancer grading. Our method utilises a deep neural network. The method performs classification on small patches and uses model averaging for boosting. In the first step, region of interest patches are determined and cropped automatically by color thresholding and then classified by the deep neural network. The classification results are used to determine a slide level class and for further aggregation to predict a patient level grade. Fast processing speed of our method enables high throughput image analysis. version:1
arxiv-1707-06750 | Temporal Convolution Based Action Proposal: Submission to ActivityNet 2017 | http://arxiv.org/abs/1707.06750 | id:1707.06750 author:Tianwei Lin, Xu Zhao, Zheng Shou category:cs.CV  published:2017-07-21 summary:In this notebook paper, we describe our approach in the submission to the temporal action proposal (task 3) and temporal action localization (task 4) of ActivityNet Challenge hosted at CVPR 2017. Since the accuracy in action classification task is already very high (nearly 90% in ActivityNet dataset), we believe that the main bottleneck for temporal action localization is the quality of action proposals. Therefore, we mainly focus on the temporal action proposal task and propose a new proposal model based on temporal convolutional network. Our approach achieves the state-of-the-art performances on both temporal action proposal task and temporal action localization task. version:2
arxiv-1706-10192 | RE-PACRR: A Context and Density-Aware Neural Information Retrieval Model | http://arxiv.org/abs/1706.10192 | id:1706.10192 author:Kai Hui, Andrew Yates, Klaus Berberich, Gerard de Melo category:cs.IR cs.CL  published:2017-06-30 summary:Ad-hoc retrieval models can benefit from considering different patterns in the interactions between a query and a document, effectively assessing the relevance of a document for a given user query. Factors to be considered in this interaction include (i) the matching of unigrams and ngrams, (ii) the proximity of the matched query terms, (iii) their position in the document, and (iv) how the different relevance signals are combined over different query terms. While previous work has successfully modeled some of these factors, not all aspects have been fully explored. In this work, we close this gap by proposing different neural components and incorporating them into a single architecture, leading to a novel neural IR model called RE-PACRR. Extensive comparisons with established models on TREC Web Track data confirm that the proposed model yields promising search results. version:2
arxiv-1707-07554 | Learning Rare Word Representations using Semantic Bridging | http://arxiv.org/abs/1707.07554 | id:1707.07554 author:Victor Prokhorov, Mohammad Taher Pilehvar, Dimitri Kartsaklis, Pietro Lió, Nigel Collier category:cs.CL cs.AI  published:2017-07-24 summary:We propose a methodology that adapts graph embedding techniques (DeepWalk (Perozzi et al., 2014) and node2vec (Grover and Leskovec, 2016)) as well as cross-lingual vector space mapping approaches (Least Squares and Canonical Correlation Analysis) in order to merge the corpus and ontological sources of lexical knowledge. We also perform comparative analysis of the used algorithms in order to identify the best combination for the proposed system. We then apply this to the task of enhancing the coverage of an existing word embedding's vocabulary with rare and unseen words. We show that our technique can provide considerable extra coverage (over 99%), leading to consistent performance gain (around 10% absolute gain is achieved with w2v-gn-500K cf.\S 3.3) on the Rare Word Similarity dataset. version:1
arxiv-1707-07538 | Infinite Latent Feature Selection: A Probabilistic Latent Graph-Based Ranking Approach | http://arxiv.org/abs/1707.07538 | id:1707.07538 author:Giorgio Roffo, Simone Melzi, Umberto Castellani, Alessandro Vinciarelli category:cs.CV  published:2017-07-24 summary:Feature selection is playing an increasingly significant role with respect to many computer vision applications spanning from object recognition to visual object tracking. However, most of the recent solutions in feature selection are not robust across different and heterogeneous set of data. In this paper, we address this issue proposing a robust probabilistic latent graph-based feature selection algorithm that performs the ranking step while considering all the possible subsets of features, as paths on a graph, bypassing the combinatorial problem analytically. An appealing characteristic of the approach is that it aims to discover an abstraction behind low-level sensory data, that is, relevancy. Relevancy is modelled as a latent variable in a PLSA-inspired generative process that allows the investigation of the importance of a feature when injected into an arbitrary set of cues. The proposed method has been tested on ten diverse benchmarks, and compared against eleven state of the art feature selection methods. Results show that the proposed approach attains the highest performance levels across many different scenarios and difficulties, thereby confirming its strong robustness while setting a new state of the art in feature selection domain. version:1
arxiv-1707-07530 | Likelihood Estimation for Generative Adversarial Networks | http://arxiv.org/abs/1707.07530 | id:1707.07530 author:Hamid Eghbal-zadeh, Gerhard Widmer category:cs.LG  published:2017-07-24 summary:We present a simple method for assessing the quality of generated images in Generative Adversarial Networks (GANs). The method can be applied in any kind of GAN without interfering with the learning procedure or affecting the learning objective. The central idea is to define a likelihood function that correlates with the quality of the generated images. In particular, we derive a Gaussian likelihood function from the distribution of the embeddings (hidden activations) of the real images in the discriminator, and based on this, define two simple measures of how likely it is that the embeddings of generated images are from the distribution of the embeddings of the real images. This yields a simple measure of fitness for generated images, for all varieties of GANs. Empirical results on CIFAR-10 demonstrate a strong correlation between the proposed measures and the perceived quality of the generated images. version:1
arxiv-1707-00189 | An Approach for Weakly-Supervised Deep Information Retrieval | http://arxiv.org/abs/1707.00189 | id:1707.00189 author:Sean MacAvaney, Kai Hui, Andrew Yates category:cs.IR cs.CL  published:2017-07-01 summary:Recent developments in neural information retrieval models have been promising, but a problem remains: human relevance judgments are expensive to produce, while neural models require a considerable amount of training data. In an attempt to fill this gap, we present an approach that---given a weak training set of pseudo-queries, documents, relevance information---filters the data to produce effective positive and negative query-document pairs. This allows large corpora to be used as neural IR model training data, while eliminating training examples that do not transfer well to relevance scoring. The filters include unsupervised ranking heuristics and a novel measure of interaction similarity. We evaluate our approach using a news corpus with article headlines acting as pseudo-queries and article content as documents, with implicit relevance between an article's headline and its content. By using our approach to train state-of-the-art neural IR models and comparing to established baselines, we find that training data generated by our approach can lead to good results on a benchmark test collection. version:2
arxiv-1707-02785 | Identity Alignment by Noisy Pixel Removal | http://arxiv.org/abs/1707.02785 | id:1707.02785 author:Xu Lan, Hanxiao Wang, Shaogang Gong, Xiatian Zhu category:cs.CV  published:2017-07-10 summary:Identity alignment models assume precisely annotated images manually. Human labelling is unrealistic on large sized imagery data. Detection models introduce varying amount of noise and hamper identity alignment performance. In this work, we propose to refine images by removing the undesired pixels. This is achieved by learning to eliminate less informative pixels in identity alignment. To this end, we formulate a method of automatically detecting and removing identity class irrelevant pixels in auto-detected bounding boxes. Experiments validate the benefits of our model in improving identity alignment. version:3
arxiv-1707-07499 | Analysing Errors of Open Information Extraction Systems | http://arxiv.org/abs/1707.07499 | id:1707.07499 author:Rudolf Schneider, Tom Oberhauser, Tobias Klatt, Felix A. Gers, Alexander Löser category:cs.CL  published:2017-07-24 summary:We report results on benchmarking Open Information Extraction (OIE) systems using RelVis, a toolkit for benchmarking Open Information Extraction systems. Our comprehensive benchmark contains three data sets from the news domain and one data set from Wikipedia with overall 4522 labeled sentences and 11243 binary or n-ary OIE relations. In our analysis on these data sets we compared the performance of four popular OIE systems, ClausIE, OpenIE 4.2, Stanford OpenIE and PredPatt. In addition, we evaluated the impact of five common error classes on a subset of 749 n-ary tuples. From our deep analysis we unreveal important research directions for a next generation of OIE systems. version:1
arxiv-1707-07493 | Modeling Label Ambiguity for Neural List-Wise Learning to Rank | http://arxiv.org/abs/1707.07493 | id:1707.07493 author:Rolf Jagerman, Julia Kiseleva, Maarten de Rijke category:cs.IR cs.NE stat.ML  published:2017-07-24 summary:List-wise learning to rank methods are considered to be the state-of-the-art. One of the major problems with these methods is that the ambiguous nature of relevance labels in learning to rank data is ignored. Ambiguity of relevance labels refers to the phenomenon that multiple documents may be assigned the same relevance label for a given query, so that no preference order should be learned for those documents. In this paper we propose a novel sampling technique for computing a list-wise loss that can take into account this ambiguity. We show the effectiveness of the proposed method by training a 3-layer deep neural network. We compare our new loss function to two strong baselines: ListNet and ListMLE. We show that our method generalizes better and significantly outperforms other methods on the validation and test sets. version:1
arxiv-1707-07469 | Character-level Intra Attention Network for Natural Language Inference | http://arxiv.org/abs/1707.07469 | id:1707.07469 author:Han Yang, Marta R. Costa-jussà, José A. R. Fonollosa category:cs.CL cs.LG  published:2017-07-24 summary:Natural language inference (NLI) is a central problem in language understanding. End-to-end artificial neural networks have reached state-of-the-art performance in NLI field recently. In this paper, we propose Character-level Intra Attention Network (CIAN) for the NLI task. In our model, we use the character-level convolutional network to replace the standard word embedding layer, and we use the intra attention to capture the intra-sentence semantics. The proposed CIAN model provides improved results based on a newly published MNLI corpus. version:1
arxiv-1707-07465 | Building Graph Representations of Deep Vector Embeddings | http://arxiv.org/abs/1707.07465 | id:1707.07465 author:Dario Garcia-Gasulla, Armand Vilalta, Ferran Parés, Jonatan Moreno, Eduard Ayguadé, Jesus Labarta, Ulises Cortés, Toyotaro Suzumura category:cs.NE  published:2017-07-24 summary:Patterns stored within pre-trained deep neural networks compose large and powerful descriptive languages that can be used for many different purposes. Typically, deep network representations are implemented within vector embedding spaces, which enables the use of traditional machine learning algorithms on top of them. In this short paper we propose the construction of a graph embedding space instead, introducing a methodology to transform the knowledge coded within a deep convolutional network into a topological space (i.e. a network). We outline how such graph can hold data instances, data features, relations between instances and features, and relations among features. Finally, we introduce some preliminary experiments to illustrate how the resultant graph embedding space can be exploited through graph analytics algorithms. version:1
arxiv-1707-07443 | Combinatorial Multi-armed Bandit with Probabilistically Triggered Arms: A Case with Bounded Regret | http://arxiv.org/abs/1707.07443 | id:1707.07443 author:A. Ömer Sarıtaç, Cem Tekin category:cs.LG stat.ML  published:2017-07-24 summary:In this paper, we study the combinatorial multi-armed bandit problem (CMAB) with probabilistically triggered arms (PTAs). Under the assumption that the arm triggering probabilities (ATPs) are positive for all arms, we prove that a class of upper confidence bound (UCB) policies, named Combinatorial UCB with exploration rate $\kappa$ (CUCB-$\kappa$), and Combinatorial Thompson Sampling (CTS), which estimates the expected states of the arms via Thompson sampling, achieve bounded regret. In addition, we prove that CUCB-$0$ and CTS incur $O(\sqrt{T})$ gap-independent regret. These results improve the results in previous works, which show $O(\log T)$ gap-dependent and $O(\sqrt{T\log T})$ gap-independent regrets, respectively, under no assumptions on the ATPs. Then, we numerically evaluate the performance of CUCB-$\kappa$ and CTS in a real-world movie recommendation problem, where the actions correspond to recommending a set of movies, the arms correspond to the edges between the movies and the users, and the goal is to maximize the total number of users that are attracted by at least one movie. Our numerical results complement our theoretical findings on bounded regret. Apart from this problem, our results also directly apply to the online influence maximization (OIM) problem studied in numerous prior works. version:1
arxiv-1707-07438 | Delineation of line patterns in images using B-COSFIRE filters | http://arxiv.org/abs/1707.07438 | id:1707.07438 author:Nicola Strisciuglio, Nicolai Petkov category:cs.CV  published:2017-07-24 summary:Delineation of line patterns in images is a basic step required in various applications such as blood vessel detection in medical images, segmentation of rivers or roads in aerial images, detection of cracks in walls or pavements, etc. In this paper we present trainable B-COSFIRE filters, which are a model of some neurons in area V1 of the primary visual cortex, and apply it to the delineation of line patterns in different kinds of images. B-COSFIRE filters are trainable as their selectivity is determined in an automatic configuration process given a prototype pattern of interest. They are configurable to detect any preferred line structure (e.g. segments, corners, cross-overs, etc.), so usable for automatic data representation learning. We carried out experiments on two data sets, namely a line-network data set from INRIA and a data set of retinal fundus images named IOSTAR. The results that we achieved confirm the robustness of the proposed approach and its effectiveness in the delineation of line structures in different kinds of images. version:1
arxiv-1706-09739 | A Deep Multimodal Approach for Cold-start Music Recommendation | http://arxiv.org/abs/1706.09739 | id:1706.09739 author:Sergio Oramas, Oriol Nieto, Mohamed Sordo, Xavier Serra category:cs.IR cs.LG  published:2017-06-29 summary:An increasing amount of digital music is being published daily. Music streaming services often ingest all available music, but this poses a challenge: how to recommend new artists for which prior knowledge is scarce? In this work we aim to address this so-called cold-start problem by combining text and audio information with user feedback data using deep network architectures. Our method is divided into three steps. First, artist embeddings are learned from biographies by combining semantics, text features, and aggregated usage data. Second, track embeddings are learned from the audio signal and available feedback data. Finally, artist and track embeddings are combined in a multimodal network. Results suggest that both splitting the recommendation problem between feature levels (i.e., artist metadata and audio track), and merging feature embeddings in a multimodal approach improve the accuracy of the recommendations. version:2
arxiv-1707-07432 | LV-ROVER: Lexicon Verified Recognizer Output Voting Error Reduction | http://arxiv.org/abs/1707.07432 | id:1707.07432 author:Bruno Stuner, Clément Chatelain, Thierry Paquet category:cs.CV  published:2017-07-24 summary:Offline handwritten text line recognition is a hard task that requires both an efficient optical character recognizer and language model. Handwriting recognition state of the art methods are based on Long Short Term Memory (LSTM) recurrent neural networks (RNN) coupled with the use of linguistic knowledge. Most of the proposed approaches in the literature focus on improving one of the two components and use constraint, dedicated to a database lexicon. However, state of the art performance is achieved by combining multiple optical models, and possibly multiple language models with the Recognizer Output Voting Error Reduction (ROVER) framework. Though handwritten line recognition with ROVER has been implemented by combining only few recognizers because training multiple complete recognizers is hard. In this paper we propose a Lexicon Verified ROVER: LV-ROVER, that has a reduce complexity compare to the original one and that can combine hundreds of recognizers without language models. We achieve state of the art for handwritten line text on the RIMES dataset. version:1
arxiv-1707-07425 | Health Analytics: a systematic review of approaches to detect phenotype cohorts using electronic health records | http://arxiv.org/abs/1707.07425 | id:1707.07425 author:Norman Hiob, Stefan Lessmann category:stat.ML  published:2017-07-24 summary:The paper presents a systematic review of state-of-the-art approaches to identify patient cohorts using electronic health records. It gives a comprehensive overview of the most commonly de-tected phenotypes and its underlying data sets. Special attention is given to preprocessing of in-put data and the different modeling approaches. The literature review confirms natural language processing to be a promising approach for electronic phenotyping. However, accessibility and lack of natural language process standards for medical texts remain a challenge. Future research should develop such standards and further investigate which machine learning approaches are best suited to which type of medical data. version:1
arxiv-1707-07418 | Generative OpenMax for Multi-Class Open Set Classification | http://arxiv.org/abs/1707.07418 | id:1707.07418 author:ZongYuan Ge, Sergey Demyanov, Zetao Chen, Rahil Garnavi category:cs.CV  published:2017-07-24 summary:We present a conceptually new and flexible method for multi-class open set classification. Unlike previous methods where unknown classes are inferred with respect to the feature or decision distance to the known classes, our approach is able to provide explicit modelling and decision score for unknown classes. The proposed method, called Gener- ative OpenMax (G-OpenMax), extends OpenMax by employing generative adversarial networks (GANs) for novel category image synthesis. We validate the proposed method on two datasets of handwritten digits and characters, resulting in superior results over previous deep learning based method OpenMax Moreover, G-OpenMax provides a way to visualize samples representing the unknown classes from open space. Our simple and effective approach could serve as a new direction to tackle the challenging multi-class open set classification problem. version:1
arxiv-1707-02637 | Local Activity-tuned Image Filtering for Noise Removal and Image Smoothing | http://arxiv.org/abs/1707.02637 | id:1707.02637 author:Lijun Zhao, Jie Liang, Huihui Bai, Lili Meng, Anhong Wang, Yao Zhao category:cs.CV  published:2017-07-09 summary:In this paper, two local activity-tuned filtering frameworks are proposed for noise removal and image smoothing, where the local activity measurement is given by the clipped and normalized local variance or standard deviation. The first framework is a modified anisotropic diffusion for noise removal of piece-wise smooth image. The second framework is a local activity-tuned Relative Total Variance (RTV) method for image smoothing. Both frameworks employ the division of gradient and the local activity measurement to achieve noise removal. In addition, to better capture local information, the proposed RTV uses the product of gradient and local activity measurement to boost the performance of image smoothing. Experimental results are presented to demonstrate the efficiency of the proposed methods on various applications, including depth image filtering, clip-art compression artifact removal, image smoothing, and image denoising. version:2
arxiv-1707-07413 | Exploring Neural Transducers for End-to-End Speech Recognition | http://arxiv.org/abs/1707.07413 | id:1707.07413 author:Eric Battenberg, Jitong Chen, Rewon Child, Adam Coates, Yashesh Gaur, Yi Li, Hairong Liu, Sanjeev Satheesh, David Seetapun, Anuroop Sriram, Zhenyao Zhu category:cs.CL cs.NE  published:2017-07-24 summary:In this work, we perform an empirical comparison among the CTC, RNN-Transducer, and attention-based Seq2Seq models for end-to-end speech recognition. We show that, without any language model, Seq2Seq and RNN-Transducer models both outperform the best reported CTC models with a language model, on the popular Hub5'00 benchmark. On our internal diverse dataset, these trends continue - RNNTransducer models rescored with a language model after beam search outperform our best CTC models. These results simplify the speech recognition pipeline so that decoding can now be expressed purely as neural network operations. We also study how the choice of encoder architecture affects the performance of the three models - when all encoder layers are forward only, and when encoders downsample the input representation aggressively. version:1
arxiv-1707-07411 | Traffic scene recognition based on deep cnn and vlad spatial pyramids | http://arxiv.org/abs/1707.07411 | id:1707.07411 author:Fang-Yu Wu, Shi-Yang Yan, Jeremy S. Smith, Bai-Ling Zhang category:cs.CV  published:2017-07-24 summary:Traffic scene recognition is an important and challenging issue in Intelligent Transportation Systems (ITS). Recently, Convolutional Neural Network (CNN) models have achieved great success in many applications, including scene classification. The remarkable representational learning capability of CNN remains to be further explored for solving real-world problems. Vector of Locally Aggregated Descriptors (VLAD) encoding has also proved to be a powerful method in catching global contextual information. In this paper, we attempted to solve the traffic scene recognition problem by combining the features representational capabilities of CNN with the VLAD encoding scheme. More specifically, the CNN features of image patches generated by a region proposal algorithm are encoded by applying VLAD, which subsequently represent an image in a compact representation. To catch the spatial information, spatial pyramids are exploited to encode CNN features. We experimented with a dataset of 10 categories of traffic scenes, with satisfactory categorization performances. version:1
arxiv-1707-07410 | Toward Geometric Deep SLAM | http://arxiv.org/abs/1707.07410 | id:1707.07410 author:Daniel DeTone, Tomasz Malisiewicz, Andrew Rabinovich category:cs.CV  published:2017-07-24 summary:We present a point tracking system powered by two deep convolutional neural networks. The first network, MagicPoint, operates on single images and extracts salient 2D points. The extracted points are "SLAM-ready" because they are by design isolated and well-distributed throughout the image. We compare this network against classical point detectors and discover a significant performance gap in the presence of image noise. As transformation estimation is more simple when the detected points are geometrically stable, we designed a second network, MagicWarp, which operates on pairs of point images (outputs of MagicPoint), and estimates the homography that relates the inputs. This transformation engine differs from traditional approaches because it does not use local point descriptors, only point locations. Both networks are trained with simple synthetic data, alleviating the requirement of expensive external camera ground truthing and advanced graphics rendering pipelines. The system is fast and lean, easily running 30+ FPS on a single CPU. version:1
arxiv-1707-07402 | Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback | http://arxiv.org/abs/1707.07402 | id:1707.07402 author:Khanh Nguyen, Hal Daumé III, Jordan Boyd-Graber category:cs.CL cs.AI cs.HC cs.LG  published:2017-07-24 summary:Machine translation is a natural candidate problem for reinforcement learning from human feedback: users provide quick, dirty ratings on candidate translations to guide a system to improve. Yet, current neural machine translation training focuses on expensive human-generated reference translations. We describe a reinforcement learning algorithm that improves neural machine translation systems from simulated human feedback. Our algorithm combines the advantage actor-critic algorithm (Mnih et al., 2016) with the attention-based neural encoder-decoder architecture (Luong et al., 2015). This algorithm (a) is well-designed for problems with a large action space and delayed rewards, (b) effectively optimizes traditional corpus-level machine translation metrics, and (c) is robust to skewed, high-variance, granular feedback modeled after actual human behaviors. version:1
arxiv-1707-07399 | Learning for Multi-robot Cooperation in Partially Observable Stochastic Environments with Macro-actions | http://arxiv.org/abs/1707.07399 | id:1707.07399 author:Miao Liu, Kavinayan Sivakumar, Shayegan Omidshafiei, Christopher Amato, Jonathan P. How category:cs.MA cs.LG cs.RO  published:2017-07-24 summary:This paper presents a data-driven approach for multi-robot coordination in partially-observable domains based on Decentralized Partially Observable Markov Decision Processes (Dec-POMDPs) and macro-actions (MAs). Dec-POMDPs provide a general framework for cooperative sequential decision making under uncertainty and MAs allow temporally extended and asynchronous action execution. To date, most methods assume the underlying Dec-POMDP model is known a priori or a full simulator is available during planning time. Previous methods which aim to address these issues suffer from local optimality and sensitivity to initial conditions. Additionally, few hardware demonstrations involving a large team of heterogeneous robots and with long planning horizons exist. This work addresses these gaps by proposing an iterative sampling based Expectation-Maximization algorithm (iSEM) to learn polices using only trajectory data containing observations, MAs, and rewards. Our experiments show the algorithm is able to achieve better solution quality than the state-of-the-art learning-based methods. We implement two variants of multi-robot Search and Rescue (SAR) domains (with and without obstacles) on hardware to demonstrate the learned policies can effectively control a team of distributed robots to cooperate in a partially observable stochastic environment. version:1
arxiv-1707-07397 | Synthesizing Robust Adversarial Examples | http://arxiv.org/abs/1707.07397 | id:1707.07397 author:Anish Athalye, Ilya Sutskever category:cs.CV  published:2017-07-24 summary:Neural networks are susceptible to adversarial examples: small, carefully-crafted perturbations can cause networks to misclassify inputs in arbitrarily chosen ways. However, some studies have showed that adversarial examples crafted following the usual methods are not tolerant to small transformations: for example, zooming in on an adversarial image can cause it to be classified correctly again. This raises the question of whether adversarial examples are a concern in practice, because many real-world systems capture images from multiple scales and perspectives. This paper shows that adversarial examples can be made robust to distributions of transformations. Our approach produces single images that are simultaneously adversarial under all transformations in a chosen distribution, showing that we cannot rely on transformations such as rescaling, translation, and rotation to protect against adversarial examples. version:1
arxiv-1707-07394 | Wavelet Convolutional Neural Networks for Texture Classification | http://arxiv.org/abs/1707.07394 | id:1707.07394 author:Shin Fujieda, Kohei Takayama, Toshiya Hachisuka category:cs.CV cs.LG  published:2017-07-24 summary:Texture classification is an important and challenging problem in many image processing applications. While convolutional neural networks (CNNs) achieved significant successes for image classification, texture classification remains a difficult problem since textures usually do not contain enough information regarding the shape of object. In image processing, texture classification has been traditionally studied well with spectral analyses which exploit repeated structures in many textures. Since CNNs process images as-is in the spatial domain whereas spectral analyses process images in the frequency domain, these models have different characteristics in terms of performance. We propose a novel CNN architecture, wavelet CNNs, which integrates a spectral analysis into CNNs. Our insight is that the pooling layer and the convolution layer can be viewed as a limited form of a spectral analysis. Based on this insight, we generalize both layers to perform a spectral analysis with wavelet transform. Wavelet CNNs allow us to utilize spectral information which is lost in conventional CNNs but useful in texture classification. The experiments demonstrate that our model achieves better accuracy in texture classification than existing models. We also show that our model has significantly fewer parameters than CNNs, making our model easier to train with less memory. version:1
arxiv-1707-07391 | Contrastive-center loss for deep neural networks | http://arxiv.org/abs/1707.07391 | id:1707.07391 author:Ce Qi, Fei Su category:cs.CV  published:2017-07-24 summary:The deep convolutional neural network(CNN) has significantly raised the performance of image classification and face recognition. Softmax is usually used as supervision, but it only penalizes the classification loss. In this paper, we propose a novel auxiliary supervision signal called contrastivecenter loss, which can further enhance the discriminative power of the features, for it learns a class center for each class. The proposed contrastive-center loss simultaneously considers intra-class compactness and inter-class separability, by penalizing the contrastive values between: (1)the distances of training samples to their corresponding class centers, and (2)the sum of the distances of training samples to their non-corresponding class centers. Experiments on different datasets demonstrate the effectiveness of contrastive-center loss. version:1
arxiv-1707-07388 | Semantic 3D Occupancy Mapping through Efficient High Order CRFs | http://arxiv.org/abs/1707.07388 | id:1707.07388 author:Shichao Yang, Yulan Huang, Sebastian Scherer category:cs.CV cs.RO  published:2017-07-24 summary:Semantic 3D mapping can be used for many applications such as robot navigation and virtual interaction. In recent years, there has been great progress in semantic segmentation and geometric 3D mapping. However, it is still challenging to combine these two tasks for accurate and large-scale semantic mapping from images. In the paper, we propose an incremental and (near) real-time semantic mapping system. A 3D scrolling occupancy grid map is built to represent the world, which is memory and computationally efficient and bounded for large scale environments. We utilize the CNN segmentation as prior prediction and further optimize 3D grid labels through a novel CRF model. Superpixels are utilized to enforce smoothness and form robust P N high order potential. An efficient mean field inference is developed for the graph optimization. We evaluate our system on the KITTI dataset and improve the segmentation accuracy by 10% over existing systems. version:1
arxiv-1707-02069 | A spatiotemporal model with visual attention for video classification | http://arxiv.org/abs/1707.02069 | id:1707.02069 author:Mo Shan, Nikolay Atanasov category:cs.CV  published:2017-07-07 summary:High level understanding of sequential visual input is important for safe and stable autonomy, especially in localization and object detection. While traditional object classification and tracking approaches are specifically designed to handle variations in rotation and scale, current state-of-the-art approaches based on deep learning achieve better performance. This paper focuses on developing a spatiotemporal model to handle videos containing moving objects with rotation and scale changes. Built on models that combine Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) to classify sequential data, this work investigates the effectiveness of incorporating attention modules in the CNN stage for video classification. The superiority of the proposed spatiotemporal model is demonstrated on the Moving MNIST dataset augmented with rotation and scaling. version:2
arxiv-1707-07360 | Compact Model Representation for 3D Reconstruction | http://arxiv.org/abs/1707.07360 | id:1707.07360 author:Jhony K. Pontes, Chen Kong, Anders Eriksson, Clinton Fookes, Sridha Sridharan, Simon Lucey category:cs.CV  published:2017-07-23 summary:3D reconstruction from 2D images is a central problem in computer vision. Recent works have been focusing on reconstruction directly from a single image. It is well known however that only one image cannot provide enough information for such a reconstruction. A prior knowledge that has been entertained are 3D CAD models due to its online ubiquity. A fundamental question is how to compactly represent millions of CAD models while allowing generalization to new unseen objects with fine-scaled geometry. We introduce an approach to compactly represent a 3D mesh. Our method first selects a 3D model from a graph structure by using a novel free-form deformation FFD 3D-2D registration, and then the selected 3D model is refined to best fit the image silhouette. We perform a comprehensive quantitative and qualitative analysis that demonstrates impressive dense and realistic 3D reconstruction from single images. version:1
arxiv-1707-07344 | Event Coreference Resolution by Iteratively Unfolding Inter-dependencies among Events | http://arxiv.org/abs/1707.07344 | id:1707.07344 author:Prafulla Kumar Choubey, Ruihong Huang category:cs.CL  published:2017-07-23 summary:We introduce a novel iterative approach for event coreference resolution that gradually builds event clusters by exploiting inter-dependencies among event mentions within the same chain as well as across event chains. Among event mentions in the same chain, we distinguish within- and cross-document event coreference links by using two distinct pairwise classifiers, trained separately to capture differences in feature distributions of within- and cross-document event clusters. Our event coreference approach alternates between WD and CD clustering and combines arguments from both event clusters after every merge, continuing till no more merge can be made. And then it performs further merging between event chains that are both closely related to a set of other chains of events. Experiments on the ECB+ corpus show that our model outperforms state-of-the-art methods in joint task of WD and CD event coreference resolution. version:1
arxiv-1707-07343 | A Sequential Model for Classifying Temporal Relations between Intra-Sentence Events | http://arxiv.org/abs/1707.07343 | id:1707.07343 author:Prafulla Kumar Choubey, Ruihong Huang category:cs.CL  published:2017-07-23 summary:We present a sequential model for temporal relation classification between intra-sentence events. The key observation is that the overall syntactic structure and compositional meanings of the multi-word context between events are important for distinguishing among fine-grained temporal relations. Specifically, our approach first extracts a sequence of context words that indicates the temporal relation between two events, which well align with the dependency path between two event mentions. The context word sequence, together with a parts-of-speech tag sequence and a dependency relation sequence that are generated corresponding to the word sequence, are then provided as input to bidirectional recurrent neural network (LSTM) models. The neural nets learn compositional syntactic and semantic representations of contexts surrounding the two events and predict the temporal relation between them. Evaluation of the proposed approach on TimeBank corpus shows that sequential modeling is capable of accurately recognizing temporal relations between events, which outperforms a neural net model using various discrete features as input that imitates previous feature based models. version:1
arxiv-1706-03860 | A Direction Search and Spectral Clustering Based Approach to Subspace Clustering | http://arxiv.org/abs/1706.03860 | id:1706.03860 author:Mostafa Rahmani, George Atia category:cs.CV cs.IR cs.LG stat.AP stat.ML  published:2017-06-12 summary:This paper presents a new spectral-clustering-based approach to the subspace clustering problem in which the data lies in the union of an unknown number of unknown linear subspaces. Underpinning the proposed method is a convex program for optimal direction search, which for each data point d, finds an optimal direction in the span of the data that has minimum projection on the other data points and non-vanishing projection on d. The obtained directions are subsequently leveraged to identify a neighborhood set for each data point. An Alternating Direction Method of Multipliers (ADMM) framework is provided to efficiently solve for the optimal directions. The proposed method is shown to often outperform the existing subspace clustering methods, particularly for unwieldy scenarios involving high levels of noise and close subspaces, and yields the state-of-the-art results for the problem of face clustering using subspace segmentation. version:3
arxiv-1707-07341 | Prediction-Constrained Training for Semi-Supervised Mixture and Topic Models | http://arxiv.org/abs/1707.07341 | id:1707.07341 author:Michael C. Hughes, Leah Weiner, Gabriel Hope, Thomas H. McCoy Jr., Roy H. Perlis, Erik B. Sudderth, Finale Doshi-Velez category:stat.ML  published:2017-07-23 summary:Supervisory signals have the potential to make low-dimensional data representations, like those learned by mixture and topic models, more interpretable and useful. We propose a framework for training latent variable models that explicitly balances two goals: recovery of faithful generative explanations of high-dimensional data, and accurate prediction of associated semantic labels. Existing approaches fail to achieve these goals due to an incomplete treatment of a fundamental asymmetry: the intended application is always predicting labels from data, not data from labels. Our prediction-constrained objective for training generative models coherently integrates loss-based supervisory signals while enabling effective semi-supervised learning from partially labeled data. We derive learning algorithms for semi-supervised mixture and topic models using stochastic gradient descent with automatic differentiation. We demonstrate improved prediction quality compared to several previous supervised topic models, achieving predictions competitive with high-dimensional logistic regression on text sentiment analysis and electronic health records tasks while simultaneously learning interpretable topics. version:1
arxiv-1707-07336 | Person Re-identification Using Visual Attention | http://arxiv.org/abs/1707.07336 | id:1707.07336 author:Alireza Rahimpour, Liu Liu, Ali Taalimi, Yang Song, Hairong Qi category:cs.CV  published:2017-07-23 summary:Despite recent attempts for solving the person re-identification problem, it remains a challenging task since a person's appearance can vary significantly when large variations in view angle, human pose and illumination are involved. The concept of attention is one of the most interesting recent architectural innovations in neural networks. Inspired by that, in this paper we propose a novel approach based on using a gradient-based attention mechanism in deep convolution neural network for solving the person re-identification problem. Our model learns to focus selectively on parts of the input image for which the networks' output is most sensitive to. Extensive comparative evaluations demonstrate that the proposed method outperforms state-of-the-art approaches, including both traditional and deep neural network-based methods on the challenging CUHK01 and CUHK03 datasets. version:1
arxiv-1707-07331 | Rule-Based Spanish Morphological Analyzer Built From Spell Checking Lexicon | http://arxiv.org/abs/1707.07331 | id:1707.07331 author:Natalie Ahn category:cs.CL  published:2017-07-23 summary:Preprocessing tools for automated text analysis have become more widely available in major languages, but non-English tools are often still limited in their functionality. When working with Spanish-language text, researchers can easily find tools for tokenization and stemming, but may not have the means to extract more complex word features like verb tense or mood. Yet Spanish is a morphologically rich language in which such features are often identifiable from word form. Conjugation rules are consistent, but many special verbs and nouns take on different rules. While building a complete dictionary of known words and their morphological rules would be labor intensive, resources to do so already exist, in spell checkers designed to generate valid forms of known words. This paper introduces a set of tools for Spanish-language morphological analysis, built using the COES spell checking tools, to label person, mood, tense, gender and number, derive a word's root noun or verb infinitive, and convert verbs to their nominal form. version:1
arxiv-1707-07328 | Adversarial Examples for Evaluating Reading Comprehension Systems | http://arxiv.org/abs/1707.07328 | id:1707.07328 author:Robin Jia, Percy Liang category:cs.CL cs.LG  published:2017-07-23 summary:Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear. To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting, the accuracy of sixteen published models drops from an average of $75\%$ F1 score to $36\%$; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to $7\%$. We hope our insights will motivate the development of new models that understand language more precisely. version:1
arxiv-1707-07321 | Exploiting Deep Features for Remote Sensing Image Retrieval: A Systematic Investigation | http://arxiv.org/abs/1707.07321 | id:1707.07321 author:Gui-Song Xia, Xin-Yi Tong, Fan Hu, Yanfei Zhong, Mihai Datcu, Liangpei Zhang category:cs.CV  published:2017-07-23 summary:Remote sensing (RS) image retrieval based on visual content is of great significance for geological information mining. Over the past two decades, a large amount of research on this task has been carried out, which mainly focuses on the following three core issues of image retrieval: visual feature, similarity metric and relevance feedback. Along with the advance of these issues, the technology of RS image retrieval has been developed comparatively mature. However, due to the complexity and multiformity of high-resolution remote sensing (HRRS) images, there is still room for improvement in the current methods on HRRS data retrieval. In this paper, we analyze the three key aspects of retrieval and provide a comprehensive review on content-based RS image retrieval methods. Furthermore, for the goal to advance the state-of-the-art in HRRS image retrieval, we focus on the visual feature aspect and delve how to use powerful deep representations in this task. We conduct systematic investigation on evaluating factors that may affect the performance of deep features. By optimizing each factor, we acquire remarkable retrieval results on publicly available HRRS datasets. Finally, we explain the experimental phenomenon in detail and draw instructive conclusions according to our analysis. Our work can serve as a guiding role for the research of content-based RS image retrieval. version:1
arxiv-1707-07961 | Time Series Compression Based on Adaptive Piecewise Recurrent Autoencoder | http://arxiv.org/abs/1707.07961 | id:1707.07961 author:Daniel Hsu category:cs.NE  published:2017-07-23 summary:Time series account for a large proportion of the data stored in financial, medical and scientific databases. The efficient storage of time series is important in practical applications. In this paper, we propose a novel \emph{lossy} compression scheme for time series. The encoder and decoder are both composed by recurrent neural networks (RNN) such as long short-term memory (LSTM). There is an autoencoder between encoder and decoder, which encodes the hidden state and input together and decodes them at the decoder side. The input window size is adaptively changing based on the local statistics of time series. The experimental study shows that the proposed algorithm can achieve competitive compression ratio on real-world time series. version:1
arxiv-1707-07312 | A new take on measuring nutritional density: The feasibility of using a deep neural network to assess commercially-prepared puree concentrations | http://arxiv.org/abs/1707.07312 | id:1707.07312 author:Kaylen J. Pfisterer, Robert Amelard, Audrey G. Chung, Alexander Wong category:cs.CV physics.med-ph  published:2017-07-23 summary:Dysphagia affects 590 million people worldwide and increases risk for malnutrition. Pureed food may reduce choking, however preparation differences impact nutrient density making quality assurance necessary. This paper is the first study to investigate the feasibility of computational pureed food nutritional density analysis using an imaging system. Motivated by a theoretical optical dilution model, a novel deep neural network (DNN) was evaluated using 390 samples from thirteen types of commercially prepared purees at five dilutions. The DNN predicted relative concentration of the puree sample (20%, 40%, 60%, 80%, 100% initial concentration). Data were captured using same-side reflectance of multispectral imaging data at different polarizations at three exposures. Experimental results yielded an average top-1 prediction accuracy of 92.2+/-0.41% with sensitivity and specificity of 83.0+/-15.0% and 95.0+/-4.8%, respectively. This DNN imaging system for nutrient density analysis of pureed food shows promise as a novel tool for nutrient quality assurance. version:1
arxiv-1707-07310 | Robust Tracking and Behavioral Modeling of Movements of Biological Collectives from Ordinary Video Recordings | http://arxiv.org/abs/1707.07310 | id:1707.07310 author:Hiroki Sayama, Farnaz Zamani Esfahlani, Ali Jazayeri, J. Scott Turner category:cs.MA cs.CV nlin.AO q-bio.QM  published:2017-07-23 summary:We propose a novel computational method to extract information about interactions among individuals with different behavioral states in a biological collective from ordinary video recordings. Assuming that individuals are acting as finite state machines, our method first detects discrete behavioral states of those individuals and then constructs a model of their state transitions, taking into account the positions and states of other individuals in the vicinity. We have tested the proposed method through applications to two real-world biological collectives, termites in an experimental setting and human pedestrians in an open space. For each application, a robust tracking system was developed in-house, utilizing interactive human intervention (for termite tracking) or online agent-based simulation (for pedestrian tracking). In both cases, significant interactions were detected between nearby individuals with different states, demonstrating the effectiveness of the proposed method. version:1
arxiv-1707-07301 | Deep Optical Flow Estimation Via Multi-Scale Correspondence Structure Learning | http://arxiv.org/abs/1707.07301 | id:1707.07301 author:Shanshan Zhao, Xi Li, Omar El Farouk Bourahla category:cs.CV  published:2017-07-23 summary:As an important and challenging problem in computer vision, learning based optical flow estimation aims to discover the intrinsic correspondence structure between two adjacent video frames through statistical learning. Therefore, a key issue to solve in this area is how to effectively model the multi-scale correspondence structure properties in an adaptive end-to-end learning fashion. Motivated by this observation, we propose an end-to-end multi-scale correspondence structure learning (MSCSL) approach for optical flow estimation. In principle, the proposed MSCSL approach is capable of effectively capturing the multi-scale inter-image-correlation correspondence structures within a multi-level feature space from deep learning. Moreover, the proposed MSCSL approach builds a spatial Conv-GRU neural network model to adaptively model the intrinsic dependency relationships among these multi-scale correspondence structures. Finally, the above procedures for correspondence structure learning and multi-scale dependency modeling are implemented in a unified end-to-end deep learning framework. Experimental results on several benchmark datasets demonstrate the effectiveness of the proposed approach. version:1
arxiv-1707-07299 | Joint DOA Estimation and Array Calibration Using Multiple Parametric Dictionary Learning | http://arxiv.org/abs/1707.07299 | id:1707.07299 author:H. Ghanbari, H. Zayyani, E. Yazdian category:cs.LG  published:2017-07-23 summary:This letter proposes a multiple parametric dictionary learning algorithm for direction of arrival (DOA) estimation in presence of array gain-phase error and mutual coupling. It jointly solves both the DOA estimation and array imperfection problems to yield a robust DOA estimation in presence of array imperfection errors and off-grid. In the proposed method, a multiple parametric dictionary learning-based algorithm with an steepest-descent iteration is used for learning the parametric perturbation matrices and the steering matrix simultaneously. It also exploits the multiple snapshots information to enhance the performance of DOA estimation. Simulation results show the efficiency of the proposed algorithm when both off-grid problem and array imperfection exist. version:1
arxiv-1707-07287 | Learning uncertainty in regression tasks by deep neural networks | http://arxiv.org/abs/1707.07287 | id:1707.07287 author:Pavel Gurevich, Hannes Stuke category:stat.ML cs.LG  published:2017-07-23 summary:We suggest a general approach to quantification of different types of uncertainty in regression tasks performed by deep neural networks. It is based on the simultaneous training of two neural networks with a joint loss function. One of the networks performs regression and the other quantifies the uncertainty of predictions of the first one. Unlike in many standard uncertainty quantification methods, the targets are not assumed to be sampled from an a priori given probability distribution. We analyze how the hyperparameters affect the learning process and, additionally, show that our method even allows for better predictions compared to standard neural networks without uncertainty counterparts. Finally, we show that a particular case of our approach is the mean-variance estimation given by a Gaussian network. version:1
arxiv-1707-07279 | Using Argument-based Features to Predict and Analyse Review Helpfulness | http://arxiv.org/abs/1707.07279 | id:1707.07279 author:Haijing Liu, Yang Gao, Pin Lv, Mengxue Li, Shiqiang Geng, Minglan Li, Hao Wang category:cs.CL  published:2017-07-23 summary:We study the helpful product reviews identification problem in this paper. We observe that the evidence-conclusion discourse relations, also known as arguments, often appear in product reviews, and we hypothesise that some argument-based features, e.g. the percentage of argumentative sentences, the evidences-conclusions ratios, are good indicators of helpful reviews. To validate this hypothesis, we manually annotate arguments in 110 hotel reviews, and investigate the effectiveness of several combinations of argument-based features. Experiments suggest that, when being used together with the argument-based features, the state-of-the-art baseline features can enjoy a performance boost (in terms of F1) of 11.01\% in average. version:1
arxiv-1707-07278 | Fine Grained Citation Span for References in Wikipedia | http://arxiv.org/abs/1707.07278 | id:1707.07278 author:Besnik Fetahu, Katja Markert, Avishek Anand category:cs.CL  published:2017-07-23 summary:\emph{Verifiability} is one of the core editing principles in Wikipedia, editors being encouraged to provide citations for the added content. For a Wikipedia article, determining the \emph{citation span} of a citation, i.e. what content is covered by a citation, is important as it helps decide for which content citations are still missing. We are the first to address the problem of determining the \emph{citation span} in Wikipedia articles. We approach this problem by classifying which textual fragments in an article are covered by a citation. We propose a sequence classification approach where for a paragraph and a citation, we determine the citation span at a fine-grained level. We provide a thorough experimental evaluation and compare our approach against baselines adopted from the scientific domain, where we show improvement for all evaluation metrics. version:1
arxiv-1707-07273 | Hierarchical Embeddings for Hypernymy Detection and Directionality | http://arxiv.org/abs/1707.07273 | id:1707.07273 author:Kim Anh Nguyen, Maximilian Köper, Sabine Schulte im Walde, Ngoc Thang Vu category:cs.CL  published:2017-07-23 summary:We present a novel neural model HyperVec to learn hierarchical embeddings for hypernymy detection and directionality. While previous embeddings have shown limitations on prototypical hypernyms, HyperVec represents an unsupervised measure where embeddings are learned in a specific order and capture the hypernym$-$hyponym distributional hierarchy. Moreover, our model is able to generalize over unseen hypernymy pairs, when using only small sets of training data, and by mapping to other languages. Results on benchmark datasets show that HyperVec outperforms both state$-$of$-$the$-$art unsupervised measures and embedding models on hypernymy detection and directionality, and on predicting graded lexical entailment. version:1
arxiv-1707-07270 | MatchZoo: A Toolkit for Deep Text Matching | http://arxiv.org/abs/1707.07270 | id:1707.07270 author:Yixing Fan, Liang Pang, JianPeng Hou, Jiafeng Guo, Yanyan Lan, Xueqi Cheng category:cs.IR cs.CL  published:2017-07-23 summary:In recent years, deep neural models have been widely adopted for text matching tasks, such as question answering and information retrieval, showing improved performance as compared with previous methods. In this paper, we introduce the MatchZoo toolkit that aims to facilitate the designing, comparing and sharing of deep text matching models. Specifically, the toolkit provides a unified data preparation module for different text matching problems, a flexible layer-based model construction process, and a variety of training objectives and evaluation metrics. In addition, the toolkit has implemented two schools of representative deep text matching models, namely representation-focused models and interaction-focused models. Finally, users can easily modify existing models, create and share their own models for text matching in MatchZoo. version:1
arxiv-1707-07269 | Asymptotic Normality of the Median Heuristic | http://arxiv.org/abs/1707.07269 | id:1707.07269 author:Garreau Damien category:math.ST stat.ML stat.TH 62E20  62G30  published:2017-07-23 summary:The median heuristic is a popular tool to set the bandwidth of radial basis function kernels. While its empirical performances make it a safe choice under most circumstances, there is little theoretical understanding of why this is the case. For large sample size, we show in this article that the median heuristic behaves approximately as the median of a distribution that we describe completely in the setting of kernel two-sample test and kernel change-point detection. More precisely, we show that the median heuristic is asymptotically normal around this value. We illustrate these findings when the underlying distributions are multivariate Gaussian distributions. version:1
arxiv-1707-07265 | Composing Distributed Representations of Relational Patterns | http://arxiv.org/abs/1707.07265 | id:1707.07265 author:Sho Takase, Naoaki Okazaki, Kentaro Inui category:cs.CL  published:2017-07-23 summary:Learning distributed representations for relation instances is a central technique in downstream NLP applications. In order to address semantic modeling of relational patterns, this paper constructs a new dataset that provides multiple similarity ratings for every pair of relational patterns on the existing dataset. In addition, we conduct a comparative study of different encoders including additive composition, RNN, LSTM, and GRU for composing distributed representations of relational patterns. We also present Gated Additive Composition, which is an enhancement of additive composition with the gating mechanism. Experiments show that the new dataset does not only enable detailed analyses of the different encoders, but also provides a gauge to predict successes of distributed representations of relational patterns in the relation classification task. version:1
arxiv-1707-07256 | Deeply-Learned Part-Aligned Representations for Person Re-Identification | http://arxiv.org/abs/1707.07256 | id:1707.07256 author:Liming Zhao, Xi Li, Jingdong Wang, Yueting Zhuang category:cs.CV  published:2017-07-23 summary:In this paper, we address the problem of person re-identification, which refers to associating the persons captured from different cameras. We propose a simple yet effective human part-aligned representation for handling the body part misalignment problem. Our approach decomposes the human body into regions (parts) which are discriminative for person matching, accordingly computes the representations over the regions, and aggregates the similarities computed between the corresponding regions of a pair of probe and gallery images as the overall matching score. Our formulation, inspired by attention models, is a deep neural network modeling the three steps together, which is learnt through minimizing the triplet loss function without requiring body part labeling information. Unlike most existing deep learning algorithms that learn a global or spatial partition-based local representation, our approach performs human body partition, and thus is more robust to pose changes and various human spatial distributions in the person bounding box. Our approach shows state-of-the-art results over standard datasets, Market-$1501$, CUHK$03$, CUHK$01$ and VIPeR. version:1
arxiv-1707-07255 | Detecting and Grouping Identical Objects for Region Proposal and Classification | http://arxiv.org/abs/1707.07255 | id:1707.07255 author:Wim Abbeloos, Sergio Caccamo, Esra Ataer-Cansizoglu, Yuichi Taguchi, Chen Feng, Teng-Yok Lee category:cs.CV  published:2017-07-23 summary:Often multiple instances of an object occur in the same scene, for example in a warehouse. Unsupervised multi-instance object discovery algorithms are able to detect and identify such objects. We use such an algorithm to provide object proposals to a convolutional neural network (CNN) based classifier. This results in fewer regions to evaluate, compared to traditional region proposal algorithms. Additionally, it enables using the joint probability of multiple instances of an object, resulting in improved classification accuracy. The proposed technique can also split a single class into multiple sub-classes corresponding to the different object types, enabling hierarchical classification. version:1
arxiv-1707-08184 | Efficient Low Rank Tensor Ring Completion | http://arxiv.org/abs/1707.08184 | id:1707.08184 author:Wenqi Wang, Vaneet Aggarwal, Shuchin Aeron category:cs.LG cs.IT math.IT  published:2017-07-23 summary:Using the matrix product state (MPS) representation of the recently proposed tensor ring decompositions, in this paper we propose a tensor completion algorithm, which is an alternating minimization algorithm that alternates over the factors in the MPS representation. This development is motivated in part by the success of matrix completion algorithms that alternate over the (low-rank) factors. In this paper, we propose a spectral initialization for the tensor ring completion algorithm and analyze the computational complexity of the proposed algorithm. We numerically compare it with existing methods that employ a low rank tensor train approximation for data completion and show that our method outperforms the existing ones for a variety of real computer vision settings, and thus demonstrate the improved expressive power of tensor ring as compared to tensor train. version:1
arxiv-1707-07250 | Tensor Fusion Network for Multimodal Sentiment Analysis | http://arxiv.org/abs/1707.07250 | id:1707.07250 author:Amir Zadeh, Minghai Chen, Soujanya Poria, Erik Cambria, Louis-Philippe Morency category:cs.CL  published:2017-07-23 summary:Multimodal sentiment analysis is an increasingly popular research area, which extends the conventional language-based definition of sentiment analysis to a multimodal setup where other relevant modalities accompany language. In this paper, we pose the problem of multimodal sentiment analysis as modeling intra-modality and inter-modality dynamics. We introduce a novel model, termed Tensor Fusion Network, which learns both such dynamics end-to-end. The proposed approach is tailored for the volatile nature of spoken language in online videos as well as accompanying gestures and voice. In the experiments, our model outperforms state-of-the-art approaches for both multimodal and unimodal sentiment analysis. version:1
arxiv-1704-04347 | Exploiting Cross-Sentence Context for Neural Machine Translation | http://arxiv.org/abs/1704.04347 | id:1704.04347 author:Longyue Wang, Zhaopeng Tu, Andy Way, Qun Liu category:cs.CL  published:2017-04-14 summary:In translation, considering the document as a whole can help to resolve ambiguities and inconsistencies. In this paper, we propose a cross-sentence context-aware approach and investigate the influence of historical contextual information on the performance of neural machine translation (NMT). First, this history is summarized in a hierarchical way. We then integrate the historical representation into NMT in two strategies: 1) a warm-start of encoder and decoder states, and 2) an auxiliary context source for updating decoder states. Experimental results on a large Chinese-English translation task show that our approach significantly improves upon a strong attention-based NMT system by up to +2.1 BLEU points. version:3
arxiv-1707-07248 | Towards Good Practices for Deep 3D Hand Pose Estimation | http://arxiv.org/abs/1707.07248 | id:1707.07248 author:Hengkai Guo, Guijin Wang, Xinghao Chen, Cairong Zhang category:cs.CV  published:2017-07-23 summary:3D hand pose estimation from single depth image is an important and challenging problem for human-computer interaction. Recently deep convolutional networks (ConvNet) with sophisticated design have been employed to address it, but the improvement over traditional random forest based methods is not so apparent. To exploit the good practice and promote the performance for hand pose estimation, we propose a tree-structured Region Ensemble Network (REN) for directly 3D coordinate regression. It first partitions the last convolution outputs of ConvNet into several grid regions. The results from separate fully-connected (FC) regressors on each regions are then integrated by another FC layer to perform the estimation. By exploitation of several training strategies including data augmentation and smooth $L_1$ loss, proposed REN can significantly improve the performance of ConvNet to localize hand joints. The experimental results demonstrate that our approach achieves the best performance among state-of-the-art algorithms on three public hand pose datasets. We also experiment our methods on fingertip detection and human pose datasets and obtain state-of-the-art accuracy. version:1
arxiv-1707-01475 | Complex and Holographic Embeddings of Knowledge Graphs: A Comparison | http://arxiv.org/abs/1707.01475 | id:1707.01475 author:Théo Trouillon, Maximilian Nickel category:cs.LG stat.ML  published:2017-07-05 summary:Embeddings of knowledge graphs have received significant attention due to their excellent performance for tasks like link prediction and entity resolution. In this short paper, we are providing a comparison of two state-of-the-art knowledge graph embeddings for which their equivalence has recently been established, i.e., ComplEx and HolE [Nickel, Rosasco, and Poggio, 2016; Trouillon et al., 2016; Hayashi and Shimbo, 2017]. First, we briefly review both models and discuss how their scoring functions are equivalent. We then analyze the discrepancy of results reported in the original articles, and show experimentally that they are likely due to the use of different loss functions. In further experiments, we evaluate the ability of both models to embed symmetric and antisymmetric patterns. Finally, we discuss advantages and disadvantages of both models and under which conditions one would be preferable to the other. version:2
arxiv-1707-07244 | Team Applied Robotics: A closer look at our robotic picking system | http://arxiv.org/abs/1707.07244 | id:1707.07244 author:Wim Abbeloos, Fabian Gouwens, Simon Jansen, Berend Küpers, Maurice Ramaker, Toon Goedemé category:cs.CV cs.RO  published:2017-07-23 summary:This paper describes the vision based robotic picking system that was developed by our team, Team Applied Robotics, for the Amazon Picking Challenge 2016. This competition challenged teams to develop a robotic system that is able to pick a large variety of products from a shelve or a tote. We discuss the design considerations and our strategy, the high resolution 3D vision system, the use of a combination of texture and shape-based object detection algorithms, the robot path planning and object manipulators that were developed. version:1
arxiv-1704-03084 | Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning | http://arxiv.org/abs/1704.03084 | id:1704.03084 author:Baolin Peng, Xiujun Li, Lihong Li, Jianfeng Gao, Asli Celikyilmaz, Sungjin Lee, Kam-Fai Wong category:cs.CL cs.AI cs.LG  published:2017-04-10 summary:Building a dialogue agent to fulfill complex tasks, such as travel planning, is challenging because the agent has to learn to collectively complete multiple subtasks. For example, the agent needs to reserve a hotel and book a flight so that there leaves enough time for commute between arrival and hotel check-in. This paper addresses this challenge by formulating the task in the mathematical framework of options over Markov Decision Processes (MDPs), and proposing a hierarchical deep reinforcement learning approach to learning a dialogue manager that operates at different temporal scales. The dialogue manager consists of: (1) a top-level dialogue policy that selects among subtasks or options, (2) a low-level dialogue policy that selects primitive actions to complete the subtask given by the top-level policy, and (3) a global state tracker that helps ensure all cross-subtask constraints be satisfied. Experiments on a travel planning task with simulated and real users show that our approach leads to significant improvements over three baselines, two based on handcrafted rules and the other based on flat deep reinforcement learning. version:3
arxiv-1707-07225 | SAR Image Colorization: Converting Single-Polarization to Fully Polarimetric Using Deep Neural Networks | http://arxiv.org/abs/1707.07225 | id:1707.07225 author:Qian Song, Feng Xu, Ya-Qiu Jin category:cs.CV  published:2017-07-22 summary:A deep neural networks based method is proposed to convert single polarization grayscale SAR image to fully polarimetric. It consists of two components: a feature extractor network to extract hierarchical multi-scale spatial features of grayscale SAR image, followed by a feature translator network to map spatial feature to polarimetric feature with which the polarimetric covariance matrix of each pixel can be reconstructed. Both qualitative and quantitative experiments with real fully polarimetric data are conducted to show the efficacy of the proposed method. The reconstructed full-pol SAR image agrees well with the true full-pol image. Existing PolSAR applications such as model-based decomposition and unsupervised classification can be applied directly to the reconstructed full-pol SAR images. This framework can be easily extended to reconstruction of full-pol data from compact-pol data. The experiment results also show that the proposed method could be potentially used for interference removal on the cross-polarization channel. version:1
arxiv-1705-00674 | Vertex Nomination Via Local Neighborhood Matching | http://arxiv.org/abs/1705.00674 | id:1705.00674 author:Heather G. Patsolic, Youngser Park, Vince Lyzinski, Carey E. Priebe category:stat.ML  published:2017-05-01 summary:Consider two networks on overlapping, non-identical vertex sets. Given vertices of interest in the first network, we seek to identify the corresponding vertices, if any exist, in the second network. While in moderately sized networks graph matching methods can be applied directly to recover the missing correspondences, herein we present a principled methodology appropriate for situations in which the networks are too large for brute-force graph matching. Our methodology identifies vertices in a local neighborhood of the vertices of interest in the first network that have verifiable corresponding vertices in the second network. Leveraging these known correspondences, referred to as seeds, we match the induced subgraphs in each network generated by the neighborhoods of these verified seeds, and rank the vertices of the second network in terms of the most likely matches to the original vertices of interest. We demonstrate the applicability of our methodology through simulations and real data examples. version:2
arxiv-1707-07213 | Spatio-temporal human action localisation and instance segmentation in temporally untrimmed videos | http://arxiv.org/abs/1707.07213 | id:1707.07213 author:Suman Saha, Gurkirt Singh, Michael Sapienza, Philip H. S. Torr, Fabio Cuzzolin category:cs.CV  published:2017-07-22 summary:Current state-of-the-art human action recognition is focused on the classification of temporally trimmed videos in which only one action occurs per frame. In this work we address the problem of action localisation and instance segmentation in which multiple concurrent actions of the same class may be segmented out of an image sequence. We cast the action tube extraction as an energy maximisation problem in which configurations of region proposals in each frame are assigned a cost and the best action tubes are selected via two passes of dynamic programming. One pass associates region proposals in space and time for each action category, and another pass is used to solve for the tube's temporal extent and to enforce a smooth label sequence through the video. In addition, by taking advantage of recent work on action foreground-background segmentation, we are able to associate each tube with class-specific segmentations. We demonstrate the performance of our algorithm on the challenging LIRIS-HARL dataset and achieve a new state-of-the-art result which is 14.3 times better than previous methods. version:1
arxiv-1707-07210 | Inspiring Computer Vision System Solutions | http://arxiv.org/abs/1707.07210 | id:1707.07210 author:Julian Zilly, Amit Boyarski, Micael Carvalho, Amir Atapour Abarghouei, Konstantinos Amplianitis, Aleksandr Krasnov, Massimiliano Mancini, Hernán Gonzalez, Riccardo Spezialetti, Carlos Sampedro Pérez, Hao Li category:cs.CV cs.CY  published:2017-07-22 summary:The "digital Michelangelo project" was a seminal computer vision project in the early 2000's that pushed the capabilities of acquisition systems and involved multiple people from diverse fields, many of whom are now leaders in industry and academia. Reviewing this project with modern eyes provides us with the opportunity to reflect on several issues, relevant now as then to the field of computer vision and research in general, that go beyond the technical aspects of the work. This article was written in the context of a reading group competition at the week-long International Computer Vision Summer School 2017 (ICVSS) on Sicily, Italy. To deepen the participants understanding of computer vision and to foster a sense of community, various reading groups were tasked to highlight important lessons which may be learned from provided literature, going beyond the contents of the paper. This report is the winning entry of this guided discourse (Fig. 1). The authors closely examined the origins, fruits and most importantly lessons about research in general which may be distilled from the "digital Michelangelo project". Discussions leading to this report were held within the group as well as with Hao Li, the group mentor. version:1
arxiv-1707-07204 | Eyemotion: Classifying facial expressions in VR using eye-tracking cameras | http://arxiv.org/abs/1707.07204 | id:1707.07204 author:Steven Hickson, Nick Dufour, Avneesh Sud, Vivek Kwatra, Irfan Essa category:cs.CV  published:2017-07-22 summary:One of the main challenges of social interaction in virtual reality settings is that head-mounted displays occlude a large portion of the face, blocking facial expressions and thereby restricting social engagement cues among users. Hence, auxiliary means of sensing and conveying these expressions are needed. We present an algorithm to automatically infer expressions by analyzing only a partially occluded face while the user is engaged in a virtual reality experience. Specifically, we show that images of the user's eyes captured from an IR gaze-tracking camera within a VR headset are sufficient to infer a select subset of facial expressions without the use of any fixed external camera. Using these inferences, we can generate dynamic avatars in real-time which function as an expressive surrogate for the user. We propose a novel data collection pipeline as well as a novel approach for increasing CNN accuracy via personalization. Our results show a mean accuracy of 74% ($F1$ of 0.73) among 5 `emotive' expressions and a mean accuracy of 70% ($F1$ of 0.68) among 10 distinct facial action units, outperforming human raters. version:1
arxiv-1707-07196 | Sketched Subspace Clustering | http://arxiv.org/abs/1707.07196 | id:1707.07196 author:Panagiotis A. Traganitis, Georgios B. Giannakis category:stat.ML cs.LG  published:2017-07-22 summary:The immense amount of daily generated and communicated data presents unique challenges in their processing. Clustering, the grouping of data without the presence of ground-truth labels, is an important tool for drawing inferences from data. Subspace clustering (SC) is a relatively recent method that is able to successfully classify nonlinearly separable data in a multitude of settings. In spite of their high clustering accuracy, SC methods incur prohibitively high computational complexity when processing large volumes of high-dimensional data. Inspired by random sketching approaches for dimensionality reduction, the present paper introduces a randomized scheme for SC, termed Sketch-SC, tailored for large volumes of high-dimensional data. Sketch-SC accelerates the computationally heavy parts of state-of-the-art SC approaches by compressing the data matrix across both dimensions using random projections, thus enabling fast and accurate large-scale SC. Performance analysis as well as extensive numerical tests on real data corroborate the potential of Sketch-SC and its competitive performance relative to state-of-the-art scalable SC approaches. version:1
arxiv-1707-07191 | MoodSwipe: A Soft Keyboard that Suggests Messages Based on User-Specified Emotions | http://arxiv.org/abs/1707.07191 | id:1707.07191 author:Chieh-Yang Huang, Tristan Labetoulle, Ting-Hao Kenneth Huang, Yi-Pei Chen, Hung-Chen Chen, Vallari Srivastava, Lun-Wei Ku category:cs.CL cs.HC H.5.2; H.5.3; I.2.7  published:2017-07-22 summary:We present MoodSwipe, a soft keyboard that suggests text messages given the user-specified emotions utilizing the real dialog data. The aim of MoodSwipe is to create a convenient user interface to enjoy the technology of emotion classification and text suggestion, and at the same time to collect labeled data automatically for developing more advanced technologies. While users select the MoodSwipe keyboard, they can type as usual but sense the emotion conveyed by their text and receive suggestions for their message as a benefit. In MoodSwipe, the detected emotions serve as the medium for suggested texts, where viewing the latter is the incentive to correcting the former. We conduct several experiments to show the superiority of the emotion classification models trained on the dialog data, and further to verify good emotion cues are important context for text suggestion. version:1
arxiv-1707-07188 | An Event-based Fast Movement Detection Algorithm for a Positioning Robot Using POWERLINK Communication | http://arxiv.org/abs/1707.07188 | id:1707.07188 author:Juan Barrios-Avilés, Taras Iakymchuk, Jorge Samaniego, Alfredo Rosado-Muñoz category:cs.RO cs.CV  published:2017-07-22 summary:This work develops a tracking system based on an event-based camera. A bioinspired filtering algorithm to reduce noise and transmitted data while keeping the main features at the scene is implemented in FPGA which also serves as a network node. POWERLINK IEEE 61158 industrial network is used to communicate the FPGA with a controller connected to a self-developed two axis servo-controlled robot. The FPGA includes the network protocol to integrate the event-based camera as any other existing network node. The inverse kinematics for the robot is included in the controller. In addition, another network node is used to control pneumatic valves blowing the ball at different speed and trajectories. To complete the system and provide a comparison, a traditional frame-based camera is also connected to the controller. The imaging data for the tracking system are obtained either from the event-based or frame-based camera. Results show that the robot can accurately follow the ball using fast image recognition, with the intrinsic advantages of the event-based system (size, price, power). This works shows how the development of new equipment and algorithms can be efficiently integrated in an industrial system, merging commercial industrial equipment with the new devices so that new technologies can rapidly enter into the industrial field. version:1
arxiv-1707-07184 | A survey of exemplar-based texture synthesis | http://arxiv.org/abs/1707.07184 | id:1707.07184 author:Lara Raad, Axel Davy, Agnès Desolneux, Jean-Michel Morel category:cs.CV  published:2017-07-22 summary:Exemplar-based texture synthesis is the process of generating, from an input sample, new texture images of arbitrary size and which are perceptually equivalent to the sample. The two main approaches are statistics-based methods and patch re-arrangement methods. In the first class, a texture is characterized by a statistical signature, then, a random sampling conditioned to this signature produces genuinely different texture images. The second class boils down to a clever "copy-paste" procedure, which stitches together large regions of the sample. Hybrid methods try to combines ideas from both approaches to avoid their hurdles. Current methods, including the recent CNN approaches, are able to produce impressive synthesis on various kinds of textures. Nevertheless, most real textures are organized at multiple scales, with global structures revealed at coarse scales and highly varying details at finer ones. Thus, when confronted with large natural images of textures the results of state-of-the-art methods degrade rapidly. version:1
arxiv-1707-07182 | Native Language Identification on Text and Speech | http://arxiv.org/abs/1707.07182 | id:1707.07182 author:Marcos Zampieri, Alina Maria Ciobanu, Liviu P. Dinu category:cs.CL  published:2017-07-22 summary:This paper presents an ensemble system combining the output of multiple SVM classifiers to native language identification (NLI). The system was submitted to the NLI Shared Task 2017 fusion track which featured students essays and spoken responses in form of audio transcriptions and iVectors by non-native English speakers of eleven native languages. Our system competed in the challenge under the team name ZCD and was based on an ensemble of SVM classifiers trained on character n-grams achieving 83.58% accuracy and ranking 3rd in the shared task. version:1
arxiv-1707-07180 | Emotion Recognition by Body Movement Representation on the Manifold of Symmetric Positive Definite Matrices | http://arxiv.org/abs/1707.07180 | id:1707.07180 author:Mohamed Daoudi, Stefano Berretti, Pietro Pala, Yvonne Delevoye, Alberto Del Bimbo category:cs.CV  published:2017-07-22 summary:Emotion recognition is attracting great interest for its potential application in a multitude of real-life situations. Much of the Computer Vision research in this field has focused on relating emotions to facial expressions, with investigations rarely including more than upper body. In this work, we propose a new scenario, for which emotional states are related to 3D dynamics of the whole body motion. To address the complexity of human body movement, we used covariance descriptors of the sequence of the 3D skeleton joints, and represented them in the non-linear Riemannian manifold of Symmetric Positive Definite matrices. In doing so, we exploited geodesic distances and geometric means on the manifold to perform emotion classification. Using sequences of spontaneous walking under the five primary emotional states, we report a method that succeeded in classifying the different emotions, with comparable performance to those observed in a human-based force-choice classification task. version:1
arxiv-1704-08795 | Mapping Instructions and Visual Observations to Actions with Reinforcement Learning | http://arxiv.org/abs/1704.08795 | id:1704.08795 author:Dipendra Misra, John Langford, Yoav Artzi category:cs.CL  published:2017-04-28 summary:We propose to directly map raw visual observations and text input to actions for instruction execution. While existing approaches assume access to structured environment representations or use a pipeline of separately trained models, we learn a single model to jointly reason about linguistic and visual input. We use reinforcement learning in a contextual bandit setting to train a neural network agent. To guide the agent's exploration, we use reward shaping with different forms of supervision. Our approach does not require intermediate representations, planning procedures, or training different models. We evaluate in a simulated environment, and show significant improvements over supervised learning and common reinforcement learning variants. version:2
arxiv-1707-07169 | Comparing Apples and Oranges: Off-Road Pedestrian Detection on the NREC Agricultural Person-Detection Dataset | http://arxiv.org/abs/1707.07169 | id:1707.07169 author:Zachary Pezzementi, Trenton Tabor, Peiyun Hu, Jonathan K. Chang, Deva Ramanan, Carl Wellington, Benzun P. Wisely Babu, Herman Herman category:cs.CV  published:2017-07-22 summary:Person detection from vehicles has made rapid progress recently with the advent of multiple highquality datasets of urban and highway driving, yet no large-scale benchmark is available for the same problem in off-road or agricultural environments. Here we present the NREC Agricultural Person-Detection Dataset to spur research in these environments. It consists of labeled stereo video of people in orange and apple orchards taken from two perception platforms (a tractor and a pickup truck), along with vehicle position data from RTK GPS. We define a benchmark on part of the dataset that combines a total of 76k labeled person images and 19k sampled person-free images. The dataset highlights several key challenges of the domain, including varying environment, substantial occlusion by vegetation, people in motion and in non-standard poses, and people seen from a variety of distances; meta-data are included to allow targeted evaluation of each of these effects. Finally, we present baseline detection performance results for three leading approaches from urban pedestrian detection and our own convolutional neural network approach that benefits from the incorporation of additional image context. We show that the success of existing approaches on urban data does not transfer directly to this domain. version:1
arxiv-1707-07167 | Attention-Based End-to-End Speech Recognition in Mandarin | http://arxiv.org/abs/1707.07167 | id:1707.07167 author:Changhao Shan, Junbo Zhang, Yujun Wang, Lei Xie category:cs.CL cs.SD  published:2017-07-22 summary:Recently, there has been an increasing interest in end-to-end speech recognition that directly transcribes speech to text without any predefined alignments. In this paper, we explore the use of attention-based encoder-decoder model for Mandarin speech recognition and to the best of our knowledge, achieve the first promising result. We reduce the source sequence length by skipping frames and regularize the weights for better generalization and convergence. Moreover, we investigate the impact of varying attention mechanism (convolutional attention and attention smoothing) and the correlation between the performance of the model and the width of beam search. On the MiTV dataset, we achieve a character error rate (CER) of 3.58% and a sentence error rate (SER) of 7.43% without using any lexicon or language model. While together with a trigram language model, we reach 2.81% CER and 5.77% SER. version:1
arxiv-1707-07165 | Coarse-to-Fine Lifted MAP Inference in Computer Vision | http://arxiv.org/abs/1707.07165 | id:1707.07165 author:Haroun Habeeb, Ankit Anand, Mausam, Parag Singla category:cs.CV  published:2017-07-22 summary:There is a vast body of theoretical research on lifted inference in probabilistic graphical models (PGMs). However, few demonstrations exist where lifting is applied in conjunction with top of the line applied algorithms. We pursue the applicability of lifted inference for computer vision (CV), with the insight that a globally optimal (MAP) labeling will likely have the same label for two symmetric pixels. The success of our approach lies in efficiently handling a distinct unary potential on every node (pixel), typical of CV applications. This allows us to lift the large class of algorithms that model a CV problem via PGM inference. We propose a generic template for coarse-to-fine (C2F) inference in CV, which progressively refines an initial coarsely lifted PGM for varying quality-time trade-offs. We demonstrate the performance of C2F inference by developing lifted versions of two near state-of-the-art CV algorithms for stereo vision and interactive image segmentation. We find that, against flat algorithms, the lifted versions have a much superior anytime performance, without any loss in final solution quality. version:1
arxiv-1707-07157 | Single-Shot Clothing Category Recognition in Free-Configurations with Application to Autonomous Clothes Sorting | http://arxiv.org/abs/1707.07157 | id:1707.07157 author:Li Sun, Gerardo Aragon-Camarasa, Simon Rogers, Rustam Stolkin, J. Paul Siebert category:cs.RO cs.CV  published:2017-07-22 summary:This paper proposes a single-shot approach for recognising clothing categories from 2.5D features. We propose two visual features, BSP (B-Spline Patch) and TSD (Topology Spatial Distances) for this task. The local BSP features are encoded by LLC (Locality-constrained Linear Coding) and fused with three different global features. Our visual feature is robust to deformable shapes and our approach is able to recognise the category of unknown clothing in unconstrained and random configurations. We integrated the category recognition pipeline with a stereo vision system, clothing instance detection, and dual-arm manipulators to achieve an autonomous sorting system. To verify the performance of our proposed method, we build a high-resolution RGBD clothing dataset of 50 clothing items of 5 categories sampled in random configurations (a total of 2,100 clothing samples). Experimental results show that our approach is able to reach 83.2\% accuracy while classifying clothing items which were previously unseen during training. This advances beyond the previous state-of-the-art by 36.2\%. Finally, we evaluate the proposed approach in an autonomous robot sorting system, in which the robot recognises a clothing item from an unconstrained pile, grasps it, and sorts it into a box according to its category. Our proposed sorting system achieves reasonable sorting success rates with single-shot perception. version:1
arxiv-1707-03124 | Adversarial Generation of Training Examples for Vehicle License Plate Recognition | http://arxiv.org/abs/1707.03124 | id:1707.03124 author:Xinlong Wang, Mingyu You, Chunhua Shen category:cs.CV  published:2017-07-11 summary:Generative Adversarial Networks (GAN) have attracted much research attention recently, leading to impressive results for natural image generation. However, to date little success was observed in using GAN generated images for improving classification tasks. Here we attempt to explore, in the context of car license plate recognition, whether it is possible to generate synthetic training data using GAN to improve recognition accuracy. With a carefully-designed pipeline, we show that the answer is affirmative. First, a large-scale image set is generated using the generator of GAN, without manual annotation. Then, these images are fed to a deep convolutional neural network (DCNN) followed by a bidirectional recurrent neural network (BRNN) with long short-term memory (LSTM), which performs the feature learning and sequence labelling. Finally, the pre-trained model is fine-tuned on real images. Our experimental results on a few data sets demonstrate the effectiveness of using GAN images: an improvement of 7.5% over a strong baseline with moderate-sized real data being available. We show that the proposed framework achieves competitive recognition accuracy on challenging test datasets. We also leverage the depthwise separate convolution to construct a lightweight convolutional RNN, which is about half size and 2x faster on CPU. Combining this framework and the proposed pipeline, we make progress in performing accurate recognition on mobile and embedded devices. version:2
arxiv-1707-07150 | Multi-Oriented Text Detection and Verification in Video Frames and Scene Images | http://arxiv.org/abs/1707.07150 | id:1707.07150 author:Aneeshan Sain, Ayan Kumar Bhunia, Partha Pratim Roy, Umapada Pal category:cs.CV  published:2017-07-22 summary:In this paper, we bring forth a novel approach of video text detection using Fourier-Laplacian filtering in the frequency domain that includes a verification technique using Hidden Markov Model (HMM). The proposed approach deals with the text region appearing not only in horizontal or vertical directions, but also in any other oblique or curved orientation in the image. Until now only a few methods have been proposed that look into curved text detection in video frames, wherein lies our novelty. In our approach, we first apply Fourier-Laplacian transform on the image followed by an ideal Laplacian-Gaussian filtering. Thereafter K-means clustering is employed to obtain the asserted text areas depending on a maximum difference map. Next, the obtained connected components (CC) are skeletonized to distinguish various text strings. Complex components are disintegrated into simpler ones according to a junction removal algorithm followed by a concatenation performed on possible combination of the disjoint skeletons to obtain the corresponding text area. Finally these text hypotheses are verified using HMM-based text/non-text classification system. False positives are thus eliminated giving us a robust text detection performance. We have tested our framework in multi-oriented text lines in four scripts, namely, English, Chinese, Devanagari and Bengali, in video frames and scene texts. The results obtained show that proposed approach surpasses existing methods on text detection. version:1
arxiv-1707-07129 | Predicting the Gender of Indonesian Names | http://arxiv.org/abs/1707.07129 | id:1707.07129 author:Ali Akbar Septiandri category:cs.CL  published:2017-07-22 summary:We present a new way to predict genders from names using character-level Long-Short Term Memory (char-LSTM). We compared our method with some conventional machine learning methods, namely Na\" ive Bayes, logistic regression, and XGBoost with n-grams as the features. We evaluated the models on a dataset consisting of the names of Indonesian people. The results show that we can achieve 92.25% accuracy by using this approach. version:1
arxiv-1707-07128 | Single Image Super-Resolution with Dilated Convolution based Multi-Scale Information Learning Inception Module | http://arxiv.org/abs/1707.07128 | id:1707.07128 author:Wuzhen Shi, Feng Jiang, Debin Zhao category:cs.CV  published:2017-07-22 summary:Traditional works have shown that patches in a natural image tend to redundantly recur many times inside the image, both within the same scale, as well as across different scales. Make full use of these multi-scale information can improve the image restoration performance. However, the current proposed deep learning based restoration methods do not take the multi-scale information into account. In this paper, we propose a dilated convolution based inception module to learn multi-scale information and design a deep network for single image super-resolution. Different dilated convolution learns different scale feature, then the inception module concatenates all these features to fuse multi-scale information. In order to increase the reception field of our network to catch more contextual information, we cascade multiple inception modules to constitute a deep network to conduct single image super-resolution. With the novel dilated convolution based inception module, the proposed end-to-end single image super-resolution network can take advantage of multi-scale information to improve image super-resolution performance. Experimental results show that our proposed method outperforms many state-of-the-art single image super-resolution methods. version:1
arxiv-1707-07124 | A signature-based machine learning model for bipolar disorder and borderline personality disorder | http://arxiv.org/abs/1707.07124 | id:1707.07124 author:Imanol Perez Arribas, Kate Saunders, Guy Goodwin, Terry Lyons category:stat.ML  published:2017-07-22 summary:Mobile technologies offer opportunities for higher resolution monitoring of health conditions. This opportunity seems of particular promise in psychiatry where diagnoses often rely on retrospective and subjective recall of mood states. However, getting actionable information from these rather complex time series is challenging, and at present the implications for clinical care are largely hypothetical. This research demonstrates that, with well chosen cohorts (of bipolar disorder, borderline personality disorder, and control) and modern methods, it is possible to objectively learn to identify distinctive behaviour over short periods (20 reports) that effectively separate the cohorts. Participants with bipolar disorder or borderline personality disorder and healthy volunteers completed daily mood ratings using a bespoke smartphone app for up to a year. A signature-based machine learning model was used to classify participants on the basis of the interrelationship between the different mood items assessed and to predict subsequent mood. The signature methodology was significantly superior to earlier statistical approaches applied to this data in distinguishing the participant three groups, clearly placing 75% into their original groups on the basis of their reports. Subsequent mood ratings were correctly predicted with greater than 70% accuracy in all groups. Prediction of mood was most accurate in healthy volunteers (89-98%) compared to bipolar disorder (82-90%) and borderline personality disorder (70-78%). version:1
arxiv-1707-07119 | Deep Networks for Compressed Image Sensing | http://arxiv.org/abs/1707.07119 | id:1707.07119 author:Wuzhen Shi, Feng Jiang, Shengping Zhang, Debin Zhao category:cs.CV  published:2017-07-22 summary:The compressed sensing (CS) theory has been successfully applied to image compression in the past few years as most image signals are sparse in a certain domain. Several CS reconstruction models have been recently proposed and obtained superior performance. However, there still exist two important challenges within the CS theory. The first one is how to design a sampling mechanism to achieve an optimal sampling efficiency, and the second one is how to perform the reconstruction to get the highest quality to achieve an optimal signal recovery. In this paper, we try to deal with these two problems with a deep network. First of all, we train a sampling matrix via the network training instead of using a traditional manually designed one, which is much appropriate for our deep network based reconstruct process. Then, we propose a deep network to recover the image, which imitates traditional compressed sensing reconstruction processes. Experimental results demonstrate that our deep networks based CS reconstruction method offers a very significant quality improvement compared against state of the art ones. version:1
arxiv-1707-07113 | Adversarial Variational Optimization of Non-Differentiable Simulators | http://arxiv.org/abs/1707.07113 | id:1707.07113 author:Gilles Louppe, Kyle Cranmer category:stat.ML cs.LG  published:2017-07-22 summary:Complex computer simulators are increasingly used across fields of science as generative models tying parameters of an underlying theory to experimental observations. Inference in this setup is often difficult, as simulators rarely admit a tractable density or likelihood function. We introduce Adversarial Variational Optimization (AVO), a likelihood-free inference algorithm for fitting a non-differentiable generative model incorporating ideas from empirical Bayes and variational inference. We adapt the training procedure of generative adversarial networks by replacing the differentiable generative network with a domain-specific simulator. We solve the resulting non-differentiable minimax problem by minimizing variational upper bounds of the two adversarial objectives. Effectively, the procedure results in learning a proposal distribution over simulator parameters, such that the corresponding marginal distribution of the generated data matches the observations. We present results of the method with simulators producing both discrete and continuous data. version:1
arxiv-1707-07103 | PatchShuffle Regularization | http://arxiv.org/abs/1707.07103 | id:1707.07103 author:Guoliang Kang, Xuanyi Dong, Liang Zheng, Yi Yang category:cs.CV  published:2017-07-22 summary:This paper focuses on regularizing the training of the convolutional neural network (CNN). We propose a new regularization approach named ``PatchShuffle`` that can be adopted in any classification-oriented CNN models. It is easy to implement: in each mini-batch, images or feature maps are randomly chosen to undergo a transformation such that pixels within each local patch are shuffled. Through generating images and feature maps with interior orderless patches, PatchShuffle creates rich local variations, reduces the risk of network overfitting, and can be viewed as a beneficial supplement to various kinds of training regularization techniques, such as weight decay, model ensemble and dropout. Experiments on four representative classification datasets show that PatchShuffle improves the generalization ability of CNN especially when the data is scarce. Moreover, we empirically illustrate that CNN models trained with PatchShuffle are more robust to noise and local changes in an image. version:1
arxiv-1707-07102 | OBJ2TEXT: Generating Visually Descriptive Language from Object Layouts | http://arxiv.org/abs/1707.07102 | id:1707.07102 author:Xuwang Yin, Vicente Ordonez category:cs.CV cs.CL  published:2017-07-22 summary:Generating captions for images is a task that has recently received considerable attention. In this work we focus on caption generation for abstract scenes, or object layouts where the only information provided is a set of objects and their locations. We propose OBJ2TEXT, a sequence-to-sequence model that encodes a set of objects and their locations as an input sequence using an LSTM network, and decodes this representation using an LSTM language model. We show that our model, despite encoding object layouts as a sequence, can represent spatial relationships between objects, and generate descriptions that are globally coherent and semantically relevant. We test our approach in a task of object-layout captioning by using only object annotations as inputs. We additionally show that our model, combined with a state-of-the-art object detector, improves an image captioning model from 0.863 to 0.950 (CIDEr score) in the test benchmark of the standard MS-COCO Captioning task. version:1
arxiv-1707-07089 | Joint Dynamic MRI Reconstruction and Aggregated Motion Estimation with Optical Flow Constraint | http://arxiv.org/abs/1707.07089 | id:1707.07089 author:Ningning Zhao, Daniel O'Connor, Dan Ruan, Adrian Basarab, Peng Hu, Ke Sheng category:cs.CV  published:2017-07-22 summary:This paper proposes a novel framework to jointly reconstruct the dynamic magnetic resonance images (DMRI) and estimate the motion vectors from the under-sampled measurements. Due to the inherent motion effects in DMRI acquisition, reconstruction of DMRI using motion estimation/compensation has been studied under a compressed sensing (CS) scheme. In this paper, by embedding the intensity based optical flow (OF) constraint into the traditional CS scheme, we are able to couple the DMRI reconstruction with vector motion estimation. The resulting optimization problem is then solved by a primal-dual algorithm with linesearch due to its efficiency when dealing with non-differentiable problems. Moreover, the proposed framework is capable of handling a wide class of prior information (regularizations) for DMRI reconstruction, such as sparsity, low rank, total variation. In order to reduce the computational cost, the OF constraint is employed in a specific coarse scale. Experiments on various DMRI data, ranging from in vivo lung data to simulated phantom, validate the reconstruction quality improvement using the proposed scheme in comparison to several state-of-the-art algorithms. version:1
arxiv-1707-02931 | Wavelet-based Reflection Symmetry Detection via Textural and Color Histograms | http://arxiv.org/abs/1707.02931 | id:1707.02931 author:Mohamed Elawady, Christophe Ducottet, Olivier Alata, Cecile Barat, Philippe Colantoni category:cs.CV  published:2017-07-10 summary:Symmetry is one of the significant visual properties inside an image plane, to identify the geometrically balanced structures through real-world objects. Existing symmetry detection methods rely on descriptors of the local image features and their neighborhood behavior, resulting incomplete symmetrical axis candidates to discover the mirror similarities on a global scale. In this paper, we propose a new reflection symmetry detection scheme, based on a reliable edge-based feature extraction using Log-Gabor filters, plus an efficient voting scheme parameterized by their corresponding textural and color neighborhood information. Experimental evaluation on four single-case and three multiple-case symmetry detection datasets validates the superior achievement of the proposed work to find global symmetries inside an image. version:4
arxiv-1707-07086 | Identifying civilians killed by police with distantly supervised entity-event extraction | http://arxiv.org/abs/1707.07086 | id:1707.07086 author:Katherine A. Keith, Abram Handler, Michael Pinkham, Cara Magliozzi, Joshua McDuffie, Brendan O'Connor category:cs.CL I.2.7  published:2017-07-22 summary:We propose a new, socially-impactful task for natural language processing: from a news corpus, extract names of persons who have been killed by police. We present a newly collected police fatality corpus, which we release publicly, and present a model to solve this problem that uses EM-based distant supervision with logistic regression and convolutional neural network classifiers. Our model outperforms two off-the-shelf event extractor systems, and it can suggest candidate victim names in some cases faster than one of the major manually-collected police fatality databases. version:1
arxiv-1707-07075 | Automatic Curation of Golf Highlights using Multimodal Excitement Features | http://arxiv.org/abs/1707.07075 | id:1707.07075 author:Michele Merler, Dhiraj Joshi, Quoc-Bao Nguyen, Stephen Hammer, John Kent, John R. Smith, Rogerio S. Feris category:cs.CV cs.MM  published:2017-07-22 summary:The production of sports highlight packages summarizing a game's most exciting moments is an essential task for broadcast media. Yet, it requires labor-intensive video editing. We propose a novel approach for auto-curating sports highlights, and use it to create a real-world system for the editorial aid of golf highlight reels. Our method fuses information from the players' reactions (action recognition such as high-fives and fist pumps), spectators (crowd cheering), and commentator (tone of the voice and word analysis) to determine the most interesting moments of a game. We accurately identify the start and end frames of key shot highlights with additional metadata, such as the player's name and the hole number, allowing personalized content summarization and retrieval. In addition, we introduce new techniques for learning our classifiers with reduced manual training data annotation by exploiting the correlation of different modalities. Our work has been demonstrated at a major golf tournament, successfully extracting highlights from live video streams over four consecutive days. version:1
arxiv-1707-07074 | What-and-Where to Match: Deep Spatially Multiplicative Integration Networks for Person Re-identification | http://arxiv.org/abs/1707.07074 | id:1707.07074 author:Lin Wu, Yang Wang, Xue Li, Junbin Gao category:cs.CV  published:2017-07-21 summary:Matching pedestrians across disjoint camera views, known as person re-identification (re-id), is a challenging problem that is of importance to visual recognition and surveillance. Most existing methods exploit local regions within spatial manipulation to perform matching in local correspondence. However, they essentially extract \emph{fixed} representations from pre-divided regions for each image and perform matching based on the extracted representation subsequently. For models in this pipeline, local finer patterns that are crucial to distinguish positive pairs from negative ones cannot be captured, and thus making them underperformed. In this paper, we propose a novel deep multiplicative integration gating function, which answers the question of \emph{what-and-where to match} for effective person re-id. To address \emph{what} to match, our deep network emphasizes common local patterns by learning joint representations in a multiplicative way. The network comprises two Convolutional Neural Networks (CNNs) to extract convolutional activations, and generates relevant descriptors for pedestrian matching. This thus, leads to flexible representations for pair-wise images. To address \emph{where} to match, we combat the spatial misalignment by performing spatially recurrent pooling via a four-directional recurrent neural network to impose spatial dependency over all positions with respect to the entire image. The proposed network is designed to be end-to-end trainable to characterize local pairwise feature interactions in a spatially aligned manner. To demonstrate the superiority of our method, extensive experiments are conducted over three benchmark data sets: VIPeR, CUHK03 and Market-1501. version:1
arxiv-1704-04920 | Deep Joint Entity Disambiguation with Local Neural Attention | http://arxiv.org/abs/1704.04920 | id:1704.04920 author:Octavian-Eugen Ganea, Thomas Hofmann category:cs.CL  published:2017-04-17 summary:We propose a novel deep learning model for joint document-level entity disambiguation, which leverages learned neural representations. Key components are entity embeddings, a neural attention mechanism over local context windows, and a differentiable joint inference stage for disambiguation. Our approach thereby combines benefits of deep learning with more traditional approaches such as graphical models and probabilistic mention-entity maps. Extensive experiments show that we are able to obtain competitive or state-of-the-art accuracy at moderate computational costs. version:2
arxiv-1704-03940 | PACRR: A Position-Aware Neural IR Model for Relevance Matching | http://arxiv.org/abs/1704.03940 | id:1704.03940 author:Kai Hui, Andrew Yates, Klaus Berberich, Gerard de Melo category:cs.IR cs.CL  published:2017-04-12 summary:In order to adopt deep learning for information retrieval, models are needed that can capture all relevant information required to assess the relevance of a document to a given user query. While previous works have successfully captured unigram term matches, how to fully employ position-dependent information such as proximity and term dependencies has been insufficiently explored. In this work, we propose a novel neural IR model named PACRR aiming at better modeling position-dependent interactions between a query and a document. Extensive experiments on six years' TREC Web Track data confirm that the proposed model yields better results under multiple benchmarks. version:3
arxiv-1707-07062 | A Pilot Study of Domain Adaptation Effect for Neural Abstractive Summarization | http://arxiv.org/abs/1707.07062 | id:1707.07062 author:Xinyu Hua, Lu Wang category:cs.CL  published:2017-07-21 summary:We study the problem of domain adaptation for neural abstractive summarization. We make initial efforts in investigating what information can be transferred to a new domain. Experimental results on news stories and opinion articles indicate that neural summarization model benefits from pre-training based on extractive summaries. We also find that the combination of in-domain and out-of-domain setup yields better summaries when in-domain data is insufficient. Further analysis shows that, the model is capable to select salient content even trained on out-of-domain data, but requires in-domain data to capture the style for a target domain. version:1
arxiv-1707-08169 | A Data-Driven Approach to Pre-Operative Evaluation of Lung Cancer Patients | http://arxiv.org/abs/1707.08169 | id:1707.08169 author:Oleksiy Budilovsky, Golnaz Alipour, Andre Knoesen, Lisa Brown, Soheil Ghiasi category:cs.CY cs.NE  published:2017-07-21 summary:Lung cancer is the number one cause of cancer deaths. Many early stage lung cancer patients have resectable tumors; however, their cardiopulmonary function needs to be properly evaluated before they are deemed operative candidates. Consequently, a subset of such patients is asked to undergo standard pulmonary function tests, such as cardiopulmonary exercise tests (CPET) or stair climbs, to have their pulmonary function evaluated. The standard tests are expensive, labor intensive, and sometimes ineffective due to co-morbidities, such as limited mobility. Recovering patients would benefit greatly from a device that can be worn at home, is simple to use, and is relatively inexpensive. Using advances in information technology, the goal is to design a continuous, inexpensive, mobile and patient-centric mechanism for evaluation of a patient's pulmonary function. A light mobile mask is designed, fitted with CO2, O2, flow volume, and accelerometer sensors and tested on 18 subjects performing 15 minute exercises. The data collected from the device is stored in a cloud service and machine learning algorithms are used to train and predict a user's activity .Several classification techniques are compared - K Nearest Neighbor, Random Forest, Support Vector Machine, Artificial Neural Network, and Naive Bayes. One useful area of interest involves comparing a patient's predicted activity levels, especially using only breath data, to that of a normal person's, using the classification models. version:1
arxiv-1706-07515 | Comparing Neural and Attractiveness-based Visual Features for Artwork Recommendation | http://arxiv.org/abs/1706.07515 | id:1706.07515 author:Vicente Dominguez, Pablo Messina, Denis Parra, Domingo Mery, Christoph Trattner, Alvaro Soto category:cs.IR cs.AI cs.CV cs.DL  published:2017-06-22 summary:Advances in image processing and computer vision in the latest years have brought about the use of visual features in artwork recommendation. Recent works have shown that visual features obtained from pre-trained deep neural networks (DNNs) perform very well for recommending digital art. Other recent works have shown that explicit visual features (EVF) based on attractiveness can perform well in preference prediction tasks, but no previous work has compared DNN features versus specific attractiveness-based visual features (e.g. brightness, texture) in terms of recommendation performance. In this work, we study and compare the performance of DNN and EVF features for the purpose of physical artwork recommendation using transactional data from UGallery, an online store of physical paintings. In addition, we perform an exploratory analysis to understand if DNN embedded features have some relation with certain EVF. Our results show that DNN features outperform EVF, that certain EVF features are more suited for physical artwork recommendation and, finally, we show evidence that certain neurons in the DNN might be partially encoding visual features such as brightness, providing an opportunity for explaining recommendations based on visual neural models. version:2
arxiv-1705-00403 | Dependency Parsing with Dilated Iterated Graph CNNs | http://arxiv.org/abs/1705.00403 | id:1705.00403 author:Emma Strubell, Andrew McCallum category:cs.CL  published:2017-05-01 summary:Dependency parses are an effective way to inject linguistic knowledge into many downstream tasks, and many practitioners wish to efficiently parse sentences at scale. Recent advances in GPU hardware have enabled neural networks to achieve significant gains over the previous best models, these models still fail to leverage GPUs' capability for massive parallelism due to their requirement of sequential processing of the sentence. In response, we propose Dilated Iterated Graph Convolutional Neural Networks (DIG-CNNs) for graph-based dependency parsing, a graph convolutional architecture that allows for efficient end-to-end GPU parsing. In experiments on the English Penn TreeBank benchmark, we show that DIG-CNNs perform on par with some of the best neural network parsers. version:2
arxiv-1707-06005 | Detecting Parts for Action Localization | http://arxiv.org/abs/1707.06005 | id:1707.06005 author:Nicolas Chesneau, Grégory Rogez, Karteek Alahari, Cordelia Schmid category:cs.CV  published:2017-07-19 summary:In this paper, we propose a new framework for action localization that tracks people in videos and extracts full-body human tubes, i.e., spatio-temporal regions localizing actions, even in the case of occlusions or truncations. This is achieved by training a novel human part detector that scores visible parts while regressing full-body bounding boxes. The core of our method is a convolutional neural network which learns part proposals specific to certain body parts. These are then combined to detect people robustly in each frame. Our tracking algorithm connects the image detections temporally to extract full-body human tubes. We apply our new tube extraction method on the problem of human action localization, on the popular JHMDB dataset, and a very recent challenging dataset DALY (Daily Action Localization in YouTube), showing state-of-the-art results. version:2
arxiv-1707-07048 | Progressive Joint Modeling in Unsupervised Single-channel Overlapped Speech Recognition | http://arxiv.org/abs/1707.07048 | id:1707.07048 author:Zhehuai Chen, Jasha Droppo, Jinyu Li, Wayne Xiong category:cs.CL cs.AI 68T10 I.2.7  published:2017-07-21 summary:Unsupervised single-channel overlapped speech recognition is one of the hardest problems in automatic speech recognition (ASR). Permutation invariant training (PIT) is a state of the art model-based approach, which applies a single neural network to solve this single-input, multiple-output modeling problem. We propose to advance the current state of the art by imposing a modular structure on the neural network, applying a progressive pretraining regimen, and improving the objective function with transfer learning and a discriminative training criterion. The modular structure splits the problem into three sub-tasks: frame-wise interpreting, utterance-level speaker tracing, and speech recognition. The pretraining regimen uses these modules to solve progressively harder tasks. Transfer learning leverages parallel clean speech to improve the training targets for the network. Our discriminative training formulation is a modification of standard formulations, that also penalizes competing outputs of the system. Experiments are conducted on the artificial overlapped Switchboard and hub5e-swb dataset. The proposed framework achieves over 30% relative improvement of WER over both a strong jointly trained system, PIT for ASR, and a separately optimized system, PIT for speech separation with clean speech ASR model. The improvement comes from better model generalization, training efficiency and the sequence level linguistic knowledge integration. version:1
arxiv-1707-07045 | End-to-end Neural Coreference Resolution | http://arxiv.org/abs/1707.07045 | id:1707.07045 author:Kenton Lee, Luheng He, Mike Lewis, Luke Zettlemoyer category:cs.CL  published:2017-07-21 summary:We introduce the first end-to-end coreference resolution model and show that it significantly outperforms all previous work without using a syntactic parser or hand-engineered mention detector. The key idea is to directly consider all spans in a document as potential mentions and learn distributions over possible antecedents for each. The model computes span embeddings that combine context-dependent boundary representations with a head-finding attention mechanism. It is trained to maximize the marginal likelihood of gold antecedent spans from coreference clusters and is factored to enable aggressive pruning of potential mentions. Experiments demonstrate state-of-the-art performance, with a gain of 1.5 F1 on the OntoNotes benchmark and by 3.1 F1 using a 5-model ensemble, despite the fact that this is the first approach to be successfully trained with no external resources. version:1
arxiv-1707-06375 | 3D Shape Reconstruction from Sketches via Multi-view Convolutional Networks | http://arxiv.org/abs/1707.06375 | id:1707.06375 author:Zhaoliang Lun, Matheus Gadelha, Evangelos Kalogerakis, Subhransu Maji, Rui Wang category:cs.CV cs.GR  published:2017-07-20 summary:We propose a method for reconstructing 3D shapes from 2D sketches in the form of line drawings. Our method takes as input a single sketch, or multiple sketches, and outputs a dense point cloud representing a 3D reconstruction of the input sketch(es). The point cloud is then converted into a polygon mesh. At the heart of our method lies a deep, encoder-decoder network. The encoder converts the sketch into a compact representation encoding shape information. The decoder converts this representation into depth and normal maps capturing the underlying surface from several output viewpoints. The multi-view maps are then consolidated into a 3D point cloud by solving an optimization problem that fuses depth and normals across all viewpoints. Based on our experiments, compared to other methods, such as volumetric networks, our architecture offers several advantages, including more faithful reconstruction, higher output surface resolution, better preservation of topology and shape structure. version:2
arxiv-1707-07013 | Confidence estimation in Deep Neural networks via density modelling | http://arxiv.org/abs/1707.07013 | id:1707.07013 author:Akshayvarun Subramanya, Suraj Srinivas, R. Venkatesh Babu category:cs.CV  published:2017-07-21 summary:State-of-the-art Deep Neural Networks can be easily fooled into providing incorrect high-confidence predictions for images with small amounts of adversarial noise. Does this expose a flaw with deep neural networks, or do we simply need a better way to estimate confidence? In this paper we consider the problem of accurately estimating predictive confidence. We formulate this problem as that of density modelling, and show how traditional methods such as softmax produce poor estimates. To address this issue, we propose a novel confidence measure based on density modelling approaches. We test these measures on images distorted by blur, JPEG compression, random noise and adversarial noise. Experiments show that our confidence measure consistently shows reduced confidence scores in the presence of such distortions - a property which softmax often lacks. version:1
arxiv-1707-07012 | Learning Transferable Architectures for Scalable Image Recognition | http://arxiv.org/abs/1707.07012 | id:1707.07012 author:Barret Zoph, Vijay Vasudevan, Jonathon Shlens, Quoc V. Le category:cs.CV  published:2017-07-21 summary:Developing state-of-the-art image classification models often requires significant architecture engineering and tuning. In this paper, we attempt to reduce the amount of architecture engineering by using Neural Architecture Search to learn an architectural building block on a small dataset that can be transferred to a large dataset. This approach is similar to learning the structure of a recurrent cell within a recurrent network. In our experiments, we search for the best convolutional cell on the CIFAR-10 dataset and then apply this learned cell to the ImageNet dataset by stacking together more of this cell. Although the cell is not learned directly on ImageNet, an architecture constructed from the best learned cell achieves state-of-the-art accuracy of 82.3% top-1 and 96.0% top-5 on ImageNet, which is 0.8% better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS. This cell can also be scaled down two orders of magnitude: a smaller network constructed from the best cell also achieves 74% top-1 accuracy, which is 3.1% better than the equivalently-sized, state-of-the-art models for mobile platforms. version:1
arxiv-1707-06992 | Ideological Sublations: Resolution of Dialectic in Population-based Optimization | http://arxiv.org/abs/1707.06992 | id:1707.06992 author:S. Hossein Hosseini, Afshin Ebrahimi category:cs.LG cs.AI cs.CC cs.NE  published:2017-07-21 summary:We propose a population-based optimization algorithm inspired by two main thinking modes in philosophy. Particles are regarded as thinkers and their locations are interpreted as the theses. Both thinking modes are based on the concept of dialectic and thesis-antithesis paradigm. Idealistic and materialistic antitheses are formulated as optimization models. Based on the models, the population is coordinated for dialectical interactions. At the population-based context, the formulated optimization models are reduced to simple detection problems. According to the assigned thinking mode to each thinker, dialectic quantities of each thinker with two other specified thinkers are measured. One of them at maximum dialectic is selected and its position is called the available antithesis for the considered thesis. Thesis-antithesis interactions are defined by meaningful distribution of the step-sizes for each thinking mode. In fact, the thinking modes are regarded as exploration and exploitation elements of the proposed algorithm. The result is a delicate balance between the thinkers without any requirement for adjustment of the step-size coefficients. Main parameter of the proposed algorithm is the number of particles appointed to each thinking modes. An additional integer parameter is defined to boost the stability of the final algorithm in facing with some specific problems. The proposed algorithm is evaluated on different problems. First, a testbed of 12 single objective continuous functions in low and high dimensions is considered. Then, proposed algorithm is tested for sparse reconstruction problem in the context of compressed sensing. The results indicate efficiency and in some cases superiority of performance of the proposed algorithm in comparison with a variety of well-known algorithms. Low runtime is another remarkable advantage of the proposed algorithm. version:1
arxiv-1707-06990 | Memory-Efficient Implementation of DenseNets | http://arxiv.org/abs/1707.06990 | id:1707.06990 author:Geoff Pleiss, Danlu Chen, Gao Huang, Tongcheng Li, Laurens van der Maaten, Kilian Q. Weinberger category:cs.CV  published:2017-07-21 summary:The DenseNet architecture is highly computationally efficient as a result of feature reuse. However, a naive DenseNet implementation can require a significant amount of GPU memory: If not properly managed, pre-activation batch normalization and contiguous convolution operations can produce feature maps that grow quadratically with network depth. In this technical report, we introduce strategies to reduce the memory consumption of DenseNets during training. By strategically using shared memory allocations, we reduce the memory cost for storing feature maps from quadratic to linear. Without the GPU memory bottleneck, it is now possible to train extremely deep DenseNets. Networks with 14M parameters can be trained on a single GPU, up from 4M. A 264-layer DenseNet (73M parameters), which previously would have been infeasible to train, can now be trained on a single workstation with 8 NVIDIA Tesla M40 GPUs. On the ImageNet ILSVRC classification dataset, this large DenseNet obtains a state-of-the-art single-crop top-1 error of 20.26%. version:1
arxiv-1705-01968 | A Workflow for Visual Diagnostics of Binary Classifiers using Instance-Level Explanations | http://arxiv.org/abs/1705.01968 | id:1705.01968 author:Josua Krause, Aritra Dasgupta, Jordan Swartz, Yindalon Aphinyanaphongs, Enrico Bertini category:stat.ML cs.AI  published:2017-05-04 summary:Human-in-the-loop data analysis applications necessitate greater transparency in machine learning models for experts to understand and trust their decisions. To this end, we propose a visual analytics workflow to help data scientists and domain experts explore, diagnose, and understand the decisions made by a binary classifier. The approach leverages "instance-level explanations", measures of local feature relevance that explain single instances, and uses them to build a set of visual representations that guide the users in their investigation. The workflow is based on three main visual representations and steps: one based on aggregate statistics to see how data distributes across correct / incorrect decisions; one based on explanations to understand which features are used to make these decisions; and one based on raw data, to derive insights on potential root causes for the observed patterns. The workflow is derived from a long-term collaboration with a group of machine learning and healthcare professionals who used our method to make sense of machine learning models they developed. The case study from this collaboration demonstrates that the proposed workflow helps experts derive useful knowledge about the model and the phenomena it describes, thus experts can generate useful hypotheses on how a model can be improved. version:2
arxiv-1707-06982 | Persistent-homology-based gait recognition | http://arxiv.org/abs/1707.06982 | id:1707.06982 author:J. Lamar-Leon, Raul Alonso-Baryolo, Edel Garcia-Reyes, R. Gonzalez-Diaz category:cs.CV  published:2017-07-21 summary:Gait recognition is an important biometric technique for video surveillance tasks, due to the advantage of using it at distance. In this paper, we present a persistent homology-based method to extract topological features (the so-called {\it topological gait signature}) from the the body silhouettes of a gait sequence. % It has been used before in several conference papers of the same authors for human identification, gender classification, carried object detection and monitoring human activities at distance. % The novelty of this paper is the study of the stability of the topological gait signature under small perturbations and the number of gait cycles contained in a gait sequence. In other words, we show that the topological gait signature is robust to the presence of noise in the body silhouettes and to the number of gait cycles contained in a given gait sequence. % We also show that computing our topological gait signature of only the lowest fourth part of the body silhouette, we avoid the upper body movements that are unrelated to the natural dynamic of the gait, caused for example by carrying a bag or wearing a coat. version:1
arxiv-1707-06978 | A Multi-Scale CNN and Curriculum Learning Strategy for Mammogram Classification | http://arxiv.org/abs/1707.06978 | id:1707.06978 author:William Lotter, Greg Sorensen, David Cox category:cs.CV  published:2017-07-21 summary:Screening mammography is an important front-line tool for the early detection of breast cancer, and some 39 million exams are conducted each year in the United States alone. Here, we describe a multi-scale convolutional neural network (CNN) trained with a curriculum learning strategy that achieves high levels of accuracy in classifying mammograms. Specifically, we first train CNN-based patch classifiers on segmentation masks of lesions in mammograms, and then use the learned features to initialize a scanning-based model that renders a decision on the whole image, trained end-to-end on outcome data. We demonstrate that our approach effectively handles the "needle in a haystack" nature of full-image mammogram classification, achieving 0.92 AUROC on the DDSM dataset. version:1
arxiv-1707-06971 | Split and Rephrase | http://arxiv.org/abs/1707.06971 | id:1707.06971 author:Shashi Narayan, Claire Gardent, Shay B. Cohen, Anastasia Shimorina category:cs.CL  published:2017-07-21 summary:We propose a new sentence simplification task (Split-and-Rephrase) where the aim is to split a complex sentence into a meaning preserving sequence of shorter sentences. Like sentence simplification, splitting-and-rephrasing has the potential of benefiting both natural language processing and societal applications. Because shorter sentences are generally better processed by NLP systems, it could be used as a preprocessing step which facilitates and improves the performance of parsers, semantic role labellers and machine translation systems. It should also be of use for people with reading disabilities because it allows the conversion of longer sentences into shorter ones. This paper makes two contributions towards this new task. First, we create and make available a benchmark consisting of 1,066,115 tuples mapping a single complex sentence to a sequence of sentences expressing the same meaning. Second, we propose five models (vanilla sequence-to-sequence to semantically-motivated models) to understand the difficulty of the proposed task. version:1
arxiv-1707-06962 | Dictionary Learning and Sparse Coding-based Denoising for High-Resolution Task Functional Connectivity MRI Analysis | http://arxiv.org/abs/1707.06962 | id:1707.06962 author:Seongah Jeong, Xiang Li, Jiarui Yang, Quanzheng Li, Vahid Tarokh category:cs.LG stat.ML  published:2017-07-21 summary:We propose a novel denoising framework for task functional Magnetic Resonance Imaging (tfMRI) data to delineate the high-resolution spatial pattern of the brain functional connectivity via dictionary learning and sparse coding (DLSC). In order to address the limitations of the unsupervised DLSC-based fMRI studies, we utilize the prior knowledge of task paradigm in the learning step to train a data-driven dictionary and to model the sparse representation. We apply the proposed DLSC-based method to Human Connectome Project (HCP) motor tfMRI dataset. Studies on the functional connectivity of cerebrocerebellar circuits in somatomotor networks show that the DLSC-based denoising framework can significantly improve the prominent connectivity patterns, in comparison to the temporal non-local means (tNLM)-based denoising method as well as the case without denoising, which is consistent and neuroscientifically meaningful within motor area. The promising results show that the proposed method can provide an important foundation for the high-resolution functional connectivity analysis, and provide a better approach for fMRI preprocessing. version:1
arxiv-1707-06961 | Mimicking Word Embeddings using Subword RNNs | http://arxiv.org/abs/1707.06961 | id:1707.06961 author:Yuval Pinter, Robert Guthrie, Jacob Eisenstein category:cs.CL  published:2017-07-21 summary:Word embeddings improve generalization over lexical features by placing each word in a lower-dimensional space, using distributional information obtained from unlabeled data. However, the effectiveness of word embeddings for downstream NLP tasks is limited by out-of-vocabulary (OOV) words, for which embeddings do not exist. In this paper, we present MIMICK, an approach to generating OOV word embeddings compositionally, by learning a function from spellings to distributional embeddings. Unlike prior work, MIMICK does not require re-training on the original word embedding corpus; instead, learning is performed at the type level. Intrinsic and extrinsic evaluations demonstrate the power of this simple approach. On 23 languages, MIMICK improves performance over a word-based baseline for tagging part-of-speech and morphosyntactic attributes. It is competitive with (and complementary to) a supervised character-based model in low-resource settings. version:1
arxiv-1707-06957 | Reconstruction of Word Embeddings from Sub-Word Parameters | http://arxiv.org/abs/1707.06957 | id:1707.06957 author:Karl Stratos category:cs.CL  published:2017-07-21 summary:Pre-trained word embeddings improve the performance of a neural model at the cost of increasing the model size. We propose to benefit from this resource without paying the cost by operating strictly at the sub-lexical level. Our approach is quite simple: before task-specific training, we first optimize sub-word parameters to reconstruct pre-trained word embeddings using various distance measures. We report interesting results on a variety of tasks: word similarity, word analogy, and part-of-speech tagging. version:1
arxiv-1707-06341 | A Sub-Character Architecture for Korean Language Processing | http://arxiv.org/abs/1707.06341 | id:1707.06341 author:Karl Stratos category:cs.CL  published:2017-07-20 summary:We introduce a novel sub-character architecture that exploits a unique compositional structure of the Korean language. Our method decomposes each character into a small set of primitive phonetic units called jamo letters from which character- and word-level representations are induced. The jamo letters divulge syntactic and semantic information that is difficult to access with conventional character-level units. They greatly alleviate the data sparsity problem, reducing the observation space to 1.6% of the original while increasing accuracy in our experiments. We apply our architecture to dependency parsing and achieve dramatic improvement over strong lexical baselines. version:2
arxiv-1707-06945 | Cross-Lingual Induction and Transfer of Verb Classes Based on Word Vector Space Specialisation | http://arxiv.org/abs/1707.06945 | id:1707.06945 author:Ivan Vulić, Nikola Mrkšić, Anna Korhonen category:cs.CL  published:2017-07-21 summary:Existing approaches to automatic VerbNet-style verb classification are heavily dependent on feature engineering and therefore limited to languages with mature NLP pipelines. In this work, we propose a novel cross-lingual transfer method for inducing VerbNets for multiple languages. To the best of our knowledge, this is the first study which demonstrates how the architectures for learning word embeddings can be applied to this challenging syntactic-semantic task. Our method uses cross-lingual translation pairs to tie each of the six target languages into a bilingual vector space with English, jointly specialising the representations to encode the relational information from English VerbNet. A standard clustering algorithm is then run on top of the VerbNet-specialised representations, using vector dimensions as features for learning verb classes. Our results show that the proposed cross-lingual transfer approach sets new state-of-the-art verb classification performance across all six target languages explored in this work. version:1
arxiv-1707-06939 | Autocompletion interfaces make crowd workers slower, but their use promotes response diversity | http://arxiv.org/abs/1707.06939 | id:1707.06939 author:Xipei Liu, James P. Bagrow category:cs.HC cs.CL cs.CY cs.IR  published:2017-07-21 summary:Creative tasks such as ideation or question proposal are powerful applications of crowdsourcing, yet the quantity of workers available for addressing practical problems is often insufficient. To enable scalable crowdsourcing thus requires gaining all possible efficiency and information from available workers. One option for text-focused tasks is to allow assistive technology, such as an autocompletion user interface (AUI), to help workers input text responses. But support for the efficacy of AUIs is mixed. Here we designed and conducted a randomized experiment where workers were asked to provide short text responses to given questions. Our experimental goal was to determine if an AUI helps workers respond more quickly and with improved consistency by mitigating typos and misspellings. Surprisingly, we found that neither occurred: workers assigned to the AUI treatment were slower than those assigned to the non-AUI control and their responses were more diverse, not less, than those of the control. Both the lexical and semantic diversities of responses were higher, with the latter measured using word2vec. A crowdsourcer interested in worker speed may want to avoid using an AUI, but using an AUI to boost response diversity may be valuable to crowdsourcers interested in receiving as much novel information from workers as possible. version:1
arxiv-1707-06932 | A study on text-score disagreement in online reviews | http://arxiv.org/abs/1707.06932 | id:1707.06932 author:Michela Fazzolari, Vittoria Cozza, Marinella Petrocchi, Angelo Spognardi category:cs.CL cs.IR cs.SI  published:2017-07-21 summary:In this paper, we focus on online reviews and employ artificial intelligence tools, taken from the cognitive computing field, to help understanding the relationships between the textual part of the review and the assigned numerical score. We move from the intuitions that 1) a set of textual reviews expressing different sentiments may feature the same score (and vice-versa); and 2) detecting and analyzing the mismatches between the review content and the actual score may benefit both service providers and consumers, by highlighting specific factors of satisfaction (and dissatisfaction) in texts. To prove the intuitions, we adopt sentiment analysis techniques and we concentrate on hotel reviews, to find polarity mismatches therein. In particular, we first train a text classifier with a set of annotated hotel reviews, taken from the Booking website. Then, we analyze a large dataset, with around 160k hotel reviews collected from Tripadvisor, with the aim of detecting a polarity mismatch, indicating if the textual content of the review is in line, or not, with the associated score. Using well established artificial intelligence techniques and analyzing in depth the reviews featuring a mismatch between the text polarity and the score, we find that -on a scale of five stars- those reviews ranked with middle scores include a mixture of positive and negative aspects. The approach proposed here, beside acting as a polarity detector, provides an effective selection of reviews -on an initial very large dataset- that may allow both consumers and providers to focus directly on the review subset featuring a text/score disagreement, which conveniently convey to the user a summary of positive and negative features of the review target. version:1
arxiv-1707-06923 | Pillar Networks for action recognition | http://arxiv.org/abs/1707.06923 | id:1707.06923 author:Biswa Sengupta, Yu Qian category:cs.CV stat.ML  published:2017-07-21 summary:Image understanding using deep convolutional network has reached human-level performance, yet a closely related problem of video understanding especially, action recognition has not reached the requisite level of maturity. We combine multi-kernels based support-vector-machines (SVM) with a multi-stream deep convolutional neural network to achieve close to state-of-the-art performance on a 51-class activity recognition problem (HMDB-51 dataset); this specific dataset has proved to be particularly challenging for deep neural networks due to the heterogeneity in camera viewpoints, video quality, etc. The resulting architecture is named pillar networks as each (very) deep neural network acts as a pillar for the hierarchical classifiers. version:1
arxiv-1707-06997 | Machine Learning for Structured Clinical Data | http://arxiv.org/abs/1707.06997 | id:1707.06997 author:Brett K. Beaulieu-Jones category:cs.LG  published:2017-07-21 summary:Research is a tertiary priority in the EHR, where the priorities are patient care and billing. Because of this, the data is not standardized or formatted in a manner easily adapted to machine learning approaches. Data may be missing for a large variety of reasons ranging from individual input styles to differences in clinical decision making, for example, which lab tests to issue. Few patients are annotated at a research quality, limiting sample size and presenting a moving gold standard. Patient progression over time is key to understanding many diseases but many machine learning algorithms require a snapshot, at a single time point, to create a usable vector form. Furthermore, algorithms that produce black box results do not provide the interpretability required for clinical adoption. This chapter discusses these challenges and others in applying machine learning techniques to the structured EHR (i.e. Patient Demographics, Family History, Medication Information, Vital Signs, Laboratory Tests, Genetic Testing). It does not cover feature extraction from additional sources such as imaging data or free text patient notes but the approaches discussed can include features extracted from these sources. version:1
arxiv-1704-05761 | Maximum Likelihood Estimation based on Random Subspace EDA: Application to Extrasolar Planet Detection | http://arxiv.org/abs/1704.05761 | id:1704.05761 author:Bin Liu, Ke-Jia Chen category:stat.ME astro-ph.IM cs.LG cs.NE  published:2017-04-18 summary:This paper addresses maximum likelihood (ML) estimation based model fitting in the context of extrasolar planet detection. This problem is featured by the following properties: 1) the candidate models under consideration are highly nonlinear; 2) the likelihood surface has a huge number of peaks; 3) the parameter space ranges in size from a few to dozens of dimensions. These properties make the ML search a very challenging problem, as it lacks any analytical or gradient based searching solution to explore the parameter space. A population based searching method, called estimation of distribution algorithm (EDA), is adopted to explore the model parameter space starting from a batch of random locations. EDA is featured by its ability to reveal and utilize problem structures. This property is desirable for characterizing the detections. However, it is well recognized that EDAs can not scale well to large scale problems, as it consists of iterative random sampling and model fitting procedures, which results in the well-known dilemma curse of dimensionality. A novel mechanism to perform EDAs in interactive random subspaces spanned by correlated variables is proposed and the hope is to alleviate the curse of dimensionality for EDAs by performing the operations of sampling and model fitting in lower dimensional subspaces. The effectiveness of the proposed algorithm is verified via both benchmark numerical studies and real data analysis. version:2
arxiv-1707-06907 | What Looks Good with my Sofa: Multimodal Search Engine for Interior Design | http://arxiv.org/abs/1707.06907 | id:1707.06907 author:Ivona Tautkute, Aleksandra Możejko, Wojciech Stokowiec, Tomasz Trzciński, Łukasz Brocki, Krzysztof Marasek category:cs.CV  published:2017-07-21 summary:In this paper, we propose a multi-modal search engine for interior design that combines visual and textual queries. The goal of our engine is to retrieve interior objects, e.g. furniture or wall clocks, that share visual and aesthetic similarities with the query. Our search engine allows the user to take a photo of a room and retrieve with a high recall a list of items identical or visually similar to those present in the photo. Additionally, it allows to return other items that aesthetically and stylistically fit well together. To achieve this goal, our system blends the results obtained using textual and visual modalities. Thanks to this blending strategy, we increase the average style similarity score of the retrieved items by 11%. Our work is implemented as a Web-based application and it is planned to be opened to the public. version:1
arxiv-1707-01378 | An Attention Mechanism for Answer Selection Using a Combined Global and Local View | http://arxiv.org/abs/1707.01378 | id:1707.01378 author:Yoram Bachrach, Andrej Zukov-Gregoric, Sam Coope, Ed Tovell, Bogdan Maksak, Jose Rodriguez, Conan McMurtie category:cs.CL 68T50 I.2.7; I.2.6  published:2017-07-05 summary:We propose a new attention mechanism for neural based question answering, which depends on varying granularities of the input. Previous work focused on augmenting recurrent neural networks with simple attention mechanisms which are a function of the similarity between a question embedding and an answer embeddings across time. We extend this by making the attention mechanism dependent on a global embedding of the answer attained using a separate network. We evaluate our system on InsuranceQA, a large question answering dataset. Our model outperforms current state-of-the-art results on InsuranceQA. Further, we visualize which sections of text our attention mechanism focuses on, and explore its performance across different parameter settings. version:3
arxiv-1707-06903 | A New Family of Near-metrics for Universal Similarity | http://arxiv.org/abs/1707.06903 | id:1707.06903 author:Chu Wang, Iraj Saniee, William S. Kennedy, Chris A. White category:stat.ML cs.LG  published:2017-07-21 summary:We propose a family of near-metrics based on local graph diffusion to capture similarity for a wide class of data sets. These quasi-metametrics, as their names suggest, dispense with one or two standard axioms of metric spaces, specifically distinguishability and symmetry, so that similarity between data points of arbitrary type and form could be measured broadly and effectively. The proposed near-metric family includes the forward k-step diffusion and its reverse, typically on the graph consisting of data objects and their features. By construction, this family of near-metrics is particularly appropriate for categorical data, continuous data, and vector representations of images and text extracted via deep learning approaches. We conduct extensive experiments to evaluate the performance of this family of similarity measures and compare and contrast with traditional measures of similarity used for each specific application and with the ground truth when available. We show that for structured data including categorical and continuous data, the near-metrics corresponding to normalized forward k-step diffusion (k small) work as one of the best performing similarity measures; for vector representations of text and images including those extracted from deep learning, the near-metrics derived from normalized and reverse k-step graph diffusion (k very small) exhibit outstanding ability to distinguish data points from different classes. version:1
arxiv-1707-00116 | Image Companding and Inverse Halftoning using Deep Convolutional Neural Networks | http://arxiv.org/abs/1707.00116 | id:1707.00116 author:Xianxu Hou, Guoping Qiu category:cs.CV  published:2017-07-01 summary:In this paper, we introduce deep learning technology to tackle two traditional low-level image processing problems, companding and inverse halftoning. We make two main contributions. First, to the best knowledge of the authors, this is the first work that has successfully developed deep learning based solutions to these two traditional low-level image processing problems. This not only introduces new methods to tackle well-known image processing problems but also demonstrates the power of deep learning in solving traditional signal processing problems. Second, we have developed an effective deep learning algorithm based on insights into the properties of visual quality of images and the internal representation properties of a deep convolutional neural network (CNN). We train a deep CNN as a nonlinear transformation function to map a low bit depth image to higher bit depth or from a halftone image to a continuous tone image. We also employ another pretrained deep CNN as a feature extractor to derive visually important features to construct the objective function for the training of the mapping CNN. We present experimental results to demonstrate the effectiveness of the new deep learning based solutions. version:2
arxiv-1707-06887 | A Distributional Perspective on Reinforcement Learning | http://arxiv.org/abs/1707.06887 | id:1707.06887 author:Marc G. Bellemare, Will Dabney, Rémi Munos category:cs.LG cs.AI stat.ML  published:2017-07-21 summary:In this paper we argue for the fundamental importance of the value distribution: the distribution of the random return received by a reinforcement learning agent. This is in contrast to the common approach to reinforcement learning which models the expectation of this return, or value. Although there is an established body of literature studying the value distribution, thus far it has always been used for a specific purpose such as implementing risk-aware behaviour. We begin with theoretical results in both the policy evaluation and control settings, exposing a significant distributional instability in the latter. We then use the distributional perspective to design a new algorithm which applies Bellman's equation to the learning of approximate value distributions. We evaluate our algorithm using the suite of games from the Arcade Learning Environment. We obtain both state-of-the-art results and anecdotal evidence demonstrating the importance of the value distribution in approximate reinforcement learning. Finally, we combine theoretical and empirical evidence to highlight the ways in which the value distribution impacts learning in the approximate setting. version:1
arxiv-1707-06885 | SGNMT -- A Flexible NMT Decoding Platform for Quick Prototyping of New Models and Search Strategies | http://arxiv.org/abs/1707.06885 | id:1707.06885 author:Felix Stahlberg, Eva Hasler, Danielle Saunders, Bill Byrne category:cs.CL  published:2017-07-21 summary:This paper introduces SGNMT, our experimental platform for machine translation research. SGNMT provides a generic interface to neural and symbolic scoring modules (predictors) with left-to-right semantic such as translation models like NMT, language models, translation lattices, $n$-best lists or other kinds of scores and constraints. Predictors can be combined with other predictors to form complex decoding tasks. SGNMT implements a number of search strategies for traversing the space spanned by the predictors which are appropriate for different predictor constellations. Adding new predictors or decoding strategies is particularly easy, making it a very efficient tool for prototyping new research ideas. SGNMT is actively being used by students in the MPhil program in Machine Learning, Speech and Language Technology at the University of Cambridge for course work and theses, as well as for most of the research work in our group. version:1
arxiv-1705-06106 | Unlabeled Data for Morphological Generation With Character-Based Sequence-to-Sequence Models | http://arxiv.org/abs/1705.06106 | id:1705.06106 author:Katharina Kann, Hinrich Schütze category:cs.CL  published:2017-05-17 summary:We present a semi-supervised way of training a character-based encoder-decoder recurrent neural network for morphological reinflection, the task of generating one inflected word form from another. This is achieved by using unlabeled tokens or random strings as training data for an autoencoding task, adapting a network for morphological reinflection, and performing multi-task training. We thus use limited labeled data more effectively, obtaining up to 9.9% improvement over state-of-the-art baselines for 8 different languages. version:2
arxiv-1707-06879 | Learning Aerial Image Segmentation from Online Maps | http://arxiv.org/abs/1707.06879 | id:1707.06879 author:Pascal Kaiser, Jan Dirk Wegner, Aurelien Lucchi, Martin Jaggi, Thomas Hofmann, Konrad Schindler category:cs.CV  published:2017-07-21 summary:This study deals with semantic segmentation of high-resolution (aerial) images where a semantic class label is assigned to each pixel via supervised classification as a basis for automatic map generation. Recently, deep convolutional neural networks (CNNs) have shown impressive performance and have quickly become the de-facto standard for semantic segmentation, with the added benefit that task-specific feature design is no longer necessary. However, a major downside of deep learning methods is that they are extremely data-hungry, thus aggravating the perennial bottleneck of supervised classification, to obtain enough annotated training data. On the other hand, it has been observed that they are rather robust against noise in the training labels. This opens up the intriguing possibility to avoid annotating huge amounts of training data, and instead train the classifier from existing legacy data or crowd-sourced maps which can exhibit high levels of noise. The question addressed in this paper is: can training with large-scale, publicly available labels replace a substantial part of the manual labeling effort and still achieve sufficient performance? Such data will inevitably contain a significant portion of errors, but in return virtually unlimited quantities of it are available in larger parts of the world. We adapt a state-of-the-art CNN architecture for semantic segmentation of buildings and roads in aerial images, and compare its performance when using different training data sets, ranging from manually labeled, pixel-accurate ground truth of the same city to automatic training data derived from OpenStreetMap data from distant locations. We report our results that indicate that satisfying performance can be obtained with significantly less manual annotation effort, by exploiting noisy large-scale training data. version:1
arxiv-1707-06878 | Unsupervised, Knowledge-Free, and Interpretable Word Sense Disambiguation | http://arxiv.org/abs/1707.06878 | id:1707.06878 author:Alexander Panchenko, Fide Marten, Eugen Ruppert, Stefano Faralli, Dmitry Ustalov, Simone Paolo Ponzetto, Chris Biemann category:cs.CL I.2.6; I.5.3; I.2.4  published:2017-07-21 summary:Interpretability of a predictive model is a powerful feature that gains the trust of users in the correctness of the predictions. In word sense disambiguation (WSD), knowledge-based systems tend to be much more interpretable than knowledge-free counterparts as they rely on the wealth of manually-encoded elements representing word senses, such as hypernyms, usage examples, and images. We present a WSD system that bridges the gap between these two so far disconnected groups of methods. Namely, our system, providing access to several state-of-the-art WSD models, aims to be interpretable as a knowledge-based system while it remains completely unsupervised and knowledge-free. The presented tool features a Web interface for all-word disambiguation of texts that makes the sense predictions human readable by providing interpretable word sense inventories, sense representations, and disambiguation results. We provide a public API, enabling seamless integration. version:1
arxiv-1707-06875 | Why We Need New Evaluation Metrics for NLG | http://arxiv.org/abs/1707.06875 | id:1707.06875 author:Jekaterina Novikova, Ondřej Dušek, Amanda Cercas Curry, Verena Rieser category:cs.CL  published:2017-07-21 summary:The majority of NLG evaluation relies on automatic metrics, such as BLEU . In this paper, we motivate the need for novel, system- and data-independent automatic evaluation methods: We investigate a wide range of metrics, including state-of-the-art word-based and novel grammar-based ones, and demonstrate that they only weakly reflect human judgements of system outputs as generated by data-driven, end-to-end NLG. We also show that metric performance is data- and system-specific. Nevertheless, our results also suggest that automatic metrics perform reliably at system-level and can support system development by finding cases where a system performs poorly. version:1
arxiv-1707-06873 | Semantic Image Synthesis via Adversarial Learning | http://arxiv.org/abs/1707.06873 | id:1707.06873 author:Hao Dong, Simiao Yu, Chao Wu, Yike Guo category:cs.CV  published:2017-07-21 summary:In this paper, we propose a way of synthesizing realistic images directly with natural language description, which has many useful applications, e.g. intelligent image manipulation. We attempt to accomplish such synthesis: given a source image and a target text description, our model synthesizes images to meet two requirements: 1) being realistic while matching the target text description; 2) maintaining other image features that are irrelevant to the text description. The model should be able to disentangle the semantic information from the two modalities (image and text), and generate new images from the combined semantics. To achieve this, we proposed an end-to-end neural architecture that leverages adversarial learning to automatically learn implicit loss functions, which are optimized to fulfill the aforementioned two requirements. We have evaluated our model by conducting experiments on Caltech-200 bird dataset and Oxford-102 flower dataset, and have demonstrated that our model is capable of synthesizing realistic images that match the given descriptions, while still maintain other features of original images. version:1
arxiv-1707-06865 | Retinal Microaneurysms Detection using Local Convergence Index Features | http://arxiv.org/abs/1707.06865 | id:1707.06865 author:Behdad Dashtbozorg, Jiong Zhang, Bart M. ter Haar Romeny category:cs.CV  published:2017-07-21 summary:Retinal microaneurysms are the earliest clinical sign of diabetic retinopathy disease. Detection of microaneurysms is crucial for the early diagnosis of diabetic retinopathy and prevention of blindness. In this paper, a novel and reliable method for automatic detection of microaneurysms in retinal images is proposed. In the first stage of the proposed method, several preliminary microaneurysm candidates are extracted using a gradient weighting technique and an iterative thresholding approach. In the next stage, in addition to intensity and shape descriptors, a new set of features based on local convergence index filters is extracted for each candidate. Finally, the collective set of features is fed to a hybrid sampling/boosting classifier to discriminate the MAs from non-MAs candidates. The method is evaluated on images with different resolutions and modalities (RGB and SLO) using five publicly available datasets including the Retinopathy Online Challenge's dataset. The proposed method achieves an average sensitivity score of 0.471 on the ROC dataset outperforming state-of-the-art approaches in an extensive comparison. The experimental results on the other four datasets demonstrate the effectiveness and robustness of the proposed microaneurysms detection method regardless of different image resolutions and modalities. version:1
arxiv-1707-06996 | A Sentiment-and-Semantics-Based Approach for Emotion Detection in Textual Conversations | http://arxiv.org/abs/1707.06996 | id:1707.06996 author:Umang Gupta, Ankush Chatterjee, Radhakrishnan Srikanth, Puneet Agrawal category:cs.CL  published:2017-07-21 summary:Emotions are physiological states generated in humans in reaction to internal or external events. They are complex and studied across numerous fields including computer science. As humans, on reading "Why don't you ever text me!" we can either interpret it as a sad or angry emotion and the same ambiguity exists for machines. Lack of facial expressions and voice modulations make detecting emotions from text a challenging problem. However, as humans increasingly communicate using text messaging applications, and digital agents gain popularity in our society, it is essential that these digital agents are emotion aware, and respond accordingly. In this paper, we propose a novel approach to detect emotions like happy, sad or angry in textual conversations using an LSTM based Deep Learning model. Our approach consists of semi-automated techniques to gather training data for our model. We exploit advantages of semantic and sentiment based embeddings and propose a solution combining both. Our work is evaluated on real world conversations and significantly outperforms traditional Machine Learning baselines as well as other off-the-shelf Deep Learning models. version:1
arxiv-1705-04300 | Challenges in Monocular Visual Odometry: Photometric Calibration, Motion Bias and Rolling Shutter Effect | http://arxiv.org/abs/1705.04300 | id:1705.04300 author:Nan Yang, Rui Wang, Daniel Cremers category:cs.CV  published:2017-05-11 summary:Monocular visual odometry (VO), which incrementally estimates camera poses and local 3D maps, is the key com- ponent of monocular simultaneously localization and map- ping (SLAM). It has seen tremendous improvements on ac- curacy, robustness and efficiency, and has gained exponen- tial popularity over recent years. Nevertheless, no compre- hensive evaluations have been performed to reveal the influ- ences of the three aspects: photometric calibration, motion bias and rolling shutter effect, which can significantly affect the VO performances. In this work, we evaluate these three aspects quantitatively on the state of the art of both direct and feature-based methods. Analysis and conclusions are given to all our experiment results. version:2
arxiv-1707-06841 | An Error-Oriented Approach to Word Embedding Pre-Training | http://arxiv.org/abs/1707.06841 | id:1707.06841 author:Youmna Farag, Marek Rei, Ted Briscoe category:cs.CL cs.LG cs.NE  published:2017-07-21 summary:We propose a novel word embedding pre-training approach that exploits writing errors in learners' scripts. We compare our method to previous models that tune the embeddings based on script scores and the discrimination between correct and corrupt word contexts in addition to the generic commonly-used embeddings pre-trained on large corpora. The comparison is achieved by using the aforementioned models to bootstrap a neural network that learns to predict a holistic score for scripts. Furthermore, we investigate augmenting our model with error corrections and monitor the impact on performance. Our results show that our error-oriented approach outperforms other comparable ones which is further demonstrated when training on more data. Additionally, extending the model with corrections provides further performance gains when data sparsity is an issue. version:1
arxiv-1707-06838 | Neuron Pruning for Compressing Deep Networks using Maxout Architectures | http://arxiv.org/abs/1707.06838 | id:1707.06838 author:Fernando Moya Rueda, Rene Grzeszick, Gernot A. Fink category:cs.CV  published:2017-07-21 summary:This paper presents an efficient and robust approach for reducing the size of deep neural networks by pruning entire neurons. It exploits maxout units for combining neurons into more complex convex functions and it makes use of a local relevance measurement that ranks neurons according to their activation on the training set for pruning them. Additionally, a parameter reduction comparison between neuron and weight pruning is shown. It will be empirically shown that the proposed neuron pruning reduces the number of parameters dramatically. The evaluation is performed on two tasks, the MNIST handwritten digit recognition and the LFW face verification, using a LeNet-5 and a VGG16 network architecture. The network size is reduced by up to $74\%$ and $61\%$, respectively, without affecting the network's performance. The main advantage of neuron pruning is its direct influence on the size of the network architecture. Furthermore, it will be shown that neuron pruning can be combined with subsequent weight pruning, reducing the size of the LeNet-5 and VGG16 up to $92\%$ and $80\%$ respectively. version:1
arxiv-1707-06833 | Date-Field Retrieval in Scene Image and Video Frames using Text Enhancement and Shape Coding | http://arxiv.org/abs/1707.06833 | id:1707.06833 author:Partha Pratim Roy, Ayan Kumar Bhunia, Umapada Pal category:cs.CV  published:2017-07-21 summary:Text recognition in scene image and video frames is difficult because of low resolution, blur, background noise, etc. Since traditional OCRs do not perform well in such images, information retrieval using keywords could be an alternative way to index/retrieve such text information. Date is a useful piece of information which has various applications including date-wise videos/scene searching, indexing or retrieval. This paper presents a date spotting based information retrieval system for natural scene image and video frames where text appears with complex backgrounds. We propose a line based date spotting approach using Hidden Markov Model (HMM) which is used to detect the date information in a given text. Different date models are searched from a line without segmenting characters or words. Given a text line image in RGB, we apply an efficient gray image conversion to enhance the text information. Wavelet decomposition and gradient sub-bands are used to enhance text information in gray scale. Next, Pyramid Histogram of Oriented Gradient (PHOG) feature has been extracted from gray image and binary images for date-spotting framework. Binary and gray image features are combined by MLP based Tandem approach. Finally, to boost the performance further, a shape coding based scheme is used to combine the similar shape characters in same class during word spotting. For our experiment, three different date models have been constructed to search similar date information having numeric dates that contains numeral values and punctuations and semi-numeric that contains dates with numerals along with months in scene/video text. We have tested our system on 1648 text lines and the results show the effectiveness of our proposed date spotting approach. version:1
arxiv-1707-06828 | HMM-based Writer Identification in Music Score Documents without Staff-Line Removal | http://arxiv.org/abs/1707.06828 | id:1707.06828 author:Partha Pratim Roy, Ayan Kumar Bhunia, Umapada Pal category:cs.CV  published:2017-07-21 summary:Writer identification from musical score documents is a challenging task due to its inherent problem of overlapping of musical symbols with staff lines. Most of the existing works in the literature of writer identification in musical score documents were performed after a preprocessing stage of staff lines removal. In this paper we propose a novel writer identification framework in musical documents without removing staff lines from documents. In our approach, Hidden Markov Model has been used to model the writing style of the writers without removing staff lines. The sliding window features are extracted from musical score lines and they are used to build writer specific HMM models. Given a query musical sheet, writer specific confidence for each musical line is returned by each writer specific model using a loglikelihood score. Next, a loglikelihood score in page level is computed by weighted combination of these scores from the corresponding line images of the page. A novel Factor Analysis based feature selection technique is applied in sliding window features to reduce the noise appearing from staff lines which proves efficiency in writer identification performance.In our framework we have also proposed a novel score line detection approach in musical sheet using HMM. The experiment has been performed in CVC-MUSCIMA dataset and the results obtained that the proposed approach is efficient for score line detection and writer identification without removing staff lines. To get the idea of computation time of our method, detail analysis of execution time is also provided. version:1
arxiv-1707-06825 | Evaluation of Hashing Methods Performance on Binary Feature Descriptors | http://arxiv.org/abs/1707.06825 | id:1707.06825 author:Jacek Komorowski, Tomasz Trzcinski category:cs.CV  published:2017-07-21 summary:In this paper we evaluate performance of data-dependent hashing methods on binary data. The goal is to find a hashing method that can effectively produce lower dimensional binary representation of 512-bit FREAK descriptors. A representative sample of recent unsupervised, semi-supervised and supervised hashing methods was experimentally evaluated on large datasets of labelled binary FREAK feature descriptors. version:1
arxiv-1705-02364 | Supervised Learning of Universal Sentence Representations from Natural Language Inference Data | http://arxiv.org/abs/1705.02364 | id:1705.02364 author:Alexis Conneau, Douwe Kiela, Holger Schwenk, Loic Barrault, Antoine Bordes category:cs.CL  published:2017-05-05 summary:Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available. version:4
arxiv-1707-06810 | Text Recognition in Scene Image and Video Frame using Color Channel Selection | http://arxiv.org/abs/1707.06810 | id:1707.06810 author:Ayan Kumar Bhunia, Gautam Kumar, Partha Pratim Roy, R. Balasubramanian, Umapada Pal category:cs.CV  published:2017-07-21 summary:In recent years, recognition of text from natural scene image and video frame has got increased attention among the researchers due to its various complexities and challenges. Because of low resolution, blurring effect, complex background, different fonts, color and variant alignment of text within images and video frames, etc., text recognition in such scenario is difficult. Most of the current approaches usually apply a binarization algorithm to convert them into binary images and next OCR is applied to get the recognition result. In this paper, we present a novel approach based on color channel selection for text recognition from scene images and video frames. In the approach, at first, a color channel is automatically selected and then selected color channel is considered for text recognition. Our text recognition framework is based on Hidden Markov Model (HMM) which uses Pyramidal Histogram of Oriented Gradient features extracted from selected color channel. From each sliding window of a color channel our color-channel selection approach analyzes the image properties from the sliding window and then a multi-label Support Vector Machine (SVM) classifier is applied to select the color channel that will provide the best recognition results in the sliding window. This color channel selection for each sliding window has been found to be more fruitful than considering a single color channel for the whole word image. Five different features have been analyzed for multi-label SVM based color channel selection where wavelet transform based feature outperforms others. Our framework has been tested on different publicly available scene/video text image datasets. For Devanagari script, we collected our own data dataset. The performances obtained from experimental results are encouraging and show the advantage of the proposed method. version:1
arxiv-1707-06807 | Recurrent Neural Networks for Online Video Popularity Prediction | http://arxiv.org/abs/1707.06807 | id:1707.06807 author:Tomasz Trzcinski, Pawel Andruszkiewicz, Tomasz Bochenski, Przemyslaw Rokita category:cs.CV  published:2017-07-21 summary:In this paper, we address the problem of popularity prediction of online videos shared in social media. We prove that this challenging task can be approached using recently proposed deep neural network architectures. We cast the popularity prediction problem as a classification task and we aim to solve it using only visual cues extracted from videos. To that end, we propose a new method based on a Long-term Recurrent Convolutional Network (LRCN) that incorporates the sequentiality of the information in the model. Results obtained on a dataset of over 37'000 videos published on Facebook show that using our method leads to over 30% improvement in prediction performance over the traditional shallow approaches and can provide valuable insights for content creators. version:1
arxiv-1707-06806 | Shallow reading with Deep Learning: Predicting popularity of online content using only its title | http://arxiv.org/abs/1707.06806 | id:1707.06806 author:Wociech Stokowiec, Tomasz Trzcinski, Krzysztof Wolk, Krzysztof Marasek, Przemyslaw Rokita category:cs.CL  published:2017-07-21 summary:With the ever decreasing attention span of contemporary Internet users, the title of online content (such as a news article or video) can be a major factor in determining its popularity. To take advantage of this phenomenon, we propose a new method based on a bidirectional Long Short-Term Memory (LSTM) neural network designed to predict the popularity of online content using only its title. We evaluate the proposed architecture on two distinct datasets of news articles and news videos distributed in social media that contain over 40,000 samples in total. On those datasets, our approach improves the performance over traditional shallow approaches by a margin of 15%. Additionally, we show that using pre-trained word vectors in the embedding layer improves the results of LSTM models, especially when the training set is small. To our knowledge, this is the first attempt of applying popularity prediction using only textual information from the title. version:1
arxiv-1707-06799 | Optimal Hyperparameters for Deep LSTM-Networks for Sequence Labeling Tasks | http://arxiv.org/abs/1707.06799 | id:1707.06799 author:Nils Reimers, Iryna Gurevych category:cs.CL  published:2017-07-21 summary:Selecting optimal parameters for a neural network architecture can often make the difference between mediocre and state-of-the-art performance. However, little is published which parameters and design choices should be evaluated or selected making the correct hyperparameter optimization often a "black art that requires expert experiences" (Snoek et al., 2012). In this paper, we evaluate the importance of different network design choices and hyperparameters for five common linguistic sequence tagging tasks (POS, Chunking, NER, Entity Recognition, and Event Detection). We evaluated over 50.000 different setups and found, that some parameters, like the pre-trained word embeddings or the last layer of the network, have a large impact on the performance, while other parameters, for example the number of LSTM layers or the number of recurrent units, are of minor importance. We give a recommendation on a configuration that performs well among different tasks. version:1
arxiv-1707-06409 | Attribution Modeling Increases Efficiency of Bidding in Display Advertising | http://arxiv.org/abs/1707.06409 | id:1707.06409 author:Eustache Diemert, Julien Meynet, Pierre Galland, Damien Lefortier category:stat.ML cs.GT  published:2017-07-20 summary:Predicting click and conversion probabilities when bidding on ad exchanges is at the core of the programmatic advertising industry. Two separated lines of previous works respectively address i) the prediction of user conversion probability and ii) the attribution of these conversions to advertising events (such as clicks) after the fact. We argue that attribution modeling improves the efficiency of the bidding policy in the context of performance advertising. Firstly we explain the inefficiency of the standard bidding policy with respect to attribution. Secondly we learn and utilize an attribution model in the bidder itself and show how it modifies the average bid after a click. Finally we produce evidence of the effectiveness of the proposed method on both offline and online experiments with data spanning several weeks of real traffic from Criteo, a leader in performance advertising. version:2
arxiv-1707-06786 | Head Detection with Depth Images in the Wild | http://arxiv.org/abs/1707.06786 | id:1707.06786 author:Diego Ballotta, Guido Borghi, Roberto Vezzani, Rita Cucchiara category:cs.CV  published:2017-07-21 summary:In wild contexts, head detection is a demanding task and a key element for many disciplines of the computer vision community, like video surveillance, Human Computer Interaction and face analysis. In this paper, we introduce a novel method for head detection, that conjugates the classification ability of deep learning approaches and depth maps, a type of infrared-based images useful to achieve reliability in case of light changes or bad light conditions. Moreover, depth data are also employed to deal with one of the traditional problems in object detection task, i.e. the scale of the target object. Two public datasets are exploited: the first one, Pandora, is used to train the deep classifier of face or non-face images; the second one, collected by the Cornell University, is used to perform a cross-dataset test during daily activities in unconstrained environments. Experimental results show that the proposed method overcomes state-of-art performance of methods based only on depth images. version:1
arxiv-1707-06783 | 3DCNN-DQN-RNN: A Deep Reinforcement Learning Framework for Semantic Parsing of Large-scale 3D Point Clouds | http://arxiv.org/abs/1707.06783 | id:1707.06783 author:Fangyu Liu, Shuaipeng Li, Liqiang Zhang, Chenghu Zhou, Rongtian Ye, Yuebin Wang, Jiwen Lu category:cs.CV  published:2017-07-21 summary:Semantic parsing of large-scale 3D point clouds is an important research topic in computer vision and remote sensing fields. Most existing approaches utilize hand-crafted features for each modality independently and combine them in a heuristic manner. They often fail to consider the consistency and complementary information among features adequately, which makes them difficult to capture high-level semantic structures. The features learned by most of the current deep learning methods can obtain high-quality image classification results. However, these methods are hard to be applied to recognize 3D point clouds due to unorganized distribution and various point density of data. In this paper, we propose a 3DCNN-DQN-RNN method which fuses the 3D convolutional neural network (CNN), Deep Q-Network (DQN) and Residual recurrent neural network (RNN) for an efficient semantic parsing of large-scale 3D point clouds. In our method, an eye window under control of the 3D CNN and DQN can localize and segment the points of the object class efficiently. The 3D CNN and Residual RNN further extract robust and discriminative features of the points in the eye window, and thus greatly enhance the parsing accuracy of large-scale point clouds. Our method provides an automatic process that maps the raw data to the classification results. It also integrates object localization, segmentation and classification into one framework. Experimental results demonstrate that the proposed method outperforms the state-of-the-art point cloud classification methods. version:1
arxiv-1707-06777 | Neural Person Search Machines | http://arxiv.org/abs/1707.06777 | id:1707.06777 author:Hao Liu, Jiashi Feng, Zequn Jie, Karlekar Jayashree, Bo Zhao, Meibin Qi, Jianguo Jiang, Shuicheng Yan category:cs.CV  published:2017-07-21 summary:We investigate the problem of person search in the wild in this work. Instead of comparing the query against all candidate regions generated in a query-blind manner, we propose to recursively shrink the search area from the whole image till achieving precise localization of the target person, by fully exploiting information from the query and contextual cues in every recursive search step. We develop the Neural Person Search Machines (NPSM) to implement such recursive localization for person search. Benefiting from its neural search mechanism, NPSM is able to selectively shrink its focus from a loose region to a tighter one containing the target automatically. In this process, NPSM employs an internal primitive memory component to memorize the query representation which modulates the attention and augments its robustness to other distracting regions. Evaluations on two benchmark datasets, CUHK-SYSU Person Search dataset and PRW dataset, have demonstrated that our method can outperform current state-of-the-arts in both mAP and top-1 evaluation protocols. version:1
arxiv-1707-06772 | Improved Bilinear Pooling with CNNs | http://arxiv.org/abs/1707.06772 | id:1707.06772 author:Tsung-Yu Lin, Subhransu Maji category:cs.CV  published:2017-07-21 summary:Bilinear pooling of Convolutional Neural Network (CNN) features [22, 23], and their compact variants [10], have been shown to be effective at fine-grained recognition, scene categorization, texture recognition, and visual question-answering tasks among others. The resulting representation captures second-order statistics of convolutional features in a translationally invariant manner. In this paper we investigate various ways of normalizing these statistics to improve their representation power. In particular we find that the matrix square-root normalization offers significant improvements and outperforms alternative schemes such as the matrix logarithm normalization when combined with elementwise square-root and l2 normalization. This improves the accuracy by 2-3% on a range of fine-grained recognition datasets leading to a new state of the art. We also investigate how the accuracy of matrix function computations effect network training and evaluation. In particular we compare against a technique for estimating matrix square-root gradients via solving a Lyapunov equation that is more numerically accurate than computing gradients via a Singular Value Decomposition (SVD). We find that while SVD gradients are numerically inaccurate the overall effect on the final accuracy is negligible once boundary cases are handled carefully. We present an alternative scheme for computing gradients that is faster and yet it offers improvements over the baseline model. Finally we show that the matrix square-root computed approximately using a few Newton iterations is just as accurate for the classification task but allows an order-of-magnitude faster GPU implementation compared to SVD decomposition. version:1
arxiv-1707-06633 | Acting Thoughts: Towards a Mobile Robotic Service Assistant for Users with Limited Communication Skills | http://arxiv.org/abs/1707.06633 | id:1707.06633 author:Felix Burget, Lukas Dominique Josef Fiederer, Daniel Kuhner, Martin Völker, Johannes Aldinger, Robin Tibor Schirrmeister, Chau Do, Joschka Boedecker, Bernhard Nebel, Tonio Ball, Wolfram Burgard category:cs.AI cs.CV cs.HC cs.LG cs.RO  published:2017-07-20 summary:As autonomous service robots become more affordable and thus available also for the general public, there is a growing need for user friendly interfaces to control the robotic system. Currently available control modalities typically expect users to be able to express their desire through either touch, speech or gesture commands. While this requirement is fulfilled for the majority of users, paralyzed users may not be able to use such systems. In this paper, we present a novel framework, that allows these users to interact with a robotic service assistant in a closed-loop fashion, using only thoughts. The brain-computer interface (BCI) system is composed of several interacting components, i.e., non-invasive neuronal signal recording and decoding, high-level task planning, motion and manipulation planning as well as environment perception. In various experiments, we demonstrate its applicability and robustness in real world scenarios, considering fetch-and-carry tasks and tasks involving human-robot interaction. As our results demonstrate, our system is capable of adapting to frequent changes in the environment and reliably completing given tasks within a reasonable amount of time. Combined with high-level planning and autonomous robotic systems, interesting new perspectives open up for non-invasive BCI-based human-robot interactions. version:2
arxiv-1707-06468 | Breaking the Nonsmooth Barrier: A Scalable Parallel Method for Composite Optimization | http://arxiv.org/abs/1707.06468 | id:1707.06468 author:Fabian Pedregosa, Rémi Leblond, Simon Lacoste-Julien category:math.OC cs.LG stat.ML  published:2017-07-20 summary:Due to their simplicity and excellent performance, parallel asynchronous variants of stochastic gradient descent have become popular methods to solve a wide range of large-scale optimization problems on multi-core architectures. Yet, despite their practical success, support for nonsmooth objectives is still lacking, making them unsuitable for many problems of interest in machine learning, such as the Lasso, group Lasso or empirical risk minimization with convex constraints. In this work, we propose and analyze ProxASAGA, a fully asynchronous sparse method inspired by SAGA, a variance reduced incremental gradient algorithm. The proposed method is easy to implement and significantly outperforms the state of the art on several nonsmooth, large-scale problems. We prove that our method achieves a theoretical linear speedup with respect to the sequential version under assumptions on the sparsity of gradients and block-separability of the proximal term. Empirical benchmarks on a multi-core architecture illustrate practical speedups of up to 12x on a 20-core machine. version:2
arxiv-1707-06757 | A Nonlinear Dimensionality Reduction Framework Using Smooth Geodesics | http://arxiv.org/abs/1707.06757 | id:1707.06757 author:Kelum Gajamannage, Randy Paffenroth, Erik M. Bollt category:stat.ML cs.CV cs.LG math.DS 68T05 H.2.8; I.2.6  published:2017-07-21 summary:Existing dimensionality reduction methods are adept at revealing hidden underlying manifolds arising from high-dimensional data and thereby producing a low-dimensional representation. However, the smoothness of the manifolds produced by classic techniques in the presence of noise is not guaranteed. In fact, the embedding generated using such non-smooth, noisy measurements may distort the geometry of the manifold and thereby produce an unfaithful embedding. Herein, we propose a framework for nonlinear dimensionality reduction that generates a manifold in terms of smooth geodesics that is designed to treat problems in which manifold measurements have been corrupted by noise. Our method generates a network structure for given high-dimensional data using a neighborhood search and then produces piecewise linear shortest paths that are defined as geodesics. Then, we fit points in each geodesic by a smoothing spline to emphasize the smoothness. The robustness of this approach for noisy and sparse datasets is demonstrated by the implementation of the method on synthetic and real-world datasets. version:1
arxiv-1707-06756 | An Infinite Hidden Markov Model With Similarity-Biased Transitions | http://arxiv.org/abs/1707.06756 | id:1707.06756 author:Colin Reimer Dawson, Chaofan Huang, Clayton T. Morrison category:stat.ML cs.AI cs.LG stat.ME G.3; I.2.6  published:2017-07-21 summary:We describe a generalization of the Hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM) which is able to encode prior information that state transitions are more likely between "nearby" states. This is accomplished by defining a similarity function on the state space and scaling transition probabilities by pair-wise similarities, thereby inducing correlations among the transition distributions. We present an augmented data representation of the model as a Markov Jump Process in which: (1) some jump attempts fail, and (2) the probability of success is proportional to the similarity between the source and destination states. This augmentation restores conditional conjugacy and admits a simple Gibbs sampler. We evaluate the model and inference method on a speaker diarization task and a "harmonic parsing" task using four-part chorale data, as well as on several synthetic datasets, achieving favorable comparisons to existing models. version:1
arxiv-1707-06729 | Predictive networking and optimization for flow-based networks | http://arxiv.org/abs/1707.06729 | id:1707.06729 author:Michael Arnold category:cs.NI cs.NE  published:2017-07-21 summary:Artificial Neural Networks (ANNs) were used to classify neural network flows by flow size. After training the neural network was able to predict the size of a flows with 87% accuracy with a Feed Forward Neural Network. This demonstrates that flow based routers can prioritize candidate flows with a predicted large number of packets for priority insertion into hardware content-addressable memory. version:1
arxiv-1707-06728 | Efficient Defenses Against Adversarial Attacks | http://arxiv.org/abs/1707.06728 | id:1707.06728 author:Valentina Zantedeschi, Maria-Irina Nicolae, Ambrish Rawat category:cs.LG  published:2017-07-21 summary:After the recent adoption of deep neural networks (DNN) in a wide range of application fields, adversarial attacks against these models have proven to be an indisputable threat. Adversarial samples are crafted with the precise intention of producing a specific response from the system. Multiple attacks and defenses have already been designed, but the lack of better understanding of sensitivity of DNNs justifies adversarial samples still being an open question. In this paper, we propose a new defense method based on practical observations which is easy to integrate into models and performs better than state-of-the-art defenses. Our proposed solution is meant to reinforce the structure of a DNN, making its prediction more stable and less inclined to be fooled by adversarial samples. We conduct an extensive experimental study proving the efficiency of our method against multiple attacks, comparing it to multiple defenses, both in white-box and black-box setups. Additionally, the implementation of our method brings almost no overhead to the training procedure, while maintaining the prediction performance of the original model on clean samples. version:1
arxiv-1705-04044 | End-to-end Recurrent Neural Network Models for Vietnamese Named Entity Recognition: Word-level vs. Character-level | http://arxiv.org/abs/1705.04044 | id:1705.04044 author:Thai-Hoang Pham, Phuong Le-Hong category:cs.CL  published:2017-05-11 summary:This paper demonstrates end-to-end neural network architectures for Vietnamese named entity recognition. Our best model is a combination of bidirectional Long Short-Term Memory (Bi-LSTM), Convolutional Neural Network (CNN), Conditional Random Field (CRF), using pre-trained word embeddings as input, which achieves an F1 score of 88.59% on a standard test set. Our system is able to achieve a comparable performance to the first-rank system of the VLSP campaign without using any syntactic or hand-crafted features. We also give an extensive empirical study on using common deep learning models for Vietnamese NER, at both word and character level. version:3
arxiv-1707-06719 | Generalized Convolutional Neural Networks for Point Cloud Data | http://arxiv.org/abs/1707.06719 | id:1707.06719 author:Aleksandr Savchenkov category:cs.CV stat.ML  published:2017-07-20 summary:The introduction of cheap RGB-D cameras, stereo cameras, and LIDAR devices has given the computer vision community 3D information that conventional RGB cameras cannot provide. This data is often stored as a point cloud. In this paper, we present a novel method to apply the concept of convolutional neural networks to this type of data. By creating a mapping of nearest neighbors in a dataset, and individually applying weights to spatial relationships between points, we achieve an architecture that works directly with point clouds, but closely resembles a convolutional neural net in both design and behavior. Such a method bypasses the need for extensive feature engineering, while proving to be computationally efficient and requiring few parameters. version:1
arxiv-1707-06718 | Convolutional Sparse Coding: Boundary Handling Revisited | http://arxiv.org/abs/1707.06718 | id:1707.06718 author:Brendt Wohlberg, Paul Rodriguez category:cs.CV  published:2017-07-20 summary:Two different approaches have recently been proposed for boundary handling in convolutional sparse representations, avoiding potential boundary artifacts arising from the circular boundary conditions implied by the use of frequency domain solution methods by introducing a spatial mask into the convolutional sparse coding problem. In the present paper we show that, under certain circumstances, these methods fail in their design goal of avoiding boundary artifacts. The reasons for this failure are discussed, a solution is proposed, and the practical implications are illustrated in an image deblurring problem. version:1
arxiv-1707-04853 | Overcoming Catastrophic Interference by Conceptors | http://arxiv.org/abs/1707.04853 | id:1707.04853 author:Xu He, Herbert Jaeger category:cs.NE cs.LG  published:2017-07-16 summary:Catastrophic interference has been a major roadblock in the research of continual learning. Here we propose a variant of the back-propagation algorithm, "conceptor-aided back-prop" (CAB), in which gradients are shielded by conceptors against degradation of previously learned tasks. Conceptors have their origin in reservoir computing, where they have been previously shown to overcome catastrophic forgetting. CAB extends these results to deep feedforward networks. On the disjoint MNIST task CAB outperforms two other methods for coping with catastrophic interference that have recently been proposed in the deep learning field. version:2
arxiv-1707-01161 | Shakespearizing Modern Language Using Copy-Enriched Sequence-to-Sequence Models | http://arxiv.org/abs/1707.01161 | id:1707.01161 author:Harsh Jhamtani, Varun Gangal, Eduard Hovy, Eric Nyberg category:cs.CL  published:2017-07-04 summary:Variations in writing styles are commonly used to adapt the content to a specific context, audience, or purpose. However, applying stylistic variations is still by and large a manual process, and there have been little efforts towards automating it. In this paper we explore automated methods to transform text from modern English to Shakespearean English using an end to end trainable neural model with pointers to enable copy action. To tackle limited amount of parallel data, we pre-train embeddings of words by leveraging external dictionaries mapping Shakespearean words to modern English words as well as additional text. Our methods are able to get a BLEU score of 31+, an improvement of ~6 points above the strongest baseline. We publicly release our code to foster further research in this area. version:2
arxiv-1707-06699 | Local Geometry Inclusive Global Shape Representation | http://arxiv.org/abs/1707.06699 | id:1707.06699 author:Somenath Das, Suchendra M. Bhandarkar category:cs.CV  published:2017-07-20 summary:Knowledge of shape geometry plays a pivotal role in many shape analysis applications. In this paper we introduce a local geometry-inclusive global representation of 3D shapes based on computation of the shortest quasi-geodesic paths between all possible pairs of points on the 3D shape manifold. In the proposed representation, the normal curvature along the quasi-geodesic paths between any two points on the shape surface is preserved. We employ the eigenspectrum of the proposed global representation to address the problems of determination of region-based correspondence between isometric shapes and characterization of self-symmetry in the absence of prior knowledge in the form of user-defined correspondence maps. We further utilize the commutative property of the resulting shape descriptor to extract stable regions between isometric shapes that differ from one another by a high degree of isometry transformation. We also propose various shape characterization metrics in terms of the eigenvector decomposition of the shape descriptor spectrum to quantify the correspondence and self-symmetry of 3D shapes. The performance of the proposed 3D shape descriptor is experimentally compared with the performance of other relevant state-of-the-art 3D shape descriptors. version:1
arxiv-1707-06690 | DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning | http://arxiv.org/abs/1707.06690 | id:1707.06690 author:Wenhan Xiong, Thien Hoang, William Yang Wang category:cs.CL cs.AI  published:2017-07-20 summary:We study the problem of learning to reason in large scale knowledge graphs (KGs). More specifically, we describe a novel reinforcement learning framework for learning multi-hop relational paths: we use a policy-based agent with continuous states based on knowledge graph embeddings, which reasons in a KG vector space by sampling the most promising relation to extend its path. In contrast to prior work, our approach includes a reward function that takes the accuracy, diversity, and efficiency into consideration. Experimentally, we show that our proposed method outperforms a path-ranking based algorithm and knowledge graph embedding methods on Freebase and Never-Ending Language Learning datasets. version:1
arxiv-1707-06682 | Resting state fMRI functional connectivity-based classification using a convolutional neural network architecture | http://arxiv.org/abs/1707.06682 | id:1707.06682 author:Regina Meszlényi, Krisztian Buza, Zoltán Vidnyánszky category:stat.ML cs.CV cs.LG 68T99 I.5.1; I.5.2  published:2017-07-20 summary:Machine learning techniques have become increasingly popular in the field of resting state fMRI (functional magnetic resonance imaging) network based classification. However, the application of convolutional networks has been proposed only very recently and has remained largely unexplored. In this paper we describe a convolutional neural network architecture for functional connectome classification called connectome-convolutional neural network (CCNN). Our results on simulated datasets and a publicly available dataset for amnestic mild cognitive impairment classification demonstrate that our CCNN model can efficiently distinguish between subject groups. We also show that the connectome-convolutional network is capable to combine information from diverse functional connectivity metrics and that models using a combination of different connectivity descriptors are able to outperform classifiers using only one metric. From this flexibility follows that our proposed CCNN model can be easily adapted to a wide range of connectome based classification or regression tasks, by varying which connectivity descriptor combinations are used to train the network. version:1
arxiv-1707-06658 | RAIL: Risk-Averse Imitation Learning | http://arxiv.org/abs/1707.06658 | id:1707.06658 author:Anirban Santara, Abhishek Naik, Balaraman Ravindran, Dipankar Das, Dheevatsa Mudigere, Sasikanth Avancha, Bharat Kaul category:cs.LG cs.AI  published:2017-07-20 summary:Imitation learning algorithms learn viable policies by imitating an expert's behavior when reward signals are not available. Generative Adversarial Imitation Learning (GAIL) is a state-of-the-art algorithm for learning policies when the expert's behavior is available as a fixed set of trajectories. We evaluate in terms of the expert's cost function and observe that the distribution of trajectory-costs is often more heavy-tailed for GAIL-agents than the expert at a number of benchmark continuous-control tasks. Thus, high-cost trajectories, corresponding to tail-end events of catastrophic failure, are more likely to be encountered by the GAIL-agents than the expert. This makes the reliability of GAIL-agents questionable when it comes to deployment in safety-critical applications like robotic surgery and autonomous driving. In this work, we aim to minimize the occurrence of tail-end events by minimizing tail-risk within the GAIL framework. We quantify tail-risk by the Conditional-Value-at-Risk (CVaR) of trajectories and develop the Risk-Averse Imitation Learning (RAIL) algorithm. We observe that the policies learned with RAIL show lower tail-end risk than those of vanilla GAIL. Thus the proposed RAIL algorithm appears as a potent alternative to GAIL for improved reliability in safety-critical applications. version:1
arxiv-1707-06642 | The iNaturalist Challenge 2017 Dataset | http://arxiv.org/abs/1707.06642 | id:1707.06642 author:Grant Van Horn, Oisin Mac Aodha, Yang Song, Alex Shepard, Hartwig Adam, Pietro Perona, Serge Belongie category:cs.CV  published:2017-07-20 summary:Existing image classification datasets used in computer vision tend to have an even number of images for each object category. In contrast, the natural world is heavily imbalanced, as some species are more abundant and easier to photograph than others. To encourage further progress in challenging real world conditions we present the iNaturalist Challenge 2017 dataset - an image classification benchmark consisting of 675,000 images with over 5,000 different species of plants and animals. It features many visually similar species, captured in a wide variety of situations, from all over the world. Images were collected with different camera types, have varying image quality, have been verified by multiple citizen scientists, and feature a large class imbalance. We discuss the collection of the dataset and present baseline results for state-of-the-art computer vision classification models. Results show that current non-ensemble based methods achieve only 64% top one classification accuracy, illustrating the difficulty of the dataset. Finally, we report results from a competition that was held with the data. version:1
arxiv-1707-06626 | Learning to Draw Samples with Amortized Stein Variational Gradient Descent | http://arxiv.org/abs/1707.06626 | id:1707.06626 author:Yihao Feng, Dilin Wang, Qiang Liu category:stat.ML  published:2017-07-20 summary:We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient direction (Liu & Wang, 2016) that maximally decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. We demonstrate our method with a number of applications, including variational autoencoder (VAE) with expressive encoders to model complex latent space structures, and hyper-parameter learning of MCMC samplers that allows Bayesian inference to adaptively improve itself when seeing more data. version:1
arxiv-1707-06618 | Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization | http://arxiv.org/abs/1707.06618 | id:1707.06618 author:Pan Xu, Jinghui Chen, Quanquan Gu category:stat.ML cs.LG math.OC  published:2017-07-20 summary:We present a unified framework to analyze the global convergence of Langevin dynamics based algorithms for nonconvex finite-sum optimization with $n$ component functions. At the core of our analysis is a new decomposition scheme of the optimization error, under which we directly analyze the ergodicity of the numerical approximations of Langevin dynamics and prove sharp convergence rates. We establish the first global convergence guarantee of gradient Langevin dynamics (GLD) with iteration complexity $O\big(1/\epsilon \cdot\log(1/\epsilon)\big)$. In addition, we improve the convergence rate of stochastic gradient Langevin dynamics (SGLD) to the "almost minimizer", which does not depend on the undesirable uniform spectral gap introduced in previous studies. Furthermore, we for the first time prove the global convergence guarantee of variance reduced stochastic gradient Langevin dynamics (VR-SGLD) with iteration complexity $O\big(m/(B\epsilon^3)\cdot\log(1/\epsilon)\big)$, where $B$ is the mini-batch size and $m$ is the length of the inner loop. We show that the gradient complexity of VR-SGLD is $O\big(n^{1/2}/\epsilon^{3/2}\cdot\log(1/\epsilon)\big)$, which outperforms $O\big(n/\epsilon\cdot\log(1/\epsilon)\big)$ gradient complexity of GLD, when the number of component functions satisfies $n \geq 1/\epsilon$. Our theoretical analysis shed some light on using Langevin dynamics based algorithms for nonconvex optimization with provable guarantees. version:1
arxiv-1707-06613 | Decoupled classifiers for fair and efficient machine learning | http://arxiv.org/abs/1707.06613 | id:1707.06613 author:Cynthia Dwork, Nicole Immorlica, Adam Tauman Kalai, Max Leiserson category:cs.LG cs.CY  published:2017-07-20 summary:When it is ethical and legal to use a sensitive attribute (such as gender or race) in machine learning systems, the question remains how to do so. We show that the naive application of machine learning algorithms using sensitive features leads to an inherent tradeoff in accuracy between groups. We provide a simple and efficient decoupling technique, that can be added on top of any black-box machine learning algorithm, to learn different classifiers for different groups. Transfer learning is used to mitigate the problem of having too little data on any one group. The method can apply to a range of fairness criteria. In particular, we require the application designer to specify as joint loss function that makes explicit the trade-off between fairness and accuracy. Our reduction is shown to efficiently find the minimum loss as long as the objective has a certain natural monotonicity property which may be of independent interest in the study of fairness in algorithms. version:1
arxiv-1707-06611 | Prolongation of SMAP to Spatio-temporally Seamless Coverage of Continental US Using a Deep Learning Neural Network | http://arxiv.org/abs/1707.06611 | id:1707.06611 author:Kuai Fang, Chaopeng Shen, Daniel Kifer, Xiao Yang category:stat.ML  published:2017-07-20 summary:The Soil Moisture Active Passive (SMAP) mission has delivered high-qualified and valuable sensing of surface soil moisture since 2015. However, its short time span, coarse resolution, and irregular revisit schedule have limited its use. Utilizing a state-of-the-art deep-in-time neural network, Long Short-Term Memory (LSTM), we created a system that predicts SMAP level-3 soil moisture data using climate forcing, model-simulated moisture, and static physical attributes as inputs. The system removes most of the bias with model simulations and also improves predicted moisture climatology, achieving a testing accuracy of 0.025 to 0.3 in many parts of Continental United States (CONUS). As the first application of LSTM in hydrology, we show that it is more robust than simpler methods in either temporal or spatial extrapolation tests. LSTM generalizes better across regions with distinct climates and physiography by synthesizing model simulations and environmental variables. With high fidelity to SMAP products, our data can aid various applications including data assimilation and weather forecasting. version:1
arxiv-1707-06600 | A multi-agent reinforcement learning model of common-pool resource appropriation | http://arxiv.org/abs/1707.06600 | id:1707.06600 author:Julien Perolat, Joel Z. Leibo, Vinicius Zambaldi, Charles Beattie, Karl Tuyls, Thore Graepel category:cs.MA cs.NE q-bio.PE  published:2017-07-20 summary:Humanity faces numerous problems of common-pool resource appropriation. This class of multi-agent social dilemma includes the problems of ensuring sustainable use of fresh water, common fisheries, grazing pastures, and irrigation systems. Abstract models of common-pool resource appropriation based on non-cooperative game theory predict that self-interested agents will generally fail to find socially positive equilibria---a phenomenon called the tragedy of the commons. However, in reality, human societies are sometimes able to discover and implement stable cooperative solutions. Decades of behavioral game theory research have sought to uncover aspects of human behavior that make this possible. Most of that work was based on laboratory experiments where participants only make a single choice: how much to appropriate. Recognizing the importance of spatial and temporal resource dynamics, a recent trend has been toward experiments in more complex real-time video game-like environments. However, standard methods of non-cooperative game theory can no longer be used to generate predictions for this case. Here we show that deep reinforcement learning can be used instead. To that end, we study the emergent behavior of groups of independently learning agents in a partially observed Markov game modeling common-pool resource appropriation. Our experiments highlight the importance of trial-and-error learning in common-pool resource appropriation and shed light on the relationship between exclusion, sustainability, and inequality. version:1
arxiv-1707-06598 | Toward Incorporation of Relevant Documents in word2vec | http://arxiv.org/abs/1707.06598 | id:1707.06598 author:Navid Rekabsaz, Bhaskar Mitra, Mihai Lupu, Allan Hanbury category:cs.IR cs.CL  published:2017-07-20 summary:Recent advances in neural word embedding provide significant benefit to various information retrieval tasks. However as shown by recent studies, adapting the embedding models for the needs of IR tasks can bring considerable further improvements. The embedding models in general define the term relatedness by exploiting the terms' co-occurrences in short-window contexts. An alternative (and well-studied) approach in IR for related terms to a query is using local information i.e. a set of top-retrieved documents. In view of these two methods of term relatedness, in this work, we report our study on incorporating the local information of the query in the word embeddings. One main challenge in this direction is that the dense vectors of word embeddings and their estimation of term-to-term relatedness remain difficult to interpret and hard to analyze. As an alternative, explicit word representations propose vectors whose dimensions are easily interpretable, and recent methods show competitive performance to the dense vectors. We introduce a neural-based explicit representation, rooted in the conceptual ideas of the word2vec Skip-Gram model. The method provides interpretable explicit vectors while keeping the effectiveness of the Skip-Gram model. The evaluation of various explicit representations on word association collections shows that the newly proposed method out- performs the state-of-the-art explicit representations when tasked with ranking highly similar terms. Based on the introduced ex- plicit representation, we discuss our approaches on integrating local documents in globally-trained embedding models and discuss the preliminary results. version:1
arxiv-1705-05627 | Picasso: A Modular Framework for Visualizing the Learning Process of Neural Network Image Classifiers | http://arxiv.org/abs/1705.05627 | id:1705.05627 author:Ryan Henderson, Rasmus Rothe category:cs.CV cs.SE  published:2017-05-16 summary:Picasso is a free open-source (Eclipse Public License) web application written in Python for rendering standard visualizations useful for analyzing convolutional neural networks. Picasso ships with occlusion maps and saliency maps, two visualizations which help reveal issues that evaluation metrics like loss and accuracy might hide: for example, learning a proxy classification task. Picasso works with the Tensorflow deep learning framework, and Keras (when the model can be loaded into the Tensorflow backend). Picasso can be used with minimal configuration by deep learning researchers and engineers alike across various neural network architectures. Adding new visualizations is simple: the user can specify their visualization code and HTML template separately from the application code. version:2
arxiv-1707-06588 | Voice Synthesis for in-the-Wild Speakers via a Phonological Loop | http://arxiv.org/abs/1707.06588 | id:1707.06588 author:Yaniv Taigman, Lior Wolf, Adam Polyak, Eliya Nachmani category:cs.LG cs.CL cs.SD  published:2017-07-20 summary:We present a new neural text to speech method that is able to transform text to speech in voices that are sampled in the wild. Unlike other text to speech systems, our solution is able to deal with unconstrained samples obtained from public speeches. The network architecture is simpler than those in the existing literature and is based on a novel shifting buffer working memory. The same buffer is used for estimating the attention, computing the output audio, and for updating the buffer itself. The input sentence is encoded using a context-free lookup table that contains one entry per character or phoneme. Lastly, the speakers are similarly represented by a short vector that can also be fitted to new speakers and variability in the generated speech is achieved by priming the buffer prior to generating the audio. Experimental results on two datasets demonstrate convincing multi-speaker and in-the-wild capabilities. In order to promote reproducibility, we release our source code and models: PyTorch code and sample audio files are available at ytaigman.github.io/loop. version:1
arxiv-1707-06573 | Structural Learning and Integrative Decomposition of Multi-View Data | http://arxiv.org/abs/1707.06573 | id:1707.06573 author:Irina Gaynanova, Gen Li category:stat.ML stat.ME  published:2017-07-20 summary:The increased availability of the multi-view data (data on the same samples from multiple sources) has led to strong interest in models based on low-rank matrix factorizations. These models represent each data view via shared and individual components, and have been successfully applied for exploratory dimension reduction, association analysis between the views, and further learning tasks such as consensus clustering. Despite these advances, there remain significant challenges in modeling partially-shared components, and identifying the number of components of each type (shared/partially-shared/individual). In this work, we formulate a novel linked component model that directly incorporates partially-shared structures. We call this model SLIDE for Structural Learning and Integrative DEcomposition of multi-view data. We prove the existence of SLIDE decomposition and explicitly characterize the identifiability conditions. The proposed model fitting and selection techniques allow for joint identification of the number of components of each type, in contrast to existing sequential approaches. In our empirical studies, SLIDE demonstrates excellent performance in both signal estimation and component selection. We further illustrate the methodology on the breast cancer data from The Cancer Genome Atlas repository. version:1
arxiv-1707-06563 | Pictures of Combinatorial Cubes | http://arxiv.org/abs/1707.06563 | id:1707.06563 author:André Wagner category:cs.CV  published:2017-07-20 summary:We prove that the 8-point algorithm always fails to reconstruct a unique fundamental matrix $F$ independent on the camera positions, when its input are image point configurations that are perspective projections of the vertices of a combinatorial cube in $\mathbb{R}^3$. We give an algorithm that improves the 7- and 8-point algorithm in such a pathological situation. Additionally we analyze the regions of focal point positions where a reconstruction of $F$ is possible at all, when the world points are the vertices of a combinatorial cube in $\mathbb{R}^3$. version:1
arxiv-1707-06562 | From Task Classification Towards Similarity Measures for Recommendation in Crowdsourcing Systems | http://arxiv.org/abs/1707.06562 | id:1707.06562 author:Steffen Schnitzer, Svenja Neitzel, Christoph Rensing category:cs.IR cs.CL  published:2017-07-20 summary:Task selection in micro-task markets can be supported by recommender systems to help individuals to find appropriate tasks. Previous work showed that for the selection process of a micro-task the semantic aspects, such as the required action and the comprehensibility, are rated more important than factual aspects, such as the payment or the required completion time. This work gives a foundation to create such similarity measures. Therefore, we show that an automatic classification based on task descriptions is possible. Additionally, we propose similarity measures to cluster micro-tasks according to semantic aspects. version:1
arxiv-1707-06557 | leave a trace - A People Tracking System Meets Anomaly Detection | http://arxiv.org/abs/1707.06557 | id:1707.06557 author:Dominik Rueß, Konstantinos Amplianitis, Niklas Deckers, Michele Adduci, Kristian Manthey, Ralf Reulke category:cs.CV cs.MM  published:2017-07-20 summary:Video surveillance always had a negative connotation, among others because of the loss of privacy and because it may not automatically increase public safety. If it was able to detect atypical (i.e. dangerous) situations in real time, autonomously and anonymously, this could change. A prerequisite for this is a reliable automatic detection of possibly dangerous situations from video data. This is done classically by object extraction and tracking. From the derived trajectories, we then want to determine dangerous situations by detecting atypical trajectories. However, due to ethical considerations it is better to develop such a system on data without people being threatened or even harmed, plus with having them know that there is such a tracking system installed. Another important point is that these situations do not occur very often in real, public CCTV areas and may be captured properly even less. In the artistic project leave a trace the tracked objects, people in an atrium of a institutional building, become actor and thus part of the installation. Visualisation in real-time allows interaction by these actors, which in turn creates many atypical interaction situations on which we can develop our situation detection. The data set has evolved over three years and hence, is huge. In this article we describe the tracking system and several approaches for the detection of atypical trajectories. version:1
arxiv-1707-06556 | High-risk learning: acquiring new word vectors from tiny data | http://arxiv.org/abs/1707.06556 | id:1707.06556 author:Aurelie Herbelot, Marco Baroni category:cs.CL cs.LG  published:2017-07-20 summary:Distributional semantics models are known to struggle with small data. It is generally accepted that in order to learn 'a good vector' for a word, a model must have sufficient examples of its usage. This contradicts the fact that humans can guess the meaning of a word from a few occurrences only. In this paper, we show that a neural language model such as Word2Vec only necessitates minor modifications to its standard architecture to learn new terms from tiny data, using background knowledge from a previously learnt semantic space. We test our model on word definitions and on a nonce task involving 2-6 sentences' worth of context, showing a large increase in performance over state-of-the-art models on the definitional task. version:1
arxiv-1609-08035 | Connecting the dots across time: Reconstruction of single cell signaling trajectories using time-stamped data | http://arxiv.org/abs/1609.08035 | id:1609.08035 author:Sayak Mukherjee, David Stewart, William Stewart, Lewis L. Lanier, Jayajit Das category:q-bio.QM cond-mat.stat-mech cs.CG cs.CV  published:2016-09-26 summary:Single cell responses are shaped by the geometry of signaling kinetic trajectories carved in a multidimensional space spanned by signaling protein abundances. It is however challenging to assay large number (>3) of signaling species in live-cell imaging which makes it difficult to probe single cell signaling kinetic trajectories in large dimensions. Flow and mass cytometry techniques can measure a large number (4 - >40) of signaling species but are unable to track single cells. Thus cytometry experiments provide detailed time stamped snapshots of single cell signaling kinetics. Is it possible to use the time stamped cytometry data to reconstruct single cell signaling trajectories? Borrowing concepts of conserved and slow variables from non-equilibrium statistical physics we develop an approach to reconstruct signaling trajectories using snapshot data by creating new variables that remain invariant or vary slowly during the signaling kinetics. We apply this approach to reconstruct trajectories using snapshot data obtained from in silico simulations and live-cell imaging measurements. The use of invariants and slow variables to reconstruct trajectories provides a radically different way to track object using snapshot data. The approach is likely to have implications for solving matching problems in a wide range of disciplines. version:2
arxiv-1707-06545 | Video Object Segmentation using Tracked Object Proposals | http://arxiv.org/abs/1707.06545 | id:1707.06545 author:Gilad Sharir, Eddie Smolyansky, Itamar Friedman category:cs.CV  published:2017-07-20 summary:We present an approach to semi-supervised video object segmentation, in the context of the DAVIS 2017 challenge. Our approach combines category-based object detection, category-independent object appearance segmentation and temporal object tracking. We are motivated by the fact that the objects semantic category tends not to change throughout the video while its appearance and location can vary considerably. In order to capture the specific object appearance independent of its category, for each video we train a fully convolutional network using augmentations of the given annotated frame. We refine the appearance segmentation mask with the bounding boxes provided either by a semantic object detection network, when applicable, or by a previous frame prediction. By introducing a temporal continuity constraint on the detected boxes, we are able to improve the object segmentation mask of the appearance network and achieve competitive results on the DAVIS datasets. version:1
arxiv-1707-06543 | An All-in-One Network for Dehazing and Beyond | http://arxiv.org/abs/1707.06543 | id:1707.06543 author:Boyi Li, Xiulian Peng, Zhangyang Wang, Jizheng Xu, Dan Feng category:cs.CV cs.AI  published:2017-07-20 summary:This paper proposes an image dehazing model built with a convolutional neural network (CNN), called All-in-One Dehazing Network (AOD-Net). It is designed based on a re-formulated atmospheric scattering model. Instead of estimating the transmission matrix and the atmospheric light separately as most previous models did, AOD-Net directly generates the clean image through a light-weight CNN. Such a novel end-to-end design makes it easy to embed AOD-Net into other deep models, e.g., Faster R-CNN, for improving high-level task performance on hazy images. Experimental results on both synthesized and natural hazy image datasets demonstrate our superior performance than the state-of-the-art in terms of PSNR, SSIM and the subjective visual quality. Furthermore, when concatenating AOD-Net with Faster R-CNN and training the joint pipeline from end to end, we witness a large improvement of the object detection performance on hazy images. version:1
arxiv-1707-06487 | A Nonlinear Kernel Support Matrix Machine for Matrix Learning | http://arxiv.org/abs/1707.06487 | id:1707.06487 author:Yunfei Ye category:stat.ML cs.LG  published:2017-07-20 summary:Tensor is a natural and compact representation for real world data which are often multi-dimensional. Meanwhile, problems of supervised tensor learning (STL) are commonly encountered in applications. Most existing classifiers based on tensor representation, such as support tensor machine (STM) need to solve iteratively which occupy much time and may suffer from local minima. In this paper, we present a kernel support matrix machine (KSMM) connected with the matrix Hilbert space to perform supervised learning when data are represented as matrices. KSMM is a general framework for constructing matrix-based hyperplane to exploit information. We analyze a unifying optimization problem for which we propose an asymptotically convergent algorithm. The goal is to both determine the hyperplane as well as predict the unlabeled samples. Theoretical analysis for the generalization bounds is derived based on Rademacher complexity with respect to a probability distribution. We demonstrate the merits of the proposed method by exhaustive experiments on simulation study and a number of real-word datasets from a variety of application domains. version:1
arxiv-1707-06484 | Deep Layer Aggregation | http://arxiv.org/abs/1707.06484 | id:1707.06484 author:Fisher Yu, Dequan Wang, Trevor Darrell category:cs.CV cs.LG  published:2017-07-20 summary:Convolutional networks have had great success in image classification and other areas of computer vision. Recent efforts have designed deeper or wider networks to improve performance; as convolutional blocks are usually stacked together, blocks at different depths represent information at different scales. Recent models have explored `skip' connections to aggregate information across layers, but heretofore such skip connections have themselves been `shallow', projecting to a single fusion node. In this paper, we investigate new deep-across-layer architectures to aggregate the information from multiple layers. We propose novel iterative and hierarchical structures for deep layer aggregation. The former can produce deep high resolution representations from a network whose final layers have low resolution, while the latter can effectively combine scale information from all blocks. Results show that the our proposed architectures can make use of network parameters and features more efficiently without dictating convolution module structure. We also show transfer of the learned networks to semantic segmentation tasks and achieve better results than alternative networks with baseline training settings. version:1
arxiv-1707-06480 | Syllable-aware Neural Language Models: A Failure to Beat Character-aware Ones | http://arxiv.org/abs/1707.06480 | id:1707.06480 author:Zhenisbek Assylbekov, Rustem Takhanov, Bagdat Myrzakhmetov, Jonathan N. Washington category:cs.CL cs.NE stat.ML 68T50 I.2.7  published:2017-07-20 summary:Syllabification does not seem to improve word-level RNN language modeling quality when compared to character-based segmentation. However, our best syllable-aware language model, achieving performance comparable to the competitive character-aware model, has 18%-33% fewer parameters and is trained 1.2-2.2 times faster. version:1
arxiv-1707-06476 | The inflation technique solves completely the classical inference problem | http://arxiv.org/abs/1707.06476 | id:1707.06476 author:Miguel Navascues, Elie Wolfe category:quant-ph math.ST stat.ME stat.ML stat.TH  published:2017-07-20 summary:The causal inference problem consists in determining whether a probability distribution over a set of observed variables is compatible with a given causal structure. In [arXiv:1609.00672], one of us introduced a hierarchy of necessary linear programming constraints which all the observed distributions compatible with the considered causal structure must satisfy. In this work, we prove that the inflation hierarchy is complete, i.e., any distribution of the observed variables which does not admit a realization within the considered causal structure will fail one of the inflation tests. More quantitatively, we show that any distribution of measurable events satisfying the $n^{th}$ inflation test is $O\left(\frac{1}{\sqrt{n}}\right)$-close in Euclidean norm to a distribution realizable within the given causal structure. In addition, we show that the corresponding $n^{th}$-order relaxation of the dual problem consisting in maximizing a $k^{th}$ degree polynomial on the observed variables is $O\left(\frac{k^2}{n}\right)$-close to the optimal solution. version:1
arxiv-1707-06474 | Learned Primal-dual Reconstruction | http://arxiv.org/abs/1707.06474 | id:1707.06474 author:Jonas Adler, Ozan Öktem category:math.OC cs.CV cs.NE math.FA  published:2017-07-20 summary:We propose a Learned Primal-Dual algorithm for tomographic reconstruction. The algorithm includes the (possibly non-linear) forward operator in a deep neural network inspired by unrolled proximal primal-dual optimization methods, but where the proximal operators have been replaced with convolutional neural networks. The algorithm is trained end-to-end, working directly from raw measured data and does not depend on any initial reconstruction such as FBP. We evaluate the algorithm on low dose CT reconstruction using both analytic and human phantoms against classical reconstruction given by FBP and TV regularized reconstruction as well as deep learning based post-processing of a FBP reconstruction. For the analytic data we demonstrate PSNR improvements of >10 dB when compared to both TV reconstruction and learned post-processing. For the human phantom we demonstrate a 6.6 dB improvement compared to TV and a 2.2 dB improvement as compared to learned post-processing. The proposed algorithm also improves upon the compared algorithms with respect to the SSIM and the evaluation time is approximately 600 ms for a 512 x 512 pixel dataset. version:1
arxiv-1707-06456 | Revisiting Selectional Preferences for Coreference Resolution | http://arxiv.org/abs/1707.06456 | id:1707.06456 author:Benjamin Heinzerling, Nafise Sadat Moosavi, Michael Strube category:cs.CL  published:2017-07-20 summary:Selectional preferences have long been claimed to be essential for coreference resolution. However, they are mainly modeled only implicitly by current coreference resolvers. We propose a dependency-based embedding model of selectional preferences which allows fine-grained compatibility judgments with high coverage. We show that the incorporation of our model improves coreference resolution performance on the CoNLL dataset, matching the state-of-the-art results of a more complex system. However, it comes with a cost that makes it debatable how worthwhile such improvements are. version:1
arxiv-1706-05656 | Lexical representation explains cortical entrainment during speech comprehension | http://arxiv.org/abs/1706.05656 | id:1706.05656 author:Stefan Frank, Jinbiao Yang category:q-bio.NC cs.CL  published:2017-06-18 summary:Results from a recent neuroimaging study on spoken sentence comprehension have been interpreted as evidence for cortical entrainment to hierarchical syntactic structure. We present a simple computational model that predicts the power spectra from this study, even though the model's linguistic knowledge is restricted to the lexical level, and word-level representations are not combined into higher-level units (phrases or sentences). Hence, the cortical entrainment results can also be explained from the lexical properties of the stimuli, without recourse to hierarchical syntax. version:3
arxiv-1707-06440 | A Novel Space-Time Representation on the Positive Semidefinite Con for Facial Expression Recognition | http://arxiv.org/abs/1707.06440 | id:1707.06440 author:Anis Kacem, Mohamed Daoudi, Boulbaba Ben Amor, Juan Carlos Alvarez-Paiva category:cs.CV  published:2017-07-20 summary:In this paper, we study the problem of facial expression recognition using a novel space-time geometric representation. We describe the temporal evolution of facial landmarks as parametrized trajectories on the Riemannian manifold of positive semidefinite matrices of fixed-rank. Our representation has the advantage to bring naturally a second desirable quantity when comparing shapes -- the spatial covariance -- in addition to the conventional affine-shape representation. We derive then geometric and computational tools for rate-invariant analysis and adaptive re-sampling of trajectories, grounding on the Riemannian geometry of the manifold. Specifically, our approach involves three steps: 1) facial landmarks are first mapped into the Riemannian manifold of positive semidefinite matrices of rank 2, to build time-parameterized trajectories; 2) a temporal alignment is performed on the trajectories, providing a geometry-aware (dis-)similarity measure between them; 3) finally, pairwise proximity function SVM (ppfSVM) is used to classify them, incorporating the latter (dis-)similarity measure into the kernel function. We show the effectiveness of the proposed approach on four publicly available benchmarks (CK+, MMI, Oulu-CASIA, and AFEW). The results of the proposed approach are comparable to or better than the state-of-the-art methods when involving only facial landmarks. version:1
arxiv-1707-06436 | cvpaper.challenge in 2016: Futuristic Computer Vision through 1,600 Papers Survey | http://arxiv.org/abs/1707.06436 | id:1707.06436 author:Hirokatsu Kataoka, Soma Shirakabe, Yun He, Shunya Ueta, Teppei Suzuki, Kaori Abe, Asako Kanezaki, Shin'ichiro Morita, Toshiyuki Yabe, Yoshihiro Kanehara, Hiroya Yatsuyanagi, Shinya Maruyama, Ryosuke Takasawa, Masataka Fuchida, Yudai Miyashita, Kazushige Okayasu, Yuta Matsuzaki category:cs.CV  published:2017-07-20 summary:The paper gives futuristic challenges disscussed in the cvpaper.challenge. In 2015 and 2016, we thoroughly study 1,600+ papers in several conferences/journals such as CVPR/ICCV/ECCV/NIPS/PAMI/IJCV. version:1
arxiv-1707-06427 | Scalable Full Flow with Learned Binary Descriptors | http://arxiv.org/abs/1707.06427 | id:1707.06427 author:Gottfried Munda, Alexander Shekhovtsov, Patrick Knöbelreiter, Thomas Pock category:cs.CV  published:2017-07-20 summary:We propose a method for large displacement optical flow in which local matching costs are learned by a convolutional neural network (CNN) and a smoothness prior is imposed by a conditional random field (CRF). We tackle the computation- and memory-intensive operations on the 4D cost volume by a min-projection which reduces memory complexity from quadratic to linear and binary descriptors for efficient matching. This enables evaluation of the cost on the fly and allows to perform learning and CRF inference on high resolution images without ever storing the 4D cost volume. To address the problem of learning binary descriptors we propose a new hybrid learning scheme. In contrast to current state of the art approaches for learning binary CNNs we can compute the exact non-zero gradient within our model. We compare several methods for training binary descriptors and show results on public available benchmarks. version:1
arxiv-1707-06426 | Semantic Segmentation with Reverse Attention | http://arxiv.org/abs/1707.06426 | id:1707.06426 author:Qin Huang, Chunyang Xia, Chihao Wu, Siyang Li, Ye Wang, Yuhang Song, C. -C. Jay Kuo category:cs.CV  published:2017-07-20 summary:Recent development in fully convolutional neural network enables efficient end-to-end learning of semantic segmentation. Traditionally, the convolutional classifiers are taught to learn the representative semantic features of labeled semantic objects. In this work, we propose a reverse attention network (RAN) architecture that trains the network to capture the opposite concept (i.e., what are not associated with a target class) as well. The RAN is a three-branch network that performs the direct, reverse and reverse-attention learning processes simultaneously. Extensive experiments are conducted to show the effectiveness of the RAN in semantic segmentation. Being built upon the DeepLabv2-LargeFOV, the RAN achieves the state-of-the-art mIoU score (48.1%) for the challenging PASCAL-Context dataset. Significant performance improvements are also observed for the PASCAL-VOC, Person-Part, NYUDv2 and ADE20K datasets. version:1
arxiv-1707-06422 | Causal Transfer Learning | http://arxiv.org/abs/1707.06422 | id:1707.06422 author:Sara Magliacane, Thijs van Ommen, Tom Claassen, Stephan Bongers, Philip Versteeg, Joris M. Mooij category:cs.LG stat.ML  published:2017-07-20 summary:An important goal in both transfer learning and causal inference is to make accurate predictions when the distribution of the test set and the training set(s) differ. Such a distribution shift may happen as a result of an external intervention on the data generating process, causing certain aspects of the distribution to change, and others to remain invariant. We consider a class of causal transfer learning problems, where multiple training sets are given that correspond to different external interventions, and the task is to predict the distribution of a target variable given measurements of other variables for a new (yet unseen) intervention on the system. We propose a method for solving these problems that exploits causal reasoning but does neither rely on prior knowledge of the causal graph, nor on the the type of interventions and their targets. We evaluate the method on simulated and real world data and find that it outperforms a standard prediction method that ignores the distribution shift. version:1
arxiv-1707-00372 | Deep Convolutional Framelets: A General Deep Learning for Inverse Problems | http://arxiv.org/abs/1707.00372 | id:1707.00372 author:Jong Chul Ye, Yo Seob Han category:stat.ML cs.CV cs.IT cs.LG math.IT  published:2017-07-03 summary:Recently, deep learning approaches have achieved significant performance improvement in various imaging problems. However, it is still unclear why these deep learning architectures work. Moreover, the link between the deep learning and the classical signal processing approaches such as wavelet, non-local processing, compressed sensing, etc, is still not well understood, which often makes signal processors in deep troubles. To address these issues, here we show that the long-searched-for missing link is the convolutional framelets for representing a signal by convolving local and non-local bases. The convolutional framelets was originally developed to generalize the recent theory of low-rank Hankel matrix approaches, and this paper significantly extends the idea to derive a deep neural network using multi-layer convolutional framelets with perfect reconstruction (PR) under rectified linear unit (ReLU). Our analysis also shows that the popular deep network components such as residual block, redundant filter channels, and concatenated ReLU (CReLU) indeed help to achieve the PR, while the pooling and unpooling layers should be augmented with multi-resolution convolutional framelets to achieve PR condition. This discovery reveals the limitations of many existing deep learning architectures for inverse problems, and leads us to propose a novel deep convolutional framelets neural network. Using numerical experiments with sparse view x-ray computed tomography (CT), we demonstrated that our deep convolution framelets network shows consistent improvement. This discovery suggests that the success of deep learning is not from a magical power of a black-box, but rather comes from the power of a novel signal representation using non-local basis combined with data-driven local basis, which is indeed a natural extension of classical signal processing theory. version:2
arxiv-1707-02530 | Deep CNN Framework for Audio Event Recognition using Weakly Labeled Web Data | http://arxiv.org/abs/1707.02530 | id:1707.02530 author:Anurag Kumar, Bhiksha Raj category:cs.SD cs.LG cs.MM  published:2017-07-09 summary:The development of audio event recognition models requires labeled training data, which are generally hard to obtain. One promising source of recordings of audio events is the large amount of multimedia data on the web. In particular, if the audio content analysis must itself be performed on web audio, it is important to train the recognizers themselves from such data. Training from these web data, however, poses several challenges, the most important being the availability of labels : labels, if any, that may be obtained for the data are generally {\em weak}, and not of the kind conventionally required for training detectors or classifiers. We propose that learning algorithms that can exploit weak labels offer an effective method to learn from web data. We then propose a robust and efficient deep convolutional neural network (CNN) based framework to learn audio event recognizers from weakly labeled data. The proposed method can train from and analyze recordings of variable length in an efficient manner and outperforms a network trained with {\em strongly labeled} web data by a considerable margin. version:2
arxiv-1707-06399 | Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors | http://arxiv.org/abs/1707.06399 | id:1707.06399 author:Hong-Yu Zhou, Bin-Bin Gao, Jianxin Wu category:cs.CV  published:2017-07-20 summary:Object detection aims at high speed and accuracy simultaneously. However, fast models are usually less accurate, while accurate models cannot satisfy our need for speed. A fast model can be 10 times faster but 50\% less accurate than an accurate model. In this paper, we propose Adaptive Feeding (AF) to combine a fast (but less accurate) detector and an accurate (but slow) detector, by adaptively determining whether an image is easy or hard and choosing an appropriate detector for it. In practice, we build a cascade of detectors, including the AF classifier which make the easy vs. hard decision and the two detectors. The AF classifier can be tuned to obtain different tradeoff between speed and accuracy, which has negligible training time and requires no additional training data. Experimental results on the PASCAL VOC, MS COCO and Caltech Pedestrian datasets confirm that AF has the ability to achieve comparable speed as the fast detector and comparable accuracy as the accurate one at the same time. As an example, by combining the fast SSD300 with the accurate SSD500 detector, AF leads to 50\% speedup over SSD500 with the same precision on the VOC2007 test set. version:1
arxiv-1707-06397 | Unsupervised Object Discovery and Co-Localization by Deep Descriptor Transforming | http://arxiv.org/abs/1707.06397 | id:1707.06397 author:Xiu-Shen Wei, Chen-Lin Zhang, Jianxin Wu, Chunhua Shen, Zhi-Hua Zhou category:cs.CV  published:2017-07-20 summary:Reusable model design becomes desirable with the rapid expansion of computer vision and machine learning applications. In this paper, we focus on the reusability of pre-trained deep convolutional models. Specifically, different from treating pre-trained models as feature extractors, we reveal more treasures beneath convolutional layers, i.e., the convolutional activations could act as a detector for the common object in the image co-localization problem. We propose a simple yet effective method, termed Deep Descriptor Transforming (DDT), for evaluating the correlations of descriptors and then obtaining the category-consistent regions, which can accurately locate the common object in a set of unlabeled images, i.e., unsupervised object discovery. Empirical studies validate the effectiveness of the proposed DDT method. On benchmark image co-localization datasets, DDT consistently outperforms existing state-of-the-art methods by a large margin. Moreover, DDT also demonstrates good generalization ability for unseen categories and robustness for dealing with noisy data. Beyond those, DDT can be also employed for harvesting web images into valid external data sources for improving performance of both image recognition and object detection. version:1
arxiv-1707-00536 | Robust Cost-Sensitive Learning for Recommendation with Implicit Feedback | http://arxiv.org/abs/1707.00536 | id:1707.00536 author:Peng Yang, Peilin Zhao, Xin Gao, Yong Liu category:cs.LG cs.IR stat.ML  published:2017-07-03 summary:Recommendation is the task of improving customer experience through personalized recommendation based on users' past feedback. In this paper, we investigate the most common scenario: the user-item (U-I) matrix of implicit feedback. Even though many recommendation approaches are designed based on implicit feedback, they attempt to project the U-I matrix into a low-rank latent space, which is a strict restriction that rarely holds in practice. In addition, although misclassification costs from imbalanced classes are significantly different, few methods take the cost of classification error into account. To address aforementioned issues, we propose a robust framework by decomposing the U-I matrix into two components: (1) a low-rank matrix that captures the common preference, and (2) a sparse matrix that detects the user-specific preference of individuals. A cost-sensitive learning model is embedded into the framework. Specifically, this model exploits different costs in the loss function for the observed and unobserved instances. We show that the resulting non-smooth convex objective can be optimized efficiently by an accelerated projected gradient method with closed-form solutions. Morever, the proposed algorithm can be scaled up to large-sized datasets after a relaxation. The theoretical result shows that even with a small fraction of 1's in the U-I matrix $M\in\mathbb{R}^{n\times m}$, the cost-sensitive error of the proposed model is upper bounded by $O(\frac{\alpha}{\sqrt{mn}})$, where $\alpha$ is a bias over imbalanced classes. Finally, empirical experiments are extensively carried out to evaluate the effectiveness of our proposed algorithm. Encouraging experimental results show that our algorithm outperforms several state-of-the-art algorithms on benchmark recommendation datasets. version:2
arxiv-1707-06386 | Bridging the Gap between Constant Step Size Stochastic Gradient Descent and Markov Chains | http://arxiv.org/abs/1707.06386 | id:1707.06386 author:Aymeric Dieuleveut, Alain Durmus, Francis Bach category:stat.ML math.OC  published:2017-07-20 summary:We consider the minimization of an objective function given access to unbiased estimates of its gradient through stochastic gradient descent (SGD) with constant step-size. While the detailed analysis was only performed for quadratic functions, we provide an explicit asymptotic expansion of the moments of the averaged SGD iterates that outlines the dependence on initial conditions, the effect of noise and the step-size, as well as the lack of convergence in the general (non-quadratic) case. For this analysis, we bring tools from Markov chain theory into the analysis of stochastic gradient and create new ones (similar but different from stochastic MCMC methods). We then show that Richardson-Romberg extrapolation may be used to get closer to the global optimum and we show empirical improvements of the new extrapolation scheme. version:1
arxiv-1707-06381 | Adaptive Learning Rule for Hardware-based Deep Neural Networks Using Electronic Synapse Devices | http://arxiv.org/abs/1707.06381 | id:1707.06381 author:Suhwan Lim, Jong-Ho Bae, Jai-Ho Eum, Sungtae Lee, Chul-Heung Kim, Byung-Gook Park, Jong-Ho Lee category:cs.NE cs.ET  published:2017-07-20 summary:In this paper, we propose a way for designing a power efficient and high speed deep neural networks (DNNs) based on hardware electronic synapse devices. A learning rule based on a back-propagation (BP) algorithm is proposed to implement a hardware-based neural network (HW-DNN) using electronic devices that exhibit discrete and limited conductance characteristics. Then, using a 3-layer perceptron network, we evaluate the learning performance according to the various conductance responses of the electronic synapse devices and the weight update methods. It is shown that the learning accuracy can be comparable to that obtained by using software-based BP algorithm when the electronic synapse device has the linear and symmetric conductance response. Furthermore, the proposed unidirectional weight update method is suitable for electronic synapse devices which have nonlinear and asymmetric conductance response. Because the unidirectional weight update method can cancel the effect of asymmetric conductance response, the better accuracy can be obtained. version:1
arxiv-1707-06378 | Large-Scale Goodness Polarity Lexicons for Community Question Answering | http://arxiv.org/abs/1707.06378 | id:1707.06378 author:Todor Mihaylov, Daniel Belchev, Yasen Kiprov, Ivan Koychev, Preslav Nakov category:cs.CL  published:2017-07-20 summary:We transfer a key idea from the field of sentiment analysis to a new domain: community question answering (cQA). The cQA task we are interested in is the following: given a question and a thread of comments, we want to re-rank the comments so that the ones that are good answers to the question would be ranked higher than the bad ones. We notice that good vs. bad comments use specific vocabulary and that one can often predict the goodness/badness of a comment even ignoring the question, based on the comment contents only. This leads us to the idea to build a good/bad polarity lexicon as an analogy to the positive/negative sentiment polarity lexicons, commonly used in sentiment analysis. In particular, we use pointwise mutual information in order to build large-scale goodness polarity lexicons in a semi-supervised manner starting with a small number of initial seeds. The evaluation results show an improvement of 0.7 MAP points absolute over a very strong baseline and state-of-the art performance on SemEval-2016 Task 3. version:1
arxiv-1707-06053 | Modeling the Intra-class Variability for Liver Lesion Detection using a Multi-class Patch-based CNN | http://arxiv.org/abs/1707.06053 | id:1707.06053 author:Maayan Frid-Adar, Idit Diamant, Eyal Klang, Michal Amitai, Jacob Goldberger, Hayit Greenspan category:cs.CV  published:2017-07-19 summary:Automatic detection of liver lesions in CT images poses a great challenge for researchers. In this work we present a deep learning approach that models explicitly the variability within the non-lesion class, based on prior knowledge of the data, to support an automated lesion detection system. A multi-class convolutional neural network (CNN) is proposed to categorize input image patches into sub-categories of boundary and interior patches, the decisions of which are fused to reach a binary lesion vs non-lesion decision. For validation of our system, we use CT images of 132 livers and 498 lesions. Our approach shows highly improved detection results that outperform the state-of-the-art fully convolutional network. Automated computerized tools, as shown in this work, have the potential in the future to support the radiologists towards improved detection. version:2
arxiv-1707-06366 | RKL: a general, invariant Bayes solution for Neyman-Scott | http://arxiv.org/abs/1707.06366 | id:1707.06366 author:Michael Brand category:stat.ML 62F10  62F15 G.3  published:2017-07-20 summary:Neyman-Scott is a classic example of an estimation problem with a partially-consistent posterior, for which standard estimation methods tend to produce inconsistent results. Past attempts to create consistent estimators for Neyman-Scott have led to ad-hoc solutions, to estimators that do not satisfy representation invariance, to restrictions over the choice of prior and more. We present a simple construction for a general-purpose Bayes estimator, invariant to representation, which satisfies consistency on Neyman-Scott over any non-degenerate prior. We argue that the good attributes of the estimator are due to its intrinsic properties, and generalise beyond Neyman-Scott as well. version:1
arxiv-1707-06357 | Improving Discourse Relation Projection to Build Discourse Annotated Corpora | http://arxiv.org/abs/1707.06357 | id:1707.06357 author:Majid Laali, Leila Kosseim category:cs.CL  published:2017-07-20 summary:The naive approach to annotation projection is not effective to project discourse annotations from one language to another because implicit discourse relations are often changed to explicit ones and vice-versa in the translation. In this paper, we propose a novel approach based on the intersection between statistical word-alignment models to identify unsupported discourse annotations. This approach identified 65% of the unsupported annotations in the English-French parallel sentences from Europarl. By filtering out these unsupported annotations, we induced the first PDTB-style discourse annotated corpus for French from Europarl. We then used this corpus to train a classifier to identify the discourse-usage of French discourse connectives and show a 15% improvement of F1-score compared to the classifier trained on the non-filtered annotations. version:1
arxiv-1707-06355 | Video Question Answering via Attribute-Augmented Attention Network Learning | http://arxiv.org/abs/1707.06355 | id:1707.06355 author:Yunan Ye, Zhou Zhao, Yimeng Li, Long Chen, Jun Xiao, Yueting Zhuang category:cs.CV cs.AI cs.CL  published:2017-07-20 summary:Video Question Answering is a challenging problem in visual information retrieval, which provides the answer to the referenced video content according to the question. However, the existing visual question answering approaches mainly tackle the problem of static image question, which may be ineffectively for video question answering due to the insufficiency of modeling the temporal dynamics of video contents. In this paper, we study the problem of video question answering by modeling its temporal dynamics with frame-level attention mechanism. We propose the attribute-augmented attention network learning framework that enables the joint frame-level attribute detection and unified video representation learning for video question answering. We then incorporate the multi-step reasoning process for our proposed attention network to further improve the performance. We construct a large-scale video question answering dataset. We conduct the experiments on both multiple-choice and open-ended video question answering tasks to show the effectiveness of the proposed method. version:1
arxiv-1707-06354 | Pragmatic-Pedagogic Value Alignment | http://arxiv.org/abs/1707.06354 | id:1707.06354 author:Jaime F. Fisac, Monica A. Gates, Jessica B. Hamrick, Chang Liu, Dylan Hadfield-Menell, Malayandi Palaniappan, Dhruv Malik, S. Shankar Sastry, Thomas L. Griffiths, Anca D. Dragan category:cs.AI cs.HC cs.LG cs.RO 68T05  published:2017-07-20 summary:For an autonomous system to provide value (e.g., to customers, designers, or society at large) it must have a reliable method to determine the intended goal. This is the essence of the value-alignment problem: ensuring that the objectives of an autonomous system match those of its human users. In robotics, value alignment is crucial to the design of collaborative robots that can integrate into human workflows, successfully learning and adapting to the objectives of their users as they go. We argue that a meaningful solution to the value-alignment problem will combine multi-agent decision theory with rich mathematical models of human cognition, enabling robots to tap into people's natural collaborative capabilities. We present a solution to the cooperative inverse reinforcement learning (CIRL) dynamic game using well-established models of decision making and theory of mind from cognitive science. The solution accounts for two crucial aspects of collaborative value alignment: that the human will not plan her actions in isolation, but will reason pedagogically about how the robot might learn from them; and that the robot should anticipate this and interpret the human's actions pragmatically. To our knowledge, this constitutes the first equilibrium analysis of value alignment grounded in an empirically validated cognitive model of the human. version:1
arxiv-1707-06347 | Proximal Policy Optimization Algorithms | http://arxiv.org/abs/1707.06347 | id:1707.06347 author:John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov category:cs.LG  published:2017-07-20 summary:We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time. version:1
arxiv-1707-06342 | ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression | http://arxiv.org/abs/1707.06342 | id:1707.06342 author:Jian-Hao Luo, Jianxin Wu, Weiyao Lin category:cs.CV  published:2017-07-20 summary:We propose an efficient and unified framework, namely ThiNet, to simultaneously accelerate and compress CNN models in both training and inference stages. We focus on the filter level pruning, i.e., the whole filter would be discarded if it is less important. Our method does not change the original network structure, thus it can be perfectly supported by any off-the-shelf deep learning libraries. We formally establish filter pruning as an optimization problem, and reveal that we need to prune filters based on statistics information computed from its next layer, not the current layer, which differentiates ThiNet from existing methods. Experimental results demonstrate the effectiveness of this strategy, which has advanced the state-of-the-art. We also show the performance of ThiNet on ILSVRC-12 benchmark. ThiNet achieves 3.31$\times$ FLOPs reduction and 16.63$\times$ compression on VGG-16, with only 0.52$\%$ top-5 accuracy drop. Similar experiments with ResNet-50 reveal that even for a compact network, ThiNet can also reduce more than half of the parameters and FLOPs, at the cost of roughly 1$\%$ top-5 accuracy drop. Moreover, the original VGG-16 model can be further pruned into a very small model with only 5.05MB model size, preserving AlexNet level accuracy but showing much stronger generalization ability. version:1
arxiv-1707-06338 | Machine Learning for Quantum Dynamics: Deep Learning of Excitation Energy Transfer Properties | http://arxiv.org/abs/1707.06338 | id:1707.06338 author:Florian Häse, Christoph Kreisbeck, Alán Aspuru-Guzik category:physics.chem-ph stat.ML  published:2017-07-20 summary:Understanding the relationship between the structure of light-harvesting systems and their excitation energy transfer properties is of fundamental importance in many applications including the development of next generation photovoltaics. Natural light harvesting in photosynthesis shows remarkable excitation energy transfer properties, which suggests that pigment-protein complexes could serve as blueprints for the design of nature inspired devices. Mechanistic insights into energy transport dynamics can be gained by leveraging numerically involved propagation schemes such as the hierarchical equations of motion (HEOM). Solving these equations, however, is computationally costly due to the adverse scaling with the number of pigments. Therefore virtual high-throughput screening, which has become a powerful tool in material discovery, is less readily applicable for the search of novel excitonic devices. We propose the use of artificial neural networks to bypass the computational limitations of established techniques for exploring the structure-dynamics relation in excitonic systems. Once trained, our neural networks reduce computational costs by several orders of magnitudes. Our predicted transfer times and transfer efficiencies exhibit similar or even higher accuracies than frequently used approximate methods such as secular Redfield theory version:1
arxiv-1707-06335 | Sunrise or Sunset: Selective Comparison Learning for Subtle Attribute Recognition | http://arxiv.org/abs/1707.06335 | id:1707.06335 author:Hong-Yu Zhou, Bin-Bin Gao, Jianxin Wu category:cs.CV  published:2017-07-20 summary:The difficulty of image recognition has gradually increased from general category recognition to fine-grained recognition and to the recognition of some subtle attributes such as temperature and geolocation. In this paper, we try to focus on the classification between sunrise and sunset and hope to give a hint about how to tell the difference in subtle attributes. Sunrise vs. sunset is a difficult recognition task, which is challenging even for humans. Towards understanding this new problem, we first collect a new dataset made up of over one hundred webcams from different places. Since existing algorithmic methods have poor accuracy, we propose a new pairwise learning strategy to learn features from selective pairs of images. Experiments show that our approach surpasses baseline methods by a large margin and achieves better results even compared with humans. We also apply our approach to existing subtle attribute recognition problems, such as temperature estimation, and achieve state-of-the-art results. version:1
arxiv-1707-06330 | Multi-Branch Fully Convolutional Network for Face Detection | http://arxiv.org/abs/1707.06330 | id:1707.06330 author:Yancheng Bai, Bernard Ghanem category:cs.CV  published:2017-07-20 summary:Face detection is a fundamental problem in computer vision. It is still a challenging task in unconstrained conditions due to significant variations in scale, pose, expressions, and occlusion. In this paper, we propose a multi-branch fully convolutional network (MB-FCN) for face detection, which considers both efficiency and effectiveness in the design process. Our MB-FCN detector can deal with faces at all scale ranges with only a single pass through the backbone network. As such, our MB-FCN model saves computation and thus is more efficient, compared to previous methods that make multiple passes. For each branch, the specific skip connections of the convolutional feature maps at different layers are exploited to represent faces in specific scale ranges. Specifically, small faces can be represented with both shallow fine-grained and deep powerful coarse features. With this representation, superior improvement in performance is registered for the task of detecting small faces. We test our MB-FCN detector on two public face detection benchmarks, including FDDB and WIDER FACE. Extensive experiments show that our detector outperforms state-of-the-art methods on all these datasets in general and by a substantial margin on the most challenging among them (e.g. WIDER FACE Hard subset). Also, MB-FCN runs at 15 FPS on a GPU for images of size 640 x 480 with no assumption on the minimum detectable face size. version:1
arxiv-1707-06323 | Automatic Segmentation of Retinal Vasculature | http://arxiv.org/abs/1707.06323 | id:1707.06323 author:Renoh Johnson Chalakkal, Waleed Abdulla category:cs.CV  published:2017-07-19 summary:Segmentation of retinal vessels from retinal fundus images is the key step in the automatic retinal image analysis. In this paper, we propose a new unsupervised automatic method to segment the retinal vessels from retinal fundus images. Contrast enhancement and illumination correction are carried out through a series of image processing steps followed by adaptive histogram equalization and anisotropic diffusion filtering. This image is then converted to a gray scale using weighted scaling. The vessel edges are enhanced by boosting the detail curvelet coefficients. Optic disk pixels are removed before applying fuzzy C-mean classification to avoid the misclassification. Morphological operations and connected component analysis are applied to obtain the segmented retinal vessels. The performance of the proposed method is evaluated using DRIVE database to be able to compare with other state-of-art supervised and unsupervised methods. The overall segmentation accuracy of the proposed method is 95.18% which outperforms the other algorithms. version:1
arxiv-1707-06320 | Learning Visually Grounded Sentence Representations | http://arxiv.org/abs/1707.06320 | id:1707.06320 author:Douwe Kiela, Alexis Conneau, Allan Jabri, Maximilian Nickel category:cs.CL cs.CV  published:2017-07-19 summary:We introduce a variety of models, trained on a supervised image captioning corpus to predict the image features for a given caption, to perform sentence representation grounding. We train a grounded sentence encoder that achieves good performance on COCO caption and image retrieval and subsequently show that this encoder can successfully be transferred to various NLP tasks, with improved performance over text-only models. Lastly, we analyze the contribution of grounding, and show that word embeddings learned by this system outperform non-grounded ones. version:1
arxiv-1707-05363 | Auto-Conditioned LSTM Network for Extended Complex Human Motion Synthesis | http://arxiv.org/abs/1707.05363 | id:1707.05363 author:Zimo Li, Yi Zhou, Shuangjiu Xiao, Chong He, Hao Li category:cs.LG  published:2017-07-17 summary:We present a real-time method for synthesizing highly complex human motions using a novel LSTM network training regime we call the auto-conditioned LSTM (acLSTM). Recently, researchers have attempted to synthesize new motion by using autoregressive techniques, but existing methods tend to freeze or diverge after a couple of seconds due to an accumulation of errors that are fed back into the network. Furthermore, such methods have only been shown to be reliable for relatively simple human motions, such as walking or running. In contrast, our approach can synthesize arbitrary motions with highly complex styles, including dances or martial arts in addition to locomotion. The acLSTM is able to accomplish this by explicitly accommodating for autoregressive noise accumulation during training. Furthermore, the structure of the acLSTM is modular and compatible with any other recurrent network architecture, and is usable for tasks other than motion. Our work is the first to our knowledge that demonstrates the ability to generate over 18,000 continuous frames (300 seconds) of new complex human motion w.r.t. different styles. version:2
arxiv-1707-06316 | DenseNet for Dense Flow | http://arxiv.org/abs/1707.06316 | id:1707.06316 author:Yi Zhu, Shawn Newsam category:cs.CV cs.MM  published:2017-07-19 summary:Classical approaches for estimating optical flow have achieved rapid progress in the last decade. However, most of them are too slow to be applied in real-time video analysis. Due to the great success of deep learning, recent work has focused on using CNNs to solve such dense prediction problems. In this paper, we investigate a new deep architecture, Densely Connected Convolutional Networks (DenseNet), to learn optical flow. This specific architecture is ideal for the problem at hand as it provides shortcut connections throughout the network, which leads to implicit deep supervision. We extend current DenseNet to a fully convolutional network to learn motion estimation in an unsupervised manner. Evaluation results on three standard benchmarks demonstrate that DenseNet is a better fit than other widely adopted CNN architectures for optical flow estimation. version:1
arxiv-1707-06315 | FLAME: A Fast Large-scale Almost Matching Exactly Approach to Causal Inference | http://arxiv.org/abs/1707.06315 | id:1707.06315 author:Sudeepa Roy, Cynthia Rudin, Alexander Volfovsky, Tianyu Wang category:stat.ML  published:2017-07-19 summary:A classical problem in causal inference is that of matching, where treatment units need to be matched to control units. Some of the main challenges in developing matching methods arise from the tension among (i) inclusion of as many covariates as possible in defining the matched groups, (ii) having matched groups with enough treated and control units for a valid estimate of Average Treatment Effect (ATE) in each group, and (iii) computing the matched pairs efficiently for large datasets. In this paper we propose a fast and novel method for approximate and exact matching in causal analysis called FLAME (Fast Large-scale Almost Matching Exactly). We define an optimization objective for match quality, which gives preferences to matching on covariates that can be useful for predicting the outcome while encouraging as many matches as possible. FLAME aims to optimize our match quality measure, leveraging techniques that are natural for query processing in the area of database management. We provide two implementations of FLAME using SQL queries and bit-vector techniques. version:1
arxiv-1707-06314 | Fast, Simple Calcium Imaging Segmentation with Fully Convolutional Networks | http://arxiv.org/abs/1707.06314 | id:1707.06314 author:Aleksander Klibisz, Derek Rose, Matthew Eicholtz, Jay Blundon, Stanislav Zakharenko category:cs.CV q-bio.NC  published:2017-07-19 summary:Calcium imaging is a technique for observing neuron activity as a series of images showing indicator fluorescence over time. Manually segmenting neurons is time-consuming, leading to research on automated calcium imaging segmentation (ACIS). We evaluated several deep learning models for ACIS on the Neurofinder competition datasets and report our best model: U-Net2DS, a fully convolutional network that operates on 2D mean summary images. U-Net2DS requires minimal domain-specific pre/post-processing and parameter adjustment, and predictions are made on full $512\times512$ images at $\approx$9K images per minute. It ranks third in the Neurofinder competition ($F_1=0.569$) and is the best model to exclusively use deep learning. We also demonstrate useful segmentations on data from outside the competition. The model's simplicity, speed, and quality results make it a practical choice for ACIS and a strong baseline for more complex models in the future. version:1
arxiv-1707-06299 | Reward-Balancing for Statistical Spoken Dialogue Systems using Multi-objective Reinforcement Learning | http://arxiv.org/abs/1707.06299 | id:1707.06299 author:Stefan Ultes, Paweł Budzianowski, Iñigo Casanueva, Nikola Mrkšić, Lina Rojas-Barahona, Pei-Hao Su, Tsung-Hsien Wen, Milica Gašić, Steve Young category:cs.CL stat.ML  published:2017-07-19 summary:Reinforcement learning is widely used for dialogue policy optimization where the reward function often consists of more than one component, e.g., the dialogue success and the dialogue length. In this work, we propose a structured method for finding a good balance between these components by searching for the optimal reward component weighting. To render this search feasible, we use multi-objective reinforcement learning to significantly reduce the number of training dialogues required. We apply our proposed method to find optimized component weights for six domains and compare them to a default baseline. version:1
arxiv-1707-06292 | STag: A Stable Fiducial Marker System | http://arxiv.org/abs/1707.06292 | id:1707.06292 author:Burak Benligiray, Cihan Topal, Cuneyt Akinlar category:cs.CV  published:2017-07-19 summary:In this paper, we propose STag, a fiducial marker system that provides stable pose estimation. The outer square border of the marker is used for detection and pose estimation. This is followed by a novel pose refinement step using the inner circular border. The refined pose is more stable and robust across viewing conditions compared to the state of the art. In addition, the lexicographic generation algorithm is adapted for fiducial markers, and libraries with various sizes are created. This makes the system suitable for applications that require many unique markers, or few unique markers with high occlusion resistance. The edge segment-based detection algorithm is of low complexity, and returns few false candidates. These features are demonstrated with experiments on real images, including comparisons with the state of the art fiducial marker systems. version:1
arxiv-1707-06286 | Pose-Invariant Face Alignment with a Single CNN | http://arxiv.org/abs/1707.06286 | id:1707.06286 author:Amin Jourabloo, Mao Ye, Xiaoming Liu, Liu Ren category:cs.CV  published:2017-07-19 summary:Face alignment has witnessed substantial progress in the last decade. One of the recent focuses has been aligning a dense 3D face shape to face images with large head poses. The dominant technology used is based on the cascade of regressors, e.g., CNN, which has shown promising results. Nonetheless, the cascade of CNNs suffers from several drawbacks, e.g., lack of end-to-end training, hand-crafted features and slow training speed. To address these issues, we propose a new layer, named visualization layer, that can be integrated into the CNN architecture and enables joint optimization with different loss functions. Extensive evaluation of the proposed method on multiple datasets demonstrates state-of-the-art accuracy, while reducing the training time by more than half compared to the typical cascade of CNNs. In addition, we compare multiple CNN architectures with the visualization layer to further demonstrate the advantage of its utilization. version:1
arxiv-1707-06267 | Shape Generation using Spatially Partitioned Point Clouds | http://arxiv.org/abs/1707.06267 | id:1707.06267 author:Matheus Gadelha, Subhransu Maji, Rui Wang category:cs.CV cs.GR  published:2017-07-19 summary:We propose a method to generate 3D shapes using point clouds. Given a point-cloud representation of a 3D shape, our method builds a kd-tree to spatially partition the points. This orders them consistently across all shapes, resulting in reasonably good correspondences across all shapes. We then use PCA analysis to derive a linear shape basis across the spatially partitioned points, and optimize the point ordering by iteratively minimizing the PCA reconstruction error. Even with the spatial sorting, the point clouds are inherently noisy and the resulting distribution over the shape coefficients can be highly multi-modal. We propose to use the expressive power of neural networks to learn a distribution over the shape coefficients in a generative-adversarial framework. Compared to 3D shape generative models trained on voxel-representations, our point-based method is considerably more light-weight and scalable, with little loss of quality. It also outperforms simpler linear factor models such as Probabilistic PCA, both qualitatively and quantitatively, on a number of categories from the ShapeNet dataset. Furthermore, our method can easily incorporate other point attributes such as normal and color information, an additional advantage over voxel-based representations. version:1
arxiv-1705-02315 | ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases | http://arxiv.org/abs/1705.02315 | id:1705.02315 author:Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, Ronald M. Summers category:cs.CV cs.CL  published:2017-05-05 summary:The chest X-ray is one of the most commonly accessible radiological examinations for screening and diagnosis of many lung diseases. A tremendous number of X-ray imaging studies accompanied by radiological reports are accumulated and stored in many modern hospitals' Picture Archiving and Communication Systems (PACS). On the other side, it is still an open question how this type of hospital-size knowledge database containing invaluable imaging informatics (i.e., loosely labeled) can be used to facilitate the data-hungry deep learning paradigms in building truly large-scale high precision computer-aided diagnosis (CAD) systems. In this paper, we present a new chest X-ray database, namely "ChestX-ray8", which comprises 108,948 frontal-view X-ray images of 32,717 unique patients with the text-mined eight disease image labels (where each image can have multi-labels), from the associated radiological reports using natural language processing. Importantly, we demonstrate that these commonly occurring thoracic diseases can be detected and even spatially-located via a unified weakly-supervised multi-label image classification and disease localization framework, which is validated using our proposed dataset. Although the initial quantitative results are promising as reported, deep convolutional neural network based "reading chest X-rays" (i.e., recognizing and locating the common disease patterns trained with only image-level labels) remains a strenuous task for fully-automated high precision CAD systems. version:3
arxiv-1707-06265 | Unsupervised Domain Adaptation for Robust Speech Recognition via Variational Autoencoder-Based Data Augmentation | http://arxiv.org/abs/1707.06265 | id:1707.06265 author:Wei-Ning Hsu, Yu Zhang, James Glass category:cs.CL cs.LG  published:2017-07-19 summary:Domain mismatch between training and testing can lead to significant degradation in performance in many machine learning scenarios. Unfortunately, this is not a rare situation for automatic speech recognition deployments in real-world applications. Research on robust speech recognition can be regarded as trying to overcome this domain mismatch issue. In this paper, we address the unsupervised domain adaptation problem for robust speech recognition, where both source and target domain speech are presented, but word transcripts are only available for the source domain speech. We present novel augmentation-based methods that transform speech in a way that does not change the transcripts. Specifically, we first train a variational autoencoder on both source and target domain data (without supervision) to learn a latent representation of speech. We then transform nuisance attributes of speech that are irrelevant to recognition by modifying the latent representations, in order to augment labeled training data with additional data whose distribution is more similar to the target domain. The proposed method is evaluated on the CHiME-4 dataset and reduces the absolute word error rate (WER) by as much as 35% compared to the non-adapted baseline. version:1
arxiv-1707-06263 | Deformable Registration through Learning of Context-Specific Metric Aggregation | http://arxiv.org/abs/1707.06263 | id:1707.06263 author:Enzo Ferrante, Puneet K Dokania, Rafael Marini, Nikos Paragios category:cs.CV cs.LG  published:2017-07-19 summary:We propose a novel weakly supervised discriminative algorithm for learning context specific registration metrics as a linear combination of conventional similarity measures. Conventional metrics have been extensively used over the past two decades and therefore both their strengths and limitations are known. The challenge is to find the optimal relative weighting (or parameters) of different metrics forming the similarity measure of the registration algorithm. Hand-tuning these parameters would result in sub optimal solutions and quickly become infeasible as the number of metrics increases. Furthermore, such hand-crafted combination can only happen at global scale (entire volume) and therefore will not be able to account for the different tissue properties. We propose a learning algorithm for estimating these parameters locally, conditioned to the data semantic classes. The objective function of our formulation is a special case of non-convex function, difference of convex function, which we optimize using the concave convex procedure. As a proof of concept, we show the impact of our approach on three challenging datasets for different anatomical structures and modalities. version:1
arxiv-1707-06261 | Rates of Uniform Consistency for k-NN Regression | http://arxiv.org/abs/1707.06261 | id:1707.06261 author:Heinrich Jiang category:stat.ML cs.LG  published:2017-07-19 summary:We derive high-probability finite-sample uniform rates of consistency for $k$-NN regression that are optimal up to logarithmic factors under mild assumptions. We moreover show that $k$-NN regression adapts to an unknown lower intrinsic dimension automatically. We then apply the $k$-NN regression rates to establish new results about estimating the level sets and global maxima of a function from noisy observations. version:1
arxiv-1707-06260 | Learning Approximate Neural Estimators for Wireless Channel State Information | http://arxiv.org/abs/1707.06260 | id:1707.06260 author:Timothy J. O'Shea, Kiran Karra, T. Charles Clancy category:cs.LG cs.NE  published:2017-07-19 summary:Estimation is a critical component of synchronization in wireless and signal processing systems. There is a rich body of work on estimator derivation, optimization, and statistical characterization from analytic system models which are used pervasively today. We explore an alternative approach to building estimators which relies principally on approximate regression using large datasets and large computationally efficient artificial neural network models capable of learning non-linear function mappings which provide compact and accurate estimates. For single carrier PSK modulation, we explore the accuracy and computational complexity of such estimators compared with the current gold-standard analytically derived alternatives. We compare performance in various wireless operating conditions and consider the trade offs between the two different classes of systems. Our results show the learned estimators can provide improvements in areas such as short-time estimation and estimation under non-trivial real world channel conditions such as fading or other non-linear hardware or propagation effects. version:1
arxiv-1707-00160 | An Augmented Lagrangian Method for Piano Transcription using Equal Loudness Thresholding and LSTM-based Decoding | http://arxiv.org/abs/1707.00160 | id:1707.00160 author:Sebastian Ewert, Mark B. Sandler category:cs.SD cs.NE H.5.5; I.2.6  published:2017-07-01 summary:A central goal in automatic music transcription is to detect individual note events in music recordings. An important variant is instrument-dependent music transcription where methods can use calibration data for the instruments in use. However, despite the additional information, results rarely exceed an f-measure of 80%. As a potential explanation, the transcription problem can be shown to be badly conditioned and thus relies on appropriate regularization. A recently proposed method employs a mixture of simple, convex regularizers (to stabilize the parameter estimation process) and more complex terms (to encourage more meaningful structure). In this paper, we present two extensions to this method. First, we integrate a computational loudness model to better differentiate real from spurious note detections. Second, we employ (Bidirectional) Long Short Term Memory networks to re-weight the likelihood of detected note constellations. Despite their simplicity, our two extensions lead to a drop of about 35% in note error rate compared to the state-of-the-art. version:2
arxiv-1707-06219 | Acceleration and Averaging in Stochastic Mirror Descent Dynamics | http://arxiv.org/abs/1707.06219 | id:1707.06219 author:Walid Krichene, Peter L. Bartlett category:math.OC stat.ML  published:2017-07-19 summary:We formulate and study a general family of (continuous-time) stochastic dynamics for accelerated first-order minimization of smooth convex functions. Building on an averaging formulation of accelerated mirror descent, we propose a stochastic variant in which the gradient is contaminated by noise, and study the resulting stochastic differential equation. We prove a bound on the rate of change of an energy function associated with the problem, then use it to derive estimates of convergence rates of the function values, (a.s. and in expectation) both for persistent and asymptotically vanishing noise. We discuss the interaction between the parameters of the dynamics (learning rate and averaging weights) and the covariation of the noise process, and show, in particular, how the asymptotic rate of covariation affects the choice of parameters and, ultimately, the convergence rate. version:1
arxiv-1707-06217 | Worst-case vs Average-case Design for Estimation from Fixed Pairwise Comparisons | http://arxiv.org/abs/1707.06217 | id:1707.06217 author:Ashwin Pananjady, Cheng Mao, Vidya Muthukumar, Martin J. Wainwright, Thomas A. Courtade category:cs.LG cs.AI cs.IT math.IT stat.ML  published:2017-07-19 summary:Pairwise comparison data arises in many domains, including tournament rankings, web search, and preference elicitation. Given noisy comparisons of a fixed subset of pairs of items, we study the problem of estimating the underlying comparison probabilities under the assumption of strong stochastic transitivity (SST). We also consider the noisy sorting subclass of the SST model. We show that when the assignment of items to the topology is arbitrary, these permutation-based models, unlike their parametric counterparts, do not admit consistent estimation for most comparison topologies used in practice. We then demonstrate that consistent estimation is possible when the assignment of items to the topology is randomized, thus establishing a dichotomy between worst-case and average-case designs. We propose two estimators in the average-case setting and analyze their risk, showing that it depends on the comparison topology only through the degree sequence of the topology. The rates achieved by these estimators are shown to be optimal for a large class of graphs. Our results are corroborated by simulations on multiple comparison topologies. version:1
arxiv-1707-06213 | Analysis of $p$-Laplacian Regularization in Semi-Supervised Learning | http://arxiv.org/abs/1707.06213 | id:1707.06213 author:Dejan Slepčev, Matthew Thorpe category:math.ST cs.LG stat.ML stat.TH 62G20  68R10  45J55  published:2017-07-19 summary:We investigate a family of regression problems in a semi-supervised setting. The task is to assign real-valued labels to a set of $n$ sample points, provided a small training subset of $N$ labeled points. A goal of semi-supervised learning is to take advantage of the (geometric) structure provided by the large number of unlabeled data when assigning labels. We consider a random geometric graph, with connection radius $\epsilon(n)$, to represent the geometry of the data set. We study objective functions which reward the regularity of the estimator function and impose or reward the agreement with the training data. In particular we consider discrete $p$-Laplacian regularization. We investigate asymptotic behavior in the limit where the number of unlabeled points increases while the number of training points remains fixed. We uncover a delicate interplay between the regularizing nature of the functionals considered and the nonlocality inherent to the graph constructions. We rigorously obtain almost optimal ranges on the scaling of $\epsilon(n)$ for the asymptotic consistency to hold. We discover that for standard approaches used thus far there is a restrictive upper bound on how quickly $\epsilon(n)$ must converge to zero as $n \to \infty$. Furthermore we introduce a new model which overcomes this restriction. It is as simple as the standard models, but converges as soon as $\epsilon(n) \to 0$ as $n \to \infty$. version:1
arxiv-1707-06209 | Crowdsourcing Multiple Choice Science Questions | http://arxiv.org/abs/1707.06209 | id:1707.06209 author:Johannes Welbl, Nelson F. Liu, Matt Gardner category:cs.HC cs.AI cs.CL stat.ML  published:2017-07-19 summary:We present a novel method for obtaining high-quality, domain-targeted multiple choice questions from crowd workers. Generating these questions can be difficult without trading away originality, relevance or diversity in the answer options. Our method addresses these problems by leveraging a large corpus of domain-specific text and a small set of existing questions. It produces model suggestions for document selection and answer distractor choice which aid the human question generation process. With this method we have assembled SciQ, a dataset of 13.7K multiple choice science exam questions (Dataset available at http://allenai.org/data.html). We demonstrate that the method produces in-domain questions by providing an analysis of this new dataset and by showing that humans cannot distinguish the crowdsourced questions from original questions. When using SciQ as additional training data to existing questions, we observe accuracy improvements on real science exams. version:1
arxiv-1707-06203 | Imagination-Augmented Agents for Deep Reinforcement Learning | http://arxiv.org/abs/1707.06203 | id:1707.06203 author:Théophane Weber, Sébastien Racanière, David P. Reichert, Lars Buesing, Arthur Guez, Danilo Jimenez Rezende, Adria Puigdomènech Badia, Oriol Vinyals, Nicolas Heess, Yujia Li, Razvan Pascanu, Peter Battaglia, David Silver, Daan Wierstra category:cs.LG cs.AI stat.ML  published:2017-07-19 summary:We introduce Imagination-Augmented Agents (I2As), a novel architecture for deep reinforcement learning combining model-free and model-based aspects. In contrast to most existing model-based reinforcement learning and planning methods, which prescribe how a model should be used to arrive at a policy, I2As learn to interpret predictions from a learned environment model to construct implicit plans in arbitrary ways, by using the predictions as additional context in deep policy networks. I2As show improved data efficiency, performance, and robustness to model misspecification compared to several baselines. version:1
arxiv-1707-06197 | Can GAN Learn Topological Features of a Graph? | http://arxiv.org/abs/1707.06197 | id:1707.06197 author:Weiyi Liu, Pin-Yu Chen, Hal Cooper, Min Hwan Oh, Sailung Yeung, Toyotaro Suzumura category:cs.LG stat.ML  published:2017-07-19 summary:This paper is first-line research expanding GANs into graph topology analysis. By leveraging the hierarchical connectivity structure of a graph, we have demonstrated that generative adversarial networks (GANs) can successfully capture topological features of any arbitrary graph, and rank edge sets by different stages according to their contribution to topology reconstruction. Moreover, in addition to acting as an indicator of graph reconstruction, we find that these stages can also preserve important topological features in a graph. version:1
arxiv-1707-06195 | Fast and Accurate OOV Decoder on High-Level Features | http://arxiv.org/abs/1707.06195 | id:1707.06195 author:Yuri Khokhlov, Natalia Tomashenko, Ivan Medennikov, Alexei Romanenko category:cs.CL  published:2017-07-19 summary:This work proposes a novel approach to out-of-vocabulary (OOV) keyword search (KWS) task. The proposed approach is based on using high-level features from an automatic speech recognition (ASR) system, so called phoneme posterior based (PPB) features, for decoding. These features are obtained by calculating time-dependent phoneme posterior probabilities from word lattices, followed by their smoothing. For the PPB features we developed a special novel very fast, simple and efficient OOV decoder. Experimental results are presented on the Georgian language from the IARPA Babel Program, which was the test language in the OpenKWS 2016 evaluation campaign. The results show that in terms of maximum term weighted value (MTWV) metric and computational speed, for single ASR systems, the proposed approach significantly outperforms the state-of-the-art approach based on using in-vocabulary proxies for OOV keywords in the indexed database. The comparison of the two OOV KWS approaches on the fusion results of the nine different ASR systems demonstrates that the proposed OOV decoder outperforms the proxy-based approach in terms of MTWV metric given the comparable processing speed. Other important advantages of the OOV decoder include extremely low memory consumption and simplicity of its implementation and parameter optimization. version:1
arxiv-1707-06194 | Entropy-based Pruning for Learning Bayesian Networks using BIC | http://arxiv.org/abs/1707.06194 | id:1707.06194 author:Cassio P. de Campos, Mauro Scanagatta, Giorgio Corani, Marco Zaffalon category:cs.AI stat.ML  published:2017-07-19 summary:For decomposable score-based structure learning of Bayesian networks, existing approaches first compute a collection of candidate parent sets for each variable and then optimize over this collection by choosing one parent set for each variable without creating directed cycles while maximizing the total score. We target the task of constructing the collection of candidate parent sets when the score of choice is the Bayesian Information Criterion (BIC). We provide new non-trivial results that can be used to prune the search space of candidate parent sets of each node. We analyze how these new results relate to previous ideas in the literature both theoretically and empirically. We show in experiments with UCI data sets that gains can be significant. Since the new pruning rules are easy to implement and have low computational costs, they can be promptly integrated into all state-of-the-art methods for structure learning of Bayesian networks. version:1
arxiv-1707-04582 | Capturing the diversity of biological tuning curves using generative adversarial networks | http://arxiv.org/abs/1707.04582 | id:1707.04582 author:Takafumi Arakaki, G. Barello, Yashar Ahmadian category:q-bio.QM cs.LG q-bio.NC  published:2017-07-14 summary:Tuning curves characterizing the response selectivities of biological neurons often exhibit large degrees of irregularity and diversity across neurons. Theoretical network models that feature heterogeneous cell populations or random connectivity also give rise to diverse tuning curves. However, a general framework for fitting such models to experimentally measured tuning curves is lacking. We address this problem by proposing to view mechanistic network models as generative models whose parameters can be optimized to fit the distribution of experimentally measured tuning curves. A major obstacle for fitting such models is that their likelihood function is not explicitly available or is highly intractable to compute. Recent advances in machine learning provide ways for fitting generative models without the need to evaluate the likelihood and its gradient. Generative Adversarial Networks (GAN) provide one such framework which has been successful in traditional machine learning tasks. We apply this approach in two separate experiments, showing how GANs can be used to fit commonly used mechanistic models in theoretical neuroscience to datasets of measured tuning curves. This fitting procedure avoids the computationally expensive step of inferring latent variables, e.g. the biophysical parameters of individual cells or the particular realization of the full synaptic connectivity matrix, and directly learns model parameters which characterize the statistics of connectivity or of single-cell properties. Another strength of this approach is that it fits the entire, joint distribution of experimental tuning curves, instead of matching a few summary statistics picked a priori by the user. More generally, this framework opens the door to fitting theoretically motivated dynamical network models directly to simultaneously or non-simultaneously recorded neural responses. version:3
arxiv-1707-06231 | From Bach to the Beatles: The simulation of human tonal expectation using ecologically-trained predictive models | http://arxiv.org/abs/1707.06231 | id:1707.06231 author:Carlos Cancino-Chacón, Maarten Grachten, Kat Agres category:cs.SD cs.LG  published:2017-07-19 summary:Tonal structure is in part conveyed by statistical regularities between musical events, and research has shown that computational models reflect tonal structure in music by capturing these regularities in schematic constructs like pitch histograms. Of the few studies that model the acquisition of perceptual learning from musical data, most have employed self-organizing models that learn a topology of static descriptions of musical contexts. Also, the stimuli used to train these models are often symbolic rather than acoustically faithful representations of musical material. In this work we investigate whether sequential predictive models of musical memory (specifically, recurrent neural networks), trained on audio from commercial CD recordings, induce tonal knowledge in a similar manner to listeners (as shown in behavioral studies in music perception). Our experiments indicate that various types of recurrent neural networks produce musical expectations that clearly convey tonal structure. Furthermore, the results imply that although implicit knowledge of tonal structure is a necessary condition for accurate musical expectation, the most accurate predictive models also use other cues beyond the tonal structure of the musical context. version:1
arxiv-1707-06185 | Simultaneously Solving Mixed Model Assembly Line Balancing and Sequencing problems with FSS Algorithm | http://arxiv.org/abs/1707.06185 | id:1707.06185 author:Joao Batista Monteiro Filho, Isabela Maria Carnei, Fernando Buarque de Lima Neto category:cs.NE  published:2017-07-19 summary:Many assembly lines related optimization problems have been tackled by researchers in the last decades due to its relevance for the decision makers within manufacturing industry. Many of theses problems, more specifically Assembly Lines Balancing and Sequencing problems, are known to be NP-Hard. Therefore, Computational Intelligence solution approaches have been conceived in order to provide practical use decision making tools. In this work, we proposed a simultaneous solution approach in order to tackle both Balancing and Sequencing problems utilizing an effective meta-heuristic algorithm referred as Fish School Search. Three different test instances were solved with the original and two modified versions of this algorithm and the results were compared with Particle Swarm Optimization Algorithm. version:1
arxiv-1707-06183 | Domain-adversarial neural networks to address the appearance variability of histopathology images | http://arxiv.org/abs/1707.06183 | id:1707.06183 author:Maxime W. Lafarge, Josien P. W. Pluim, Koen A. J. Eppenhof, Pim Moeskops, Mitko Veta category:cs.CV  published:2017-07-19 summary:Preparing and scanning histopathology slides consists of several steps, each with a multitude of parameters. The parameters can vary between pathology labs and within the same lab over time, resulting in significant variability of the tissue appearance that hampers the generalization of automatic image analysis methods. Typically, this is addressed with ad-hoc approaches such as staining normalization that aim to reduce the appearance variability. In this paper, we propose a systematic solution based on domain-adversarial neural networks. We hypothesize that removing the domain information from the model representation leads to better generalization. We tested our hypothesis for the problem of mitosis detection in breast cancer histopathology images and made a comparative analysis with two other approaches. We show that combining color augmentation with domain-adversarial training is a better alternative than standard approaches to improve the generalization of deep learning methods. version:1
arxiv-1707-06180 | Object-Extent Pooling for Weakly Supervised Single-Shot Localization | http://arxiv.org/abs/1707.06180 | id:1707.06180 author:Amogh Gudi, Nicolai van Rosmalen, Marco Loog, Jan van Gemert category:cs.CV  published:2017-07-19 summary:In the face of scarcity in detailed training annotations, the ability to perform object localization tasks in real-time with weak-supervision is very valuable. However, the computational cost of generating and evaluating region proposals is heavy. We adapt the concept of Class Activation Maps (CAM) into the very first weakly-supervised 'single-shot' detector that does not require the use of region proposals. To facilitate this, we propose a novel global pooling technique called Spatial Pyramid Averaged Max (SPAM) pooling for training this CAM-based network for object extent localisation with only weak image-level supervision. We show this global pooling layer possesses a near ideal flow of gradients for extent localization, that offers a good trade-off between the extremes of max and average pooling. Our approach only requires a single network pass and uses a fast-backprojection technique, completely omitting any region proposal steps. To the best of our knowledge, this is the first approach to do so. Due to this, we are able to perform inference in real-time at 35fps, which is an order of magnitude faster than all previous weakly supervised object localization frameworks. version:1
arxiv-1707-06175 | Deformable Part-based Fully Convolutional Network for Object Detection | http://arxiv.org/abs/1707.06175 | id:1707.06175 author:Taylor Mordan, Nicolas Thome, Matthieu Cord, Gilles Henaff category:cs.CV cs.AI cs.LG  published:2017-07-19 summary:Existing region-based object detectors are limited to regions with fixed box geometry to represent objects, even if those are highly non-rectangular. In this paper we introduce DP-FCN, a deep model for object detection which explicitly adapts to shapes of objects with deformable parts. Without additional annotations, it learns to focus on discriminative elements and to align them, and simultaneously brings more invariance for classification and geometric information to refine localization. DP-FCN is composed of three main modules: a Fully Convolutional Network to efficiently maintain spatial resolution, a deformable part-based RoI pooling layer to optimize positions of parts and build invariance, and a deformation-aware localization module explicitly exploiting displacements of parts to improve accuracy of bounding box regression. We experimentally validate our model and show significant gains. DP-FCN achieves state-of-the-art performances of 83.1% and 80.9% on PASCAL VOC 2007 and 2012 with VOC data only. version:1
arxiv-1707-06170 | Learning model-based planning from scratch | http://arxiv.org/abs/1707.06170 | id:1707.06170 author:Razvan Pascanu, Yujia Li, Oriol Vinyals, Nicolas Heess, Lars Buesing, Sebastien Racanière, David Reichert, Théophane Weber, Daan Wierstra, Peter Battaglia category:cs.AI cs.LG cs.NE stat.ML  published:2017-07-19 summary:Conventional wisdom holds that model-based planning is a powerful approach to sequential decision-making. It is often very challenging in practice, however, because while a model can be used to evaluate a plan, it does not prescribe how to construct a plan. Here we introduce the "Imagination-based Planner", the first model-based, sequential decision-making agent that can learn to construct, evaluate, and execute plans. Before any action, it can perform a variable number of imagination steps, which involve proposing an imagined action and evaluating it with its model-based imagination. All imagined actions and outcomes are aggregated, iteratively, into a "plan context" which conditions future real and imagined actions. The agent can even decide how to imagine: testing out alternative imagined actions, chaining sequences of actions together, or building a more complex "imagination tree" by navigating flexibly among the previously imagined states using a learned policy. And our agent can learn to plan economically, jointly optimizing for external rewards and computational costs associated with using its imagination. We show that our architecture can learn to solve a challenging continuous control problem, and also learn elaborate planning strategies in a discrete maze-solving task. Our work opens a new direction toward learning the components of a model-based planning system and how to use them. version:1
arxiv-1707-06169 | Fish School Search Algorithm for Constrained Optimization | http://arxiv.org/abs/1707.06169 | id:1707.06169 author:Joao Batista Monteiro Filho, Isabela Maria Carnei, Fernando Buarque de Lima Neto category:cs.NE  published:2017-07-19 summary:In this work we investigate the effectiveness of the application of niching able swarm metaheuristic approaches in order to solve constrained optimization problems. Sub-swarms are used in order to allow the achievement of many feasible regions to be exploited in terms of fitness function. The niching approach employed was wFSS, a version of the Fish School Search algorithm devised specifically to deal with multi-modal search spaces. A base technique referred as wrFSS was conceived and three variations applying different constraint handling procedures were also proposed. Tests were performed in seven problems from CEC 2010 and a comparison with other approaches was carried out. Results show that the search strategy proposed is able to handle some heavily constrained problems and achieve results comparable to the state-of-the-art algorithms. However, we also observed that the local search operator present in wFSS and inherited by wrFSS makes the fitness convergence difficult when the feasible region presents some specific geometrical features. version:1
arxiv-1707-06168 | Channel Pruning for Accelerating Very Deep Neural Networks | http://arxiv.org/abs/1707.06168 | id:1707.06168 author:Yihui He, Xiangyu Zhang, Jian Sun category:cs.CV  published:2017-07-19 summary:In this paper, we introduce a new channel pruning method to accelerate very deep convolutional neural networks.Given a trained CNN model, we propose an iterative two-step algorithm to effectively prune each layer, by a LASSO regression based channel selection and least square reconstruction. We further generalize this algorithm to multi-layer and multi-branch cases. Our method reduces the accumulated error and enhance the compatibility with various architectures. Our pruned VGG-16 achieves the state-of-the-art results by 5x speed-up along with only 0.3% increase of error. More importantly, our method is able to accelerate modern networks like ResNet, Xception and suffers only 1.4%, 1.0% accuracy loss under 2x speed-up respectively, which is significant. version:1
arxiv-1707-06167 | Sentence-level quality estimation by predicting HTER as a multi-component metric | http://arxiv.org/abs/1707.06167 | id:1707.06167 author:Eleftherios Avramidis category:cs.CL  published:2017-07-19 summary:This submission investigates alternative machine learning models for predicting the HTER score on the sentence level. Instead of directly predicting the HTER score, we suggest a model that jointly predicts the amount of the 4 distinct post-editing operations, which are then used to calculate the HTER score. This also gives the possibility to correct invalid (e.g. negative) predicted values prior to the calculation of the HTER score. Without any feature exploration, a multi-layer perceptron with 4 outputs yields small but significant improvements over the baseline. version:1
arxiv-1707-06163 | Metrical-accent Aware Vocal Onset Detection in Polyphonic Audio | http://arxiv.org/abs/1707.06163 | id:1707.06163 author:Georgi Dzhambazov, Andre Holzapfel, Ajay Srinivasamurthy, Xavier Serra category:cs.SD cs.CL cs.MM  published:2017-07-19 summary:The goal of this study is the automatic detection of onsets of the singing voice in polyphonic audio recordings. Starting with a hypothesis that the knowledge of the current position in a metrical cycle (i.e. metrical accent) can improve the accuracy of vocal note onset detection, we propose a novel probabilistic model to jointly track beats and vocal note onsets. The proposed model extends a state of the art model for beat and meter tracking, in which a-priori probability of a note at a specific metrical accent interacts with the probability of observing a vocal note onset. We carry out an evaluation on a varied collection of multi-instrument datasets from two music traditions (English popular music and Turkish makam) with different types of metrical cycles and singing styles. Results confirm that the proposed model reasonably improves vocal note onset detection accuracy compared to a baseline model that does not take metrical position into account. version:1
arxiv-1707-06151 | Expect the unexpected: Harnessing Sentence Completion for Sarcasm Detection | http://arxiv.org/abs/1707.06151 | id:1707.06151 author:Aditya Joshi, Samarth Agrawal, Pushpak Bhattacharyya, Mark Carman category:cs.CL  published:2017-07-19 summary:The trigram `I love being' is expected to be followed by positive words such as `happy'. In a sarcastic sentence, however, the word `ignored' may be observed. The expected and the observed words are, thus, incongruous. We model sarcasm detection as the task of detecting incongruity between an observed and an expected word. In order to obtain the expected word, we use Context2Vec, a sentence completion library based on Bidirectional LSTM. However, since the exact word where such an incongruity occurs may not be known in advance, we present two approaches: an All-words approach (which consults sentence completion for every content word) and an Incongruous words-only approach (which consults sentence completion for the 50% most incongruous content words). The approaches outperform reported values for tweets but not for discussion forum posts. This is likely to be because of redundant consultation of sentence completion for discussion forum posts. Therefore, we consider an oracle case where the exact incongruous word is manually labeled in a corpus reported in past work. In this case, the performance is higher than the all-words approach. This sets up the promise for using sentence completion for sarcasm detection. version:1
arxiv-1707-06145 | Self-paced Convolutional Neural Network for Computer Aided Detection in Medical Imaging Analysis | http://arxiv.org/abs/1707.06145 | id:1707.06145 author:Xiang Li, Aoxiao Zhong, Ming Lin, Ning Guo, Mu Sun, Arkadiusz Sitek, Jieping Ye, James Thrall, Quanzheng Li category:cs.LG stat.ML  published:2017-07-19 summary:Tissue characterization has long been an important component of Computer Aided Diagnosis (CAD) systems for automatic lesion detection and further clinical planning. Motivated by the superior performance of deep learning methods on various computer vision problems, there has been increasing work applying deep learning to medical image analysis. However, the development of a robust and reliable deep learning model for computer-aided diagnosis is still highly challenging due to the combination of the high heterogeneity in the medical images and the relative lack of training samples. Specifically, annotation and labeling of the medical images is much more expensive and time-consuming than other applications and often involves manual labor from multiple domain experts. In this work, we propose a multi-stage, self-paced learning framework utilizing a convolutional neural network (CNN) to classify Computed Tomography (CT) image patches. The key contribution of this approach is that we augment the size of training samples by refining the unlabeled instances with a self-paced learning CNN. By implementing the framework on high performance computing servers including the NVIDIA DGX1 machine, we obtained the experimental result, showing that the self-pace boosted network consistently outperformed the original network even with very scarce manual labels. The performance gain indicates that applications with limited training samples such as medical image analysis can benefit from using the proposed framework. version:1
arxiv-1707-06142 | Naive Bayes Classification for Subset Selection | http://arxiv.org/abs/1707.06142 | id:1707.06142 author:Luca Mossina, Emmanuel Rachelson category:cs.LG  published:2017-07-19 summary:This article focuses on the question of learning how to automatically select a subset of items among a bigger set. We introduce a methodology for the inference of ensembles of discrete values, based on the Naive Bayes assumption. Our motivation stems from practical use cases where one wishes to predict an unordered set of (possibly interdependent) values from a set of observed features. This problem can be considered in the context of Multi-label Classification (MLC) where such values are seen as labels associated to continuous or discrete features. We introduce the \nbx algorithm, an extension of Naive Bayes classification into the multi-label domain, discuss its properties and evaluate our approach on real-world problems. version:1
arxiv-1707-08872 | Algorithms for Approximate Subtropical Matrix Factorization | http://arxiv.org/abs/1707.08872 | id:1707.08872 author:Sanjar Karaev, Pauli Miettinen category:cs.LG  published:2017-07-19 summary:Matrix factorization methods are important tools in data mining and analysis. They can be used for many tasks, ranging from dimensionality reduction to visualization. In this paper we concentrate on the use of matrix factorizations for finding patterns from the data. Rather than using the standard algebra -- and the summation of the rank-1 components to build the approximation of the original matrix -- we use the subtropical algebra, which is an algebra over the nonnegative real values with the summation replaced by the maximum operator. Subtropical matrix factorizations allow "winner-takes-it-all" interpretations of the rank-1 components, revealing different structure than the normal (nonnegative) factorizations. We study the complexity and sparsity of the factorizations, and present a framework for finding low-rank subtropical factorizations. We present two specific algorithms, called Capricorn and Cancer, that are part of our framework. They can be used with data that has been corrupted with different types of noise, and with different error metrics, including the sum-of-absolute differences, Frobenius norm, and Jensen--Shannon divergence. Our experiments show that the algorithms perform well on data that has subtropical structure, and that they can find factorizations that are both sparse and easy to interpret. version:1
arxiv-1707-06132 | Solving Mixed Model Workplace Time-dependent Assembly Line Balancing Problem with FSS Algorithm | http://arxiv.org/abs/1707.06132 | id:1707.06132 author:Joao Batista Monteiro FIlho, Isabela Maria Carnei, Fernando Buarque de Lima Neto category:cs.NE  published:2017-07-19 summary:Balancing assembly lines, a family of optimization problems commonly known as Assembly Line Balancing Problem, is notoriously NP-Hard. They comprise a set of problems of enormous practical interest to manufacturing industry due to the relevant frequency of this type of production paradigm. For this reason, many researchers on Computational Intelligence and Industrial Engineering have been conceiving algorithms for tackling different versions of assembly line balancing problems utilizing different methodologies. In this article, it was proposed a problem version referred as Mixed Model Workplace Time-dependent Assembly Line Balancing Problem with the intention of including pressing issues of real assembly lines in the optimization problem, to which four versions were conceived. Heuristic search procedures were used, namely two Swarm Intelligence algorithms from the Fish School Search family: the original version, named "vanilla", and a special variation including a stagnation avoidance routine. Either approaches solved the newly posed problem achieving good results when compared to Particle Swarm Optimization algorithm. version:1
arxiv-1707-06130 | Improving Language Modeling using Densely Connected Recurrent Neural Networks | http://arxiv.org/abs/1707.06130 | id:1707.06130 author:Fréderic Godin, Joni Dambre, Wesley De Neve category:cs.CL  published:2017-07-19 summary:In this paper, we introduce the novel concept of densely connected layers into recurrent neural networks. We evaluate our proposed architecture on the Penn Treebank language modeling task. We show that we can obtain similar perplexity scores with six times fewer parameters compared to a standard stacked 2-layer LSTM model trained with dropout (Zaremba et al. 2014). In contrast with the current usage of skip connections, we show that densely connecting only a few stacked layers with skip connections already yields significant perplexity reductions. version:1
arxiv-1707-06119 | Discriminative convolutional Fisher vector network for action recognition | http://arxiv.org/abs/1707.06119 | id:1707.06119 author:Petar Palasek, Ioannis Patras category:cs.CV  published:2017-07-19 summary:In this work we propose a novel neural network architecture for the problem of human action recognition in videos. The proposed architecture expresses the processing steps of classical Fisher vector approaches, that is dimensionality reduction by principal component analysis (PCA) projection, Gaussian mixture model (GMM) and Fisher vector descriptor extraction, as network layers. By contrast to other methods where these steps are performed consecutively and the corresponding parameters are learned in an unsupervised manner, having them defined as a single neural network allows us to refine the whole model discriminatively in an end to end fashion. Furthermore, we show that the proposed architecture can be used as a replacement for the fully connected layers in popular convolutional networks achieving a comparable classification performance, or even significantly surpassing the performance of similar architectures while reducing the total number of trainable parameters by a factor of 5. We show that our method achieves significant improvements in comparison to the classical chain. version:1
arxiv-1707-06089 | Deep View-Sensitive Pedestrian Attribute Inference in an end-to-end Model | http://arxiv.org/abs/1707.06089 | id:1707.06089 author:M. Saquib Sarfraz, Arne Schumann, Yan Wang, Rainer Stiefelhagen category:cs.CV  published:2017-07-19 summary:Pedestrian attribute inference is a demanding problem in visual surveillance that can facilitate person retrieval, search and indexing. To exploit semantic relations between attributes, recent research treats it as a multi-label image classification task. The visual cues hinting at attributes can be strongly localized and inference of person attributes such as hair, backpack, shorts, etc., are highly dependent on the acquired view of the pedestrian. In this paper we assert this dependence in an end-to-end learning framework and show that a view-sensitive attribute inference is able to learn better attribute predictions. Our proposed model jointly predicts the coarse pose (view) of the pedestrian and learns specialized view-specific multi-label attribute predictions. We show in an extensive evaluation on three challenging datasets (PETA, RAP and WIDER) that our proposed end-to-end view-aware attribute prediction model provides competitive performance and improves on the published state-of-the-art on these datasets. version:1
arxiv-1707-07585 | Stock Prediction: a method based on extraction of news features and recurrent neural networks | http://arxiv.org/abs/1707.07585 | id:1707.07585 author:Zeya Zhang, Weizheng Chen, Hongfei Yan category:q-fin.ST cs.CL cs.IR cs.LG  published:2017-07-19 summary:This paper proposed a method for stock prediction. In terms of feature extraction, we extract the features of stock-related news besides stock prices. We first select some seed words based on experience which are the symbols of good news and bad news. Then we propose an optimization method and calculate the positive polar of all words. After that, we construct the features of news based on the positive polar of their words. In consideration of sequential stock prices and continuous news effects, we propose a recurrent neural network model to help predict stock prices. Compared to SVM classifier with price features, we find our proposed method has an over 5% improvement on stock prediction accuracy in experiments. version:1
arxiv-1707-06068 | On Finding Maximum Cardinality Subset of Vectors with a Constraint on Normalized Squared Length of Vectors Sum | http://arxiv.org/abs/1707.06068 | id:1707.06068 author:Anton V. Eremeev, Alexander V. Kelmanov, Artem V. Pyatkin, Igor A. Ziegler category:cs.DS cs.CV  published:2017-07-19 summary:In this paper, we consider the problem of finding a maximum cardinality subset of vectors, given a constraint on the normalized squared length of vectors sum. This problem is closely related to Problem 1 from (Eremeev, Kel'manov, Pyatkin, 2016). The main difference consists in swapping the constraint with the optimization criterion. We prove that the problem is NP-hard even in terms of finding a feasible solution. An exact algorithm for solving this problem is proposed. The algorithm has a pseudo-polynomial time complexity in the special case of the problem, where the dimension of the space is bounded from above by a constant and the input data are integer. A computational experiment is carried out, where the proposed algorithm is compared to COINBONMIN solver, applied to a mixed integer quadratic programming formulation of the problem. The results of the experiment indicate superiority of the proposed algorithm when the dimension of Euclidean space is low, while the COINBONMIN has an advantage for larger dimensions. version:1
arxiv-1707-06065 | Dynamic Layer Normalization for Adaptive Neural Acoustic Modeling in Speech Recognition | http://arxiv.org/abs/1707.06065 | id:1707.06065 author:Taesup Kim, Inchul Song, Yoshua Bengio category:cs.CL cs.LG  published:2017-07-19 summary:Layer normalization is a recently introduced technique for normalizing the activities of neurons in deep neural networks to improve the training speed and stability. In this paper, we introduce a new layer normalization technique called Dynamic Layer Normalization (DLN) for adaptive neural acoustic modeling in speech recognition. By dynamically generating the scaling and shifting parameters in layer normalization, DLN adapts neural acoustic models to the acoustic variability arising from various factors such as speakers, channel noises, and environments. Unlike other adaptive acoustic models, our proposed approach does not require additional adaptation data or speaker information such as i-vectors. Moreover, the model size is fixed as it dynamically generates adaptation parameters. We apply our proposed DLN to deep bidirectional LSTM acoustic models and evaluate them on two benchmark datasets for large vocabulary ASR experiments: WSJ and TED-LIUM release 2. The experimental results show that our DLN improves neural acoustic models in terms of transcription accuracy by dynamically adapting to various speakers and environments. version:1
arxiv-1707-06029 | Supervising Neural Attention Models for Video Captioning by Human Gaze Data | http://arxiv.org/abs/1707.06029 | id:1707.06029 author:Youngjae Yu, Jongwook Choi, Yeonhwa Kim, Kyung Yoo, Sang-Hun Lee, Gunhee Kim category:cs.CV  published:2017-07-19 summary:The attention mechanisms in deep neural networks are inspired by human's attention that sequentially focuses on the most relevant parts of the information over time to generate prediction output. The attention parameters in those models are implicitly trained in an end-to-end manner, yet there have been few trials to explicitly incorporate human gaze tracking to supervise the attention models. In this paper, we investigate whether attention models can benefit from explicit human gaze labels, especially for the task of video captioning. We collect a new dataset called VAS, consisting of movie clips, and corresponding multiple descriptive sentences along with human gaze tracking data. We propose a video captioning model named Gaze Encoding Attention Network (GEAN) that can leverage gaze tracking information to provide the spatial and temporal attention for sentence generation. Through evaluation of language similarity metrics and human assessment via Amazon mechanical Turk, we demonstrate that spatial attentions guided by human gaze data indeed improve the performance of multiple captioning methods. Moreover, we show that the proposed approach achieves the state-of-the-art performance for both gaze prediction and video captioning not only in our VAS dataset but also in standard datasets (e.g. LSMDC and Hollywood2). version:1
arxiv-1707-06017 | EnzyNet: enzyme classification using 3D convolutional neural networks on spatial representation | http://arxiv.org/abs/1707.06017 | id:1707.06017 author:Afshine Amidi, Shervine Amidi, Dimitrios Vlachakis, Vasileios Megalooikonomou, Nikos Paragios, Evangelia I. Zacharaki category:q-bio.QM cs.CV stat.ML  published:2017-07-19 summary:During the past decade, with the significant progress of computational power as well as ever-rising data availability, deep learning techniques became increasingly popular due to their excellent performance on computer vision problems. The size of the Protein Data Bank has increased more than 15 fold since 1999, which enabled the expansion of models that aim at predicting enzymatic function via their amino acid composition. Amino acid sequence however is less conserved in nature than protein structure and therefore considered a less reliable predictor of protein function. This paper presents EnzyNet, a novel 3D-convolutional neural networks classifier that predicts the Enzyme Commission number of enzymes based only on their voxel-based spatial structure. The spatial distribution of biochemical properties was also examined as complementary information. The 2-layer architecture was investigated on a large dataset of 63,558 enzymes from the Protein Data Bank and achieved an accuracy of 78.4% by exploiting only the binary representation of the protein shape. Code and datasets are available at https://github.com/shervinea/enzynet. version:1
arxiv-1707-06519 | Language Transfer of Audio Word2Vec: Learning Audio Segment Representations without Target Language Data | http://arxiv.org/abs/1707.06519 | id:1707.06519 author:Chia-Hao Shen, Janet Y. Sung, Hung-Yi Lee category:cs.CL  published:2017-07-19 summary:Audio Word2Vec offers vector representations of fixed dimensionality for variable-length audio segments using Sequence-to-sequence Autoencoder (SA). These vector representations are shown to describe the sequential phonetic structures of the audio segments to a good degree, with real world applications such as query-by-example Spoken Term Detection (STD). This paper examines the capability of language transfer of Audio Word2Vec. We train SA from one language (source language) and use it to extract the vector representation of the audio segments of another language (target language). We found that SA can still catch phonetic structure from the audio segments of the target language if the source and target languages are similar. In query-by-example STD, we obtain the vector representations from the SA learned from a large amount of source language data, and found them surpass the representations from naive encoder and SA directly learned from a small amount of target language data. The result shows that it is possible to learn Audio Word2Vec model from high-resource languages and use it on low-resource languages. This further expands the usability of Audio Word2Vec. version:1
arxiv-1707-06012 | Modeling Target-Side Inflection in Neural Machine Translation | http://arxiv.org/abs/1707.06012 | id:1707.06012 author:Aleš Tamchyna, Marion Weller-Di Marco, Alexander Fraser category:cs.CL  published:2017-07-19 summary:NMT systems have problems with large vocabulary sizes. Byte-pair encoding (BPE) is a popular approach to solving this problem, but while BPE allows the system to generate any target-side word, it does not enable effective generalization over the rich vocabulary in morphologically rich languages with strong inflectional phenomena. We introduce a simple approach to overcome this problem by training a system to produce the lemma of a word and its morphologically rich POS tag, which is then followed by a deterministic generation step. We apply this strategy for English-Czech and English-German translation scenarios, obtaining improvements in both settings. We furthermore show that the improvement is not due to only adding explicit morphological information. version:1
arxiv-1707-04444 | Monocular Visual Odometry for an Unmanned Sea-Surface Vehicle | http://arxiv.org/abs/1707.04444 | id:1707.04444 author:George Terzakis, Riccardo Polvara, Sanjay Sharma, Phil Culverhouse, Robert Sutton category:cs.CV cs.RO  published:2017-07-14 summary:We tackle the problem of localizing an autonomous sea-surface vehicle in river estuarine areas using monocular camera and angular velocity input from an inertial sensor. Our method is challenged by two prominent drawbacks associated with the environment, which are typically not present in standard visual simultaneous localization and mapping (SLAM) applications on land (or air): a) Scene depth varies significantly (from a few meters to several kilometers) and, b) In conjunction to the latter, there exists no ground plane to provide features with enough disparity based on which to reliably detect motion. To that end, we use the IMU orientation feedback in order to re-cast the problem of visual localization without the mapping component, although the map can be implicitly obtained from the camera pose estimates. We find that our method produces reliable odometry estimates for trajectories several hundred meters long in the water. To compare the visual odometry estimates with GPS based ground truth, we interpolate the trajectory with splines on a common parameter and obtain position error in meters recovering an optimal affine transformation between the two splines. version:2
arxiv-1707-03123 | SaltiNet: Scan-path Prediction on 360 Degree Images using Saliency Volumes | http://arxiv.org/abs/1707.03123 | id:1707.03123 author:Marc Assens, Kevin McGuinness, Xavier Giro-i-Nieto, Noel E. O'Connor category:cs.CV cs.MM  published:2017-07-11 summary:We introduce SaltiNet, a deep neural network for scanpath prediction trained on 360-degree images. The first part of the network consists of a model trained to generate saliency volumes, whose parameters are learned by back-propagation computed from a binary cross entropy (BCE) loss over downsampled versions of the saliency volumes. Sampling strategies over these volumes are used to generate scanpaths over the 360-degree images. Our experiments show the advantages of using saliency volumes, and how they can be used for related tasks. Our source code and trained models available at https://github.com/massens/saliency-360salient-2017 . version:4
arxiv-1707-06002 | Argotario: Computational Argumentation Meets Serious Games | http://arxiv.org/abs/1707.06002 | id:1707.06002 author:Ivan Habernal, Raffael Hannemann, Christian Pollak, Christopher Klamm, Patrick Pauli, Iryna Gurevych category:cs.CL  published:2017-07-19 summary:An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies. Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to `wrong moves' in a discussion. Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically. The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative. We present Argotario, a serious game that deals with fallacies in everyday argumentation. Argotario is a multilingual, open-source, platform-independent application with strong educational aspects, accessible at www.argotario.net. version:1
arxiv-1707-05987 | Probably approximate Bayesian computation: nonasymptotic convergence of ABC under misspecification | http://arxiv.org/abs/1707.05987 | id:1707.05987 author:James Ridgway category:math.ST cs.LG stat.CO stat.TH  published:2017-07-19 summary:Approximate Bayesian computation (ABC) is a widely used inference method in Bayesian statistics to bypass the point-wise computation of the likelihood. In this paper we develop theoretical bounds for the distance between the statistics used in ABC. We show that some versions of ABC are inherently robust to misspecification. The bounds are given in the form of oracle inequalities for a finite sample size. The dependence on the dimension of the parameter space and the number of statistics is made explicit. The results are shown to be amenable to oracle inequalities in parameter space. We apply our theoretical results to given prior distributions and data generating processes, including a non-parametric regression model. In a second part of the paper, we propose a sequential Monte Carlo (SMC) to sample from the pseudo-posterior, improving upon the state of the art samplers. version:1
arxiv-1707-05974 | Orthogonal and Idempotent Transformations for Learning Deep Neural Networks | http://arxiv.org/abs/1707.05974 | id:1707.05974 author:Jingdong Wang, Yajie Xing, Kexin Zhang, Cha Zhang category:cs.CV  published:2017-07-19 summary:Identity transformations, used as skip-connections in residual networks, directly connect convolutional layers close to the input and those close to the output in deep neural networks, improving information flow and thus easing the training. In this paper, we introduce two alternative linear transforms, orthogonal transformation and idempotent transformation. According to the definition and property of orthogonal and idempotent matrices, the product of multiple orthogonal (same idempotent) matrices, used to form linear transformations, is equal to a single orthogonal (idempotent) matrix, resulting in that information flow is improved and the training is eased. One interesting point is that the success essentially stems from feature reuse and gradient reuse in forward and backward propagation for maintaining the information during flow and eliminating the gradient vanishing problem because of the express way through skip-connections. We empirically demonstrate the effectiveness of the proposed two transformations: similar performance in single-branch networks and even superior in multi-branch networks in comparison to identity transformations. version:1
